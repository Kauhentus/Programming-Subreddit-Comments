Is the server yours or do you need to go through the client? Anyway, I think you're looking for the file /etc/motd, as it's the one displayed on ssh logins.
When in doubt, use _find_ instead of ls. Never ls.
Here's how I'd do it for file in file-[1-9].png file-[1-9][0-9].png; do num=${file%.png} num=${num#file-} mv -i "$file" "file-$((num-1)).png" done
I act as a client. Please see the response given to /u/whetu for further details.
Tried. Presented files in the wrong order. Said "FUCKASSBITCHSHIT" very loudly. Upset the cat. Grumbled and tested and wrote post based on `ls`. Trust me: I don't take parsing `ls` fucking lightly. If you can promote a *portable* way to use `find` to achieve the goal, then I'm all ears. I guess I should add: I have built a *portable* replacement for `locate` using `find`. I'm not entirely unfamiliar with the idiosyncrasies of `find` but I'm always glad to learn something new.
You might be able to save some time by using the non-interactive usage of ssh, namely `ssh user@server1 command`, where it runs `command` and then exits the session. If you use `true`, it'll just exit straight back out. As for capturing the output, a quick test shows that I can capture it with backpacks if I redirect stderr to stdout, so `a=$( ssh host1 true 2&gt;&amp;1 )`. Then `echo "$a"` to see what you captured. edit: this formatting is beyond garbage and I can't easily work out how to fix it. Hopefully you can work out my intent.
It is not my server, I have only user access, no root. To make things worse, *chage -l myname* returns: chage: Unknown user 'myname'. It is not a local user, I assume Active Domain or something.
 ssh -oLogLevel=VERBOSE host1 true Authenticated to host1 ([x.x.x.x]:22). Transferred: sent 3888, received 2792 bytes, in 0.2 seconds Bytes per second: sent 16812.3, received 12073.0 
Browser/reddit ate my edit, sorry. My find-solution would be: find -type f -name '*.png' &gt; listing sort -o listing listing And use listing file as input for a read - while loop. Add levels to restrict recursion. And alternatively use redirection instead of a file. Having done this recently, not only does find mix up the order of things, but for and while loops behave differently in going through items. (It's very tempting to use ls. It's the village bicycle of bash. But you will pay for it eventually.)
Well if you log in and run the following PS4='+ $BASH_SOURCE:$LINENO:' bash -xlic '' You should see some debug output and what file (`/etc/profile` perhaps) and what command is producing `password will expire` output. You could then just run that command directly and parse the output e.g. ssh user@host command | ... Alternatively you could try to force tty allocation e.g. ssh -n -t user@host 2&gt;/dev/null
try [command substitution](https://github.com/learnbyexample/Linux_command_line/blob/master/Shell.md#redirection) vim $(ls | grep testfile) but why not simply use `vim *testfile*` ?
Hm. okay. Did you try just running `ssh -n -t user@host 2&gt;/dev/null` 
This will mostly emulate logging in with an interactive shell and immediately run `exit`. You should get the motd, but also the prompt. output=$(ssh -tt host1 &lt;&lt;&lt; exit)
&gt;output=$(ssh -tt host1 &lt;&lt;&lt; exit) Interesting. It is definitely a step in the right direction. I tried it on another server, no password problems here, the normal message when I log in is Last login: Mon Oct 3 16:59:52 2016 from x.x.x.x If I run it: $ output=$(ssh -tt host1 &lt;&lt;&lt; exit) $ echo $output logout exit/home/noxul17:00:13 2016 from x.x.x.x It is somehow mixed with the prompt. I suppose it is enough, I should be able to see if it contains some keywords.
$(!!) will run the previous command again, but you can use it like so (regardless of what your reasoning is): $ ls | grep testfile $ vim "$(!!)" Always safer to use double quotes. Keep in mind if you want to use this functionality in a script, you will need to enable shell expansion or whatever, which is turned off by default. You can turn it on using one of the "set -" flags, but I forget which, because I rarely use this in scripts. 
So I go around the problem by just avoiding the whole stdin part and creating another file descriptor #!/bin/bash file=nodes.txt password=password.txt exec 3&lt;$file while read line &lt;&amp;3; do sshpass -f $password ssh -o StrictHostKeyChecking=no $line done 
Try `echo "$output"` - the quotes around it might make the output clearer if there are terminal escape codes in there.
xargs will do this. Simple example: (note the different results) ls /var | xargs echo More control.. ls /var | xargs -i% echo we can say % anywhere this way
 $ ls | grep test test $ vim !$ vim test edit to point out this worked because of luck more than anything here as galaktos pointed out.
You want to use the `-v` option for `awk`. awk -v awkvariable="${bashvariable}" [rest of awk statement] e.g. (this is untested and off the top of my head - if it doesn't work, you've at least got your next google clue) awk -v awkn=$n '{print awkn}'
The variables passed via -v can be used as they would in many programmatic contexts. The manners in which I have used them: awk -v t="${col1}" c="${col2}" v="${val}" s="${col3}" \ '$t==$c || $t==v {print $s}' I refer to v as though it is the value to which it refers. The rest of them I use as column index references. They work either way. 
Why is the data stored in one array and not multiple (one for each column) in the first place? Anyway, to split a string, awk is overkill. Just use read. read -ra col &lt;&lt;&lt; "${array[rowNum]}" printf 'Second column is: %s\n' "${col[1]}" 
Good, I'm glad you got a solution. On that basis, I've upvoted /u/geirha's comment too!
Testing for the file is OK, but not for the reason you stated. "never met" should use some value, e.g. 0 (zero) for consistency.
Instead of a file you can have a persistent environment variable (i.e. one that is not deleted after a reboot). Or your script could use a hardcoded value and just overwrite itself with an incremented value after each time it runs.
"never met" could be: * 0 for consistency * no such file or directory for proper init (important)
I am using a lot: find . -name file.txt vim `!!` I expect, that find is searching just for a one file. Then !! is command for bash history: repeat the last command. So at the end it will be expanded to: vim `find . -name file.txt` I prefer `!!` instead its equivalent $(!!), because you can write it just with a left pinkie :)
is that best practice in bash? I figured it shouldn't be too difficult to read data from one array along rows and columns. Thanks for your suggestion, but I already have it working and really don't want to touch it anymore. 
I assume you are trying to do a modulo operation on $i. That line should be this instead: if [ $((i%2)) = 1 ];
 for i in {1..99} do if [ $((i%2)) = 1 ]; then echo $i fi done The above code worked perfectly. Thanks.
This is a cleaner way to do it, IMO: for i in {1..99}; do if (($i % 2 == 1)); then echo "$i" fi done
 ! /deny=([1-9]|10)/ Matches deny=3, or deny=56 or deny=333... This works for deny values from 0 to 99: '$1 ~ /[^#]*/ &amp;&amp; /deny=[0-9]/ &amp;&amp; ! /deny=1[1-9]/ &amp;&amp; ! /deny=[2-9][0-9]/' A more general and arguably sensible solution would be to filter and parse the lines, extract the value and use a condition to decide printing. Meh! Whatever works.
This is the right way 
There are a couple of problems.. Your first pattern will match everything because `*` matches zero more more instances so it will match lines with zero or more characters that are not #. Zero instances of # matches everything. Second your deny pattern will match pretty much all numbers except those starting with 0. Do you want to print lines that don't have "deny=" at all? If not, then I'd suggest the following: awk '!/^#/ &amp;&amp; /deny=(1[1-9]|[2-9][0-9]|[0-9]{3,})/' /etc/pam.d/system-auth EDIT: If you want to print lines that don't have "deny=" then try this... awk '!/^#/ &amp;&amp; (!/deny=/ || /deny=(1[1-9]|[2-9][0-9]|[0-9]{3,})/)' /etc/pam.d/system-auth
And if you're nitpicking you can just do this `seq 1 2 99` And that's it 
But that unnecessarily spawns a new process and isn’t portable.
`grep` "extended regex" doesn't have look ahead or behind. Try: grep -P ... 
Which OS do you use that seq isnt cooked in
no i understand that, i was just giving another method, and most newer distros have it. my original comment was about using if (( )), not the whole method, and that guy thought i was commenting on the whole function, so i offered up a shorter, easier alternative 
I admin some BSD boxes that don't have it, and so I have a step-in function in my `.bashrc` that offers its basic `seq FIRST LAST` functionality if the real `seq` doesn't exist (I have a bunch of functions that do this, in fact). This from a FreeBSD box: $ which seq $ type seq seq is a function seq () { if [[ -z "$@" ]]; then printf "%s\n" "Usage: seq x [y]"; return 0; fi; if [[ -z $2 ]]; then for ((i=1; i&lt;=$1; i++)) do printf "%s\n" "$i"; done; else if [[ $1 -lt $2 ]]; then for ((i=$1; i&lt;=$2; i++)) do printf "%s\n" "$i"; done; else for ((i=$1; i&gt;=$2; i--)) do printf "%s\n" "$i"; done; fi; fi } I went ahead and checked on some Solaris 9 and 10 boxes too: $ which seq no seq in /usr/xpg6/bin /usr/xpg4/bin /bin /sbin /usr/bin /usr/sbin /usr/local/bin /opt/sfw/bin /opt/sfw/sbin /usr/sfw/bin /usr/sfw/sbin /home/[redacted]/bin 
You can use `deny=` as the field separator, then coerce the second field into a number. awk -F deny= '/^[^#]/ &amp;&amp; $2+0 &gt; 10' This assumes there are at most one `deny=` entry per line.
To do the actual copying, `rsync` is probably a good idea. To run the job as soon as a particular device is plugged in, you can probably use systemd hardware activation to pull in a service that does the copying. Something like this in a file in `/etc/udev/rules.d`: SUBSYSTEM=="usb", ENV{DEVTYPE}=="usb_device", ENV{ID_USB_INTERFACES}=="TODO", TAG+="systemd", ENV{SYSTEMD_WANTS}="copy-files.service" And a service like this in `/etc/systemd/system/`: [Unit] Description=Copy files from a folder to a flash drive RequiresMountsFor=/run/media/you/flash-drive-label [Service] ExecStart=/usr/bin/rsync your-folder /run/media/you/flash-drive-label Type=oneshot
I'd be happy to write it for you ... let me know.
Sounds like it would be simpler to use `sed` user@host $ cat file one [P2016TABLE] one two one [END] one user@host $ sed '/\[P2016TABLE]/,/^\[/{ /one/d; }' file one [P2016TABLE] two [END] one So `/\[P2016TABLE]/,/^\[/` matches the range of lines you want then `{ ... }` groups command to only execute on those lines. `/one/d` matches any line that contains `one` and **d**eletes it
Well, you could declare and use a function in the same line: f() { head -n1 "$1" | tr ',' '\n'; }; f filename.csv But if you learn to use readline – the library that Bash uses to read the command line – that might not be necessary. - `^foo^bar` will re-run the previous command, replacing the first occurrence of `foo` with `bar`. For example, you could enter `^csv^dat` to re-run the command on `filename.dat`, regardless of where in the command `filename.csv` appeared. - C-a (read: Control + A) will move you to the beginning of the line. - M-Backspace (M stands for Meta, and usually means the Alt key on most keyboards) will delete the previous word. - M-d will **d**elete the next word. - M-b will move **b**ack one word. - M-f will move **f**orward one word. With those movement commands, it shouldn’t take too long to navigate to the filename and change it. This is also transferable knowledge: a lot of these shortcuts are shared with other programs, especially Emacs.
Is there no way to just reference the variable preemptively? Ie; $head -n 1 {some var} | tr ',' '\n' "MYVAR.CSV" 
No.
&gt; (head -n 1 | tr ',' '\n') &lt; file.csv The bomb. Thanks, I tried that without the parens! Kudos
`${name:0:15}` expands to the first 15 characters of `$name`. (This works in bash, zsh, ksh93 and mksh, but not plain sh.) 
Perhaps there is another way around it. For example if the message is passed through MOTD. Then you can just read the file and check. All speculations however.
This looks like what I was looking for. The main hurdle for me, is that I dont know how to do a column name change in-place. And after that, how to take length of column name into account. I'll try this today.
That's where I'm going with it, but in the testing phase right now- so I'm tinkering at the terminal. Which I why I wanted a fast extensible way to plug in arguments.
Thanks, good snippet to know.
I think it works, and I am wondering how I can use it to scan all the columns in the first line. Here's my code so far. It trims to 15 chars, then prints each column name on its own line. Or it should, but it doesnt trim. (head -n 1 | sed -r "1s/([A-Za-z]{15})[A-Za-z]+,/\1,/g" | sed 's/\"/\n/g') &lt; FRB_G19.csv 
Likely happens when no files are found. Try adding `-r` to the the final `xargs` command: ... | xargs -r chmod a+t
I envy this man. 
If they display a custom MOTD to each user, then it might not be stored in /etc/motd. Try look in your .bashrc or .profile, there might be something in there. Or you can just keep with your current solution if it works as intended.
Try this (WARNING: not thoroughly tested): #! /usr/bin/env bash tr A-Z a-z | while IFS=: read -r firstname lastname; do username=${lastname:0:6}${firstname:0:2} username=${username//[![:alnum:]]/_} useradd -m -c "$firstname $lastname" -d "/home/$username" "$username" || exit password=$(LC_ALL=C tr -dc _A-Z-a-z-0-9 &lt; /dev/urandom | head -c9) || exit chpasswd &lt;&lt;&lt;"$username:$password" || exit echo "$username:$password" done It reads from standard input, so save as a script file and then use input direction (`&lt;`) to feed the CSV file into it. It outputs the usernames and passwords of each accounts it created, separated by a colon. For instance, if you save the script as "gold.sh" and your names in "gold.csv" you can do: bash gold.sh &lt; gold.csv *Edit:* Tested now. This worked for me except for one thing: spaces and other odd characters in the first and last names would screw up the username. Edited to add the line `username=${username//[![:alnum:]]/_}` which replaces all non-alphanumeric characters in `username` with underscores. Also, forgot to actually set the password -- that is what the line `chpasswd &lt;&lt;&lt;"$username:$password" || exit` does.
OP never wrote comma, just CSV, and obviously meant colon separated file ;)
&gt; Also we aren't supposed to use any if statements You might want to let your instructor know that people with professional experience find that kind of exercise pointless and potentially damaging to your education. Avoiding if statements just to avoid them is going to lead you to bad practices. Something like `[ -e "$2"] &amp;&amp;` is not a substitute for `if [[ -e "$2" ]]; then` (or `if [ -e "$2" ]; then`), it's ugly and annoying to maintain. Also your instructor should be telling you to test your inputs, e.g. ensure that `$1` and `$2` contain valid (or any) data. Your instructor _might_ be trying to get you to use a case statement which tests the value of a variable and does something depending on what it is. case "$variable" in 'match1') some_command ;; 'match2') some_command2 ;; *) printf "Unknown option: %s\n" "$variable" 1&gt;&amp;2 exit 1 ;; esac
Thank you, I got it working :)
Instead of looping through and running chpasswd(8) and useradd(8) for each record, you can create a passwd-like file and just feed it to newusers(8) to create and/or update users in batch. man newusers
Awesome that! I knew there was some underlying template somewhere that I wasnt utilizing. I appreciate it- and will be experimenting with this today. 
Well you would use: read input echo $input 
 "${1:-/dev/stdin}" That's an option that I often use... e.g. while read -r line; do ... done &lt; "${1:-/dev/stdin}" You should probably put in checks as /u/commandlineluser has demonstrated to ensure that neither are empty and that you get one and not both, which is also something I've done. Something like: if [[ -t 0 ]] &amp;&amp; [[ -z $1 ]]; then ... elif [[ ! -t 0 ]] &amp;&amp; [[ ! -z $1 ]]; then ... fi
Damn, I think I may try to make something like this. Way more useful than my typical 'recreational' scripting. Great post!
1. Portability.
Speed
To be honest, no. I can't think of any situation where `awk` would be necessarily better than `ruby`, perhaps outside of situational familiarity. It's almost in muscle memory to type something like `| awk '{print $2}'`. It's just more familiar than whatever `string.split[2]` nonsense that `ruby` has. I work on a wide range of *nixes, so portability is a high priority for me for any code that I write. Often I wind up with large functions that walk through multiple methods to achieve the same thing. For example, I have a `.bashrc` function that checks if `shuf` is available, if it isn't it steps in and offers some of the basic capability. First off the rank: `if command -v ruby &amp;&gt;/dev/null; then`... if `ruby` is found, it uses it to shuffle the input. It works its way through a list of two `perl` methods, a `python` method and then a `bash` method.
Each line of the script will be executed as though you had typed it in a terminal. Just remove `run` and the quotes and it should run that command for you whenever you run the script
&gt; Cannot open: No such file or directory Is the file there? `ls -l lynx2.8.8rel.2.tar.gz`
For this, tab-complete is your friend. First, it ensures the file exists, and second, it ensure your spelling is accurate. Do tar xvzf ly[tab][tab]
I think performance is a great point. I did a little experiment and `awk` is way faster! ➜ awk-example time (echo "foo bar baz matz" | awk '{print $4}') matz ( echo "foo bar baz matz" | awk '{print $4}'; ) 0.00s user 0.00s system 86% cpu 0.005 total ➜ awk-example time (echo "foo bar baz matz" | ruby -ane 'puts $F[3]') matz ( echo "foo bar baz matz" | ruby -ane 'puts $F[3]'; ) 0.14s user 0.13s system 61% cpu 0.441 total Also I think the single responsibility principle is super fundamental. However, just curious, how would you sum up `awk` in that context? Like what is `awk`'s "single responsibility" I've had trouble pinning it down. For example: `grep`: search lines of text and print results `sed`: search lines of text and make substitutions `awk`: search lines of text and do...all kinds of stuff the confusion I'm having with `awk` is I don't have an intuition for when I should reach for `awk` instead of `ruby`. However, after the above experiment I at least know to reach for it if I want to "print the Nth field" so thanks for that :) 
Classic? Are you being ironic? tail is a classic of this. AWK is great, but it's a fat Swiss army knife. You could write small scripts entirely in AWK.
 $ apropos -es1p awk grep sed awk (1p) - pattern scanning and processing language grep (1p) - search a file for a pattern sed (1p) - stream editor $ sed(1) does a lot more than your description suggests. An awk program's structure is a sequence of `pattern {action}' pairs, with either but not both optional.
If you don't know Ruby then I expect your Ruby code can be improved a bit, but still be longer than the original awk. That awk was just made up on the fly, being typical of the ad hoc text query one uses it for. It's a small language, but quite powerful, and I'd recommend *The Awk Programming Language*, by the language's authors, Aho, Weinberger, and Kernighan. It's probably out of print and so quite expensive new, but you should easily be able to pick up a used copy cheaply. See http://amzn.to/2dDouxs It doesn't just explain the language, but has interesting programming pearls along the way.
Are you getting any errors?
 find . -type f -name '*.dat' -exec ls -l '{}' \; Breaking that down. Find is automatically recursive from whatever directory path you specify. We specify . which means "the current directory". -type f means search for files of type files, as opposed to directories. -name '*.dat' filters on name. Enclose it in quotes to prevent the shell from pre-interperting thw wildcard. -exec says to apply the following expression to any results it finds. ls -l is the command you want. '{}' says to do the command on the file found. \; terminates the command to be executed. 
Same issue, how can I use it recursively to find filetypes? ls -R .: dir1 dir2 ./dir1: file1.dat file1.ext ./dir2: file2.dat file2.ext I want the output to list the two .dat files and their associated directories.
`history` is a shell build in. `/bin/sh` on Debian systems is symlinked to `/bin/dash`, which is different from `/bin/bash`. Even if `/bin/sh` is symlinked to bash it would only clear the history for the current process. Basically you would need to create a function: $ cat ~/.bashrc ... ... clear_hist() { history -c &amp;&amp; cat /dev/null &gt; ~/.bash_history } ... ... 
Thank you! Edit: Seriously, thank you. Instead of RTFM, which I totally anticipated. You ELI5TFM, much more helpful. 
The thing you need to understand about `ls -R *.dat` is that `*.dat` is expanded by the shell before the `ls` process is executed. That means that all files in the current directory matching `*.dat` will be send as arguments to ls, eg: $ ls a.dat b.dat dir Running `ls -R *.dat` will expand to: ls -R a.dat b.dat As other have mentioned consider using `find -name '*.dat'` instead.
Spoiler: `find . -type f -iname '*.dat'`
Gotcha. I haven't use linux in about 10 years and am now working off a cluster so some of this stuff is a bit foggy (but a lot of it came back quick, which is nice). I was under the impression find needed to have a database setup, perhaps that's 'search'?
No, that's `locate`. `locate` searches your entire filesystem (and uses a database/cache, which may be out of date). `find` just searches the current directory tree.
With GNU find one can also use `find -type f -name '*.dat' -ls`
Find is great but don't forget that grep can do it too. grep -r "*dat" . http://www.cyberciti.biz/faq/howto-recursively-search-all-files-for-words/
If you don't want your session history flushed back to `~/.bash_history` when you exit your session, you can always tell it to write the history to `/dev/null`: export HISTFILE=/dev/null This clears your history for *just that session* (which is often preferable to me, since I don't necessarily need to wipe *all* history... just that which I created on this past session...). I've not encountered a system where this didn't work. 
&gt; find just searches the current directory tree. Super pedantry here, but find searches from the "starting-point", which is commonly specified as the current directory tree (using a period), but could be any directory.
This searches for files *containing* `*dat`, regardless of filename.
Is there some way to just automate upvoting everything that you and /u/geirha post?
Note this will expand all matches in memory, which can cause a huge pileup of used memory, i.e: $ pwd / $ ls */**.txt
No problems with my measly system. Of course I don't often run from root directory. But I tried a few after your post. No problems arose. Test it some more - - - Kudos. Running from root directory with ls ****/******.txt did give an error for ls. Maybe because there are so many text files. However, ***png worked fine. But, for that thorough of a search I resort to find. But thanks good information to have. 
It's something to be aware of that pathname expansions are expanded by the shell, in memory. Might not be an actual problem, but one should consider twice before adding to a shell script, that will last for long.
No, that’s not the point. With `grep -r $pattern`, you’re searching the file *content* for the pattern. OP wants to find files where the *name* matches the pattern. You can do this with `grep`, too: grep -r -l --include=*.dat . . But it’s the wrong tool for the job.
Oh I got it now. It's been a long day/week/month. Thanks for clarification. 
X-Post referenced from /r/linux by /u/xuhdev [Speed Test: Check the Existence of a Command in Bash and Zsh](https://www.reddit.com/r/linux/comments/56w54n/speed_test_check_the_existence_of_a_command_in/) ***** ^^I ^^am ^^a ^^bot. ^^I ^^delete ^^my ^^negative ^^comments. ^^[Contact](https://www.reddit.com/message/compose/?to=OriginalPostSearcher) ^^| ^^[Code](https://github.com/papernotes/Reddit-OriginalPostSearcher) ^^| ^^[FAQ](https://github.com/papernotes/Reddit-OriginalPostSearcher#faq)
Try one of these: http://wiki.bash-hackers.org/scripting/tutoriallist
It looks like you're assigning the action to a variable: #Move the file and log moveFile=`mv $i "${Path}/${newName}"` That should just be: #Move the file and log mv "$i" "${Path}/${newName}"
Post the problem description and I'll give it a whirl. I'm no BASH God, but I've dabbled as a Linux user for years.
Learn about bash parameter expansion to know why `ls -R *.dat` is not solution to your problem.
Which as I said in the post, I was trying to do but cant get my head around using SED to rename the file using variables. 
Well can you show us a demonstration of it only processing the last file perhaps? user@host $ find . ./run ./a ./a/b ./a/b/c ./a/b/c/FB_QuoteRules.2.txt ./a/b/c/FB_QuoteRules.4.txt ./a/b/c/FB_QuoteRules.5.txt ./a/b/FB_QuoteRules.10.txt ./a/b/FB_QuoteRules.1.txt ./a/b/FB_QuoteRules.3.txt Your script apart from using `echo mv` instead of `mv` user@host $ cat run media="01029372" fname="FB_QuoteRules" for i in $(find . -type f -name "${fname}.*") do #Grab the basename and the path name="${i##*/}" Path="${i%/*}" #Build new name newName="MA_${media}_${name}" #Move the file and log #moveFile=`mv $i "${Path}/${newName}"` echo mv $i "${Path}/${newName}" done **OUTPUT** user@host $ bash run mv ./a/b/c/FB_QuoteRules.2.txt ./a/b/c/MA_01029372_FB_QuoteRules.2.txt mv ./a/b/c/FB_QuoteRules.4.txt ./a/b/c/MA_01029372_FB_QuoteRules.4.txt mv ./a/b/c/FB_QuoteRules.5.txt ./a/b/c/MA_01029372_FB_QuoteRules.5.txt mv ./a/b/FB_QuoteRules.10.txt ./a/b/MA_01029372_FB_QuoteRules.10.txt mv ./a/b/FB_QuoteRules.1.txt ./a/b/MA_01029372_FB_QuoteRules.1.txt mv ./a/b/FB_QuoteRules.3.txt ./a/b/MA_01029372_FB_QuoteRules.3.txt The way to do it using `-exec` would look like user@host $ find . -type f -name "${fname}.*" -exec sh -c 'for i; do name=${i##*/} path=${i%/*}; echo mv "$i" "$path/MA_${media}_$name"; done' _ {} + mv ./a/b/c/FB_QuoteRules.2.txt ./a/b/c/MA__FB_QuoteRules.2.txt mv ./a/b/c/FB_QuoteRules.4.txt ./a/b/c/MA__FB_QuoteRules.4.txt mv ./a/b/c/FB_QuoteRules.5.txt ./a/b/c/MA__FB_QuoteRules.5.txt mv ./a/b/FB_QuoteRules.10.txt ./a/b/MA__FB_QuoteRules.10.txt mv ./a/b/FB_QuoteRules.1.txt ./a/b/MA__FB_QuoteRules.1.txt mv ./a/b/FB_QuoteRules.3.txt ./a/b/MA__FB_QuoteRules.3.txt
Focus on learning the terminology. You will get much better results from Google if you know what to search for.
Oh I'm a dummy. Another issue is the variables are not visible - you'd need to `export` them before the find command. export fname media find ... (It was blank in my initial example too but I failed to notice - oops)
Well you seem to have several replies in that thread already. Are these just logs for a single day? Are there no dates? Is it possible to have the following? [11:10:02] User logged in [01:10:22] User logged out
Interesting tests... You are right about the Debian's which -- it is the script in the link you gave. For the RHEL version, which is the GNU's implementation of `which` by Carlo, seems more complicated and has more features (See [here](http://cvs.savannah.gnu.org/viewvc/which/which.texi?root=which&amp;view=markup) ) and is understandable if it is slower than Debianutils.
I have something here that some people might find usefull in combination with this script: https://github.com/Knusper/flickerfavsaver.sh Bash Script. Downloads Flickr!-Favorites from your Flickr!-Favorites RSS Feed
put your script somewhere so we can replicate the issue (e.g. http://gist.github.com/). Also, use explicit and meaningful variable/file/arg names, disk's space is not an issue anymore, cognitive load is, i.e. KISS.
Thanks for the input! Is there an accessible example that you would recommend I try first? 
I'm not sure if this is exactly what you are looking for but it might be enough of a start: echo atgactatgtcaag | ( read seq; while egrep '^.+atg' &lt;&lt;&lt;"$seq"; do seq=`echo "$seq" | perl -pe 's/^.+?atg/atg/'`;done;echo $seq ) | sed 's/tcaag.*/tca/' Not sure about your step 3 but I interpreted as finding the first occurrence of the sequence "tcaag" and trimming starting from "ag" to the end of line so if a line has "atgactatgtcaagatgact" you would get: atgactatgtca atgtca atgact EDIT: Oops... I think this is actually what you want instead echo atgactatgtcaag | ( read seq; while egrep '^.+atg' &lt;&lt;&lt;"$seq"; do seq=`echo "$seq" | perl -pe 's/^.+?atg/atg/'`;done;echo $seq ) | perl -pe 's/(tca|aag).*/\1/'
that's weird atom linter-shellcheck doesn't show any error [1], yet shellcheck does detect them. 1: https://github.com/AtomLinter/linter-shellcheck/issues/82
fixed
As describe in the README either: * copy the function in your code, then call it ; * save the file in your project, include it your script then call it source ./progress-bar.sh
Please don't. ~~Also `exit(status)` is a GNU awk extension.~~
The original production scripts were written on Ubuntu 16.04, which is bash 4.3.46(1)-release, and they worked fine. I moved them to our shiny new CentOS 7.2 server and that's where I found the issue. Thanks for running the scripts, I don't suppose you notice any issues with how I'm using traps?
I don't understand, it is supposed to be an opinion?
Actually it is not. Just found this by accident: https://github.com/koalaman/shellcheck/wiki/SC1014 &gt; [ is just regular command, like whoami or grep, but with a funny name (see ls -l /bin/[). It's a shorthand for test. Try which [
Well, the issue is that '[' is a binary file. On the other hand, it cannot be used properly without ']', which is chosen in such a way to mimic standard syntax for brackets or parenthesis. So, is it simply a binary or a binary that is used as syntax for bash?
 user@host $ echo $SHELL /bin/bash user@host $ type [ [ is a shell builtin
It can be used as test without ] no?
$ type -a [ This will show you all available [. There is both a binary plus a bash built-in. There are a number of commands out there which have multiple versions, like echo. The which command only shows binaries, similar to type -p
Not even a full page and then a next button? Are you payed pr. page view?
Sure thing, just throw this in a text file and you're all set: ctcgaggaccggcgcatccgcggctcccctcctggctggtcgctcgcccggccgtttcctggagtggtgacctgcgctttcattgagataaggggcggttcctcggagctaagcggcggaaagagcctcttaggacgaaggccgtgtgcggcccgtagagaaccccgcacggatctgacacctgggagacgcgccgtgaggtgatcgcgcgcgagaggggccaccaaggggcggtacccctcttcctgcccggtggccgtcttatcggttgatccgccgttgtgggctcaccggaccttgcggtccggtccggcagtgcgtcgcctccggaggccggaccctgtgggctggtgtaggccatagcggcctcctactagcgacccctccgctgcgctccggggctacgggctacgcttgcgcacacccccggcgggctcctccggacccccgcccgccggggcctggtccccgctgctgcccggtacctaccgcacccccacccagcgacgtgcgcacgcgcgccacctcgggctgggccctccctggtgcgggtgatcaatggcgggggaatcgacctcagccacagaggcaacccctgcggcgggggcgacaacggcggcggtacggaggtacctcagccgcccaggcaggacgacgcttccttcctgcttgtggccggccgaggacagcgtgcggtcgccaggtgatcaggtggcatcagtcgggacccgcaagcccgccagggctgaggactcgccgactaggcgccgacgaggaccaggtgcgcaggaccgccggccttccccgtagaagctaagaggcccggtatgccgggcgggtaggagtccagggcggtcaccacggtgtgcgccgtggtgtgagtgacggcgcgcgccttctagtgaagaaggggcgcatgctcttgacctggtaaagcgcggctaagcggctaaaaaccgccggttactgggtcaaaaatcgccgcttagctacaccgtgcgtccctcgtcgcgcccggtcgccaggaagtcgcgtcacctatgcgtgtgacacgcggactaagcggctgtttttcggagtggtgacctgttagtttcctctcgtaagcggcttcatcggagctaaggggtcaaaaaccgccccttagcgcgaggatgggagaggcgcgagccgacgaggaagcgcgggccgaacatggccctggtcaacatggacaccggagaggcggtccgccaggccgcggactccgcaccagttcgacgggaaggggtacaccttgcaggccaggcagcgacgtccccctgtactccctcgggctggccgcagcggagtgggcgacgctcatggctccgcgaacacggaggcgcggccggatacgtcccggtcacgcccgaggagctgcgaggacgtcggcgccagcaaggacacctgccggaaggcccttaaccggctggtcaagcgggcttgtggtcaagccgggcccgcgatccggctcttaccagctgaaccccctccgactgggagggagccgggagcacgcaggtcaacgcctgccgccgcatggcgccgccgcgttggccccggacgacaaggccatgaccaggtccgccagcaagcccaagaccatcccggctcccgccgccgcgccgcaggagagacgcgatgacgaccatgcccgtagaaggcttcaaccggagcgcgacctgaccgccccgtcgctgtactcgctgaacctgtccgccgctcagcactcacgctcgcgtgggtggaggaccacggcggcctgtttgacgtcatccccgtaccggtcgaaccgtcgccgaggactgcggcaactccgtctccacggtgcacgaggctctcgcccgccggaggccctgaacctcctcgtgcggacctccgccggcctctaccggatcaacgcccggtctacttcacgctgcaccccgagctgcgcgagatgatcaccgccgccctcacggacccccggtcaccccggacgaccgtgcccgcgcgccccgcaaggtcagcaacaccgacgctcgccccgccggacgatccgccccgtctcttgaccgcacaacacagcgcccccgctccgatctccacggagcgggggcgctgatctatgtgccagacggtcagttgccgccctgtacgggaggagctcgaagccttcaggctgctcgtgtccatcgccaacgagcgtctgcgtcacggccagacgtcgcccttcgcgtcgtactggacggtccggtacagcatcacaggcttgctcgcggaggcggaaggccgaagtcttcgcactcgaaccaggcgagcatccgagcggtcagggtgcgtccagccggacgcaccccggaatcgtgggggccacaggcgttagagccaggtccggcgaacgcgcggcggcgggatcgggagcccaagacctggcgcaagcctccgcaccgtctcactacgacggccaccgggtcaccaaggctggtcaggtcgaaccactcgccccgccggttgtgtcacggaactcctggtggagcgccccctcaagggcgcggccgccctcgcacgtccacagaccgacagcgtcagcggcagaccggtctgcatcgtgcggactctcctctccacgtctgtcgtggtgccgatcttcaccaggtctaggccctcggctcctaagagatagacgacttccgaggcttccgggattgggtcacggggtgatcctccaagggtgtgttggctctggtgcggcaaggaccgcccccgttccggtggctgcggaaggggggcggtctcgtgtccgggcggggccgcctacgcctggcctggcttgagcgacgcggcggcggcccgggccgtgccgaacggacgccgttgaagtcgggggcctccgccgtcggctcctcgtcgtcgccgtacggcagcacgtacaggagtgcagataggccggaccgtgccggtgcacctcgccaacgaaccggccctcccagccaccagatagggcggctccatgccgtccagcgcccggtagaccaggccgtgcgtggccgtagctcccgcaccacctggaggcggaccagttccgccgccgacctctccagcgtctcctgcgcggccgcgctggcggtgtccagctcgttcgtcatgacgtgctcccctcggctccgtcgcccggagtggcaggcccttgtaggtcagcgtcagcctgtcagccgcgcccgtgtgagggtcagttccaggacacggaccgtcgcgtcgtaggtgacgcgctcgacgaccaggaccacacgcgggagccgagggagagttccgcggcttgctgcgcggacggcacccacacctcgcgtcgtggtcggtggacgtcggcgaaaggccggcgcccgtcatggcaccgaggacaccaccacgaccttccccggccggtccaggccggcggcccgggcgatctccagcgggtaccagcgtcttggagctggacgacgtcctcgccgatcgtggcgcggcgccgccggtggacgaccgggcgcccggctcgatgccgaggcgcgcggcgacgtccgccggggccccgacctcctcggcgcctccacgagcatccggccgtcaaggccctgcgcggccgtcgcacgctcccacgggccttatcgccgcccggcgccaggacgtcgccgtacgtactgaacggcacccgaacccggacatgtcccggacgatcgtgcccacgcccggcttggagaccgtccggccctcctcctggggagccggaacgcccggttcaccgtcgtgatcgccgaaccgaactggtcgcacacgtcggcatggagggcagcgggtcgccaggggacaactcgcccgagtccatgagccgccgaaaggcgcggcgatttcctcatagccgccagggcggcccttccgcctagtcgccatcggtccctcctgctcatcgtgctgacgctcttgagtgtagtgcttgcgattccttaagtgtagtgcttacttaagcccagaggggccaccacgcaccgaagcgaggtgatcactcaacgcccggaggacagcactgacggtggtctcgaaggaagcgacagcacgttgataaccgcagatcagggccacgccggtaacccgtggaccgccagccttcgagcgtgtgggaggtcggaaacatggcgtgaagaccggcaccgacggctccgagtcgtcgcggtccagcacctcgcgcgtcacgcggtcgtgccggagccgcgcctactcggcaccccggccgccaggggcgatagcagcgccccgtggccctcgcacgaccagcaccagtcaccaggaggcaccaccatgatccgtagcgtcacacccgcgcgcgtcgcgccttccgcaccgtcgccgacgccgtccgctccaccgtggcccggcctccctggtccgctcccgcgccgacgagacggcgcccgacccgaccggcctcctggtccggaggagatcgaggcccgcgccgaggagatcgaggacgcggcagccgactacgccgcgccaccgaccgggcccgctccggagaccggggcaagcgcaaggcccgcaagctcctggccgccttcccgccgggcgttacggcgtctggaccgtggagcgcgtcccgtcctcgcggcgaccccggacctggaggccatccgcgccacctacaagcggctcgggctcggggacgtcccatgcggacctgcgcgccctcgctgcgcgtcacccgggccgccgctgacgtcgtgccctcccggccgccgacgaggccgccacggcgcagctcgccgcctgaccagacctcaccccccccggcccccggcacccgccgggggccttcgcacgagacgagagggaccgaccgcatgacgatgacgttcacgcgcacccgatcgaccagccgctctacggccgcaccgccgacgccatcgggaccagctccgcgagcacccggaccccggcggcacactctcccggatgaccctccggtgagcacggacggcggccgctcgtacggcagcgccgtgaccgaggccgtcgaccacgaacggcatgggagaacgcggggccgctgggccttgggcccggcccctggccgccctgccatgcccccgccaccggggcgccggccttcccggcccccgcggctgaccagacacgacgacgcccccgaggcgatagcagcgcctgaaccgggggccgtgcccgcgcgcaccaaccgaataccaggaggaacgacgcatgacggaccgtaccaacaacctggccacctgccccaccgacccgacccggacatggacgaggccctgcgccgcgtccgccagggcaagcggtgaccgccggcccgaccgccccgagcagccgcagcgcaccgtccccccgcagcgccgccgcatcgtcgcgtgccgacgccgaccccgatgccgccgctgccccgggaccccgccgcccgccgccgggcatccggcagcgcccgatggtgaccggccgccggcctccgcgtcggctgaccgtccgcgggccgccgccgtcctggtcctcaccgtgcacgccacggcctggctggcgtctcatcgtcagccgtccgtgcccacggtgctcacctgcttgtcggcgtacggcgccgcgctcgccacctcgccctggtcctcaccgccgggcgagacggccggacctgaccgaccttcgggcgccacgcggccgccacaccccggcttcgggggcggcggccgccgcttcggacacttcgcccgacatcacccggaggacctgatgaccctcaccaccctgcccctcagcaagcagcgccccggcccactccgtcctcgccgcgccccgcttcggacgcgccgcccacggcttcggccacgacgccgccgcttcgagcccggccgccccggctccggagacgaccgcgacggctccgggcacggccgccgctggagtctccccggcgggctcacccgggcgcagtcggccaccgccggagcgtcgtcctcgccgccctggcgctcgccgggatcggcctctacctctccttcgagcacgtcccacgttcgcgcacgaccggctcgggttcgccacgctgggcaaggcccggctgttcacgtcggcgtcgacgtcggcatcctggtcctgatcgccctcgacctgctcatggcgtggctgcgccgccccatcggctgggtccgctttcccgtgtggctgctgaccggcgcaacgatcgtctcaacgcggcctccgccgccccgtcggccggcgcctggaccgccctggactacgtggcccgttcgcccacgcgatcgtgcccgtgctgttcatcgccatcgtggaggtcggcaagaccccgttgaccgcgtggtccgccccgacgcccacaacggcccgggcgtcccgctctaccgcggttcctcgcccccgccccgaccttcgccctgtggcgccgcatgaagctgtgggcggtcccacctacgcggaggccgtggagctggacaaggagctgcgcgtctaccgcgtcatgctgaacgcgaatacggcagcgtccgcaaggccccctcggacgtccggctgcccctcaccatgagcggtacggcctgaccatcgcggaggccctggcgctcccccggcaggccgaggagcgccgcaggccctccgggaggccgaggaggacgccaggctcgccgaggaggcccgcaagcagagcgggccgccgccgccgagatcgcccgccttaaggccgctggagccgtccaagccgccgtaccgaggtgaatgcgtcgaccagccgcgcggaggtccaggcggccgccgaggtcgccccgccgagcgggccgcgaccgccgagacggaggccgtccagtcggaggccgccgcccggccgaagccgaccgcgcggccgccgagcaccgcgccgccgaagcccgccgccgcgcggccaagccgacgaggccgcagccgaagccagggcccgcgaagccgaagcggccctcactgcgccgaagacgaggcccgcacggcggccgccgaggccagcaccgaggaggcccgggcccgccctcccaggcacagcgggacgcagccgaagccgagcaggccgccgccgaagcccgccacgcgcggccgaagcggagcgccgggcggtcgaagccgaggacgaactgaccctctccccggtgaccgcaaggtccgcaaggtggcccggatgatcctcgccgagggcgccggacacccgagaacctccccctggagtcggtcatgaccgcctgctccgtctcgcagacgacggcctcgagtaccggtcggccgccgcgcagctcctcgccgagggctacaccccggaggcccgctgaggcccgcagccgcgtcaagccacgcgcgccgcgccgagcgcccgaggagaacgtgcccgccagctcgggctggtcggctccgccgacccctggcagcccaccggctgccgctgctggcgcccgacaaccgcggctgtggccactgccggacctgctctgcctgccaggactgcggagcatgcc
Are you referring to the `bash` string slicing using `${name:pos:len}` method? If so, then just omit length if you want to get position 65 (zero based) to the end of line. The begining is 0. So: line="abcdefghijklmnopqrstuvwxyz" echo "${line:12}" mnopqrstuvwxyz echo "${line:0:12}" abcdefghijkl Here's a neat one.. you can reference from the back of the line if you want: echo " ${line: -10:4}" qrst Note the space before the negative sign is important since `${name:-value}` means something different.
Sorry, it was not meant to be an actual expression. I probably shouldn't have used coding format for it. Thanks for the help.
Without wanting to take away from OP's achievements, you may want to look at googling `tool + pv` e.g. `cp + pv` or `wget + pv` You might find that certain tools, such as `wget`, have some progress bar goodness built in already (and/or their alternatives like `curl` do). `cp` can be replaced by `rsync -ah --progress source destination` and so on. Then there's this, which has the downside of being an external dependency, if that's an issue for you: https://github.com/Xfennec/progress
Well you would either have to read all of the lines into an array - or else keep a count of what line number you're on and use a tool such as `tail` You could use `mapfile` to read the whole file into an array (or use a `while read` loop if you don't have it) mapfile -t lines &lt; input.txt for ((i=0; i&lt;${#lines[@]}; i++)) do [[ ${lines[i]} = atg ]] &amp;&amp; printf %s\\n "${lines[@]:i}" &gt;&gt; output.txt done You can use `tail` to skip the first `n` lines e.g. to start from line #3 user@host $ printf %s\\n {a..e} | tail -n +3 c d e 
Would these go within the if-then statement? Or replace it altogether? Also, thank you.
It's a command, a built-in one, yes, but it wouldn't appear in the AST for the language. Therefore it isn't syntax.
Yes the mapfile + for loop would replace your while loop. `tail` would be something you could insert into your while loop if you kept a line counter 
That's fine by me, it's not really the purpose of my progressbar to support this kind of scenario. It's more of a countdown progressbar. You could estimate the duration of the copy but that would be a twisted approach when in fact there is good tools to do that as suggested by @whetu
Okay, awesome. Is there a way to put a blank line at the end of every print? So we can tell the difference between each loop?
You could track the line number in parallel, starting at 1, and on a matching line do `sed -n "${n},\$p"' input.txt` to print from line $n onwards.
Thanks! Not the cleanest, but I think this does what you want #!/usr/local/bin/bash #created: 10/13/2016 # Script reads though a fasta file line by line. It keeps line that contain the # sequence atg, and removes everything appearing before the first atg. It then # prints all the substrings that start with atg, trimming them at the first # occurance of the substring tcaag for line in $( egrep -o 'atg.*$' "$1" ) do more=true while $more do if [[ $line == *"atg"* ]] then line=$( egrep -o 'atg.*$' &lt;&lt;&lt; "$line" ) echo "$line" | sed 's/tcaag.*/tca/' line=${line#atg} else more=false fi done done I'm not the best at bash scripting, so it may have weird syntax patterns...if so I apologize in advanced. Edit: Here is the output, btw: http://pastebin.com/006tnq1E
Hi, thanks for this, it works fine and prints the result to the terminal however if I tell it to redirect to a file just seems to copy the content of the original file to the new file. perl -pe 's/(\d{11})\d{7}/"DATE-AD(".scalar(localtime($1-11644473600)).")"/e' computerlist.txt &gt; newcomputerlist.txt 
Well that doesn't sound possible :-/ Are you sure you're checking the correct file? user@host $ cat computerlist.txt ben:131159832017796720 james:131208206662986978 mark:131146980431414623 user@host $ perl -pe 's/(\d{11})\d{7}/"DATE-AD(".scalar(localtime($1-11644473600)).")"/e' computerlist.txt ben:DATE-AD(Thu Aug 18 09:40:01 2016) james:DATE-AD(Thu Oct 13 09:24:26 2016) mark:DATE-AD(Wed Aug 3 12:40:43 2016) user@host $ perl -pe 's/(\d{11})\d{7}/"DATE-AD(".scalar(localtime($1-11644473600)).")"/e' computerlist.txt &gt; newcomputerlist.txt user@host $ cat newcomputerlist.txt ben:DATE-AD(Thu Aug 18 09:40:01 2016) james:DATE-AD(Thu Oct 13 09:24:26 2016) mark:DATE-AD(Wed Aug 3 12:40:43 2016)
Haven't read it yet, but noticed this garbage on page 4: &gt; [user@computer bin]$ ls | grep vim mken&lt;strong&gt;vim&lt;/strong&gt;age r&lt;strong&gt;vim&lt;/strong&gt; &lt;strong&gt;vim&lt;/strong&gt; &lt;strong&gt;vim&lt;/strong&gt;diff &lt;strong&gt;vim&lt;/strong&gt;tutor I don't care about the broken syntax highlighting, but with the fact that you are parsing the output of `ls`. [Don't do that](http://mywiki.wooledge.org/ParsingLs).
Hi thanks again, I think I was not clear with my previous reply, it works fine from the command line but as soon as I try to add that line in my bash script it fails.
Can you show your script?
#!/bin/bash -x ldapsearch obfuscatedldapinfo sed -i -n -e '/name/{p;n;}' -e '/last/{p;n;}' computerlist.txt perl -pe 's/(\d{12})\d{7}/"DATE-AD(".scalar(localtime($1-11644473600)).")"/e' computerlist.txt &gt; newcomputerlist.txt
Definitely sarcasm.
.... I have no idea how that got changed. Thank you.
Thank you so much, man. One last thing: is there a way to make it stop recording and start from the beginning once it hits a specific matching line? Say, tca or something like that? Thanks again.
Never mind! I solved my own problem. It may not be the best, however, but it gets the job done. If you guys want to give it shot, by all means :) mapfile -t lines &lt; input.txt for ((i=0; i&lt;${#lines[@]}; i++)) do [[ ${lines[i]} = m ]] &amp;&amp; printf %s\\n "${lines[@]:i}" "&gt;" | tr -d '\n' | tr '&gt;' '\n' | cut -d 'X' -f 1 | sed 's/$/X\n/g' &gt;&gt; output.txt done
So you want this: m 1 2 3 X 4 5 6 m 7 8 9 to print this? m 1 2 3 m 7 8 9 Then you should use a flag that toggles (here I use the variable `doprint`): doprint=yes while read -r do [[ "$REPLY" == m ]] &amp;&amp; doprint=yes [[ "$REPLY" == X ]] &amp;&amp; doprint=no [[ "$doprint" == yes ]] &amp;&amp; echo "$REPLY" done &lt; input.txt &gt;&gt; output.txt
Hmm.. i'm not sure I follow? perhaps some input/output would help..
This. Keep it simple guys. 
Don't reinvent any wheels unless there's a really good reason. Monitoring/alerting has plenty of options e.g. check_mk
And I meant to include that if you were providing great full paths for both you were looking for the home folder to be within the home folder at the level of the file. Toss in some echos to check your progress as your variable changes. set -x will also help but I find that overwhelming at times, especially for simple things. You can also toss in an exit if you are just checking something and don't need the full script to run. 
thanks for the advice!
first make sure that your script is executed with the correct shell by making this the very first line: `#!/bin/bash` And make the script executable. Now, if you want to know how bash interprets your script (for debugging purposes), put `set -x` above the lines you want to examine. You can put `set +x` below the block of code to turn it off again if you want. To debug the whole script you can ditch the `set` lines and add ` -x` add the end of the first (hashbang) line. a few comments: * shell does what you tell it to do, not what you intend it to do. * start the script with putting the `$1` and `$2` values in variables with meaningful names. * don't use `..` in absolute paths. It can be useful, but not in the solution for this assignment. If you meant it to mean 'somethingsomething' in an example, then use `...` * how about a variable `add_comma` (value 0 means 'no comma', 1 means 'add comma'), instead of testing again what has already been tested.
Interesting, i have never heard of/ran into that before. I'll provide an alternative 
Here is how I would write the script. Call it like this: shellscript /path/to/ file --- #!/bin/bash # Assign the arguments to vars. This makes the script more flexible and clear. dir="$1" file="$2" # Concatenate the two args together to form the full path. path="$dir/$file" if [ -d "$dir" ]; then echo "Directory exists: $dir" else echo "Directory does not exist: $dir" exit 1 # Since this is an error state, why continue running? fi # Don't put a newline in a quote unless absolutely necessary. # They make indenting more difficult. echo # Use -e instead of -f because -f only tests regular files. if [ -e "$path" ]; then echo "File exists in the directory: $file" echo "File properties: " else echo "File does not exist in the directory: $file" exit 1 # Since this is an error state, why continue running? fi if [ ! -r "$path" ] &amp;&amp; [ ! -w "$path" ] &amp;&amp; [ ! -x "$path" ] then echo -n "No permissions." # Permissions, not properties. fi if [ -r "$path" ]; then echo -n " read" fi if [ -w "$path" ]; then echo -n " write" fi if [ -x "$path" ]; then echo -n " execute" fi echo if [ -k "$path" ]; then echo " The sticky bit is on." else echo " The sticky bit is off." fi if [ -s "$path" ]; then echo " The file is not empty." else echo " The file is empty." fi
Yeah, I get what you mean. I'm the *nix sysadmin who would much rather be automating things in Ansible as the interesting challenges that dominate my days, but instead I'm constantly sidetracked fixing up other people's scripting fuckups. That said, I work a lot on non-Linux unices, and so I've had to write a whole bunch of scripts and functions over the years to provide certain capabilities (fuck.you.so.much.Solaris). So certainly there have been some interesting challenges replacing GNU luxuries like `shuf` and `timeout`, or a core subset of what those binaries provide. I wouldn't ever go so far as to try and replace `test` though... That's time to-get-a-new-shell material.
The `PATH` can contain any number of lookup paths, separated by colons. Each of those `PATH` assignments includes the old value of `PATH` at the end (except that the one for Python.framework is typoed; I hope that’s not in your .bashrc?), so they add paths to the `PATH`.
Now I'm curious why you would need `shuf` to do 'work'... :P
This is a good guide. In case another perspective is helpful to anyone, I've also written a little on the topic of bash completion: - [Bash Completion, Part 1: Using Tab Completion](https://spin.atomicobject.com/2016/02/13/bash-completion-tab/) - [Bash Completion, Part 2: Programmable Completion](https://spin.atomicobject.com/2016/02/14/bash-programmable-completion/)
No problem, you’re welcome!
There is also: http://mywiki.wooledge.org/BashFAQ/045 and http://wiki.bash-hackers.org/howto/mutex Particularly useful for the alternatives when `flock` is unavailable. You could also probably improve your library-esque solution by adding a `trap` for exit to call `eexit`, and then add stuff like `set -fue` to your script to ensure that errors exit.
Thanks! &gt; Particularly useful for the alternatives when flock is unavailable. I did recently find what looks to be a good cross-platform `flock(1)` implementation, too: https://github.com/discoteq/flock &gt; What makes discoteq flock(1) different is: &gt; &gt; - Support for latest stable Linux (Debian &amp; CentOS), Illumos (OmniOS &amp; SmartOS), Darwin &amp; FreeBSD &gt; - Testing for all major features and edge conditions &gt; - ISC license &gt; - Public access to source history and bug tracking
Hmmm. I just create a file in /tmp or exit of it exists. At the end of a script I delete this file. ELI5 why it's a bad solution? I'm not a programmer. 
some more info about race conditions and locks in *nix for better understanding http://www.tldp.org/HOWTO/Secure-Programs-HOWTO/avoid-race.html
You should handle cleanup of lock files with signal handlers and place them in unshared directories like /var/lock and have proper permissions as well as write the PID to the file. Generally when the program crashed unexpectactly you should have to troubleshoot manually anyway and delete the lock file if it hasn't been deleted.
The node.js script is actually a tradebot for steam. Since it crashes sometimes for multiple reason, I want to restart it every now and then (not every minute though). On windows I used a batch file like: :START start node "MainBot.js" timeout /t 3600 taskkill /IM node.exe timeout /t 30 goto START And now I am trying to recreate this for my RaspberryPi. &amp;nbsp; &amp;nbsp; I know, the n°1 solution would be to fix the bugs that crash the script, but I had a professional check my code and he didn't find the reason since it's probably being caused by my network connection or the connection to Steam itself. Restarting the node script like once every hour would be a working solution - even if it's not the best!
I think this worked! &amp;nbsp; #!/bin/bash while [ 1 = 1 ] do echo "Restarting..." node script.js &amp; sleep 300 killall node done &amp;nbsp; This restarts the script every 5 minutes for example! :) Thank you! (And to all the other guys!) :) &amp;nbsp; And in general: I am sorry for this poor solution. I need this to run for two or 3 days and I don't have the time to learn much about linux. It's a temporary solution! ;) 
I found something that works (see the first comment). Thank to you also! :)
&gt; while [ 1 = 1 ] If you want something that will always return true, just use the command 'true'. while true; do ...
Oh. Didn't know I could do this! Works just as well and might be the cleaner version! ;)
This doesn’t sound like a Bash-related problem, so you might get better help over at /r/linuxquestions. But you could try “poor man’s scp”: tar cz path1 path2 | ssh laptop tar xz or, for a speed test: dd if=/dev/urandom status=progress | ssh laptop 'cat &gt; /dev/null' (requires a recent GNU coreutils `dd`for `status=progress`). If those commands are significantly faster than `scp`, there’s probably some `scp`-related problem.
Thanks, I wasn't sure it was a problem with how scp specifically operates under different conditions or if thr problem is entirely external to it, either. Knowing how to test that is really helpful in ruling things out and eventually narrowing down the answer. I considered r/linux too but since the problem exists in OSX too i was afraid they'd flay me for a heretic haha. edit: originally linked to r/linus by mistake. i haven't been but i really hope it's dedicated to the Charlie Brown character. 
Sounds to me like you just have slow wireless. Try plugging your laptop into the WRT54GL via ethernet and measure again.
Had a similar problem this week, except I wanted to wait until the lock get released to resume blocked run (instead of quitting). Here is what I did: while ! mkdir /tmp/mast.busy 2&gt; /dev/null; do sleep .1s; done # waiting for lock to free # do what I need to do… rm --recursive --force /tmp/mast.busy Here is the test to validate my implementation: https://github.com/Coaxis-ASP/opt/blob/02610f9fa69be7265a34ebb7f62a595be6a1e357/daemon/test/add-channel.tests.bats#L81 Feel free to point any loopholes.
x-posting to [/r/commandline](/r/commandline)
Check '-c' for uniq: tr ' ' '\n' &lt;&lt;&lt; ${a[*]} | sort | uniq -c It will prefix occurrence in front of array's number, you can send it to another pipe to sort -rn to see top occurrences.
No probs, glad it helped. I've been using Linux for more than 10 years, and still learning - even now I have to trial-and-error a lot to get what I want out of awk and sed... wish it wasn't the case :-)
You could use an associative array and increment its value each time you see a hostname: declare -A hostnames for …; do … let hostnames[$hostname]++ done For sorting them, I’d fall back to `sort`: for hostname in "${!hostnames[@]}"; do printf '%d %s\n' "${hostnames[$hostname]}" "$hostname" done | sort -n The number of host names is `${#hostnames[@]}`.
Needs more context because it sounds like you're reinventing a wheel. logcheck/logwatch/swatch are all well established things. Graylog2 can do some alerting too.. The next step is what you're alerting to? Nagios has the sendalert.sh script, for example. Tying the whole lot together is very simple...
Yeah, there are a few pretty popular style guides out there for bash, even one from Google. They all go over things like this, some of which enhance performance and many others that are simply easier in the eye.
Hopefully you're not planning on running any other node processes on that machine in the meantime. It should also help you in the future to learn that you meant "shell", not "terminal" in your OP. Xterm is an example of a terminal while Bash is an example of a shell.
Just my small effort into finding the functional patterns in bash. Any other patterns that I have not covered yet are welcome and will include them
&gt; On the outside it seems it feels like this should be easy. But in reality this is very hard to implement and reason about. That's because bash is a procedural programming language, not a functional one. If you want a functional programming language, you should use a functional programming language. Scheme, Emacs lisp and Clojure come to mind. &gt; As you know all variables in bash is global. this greatly hampers code reading. Nonsense! It's well known that bash supports function-local variables. Look up the `local` builtin. Your unnecessary workaround with forking command substitution subshells works, but badly hampers performance. I'll not bother with the other bad practices in your coding examples, but do run them through [ShellCheck](http://www.shellcheck.net/).
The section on referential transparency is completely bizarre, and I have no idea what it’s supposed to mean. I suspect the author just saw “referential transparency” listed as a property related to functional programming and wanted to put it on the list. But all the example shows is that if you do the same operation with the same input, you get the same output. That’s determinism, not referential transparency. It also makes no sense to refer to “a program’s programs”, referential transparency goes beyond algebraic equations, and arithmetic operations are not a significant part of typical Bash scripts. The same goes for the section on lazy evaluation, and I’m rapidly losing any motivation to even comment on this charade (like /u/McDutchie, I assume), but a for loop is not an expression, `seq` is an anti-pattern in Bash, and the differences between `[` and `[[` are manifold but entirely unrelated to lazy evaluation.
That looks very odd; I suspect you have some non-printing characters in there somewhere. Try removing the whole line and typing it in again (by hand). EDIT: Or perhaps Bash doesn’t like `\r`, i. e. Windows line breaks?
are you from india?
It might be better if you setup an ssh config file correctly and automatically built a menu out of that. Here's some related `.bashrc` code for you: # SSH auto-completion based on ~/.ssh/config. if [[ -e ~/.ssh/config ]]; then complete -o "default" -W "$(grep "^Host" ~/.ssh/config | grep -v "[?*]" | cut -d " " -f2- | tr ' ' '\n')" scp sftp ssh fi # SSH auto-completion based on ~/.ssh/known_hosts. if [[ -e ~/.ssh/known_hosts ]]; then complete -o "default" -W "$(cut -f 1 -d ' ' ~/.ssh/known_hosts | sed -e s/,.*//g | uniq | grep -v "\[" | tr ' ' '\n')" scp sftp ssh fi
The dollar sign before the string means that escape characters are interpreted within it. In this case, you've got a stray `\r` (`Ctrl+M`, carriage return) in there. You'll need to sanitize it.
&gt; bles in bash is global. this gr Thanks for the feedback. This was meant as a way of refactoring bash code that you might find to make them more readable. And, you are right. a person can use the local var. But the var is global by default and generally everyone tends to use the default patterns.
You are right I don't completely understand referential transparency and would like some guidance on that aspect.
Found the answer : Note the ending semi-colon is req'd var1=$( { head -n1 TempFile.csv | awk -F'"' -v OFS='' '{ for (i=2; i&lt;=NF; i+=2) gsub(",", "", $i) } 1' ; } 2&gt;&amp;1 ) echo "VAR1: $var1" 
Why not just use mysql connector and do a Load Data query
I'm not familiar with that method. Are you saying its a bash connector that will load from CSV? I'm trying to not have to specify column names, is that what that does?
Well did you install the `MySQL-python` backend like it suggests?
Without files (and without nullglob) `*.class` stays literally the same, so you can do `if [[ "$(echo *.class)" != '*.class' ]]`, but an alternative without `if` is using `||` after `mv` because if there are no files, then `mv` will fail: `mv *.class class_files || echo do something else`
 class_files=$(find -name '*.class') if [[ -n $class_files ]]; then mv $class_files class_files else ; # do other stuff... fi
This. The find command is faster than using globs in BASH. 
https://chrome.google.com/webstore/detail/secure-shell/pnhechapfaindjhompbnflcldabbghjo http://www.web-console.org http://firessh.net
More context please. Perhaps something like rundeck is really what you're after?
Call the terminal program and pass it the call to vim. 
Big thank you! I got it working. I really appreciate the help!
Start with gvim some.txt I have never (and probably will never) try the windows bash terminal, so I'm not sure I can do much else for you. 
Alternatively you could get an IDE that facilitates refactoring.
I have a bash script which uses GNU paralell to retrieve info from a DB in a site. The DB is huge and so the number of requests to do (10M i think). With GNU parallel it takes less but it would be nice to have more machines running it together and silently. After that i would just have to copy/paste the *.txt generated file and the job is done
It sounds like you're looking for something like Microsoft Azure, DigitalOcean, or AmazonAWS. They make it easy to get a pool of machines which you can then run your scripts on.
In the select statement you wrote: select *option* But in the case statement you have: case *$opt*
Hi, I have some utility belt written in bash for my own. It would be great to have some lodash like utility for bash. But bash is so simple as javascript ;)
I'm going to assume your doing this because you're aiming to teach yourself some bash. (Otherwise, what you're doing can already be accomplished with the 'ls' command.) You've already received some pretty good advice on how to get what you have to work, so I took it upon myself to clean things up a bit as well as introduce you to the 'printf' command and why you might want to use it over the 'echo' command. I also added a couple of variables to show you how you can use color to highlight text. Oh, and there's some awk in there as well. *NOTE: for brevity's sake, I removed all the if statements testing whether a file is read, write, or executable, and instead chose to print the output of 'ls' command.* #!/bin/bash DIR="$1" FILE="$2" #For highlighting text RED=$(tput setaf 1) NORMAL=$(tput sgr0) if [ -d "$DIR" ]; then printf "\n%s\n" "The directory $RED$DIR$NORMAL exists." else printf "\n%s\n\n" "The directory does not exist." exit 1 fi if [ -e "$DIR"/"$FILE" ]; then printf "\n%s\n" "The file $RED$FILE$NORMAL exists and has the following properties:" else printf "\n%s\n\n" "The file does not exist." exit 1 fi # Variable command to get file properties COMMAND=$(ls -lh "$DIR"/"$FILE") printf "\n\tPermissions:\t%s" "$(echo $COMMAND | awk '{ print $1 }')" printf "\n\tOwner:\t\t%s" "$(echo $COMMAND | awk '{ print $3 }')" printf "\n\tGroup:\t\t%s\n\n" "$(echo $COMMAND | awk '{ print $4 }')" exit 0 
We'll probably need more context. I see nothing in that single line that shouldn't work. I'd suspect something along the lines of the bash file itself not being constructed correctly.
Are you saying your simplified test case did or did not work? Assuming that test_env/bin/activate contains env **and** you've truncated the 'hi', that seems to be a fully functional demonstration of what source does. Your primary script seems weak to me on its handling of paths, but that should generate very obvious file not found errors. What exactly are the errors or unexpected outputs/behaviors you're getting? (Sourced files don't need to be executable. Or even include a #! for that matter.)
This is the reason 99% of the time. To find out the absolute path of whatever alias you're used to running you can use: which [alias]
`type` is generally recommended over `which` these days, I think because it's a shell builtin command. Also has some useful cli options. Not a criticism, just sharing.
Never knew about type! I'm sure there are many ways. Thanks for sharing. That's what this whole community is about!
I don't see the contents of my_env/bin/activate, so I can't help you debug that. Can you explain why you'd want to execute the script using source instead of execute or sh or /path/to/script? --- **source** is a shell built-in that is an alias for the "dot command" ( **.**). The difference between this and "sh" or "execute" or ./*command*" is that it runs using the current shell, rather than executing a new shell. There is basically only one reason that I can think of that you would want to do this, and that is to (temporarily) change the environment variables of the shell. For this reason, source/. is almost universally used to set those variables. . ~/.my_new_environment_variables Stylistically speaking, if you want to run a command or a script, you should use execute instead. http://superuser.com/questions/176783/what-is-the-difference-between-executing-a-bash-script-and-sourcing-a-bash-scrip --- e: for the sake of doing it, I did the following: $ cat test_source.sh #!/bin/bash me=`basename "$0"` /bin/echo "running " $me source /home/foo/activate and $ cat activate /bin/echo "running activate" When I run the test_source.sh command, I get this: $ sh test_source.sh running test_source.sh test_source.sh: 5: test_source.sh: source: not found When I change the source command to . it works: $ sh test_source.sh running test_source.sh running activate So, maybe try it again using . instead of **source** ? (also, you really should use absolute paths, not doing so is a terrible habit to get into as a newbie)
&gt; When I run the test_source.sh command You’re running a Bash script with `sh`, which may point to a different shell, that’s why it doesn’t work.
[The 'activate' file states it can't be run directly.[(http://pastebin.com/ugA3pZy5) I feel like there's something I don't get and that I ask a lot. `. env_folder/bin/activate` works when I type it in the terminal, but not when run as a bash line. Does source work in a bash script like it does when entered in terminal?
Note that activate does not start with the shebang line. E.g. #!/bin bash . That would allow the shell to execute the file directly. Barring strangeness, source should work in a script identically to how it works on the terminal. As for why source isn't working, they should be working in the use cases you've described. I replicated your test case and everything worked as expected on my system. Your environment itself may have something strange in it, but it looks like you're running Ubuntu with proper bash, so that shouldn't be an issue. Last ditch approaches that might work for you: * Wrap the entire thing into a tarball and dump it somewhere so folks can get a higher fidelity view of what you're doing. * Clean up path handling. * Refactor your code and dump the contents of activate directly into your shell script. * Start from scratch and see if it fixes something you didn't notice. 
&gt; $ cat test_source.sh &gt; &gt; \#!/bin/bash No i'm not.
&gt; sh test_source.sh Yes you are. The shebang only matters when you call the script as `./test_source.sh`. If you supply it as an argument to `sh`, `sh` will simply run it as a script, completely ignoring the shebang (which is just a comment).
To boost off of /u/weisbrot's answer, I would also do it in the form of `read name; echo "welcome, $name"` just because that seems like the most pragmatic approach. However, if you'd like to use the `$(command)` format, the problem with doing `echo "Welcome, $(read name)"` is that `read name` doesn't actually return anything. That is to say that whenever you put `read name` in a terminal and then type in a name, nothing gets printed. If you were so inclined, you could set it up as such: echo "Welcome, $(read name &amp;&amp; printf $name)" 
It's essentially asking you to take arguments for the number of sides on a dice - i.e; d6 (six sided dice), d20 (twenty sided dice), etc and prompt if none given. It's a series of if statements. Can prob use case to handle the options side of things. https://bash.cyberciti.biz/guide/The_case_statement http://www.thegeekstuff.com/2010/07/bash-case-statement/ I've no intention of doing your homework for you tho; but I'll answer specific questions if you have any.
It’s probably part of `PROMPT_COMMAND` – if you have a stock Ubuntu lying around somewhere, try looking in that variable.
Check your PS1 and PROMPT_COMMAND environment variables. Perhaps the Python virtual environment has overriden these? I'd also check the 'activate' script in the virtual environment. 
PS1 is as follows: [\[\033[1;35m\]\w\[\033[0m\]]\n[\[\033[0;32m\]bash\[\033[0m\]] $ PROMPT\_COMMAND is: `__prompt_command` *edit* I will post my full prompt in a second
Ive added my prompt to the OP
I'm suspicious of this line: PS1+="\[$Yellow\]("${$SSH_CLIENT%% *}")\[$Color_Off\]" and specifically of how the SSH_CLIENT environment variable is being used. When I try to do the same thing, I get bad results: echo ${$SSH_CLIENT%% *} -bash: ${$SSH_CLIENT%% *}: bad substitution The [bash manual](https://www.gnu.org/software/bash/manual/bash.html#Shell-Parameter-Expansion) lists ${parameter%word} ${parameter%%word} as valid uses, but not ${parameter%% *}
ok, I will comment that out, see what happens
OK, fair enough. I thought the bad substitution error was with the " *". As it turns out, the bad substitution error is caused by the extra $ sign before SSH_CLIENT in: PS1+="\[$Yellow\]("${$SSH_CLIENT%% *}")\[$Color_Off\]" it should be: PS1+="\[$Yellow\]("${SSH_CLIENT%% *}")\[$Color_Off\]" Assuming, of course, that the $Yellow and $Color_Off variables are defined.
I spoke too soon, git status doesnt work now. do You also have git status in your prompt? can you share it then? I seem to have either broken virtualenv or git status now
thanks! after furiously googling around, I think I have a rough working version now, I need to clean it up though
 seq 200 \ | tac \ | while read -r num &amp;&amp; sleep 1; do echo "$num"; done
 #! /bin/bash echo "Countdown" echo " Reset counter: Ctrl-C or kill -INT $$" echo " Exit: kill -TRAP $$" while ! [[ "$originalcount" =~ ^[0-9]+$ ]]; do read -p "How many seconds? " originalcount done count=$originalcount trap 'count=$originalcount' INT trap 'echo Bye; exit' TRAP while ((count &gt;= 0)); do echo $count ((count--)) sleep 1 done 
Wouldn't `&amp;` "solve" the issue? while sleep 1; do date &amp; done
No, still a small delay: $ while sleep 1; do date +'%T %N' &amp; done 17:14:37 994683694 17:14:38 999605529 17:14:40 003608665 # a second was skipped here 17:14:41 007245655 
timing is really something difficult...
Sounds like perhaps the connection is hanging somewhere during establishment. Have you tried enabling the debugging output with the verbose flags in the script? Also, you can't specify two commands to be run over ssh, you'll have to split them into two separate ssh calls per host: for i in cat hosts.txt; do ssh -A $i "cat /etc/puppet/disabled" ssh -A $i "df -kh" done
Oh my goodness, you done gone and did it! Thank you so much! I wasn't aware you couldn't run multiple commands for an ssh! 
...but you can run two or any number of commands with quotes and ; or &amp;&amp;
You are correct! Write your function() and set trap &lt;signal&gt; to run the function. E.g. I have a CleanUp() function and use: trap CleanUp SIGHUP SIGINT SIGTERM This catches ctrl+c. From Wikipedia: &gt; Ctrl-C (in older Unixes, DEL) sends an INT signal ("interrupt", SIGINT); by default, this causes the process to terminate. However, ctrl+z specifically requires SIGTSTP: &gt; Ctrl-Z sends a TSTP signal ("terminal stop", SIGTSTP); by default, this causes the process to suspend execution. Haven't really tried to test ctrl+z. (Sorry, phone lost the urls.)
just to show what that means in case someone doesn't understand (I was going to say that then I saw you beat me to it).. for i in cat hosts.txt; do ssh -A $i "cat /etc/puppte/disabled; df -kh &amp;&amp; ls ~" done The difference between the ; and &amp;&amp; being that the ; will always run the second command and &amp;&amp; will only run the second command if the first one succeeds.
`declare` command don't work in bourne shell , you should consider changing your hashbang line to `#!/bin/bash`
&gt; seq 0 5 | xargs -t -n1 -P10 sleep That's what I've been missing ^^ Thanks!
The first one works for me: $ bash traps.bash Counting to 5 slowly, press Ctrl-C to interrupt. 1 2 Hey, you pressed Ctrl-C. Time to quit. I managed to catch Ctrl-Z in one script, but this method doesn't seem very useful in a bigger script. When you have a trap for TSTP, when that script is running `sleep 1`, then `sleep` seems to catch it (and freezes). But using `&amp;` and `wait` works for me: #! /bin/bash trap 'echo You pressed Ctrl+Z.; exit' TSTP for ((n=10;n&gt;0;n--)); do echo $n sleep 1 &amp; wait done 
I find it much easier to create a bash or perl script and call that from the SSH command. for host in server1 server2 server3; do ssh $host bash &lt; ~/multicmd.sh; done 
&gt; but to avoid seq use echo {0..5} instead printf '%s\n' {0..5} To get line separating instead
|| works as well me@mine:~$ ls foo ls: cannot access 'foo': No such file or directory me@mine:~$ ls foo 2&gt;/dev/null || echo "In the or" In the or me@mine:~$ touch foo me@mine:~$ ls foo 2&gt;/dev/null || echo "In the or" foo 
That sounds incredibly retro but I can't recall it. I assumed this kind of thing would be restricted to diskzines and the like. What's the publication if you don't mind me asking?
The one I am making is a collection of science fiction stories. Having a jingle, and having the jingle included in code, would be a fun gimmick in my opinion. I did an anthology a few years ago with a full theme song. I think that worked very well. If you jump to page 36 here (I hate the design!) you can see some "try at home" code for the Amiga: http://www.e-pages.dk/audiomedia/706986168/
Someone used /dev/urandom back then as an input for the beep. You could try looking into that.
That just generates random noise?
Yeah it sounded pretty cool, though. Link to post http://blog.robertelder.org/bash-one-liner-compose-music/
Check out [expect](https://en.wikipedia.org/wiki/Expect).
I agree that it's fascinating, but a jingle is per definition fixed, at least in my view.
Look at /proc/[pid]/status. Big hint: declare -A tree for status in /proc/[0-9]*/status; do while read type value; do [[ "$type" == Name: ]] &amp;&amp; cmd=$value [[ "$type" == Pid: ]] &amp;&amp; pid=$value [[ "$type" == PPid: ]] &amp;&amp; ppid=$value done &lt; "$status" tree[$pid:$ppid]="$cmd PID:$pid PPID:$ppid" done Then you just need a recursive function that prints the command name with the indentation you want for the location specified (hint, the first one is pid 1, ppid 0) and runs through the tree to call itself on all instances that have a ppid that's the current pid with the indentation increased.
I don’t really want to do your homework for you, and /u/ray_gun already gave you some hints (though I don’t know if reading `/proc/$pid/status` will be considered acceptable if the task tells you to use `ps axo`), so instead I’m going to mention some pre-existing programs that do the same job, and which you should instead use if you actually need something like this outside of a homework situation: - `top` – the classic table of processes. On my system, with procps-ng 3.3.12, `top` starts in tree mode by default, but you can also toggle it with `V`. - `htop` – better `top`, essentially. It’s awesome, and I don’t have to tell you how to use it because it does that itself at the bottom. - `systemd-cgls` – shows cgroup tree instead of parent-child relationships. - `systemd-cgtop` – a mixture of `systemd-cgls` and `top`, showing resource usage of cgroups (also, unlike `systemd-cgls`, interactive and auto-refreshing). Only shows cgroups that have some resource accounting enabled, so many units will just be grouped under their slice or scope.
Would it otherwise be a nice implementation? I really thought it'd be nice to have something built in.
I do not use pandoc from command line, but it looks like options behind -f must not be divided by whitechars: -f markdown_github+footnotes+fenced_code_attributes \ In your example the '+footnotes' is taken as a separate parameter, because pandoc thinks it is a filename. 
yes, that's what's happening. Is there a way to force bash to read these as one argument? if not then it isn't a big deal, but I'm curious
I have got exactly the same homework about 14 years ago: http://bruxy.regnet.cz/fel/36UNX/ptree Computer science motto: "Everything was already implemented, but not by everybody." 
&gt; Any opinion on how I should go about replacing old video links with new ones automatically? It depends on how your HTML is structured I suppose - do you have an example? &gt; Also, would the script wait for the ffmpeg conversion to complete if I add more lines underneath? It would, yes.
wow that works, thanks. and it looks really clean now. nick checks out ;) . Fixed the quotes thank you for pointing that out. bonus question if that's ok, what are the possibibilites for commenting inside functions? for now, the only way I found that works is at the top before any commands. If I try putting comments at the end of the lines like this `--toc \ #table of contents` it won't work. putting the comments one line below also makes the function hang. any tips for that?
thanks! my bash-fu is decent for day-to-day home-user-style kind of work, so I can learn a thing or two from these tricks. Your second solution looks cleaner and I will use that :) If only You could educate me more on why You switched from `{}` to `()`. i dont get it
thank you. this is very interesting. the function is getting pretty complex, but for me it has an additional educational value
&gt; You call `recurse` from within `recurse`... that might be infinitely looply problematic The recursive call also looks incorrect – the call pipes something into the function, but the function doesn’t seem to read from stdin, it expects an argument (`$1`).
`{}` runs the commands in the same shell; `()` will run them in a subshell, which has various implications. The implication I cared about was that variable set in a subshell don't propagate up to the parent shell. IFS is a funny tricky variable that affects the behavior of the shell, and it's easy to accidentally screw it up. A different way of doing it would have been to save the old value and restore it: local oldIFS=$IFS IFS=+ ... IFS=$oldIFS Or, we could have used Bash's dynamic scoping to have it only set IFS inside of the function: md2html() { local format=(...) local IFS=+ pandoc ... } Which might have actually been the better solution. But, because IFS is a magical global variable, I'm not 100% certain that masking the global value worked "correctly" in all previous versions of Bash.
Yes.
I really don't think bash is the right tool for this job. Something that has an actual HTML parser would be a much better idea..
I’ve never tried this out, but perhaps you could conditionally redirect stdout and stderr: if interactive; then # substitute real condition here exec 1&gt; &gt;(tee -a /tmp/logfile.txt) else exec 1&gt;&gt;/tmp/logfile.txt fi exec 2&gt;&amp;1 # rest of script here Note that `&gt;(command)` is Bash-specific afaik, I’m not sure if it’s possible to achieve this without that syntax.
Sometimes you can do this with a variable, other times you need to reach for a function. I think this is a case where a function is required. So you'd re-jig it kind of like so: # If we are interactive, output to both the log file and the console if [ "${interactive}" = "TRUE" ]; then funcOut() { tee -a /tmp/logfile.txt } else funcOut() { cat - &gt;&gt; /tmp/logfile.txt } fi The big secret is that this uses a dirty use of `cat` (i.e. not a UUOC) to stream the output on through as the alternative to some other action. Without testing, the `tee` variant may or may not require `&lt; "${1:-/dev/stdin}"`. You'll notice I've lowercased your variables. They're not globals, so don't uppercase them. I have kept your single brackets rather than doubled them though, because: portability is something that may be useful for you (although I can't guarantee complete portability with anything else e.g. the dirty use of `cat`). Next up, the DRY principle (i.e. Don't Repeat Yourself). Get rid of all those instances of $LOGGING, group all your commands and pass them to your output function # Start capturing all output { # Run command with desired logging echo "Running ..." /usr/bin/date echo "Complete." # Run command with exit code capture echo "Running command with exit code capture..." /usr/bin/true if [ $? -eq 0 ]; then echo "Command successful." else echo "Command failed." fi # Run some chained commands echo "Running 3 chained commands..." date | grep -v 'Fri' | awk '{print $1}' echo "Chained commands complete." # Pass all output to the output function } | funcOut Obviously there are other habitual improvements you can make like `printf` instead of `echo`, not using full pathing unless you really need to, skipping the return code check and using the command directly e.g. `if true; then` and so on. That's basically the guts of it.... all off the top of my head. I have done this before using both the variable and function approaches, so if need be I have code to reference if the above doesn't work out. Good luck!
&gt; You've got an array named array and you're calling arrary :) I've been doing doing this all morning. Lol.
&gt; I read somewhere that readarray can make a two dimensional array, but is this not true? I wouldn't think this to be true - bash doesn't support 2d arrays. (they can be simulated but it's pretty horrible) You would have to split up the line again into an array using `read` e.g. user@host $ array=( 'one two three' 'four five six' ) user@host $ read -a columns &lt;&lt;&lt; "${array[0]}" user@host $ declare -p columns declare -a columns='([0]="one" [1]="two" [2]="three")' You may wish to investigate something like `python` and its `csv` module for such a task like this though.
That's a great tool. Thanks! Looks like I broke the if statement when I was fixing indenting for reddit. I completely missed the "Name" variable when I reused the 'file not found' portion from another script.
I only used Bash on Windows for a little while but I have been using Bash for longer than that on a Mac. I guess it partly depends on what you want to do on the command line on a Windows machine. I love Bash because it gives me awesome power over text files, let's me run the Python and R code I want and the work related software I might run is all designed to run only on a Unix system, which the Bash on Windows allows. I'm not sure what things you want to do are suited to Bash it another shell that is native to Windows (and sadly I know nothing about). PS, you'd probably run into permission issues where ever you were running Bash, it is a very Unix thing to happen!
The bash guides at tldp.org are complete garbage. The Linux Command Line is a tad better, but still teaches a lot of bad practices, so I would not recommend it. There's a reason they are not in the sidebar. The only good guide for beginners that I know of is the wooledge wiki [BashGuide](http://mywiki.wooledge.org/BashGuide).
See [FAQ 35](http://mywiki.wooledge.org/BashFAQ/035) for a good example on how to use getopts.
It really just depends on which environment you want to work with. PowerShell is designed for Windows and the Unix shell is designed for Unix/Unix-like operating systems. Bash (and the rest) are, imo, easier to get into and more intuitive; everything is treated as a file. But you'll want to be using a system running *nix (macOS being the most consumer-oriented example). PowerShell treats everything as objects, which adds a lot more complexity which is great for performing advanced tasks without needing to use another language (oftentimes with Unix shell scripting you'll need to leverage perl and python) but a lot more difficult for a beginner to understand.
I read only one book about Linux in hard paper and it was this one: [O'Reilly learning the Bash Shell](http://shop.oreilly.com/product/9780596009656.do). I went from your position to actually committing stuff to upstream packages (some grml-zsh-config, some `iocage(8)`, some games that use shell scripts for installing/running, like `openra(6)`) The wooledge wiki is also a great reference.
[deleted] ^^^^^^^^^^^^^^^^0.8219 &gt; [What is this?](https://pastebin.com/64GuVi2F/69728)
Overriding PATH is cool for security, but maybe not in the context of this program. The spaces and tabs are the fault of the text editors I've used (mostly nano).
My favorite book on BASH is "Classic Shell Scripting" by Arnold Robbins.
&gt;So my question is how do I test whether or a script was invoked via a link. You need to capture the script name from within the script and test against it. Here's an example, using a script named `testforward`: #!/bin/bash scriptName=[I'VE REMOVED THIS SECRET SAUCE, I'M NOT DOING ALL YOUR HOMEWORK FOR YOU] if [[ "${scriptName}" =~ "forward" ]]; then printf "%s\n" "Operating in forward mode" elif [[ "${scriptName}" =~ "backwards" ]]; then printf "%s\n" "Operating in reverse mode" else printf "%s\n" "Generic failure exit condition!" exit 1 fi Right, so I've created a symlink to `testforward` named `testbackwards`, let's see what happens: # ./testforward Operating in forward mode # ./testbackwards Operating in reverse mode There are other, more portable ways to test whether a substring is within a string that you should also be aware of. (Another edit to make it clear: I generally don't recommend these methods, but it's handy to be aware of this type of idiom - as it applies elsewhere - should you ever come across a clunky ancient shell. The point is that there are real portability problems to be managed and more than one way to skin a cat.) The most basic would be something like: if printf "%s\n" "${scriptName}" | grep "forward" &gt;/dev/null 2&gt;&amp;1; then And the `bash`ism+`GNU`ism way to write that would be: if grep -q "forward" &lt;&lt;&lt; "${scriptName}"; then With regards to this: scriptName=[I'VE REMOVED THIS SECRET SAUCE, I'M NOT DOING ALL YOUR HOMEWORK FOR YOU] (/edit: I've changed this next bit for readability and sense) One problem you will have with grabbing the invoking process' name is that you'll grab the full path, which may be a problem if the substring you're searching for is in the path e.g. `/tmp/forward/testbackwards` will match the "forward" test. So you really need to strip the path. There are two common ways to do this: one way uses an [external program](/s "basename $0"), the other way uses an internal variable (a positional parameter, really) and some [fancy looking builtin string manipulation](/s "${0##*/}").
I appreciate you taking the time to type all this out. I found a much simpler way though. I just used $0 to echo out the file name. Then I piped that to sed to remove the path and place that string in a variable. Once the path was removed I knew there was only one of two filenames that could be invoking my script so I just tested the variable against the file names to determine which "path" I wanted my script to take. Essentially my problem was not knowing that $0 existed. From there I was cooking with fire. Edit: I've been looking at this script all day so my brain is fried. I didn't realize that what you typed out was more or less what I did.
&gt;Personally that's just a stylistic thing for me, the all-uppercase variables stick out more. shrug Yeah, you can easily change your style and remove the chance of clobbering your environment at the same time. A style like `"${variableName}"` sticks out like dog's balls. I've told this story before: I was given a script to debug that a colleague had written. A few other people had tried to figure out what was wrong with it, and I have to admit it took me a few minutes of staring at it blankly before I clicked. He'd wanted a variable to represent the current directory, so he'd entered: PATH=`pwd` After I stopped laughing was the point at which I became firm in my opinion on variable casing. But to each their own, consistency is the more important thing. &gt; Full pathing of commands, surprisingly, is something of an issue for some of my scripts on some systems, as we may have multiple versions of programs on our systems. Of course my sample code was heavily modified for this example and it was unnecessary. However, for example, under AIX, there are two date commands, one in /usr/bin/date, and another in /opt/freeware/bin/date. The one in opt is the 'Linux' style one, that understands epoc calculations whereas the AIX one does not. Strange, but there you have it. Still, the better way to manage this is to either make it a variable e.g. dateCmd=$(/usr/bin/date) and then call the variable as needed, OR to manage your PATH variable (this is my preference). You shouldn't be full pathing within your code. Your example's not strange or surprising to me, I sadly have to code for AIX, HPUX and Solaris (fuck you Solaris) on top of Linux scripting, with a little bit of BSD thrown in now and again :( &gt;And finally, the reason I write my code like I do is so that our offshore folks can understand the script. It reads more like a 'script' and less like a 'program'. For those that don't do much coding, they are able to understand the this-then-this-then-this (and so on) flow of the program better and I've had better results when I have to hand it off for long-term support. :-) Comments, comments, comments :)
&gt; Essentially my problem was not knowing that $0 existed. Yeah, that’s the essential part :) the rest of the secret sauce is just how to get from `path/you/dont/care/about/Purge` to just `Purge`, and `sed` works well enough for that.
So does `${myvar##*/}`.
I actually ended up pulling that particular line, and regex, from another imgur album downloader. I'll probably end up playing with that line a bit more, and possiby adding functionality to accept just the unique ID.
Are you sure you linked to the correct script? That doesn't look like it contains anything related to `showinterfaces.sh` Regardless of that - it sounds like they want you to accept an interface name as a command line argument
Potential spoilers? 1911 2193 3735 5397 7335
Hey, you got it! Aren't binary palindromes cool? You're the second person so far to solve it!
Very impressive piece of work you put together. Although I am not too keen on capitalized variables, and it almost seems a shame that you didn't write this in C or Python.
It is interesting that they're all odd. This came from one of my early attempts at writing a script. I had _to_binary() and _reverse() and then thought to use them together. 
Seconded, I've run Cygwin + windows for years, and can't live without it now. Both at work and at home. Best of both worlds!
Argh! You spoiled it! Haha, it was a good puzzle while it lasted though
Line 17 seems to be where the program ends if there's nothing more to do. Using ls | grep is considered bad form, so it might be a good idea to write some small functions that use for loops to iterate over the files in /backup1, then do some if-statements with some comparison tests. That way you could get rid of some grep and find statements. Instead of 'grep -s ... wc -l' use grep -c -- that will count occurrences. Quote all file variables that store strings. Since this script requires a mounted directory, it's hard for me to test, but if MOUNT_COUNT is zero, then /backup1 will no longer exist. So test if /backup1 exists and is a directory. Again, that's how I see it; I may be wrong.
Now post the bash script that solves it and earn another point, haha.
I think this whole line: if [ -f $backupfile ] &amp;&amp; [ "`ls -l $backupfile | awk '{print $5}'`" == "0" ] Can be replaced with if [ ! -s "$backupfile" ]; then From `man test`: -s FILE FILE exists and has a size greater than zero Or flip the whole thing up: # Checking to see that the backup exists &amp; the file size is not zero bytes if [ -f $backupfile ] &amp;&amp; [ "`ls -l $backupfile | awk '{print $5}'`" == "0" ] then backupsize=0 else backupsize=1 fi Becomes # Checking to see that the backup exists &amp; the file size is not zero bytes if [ -s "$backupfile" ]; then backupsize=1 # Otherwise, throw in a cursory check that the file exists and we can read it elif [ -r "$backupfile" ]; then backupsize=0 # This next bit is optional #else #printf "%s\n" "$backupfile does not appear to exist or is not readable." #exit 1 fi
Also, generate the menu in guide() using the contents of $intname. If an interface doesn't have an IP address -- make a test statement -- it shouldn't be on the list.
 #!/bin/bash stop=0 if [ "$1" ]; then start=$(( $1 + 1 )) else start=201 fi while sleep 1 do if ((stop == start)); then clear printf "\n\n\t%s\n\n" "Done" break fi tput sc tput cup 1 68 tput cup 1 $(($(tput cols)-5)) echo $((--start)) tput rc done &amp; 
&gt;echo "$(cat - compsimp2016.txt | cut -d ';' f4,5 | grep $dep | cut -d';' - f4)$APPEND" &gt;&gt; caracteristiques_2015_NEW.csv You do have a few problems here. What sticks out immediately is that your first `cut` invocation is missing the dash for the field switch i.e. it should be `cut -d ';' -f4,5`, and your second use of `cut` has a space between its dash and switch i.e. it should be `cut -d ';' -f4` You've got a Useless Use Of Cat there as well. There's no point `cat`'ing something into a program that can handle files directly cut -d';' -f4,5 compsimp2016.txt | grep "$dep" | cut -d';' -f4 It would be a bit more elegant and robust to do this in `awk`
thanks for this one mate. I started reading it and I'm on Chapter 6 already. I can say that it's better than the ones in the TLDP. 
thanks mate. I'll keep this book for the future. I just need to be comfortable with Bash. No need for me yet to become pro. I'm reading the woodledge wiki right now. :)
I was suggesting parameter substitution because it doesn't require an extra process. I don't know if you use other languages or not, but would you run `sed` from Python to trim a string? Of course not, it would be overkill. Python, and every other language has a built-in method for that, including bash. This still isn't as bad as the `printf | grep` suggestion I saw in this thread (for testing substrings).
i'm not quite sure I get this ?
* Don't use full caps. These are used for global variables. `$BROWSER` may even already be one. * Test for `$BROWSER` being set first `: ${BROWSER:-"w3m"}` (IIRC). So you can use `BROWSER=firefox ./script` * Give shellcheck a shot. The link is in the sidebar. * Use `[[` instead of `[` (it is bash after all). * if you care about portability, `echo(1)` is not your best bet. Use `printf '%s' 'Stuff'` instead. * I'd use the quiet options of wget/curl instead of `2&gt;/dev/null`
* You could drop either `wget` or `curl` in favor of only one of both. * `echo(1)` does not support options on some OSes ([OpenBSD's man is clear on that matter](http://man.openbsd.org/OpenBSD-current/man1/echo.1) *Where portability is paramount, use printf(1).*) * If you use some not-too-exotic options for `grep(1)` and `tr(1)`, you should be fine.
Oh, sorry, I didn’t notice that.
I haven’t looked through the whole thing yet, but here are some comments: - The error message at the bottom should go to standard error: echo &gt;&amp;2 malformed expression Better yet, use `printf` exclusively: printf &gt;&amp;2 '%s: malformed expression\n' "$PROGRAM" - Always use `[[` instead of `[`. - For arithmetic conditions, use `((`: if ((${#bot1) &gt; 1)); then if (($# &lt; 2)); then while (($# &gt; 1)); do - There’s some random inconsistent indentation at `$1 == [0.]* ||` and the line below that; tabs?
The [[ ]] are being used for string tests. (( )), I think, depend on preference, but they do look better. I'm typically not good at error messages. Thanks for the comment!
That's impressive! I'm sure that this is a learning exercise, but an easier way to work around the floating point math limitations in `bash` is by leveraging [`bc`](https://www.gnu.org/software/bc/manual/html_mono/bc.html), like so: function mult() { echo "$1 * $2" | bc --mathlib --quiet } $ mult 4.5 9.6 43.20
Oh, right, very good point! Better stick to `((` then, more readable than `-gt` :)
&gt; external program The whole point of bash is to string external programs together. 
In that case, well done :D (but you really should have said so in your opening post)
&gt; Heck I would even be happy with Python (2.6) Using the `ConfigParser` module will make your life easier as opposed to doing it manually with sed or awk. import ConfigParser configfile = 'ansible.cfg' config = ConfigParser.ConfigParser() config.read(configfile) config.set('defaults', 'inventory', '/new/path') # assuming it's in the [defaults] section with open(configfile, 'wb') as f: config.write(f) http://docs.python.org/2/library/configparser.html#examples
You were so busy seeing if you could you never bothered to wonder if you should. 
I think replying to your comment is an example of that. Jeez, it seems like I can't help but piss people off on here. 
I like this one a lot. I'll give it a better look soon.
Ah, I forgot about WINE. I played with ReactOS years ago. Has it gotten better? I remember it not having many features. 
It totally works as expected! The only addition I would make is to check to see if inotifywait is installed - since it isn't installed by default. 
Thanks for the link. This looks a lot more sophisticated, but also a bit more complex to set up. I've added it to the "Related projects" section of the README.
How would you be running it in Windows? Or are you cross-compiling? Running your commands manually in the Linux subsystem on a Windows box complains about "ld -m win64" with: ld: unrecognised emulation mode: win64 Supported emulations: elf_x86_64 elf32_x86_64 elf_i386 i386linux elf_l1om elf_k1om i386pep i386pe
Yeah, in ld -V ,I didn't find that emulation. How would you cross-compile it?
I forgot about the score-tracker. Here's the script for it. For pyramid.sh, do: ./topscores ~/.pyramid/pyramid-scores "$@" #!/bin/sh - # USAGE: topscores /path/to/score-file [-a] # This script reads score files and reports the top five and # bottom five scores for a particular game. # The field separator for these files is the vertical bar '|'. # Entries are sorted by the third field - the score number. # # FLAG: -a Show entire score file # # Example score-file line: # # Sun Sep 13 23:23:57 PDT 2015 | name | 50 | easy | won # f 1 f 2 f 3 f 4 f 5 if [ $# -eq 0 ]; then echo "Usage: ${0##*/} /path/to/score-file [-a]" exit 1 fi SCORES="${1}" [ -f "$SCORES" ] || exit 1 if [ "$2" = "-a" ]; then cat "$SCORES" exit 0 fi echo echo "${1##*/}" echo echo Top 5 scores sort -t"|" -r -k3 "$SCORES" | head -5 echo echo Bottom 5 scores sort -t"|" -r -k3 "$SCORES" | tail -5 echo echo $(wc -l "$SCORES" | awk '{ print $1 }') games played echo 
I don't know anything about bash :/ My friend uses Linux and I constantly need to get his latest renders to work on, and looked into automating the task. I did try, found about rsync and figured the time it would take me to learn bash and make one myself would be much longer than just doing it manually every time. However I can see in the posts I found that its seemingly a trivial thing for those who do know bash, so I figure why not make a post and see if someone makes it. Anyways, thanks for offering your help, but I'm afraid I can't take you up on your offer right now. 
Thanks. 
sounds like *rysnc* would be the way to go. something like rsync -raut /path/to/source/folder /path/to/dest/drive
I know it will use rsync. However I need it to run with only 1 pendrive, and not to copy to every drive I plug in. For that, I will need udev rules. However, I don't know bash, and I don't know how to combine the two to make the script. 
The line /u/soap_dispencer wrote *is* the script you need. Just slap `#!/bin/sh` as first line and BOOM, you got it. As for udev... I have no clue.
I suspect that doing this with udev might be subject to race conditions, since it might be possible that your script is run before the drive has actually mounted. (Or perhaps udev takes care of that? I don’t know.) If the drive is automatically mounted under a predictable path (for example, GNOME and (I believe) KDE automatically mount drives under `/run/media/your_username/label`), you can use systemd path activation. Add these files under `~/.config/systemd/user/`: # backup.path [Path] PathExists=/run/media/%u/label # backup.service [Service] ExecStart=/usr/bin/rsync -raut /path/to/source/folder /run/media/%u/label/backup Replace `label` with the label of your flash drive.
so put a file on it called .one_pen_drive and test for its existence. if present rsync. if not exit.
If you're having a hard time finding someone to do this for free you might want to try booking someone on [fiverr](https://www.fiverr.com/search/gigs?utf8=%E2%9C%93&amp;locale=en&amp;query=script&amp;search_in=category&amp;category=10&amp;sub_category=146&amp;page=1&amp;filter=rating)
http://mywiki.wooledge.org/ParsingLs $(ls -l | grep -i "mov" | wc -l) There is never any excuse for using ls like this. Instead use: find . -type f -name \*.mov | wc -l or put the contents of the above into an array and count the num entries. And even if you take the argument that you're just counting them and so thats safe; then: ls -l | grep -ic mov Even then I disagree, as you're risking miscounting the number of files as your grep doesn't look for files ending in mov - for example mymovie.someotherextension would be matched by your one. This could be fixed with grep -ic '.mov$' filesize=$(ls -lah "$filename" | awk '{ print $5}') Again; stop using ls like this. The correct form is: stat -c %s "${filename}" The rest seems fine, but your use of ls like this is just bad practise.
This line: $input1="$v_frames_""$clean_name".png should be more like: input1="${v_frames}_${clean_name}.png" and all the other similar lines.
Is this the cause of why the loop does not work? Or is it poor formatting that I should fix?
stat should be available to you on macos: https://developer.apple.com/legacy/library/documentation/Darwin/Reference/ManPages/man1/stat.1.html I'd recommend figuring out why you don't have stat installed rather than using wc -c ; as that would be very expensive, io/cpu wise. 
So I tried the changes: &gt;for r in `seq 1 $num_frames`; do &gt;convert -rotate $rotation_value -gravity center -crop "$widthcrop"x"$heightcrop"+0+0 $input "${v_frames}_${clean_name}.png" &gt;$input="${v_frames}_${clean_name}.png" &gt;v_frames=`echo $v_frames 1 | awk '{print $1+$2}'` &gt;$out_file="${v_frames}_${clean_name}.png" &gt;neural_style $input $style $out_file &gt;done and got: &gt;Neural Style Transfering 92fXY3q.jpg &gt;./neural-zoom.sh: line 57: 92fXY3q.jpg=8_92fXY3q.png: command not found &gt;./neural-zoom.sh: line 61: =9_92fXY3q.png: command not found &gt;Neural Style Transfering 92fXY3q.jpg &gt;./neural-zoom.sh: line 57: 92fXY3q.jpg=9_92fXY3q.png: command not found &gt;./neural-zoom.sh: line 61: =10_92fXY3q.png: command not found &gt;Neural Style Transfering 92fXY3q.jpg 
Thank you again. The -c options don't work on BSD stat. This confirms the statement from your article: "stat is not available on every platform, and when it is, it often takes a completely different syntax of arguments". A solution is to determine the stat version and then adjust the options. A little complicated... I use the wc command and observe the behavior.
Yes, the names are working now. What is 'th' on line 75?
&gt;What is 'th' on line 75? The "th" is for Torch7, which is a machine learning/artificial intelligence framework for LUA. Link to the site: http://torch.ch Github page: https://github.com/torch/torch7 --- This is the current output. Looks likes it's working: https://gist.github.com/ProGamerGov/65770e1ed90484c939fb52773502df01 Not sure if it is attempting to do what I want it to, so I'll have to go get an AWS spot instance to test it.
The script is to be placed in the directory called "neural-style", which contains neural_style.lua.
&gt; find . -type f -name \*.mov | wc -l This is not equivalent, since `find` searches recursively.
&gt;Ok, so th takes a lua script as an argument? In my experience, yes. Though I have only really used it, and seen it used with a lua script. &gt;Do the arguments that come after it go to th or neural_style.lua? The arguments are going to neural_style.lua, I believe: https://github.com/jcjohnson/neural-style/blob/master/neural_style.lua#L9-L46 Though this page here sheds some light on things and also probably explains things better than I could: https://github.com/torch/torch7/blob/master/doc/cmdline.md
So testing the script results in the first image passing through neural_style.lua repeated, instead of each of the cropped and rotated images: https://imgur.com/a/8VVvp The log from the test that produced those images can be found here: https://gist.github.com/ProGamerGov/04eea8d9e7c2d527972ec2271cb46889 Not sure exactly why it appears to be only running the first image through and not each image through? This is the fixed version of the script I used: https://gist.github.com/ProGamerGov/a5163a3a7224dfc43d03a6238fe5580c
From the manpage it seems to be: stat -f %z filename Don't use wc -c - especially for large files. It would have to count every single character.
The three arguments to neural_style are: neural_style $input1 $style $out_file1 main uses $1 $2 $4 $5 $6. Three is missing.
Arg 3 in your gist is '75'
I changed $out_file1 back to $out_file and the same for $input1 to $input: https://gist.github.com/ProGamerGov/a5163a3a7224dfc43d03a6238fe5580c I thought this would work better than creating new variables. I have been using this other script as a reference for this current script: https://github.com/ProGamerGov/larger-neural-style/blob/master/bigbrush.sh
I understand now. 
You can used the which command instead, to find the path of an application/program. I find this easier to read and cleaner to execute: if [[ -z `which $convert` ]]; then echo "!!! $convert it's not installed. Aborting."; exit 1; fi if [[ -z `which $exif` ]]; then echo "!!! $exif it's not installed. Aborting."; exit 1; fi Some suggestions: function usage { returnCode="$1" echo -e "Usage: $me [-t &lt;title&gt;] [-h]: [-t &lt;title&gt;]\t sets the title (default: $title) [-h]\t\t displays help (this message)" exit "$returnCode" } function debugOutput(){ if [[ "$debug" == true ]]; then echo "$1" # if debug variable is true, echo whatever's passed to the function fi } while getopts ":t:h" opt; do case $opt in t) title="$OPTARG" ;; h) usage 0 ;; *) # this is a better catch all, it also ensures that a title is passed along with the flag echo "Invalid option: -$OPTARG" usage 1 ;; esac done debug=true debugOutput "$title" # easier to read than previous. Also note that I've wrapped the title in quotes so that you can run: bash gallery.sh -t "This is a longer title" 
&gt; ./neural_zoom.sh 92fXY3q.jpg 143.jpg 75 75 1 10 1 1 1 Here's the #!/bin/bash -x output https://gist.github.com/ProGamerGov/695c55289a4b7942576f1f1be37184fe Image _92fXY3q.png and image: 10_92fXY3q.png, have been changed by neural_style.lua, though oddly enough, images 0,1,2,3,4,5,6,7,8,9 have not been changed.
`which` is an external command (which may not even be installed), whereas `command` is a built-in. Perhaps `type` would be more appropriate, but I would recommend against `which`.
Ok, $3 is certainly not needed to run the program. You might have typed 75 twice, because zoom=75. for now, change: input=$1 style=$2 zoom=$3 rotation_value=$4 num_frames=$5 and change: main "$@" Let's leave it there for now. So. Images 0-9 aren't working because they're not files; they're just filenames. For your 0-9 series, you need to use cp to copy the original file to each name in the series. And, in your repost, you renamed input1 to input, but the argument to neural_style is still $input1.
I now check the stat version and then use the command: https://github.com/Cyclenerd/gallery_shell/commit/1ae9e7673a85e5a50f8ad5560fb63815e741b445
curl http://wttr.in/indianapolis http://i.imgur.com/BT701jk.png
Ok?
[lol](https://i.imgur.com/0o9IgH3.png) Is that intended to be a negative example? How not to do it? Regarding the question, I mostly agree with /u/Badabinski. A shell script is the first solution you reach out for, not the best one. Once you start running into problems, you probably rewrite the thing in Python or Perl, and you never find out that some simple quoting would have solved your problem too.
 E10) Why does `cd //' leave $PWD as `//'? POSIX.2, in its description of `cd', says that *three* or more leading slashes may be replaced with a single slash when canonicalizing the current working directory. This is, I presume, for historical compatibility. Certain versions of Unix, and early network file systems, used paths of the form //hostname/path to access `path' on server `hostname'. http://git.savannah.gnu.org/cgit/bash.git/plain/doc/FAQ
Here’s an [archived version](https://web.archive.org/web/20161107163547/https://bluepenguinlist.com/2016/11/04/bash-scripting-tutorial/) of that website, for those who don’t want to give it more clicks.
Previous discussion of this on stackexchange is [here](http://unix.stackexchange.com/questions/12283/unix-difference-between-path-starting-with-and)
I'm not. Even trivial scripts should be coded to a strict style that doesn't suck.
I looked it up. zsh's printf prints a control character at its end: ^M. For a zsh-only script, use print instead of printf. http://zsh.sourceforge.net/Doc/Release/Shell-Builtin-Commands.html
Thanks for the info. Incidentally, after adding short flags, I had to switch to double brackets for my 'or' statements to work properly. BTW, I'm not experiencing the 'unary operator' error when running the script. Is this happening to you? And on which lines?
any line that checks for a condition that has to do with a list , for example line 220. What bash version do you use ?
I use zsh. I'll fix the lines in question though.
Thank you. I don't know why I didn't see if it was already out there. I was enjoying trying to solve the problem, but also raging a little. Thanks again.
Well you could modify your `awk` command to print them all. `getline` reads in the next line of input and `$1=$1` has the side-effect of stripping the leading whitespace $ awk '{$1=$1} /Not (Before|After ):/{ print } /X509v3 Subject Alternative Name:/{ printf "%s", $0; getline; $1=$1; print }' ssl-cert Not Before: Oct 18 00:00:00 2016 GMT Not After : Dec 8 23:59:59 2017 GMT X509v3 Subject Alternative Name:DNS:*.eff.org, DNS:*.dev.eff.org, DNS:*.staging.eff.org It's essentially the same as doing the following in `sed` $ sed -E -n 's/^ *//; /Not (Before|After ):/p; /X509v3 Subject Alternative Name:/{ N; s/\n *//p; }' ssl-cert Not Before: Oct 18 00:00:00 2016 GMT Not After : Dec 8 23:59:59 2017 GMT X509v3 Subject Alternative Name: DNS:*.eff.org, DNS:*.dev.eff.org, DNS:*.staging.eff.org `n` in sed is the same as `getline` `N` too reads in the next line but it appends it to the current line (well, current pattern space) - so we then need to strip `\n *` `p` is print
&gt; rm -f $files I suspect this is going to end terribly for you. If you re-read your logic, you're running that that for each iteration of 'entry'. What you probably want to do is set a variable to true if you find a match, and then delete if its still false at the end of the loop. 
&gt; but I would need to change my shell back to bash to confirm the behavior No, you don't. Just feed your script to the ```bash``` executable. $ bash ./todo3.sh Also if you don't test it with bash, you might wan't to update the Hashbang line to use zsh instead of bash.
Why? No they shouldn't. You're wasting paid time for no benefit. It's literally a waste of money. If it works and it works, it ain't stupid. And you can move on to serious tasks.
 #!/bin/bash -x enables debugging mode. 
As in {function name} {file name} {line number} ? I can do that. 
Here is it: https://gist.github.com/ldante86/08aeb2bbe2d302ab12dd0b0f31a7fd71
Line 48 can be changed to any printing style.
This is probably best: printf "%s\t%s\t%s\n" "{$(echo ${fname[i]} | tr -d '()')}" "{${in_file}}" "{${lineno[i]}}" &gt;&gt; "$out_file"
a few curated links: https://github.com/learnbyexample/scripting_course/blob/master/Linux_curated_resources.md#shell-scripting
I spend so much of my computer time in the shell that it has become second nature. I got into the shell and scripting for it immediately when I started to use Linux several years ago. Before I started shell scripting I was proficient in C/C++/python. The only computer science-related class I ever took was Web Development in high school where l I learned HTML. Everything that came later was self-taught. Since the shell I’ve learned a great deal about Ruby and FORTRAN and better web development tools like CSS and PHP. After nine useless years of college I spend all my time working (nothing to do with technology, unless you consider a pallet-jack an interface), so I don’t have the time to do much beyond the shell. That’s why I learned bash: I wanted to do a lot in a short amount of time. How I learned it was from printed books. Classic Shell Scripting is my personal favorite. Learning the Bash Shell and the Linux Phrasebook (the first one I ever read) should be required texts. I recommend reading as much on the subject as possible, write as often as you can, read man pages and, most importantly, study real full-length scripts (not just the minimal ones found in textbooks). It takes time, but if there’s a will....
I learned commands on unix from college. When I got more info linux, one thing that helped a podcast, Linux Reality by Chess Griffin. He stopped making episodes at 100, and that was awhile ago, but they are still available online. I also like the book *Linux in a Nutshell*, both the Pocket Guide and the full version. They cover shell-scripting. Another book I like is *The Linux Command Line A Complete Introduction* by no starch press. I guess I like books, but I do use Google a lot when I'm trying to solve a particular problem and run into trouble. 
Started with Bourne shell on Unix System 7 in the early 80's. Didn't have command line recall or editing, so that was painful. Didn't even have vi back then. Just ed. After that I used ksh for a while. When bash came along it had a bunch of nifty features, so I've stuck with that since, but I still tend to write my scripts without much bash-only extensions. Once you understand parsing, everything else is simple. I think learning bash, as with any other language, is best accomplished by actually writing utilities in it, things that are useful to you, as needs come up, figuring out what is its strengths, its weaknesses, what it can do well and efficiently, and what it can't.
I got started by basically using Linux as my main system.
I was living away from home one year, didnt have any friends over there, nor internet where I lived, and I had linux installed on my computer.. so there wasnt much I could do, really. Started to make small stuff like /mp3-commands for irssi/BitchX (for when I got back home) that said what kind of music i was listening to, then system information scripts, and so on. Today I have a facebook-messenger bot, that takes command via the facebook chat and can initiate downloads of Movies and shows just by doing '.request Thor', and it then tells me when its done and ready to view on Plex.. So went from small tools, to big tools. Learned by failing. 
[Here is the mobile version of your link](https://amazon.com/gp/aw/d/1593273894?tag=as_mi_tl-20&amp;sr=1-1&amp;ie=UTF8&amp;keywords=how+linux+works&amp;qid=1415866438)
You could probably update it to match: function poop() { } function poop { } poop() { } I'm also curious if you could somehow leverage `declare -F`... edit: sed ':a;N;$!ba;s/\n/ /g' &lt;file&gt; \ | grep -oE '(function)?\s*([0-9a-zA-Z_-]+)\s*(\(\))?\s*{' \ | sed -e 's/function//g' -e 's/[(){ ]//g'
why not `while (( i &lt;= users ))` ? or `for (( i=1; i&lt;=users; i++ ))`
I started on bash for creating outputs that are legible, simple parsers for reading some logs and stuff. I learned about piping outputs from one command to another etc. Most commands being grep, cut, sed and curl. After a while, I started aliasing common commands and then moved on full fledged bash scripting. I went in with the same programmer mindset: how can this be automated? Started searching and stackoverflow had a lot of my answers. Sometimes I google for a solution I already know to see others' solutions to the same problem. This helped and pointed me to tldp.org. This site had a lot of examples and more documentation than plain man pages. 
Just use cron. 
`function poop {}` is a function, unless you're saying its emptiness makes it not a function? If `.` is a valid character for a function name, then add it to the list of chars being matched by `sed`. If you want to ignore commented functions, add something to process the file first, to remove `#.*$`.
Thank you, geirha, for pointing this out. 
Put that loop in a script with a different name, and `exec` it inside a sub shell? I'm not sure. 
Fun stuff. How about adding a function that pulls the 5 top posts in a passed subreddit and outputs them to you cli?
What is a passed subreddit? Google doesn't know.
The hardest part is the fact that everything -- apart from page generation code -- is on the first line of the source file, which is usually 30,000 characters wide. 
You should post a gist from www.github.com that contains all your code. Better yet, just create a github account/repository and store it there.
http://www.github.com/ldante86 I also have gists. 
Thanks a lot! Since I was never a CS major, it took years of trial and error to get good. Lcal was originally over 5000 lines, had 50 flags and was UGLY. This version is how I think it should be. I also have a ruby version called rcal. I'm not the best at ruby, but I'm working on it.
&gt; This is a feature inherited from the Bourne shell. It's an almost useless feature by today's standard, but maybe it made sense way back then. Not useless at all. It's great for parsing text files without any external commands (i.e. with good performance). 
I'm not sure what you mean by "web data" but if it's anything you care about, or that the application cannot simply recreate required, then it shouldn't be in ~/.cache. There's a lot more in ~/.cache than "web data". My ~/.cache currently contains files from 30 applications totals 1.5GB and 25k files. That's a lot of stuff to pointlessly back up.
I mean web data when I mean web data. Firefox uses ~/.cache/mozilla for its temp files. 
You might want to remove your client id. And for those who do not know mpv's format string format, I would appreciate a case there to choose a format for the users convenience. :-) otherwise, well done. :-)
I'm having difficulty finding out what your `declare -p` and `declare --` are doing. Can you clarify? 
Oh. Thanks. I did `man declare` and it took me to DECLARE -define a cursor which is a postgres thing. 
And arrays are zero indexed: k=1 streams=() streams[k]+="xxx" Should be: k=0 streams=() streams[k]+="xxx" Or even: streams=() streams+=("xxx")
&gt; read(1) only read(2)s one byte at a time Really? I was playing with Bash workers via FIFOs before, and it seemed that `read` would read chunks of data at a time, so you’d have to write constant-length messages and use `read -N` – a normal `read` would consume data past the line break, which would no longer be available to other workers.
Thanks for taking your time correcting the script and write all these! Appreciate it! They do say you learn something everyday...
My preference would be to code this for an arbitrary number of users, rather than asking for the size of the array as an input. #!/bin/bash # A script for adding an arbitary number of users from prompt input echo "Enter the users' names, one per line. When done, press [ENTER]" while read USER; do if [ -z $USER ]; then echo "All done, exiting." break fi echo "adding user " $USER # replace with your USERADD command done 
Nearly everything in bold in my original post is a comment, reddit formatted it that way for whatever reason and I just left it, thinking that that was normal behavior. echo "From which machine would you like to pull files?" read machine ssh -q "$machine" ls -lthr /tmp/directorya /tmp/directoryb echo "Which files would you like to copy?" read -a files arraylength=${#files[@]} prefix=$machine suffix="$(date '+%d-%m-%y')" directory=${prefix}_$suffix mkdir /tmp/"$directory" for ((i=0; i&lt;arraylength+1; i++ )); do if ssh -q "$machine" test -e /tmp/directorya/"$files" then for files do scp "$machine":/tmp/directorya/$i "$(hostname|cut -d. -f1)":/tmp/"$directory"/ done elif ssh -q "$machine" test -e /tmp/directoryb/"$files" then for files do scp "$machine":/tmp/directoryb/$i "$(hostname|cut -d. -f1)":/tmp/"$directory"/ done fi done
cool whats the $ , I dont know any of bash's syntax, never done any scripting with it before, just some parted, got a ggod synatx guide for these symbols?
Man bash is a good start, explainshell.com is handy, nixcraft is a decent resource a well
The $? is a special variable in bash that holds the exit status of the last-ran command. By convention (generally speaking), if it's zero, then the command exited successfully; otherwise, an error or something unusual occurred. (Always check the man pages to see what exit statuses mean what). In the case of grep, an exit status of zero means that an instance of your pattern was found. But, as /u/buckyball60 points out [here](https://www.reddit.com/r/bash/comments/5cqi97/i_need_to_parse_a_file_and_depending_on_a_keyword/d9yr1xv/), you can simply use grep inside of an if/else.
There's also a bug I found, so I made a BUGS file for documenting those. https://github.com/ldante86/lcal/blob/master/BUGS.md
Thanks for the reply! I live in California so I've been through a few earthquakes, they can definitely be unnerving. I hope you're ok and none of your stuff broke! I have already accounted for the spaces, the file names on the other end are created with another script when a user takes the appropriate action, they have been designed to not have spaces in the names. I'm not sure if that's technically the correct way to handle that, but it should work, right? Also, IT FINALLY WORKS!!!!! THANK YOU SOOOOOO MUCH!!!!
Three main ways: 1) `tr` to a temporary file and overwrite the original file. e.g. `tr '[:upper:]' '[:lower:]' &lt; inputfile &gt; outputfile; sleep 1; mv outputfile inputfile` 2) `awk` in a similar fasion e.g. `awk '{print tolower($0)}' &lt; inputfile &gt; outputfile; sleep 1; mv outputfile inputfile` 3) `sed` using `-i` for inline editing is the immediate option that comes to mind for doing this without having to manually handle a temporary file, something like e.g. `sed -i 's/\([A-Z]\)/\L\1/g' inputfile` Note: this is GNU `sed`, other versions of `sed` likely won't work with this. There will, of course, be 800 different ways to do it with `awk`, `perl`, `python`, `ruby`, `golang` or whatever else. `tr` is almost always the first option used. Maybe after I have my dinner I'll give a bonus "pure `bash`" option. It won't be pretty. /edit: Dear downvoters: `&lt; in &gt; out; sleep 1; mv out in` is just one way to do it. I've personally seen `; mv` and `&amp;&amp; mv` fail as a race condition, but you're free to use those if you please. Throwing a cursory `sleep 1` in there is safe, defensive coding, and portable too. A `bash 4` option is shown below that proves my point - it's not pretty relative to any of the one-liners mentioned or available. For older versions of `bash` it would be even worse. It also uses `echo` instead of `printf`.
sed -i
&gt; Everything I have seen so far needs you to have another output.txt file for it to work That's because none of the commands you've seen are actual file editors - if you want to modify the original file you would need to use an actual editor such as `ed`, `ex`, `vi`, etc. Some commands will store the output into a temporary file and replace the original file for you e.g. `perl -i`, `sed -i` (depends on your version of `sed` as already mentioned by others), and `gawk` The simplest of these options would be `perl` perl -pi -e 'tr/A-Z/a-z/' run.txt If you want to actually edit the original file as opposed to overwriting the original file it's probably simplest using `ex` ex -c ':%s/.*/\L&amp;/' -c wq run.txt 
None of the answers so far validate the user input. You should do that before using it in an arithmetic context. read -rp 'Enter number of users: ' n while [[ $n != [1-9]*([0-9]) ]]; do printf &gt;&amp;2 'Please enter a positive integer\n' read -rp 'Enter number of users: ' n done for (( i = 0; i &lt; n; i++ )); do printf -v username user%02d "$i" printf 'Creating %s\n' "$username" # useradd ... "$username" done
Great project... I'll try my hand at it and moreover I'd like to include your work as a module in my own library https://github.com/bashlets/bashlets
Wow, I had no idea tar had auto-detection. Makes my script a bit superfluous. 
Thanks! You can use it any way you'd like! Your project is quite extensive. 
Fixed.
This is a commonly found `.bashrc` function (almost always named `extract`), you may like to investigate one of those and possibly add your own changes e.g. http://www.tldp.org/LDP/abs/html/sample-bashrc.html (ctrl+f &gt; extract) https://wiki.archlinux.org/index.php/Bash/Functions#Extract https://github.com/xvoland/Extract/blob/master/extract.sh An example of a modified version (that I haven't used or tested) can be found here: https://bbs.archlinux.org/viewtopic.php?id=110601 Another modified version (that I haven't used or tested) can be found here: http://bashscripts.org/forum/viewtopic.php?f=28&amp;t=231 /edit: and the counter-function `compress` is rarer, but google-able e.g. https://gist.github.com/itelo/50f4a7c606af90b3c61c
I can see that you have some `bc` functions. I have a few of my own if you need them. https://github.com/ldante86/bc-scripts
show us a chunk of your code
you should use a case statement case $? in 0) # Success ;; 1) # Error ;; # continue to 30 esac
Thanks! That should work.
I normally use the 'unp' command to extract most any archive i come across. (paste of the man page, it goofs up reddit formating however, sorry) --- unp(1) General Commands Manual unp(1) NAME unp - a shell frontend for uncompressing/unpacking tools SYNOPSIS unp [-u] file [ files ... ] [ -- backend args ... ] ucat file [ files ... ] unp is a small script with only one goal: Extract as many archives as possible, of any kind and from any path to the current directory, preserving the subdirectory structure where needed. Is a Do-What-I-Want utility and helps managing several extraction programs without looking for needed options for the particu‐ lar tool or worrying about the installation of the needed program. Run unp without arguments to see the list of supported archive formats. The special version ucat acts as wrapper for commands that can output the extracted data to standard out‐ put, like bzip (bzcat), gzip (zcat), tar, zip and others. USAGE unp extracts one or more files given as arguments on the command line. Additionally, it may pass some options to the backend tools (like tar options) when they are appended after `--´. There is also a special option (-u) which is very useful for extracting Debian packages. Using -u, unp extracts the package (i.e. the ar archive) first, then extracts data.tar.gz in the current directory and then control.tar.gz in control/&lt;filename&gt;/. NOTES unp will try to decompress into a FILE.unp if it get trouble with existing files. But don't count on this feature, always look for free working space before using unp. Unlike gunzip, which decompresses the file in the target directory of the source file, unp uses the current directory for output. AUTHOR Development started by Andre Karwath &lt;andre.karwath@informatik.tu-chemnitz.de&gt; Now maintained and packaged for Debian by Eduard Bloch &lt;blade@debian.org&gt; 18 Feb 2001 unp(1) 
With `bash` you can just do this with `mv`. Example: mv /path/to/original_file.txt /path/to/new_file.txt However I am not very versed or familiar with bash on a Windows file system.
If that suits your situation, then that's exactly what you should do! You hadn't said if you expected `c:/out/out_a.txt` to already exist or not. Keep in mind it needs to go between the word move and the first file name.
This is what I use. Life has been so much easier with this function. Well not really, but it is very useful. 
`#!/bin/bash` will not be portable to most UNIX-like systems. Lots of interesting stuff though, most notably the version sorting.
Seems to rely heavily on GNU tools and non-standard commands anyway, so it will most likely only work on GNU/linux systems.
Thank you very much, I'm always keen to learn more about bash, I work as a Linux admin (RHEL mostly) but because I have a good Windows scripting background my bosses have me spending so much time in PowerShell that I'm way out of practice with bash. I'll test your suggestions out over the next couple of days.
Another reason is that older versions of `test` often got confused if the string was empty or started with a hyphen. This is no longer a problem.
Speed results are just in! **TL;DR**: on bash 4.4.0, `[ -z "$a" ]` is the fastest way of testing for zero-length (unset) arguments. # a is unset at first sh-4.4$ i=0; time { while ((i &lt; 1000000 )); do [ "x$a" = "x" ]; : $((i+=1)); done } real 0m5.600s user 0m5.593s sys 0m0.000s sh-4.4$ i=0; time { while ((i &lt; 1000000 )); do [ "x$a" = "x" ]; : $((i+=1)); done } real 0m5.592s user 0m5.570s sys 0m0.003s sh-4.4$ i=0; time { while ((i &lt; 1000000 )); do [ "x$a" = "x" ]; : $((i+=1)); done } real 0m5.649s user 0m5.650s sys 0m0.000s sh-4.4$ i=0; time { while ((i &lt; 1000000 )); do [ -z "$a" ]; : $((i+=1)); done } real 0m4.982s user 0m4.967s sys 0m0.000s sh-4.4$ i=0; time { while ((i &lt; 1000000 )); do [ -z "$a" ]; : $((i+=1)); done } real 0m5.038s user 0m5.037s sys 0m0.000s sh-4.4$ i=0; time { while ((i &lt; 1000000 )); do [ -z "$a" ]; : $((i+=1)); done } real 0m5.016s user 0m5.017s sys 0m0.000s sh-4.4$ a=testing; i=0; time { while ((i &lt; 1000000 )); do [ "x$a" = "x" ]; : $((i+=1)); done } real 0m5.725s user 0m5.727s sys 0m0.000s sh-4.4$ a=testing; i=0; time { while ((i &lt; 1000000 )); do [ "x$a" = "x" ]; : $((i+=1)); done } real 0m5.741s user 0m5.717s sys 0m0.020s sh-4.4$ a=testing; i=0; time { while ((i &lt; 1000000 )); do [ "x$a" = "x" ]; : $((i+=1)); done } real 0m5.696s user 0m5.657s sys 0m0.020s sh-4.4$ a=testing; i=0; time { while ((i &lt; 1000000 )); do [ -z "$a" ]; : $((i+=1)); done } real 0m5.202s user 0m5.193s sys 0m0.000s sh-4.4$ a=testing; i=0; time { while ((i &lt; 1000000 )); do [ -z "$a" ]; : $((i+=1)); done } real 0m5.288s user 0m5.277s sys 0m0.000s sh-4.4$ a=testing; i=0; time { while ((i &lt; 1000000 )); do [ -z "$a" ]; : $((i+=1)); done } real 0m5.302s user 0m5.283s sys 0m0.000s
Can you sum it up for me?
Ha, I rarely see examples like this anymore. Your beard just got longer and grayer my friend!
Please don't `curl | bash`
Look at udev and systemd. Then again, you should not bypass your company policy and check whether thats ok.
Why not?
I want to stress the fact that this is not a generically-compliant POSIX shell project; on the contrary, the aim of the project is to write code that will run on (and require) Bash. As to the rest of the environment, however, the long-term goal is to get rid of dependencies on external tools as far as it is possible (or reasonable) to do so, even though at present the code does assume a reasonably standard GNU/Linux system.
Because security. https://www.idontplaydarts.com/2016/04/detecting-curl-pipe-bash-server-side/
Actually, the project has a threefold aim: 1. bringing together the largest possible corpus of useful pieces of reusable Bash code, with everything organized in as neat a fashion as we can think of 2. shielding the user from some of the Bash technicalities and idiosyncrasies 3. writing a consistent and portable API (well, kind of) towards the operating system
You might like to keep your logic simpler, e.g: 1) remove any instances of 'nousb', as this should only be on the kernel line you shouldn't need any great smarts here, something like `sed -i 's/nousb//' /boot/grub/grub.conf` 2) Next, if your line starts with 'kernel', append 'nousb', using your current `sed` command: `sudo sed -i '/^\s*kernel/ s/$/ nousb/' /boot/grub/grub.conf` 
It's all theory, at this point. Assume all security has been considered. I am not bypassing company policy in doing this, but I appreciate your concerns! There are several reasons why this would be ok in my situation, but the short of it is that there are several factors limiting access to the machines that would be capable of auto mounting this ironkey and even the ironkey itself.
I have been writing shell wrappers for years, and never did this. Will do it from now on.
I have recently started doing bash -$- ./subscript.bash in my scripts that call sub scripts That means that I can use bash -x ./manuscript.bash and automatically run sub scripts with the -x flag Fully agree on pipe fail etc, see http://redsymbol.net/articles/unofficial-bash-strict-mode/
`set -e` gets tricky very fast for larger scripts, when you start splitting them into functions. There are a lot of special cases for it, for instance the `if` statement disables it: set -e mytest() { false ; # does not exit here true } if mytest; then echo this prints fi It doesnt carry on in subshells, so you'd have to re-enable it each time. In the end, you should do your own error checking instead of trusting an automated mechanism. 
Thanks for the tips! Especially shellcheck, that was very useful as I rewrote the code :) 
This is probably a very basic silly question, but if I want to package and distribute a script like this, how do I make sure that other people also have the files I'm copying? Is it typical package your script as a script that creates these files in, say, ~/bin/myscript, and then add the path to their ~/.bashrc? And thank you so much for the tips!
That used for checking if something else you called ran successfullylike if [[ $? -ne 0 ]]; #error stuff And on command like to string things together like cmd1 &amp;&amp; cmd2 cmd2 will only execute if cmd1 succeeds (0 exit code). Opposite pattern cmd1 || cmd2 cmd2 will only execute if cmd1 fails (non zero exit code). Generally cmd2 would be some kind of error handling situation. 
Using builtin `read` (I don't have `rpm` so I'll fake that part with a function) $ rpm() { echo 'chefdk-0.18.30-1.el6.x86_64 Wed 26 Oct 2016 12:42:32 PM CDT'; echo 'hurr durr'; } $ rpm chefdk-0.18.30-1.el6.x86_64 Wed 26 Oct 2016 12:42:32 PM CDT hurr durr $ read -r pkg dt &lt; &lt;( rpm -qa --last ) $ echo $pkg chefdk-0.18.30-1.el6.x86_64 $ echo $dt Wed 26 Oct 2016 12:42:32 PM CDT 
That depends on who you are intending to distribute it to. This seems unlikely to be something that is mass-consumed.
 for (( i=1; i &lt; 100; i++ )); do # loop from 1 to 100 printf -v name "$02d-filename.txt" "$i" # use %02d to zero-pad and get your name [[ -f $name ]] || break # Stop once you got a name which is not already used done if (( i == 100 )); then # Make sure we found a filename and not 100 printf "You already got 99 files." &gt;&amp;2 exit 1 fi foo &gt; "$name" # Use the file
It's done with parentheses: min=$(( (main_length - currsecs) /60 ))
P comes before D in PEMDAS
Since your filename starts with a number we can use a quick awk hack to do it: name=$(ls|sort -n|awk '{last=$1} END { num = last+1; printf("%02d-filename.txt\n", num) }')
your pallete= line didn't quite work, ffmpeg seems to check the file extension of the pallete file so to solve that I just put the mktemp in quotes with .png on the end: palette="$(mktemp).png";
Tsk, bad ffmpeg ;) File extensions are but three letters at the end of the name and shouldn't be relied upon as an indicator nod file type. 
Yeah, I would have expected ffmpeg devs to be beyond extensions... oh wells its an easy fix.
 n=$(grep -c $username /etc/passwd) Your n contains the string, not the value returned by subshell.
He wants you to read a text file (a bash script) line by line. If you find a line that starts with `while` `until` or `for` you need to add "#loop n" to the end of that line. "n" is the number of the loop. So the first time you add one of these comments, you add, "#loop 1". The second time you add "#loop 2" and so on. Find the corresponding `done` for each of the above and add "#loop n" after it as well. Same for `if` -&gt; `fi` and `case` -&gt; `esac` blocks. These should have "#selection n" appended. The "include all of the following" part of the instructions is just telling you to include lots of comments and format your code properly. The tricky part is that the loops and conditional blocks could be nested in the input. The output would look like this (and the input is the script without the comments): #!/bin/bash while true; do #loop 1 echo "ok" while false ; do #loop 2 if true ; then #selection 1 echo "stuff" fi #selection 1 echo "hello" done #loop 2 done #loop 1 
Holy shit thank you so much man. Thats an absolutely perfect explanation, I understand completely. Thanks again!
Put quotes around the subshell. Otherwise its results are subject to word splitting. Also, I'm going to guess based on that message you're getting more than one result from your `grep` so this might not end up doing what you want anyway. Still, it's almost always the right choice to quote your variables/subshells: elif [ "$(echo "$bat" | grep -Eo '[0-9]{2}')" -gt 75 ]; then Also, consider using `printf` instead of `echo` since it handles more situations correctly (see [here](http://unix.stackexchange.com/questions/65803/why-is-printf-better-than-echo)) elif [ "$(printf '%s' "$bat" | grep -Eo '[0-9]{2}')" -gt 75 ]; then 
The single quote in "Don't" introduces a string literal. These can be multiple lines, so it lasts all the way to the `'` in the following "Don't". You can escape the single quotes with backslashes: echo Don\'t forget to fold the laundry or just enclose the string in double quotes (but note that `$` and a few other chars retain their special meaning within double quotes, unlike in single quotes): echo "Don't forget to fold the laundry" [Here is some more information on how quoting works in the shell.](http://linuxcommand.org/wss0060.php) (edited: better link) Also, if you're on bash, use `[[` instead of `[`; the former has much fewer pitfalls. *edit:* Can whoever downvoted this please clarify how this is wrong?
Why don't you google around for some basic tutorials, [Link](http://ryanstutorials.net/linuxtutorial/scripting.php). Your assignment is actually pretty simple once you go through a few online tutorials to help you start...
shellcheck.net is your friend for these kinds of issues also.
Yeah I have. Watched some intro videos too. I realize they are simple assignments but not when you have never done this before. I guess it just feels like an awful lot to learn in a weeks time (There are 9 scripts we have to write). Since the professor gave me no instruction, I was hoping for some help or suggestions from an actual human. Thanks for the link, I'll read that too
Np, if you need any help while you work on your assignment you can pm me :) I'd recommend testing out the scripts while you write them and run them with the debugger flags set around the code you want to test: #!/bin/bash set -x ..code to debug... set +x or even run the entire script bash -x script.sh
Indeed, and that's certainly works on a bash themed subreddit. It's worth pointing out that `[[` is not portable though. It does more often work how people seem to expect, and also allows regex comparisons.
And this is the nature of programming, starting with WTF, then figuring crap out one step at a time. 
You may want to use integer comparison. if (( $(echo $bat | grep -Eo '[0-9]{2}') &gt; 75 )); then Or, better yet, capture the command output in a variable. val=$(echo $bat | grep -Eo '[0-9]{2}') if (( val &gt; 75 )); then Make the variable something that adds to readability. 
To the top with you!
Does your school have a library? With books? With books about basic bash usage? Maybe some that a professor might give the names of at the start of the course?
Well what have you tried? The second one is much easier - so starting with that: You can use `variable=$(command)` to store the output of `command` into `variable` To get the number of lines in a file you can use `wc -l &lt; filename` (or a `while read` loop if you have to do it in bash) For arithmetic testing - there are a few ways - one of which is x=7 ((x &gt; 5)) &amp;&amp; echo "x is greater than 5, it is $x" As for the first question - I'm not sure how `ls` is going to be useful. I'd imagine you would have to use a for loop to process each entry for name in * do if [[ -d $name ]] then # directory else # not a directory fi done 
You can simplify the last part with for dir in */ do # directory done
Have you googled anything? Because I did and found a solution for your first one immediately. Seems to be a common homework task. You need to search for solutions to your problems first, then try and understand them, try to apply them to what you're trying to do, and if you need something explained, that's when you come here. We're not here to do your homework for you.
With `ls` it might work like this: function recursivelist() { indent+=' ' ls --group-directories-first | while read; do echo "$indent$REPLY" ( cd "$REPLY" &amp;&gt;/dev/null &amp;&amp; recursivelist ) done } indent='' recursivelist
Believe me, I've tried searching for at least 3 hours now. 
 if [[ wc -l $file -lt 5 ]] Yeah you'd need to use `if [[ $(wc -l &lt; "$file") -lt 5 ]]` the `$()` captures the output of a command as mentioned. The file could also have 5 lines exactly, you'd have to handle that case also.
"bash implementation of tree" Plenty of results there. I'm not going to point to any one result in particular, I'll leave that to you. There is at least one that meets your requirements, and it could still do with some fine-tuning, enhancement and customisation. /edit: accidentally a word
Still not getting it too work... batperc=$(echo $bat | grep -Eo '[0-9]{2}') elif [ $batperc -gt 75 ] ; then And it says I have too many arguments. If I do this: elif [[ $batperc -gt 75 ]] ; then I get: 47: syntax error in expression (error token is "030147") 
Note that the variable `indent` and the current working directory are changed inside a subshell, which means they're 'forgotten' when that subshell exits. Merely calling and returning from a function will keep the variable and current working directory intact which is NOT what you want (unless you use `local` and `cd` to the previous working directory). So for the first directory you update `indent`, and go through the directory list (`ls | while read` puts files/dirs into the variable $REPLY). They can be printed straight away with the indent. `cd` will fail if the file is not a directory (`&amp;&gt;/dev/null` will stop it printing errors), otherwise it'll go inside that directory and start another function call as if from scratch (but `indent` is bigger). When everything inside a subdirectory has been printed, the program should restore `indent` to what it was previously (or else the other files in the current directory will get extra indentation) as well as actually return to the previous working directory and that's easiest by doing all the commands that change things inside a subshell that'll forget the above stuff on exit which is started like this: `( command )`.
I'd set up a CRON to run the script every minute and track the variable in a flat file. The hard part is that there are many ways to do it. Is for like resource monitoring, cpu and such?
something along the lines of: if int &gt; 10 start counting if not already counting if you you've been counting for 5 mins freak out else increment counting else reset counter phone pseudo-coding at its best/worst.
 high=0 # Assume it starts not-high, ie under 10/20 while sleep 10; do output=$( curl ... ) if (( output &lt; 10 )); then high=0 # Record if it's not high queue len elif (( ! high &amp;&amp; output &gt;= 10 )); then # First time we see high queue. SECONDS=0 # Record the start time high=1 # Note that it is high queue len elif (( high &amp;&amp; SECONDS &gt; 5*60 )); then # High queue len for over 5 min echo "High qLen for 5 min" cp logs backup pkill -HUP app mail -s "High qLen" $USER &lt;&lt;&lt; "Message" fi done Note: I got conditions in there that can be derived and are not actually required. while time_left=$((end - SECONDS)); inotifywait -e close_write -t "$time_left" -q "$file"; do This is a while-do loop. The while condition is the list of command: time_left=$((end - SECONDS)); inotifywait -e close_write -t "$time_left" -q "$file" This (1) computes the time left until 5 minutes (or $end) is reached, ie $end minus the number of $SECONDS passed. It then calls the program inotifywait. It will wait until a "close_write" event occurs on file "$file". The -t tells it to only wait $time_left seconds and -q is the quiet mode. If a close_wait occurs, it exits with success and the loop body is executed. If it times out, ie we ran out of time to hit 5 min, it exits with 2 and the while loop ends.
Most logic and more complex code in the shell can be done in Perl or Python. It's all a balancing act of finding the tool most appropriate for the task at hand. Note, that article has a few stylistic choices which fail best-practices: * All-upper-case variable names are strongly discouraged. * Variable expansions (eg echo "$now") should **always** be quoted.
Can you explain this one to me This is what I got: &gt;If the output is greater than 10 then &gt; Flag high=0 &gt;else if high is not 0 AND output is greater than 10 &gt;Start timer &gt;Set high to 1 &gt;else if high AND Seconds are greater than 5 minutes &gt;echo 'blah blahblah' This part is confusing to me elif (( ! high &amp;&amp; output &gt;= 10 )); then SECONDS=0 high=1 To me this means that it is changing the variable high to 1, if high already =1 and output greater than 10 since this is the only place in the script that flags high=1 - how can it be 1 in the first place? 
So actually what it means is if high is true and output greater than 10 
That means you failed to parse out the wanted value. Instead, the grep outputs multiple lines because there were multiple matches in the input. If you show the command or file you originally extract the data from, we can help you choose a better way to parse it. A good solution will likely not involve grep at all.
I don't think your `grep` will get the percentage very well. If it's full, for example, you won't match `100`. If you have GNU's grep you could do this instead as if [ "$(acpi -b | grep -Po ', \K\d+')" -gt 75 ]; then the `-P` uses perl style regex, and in particular we want that for part of the pattern. In this case, we'll look for a comma and space followed by some numbers. The `\K` tells grep to not include the part of the pattern before that in the part that's output. Of course, if you have more than one battery this will still produce too many results to be used in the test this way.
Yeah, sorry. Thought about it but I don't have access to my computer. Realized I have another laptop with it at home with ssh on, here's the output: Battery 0: Charging, 98% As I said, my grep currently looks like it only returns 98 (or whatever the two last numbers are).
Thanks, didn't think about that. I'll test it when I get home tonight.
It works this way as well, but how does it differ from my script?
Thank you! I get it, I guess :D
thanks again, will change to `env` when I try to make the script portable :) by interactive usage, I meant `ch` not `mktemp` :) 
what about two users running it at the same time? ;)
:) You might be interested in [resources to learn about text processing commands](https://github.com/learnbyexample/scripting_course/blob/master/Linux_curated_resources.md#text-file-processing) see also: https://unix.stackexchange.com/questions/169716/why-is-using-a-shell-loop-to-process-text-considered-bad-practice
Got a chance to look at this, and after looking up what your example does, replacing 4 with 7 does the trick for me. Thanks a lot!
Take a look at `crontab` as well as `notify-send` Alternative one can run a command in background by appending `&amp;`, i.e: while sleep 15; do check_mail done &amp; 
It's shorter for one, but it also tests ( -f "$1") whether the argument is a file and exits with error (1) if not. Since Valve's steam package deleted home directories (or was it root) due to NOT CHECKING, I always check input _especially_ before deletes but it's nice to get in the habit of it.
I'm pretty sure synergy actually already has this built in. 
Pretty sure, huh? What do I need to do to make it work? It doesn't do it by default, that's for sure.
You may want to standardize on your tab spacing. Don't use capitalized variables, they can clobber environment variables. `$(echo $(ssh ... ))` ... the echo here is superfluous. For giggles (I recommend you join wakeup and lock-xscreensaver into `remote-screensaver [lock|unlock]` or something.) wakeup: #!/bin/bash # Ensure only 1 copy of script can run at a time (example in 'man flock') if [[ "$FLOCKED" != "$0" ]]; then exec env FLOCKED="$0" flock -en "$0" "$0" "$@" fi log_file='/tmp/wakup.log' # Write STDOUT to $log_file exec &gt;&gt; "$log_file" port=24800 hosts="$(netstat -an | awk -v port="$port" '$5 ~ port { print $5 } \ | cut -f1 -d: | sort -u)" max_retries=3 user=username ssh="ssh -o 'StrictHostKeyChecking=no' -l $user" while read -r host; do # Start sub-shell so commands can be backgrounded and unlocking isn't serial ( retries=0 while $ssh $host "xscreensaver-command -time | grep locked"; do $ssh $host "pkill -HUP xscreensaver" retries=$((retries + 1)) if [[ "$retries" -gt "$max_retries" ]]; then printf "Max retries (%s) hit; Failed to unlock host %s\n" \ "$max_retries" "$host" 1&gt;&amp;2 break fi done ) &amp; done &lt;&lt;&lt; "$hosts" wakeup-watcher: #!/bin/bash /usr/bin/xscreensaver-command -watch | while read input; do if [[ "$input" =~ ^UNBLANK ]]; then /path/to/wakeup fi if [[ "$input" =~ ^LOCK ]]; then /path/to/lock-xscreensaver fi done lock-xscreensaver: #!/bin/bash # Ensure only 1 copy of script can run at a time (example in 'man flock') if [[ "$FLOCKED" != "$0" ]]; then exec env FLOCKED="$0" flock -en "$0" "$0" "$@" fi log_file='/tmp/wakup.log' # Write STDOUT to $log_file exec &gt;&gt; "$log_file" port=24800 hosts="$(netstat -an | awk -v port="$port" '$5 ~ port { print $5 } \ | cut -f1 -d: | sort -u)" max_retries=3 user=username ssh="ssh -o 'StrictHostKeyChecking=no' -l $user" while read -r host; do # Start sub-shell so commands can be backgrounded and unlocking isn't serial ( retries=0 for display in $($ssh $host "pgrep -a Xorg | grep -o ':[^\b]' | sort -u); do while ! $ssh $host "xscreensaver-command -time | grep locked"; do $ssh $host "DISPLAY=${display}.0 xscreensaver-command -lock" retries=$((retries + 1)) if [[ "$retries" -gt "$max_retries" ]]; then printf "Max retries (%s) hit; Failed to lock host %s\n" \ "$max_retries" "$host" 1&gt;&amp;2 break fi done done ) &amp; done &lt;&lt;&lt; "$hosts"
A couple of things here. * You quote `"$file"` which is good ... but you fail to quote `$1`. * You got a for-loop that iterates over a single value. You could achieve the same using `file="$1"` * This is a useless use of cat - rather than doing `cat "$file" | sed` you can pass the filename to `sed` directly, ala `sed "$file"` * When you say "k times" do you mean k times per line? Your `sed` expression specifies to replace just one occurrence. Or do you mean once per line for the the first k lines that have that expression? Or some combination thereof? * If `sed` isn't writing to a file, then each instance of `sed` will read the same input. You could write the output back to a file. Or not use sed at all.
Your instructions say "a file". If you are only handling 1 file, the loops are unnecessary and may be hindering your progress. You also don't need cat. sed itself will read whatever file is given as its final argument. Since this sounds like a class assignment, see if you can figure out the correct syntax. If not, reply, and I will give more. 
Yes I do mean k times per each individual line. I totally agree the sed expression specifies to replace only one occurrence but that's what the instructions say verbatim: "but you can only use sed to do one substitution at a time, i.e. sed 's/ ... / ... / 1'" However it's supposed to make multiple passes if argument 2 "$2" is greater than 1. Does that make a bit more sense?
To do multiple passes of 1 substitution each time as the assignment instructions say...unless I am missing something you are saying
The 1 at the end of the substitution says "only change the first 1 occurrence on *every line of the file*. So if the input line is "I'm so happy to be happy that it makes me happy", after you run it, it will be "I'm so *very happy* to be *happy* that it makes me *happy*" If you loop that a 2nd time, it still only affects the *first occurrence in the line*, so the result will be "I'm so *very very happy* to be *happy* that it makes me *happy*"
Thank you! I did not know that you can do this without sed. 
Hint: look into a regular expression feature called "negative look behind"
&gt; The only problem is that when sed passes a second time if the integer is greater than 1 it changes "very happy" to "very very happy" Why is that a problem? That sounds like it's the output you're supposed to generate. If you have `very happy` and replace `happy` with `very happy` - you will end up with `very very happy` ...
How about them potatoes? Or are you really forced to use `/1` only? #!/bin/bash FILE="$1" NUMBER="$2" cp $FILE ${FILE}.bak for i in `seq 1 ${NUMBER}`; do sed -ie "s/happy/very happy/$i" $FILE done echo "RESULT:" cat $FILE rm $FILE mv ${FILE}.bak $FILE *creating and restoring the .bak is of course not necessary, but it helps troubleshooting to not have the file destroyed after each run*
Yes sadly I have to use /1 it's so silly. I feel like our instructor likes to be like "ha! I tricked you" instead of teaching us practical things.
Try /r/compsci this is not a bash question in the slightest.
oh sorry :(
No need to be sorry. I just hope you find your answers. :)
I've put in my code the getpid() and getppid() functions to everything so I can check if it works properly. In the "else" section it gives me the same PID (x) for all 3 of my processes. Then, in "if" it gives me 3 different PIDs (y1,y2,y3) for each (which is what it is supposed to do), but it gives me the PPID of the ones in "else"(x). Then in the waiting part, it gives me the PID (x) and the PPID (y1) for each of the processes. After compiling your code, it seems to work, it doesn't give me any errors, but I think it doesn't do anything different because of the error in my code. 
If you keep assigning to pid then it's getting overwritten? 
Neither of your links say this is a bad idea. The first says that there are still many ways it can fail (which is true; `pipefail` catches some of them, but you still have to be stringent in your code review); the second says that it will break many existing scripts, which is always the case when you start enforcing stricter standards and isn't an issue if you do it from the get-go.
I'm not suggesting relying on it entirely, but rather that it's a useful tool to help catch bugs. In that way it's similar to code review - it won't catch everything, but it catches enough things for a low enough cost that it's worth it.
An authority? No. Except maybe Chet Ramey, bash's maintainer. For good resources, check out the side bar of this sub under "Guides". `test` and `[` are synonyms. They are regular commands. They are included for compatibility with Bourne and POSIX shells. If you code for bash only, it's best to ignore them. Many people keep using them anyway, which caused unnecessary pitfalls and confusion. `[[` is a successor to `test`/`[` that is not a regular command; as a reserved word, it's half-embedded in the shell grammar, suspending things like field splitting or pathname expansion that are normally active all the time, so it's a lot more robust. If you program for bash, always use `[[` instead of `test`/`[`. `((`...`))` are a completely different animal altogether. Normal shell grammar doesn't apply between these; this encloses integer arithmetic expressions with C syntax. For instance, `((i++))` increases the variable `i` with 1. You can also do things like `if ((i&lt;1)); then ...` These are all features borrowed from the Korn shell, by the way.
Welcome to the wonderful world of threads! I think that's what you'll need. Fork() doesn't wait. 
To me these points make it abundantly clear that they are a bad idea. Having your script arbitrarily fail because it enters a condition that is not even an error, or because you ran it with a slightly different version of bash than before, does not make it a robust script. "Enforcing a stricter standard" by using set -eu is clearly an illusion when a non-zero exit status is a fatal error in one context, and not a fatal error in a slightly different context. The rules of what is considered a fatal error have already changed between bash versions. What if the rules change again in bash 5.0? You are just adding technical debt. There is no shortcut for writing robust scripts. You must learn the language.
The state of bash resources on the internet is a sad story. Most of what you find via google searches is wrong in one way or another. The Linux Documentation Project has some bash guides that will often be among the top hits on google, which is sad since they teach bad practices, and in some places they are just plain wrong. The #bash community tried to reach out to the author of The Advanced Bash-Scripting Guide to get some of the worst errors fixed, but the author refused, so instead they started a new guide, the [BashGuide](http://mywiki.wooledge.org/BashGuide), which tries to teach good practices in addition to teaching the basics of the language. This is the only good bash guide I know about. What beginners tend to struggle with the most, is [quoting](http://mywiki.wooledge.org/Quotes). That most guides, tutorials, stackoverflow answers and blog posts often fail at using proper quoting in examples, nor explain their importance, doesn't help. Another common point of confusion is the difference between sh and bash. A history lesson about the origin of Bourne, POSIX, ksh and bash would be a good starting point. As for what syntax to choose, my general advice is to avoid the commands/features that are completely covered by newer commands/features. * Use [[ ]] to test strings and files. [[ ]] can do everything the [ and test command can, but it can also do more, such as pattern and regex matching. Therefore [ is completely redundant. [FAQ 31](http://mywiki.wooledge.org/BashFAQ/031) * Use (( )) to test numbers (integers). [[ ]] can test numbers too, but the syntax is inherited from the [ command and is clunky. (( )) uses C style syntax for arithmetics. [ArithmeticExpression](http://mywiki.wooledge.org/ArithmeticExpression) * Use arrays to store multiple pieces of data. In bourne and sh, you are limited to storing multiple items in strings, or hijacking "$@". In bash, have arrays, so use them. Since bash 4.0 there is also associative arrays. [FAQ 5](http://mywiki.wooledge.org/BashFAQ/005), [FAQ 50](http://mywiki.wooledge.org/BashFAQ/050) * Use printf to output strings. Bash's echo has options, yet it does not have a way to "escape" the options by the usual means (the `--` argument), which means it can't always output the data you want it to (`var=-e; echo "$var" # empty line`). * Avoid `set -e` and `set -u` which give the illusion of "aborting on errors". They don't work like you expect and adds more problems than they "fix". [FAQ 105](http://mywiki.wooledge.org/BashFAQ/105), [FAQ 112](http://mywiki.wooledge.org/BashFAQ/112) * Use $() for command substitution. The older `` `...` `` syntax has various problematic parsing issues. [FAQ 82](http://mywiki.wooledge.org/BashFAQ/082) * Use the read command and parameter expansions to do string manipulations. E.g. instead of `foo=$(echo "$line" | cut -d, -f1)`, you can use a parameter expansion like `foo=${line%%,*}`, or split with read: `IFS=, read -ra array &lt;&lt;&lt; "$line"`. [FAQ 100](http://mywiki.wooledge.org/BashFAQ/100) * Avoid parsing the output of `ls` and `find`. [Pitfall 1](http://mywiki.wooledge.org/BashPitfalls#pf1), [ParsingLs](http://mywiki.wooledge.org/ParsingLs)
I've been learning a ton using this course. https://www.lynda.com/Bash-tutorials/Up-Running-Bash-Scripting/142989-2.html Check with your local library. They may offer free access to Lynda.com. The Boston Public Library does. https://www.bpl.org/kbl/2015/12/08/lynda-com-is-live/comment-page-1/
It looks like a rather roundabout alternative to setting `IFS=,` for splitting the variable.
Well, apparently storing the function invocation and then the other command works, though I don’t understand why… [lucaswerkmeister/cheats@52c18f6](https://github.com/lucaswerkmeister/cheats/commit/52c18f63decf79371ff753fa8c946c14ad1abc81)
Is that really implemented in the sed regex engine? The duck suggests [no](http://i.imgur.com/deh5btM.png).
Thanks Let's see in the next hour. 10:30 edit: it works!
Mmm, not really, I think. G_ROLE=(gid1 gid2 gid3) I need to be able to put -r G_ROLE and based on an if get either ${G_ROLE[0]}, ${G_ROLE[1]} or ${G_ROLE[2]}. This output will later be used in the useradd command with the -G option. Does that make more sense? I wrote this in Python and maybe it's a wrong way of going about it trying to translate it directly, here's the python code. The roles are in a nested dictionary: ROLES = { 'g_role1': {'dev': '8027', 'uat': '8017', 'prd': '8007'}} PARSER = argparse.ArgumentParser(description) PARSER.add_argument("-r", "--role", type=str, help="Role across environment.", nargs=1, required=True) ARGS = PARSER.parse_args() def does_role_exist(): if ARGS.role[0] in ROLES.keys(): pass else: sys.exit("Exiting - role does not exist")
No, the ROLEs are mapped according to environments i.e. g_role1 maps to GID 8027 in prod, GID 8017 in acceptance, GID 8007 in dev. The naming convention is such that I can do an if and determine which env I am on and thus use either ${ROLE[0]} or ${ROLE[1]}, etc, etc.
On older bash versions you can do the same with eval: eval echo '${'"$array[$index]"'}'
Still errors out. bash-4.2.46-20.el7_2.x86_64 then echo $SERV echo "${array[$index[1]]}" line 56: [1]: syntax error: operand expected (error token is "[1]") So how do I access the second index? Ugh, the eval errors out also... ./bubble.sh: line 46: ${test[]}: bad substitution 
You can't append `[1]` to an integer. `$index` already has the value 1. And you have to put `eval` before `echo`.
what is UUOC ? o.O
If you've launched Bash as a login shell, it looks for (in this order) `~/.bash_profile`, `~/.bash_login`, and `~/.profile`, and sources the first of those that it finds. So, the existence of either `~/.bash_profile` or `~/.bash_login` could prevent `~/.profile` from being sourced. Or, maybe Bash is not being launched as a login shell (you didn't tell us anything about your setup) in which case it's using `~/.bashrc` instead of the previously mentioned files.
Honestly this is a terrible reply considering we're in /r/bash but I would say this is too much for a bash script, and I would personally at this point run it in Python or Ruby.
Here you go, thanks! The only modifications I made was to add my scripts folder to the path and to add aliases for a couple scripts I made. # ~/.profile: executed by the command interpreter for login shells. # This file is not read by bash(1), if ~/.bash_profile or ~/.bash_login # exists. # see /usr/share/doc/bash/examples/startup-files for examples. # the files are located in the bash-doc package. # the default umask is set in /etc/profile; for setting the umask # for ssh logins, install and configure the libpam-umask package. #umask 022 # if running bash if [ -n "$BASH_VERSION" ]; then # include .bashrc if it exists if [ -f "$HOME/.bashrc" ]; then . "$HOME/.bashrc" fi fi # set PATH so it includes user's private bin directories PATH="$HOME/bin:$HOME/.local/bin:$PATH" # add Scripts directory to PATH export PATH=$PATH:$HOME/Documents/Projects/Scripts # custom aliases alias backdown-photos='gdrive-backup-photos.sh' alias backdown-docs='gdrive-backup-docs.sh'
There are programs like `optipng` and `jpegtran` that can reduce the size of images while keeping the exact same pixel data, so this method of finding duplicate files breaks down at that point. Geeqie has a "find duplicates" function you may find useful. There's an error on line 90, `mv $f $newName`. Use quoting to prevent argument splitting on whitespace. Also I would use `mv -i` to ask the user before overwriting.
Using global in functions doesn't sound like a good idea [...] case ... hotel_1) echo "0700" return [...] orig_prop="$(select_hotel "Your message here")" dest_prop="$(select_hotel "Your message here")" Sorry I'm on the phone, this the short code snippet.
I agree - I forgot to mention this in the *global variables* bullet. The reason why I didn't suggest command substition in the first place, is that it has its own set of things to be aware of and I wanted to keep things simple. *$(&lt;command&gt;)* starts a new shell to evaluate the new call. That means, in the context of OP's script: * whole standard output is now captured and returned as a result. Including the intro message that the function prints on top. So you'd have to refactor that out. * *exit* no longer terminates the entire script, just the sub-shell. We are not using it here, but could be a problem in other parts of OP's script. * Weridness with trailing new lines. Not really important, since it usually works as intended, but I find it super confusing: select_hotel() { echo "0700" # This prints to stdout, "0700\n" } result=$(select_hotel) if [ "$result" = "0700" ]; then echo "We're in!" # Why? "0700\n" should be different than "0700". # But Bash removed the new line in command substition -.- fi
[Here's an image which describes the order that bash loads its dotfiles](https://shreevatsa.files.wordpress.com/2008/03/bashstartupfiles1.png) Your solution has already been offered in this thread, but this image might help you to better visualise things. /edit: Correcting muh england speel gud
I’m considering if I should remove it – this is a [typical speckz submission](https://www.reddit.com/r/bash/comments/4s5rn8/bpkg_is_a_bash_package_manager/d5gxfb2/?context=1), it’s of no current interest other than historical / “archeological”, and there’s a risk that some people will read it without realizing how outdated it is (though hopefully most will read the comments and find this discussion).
Thank you both for the insight. Just for my own knowledge would you mind further detailing the advantages of using ruby or python for a project like this? I'm not disagreeing, just trying to learn more about the reasoning and the languages in general. I enjoyed scratching my brain for work arounds (and more work arounds once I started running the script on my Mac) in bash, but I definitely want to accomplish the same goals using something like python....especially if this becomes something my company would like to use outside of our market. Like I said in another post, I'm just starting to learn the language, but I'm looking forward to the challenge. For now I think I plan on using the script as is until I've built something a bit more functional and efficient. 
Please don't use `.sh` for bash scripts. POSIX shell and bash are two different things.
I was actually thinking about renaming to .bash but it escaped me. I will correct that latter. Thanks 
That tutorial comes highly un-recommended. For a list of tutorials with ratings, see http://wiki.bash-hackers.org/scripting/tutoriallist That said, the concept of parent and children processes is an OS level concept, not a shell level concept. A quick Google search for "what is a process in operation systems" returns: &gt; In computing, a process is an instance of a computer program that is being executed. It contains the program code and its current activity. Depending on the operating system (OS), a process may be made up of multiple threads of execution that execute instructions concurrently. * https://en.wikipedia.org/wiki/Process_(computing) * https://www.tutorialspoint.com/operating_system/os_processes.htm Those OS links may help you understand processes. Processes are created by other processes. When your OS begins, there is a single process which starts other processes which, in turn, can create more. When you log in, you got a login process which creates a desktop environment process which creates a terminal app process which creates a bash process. It's a tree structure with parent-child relationships between processes. Those OS links may help and ... switch tutorials. Really.
Nice :-] Emacs is a brilliant OS that only lacks a decent text editor :-P
Thank you so much for your full writeup on this. It's more feedback than I have ever gotten on this script. I'm going to implement these features as time allows. I think my favorite part is "pkill -HUP xscreensaver"... I was going the hard way around trying to get this to work with xdotool. Long story short, xscreensaver documentation says not to do this because it could cause instability or some BS, so I hadn't even tried it. Now that Fedora 25 is out with Wayland (so xdotool is going to stop working I presume), I'm going to change that part first. Edit: it occurs to me that xscreensaver is probably not going to work in Wayland either...
Shift + Ins should paste buffer contents. You can also copy with GNU screen.
it would be much easier using awk and/or sed, but you could try looking at `column` and `tr` to achieve this column being the sorting method, tr being the formatting of `:` as an example (albeit not exactly the best admittedly) ┌─[root@Fedora]─[~]─[04:54 pm] └─[$]› echo -e "hello\nworld" hello world ┌─[root@Fedora]─[~]─[04:54 pm] └─[$]› echo -e "hello\nworld" | column hello world ┌─[root@Fedora]─[~]─[04:55 pm] └─[$]› var1=$(echo -e "hello\nworld" | column); echo $var1 | tr " " ":" hello:world column can be a bit of a bugger for formatting afterwards though, awk/sed in this case would make your life much easier. 
* Use a loop to repeat code for multiple values. * The `mv` command can be used for both moves. * The rest is pretty straight forward. edit: changed to guidelines from code
Great idea. I didn't actually think of that. Thanks.
Hey you want to write my scripts for me too? Thanks! My ~~classwork~~ totally legit project I need help with is due on Monday.
I'm busting your chops man. OP is clearly trying to crowdsource their homework. :P
One can use sed: $ sed '/^$/!{H;$bp;D};:p;x;s/\n//;s/\n/ : /g' file first name : last name : ID : email first name : last name : ID : email 
/r/itsaunixsystem
Hey guys I figured it out. This is what I came up if anybody is interested.. regex='^[A-Za-z]' while read line; do if [[ $line =~ $regex ]] then var="$line" echo -n $var &gt;&gt; temp.txt else echo " " &gt;&gt; temp.txt fi done Not exactly the format I want it presented in but I'll clean those up tonight. Thanks for help everyone. 
Hey man, did you end up solving this problem?
I finished writing the script, but im having trouble implementing working done/esac/fi comments for *both* loops that are next to eachother and loops that are nested within each other.
I didn't really read the script but I do think you should use ansible to do this, it's way more robust and you won't reinvent the wheel.
They have docs to get you started. http://docs.ansible.com/ansible/intro_getting_started.html
Ansible has the enormous benefit of being idempotent, just this will convince me to use it instead of a simple shell script.
And just how does ansible achieve this idempodence? But either running state setting commands (eg. Chmod 0755 file); or by doing checks if [[ !-f file ]]; then touch file; fi. Ansible is not magic. It saves you writing some glue bash, at the cost of a while python toolchain. It has its value, but it's not always the right tool for the job, especially not in the context of this post :)
Thanks for taking the time to review this! I really appreciate it. I will certainly use your advice to improve on the script.
I prefer laying my scripts out like this [setup script for nodejs project](http://pastebin.com/sLd5R0aw). You mix functions and running code, which can be more difficult to read. Having a main function allows you to declare all the functions first, and easily see the running order of the script. Make sure you quote all your variables for paths too, or you could hit issues with paths with spaces, echo ${current_dir} as an example.
Some thoughts: Get rid of the word function, it's redundant and non-portable. For your passwords not matching bit, you can loop it... here's how I did it years ago in another script... probably not how I'd do it now (I don't indent like this anymore), but you get the idea: # Prompt for the new password twice while [ "${MATCH}" -gt "0" ]; do echo "================================" echo -ne "Please enter the new password for ${USER} and press [Enter] (default: ${GenPwd}): " read -s pwdin1 # If the read is blank, we default to the generated password if [ "${pwdin1}" == "" ]; then echo "${GenPwd}" &gt; "${USERPW}" # And give the condition to exit the while loop MATCH=0 else # Otherwise, we prompt again for the password echo -ne "\nPlease confirm the new password and press [Enter]: " read -s pwdin2 # Compare the two, if they don't match, try again if [ "${pwdin1}" != "${pwdin2}" ]; then echo "" read -p "The passwords entered do not match. Press [Enter] to start again." MATCH=$(( MATCH + 1 )) else # If the passwords match, write it to .newpwd echo "${pwdin1}" &gt; "${USERPW}" # And give the condition to exit the while loop MATCH=0 fi fi done You could have the password hashed and use `chpasswd -e`, password hashing is easy e.g. python -c 'import crypt; print(crypt.crypt("YOURPASSWORD", crypt.mksalt(crypt.METHOD_SHA512)))' If your version of the `python` crypt module doesn't have the mksalt function, then you could try: python -c "import crypt; print crypt.crypt('YOURPASSWORD', '\$6\$$(tr -dc '[:alnum:]' &lt; /dev/urandom | tr '[:upper:]' '[:lower:]' | tr -d ' ' | fold -w 8 | head -n 1)')" Or look at the hashlib module. If you're thinking of getting anywhere with portability, you should probably use `useradd` over `adduser`, that said, you can set your supplementary groups immediately from either of those commands and thus not need the `usermod` The `touch` of `authorized_keys` seems redundant `execAsUser` can get a bit more complicated if you want to try out portability. I didn't give you this: # Now that we know the account exists, figure out how to run tests as another user # First we test with 'sudo'. If "true" returns 0, we can go ahead with this style if pathfind sudo &gt;/dev/null 2&gt;&amp;1; then if sudo -u nobody true &gt; /dev/null 2&gt;&amp;1; then suMethod="sudo -u ${User} sh -c" fi else # Next, we move to 'su'. This is theoretically the most portable option if su nobody -c "true" &gt; /dev/null 2&gt;&amp;1; then suMethod="su ${User} -c" # Next, we try '-s', we use '-s' to override /bin/false or /bin/nologin i.e. (some) Solaris elif su nobody -s /bin/sh -c "true" &gt; /dev/null 2&gt;&amp;1; then suMethod="su ${User} -s /bin/sh -c" # Next we try to cater for '-m' i.e. FreeBSD elif su -m nobody -c "true" &gt; /dev/null 2&gt;&amp;1; then suMethod="su -m ${User} -c" fi fi (BTW: `pathfind` is a function that acts as portable alternative to `which`/`type`/`command`, I forget why it has to be used here, let me know if you want it though...) You should consider handling user specific sudo rules in `/etc/sudoers.d`, this makes adding and removing access as easy as adding and removing a file. Protip: You can couple this with the `at` command to give time-restricted `sudo` access i.e. you can create an `at` job that runs at, say, 5pm, and it invokes: `rm -f /etc/sudoers.d/somejerk`. Beware: these files MUST be `440` or `sudo` will break! In the context of scripting this, you may like to generate your `sudoers.d` conf frag somewhere else and use `install -m` to move it into `/etc/sudoers.d` I probably have other thoughts but that's plenty for now 
&gt; I don't even know `whereis` $ man whereis | sed '$!d' util-linux October 2014 WHEREIS(1) So it's a command from the util-linux package. OP should just use `command -v` as it's part of POSIX. 
I would argue otherwise. Yes, Ansible achieves the same thing through roughly similar routes, but the key thing here is that the implementation is abstracted away from the user - you don't need to write lots of conditional tests to ensure the outcome because the Ansible modules do that for you. The important thing here is that user error is less of a factor. I'm a sysadmin by trade and I manage thousands of servers - I'd use Ansible over a custom bash script any day if the two are interchangeable. Just yesterday I wrote a playbook to bootstrap several Puppet masters from scratch - a bash script with all the necessary checking would have been at least twice as long and more prone to failure. 
I would thoroughly recommend Ansible for Devops which is written by /u/geerlingguy. I've dabbled in Ansible for a while but my skills have really started to come together since I picked it up last weekend - it'll take you through the very basics right up to much more complex stuff. 
go to your folder : cd myfolder and then : **find . -maxdepth 1 ! -path . -type d -exec cp -R {} {}_custom \;** -maxdepth 1 : for get only folder on first level (not go deeper) ! -path . : for omit ./ directory -type d : for get only directory, omit files -exec cp -R {} {}_custom : do "cp -R {} {}_custom" 
Someone awoke me from my slumber. Here's a half-off coupon good until December 8th; have at it! https://leanpub.com/ansible-for-devops/c/VkzlSuAtAkpT
There you go /u/jasonheecs!
You can use indirect expansion: $ a=b $ b=c $ echo "${!a}" c It's get a little convoluted with arrays: list=(a b) a=(1 2 3) b=(4 5 6) for l in "${list[@]}" do arr="$l[@]" echo "${!arr}" done The above will output: 1 2 3 4 5 6 See man bash for more information: $ man bash | awk '/indirect.*!/' RS= If the first character of parameter is an exclamation point (!), and parameter is not a nameref, it introduces a level of variable indirection. Bash uses the value of the variable formed from the rest of parameter as the name of the variable; this variable is then expanded and that value is used in the rest of the substitution, rather than the value of parameter itself. This is known as indirect expansion. If parameter is a nameref, this expands to the name of the variable referenced by parameter instead of performing the complete indirect expansion. The exceptions to this are the expan‐ sions of ${!prefix*} and ${!name[@]} described below. The exclamation point must immediately follow the left brace in order to introduce indirection. 
Having a main function does seem to reduce the cognitive load of reading the code, thanks for the tip!
I've told this story a few times now :) I used to throw tabs everywhere. When you're scripting in an editor on a widescreen with a kajillion pixels it doesn't matter, right? One day a big old HP 9000 N-Class threw a fit and rebooted, and it wasn't coming back up. So I had to go down to the server room, hook up a dumb terminal and see what was going on. A script was somehow blocking the boot. Not one of mine, fortunately. But editing it on a dumb terminal was like having a tooth pulled while listening to Nickelback and Creed at the same time. The Creedelback torture. So these days I use 2 space indenting and I try to keep to an 80 column width limit. It makes the code look a lot tighter, but you can always throw in empty lines to break it up.
the script has a tar.gz file appended. the `sed -e '1,/^exit$/d'` removes the script part and pipes the rest of the file through a 'cleanup, mkdir tmp-dir, cd tmp-dir, tar zxf whatever sed doesn't delete and run the installer' script. It's an old trick, a self executing archive. Remove the 6 lines up to and including 'exit' and save it as `whatever.tar.gz`. Then `tar zxvf` it and examine the contents.
Neat. Hadn't heard of that before. I did what you said and it looks like it has a bunch of ruby scripts for network setup. As I don't know Ruby I'm kind of taking their word for it.
 ls /this/is/a/very/long/**/name/42 should not work. '*' means 'anything' and so does '**'.
With globstar `**` will be recursive.
Done some looking into it, that installer just seems to be a fancy GUI to install openvpn and put all the config files in place. They have an install script available [here](https://www.privateinternetaccess.com/installer/install_ubuntu.sh) which is a bit easier to read, either that or they have .ovpn files for all of their servers that you can download and do it more manually. In terms of verifying the installer you've got, check the SHA-256 checksum on their website and you should be fine.
Where is the Puppet love? I find Puppet to be much more powerful and easier to develop both simple and complex deployments. Only downside I can think of is the agent is required. 
Awesome, thanks for the help. I will try that out.
I stand corrected. Thank you. I didn't know 'globstar' option.
Wish I had recommendations to add... I just wanted to comment that I think it's awesome you've posted this and sharing a working solution out into the world. Keep it up, improvements happen over time naturally. 😎
Looks pretty good (but I've never tried this in bash, so take it with a grain of salt). My one comment is it's probably not a good idea to hard code the password into the script. Instead, use `read -s password`. This will ask you for your password the same way `sudo` does.
Thank you so much for taking a look! Over time I'd definitely like to build this out to back up multiple sites.
You can do a lot of things to make it a little less insecure such as using gpg to encrypt the password in ~/pass.gpg and then decrypting on the fly when the script runs with something like `pass=$(gpg --decrypt ~/pass.gpg)`
Awesome! Thanks for checking it out! &gt; Let have shellcheck have a look at this. There are the usual missing quotes, nothing that's hard to fix. Whoops - thanks for spotting that spelling error. I was just doing some reading about the importance of those missing quotes, so I'll fix that up. I just made this last night and it's only working on one site now. I would like to have a solution that works well for multiple sites. I haven't seen examples of using configuration files in BASH but I'll check that out. &gt; Why do you copy your files, tar them and delete the copy, why not just tar them? I wanted to include the mysqldump in the site files and tar it all together. I wasn't sure how to do this any other way. Is there a better way? &gt; Have you considered using an of the shelf backup solution? rsnapshot for example does all what your backup does plus: it deduplicates and it can work over ssh. Oh, sweet. Maybe I wasn't using the right search terms when looking for a backup solution. rsnapshot looks nice. Thanks for pointing that out. &gt; Have you thought about storing your backup in another location? I've *thought* about it, but haven't gotten there yet. I think it'd be nice to push backups to S3 Thanks so much for your feedback. I really appreciate it! 
I think a lot of the comments aren't necessary as your variables are pretty well named. Site name for example - its fairly obvious and just adding noise imo. 
Puppet is definitely very powerful, it's our main config management tool at work, however I wouldn't always recommend its usage. It has a relatively high barrier to entry (DSL, some infrastructure to set up, the need to use ruby to extend it etc). Generally I'd say that bootstrapping a server like this is easier to get done with Ansible. 
There are links in the sidebar. wooledge is the online reference and the O'Reilly books are its paper equivalent. Not sure if the https://HumbleBundle.com UNIX book deal is still up, but you should grab it.
I am betting this is only if one is using Emacs line editing (default). set -o emacs 
You can replace everything but numbers with spaces, then use `read`: read -r num1 num2 num3 &lt; &lt;(sed 's/[^0-9][^0-9]*/ /g' The above will store: 74067 in `num1`, 73535 in `num2` and 1064960 in `num3`
For example, you might want to sudo the last command, but see what it looks like before pressing ENTER. `sudo !! M-^` will do that. Using the arrow keys, then doing a `C-a sudo `also does the same, so this is just an alternative approach that some people who do not use arrow keys might prefer. Note that it is not restricted to `!!`. You can expand in any combination. For example, `!-2:s/x/y M-^` will expand the second last command, replacing the first occurrence of `x` with `y`.
The books are still available https://www.humblebundle.com/books/unix-book-bundle Just picked up the mid range deal for 8 bucks Thanks for the tip! 
Well, you can just install it on your distro, and use it as a linter in your editor of choice: https://github.com/koalaman/shellcheck#installing
Take a look at 'find' and 'inotify'.
I think writing a bash script that runs as a cron job periodically would work well for this task. I have a script that I wrote at work that does basically the same thing; it copies text reports that are created locally from our business system to a Windows server across a share that is home to our enterprise document storage software. It works as you suggest, where it dives into the subdirectories of a certain starting point, and copies the files into the same relative subdirectories in the destination. Since you don't just want a script written for you (good on you!), I will give you some pointers and lessons learned from my experiences: * Read up on how to properly handle file names in a script. You'd be surprised at how many crazy characters can end up in a file name in Linux, and how they can potentially hose up your script. Proper quoting of variables goes a long way, and using things like the `-print0` option on `find` will help a ton * Protect yourself against two copies of the script running at the same time. You might think "well, my script couldn't *possibly* take more than 5 minutes to run, and I'm only running it every 5 minutes, so I should be safe". I can almost guarantee you'll be wrong at some point. Some scripts are perfectly safe to have multiple copies running at once, but a script that's trying to move files around can get ugly if you have two copies of the same script running at the same time. * Just because a file exists, doesn't mean the process that was writing it is done, and it's safe to move. Always make a reasonable effort in your script to make sure the file you're about to move is in a "stable" state before you start monkeying with it. I've found the `fuser` command, which tells you open file handles on a file, to be very helpful for this sort of thing. However, also be aware that the fuser command usually has to be run as root to give you any useful/accurate information. So you may need to run your monitor script from root's crontab, or use sudo to elevate the privileges of just the fuser command.
[incron][http://inotify.aiken.cz/?section=incron&amp;page=about&amp;lang=en] is an "inotify cron" system. You specify paths and events you want to monitor. It runs your command when that event occurs on that path, very much like cron. You can use incron to trigger a shell script when a file is written to that path, eg the CLOSE_WRITE event. For the other part, extract the bit of the path you want to match then use a glob to find if it matches elsewhere. If it does, move it. dir=something matches=(/path/category*/"$dir") if (( ${#matches[@]} == 1 )); then mv "$file" "${matches[0]}" rmdir "$path" elif (( ${#matches[@]} == 0 )); then echo "No match found" else echo "Found multiple candidates." fi
That's pretty cool. I'll have to look into those.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/linux] [Bash Color Scheme Designer; a palette generator using 256 colors (x-post from \/r\/bash)](https://np.reddit.com/r/linux/comments/5gva9m/bash_color_scheme_designer_a_palette_generator/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
Nice! But perhaps use `tput` (`tput setaf 123` or `tput setab 123`)?
Good idea. I vaguely remember using tput a while ago to set my colors, but I don't remember why I opted for echo. I develop on both linux and osx, so maybe there was an incompatibility with tput somewhere.
Thanks for the kind words! :D
Another alternative to `tput` is to use `printf` to improve your portability. For example: printf "\e[38;5;50m%s\e[0m\n" "Your text goes here" You can remove the `\n` if you want to emulate `echo`'s `-n`
Yeah, I was going to suggest that too, `printf` is still better than `echo`. But actually, I checked the POSIX manpage, and it turns out that: &gt; 6\. The a, A, e, E, f, F, g, and G conversion specifiers need not be supported. So I guess for absolutely maximum portability you might want to use `\033` (octal representation of ASCII ESC) instead of `\e`…
If I may suggest a feature – it would be nice to be able to share color schemes, e. g. if selecting a color updated the URL (something like `#splitcomplementary-201`) and loading the page on that URL initialized it with the selected color scheme?
I know, I've been using `sh` hours a day for too many months! I'm building a tool to... manage my git repos, which I've barely used for a month or two because I was doing `sh` programming... I'm thinking I might have to go into `sh` rehab. Your construct looks nice, I usually just wrap mine in a function if I use it a few times in one program, so it ends up like: process_list() { xargs -rn 1 sh -eu -c "$@" } # find gifs in folders find_me_gifs() { process_list '# do find "$0" -name '"'"'*.gif'"'"' # done' } echo cats dogs emojis | find_me_gifs # cats cats cats # dogs dogs dogs # emojis emojis emojis Then you still might have to get into details such as null delimited input and output, handling both arguments and piping, and in the handling of errors and dealing with many pipes. At least that's how I do it in `sh`. I do like the command-with-automatic-implicit-FIFO syntax and the `read -r` `\0`-delimited splitting.
&gt; limited 256 color palette question: some (majority I think) terminals now have support for truecolors. so, can we now use hex color codes instead of 256 palette to define colors?
&gt; &gt; 6\. The a, A, e, E, f, F, g, and G conversion specifiers need not be supported. Point 6 is about `%a`, `%A`, `%e` etc..., but since point 3 does not explicitly list `\e`, it cannot be relied upon in sh scripts.
Hey, sorry to confuse, but I meant it produced the same output with single quotes as with double quotes. But I can try it again tomorrow without escaping the double quotes then. For now I'm off to home.^^ 
I've found this site to be really well done for this purpose - https://terminal.sexy/
Feature added :) [http://bashcolors.com/#tetradic,73,131,61,143](http://bashcolors.com/#tetradic,73,131,61,143)
I found this site a while ago too. Some things I wanted that it doesn't have: * limited to 256 colors * color code display, for copying into my own scripts * color palette generator; Complementary, Split Complementary, Triadic, etc. * simple interface
I see, that doesnt look pretty ;)
A couple of things: 1. I assume that you've pasted wrapped output here and your real output is all on one line. The first `sed` command can't work because the pattern crosses a newline boundary and `sed` works on one line at a time (although it's possible to concatenate the next line onto the current line). 2. When I save the output all on one line into a file, and `cat` the file at the beginning of the pipe, the commands work for me whether I run the pipe directly in the shell or save it to a script and run the script. Are you sure that you know what `$response` contains? Have you tried printing it from inside the script? Does it perhaps have the header on one line and the JSON data on another line? If so, see point 5. 3. Instead of using double quotes around your `sed` commands and having to escape double quotes inside, use single quotes and don't escape the double quotes. You can't always use this trick, e.g. if you need to expand a bash variable inside the pattern or if you have both single quotes and double quotes. But in this case it's a straightforward simplification that makes the pattern more legible. For future reference, you can also use any character as a delimiter for the regular expression, so if your pattern is full of forward slashes you can use something other than forward slashes to avoid escaping them (i.e. `s#a/b#a_b#` instead of `s/a\/b/a_b/` ). 4. Instead of piping to `sed` multiple times you can chain `sed` commands with semicolons inside the parameter string. I.e. `sed "s/a/b/;s/d/e/;s/f/g/"` 5. If your output is split over two lines, you can join them together before doing your substitutions to make the first one work. The `sed` command to append the next line to the current line is `N`, and you can prepend it to the chain of substitution commands. 6. You're leaving in the leading double quote of your passphrase. Instead of adding another substitution to get rid of it, you can add a bit to the last one to replace the final `":"` with `:`. Putting all of that together, I get this: | sed 'N;s/HTTP.*InfoList":\[{"id":"//;s/","wlanId".*passphrase":"/:/;s/","vlanId.*//' *However*, this is conceptually a really untidy way to extract this information. Instead of deleting everything *around* the parts you want, you can match the whole thing and pick out just the parts you want. You can do this using brackets to mark the parts of the pattern that you want to keep (these are called groups). You can use `\1`, `\2`, etc. to access these groups when doing the replacement. 1. By default in `sed` you need to escape round and curly brackets to use them as regular expression symbols, and if they're not escaped they are treated as literal brackets. I'm going to use the `-r` flag to invert that behaviour, because it's cleaner and in line with other common regex implementations. 2. By default `sed` prints every line of its input. You can suppress this with the `-n` flag, and use `p` to print specific lines. We only want the line with the data on it; I suspect that you also have a header, which we want to ignore. 3. By default `*` matches as many characters as possible (a "greedy" match). In many regex implementations you can put `?` after it to make it match as few characters as possible. It's often useful for matching things between delimiters (e.g. quotes) -- you don't want your match to spill over the closing delimiter and carry on to the very last closing delimiter on the line. *But* this option is a feature of Perl regex which is not supported by `sed`, so instead we'll need to use the alternative hackaround of matching `[^"]*` (anything except a quote repeated any number of times) instead of `.*`. Using these techniques you can do something like this: | sed -rn 's/.*"id":"([^"]*)".*"passphrase":"([^"]*?)".*/\1:\2/p' ... which is shorter and prettier. ;) You can use `perl` instead to use the non-greedy operator, but then you'd either need to use a completely different syntax to suppress printing and print the substituted line... | perl -ne 'print if s/.*"id":"(.*?)".*"passphrase":"(.*?)".*/\1:\2/' ... or just add `grep` to the pipe to pick out the line you want beforehand, e.g. cat foo | grep dpskInfoList | perl -pe 's/.*"id":"(.*?)".*"passphrase":"(.*?)".*/\1:\2/' *Edit:* /u/AnotherIsaac's parser solution is the most correct -- don't use regexes for parsing structured data at all if a real parser is available! If your header is already on a separate line, use `grep` to extract the line with the data, and pipe that to the parser.
Another short plug for a JSON parser. With a parser, things will work just fine even if the server arbitrarily decides to reorder the output or move line breaks around. A parser is far, far more resilient to any changes in the output format.
hey man did you get it to work? I'm still trying to solve it but running through difficulties...
Quoth the raven, 404.
thank You, fixed and working now
[Here](https://www.reddit.com/r/bash/comments/4pbnd8/bash3_boilerplate_template_for_writing_better/)’s an older thread for the website. TL;DR: not thrilled, but looks like they’ve been responsive, so perhaps it’s better now.
I consider most of that bad practice. In particular, set -e and set -u are unreliable and just makes your scripts more buggy.
&gt; I just found out the google style guidelines, maybe their advice will be more universal? It's better than that "boilerplate" crap, but far from perfect. There aren't any good style guides out there. &gt; As a side qeustion, since I see these two lines in different blogs and guides - do these commands do the exact same thing? (defining a variable that represents script's parent directory): &gt; PROGDIR=$(readlink -m $(dirname $0)) `readlink -m` probably requires that GNU coreutils is installed. It is also missing quotes, and assuming `$0` expands to the location of the script is flawed. Lastly, uppercase variable names should be avoided. &gt; PROGDIR="$( cd "$( dirname "${BASH_SOURCE[0]}" )" &amp;&amp; pwd )" This is closer, but it's lacking a crucial step; if `cd` fails, PROGDIR will be empty, which could be catastrophic later on. One must always handle the case where `cd` fails. progdir=$(cd "$(dirname "${BASH_SOURCE[0]}")" &amp;&amp; pwd) || exit Or just avoid relying on the script's location at all.
that's very informative, thank You. I will keep in mind the additional `|| exit`. I have some scripts, that are not self-contained and rely on other files located in the same folder.
&gt; Lastly, uppercase variable names should be avoided. I was unaware of this, and read up on it. TIL. Now, time to go fix all my scripts. Thank you.
1. That is fine, 2. See http://mywiki.wooledge.org/BashFAQ/105 3. Above 4. Just use `${var:-default}` instead. And if it's critical to have a value make your script explicit `${var:?Missing var}`. 5. Please don't, it will make to much noise in a pipeline, and mask potential errors from other processes. Use for debugging but nothing else. 6. See 2. 7. Sure go nuts. 8. `#!/usr/bin/env bash -e` is not valid. Use `/bin/bash -e` or see 7. 9. Surrounding parameters doesn't really adds to readability, isn't really something you should force upon people. 10. `[ a == b ]` is not POSIX. If you only wanna learn one way it should be the POSIX way. Else use `[[` 11. Always\* wrap parameter expansions, and the like, in double quotes. \* see: http://mywiki.wooledge.org/Quotes 12. What bothers me most about this is that you use UPPERCASE ONLY parameter names, for application variables. See &lt;https://en.wikipedia.org/wiki/Scope_(computer_science)#Dynamic_scoping&gt; for why this can and eventually *will* cause problems. 13. Sure, that is fine. 
Great suggestions, thanks. 
Thanks for the reply :) I tried what you suggested and it's definitely a step in the right direction! Script doesn't show up on the list of jobs but when i run, ps -ef | grep script I get, root 48369 48367 0 14:52 pts/2 00:00:00 script /home/usr/../cmd.log root 48370 48369 0 14:52 pts/2 00:00:00 script /home/usr/../cmd.log If I kill either of those processes I get the same message as when i type 'exit', Script done, file is /home/usr/../cmd.log And both processes disappear. This looks right but then when I check the log file it's empty and nothing has saved :/ 
There really isn't a why to tell if a host has disconnected using only dhcp. Your best bet will be to setup a cron job that will periodically ping all your hosts and report if one is no longer on the network. 
Hmm...I see, thank you for your reply ! :) I don't know how to do it dynamically for showing the reports in live time on a web page...
What is Rpi? Are these VPN clients?
Using DHCP only you could set a short lease time, 1hour maybe, and monitor the logs on the DHCP server logs for requests. It would only have a resolution of whatever your lease window was but it could work if there were no better options available. The better way to go about it would be to use something like nmap to scan your subnet periodically. A ping sweep of your network would work as well but nmap will scan faster and require less work to setup since it has native address range support.
Why aren't you using `cat`? cat header.txt new.txt &gt; alert.txt /edit: for what it's worth, you can emulate `cat` in `sed` like this: sed : header.txt new.txt &gt; alert.txt
I don’t see what would be wrong about that, but Vim also doesn’t seem to do the red highlighting for me…
Vim bash syntax is bad. This also fails and makes the rest of the script part of `${}` while it's valid bash. #!/bin/bash #comment color a=${b//[} #not a comment according to vim 
I do a similar thing using ffprobe so I thought I'd share my check line. if ! ffprobe -v "${LOGLVL}" -select_streams v:0 -show_entries stream=codec_name -of default=nokey=1:noprint_wrappers=1 "${INFILE}" | grep -q hevc; then ... 
Looks like you’re running into the same problem as this [StackOverflow question](https://stackoverflow.com/questions/21498991/head-usage-unknown-option-1-n-error-possibly-ruby-related). TL;DR: Make sure any adjustments to your `PATH` are *appended* to it, not prepended, so that `head` still refers to the “first lines of text” program and not the “make HTTP `HEAD` request” program.
Your use of quoting is broken in various ways, but I'm not going to spend time explaining that because there is a much better way to do this: use a shell function. First define the function: doSqlite() { if ((remote)); then ssh "$remotehost" "sqlite3 '$database'" else sqlite3 "$databsae" fi } This function definition does nothing in itself, but defines `doSqlite` as a new command to use later. So after defining it you can use the function like any other command: checkdatabase=$(echo "select * from release where releasename='$Filename';" | doSqlite) *edit:* quoting tweak to ssh command in function
I'm laughing right now. OSX ships a binary named `head` that isn't [`head(1)`](http://pubs.opengroup.org/onlinepubs/009604499/utilities/head.html)?...
Ok. You can get rid of it thusly: SDK=`$ADB shell getprop ro.build.version.sdk | tr -d "\015"` 
You seem to have trouble reading the post. Read the usage line.
You seem to have trouble reading beyond the usage line. The binary invoked there is not the one you think it is.
This is away to solve the problem, was hoping there was a more efficient way then adding a bunch of else statements, added like 100 line of code as this function is called allot. was thinking a wrapper of some sorts, or just getting the quoting down. yes there is different ways of doing it but the main thin is also capturing special characters that may be contained in those verribles. im fully open to any suggestions. just working with a bunch of constraints... how you use sqlite3 statements, files with special charators suchs as ' and then useing the command local and remote so dealing with sending the command as one statement or it breaking up because of the quotes.
I'll have re look at -t, I checked the man pages and it didn't stand out initially.
Its very existence is a nonsense. It shouldn't be named like that. Imagine using the `curl` name for something that isn't curl... Oh wait, someone already did that. So yeah, the presence of this binary is laughable.
Except it isn't named that. It's named `HEAD`, not `head`, and it's part of Apache. If you're still not getting it, read the top-voted reply in this thread and follow the link.
The output is what I would expect... What were you expecting this to do?
It's probably a part of Xampp which bundles apache, php, &amp; mysql. Xampp comes with files named head and get which are duplicates of the same perl script that does some kind of http request task.
This does appear to work. What are you trying to do? Keep in mind that as you increment a,b,c,d you are also incrementing I, so the difference will remain the same. For a: 16-3 17-4 18-5 Etc. 
That *doesn't* increment `a`, `b`, `c`... If you increment them, then you get the same set of numbers over and over, because `i` is also incrementing.
You can enable `pipefail` for that one pipeline by running the pipeline in a subshell: ( set -o pipefail; lynx --source "url" | cut | sed | cat &gt; file ) || exit or just enable it for the entire script, which is safe as long as it's not combined with set -e, and you are aware whenever you test pipelines elsewhere in the script. #!/usr/bin/env bash set -o pipefail ... lynx --source "url" | cut | sed | cat &gt; file || exit Another alternative is checking PIPESTATUS immediately after the pipeline. lynx --source "url" | cut | sed | cat &gt; file status=( "${PIPESTATUS[@]}" ) if (( status[0] &gt; 0 )); then printf &gt;&amp;2 'lynx failed with status %d\n' "${status[0]}" exit 1 fi **EDIT**: Another option is to run everything but the lynx in a process substitution. lynx -source "url" &gt; &gt;(cut | sed | cat &gt; file)
thanks. ok, so I will examine all my pipes, and if its ok set pipefail globally, or use Your first method
Glad to be of service. Have a nice day.
See [FAQ 105](http://mywiki.wooledge.org/BashFAQ/105) and [FAQ 112](http://mywiki.wooledge.org/BashFAQ/112).
Perhaps this? { lynx --source "url" || exit; } | cut | sed | cat &gt; file
Damn, I forgot pipes also create subshells.
Can `{`,`}` be used for grouping stuff in bash? Eg. in the following scenario: if [[ ($# -gt 1) &amp;&amp; (! "$2" =~ ^-) ]]; then what's the best way to do this?
&gt; How do I make || exit respond only to lynx, or alternatively to each command in the pipe? 1. Use exit codes ($?) VAR=$( lynx stuff ) &amp;&amp; editing $VAR || exit 2. Create a flag VAR=$( lynx stuff ) &amp;&amp; f=0 &amp;&amp; editing $VAR || [[ -z $f ]] &amp;&amp; exit 1 || exit 0 $f is set only if lynx stuff returns zero, so exit status 1 means lynx stuff failed, exit 0 means lynx returned 0 but editing failed. I have a feeling this would be even nicer with proper redirection instead of variables but I might be wrong. 
I dunno, maybe do: kill -s SIGTSTP [process id] ? PS, you can use ps -C [command name] rather than ps -aux | grep [command name]
I was able to get it working if I don't use cat but read in the file with read in a while loop, but if anyone knows a way without having to output it to a temporary file I'd be all ears.
https://stackoverflow.com/questions/3211595/renaming-files-in-a-folder-to-sequential-numbers
Wow, thanks for the very thorough explanation. Even though I'll be using the Json parser like you mentioned, this really helped me understand regular expressions much better. Really appreciate it!
Take a mook at awk, its very suitable for this kind of work. We use awk scripts for ldif parsing at a regular basis.
"Remember the Cant" /irrelevant comment
To answer the question in the title: no, this is not a "subshell thing". Arithmetic expansion and arithmetic commands don't fork subshells.
I wrote a bash script to automate post-installation steps. It helps to install packages on different operating systems. Maybe it will help you. Feedback welcome.
Look into ansible. You end up with 1000% more readable and brief configuration.
Is already in the README :-) "postinstall.sh is not a configuration management system. If you want to install many servers automatically, you should look at ansible."
I briefly looked through the script again and probably one excuse to use it is its zero dependencies. To start using ansible you have to instsall it and it pulls at least half a dozen of packages. I'd prefer it anyway but OP preferred his way which is ok.
What are you talking about, the shebang is `/bin/bash` and as far as I'm aware `echo` have worked the same for bash for ages! If you want to remove bash as a dependency `echo` -&gt; `printf` is the least to worry about! Edit: s/wan't/want/
My case still stands, as OP is using `/bin/bash` as the shebang.
Thanks, I didn't know that I can combine the brackets like so `((...)) &amp;&amp; [[ ... ]]` or even `[[ ... ]] &amp;&amp; [[ ... ]]` for that matter. That answers my question.
wow :) I will um, go through this, thanks very much for Your time to explain ;)
Too complex for the 1$ a month host server I'm using. I could use a computer at home but I don't want to run an email server at home.
Procmail also requires that you run your own mail server. Basically, you use cron to run a script or scripts at specified intervals. So, figure out what commands are needed to do what you want and put them in a text file with #!/bin/bash at the top. Do a chmod to make it executable and you have a bash script. Once it's working properly, add an entry to cron to run it periodically. 
Why are you asking for batch script help on the bash subreddit?
You should just use the `-exec` option on `find` like so: find /storage/tv/* -type d -exec /root/Batch-H.264-Converter/batch-h264-converter "{}" \; 
Alternatively, xargs is pretty flexible for things like this, especially if your batch converter can accept more than a single file to process in one invocation: find /storage/tv -type d -print0 | xargs -0 -i /root/Batch-H.264-Converter/batch-h264-converter "{}"
This is the best answer for simple tasks. Note that if you're using a modern system you don't need the quoted around the {} anymore.
That's cool, I wish it was a little more configurable though. I have to alias it to `shfmt -i 4` instead of setting `"indent: 4"` in some config file.
Wow, thank you for showing me that. I didn't know such a thing existed for bash. Tab completion is cool, but this is awesome.
Yes, fzf is awesome. Not only for searching the history or completing files. I've wrapped many scrips around it...
related: https://unix.stackexchange.com/questions/321697/why-is-looping-over-finds-output-bad-practice
I think a config file at this point is a bit overkill. There are barely any options, and this one can change between projects. As far as convenience goes, a script in your PATH or an alias does the same thing and keeps the tool simpler.
That's because I didn't pay a lot of attention when adding support for bash-style functions. I never use these, and assumed that the common format was with the `()`, not without. After a quick search, most guides use the form `function foo {}`, and the bash repo itself seems split - most of the examples use `()`, but most of the tests don't. For consistency, and to not break the current format after 1.0, I'm inclined to keep things as they are. Do you have any better proof that `()` should be dropped?
I actually found something juicy in the bash manual: &gt; If the function reserved word is used, but the parentheses are not supplied, the braces are required. Basically, if we always remove `()`, we might turn valid programs like: function foo() bar into invalid programs like: function foo bar
 while ((n&gt;0)); do scp remote:file_$n.txt . let n-- done &gt; I am trying to only have to input the password once. Set up `ssh-agent`.
 scp server:file_{14..1}.txt . Courtesy of [brace expansion](http://wiki.bash-hackers.org/syntax/expansion/brace).
Yay! Its works! Thank you!
In this exact case it can be quite simple: var=test_suffix.sql echo ${var//_*/}.sql Second option is to use sed, in case you do have some more complex string: sed -e "s/\(.*\)_.*/\1.sql/" &lt;&lt;&lt; $var
Thank you so much - I knew it was simple.. I totally forgot how though :-) mv "$BACKUP_DIR/sql/$db.sql" "${db//_*/}"
You may want to think about changing the name as cheggit with two Gs is a porn site.
Somewhat related? Like skateboards are related to cars, jk. I know why you suggest this and I agree with you! +1 for recycling ;-)
Try this: Script A: export variable and then call script B (child process). Script B: echo variable.
`find -exec` can also support multiple arguments per exec, eg `find . -exec echo {} +`. Unless you're launching parallel processes, there's little value in piping from find to xargs.
Sounds like what you want is a git hook. Unfortunately, while I know bash, I'm not very familiar with how git hooks work. You may want to look into those.
Hey so... bit belated on this thread, but I feel like an easier way to do this would be to just use ldapsearch syntax without going through the loop. Eg. ldapsearch -QLLLr -x -h winad.test.com -D "ldapuser@test.com" -w $SecretPassword -b "ou=users,dc=test,dc=com" -s sub "(&amp;(objectclass=person)(|(cn=user1*)(cn=user2*)(cn=etc..*)))" dn (my filter syntax might be screwy. Don't have a test system onhand, but you get the gist. Then you can just trail at the end for any attributes you want to parse out. Also tagged on -QLLLr for prettier output.) Edit: Actually, on second thought, I suppose it isn't realistic to include users in the filter. I'd imagine there's a dynamic (and large) number of them. In which case, I'd still say you could probably just use the search to parse out DNs and then grep/parse to your fancy from there without looping. Just something to consider anyway. Best of luck to ya.
Argh! Yes...can't (with the apostrophe) is correct.
Sorry for the slow response - had a weekend away. As an example, you can use something like this: net ads sid $(wbinfo -n "${user}" | awk '{print $1}') -U $SomeLDAPAdmin%$SecretPassword -S PrimaryDC 2&gt;/dev/null | grep "^pwdLastSet" This bit will pull the AD SID for the target user: wbinfo -n "${user}" | awk '{print $1}' The `net ads sid` bit will dump out a whole bunch of attributes just like `ldapsearch` does. The `2&gt;/dev/null` may be required depending on your terminal, PuTTY definitely gets upset without it. You can generate a list of users to process with `wbinfo -u` and filter that with `grep -v` or `grep -vf` This does appear to approach your problem from another angle, but I thought I'd still FYI you. 
Don't prepend `$` to left-side variables on assignation! Correct: foo="bar" Incorrect: $foo="bar" 
But `_var` is a variable of a variable... not the variable to be assigned.
True, sorry :) It appears `typeset` would be the most portable/safe way to handle it, as [discussed in this thread](http://stackoverflow.com/questions/9938649/indirect-variable-assignment-in-bash), while `eval` would work but open a can of worms.
DIR A: /A/banan.txt DIR B: /B/banana/ I want to cp banan.txt into /B/banana/ if there is a partial match between "banan" and "banana" Please let me know if I am writing totally gibberish here
You're writing gibberish. You could extract the filename without the extension, ie banan, and test if that is a substring of the other directory. 
My approach in GNU/Linux will be: BEG=$(date --date='2016-12-13' +"%s") END=$(date --date='2016-12-20' +"%s") echo $[(END-BEG)/(24*60*60)] Conversion to unix timestamp and then simple arithmetic. However, date command in non-GNU unix-like system sucks (at least MacOSX and HP-UX) and approach with some another scripting language will be necessary.
I would try it with the unix timestamp. 7 days are: $ echo "$((7*24*60*60)) sec" 604800 sec Now: $ date "+%s" Timestamp of file with GNU stat: stat -c %Y yourFile.txt
It’s worth noting that `$[EXPRESSION]` is the older, unspecified syntax for arithmetic expansion – the standard way to do it is `$((EXPRESSION))`.
&gt; I tried it a few different ways but was not successful. I think you forgot to post your attempts :-)
Use a while loop. Something like read filename while ! [[ $filename =~ 'some regex magic here' ]] ; do something done
How do you make "something" return you to the input on the earlier line?
If you're looking to continuously prompt the user until they give you a valid filename, you could set the prompt within a while loop that checks to ensure the file extension is correct. Building upon /u/blitzkraft's answer, you could do something like the following to accomplish this. filename='' while [[ ! "$filename" =~ \.ext$ ]]; do read -p "Please enter a filename ending in '.ext': " filename done This will set the filename to an empty string, and prompt the user to enter a filename until they have provided one ending in ".ext".
Ah. My bad. This should be: filename="" while ! [[ $filename =~ 'some regex magic here' ]] ; do echo "Input filename: " read filename something done
On mobile with some freetime, try this. Edit: fixed, works while true do read -ep "File Name: " filename [[ $filename == *.ext ]] &amp;&amp; printf "Valid\n" &amp;&amp; break printf "Invalid, Try Again\n" sleep .5 done 
Using `echo -n` would essentially do the same thing as `read -p`, but it's calling a second binary. I try to use a few binaries as possible to increase efficiency. While efficiency really isn't affected in such a small block of code, I find it's good practice to always be as efficient as possible.
You want to use `[[` and `]]` instead of `[` and `]`, especially for bash regex. You want to use `=~`, because ~= is a typo. Beyond that, I can't help you with your homework.
good up regex, but the hint here is `^banan*` if you want T type then do `^$var[0-5]*`
Both stat and date have options to return the number of seconds since "epoch", i.e., 00:00 UTC on 01 January 1970. For stat, it is -c%Y while for date, it is +%s. This allows you to easily determine the difference. The following gives the number of days between a file date and the current date. echo $(((`date +%s`-`stat -c"%Y" DiskAllocationUpgrade.ods`)/3600/24)) If you only wanted to express the difference in seconds, you could drop the divisors /3600/24. I use that case in a crontab executed script to ensure that a file has been updated within the last 120 seconds, and take action if not.
 while true; do echo enter filename read filename ext="${filename##*.}" if [ $ext != "ext" ]; then echo "try again" else break fi done Edit: the `ext="${filename##*.}"` is called parameter substitution and the `*.` is like a regex that replace the file name (without the extension) with nothing. 
Are the partial matches always structured the same? i.e. Is it always going to match at the start of the directory? (Will it always be the first 5 chars?) Can there be multiple matches? e.g. /A/foo.txt /B/foobar/ /B/foobarbaz/ If there are only single matches you could use a glob e.g. $ find . ./A ./A/banan.txt ./B ./B/banana $ for path in A/*; do f=${path##*/}; echo mv "$path" "B/${f:0:5}"*; done mv A/banan.txt B/banana So this tests the first 5 characters of the filename in `A` and uses a glob to find a match in `B` - if there is more than one match - it will break the resulting `mv` command however. If you wanted to test the full filename minus the extension as opposed to the first 5 chars you could use `${f%.*}` instead of `${f:0:5}`
You need to learn version control.
Buth `read` and `echo` are build in to bash. And `-p` flag on read is bash flavor. So your concern is worth nothing. If you care about POSIX you would use `printf` and `read`: printf "Please enter a filename ending in '.ext': " read filename And you wouldn't use `[[` either. But `[ "${filename##*.}" != "ext" ]`. This will however let `filename=ext` split though. 
if you are running `cd $iCLoud`, run `cd "$iCLoud"` instead. The spaces are saved in the variable since it's quoted but if you don't quote the variable when used by cd it will break. Also the end of your variable definition looks wrong but I'm not sure what you are going for exactly.
I just used the format that anaconda used in the .bash_profile. Is there a better way to define this so that I dont have to use quotes when i cd?
you should almost always quote variables.
No, there’s no way to disable word splitting for some variables. But you could define a function: function cd-iCloud { cd "$iCloud" } and call it as `cd-iCloud` (using tab completion as well).
I don't get it.
That I'm not sure of. 
what about `lshw -short | grep disk`?
You're doing quoting wrong. You want: dir="/somepath/$(date +%y%m%d%H%M)-backup" mkdir -p "$dir" 
Looks to me like `lshw` needs `sudo` to show information about my hard drives (SSDs FWIW).
This should do the trick. It's my first *useful* bash script. yay! #!/bin/bash COUNT=1 for file in $(ls /path/to/folderA) do if [ "${file: -4}" == ".cvs" ] then mv ${file} /path/to/folderB/today.cvs cd /path/to/folderB echo `java -jar program.jar` mv out.drf /path/to/folderC/out_${COUNT}.drf ((COUNT=COUNT+1)) fi done 
Note to OP you're essentially destroying all of the files in "folder a" when you move them one by one to the same location with the same name. a.csv -&gt; today.csv b.csv -&gt; today.csv #a.csv is now gone So, probably back that stuff up or use cp instead of mv until you feel confident of the results. Edit: Also I'm not sure this script will work? You're cd'ing into "folderB," so on the next iteration of the loop I think you'll get a "file not found" or whatever when you try to mv because "${file}" isn't in that directory. I think you might need to cd back and forth or use absolute paths all over.
No. Not as a user it does not. As a user, `fdisk -l' puts what I need on 'stderr', so I can use that. But running 'lshw' as a user does not put what I need on either 'stdout' or 'stderr'. Using /u/piggahbear's suggestion puts the drive on 'stdout' as user, which makes it much better for my purposes, and is what I asked for. What I am doing is creating a library of scripts that can be used by other scripts. Getting the disk information was part of one of those common scripts. Getting the hard drive version and serial, was one part of my many scripts that source the common script. So a file called 'myCommonScript' might look like this #!/bin/bash # This script populates many bash variables with various system information. DISTRO=$(lsb_release -i) for i in $(lsblk -dn | cut -f 1 -d ' '); do DISKS+=($(echo /dev/${i})); done One script that uses it might be written by an admin: #!/bin/bash source myCommonScript #Sourcing above script for DISK in ${DISKS[@]}; do sudo hdparm -I ${DISK} | grep Number &gt; hdInfoDocumentation.txt done Another script that uses it might be written by a user with no admin privliges: #!/bin/bash source myCommonScript #Sourcing those variables again. if [[ "${DISTRO}" == "Debian" ]]; then echo "Do Debian specific thing" fi
OP says they're looking for a way to do it without `sudo` or root privileges.
we have a backup. but once the java app does its thing it is basically not needed
whoa thanks a lot. I'll use it in the futur
sounds like homework from a 3rd-rate professor
I’m surprised that your treatment of `~/blacklist_buffer` works as intended. Usually, a redirection opens the file and then just continues to use that file descriptor; if the file is unlinked on the file system, that doesn’t change anything for the program that still has the file descriptor. But apparently in this case, the file is recreated each time you write to it after it’s been deleted, and starts out fresh again. Is this a Bash feature or does this happen to any file opened with `O_APPEND`? &gt; if [ -f ~/blacklist_buffer ] If you’re using Bash, using `[[` in favor of `[` is preferred. &gt; sort ~/blacklist | uniq You can abbreviate this to `sort -u ~/blacklist`.
It's been one week. I've completed the entire thing. Here's where I ended up taking it. Procmail is just a mail handler. You don't have to be running a mail server, but exim4 (the service) can act as a mail store, running each mail file through procmail. Using fetchmail to get the mail from another server. I set procmail to save the mail files (that have pdf as the subject) to a folder on the server. Cron the fetchmail command every minute to get email from gmail. Also every minute I have cron'd a bash script to go through each file saved in the folder to send the filename to a python script. The python script has inherent tools to handle email content. It reads the link in the body of the email, runs the wkhtmltopdf program, and emails it off to the original sender. Then the script deletes the pdf, the original email, and the log. I get an email back within 2 minutes of sending a request. And works exactly as I wanted it to.
OP. http://pastebin.org
thanks. I did mess up on something A.csv is actually numerical. 1,2,3 and so on. Main folder is actually the home folder. Going to play with this tomorrow while at the family's for Christmas. Need to have it up and running for the new year. So in theory if folder a goes 1.csv, 2.csv and so on if we keep adding more to be processed it can run till we run out of work. So today we start 1.csv to 100.csv tomorrow as we are still working on the original 100 we go 101.csv to 200.csv and so on.
[removed]
how does the script manage to send the email without providing any user credentials for the email account?
Changeip.net &amp; ddclient This will update a DNS name for you when your IP changes.
It uses ssmtp, you'll have to provide email credentials in ssmtp.conf file
You have to edit /etc/ssmtp/ssmtp.conf, it should look something like this; root=MyEmailAddress@gmail.com mailhub=smtp.gmail.com:587 AuthUser=MyEmailAddress@gmail.com AuthPass=MyPassword UseTLS=YES UseSTARTTLS=YES rewriteDomain=gmail.com hostname=MyEmailAddress@gmail.com FromLineOverride=YES
Some people will probably recommend `set -e`, which makes every* error (nonzero return value) into a fatal error - it's a useful tool, but don't rely on it. *The rules for which errors it ignores are very complex (e.g. it doesn't affect commands in if-statements), so you're likely to miss something.
Assuming that we always get 5 characters preceding the 5 digit string: line="K1ABA00128ms" identifier=${line:0:5} # store first five characters latency=`echo -e ${line:5} | sed 's/^0\{1,5\}//g'` # strip out preceding 0's echo "$identifier $latency" # print out the information, with a single space Output: K1ABA 128ms
&gt; There will always be at least 5 digits beginning at the first 0 position, but the name preceding that can vary in length. It is guaranteed that there will be a leading zero in the time and no `0`'s in the name? If so, a pure bash solution is shopt -s extglob # turn on extended pattern matching echo "${data/+(0)/ /}" # replace the first run of zeros with a space 
How do you differentiate a trailing zero in the name from a leading zero in the time? e: also, is it possible to have a 10-second or longer latency result? I understand that the latency time is zero-*padded*, but that does not necessarily imply that the time always *begins* with a zero. If you have any control of the application producing the output, I'd recommend using a separator between the name and the time that cannot appear as as part of either (e.g. a space, comma, etc).
Putting ` || true` after a statement will ignore a nonzero return value, but I suspect that's not so useful if you're examining the return value manually.
 $ cat possible-names WD0ABC00128ms ABCD1234ms K0MX00087ms $ sed 's/[1-9]/ &amp;/; s/0* / /' possible-names WD0ABC 128ms ABCD 1234ms K0MX 87ms
Awesome, thanks so much. I can't test it out right now, really hoping it works.
Also keep in mind everything's case sensitive!
Bash + Python? You might be interested in the subprocess module for Python 3. It allows you to use shell commands in Python scripts. https://docs.python.org/3/library/subprocess.html #!/usr/bin/env python3 import subprocess subprocess.run("echo run any shell commands this way; echo $SHELL", shell=True) Or maybe not. Just a thought.
Thanks for the suggestion, I'll try it out.
Some feedback: Line #9 should be Line #1 Lines #1 to #4 should be somewhere after the above correction and commented out. Your word wrapping is a bit of a mess. Example: arp-scan --localnet --numeric --quiet --ignoredups | awk '{print $1}' | grep -v Starting | grep -v Interface | grep -v packets | grep -v Ending | grep -v respon ded | grep -v "arp-scan" &gt;&gt; /BadMuffin/ScanLogs/FoundHosts | echo "Arp Scan Comp lete... Starting NMAP" Should be something more like this: arp-scan --localnet --numeric --quiet --ignoredups \ | awk '{print $1}' \ | grep -v Starting \ | grep -v Interface \ | grep -v packets \ | grep -v Ending \ | grep -v responded \ | grep -v "arp-scan" &gt;&gt; /BadMuffin/ScanLogs/FoundHosts echo "Arp Scan Complete... Starting NMAP" Note that I've removed your random pipe-into-`echo`. Even better would be to collate all those `grep -v`'s into a single `egrep` or `grep -E` e.g. arp-scan --localnet --numeric --quiet --ignoredups \ | awk '{print $1}' \ | egrep -v 'Starting|Interface|packets|ending|responded|arp-scan' \ &gt;&gt; /BadMuffin/ScanLogs/FoundHosts And in fact your ordering is all wrong too: arp-scan --localnet --numeric --quiet --ignoredups \ | egrep -v 'Starting|Interface|packets|ending|responded|arp-scan' \ | awk '{print $1}' \ | grep . \ &gt;&gt; /BadMuffin/ScanLogs/FoundHosts The above are examples of one way to neatly wrap long pipes when your lines pass 80 columns. nmap -O -sV -Pn -iL /BadMuffin/ScanLogs/FoundHosts &gt; /BadMuffin/ScanLogs/Scanned Hosts | grep -v setup_target | echo "NMAP complete" | grep -v setup_target Again you're trying to magically pipe into `echo` when you shouldn't... and the double `grep -v` does... what? I'm guessing here but maybe you mean something more like: nmap -O -sV -Pn -iL /BadMuffin/ScanLogs/FoundHosts | grep -v setup_target &gt; /BadMuffin/ScanLogs/Scanned echo "NMAP complete" Your use of `cat` is textbook Useless Use Of Cat (UUOC). e.g: cat /BadMuffin/ScanLogs/ScannedHosts| grep -n 445 Can be achieved thusly: grep -n 445 /BadMuffin/ScanLogs/ScannedHosts UUOC is a sign that you have no idea what you're doing or at best you know only enough to be dangerous, so avoid UUOC. You need to add checks for the existence of `arp-scan` and `nmap` and another check for whether or not the invoking user has the correct privileges (i.e. am I root?).
&gt; Even better would be to collate all those `grep -v`'s into a single `egrep` or `grep -E` Or just `grep` with multiple expressions: grep -v -e Starting -e Interface -e packets -e Ending -e responded -e arp-scan Could even be a `grep -F`.
I'll give python subprocess a shot and see how it goes! Thanks for the suggestion ☺️
Thanks for the tips, I wrote this in 10th grade 2 years ago when I was just starting out in bash. I still obviously have a lot to learn as I didn't know about UUOC to this day. I should also start looking into checking the user privileges as you mentioned as I don't do that in any of my scripts (bad habit).
Neat stuff, thanks for the feedback. I'll be sure to incorporate what you mentioned in future scripts as I have a bad habit of setting personal paths in whatever I write and forgetting about them in the future.
"Yet another"? Which others are there?
Tons. Jekyll is the biggest.
You should learn bash scripting then. I find it so much more useful at integrating with Linux apps than ruby. I can usually do almost anything I need by searching repositories and combining tools with bash a lot quicker than writing a ruby script, unless specifically working with an API
baker, bashblog, skf, there's quite a few more that I'm too lazy to Google. Not to mention static site gens on bash, and other alternatives on sh. 
Very minimal but why not... use it direct in your shell :-D
The problem in this case, is that fail2ban won't work =) The linux box is functioning as a router. Thus, it is forwarding traffic and not logging any authentication. In fact, the multi-homed box has 5 forward facing public IP's associated and NAT's the RDP to internal MS servers ;)
Hi /u/andlrc, thanks for the reply, but I think you misunderstood my post -- "What I do for sourcing external config files" is not a question, it's a statement. I posted to share my method as it works quite fine.
When now is then, then is now.
Hi, thanks for a reply, but I think *you* misunderstood my post above. It's not an answer it's a question. &gt; I posted to share my method as it works quite fine. And I asked for you to elaborate on what is going on, as for me it seems you simply add the filename to the button of each sourced file, which for me makes no sense! 
You don’t even need to put all this information into the error message – if you want to get really fancy, you can extract it inside the `die` function using the `BASH_SOURCE`, `FUNCNAME` and `BASH_LINENO` arrays (each entry represents one call stack entry) or the `caller` builtin :) I don’t think something like that exists for `$?`, though.
You could also detect passage of time with `SECONDS` and only do the slightly more expensive date formatting every second instead of every 0.08 seconds.
I don’t get it. Is there some relation between `~/.bash_webdev` and `~/.bash_web_aliases`? Is that supposed to be the same filename?
Good day! Thanks, my OP was not clear enough. I will fix that.
It earned it when I tried installing Debian stable on Skylake.
Sorry I am not getting formatting correct for this reddit. Tested on xterm, Tilda, and lxterminal, which reports $TERM=xterm but is in fact not very compliant. Edit: Maybe formatting is better now.
I gave in and went with Debian stretch/sid, I still have minor graphics issues with intel video, but haven't been able to put a finger on it. Clock in Fluxbox seems to 'flicker' every now and again, some sort of double buffering issue. Current kernel 4.8.0-2-amd64 has not had any problems with booting or hanging randomly. I have had a few kernels and 'configs' cause issues with occasional hard-lock, but not in a while. I have `GRUB_CMDLINE_LINUX="ipv6.disable=1 intel_pstate=no_hwp i915.modeset=1 i915.enable_rc6=0 i915.enable_psr=0"` in `/etc/default/grub`
Flair is not available while you write the post. It's an option that becomes available after posting.
FWIW AIDE appears to be sliding out of favour in the *nix admin community with OSSEC being the current choice du jour. You may like to look into OSSEC...
You don't need to loop multiple times - you can loop just once - but what you have looks fine. To read line-by-line one would normally use a while loop. Sometimes it's helpful to use `echo` to see what commands would be executed without having to run them: while read listname do echo mv "/home/$listname/"{users,users_old}.txt echo touch "/home/$listname/users" ... done &lt; lists.csv As for your `sed` commands you would need to use `-i` to overwrite the original file (assuming your sed supports `-i`)
Very interesting! It looks great, must read up on it. AIDE is pretty basic, I suppose. Thanks for the recommendation.
[removed]
I like it! It's not in any way perfect,- but I do enjoy portable software like this and I think the idea is neat. Keep working on it!
SAP has a good documentation in most cases: For ABAP: http://help.sap.com/saphelp_nw73ehp1/helpdata/en/4e/c26cdc58e968b9e10000000a42189e/frameset.htm And for JAVA: http://help.sap.com/saphelp_nw73ehp1/helpdata/en/a2/f9d7fed2adc340ab462ae159d19509/frameset.htm ping /u/Cyclenerd,- in case you haven't seen yet.
That sounds like exactly what I'm looking for. I'll look into it. Thanks!
For better names and port not included.
`/etc/services` is now checked: https://github.com/Cyclenerd/static_status/commit/3f943e7d80411ba29a37763280f38a499d446a9d
Thank you for the help! The $(&lt;lists.csv) worked perfectly. You are also correct on the sed order, I did have to reorder to sed [sed command] [/path/to/file]. I was able to successfully get the scripts written and the ran today and worked perfectly! Thanks again!
I was definitely banging my head against the wall with the permissions error on the sed command. Thank you so much for the info about the -i on the sed command. That was the last piece to make with work as I wanted it to. Really appreciate your time and help! Thank you again! 
 $ sed 's \([0-9]\{1,3\}\)\.\([0-9]\{1,3\}\)\.\([0-9]\{1,3\}\)\.\([0-9]\{1,3\}\) \1.8.\3.\4 ' &lt;&lt;&lt; 192.168.15.1 192.8.15.1 But I’d personally prefer to do this without regexes: $ IFS=. read -a ip &lt;&lt;&lt; 192.168.15.1 $ echo ${ip[0]}.8.${ip[2]}.${ip[3]} 192.8.15.1
I found dozens of strong examples just by adding the terms of what you're looking for to Google: * https://www.google.com/search?q=sed+replace+octet+in+ip+address * https://www.google.com/search?q=bash+replace+octet+in+ip+address Search is your friend.
Are you saying you want to replace the 2nd octet with its last digit? $ echo 192.168.1.1 192.101.1.1 192.102.1.1 | sed -E 's/([0-9]{1,3}\.)[^.]*([0-9]\.[0-9]{1,3}\.[0-9]{1,3})/\1\2/g' 192.8.1.1 192.1.1.1 192.2.1.1
[removed]
Perhaps it would work if you updated `READLINE_LINE` and then ran the readline command normally bound to C-j, `accept-line`… the problem is, I have no idea how to run a readline command directly (outside of keybindings), and a quick search didn’t turn up anything.
1. read `man 1 find` and about regexes. (Write something along the lines of: `find all files that match NOT( ^.*[a-j].*$ AND ^.*[0-9].*$ )` 2. sed or awk yes, but I don't know these tools. Also, you can use the result of sed instead of sed directly: `mv "$stuff" "$(sed -some -things "$stuff")"`
Well you can use `[[ -e filename ]]` to test if a file exists from `help test` -e FILE True if file exists. -f FILE True if file exists and is a regular file. So `[[ -e file1 &amp;&amp; -e file2 ]]` ... As for getting the size you would probably use `wc -c &lt; file` e.g. size1=$(wc -c &lt; file1) size2=$(wc -c &lt; file2) and you could use `[[ $size1 = $size2 ]]` to test
* To iterate over an array, you need to do: `for i in "${vrm[@]}"; do` * `seq` is a nonstandard tool. You can loop over a fixed list using `for i in {1..10};` or use a c-style for loop: `for ((i=1; i&lt;max; i++));` * You can get file sizes using GNU `stat`, ie `size=$(stat -c %s file)`. See `man stat` for the long list of options for -c (or --format). * The `[[` operator is intended for string operations. To compare numeric values use `((`, ie arithmetic evaluation. `(( sizeA == sizeB ))`. If you run the script above before running Matlab, the mkfile commands should be complete and things should be ready to go. If you did need to verify the files, the `[[ -e filename ]]` and comparing file sizes as above is the right way to go.
`/etc/services` is now checked: https://github.com/Cyclenerd/static_status/commit/3f943e7d80411ba29a37763280f38a499d446a9d 
Good point.
You didn't create any signs; you opened a `vi`-clone text editor.
Hmm, do you think you could explain what that means? I just tried setting up a localhost, and I ended up like that. I couldn't delete them and (which might just be my lack of knowledge) terminal behaved differently 
Ahh, now I see. Thank you!
Ah come on, we know exactly what he meant.
Well, I do know approximately what he meant by "created a bunch of '~' signs". I have no idea what is meant by "setting up a localhost". Since you clearly know what is meant, why don't you explain it?
I think it's fair to say that someone who doesn't know they're in vi might not understand what 'localhost' is, especially because his or her post only makes sense if you read 'localhost' to mean 'a computer on my desk'.
Wow, that's interesting. Never thought of that possibility before. I haven't ever come across a way since I believe it is a shell builtin but I'm not on terminal. Actually just got an Android.... On BusyBox, it's nothing. I personally would just recompile bash and remove the related code that looks for &amp;. 
The OP is using localhost as a synonym for local machine. They likely don't know it's a technical term yet.
It could also make sense if `localhost` meant "networking stack". Or "hosts file". Or really, many other things.
Post of the year 2017
Yeah, well, I guess we all gotta start somewhere
The "Let's pretend this never happened." command.
what tutorial? I'm curious 
No worries dude, the terminal is learned, it's not like anyone here was born knowing how to navigate it.
[removed]
Don't fall for this OP. 
Huh, someone reported this comment… I’m not gonna remove it, but just to be absolutely clear, **do not run that command.**
Wow how much of your lifetime does it take that you insist on using it so much that you keep looking for it? You spent more time looking for a solution than the real deal would have cost you.
[removed]
I'm not sure I understand what you're trying to say here?..
1. First two links are not good and often not recommended on this sub. (`#!/bin/bash`, usage of `[`...) 2. First two links are not good and often not recommended on this sub. (`#!/bin/bash`, usage of `[`...) 3. Interesting in how concise it is 4. Is the good (best?) wiki 5. From looking at [this page](https://bash.cyberciti.biz/guide/For_loop): nope (`for file in $(ls /tmp/*)`) 6. Didn't read much, looks somewhat OK, usage of `[` 7. Sane defaults, but some things specific to Google can't be used in a broader scope (their shebang for instance) 8. Very good. I didn't know of it, but Gentoo's contributors look sane. 9. Gone
you can't tell me what to do
Well, he's stuck in VI so it would not be to bad. 
You should just use double or single quotes, they are meant exactly for this. Even if you don't use &amp;, scripts that you run may need them. 
Well `find` has `-exec` which executes commands - so when they say it can be done with `find` you would still be using `grep` too $ egrep -L -Z -r '[a-j]' . | xargs -0 grep -l '[0-9]' ./b $ find . -type f \( -exec grep -q '[a-j]' {} \; -o -exec grep -q '[0-9]' {} \; \) -print ./b You could use something like that if your `grep` didn't support `-r / -R` for example
“Set up a webserver on localhost” would have been a more precise way of saying that, or “set up a local webserver”.
Natural selection can sort this one out
&gt; That's like saying you were just sitting around at home, then you tried to set up your house. "Set up your house" can make a lot of sense depending on the context. The OP didn't give the context but it's easy to guess. 
&gt; The OP didn't give the context but it's easy to guess. Easy to guess, huh? So _that's_ why everyone who guessed here got it wrong.
&gt; So that's why everyone who guessed here got it wrong. Who got it wrong?
I wonder if you could do some CSS to allow people to mark commands as dangerous and disable copy pasting and show a visible warning. Won't be useful just for joke posts, might also be handy for commands that do significant changes to the system (Or require editing before use depending on your system).
I guess I could add spoiler tags in monospaced font… they would be more difficult to copy+paste because they’re links, so when you click on them to select them you go to the link target. Not sure if it’s worth it though, how many people would use them?
Selected quotes: &gt;The OP is using localhost as a synonym for local machine. They likely don't know it's a technical term yet. Technically true statements, but doesn't really explain what OP was doing. The first statement is always true anyway, so that's not surprising. The second statement is obvious given how OP worded his replies. But neither clarifies what is meant by "setting up a localhost". &gt;I think it's fair to say that someone who doesn't know they're in vi might not understand what 'localhost' is, especially because his or her post only makes sense if you read 'localhost' to mean 'a computer on my desk'. Wrong. &gt;Ah come on, we know exactly what he meant. Wrong, since nobody guessed correctly. OP already clarified what was meant, and nobody got it right.
thanks very much for pointing me in a direction. i'll try r/learnpython as well.
hold down the power button of your computer until it shuts down
try `-size -2M` to specify less than 2M... also no need for quotes around curly bracket... try `-exec rm -rf {} +` and a tip: first check the command is filtering the right folders before trying to delete them
tried both of those I'm afraid...
if I run it from shell it says No such file or directory which is strange because there is most defiantly folders in there. 
Remove the quotes from around the directories in the find command. Also the period after the directory isn't needed unless you're trying to specify that directory as in ( DOWNLOADS/. not DOWNLOADS/0. )
The first and third one are not guesses. The second one is the only actual wrong guess (and it's not even completely wrong). It's a pretty small sample to say "everyone got it wrong". Especially considering all the people who might have guessed right or wrong that didn't write their guesses because it's not relevant to the OP question. In any case if it's too difficult to guess for someone they can always try googling "set up localhost".
Making an assumption that you don't actually need recursion here. for dir in "/7. DOWNLOADS/0. TORRENTS/0. INCOMPLETE"/*/; do read -r size _ &lt; &lt;(du -ks "$dir") if [[ -n $size ]] &amp;&amp; (( size &lt; 2048 )); then printf 'Removing "%s" with disk usage: %s KiB\n' "$dir" "$size" # rm -rf "$dir" fi done
It looks like your submission contains a shell script. To properly format it as code, place four space characters before every line of the script, and a blank line between the script and the rest of the text, like this: This is normal text. #!/bin/bash echo "This is code!" &gt; This is normal text. &gt; &gt; #!/bin/bash &gt; echo "This is code!" *I am a bot, and this action was performed automatically. Please [contact the moderators of this subreddit](/message/compose/?to=/r/bash) if you have any questions or concerns.*
[removed]
`old` creates a copy of a file with an `.old` postfix. A poor man's backup ;). ``` old() { cp "$1"{,.old}; } ``` 
Haha fantastic point. This would severely harm a system. I wouldn't actually do this and wasn't thinking at the time but recompiling bash probably is the only way to achieve the literally asked question. But yeah don't do this. 
pastebin from STDIN: alias sprunge="curl -F 'sprunge=&lt;-' http://sprunge.us"
 alias lines="wc -l" I like this one. I use it so often that typing lines is easier than reaching for that hyphen.
You should drop the use of cat inside and call it `indent` instead
`psl` makes searching for processes a bit prettier, keeping the header and doing multiple searches at once psl() { ps -eo pid,euser,etime,pcpu,cmd | head -n 1 for word in "$@" do ps -eo pid,euser,etime,pcpu,cmd | \grep "$word" | \grep -v "grep" done } 
[Auto-color all the diffs](https://lukeshu.com/git/dotfiles/tree/.config/bash/rc.d/10_aliases.sh) diff() { if [[ -t 1 ]]; then ( set -o pipefail command diff "$@" | colordiff ) else command diff "$@" fi } Diff is piped through colordiff instead of calling colordiff correctly because colordiff doesn't handle all of the flags correctly. wdiff() { if [[ -t 1 ]]; then local old new off if type colordiff &amp;&gt;/dev/null; then eval "$(colordiff &lt;(echo old) &lt;(echo new)|sed -rn 's@(.*)[&lt;&gt;] (old|new)(.*)@\2='\''\1'\''\noff='\''\3'\''\n@p')" else new="$(tput setaf 2)" old="$(tput setaf 1)" off="$(tput sgr0)" fi command wdiff \ -w "$old[-" \ -x "-]$off" \ -y "$new{+" \ -z "+}$off" \ "$@" else command wdiff "$@" fi } Parse colordiff's output to figure out which colors to use; easier than parsing colordiffrc ourself. Colordiff supports coloring wdiff via piping to it, but doesn't deal with newlines correctly. diffstat() { if [[ -t 1 ]]; then command diffstat -C "$@" else command diffstat "$@" fi }
Does xdg-open work by itself? Everything is syntactically correct. If the Hulu file exists, remove it, killall openvpn, and then xdg-open. Seems solid to me.
You would simply replace the &amp;&amp; with the &amp;. You can't do the &amp;&amp; because the command doesn't finish so you can't check its status.
In bash the prompt is defined by the PS1 environment variable. The "~" means that your current directory is your home directory, and the $ means this is a prompt. The $ will be replaced by a # if you're root.
Yes it's a shell like bash. I think it's also available on Mac but I'm not sure. 
`sudo` runs a command as the users root. So you're editing root's crontab file and the script is launched as root. If you're already running as root, there is no reason to use `sudo` to run `rm` or `killall`. The current user is already root. However, when you run `xdg-open` you want that to run as the non-root user. To do *that* you need sudo, ie `sudo -u *your_username* DISPLAY=:0 xdg-open ...`.
Interesting. Thank you, I'm downloading debian now :)
I do have a question about this. I tried to use an alias like: open file, where open is a function which contains "xdg-open "$1" &amp;" , but I had issues with spaces. In your case, if the file name has spaces, does your alias work? 
I meant that I used a function in an alias. And you are right: I used if-then to check if a parameter was given(with "") , yet I used $1 instead of "$1" within the if-then. Thanks
 old() { cp --reflink=auto "$1"{,.old}; } Saves disk space :) (on GNU/Linux, will break on non-GNU systems)
Pastebin from `stdin` + ... You can use this file as an external script or source the `__sprunge` function and invoke it #!/bin/sh # Usage: # $ sprunge ./file # $ sprunge some command # $ some command | sprunge # The explanation of the following code is left as an exercise to the user __sprunge () { [ -z "$1" -o -r "$1" ] &amp;&amp; curl -F "sprunge=&lt;${1:--}" sprunge.us || printf '$%s\n\n%s' "$*" "$("$@")" 2&gt;&amp;1 | __sprunge } __sprunge "$@"
Only works on modern FS though (btrfs being the one I have in mind) (it's also a life-saver when dealing with Windows VMs)
If you run the command asynchronously (with &amp; after it), cron may not capture the output. Either cron waits from a command to exit and takes its output or cron does not capture the output. Is there a sudo log? Also note that DISPLAY is not the same as Display. ENV variables are usually all caps.
I'm half-awake but this seems to test fine on a non-GNU system (specifically FBSD7) old() { cp --reflink=auto "$1"{,.old} 2&gt;/dev/null || cp "$1"{,.old} }
One stylistic suggestion is that the new name of Apple's OS isn't capitalized. It's just `macOS`. Still working my way through the content, though. So far, so good!
Another pedantic bit I've found: `sh` _is_ the Bourne shell. `bash` is the Bourne _Again_ Shell.
Allow me to chime in here... &amp;nbsp; Powershell is indeed a terminal, and it has some extra features over the basic windows terminal. The basic terminal for windows is `cmd.exe` which you can find just be searching `cmd` in the start menu. I'm no powershell expert, but take a look at 'cmdlets' to see the added functionality. For example, a usefull cmdlet in powershell would be `Get-Process`, which is similar to `ps` in bash. You can use the cmdlet `Get-Command` will show you all cmdlets as well as normal commands. For example the command `chdir` works in cmd.exe and powershell, but `Get-Process` only works in powershell.&amp;nbsp; As for bash vs zsh, bash is the default terminal in a lot of unix operating systems, so that's what I've learned on and I'm sure many others have too. zsh has some features that bash doesn't have, which is why some people enjoy using it. But I'd say for a noob stick with bash because there are probably more online resources for learning.
&gt; Powershell is Windows terminal emulator, like terminal is in macOS. Is that correct? &gt;&gt;Terminal on mac is a GUI application that runs `bash` or `zsh` within it. Powershell is [many things](https://en.wikipedia.org/wiki/PowerShell). Here's my take on it, anyone else is free to correct me where I'm wrong or to add more detail: One of the problems with *nix shells is that they're [non-standardised](https://imgs.xkcd.com/comics/standards.png), and indeed the same is true of the usual suite of *nix commands. Some require `-` for their options, some require `--` for their options, some do both, some do none at all. Some... [who really knows](https://imgs.xkcd.com/comics/tar.png)? Some are feature rich (e.g. GNU) and others are feature-barren (e.g. Solaris) And there's no strict standard on what options are: `-r` for one command means something different on another command, and the same functionality (let's say, recurse) is specified by `-R` on another command. (There are loose standards as documented by Eric S Raymond, [for example](http://catb.org/~esr/writings/taoup/html/ch10s05.html).) This is why you'll see POSIX mentioned as a recommended practice - if you write POSIX-ly, your code will have a decent chance of working portably across almost any *nix released since the early 90's (i.e. a *nix that has `ksh` at least). Then your only problem is catering for things like GNU-isms and Solaris-isms, which is a whole other story. ^Fuck ^^you ^^^Solaris! Microsoft took a look at the best ideas from the major *nix shells and commands, cleaned up the mess, applied object-oriented principles (most popular *nix shells, by contrast, use stream-processing, which has its limits), and tooled it in such a way that it could be used for things like config management. They saw the writing on the wall (i.e. puppet/salt/ansible/etc, vm's, containers etc) and recognised that they had to get in on that game. Whether someone finds powershell decent or a repugnant cur against all that is CLI is a personal exercise. &gt;Thanks for clarifying Bash and zsh. Is there a preference for either in the community? Do I learn both side by side? Are there commands the same? Well... you're in /r/bash so you may get a biased response. Personally, I don't mind either (I use `zsh` via babun when I'm on Windows, for example), but because I sysadmin a wide range of *nixes, I will tend towards `bash` and `ksh`. Discussions comparing the two are already available at the better end of a search e.g. https://www.reddit.com/r/linux/comments/1csl7c/bash_vs_zsh/ You can learn both side by side quite happily because they're 95% the same. Like dialects of a parent language, so to speak. An external command will be the same regardless, there may be differences in their built-in commands though. `man` pages are your friend. You may also find this site useful, if somewhat exhaustive: http://hyperpolyglot.org/unix-shells
[Original Source](https://xkcd.com/1168/) [Mobile](https://m.xkcd.com/1168/) **Title:** tar **Title-text:** I don't know what's worse\-\-the fact that after 15 years of using tar I still can't keep the flags straight, or that after 15 years of technological advancement I'm still mucking with tar flags that were 15 years old when I started\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1168#Explanation) **Stats:** This comic has been referenced 190 times, representing 0.1325% of referenced xkcds. ---- [Original Source](https://xkcd.com/927/) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 4082 times, representing 2.8472% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_dc7nrbh)
[removed]
An interesting little backstory about single (Unix) and double hyphen option (GNU) styles: &gt; In the original Unix tradition, command-line options are single letters preceded by a single hyphen... The original Unix style evolved on slow ASR-33 teletypes that made terseness a virtue; thus the single-letter options. Holding down the shift key required actual effort; thus the preference for lower case, and the use of “-” (rather than the perhaps more logical “+”) to enable options. &gt; The GNU style uses option keywords (rather than keyword letters) preceded by two hyphens. It evolved years later when some of the rather elaborate GNU utilities began to run out of single-letter option keys (this constituted a patch for the symptom, not a cure for the underlying disease). It remains popular because GNU options are easier to read than the alphabet soup of older styles. From [The Art of Unix Programming](http://www.faqs.org/docs/artu/index.html) by Eric Steven Raymond And I'll echo the bash vs zsh comment. I use zsh when using my own terminal, because it's way faster and get more customizable, but since I'm a Mac sysadmin, anything I build I build in bash (v3.2, unfortunately) or sh. Zsh has a lot of tiny little differences in syntax that aren't portable.
The "uniq" command will filter duplicate messages and can be run with stdin as input. 
Sorry, will add to the main post right now.
Yeah. If you simply want to ignore lines identical to the previous line, `uniq` is your friend. I would use a JSON parser to parse the JSON (eg to extract the id), like jq. But matching the numbers anywhere in the string should mostly work here. /usr/local/bin/rtl_433 -F json -C customary -R 39 | uniq \ | while read line; do if [[ $line = *12381* ]]; then /usr/bin/mosquitto_pub -h "$MQTT_HOST" -u temps -P temps1 -p 1883 -i RTL_433 -l -t "livingroom/temp" &lt;&lt;&lt; "$line" elif [[ $line = *12963* ]]; then /usr/bin/mosquitto_pub -h "$MQTT_HOST" -u temps -P temps1 -p 1883 -i RTL_433 -l -t "evansroom/temp" &lt;&lt;&lt; "$line" fi done
So that script works perfectly for me on Ubuntu 16.04. Are you explicitly setting it up as a bash script? (#!/bin/bash on first line or running it via bash (bash &lt;file.sh&gt;))? The default in Ubuntu is dash and that often barfs
The advantage of screen/tmux comes when you're connecting to a remote server. When the connection dies, your multiplexer and any jobs started there are still running. In case of straight SSH, it will break. If you're running things on your local machine, then it's usually easier to handle multiple terminal tabs/windows. Running multiple jobs (in background) in single terminal can just get a bit messy if all are providing output.
Pretty much the only time I use job control in an interactive shell is to send an `evince` I started from the command line to the background. (And since `evince` is pretty noisy, I put this in `/usr/local/bin/evince`: #!/bin/sh exec /usr/bin/evince "$@" 2&gt;/dev/null which effectively shuts it up.) For everything else, I use `tmux`. I’ve set GNOME Terminal to run `tmux` as the shell command – that is, every new terminal window (or tab, but there’s no point with tabs if you use `tmux` already!) gets a new `tmux` session automatically – which very effectively removes the previously felt occasional burden of “I should probably start a `tmux` session for this, but I already have some content in my terminal I don’t want to lose”.
thanks, I just typed it by memory
The thing is, `split()` is part of the POSIX specs for awk so it ought to work regardless.
Ran it explicitly as a bash script, same result.
In the .rc file, add `cd "some path here"`
Not a real answer but some définitions : Process are all the activities on the os everything witch runs on a Os is a process. Jobs are batch witch start and stop at a precise time. Terminal is your connection to the server 
That's because Bash for Windows doesn't see your drives that way. Bash for Windows is a set of linux subsystems ported and running on windows. It has an entire linux filesystem that bash is sandboxed too and a huge library of Ubuntu applications ported to windows. Bash for Windows mounts all of your Windows System drives to "/mnt/" inside that sandboxed filesystem. So in your case you would want the following: cd /mnt/c/Users/yourusername/Documents
Ran it, version is 1.3.3
are you able to pass the remote and local file to pv and it work out the progress or are you only able to pipe into it?
&gt; What I'm wanting to do is as show the progress of the transfer in percentage on a third line, but I'm a bit stuck with where to start does anyone have any ideas? Drop the oneliner approach and make yourself a small script. Get the total size and the transferred size as variables and then `printf "%s\n" "$(( 100 * transfered / total ))"` ? Assuming, of course, that you're outputing integers and not floats... `pv` has already been mentioned, but you may like to also look at `progress`: https://github.com/Xfennec/progress
Well at least you didn't finish the code for me. I guess I should stop doubting myself :P Didn't know about that site either, so thanks a lot! Time to finish what I started.
Just ran it, sar as a command isn't installed
That's a great site / script to use. Thanks for sharing!
Well the instructions are in the comments # Init: # $DATAPATH/.zyklus file must exist, initialize content with -1 # $DATAPATH/dirs file must contain absolute pathes to to-be-backed up dirs # $DATAPATH/.medium file should be initalized with 3 2 1 6 5 4 0 # $DATAPATH/medium "0-6" dirs must exist! Although it seems rather complex - is there any particular reason you're using this script? Can't you just use `rsync` or even `cp -a` if all you want to do is backup a single folder?
Don't have a system to test on right now - but from a quick search it looks like `mawk 1.3.3` is/was buggy - so i'd imagine your error has something to do with that. http://bugs.launchpad.net/boot-repair/+bug/1331381 It looks like the `awk` command you have is just isolating the %id column from the Cpu line in `top` You should be able to replace it with: top -b -n2 -p 1 | awk -v "prefix=$prefix" '/Cpu\(s\):/{ sub(/%.*/, "", $5); printf "%s%.1f%%\n", prefix, 100 - $5; exit }' The %id seems to always be in "column 5" - so we can just use `$5` directly - otherwise you could loop over each field.
Hey, thanks for the help. Line 3 returns an "unexpected EOF while looking for matching )" and line 10 "unexpected end of file". Adding a ) to the end of line 3 returns an unexpected end of file on a separate line.
yes, I have to use this script. I have seen the instructions but I don't understand it. The .zyklus file is responsible for the cycle when a backup is made, I guess. How do I initialize it? What is written into it? Same with .medium: "initialize with 3 2 1 6 5 4 0"? What does that even mean? I'm desperate... We already have a similar rsync script btw. 
What happens if you run the `top | awk` command as shown above on its own? Can you post the full code you're using?
&gt; The .zyklus file is responsible for the cycle when a backup is made, I guess. How do I initialize it? What is written into it? # $DATAPATH/.zyklus file must exist, initialize content with -1 Well it says that it must contain `-1` - so it sounds like you just create it and put `-1` in it e.g. echo -1 &gt; "$DATAPATH/.zyklus" ... or by using whatever editor it is you like to use. &gt; Same with .medium: "initialize with 3 2 1 6 5 4 0"? What does that even mean? I'm desperate... I'd imagine it's the same thing the file contents should be `3 2 1 6 5 4 0` 
ok, so with this bit you're testing that the program is running: if ps ax | grep -v grep | grep $SERVICE &gt; /dev/null shellcheck would have directed you to use `pgrep` e.g. if pgrep "${SERVICE}" &amp;&gt;/dev/null; then but either way will test whether or not the service is running. So ... `while` ... we know that the service is running, we can perform your backups, conceptually something like this: # Check that the service is running if pgrep "${SERVICE}" &amp;&gt;/dev/null; then # If so, then while it's running, sleep for 300 seconds and create the backup1 file while pgrep "${SERVICE}" &amp;&gt;/dev/null; do sleep 300 cp "$HOME/Zomboid/Saves/$GameType/$SaveName/map_p.bin{,.backup1}" # Now sleep for another 300 seconds and create the backup2 file sleep 300 cp "$HOME/Zomboid/Saves/$GameType/$SaveName/map_p.bin{,.backup2}" done else ... Note that this is untested etc
Thanks. I've been playing with this and trying to figure out why it seems like the process is delayed using this method. Just using one id and watching it appears that it captures 6-8 entries before sending them through. Basically posting all entries every 2-5 minutes after they have occurred.
See http://mywiki.wooledge.org/BashFAQ/009
lol that is actually way better then what i had, and its clean
How about this... if [ "${entered_number}" -lt 255 ]; then echo "Number is OK" else echo "OOPS, need to pick a different number" fi You could put that into a function but that's the guts of it.
You are not storing the result of the find command, you are storing the find command. What you want is something like this... FIND=$(find /mnt/user/me/Inbox -mmin -1) You should echo your values when they don't do what you expect.
I was surprised to find you hadn't gone there! But clearly you were in a different train of thought :)
Why not just allow the whole IP address and use pattern matching to check the first octet? ipa="8.8.8.8"; [[ "$ipa" =~ ^[0-9]\. ]] &amp;&amp; echo true I'm not sure what you're doing with the other line. Edit: okay, reddit is stripping characters, I'll fix this real quick... fixed 
If you read one key at a time (with `read -n1`) you can add a simple check so the number is only accepted if the current input doesn't go above 255. Example (this doesn't check to see if the IP address is four numbers long): #! /bin/bash IFS=$'\n' while true; do echo -ne "\r\e[2KIP:$ipaddress$number" &gt;&amp;2 read -n1 -s key if [[ $key =~ [0-9] ]] &amp;&amp; (($number$key &lt;= 255)); then # input is: number (add it to the current number if it doesn't cause it to go above 255) number+=$key fi if [[ $key == . &amp;&amp; -n $number ]]; then # input is: dot (go to the next number in the ip address) ipaddress+=$number. number= fi if [[ -z $key ]]; then #input is: Enter (echo the current ip address) break fi if [[ $key == $'\x7f' ]]; then #input is: backspace (remove last character) number=${number%?} fi done echo -ne "\r\e[2K" &gt;&amp;2 echo $ipaddress$number 
[removed]
&gt; find /mnt/user/me/Inbox -mmin -1 Also if you only need to know whether *any* files were changed and don't actually care which ones they were, you can do `find /mnt/user/me/Inbox -mmin -1 -print -quit` and it will just print the first thing it finds and then exit.
Yes, but it only makes sense to do that if the '…' is some other command that writes multiple usernames to standard output.
&gt; The README doesn’t seem to have any simple syntax examples Sounds like a valid "todo" item. Adding to the queue. Meanwhile [this information is a bit buried](https://github.com/ilyash/ngs/blob/6ffa89ad56a8e17a02ae045c5e0017440731de7c/doc/ngslang.1.md#syntax-and-basic-functionality). Yes, the sneaky word splitting has to stop... and the syntax is very close to what you suggest. `ls $a` - no word splitting. `ls $*myarr` or `ls $*{my+expr}` - explicit word splitting. &gt; too much value on the programming language it was based on Again, I don't think it's optimal to base a new shell on an existing language in the long run. &gt; That is a no-go for a general purpose shell in my opinion ... and that's one of the examples why
Thank you. This is what I ended up with. While it may not be perfect I am no longer getting errors reported in HAS. http://pastebin.com/0kCCHmMm Can't get the formatting right on here. stdbuf -i0 -o0 -e0 /usr/local/bin/rtl_433 -F json -C customary -R 39 | stdbuf -i0 -o0 -e0 uniq -s 33 \ | while read line; do #echo $line if [[ $line = *12381* ]]; then LvngRm=$(echo "$line") echo $LvngRm | /usr/bin/mosquitto_pub -h "$MQTT_HOST" -u temps -P temps1 -p 1883 -i RTL_433 -l -t "livingroom/temp" #echo $LvngRm elif [[ $line = *12963* ]]; then EvnRm=$(echo "$line") echo $EvnRm | /usr/bin/mosquitto_pub -h "$MQTT_HOST" -u temps -P temps1 -p 1883 -i RTL_433 -l -t "evansroom/temp" #echo $EvnRm elif [[ $line = *3360* ]]; then BdRm=$(echo "$line") echo $BdRm | /usr/bin/mosquitto_pub -h $MQTT_HOST -u temps -P temps1 -p 1883 -i RTL_433 -l -t "bedroom/temp" #echo $BdRm elif [[ $line = *7329* ]]; then Ktchn=$(echo "$line") echo $Ktchn | /usr/bin/mosquitto_pub -h $MQTT_HOST -u temps -P temps1 -p 1883 -i RTL_433 -l -t "kitchen/temp" #echo $Ktchn fi done
Sooo.... a thin wrapper around openssl with a shared secret? 
You've got multiple issues here. You can't use 1 and 2 for the variables. 0-9 are reserved for command line arguments. Don't prefix variables with dollar sign on the read. You've got various whitespace issues around the if statements. #!/bin/bash read a b if [ $a -gt $b ]; then echo '1st &gt;2nd' elif [ $b -gt $a ]; then echo '2nd&gt;1st' else echo equal fi
I was able to find multiple sources to help you with [this link](https://www.google.com/search?q=bash+compare+integers). [Edit] Yeah downvote the guy who sends the lazy person to Google. Goodness forbid someone oppose doing work for people too lazy to google the question before posting.
I think others have answered, but here's one other subtle point. If the integers in question are extremely large (e.g., several dozen digits requiring multiple precision), then you might need to use `bc` to compare them reliably: booltest=$(echo "$integer1 &gt; $integer2" | bc) if [[ $booltest -eq 1 ]]; then echo "$integer1 &gt; $integer2" fi
Great point, I'll have to fix this! [Edit: [fixed!](https://github.com/BrandonRomano/teamcrypt/commit/8df9f1436dbd9361a9b234b01e68557d1b5450cf)]
Yup! I suppose the argument for it is that you don't have to communicate what algorithm you've used, and also you can establish a consistent key with your team. It's not complicated, but this solves a problem I was having, there was absolutely no way I was going to get my team to remember how to use openssl.
&gt; attack-plans.txt You're on the list now ;)
Hm, I'm not sure that will work will it? I thought I have to actually pass through the stdin to openssl right? stdin doesn't automatically get passed to it. Am I missing something? Just to verify, I've just removed it and am getting this error from openssl: &gt; error reading input file
You've misunderstood a bit how pipes and redirection work. Removing the `cat &lt;&amp;0 | ` really should work as before. The error message doesn't make sense in that regard, so maybe you added something extra while you were at it? I'd need to see the actual line that caused the error...
Nice :) 6 days later I stumble across this and think "why didn't I think of that?". Thanks for the contribution.
Ah yup you're right, my mistake I tested it incorrectly. I understand why it's not needed now! Thanks for the help :D
&gt; If the integers in question are extremely large (e.g., several dozen digits requiring multiple precision), then you might need to use bc to compare them reliably: For reference those numbers are: 9223372036854775807 #2^63-1 2147483647 #2^31-1 32767 #2^15-1 `bash` by itself typically supports 2^63 - 1 which IIRC is defined by LONG_MAX: # Integer overflow represented by a negative number $ echo $((2**63)) -9223372036854775808 $ echo $((2**63-1)) 9223372036854775807 I have seen some applications choke around 2^54 - 1, but usually the above three numbers are safe 
this is what i've done but i want my name to be green. COLUMNS=$(tput cols) title="Created by KittenOnCatnip" printf "%*s\n" $(((${#title}+$COLUMNS)/2)) "$title" 
How can I integrate this function in a backup script? The sets of folders to be backed up are moved to a new folder named by the function. This is intended to make way for a new set of folders. Then certain parts of the backed up folders are extracted to select folders in the newly created set. Any tips and contributions are welcome. Thanks all.
 function backup(){ newDir=$(dateNoSpaces) mkdir "$newDir" &amp;&amp; cp -r "$@" $newDir } Above is an example of using the dateNoSpaces function to create a new directory (named by the dateNoSpaces function) and copy the provided folders into the newly created directory. For example, backup dirOne dirTwo fileOne would yield a directory named by the dateNoSpaces function containing dirOne, dirTwo, and fileOne
mkdir (dirname) &amp;&amp; cd (dirpath) this should work
You need a function that will be executed in the current shell. function mkcd { mkdir -- "$1" &amp;&amp; cd -- "$1" } You need to put that somewhere in your Bash initialization files, e. g. in `~/.bashrc`.
my approach: function in .bashrc call: mkcd myNewDirectory function mkcd() { mkdir $1 &amp;&amp; eval cd $1 } 
Yes, thank you. /u/galaktos sorted it for me. Made it a function in /etc/bashrc 
I put it in /etc/bashrc where the whole one user can benefit from it. Thanks!
I made this version, which is more versatile: mkcd() { mkdir "$@" || return shift "$(( $# - 1 ))" cd -- "$1" } Advantages: * All given arguments are passed to `mkdir` without modification. This means `mkcd` inherits all of `mkdir`'s possible options, such as `-p` and `-v`. * As with `mkdir`, you can make several directories at once. If you specify several directories, `mkcd` will create all of them and upon success `cd` into the last-mentioned one. (That's what the `shift` command in the function is for.) Note that this works on every POSIX shell, not just bash. 
All these are great. While it's still more verbose, I wanted to mention the Alt+. key combo; it repeats the last argument from the previous command. It's applicable here as: $ mkdir foo $ CD Alt+. - the Alt+. gets interpolated to 'foo' Jumping to a directory just made is convenient, but I wanted to highlight the more general convenience of repeating the last argument from the previous command.
&gt; I wanted to mention the Alt+. key combo That's pretty cool! Thank you.
I added the wtf function, it's fun.
 alias pbcopy='xclip -selection clipboard' alias pbpaste='xclip -selection clipboard -o' You might like to build on these for portability e.g. if ! command -v pbcopy &amp;&gt;/dev/null &amp;&amp; command -v xclip &amp;&gt;/dev/null; then alias pbcopy='xclip -selection clipboard' fi Using `find` `ag` and `tree` to look for a file ignores the `locate` command. I don't know if it still needs to be manually enabled on mac though, but to `locate` your example file `auth.py`, you could have simply used `locate -r "/auth.py$"` and got an immediate result.
Thanks! Just put this in my .bashrc. I've always needed this so it's gonna be pretty useful.
For directories you can use the `*/` pattern. I think you're trying to go into each directory, do something, then move into the next? If so, you can do something like this (cd'ing back out of each so you can cd into the next): `for i in */ ; do cd $i ; pwd ; cd .. ; done` I'm not seeing an issue with renaming using the above, but I did have to trim the trailing slash. So, something kind of messy like the below seems to work (someone else will probably have a better solution): `for d in */ ; do d=$(echo $d | tr -d '/') ; cd $d ; for f in * ; do mv "$f" "$d - $f" ; done ; cd .. ; done` As an example, start with this (directories a, b, and c each containing files aaa and bbb: $ ls -R .: a b c ./a: aaa bbb ./b: aaa bbb ./c: aaa bbb Do this `$ for d in */ ; do d=$(echo $d | tr -d '/') ; cd $d ; for f in * ; do mv "$f" "$d - $f" ; done ; cd .. ; done` Get this $ ls -R .: a b c ./a: 'a - aaa' 'a - bbb' ./b: 'b - aaa' 'b - bbb' ./c: 'c - aaa' 'c - bbb'
[I blogged about this a while back](http://blog.ryanmccoskrie.me/2015/11/mkcd-my-favourite-script/)
 for directory in *; do test -d "$dir" || continue touch iwashere.txt done You could try this another way e.g. for directory in $(find . -type d); do You will probably want to check `man find` to nail down exactly what you want, specifically options like `-maxdepth` (note this isn't portable, but I suspect that's a non-issue) and `-print`
I got used to the following, quick to type and doesn't require anything special in the shell: $ mkdir name_of_new_directory $ cd $_ The shell expands dollar-underscore into the last argument of the last executed command, so there you go. Can also be used multiple times in a row, for example to rebuild a program: $ rm -r build # Usually type "rm -r b" and press Tab $ mkdir $_ $ cd $_ $ cmake .. # etc. Edit: The first is your standard mkdir, the second is cd space dollar underscore Edit 2: Hopefully got formatting right this time Edit 3: Explain how it works
Not by default no, you're right. Prezto is a config framework for zsh that out of the box has great defaults (including mkdcd) and it's really customisable. Makes shell work easy. https://github.com/sorin-ionescu/prezto
&gt; for directory in $(find . -type d); do OP is likely to have spaces and other special characters in their file and directory names. Since the command substitution is split into words at whitespace, this will not work for that. Using globbing is the only reliable way.
You could add `whatis` to your `wtf` function, I think that'd be a nice addition. ~ $ whatis whatis whatis (1) - display one-line manual page descriptions 
This is close. The last line (mv "$f" /completely/new/location) moves the original zip files to the new location, not the extracted and renamed ones. I changed it to this: for f in *.zip; do d=${f%.zip} unzip -d "$d" "$f" cd "$d" for file in *; do mv "$file" /completely/new/location/"$d - $file" done cd .. done And it's very close. It unzips into sub-folders, renames each file in the resulting sub-folders, but then moves each of the new FOLDERS into the new location instead of the individual FILES into one flat location. Does this have to do with what /u/rumbling_trashcan said about trailing slashes? How do I fix that?
An alias in bashrc should work here? No? Alias execute in your current shell if I'm not mistaken
Do both.
Doesn't POSIX require the flags before the arguments? At least getopt works like this.
You're right, but so will most implementations of `mkdir`. In UNIX commands, options are always supposed to come before operands, and the first operand will turn off option parsing. For instance, on the Mac (with FreeBSD `mkdir`), this throws an error and makes a directory called `-p`: $ mkdir a/b/c -p mkdir: a/b: No such file or directory $ ls -ld -- -p drwxr-xr-x 2 MY_USER staff 68 Jan 17 16:51 -p $ rmdir -- -p But yeah, GNU `mkdir` apparently supports that weird syntax. I'd ignore it. It's a bad habit at best. There are many good reasons for options to precede operands. 
I suspect there’s an unclosed `"` somewhere before this function, so that the `"` in `echo "'$1' cannot…` in fact closes that earlier `"` and the `()` in `…via extract()` is unquoted and misinterpreted.
what kind of shell do you use? because this function works perfectly on my box `bash 4.4.5`
Thanks man! I solved my problem thanks to your answer. I created a back up file, then line my line where the error occured I deleted them until I spotted a sneaky " " at the end of a echo line in a different function.
Isn’t this a repost of [this post](https://www.reddit.com/r/bash/comments/4xgjhu/blackoprhan_remote_shell_access_tool_built_with/)? Did something change since then that merits a new post?
something changed
I’m sorry, you’ll need to elaborate a bit more to convince me that this isn’t a repost… what changed, apart from new commits in the repository?
To add to you: automatetheboringstuff.com
To clarify, do you want things to happen on the connecting system or on the netbook/server?
Oh, on the server. Sorry!
[removed]
Completely untested, but if SSH is compiled with PAM support (almost certainly true) Then you can get PAM to execute stuff on the server for each SSH login Try something like this to the server's pam config for SSH `/etc/pam.d/sshd` session optional pam_exec.so seteuid /path/to/script Note: `optional` means that if the script returns an error (returns non-zero exit code), you can still login changing this to `required` would prevent logins if the script returns non-zero Info on pam_exec here http://www.linux-pam.org/Linux-PAM-html/sag-pam_exec.html
Oh, nice! I wasn't actually aware of PAM. That looks like it might work. How about using the variable $SSH_CONNECTION? Like seeing if it *isn't* blank and then prompting some command to run. Not sure it would work, just wondering.
I think the best data structure in this case would be none at all: instead of first parsing the command line and then operating on it, operate on it as you walk it. #!/bin/bash function ripfile { # stub printf 'ripping file #%d out of file %q\n' "$2" "$1" } file="" while (($#)); do case $1 in -d) shift file="${1:?-d operand missing}" ;; *) ripfile "${file:?file not specified (no -d FILE seen)}" "$1" ;; esac shift done Or, if you need to process additional options that should apply to all rips, even if they occur later in the command line, you can first parse those options and push all other arguments into an array that you then walk later. #!/bin/bash function ripfile { # stub printf 'ripping file #%d out of file %q (flag1=%q, flag2=%q)\n' "$2" "$1" "$flag1" "$flag2" } args=() flag1="" flag2="yes" while (($#)); do case $1 in -f) shift flag1="${1:?-f operand missing}" ;; -g) flag2="no" ;; *) args+=("$1") ;; esac shift done file="" for ((i=0;i&lt;${#args[@]};i++)); do case ${args[i]} in -d) file="${args[++i]:?-d operand missing}" ;; *) ripfile "${file:?file not specified (no -d FILE seen)}" "${args[i]}" ;; esac done In this case, the first loop could probably also use `getopts` too. (Edit: removed a leftover `shift` in the second-to-last line of the second script.)
Thanks! I'll try that.
 #!/usr/bin/env bash shopt -s globstar echo "${FILES}"/**/*.xml # or loop over the files for f in "${FILES}"/**/*.xml; do echo "$f" done
 find folder/ -type f -name "*.xml"