Really, this statement is worth adding to the headline of the akka-http page. Thanks for the explanation.
Still, is Akka-Http ready to replace Spray in production? Just want some "unofficial opinion", cuz we're using Spray heavily.
Even after refreshing/reloading the project? Intellij seems from time to time to have some issues, sometimes that helps.
I am amazed by the many articles and blog posts that sprout up everywhere that mention "Pokémon Go" in their title ... and then have nothing to do with Pokémon Go whatsoever. The example is not even remotely convincing. It looks more like a TODO list than anything else.
Indeed, very happy about this release.
It is? I wouldn't expect an implicit SemigroupK instance for Option at all (both first and last semantics are equally valid), just as I wouldn't expect one for `Option [A]` if A is some arbitrary type. If A forms a semigroup then they might make the lifted instance implicitly visible on the grounds that it's the most common one people would want to use, which is not wrong as such but kind of misleading when the lifted instance isn't (and can't be) implicitly visible for e.g. List. As I said, the decisions about which typeclass instances are implicitly visible when there is more than one possibility are kind of ad-hoc and I'm not at all surprised if they've ended up being inconsistent. If you're using IntelliJ you may be able to ctrl-shift-P to see where an implicit is coming from which should give you more idea exactly which instance you're getting. 
What does "*type ensurer*" means? If you're referring to what I think you do, that has been a good thing. Also, what's the problem with primitive types? They are only stack-allocated values and the real problem is that we cannot define our own stack-allocated values. But they are definitely coming on the JVM, see this presentation: https://www.youtube.com/watch?v=Tc9vs_HFHVo The existence of "null" can be a PITA, but I'm not experiencing problems with Scala's libraries. The importance of its existence is a little overblown by critics imho, as it tends to go away with a good Option type and Java isn't even unique in this regard, as "null" is present in the top 30 languages (with exceptions like Haskell and Ocaml, which depending on your source, are either in top 20 or not in top 30 at all). In general OOP languages or languages with manual memory management have "null". Not ideal of course, but Dotty has both intersection and union types and so AnyRef references are non-nullable by default. So this too will happen at some point.
If Scala were it's own runtime, I'm sure there'd be complete erasure, with no reflection outside of pattern matching. Erasure ensures programs are correct.
I see it as providing a test bed for features that may later become part of the "official" compiler. The conditions for accepting things into the Typelevel compiler make it pretty clear they want their changes to make their way into the main compiler in the future.
The fix is available in [Typelevel Scala](https://github.com/typelevel/scala) for 2.11.8 and will be available in Typelevel Scala 2.12.0-RC1 very shortly.
I'm still wondering whether your smartphone has some really weird autocorrect or you just made that word up...
He probably meant type *erasure*
My thoughts exactly. Click-baits are strong with OP
Interesting article. Is there a more functional way to use slick? For example, this db.run will apply a side effect, so every time we will call insert the side effect will be applied immediately, would it make sense to not run this in the repository? Will it change the testing part?
You can try https://github.com/nafg/slick-migration-api
I made [this](https://github.com/blbradley/kafka-cryptocoin). I feel that it is a decent example of how to use Akka Actors and Streams. The commit history is fairly clean.
Hi , Starter here, Can I know what is the point of collecting cryptocurrency exchanges? 
I like the first half of your post. Your point about algebras really strikes true and I need to look into that more. I found that the last half of your argument about "shared understanding of what constitutes good code" to be a tautology though. It's strictly cultural and therefore a sort of confirmation or belief bias. That said, I understand where you're coming from. When OOP became popular, it was largely around Java and Java was clearly, from the point of view of being able to reason about one's own code, better than any mess of global variables could hope to be in other languages. Now you're saying that (my interpretation) stateless algebras of composable functions are superior for similar reasons; i.e. they make reasoning about state easier. The danger in the long term lies in assuming that the benefits are self-evident. Obviously, they are, if you present findings in a mathematical or even merely repeatable test driven approach, but the approach is sufficiently abstract that it is not intuitive; or at least history would indicate that it is not. I believe making referential transparency THE new principle around software design is key to future FP success; much as encapsulation was to OOP. That will provide the next major step for the industry to more sound practices. God only knows what lies beyond that. Any takers? ;)
In general you won't find many such bigger projects worth looking at their history, either because in the beginning there's no coherence, no clear idea of what is meant to be achieved, so the repository starts with a bunch of throwaway code, many times without making any sense. And other times it starts out with a code dump that was used internally or in another library and it develops from there. There are two libraries whose code is worth reading and that would be Cats and Scalaz. Cats being newer, it also has a shorter history, especially because they could be inspired by Scalaz before it, but you'll find many gems in it and the code is worth reading because they are doing a lot of FP *design*. And reading the code and the discussions around those pull requests can be very enlightening.
no, it does not work effectively in most scenarios, besides the fact that this does not answer OPs question. Although for to-do lists it's great. Try it for developing a game, or a more complex system. You will struggle to come up with sensible test scenarios, since a lot of times, you only you know what exactly want after you tried it. It will result in a pigeonhole product, where the user can do stuff that doesn't work properly, but you don't every try finding these cases , since you have tests, and they all pass. Also it's not necessary with Scala if you use the type system properly, since TDD comes from dynamic languages, where a LOT can go wrong on runtime, types can be different, anything can be null, casting fails, function doesn't exists, dynamic invocations, etc.... In Scala you only really need to verify your core business algorithms.
&gt; I found that the last half of your argument about "shared understanding of what constitutes good code" to be a tautology though. It's strictly cultural and therefore a sort of confirmation or belief bias. All communication relies on shared culture. I can't speak for the OP article, and maybe that particular talk doesn't provide enough motivation. But in general, the ideas of representing programs as values, composable algebras, and interpreters are pretty established *in the FP culture/community*, and I wouldn't want every talk to spend time deriving them from first principles again. I mean, the "bad" code you posted is already Haskell and is already using `IO` and explicit composition of effects (`*&gt;`), so it's fair to assume that the audience for that talk was already familiar with those ideas. Just as when giving a talk about a new OO pattern you'd probably assume that everyone already agreed that encapsulation was valuable, and not spend a lot of time talking about the general benefits of encapsulating state in small pieces. &gt; That said, I understand where you're coming from. When OOP became popular, it was largely around Java and Java was clearly, from the point of view of being able to reason about one's own code, better than any mess of global variables could hope to be in other languages. Now you're saying that (my interpretation) stateless algebras of composable functions are superior for similar reasons; i.e. they make reasoning about state easier. Ideally you don't even reason about state at all - only about values and pure functions. Eventually you need an interpreter that performs actual operations based on the values it's run with, but you make the low-level value representation close enough to the actual operations that the lowest-level interpreter is obviously correct, and the higher-level interpreters are just pure functions that transform values so you can test them as such. &gt; The danger in the long term lies in assuming that the benefits are self-evident. Obviously, they are, if you present findings in a mathematical or even merely repeatable test driven approach, but the approach is sufficiently abstract that it is not intuitive; or at least history would indicate that it is not. Well, FP seems to be on the up-and-up. If one believes that FP will "win" then it could be reasonable to assume that future generations will find the value of referential transparency etc. to be exceedingly obvious. Again, one writes for a particular audience, assuming a particular culture and a baseline of shared understanding - and it's possible to be mistaken about the specifics and spend too much or too little time giving the motivation in terms of the basics, but the general principle is sound. I would agree that there's value in talks that clearly demonstrate the merits of the basics to newcomers. But there's also value in high-level talks that take the basics as read. &gt; I believe making referential transparency THE new principle around software design is key to future FP success; much as encapsulation was to OOP. That will provide the next major step for the industry to more sound practices. Sure. I think most FP advocates already agree with that. &gt; God only knows what lies beyond that. Any takers? ;) Provable correctness, enforced by the type system, i.e. Idris et al.
It seems ["2.12.0-RC1 is extremely nigh!"](https://groups.google.com/forum/#!topic/scala-internals/JslA9u20mow)...
In SBT, there are different kind of dependencies. `addSbtPlugin` is used to add more functions to SBT, e.g. to add or change build options (I use sbt-assembly** for my projects to build a single file with all dependencies included. ScalaJS is also supported using a plugin). For libraries that you use for applied tasks (e.g. parsing JSON) there is `libraryDependencies`. It's quite common to see something like this: libraryDependencies += "org.typelevel" %% "cats" % "0.7.0" or even libraryDependencies ++= Seq( "org.scalatest" %% "scalatest" % "3.0.0" % "test", "org.scalaj" %% "scalaj-http" % "2.3.0", "org.typelevel" %% "cats" % "0.7.0", "com.typesafe" % "config" % "1.3.0" ) in the code. Where do these libraries get downloaded from? Well, you specify **resolvers** for this. resolvers += "jgit-repo" at "http://download.eclipse.org/jgit/maven" It's totally OK to have multiple of those, and SBT has most common ones available by default. See the [documentation for resolvers](http://www.scala-sbt.org/0.13/docs/Resolvers.html) to see which are. For publishing, documentation again has it explained: http://www.scala-sbt.org/0.13/docs/Using-Sonatype.html. To be honest, I never done this (at least yet). I'm using [JitPack](https://jitpack.io), it's a decent option if your library is in a public GitHub repo. As for registry, Scala and Play are part of more general Java ecosystem, so you can look up stuff in [Maven Central](http://search.maven.org/), although most of it will be Java libraries - usable, but likely not idiomatic Scala. For Scala in particular, library index called [Scaladex](https://index.scala-lang.org/) was made recently, but relevant results are often not at the top. Take a look also at [Scala-awesome library list](https://github.com/lauris/awesome-scala). Some community SBT plugins are also [listed here](http://www.scala-sbt.org/release/docs/Community-Plugins.html) Hope it was helpful in some way.
&gt; it completely destroys the credibility of any position really? are you that shallow and judgmental? it was a minor, simple mistake, and an easy one to figure out. maybe he is not a native speaker, didn't you think that?
Comparison can be found [here](https://monix.io/docs/2x/reactive/observable-comparisons.html).
Nice! Thanks for your awesome work on Monix. Its a really great library, i especially love how well documented it is. Question - can observables be created in Scala.JS using event listeners? I didn't find any examples of that. It would be nice to have an observable for say an html slider or input streaming the current value.
oh damn thanks man! I missed a good ploting lib
it would be worth mentioning that Either will be right-biased in 2.12
What impact, if any, will that have on Disjunction and Xor in scalaz and cats, respectively?
[Jsoup](https://jsoup.org) worked well for me.
You could run two JVMs and then pipe the data through. Kind of a gross work around though. Also define "A lot of data". Spark might be overkill for some amounts of a lot of data.
Does that mean we should prefer Try for the meantime?
Array only exists for Java compatibility?
A lot of which is at least alluded to in the article - which I should have read before commenting :-) But at least consider my comment another vote for why `Either` is often something to reach for when writing code, *before* considering `Try`.
I actually don't undersand why. Either is or was for me not something I handle errors with or have a "default" case. It is a type that allows me to store either A or B which are both equal and are just different. That is, every time you want to do something with it, you should be forced to decied, what to do. I could also use sealed traits with 2 implementing case classes but that seems not a good solution in most cases. What would be the alternatives?
What usually happens to me is that side-effecting I/O code is where all the exceptions are coming from. And since I (almost) always want to do asynchronous I/O, I wrap up those parts inside Futures, which capture (almost all) exceptions automatically. Of course, once you've lifted your error handling to the type system, you can do things like swap out the side-effecting 'container' type (like Future) for a non-side-effecting type like (like State) for testing purposes. Rough draft of the idea [here](https://github.com/yawaramin/fake-io).
Try is only for Exception interop. Use cats Xor or scalaz \\/ instead. There are other right-biased Either library types out there too (I think Scalactic has one?)
I will be reading 2 tables and joining them. One of them has 20 million rows and second one has 2 billion rows. I don't need all the data. I will be filtering the data and taking the stuff which I need.
I will be reading 2 tables and joining them. One of them has 20 million rows and second one has 2 billion rows. I don't need all the data. I will be filtering the data and taking the stuff which I need. 
You can use Phantom. Works pretty well. You can set up a stream and do processing as you're streaming.
Please see this page in the doc: http://japgolly.github.io/scalacss/book/ext/scalatags.html It seems you're missing step 4.
Something has gone wrong with your artifact publishing, all the modules that are meant to have a hyphen in its name ("ext-react", "ext-scalatags", etc) have been published without that hyphen in their names: http://search.maven.org/#search%7Cga%7C1%7Cscalacss
Check the other scalacss thread: The artifact names for 0.5.0 are missing the dashes. Workaround is to use `"com.github.japgolly.scalacss" %%% "extscalatags" % "0.5.0"`
yep, that's fixed now, thanks!
Thanks, works now, but it's a bit nasty... trying to clean it up :) import css.TestCss import org.scalajs.dom import org.scalajs.dom.raw.HTMLStyleElement import scala.scalajs.js import scalacss.Defaults._ import scalacss.ScalatagsCss._ import scalatags.JsDom.all._ object Index extends js.JSApp { def main(): Unit = { val doc = dom.document val body = doc.body TestCss.render[scalatags.JsDom.TypedTag[HTMLStyleElement]] // TODO why you no work? val b = div(cls := TestCss.t.htmlClass, TestCss.render[scalatags.JsDom.TypedTag[HTMLStyleElement]], "I am a button!" ) body.appendChild(b.render) } Looks like I need to add `TestCss.render[scalatags.JsDom.TypedTag[HTMLStyleElement]],` to each and every element? If so, that's really nasty... of course I can do it like this: `val x = TestCss.render[scalatags.JsDom.TypedTag[HTMLStyleElement]]` val b = div(cls := TestCss.t.htmlClass, x, "I am a button!" ) body.appendChild(b.render) but if I remove that "x" in the div definition it does not get "attached" :(
For the // TODO why you no work? case, I'm pretty sure you're just rendering the style-tag into nothingness: there is no receptacle for it. Having not worked with the library myself, try something like this and see if it works val myStyles = TestCss.render[scalatags.JsDom.TypedTag[HTMLStyleElement]] doc.head.appendChild(myStyles) 
Have you looked on glassdoor.com?
Hi guys, this is my first project in ScalaJS. Its a game of life in ScalaJS/HTML5 canvas. The features are * Board updates with screen size and works on mobile (tested only on my iphone) * Change board size or max fps on the fly Updating the board is also a fun way to measure cpu performance, so it has JMH benchmarks. The code is pretty terrible in some places for now - probably could be improved by cleaning up the game logic and moving css to ScalaCSS. Any feedback is welcome!
you talking about the dublin office?
SBT / Maven for Scala are a disaster area and a disgrace. Too bad about that, I guess; there doesn't seem to be enough impetus to replace and/or fix them. In order to get anything done, I have resorting to working in the Scala or Spark repl and/or compiling stuff with scalac. I think I might have even created a makefile for one project. Laugh if you want, but make is an improvement over many of its successors.
Maybe not the exact answer you're looking for, but if you're going this route in the first place you might want to consider scalatex: http://www.lihaoyi.com/Scalatex/ The only issue I see is that there is no straightforward way to pass in arguments to scalatex templates like with twirl.
Based on my last experiences with using Eclipse on a daily basis (about 2 years ago) , it was a bit finicky with Maven. I do like Scala, but it is not exactly fun to program with. Oddly enough I've been enjoying ES6 and Elixer more lately on personal projects. Swift is also pretty awesome, and Kotlin looks promising.
Can you enumerate what's so good about SBT compared to others, or at least state what you miss?
SBT is pretty terrible. I will admit that it's a victim of its own time, when library authors that they should create a DSL for every library they wrote. Which is unequivocally a terrible idea in 99% of cases, because you just add even more cognitive overhead to learning a library and make your code impenetrable. I've been writing scala for two years and I still don't know what all of the different operators in sbt files mean, or what an inputtask is and I've written sbt plugins. The fact that build files are not only scala files was a terrible mistake and that lightbend (or whoever is responsible for sbt) decided to deprecate scala build files, is most definitely, a disgrace. SBT is so bad that someone actually has written an alternative [cbt](https://github.com/cvogt/cbt), which has been gaining a decent amount of traction. I expect it to eventually replace sbt, but it will take several years. You're right that sbt will build your files for you. But let's be realistic, that isn't that hard sbt is not scalac or ivy. The first version of cbt which was &lt; 100 LOC could build your projects too. SBT syntax is such a nightmare and there has been 0 attempt to fix it, indeed they've only removed the way that was easier to deal with. So yeah, I'd say it's a disgrace. My final piece. SBT used to stand for simple build tool, this was ridiculed so much that the name was changed to scala build tool.
A few suggestions: 1. [Give Eclipse more memory](https://wiki.eclipse.org/FAQ_How_do_I_increase_the_heap_size_available_to_Eclipse%3F). For some reason, by default, it seems to be configured a little stingily. 2. Whatever you do, pick _one_ of sbt or Maven. I _strongly_ recommend making your peace with sbt, but if you must use Maven, then yes, you'll need [m2eclipse-scala](http://scala-ide.org/docs/tutorials/m2eclipse/) as well as the Scala IDE. 3. It sounds like you may be overspecifying your dependencies. Normally, you let sbt or Maven transitively download dependencies of a (relatively) small number of your project's dependencies. You may also want to check out [Activator](https://www.lightbend.com/activator/download) and its project templates, or, if you use Maven, look for Maven Scala project archetypes. 4. As others have suggested, don't hesitate to post your project files, source, etc. here and ask questions. 5. That reminds me: you can simplify doing 4) by taking advantage of [scastie](https://github.com/OlegYch/scastie), a web based Scala compile-and-run environment that even lets you put your sbt config in a comment and uses it. Very neat! Hope this helps!
Why is considered okay that tony morris was censored out of the scala community? Seems like there should be global outrage that someone's free speech was attacked.
9/10 when I go to practice my Scala I end up just configuring my IDE or spark, or Jupyter, then 3 hours go by, I give up and next thing you know the weekend is over and I just wasted it.
SBT may be slow and cumbersome, but it still beats any other build system out there. I've used most of them, from BSD make to leiningen to gulp to msbuild to ant. Nothing comes close in versatility. The only system I find more pleasurable to work with is Cargo in Rust and sometimes Leiningen in Clojure.
Bazel (AKA Blaze at Google) is notably absent. And it basically runs circles around all other build systems as far as I'm concerned.
This reminds me good times, keep going :)
Hi @stonerbobo, thanks for your kind words. Yes, you can create observable streams from anything, including event listeners. I hope to add a tutorial in the documentation, but just initialize a `ConcurrentSubject.publish` or a `Pipe.publish.multicast` (same thing, Pipe is a factory of subjects) and then you can push events on one side in an imperative way, then subscribe to the source for listening and reacting to events. Use `OverflowStrategy.Unbounded` and in case you're talking about mouse events or another source that's noisy, you might want to do throttling, like by means of `sample` or `debounce`.
I am quite sure you should start it with a @, but I guess you tried that? Depending on the return value of h3, you may have to wrap it like this @Html( h3("hello" ) ); Disclaimer: never used scalatags
Your example does _not_ compile: &gt; error: type arguments [String] do not conform to class Node's type parameter bounds [TypeOne &lt;: Node[TypeOne]] So yes, your assumption is correct, the type constructor parameter `TypeOne` must be a sub-type of `Node`. `type X[Y &lt;: X[Y]]` is called an f-bounded quantification. See also: https://tpolecat.github.io/2015/04/29/f-bounds.html ; and https://en.wikipedia.org/wiki/Bounded_quantification#F-bounded_quantification
Couple of suggestions based on my own experience: * give IntelliJ IDEA a serious look, I find the Scala support to be more mature and I consider IDEA a better IDEA overall, but ymmv of course. You can just install IDEA through brew. * if you run builds from the command line, leave Sbt running, it will dramatically speed up your build times * if dependency resolution is slow (and it likely is) try replacing the Sbt default resolver with [Coursier](https://github.com/alexarchambault/coursier) * finding library versions should be easy, they just need to match the scala binary version (eg. 2.11 being the latest) Sbt will fetch these for you by default if you set it up correctly. Maven, not so much. Mixing libraries from different major releases will generally not work. Any library that still doesn't have a build for Scala 2.11 can be considered dead as that release been out for quite a while now. * Libraries that excessively use Scala's freedom to define whatever as method names are ones I tend to avoid (can't think of any major ones that do this though). I also consider the fold operators to be mistakes (/: and :\ iirc) and will remove them in every project where I have the power to do so. Sbt does have its issues, but none that other build tools don't have, things I ran into: * using a proxy repository is extremely painful, for a feature this important to professional development its kinda shocking (but the same goes for Leiningen, it's not exactly straightforward in Gradle either and arguably there be dragons there in Maven as well) * the Sbt codebase doesn't appear very well documented, there's a few issues I have with it but diving into the code to fix them is just too daunting a task so I resigned myself to implementing workarounds in the client code * documentation can be confusing and scattered (eg. some information is not where you would expect it to be), then again I haven't done anything to update it so can't really complain too much I guess ;)
@predef has a good answer, but if you're wondering about usefulness, well it's usually used to inject the Self type in the super-type you're inheriting from. Take this example: trait StreamLike[+A, Self[+T] &lt;: StreamLike[T,Self]] { self: Self[A] =&gt; def flatMap[B](a =&gt; Self[B]): Self[B] } class MyStream[+A] extends StreamLike[A,MyStream] { def flatMap[B](a =&gt; MyStream[B]): MyStream[B] = ??? } Without this facility, there would be no way to define that `flatMap` in children with this.type - the return type would work, because functions are covariant in their return type, but it wouldn't work for the parameter.
This is beautiful, thanks :)
Where I work, we have a large number of java projects, and a good many of them use a ton of dependencies, like Spring and guava and a zillion others. Many of these dependencies use asm and bytecode manipulation at some point. Now, our dependency tree includes about 3 different versions of asm. Our projects get "stuck" on a version of java (many 1.6) because upgrading that version causes a cascade of updates to these dependencies that has, in several projects, led to a contradictory need at the asm library, and bytecode manipulation that requires jdk 1.6 and jdk1.7. In other words, no can do. Using scala is like using bytecode manipulation. Your code can't just be compatible at the source code level, it has to be compatible at the bytecode level, which is really against the write-once, run-anywhere schtick of simple java. I love scala. But when I go looking for third-party libraries to use to help me in my project, I desperately want them to be written in java, and not scala (and no asm either, thank you!).
To some extent, this sounds like environment setup issues, which ultimately do go away as you figure it out. So, hang in there, get your environment setup right, and then most of this will stay out of your way for a good while.
Might need to wrap in an `Html` so it doesn't escape the tags
I've given up responding to sbt criticism, not because there is no valid sbt criticism (that'd be ridiculous), but because the bad faith:good faith ratio is so high.
I work in a large groovy/java shop. I think akka streams is the first time some of my colleagues have understood the benefits of akka. In some code I rewrote, which before took a couple hundred lines of groovy and several types of actors, the core logic was reduced to 15 lines of code. It had the exact same performance(which was good before) and much less boilerplate.
I was playing with free monad from cats to do some concrete I/O operations, and there are few points that bother me, and I'm not sure if I'm doing something wrong, since I'm new to FP. Code is [there](https://gist.github.com/oleg-py/9130cdfc620aff34fedecde9ab9eb971). First, I have to cast the result using isInstanceOf because Intellij IDEA doesn't understand that result is assignable to type B. Second, I have problems using extension methods from cats like List.traverse with this monad, because type is always getting inferred as Free[FileOperationA, A] instead of IO[A], which doesn't match required shape (and IDEA isn't exactly friends with scalac from Typelevel, which would help) There is also a lot of methods with one symbol suffix, and I have problems seeing the difference between them. E.g. OptionT.liftF vs XorT.liftT, traverse vs traverse_ vs traverse1_, etc.
I follow his Twitter religiously. I love the guy, he's very entertaining, very informative, probably in my Top 3 favorite Scala personalities.
And… you don't happen to be identical with him? ;)
Sounds like a good case for using actors. Then you ping immutable data forward and backward. You keep the user list in one actor and then each client comes and goes with two types of messages. Server could announce changes to registered clients.
it's not really SBT's fault, it's just on github, or documentation for lots of Scala libraries are never updated thus I need to spend hours tracing dependencies. For Go decencies are a little strange but few libraries depend on other libraries. To add a non-standard library you just add it like **"github.com/andrew-d/goscrape"** and the library will be installed. I would say Go as a language would really turn Scala Devs and even hardcore OOP Java types off due to it's lack of classes, lack of FP features etc. But what I do like about Go is: * I can understand the other people's code very quickly, since there are few options in the language thus I don't need to figure out the authors approach. * Go complies super fast, it takes maybe 2 seconds to test and see the results * In my experience Go doesn't seem to have dependency issues common in essentially any language I have used. I just works. * I once googled "How to set up a server in Scala" and what I saw scared me, giant XML config files, multiple libraries. But for go it's just built in. * Go is also super easy to deploy and uses up barely any memory. But there are multiple downsides to go, mainly being new so there is no cool tools like Spark. The lack of FP features makes doing things like transforming clunky feeling. I have been using Go for almost 2 months, and it took me 3 days to learn. Maybe one day someone will build a GoScalaFP and then I will be happy. 
Thanks for the suggestion. I tried writing the program with akka actors but could not figure it out. Is actors the only way?
"I'm so correct that I **refuse** to speak with you any furhter." Ok.
Actually using a @volatile var is probably the best way. even immutable List's are sometimes leading to race conditions: https://github.com/scala/scala/commit/a52882333e0d690304d0c49a89a0725d0934f43a I already ran into those and wondered.
&gt; Even with F-bounded types there are holes where you can make an ill-defined one. Do you have an example for that?
Hm, I disagree that this an "ill-defined" type. Perhaps it's not what the user wants, but there is no unsoundness from the type-system perspective, as far as I can see.
How is Task's feature parity with Scalaz Task? Is it a basically a drop in replacement? 
&gt; Maybe one day someone will build a GoScalaFP and then I will be happy. [Oden](https://oden-lang.org/), in other words. :-)
Ah, lists and mutation. That brings back memories of https://github.com/scala/scala/pull/5316... I'm known not to be a fan of actors but this really looks like a good use case. The best way to handle shared mutable data is not to have any. Let one actor manage the mutable state and only pass immutable data to other parts of the program.
&gt; I once googled "How to set up a server in Scala" and what I saw scared me, giant XML config files, multiple libraries. It depends a lot on what you mean by "server." If you just want to run an HTTP(S) server hosting some JSON REST API, there are several good, simple, XML-free frameworks for that. I'd have a look at [this ScalaSyd 2015 example](https://bitbucket.org/da_terry/scalasyd-doobie-http4s) using [http4s](http://http4s.org) for the HTTP stuff, [Doobie](https://tpolecat.github.io/doobie-0.3.0/00-index.html) for the database stuff, and [Argonaut](http://argonaut.io) for the JSON stuff. You may also want to check out [Unfiltered](http://unfiltered.databinder.net/Unfiltered.html) for HTTP, which I think has fewer dependencies than http4s does. Hope this helps!
18 pull requests the last week is dead? It's very active, and I'm using it. 
Works for me with OS X 10.10.3, IntelliJ 15.0.6 and iTerm2 2.1.1, maybe there was a regression in one of those?
Tony is on IRC and the scalaz mailing list and some Gitter channels and anywhere he wants to be. He's easy to find, I just don't think he's interested in Scala programming anymore.
About Go: So when you just add a Github repo to your build.. how do you make your build reproducible? You'll be relying on a specific version, I don't see how you ensure that with this approach. And how do you manage transitive dependencies? About sbt: Why would you spend hours "tracing" dependencies? Dependency management is there to free you from that. Each external library will clearly state it's dependencies (usually in its "pom" file), and the dependency manager will get them for you, and then recursively all the dependencies for each of them and so on. Maybe you could give an example for a build or a library that's causing this pain. I get a feeling you might be managing your Scala dependencies in some rather peculiar way, and thus making your life much more difficult than it has to be. "How to set up a server in Scala" - on MacOS: brew install typesafe-activator activator new play-scala play-scala Done (... ok.. after sbt downloaded what looks like the whole internet. But then, done!). 
Does anyone have a link to up-to-date release roadmap for scala 2.12? The only ones I've seen are hopelessly out of date and past the supposed release date already.
I really don't see why they can't even be monthly, in my eyes all it does is bury the conversation faster. Having them less often, as they are stickied, means they will each contain more content, and thus more eyes on each thread right?
[removed]
yep, too bad no scala release can make you less shitty tho
Why are you here?
Bintray is blocked on my office proxy server. I'd like to use scala and sbt for a poc project but I cannot get it on the whitelist yet. The maven central repository is accessible as well as sonatype oss. Are there any repositories which mirror the bintray one that I can try out? EDIT: I have looked a bit into using gradle and it seems to work so far, it can fetch dependencies using its scala plugin from maven central. Would have liked to use sbt but this will do for now.
Regarding your first two questions, yes: for `Food[+A]`, `Food[Animal]` is a subtype of `Food[Animal]`. Contravariance is denoted by `-`, so `Food[-A]` would mean that `Food[Animal]` is a subtype of `Food[Any]` (also including the declared type). Variance is annotated at the place of declaration: You don't declare a specific instance of `List` to be covariant; rather, the type `List` itself is declared to be covariant. This means that for `trait Foo; trait Bar extends Foo`, a `List(new Bar{})` is a subtype of `List[Foo]`
`product` takes two `Parser`s and uses them to parse their respective contents, yielding a "product," in this case a pair, `(a,b)`. The `ParserOps` define a few convenience "operators" (Scala doesn't have operators; it just has methods, but since you can use them infix style they look like operators). Which "side" the `*` is on determines which "side" of the `product` you get. So `*|` takes `._1` from the pair, `|*` takes `._2` from the pair, and `**` just returns the pair. Hope this helps!
Trying to learn about the principals of functional programming is not difficult, it is just like anything at a beginner level, the foundations need to be built up to you understand how things fit together and are built on top of each other. An example -- How Functor leads to Applicative, which leads to monad, and the relationship of the three. Scala adds cognitive overhead to trying to learn about these simply because it is multi paradigm and built of the JVM. Typeclasses arneed an understanding of Traits and implicits for things that are more straight forward /transparent in a language like Haskell. These libraries are cryptic in that they generally require a bit of an understanding of functional programming and try to implement features found in other languages. They are not the best didactic resources, although there are some gems. Functional Programming in Scala (the manning one with a red cover) is an extremely good book by contributors to Scalaz. Also, in keeping with a rich history in haskell / category theory many operators are representations of their category symbols (&lt;*&gt; in haskell |@| in Scalaz). How does a beginner even google these? How would I say |@| or ~&gt;? Once you know a bit about functional programming cats and scalaz are the tools that let you implement well defined design patterns (ex. monad) without needing to re implement all the machinery. In summary, various layers of cognitive burden can at times obfuscate the underlying functional design patterns. To add to this, brogrammers called fp hard because it was in fashion to called functional programing difficult in 2012/2013 when Scalaz came out. Learn you a Haskell also came out and it became 'the language' to say you were learning. Also various people in the FP scene / drama in scalaZ resulted in an underwhelming amount of documentation and among various other reasons, the creation of cats.
Using Scalaz and Cats (properly) represent the *purely functional programming paradigm*. It has a great cognitive load for those who are coming from other paradigms, particularly those trained to think *imperatively*. And since that population is quite large (mostly coming from Java), its difficulty makes it seem a prevalent sentiment.
www.scala-lang.org/news/2.12.0-M4 This one is for 2.12.0-M4 (from April), but it's described as feature-complete
From my experience, understanding libraries like Scalaz or Cats isn't hard at all and if you're into reading of source code, well some of that source code is quite beautiful. You just have to get started and the cool thing is, you don't have to understand everything at once, you just have to find some bits and pieces that'll make your life easier and your understanding develops from there. I was one of the people that bad-mouthed Scalaz back in the day, not entirely without merit, but thinking back I was doing so mostly out of ignorance. The real problem of such libraries is the lack of documentation. Unfortunately we copied the good along with the bad of Haskell's libraries :-P
&gt; Also, in keeping with a rich history in haskell / category theory many operators are representations of their category symbols Ah, okay, I guess here is where the disconnect is for me. I don't have a degree in math, far from it, but I came into programming knowing about, for example, the λ calculus and miscellaneous relata just as a consequence of a liberal arts curriculum. I was the TA for a few (large, 50 person+) logic courses while in undergrad, and the diversity of majors that passed through maybe skews my perspective a bit in terms of assuming some exposure to related concepts. Of course, I'm not saying that a few logic courses are going to make you good at FP; however, I feel like exposure to the various domains of knowledge that are connected to the more theoretical aspects of comp sci and/or mathematics, especially those that teach formal grammars, would make FP libraries less intimidating. I can see, however, that if one has had no exposure to symbolically-heavy languages in any capacity, then trying to understand code that's full of (λ, |@|, \ /, |=, ~&gt;)'s might be confusing, not necessarily because they represent hard concepts, but rather simply because it's not obvious what various symbols represent. Kind of like a Russian-speaker showing me, "У Мэри был ягнёночек" (Mary had a little lamb). 
&gt; I think people say it as a gesture of understanding/solidarity/self-forgiveness ("I don't understand these libraries and it's ok if you don't either") but it's self-defeating because it makes them seem more intimidating, which becomes reinforced through repetition. I never thought about it like that. Putting it that way reminds me of that anecdote about George Dantzig. While a grad student, he came into class late, and assumed that the two problems written on the board, which were actually two famously unsolved problems in statistics, were just homework assignments. Dantzig solved them a few days later; however, I've always wondered what would have happened if he'd been on-time to class. Coming at a problem with a certain mindset that something is easy/solvable makes the actual problem itself easier, as opposed to coming at something from the already self-defeating perspective of "this is hard," even if it's not.
This stuff is awesome! Thanks, for me understanding the inner workings is essential to being able to design and read code. 
Here is your code partly rewritten using a library I just made to provide an easier way to create free monad. https://gist.github.com/Thangiee/36190c39b2b6553cd87e4b418246d6c6 Best of all, it works great with Intellij (no error marks). See the repo for more details. https://github.com/Thangiee/Freasy-Monad For your second problem, try using traverseU/sequenceU, it may help with the type inference.
&gt; well some of that source code is quite beautiful This is one of the things that drew me to FP initially. I'm big on code that looks/is beautiful and elegant. It gives me pleasure similar to when writing a long, terrible proof, and then finding a much shorter solution and having a *proofgasm*. &gt; The real problem of such libraries is the lack of documentation. "Observable ... to be continued". Haha, just kidding, the Monix doc's are really good. They're pretty engaging, too, which I can't say for a a lot of doc's I've read. 
Always good to see more deep learning projects in Scala. Having to always go to Python is just uncomfortable since I'm so used to static typing. What are you plans in terms of implementation? Will it be modeled like Keras' functional API insofar as it will be easy to define mutli-input/multi-output models, shared layers, lambda layers, etc? 
Very good point. We should empasise more that scalaz implements purely functional data structures and design patterns. That should make it more approachable.
There used to be more merit to this point (and there still is some), but things are a lot better lately thanks to: * [Learning scalaz](http://eed3si9n.com/learning-scalaz/) * [Herding Cats](http://eed3si9n.com/herding-cats/) both from the incomparable [Eugene Yokota](http://eed3si9n.com/).
At least I have an opinion, unlike Scala. 
That's definitely interesting, but a feature that I'd like to see is the ability to compose interpreters. [Freek](http://perevillega.com/freek-and-free-monads) does it rather elegantly. 
Is this specific to the REPL or can you not paste _any_ text from IntelliJ into _any_ iTerm2 app, e.g. into a vim buffer? Also, what happens when you try to paste from IntelliJ into Terminal.app?
shameless plug if you like scalaz - https://github.com/mblink/composefree
I thought it might be useful for others
If you suffer a breach, you're going to be doing a *lot* more than one click, so this headline makes me suspect some kind of scam.
I ran the scala REPL in the normal terminal app of mac, and I was able to copy paste from IntelliJ to the terminal. but no luck when the scala REPL is run inside of iterm.
&gt; I don't how this is the case when implementing his interpreter trait is more boilerplate than just implementing a natural transformation. I disagree that the [interpreter trait](https://cloud.githubusercontent.com/assets/4734933/18316104/f9025b4a-74de-11e6-8b4f-8414df117cea.png) is more boilerplate than the [natural transformation](https://cloud.githubusercontent.com/assets/4734933/18316097/f5de4ff0-74de-11e6-8542-00daa28c04c7.png). Using the interpreter trait gets the added benefit of its methods signature being able to be generated by the IDE. And imo, having separated methods is cleaner than stuffing everything into a pattern match. &gt; I get that the trade off here is not having to define the ADT and members of your DSL, but it doesn't seem worth the boilerplate and restrictions on composition when defining your interpreter. I'm no expert on Free Monad, can you elaborate on those restrictions? Under the hood, it's still a pattern matching with the addition of delegating to abstract methods.
It's not bad. You can write: protected class MatchPathVar[A](cast: String =&gt; Option[A]) { def unapply(str: String): Option[A] = cast(str) } object SSNPathMatcher extends MatchPathVar(a =&gt; SSN(a).toOption) So you can write: def personService(personRepo: PersonRepository) = HttpService { case GET -&gt; Root / "person" / SSNPathMatcher(ssn) =&gt; personRepo.get(validSSN) flatMap { ... } } }
I say this as someone who only has a baby's understanding of Category Theory, but you may want to start here: https://bartoszmilewski.com/2014/10/28/category-theory-for-programmers-the-preface/ In terms of 'when to use different things', I'd take a look at good repos. I have a simple 'pure functional program' that i've passed around a bit: https://github.com/vmarquez/purebomberman http://tpolecat.github.io/ is another great resource. FYI, Scalaz is going to have more of the category theoretic constructs than Cats, so if you care about that sort of thing you may want to start there. http://eed3si9n.com/learning-scalaz/
I'm not sure that would help. What would help is to show real life problems solved with it, where it actually makes it easier. For example, i'm not going to use a library or a framework just because it implements a design pattern, because i don't do buzzword programming. I need a real, tangible value added.
I've seen the MatchPathVar class defined in the sources under another name for IntVal and LongVal, you should be able to refuse that. 
Yeah, I just put it here to show how it works. Also, hi from gitter :P
Does anyone have any experiences of Crypteron, highly curious in how it actually works?
As far as I remember it is pretty close to `sbt clean compile test` using the buildin sbt in teamcity
While this makes perfect sense, the problem is that it's easy to state the value-add of scalaz or Cats in a single sentence: it supports doing referentially-transparent programming in Scala. Now would you use scalaz or Cats? My guess is: no. You asked for an example of "real life problems solved with it, where it actually makes it easier." Let me (again, serious broken record time) link to [this ScalaSyd 2015 http4s/Doobie/Argonaut example](https://bitbucket.org/da_terry/scalasyd-doobie-http4s). Obviously, it's real-world: it's a bread-and-butter JSON REST microservice talking to a SQL database. As for "easier," I'll make two observations: 1. It's difficult to imagine code much easier to read than this. 2. It's difficult to imagine much simpler code, with as few failure modes, all of which are handled by the code, than this. In other words, you could almost certainly write code as simple as this with Ruby on Rails, or a combination of Pyramid and SQLAlchemy in Python. What you wouldn't get is anything remotely resembling the same level of assurance of point 2 (believe me; I did a Python web app professionally for two and a half years). Now, you may say, again essentially correctly, "Well, OK, but the reality is that any modern web and database framework lets you get within ε once it's mature and battle-tested." The possibly surprising thing about http4s and Doobie is that they give you this assurance _without_ being mature and battle-tested (sorry, Ross Baker and Rob Norris, but my guess is they'd be the first to agree). There are essentially two reasons for this: 1. http4s and Doobie are "purely functional." This immediately severely limits the scope of possible errors. Taking good advantage of the type system in Scala further narrows that scope. 2. They both rest on scalaz, which is typed and purely functional, and _is_ mature and battle-tested. So it's not a question of being "buzzword-compliant" at all. Rather, it hinges on the ability to make very strong claims about any given function, at any level of the system, with extremely high confidence, and therefore on the ability to compose those functions into the kind of higher-level behavior you expect from a microservice framework, a database access framework, a JSON parsing-and-generating framework...
The one-click response allows you to instantly isolate the key management systems from the data. So if a malicious user gets access to your data they won't be able to fetch the keys needed to decrypt it even if they're in your app code itself. No scam. Promise :-)
You can read a customer success story here: https://www.crypteron.com/case-study And there's sample code and a 3-minute demo video here: https://www.crypteron.com/community-edition/#how-it-works Hope that helps! Happy to answer any questions you have! 
If you are going to talk about ADTs, show some pattern matching examples.
Start simple. Show code examples, and bring up IntelliJ IDEA and write code examples with them. There's a feature in IDEA that autoconverts code from Java to Scala (Ctrl-Shift-G?) that is very helpful for connecting concepts. I think the most powerful introduction is Scala's collections API, and how it works with functions. Start with some Java code working with lists and maps, and then start pulling bits out. Start with a Java DTO and then show case classes. Don't mention the M-word ("monad") -- show them .map, flatten and flatMap and then show how you can nest them. Option will do fine on its own, and then you can introduce pattern matching as a more powerful switch. I would not go into for-comprehensions as that's going to be a bit much. Show them practical things that they do in Java every day and then show how Scala can do it better.
I was thinking on using [scalakata](http://scalakata.com/) for the whole workshop. It does not require any previous instalation allowing even the people that are there "because" to probably get involved and try some scala lines. For a more complex example i might show in intelliJ but not sure if necessary. I was thinking on something along those lines, yeah... keep it up with java style at first, show some classes java style and then move to case classes, play with pattern matching, options, use map, flatMap etc.
This is how it would work: `@Html(h3("I am so awesome").toString())` or `@Html(h3("I am so awesome").render())` Will have to see what I use though. That syntax looks awful I think. ScalaTex would be a great alternative to Twirl if it could take parameters easily 
I feel like Akka should be on this list. 
Only Play and ScalaJs (and maybe JSON) on the list are related to a webapp.
Finagle / whole Twitter stack seems very very very decent/good. Any experiences?
I would also go with the start simple approach. But I found "simple" to be highly dependent on the listeners and had groups that I underchallenged and some that I overchallenged. It might be a good idea to prepare at least a few extra pieces that are either easier or harder then the rest and just go with the flow, depending on how the audience acts. Also, it might be a good idea to show IntelliJ as a good scala IDE, so that they know that there is something out there that they can use, maybe also mention ensime for emacs. Also mention sbt and maybe offer them a link to a basic template to get them up and running. You don't have to actually use in the workshop, but it's nice for all those that want to dig deeper as a quick start. And otherwise, examples, examples, examples. I tend to like the functional approach and often show stuff like monoid for maps (what it does and not how it's implemented, unless the audience wants to know), simple example Validation code for some REST API, equality from cats/scalaz etc. nothing too fancy though. Mentioning scalafmt might also be nice, especially for those that work in teams. Otherwise, you already gave a few good examples yourself, but would probably leave out ad-hoc polymorphism and promises, parametric poly is okay though. And mention exhaustivity checking regarding sealed ADTs. Oh, and if there are Java programmers among the crowd prepare to answer interop questions.
&gt; Most of my friends got interested in scala after i explained I think you're perfectly fit to make a great presentation / workshop. Just tell them what you told your friends. Don't care what reddit says you should present, tell them about your personal view of things. Why do *you* like Scala? I'd much rather hear a talk where the speaker shares what they're passionate about, and what brought them to Scala personally, than one where they present what people on the internet said was the essence of Scala. 
Why do you need a DI framework with Scala? 
Take a look at macwire. It mostly just simplifies passing around your dependencies with a simple macro.
Just write your enum in Java. Better than `scala.Enumeration` and you get exhaustiveness checking for matches.
Same reason people use one in Java. Sure, you can always pass in your dependencies as constructor arguments but we can make the code less verbose using a DI framework (especially true if you have tests and you want to instantiate things slightly differently in tests).
I like the idea behind it but I'm less of a fan of their entire ecosystem (own futures, try ,etc.). Maybe try Remotely, It's similar but I much prefer the Scalaz-stream integration. http://oncue.github.io/remotely/
Thanks, I'd probably use it for personal projects with htt4p and doobie... but just that finagle comes with whole stack of things/solutions is reason why it's preffered by team I'm in, which I guess is fair game :) I'd also be happier if http4s was compiled also with cats+fs2 dependency doobie-style. Nothing against scalaz (I was using it on all my personal projects), but using Finagle/Finch at work, which naturally comes with Cats... I don't want to mentally swap between frameworks all the time :D (although it's less difficult than it sounds)
Yes, accepted best practice is to use Java enums and avoid the disaster that is Scala Enumeration. Your instructor should know better. If they insist on Scala Enums then I question their competence because you will have unlearning to do after the course.
The cake pattern is controversial. [Here](https://www.reddit.com/r/scala/comments/2xpozl/cake_pattern_bakery_of_doom_and_alternatives_what/?st=isv8ur1u&amp;sh=5e0a8165) is a previous discussion about it.
Someone is actually using my plugin!? (scala-commas)
I'm not sure you understand what censorship means. Imagine you have a guy shitting in people's front yard because he disagrees with the color of the flowers the owner planted. Nobody is telling him he can't do that on his property, they just want him to stay out of theirs if he can't behave. Also keep in mind that this "free speech" thing is pretty US-centric, and most other places have a much saner version of it. In general, my front yard rules are that I don't want him or anyone who enables him on my property. Your rules might vary and that's fine.
Quit. Because why the heck do you have have an office proxy as a developer...
Authentication How are you doing this? I have a server and several predefined clients which will communicate with server remotely. How can I make sure the requests are coming from my clients. Maybe using private / public keys? Sorry if this is not the right place to ask. My server and clients are in Scala :)
I would use a common trait and standard sub-classing trait CustomerLike { def name: String def age: Int } case class Customer(name: String, age: Int, imageId: ImageId) extends CustomerLike case class RichCustomer(name: String, age: Int, image: Image) extends CustomerLike Or you move the optional parts into another type sealed trait ImageState case class ImageId() extends ImageState case class Image() extends ImageState case class Customer(name: String, age: Int, image: ImageState) 
Interesting, TIL. I guess I have some more reading to do 
A couple of years ago, I gave a presentation on Scala to a room full of Java developers. Basically, it consisted of two parts. The first part was about the basics - classes, objects, functions etc. The second part was about FP and touched some topics you mentioned, including Options, Futures, higher order functions etc. The talk didn't include any live coding, though. The slides are uploaded to SpeakerDeck, so you can check them out if you need some inspiration: https://speakerdeck.com/denisftw/demystifying-functional-programming-with-scala
Whereas I would consider it the _first_ option, since all the other ones are _excruciating_. :-)
Hey paultypes! It would be really nice if you could elaborate in what ways the `Customer[A](..., image: A)` solution of tpolecat has drawbacks that the shapeless solution doesn't.
Thank you very much!! The presentation looks really great. I am completely inclined to do live coding because i prefer to just keep showing examples as i remind them (according to a certain order i decide previously) and i would very much like to show them some of the REPL feedback. i.e. when you run a future without a execution context , etc.
I wrote my reply before seeing Rob's response. :-) I'll have to think about it a bit more, but off the cuff it'd probably be my second choice. I want to ruminate a bit about possible issues of variance, and to see if I can qualify my general distaste for introducing a type variable to account for what is, after all, just one element of a `Product` type. In other words, I guess, to me, it feels like an unfortunate workaround for the _inability_ to easily slice-and-dice `Product` types in Scala. Shapeless' `LabelledGeneric` facility provides exactly that kind of ability to easily decompose/recompose `Product` (and `Coproduct`, which it provides, because Scala doesn't) types without being essentially "stuck" with a single composition of elements, if that makes any sense.
Well one you can know about at compile time. Customer[ImageId] is known to have the ImageId field whereas for Customer (no image type) the Image field could be any of those. It depends how you are using the class, if it is unknown image type then don't use generics for it. It's just a question between Compile time vs Runtime understanding of your case class
Thanks, it looks interesting. Is trait supposed to be inheritable, or it should be sealed? sequenceU helped with scalac, but again IDEA's highlighter is breaking the fun. Thanks for the pointer though.
It doesn't solve the problem of variations in testing mode creation. Implicit parameters require implicit arguments, which means specializing the creation scope in greater detail than most people are interested in doing. Also, taking the time to define that construction scope doesn't carry it's own weight as an abstraction mechanism.
&gt; Does anyone know why this is occurring, and how can I resolve it? Type aware highlighting in intellij is broken, just turn it off.
Yeah once your types get even a little bit fancy there is no IDE or editor plugin that can handle it. Most people I know use Sublime/Atom/vi/emacs with syntax highlighting and that's about it (and sbt in a terminal window). I am optimistic that some combination of TASTY and scala.meta will improve the tooling landscape.
I have some questions about Cats: 1. How do you redefine semigroup |+| to use another associative operator. For example multiplication or max(a,b) 2. Is there a operator to do shorthand for comprehensions on options? option1 |@| option2 map ((x:Int,y:Int) =&gt; x + y ) does not seam shorter then writing out a for comprehension. 3. Are there any examples out there that provide code comparison between vanilla Scala and Cats? I haven't found good use cases for it in the code I am writing based on Scala Exercises. Normally I deal with 1 or 2 options at a time not lists of them, don't seem to need validation and switching from Either to Xor doesn't provide too many advantages. 4. This is a function I made to read a Map[A,B] from a two dimensional ( N x 2) JSON array. Can this somehow be written nicer using Cats? : def readsMap[A: Format, B: Format](json: JsValue) = json match { case JsArray(outer) =&gt; val seq = for { inner &lt;- outer tup = for { cord &lt;- inner(0).validate[A] texture &lt;- inner(1).validate[B] } yield cord -&gt; texture } yield tup seq.forall(_.isSuccess) match { case true =&gt; JsSuccess(seq.collect { case JsSuccess(value, _) =&gt; value }.toMap) case false =&gt; JsError(seq.collect { case JsError(errors) =&gt; errors }.flatten) } case _ =&gt; JsError("data needs to be [[_,_], ...]") } This piece of code looks like it could use some syntax sugar from a functional library, but I have no clue how to implement it. Is there a way to write these transformations with Cats (in a neater way) ? (JsResult[A], JsResult[B]) =&gt; JsResult[(A,B)] //and Seq[JsResult[(A,B)]] =&gt; JsResult[Seq[(A,B)]] 
I'm not too familiar with Cats directly, but from the scaladoc it looks like all you need for (1) is an implicit `Semigroup[T]` instance. implicit object MultiplicativeIntegerSemigroup extends Semigroup[Int] { override def combine(l: Int, r: Int) = l * r } Of course that can be made generic over for than just integers.
Same. Ctags can help with (3) I don't bother with it. I would use an IDE if there existed one that worked, but there's not so I don't.
honestly, more than anything Scala has really helped me understand programming theory a lot more if that makes sense it also helped me see that Java sucks
To my everlasting surprise, I find myself having switched to [Visual Studio Code](https://code.visualstudio.com/) with [vscode-scala](https://github.com/itryapitsin/vscode-scala)... and _liking it_.
Imho they shouldn't, in terms of "method line count" inner methods should be considered separate methods and not add to the containing methods line count. 
I think rules like "no more than 50 lines in a method" are silly. is a 49 line method better than a 51 line method? Sometime 100+ line methods make sense. Often long methods should be broken into small pieces, but not always, and "50 lines" is an arbitrary threshold. Treat these kind of things as guidelines. Religious adherence to arbitrary rules is unnecessary and can make things worse, not better.
It's not released yet regardless of what people are posting. It's just "release ready" It's still pending announcements and all the little details that go into a release. http://www.scala-lang.org/download/all.html
Same thing that's so great about hiding the fact that your program is doing too much by putting parts of it in a method, right? :-) The inner methods are like non-inner methods, if there were a way to make them private to the enclosing method.
Thanks, will check :)
How did you get/make those performance metrics at the end? :)
I am happy user of doobie :-) + postgres... are there any examples of usage? I will check them out! Now Im looking forward to them...
Thanks!
Thanks for the responses /u/tpolecat &amp; /u/beezeee. I have bought into strongly typed pure FP to a large extent (to the extent that I have managed to internalise "The Red Book" at least), but I often also find myself having to those tools to corral academic java codebases into something vaguely resembling production readiness. In that world, let me tell you, debugging is a must &gt;.&lt; I do take the point that in my own greenfield development I am probably over valuing debuggers and semi-automated refactors though. I don't find myself reaching for them often. Perhaps they are more of a mental crutch :) 
I really need to start using Ammonite REPL. I suspect its various niceties would encourage me to rely on exploratory work in the REPL far more than I already do. I've never really gone through the process of getting ctags to be honest. Perhaps I should give it a try. I did try Ensime - but found it a little janky for my tastes. A cool project though.
Most of the people I've worked with who have had troubles learning Scala have come from a Java background, actually. People with a JavaScript background seem to do better in Scala. May I ask why you're planning to use Scala? 
https://scalameter.github.io/
Answered on StackOverflow.
Your function-that's-a-program is also still a function, and should follow guidelines for that smaller level, rather than the guidelines for the larger level. Otherwise, we're going to be arguing about every line being a function and it should be ok for it to be 80,000 character long so long as we're breaking it up with inner methods and local scopes etc. No, it may be a program in some aspects, but it's also a line of code, and should look to those more restrictive guidelines.
&gt; The reason I bring up Java is only an example of a language that does not allow inner methods. An inner method is a lot like just putting in a comment saying what this portion of the code does, the only real difference being that the local variables are encapsulated and it can be referred to in order to move execution back to that point. That's just one particular usage, the most simple one where you just replace a chunk of code with the method and call it once in the same place. There others, such as restructuring code into independent branches instead of accumulating results before some trailing code, implementing recursive steps of an algorithm more easily using closures, etc. &gt; Perhaps the solution is that a method that requires a lot of inner methods should have those methods moved to another class, as they have a single responsibility of providing whatever functionality is required by that method. What's the advantage in artificially introducing a class when it wouldn't be necessary? &gt; his ends up further encapsulating the methods so their implementations can be more easily modified in the future How is it more encapsulating than inner methods? &gt; without having to worry about closures from the parent method. Or, alternatively, having to write boilerplate code just to copy data around that could be much more easily accessed through a closure.
Scala is great, but I doubt anyone would claim with a straight face that it is easy to learn. It is the hardest language to learn I have ever encountered. You can get started with simple programs very quickly, but as soon as you start dealing with other people's code you will realise that you are not ready yet. You need to read Odersky's Programming in Scala, end to end. Preferably twice. Then Functional programming in scala. Maybe take a couple of Coursera courses. Then you will be ready to call yourself a novice. 
There shouldn't be any issues. They are different languages, and have a different feature set. Other than being on the JVM, there isn't a whole lot of similarities really. Scala is both an OOP and a functional language. If you know any functional and an oop language you should be fine.
You're scaring me bro. I do hope it results in a big enough pay check to justify the effort!
Glad to hear that!
Doesn't creating a companion object for case classes disable the implicit creation of the standard apply/unapply methods? 
Interesting! 
It's definitely up the harder end. For me it was easier than Rust + Haskell, but harder than pretty much everything else I've learnt. Having said that ... when I first used it I was pretty much writing statically typed Ruby, and I was "getting shit done" at a great rate, though I wouldn't have faired well in a team. Growing out of that was the slower part. The contexts of using Scala vary quite wildly.
Yes, imagine the follwing: ``` case class Customer(address:Address, ...)``` ``` case class Address(street:Street, ...)``` ``` case class Street(streetSigns:List[StreetSign], ...)``` ``` case class StreetSign(imageId:ImageId, ...)``` maybe seems a bit overengineered, but for the sake of the argument let's assume it should be modeled like that. Now, what if I sometimes want a `Customer` where the streetSign has only an ImageId and sometimes I want a `RichCustomer` where the imageId has been resolved to the image itself. And, additionally, this should be typesafe at compiletime, thus a trait is not exactly my favourite solution.
Is it possible to fix this with explicit extending `Function1`?
Using unicode makes this much clearer: `e2 ⇒ e1 ≤ e2`. I autoformat my arrows to arrow characters.
Use SSL with client certificates? It's established and mature/well-tested, and it's transport-layer so mostly gets out of your way. Working with java keystores is tedious (there aren't any good native-scala libraries for this I'm aware of yet) but workable.
Known issue with IntelliJ (I filed it as https://youtrack.jetbrains.com/issue/SCL-10168 - though that's now claimed to be fixed?), and the main reason I still prefer Eclipse. It's actually the workaround for SI-2712 that IntelliJ has issue with, so once the fix for that is out and libraries have removed the workaround this should stop being an issue, but in the meantime it's a huge pain.
Oh fair enough, I don't know the details of SBT itself and didn't even think about the possibility of that kind of problem. 
Eclipse's "problems" panel is good enough IME. What I've been doing in paperdoll is as complicated as I've seen anywhere and eclipse hasn't let me down yet.
Mother of lord, had no idea JS did that.
Where is your `.schema` method coming from? I don't see one on `TableQuery` in the documentation you linked. I would stay away from reflections. Generally you want to look at the types/implicits that are required by what you're calling, and "ripple them up". I can't talk about Slick specifically because I don't use it myself, but if you can show the signature for what you're trying to call and the error you're getting then I can try to help.
Thanks for the explanation.
Any one knows if there is an updated roadmap for scala 2.12? The one on the website is from 2014 and annonces it's release for january 2016.
And that would actually override the old server and start the new one?
 kleisli(fa) andThenK fb andThenK fc andThenK map fd
I guess I just don't understand how team city works. Does it run bash scripts? Does it just look at a version control repo and figure out what the project is, based on what plugins you have, then build, test, and deploy it?
I might be missing something, but what's so bad about `.map`ping `Kleisli.ask` over the result of your function? **Update:** Also remember that you can `.map` over a `Function`, so my guess is you can write a very simple function to turn your `D =&gt; E` into a `Kleisli[M[_], D, E]` for any `Monad` `M`, `D`, and `E`.
Knowing Java might even confuse you on certain concepts of methods vs functions.There is absolutely no disadvantage. Scala has two sides, one is object oriented, the other is functional.The functional side is pretty hard as with any functional language. There are several resources to learn. 1) Coursera scala specialization (Its 5 courses now) 2) Twitter scala school - https://twitter.github.io/scala_school/ 3) Books on scala - Scala for the impatient - http://horstmann.com/scala/ - Scala in depth - https://www.manning.com/books/scala-in-depth - Programming in scala - http://www.goodreads.com/book/show/5680904-programming-in-scala Once you are beyond the novice point, there are so many sources to improve.I would advise starting at open source code bases such as Apache Kafka,Spark and then contribute to them. P.S : Shameless plug.I also write scala tutorials whenever I find time/master a concept here -&gt; https://madusudanan.com/tags/#Scala 
Some would say you haven't been poisoned by Java.
The latest development builds of IntelliJ come with the option of using ligatures with Fira Code, see: https://blog.jetbrains.com/idea/2016/09/intellij-idea-2016-3-eap-sf-fira-code-and-debugger-improvements/ Using ligatures is basically using the same feature that makes "fi" look like a single joined-together character; but for meaningful combinations of programming characters. You can see some available ligatures at https://github.com/tonsky/FiraCode
This seems silly. To make use of *any* value, you need to know its provenance. I can't understand why he's singled out booleans. Numbers don't inherently mean anything. Strings don't inherently mean anything. Lists don't inherently mean anything. Nothing inherently means anything. In order to use any value, you must already know what it means. Maybe I'm just not an academic enough computer scientist, but the proposed cures to "boolean blindness" sound much worse than the disease. Maybe I just don't understand the notation. (I think `Z` is integers, `S` is successor, but what is `x'`? It seems to be the predecessor of `x`, although he strenuously objects to a function that actually computes predecessors for some reason)
In Eclipse it's an option for the autoformatter (which you can also set to run automatically on save). I can't speak to IntelliJ.
If you don't use for-yield, I would just use an underscore and it then doesn't look confusing list1 flatMap { e1 =&gt; list2 map { e1 &lt;= _ } }
&gt; For that particular case you should be able to just use option1 |+| option2 - semigroup lifts into apply. If you're asking about a general case could you give more examples? If you do Some(1) |+| None you will get Option (1). |+| treats None as identity. Int this case 0. If you do: for{ int1 &lt;- Some(1) int2 &lt;- None } yield int1 + int2 you will get None. Doing Some(1) |@| None and then mapping over it with ( _ + _ ) will also result in None. --- &gt; Yes, if you make JsResult an Applicative Thanks. I somehow didn't realize Applicative was a typeclass. 
I've been tasked to write non trivial amount of javascript (not scala-js :( )... what are popular libraries for Scala developers that have to write JS? I don't mean frameworks (we have that set up - react, redux), but stuff that would give me useful tools and combinators (such map, traverse etc) one is used to from scala.
Oh yes, Cats has a bad default semigroup instance for `Option`. I'd suggest filing an issue with them - you're not the first to ask about its inconsistency here. 
Sorry for not being clear. I am for thinking about frontend libraries such as immutable-js that are popular among Scala developers that have to do javascript frontend. JS ecosystem is huge, and I am looking for such set of libraries that would be most familiar to me as Scala developer, so I can be productive in JS as soon as possible. So if there are scala developers that had to do javascript - what are good libraries that they became fond of.
In my cases, these methods definetely should not be documented or tested in a standalone method. the unit of documentation and testing is still the outer method. I am refactoring these into inner method just to make the code clean. These names should be enough to the reader unless and until they are really bothered about how I wrote the inner method.
Check out [the docs](http://www.scalatest.org/user_guide/using_matchers#checkingEqualityWithMatchers). For simple value comparisons the difference between `shouldBe` and `should be` is only whether parentheses are required on the right hand side. In general `should be` doesn't require parentheses when it can be appropriately used as infix notation. The `should equal` construct allows you to customize what it means to be equal while `should be` does not and always relies on `==`.
&gt; What do you do if you want to define a data type using case classes and not all possible constructor inputs are valid? Maybe look at [refined](https://github.com/fthomas/refined)? &gt; But how do I get rid of the partiality of Foo? `Foo(b).getOrElse(someB)`?
Ah cool, makes sense now. Makes me wonder if there are any "For Javascript" Scala-JS libraries that compile out to JavaScript with nice JS facing facades / compatibility. It would seem to me that the most familiar libraries would be those written in Scala.
This is a pretty reasonable approach to some concepts, provided you know what all the base concepts are.
Isn't it the same thing though? If the user is expected to understand those methods without reading their bodies then surely that means they should be documented/tested? If the names are meaningful enough then they are probably part of the language of the domain, in which case they're worth having as standalone things.
&gt; What do you do if you want to define a data type using case classes and not all possible constructor inputs are valid? You refine the constructor inputs so that they they are. E.g. if a list needs to be non-empty, you use `NonEmptyList`. If an integer needs to be positive, use a positive-integer type. &gt; Currently, I use require for such cases, but that's not very functional. Often it's the right tradeoff, particularly for cases that should never happen. If a particular program state indicates a programming error, there's nothing you can reasonably do other than fail-fast, and `require` is a perfectly legitimate way to do that. You shouldn't do it for cases that you want to catch though. In that case you should offer a method in the companion object that does checked construction and returns option/validation/whatever. E.g. you might define a nonnegative integer type like: case class NonNeg private (value: Int) object NonNeg { def from(i: Int): Option[NonNeg] = if (i &gt;= 0) Some(new NonNeg(i)) else None } &gt; The thing is, in this case it does not make sense for me to make Bar partial, because I know for theoretical reasons that Foo will never fail in this specific instance, so the algorithm is in fact total. Think about why you believe that `Foo` will never be failure. Try to lift that reasoning into the type system. E.g. if you know that a list is non-empty or an int is non-negative, use types to express that. (This may mean converting `someFunction` into a polymorphic method that e.g. operates on any `F[_]: Functor`, so that you can use it with both `List` and `NonEmptyList`. Or some other way of refactoring `someFunction`). If you can't express your reasoning in the type system then sure, you give up, put a cast (I prefer to use `.asInstanceOf` so that it looks exactly as ugly as it is), and make sure the function is well-tested and carefully reviewed. But usually I find that one can.
"would/could/should of" does not exist. What you're thinking of is "would/could/should've", a contraction of the word and have. Please do not use would of, could of or should of. 
You would be much better served with OptionValues. http://www.scalatest.org/user_guide/other_goodies#optionValues
The question isn't about Scala libraries. It's asking for JS libraries that will make JS development more like Scala. 
This is well organized and easy to understand! Thanks for sharing.
I have yet to see a business where the primary goal of the internally produced code is to have internal staff work with the code, even if that's a necessary means to the desired end. That alone makes it hard for me to accept it as an organizing principle. High priority? Sure. So within reason, like when I gave up using github based sbt deps because it made intellij impossible for people to use, it's worth accomodating. But tell me I can't use HLists or typeclasses because intellij can't handle the implicit resolution? Time to be hitting the ol' dusty trail... This IMO is not far off from the "we don't use functional because it adds ramp time." Both messages sound the same to me at their basest level, "we don't mind writing shitty code as long as it doesn't take extra effort or make anyone uncomfortable." Admittedly an exaggeration but it communicates my point. -- edit for grammar
We're deep enough in a hypothetical that we're probably talking past each other, but fwiw when I say "shitty code" it's not about trends or dogma or craftsmanship, I'm referring to an objective measure of quality based on defect rate. My experience has shown me a _dramatic_ variance in this particular metric between code that leverages advanced language features and code that does not. Of course that's not to say you can't write broken software with advanced scala, it's just harder to get that broken software to compile. To me the choice is between catering to tooling at the cost of higher probability of defects, vs roughing it because the tooling can't keep up with the language, and I can't see how there's a reasonable comparison between the two.
That was great. For some reason I can never intuit what this syntax means: &gt; trait Natural { self =&gt; It would be easier to remember if the motivating example on the Scala tutorial site weren't so [insanely complicated]( http://docs.scala-lang.org/tutorials/tour/explicitly-typed-self-references.html)...
Very nice answer. I looked into the `transfigureTo` source and got headache, good work there! I think I'll stick with the `liftMK` and try `transfigure` at home.
Any word on where/when this training will be offered next?
This is amazing and will mean a lot for newcomers. Being able to be "up and running" in a second means **everything** when trying something for the first time. Make it extremely accessible and fun to play with for the first time, and get people hooked. I would like to see more templates though. Perhaps lihaoyi's original drawing example could be one of the templates? And perhaps something that illustrates the power of ScalaRx + Scalatags for an angular-level magicly updating DOM..? I've played around with that a year ago, and was blown away by how simple it was to achieve what angular does with almost zero code. (I used this https://github.com/rtimush/scalatags-rx ; Would be cool if that behaviour was out of the box from scalatags or scalarx?). I like how easy it is to add libraries
pretty sweet! question, though: shouldn't something like this work: https://scalafiddle.io/sf/6xYtV80/2
disclaimer: it ends in July 2015. But there are more visualizations of Scala projects https://www.youtube.com/results?search_query=gource+visualization+scala (e.g. scala-native)
It's not in a great place at the moment - I lost interest once I realised that technique can't handle effects that don't commute. Paperdoll is my newer effort at this kind of problem, but I think FreeK does something very similar and may well be more mature. 
I'm in the same boat. I'm a huge fan of the basics principles of functional programming such as immutability, delaying side-effects (functional core / imperative shell), ADTs, disjunctions and to some extent the "cats" typeclasses (Monoid, Applicative, Functor, ...). But when you it comes to more complicated "cats" and "transformers" and things like: `type Interpreter[T[_[_], _], F[_], G[_]] = F ~&gt; T[G, ?]`I realize just how deep the rabbit hole really goes. It's like space. I'm comfortable with the size of the sun, but Vy Canis Majoris makes me kinda uncomfortable :p I comfort myself with that I don't have to use the most advanced functional programming constructs out there until I *actually need it™* though. I mean, the huge gains of FP are the basic principles I listed above, right? I don't actually have to use `Interpreter[T[_[_], _], F[_], G[_]] = F ~&gt; T[G, ?]` all day in my production code to be productive, do I?
I've just tried to use it with Safari and Chrome and the box where I think I'm supposed to use to type scala code doesn't allow editing. Am I missing something? Also, what is the process to add new libraries?
Is it Scala**Js**Fiddle rather than scala fiddle? Compiling backend is scala.js and all available libraries are cross-compiled to scala.js. Are there plans for JVM backend and libraries in future?
What did you try so far and why didn't it work? (Not being sarcastic, I genuinely want to compare our experiences.)
I'd say once you can do functional programming with Scala, you're ready for _Advanced Functional Programming with Scala_ :-)
It's essentially the `this` value for traits, no? I.e., you use `this` to refer to a class instance value inside the class, and similarly you use `self` to refer to the eventual instance value that extends the trait.
Newbie here - comparing this approach versus the one recommended by /u/kevin_meredith [here](https://www.reddit.com/r/scala/comments/51wj73/how_to_avoid_duplication_with_slightly_different/d7fte28), doesn't this one have the drawback that you can no longer match on the type of `Image` (without using `ClassTag` or `TypeTag`)? Namely, using that approach, I can write: def foo(cust: Customer) = cust match { case Customer(n, _, _:ImageId) =&gt; { println("Simple") } case Customer(n, _, _:ImageImpl) =&gt; { println("Enriched") } } and get the following behavior: scala&gt; foo(Customer("Bob", 30, ImageId(20))) Simple scala&gt; foo(Customer("Bob", 30, ImageImpl("./bob.png"))) Enriched It seems like this could be important if there were many different `Image` subtypes. It seems like you can still get the same sort of functionality that you describe (e.g. `case class ImageUnknown extends Image` could be for "I don't know" and `case class ImageDontCare extends Image` could be for "I don't care" - you could then match on those). Can you explain why the type-parameter approach might still be preferred?
Thanks it is interesting, but if I could bringing new language it would be ScalaJs... sadly that's not the case...
No, it genuinely isn't very usable - I'm the author (of most of the current version), I can say these things.
What's the state of type providers in Scala ? Why are they not more popular (for example as in F#)? I know Travis Brown has example on https://github.com/travisbrown/type-provider-examples, how relevant is it since its 2 years old? If macros are changing and I were to implement type provider, should I use Scala Meta? I often waste manhours on fixing Typesafe Config stuff failing on runtime and I had hoped there would be a type provider for that... is there some showstopper in doing that?
The same page also has this usage: abstract class Getter[S, A] extends Serializable { self =&gt; def get(s: S): A } What is the role of `self` here?
Well, pointer arithmetic is rather difficult in Scala. Also manual memory management is not easy. But in all seriousness i'd say Union and Intersection types are problematic in Scala, which is solved by Typescript pretty neatly and that means you don't have to use Option[T] since, you can just write MyClass | null, which obviously reduces the overhead, both in writing and in performance. Also, which is neat in typescript, not not really necessary in Scala is the execution flow dependent type inferred, if you check for the type in an if statement, the compiler will guarantee to you that in the scope of the if, it will have that concrete type, but it's not really a problem in scala, since we have pattern matching, which is a superior solution.
Great work! The compiler feels really snappy, much more so than fastOptJS does when I run it on my local dev machine. Is there black magic involved here? 
If it's possible, I'd strongly recommend using Typescript if you can. It's a much easier sell than Scala.js. The project I'm working on atm initially started as in JS and we gradually transitioned to TS. It's a very well designed language (as best it could while maintaining compatibility with JS..) and makes our lives so much more enjoyable. (Yay union types!) In terms of libraries, we've found that the benefits immutable.js provides isn't worth it (too verbose and conflicts with the JS ecosystem in general). Other than that, rambda or lodash is probably the libraries that is useful for every project. You can also try `jsverify` for property-based testing.
Option[T] is much more then just something or null, but union types are a much desired feature in Scala, indeed.
I know that Option is much more than a Union type with Null, but using Scala make feel a lot of times, that it's not necessary, and it's easy to convert it to an Option if you need a monadic context. You can create accidental null with Scala, when declaring a val in a trait, that's value refers to abstract members. I think it should be a compile time error, not a runtime null pointer exception, also i think two dimensional arrays can only be created with nulls at first, and there is no check that they actually get values, although, i rarely use that construct in Scala, i just stumbled upon once.
You can have Heterogeneous maps in Scala, but it's not supported out if the box, and it's different since for the current implementations each element has it's concrete types, when we can use dotty, with union and intersection types, this will be solved, but honestly, you can work around this with type classes. What do you mean by JSON? what's there that is missing from scala.
You can have HMaps in Scala, but it certainly qualifies for "things that are easier to express in other languages"; dito for JSON.
Nothing, I think ... that `self` can be removed.
The official answer is on GitHub [here](https://github.com/fpinscala/fpinscala/blob/master/answerkey/monads/09.answer.scala).
I agree. However, Option[T] could be a virtual construct over the union of T and Null, like so: implicit class Option[T](private val ot: T|Null) extends AnyVal { def map[U](f: T =&gt; U) = … def flatMap… }
This issue mainly boils down to doing *reflection* on generics, which is harder. The more "Scalaesque" way of doing this is type classes, which also ensures you don't get any runtime-related problems.
Each step of the proof holds in both directions though, right, so you can also read it backwards.
Hmm, I'm not sure it does. For a start, the proof doesn't make use of a definition of `flatMap` expressed in terms of a provided `compose`.
Is it possible to give a type argument to an annotation macro? If it's possible what is the syntax?
What do you mean "which satisfies `compose(compose(f, g), h)`"? Presumably it satisfies that that's equal to something? I don't *think* you should need that identity. You should be able to work solely in terms of Kleisli composition, only ever "running" the Kleislis at the "boundaries". I'm happy to do a full solution of the problem and check as much if you think that would be helpful - if you want that then please post the full statement.
&gt; What do you mean "which satisfies compose(compose(f, g), h)"? Presumably it satisfies that that's equal to something? Apologies, I missed a bit, and I've edited my post (just the obvious associativity law).
You can derive the identity from the definition of both `compose`s: cp(f, g) . h == cp(f . h, g) =&gt; (a =&gt; fm(f(a), g) . h == a =&gt; fm((f . h)(a), g) [from def of compose] =&gt; == a =&gt; fm(f(h(a)), g) [from def of .] =&gt; LHS reduces to: x =&gt; fm(f(h(x)), g) [from def of .] QED (both sides are the same) (using cp = compose, fm = flatMap &amp; . = function compose)
What's funny is that Paul Graham suffers most from the blub paradox: he still thinks _Lisp_ is the "best language," by definition, because it's the "programmable programming language," where what that means is "we have unhygenic macros." The capital-T Truth, though, is that if you actually study PLT (Programming Language Theory) deeply, then you can make informed judgments about languages along multiple dimensions, often without bothering to actually even use them, assuming they actually have definitions. For example, I didn't have to lay a finger on go to realize it was hopeless: it has a definition, and one look at its type system is sufficient to answer the question. I don't have to fall into Graham's trap; I already know statically-typed is better than dynamically-typed, and there is some sweet spot roughly where Standard ML, OCaml, Haskell, and Scala lie with respect to "pain of satisfying the compiler" vs. "the compiler helping me express what I need to express." I already know hygenic macros are preferable to unhygenic, whatever the language. And so on. So I try not to start from a false premise. With that said, there definitely are things I find in other languages it pains me not to in Scala, but I can't take those things in a vacuum. The fact that Scala runs on the JVM and is comparatively popular are points that outweigh the technical weaknesses it has relative to the "better" (along those technical dimensions) alternatives. At least until people figure out the JVM stopped being relevant about five years ago, anyway.
Absolutely. `Interpreter` is handy when you've created a `Free` `Monad` and now want to actually run it, because `Free` `Monad`s can't do anything by themselves: they have just barely enough structure to be `Monad`s. You need an `Interpreter` to interpret them as some other `Monad` that actually does stuff, like `IO` or `Task`. But there are stacks and stacks of things you can—and I would argue, should—do before writing your first `Free` `Monad`, if indeed you ever do. Unsurprisingly, I'm with [/u/runT1ME](https://www.reddit.com/r/scala/comments/52ghye/advancedfpwithscala_john_de_goes/d7lx6d6): I mostly think about `Interpreter` when I want to create a monadic API with some relatively nasty gobbledygook in the implementation. Then I find the discipline of designing an algebra, creating its `Free` `Monad`, and writing an `Interpreter` for it worthwhile.
This is impressive and also mind boggling. What are some use cases for using this in the browser? Or is this more targeted towards server-side js?
I think many of the types of problems often solved with type providers be can be solved just as easily with Free Applicatives. So there's not much motivation into investing to that particular use of macros.
Scala is like a good game: easy to learn, hard to master. Just start by programming as you would in a language you know. Once you get the syntax, you're ready to go! People find Scala difficult because the language is so rich that you can use very high-level concepts. But nothing will ever force you to do so! You don't need to understand neither object-oriented nor functional programming to be productive in Scala. Learning a language does not mean knowing 100% of it, but enough to be productive. Do you know all of the English words? Does it really matter? Don't be scared, just learn Scala at your own pace and everything will be fine. Of course is one day you want to master asynchronous computing, persistent data structures, generic programming, ... you'll discover that Scala let you express these concepts quite easily. But that's not Scala that is difficult, the concepts are!
Well said.
Well, schema is in there, somewhere *g* ;) http://stackoverflow.com/questions/32522128/slick-3-reusable-generic-repository is basically what I want to do, but in a driver agnostic way and on the model layer
But what about `Option[Null]`?
Tough question. Basically we've tried a lot of frameworks on the front end side (long before scala-js was born) and we still struggle a lot to have a good experience to test and have a good feeling about our frontend code. At the moment we use AngularJS 1 at one of our biggest projects and drop to React where we need. Basically we have as much JavaScript Code than Scala code (mostly boilerplate) which is a pain. It's really hard to move forward i.e. Angular 2. It would take a huge amount of time. The developing experience is worse than any maven, gradle, sbt stuff. I mean npm downloads the world. Also the experience with Scala-JS Shim's isn't to great since you still have a lot of mutable state. But there are new projects and we may pick some of the new scala-js projects if we find it matured enough I guess. The whole story is probably longer.
 &gt;What is it you're using typesafe config for? I prefer to keep my config as case classes with instances that are just defined in code, could that be an option for you? If it's for configuring a library, could you request (or contribute) an actually type-safe config interface for that library? So here's how story usually goes from my exlerience: - chug every single thing (the ones that you wont ever change, even between enviroments) into this massive config that keeps growing - its too big (yea no wonder) split it to multiple configs, start putting includes all over (also move some parts across to inhouse libs we're using ...) - ConfigFactory.load. more than once. on every place. :( why did they make it so easy? Should be at least as hard as awaiting Future (where they moved it for this reason to Await ...AFAIK) I push for case classes approach and loading config in main. But even that is still very far from ideal... for reasons... (political, personal, ego etc.)
Thanks!!!
They meant typeclasses. 
Thanks, this made the difference 'click' for me.
Yes, I've had similar feelings about the problems being at both ends of the stack: the closer your language is to 'plain old' JS, the less type safety you have; and the further away it is, the more you rely on rickety and possibly-outdated shims and wrappers (not to mention that you don't get thing like JSX syntax in other languages and have to adapt every example). We're recently starting work on a frontend project. I've been able to convince my team to let me use scalajs-react and https://github.com/chandu0101/scalajs-react-components which are definitely both godsends (we're a full Scala stack, more or less). If I couldn't get buy-in for Scala.js I would have pushed for TypeScript. It has typechecking, type inference, JSX syntax (in `.tsx` files), and serious effort in the community to wrap libraries in type-safe wrappers. They even have a dedicated wrapper repository and associated tool, Typings.
So the central idea here is to use function composition to implement the builder pattern, so instead of doing HttpRequestBuilder .get("http://example.com/foo") .setHeaders(Map("a" -&gt; 1)) .setQueryParams(Map("b" -&gt; 2)) .build .exec we're doing (something like) HttpRequestBuilder .get("http://example.com/foo") .andThen(HttpRequestBuilder.setHeaders(Map("a" -&gt; 1))) .andThen(HttpRequestBuilder.setQueryParams(Map("b" -&gt; 2))) .exec // This is added on with an implicit conversion I suppose it's a matter of preference; I prefer the former. The latter doesn't seem as 'fluent' in the sense that the `andThen` wording gives the impression that those things are actually happening one after the other, which of course doesn't make sense because nothing is actually happening until the request is built and executed. (Also more verbosity and static monkey patching.)
I vomited in my mouth.
With remote transport over websockets it would be a breeze to communicate over the client/server boundary. This would be damn cool.
Sure. There are even facade types for a large portion of the Node.js APIs: https://github.com/ldaniels528/scalajs-nodejs
You can pass A and B and then call instanceof to test the object. function Cat(){} function Dog() { } function compare(a,b,obj){ if(obj instanceof a){ alert("its A") } else if (obj instanceof b ) { alert("its B") } } var dog = new Dog compare(Cat,Dog, dog) //its B
&gt; I'm happy to do a full solution of the problem and check as much if you think that would be helpful - if you want that then please post the full statement. If you could, that would be much appreciated. The statement would be &gt; Given a `compose` which satisfies `compose(compose(f, g), h)= compose(f, compose(g, h))`, I want to show that I can derive a `flatMap` that satisfies `flatMap(flatMap(x, f), g) == flatMap(x, a =&gt; flatMap(f(a), g))`.
And how is that better than the Scala version with a `ClassTag`: def compare[A: ClassTag, B: ClassTag](obj: Any) = obj match { case obj: A =&gt; "it's A: " + obj.toString case obj: B =&gt; "it's B: " + obj.toString } val dog = new Dog compare[Cat, Dog](dog) // it's B Instead of reifying `a` and `b` as value parameters in JS, you reify them as `ClassTag`s in Scala. TBH I fail to see why you consider the JS version superior. You might answer: because you need to thread `ClassTag`s along all the code paths leading to where you need them. This would be exactly the same in JS with having to thread the value parameters `a` and `b`. There's no magic.
Why not help the IntelliJ guys? I don't get that.
I'd like to know this as well.
Or the ensime guys who are already doing this 😕
The post says: "*join the efforts of the Ensime folks*". Don't take out your pitchforks just yet.
Probably because IntelliJ IDEA is a commercial product and Jetbrains a private company whose interests or vision don't necessarily align with Scala IDE, plus they are doing a good job without any help and besides, it's better to have choice.
Oracle projects being transitions to Apache is most likely a sign that the project is dead.
I would like VSC integration. Would also like Emacs and Atom integration. Joining forces with Ensime would be best. I'm not an Eclipse user, have left it a long time ago because I can't stand Eclipse due to practical concerns - I never managed to have an Eclipse install that wouldn't crash due to incompatible plugins. I use IntelliJ IDEA daily, but I've been flirting with Ensime. IntelliJ IDEA is a great IDE, however it is slow and cannot handle advanced Scala code. I've seen it having problems with implicits, with higher kinded types and with cross-platform projects that have a shared code directory. If ScalaIDE / Ensime could do a better job at type-checking my code, then I would switch. Heck, I'm actually using Emacs with just syntax highlighting for quick prototypes, because IntelliJ IDEA stands in my way. But IntelliJ IDEA has great refactoring and code navigation prowess and I hope you match it.
I don't know. But NetBeans platform is an interesting technology, much less complex than Eclipse RCP, and IntelliJ while having the open source CE doesn't really have a good separable platform. Anyway, what I'm saying is that the best would be to put effort in making it possibly to connect Scala IDE components (presentation compiler, analyzer, search, refactoring) from other desktop systems.
Of course trust is important, but why would you trust Microsoft more than JetBrains? For example, JetBrains doesn't develop an operating system. Who guarantees that we won't see MS eventually favouring Windows as the platform for VSC, and so Linux folks are screwed. JetBrains benefits from Scala, because it's the most downloaded plugin for IE, so there is a huge user base, and that's why they attribute large resources to the plugin development.
Netbeans has kind of being dying for some time and netbeans for Scala has definitely been dead for quite some time. Also editors like VSC are specifically designed to have tighter integration with servers that provide autocompletion (amongst other things), i.e. ensime
Microsoft recently has been making huge strides in this area (i.e. open sourcing .net). In any case, VSC is under MIT license, IntelliJ is closed source
It is not that I trust Microsoft more, but the situation is different. VSC is "just" an editor, most IDE functionality would come from our side and therefore is owned by us. At least at the beginning, VSC would be responsible for the GUI and the interaction with it. Later they may provide more powerful IDE functionalities by themselves. IntelliJ is as well as Eclipse already a full fledged platform, we would give up our ownership of our code - we would just be contributors and we would depend on what JetBrains want. I also think that Microsoft will have a hard time in doing anything that does not please the community. They started VSC with the promise that the community can trust them and they built their product accordingly. For example, they can not simply drop Linux support because Linux support is provided by Electron, a product that is owned by Github. And VSC uses many more libraries from the community - Microsoft only owns a small fraction of all the code that is responsible for making VSC to what it is.
Also really support this move, happy that VSC was chosen (atom would have also been nice, however its not a deal breaker)
Thanks for clarification. I guess I need to learn more about VSC. So putting "Visual Studio" in the name is just a marketing thing? What's Microsoft's motivation - spreading C# and Typescript on all platforms?
IntelliJ IDEA community edition is fully (AFAIK) open source, licensed under Apache: https://github.com/JetBrains/intellij-community
Yes, the Visual Studio thing is mostly marketing. They do not share any code and I do not even know if former developers of VS work on VSC. What Microsoft wants to achieve with VSC I do not know either - I guess they just want to find out how successful they are by doing software development in the modern Open Source way.
I for one would love to see some kind of IDE-light based upon VSC. I currently hop from IntelliJ to Vim, but always find myself skulking back for some features that neither Sbt or Ensime provide. Another outcome I would support would be you guys really throwing your hat in with the Ensime folks and working on bringing its support for editors besides Emacs up to scratch. Whichever you decide on, just want to say thanks for all your work. I think IDE competition/variety is important.
Will the vscode support support type safe refactoring, debugging, debugging eval window, semantic auto complete, a repl, auto imports, dependency management, right click to run app/tests (scala test/specs/ju it), inspecting implicits, auto adding type signatures, namespace renaming, decomposing and viewing of source files/jars, maven and sbt support, mixed Java scala code, code coverage, etc? The only thing that's going to get me off IntelliJ are these kinds of features. I want zero fuss getting started and professional tooling for both personal and professional projects. I tried ensime/vim/emacs (spacemacs)/scala ide, and everything was just horrendously painful or broken. IntelliJ was the only one that just.worked. Life is too short to futz with crappy broken tools (if I wanted that I'd go back to Haskell) That said, I'm all for support in another ide of it's going to be real support and not just auto complete. Having options is awesome, but these days people treat the most minimal semantic feature as an IDE. the sublimetextification of our tooling is irksome Reason I bring it up is look at the c#f# support in vscode. It can't manage project files, it can't run tests, refactoring is non existent. it's basically atom/sublimetext with a nice skin and a few stripped down options. Yeah, it runs fast, but it's useless for real development of anything non trivial and you end up doing all this crap by hand that the IDE was supposed to be doing for you
&gt; Furthermore, IntelliJ has no interest in using the official Scala compiler or the soon-to-be official Scala compiler https://github.com/lampepfl/dotty/wiki/Using-Dotty-with-IntelliJ-IDEA https://www.jetbrains.com/help/idea/2016.2/getting-started-with-dotty.html ?
I think that's fair but they set an incredibly high bar of what the tooling should be like. Are you planning on going beyond that with the same polish? if so count me in :)
Is there anything one can already play around with? Is this your Amora project, or something else?
nixos :-)
&gt; Will the vscode support support type safe refactoring, debugging, debugging eval window, semantic auto complete, a repl, auto imports, dependency management, right click to run app/tests (scala test/specs/ju it), inspecting implicits, auto adding type signatures, namespace renaming, decomposing and viewing of source files/jars, maven and sbt support, mixed Java scala code, code coverage, etc? Not sure what to say about maven and sbt support and code coverage but all the other features: Yes, the plan is to support them all. Maven support is not very important for Scala developers, therefore sbt support would have higher priority. But sbt server, the technology that enables sbt support in IDEs, has shortcomings and therefore it is difficult to support this feature. code coverage technically is a separate product, I would prefer that this is done by the build tool and the IDE only integrates the code coverage report in its UI. We won't be able to provide all of these features from day one but Scala IDE already exists for a long time and we made huge refactoring over the years to make our codebase independent from Eclipse (as much as possible). Therefore, we are be able to move code in our backend to the new VSC code implementation.
My dream would be to go beyond that but of course that is easier said than done. ;)
If you could provide all of that I'd consider switching from IntelliJ, but I agree with monumentshorts that we need some pretty good integration before I could be equally productive in VSC. The semantic auto-complete and auto imports would be the highest features on my list if I were prioritizing; without those it's worthless to me for writing in scala.
If you are looking to get off eclipse, and want an open source platform to build on, you might consider atom as well as vsc. Emacs also is a good starting choice - it doesn't have to be keyboard navigated and has some decent widgets, popup menus, and built-in customization and mouse support. Lighttable is another starting point. You might also consider layering a gui on top of ENSIME, but that would mean supporting text editors that are not open source (sublime) as well as ones that are, and I don't know how well vim handles gui widgets - could be starting from scratch there, though starting a server to run in the background and manage communication from the buffer to the gui windows shouldn't be a huge hurdle and would be reusable across editors if you chose to go that route. Aside - it's nice to hear my thoughts echoed from a team member about the concerns around Intellij. Been blown up on here about that.
Absolutely. IntelliJ is great, but it's overkill for smaller projects. There is a gap right now between the interpreter and IntelliJ, and VS Code would be a fine fit.
JetBrains does, however, develop Kotlin. To my knowledge they don't favor or promote Kotlin at the expense of Scala, but there's no guarantee that will always be the case. It makes sense not to put all of our eggs in the IntelliJ basket, even if it's a pretty sweet basket right now.
Try https://gitter.im/http4s/http4s to get a fast answer.
Why that? It is not the programming language that is responsible for the overall quality of a software product but the people behind it. In our case a lot of code will run on the server, which is a JVM application, and then communicate with a JS app that runs in the browser.
That's true. But basically it comes down to the following things: A JS Editor will hook way more Resources than it needs to, I mean it's an editor not an IDE (Sublime Text handle's that twice as good). JavaScript I dislike to write JavaScript (and at the moment I still need to until we have everything on Sjs) and when it comes to an Editor that is plugable and not a full blown IDE I probably want to write my own (small) plugins, which is not hard in Sublime Text (python) and probably not hard in JavaScript (but it's akward). Than there is the whole feeling about developing with an Editor and a IDE. I mean a IDE is great for Scala, caused by the type system, however a Editor will always be worse than a IDE no matter how much effort you put into.. And somehow VSCode doesn't provide a good experience to me, even when Microsoft has put a lot of effort into it. I mean they basically are 100% better than Atom. But they should've probably added a lot of stuff to IntelliJ CE, like Android Studio. I mean well you would still have two IDE's but well if I could've compare Rider EAP with a Tool from Microsoft that would be cool and I guess Microsoft would've a full blown IDE already, while JetBrains is still in a private EAP. Well I didn't used Scala IDE since I dislike Eclipse, their interface looks the same as it looked 2002 I mean something doesn't need to change their interface all of the time, but well I it could have gotten a lot of UI/UX improvment's since then. I mean that's why IntelliJ skyrocketed that market. It looks cleaned up and has a good UI/UX since 1.0. Edit: Missed the most important part: I even think that Eclipse UI/UX got worse after 2.0. I also wonder why nobody tried to recreate button's and improve the Settings Menu and everything like Bar's, Sidebar's Keys.
I am not sure why you replied to my comment
Would it continue to use the presentation compiler? I'm assuming yes, but just to verify.
In the long term, no, we do not want to continue to use the PC. We want to be compatible with scalac, dotc and javac at the very same time, which we can't by using the PC of scalac.
your not a robot :-P ?
it is extremely daunting that someone involved in developing editor support for scala has such misconceptions against one of the most loved (outside of emacs and vim) and popular editors 
Considering that time and time gain i've been trying to switch from intellij to sublime+ensime / eclipse / even netbeans once, yes please! Anything that offers proper refactoring / code completion / auto import / scaladoc lookup would be a welcome addition to the scala ecosystem. To me ide support is one of the major pain points of the scala ecosystem. Intelij is nice and all when it works, but more often than not it doesn't. It (still) chokes as soon as there is a non standard directory structure and things like mixing scala/scala-js in one code base is (for me) unworkable, even when using intellij ti import an sbt crossproject. (as nothing else seems to reliably work, i've started to manually define my scala-js + shared as one project, and scala-jvm + shared as another, with as huge drawback i can only work on scala-jvm or scala-js code at once). Once scala-native gains any traction, i'm almost sure intellij will break best case it'll create a dozen of modules for one mixed project. Not to mention the completely broken error highlighting when anything advanced goes on. For this vsc based ide, please please please be conservative in error highlighting, i much rather have (the option to have) bad code ignored (it'll not compile anyway) than work through a screen filled with red warnings that aren't really there and i can't get rid of (it's usually the moment i start sublime again).
I still have no idea why one would choose Play over something like http4s or Finch. Everything seems to be designed as if it came straight out of Java circa 2007.
I don't think I have misconceptions against IntelliJ. Also, just because a tool is beloved by many people doesn't mean there can't be people that are unhappy with it - I'm by accident just one of these people and I criticize IntelliJ for not being perfect. I would like to continue to work on an Eclipse based IDE or even on an IntelliJ based IDE if I could see that they can solve my problems but the reality is that I can't see that I can ever be a happy user of one of these IDEs. After years of trying to build an IDE I love to use I came to the conclusion that Scala IDE needs to change and this change includes to switch to a browser based platform.
Most likely it's about simply keeping brand recognition. Since it's only an editor, they don't need to devote the same kind of resources they do to VS, and they can keep their name in circles they don't normally have a big representation (Linux, for example). That's really the only reason I could think of, anyway.
&gt; gui on top of ENSIME ENSIME is a IDE backend, the gui(s) are the supported editor + a plugin per editor. You assume a feature parity with the current Scala IDE. I assume they are stopping development for Scala IDE and joining efforts with Ensime.
Or akka http.
&gt; Not only would VSC give us a new modern look but it would also give us the chance to make Scala IDE more lightweight and join the efforts of the Ensime folks to provide a standalone IDE implementation for all Scala users. That doesn't sound like they are stopping development on *a* IDE, but it sounds like they are looking to use the ENSIME backend. In which case I'd expect them to provide gui plugins for all the editors supported, especially if the gui features are compelling enough to get people to switch from Intellij or abandon an existing platform with a large, albeit grumbling, userbase in Eclipse*. I'm already an ENSIME user, and I love it in Emacs. It'll be interesting to see what they choose to do, and what effect it will have on the ENSIME project. I'm excited to see what will happen, even if they don't use the ENSIME backend. Edit: *When I say large, I mean the Eclipse userbase, not necessarily the ScalaIDE userbase, which I agree is probably smaller.
We don't have hard numbers but download statistics and surveys during conferences tells us that IntelliJ has an order of magnitude more users. It is not that we only care about the number of users. But there are many problems in Scala IDE right now, which we realistically can't address without a larger change in our internals. The dependency to Eclipse is just one of these problems.
A thousand times yes, please do it.
I don't know how Visual Studio Code differs from Visual Studio Professional in usability and stability. The latter offers a very bad usability experience! It lacks lots of features and the refactoring options are far from those you know from eclipse for Java. (C# is a little bit better supported than C++. The refactoring for the latter is a bad joke!) There are a lot of people that celebrate VS as the best IDE in the whole universe - I cannot imagine how those opions could have come to life! If VS Code is a complete different project, the choice might be ok, although I would prefer something less MS dependant. But after all IntelliJ exists 😉
&gt; look at the c#f# support in vscode. It can't manage project files, it can't run tests, refactoring is non existent. Some of the things that VS Code is incapable of doing is due to their tooling. In the Scala world, all project building, testing, dependency management and deployment concerns are managed by SBT, including code coverage. They do not have their own SBT or any Maven-like solution. Their build system is MSBuild which is basically like Make and Ant. And managing an MSBuild project file is not feasible. That said, what the C# and F# folks are doing is to expose the compiler as an API for tooling. That's actually really smart, because you can now extend any editor to support C# and F#. And also, at least the C# and the TypeScript compilers are designed to be provide efficient Intellisense support in IDEs. That's actually hard to do because the concerns of a compiler that compiles a whole binary is different than that of an IDE, because an IDE compiler has to be *tolerant*, has to be incremental and to update its output very quickly in response to user keystrokes. And sure, the refactoring support is rudimentary, but it will improve and when it does, you'll be able to benefit from it in your favorite editor. Checkout this presentation: [Anders Hejlsberg on Modern Compiler Construction](https://channel9.msdn.com/Blogs/Seth-Juarez/Anders-Hejlsberg-on-Modern-Compiler-Construction). And I think this should be the value proposition of Scala IDE. Thing is, we already have IntelliJ IDEA, which is a tough act to follow. Not even Microsoft can do it. The Jetbrains folks are experts at building tools for refactoring and code analysis. That's hard to beat. But Scala IDE can differentiate itself by doing a better job at type checking Scala code (as I said before, IntelliJ has problems with advanced Scala) and by providing the flexibility to use whatever editor you want. I for one love Emacs. Editing in Emacs is extremely efficient and some of the things that Emacs does no other editor can match. And having IDE capabilities in Emacs is great.
Had no idea, thanks for the correction!
If you are looking for an editor where you can basically almost configure anything, Atom is your best bet. VCS is closer to sublime in design, that is they editors have reduced functionality in turn for providing better performance. VCS sits in between Sublime and Atom in this regard.
I find that Scala IDE has far better compilation feedback than IntelliJ, but IntelliJ has much better refactoring and code nav. 
By the way, what happened to `Trace` and `runTrace` methods? :) Looks like they didn't make it to the final release. Did you need them only for the initial stage of development?
I cannot find it, but I remember I had a graph of total download with Scala IDE and IntelliJ scala plugin. The first data source is from internal typesafe download, ask them. The second data source is from https://web.archive.org/web/*/https://plugins.jetbrains.com/plugin/?id=1347, check the download count at each date. The graph looks exponential for IDEA and linear for scala IDE. We don't have a per version breakdown. Maybe intellij has a cumulative count.
You could merge the `Option` and the `Try` into an `Either` (`\/` from scalaz or `Xor` from cats for a right-leaning one) and represent the two failure modes via an ADT on the left side.
No, not really ) I discovered it accidentally via auto-complete while I was playing with 0.9.0-M3. Just wanted to confirm that this was a debugging feature. Thanks for info!
I don't think those courses will be ready in one week. Stay tuned.
How was the rest of the courses? I had difficulty with the Scala class 4 years ago, but my skills have slowly improved.
My immediate reaction is: you're using three failure monads, which is a lot. I'd reduce it to one, and you probably know I'm going to say `Task`, because it encompasses both the notion of failure encompassed by `Future`, `Option`, and `Try`, but also the asynchronicity encompassed by `Future` as well. Then you can use a good old for-comprehension to do authentication, then look up the `Product`, etc. and have very clean, very concise code that nevertheless handles the authorization and its failure modes, the `Product` lookup and its failure modes...
While I agree that Intellij is a great editor and that picking Eclipse as a preferred IDE was a really dumb idea (although at the time only really sublime existed as a real alternative), there are a few things to consider * When using Intellij for a plugin, you are forced to use the internal PsiTree structure (this is how Intellij does all of its completion and inspection features). Unfortunately there isn't any real way around this (barring doing a complete recode of Intellij which isn't going to happen). The PsiTree structure is probably one of the biggest reasons why Intellij has performance/memory and completion issues and there doesn't seem any real way around this. Its not usually so much of a problem with languages that have simpler type systems, but with something like Scala its really starting to show its drawbacks * Even though the plugin for Intellij is open source, the control of the plugin is still in Intellij's hands. Its unknown whether or not Intellij's Scala plugin would implement the features (i.e. the new dottyc presentation compiler) instead of IntelliJ doing their own thing. * Expanding more on the previous points, Intellij isn't really designed to have a client/server protocol (i.e. you have some program running in server mode that provides completions and type information). This provides problems in regards to duplication, i.e. most people run both SBT and Intellij (both taking a huge amount of memory) and Intellij doing typing information itself is duplicated by SBT/ensime doing the same thing. Having an editor that is just a pure client means that VCS only needs to worry about the UI elements where as the server can worry about completions/type information/etc etc. Also Intellij's UI is blocking (this is why the editor blocks/lags when Intellij is trying to figure out type information) where as VCS/Atom the UI layer is evented/asyc which provides a far smoother user experience. tl;dr Intellij is as its core designed to be a monolithic editor that tries to do everything itself which would probably work out better if its primary language was Scala instead of Java
If working with IntelliJ is off the table then I think VSC would be preferable.
Putting on my [amazedballer](https://www.reddit.com/user/amazedballer) hat here, maybe check out [slim-play](https://github.com/lloydmeta/slim-play)? **Update:** Oh, he's the OP! &lt;emily_litella&gt;Nevermind.&lt;/emily_litella&gt;
Hmm, I wonder if encoding Authorized as a Functor would make sense.. or even as a Monad. Having authorization at the type level would be interesting. 
That is for Java, the story is very different for pure Scala users. As has been said elsewhere, Intellij + Scala Plugin is most likely the most used IDE/Editor for Scala programmers.
In practice, it's usually Play or Akka-HTTP. http://blog.scalar-conf.com/post/143419902425/scalar-2016-whiteboard-voting-results
Hi Paul! So what do you think of the guide? I had to pull out a bunch of stuff and make it into a series -- eventually it's going to have custom execution contexts, content negotiation, and timeout management, but I figured starting with something SIRD based would save pointing people to slim-play.
+1. When I used `Option[A]` at work for a web service, I eventually found myself re-writing it to `Either[Err, A]` due to the ambiguity of `None`.
&gt; Apart from the above, why is it less effort to integrate everything in a new "IDE" than fixing the existing issues? I know that producing something new in a new environment feels good, but it is (unfortunately) often not the most efficient thing to do. Because of technical dept (as always). Most of the limitations in Scala IDE come from scalac and Eclipse. In order to improve over what we currently have we need to rewrite a large amount of code at some point. If we go that route I would like to do it correctly and that means to not just update our internals but also to update the surface.
Yes, that is what we would like to do.
For what you're doing, I'd use a `Future[Option[Product]` and have a failed future with an `AccessControlException`. Then use an error handler around the request with `recoverWith` to return a 401 result on an `AccessControlException`. This is because it's not an expected failure -- there isn't a situation in which you want to aggregate authentication errors with other kinds of errors and ask the user to fill out that info. It's not parsing -- they don't have access rights, and that trumps everything else. Wrote more about it here: https://tersesystems.com/2012/12/27/error-handling-in-scala/
What would be some reasons someone would choose http4s over Play? Play so far has: * good community support with tons of plugins and modules * Better documentation than http4s * It's easier for Java guys to covert over to Play than the other web frameworks. It can also be used as THE framework in an organization if the company uses both Java and Scala. * It's pretty simple. Routes to controllers. 
McLaren Applied Technologies.
Check out https://scalac.io ;)
Off the top of my head, 47 degrees, chariot, yopp works, cake solutions. Plenty around Europe too.
Do some java. It only feels dirty the first day or two.
Should laws of my modules be shipped with implementation, or be part of test module? I personally feel they are almost as extension to type signature and they feel like part of implementation... provisional simple example: object codec { def encode[A](x: A): Array[Byte] = ??? def decode[A](xs: Array[Byte]): Try[A] = ??? // I feel properties/laws should be right here object laws { def bijective[A: Gen] = forAll { (a:A) =&gt; decode(encode(a)) == a } } } Any opinions? Some can say that it's test code and has no reason to be there... For me it's property which is as important as implementation, and "test" code is actually real call of bijective method... what are your experiences? 
North Phoenix. I'm available throughout the metro area. Or even out of state with apartment help. ;)
I would say that only applies if you are using Scala as better Java.
Nice, but it's not clear from their website if this is a loose collection of consultants or full-time employees.
`Tree` is covariant in `T` which means a `Tree[Monkey]` *is* a `Tree[Animal]` by subtyping. This also means that it's a `Tree[Any]`, so any method consuming a `T` must also work with any supertype of `T`. Doing otherwise would be unsound, and Scala knows this; if you just have `T` it won't compile. You must use the `U &gt;: T` widening trick. Now, if `Tree` were *invariant* (i.e., `[T]` rather than `[+T]`) then this restriction would not apply but you lose the subtyping relationship among trees; `Tree[Animal]` and `Tree[Monkey]` would be unrelated.
I arrive late to the party, but I hope my comment gets read anyway. If building something new, whatever the platform, **pay attention to Scala.js**, in particular *cross-compiling* codebases. Mostly, Scala.js doesn't need special support from IDEs, because it's "just Scala". This is one of the reasons it could take off, because we didn't have to build an IDE for it; there were already several. However, there is at least one aspect of an IDE/editor that makes Scala.js support look more or less native: * Support for **one file belongs to separate projects/modules**. This is extremely important for cross-compiling libraries, because their `shared` part contains source files that are compiled in two different projects (with a different classpath). This means that those files typically need to exist *twice* in the IDE model: one in the JVM project, and one in the JS project. And in each, the `shared` files must be able to see the platform-specific files as part of the same compilation run. Concretely, we often see this pattern: shared/src/.../mylib/Foo.scala object Foo { def myFeature(x: Int): String = Platform.someCompatAbstraction(x) } jvm/src/.../mylib/Platform.scala import java.io._ private[mylib] object Platform { def someCompatAbstraction(x: Int): String = { /* use JVM-specific thing like java.io */ } } js/src/.../mylib/Platform.scala import org.scalajs.dom private[mylib] object Platform { def someCompatAbstraction(x: Int): String = { /* use JS-specific thing like the DOM API */ } } If the `shared` code does not see the platform-specific parts, it cannot compile because `Platform` does not exist. The deep, built-in inability of IntelliJ to model this is the reason some cross-compiling codebases will always be Red. ScalaIDE handles this very well, on the contrary. I would urge new development of an IDE to consider this aspect very carefully.
Eclipse is project-first. When I open a file, I'm not just opening "a file"; I'm opening a file *within a project*. If I open "the same file" (on the file system) through a different project (the JS project), I get a different tab, with a compiler linked to the other project. In a sense, it's *not* the same file, from Eclipse point of view. In the tab linked to the JVM project, I can link to definitions in `jvm/`. Open Declaration (F3) will open the file in `jvm/`, linked to the JVM project. In tab linked to the JS project, things work the same but with `js/`. It Just Works! Edit: I get all that for free with projects generated by `sbteclipse`.
I'm not necessarily recommending getting a full-time job either, but rather to think about what it is that you want and are trying to achieve, before you jump to solutions. For example, I sense that you want something that provides income, but leave enough time/energy left that you can continue to advance your startup. Part-time or hourly contract-work seems like what you ideally want, though I personally haven't seen (or looked for) many part-time CS jobs. Freelance work might be one possible solution. However, you'll also need to be able to find clients, sell yourself, and be prepared for inconsistent work/income. A full-time job with great work-life-balance might be another option. Sure, you'll be working a full work-week, but you might have enough time and energy left over to continue to advance your startup little by little. Stop by /r/cscareerquestions and ask around there.
[rant] The reason I caution against seeking work at many consulting companies is because I don't think it offers anything you want, versus a "normal" full time job. Worse, it would likely be extremely draining and work against your interest. The norm of working for a consulting companies tends to be highly stressful and unfulfilling. The reasons why can be traced back to the business model. In consulting you have double (or more) the management/bosses. You answer to both your employer, and the client, whose interests are often not aligned, and you're expected to keep both happy. You the consultant are stuck in the middle of these competing interests. A consulting company's first priority is maximizing billing. The employee's and client's best interests typically matter only so far as they lead to more billing. On the client side, this often leads to shady billing practices and selling clients stuff they don't need. On the employee side (you), this means project quality, best practices, and applicability to your skillset (ex: SysOps work) matter far less than the ability to bill. From a client perspective they're trying to get the most for their money, and consider consulting companies are a very expensive, but necessary evil. Scope creep is their best friend; any free work or support they can squeeze out of you is in their best interest. Good projects and tasks tend to be acquired by internal teams/employees, leaving the "scraps" of the most tedious, complex, risky, and stressful projects for consultants. Unlike a regular employees, consultant retention, morale, and burnout is practically meaningless. Consulting often involves a lot of overhead. More estimates, bids, detailed time tracking, spread-sheets, bids, meetings, paper-work, deadlines, on-call, re-interviewing, travel, supporting multiple/previous projects/clients, time-zone issues, and more. You may be under contract to work 45+ hours per week for a client, while your employer demands/needs you to perform additional work - such as analysis and estimates of new projects. Fluctuations in demand cause wild swings between being over-worked, to borderline unemployment, or whoring your skills out on shitty projects (SysOps, PHP, database migrations, software installation) because that's all your employer can currently bill for. Most consultant agencies will try to sell themselves as "we're not like those other [shitty] consultancies" and "clients hire us because we're experts." Not all consulting agencies are shit, and not all of them are run this way. However, if you do consider working for a consulting company beware the above signs. 
[Journal](http://oncue.github.io/journal/)? It's asynchronous, and we think it fits into the ecosystem nicely. As for "purely functional," it is, in the sense that you'll always get the same `()` back for any given logging message. :-) More seriously, someone (I think Daniel Spiewak) has argued that logging is inherently purely functional: yes, logging changes "the state of the world," but it does so in a fashion that's unobservable to the system (hence the `Unit` return type). That said, it's not, in and of itself, _monadic_, but that's no big deal. We routinely do `Task.delay(log.debug(...))` when we need to. Hope that helps!
thanks! didn't know about this one. will check it out.
After having thought about it, I guess you're right. So if I understand correctly, I should do something like this in my play controller? val product: Future[Option[Product]] = ... product.map { case Some(p) =&gt; Ok(toJson(p)) case None =&gt; NotFound }.recover{ case e: AccessControlException =&gt; Unauthorized } 
You don't need a "purely functional" logging framework. If you need async logging, then the major logging frameworks will do it already. Logback has the AsyncAppender: http://blog.takipi.com/how-to-instantly-improve-your-java-logging-with-7-logback-tweaks/ and Log4J 2 has the async loggers: https://logging.apache.org/log4j/2.x/manual/async.html There's little practical difference between the two, as the performance level is so high you'll never run into anything. https://www.grobmeier.de/log4j-2-performance-close-to-insane-20072013.html If you really have a need for some kind of low latency logging that doesn't allocate, check out [Chronicle Logger](http://chronicle.software/products/chronicle-logger/) or [Corellog](http://www.coralblocks.com/index.php/2014/04/corallog-performance-numbers/). 
Shouldn't asynchrony be the logging backend's problem? For instance, if the logging backend is only sending log messages over a socket to a log daemon, then passing the log message between threads in your application would be a pointless overhead—there's already a socket buffer and external log daemon between you and the disk. But your application has no way of knowing that; only the logging backend knows where the log messages are actually going, and in particular, whether emitting a log message can cause the emitting thread to block.
Thanks, I'll give it a try.
This is nonsense. These programs do have different results, as one logs something and the other doesn't. If you said you don't wan't to make any assumptions about the log output you could argue that it is pseudo-referentially transparent. But that is just like saying "I don't see Antarctica as part of the World", hence `nukeAntarctica()` is referentially transparent. What if another part of your program happens to open up the log file? What about exceptions or transient effects due to disk usage. Might be fairly safe to do that but saying it is referentially transparent is just not right. Never. 
How are you doing this? I've wanted to, but haven't taken the time yet to figure out how to get out from under log4s's slf4j dependency that brings in log4j 1.x.
&gt; This is nonsense. These programs do have different results, as one logs something and the other doesn't. I was _extremely_ thorough in explaining the fact that "referentially transparent" refers to the _value returned by the expression_. "Logging something" or not does not affect the _value returned by the expression_. &gt; If you said you don't wan't to make any assumptions about the log output... Which, as far as the _value returned by the logging expression is concerned_, is correct. &gt; ...you could argue that it is pseudo-referentially transparent. There's nothing "pseudo" about it. I both linked to and quoted the _definition_ of "referentially transparent." You might not _like_ it, but that's also irrelevant. &gt; But that is just like saying "I don't see Antarctica as part of the World", hence nukeAntarctica() is referentially transparent. That's _entirely_ dependent upon what you mean by "see," "part of," "world," and "`nukeAntarctica`." For example, I could very easily create a program that implemented an _extremely_ rich model of economics and trade, international politics, travel, religion, terrorism, etc. etc. etc. in which `nukeAntarctica` could have return type `Unit` (or its equivalent in whatever language), and calling it could _very easily_ have no observable effect whatsoever upon the result of this program. As Rúnar also pointed out: &gt; Now, something needs to be made clear right up front. Like all definitions, this holds in a specific _context_. In particular, the context needs to specify what “evaluating” means. It also needs to define “program”, “occurrence”, and the semantics of “replacing” one thing with another. You'd like to establish a context in which replacing `log.debug(...)` with its result, `()`, is disallowed even though `log.debug(...)` is referentially transparent, and the reason seems to be simply that you want to account for the fact that output that has no effect on the program is done. Or maybe not... &gt; What if another part of your program happens to open up the log file? Then you're no longer just doing logging, and one of the underlying assumptions has changed. &gt; What about exceptions... Exceptions are well known to be effects, and not referentially transparent. &gt; ...or transient effects due to disk usage. What about them, _especially_ if they're transient? &gt; Might be fairly safe to do that but saying it is referentially transparent is just not right. Never. I'm afraid that's wrong. Please look at the definition and my explanation of it again.
I've sent a resume via email as uploading via the website was broken.
Everyone loves it: http://www.meetup.com/Seattle-Scala-User-Group/events/220102798/
Personally, I don't find slick particularly difficult, but I also find it doesn't do particularly much. It's perfect for making web service APIs, because each does so little. I'd find it more challenging to use in an app with complex database interactions. 
I don't think that's a bijection. A prism perhaps. Btw, not sure if your'e on the #scalaz channel on irc, but there are quite a few there who have a lot of haskell experience learning scalaz. But not me, I only know a tiny bit of Haskell. :) 
Wouldnt the only dependency be scalacheck ? :)
Do you have any reasoning for wanting something that is pure functional? It's logging...no need to get fancy. 
If you're doing pure FP it's important for your logging to be pure as well, otherwise you may end up logging things on construction or interpretation rather than on execution.
Assuming you mean aerospace engineering. It depends which area you want to do phd in. I find aerodynamics much harder and far less comprehensible then reading library sources. 
I'll forward that info. Thanks!
For the love of God, this is the functional mindset gone mad. The whole point of logging is to get some insight as to what is actually happening, not some mathematical equivalent. A logging call is supposed to produce a side effect, immediately, and nothing else. So no, care does not need to be taken, it is a perfect example of something where the functional approach is completely meaningless. A purely functional logging system would not do anything.
Hmm, I see what you mean. Expanding out what I have in case it helps anyone else: Assume we're working in some fixed `F[_]` and that's Kleisli `compose: [A, B, C] (B =&gt; F[C], A =&gt; F[B]) =&gt; (A =&gt; F[C]))` and `flatMap: [A, B] (F[A], A =&gt; F[B]) =&gt; F[B]`. Let's define `flatMap` as: def flatMap[A, B](fa: F[A], fab: A =&gt; F[B]): F[B] = compose(fab, {_: Unit =&gt; fa}).apply({}) Then we have: flatMap(flatMap(x, f), g) == compose(g, {_: Unit =&gt; flatMap(x, f)}).apply({}) // definition of flatMap == compose(g, {_: Unit =&gt; compose(f, {_: Unit =&gt; x}).apply({})}).apply({}) //ditto == compose(g, compose(f, {_: Unit =&gt; x})).apply({}) // unit is always {} == compose(compose(g, f), {_: Unit =&gt; x}).apply({}) //associativity of compose == flatMap(x, compose(g, f)) // definition of flatMap == flatMap(x, {a =&gt; compose(g, f).apply(a) }) // name the variable And while it's "obvious" (e.g. by parametricity) that `compose(g, f).apply(a)` is our `flatMap(f(a), g)`, we don't have a proof of that.
&gt; I cant put type constrain on Reads[_] as Reads[ _&lt;:T]. I don't understand why. Compiler error: argument expression's type is not compatible with formal parameter type. Can you make a self-contained example? That sounds like an error you'd get when calling it with a function that didn't match. &gt; If the reads succeed I should end up with case Success(jsResult: JsResult[T]). Here compiler wines that type T is unchecked due to erasure. Adding (implicit ev: TypeTags[T]) doesn't help. At runtime, generics are erased, so `jsResult` will just be a `JsResult` - the compiler has no way of checking whether that's a `JsResult[T]` or a `JsResult[String]` or whatever. Maybe you can match `JsResult[_]` and then do something `JsResult`-specific to figure out whether it's really a `JsResult[T]`?
&gt; A purely functional logging system is an absurd notion, because the entire purpose of logging is to produce a side effect Before posting this thread I had the same doubt in mind. You can apply the same argument to database programming saying that the whole notion of database programming is to produce a side effect. So by this reasoning there should be no functional libraries for DB programming. 
&gt; That's not true, unless you're using some special definition of "result"? I don't know if it's "special" or not. As I've explained several times now, looking at the definition of referential transparency, it's actually the only interpretation that's consistent. You can't "replace `e` with the result of evaluating it" in _software_ in any sense other than replacing it with its _value_. That is, you can't somehow put "the physical launching of the missiles," or whatever, in the code. So by parallel construction, we're forced to the admittedly disquieting conclusion that logging is referentially transparent. But it's not a _robust_ conclusion, as the counterexample of reading the logs back—that is, the program implementing both ends of a protocol—shows. In other words, doing output _and nothing else_ is a special case.
&gt; That sounds like a Daniel argument ;-) It totally is, and I confess my immediate reaction was that it's too positivist/instrumentalist for me, too (which is how I would characterize most of Daniel's arguments from my POV). &gt; Program output is generally considered to be observable: `putStrLn("hello") *&gt; 42.point[IO]` is not the same program as `42.point[IO]`, nor would it be if you `s/putStrLn/logInfo/`. I agree output is generally considered to be observable (by human beings, and I have this funny idea that human beings matter). I also agree those programs have different denotations. So far, so good. The problem is the definition of referential transparency couldn't care less. It also "helps" that it's easy to demonstrate as many examples as you want—the algebraic reasoning works exactly as Daniel claims. It also "helps" that, as Daniel also pointed out, he `.observe`s through a `Sink` to a logger in scalaz-stream without changing the result of the program _all the time_. But... &gt; If your logging is done via Unit-returning expressions then my reading is "it's ok to delete all this logging because equational reasoning tells me that it can't possibly matter" which probably isn't anyone's intent. Exactly. Daniel's argument, which I was forced to accept based on the definition of referential transparency, tells us a couple of important things: 1. Referential transparency and denotational semantics are not isomorphic. 2. Modeling "intent" in a program can't (just) be reduced to making the program referentially transparent. 2) is probably not surprising to anyone who's been doing FP for any amount of time. 1) shouldn't be, but given my own initial reaction to Daniel's argument, I think I hadn't actually internalized it. But I'm afraid I have to stick to my guns: _Just emitting output and doing nothing else with it_ is referentially transparent because it satisfies the definition. All arguments to the contrary either change an assumption (e.g. "What about reading the logs elsewhere in the program?") or discuss human intent ("What about writing the logs 'too many times?'" etc.) They're not successful arguments that logging isn't referentially transparent. They are successful arguments that referential transparency _alone_ doesn't meet those requirements.
&gt; Maybe you can match JsResult[_] and then do something JsResult-specific to figure out whether it's really a JsResult[T]? I checked how I use JsResut: case json: JsValue =&gt; json.validate[T] match { // T here is not abstract case JsSuccess(value, _) =&gt; value match { //value is deserialized object of type T The way I defined my abstract reads and writes is that I can stick in reads and writes from classes that do not inherit from that class. Meaning I would have a rune time cast exception or have to define a case where I deserialized an unexpected type XD. What I want are type constrains in the function which compiler will check. If I have some abstract type T and I deserialize JsValue with Reads[ _ &lt;: T] then the deserialized object will always be of correct type. 
&gt; You can't "replace e with the result of evaluating it" in software in any sense other than replacing it with its value. That is, you can't some how put "the physical launching of the missiles," or whatever, in the code. Isn't that precisely the fact that a function that physically launches the missiles isn't referentially transparent? &gt; In other words, doing output and nothing else is a special case. A definition that treats it as such seems pretty useless. The classical example of launching the missiles is also output only, but the denotation of a program that launches the missiles and does nothing else is very different from the denotation of a program that does nothing.
&gt; Isn't that precisely the fact that a function that physically launches the missiles isn't referentially transparent? It's often used as an example, but it turns out to be a bad one! The problem is, yeah, it has an effect on the world that "you care about," but _caring about an effect is distinct from whether an expression is referentially transparent or not_. If you want to express the fact that you care about what the missile did, you must _add something beyond referential transparency_. &gt; A definition that treats it as such seems pretty useless. That's definitely _not_ true: it's the definition that makes equational reasoning possible! &gt; The classical example of launching the missiles is also output only, but the denotation of a program that launches the missiles and does nothing else is very different from the denotation of a program that does nothing. Very true. So as I told [/u/tpolecat](https://www.reddit.com/user/tpolecat), one important takeaway is that referential transparency and denotational semantics are not isomorphic, and another is that "intent" can't be reduced to (just) referential transparency. But it's important not to misunderstand what referential transparency is because of those observations.
The point he's making is that, in a functional approach, the compiler could optimize the application by removing the log statements because they produce nothing as far as it can tell. Scala won't do that because it's not purely functional, but haskell, for instance, will. It's a good thing for the compiler to be able to make significant optimizations. 
I tried quill a few months ago against MySQL 5.7, and a simple join between two tables which matched the project examples caused compilation to fail with no real reason. I went as far as using the tables in the example and trying the example code verbatim. It still didn't work. I assume it was some dependency version conflict with other Finagle dependencies in my application, but I went with finagle-mysql directly. I plan to revisit quill when it's more stable, because it'd make things a lot simpler.
The only additional dependency besides whatever library you're creating, sure. But that dependency is not strictly necessary to the functioning of your code and that's what I'm philosophically against but practically in favor of.
&gt; `log.debug(...)` that is of type `Unit` But that's inaccurate, isn't it? It's really more like the type `IO[Unit]` (roughly speaking) because Scala is an impure language, and thus all operations are effectively inside a global `IO` monad. It's just that most effectful functions in Scala ignore this and pretend that the types are really `Unit`, or whatever.
What if you have a logging library that is implemented by writing to a database? Can it then be, in your words, 'useful to separate the intention to write to the log to the actual writing'?
I recommend you take VSC out for a test drive. E.g., check out its TypeScript support. Try out the auto-completion, mouse-hover type inference, jump to definitions, symbol renaming, project view, syntax and error highlighting ... etc. I've been using IDEA for a while and VSC does like 90% of what I do in IDEA on a day-to-day basis.
&gt; Slick works well for a lot of people Well, sure, PHP also works well for a lot of people, or rather companies, while the developers (like myself) go bald prematurely.
Kind of, except that not only do effectful functions ignore it, they don't have to (and generally don't) satisfy the monad laws, so you lose the equational reasoning benefits of actually using monads. So the question in this context is "does it matter if output-only logging is not actually done monadically?" Daniel Spiewak's perspective, which he convinced me of, is that the answer is "no," under the stringent condition that the program does not, in any way, shape, or form, depend on the output generated by the logging. So far, every claim to the contrary I've seen comes down to "something, somewhere, cares about that output, even if it's just Splunk," and I agree wholeheartedly. It just doesn't change the fact that you can indeed do equational reasoning about the program doing the logging, by virtue of the fact (sorry, guys, but it is a _fact_) that logging is referentially transparent. To recapitulate, I have _no problem_ with the observation that you almost certainly _do_ want to indicate something above and beyond the ability to do equational reasoning in the presence of logging. An obvious example is that you often want to log the fact that you just took some other action that _is_ observable by the program. In Scala, I might say: myConnectionIO.transact(xa) &gt;&gt; Task.delay(log.info("Wrote the frobnitz of the jimjam to the DB")) But let's be clear about this: the `Task` monad is used to reflect that I want to do the logging _after_ committing the database transaction, not to "make the logging referentially transparent." In other words, the monad is doing what monads always do: sequencing things.
Hopefully you know I both understand and agree with this. I'm certainly not claiming you can replace one `IO[Unit]` with another, or one `Task[Unit]` with another, because of the conjunction of the facts that: 1. Use of these monads signifies that the functions "do `IO` stuff" or "do `Task` stuff." 2. `IO` and `Task` are really "big" monads, which is to say, they underconstrain what that "stuff" can be. &gt; Unlike the case with all `Unit`-returning expressions being equivalent... _Exactly_. Declaring a function to be of type `Unit` is making a _very strong claim_, which is precisely that the function has an effect that the program _does not care about_. Daniel's persuasive (to me) argument is: logging, in practice, often fits that bill, especially when the output is treated—as, again, it often is—as purely unstructured data, indexed by some full-text search engine, etc. Now, you, of all people, [know that's not a _robust_ assumption](https://github.com/tpolecat/doobie/issues/7): _very_ often, you do, in fact, want to impose an interpretation/some structure on your logging, or have your logging depend on some context. I completely agree. All I'm saying, and/or all I understand Daniel to be saying, is those (common) use-cases are materially different from the "throw it over the wall and walk away" case, but that doesn't make the latter somehow non-referentially-transparent. 
You had trouble getting it in your build and connecting to the database? Or learning how to work with the API?
Why do you believe it wasn't sending the message? If you put log lines before or after the message sending, are those logging lines outputted? (Or better still, if you breakpoint the sending in a debugger, do you hit that breakpoint?)
Both, actually. First problem: supporting multiple databases. It's not best-practice, but we use H2 for our tests and MySQL for production. Slick supports multiple DBs, but figuring out how to wire the DI for this was...more involved than I'd like. I remember having to find a blog post and attached Github project to figure out how to do this. Second problem: using Slick table objects. In our code all database access is done using DAOs. These DAOs have constructors that take Slick Table objects as parameters (DI; helps with testing). My memory is fuzzy, but I remember this being impossible and requiring self types, so in the end we copy/pasted a modified version of the Table code from inside Slick to make this happen. Third problem: Slick code is inscrutable. Want to figure out which type you're dealing with? What methods are available where and why? What to import? I challenge you to look at the Slick code and figure out what's happening. There are traits, type aliases, generics and implicits all over the place, which makes grokking what's going on ridiculously hard. It's by far one of the most complicated DB libraries I've poked into. Fourth problem: actually using the Slick API with multiple databases. It took me an embarrassing amount of time to puzzle this one out, but I had no idea that you had to import driver._ (where driver is your injected DB-specific driver val) to get all the Slick methods to work. The examples all assume you're supporting a single DB type and import _a specific DB driver's methods_ as a top-level import. I went trawling through the code for for top-level package imports and couldn't find any. It was incredibly frustrating to see examples that used asSet or === or whatever and have nothing work. It makes sense in hindsight, but was not obvious IMO. It's not all bad though. First off, Slick "just works". The SQL generation actually generates performant queries for the use cases we have. The debug output while verbose, is incredibly useful. It gives you a sample of the data returned, shows the generated SQL, etc. The ability to compose query-fragments is flat-out cool. It's really incredible to define something like "filter by customer" as a fragment on a Table trait and use that everywhere. It really makes query reuse and composition possible. Once you get it working it's trivial to get additional tables in. So my complaints above all refer to a one-time and not ongoing cost.
I understand your view but may I ask if you are a command line user or a IDE only user? command line users are happier with sbt than with maven as I understand, for IDE only users however it is the other way around. I would like to design an IDE that makes both type of users equally happy - even though I understand that this may be difficult to achieve.
I'm doing the same thing in my code, except that the message sending is inside the complete directive. Not sure if it makes any real difference, but it works for me (akka-http 2.4.3). e.g. complete { masterActor ! MasterActor.StartFetch .... something else ... }
I would separate it out because I don't think it belongs in the actually deployed target. My general rule is that code that's used for any specific subset of "deployables" (where I consider test results as a deployable) should be in its own module. In practice I might only bother once it got to the point of two or three different classes.
Yeah, I'm not suggesting collapsing the error types beyond making them subtypes of `Throwable`. I'm only suggesting using `Task` as both the concurrency and failure monad to simplify the code, probably into a single for-comprehension.
I have been both. I'm pretty much full-time IDE at the moment. I think command line users' current preference for SBT (which I agree exists) is more an artifact of what integrations exist (e.g. emacs) and of having the `~` functionality built in. I think Maven will always be better in the long run due to having a much more rigid/restricted model, requiring project definitions to be expressed as a plain value.
&gt; You can't if the result of evaluating `e` includes effects on the world outside the program, which is precisely the fact that such an `e `can never be referentially transparent... &gt; ...what I'm arguing is that that paragraph means what it seems to mean (in particular, that the word "result" means what it usually means). It can't, because by that definition, literally _nothing_ is referentially transparent: all `e` affect the time taken by the CPU, the energy consumed, very often memory and disk space, etc. Now, you can say you only mean effects that are "significant to the user." But that's all I've ever said: if launching the missiles isn't significant to the user, then it need not be represented in the type of the function launching the missiles for that function to be referentially transparent. You can't have it both ways: if no expression that "affects the world outside the program" can be referentially transparent, no expression can be referentially transparent. The moment you make a distinction, you need a means of encoding that distinction, and now the _formal_ meaning of the definition holds. The "plain English" meaning is irrelevant. This is software, not English Lit.
&gt; It can't, because by that definition, literally nothing is referentially transparent: all e affect the time taken by the CPU, the energy consumed, very often memory and disk space, etc. Now, you can say you only mean effects that are "significant to the user." But that's all I've ever said: if launching the missiles isn't significant to the user, then it need not be represented in the type of the function launching the missiles for that function to be referentially transparent. Sure. So referential transparency is not an absolute objective property of a given function; it's relative to some notion of equivalence. That's already implicit in the definition: whether we can substitute "without changing the result of evaluating `p`" depends on what we consider a change in that result. &gt; But that's all I've ever said: if launching the missiles isn't significant to the user, then it need not be represented in the type of the function launching the missiles for that function to be referentially transparent. You can't have it both ways: if no expression that "affects the world outside the program" can be referentially transparent, no expression can be referentially transparent. Well, sure. A logging function is referentially transparent for some definitions of result equivalence, and not referentially transparent for other definitions, and this is true for all functions - even `identity` may create a relevant distinction (e.g. use of a stack frame) for some interpreters and/or some users. In practice we have a shared cultural understanding that usually allows us to assume a common notion of result equivalence - as you say, the distinctions that are significant to the user. But under that definition a function logging must be a different result from not logging, because a logging framework that was usable only where logging wasn't significant to the user would be absurd.
interesting, but apparently the table of contents in the sample is only for the sample... is there a place where I can see the whole index?
&gt; Because a mono IDE culture is not what I think would be best for the Scala community (or for any community). Thank you! If Eclipse can't be saved, the worst thing would be to have only one full-featured IDE.
Yeah, this is the way the Leanpub generator works. Fortunately, the full table of contents is showing on the web site below the description.
This first hit of 2.12.0 sets Java 8.0 compatibility as a much higher priority than improving performance. IOW, first it gets things working with the Java 8 (and it's associated JVM) in a maximally compatible way. As a second and lower priority, there has been a small amount of focus on producing small risk optimizations. I suspect that 2.12.1 will be much more focused on optimization, both for compile time and run time.
Yes! I knew we'd come to the middle eventually. Since we got to quoting the [post](http://blog.higher-order.com/blog/2012/09/13/what-purity-is-and-isnt/) I've taken definitions from to this point: &gt; Now, something needs to be made clear right up front. Like all definitions, this holds in a specific _context_. In particular, the context needs to specify what “evaluating” means. It also needs to define “program”, “occurrence”, and the semantics of “replacing” one thing with another. We clearly agree on this. So: &gt; But under that definition a function logging must be a different result from not logging, because a logging framework that was usable only where logging wasn't significant to the user would be absurd. That was my initial reaction as well. But Daniel's point was that it actually happens all the time. And when I reflect on that, I realize he's right. I'm constantly adding logging that I _never look at the output of_, and _neither does anyone else_, the vast majority of the time. And even when they (some poor schmuck in ops) do, they grovel over the logs with some completely unstructured search engine. And that's only in response to _something else_ going wrong. I could completely remove that logging without affecting the _intended meaning_ (correctly expressed or not!) of the program _one iota_. This is the context in which logging is referentially transparent whether it's expressed monadically or not. But again, we agree: very often (more often? less often? I'm not sure) I'm _not_ just throwing some information over the wall that goes into an indeterminate blob that may or may not ever even be observed. I care about the context the logging occurs in; I care about its sequencing relative to other effects; etc. In _that_ context, an unconstrained effect (function of type `Unit`) will, as you and others have said, not be referentially transparent.
Yeah, it's an important design decision as to whether you want to separate "system level" vs. "application-level" failure along flow-of-control lines or not. &gt; well in practice you can recover the distinction with a runtime pattern match but urgh Yeah. So maybe instead of having everything just indiscriminately handle `Throwable`, or whatever, establish distinct hierarchies that are implemented by subtyping `Throwable` (because that's what `Task` uses to model failure), but are otherwise disjoint. You could enforce that at function boundaries with [tagged types](http://eed3si9n.com/learning-scalaz/Tagged+type.html) and it might even turn out to be relatively nice. I'm just allergic to nested for-comprehensions, though, and that could just be me. There's nothing particularly wrong with nested failure monads _a priori_. I just think they're ugly.
oh you are right! sorry about that
I love the writing style. The discussion about type classes is perfect, and it segues well into using typeclass as the underlying point of reference for other functionality. I hope you mention context bounds and variance in there as well. The biggest problem I have with functional programming books is that they're typically long on the theory but light on the actual utility and practicality, especially when it comes to asking app developers to build on top of the feature set. Instead, FP writings seem to be mostly oriented towards library developers, and because they depend on scalaz or cats, they don't teach technique. If anything, they seem to make FP predicated on the use of the library. Added to this is the problem that when they do have examples, they're almost all the same -- JSON parsing, HTTP requests, and maybe JDBC wrappers. I'm actually thrilled when I find something like https://github.com/lancewalton/treelog that does something new and useful. Anyway, thanks for putting something together that isn't focused on the "monad is just a..." classification, it looks great. 
Wouldn't logging things on construction or interpretation be considered a bug in pretty much any logging library? I mean, that's kind of a deal breaker, with or without an IO monad wrapping the operation. And with Scala's strict eval, you have the guarantees of sequential evaluation that you don't get in a lazy language outside of monadic IO. 
&gt; Yeah. So maybe instead of having everything just indiscriminately handle Throwable, or whatever, establish distinct hierarchies that are implemented by subtyping Throwable (because that's what Task uses to model failure), but are otherwise disjoint. You could enforce that at function boundaries with tagged types and it might even turn out to be relatively nice. I don't see a nice way to do it? They don't exist at runtime, and all `Task`s may contain system-level failures. You could use `Task` and `Task @@ MightContainApplicationLevelFailure` but then you'd have to explicitly convert between them and define map/flatMap/etc. (because tagged types are not subtypes at compile time any more, AIUI) and at that point I don't think it's any simpler than using a monad transformer. &gt; I'm just allergic to nested for-comprehensions, though, and that could just be me. There's nothing particularly wrong with nested failure monads a priori. I just think they're ugly. They're ugly sure, but I think it's the same tradeoff as the decision to use a monad/for comprehension at all.
When you're doing pure FP it is commonly the case that your program is a piece of data that is constructed/manipulated and then interpreted into a runnable form, and finally executed at some later time. You usually want to introducing logging in the first stage, to be performed later. So it needs to be pure data.
I agree with Paul here. Logging is not program output. If it was, it wouldn't be logging, it'd be IO. I'd argue most people don't write tests to ensure their logging is working properly. :) 
Thank you so much. this book was highly needed.
I understand that, and I want to emphasize that I'm not worried about the edge-case regressions. But something like java 8 lambdas replacing generated classes should yield valuable information about the future bulk of scala code. Functions and SAM interfaces aren't going away, so any measurement- good, bad, no result- is valuable information. It's also unlikely to improve significantly in a point release if the approach is less effective.
OK, if we're talking about sequencing, let me put it this way: do you care to make sure that you call `log.debug("blah")` _after_ you complete operation `blah`? Then your program _does_ care about the 'result' of the log operation--because it doesn't want that result to be evaluated before the corresponding `blah` operation. In that sense, logging is not RT.
Been working through this one, and I highly recommend it because of its exercises. I really liked LYAHFGG when I was reading it, but a lot of the concepts didn't stick to well after reading them. I personally am not as huge of a fan of Haskell Programming from First Principles as everyone else because it takes *wayyy* too long to work through after reading LYAHFGG - however, I think that book goes in to a lot more depth of each subject covered, so I'll have to revist it at some point. I feel like FPiS hits the sweet spot where it gives just enough exposition to get through the topics and gives easy but meaningful exercises to make sure all the concepts stick. However, I haven't yet finished it (so maybe it loses steam when it gets to IO - as many books on FP do - I just haven't got there yet). Also, it claims no need for a prior knowledge of Scala (which may be true), but I do think you should get another resource for learning other parts of the languages (of which I still know very little). I'll take a look at the this book by /u/denisftw right after I finish. It looks to be a good continuation of "now that you have the theory under your belt, what can you do with it?".
&gt; In that sense, logging is not RT. That is the important point. Everything is a side effect in a broader definition. But more narrow, there are side effects we care about and we don't. E.g. we don't care about something written into the RAM at a certain position - even though it could lead to OutOfMemoryException or could influence part of the programs (i.e. rowhammer attack). But logging does not fall into this category in most of the cases. We actually care when and how it happens. Thus, it is a side effect both in the wider *and* the more narrow definition.
The scarlet book is one of the best programming books I've read, but I still had a hard time applying the divine knowledge it holds. I'm not saying this is something Runar should have done differently, but there's definitely a need for another scala book like this one to complement it, especially wrt how typeclasses, implicits and similar concepts work.
Yeah, you're right that some details are missing, but my intention was to write a book that could be easily read from cover to cover by people with about 3-6 months of Scala experience. As for the difference between `Task.apply` and `Task.delay`, I'll definitely add it, thanks for the suggestion :) Talking of the last chapters, I'm using real world libraries more as model examples than something a reader should implement. Here, doobie shows how free monads can be used by library designers. Therefore, natural transformations are mentioned in the Cats chapter in the Free monads subsection. By the way, this idea is the primary reason why I depend on a custom-built version of doobie developed against Cats and FS2 as opposed to ScalaZ. 
My intention was actually the opposite :) The thing is the theory is hard, no questions about that. But using it is easy, and if you've already seen this stuff in action, you will appreciate the theory even more. Rob Norris said about doobie that "it just works" and I agree. Similarly, you don't need to know Shapeless to use Circe and its generic codec derivation. So, FSiS is a very serious book and if you get through it, you will probably read mine in a couple of hours and start wondering what's so advanced about this stuff and what's the point. My estimation is that an average Scala developer will learn all the content presented in my book in a month of googling, reading Stackoverflow and blogposts, watching presentations etc. But now they don't need to because everything is in one book, which can be read in a day.
any idea how to do it ?
As a longtime Eclipse user, and someone who prefers Eclipse to IntelliJ, this is sad news, but understandable. VS Code is ok, and cross-platform, but it's basically "just" an editor. Whatever foundation you choose, I hope you build something that's a "real IDE", like Eclipse is. I'd like debugger support, integration with Maven and SBT, good JS support (and debugging, if possible), and "real", intelligent completions and code templates, not just prefix-matching. The current ScalaIDE isn't perfect, but I use it full-time every day, and it's pretty good. If switching to VSCode would mean dropping any of the current functionality, I probably would not use the new version.
&gt; the book concentrates on exploring popular libraries such as ScalaZ, Cats, Monocle, Circe, Monix, Shapeless, doobie, http4s, Finch etc I would have killed for this book 6-9 months ago. It definitely fills an unmet need; thank you very much, OP.
It looks like it would fit right in as an Ingress badge.
I'm having a lot of frustration trying to run all my tests - while excluding a specific tag. Here is what I am trying to run: testOnly -- -l "com.my.project.path.tags.ValidationTest" I just read that `testOnly` is used in the new version of `sbt` and not `test-only`. I've tried this syntax (and many variations), and nothing seems to work. I have my tests set up like this: "some method" should "fail when doing something" taggedAs ValidationTest in { ... } EDIT 2: Still haven't figured this one out.
Try `case class Cont[R, A](run: (A =&gt; R) =&gt; R)` instead.
Better yet, compose the `DBIOAction`s and only call `.run` once, at "the end of the world," and `whenReady` that.
ScalaTest 3 has newer ways of working with futures: http://www.scalatest.org/user_guide/async_testing
Why the curls? 
Would be very helpful if you added syntax highlights to your snippets. 
If you're stepping through, that probably gives the async write enough time to happen before you get to the read.
 trait Cont[A] { def run[R](c: A =&gt; R): R }
My point is, it _should not_ be in there (at any given point in time after the constraint is in place ;)), as that is violating a sql constraint. Is that because of h2? Also, when wrapped in `whenReady`, it works all the time, because thats the use of `whenReady`. I should just also wait for the insert as well to make sure test data is there before asserting anything. But again, there are two problems: 1) sql constraint always violated 2) test data not always inserted before assertion (that one I will hopefully be able to use with wrapping this. I tried with `whenReady` on that as well, yesterday, but no luck... so it didn't block for a `DBIO[Unit]`)
Thanks for your concerns but I'm not sure if this case is similar to earlier ones. As I said [here](https://www.reddit.com/r/scala/comments/52w7n8/future_of_scala_ide_would_you_like_to_see_an/d7nvqfv), their entire product is open source and they build on this fact. What you say about freeware is simply not true, their build is open source too.
H2 is generally pretty good. I don't know much about slick, but can you look at your H2 and see what table definitions and data you've got there? I think it's a lot more likely that you are somehow not getting the foreign key constraints set up on the tables than that H2 is somehow failing to enforce them.
I can if I set it to be a persisted to a file. Will do that in the evening
You should be really using watches to invalidate the cache. Use true here and learn to listen to the messages from zk: https://github.com/astonbitecode/scakka-zoo-cache/blob/master/src/main/scala/com/github/astonbitecode/zoocache/CacheUpdaterActor.scala#L77
Another possibility is that you aren't using a connection pool, Slick is opening and closing connections to an in-memory H2 DB that is destroying the DB when the connection is closed, and that, plus the fact that you're running a bunch of `DBIO`s in parallel non-deterministically, is causing your woes. I would make sure that each test case has exactly one `.run` and use ScalaTest's [Asynchronous testing](http://www.scalatest.org/user_guide/async_testing) support first, then make sure you're using a connection pool. If that still doesn't fix things, consider a disk-based DB. **Update:** In other words, be sure you've read and understood [this](http://www.h2database.com/html/features.html#in_memory_databases).
Do you guys create values classes for most Ids when defining case classes for database schemas? I mean, the `id` column from the table `users` is not really a number , doing arithmetic operations on it doesn't really make sense , and you can't really compare it the `id` column from the `messages` table since they are totally unrelated. Making value classes as UsersId and MessagesId makes sense to me, since besides type safety it also makes it easier to understand relations between the tables ( like how `messages` table could have a column with a type UserId, it becomes immediately obvious that you can join the users table to it.) On the other hand i'm wondering if it's worth it, because it does add some overhead, and makes it's less obvious that it's a simple Int in reality, and i'm not sure if the advantages listed above really apply in real life, or just in theory.
Using Monadic composition is usually fine until you start mixing monads. If you return a Try from your insert, and an Option from your select, you're gonna have a bad time. The usual response from those that like to stay as functional as possible is to use monad transformers, which is a huge kludge IMO. I much prefer handling responses using Async/Await, which allows you to break out of the monad and handle responses using normal control flow constructs...but it has its own drawbacks, the biggest of which is that Slick doesn't really have a way to manage transactions outside of monad-composed queries. 
Yeah. I'm on the record as preferring [`Eff`](https://github.com/atnos-org/eff-scalaz) to monad transformers, for this reason among others. Personally, I'd probably take the shortest path and lift the `Future`s, `Option`s, etc. into `Task`, but that introduces a new dependency, and if I'm going to talk to a relational DB with `Task`, I'll just use [Doobie](https://tpolecat.github.io/doobie-0.3.0/00-index.html) anyway. :-)
I've been evaluating doobie, and it certainly looks nice. How exactly do you lift all of your `Future`s and `Option`s into `Task`? How about `Try`?
I am sorry, I am not sure I fully understand what you're suggesting. I am setting up the db in a `before {` block, so I assume for each test my constraints and the schema in general is in place. I also already use: `;DB_CLOSE_DELAY=-1`
I am sorry to ask so much stupid questions, but wouldn't `db.run(DBIO.seq(nodes.insert(Node(), nodes.insert(Node(),...))` also suffice? I am asking for: what does the for-comprehension with yield give me, that a `db.run(DBIO.seq` would not? Because I am using that as well and still sometimes the tests fail. Does `yield` block differently? Basically, would: val setup = DBIO.seq( nodes.insert(Node), nodes.insert(Node), edges.insert(Edge(-1337L, 666L)), edges.insert(Edge(0,1)) ) whenReady(db.run(setup)) { val result = db.run(nodes.tableQuery.result).futureValue result shouldBe a [Seq[_]] result.distinct.length shouldEqual 2 result(0).id should not equal result(1).id } always work? Here I definitely tell it to wait for de insert. Although thats a Future[Unit] it should wait because of the `whenReady` right? Then in there I can use `futureValue` instead of `whenReady` for the actual assertion. Yes? Because that way I could structure my tests a bit more. (I like that "Given, When, Then" -&gt; Given is input, When is insert action, Then is querying + assertions)
Yeah, as far as I know, `DBIO.seq` should also work here. If you have a sample project that's small enough and doesn't contain anything proprietary, why not post it somewhere so we can help with it? Better yet, can you just paste the whole thing into [scastie](http://scastie.org/)?
One last question. Judging from your blog, you put much thought in the "expected vs. unexpected failure" subject. This is where I'm stuck at the moment, on a very fine-grained level. I implemented the `retrieve` method of the service as you suggested. Trying to retrieve a product that does not exist is not an unexpected error (although the method name *find* would probably be more suitable). But I'm not sure about the semantics of the `update` and `remove` method. Imagine you want to update or remove something that does not exist. Is that an expected or unexpected error? Or in other words, should the `update` method return... * a `Future[Option[Product]]` - in case the element to update does not exist, the `Future` contains `None`, if it exists and was successfully updated, it contains `Some(updatedProduct)`, * or a Future[Product] - in case the element to update does not exist, the `Future` fails with something like an `ProductNotFoundException`, if it exists, the Future contains the updated `Product`. Similarly, should `remove` return `Future[Option[Unit]]` or a `Future[Unit]` that can fail with a `ProductNotFoundException`? You may ask why I think there is a difference between `retrieve` and `update`/`remove`. To be honest, I don't know. Maybe because `None` representing a missing `Product` (in case of `retrieve`) is easy to understand, but `None` representing a failed `update`/`remove` not so much. What do you think? 
Thanks for all your work on getting this (back) into the language! I know some people don't get the niceness of trailing commas, but I write a lot of code in Scala where I have to toggle items on and off interactively and this saves me from tons of comma juggling.
Yes, it is just going to take a little time to put them together.
This is again a surprisingly tough question to answer head-on, because there are a bunch of assumptions behind the scenes. The short answer is that you don't know what happens when you ask a service for something, you're giving it a command in the Command Query Separation sense. It might work, or it might not, and you have to deal with it. If you can return a Future[UpdateResult] where UpdateResult is a sealed trait, and the result is Work vs NotFound vs InconsistentState then you can deal with that failure more accurately. It's generally good if you can just hand back the ID rather than the entire state of the product, because then you're not querying the system at the same time you're giving a command. Handling failure and establishing consistency used to be a bit of a problem in databases, but ACID transactions gave some kind of consistency that allowed CRUD, with the option of optimistic locking. This goes away when you look at microservices, and ["data on the outside vs data on the inside"](https://blog.acolyer.org/2016/09/13/data-on-the-outside-versus-data-on-the-inside/). You're working with eventually consistent data that doesn't always match up in time and space, and so it's harder to get to a question of what's actually going on. The point is that whenever you're issuing a command, you need to deal with the possible results of the command -- those are expected failures, because they can and will happen even if you've done everything right, and there are fallback positions. This is distinguished from unexpected failures like timeouts, which can happen anywhere and can be much harder to recover from.
&gt; I want to create this small library to get to know ... Slick better. Well there's your first problem. "Doctor, it hurts when I use Slick" "Maybe stop doing that?"
&gt; Answered on StackOverflow. I didn't understand it but I found an example from github , it seems it is working now :) thank you 
&gt; Looks good in my ide but then the compiler moans that it expects invariant type instead of covariant type... yes, that's what I wanted, I want covariance here. Can you give a standalone example of the code and the actual error that results?
I personally do this lifting explicitly. There is more code, but I also find its clearer for both myself and the people reading it. People on our team are however starting to use `Eff` (Eric's implementation of it), but it still needs some work in regards to syntax sugar for it to be seamless to use (or so I have heard)
`DBIO.seq` should work (and indeed is better, since it can potentially be more parallel than `for`/`yield`). A good way to detect the gotchas is to always build with `-Ywarn-value-discard -Xfatal-warnings`, and look for any unused variables.
It's nothing super secret, but it's not pretty either. I will once I am home :)
The initial PR (https://github.com/scala/scala/pull/5245/files#diff-e059ce64777235990044f1624042e5d0) is only 16 lines, if you exclude docs, spec and test changes, so I don't expect the final PR to be too much more than that.
That's one of my worries gone at least. I don't really understand the concerns that people were having with HLists instead of tuples, as I've not really ever dealt with HLists, but that didn't stop me from being worried about it.
Is it possible to get a quick look at the projects and particular use-cases that you have problems with? I could connect you with the developers of the Scala Plugin at JetBrains and perhaps they could fix it. Its hard to fix something that you don't know it doesn't work.
mostly focused on intermediate/advanced Scala, nothing about jobs
I just copy-pasted the code from OP (which had them) and changed it
I tried doing this: testOnly * -- -l "com.my.project.path.tags.ValidationTest" Because I want to run *all* tests, except the ones marked with `ValidationTest`.
`testOnly` is a sbt command for only running a given test name, `-- and -l` are arguments to ScalaTest. &gt; inspect testOnly [info] Input task: Unit [info] Description: [info] Executes the tests provided as arguments or all tests if no arguments are provided. The test names you pass into testOnly come from the `definedTestNames` where sbt asks all of the test frameworks for a list of tests they find in the project. ScalaTest in this case reports back the name of the classes your test are contained in: &gt; inspect definedTestNames [info] Task: scala.collection.Seq[java.lang.String] [info] Description: [info] Provides the set of defined test names. &gt; show test:definedTestNames [info] List(com.mycompany.MyTest1, com.company.MyTest2)
Thanks again for your input
Thanks for the answer. I think there must be a misunderstanding here, VSC binary downloads are in fact proprietary as far as I can tell. See the wiki article: https://en.wikipedia.org/wiki/Visual_Studio_Code The article links to this page, which seems valid, too: https://code.visualstudio.com/license It would be an appealing thought that Microsoft would not do anything that would not please the community, but my opinion is that this, unfortunately, it's not the case, and they will (if the product will become popular at all). No technical limitation forbids mixing Electron with windows-only technologies, or aggressive spying (sorry, analysing and doing telemetrics). It's only ethical. And Windows is as far from ethical as possible. Speaking aside, I currently live in Russia, and some people think they don't hesitate to bribe the government here. For example, how would you like a formal constraint on office suites that are used in schools: an office suite archive used in school should not be less that 350 Megabytes in size. Sounds stupid, right? Well, it's reality here, as I've heard from many different sources back when I was a math teacher myself (about 8 years ago). Do you also like "Secure boot"? My opinion is that this company takes as much as the majority would allow giving, and does right about what the majority would allow to. And that's awfully too much, I just can't be ignorant of the consequences. Sorry for being harsh, I tried to restrict all emotions to last paragraph only..
Is there ever a reason not to use `final` on a `val` in an `object`? In other words object Foo { final val bar = 1 // vs val baz = 1 } The object can't be overridden so there shouldn't be any semantic difference between the two except that declaring the `val` as `final` allows it to be use in annotations without `annotation argument needs to be a constant` error. If this is the case, why is it so rare^1 to see `final`? 1 - Disclaimer: My personal observation, may not be correct. Certainly haven't seen everything. 
&gt; show test:definedTestNames Ok that's, cool, so I run that, and I can see what ScalaTest returns to sbt. But still, how do I filter out the "ValidationTest"s? I don't know if this helps, but the following (with package names changed) is in my `build.sbt` file: lazy val testProperties = Seq( scalacOptions in Test ++= Seq("-Yrangepos"), testOptions in LocalTest := Seq( Tests.Argument("-l", "\"com.my.company.tags.DbTest com.my.company.tags.LoadTest " + "com.my.company.tags.DbTest com.my.company.tags.IntegrationTest " + "com.my.company.tags.DbTest com.my.company.tags.ValidationTest " + "com.my.company.tags.DbTest com.my.company.tags.DbTest\"")) The `testProperties` is used in our common settings. lazy val `my-api` = (project in file("my-api")) .settings(commonSettings: _*) .dependsOn(`common-test` % "test-&gt;test") .dependsOn(common) .configs(LocalTest) .settings(inConfig(LocalTest)(Defaults.testTasks) : _*)
you can use scalac option `"-Yno-adapted-args"`.
Check your credentials -- you could be creating that table under a different MySQL schema than you think.
To start from the beginning: [FPiS](https://www.manning.com/books/functional-programming-in-scala), written by one of the primary contributers to scalaz. Even though scalaz isn't mentioned by name you basically end up implementing a large part of scalaz by the end of the book. For a headfirst dive try [Learning Scalaz](http://eed3si9n.com/learning-scalaz/).
Second what /u/Milyardo said, definitely FPiS. You may also want to follow folks on twitter who contribute to Scalaz and/or check out #Scalaz on IRC (freenode) if you have questions, there's a REPL in the chat. Also, ask stuff here. :) 
Is your h2 instance in memory? In that case, it could be a new database every time.
In addition to what others have said you could also learn about the typeclassopedia and its implementation in Scala. I started a small project that implemented some of the basic typeclasses which you might find useful - https://github.com/channingwalton/typeclassopedia
 In java, `final static` fields[1] with concrete values will be inlined - the problem with inlining that it mustn't be changed because it can cause binary compatibility issues. [1] In Scala, a member in object will be `static` and every `val` will be compiled to `def`.
If you don't get an answer I suggest you try again with a *minimal* example (with no dependencies) that demonstrates the problem.
I still like this approach, one question though. In another comment, you mentioned that you aren't a fan of pattern matching exceptions (e.g. those embedded in `Task` or `Future`) in order to distinguish them. But what's the difference when using `MyErrorType`, I still need to pattern match it, or am I wrong? Is it the missing exhaustive check by the compiler that doesn't work in the first case?
Interesting. I hadn't thought about that. So if you're writing an application rather than a library, and binary comparability isn't a concern, there's no reason not to. Thanks. 
Honestly... Is this a pain that merited solving, IYHO? If we're not arguing the obvious relative improvement this feature has over not having it, would this even be near the top of the list of pain points you'd like addressed?
I actually had to use ListT with Task today. Here was my PoC gist if it helps anyone else with these. It also shows you can use liftM on an instance of your inner monad so you don't actually need lists of everything. [Gist](https://gist.github.com/kraigmckernan/09dfad4b58a83a5e38c66b6ccbe8b006)
Huh, I never thought of that as a consequence. I remember wanting that when using shapeless.
To answer my own question and add to what /u/idobai mentioned, see https://github.com/sbt/sbt/issues/1543 for issues with inlining `final val` and its impact in incremental compilation in SBT
Does anyone know how to access a private variable in a parent class within nested function literals/anonymous functions? For example, I have some code [here](https://gist.github.com/MRuth/1207c685fbf081753dd5f18a3602be53) that is a controller class that has FXML elements injected into it at runtime. on line 14 I declare a private variable tblSongData and bind it to a table view. In my initialize method, I am trying to disable the column reordering by adding a function literal to a few of the property listeners. On line 31 I need to access this tblSongData variable to bind a separate function literal to a different property listener, however on execution the variable being accessed in the function is null. If I change the scope of the variable in the parent class to protected, everything works. It is only when the variable is marked as private that I get an error. Any advice/help would be awesome!
Hi, answered at stackoverflow, scalafiddle here: https://scalafiddle.io/sf/FrjJz75/0
What compile units? If you mean packages(or something like that) then I don't think you can measure it without a plugin.
It's definitely not at the top of my list of pain points I'd like to see addressed. However, it is very close to the top (if not #1) of a different list: the one ranked by the ratio (how much I want it be addressed) / (how hard it is to fix it, and without breaking backwards compat).
Hi, I added another answer (VeriTi @ SO). It seems to do what you want, with syntax shown at your example.
Constructing of a transaction looks about as complicated as I expected, given their very clear warning at the start. On a side note, I've been hodling for years, since the term "hodling" came into being. [My, those were the days...](http://bitcoincharts.com/charts/bitstampUSD#rg180zczsg2013-08-01zeg2014-08-01ztgSza1gSMAzm1g8za2gEMAzm2g20zv)
IntelliJ can't handle that sort of patter match. I've run into the same problem when writing natural transformations.
Glad my disclaimer was clear as day :) You're correct that 'hodling' isn't new with BIP65. I like to refer to OP_CLTV as a "OP_HODL" simply because it is impossible to spend the bitcoins until the time-lock has been reached. For those reading wondering why we're typoing the word "hold" -- [it's a bitcoin meme](https://bitcointalk.org/index.php?topic=375643.0). :)
It's really a good choice of alias, all things considered.
I guess it's files. Things which compiler compiles. Measure how long did `X.scala` take to compile. I dont mind plugin, hence the question, if there is a way.
Thanks for your concerns and moving attention to this topic. I think that using vscode is a good technical decision because the proprietary license only applies to the vscode product, not the source code. If Microsoft is doing anything that doesn't please us in future, we can in fact distribute our own product, we can even fork the source code. The Scala IDE team did already provide own products for Eclipse, we could do the same for vscode. Forking the source code would not be in our interest but since it is licensed under MIT I'm not worried that this becomes necessary.
Good job description except for the "competitive salary". That doesn't mean anything wrt San Francisco. Competitive with a startup or with Google/Facebook/OtherBigCo?
OK, thanks for the answer and best luck with the project!
you could create a public template if that's fine for you https://www.lightbend.com/activator/templates
Looks really cool!
I would recommend a library out of principle. Templates are essentially automated copy-paste and have all the problems of copy-pasted code (duplication, subtle differences, not all versions being kept up to date...). I'd create a maven parent pom with all the dependencies (I assume SBT has some similar functionality), and try to set up a library so that the "skeleton" project can be a one-liner or close to it and you don't need a template. Scala has very powerful abstraction facilities, so there's no reason you couldn't write a library function that e.g. supplies a complete set of CRUD routes (as http4s) for a given case class. If you reach a case where you really can't factor out the common pattern then that's the time to start considering code generation/templates/etc., but most of the time you can. Edit: to be clear I'd also configure plugins / compiler arguments / etc. via the parent pom.
At Verizon Labs, we use [giter8](http://www.foundweekends.org/giter8/). [/u/m50d](https://www.reddit.com/r/scala/comments/54hq12/skeleton_code_as_a_library_or_a_template_you_fork/d82gkn3) has some good points well worth reading. Let me explain some steps we've taken to mitigate some of the issues: * We use a custom sbt plugin to reject dependencies outside defined version ranges. This is probably the least reproducible aspect of our approach. * Our templates not only provide some predefined dependencies, they provide working purely-functional microservice code, the point of which is to teach APIs and best practices by example. Using [knobs](https://github.com/Verizon/knobs) for configuration; [http4s](http://http4s.org/) for routing and service definition, [Argonaut](http://argonaut.io) for request/response (de)serialization; [Kleisli](http://eed3si9n.com/learning-scalaz/Composing+monadic+functions.html) in scalaz for writing handlers that _eventually_ take an `ApplicationConfig` object and return a `Task` that will _eventually_ return a result... it's all in there to be elaborated. * You can use [sbt-updates](https://github.com/knutwalker/sbt-updates) to be informed of available (Maven-style) dependency updates. * [sbt dependency-graph](https://github.com/jrudolph/sbt-dependency-graph) is indispensable, especially coupled with recent sbt's eviction warnings. You can fairly easily track down what's bringing in what and, if necessary, adjust versions accordingly or add appropriate exclusions. * We also integrate some other really useful stuff, like [wartremover](https://github.com/puffnfresh/wartremover) and [scoverage](https://github.com/scoverage/sbt-scoverage), that's more YMMV. Our default compilation arguments are also pretty restrictive: warnings are errors, etc. On the other hand, we enable pretty much all of the language features, because we use pretty much all of them. To me, the key things about our templates are the purely-FP stack, the architectural best-practices, and wartremover and the restrictive compilation settings. The emphasis is on making the right thing the easy thing, and helping the compiler tell you when you've wandered onto thin ice anyway. :-)
That's what I came to say. OP: it's really easy to do. All you have to do beyond the normal work of the project is create a metadata file. This page shows you how: http://www.lightbend.com/activator/template/contribute
Sad. :(
This is an experimental mixing up of our usual weekly discussion threads, since a few weeks back some people were asking about making the weekly discussion threads bi-weekly or monthly. I thought we would try alternating 1 week of discussion, 1 week of show-off threads, and see how it goes.
&gt; create a maven parent pom with all the dependencies I've had trouble with this in the past and ultimately concluded parent poms were better suited for consistent build rules rather than consistent dependency management. Or maybe less "trouble" and more "persistent annoyances". For instance, when you need to update a dependency you have to update the parent pom and then go update all of the child poms anyway so they have a new parent. You could just update the children directly and be done. To avoid needing to update both parents and children I've seen people try using only a snapshot parent (and consequently not use the maven release plugin), or use version ranges in parent poms, but both of those lead to non-reproducible builds because dependencies are recalculated and not fixed. I've seen children evolve to the point where they need a dependency incompatible with one from the parent pom, and then the children start overriding versions and doing special things, leading to a complicated mix of shared and special cases. Or someone updates the parent and breaks other children because they're forcing their special needs on everyone. All in all I've found it much simpler and consistent and reliable to let each runnable artifact specify and manage its dependencies in full. You get reproducible builds and changes meant for one purpose don't implicitly propagate so you don't even have to consider breaking other builds. I've found the benefit of identical dependencies across artifacts doesn't outweigh its costs. I'm curious if you have a method for avoiding some of those issues while still getting shared dependencies.
&gt; We use a custom sbt plugin to reject dependencies outside defined version ranges. This is probably the least reproducible aspect of our approach. We do something similar at work. But instead of rejecting versions we keep all the dependencies in a sbt plugin and always use stuff from there (also kinda forces everyone to update their stuff sooner or later). So you just write 'package-name' instead of the `"org" % "package" % "version"` in build.sbt
Like [this](http://www.foundweekends.org/giter8/testing.html).
Thanks paul. So how do you integrate upstream changes in util code? One of the issues we have with our current 'util' library, is around versioning, and I'm not sure how to solve it. Lets say I have projects A B and C using this util library Z. Inside Z, it provides functions on top of scalaz and maybe some argonaut helpers too. Inside A, B, and C, do we include scalaz and argonaut manually? Or do we rely on the fact that util has it, and we get it through them? 
We've run into more issues including dependencies explicitly that are also brought in transitively than bringing them in transitively... but I can't say that's a straightforward answer, as we definitely have had to figure out where some dependencies come from and either make our peace with using whatever version of the depending library uses the transitive dependency we need, using "excludes" to exclude that version in favor of another one, or—absolute worst case—fork a third-party dependency, revise it to work with a different version of a dependency we also require, and maintain that fork. One example of that last is what prompted me to comment that "private forks are the payday loan offices of technical debt." :-)
I'm currently working on adding ECMAScript 2015 module support in Scala.js. See wip at https://github.com/scala-js/scala-js/pull/2572 Currently, it compiles down to Node.js modules exclusively, but eventually this will allow Scala.js to produce ES2015 modules which can then consumed from Webpack, Rollup, etc. Basically this will provide better integration between Scala.js and JavaScript ecosystems.
1. Learning Scala is the easiest with [Scala for the Impatient](https://www.amazon.com/Scala-Impatient-Cay-S-Horstmann/dp/0321774094) - most people I've introduced to Scala liked it. 2. To get deeper into Scala: [Programming in Scala 3rd Edition](http://www.artima.com/shop/programming_in_scala_3ed) - I've read the 1st version and it was a nice way to extends my knowledge. 3. Checkout the [strategic scala style](http://www.lihaoyi.com/post/StrategicScalaStylePrincipleofLeastPower.html) and the [scalazzi safe scala subset](https://imgur.com/a04WoHn) to learn about the safe and effective usage of Scala. 4. Try [IntelliJ Idea Community Edition](https://www.jetbrains.com/idea/download/) with the "Scala" recommended plugin or try [ensime](http://ensime.github.io/) with [one of your favourite text editor](http://ensime.github.io/editors/). 5. [Befriend SBT](http://www.scala-sbt.org/0.13/docs/Getting-Started.html), the build tool - activator is a wrapper around SBT supporting [play! framework](https://www.playframework.com/) and tutorial templates. 6. Try [play! framework](https://www.playframework.com/) as a MVC framework - it's fast, easy and widely used amongst the Scala community. 7. Learn [quill](http://getquill.io/) or [slick](http://slick.lightbend.com/) to communicate with your database while exploiting Scala's functional/typesafe/macro capabilities. 8. Keep in touch with the community by r/scala, [freenode/scala](irc://irc.freenode.net/scala), [gitter/scala](https://gitter.im/scala/scala) and on other gitter rooms. 9. Embrace the functional concurrency - we've [FP](https://en.wikipedia.org/wiki/Functional_programming) and we've [referential transparency](https://en.wikipedia.org/wiki/Referential_transparency) - therefore we can use Scala's non-blocking concurrency units easily - the [Futures](http://docs.scala-lang.org/overviews/core/futures.html). There is also [monix](https://monix.io/) - a new tool for asynchronous programming, [scala-async](https://github.com/scala/async) for the async/await model and [Akka](http://akka.io/), an actor-based toolkit as the JVM's No1 distributed messaging API. 10. One of Scala's biggest selling point is Big Data and Statistics - [apache spark](http://spark.apache.org/) is written in Scala and it's one of the fastest cluster computing tool around. 11. Scala is a multi-platform tool and it's present on the JVM and on js too by [scala.js](http://www.scala-js.org/) - you can write your scripts for browsers, use react/angular/etc. and run it on node.js. It's also coming to native by [scala-native](https://github.com/scala-native/scala-native)([LLVM-based](http://llvm.org/)).
With Play, there's a couple of places to start to get examples up and running quickly: * https://www.playframework.com/documentation/2.5.x/Tutorials * http://developer.lightbend.com/guides/play-rest-api/
Thanks, I will look at it for sure 
I started with PHP and Wordpress, but that was a looooong time ago. I write in several languages now, but I really like Scala. I'd use it for work if I could.
Other answers have done a good job with scala-specific advice, but let me add a few small points re: moving from PHP to the JVM. This may be very obvious to you, but as someone who once upon a time went from PHP to Java, there are some particulars about working with PHP vs a JVM-based language that took some getting used to. I'll try my best to outline them here for you just in case it is helpful. # Application Runtime Environment ##PHP In PHP, your code is **interpreted** by another program. Thus, the process that is actually running is `php` (or, perhaps, `php-fpm`) and your code is dynamically read and executed at runtime. This interpreter program has its own configuration (`php.ini`), its own logging, etc. separate from that of your application. This means that the actual OS-level process running your code references this interpreter program rather than your application itself. It also means the interpreter program is compiled for individual platforms and is responsible for making sure your code runs properly on each - for the most part, as PHP does have a few Windows vs Linux gotchas. ## Java VirtualMachine (JVM) JVM languages are actually quite similar. Your application is run inside the JVM which, much like PHP, means that the actual running process is that of the JVM executable itself. The JVM also has its own configuration options (often passed as command line arguments) and will have its own output separate from your application. There are two key differences between the JVM and PHP, however. - JVM languages are compiled vs interpreted - JVM supports multi-threading ### Compiled vs Interpreted This is the obvious one. While the PHP runtime executable and the JVM runtime executable are both responsible for ensuring your applications behaves properly on each platform they support, the JVM achieves this by having all of your application code, regardless of language, compiled into a common machine-code-esque format known as Bytecode. It then can translate this to the appropriate machine code and, generally, provides far better performance than PHP or other interpreted languages. ### Multi-threading This difference is, perhaps, less obvious at first. PHP is not multi-threaded, while the JVM is. Putting aside the details regarding writing thread-safe code in Java, the way this difference manifests itself to a PHP developer is generally in regard to what it means to setup a web-based application in a JVM-based language vs PHP. PHP relies on external programs to provide the various functions required for the web `Request -&gt; Response` lifecycle. In general, a production-ready setup will have some sort of web server (usually Nginx or Apache), some sort of scalable PHP (usually `php-fpm`), and some way of linking the two together, which is, most often the `fast-cgi` protocol. `php-fpm` is the most common method for deploying a web-based PHP application. The `fpm` part stands for **F**ast-cgi **P**rocess **M**anager. The reason this is needed is becuase PHP isn't multithreaded. Instead, we use `php-fpm` to fork some number of PHP processes which stand at the ready, waiting for your web server to tell it the name of a file to interpret and execute. In order to handle 10 requests at the same time, you need 10 separate PHP processes available. Thus, PHP scales at the process level. And, perhaps, more importantly from a development perspective vs operations, **PHP's application lifecycle in the common case (web-based applications) is bound to the http `Request -&gt; Response` cycle**. JVM-based applications have no such restriction. **Unlike with PHP, A single JVM-process running your application can handle many requests simultaneously by utilizing multiple threads within the same process.** # Application as the Server Because of the multi-threaded nature of JVM applications, there are, in general, two ways to achieve a web-based application. - Using the Servlet API and using a Servlet or App Container such as Tomcat, Glassfish, JBoss, etc. to run your code - Having your application be its own server In the past, the former was the default choice. Web-based Java applications were written using servlets and then would be run inside a container of some sort which were often bloated with many different runtime options and vendor-specific features like database pools, etc. Today, however, with the move toward microservices, the approach is generally for your application to act as its own server. Thankfully, you don't have to worry about the finer details of writing an HTTP server! With Scala, we have Play, we have Spray, we have Akka Http, etc. The point being, when you deploy your app, you will run a single instance of it per server (generally speaking) and your web server will simply proxy to the port your app is listening on directly. No need for another middle man such as an application container or (in PHP's case) a process manager. #Issues this creates So, this distinction can make certain things feel awkward vs PHP. - With PHP, we are used to our application living only as long as an individual http request - All connections, all variables, etc. are cleared (some exceptions apply) and are fresh at the beginning of a new request - No worries about one request interfering with another request unless both are trying to access shared resources such as the file system, databases, etc. - If we do want to share data between requests, we need special shared memory extensions, etc. - We can't easily do things like create connection pools within our application code - Standard memoization has potentially limited value - Coordinating access to shared resources can be more difficult - With the JVM, we can write code that is inherently broken in ways that are completely unobvious when not thinking about threads (**note:** In Scala, this will really not be a problem for you) - When code is not thread safe, one common type of bug is when one thread mutates a variable that another thread is reading causing one request to corrupt another - However, this also means we can far more easily (**especially** in Scala!) achieve parallel processing (especially IO) which is often impossible or, at least, very difficult in PHP whereby all operations are generally run serially - This sometimes requires that we re-think how we approach a problem and, often, can result in race conditions that we might not have encountered in PHP - These race conditions can be occasionally disastrous or they can be rather innocuous, like realizing your log output isn't as predictable as you might be used to with PHP applications since things can be ordered quite differently than one might expect at first **tl;dr** Remember that PHP is generally `Request-&gt;Response` based and JVM apps are long-living and multi-threaded 
If you have an option to use a JSON codec other than argonaut, you can use something that doesn't require implicit encoder/decoders. Like Jackson with jackson-module-scala
I really like the "opt-in" rule for function application/ declaration. Is it possible to enforce it through configuration by any chance ?
They mean you don't have to maintain generated source; whatever you want to call it that's an important difference from "traditional" code generation.
if you want to use macros, have a look at this project: https://github.com/codacy/codacy-macros
I've heard these difficult operators were going to be deprecated in 0.13.13 http://www.scala-sbt.org/0.13/docs/sbt-0.13-Tech-Previews.html#Deprecate+old+operators
Oh, thanks. I guess I was stuck on the idea that the build.sbt file is written in plain Scala. Don't know how I came up with this assumption... 
Hi you can check out http://idarlington.github.io/2016/best-resources-for-learning-scala/ where I wrote about the best resources I used in learning Scala (Also coming from PHP)
It means predictable and automatic builds and deployments, provisioning of new instances as needed, etc. You can thus build an "elastic" infrastructure that responds to the needs of the application. For example you could have a cluster that automatically adds or removes nodes in response to load, achieving automatic horizontal scalability. Or in case you have singleton instances that processes stuff and want to keep them online, you could have a process that detects failure and then kills the old node while creating a new one, thus achieving redundancy. You could also think of services like Heroku or Google App Engine, but managed by you on infrastructure that you control.
To be honest I couldn't remember what &lt;+= does off the top of my head, as its usage is rare and it is also deprecated. I only used it like this: unmanagedSourceDirectories in Compile &lt;+= baseDirectory(_.getParentFile / "shared" / "src" / "main" / "scala") And it is like a `+=`, but different probably because the context of this setting is relative to the sub-project you're talking about, or in other words the value exposed by `baseDirectory` is relative, so you need some sort of function instead of a value. As an advice for when you get stuck, the community is very active on Gitter. For example there's an [SBT channel](https://gitter.im/sbt/sbt) with people that know SBT and can help, alongside the more general [Scala channel](https://gitter.im/scala/scala).
Sure, I see the value in that. What I don't see the value in is having an extra layer in between the OS-on-bare-metal (dom0 or whatever your preferred terminology is) and the JVMs. A unix system is already very capable of running a number of JVMs isolated from each other (with their own memory allocations, CPU time quotas etc.). I can see the value that docker adds in the case of e.g. a Python service - Python libraries are often installed system-wide, or at least linked against system-wide DLLs, and Python systems often make use of the native filesystem and/or fork native processes, so if you had two unrelated Python services running on the same dom0 without any container level they might interfere with each other (or might not even be installable at the same time at all, if they depend on different versions of the host libraries). But I don't think that applies to Java where services often don't use any native libraries or touch the native filesystem. Am I missing something?
&gt; With operator overloading it's fairly easy to define DSLs where it looks like something is part of the language when it's not. This is nonsense. How do you define something in the language and have it not be part of the language?
Scala's syntax is very flexible. You can omit the dot in `myobject somemethod()` and even parenthesis! So syntactic constructions that have to be part of the languages in many other languages, can in Scala be implemented as simple regular methods. If you want the syntax `object1 + object2` in Java for example, you need to add this special case in the language reference and the compiler but in scala, you can simply define a method : class Toto { def +(obj : Toto) : Toto = ... } val obj1 : Toto = ... val obj2 : Toto = ... val obj3 : Toto = obj1 + obj2 That's the reason why Scala is so nice to implement embedded domain special languages (EDSL): you can design you classes and their methods to mimic the syntax you want. Yes sbt files are plain scala files and sbt operators are plain scala methods. But sbt operators also forms a specific language with its syntax and semantics. 
Reference: https://stackoverflow.com/questions/39724108/how-to-get-rid-of-this-boiler-plate-code/39724465
&gt; A single JVM-process running your application can handle many requests simultaneously by utilizing multiple threads within the same process. This is not 100% correct and not 100% wrong. However more modern frameworks (not restricted to Scala/Java) use a EventLoop where you can handle multiple requests at once without multiple threads. It mostly uses preemptive multitasking to handle the requests (this is quite different from multiple threads) however it really depends on how it is configured/implemented. You can basically handle all connections with a single thread (but you don't need to). The basic concept is That you have a single event loop (can have multiple threads, but doesn't need to) that accepts all the connections and multiple child event (can have multiple threads, but doesn't need to) loop that handles the request/response. still the less "blocking" your application is the more troughtput you will have, that's why you should use different thread pools for blocking operations so that the event loops can still do work without hanging on a jdbc call etc.. P.S.: it's not 100% described and probably not strictly correct since it goes into detail pretty fast. And basically a lot of implementations are different. but most of the time you have threads for accepting connections that should handle the code as fast as possible and handoff the "real" work to another thread and can then accept new connections while the response for the request that still needs to do work is still ongoing. TL;DR modern architecture is more message driven than thread driven.
So the issue here is there's no such thing as "plain" Scala. I should put these on a flying banner message or something: 1. Scala has _no operators_, only methods. So the place to look for weird "operators" is on the object to the left, unless the "operator" ends with a `:`, in which case look on the object to the right. 2. In Scala, implicits are often used to retroactively add methods to objects that don't have them, so you should be aware of what implicits are in scope any time you see an unfamiliar method that you want to look up. 3. [SymbolHound](http://symbolhound.com/) is your friend. :-) To answer the specific question, `&lt;+=` adds a value to a `Setting` that holds a sequence, and the value depends on the value of some other `Setting`. For example: libraryDependencies &lt;+= sbtVersion("com.github.siasia" %% "xsbt-web-plugin" % _) `sbtVersion` is itself a `Setting` in sbt, so this says, in effect, "add a dependency on the artifact from group com.github.siasia named xsbt-web-plugin of whatever version sbt says it is."
People not familiar with operator overloading look at something like a &lt;+= b and think that the &lt;+= has some special meaning in scala, ie its part of the language (like &lt;= *is* part of the language). It's not part of the language, its part of a library.
Right, you are a troll. Please go away
&gt; Scala's syntax is very flexible. It really isn't more or less flexible than any other language. You have four forms of method invocation. Dot, Infix, Prefix, and Postfix notation. You can't for example invoke methods with RPN. You can't redefine keywords. You can't define new literals. You can't make method invocation right to left. You can't reimplement for-comprehensions. Scala has few language constructs. That's not the same thing as it being flexible. &gt; You can omit the dot in myobject somemethod() and even parenthesis! You did not omit the dot. You just changed from dot notation to postfix. And dropped the parentheses is a part of Universal access(not that you're allowed to drop the parens for nullary methods if using reasonable compiler flags). &gt; But sbt operators also forms a specific language with its syntax and semantics. Identifiers alone don't define a grammar or language. It's operators don't make a DSL. SBT is a DSL because it constrains the type of assignments you make; because it controls effects outside Task definitions; because expressions that should be discarded return a value to SBT. If it weren't for those SBT would just be a build definition with applicative functors.
The first four years of my consulting life were in php. It was an in demanding language which taught me very little bit did give me my first opportunity to earn money for programming. 
Use [Value Classes](http://docs.scala-lang.org/overviews/core/value-classes.html). That way you (almost always) get the best of both worlds.
Let me know if you have any questions about it
You could use a [tagged type](http://eed3si9n.com/learning-scalaz/Tagged+type.html), which allows you to work with labels generically.
Just use case classes. You can extend AnyVal (and make it slightly more performant) if you want. It's not really any more heavyweight, and it adds so much more clarity to the code.
The idea is to alternate -- one week of show-off thread, one week of ask-anything/discussion thread, would you prefer to have both every week? We could try that out in a while too.
I don't need every week per se, I just wanted it to stay at the top just in case I have a question during the second week. For instance, I have a question/thought now, but would be afraid to post it to a no-longer-at-the-top thread for fear of it being missed.
I think Verizon's journal can do this but I'm not sure
Value classes is exactly right. These are classic [value objects](https://en.wikipedia.org/wiki/Value_object).
I've been working on a type-safe and boilerplate-free ORM and query language for Couchbase lite: https://github.com/a-reisberg/typebase-lite It works on both android and the usual jvm.
Nice! That's literally something that I was thinking to myself the other day, 'I hope/wish sjrd gets to work on that'. :-)
Yes, I've read at least one 'Scala is complex' post about how confusing `&lt;=` and `=&gt;` are (don't have the link handy, though). Edit: just found it https://www.reddit.com/r/scala/comments/52d823/list1flatmape1_list2mape2_e1_e2/?st=itnsslpl&amp;sh=9c366528
Have to disagree with you about 'there are no operators', no matter what the language reference says. Whether you call them operators, methods or members, symbols like `+:` in Scala can do something that no other method can: they can be right-associative. They are, functionally, operators.
Associativity is a detail in the application of infix notation, and consistently for all functions. `+:` isn't right associative when using dot notation. This also applies to precedence rules, only applicable as a rule of infix notation.
Yep, this is the only possible flaw that stuck out to me right away too. I think Binding.scala is a good starting point to build an FP client-side web framework on top of it, or at least extend it with FP concepts.
This has the advantage of making sure that the values are never boxed. Value classes (AnyVals) are actually instantiated in [several cases](https://ivanyu.me/blog/2014/12/14/value-classes-in-scala/) However, Value classes have the advantage of allowing you to define custom methods. I don't really like it though, in my opinion data model (ie ADT, traits and case classes) should rarely define inner methods, and typeclasses should be used instead. 
log4j has a programmatic interface, look at e.g. `BasicConfigurator`.
What does the Spring interface offer? If it's callback-based, look at something like https://github.com/mgp/effective-rxjava/blob/master/items/convert-callbacks-to-observable.md . If it's based on events on the UI thread or something then you might have to have a "dispatcher" on the UI thread that just puts events onto (thread-safe) queues, and then have your observables use those queues, or something on those lines.
I've did a quick POC using JavaFX a while back that worked. Should be straightforward porting it to Swing. implicit class ObservableButton(buttonBase: ButtonBase) { def clicks(implicit scheduler: Scheduler): Observable[ActionEvent] = { val subject = PublishSubject[ActionEvent]() buttonBase.setOnAction( new EventHandler[ActionEvent] { override def handle(event: ActionEvent): Unit = subject.onNext(evt).onComplete { case Success(Stop) =&gt; subject.onComplete() case Success(Continue) =&gt; case Failure(ex) =&gt; subject.onError(ex) } } ) subject.share } } Also need to create a custom scheduler for running actions on your UI thread: object schedulers { val JavaFx = Scheduler( new ExecutionContext { override def execute(runnable: Runnable): Unit = Platform.runLater(runnable) override def reportFailure(t: Throwable): Unit = sys.error(t.getMessage()) } ) object Implicits { implicit val JavaFx = schedulers.JavaFx } }
When I posted I was hoping /u/alexelcu would check in and comment on implementation errors. Thanks for the feedback!
I believe it also has hocon configuration
Update: [We successfully spent the coins after the time-lock expired.](https://medium.com/@thomasmccabe/spending-a-time-locked-bitcoin-transaction-651870277d93)
Hi rafamds, I am also a PHP developer who now mostly works with Scala. Most of the answers suggest you to dive into books, but I suggest to do it the other way. I had to create a real time bidding system and wanted to dive into Scala, therefore I chose Akka as my starting point. 1st day of scala and I had a project running and started programming. At first everything looks weird and unusual, but it is fine. I chose Akka, because I had no idea what is actually happening under the hood of multithreading. Hey, even very experienced programmers state that multithreading done right is hard to achieve. My point here is that you can ommit things that you don’t know yet and let the mature toolkits do the hard part for you. You spin an actor and you send a message to it and it just works. However your case can be different and you might want to dive into Play! Framework. Play! Framework under the hood also works on Akka actors which brings great performance for your website. What was hard/strange for me at first: parsing json and understanding all this implicit thing. I just could not believe that there was no json_decode in scala or java (you can use any java library out there in your scala projects - think composer on steroids). I ended up using spray-json for parsing json to case classes - wow who needs classes for simple json structure, right? After a day of struggle I could successfully parse my custom json file - yay, happy days! To understand implicits I suggest first spend some time with language and coding in it until you meet a need of implicit (can happen the very first hour). For whatever problem you face in scala there is one rule I use - never back down. If I backed down when faced json issues - I’d still be doing php.. Search for help - ask people or simply solve the problem on your own. General compiler errors are self-explaining - is it usually easy to solve them. Reading all the links and books that other people recommended is sure worth it, but I still suggest to dive into the code first. There’s a lot about that “immutability thing” - learn it. Mutability in some state is ok, just don’t overuse it like I did: var records: mutable.Map[String, String] is a no-go. Here I have a variable (mutable thingie, like $anything) and a map that can mutate itself - in final we have duplicate mutablity. My first commits in scala are really ugly and it’s ok - you’re coming from a language that has a lot of black magic under the hood, so don’t worry about how readable/maintainable your code is (if you work alone). You will feel joyful when improve a little and start refactoring your code. It is easy as: change code, press run, get compiler errors and smile - compiler just saved you from buggies! And refactoring in scala is fun :-) IDE functionality “find usage in code“ is way different than php - there is no $var = “counter”; ${$var}++; and IDE pretty much actually find all usages in code. Once you get your feet wet with Scala you are likely to get “sucked in”. What I mean is - a year ago if I had to pick my next job it would definitely be a PHP job. Now I only want a scala job (the grass is really greener in scala world). Even though php is very popular, but scala just brings you to the next level. All those tiny bugs where you do a array_map(‘intval’, []) and get an array(0) are gone - compiler always kicks your ass if you forget something and I love this so much - the quality of things you do is way different. Compared to java - you don’t have to do all that variable type declaration everywhere: List&lt;TheIncredibles&gt; = List(new TheIncredible, …) yuck. Scala gives you dynamic world of php + performance and ease of use - just dive into it and I bet you won’t regret. Regarding to question part “how to launch xampp for scala” - it depends. If you want to make a website go for it with Play! Framework. How to get things running: you’ll need unix type console (I hope you’re on Linux os OsX. For win - use cygwin). Lightbend’s Activator is ain’t that evil. What I did was: curl -OL https://downloads.typesafe.com/typesafe-activator/1.3.10/typesafe-activator-1.3.10.zip unzip typesafe-activator-1.3.10.zip cd typesafe-activator-1.3.10/bin ./activator ui (have patience - first time it compiles all scala and stuff, but this won’t happen next time, things will be quick). After this command finished job - you end up in Activator’s localhost. Just pick a template (for example Play! Framework) and ask activator to create if. After it creates it you might want to explore the tutorial or just open this project in your IDE (I suggest Intellij Idea). And here you are - it’s like you did a cake bake app (in cakePhp) - you have a skeleton (minimum version) for your project. Now the other part is not changed - you change code, hit refresh and see what happens. Personally for me to do changes I had to read Play! Framework documentation, but that’s fine. If you don’t want that much magic - you can always try Akka-http, but the thing is that you’ll have to work on rendering on your own (just like plain php). For a quick start with Akka I suggest you open up intellij idea -&gt; create new project -&gt; Choose scala and then SBT. Name it and click Finish. Your IDE will start downloading files, creating folder structure - give it some time (again - first time only per project). After it finished you’ll have a project with .idea/ project/ src/ and target/ folders. In this level (project root) open up a file named build.sbt and add this: val akkaVersion = “2.4.10” libraryDependencies ++= Seq( "com.typesafe.akka" %% "akka-actor" % akkaVersion, "com.typesafe.akka" %% "akka-http-experimental" % akkaVersion ) this includes akka-actor and akka-http in your project. After you paste this you should see a message that “build.sbt was changed” with option to refresh project - hit that. If you don’t see this just close -&gt; open project - the selection will appear. And hey - you got packages fetched, go start using them: open up src/main/scala and create a new file Main with this code: import akka.actor.ActorSystem import akka.http.scaladsl.Http import akka.http.scaladsl.server._ import akka.http.scaladsl.server.Directives._ import akka.stream.ActorMaterializer object Main { def main(args: Array[String]) = { implicit val system = ActorSystem("hello-sunshine") implicit val materializer = ActorMaterializer() val api: Route = { get { path("hi") { parameter("id".as[String]) { getId =&gt; complete(s"Hello, you sent me a GET[id] = $getId") } } } ~ get { path("health") { complete("Alive") } } } Http().bindAndHandle(api, "0.0.0.0", 1337) } } Right click on Main -&gt; Choose Run. After it’s online just go to: 0.0.0.0:1337/health and 0.0.0.0:1337/hi?id=3 Congrats! You’re up and running Scala thingies! Go dive deeper now :) P. S. I still do php and it is ok, but now I really prefer working with Scala. Sorry for my mind waterfall - just wanted to let you know everything I remember about my journey. Shoot me questions if you have them - I don’t promise fast response time, but I will surely help to clear at least some obstacles :-) Welcome to the Scala world and happy programming! P. S. 2 - When you get your feet wet I highly recommend https://medium.com/@cscalfani/so-you-want-to-be-a-functional-programmer-part-1-1f15e387e536 It’s a great series for people coming from our world and can instantly clear some obstacles.
I had thought it might depend on [Knobs](http://verizon.github.io/knobs/), in which case it would support HOCON configuration. But it doesn't, presumably in order to keep dependencies to a minimum. So personally, that's what I'd do: use Knobs to read the configuration, construct the slf4j `Logger` from that, and construct the Journal `Logger` from the slf4j `Logger`, aka `Backend`.
"Append a sequence of values that depend on some `Setting` to a `Setting` that contains a sequence." The general pattern is: `:=` suggests assigning a value (shades of Pascal!), `&lt;` instead of `:` means "extract a value from some other `Setting`(s)," and `+` means "add a single item" and `++` means "append a sequence," just like anywhere else in Scala collections. In other words, there's a definite set of rules to these symbols, just as there is a definite set of rules to Databinder Dispatch's [much-maligned symbols](http://www.flotsam.nl/dispatch-periodic-table.html). The fact that even the "periodic table" doesn't express the symmetries between the `&lt;&lt;` and `&gt;&gt;` type symbols, I think, points to the real issue, which seems to be that a lot of people don't see these lexical patterns, so it's hard to form an intuition around them.
Thanks. Honestly, for my cases, the difficulty is mostly that it's hard for me to find the documentation for this. When I searched SymbolHound for this operator and sbt, this answer that *uses* but doesn't define the operator was the only hit: http://stackoverflow.com/questions/6589067/how-to-fallback-scala-version-for-sbt-dependencies 
I would try to use a package private variable like this: private[packageNameHere] example:String
&gt; It should be quite obvious by now that in Scala you can do pretty much everything you can do in Haskell. Shots fired! That was a sentence best left out, in my estimation.
Oh come on, there is nothing combative there
Because I want to read config file at runtime. And in this case I would kinda have to deal with both HOCON and XML (to generate correct config) and I'm trying to avoid the latter.
Can methods that don't have symbolic names be used infix-style right-associative? If not, there's obviously a difference between symbolic names and alphanumeric names. If it walks like an operator, and if it quacks like an operator, it is an operator--regardless of what the language lawyers say.
Or even better: in Scala, records (i.e. classes) can share field names.
A container is a unit of deployment. It contains your app, as well all the programs and their configuration to support it. Your app is insulated from the actual OS and server it runs on. This is important, because managing what programs (and versions) are installed on each application server is simply unreasonable when you have dozens of app servers and hundreds of microservices being written and deployed by several teams using different languages. 
Just as they can in Haskell with OverloadedRecordFields in GHC8
You're right. I think you can use `tee` to get both though.
But the app is already insulated from the actual OS and server by dint of being a Java app, isn't it? I mean I was part of a team that deployed hundreds of microservices to dozens of app servers four years ago at last.fm, using puppet or fabric or something like that (I forget the tool specifics), and it didn't matter what OS was on the server and which specific servers it was beyond "it's a platform with JVM version x.y installed".
Once you have everything in docker, you can set up a Kubernetes cluster and throw containers into it. Kubernetes dynamically manages replication, load balancing, DNS, and config for all your services. It will also shuffle your containers around hosts, so isolation from the host is critical. The key point is that Scala isn't the only language we use. There's a lot of Go, with some Rust on the horizon, and a lot of infrastructure like Jenkins in docker too. Having everything in containers means your apps can be shuffled around instances trivially, with no prep work needed. 
Yup. I just started using Hasklig with the ligatures, it is _so nice._
I used to work for Godaddy (based in scottsdale) and they have some teams doing scala. 
I know they do. But maybe I was missing some good backend which matches my criteria
I can see that it might make sense to put JVM applications in Docker for consistency. I just don't think it adds anything in an all-JVM shop. 
It's well worth considering these questions. The wishy-washy approcah to comparisons where one carefully avoids claiming any tool is better than any other does nobody any favours. (I disagree with the claim given that Scala lacks kind polymorphism, but I respect the author more for being willing to take a position on the subject, even a wrong one).
What if you have a Map of String -&gt; type, and want to generate a case class? Example: f (Map ( "foo" -&gt; JsString) ) === case class X (foo: String) where X is arbitrary
Scala has kinds at type level ? What's going on here? I'm so confused to what I'm seeing.
I don't know If I can correctly answer your question. Scala has [higher kinded types](https://twitter.github.io/scala_school/advanced-types.html#higher). And you can express kinds using type level programming but I don't think you have kinds at the type level. This video: [High Wizardry in the Land of Scala](https://vimeo.com/28793245) explains it much better. (It is also the proverbial first dose is for free when it comes to type level programming in scala.) PS: [this](https://www.youtube.com/watch?v=GKIfu1WtSz4) could be the second dose.
I really don't understand the `null.asInstanceOf[T]`. Let me try to explain what I want to achieve in a better way. I have a Task class, this class performs some computation, however that computation will only start if all the dependencies (which are also tasks) have a state equal to Finished (this state also stores the result of the task which is of type R). class Task[R](name: String, dependencies: Set[Task[_]]) { def state: State = ??? } I want to create a special Task which creates subtasks, but these subtasks are created using the results of the dependent tasks. For example (in pseudo-code): class SpecialTask[R](name: String, dependencies: Set[Task[_]])(subtaskCreator: /*Something here*/ =&gt; Seq[Task[R]]) extends Task[R](name, dependencies) val a: Task[Int] = ??? val b = new SpecialTask("B"), Set(a))(/*something here with a result*/ =&gt; Seq(new Task[String](...){})) The "trick" here is SpecialTask will only start when its dependencies have finished, so at that time it can extract the result from each dependent task and invoke the subtaskCreator. However having the dependencies has a `Set[Task[_]]` defeats this purpose since all type information is lost. So I would like to have the `dependencies` be an HList, and would also like to restrict the subtaskCreator to only using the results of the tasks declared as dependent. So in pseudo-code something like: val a: Task[Int] = ??? val b: Task[Double] = ??? class SpecialTask[R, L &lt;: HList : *-&gt;*[Task]#λ](name: String, dependencies: L)(subtasksCreator: /*Something*/ =&gt; Seq[Task[R]] new SpecialTask("B", a :: b :: HNil))( /*something*/ =&gt; Seq(new Task[String](...){ /* something that uses the result of a and/or of b */ })) So in this example I'm creating a new special task declaring the tasks `a` and `b` as dependencies, I want to ensure the `subtasksCreator` can only be a function of type `(Int, Double) =&gt; Seq[Task[String])`, or most likely a function of type `shapeless.::[Int,shapeless.::[Double,shapeless.HNil]] =&gt; Seq[Task[String]]`. But if I just declared `a` as the only dependency then subtasksCreator would be a function of type `Int =&gt; Seq[Task[String]]` or `shapeless.::[Double,shapeless.HNil] =&gt; Seq[Task[String]]` PS: even with this big explanation I feel I haven't really explained very well.
Scala might be like high grade LSD, but I looked at the php docs and it was like a salvia bad trip
If you like books: [Scala for the Impatient](https://www.amazon.com/dp/0321774094/) If you like reading online: [Scala School](https://twitter.github.io/scala_school/)
Some tips: 1. Use `scalaHome := Some(file("/path/to/scala/home/"))` to avoid downloading Scala 2. use [coursier](https://github.com/alexarchambault/coursier) to get a faster artifact fetcher 3. download the full [lightbend activator](https://www.lightbend.com/activator/download) to get more dependencies present by default.
I like [Constraints Liberate, Liberties Constrain](https://youtu.be/GqmsQeSzMdw), from Runar Bjarnason (one of the authors of FP in Scala).
&gt; Dick Wall called effective Scala https://www.youtube.com/watch?v=rhXUlPmLLts
https://m.youtube.com/watch?v=XHiTK4UOIf0 (Programs as Values Pure Composable Database Access in Scala) In general each talk from Rob Norris is very useful for learning.
Is it true that the `wrapped` value of the `class` `extend`-ing `AnyVal` must be a sub-type of `AnyVal`? I'm guessing no since you're suggesting wrapping a `String` (per the OP's question) in a value class. The post that you linked notes: &gt; Value classes are a new mechanism in Scala to avoid allocating runtime objects. This is accomplished through the definition of new AnyVal subclasses. So, if I understand correctly, you're recommending the usage of value classes to avoid run-time allocation? *Edit* Can you please elaborate on "almost always?" What happens in the negative case?
I think I've discovered what was causing you the confusion. It was probably this: `*-&gt;*` This is just a type alias https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/hlistconstraints.scala#L43
Not 100% sure, but I think [result from rapture](https://github.com/propensive/rapture/blob/dev/core/shared/src/main/scala/rapture/core/result.scala) is another solution to the same problem. 
watched the talk, and one of the comments where how dotty compares to all of this. got any input on that? what have happened over the past 3 years?
While it looks similar, I am seeing several distinct differences. 1. It doesn't attempt to model itself after scala.util.Try. It is its own new definition of the domain. 2. it uses java.lang.Exception as the root, not Throwable, meaning it cannot be used for any of the java.lang.Error throwable classes or for Throwable itself. 3. It doesn't have any Scaladoc describing the API in more detail and/or giving example usages. 4. Given point 3, I am not seeing how to go about capturing the "enclosing context" if/when the Errata is being generated. It could be there, I am just not able to identify how to find it and use it without spending quite a bit more time trying to tease it out. 5. It doesn't provide a drop-in replacement for scala.util.Try to ease a transition to the Result mechanism. Again, without documentation, I'm not able to easily see if some of my above points are strong, weak or easily implemented with the Result API. 
The o'reilly programming scala book is pretty nice.
You can customize the artifact directories. What CI are you using?
Also, just actually playing with the language does wonders (at least for me). Reading is good, but you have to try things out right away too! So that why I recommend: https://scalafiddle.io/ Ammonite repl is also really good for experimenting. And the best IDE is IntelliJ with the scala plugin btw. Just go "Open", and then locate the `build.sbt` file, and intellij will resolve all dependencies and everything will get nice autocompletions.
This will probably be an unpopular opinion, but I recommend *not* watching that. It's just a little unnecessary negative. Sure we can all just stop making stuff because Scala is isn't perfect (like everything else), or you can actually appreciate being productive in what's probably one of, if not the most, comfortable languages to date. I mean he has a bunch of good points, and he's a super intelligent guy and I appreciate all his contributions, but you're not gonna walk out feeling inspired to go make awesome stuff after his talks - at least that's I feel about it.
All of Li Haoyi's talks always makes me inspired to go make stuff. It's very inspiring and pragmatic. I also recommend his blog - in particular principle of least power
Hello /r/Scala! Perhaps, my question might seem inappropriate, but I've been struggling with this problem for a pretty long time. I'm trying to setup an Android project for Intellij IDEA to be able to start developing in Scala for Android. All tutorials I've found so far turned out outdated and didn't work for me. My android-sdk is currently configured to support Android API 21 up to API 24. Any help or advice strongly appreciated. 
Yeah you don't need to know too much about GDS but it will help you over someone else applying for the position (they might not even ask about it if you haven't worked in gov before). I don't know which agencies sorry, I just know of contractors who work their. There are several companies that hire for positions there, if you know you can get paid more then you must already know some company hiring for it. Or you can be hired into the public sector but generally doesn't pay as well 
&gt; Now, they don't profit from the widely accepted precedences. Why would that be? &gt; What is your personal opinion? Would that be a nice enhancement for (e.g.) scala-dotty or is it something for the kitchen sink? Definitely kitchen-sink. The current rules are simple, easy to understand and don't require that a reader investigates the definition of a symbolic method to figure out its precedence. I couldn't care less about the needs of people who want to do fancy stuff with operators, indeed I'm happy that their "creativity" is somewhat constrained.
&gt; it cannot be used for any of the java.lang.Error throwable classes Which is sensible, given that, as the Java documentation clearly states: &gt; An Error is a subclass of Throwable that indicates serious problems that a reasonable application should not try to catch If it shouldn't be caught then why would you want to propagate it in a container class?
I'd put it significantly more strongly than that: run far, _far_ away from anywhere idiotic enough to _ban_ FP. Have a debate about, fine. Recommend against, OK, I guess, as long as there's a frequent, and open, appeals process. _Banning outright_ is just a clear "do not want to work there" signal. It screams "any warm body with N years' OO experience we can make work too hard will do."
Because "should" isn't never. And there are applications, for example application frameworks and JVM device driver implementations, which do have to catch some descendants of Error. So, making Throwable the root (as opposed to Exception) enables these fringe use cases. And most use cases will favor the Exception side of the Throwable hierarchy, and in fact ought to strongly favor the narrowed RuntimeException descendant of Exception. IOW, the actual primary use case for the largest group of clients is for RuntimeException, not Exception. So, for the same reason one might occasionally need something not deriving from RuntimeException, Exception needs to be included. The same goes for Error, but at a magnitude smaller number of use cases. BTW, that is why I offered 4 solutions on mine. TryRuntimeException is the one I end up using +95% of the time. However, because I also implement an application framework, the other 4.9% of the time I have to jump to Throwable so I can emit logging indicating a low level thing happened before the JVM exits. This is for obvious reasons given the context of implementing lower level system-like exception/error capture which clients of the framework won't ever need.
it didn't work on mobile for me, but works fine on my desktop. maybe it was that?
&gt; This was not intuitive for me. I would have preferred that "-&gt;" has the lowest precedence which is possible. I hear you. Operator precedence in Scala is a push-and-pull between ergonomics and 'correctness', mostly because precedence is currently determined by the _first letter of the operator's symbol:_ http://stackoverflow.com/a/2922456/20371 (note that the listing starts with lowest precedence and ends with highest precedence). So by that precedence listing if the `-&gt;` operator had been named, say, `x`: object PairOps { implicit class T[A](val a: A) extends AnyVal { def x[B](b: B): (A, B) = (a, b) } } import PairOps._ Your first try would have worked because `x` has a lower precedence than `-`: scala&gt; Map.empty + (5 x (Math abs 5) - 1) res4: scala.collection.immutable.Map[Int,Int] = Map(5 -&gt; 4)
I would go even farther and say that the current rules are only for "backward compatibility". I'm not even sure it's a good idea to have that kind of operator precedence at all. Maybe it's better to go with the lisp-like-approach in this case.
Maybe he'll walk out inspired by the thought that criticism is healthy, or by the idea that we need not accept the limitations of our tools as if they were laws of nature, or by the fact that there's still so much room to improve. Some people find cheerleading inspirational, but I find it disheartening. Most people are like you, but some are like me.
Good, [Summerized all links](https://gist.github.com/ikhoon/d3c2de5c99ef2bac61e14dbeb87ac563) commented above.😀 
If it's only your second language you might do better off with a more purist/consistent language like standard ML. Scala is a great practical language but it's also a bit of a mess, especially to someone who doesn't know Java already.
Launching a REPL with `-Xlog-implicits` can be very helpful. IntelliJ's ctrl-shift-P would be extremely useful if implicit resolution in IntelliJ actually worked, but unfortunately it doesn't.
Without operators or precedence we could still write 2 plus (3 times 6) plus 1 which is frankly not that bad. I would be extremely wary of generalising from mathematical notation. Everyone learns the precedence of the basic mathematical operators at school; I can't think of any other symbolic notation for which that's the case. Operator precedence makes code more readable *for people who know the operator precedence* at the cost of making it almost unreadable for people who don't. I think customizable precedence would make code a lot less readable (it would mean the same expression would parse differently depending on which libraries you were using), and frankly I think we should be reducing the amount of symbolic operators with precedence that we have in Scala, not adding more.
Slides: https://speakerdeck.com/kvnwbbr/scala-state-of-the-union
You might want to give F# a look first - much more interoperable with C# and it offers most of the cool stuff that Scala does. Even if you eventually do move to Scala, familiarity with F# will be a big help when learning.
As someone who's had to go the other way I really can't find any good reason to try to talk you out of it...
I learnt F# to discover there's zero commercial interest in it... :|
Well, that took awhile ;-) Nice conference, enjoyed it, particularly Spiewak's keynote and Norris' talk on type level programming and his query dsl, Doobie. Montreal's a fun city as well, taste of Europe in North America.
the staircase book 3rd ed as a reference to learn the language and the red book to learn the fundamentals, doing all the exercises is crucial.
What's it supposed to do? Try splitting your function into smaller functions and then you can test them individually.
Try running you function with a big input (10k or 100k elements). Does it still works? In any case, a much simpler solution will be to fold over the array and keeping the top k elements
You are probably going to have a much easier time if the array is sorted first and then writing your functions based on a sorted array. It allows you to separate your concerns and reuse functions. find(list.sorted, k) Hint: where is the kth smallest element of an array that is sorted smallest to largest?
I can see some things: 1. require(0 &lt;= k &amp;&amp; k &lt; seq.length) I can ask for the 0th (?) smallest element but I can't ask for the 10th element in a 10-length list? You are working with k:th so I fell like the first k should be 1. 2. As @sepp2k said: else if (low.length == 0) a(pivot) is wrong 3 For me is easier to thing te algorithms using: val (low, high) = a.partition(_ &lt;= a(pivot)) This way is easier to build the if-else. 4. You should only cast to Array once: def find(seq: Seq[Int], k: Int) = { require(0 &lt; k &amp;&amp; k &lt;= seq.length) def _find(a: Array[Int], k: Int) = {....} _find(seq.toArray, k) } Try it. If you still can't make it work I'll post my full code. 
Your partition method should only return the indexes left and right, not two new sequences. Even if the function worked it would be significantly slowed down by the memory allocation. Is the code not working at all or is it just too slow?
Oh didn't see he was supposed to use a specific algorithm.
any suggestions for a one-and-a-half year old Scala dev? 
Anywhere I can see the collection of slides for each talk?
I was a professional C# developer for a while that transitioned to Scala, couldn't be happier. I looked at F# and decided that even though it has nicer interop with F#, you don't have as powerful of a language. So I do sometimes miss Visual Studio (post 2013 it really was a nice IDE), but the language power more than makes up for it. Feel free to ask other questions. 
I am similar in terms of Scala dev age. What are you interested to know?
Swapping the parens?
Banning scalaz (for which there may be good reasons for a particular team) is not the same as banning FP.
I'm working on implementing a relatively simple, stack-based programming language. It's actually blown up into quite the project. I already wrote an interpreter in Python if you want to have a look at the language: http://github.com/tripl3dogdare/Subterra
&gt; "declare that your notion of equivalence ignores parallelism" - are you suggesting that Fetch is an example of following this approach? Can you break this idea down a bit if it is logically feasible? The for/tuple example is the simplest case. If I ask "are those two snippets equivalent?" your framework/philosophy can answer yes or no, but either answer has unpleasant implications: if you say "yes" then that means a "safe" refactor where I replace code with equivalent code can have extremely negative performance implementations (just imagine there are a thousand `p`s rather than two). If you say "no" then your monad and your applicative are no longer consistent with each other and the developer's expectations are violated (even if you declare that this refactor is unsafe, the developer still expects it to be safe). &gt; Is ArrowChoice a pseudo-concept, or is it concrete in Haskell or otherwise? If former, is it composed of concrete concepts and what are they, if latter, can you point to an example? It exists in Haskell, http://hackage.haskell.org/package/base-4.9.0.0/docs/Control-Arrow.html#t:ArrowChoice . Vanilla arrows are pseudo-equivalent to applicatives; choice allows a weak kind of chaining where the next effect can be an if/else of the current value, but not an arbitrary function of it. I suspect/hope this is powerful enough to implement most of what we currently use monads for, but weak enough to allow more efficient interpretation. Maybe. Or maybe I'm grasping at straws.
Seems like all you need to learn is the syntax. Maybe the fastest path is: - Take a good Scala book such as [Functional Programming in Scala](https://www.manning.com/books/functional-programming-in-scala). You're probably already familiar with most or all of the concepts, but it will show you idiomatic Scala code. - Read real Scala code. There is a library index [awesome-scala](https://github.com/lauris/awesome-scala). It will give you both a good knowledge of the eco-system and show how people code in Scala. - Have a look at the [language reference](http://www.scala-lang.org/docu/files/ScalaReference.pdf). It's the best place when you have questions about the syntax or semantics of the language. Good luck and have fun!
Yeah, I like this talk as well. I think it's not good to throw some M word to the people who are new to Scala :-)
&gt; I really don't understand the null.asInstanceOf[T]. Sorry, that was a little bit of copy-pasta from some of my own code. Really you could just as easily done `x.head` or something to extract the values. In the example I gave the FlatMapper wasn't actually being used, so it really didn't matter what happen do the values, just what was happening to the types (and really in the code I copied this from, there wasn't a value yet to be retrieved, just the type so the null made some sense there). Hope this explains that a little, but I think the other advice in this thread may have gotten you what you need.
I actually have an application here which only runs on java 1.6 and not java8. But yes it has sth to do with how your architecture looks like (cloud vms or self managed servers etc.)
Very cool stuff, thank you.
Lot's of things at the data level. Here is an example of using scodec to [read DNS Request](https://github.com/MasseGuillaume/Scala-DNS/blob/master/src/main/scala/dns/3_scodec_dns_request.scala#L7) and convert it to scala case classes. 
Thank you! Effective Scala is very useful indeed. As for the build tools, we're a gradle shop, but the same rules apply. That's basically how we do it.
Thankyou for this! Wrangling build scripts is definitely my least favorite part of programming.
Thank you very much. I played with Scala.js last year and liked it, and I used Play years ago. Definitely going to play with this, no pun intended :-)
If that's true that's a hell of a trap to fall into.
Gonna be slowly adding features to become a more feature rich starting point. (First up is Auth, db and then maybe user management/admin panel). What stuff do you find useful when starting a new project? More generally, what would you like to see demonstrated?
Definitely agree - and part of the reason I am making it is that a bunch of the existing starters put way too much into it and it got quite confusing as to "why" I would choose a specific way to do it. I plan to have multiple branches or Repos for each stage / variations and some notes on when I'd choose that way of doing it. This one will likely not change much at all - each will build from it.
Akka camel has a concept of producers and consumers where you specify the endpoint at which the actor sends or receives messages.so you can safely add or remove actors based on this. I hear your arguments but I still find them easier to reason about than futures 
What is it that you find easier about actors? Have you looked at iteratees (either play or fs2)? You write ordinary functions that return futures, and can very easily wire them up into a pipeline with producers/consumers at the ends.
If you've got the time it's well worth implementing iteratees yourself - the actual core pattern is extremely simple, some of the libraries put dozens of operators on top which are useful but make everything look a lot more complicated than it actually is.
How did you decide on Binding.scala? 
It's a tough way to generate a list. Most of those job posting link to browser job descriptions. Like at Credit Karma we have about 30 software engineering jobs looking for scala but the post was mostly a link to our jobs page. My guess is 80% of all scala posting for any company larger than 15 will be like that (like the Twitter and Verizon example). It's too hard to post on hacker news like it's a job board with tons of skills you want. In other job board style news, if you are interested in scala jobs you can email me, matt at creditkarma dot com. :)
oh ok interesting I have used sclajs-react and once did some very basic stuff with scala.rx - This was my first time hearing of Binding.scala. If I own the full stack I do appreciate Autowire but I understand your arguments against complexity etc
Seems very relevant - https://github.com/typelevel/cats/issues/983
Thank you! At my last job people threw actors around all the time and I could neither understand why, nor get them to justify it with anything but buzzwords and marketing, nor convince them to stop. Actors and the actor model can be fine, but they solve a problem we didn't have, and usually introduced more because you still get the costs of the actors without any of the benefits.
What's your background, familiar with Scala.js/react?
&gt; I consider SBT more trouble than it's worth Do you use zinc standalone for incremental compilation or something? Because incremental compiles/test runs/repl sessions are outstanding.
This is part of [assignment operators](http://scala-lang.org/files/archive/spec/2.11/06-expressions.html#assignment-operators) in the language spec. &gt; Assignment operators are treated specially in that they can be expanded to assignments if no other interpretation is valid. &gt; Let's consider an assignment operator such as `+=` in an infix operation `l += r`, where `l`, `r` are expressions. This operation can be re-interpreted as an operation which corresponds to the assignment &gt; `l = l + r` &gt; except that the operation's left-hand-side `l` is evaluated only once. So the compiler is effectively re-writing the code to be `i = i + 4`. The `+` is defined in `Int.scala`, and the assignment is as normal, which is why it fails if you try to assign to `val`.
Ahoy /r/Scala! I'm a mostly Java developer who has been hacking around Scala for a while on my own (by way of Akka, the gateway drug), hoping to make the jump using FP professionally. Something I'm getting hung up on, and am not finding a lot online about, is how high-quality production Scala _application_ code is designed and structured. At least in the Java world, there is a mile of distance between correct code that would be passing course homework, and production-grade code. Concerns like: - dependency injection (or not?) to facilitate unit/integration/component testing - configuration handling - resiliency and error handling - complex transactions - modularity and project structure - etc etc There are of course a ton of excellent Scala libraries to learn from, but in my experience high-quality library code is stylistically very different from app code. (Maybe this isn't accurate in the Scala dev world?) Could someone point me in the direction of open source Scala projects that, I guess, look like production code that would make it past code review at your company? (Or, if I'm completely off base, please let me know!)
Hi, thanks for trying scala on Android. If you want to start just go to http://scala-android.org and take a look. It's not finished yet but tutorial and quick start is fine. You might also drop by our gitter channel. Cheers 
For this kind of "what-if" scenarios, I suggest trying out the examples in the scala console (REPL). In the first case, we get: scala&gt; val listOfFutures = Seq( Future { true }, Future { throw new RuntimeException("e1") }.recover { case NonFatal(e) =&gt; println(e); false }, Future { throw new RuntimeException("e2") }.recover { case NonFatal(e) =&gt; println(e); false }, Future { true } ) java.lang.RuntimeException: e1 java.lang.RuntimeException: e2 listOfFutures: Seq[scala.concurrent.Future[Boolean]] = List(Success(true), Success(false), Success(false), Success(true)) scala&gt; Future.sequence(listOfFutures).map(println) List(true, false, false, true) res5: scala.concurrent.Future[Unit] = List() In the second case, we get: scala&gt; val listOfFutures = Seq( Future { true }, Future { throw new RuntimeException("e1") }.recoverWith { case NonFatal(e) =&gt; println(e); Future.failed(e) }, Future { throw new RuntimeException("e2") }.recoverWith { case NonFatal(e) =&gt; println(e); Future.failed(e) }, Future { true } ) java.lang.RuntimeException: e1 java.lang.RuntimeException: e2 listOfFutures: Seq[scala.concurrent.Future[Boolean]] = List(Success(true), Failure(java.lang.RuntimeException: e1), Failure(java.lang.RuntimeException: e2), Success(true)) scala&gt; Future.sequence(listOfFutures).map(println) res6: scala.concurrent.Future[Unit] = Failure(java.lang.RuntimeException: e1) scala&gt; Future.sequence(listOfFutures).map(println) res6: scala.concurrent.Future[Unit] = List() scala&gt; Future.sequence(listOfFutures).map(println) res6: scala.concurrent.Future[Unit] = Failure(java.lang.RuntimeException: e1) scala&gt; Future.sequence(listOfFutures).map(println) res6: scala.concurrent.Future[Unit] = List() Alternatively, scala&gt; def listOfFutures = Seq( Future { true }, Future { throw new RuntimeException("e1") }.recoverWith { case NonFatal(e) =&gt; println(e); Future.failed(e) }, Future { throw new RuntimeException("e2") }.recoverWith { case NonFatal(e) =&gt; println(e); Future.failed(e) }, Future { true } ) listOfFutures: Seq[scala.concurrent.Future[Boolean]] scala&gt; Future.sequence(listOfFutures).map(println) java.lang.RuntimeException: e1 java.lang.RuntimeException: e2 res28: scala.concurrent.Future[Unit] = List() scala&gt; Future.sequence(listOfFutures).map(println) java.lang.RuntimeException: e2 res29: scala.concurrent.Future[Unit] = List() java.lang.RuntimeException: e1 scala&gt; Future.sequence(listOfFutures).map(println) java.lang.RuntimeException: e1 res30: scala.concurrent.Future[Unit] = List() java.lang.RuntimeException: e2 scala&gt; Future.sequence(listOfFutures).map(println) res32: scala.concurrent.Future[Unit] = List() java.lang.RuntimeException: e2 java.lang.RuntimeException: e1 scala&gt; Future.sequence(listOfFutures).map(println) res33: scala.concurrent.Future[Unit] = List() scala&gt; java.lang.RuntimeException: e2 java.lang.RuntimeException: e1 Future.sequence(listOfFutures).map(println) java.lang.RuntimeException: e1 res34: scala.concurrent.Future[Unit] = List() java.lang.RuntimeException: e2 scala&gt; Future.sequence(listOfFutures).map(println) java.lang.RuntimeException: e1 java.lang.RuntimeException: e2 res39: scala.concurrent.Future[Unit] = Failure(java.lang.RuntimeException: e1) Hope this answers your questions.
Thanks, I've found a lot of the time the answer to things I try to do are in scalaz or cats. I'm still doing it mostly in plain scala, but I'll take a look. It won't make this pass but might be a future upgrade.
that sounds like a hassle :(
Functional programming is necessary to master time, space, and the Universe. Once you have accomplished this, webapps are also quite achievable. 
Cool. A few questions about your implementation: * What happens if the host crashes? * How come you didn't use Akka's FSM mixin? * How does this (single-use FSM actors) compare to having an actor (multiple-use) for each "state"? Single-use actors seem like an interesting approach, but they can't take advantage of a dispatcher's throughput parameter. 
Awesome! Now if I could get someone to marry multi-module project along with their respective client-side Scala.js modules, that would be great. Setting up a 'regular' Play app in a multi-module setting was painful enough on its own, I just can't get myself to try to go through that again... Also, a slightly tangential question - does Scala.js support 'hybrid' apps, so I can have multiple, yet separate components that I attach on different pages? I'd assume it does, but I never had the time to dig deeper.
Functional programming is king 
So it would be beneficial but not necessary is what I'm getting. I wish I could buy the book haha. However I live in the third world and am still a college student with no sure/consistent income. Not saying I'm poor, just saying that whatever income I get is way less than the dollar value. 
Got an example of play in your preferred multi-module setup? If you shoot that through I'll take a crack. Couple of ways to do it, I'll see if I have time to spin something up this weekend. Re: Hybrid apps - yes definitely. Scala.js can do anything JS can :-). I really like Binding.scala for making small reusable, isolated components. 
I am making a bunch of different alternatives for starting points. This being most simple / least opinionated. Next will have JWT auth and such. If you have any ideas of stuff that you'd like to see, I do enough early stage prototyping that it is worth it to put some effort into making nice starting points.
realistically though, common scala webapp frameworks tend to be a bit forgiving on the fp side-- Play especially. Incorporate more and more fp style as you get used to it.
What about something relating to the new Web Components standard?
Is functional programming necessary? No. Is object oriented programming necessary? No. Is structured programming necessary? No. Is procedural programming necessary? No. Is imperative programming necessary? No. Nothing is necessary. However each will increase your level of abstraction, giving you ever increasingly powerful tools to work with. Use at your own risk. 
I see no reason we should take your conjecture at face value.
It shouldn't be that way, of course. Stackoverflow does seem to have a bit of a problem with noob questions, not just regarding Scala. There is always a conflict/compromise between allowing noob questions and treating them seriously, and the long-term users being easily annoyed when the same question is asked the nth time, or the user hasn't followed the basic etiquette of SO, like state what you have tried so far, search for duplicate questions, make a simple reproducible case. As SO grows, there are unfortunately a lot of questions that are essentially duplicates. In any case, I think /r/learnscala is good idea, and I see this sub-reddit already exists. But I also think things like the recently added ask-anything on this reddit are meant for any type of questions, and I haven't seen rude answers there yet.
Do you have any concrete examples ?
I don't see how.
/u/know_not_much Here's a new tutorial on the current syntactic API of scala.meta: https://olafurpg.github.io/scala.meta-workshop/ The current de-facto metaprogramming API is still scala.reflect, but you may find scala.meta more approachable and sufficient for your needs. We're still in the early days so you can expect some quirks, esp. around the inline/meta macro annotations.
The author is very confused. There is no such thing as "functional programming" in Java. The only library I can think of is [this one](http://www.functionaljava.org/), which is probably developed and used by some Scala devs and I've yet to meet a single Java developer that knows about it. It's just not the kind of environment where FP can thrive and it will never be - which is OK for Java developers actually, since if they are using Java, they probably don't want something different. Because passing closures around is not functional programming and this isn't mere pedantry, because if you change the [agreed upon meaning](https://en.wikipedia.org/wiki/Functional_programming), then it loses all of its value. I'm actually in awe of the author's analysis, given that Yammer moved away from Scala *in 2011*. The story is so old that the author might have missed that a year later Yammer was also bought by Microsoft and they are slowly killing the product. In another year from now yammer.com will probably redirect to some Office365 Sharepoint-enabled bullshit. And those TIOBE stats are very trustworthy.
I won't say you're wrong, OP, but that hasn't been my experience. I was offered polite, generous answers on SO when I was first learning Scala, and since then I've offered (and seen other, more knowledgeable folks offer) respectful help when asked. Some fraction of any community are always going to be jerks; maybe you've just been unfortunate in who you've interacted with? /r/learnscala sounds like a fine idea, though.
Yet another: "Java 8 made Java a functional language, so Scala is now pointless". This assertion could not be more wrong: - It was possible to write functional code is Java much before Java 8. All you need is anonymous classes and closures. Java's been those two for ages. What Java 8 brings is nice syntactic sugar and very welcome JVM ad-hoc support. - Writing functional code is Java is **so painful** because Java is still a very opinionated towards imperative first-order style. When Java gets algebraic data types, pattern matching, (co)variance type-annotations, immutable versions of its standard library, inference, type aliases, ... then i will call Java a functional language. Until then, Java is an imperative language with some very limited and frustrating fp features. Using the same argument we can claim that C is an Object-Oriented language. After all, are't C's **struct** just **classes**? Classes are types whose objects package attributes and function pointers. Structs are types whose values **also** package attributes and function pointers! Furthermore lots of people are writing OO code in C (see GTK+).
I agree with /u/m50d that it is not as common to find open source applications in Scala, but there are a few big ones, the easiest way to find them would be by checking out the [Scaladex most-starred Scala repos](https://index.scala-lang.org/search?q=&amp;page=1&amp;sort=stars). On the first page you can find quite a few app or app-like repos, like Spark, PredictionIO, Kafka and Gitbucket.
At the very end, the author finally reveals what he thinks of Scala: &gt; To summarize: Scala played a key role as a catalyst in popularizing functional programming, and it exerted a strong influence on the design of functional programming in Java. Scala will probably never become the next big programming language. But, it will be around for years to come as the language of choice for niche problem domains such as Big Data programming. If that would have been written at the beginning, I could have stopped reading immediately. It is no surprise that someone who sees (or saw) Scala as a replacement for Java turned out to be wrong. That is not what Scala ever wanted to be. Also, big data programming is not niche anymore and very likely will continue to grow, which means there is still enough space for Scala to grow.
You're refusing to take his situation at face value and sidestepping the question entirely. It implies a certain degree of pedantry or even outright resentment towards the question. 
I guess it depends. Give it a try, writing controllers and passing data around should come pretty naturally. Then if you start writing more serious logic, you might want to pick up a book (like Scala for the Impatient) or one of the numerous online resources. In my opinion, most of Scala's complexity hits you in the face when you starting looking into the implementation of libraries and frameworks. If you write a Play application from scratch, in an idiomatic way, there shouldn't be too many issues. But it'll get hairy as soon as you start fighting the framework (which sadly can happen pretty quickly if you're porting legacy code, for instance from a Spring project).
The problem with scala beginner questions on SO is that lots of them were answered at least 5 years ago... It is very complicated to give some useful feedback under the SO rules in that case and more advanced users will see this behavior as lazy (you are suppose to make some efforts before asking for help).
sbt is powerful but using it to mess around with FP libraries is stupid easy. Make a new directory, make a build.sbt that looks like this: scalaVersion := "2.11.7" // or whatever version you want libraryDependencies += "org.scalaz" %% "scalaz-core" % "7.1.3" // or whatever version you want ```sbt console``` and you're good to go. If you want to write a small project, put your stuff in ```src/main/scala``` and ```sbt compile``` to get compiler feedback (compiler feedback is the best) or ~~sbt compile~~ ```sbt console``` to interact with your code.
&gt; To illustrate, today's example is me trying to decide if there is an appreciable difference between using a pool of Akka actors to handle a blocking process concurrently, configured to run in a thread pool sized the same as the pool size, or using a single actor and a Future configured to run in an execution context with an appropriately sized thread pool. I like the configuration of the actor approach more since it is in a single place, but the Future seems to make more idiomatic sense. But is there an actual difference, in practice? I don't know and it's hard to figure out. I'm not sure why you think those things are comparable. They're two completely different models of computation that's like comparing graphs with cartesian or polar coordinates to define a trigonometric function.
What would be a minimal example of state receiving concurrent updates that cannot be managed by concurrent data type like `AtomicInt`?
I don't want to derail the conversation to this particular example too much, but the application, as a whole, is actor based. Thus a Future would simply be run inside an actor for concurrency in this particular setup. If we assume this is unchanging, then understanding if there is an appreciable difference between using a Future or using actors themselves for the concurrency is the key. The only difference that comes to mind immediately is that with Futures directly back pressure is based on hitting a thread limit whereas with actors directly I might choose to short circuit based on mailboxes filling up. /shrug 
There's also http://www.javaslang.io/
No worries. I was mostly just curious about how you handled fault tolerance, and didn't feel like delving into the code to find out. :) &gt; Not sure if I understand this question. Can you elaborate? You seem to create a PaymentActor per payment-to-verify; when it's transitioned through its 6 states, it's destroyed. Alternatively, you could have created 6 actors that passed messages to each other and kept them around, possibly increasing throughput thanks to better locality of reference; I'm not sure if this is worth doing for this particular case. http://letitcrash.com/post/40755146949/tuning-dispatchers-in-akka-applications 
&gt; I've yet to meet a single Java developer that knows about it. You've met one now! Hah, although I somewhat lied, as I'm not so much a Java-dev, as much as a dev who most often uses Java because that's what is used on most projects where I work. Functional Java is still light-years behind Scala, which isn't FJ's fault because there's only so much you can do with the Java language. I mean, I've seen some rather creative ways of attempting to implement case, for-yield, etc, but it's not even remotely close to native language support for these basics. As an analogy, if one eliminates for/while/do (and similar) loops from a language, it's still entirely possible for one to write software using GOTO statements instead, but I doubt most any programmer whose not dealing with highly optimized bite-code would give such a language a serious look.
In my opinion anything you do in Java is very painful, even the preferred OOP-inflated imperative style that's so common with Java. Seriously, Java isn't a good OOP or a good static language either. People *could* do FP in any language, after all, people could do OOP in C and have built Gtk and Gnome on top of those foundations, which is quite the feat. However the ecosystem around a language is even more important than the language itself. Because if the tools you have, the libraries you end up using and your colleagues end up actively fighting against you, it's like swimming against the tide and you don't get to have sources of inspiration either. Hence, the only people that are ever going to do FP in Java are those that have experienced FP in other languages and are now forced to use Java, hating every minute of it in that process and seriously reconsidering their career choices.
...but I know the stream library and lambda syntax! I have everything I need from FP, keep your fancy maths to yourself! The issue I have with this article, is it's written by someone who is politically interested in Scala's death, but doesn't have half a clue what Scala or FP is about. Naively, it would be easy to interpret this as "another FP elitism comment." FP is a collection of ideas, as OOP is a collection of ideas, but not a singular idea. For better or worse, Scala's (Clojure, Groovy, etc) existence perpetuate's Java's existence. Java may be a few steps behind, but it's not 10 steps behind, mostly as a result of efforts in Scala (etc). To be blunt, the biggest difficulty I have making the jump into Scala is that it's an abstraction on top of the JVM. Much of what Scala tries to do, is a battle against what the JVM allows it to do. As such you get inefficient workarounds to things that should be more straightforward.
The reason it is hard to find good scala devs is that it is hard to become a good scala dev. Developers need to be motivated to make the effort, and it's a big effort. Not worth it for just a-better-Java ( maybe worth it for individual developer, but not worth it for largish organisations which would take a huge productivity hit in the interim and have a hard time finding devs). I think he's wrong about it declining though, and the reason for this is scala.js. This means for the first time there is a language that works well for both front and back end web development. It is such a new development that very few organisations have noticed. GWT was a failure, typescript is good on front end but node.js is a disaster area, Python sucks balls on the front end, clojurescript is inferior for js integration etc etc. There are huge success stories starting to emerge from scala startups, which benefit massively from an end to end, type checked (hence refactor-able) code base. ( thanks autowire). Most of all they benefit from only needing a single language which allows for highly effective small teams rather than two separate teams with a sharp edge between them. These success stories have not emerged yet because the tech is very new, and you need a substantial project for the benefits to matter. They are coming though, and soon.
People on SO are pretty rude in general. Travis Brown answers a shitload of Scala questions on SO and he seems genuinely nice.
Is your objection the word "any" in that description?
Not yet, there is support for simulated annealing and coupled simulated annealing. The global optimisation API of DynaML was created with one particular use case in mind: tuning of Machine Learning models such as Kernel SVM, Gaussian Process and so forth. But evolutionary algorithms would be an interesting addition, you can log into the gitter channel and spell out what kind of use case you are looking at. (https://gitter.im/mandar2812/DynaML?utm_source=badge&amp;utm_medium=badge&amp;utm_campaign=pr-badge&amp;utm_content=badge)
&gt; Nope, reflection is not supported One way in which Scala.js dramatically improves on Scala.jvm!
By most people's definition, I'd have to say there are no non-functional languages. Even C has function pointers. I've started to maintain that "functional" means "referentially transparent by default." [/u/runT1ME](https://www.reddit.com/user/runt1me) rightly points out this has the opposite problem: only Haskell, Idris, Mercury... are functional. Not even Scala or OCaml make the cut, which feels ridiculous, intolerable. But I can't find a definition of "functional" that includes Scala and OCaml that excludes JavaScript, PHP, Ruby, Python, C++...
So Scala is the Bernie Sanders to to Java's Hillary Clinton?
awesome. thanks. will check it out.
That's a good thing, since we have macros in scala, you can do 95% of what's possible with reflections. The remaining 5% are very unsafe, and you can live without it.
&gt; functional" means "referentially transparent by default. If I understand, Haskell and Idris (I don't know what Mercury is) fall into this category due to their handling of `IO` and immutability? Scala does not fall into this bucket due to side-effects, i.e. not using the `IO` approach?
Interesting...why should Scala not be viewed as a replacement for Java? 
Aye, that's a good point. That is an example of the kind of consequence of design choice that is hard to glean as a beginner. That isn't necessarily unique to Scala and its iibraries, of course, but I do feel like the amount of choice and their consequences are both more vast and more subtle with Scala compared to other languages and their frameworks that I've used.
http://www.lihaoyi.com/hands-on-scala-js/
I definitely recommend giving it a try, especially for any sort of serious client / server environment. Being able to have the web client, the server *and* the APIs all written in the same strongly-typed language makes it far easier to develop and maintain a complex application, I've found. (I made this jump about two years ago, and haven't regretted it at all.)
remote?
Iirc one of the very early k&amp;r editions did this in the glossary decades ago. Someone correct me if that's an urban legend.
https://github.com/japgolly/test-state
&gt; I just started learning scala, and i'm finding it challenging to get my head around all the new concepts, and i want to appologize for this question. /u/zzyzzyxx answered perfectly but I just wanted to emphasis that almost *everyone* learning scala finds it challenging to get their head around and you shouldn't apologize for any questions here. *trust* me, I asked and will continue to ask a lot of really silly (and some not so silly) questions. :) 
Hey, am on mobile now, but pm me a LinkedIn/resume?
Hi /r/Scala, Im trying to understand streams using [FS2](https://github.com/functional-streams-for-scala/fs2) and im having some difficulty. Basically, im trying to understand how to lift an incoming message/case class into an fs2 stream (sink) then have those messages get transformed and processed into redis or an in memory datastore. The README for fs2 had a great example of how to do this from disk, using nio as a sink however I wanted to set up a stream that is always "on" and getting messages. I searched through the tests (found some work with pub/subs) but was unable to find a simple example of setting up a sink, transforming, and outputting especially since I needed to run unsafeRun to get the stream to start. If anyone has any expertise to share that would be appreciated. 
I'd never heard about this concept before, but now I'm interested!
&gt; FP in Scala is worth doing, but it's definitely true that it's harder than it needs to be. Since Frege is available JVM-wise and Haskell/OCaml/Idris/etc are available natively, what niche do you see Scala filling? Is it mostly that Scala has a lot of the ecosystem already established? Or are implicits sufficiently different from typeclasses to warrant Scala's popularity? Asking earnestly as a beginner, not to start a language war :)
[removed]
There is another way to see it. If there are no women is possibly because the Scala community has not been a good environment. You may not be sexist but there are others that are not as welcoming. There are other communities with more diversity. Why do we need to set the bar so low for the Scala community? Even a 15% participation would have translated in 3 female speakers but instead there is only one. If you want a course of action here is a proposal: next time you see someone being sexist call them out, instead of just saying "I'm not the sexist one".
I'm bothered by the number of people jumping to conclusions saying that this comment is calling the Scala community sexist. Maybe the comment is asking for a better effort in diversifying the speakers at the Scala World con. 
An FS2 stream terminates when it's sources sends a Halt command. If the source never sends a Halt, the the stream never ends. For example, a file halts when it reaches EOF. A connection halts when it it is closed. You could use a source that never halts, like a [mutable queue](https://github.com/functional-streams-for-scala/fs2/blob/series/0.9/core/shared/src/main/scala/fs2/async/mutable/Queue.scala) or more generally a [Topic](https://github.com/functional-streams-for-scala/fs2/blob/ee8e8398c2788b66c30a61a0f1451ade7c542fee/core/shared/src/main/scala/fs2/async/mutable/Topic.scala). You just first create a reference to you queue like so: import fs2.async._ val myQueue = boundedQueue[Task, MyMessage](10) def myProcess(): Unit = myQueue.dequeue //Returns a stream of Task[MyMessage] .map(myMessage =&gt; ...) .to(redisSink) .run //Run the stream for it's effect. .unsafeRunAsync(attempt =&gt; myProcess) //Run this task in the background. It should never return, but in case it does, because of error, we just call myProcess again and restart. myProcess() // call my process and start the stream. This immediately returns so we continue on with our program, putting things into the queue. val mySource = fs2.io.file.readAll(someFile) .map(toMyMessage) .to(myQueue.enqueue) //Read a MyMessage from a file. Send it to our Queue. .run .unsafeValue() //Run it immediately and profit. 
I agree, but the article is not correct.
I agree, but the article is not correct.
You're jumping to conclusions about what's being asked here. There is no implied sexism but an open question to the reader on how we can make the Scala community more diverse. This is a good thing (if you're into a diverse community). 
No, it's a great question! Scala is deliberately a hybrid OO/FP language, in the informal sense that people usually mean "FP." It runs on the JVM and, again deliberately, can be used as a "better Java" without a lot of muss or fuss. There's no question in my mind that this has been crucial to Scala's success, even though I personally came to Scala with a fair amount of OCaml experience. Fast forward to today, and it surprises me as much as anyone else that I work on a team that basically writes Scala as if it were a strict (that is, not lazy) dialect of Haskell. Frege is quite an achievement, but is what it says it is: a Haskell on the JVM. It's unlikely to appeal to moderately-frustrated Java developers, and because it isn't GHC, isn't likely to appeal to Haskell developers who might want to target the JVM, either. For that, you want [GHCVM](https://github.com/rahulmutt/ghcvm). So Scala's a different beast, one I think has been instrumental in increasing FP's popularity, both in the OCaml and Haskell senses, if you will. Running on the JVM (and now JavaScript runtimes) is, to me, a huge part of the value proposition, and again for me, "Scala.native" offers no compelling value at all... eh, other than maybe being able to write tight mobile code, browser code, and server code in one language. But honestly, I'd likely still look at OCaml first for that.
Exploring the question doesn't have to mean we put anyone to blame. Maybe it turns out women, for some arcane reason, just aren't interested in Scala. Maybe they are but feel there is a hindrance of some kind and are reluctant to voice their opinion. Without asking we won't know, and without knowing it is difficult to adjust. This thought really extends to any underrepresented group in the community piechart and not just women, but this thread of the discussion specifically targets that slice. 
For what it's worth, I know Jon (Pretty, the organizer) takes this _very_ seriously. Last year, Amanda Laucher and Heather Miller were scheduled to present. Unfortunately, both withdrew for whatever reasons, resulting in an even more obvious imbalance that was frustrating and disappointing to Jon, which I know because I've worked with Ms. Laucher twice, and Jon discussed it with me. Ultimately, the solution to this is more women submitting their work to conferences, which in turn implies addressing the issue at the source. At this point in time, having female leadership in programming and computer science education seems to make a big difference—I imagine comments like [this](https://twitter.com/pandamonial/status/759100673820459009) have essentially _everything_ to do with Ms. Laucher's example and leadership.
I disagree with predef's tone, but I agree with the message that the Scala community should be challenged to do a better job at diversity. I don't really know much about Scala World's policies so I'm not going to criticize it specifically, but I have noticed that many community driven events whether they be confs, hackathons, OSS, don't do a great job at promoting diversity. The best way to bring in more diversity is to make your position on diversity clear and if necessary to actively solicit people to get better representation at your event. I know this always brings up the affirmative action vs meritocracy debate, but IMO these sorts of problem are like the classic chicken in the egg. The talent in community is heavily skewed towards one demographic which begets yet more of the same. Ensuring at least some diversity lets those that are underrepresented to see people like themselves are playing a part in that community. Hopefully this encourages them to begin participating as well. It's easy to maintain the status quo, but with some effort we could try and make our community more representative just like other development communities have done.
&gt; Exploring the question doesn't have to mean we put anyone to blame. (...) This thought really extends to any underrepresented group in the community piechart and not just women, but this thread of the discussion specifically targets that slice. The fact that it is only THAT question (and not: why are there less disabled devs than not disabled ones) is a problem. It shows that peoples minds are not rational anymore but they rather focus on specific things even though there is no reason to. I mean, how often do you see similiar questions for other underrepresented groups? And there are many dozen of these...
Disregarding that this discussion is specifically about the ratio of women presenters to men, I agree with you. However I also believe that the stereotype is more negatively biased against women in tech, compared to other minorities. While I've seen presentations that may in some way be interpreted as sexistic, I've never seen anything similar about disabled or coloured people. I don't mean to say that such doesn't exist or isn't as important, but that it simply doesn't seem to be as prevalent.
I don't know all the details but Amanda Laucher, who was to do a presentation at Scala World, allegedly cancelled due to sexism. https://twitter.com/pandamonial/status/641048170470973441 Should we not feel an obligation to take this seriously? 
Has anybody done anything with ScalaFX in pure functional style? I'm working on a desktop app for personal use, learning *cats* in the process, and while app logic was easy and fun thing to do, I'm struggling to find a good way to go with for decomposing UI code.
The first thing to bear in mind is what kind of source you are using; push or pull? "Pull" can basically be summarised as "for every data request you send, you get one reply with the response". You can model this with combinators like `Stream.eval`, `Stream.repeatEval`, `Stream.unfold`, where the provided effect invokes the request, and returns the response (`Task.async`, for example, can create an effect based on a callback-style API). If instead, the source itself occasionally invokes some API with data (it's not a 1-1 correspondence), that is a push datasource. You will usually need to create a queue (e.g. a boundedQueue) which will sit at the boundary of the two worlds. From your datasource, you can call `enqueue1`, and then you can use the `dequeue` side of the queue as a source for your stream.
&gt; Should we not feel an obligation to take this seriously? Yes we should! But there is nothing for us to do, except encouraging her to still go to the conference and support her e.g. by providing support for giving the talk via video conference. I don't think anyone from the conference did something bad that could be changed, or do you know of something like that? And I can understand that she gives up to the terrorists - it's her decision. But the only thing that we can do in this situation is to ignore such blackmail (if it was blackmail) and send notice to police.
&gt; However I also believe that the stereotype is more negatively biased against women in tech, compared to other minorities I cannot speak for every community and location but I have not experienced that. I mean, if it would be like that, there are certainly *concrete* actions relating to the conference that could be fingerpointed right? But you almost never hear of those. I wonder why... And if you really do, I have *never* seen someone encouraging sexism. They all blame the one who did something wrong. I would see a big problem if someone, in a talk, say something like "women won't be able to understand what I'm going to explain right now because they suck as developers" (or sth. similiar) and the crowd agrees or encourages such a talk. But I cannot remember of something like that at all. Someone saying this would be kicked out at least after the talk and will be shitstormed.
Hi, thanks for the harsh criticism :-) I'll do my best to explain! The choice of Scala over Java was specifically because Scala is just a vastly better language. It made no sense to stick with Java when its possible to cut out more than half the java code with Scala's language features and be more productive. Please see my comment above as to why the tool-kit was developed using a **hybrid imperative/language feature driven/some functional approach**. But basically, it was a **cost issue** and also involved **balancing other tasks** and providing a **transition** path to Scala. The tool-kit will get more functional in the upcoming releases. :-) 
Have you tried ScalaCheck? https://scalacheck.org Property testing is another name for mutation testing AFAIK. 
https://en.wikipedia.org/wiki/Mutation_testing
 def myProcess(): Unit = myQueue.unsafeRun.dequeue.map(_.x.toString).through(log("A")).run.unsafeRunAsync(attempt =&gt; myProcess)` Create a queue, take the "dequeue" side as a stream, eventually print out a value via "log", and run it asynchronously, I'm not sure what the last call in `unsafeRunAsync` is trying to do - that is supposed to be a callback to deal with the result of running the stream, and that's not what's happening here. myProcess() Does all of the above myQueue.unsafeRun.enqueue(Stream(MyMessage(1))).run.unsafeValue() Create a new queue (different from the queue used in `myProcess`!), and enqueue a message to it. Also, `unsafeValue` is an unusual call to make, read the comment with the method to understand what it does. myProcess() Does everything in the method again (note that this creates a third queue). The fundamental problem here is that `myQueue` is a queue constructor, and every time you call `unsafeRun`, you create a new, different queue. So you might be listening for values from one queue, and adding values to a completely different queue.
Mutation testing is when you introduce bugs in your code in order to see if your test suite finds them.
We're using heroku run our environments and move build versions between them using their deployment pipeline. It's been pretty nice as far as a turn-key solution goes. For CI, we're using Solano. We've found their hardware to be significantly faster than Circle CI (about 2-5x, depending on which circle host you gave the misfortune of landing on). Github integration works just fine, too.
Sbt assembly. Read in environment variables.
Fatjar pushed out and symlinked and blamo
What, the language? No. But the community around it is lacking in diversity, relative to many other parts of the software world, let alone the general population.
Ah, that's right. Nope, I've got nothing, then. 
Rpm deployed to an ASG
sbt stage + Docker + GKE.
Sbt native packager with the docker plugin on a java or openjdk docker image. Ansible to run containers on EC2 using ECS private repository and instances with ECS AMI. 
/u/Duralumin has done a pretty good explanation of where you went went wrong. I've created a working example here: http://scastie.org/22846
I git push on Clever Cloud and^I^totally^do^not^work^there...
I haven't heard of anyone using it in production yet. And I've never got a convincing answer to what it offers over Spray (which works in production already).
I've never understood what json4s is supposed to be for. It seems to just add an extra layer with its own json model that doesn't actually help anything; sure it makes it easy to port between three or four interchangeable JSON libraries but the main reason you want to switch libraries is because you believe one has a better model.
If you're an experienced Java programmer you need maybe half an hour of Scala to be productive with Scala. I did my first bit of Scala in an agile environment where I had a 2-week story card and was able to comfortably finish the task more effectively than if I'd done it in pure Java, starting from zero Scala (I literally wrote Java in my IDE and then fixed the compilation errors). Of course I was barely using the power of Scala (5+ years on I'm still learning some of the things you can do with it), but I was writing code as good as I would've in Java and it worked. (You'll need more experience to be able to *read* Scala written by other people, but writing it you can learn piecemeal). So to the extent that one can be effective with Play at all, you don't need any Scala experience (indeed it offers a Java API - if you know that API already I might stick with it for the first week or two of Scala, just so that you're not shifting API at the same time as shifting language). FWIW I dislike Play (I stick to Wicket for HTML UIs even when using Scala; I use Spray for REST APIs), but as far as I know it doesn't make much use of fancy Scala that you'd need to know about. Knowing more Scala will definitely help (e.g. `for`/`yield` makes working with Futures much nicer than anything you would do in Java), but naive Scala isn't going to be any worse than what you'd write in Java.
FP is never necessary (at least for a sufficiently smart developer - anything a given person can do with FP, a smarter person could do without FP) but usually helpful.
I suspect the close-to-metal space is shrinking dramatically. A lot of embedded programming (or, if you want to argue definitions, tasks that would previously have been solved with embedded programming) can be reasonably done in Java (or even Python) these days. A lot of modenrn games do a lot in C# that would previously have been in C++. And so on.
`AtomicInt` supports that.
Thanks for the kind words! &gt; On the other hand, it feels like if you are programming in a type-oriented/referentially-transparent way, then Scala is a less natural fit than Haskell/Idris (which are pure) or ML-variants (although these don't enforce referential transparency). Definitely. Coming to Scala from OCaml felt very natural and obvious in a lot of ways, but the more I emphasized Church vs. state (sorry, I couldn't resist!) the less comfortable it felt to me. &gt; I see your point about why Frege (or Yeti) may not appeal to Java developers or Haskell developers in particular, but it seems like Frege (or GHCVM) does fit the space of "strongly-typed purely functional programming language for the JVM" better than Scala does. Oh, definitely. In particular, GHCVM is "just" GHC, the poster child of "strongly-typed purely functional programming language." I'm sure it has some warts relative to plain GHC, just as Scala.js has a few warts relative to Scala, but I similarly doubt they're worth making much of. &gt; So would you say that Scala's advantage, other than being hosted on the JVM, is its accessibility to those coming from backgrounds that aren't necessarily FP while also giving FP capabilities to those that do? Absolutely. Taking my own experience at Intel Media/Verizon Labs as an example, I came in writing kinda-sorta functional Scala—certainly emphasizing immutability and relying on good ol' `map`, `filter`, etc. but without ever having used, e.g. scalaz before—and now am another pure FP scalaz weenie. Many others at Verizon Labs are still somewhere on that journey. That journey doesn't exist in Haskell or Idris, and so wouldn't be possible in Frege or GHCVM.
On my personal project, I've adopted&lt;fanboi&gt;[OpenShift](http://openshift.org)&lt;/fanboi&gt;. This is essentially Kubernetes plus a whole bunch of extra developer-oriented stuff from Red Hat. So it's a Docker/Kubernetes-based PaaS that you can run locally, run on their hosted service, or install on whatever IaaS you use. They have a very nice build system called [S2I](https://github.com/openshift/source-to-image), or "Source to Image," that stages builds across Docker images to construct a final, deployable image. OpenShift can be configured (and the [All-in-One Vagrant box](https://www.openshift.org/vm/) _is_ configured) with an internal Docker registry into which your ultimate built image goes. Then OpenShift lets you manage scaling Kubernetes pods up and down, provide routing, secrets for credentials, persistent volume claims, etc. etc. etc. This probably sounds _way_ more complicated than it is. Check out [OpenShift for Developers](https://www.openshift.com/promotions/for-developers.html), which is a free eBook. It describes OpenShift Origin 1.2. The current version is 1.3, and all I can say about it is that it's even better than 1.2. :-) I should add that OpenShift has [Eclipse tooling thanks to JBoss Tools](http://tools.jboss.org/features/openshift.html), and there is an [sbt S2I builder](https://github.com/Ticketfly/sti-scala), although I haven't yet tried to add a custom builder to OpenShift. What I have done is stood up the Vagrant box, given it 8G of memory, and used it to run Jenkins 2.x for my build pipeline (I'm using an SDK that essentially forces me to use Maven, which I'm slowly making my peace with), and installed GitLab using their [OpenShift template](https://gitlab.com/gitlab-org/omnibus-gitlab/blob/master/docker/openshift-template.json). I have the JBoss Tools in Eclipse talking to my Vagrant box, my project in GitLab in Eclipse thanks to EGit, and my GitLab project issues in Mylyn thanks to the [GitLab Mylyn connector](https://marketplace.eclipse.org/content/mylyn-gitlab-connector). This is all on my quad core 16G MacBook Pro for now, but of course the idea is that, eventually, I'll be able to put all of this on some IaaS (maybe Linode?) or, if I feel it's worth it, [Red Hat's own hosted OpenShift](https://www.openshift.com/). Hope this helps! **Update:** Here's a [blog post on autoscaling pods in OpenShift 3.1](https://blog.openshift.com/openshift-3-1-pod-autoscaling/), which I believe maps 1:1 to OpenShift Origin 1.1, so is supported in 1.2 and 1.3. "Origin" is the open source upstream code of Red Hat's commercial offerings.
Using Maven, Jenkins and Artifactory (because everyone knows that, right...?), and deployment is then done plant-wide (from S3) via Ansible (because its "as simple as it gets" right now). Ansible deployment isn't lighting fast, but rock-solid once it gets going and easy to on-board new devs that are not familiar with it.
It's a valid question. Something I keep noticing is that when a conference or meetup explicitly _says_ they embrace gender and other diversity, they attract more diverse speakers and attendees! It seems like magic, but I'm sure the organisers put in a tremendous amount of work into outreach, mentoring and managing first-time speakers who would be otherwise reluctant for whatever reason. So maybe for Scala we should ask--can Scala conference organisers get in touch with people who have proven success in organising diversity-friendly meetups (I've attended a couple, they were great, and I fully intend to attend more) and conferences, and put the word out that Scala is actually very diversity friendly, that we would all here love to help folks learn and talk about Scala.
It provides consistent types that you can match against. I believe the main reason for switching between json4s backends is performance options. Just because one backend performs better now doesn't mean it will in the future.
Good luck!
Really, the only thing we can do is observe and cheer on? That's like saying the only thing we can do to help sexual assault victims is to keep telling them to get out there and hope for the best, which is basically a nicely put way of saying that we don't take responsibility or give a crap for their well being. I'm of a different opinion: We can do a ton of things to help victimized individuals or groups from a grass root-level by inviting them into safe harbours with a zero tolerance for the kind of bullshit they put up with. We can think of how we act as individuals and invite our fellow human to partake in what we enjoy rather than assume they're not interested and expect them to seek us out if they are. The scenario is not monochrome. People have all sorts of reasons for why they are uncomfortable in a given situation; we shouldn't blanket treat them as if they are unwilling to partake because that's what they choose, but listen to their worries and try to help them. That's what a community **should** be about to begin with. It doesn't take much effort to adjust our ways, it doesn't dig into our budget of freedom and it doesn't endanger our existence. Which is why I find it so surprising that the people voicing concern in this post are being met with distrust and downvoted into the abyss. What are you all afraid of?
&gt; Really, the only thing we can do is observe and cheer on? &gt; That's like saying the only thing we can do to help sexual assault victims (...) That's a difference. If you wanna compare it, choose victims that have been threatened by getting sexual assaulted if they do some actions. &gt; by inviting them into safe harbours with a zero tolerance for the kind of bullshit So you think there is, at this moment, tolerance at the conference for threatening other people? No way! &gt; but listen to their worries and try to help them Has someone that we know and can identify done something different? Like telling "idc if you get threatened" at the conference? Sorry, but you are talking as if such things happen, but I neaver heard from it. Do you have any proof or actual quotes of what you imply happens all the time?
Check out [Your Server as a Function](https://monkey.org/~marius/funsrv.pdf). It's an alternative worldview in which asynchronous state machines aren't actors sending messages to each other, but type-safe asynchronous functions that can be composed with each other.
&gt; `sbt compile` to interact with your code. `sbt console`
Maybe you're looking for ... https://github.com/json4s/json4s#guide
Yikes. Try https://github.com/travisbrown/circe
Could you please elaborate on the "Yikes" reply? 
No, I quite deliberately meant the json4s AST. OP was looking for a DSL for JSON. Circe is not a JSON DSL; it actually indirectly uses json4s's AST (through Jawn).
&gt; That's a difference. If you wanna compare it, choose victims that have been threatened by getting sexual assaulted if they do some actions. You/I don't know if any given person being threatened has experienced previous actual mental or physical violence. Would you require a concrete police incident report to take these threats seriously? It is irrelevant to the point, contra-productive really. Just as I may shrug off a threat as unbased, someone who is not me may take it very seriously. And it is still utterly stupefying to try and argue generally if a threat is severe enough to be considered valid or not. &gt; So you think there is, at this moment, tolerance at the conference for threatening other people? No way! A threat was made. Someone obviously thought differently. &gt; Has someone that we know and can identify done something different? Like telling "idc if you get threatened" at the conference? Well see, what I've been getting at is it takes an active stance to change things around. I'm certain most mentally balanced individuals would agree it's a bad thing if someone in their community is threatened. The thing is, it is the community that should prevent these things from happening. That means us. Being a passive observer doesn't magically solve the issue no matter how much we condemn it. &gt; Sorry, but you are talking as if such things happen, but I neaver heard from it. Do you have any proof or actual quotes of what you imply happens all the time? Obviously they happen or no one would feel they are in danger doing a public appearance at a conference. Some people, somewhere, thinks it's ok to make threats based on an individual's or a group of people's ethnical/sexual/ideological/whatever background. We can do plenty to nurture a culture where this behaviour isn't accepted by actively giving our support to those who ask for it, by introspection of ourselves and how we act, and by changing the way we approach the issue. Recommending that people do video casts from a bunker is sidestepping the problem and a poor treatment for a symptom that's, at the root, a sickness in the community.
ty my b
http://engineering.ooyala.com/blog/comparing-scala-json-libraries I know this benchmark is two years old, but json4s was faster at the time than most other options. Are you assuming reflection is slow?
The point is not really to map json particularly. I may have given the wrong impression. Even if it was, i would consider this as a learning experience and my first step into DSL. My purpose is to focus on converting any representation of Data into my own and use an high level DSL to apply transformations and representations of that data. For instance, lets call my data (map of maps whatever) Model[_]. Taking for example from XPATH or whatever i would like to do something like model1 add model2 remove model3 select "path". I am not really sure about the language or the specifics itself (i got a prototype but it follows absolutely no DSL rules so the code got pretty bloated and i find the usage to be horrible and not intuitive)
I've been doing this for the past few months, just reading every morning/afternoon on the subway... A word of advice.. do ALL the problems, I found that implementing them makes me read through slower, but allowed me to understand the later concepts much easier
&gt; Would you require a concrete police incident report to take these threats seriously? What are you talking about? Read again what I wrote. I just said that your comparison is invalid, that's all. No idea why you now try to imply that I would not take the claim of these threats seriously. I even said the opposite. &gt; &gt; So you think there is, at this moment, tolerance at the conference for threatening other people? No way! &gt; &gt; A threat was made. Someone obviously thought differently. Read again: is there tolerance for threatening *at the conference*? Because again, what else do you expect people to do when she gets some mails? Do you think us scala devs should now try find who sent those mails? Or what? We can only encourage her and help her, that's it. And that has been done, look at the twitter comments. &gt; Obviously they happen So you don't have any. Thx for the discussion. Else, give some *concrete* examples of what to do. E.g. "Getting an active stance" is not concrete. It's just bullshit, sorry. In my ears, you are talking like a politician.
I guess I just don't believe the claims of deprecation. It's effective enough that I'm sure people will keep using it. Hell, if I have to maintain it myself that's ok.
I really like Spray that much. As and when akka-http matures I'll take a look and see whether it has the things I like Spray for, but even if it does I'd rather not have to switch for what feels like no reason.
I'm working on combining the new Scalafiddle with Reveal.js for doing presentations with embedded runnable Scala examples. Got a basic POC running locally, but still need to work on ways to package it up nicely to make it deploy simply and quickly.
Yeah at Scala World some of us were talking about implementing an extension point in the compiler for pretty-printing types and terms, kind of like what Ammonite does but integrated at a lower level. But at this point no, there's no way to do it.
See https://github.com/cvogt/scala-cosmetics
I'm confused, are you talking about compiler errors, exceptions, or debugger information?
I'm working on a project for myself that utilizes the Goodreads API; [goodreads](https://www.goodreads.com/) is a website for book rating/reviews. The code is up on [github](https://github.com/alexisraykhel/scalareads). I don't know where I want to go with this exactly, just trying to see what different things I can do with their data mostly. I made a rudimentary nearest neighbor algorithm for book recommendations based on a user's read and to-read shelves. I originally wanted to make a library for others to use that would make nice ADTs from the API output, but that's on the backburner now as I am kind of lost with how to make a library for other people. Any ideas?
Json4s is awful
Let me know how you find Sangria.
Compiler errors
I'm curious why reflection is hated so much. For example, don't all pattern matches compile down to `instanceOf` which is like canonical reflection? Why is it bad?
I just merged my big update to [Boilerplay](https://github.com/KyleU/boilerplay), a starter reactive web app based on the latest Play, Scala.js and Silhouette versions. It includes sign in, an admin section, and most of the basic stuff you'll need for new apps, including a whole bunch of dev tools and metrics. I extracted most of the code from my [Solitaire](https://solitaire.gg/) game.
They compile down to yes. Operative word is compile, and that the user should be prevented from doing funky runtime checks without assistance from a tool (the compiler)
&gt; I'm curious why reflection is hated so much... Why is it bad? Good question. [This post](http://bugsquash.blogspot.com/2014/05/on-parametric-polymorphism-and-json.html) explains it very well. The tl;dr is that reflection very often (not always!) breaks [parametricity](https://en.wikipedia.org/wiki/Parametricity), and when we FP nuts talk about "reasoning about our code" and "being able to tell what a function does just from its type," this is what we're talking about. &gt; For example, don't all pattern matches compile down to instanceOf which is like canonical reflection? That's explained quite well [here](http://typelevel.org/blog/2014/11/10/why_is_adt_pattern_matching_allowed.html).
Awesome! &gt; Many others at Verizon Labs are still somewhere on that journey. That journey doesn't exist in Haskell or Idris, and so wouldn't be possible in Frege or GHCVM. I definitely see the value here - it gives people the opportunity to move towards functional programming incrementally without having to sacrifice huge amounts of productivity in the process. I like the idea of a "bridge" language that services the needs of both OO people and pure FP people along with everyone in-between. It yields utility to those who don't do full pure-FP, but also increases accessibility to those who are interested in eventually programming in a type-focused, referentially-transparent way. Thanks again!
&gt; remaining productive the whole time. I think that's a pretty big point that I never really thought about before. I just started using some Scala at work, and (after doing some reading) I'm able to be productive immediately. I don't think I would have been able to switch gears from C++ -&gt; Haskell without a significant amount of time being sacrificed simply to learning and inexperience.
Right, and the article implies (however it reaches an incorrect conclusion through logical fallacies) that there is a problem is with the way that society raises girls/women which isn't a problem with the **tech industry**. Work and professional life should be meritocratic by nature, its a competitive marketplace. If the value isn't placed on meritocracy, you end up losing and someone ends up suffering. The point I am making is its a problem with societal norms in how kids are raised and a bit of the education system. We shouldn't be scapegoating the problem onto the tech industry, its not their fault. If at first level uni courses you only have around 10% women (which was the case when I went to uni) then its completely irrational to blame the entire tech industry.
&gt; Java has surpassed Scala as the preeminent functional programming language, because programmers already know Java. JavaScript has surpassed C as the preeminent programming language for embedded systems, because programmers already know JavaScript.
It was just merged in dotty: [preview](http://imgur.com/a/rijPg)
Perfect, just when my associate and myself decided to start doing more complex games ;)
Regardless of whether your point is true, I believe that it's worthwhile to mention the reasons why you find it to be awful.
That all sounds good. I'll keep watching! 
Question mostly correspond to Play framework users. How do you unit testings controllers? For example I'm always **mock** my dependent Components(like userService) and **inject** Play Components. Like this: //app.controllers.MainController.scala class MainController @Inject()(userService: UserService, val messagesApi: MessagesApi) extends Controller { def index = ??? } //tests/controllers.MainControllerTest.scala class MainControllerTest extends PlaySpec with MockitoSugar { "A MainController.index" should { "return index page" in { val injector = new GuiceApplicationBuilder().build().injector val messagesApi = injector.instanceOf[MessagesApi] val userService = mock[UserService] val controller = new MainController(userService, messagesApi) //actually test will be written below controller.index } } Do you test like this, or do you mock Play components also? 
Thanks for taking the time to answer my question and for the links!
Agreed. Toward the end of the article they mention their [Slickless](https://github.com/underscoreio/slickless) library, which is a whole lot easier to work with than vanilla Slick, if there's any tiny chance of running into that situation in the future.
There's https://github.com/hcoles/sbt-pit, but it doesn't generate meaningful mutations in Scala. I've [tried](https://github.com/getquill/quill/issues/38) to use it with Quill almost a year ago, so things could have changed.
At first I was very sceptical about video material (usually I prefer written articles) but this is total cool. The only thing which you could improve, IMO is sound - good microphones aren't that expensive. But anyway great job!
&gt; It is a problem of the tech industry. I'm working in a different area, so luckily I'm not surrounded by an all-boys-club, although there is also a gender disparity. No it really isn't. If the tech industry is receiving workers with a ratio of 1:10 for women to men (or w/e it happens to be) then it isn't the tech industries fault, they unfortunately have to suffer for it. If it is a problem within tech industry, then you need to state how and why. I haven't seen any rationally consistent answer so far Note that I am not saying there is no problem, I am saying that people are scapegoating the problem onto another area for largely political and ideological reasons.
This was originally not intended to be published, and just used as a quick and dirty internal tool. The problem with macros is that they need to be compiled before the rest of the project; which means they need to be in a subproject or a different project. I didn't want to bother with that at the time. If there is enough interest in this project, I will likely add a macro implementation.
Agreed, my stack of choice with Scala except I prefer ScalaTags over Twirl. To the poster: Is FP necessary. No. From experience: * If you write your code in a FP style will it be easier to test? Yes * Will it help remove common runtime errors? Yes * Will it lead to faster development? Yes, FP is about composing small reusable functions together to make bigger functions. You grow your own library, refactors are easier, easier tests, less runtime errors lead to a better development cycle. Is FP hard? If you do not know OO no, it takes the same amount of effort to learn. If you have 10 years of OO, then yes you need to approach with a open mind and forget what you already know. Free copies of the Manning Functional Programming in Scala book. It's a very good book. The authors put a great deal of time in to it no doubt and have bills to pay, it's very reasonably priced, they're just like you and me so support their work. Check out the authors blogs for the free content.
Step into the freezer
Shalemess plug: Have you seen my lib: https://github.com/jto/validation ? It's basically a generic version of play/json that support other formats (including UrlFormEncoded). The validations can be generated from a case class at compile time (based on macros). Full doc lives here: http://jto.github.io/validation/docs/book/ See macros in action here: https://github.com/jto/validation/blob/master/validation-form/src/test/scala/MacroSpec.scala#L87-L92 
Project will likely generate more interest with a compile time variant. Maybe join forces with sibling commenter [skaalf](https://www.reddit.com/user/skaalf)
(along with this are new versions of protify, sbt-android-gradle and sbt-android-gms)
I had not seen that before! Hmm... it does look like it provides a very similar API, and is definitely better in that you're using macros... It does seem different though, in the sense that everything in your library works with your custom validations and rules. It seems like it would be a bit harder to just drop into an existing project, and wouldn't particularly play nice with Forms/Mappings if it had to for some reason. The stuff I built is on top of the rest of the forms api as opposed to custom things. (Not saying one way is better than the other - just pointing out differences)
I agree, but it's also easier to compose queries that are going to be much, much wider with HLists as well, though possibly not with the changes. I'm not sure if I'll bother finding out.
Stop reading and start writing. 
Write a basic CRUD app for something like Books, there's enough information and hand-holding in the play documentation to make this fairly simple to do. 
Moved from C# to Scala. Never want to go back. Let me share the story here. At the start I knew that "Scala is java with good linq, so it's like C#". So I kept using `var`, `return`, I learned stiff like "null-None-Nothing-Unit" difference, got some understanding of powerful `for` operator which works with `Option` and `List`(in a very strange way, I thought) and whatnot. Some concepts like `pattern-matching` seemed natural, the others like `implicit` were frustrating and misunderstood. Seriously, passing an argument without actually passing it??Of course I had no idea on typeclasses, ADTs, monads, or anything about FP. Well, I thought lambas in C# are the FP. If I could time-travel and give myself an advice on learning scala, it would be "Learn a little haskell first". Some might disagree and say that this step is not necessary, you can start FP in scala(the red book) as well, but for me it was crucial to understand where the new concepts actually came from. Breaking from the OOP bubble is invaluable.
Perhaps [activator templates](https://www.lightbend.com/activator/templates) might give you some good examples to work with?
oke, so I can take the first coin and use it and then go on with the tail. Then I could take the first item and use it or not. But then I could not go back to a earlier used coin. so if I have [1.2] I use the 1 , make the recursion with the 2 and have 3 and have 1 left. 
I guess one more tip would be that you don't have to only have one recursive call in your code.
The idea behind this is to allow people who do not want to code but still be able to get streaming data via a configuration file. Thats the only idea behind Tweezer.
And we are planning on providing mechanism to write it to any data store depending on the velocity of the data that they want to stream. So that way it becomes a one stop shop for retrieving and storing twitter data.
I love [json4s](https://github.com/json4s/json4s)!
So, what it boils down to is how you want to process your data: stream vs batch. Spark streaming from a queue is great for batch processing, so if you want to just pull everything out every second and process, that's the way to do it. If you would rather process each message as it comes in (which is usually how you want to deal with queues), you'll want to use something like akka-streams to read each message from the queue as it comes in.
That's why I was thinking about non-Spark-based ways of working with the data. Right now I can get away with batch but I know where the project is headed and that's single-message processing. Thanks for confirming my suspicions. 
I agree most books are out of date and you always need to be careful with the activator templates if they are for current version. I think the most up to date book with play stuff is [reactive-web-apps](https://www.manning.com/books/reactive-web-applications) however its not a comprehensive overview of everything in Play
No worries, I have a similar project at work that pulls from a queue and compares all the results against a databse, and updates things as it goes along. I found that spark was great, but takes a lot more maintenance work than a single message processing system. The stream processing was also much easier to write than the spark jobs.
Having used both of those (and assuming you are not talking about their IO iface, but just concurrency), I wholeheartedly recommend [Monix](https://monix.io/). I am unfamiliar w/ Universal Messaging, but I'd say find a way on the JVM to get messages async (even if you have to poll a "page" at a time...preferably w/ a reactive-friendly lib), use Circe's CirceSupportParser along w/ Jawn to stream-parse the JSON (especially if you need to async parse inside a single large JSON array), flatten it into an Observable, transform or do whatever with it, and feed into MySQL. I'd then recommend [mysql-async](https://github.com/mauricio/postgresql-async) to async update the DB (I'd prefer a more reactive-friendly lib, but I don't know of one). Granted you should group some of the observable values for the MySQL work since one statement at a time is likely slow and IIRC the lib doesn't have a bulk option. I have now written a few large, non-distributed (i.e. local machine only) ETLs w/ Monix and am very happy with the "composability"...it's like a local Spark.
Given a total N and a coin denomination d1, it is easy to determine the number of ways of adding up to any total from 0 to N using only d1. If you tabulate the number of ways for each total using only d1, and tabulate the number of ways using only d2, you should be able to easily combine the two tables that give the number of ways to get the corresponding table when using combinations of d1 and d2. Keep adding coins until you are done, and then take the entry in the table with all the denominations for amount N. This approach works exactly the opposite of the recursive top-down divide and conquer approach that the instructor probably wants to see. That approach leads to very attractive and simple code, but it is terribly inefficient for large N with a large number of denominations. 
I have this exercise of the coursera course : /** * Returns whether all bounded integers within `s` satisfy `p`. */ def forall(s: Set, p: Int =&gt; Boolean): Boolean = { def iter(a: Int): Boolean = { if (a &gt; bound) true else if (???) ??? else iter(a+1) } iter(???) } Am I on the right track that after the if I have to do something with the function p and the a (iterator) 
Inside the if (the branching condition), you should do something with the p and the a
It sounds like you may want to check out [Akka SSE](https://github.com/hseeberger/akka-sse). In general, [Akka HTTP](http://doc.akka.io/docs/akka/2.4.7/scala/http/) already gives you "an HTTP endpoint as an Akka Streams source."
It seems like that doesn't necessarily provide the polling behavior. Although it seems like it could be straightforward to do so with something like: Source.tick(0.seconds, 5.seconds, ()) .take(maxPolls) .flatMapMerge(_ =&gt; someSingleHttpSource) .filter(checkForSuccess(_) .runWith(Sink.headOption) 
Yeah. I kind of figured, worst case, you might have to drop down to the connection-oriented API and handle the polling yourself. Your snippet makes sense to me.
Hmm, interesting. The way i've been doing it is writing a blocking http client that retrieves a List[A] from some GET endpoint, and then writing a custom iterator around that. It will then poll the server again once I go through all those elements and effectively create an "infinite" iterator. Then I use the Source.fromIterator. Backpressure should limit my polling rate to how fast I can consume the elements, and I'd have to do some deduplication in the flow stage after. Does this seem like a huge hack to you?
I'm working on a data science-y project outside of work, and I use it for NLP stuff at work. But there's always sooooo much to learn.
What about using camel'ls [http component](https://camel.apache.org/http.html) via [akka-camel](http://doc.akka.io/docs/akka/current/scala/camel.html) and then convert that actor into a Source? Should be not too hard.
Im not trying to bitch about it but there are some talks I really want to see : ) also say big thanks to ScalaWorld as their videos/editing/sound are one of best quality I know.
&gt; But if you have to poll, I do think describing your process using the stream DSL can be really helpful from the standpoint of maintainability. It's so easy to accomplish variations on the different parameters of the process. Yeah, I don't control the server. I do like the idea of wrapping the polling api in as a stream api, but I don't know how to do it nicely. I want to avoid explicitly using actors if possible, but how I've been doing it so far seems ugly too.
Agreed that you should avoid using actors directly. That's what makes streams great. I may not understand though -- does the example above not work for you? The one thing I think I messed up is that Akka HTTP's client returns a `Future`, not a `Source`. So it's really more like: val pollRequest = HttpRequest(uri = someUri) Source.tick(0.seconds, 5.seconds, ()).take(maxPollCount) .mapAsync(1)(_ =&gt; Http().singleRequest(pollRequest)) .mapAsync(1) { case HttpResponse(StatusCodes.OK, _, entity, _) =&gt; Unmarshal(entity).to[JsObject].map(Some(_)) case other =&gt; Future.successful(None) } .collect { case Some(jsObject) if isSuccessful(jsObject) =&gt; jsObject } .runWith(Sink.headOption) That's just one way to do it. I think that really nicely breaks down to setting up the polling timing, making the request, deserializing to JSON (or your own domain object), checking for success, and returning the final result.
Not Scala, but Akka.net has great docs and examples. A lot of times, it's trivial to port over to Scala: https://petabridge.com/blog/how-actors-recover-from-failure-hierarchy-and-supervision/
I don't have an article to share but I'd suggest having separate repositories for snapshots and releases. This is configurable with Maven in the [distribution management](https://maven.apache.org/pom.html#Distribution_Management) section. Then use the [Maven release plugin](https://maven.apache.org/maven-release/maven-release-plugin/) to do the actual releases. This will adjust the version in the pom and commit tags to source control. I find it makes for a reasonable and useful commit history. You can also use the [Jenkins plugin](https://wiki.jenkins-ci.org/display/JENKINS/M2+Release+Plugin) if you like.
Yeah, this is the frustration I have with all Lightbend products. The narrative documentation is great if you're going to sit down and read the whole manual (which I have), but if you want a simple answer to a simple question, you're basically out of luck. Google will take you to a page in the docs with a big red warning that it's out of date (and frequently completely inapplicable). The link that says "view this page in the current documentation" takes you to the table of contents. API documentation and runnable examples are nowhere to be found. I'm not entirely sure what you mean by the "Actvator repositories" but if you can link to an example project that implements a supervisor strategy for fault tolerance, I'd appreciate it.
Thanks, I didn't see this because I think it got posted as a top level comment. That's really helpful, but not what I was asking for. The Akka ecosystem (and Play, and SBT) seams really big on descriptive blog posts and videos, etc. I don't understand why its so hard to just fine a working demo. That post is a great example. They clearly put a ton of work into it, so where's the link to the github repo with the complete example implementation? There's some code snippets but nothing I can download and type `sbt run`and then play around with.
To handle backpressure correctly, I think your best bet is to implement it as custom `GraphStage` logic. The you can poll `onPull` whenever your downstream consumers are ready for more data. edit: [here](https://www.reddit.com/r/scala/comments/57ijlm/best_way_of_converting_a_polling_api_into_an/d8uwg0b)
Here's an example based on something similar I wrote. If you want to add a hold off that should be pretty easy too. Just set up another callback. class HttpPollingSource(url: String)(implicit ec: ExecutionContext) extends GraphStage[SourceShape[String]] { // Pretend this fetches the web page you're polling def httpRequestFunction(path: String): Future[String] = ??? val out: Outlet[String] = Outlet("HttpPollingSource") override def shape: SourceShape[String] = SourceShape(out) override def createLogic(inheritedAttributes: Attributes) = new GraphStageLogic(shape) { val callback = getAsyncCallback { (response: String) =&gt; push(out, response) } setHandler(out, new OutHandler { override def onPull(): Unit = { val res: Future[String] = httpRequestFunction(url) res.foreach(callback.invoke) } }) } }
Sorry for the top level comment. I hardly use Reddit on non-mobile, and I'm struggling with a cold. Not a good excuse, but that's why I didn't pay close attention. I agree with your statement about Akka documentation versus readily available examples. Even Effective Akka, which has great examples in the book, has a pretty light github repo of companion code.
Just looked at your books table of contents. Am very interested in it
Debugging tools.
Do you have to do this in Scala? The impression I've gotten from coworkers researching this is that the ecosystem is significantly behind Python or R. Scala's main data science advantage is with production pipelines and distributed analysis on large datasets via Spark. (That said, I like Scala a lot more than Python, and would happily switch if there's something even half as good.)
You might want something like Or / Every: http://www.scalactic.org/user_guide/OrAndEvery And then do a badMap / mkString to accumulate `ErrorMessage` into a single string.
https://zeppelin.apache.org/ I've seen a demo, it's pretty neat and extensible.
That type is correct, it's simply that `::` is covariant. You can work around it by giving explicit type annotations (i.e. declare `val a: Task[String] = ...`, or else give `a :: HNil` an explicit type), but fundamentally this is a bug in Idea (one of many, IME) and the only thing to do is reduce it to a minimal example and report it in their bug tracker.
http://www.lightbend.com/activator/template/akka-supervision
I too am a huge fan of Scala, but you are asking for notebook-functionality. Generally, I too would suggest you go with Python. As to productionizing notebooks, I'm sure that sounds like a cool thing at a first glance, but unless your techops team is very green or unaware, mine at least would probably go up on barricades if I'd even just as much as hint at something like that :-). It really only matters how fast you can prototype in your language of choice and show of some graphical results. So if you still want to go down that lane (protoype in Scala), you have these options: - [Beaker notebook](http://beakernotebook.com/index) - Jupyter notebooks with the kernel [of](https://github.com/apache/incubator-toree), [your](https://github.com/mattpap/IScala), [choice](https://github.com/alexarchambault/jupyter-scala) - [Zeppelin](http://zeppelin.apache.org/) notebook - [Spark](http://spark-notebook.io/) notebook I myself prefer the last one over all others, because it has more functionality and is well designed (but admittedly very poor documentation; however, I didn't care, as I prefer reading code than documentation, assuming that the code is well written - but that is subjective). Also, it is far easier to run the Spark notebook against a production Spark cluster than getting Zeppelin to work properly, but that again was just my experience. And I've never tried Beaker, and only have heared mixed opinions (it seemed beta-y to others, but that might have improved by now). Also, I use this way of protoyping only because it allows me to import and use our in-house "data science library" (Java and Scala stuff), which wouldn't be an option in a Python notebook. (That last point might make Beaker interesting, it just wasn't around when I made my choice.) ADDENDUM: Due to your comment about the Ammonite repl and not mentioning Spark explicitly, your "right" choice might be the [jupter-scala kernel](https://github.com/alexarchambault/jupyter-scala).
People keep telling me how wonderful IntellJ IDEA's Scala support is. But every time I try it—and I mean _every_ time—I run into issues like this. As far as I know, the Scala plugin _still_ uses its own parser, and _still_ has a dodgy relationship with the actual compiler, such that on even moderately sophisticated code it reports false compilation negatives. Since one of the very few things I want an IDE for is to tell me whether my code will even compile or not, _one_ false negative means out it goes. For 99% of everything I want from an IDE anyway, I'm actually liking [Visual Studio Code](https://code.visualstudio.com/?utm_expid=101350005-28.R1T8FshdTBWEfZjY0s7XKQ.0&amp;utm_referrer=https%3A%2F%2Fwww.google.com%2F) a lot. And if you give it enough memory, modern [Eclipse](http://www.eclipse.org/) and the [Scala IDE](http://scala-ide.org/) is actually not bad.
I'm working on a [gRPC + Scala example project](https://github.com/vyshane/grpc-scala-microservice-kit). Comes with TLS + mutual authentication configured out of the box, and JSON Web Token verification for user sessions. Still to come: [Helm chart](https://github.com/kubernetes/helm) for deployment to Kubernetes and [grpc-gateway](https://github.com/grpc-ecosystem/grpc-gateway) as a sidecar container for JSON/REST.
I'm new to scala but have the impression I'm stuck with R and Python. I spent a LOT of time in RStudio. You can't really beat the speed / iteration in R when exploring tbh. Shoutout to Hadley Wickham for making my life easier. But I didn't mess with that JS stuff either. That said, I LOATHE notebooks and usually just like to work in an IDE / REPL+Sublime.
Does using Future's part of **reactive programming**? --------------------------------------------------------------- For example in [An introduction to reactive programming]( https://codewords.recurse.com/issues/two/an-introduction-to-reactive-programming) it is. But I thought that reactive programming should follow "Reactive manifesto". But Future's are not "message-driven".
Take a look at [Functional and Reactive Domain Modeling](https://www.manning.com/books/functional-and-reactive-domain-modeling). Here are some videos by the same author where he covers some of the topics in the book. https://www.youtube.com/watch?v=U0Rk9Knq8Vk https://www.youtube.com/watch?v=TiwNrioZoTo
Yeah, polling an endpoint that will return a collection.
Thanks. I do have two repositories. I'm more wondering about the process in CI/CD and Scrum. For example, Jenkins builds on every commit, then publishes to a test and integration environment. Would you have a job kick off after integration to publish a release of any artifacts? On a previous team, we solved this by publishing artifacts automatically tagged with the week number (or sprint number, as I think it later became). This was done by our devops team, and I had no authorization or insight into what was done there. I'm fairly certain the versions were just overwritten if they existed in the release repository. I'm looking for processes which result in more repeatable builds and artifacts than that.
Cool. I should warn you that most of the Scala community prefers to use SBT (I've never understood why), but personally I find maven a lot clearer and I'll be happy to help as much as I can (I did exactly this at a previous job, though sadly my current job uses different tools).
&gt; Would you have a job kick off after integration to publish a release of any artifacts? Yes. You could automatically have releases made after every successful integration test. Jenkins has an API you can use to trigger that with the necessary parameters. You could also manually kick off releases in Jenkins and ensure that the release is from a commit that passed integration. Or you can let developers prepare releases themselves (which is how my last company did it). There are significant tradeoffs among the approaches. &gt; I'm looking for processes which result in more repeatable builds and artifacts than that. Maven is built around the idea that non-snapshot artifacts never change. So if you use the release plugin and generally adhere to "the Maven way" you'll get your repeatable builds. For example, with the release plugin you can't make a release unless everything you depend on is also non-snapshot artifact\* and the plugin supports a "prepare-with-pom" which creates a resolved pom for the actual release if you need to re-use it. You can probably configure your repositories to reject duplicate versions by default too. \* You can use version ranges, which can result in less-repeatable builds, but can also be useful if you adhere to semver.
Yep, this was fantastic when Elm came up with it, when Rust adopted it, and it's fantastic now. Really glad to see attention paid to quality-of-life issues like this.
Presumably the OP has some types in his `List` that are not `Option`s, but are `Serializable`. I didn't take his examples to be exhaustive. If they _are_ exhaustive, there's some other aspect of his code that results in the unification to `Serializable`. In any case, if he actually wants a `List` with different types of elements, then he wants an `HList`. But: &gt; The reason I am putting it into a list is because I want to collect them into a single error message... This sounds to me like he wants a [`ValidationNel`](https://oss.sonatype.org/service/local/repositories/releases/archive/org/scalaz/scalaz_2.11/7.2.6/scalaz_2.11-7.2.6-javadoc.jar/!/index.html#scalaz.Validation) almost regardless of what the right type is. But: &gt; ...**also** reusing the values to populate an object if there are no errors. This could mean either the usual use-case for `Validation`, which is to use the applicative-builder syntax as in [/u/m50d](https://www.reddit.com/r/scala/comments/57vg14/question_how_can_i_elegantly_accumulate_errors/d8vi1jn)'s comment, or to do something incrementally, in which case making the right type some sort of `Monoid` and taking advantage of the fact that `Validation` then also forms a `Monoid` would be helpful. You could probably even use [shapeless-contrib](https://github.com/typelevel/shapeless-contrib) to automatically derive the scalaz `Monoid` instance for `HList`s if you wanted to go that route.
https://news.ycombinator.com/item?id=12727339
It's a special builder syntax that is analogous to the applicative `&lt;*&gt;` in Haskell. (+) &lt;$&gt; Just 1 &lt;*&gt; Just 2 Evaluates to `Just 3`. In Scala (with scalaz) we can write this as (Option(1) |@| Option(2))(_ + _) Which evaluates to `Some(3)`. This is equivalent (because `Option` is a monad) to: for { a &lt;- Option(1) b &lt;- Option(2) } yield a + b However applicative is weaker than monad so you can use `|@|` with some data types that won't work in a `for`-comprehension. I realize this may not have been helpful, sorry, I need to run. But look up applicative functors if you want to know more. 
If you do hard stuff then need to know it good, this language can be very tricky 
It's just syntax (I've heard a few people call it the "snail operator", but that name comes from the syntax rather than the other way around) - I wish I had a good name or a word-based way to express the same thing in code, but I don't. The way I think of it is: `(a ⊛ b ⊛ c)(f)` is syntactic sugar that applies `f` "inside" some kind of "context" type, if `a`, `b` and `c` are all "contextual values". More specifically I mean a higher-kinded type shaped like `F[_]: Applicative`, i.e. one that forms an "applicative functor". This is like a weaker form of a monad: it says that we know how to wrap up pure values in our context, and how to merge two contextual values or apply a contextual function to a contextual value (somehow combining the contexts), but we can't necessarily "chain" successive function calls that have contextual effects like we can with a monad. If we want `Validation` to always return all the failures in failure cases, then that's exactly what we need: we can't allow you to chain two function calls, because if the first function is a failure then there's no way to know whether the second function would have succeeded (by contrast `Either` does form a monad, because it's expected to fail fast, returning only the first error in failure cases). And so we can't allow `for`/`yield` either. As /u/tpolecat said, it's equivalent to a `for`/`yield` where you don't use any of the values that came out of the `&lt;-`s until the end - but it has to be different syntax to enforce that you don't do that.
Gotcha. So unmarshall to `Collection[A]`, and then the whole thing will return a `Future[Option[Collection[A]]]`, and you can work with it from there.
The only thing I've heard it called is an "applicative builder". It's a bit of a hack really (what's "really" happening is that the `⊛` constructs a "builder object" with an `apply` method that you can use to actually apply the function - you can see this happening if you click through in your IDE), but in practice it works, and lets us have a reasonably elegant-looking way of expressing this kind of operation. (This kind of thing is a bit of an open research area - it's hard to strike the right balance between being able to express monadic operations (chaining) when you need to, but also be able to express when a given snippet *doesn't* need that kind of chaining. Haskell's arrow syntax does this by offering a for-yield style syntax but with a distinction between `-&lt;` and `-&lt;&lt;` operators - I'd like to see something like that in Scala, but I'm not holding my breath)
Yep, I have the book in bookmarks, wasn't sure whether it's the right fit. Will probably read that now, thank you.
I have 2 question. 1: why this behaviour is allowed at all? 2: what exactly m equals to? It's funny to think, that it is simply two bracers, but ... no. The code below broke my morning. Thanks everyone for explanation. scala&gt; val m = if (1==2) {0} m: AnyVal = () scala&gt; println(m, m==()) warning: there was one deprecation warning; re-run with -deprecation for details ((),true)
This is one thing I've really struggled with with Scala. I've often wondered about the Scala community as a whole as a result of it too. If the documentation could be improved, and important things could be tied together from the main site, then the language would probably see much wider adoption. One of the reasons I really like Go is because it's documentation is awesome. Their website is great too, and answers loads of questions, and is pretty concise.
I don't have experience with Finatra but we use Finagle for writing services at work and I quite like the framework and think it has its purpose. The problem with the finagle universe is its divergence with the rest of scala ecosystem. The twitter Future is not the same as the scala Future and in all honesty i'd much rather have them just rename it to Task or something. That seems to be the biggest confusion among other devs using finagle that I have seen, but I have a few other gripes (mainly around the lack of effort to keep versions compatible. Upgrading from 6.35 to 6.36 introduced some breaking changes, and going to 6.38 caused a massive headache for our infrastructure teams.) So while finagle has its place, and it is really good for what it was designed for, it seems like scala devs are moving en masse towards all akka all the time. There is still some really good backing of finagle from various companies but it's not the same as it was in 2012 - 2014 
It seems the whole Finagle/Finch/Finatra stack is the 'open secret' of the Scala ecosystem ... whoever's using it (if anyone) is certainly very hush-hush about it. Competitive advantage maybe? Edit: Finch has a list of its users: https://github.com/finagle/finch also, take a look at this post which talks about the Finagle stack's constant efforts to get performance improvements http://vkostyukov.net/posts/how-fast-is-finch/
If you don't specify an `else` clause, and the `if` condition is false, the `if` expression evaluates to `()` (unit). But the `if` clause evaluates to `Int`, so the compiler has to unify the two, so it upcasts to their common supertype, `AnyVal`. Also, `-Yno-adapted-args` and related compiler flags are your friends, use them: http://blog.threatstack.com/useful-scalac-options-for-better-scala-development-part-1 That would have given you scala&gt; println((), ()) &lt;console&gt;:11: error: too many arguments for method println: (x: Any)Unit println((), ()) ^
This seems like a good opportunity to link again to [this ScalaSyd presentation](https://bitbucket.org/da_terry/scalasyd-doobie-http4s) using http4s, Doobie, and Argonaut to develop a complete, purely-functional microservice. It's _ridiculously_ simple!
You might appreciate [remotely](http://verizon.github.io/remotely/), then.
Thanks for the suggestion. I'll check it out.
I cannot disclose numbers unfortunately, but it's not hard to find ranges for Scala engineers. This obviously varies depending on your experience and the value you create for the company—there are outstanding engineers that are rewarded with far above average salaries. As far as work hours: technically it's 9-6. But as long as you're a sensible person and get shit done, we don't really care about your hours. Most people roll in at like 10. The office is pretty empty by 6:01 PM.
&gt; which I'll continue to associate scalaz with in spite of its being formally kicked out of the club. How has it been kicked out?
[This search](https://www.google.com/search?q=scalaz+tony+morris+typelevel&amp;oq=scalaz+tony+morris+typelevel&amp;aqs=chrome..69i57.4278j0j7&amp;sourceid=chrome&amp;ie=UTF-8) probably leads to more than you want to know. A shorter answer might be to just link to the [Typelevel](http://typelevel.org/) home page and see if you can find scalaz anywhere.
It is published to maven central repository http://search.maven.org/#artifactdetails%7Ccom.typesafe.akka%7Cakka-http%7C3.0.0-RC1%7Cjar
I personally prefer http4s. I use finatra at work, and it feels very opaque. It uses side effects to construct its routes, it uses reflection to process request data, you have to spin up a server in your tests in order to test your controllers, you're basically forced to use their DIC. If you want everything and the kitchen sink, then you'll like finatra. But even then I'd suggest Play. Http4s on the other hand is the polar opposite. A controller is simply a `Request =&gt; Task[Response]`, and there's no magic whatsoever. Mounting the services just means binding your controllers to your web server. It stays out of your way and is principled. 
I have used both Finatra and Play. My current product was originally written in Finatra and then I switched to Play. The simplicity of Finatra was great and I like that it was minimal. Developing with it was easy and the feedback/support from the guys at Twitter was great. The reason I ended up switching was because after I upgraded my version of Finatra, my web service eventually started hanging after a couple hours and would not respond to requests until I restarted the server. Whether this was an issue with my code or the way Elastic Beanstalk handles JVM-Finagle applications, I got stuck and could not figure this out. But when I reverted my version of Finatra, my web service was fine again. So I ended up moving everything to Play in a few hours (I made my code as framework-agnostic as I could) and my web service was working fine. Aside from this stability issue, which I'm not sure if I can blame myself or Finatra for, I had an overall good experience with Finatra. I switched back to Play because I was already familiar with Play from a previous project.. and needed my app to just work. Play is as simple as you make your app. If you want to make basic web services, it's totally fine and that's what I am using for. 
We're using finch, it's ok but compile times aren't best I think due to all shapeless stuff. I don't like finatra, but I guess that comes from me preferring libraries rather than frameworks. I prefer to pull in set of combinators and orchestrate their usage myself than pull in framework that dictates me how to do DI etc... But each to its own! I'd really really like to use http4s but I'd very much prefer to depend on cats+fs2....
I like Finatra and use it for an application that strings together a couple of REST APIs, it uses Finagle's HTTP client (obviously), MySQL client and Redis client. The best thing about it is that it doesn't try to be super-pure, it treats Scala mostly as Java++, so it's very easy to start. PS. Play is not great.
How [risk-tolerant](https://github.com/http4s/http4s/tree/topic/cats) are you? :-)
As far as I remember Beanstalk doesn't have any special treatment for JVM apps, it just puts them in a Docker container. I used `sbt-elastic-beanstalk-plugin` and everything worked fine. I did have similar problems with Finatra when an application would stop processing any requests and eventually crash with some [weird exception](https://gist.github.com/anonymous/5a00c66c7f4b8c139f61632acc9beb5b). It turned out that some of my code was incorrect and when I untangled overly complex anonymous functions, everything started working fine though I think the framework should've handled this situation better.
Good start. There's a few things that I think can be improved however. 1. Your UserService trait doesn't capture errors or optionality as well as I would prefer: trait UserService { def save(user: User): Task[Unit] def findAll(sort: UserSorting): Task[List[User]] def find(id: Long): Task[User] def remove(id: Long): Task[Unit] def edit(id: Long, age: Int): Task[Unit] } is perhaps better defined as: sealed trait UserServiceError case class DuplicatedUsernameException(username: String) extends UserServiceError case class UnknownError(e: Throwable) extends UserServiceError trait UserService { def save(user: User): Task[UserServiceError \/ User] def findAll(sort: UserSorting): Task[UserServiceErrpr \/ List[User]] def find(id: Long): Task[UserServiceError \/ Option[User]] def remove(id: Long): Task[UserServiceError \/ Option[Unit]] def edit(id: Long, age: Int): Task[UserServiceError \/ Option[User]] } You will want to call .attempt on your tasks to lift the Throwable into a UserServiceError: def find(id: Long): Task[UserServiceError \/ Option[User]] = { someTask(id) .attempt .leftMap(UnknownError.apply) } The main changes are: - Returning an error ADT, rather than using Task as a way to capture errors. This way you get exhaustiveness. The error in Task is just a throwable, and thus, you can't match on them in an exhaustive way. - Return Option[User] for find, edit and delete. You aren't really handling when the user isn't found in a nice way. I don't think it's an "error" - Using EitherT makes things significantly nicer, but i'll leave that decision to you. Your HttpService would then look like: val service = HttpService { case GET -&gt; Root / "users" : ? SortQueryParamMatcher(sort) =&gt; UserService.findAll(UserSorting.from(sort)) flatMap { case \/-(users) =&gt; Ok(users) case -\/(error) =&gt; handleUserServiceError(error) } case req @ POST -&gt; Root / "users" =&gt; req.decode[UserForm] { userForm =&gt; val user = User(Random.nextInt(1000), userForm.username, userForm.email, userForm.age) UserService.save(user).flatMap { case \/-(user) =&gt; Created(s"User with id: ${user.id}")) case -\/(error) =&gt; handleUserServiceError(error) } } case GET -&gt; Root / "users" / LongVar(id) =&gt; UserService.find(id) flatMap { case \/-(Some(user)) =&gt; Ok(user) case \/-(None) =&gt; NotFound() case -\/(error) =&gt; handleUserServiceError(error) } case DELETE -&gt; Root / "users" / LongVar(id) =&gt; UserService.remove(id).flatMap { case \/-(Some(_)) =&gt; NoContent() case -\/(None) =&gt; NotFound() case -\/(error) =&gt; handleUserServiceError(error) } case req @ PUT -&gt; Root / "users" / LongVar(id) =&gt; req.decode[UserAgeForm] { ageForm =&gt; UserService.edit(id, ageForm.age) flatMap { case \/-(Some(_)) =&gt; Accepted() case \/-(None) =&gt; NotFound() case -\/(error) =&gt; handleUserServiceError(error) } } } private val handleUserServiceError(error: UserServiceError): Task[Response] = error match { case DuplicatedUsernameException(username) =&gt; Conflict(s"Username $username already in use!") case UnknownError(throwable) =&gt; InternalServerError(throwable) } 2. You can just decode your QueryParam into UserSorting directly: implicit val UserSortingDecoder = QueryParamDecoder.decodeBy[UserSorting, String](UserSorting.from) object SortQueryParamMatcher extends OptionalQueryParamDecoderMatcher[UserSorting]("sort") Which cleans up: case GET -&gt; Root / "users" : ? SortQueryParamMatcher(sort) =&gt; Ok(UserService.findAll(sort))
https://github.com/http4s/http4s/pull/661 is this actual ? If it's truly just 3/25 then I'm not sure I can handle :D
Heh. I'll ask Ross for a status update tomorrow.
Is there a template / way to configure sbt so that I have multiproject with complete separation for scalajs clint/server? where server is some decoupled app, has no html no twirl templates, just purely backend, and frontend is scalajs, and it's all in pipleine where files get sha1 digest etc... I would serve the frontend using nginx... On every example the actual html files reside on server project with twirl template etc., which is not something I want.
Spay is no longer maintained and Akka http is "spray 2.0"
We've been frustrated with the Akka-HTTP (then Spray) DSL... IntelliJ would just give up attempting to parse the endpoint definitions! If I may bang my own drum for a moment (and this is the internet, so I'm going to :), can I suggest that http://fintrospect.io might give you the mix of things that you're looking for? It's essentially a thin layer over the base finagle-http which allows you to define typesafe HTTP contracts for both Server and Clients. . There's support for all manner of message formats (all the JSON libs/XML/MsgPack ...) and it auto-validates and marshals messages (and parameters) for you, as well as generating Swagger docs for your endpoints. The core module also has no compiler-crippling dependencies :) At the end of the day though, what you're buying with any Finagle-based system is an simple and elegant programming model (symmetrical Service/Filter interfaces for both client and server) combined with real battle-hardened technology which has a bunch of sophisticated features thrown in for free (load balancing/circuits etc...).
In a previous job I used the ScalaZ version in production (Cats was very immature at this stage; if I were still there I would probably have switched to it by now for political reasons). Obv. your exception tracebacks become a lot less useful - this is a real cost that some of the functional folk seem to want to sweep under the table, but it is manageable. Other than that no real gotchas. It was a small team and we were happy with it. At my current job I have a custom implementation in production-ish (internal tool). (ScalaZ is forbidden by policy; I may attempt to switch to Cats once it goes 1.0). This is a larger team where not everyone has much functional experience, so I've actually ended up using more concrete/specific names for parts of it, with just a small note about the "official" names (which I'm fine with; I don't think the name "Free Monad" is very enlightening or helps with intuition at all, and if it's not meaningful to the rest of the team then there's no value in using it). Also heavy comments (which I do think are valuable) and unit test coverage (which I think isn't actually adding any value but if it's what's needed to keep the rest of the team happy then I'll go along with it). Code reviewers were (rightly) skeptical about whether what I was introducing was justified in terms of the problem it was solving, but it was a problem that we did need to solve and my implementation at least worked.
I don't have extensive training in category theory, but I've been learning FP via scalaz/cats over the last year and a half or so and I know enough to be dangerous with it. I personally don't think it's a large investment, especially when you consider how long you've spent learning OOP anyway. For some reason people are okay with spending years and years of learning OOP and still not getting it right (OO is hard to get right), but they're not okay with spending maybe a couple years to learn FP and category theory. It's significantly harder to accidentally create a bad architecture with FP than it is with OO in my experience. 
We (Redbubble) are using it for a new project. It definitely is not as high profile as the Typesafe sponsored stacks, but I favour its (more) pure approach.
I mostly learned it from hanging out in IRC back when it was more active, and then also hanging out in the cats gitter channel. At first I ignored it when people brought up FP solutions or category theory. But I kept seeing it often enough that I decided maybe it was worth learning. So I just paid attention, asked questions, and applied it where I determined I could. I'm sure I have knowledge gaps, but those will close over time. I'm also sure I have knowledge gaps in OO though, so that's pretty moot. The big thing that kicked me in to gear was understanding the whole thing about "types are theorems; programs are proofs". Once I figured that out, I realized how unprincipled Akka was (I started with Akka), and then began to realize the benefit of composing things and ditching inheritance. I also read up a bit of Dependent Types which helped me understand some portions of shapeless. Lots of YouTube videos from things like nescala and typelevel summit really hit things off for me. The first one being Daniels video "may your data ever be coherent". That's when I really learned how to leverage types to create even safer applications. From there things just started falling in to place. Also, shout out to /u/tpolecat, /u/milyardo, and /u/dibblego for helping me out and explaining things to me. 
They also broke JavaScript! (The example switching links are not working for me)
I heard good things about this video series about category theroy: https://www.youtube.com/watch?v=I8LbkfSSR58&amp;list=PLbgaMIhjbmEnaH_LTkxLI7FMa2HsnawM_ Didn't watch it yet, but maybe that helps.
I think you answered your own questions. People are okay with learning OOP because as soon as you understand the very basics (which are easy to pick up), you can do a lot of stuff – but you're likely to do them in a terrible way. In FP, you have to learn the right way up front, so it's a steep learning curve before you do actually interesting stuff. This may deter people, especially those who don't care too much about the programming technology and just want to code things away.
I think that was me. :-) [/u/m50d gets it right here](https://www.reddit.com/r/scala/comments/588nuh/lightbend_and_typelevel/d8yhmn6). Taken as a whole, the communities overlap some, and it's certainly true that there are many people in both communities (to the extent we can even define those boundaries) who know and respect each other. I definitely know and respect at least half a dozen people at Lightbend, and they know me... ;-) I really intended "I'm one of those Typelevel guys" as a kind of convenient shorthand to say: there are architectural differences among frameworks, and the more OOP-y, MVC-y, imperative-y, reflection-y, etc. a framework is, the less likely I (and most other developers I tend to hang out with) am to choose it, because my preferences run strongly to the pure FP approach to programming. I didn't, and don't, intend a value judgment on any community or technology many other people choose for good reasons.
You don't need to know any category theory at all, but it can help you to see how some things fit together. The amount of category theory I know I could write down on one sheet of paper. The number of people with "extensive training" is almost zero.
That's some solid advice. I think I'll take the advice to heart and start with working on an ideal generated datastream before worrying about the endpoints, that will help me get a better understanding. Since I'm basically just sending well defined arrays of 32bit ints over the net I don't think raw tcp is a problem, but I duly note your concerns, maybe I'm very mistaken in thinking that I'm keeping things simple since I've never really done anything like this. With the loose coupling offered by scala it's not like I'm gonna paint myself into a corner anyways so I could try several approaches. You're right about the documentation on fs2, I think I'll start with akka streams and take it from there. Thanks for the advice :)
Ditto (using Chrome).
Or get on the `typelevel/cats` channel and ask someone. We are very happy to help. That's a big part of what we do.
Do you have some examples you'd like to have explained? The nomenclature definitely is unfamiliar if you don't at least have some background in abstract algebra or category theory, but the dirty little secret of FP is that the concepts themselves are really trivial: * Semigroup: a binary associative operator, like `+` or `*`. * Monoid: a semigroup with a zero element, e.g. `Int` forms at least two monoids, with `0` as the zero and `+` as the binary associative operator, or `1` as the zero and `*` as the binary associative operator. * Functor: a structure you can `.map` over. * Applicative: a structure you can `.map` over, having some context that can't be shared. * Monad: a structure you can `.map` and `.flatMap` over, having some context that can be shared, which implies that monadic operations are done sequentially. * Traversable: a structure you can apply a monadic operation to all elements of and/or fold into a smaller structure. There. That's easily 90% of the abstract algebra/category theory you'll ever use in FP. Each of the above also has certain laws it must obey in order to actually be what it claims to be, but there's no need to spell them out here (you can look them up if you're really curious).
Okay, makes sense so far. Thank you. Problem: I still cannot use this nomenclature myself, without knowing the “certain laws” you mentioned.
Once in a while we get a post here about how scala is bad because its community is toxic. I just want to mention that this thread is a good counterexample.
We use scalaz and shapeless at work and our team is pretty much all new grads and I was a new grad when I lead the team to start using those technologies. If we can do it, so can you!* \* so long as you *actually want to learn*
I still think it's a good choice: Debasish doesn't just talk about Scala, but even when he does, it should read pretty easily as F#, in the same way that Scala reads pretty easily to my OCaml programmer's eyes. :-)
Why not? Oh, I think I understand: you wouldn't want to try to develop your own `Monad` or whatever. Yeah, fair enough. But you don't have to: scalaz and Cats, for example, already provide all of these typeclasses and property-based tests of the laws. Also, one of the main reasons to like the `Free Monad` stuff you sometimes read about lately is that you just define an "algebra" (i.e. a `sealed trait` hierarchy) and you can trivially build a `Monad` automatically from it in just a few lines. Then you just write a little interpreter from your `case class`es to some other `Monad` you already have, like `Task`, and you're done. It's the lazy way to write your own `Monad`!
It's not a follow-up of FP in S. A follow-up would continue where FP in S would finish and dive more deeper into the FP mindset, but that's not what's happening here. It's more focused on how to do domain modeling in the FP-world and geared towards programmers familiar to DDD. So it's more a follow-up on Vaughn Vernon's Implementing DDD (https://www.amazon.com/Implementing-Domain-Driven-Design-Vaughn-Vernon/dp/0321834577). That being said, I still found it worth reading, especially the first half. It's a practical view on how to separate side effects, how to inject dependencies, why and how to use free monads, natural transformation etc. The second part is more focused on the reactive part using akka-streams which I found less interesting. 
Oh, yeah, sorry about that.
Because Dotty abandoned general type projections, precisely because of that specific discovery. So they did break Dotty at the time of the discovery.
Yeah, and I've actually tried using it against a cluster. Not so pretty or easy then... :-S
That implies running the Toree kernel. According to OP's requirements (Ammonite repl, no mention of Spark as being the primary/only use-case, etc.) I think that's not the right answer. Rather, the [jupyter-scala](https://github.com/alexarchambault/jupyter-scala) kernel provides most features requested by OP.
Do I need to read Vaughn's DDD book before reading this book?
Why not use cats? I heard scalaz is stopped development.
How do you think Finch and Akka http?
But looks like there is no grpc sdk for Scala. I am still waiting for it.
What way did Martin and haoyi suggest? 
Do you see any path towards a more intuition-friendly nomenclature? "Traversable" is good (a traversable is something you can traverse), and maybe "Applicative" is ok (though "apply" is a horribly generic name for an operation especially in Scala where the word already means something different), but the rest are either meaningless or outright misleading ("Functor" in particular I still have to constantly remind myself means something very different from what it sounds like). I've written two internal-only libraries that offer these concepts with more use-oriented names that reviewers at those organizations felt were clearer. I guess I could start maintaining a set of aliases on top of cats or something, but since error messages in Scala tend to use the "original" type I fear that would only add more confusion; likewise creating yet another library of functional typeclasses. I've got enough experience at this point that I feel confident to say that the standard fp names really are just bad, that we really could improve the beginner experience a lot (at relatively low cost) by changing them. But I have no idea how to effect that, or if it's even possible.
Martin gave a keynote talk for Scala days 2013 and 2014. And Haoyi has series talk on Scala strategies, have a look of his blog.
I've found it was always fine in Eclipse, and horribly broken in IntelliJ. (This isn't due to Cats doing anything particularly weird - basically any code that uses dependent types (at least higher-kinded ones) is broken in IntelliJ, and because of SI-2712 any library that uses typeclasses has to use the `Unapply` hack to offer a non-horrible user experience. I would expect ScalaZ to be horribly broken in IntelliJ too unless IntelliJ contains some ScalaZ-specific hack (which, to be fair, I wouldn't put past them)). Particularly if you haven't tried actually doing the same thing in both, I wouldn't draw a big general conclusion about the level of IDE support in both projects (I would make a bug report with scala-ide for the eclipse issue though).
I know, but Spray continues to work and work well, at least for me.
"I don't care about the asymptotic performance" is probably the most common use case and certainly the most beginner-facing one. So it seems unfortunate to make that the case that requires typeclassing (and therefore e.g. won't show up in IDE autocompletion as readily as the specific methods).
I don't think Scala's document is worse than Go.
Well, I suppose to a point that's subjective. But Go has things like the tour, guides on how to write go code, "Effective Go", an FAQ with some excellent questions and answers in, a helpful wiki, a short and clear language specification, and very clean and clearly designed code documentation. Then there's other little cool things, like the Go playground too. I know Scala's code documentation is being updated, and I've never really had a problem with it, but the documentation site, as the original post lists, does have a _lot_ of problems that if solved would make Scala much more accessibly and welcoming. Go's isn't perfect, but it is very, very good. In my opinion, it makes Scala's documentation look pathetic.
I have a lot of scalaz feature code and tests. While Intellij requires time to verify it - it does verify, compile and the tests run. Currently, I can't develop many of those same features in cats using Intellij. As I recall, there is an outstanding Intellij bug report filed by cats users. I can't find it at the moment. But, hopefully, cats development in Intellij will work well in the future. See: https://youtrack.jetbrains.com/issues/SCL Ensime still doesn't fair well with cats. But Eclipse seems to have no issues this morning with my cats work. I thought it was having issues at one time. Operator error, perhaps.;)
IDEs can adapt to the change by knowing what typeclasses are available (in scope or not) and providing the autocompletes.
I've been using it via [ScalaPB](https://trueaccord.github.io/ScalaPB/grpc.html). I have an example project for [gRPC with Scala here](https://github.com/vyshane/grpc-scala-microservice-kit).
I understand the impetus, but I think it runs into two problems: 1. I haven't heard any alternative names that aren't too vague, and I find specificity in these things important, at least in the long term. 2. Alternative names cut users off from the literature and other functional languages. This is a general problem with trying to simplify things, especially for newcomers. It really seems to mostly be a matter of shifting learning costs, and possibly even imposing new ones. It's a very thorny issue!
That's the mythology, yes. I mean, yes, there was a coup in which Tony Morris was ousted (and I have a _lot_ of problems with how that was done). But scalaz had, and continues to have, more than one developer. If you look at the [scalaz commits](https://github.com/scalaz/scalaz/commits/series/7.3.x), you'll see it remains in very active development. Important libraries like [Doobie](https://github.com/tpolecat/doobie) and [http4s](http://http4s.org/) continue to build on it. At least three of my colleagues at Verizon Labs are active scalaz contributors. Suggesting scalaz is dead because of a long-ago coup against Tony Morris _wildly_ overstates the case.
The reason people are kind of looking at FPiS and Functional and Reactive Domain Modeling as related is because they both _do_ mean "functional" in the "pure," or "Haskell," sense.
I'll go ahead and say it: someone's lying. BTW, you don't have to settle for "heard." scalaz is [open source](https://github.com/scalaz/scalaz). See for yourself.
IntelliJ gives auto complete for ones in scope. I doubt it'd be terribly difficult for it to give suggestions for ones that are out of scope.
What's you or your colleagues opinions about scalaz vs cats? Since cats is under typelevel umbrella, why you guys don't contribute to cats? 
Same here in Chrome, but it works fine in Firefox.
Several do. Let's have a look: * Rúnar Bjarnason—recently left Verizon Labs, contributor to scalaz * Cody Allen—contributor to scalaz and Cats * Stew O'Connor—contributor to scalaz and Cats * Vincent Marquez—contributor to scalaz * Ross Baker—contributor to scalaz and Cats * Daniel Spiewak—contributor to scalaz and Cats There are probably others I'm forgetting.
At the time of reading this book, I had not read DDD. I had no obstacle learning from this book despite having not read DDD. In short, my opinion is no - it's not necessary to read DDD before learning from this book. 
Very good point, thanks for taking the time to write down how you would have done it. In this example I used UserNotFoundException but you're right, I'd rather use Option[User] to represent a "maybe" value. Cheers, Gabriel.
I'm glad you're finding this stuff helpful! I don't know anyone using scalaz-eff in production yet. Verizon Labs has definitely used both monad transformers and monad coproducts. Which is preferred seems to be more closely associated with the engineer than the type of code, i.e. it seems to be primarily a matter of personal preference. A couple of notable exceptions: Daniel Spiewak points out that monad coproducts don't deal well with a couple of types of monads. Continuation monads are one of them, and I forget what the other one is (maybe `ST`). His observation is that sometimes the predefined order of the monad stack you get from monad transformers is _exactly_ what you want. And, of course, he's right. So I guess that's the kind of handwavy guiding principle I'd suggest: think hard about whether the order of monadic effects matters in your case or not. If it does, then you want monad transformers. If it doesn't, you can get away with monad coproducts. I should add that all of this motivated Daniel to write [Emm](https://github.com/djspiewak/emm), which I forgot to mention earlier. But I don't know if Daniel believes Emm is ready for prime time yet, either. On the third hand, it never will be if no one uses it... :-)
And I wonder if any one has done a comprehensive comparison between the two. Which of the f/w is more friendly for devops?
It sounds like you want a sealed trait with three implementations
Whoops, I think I need to elaborate more. The types that could be returned are any of the HTTP response codes, the example just uses 3 of them. Each method could return any combination of these response codes. For example I may have these methods: def getAccounts(): AnyOf[OkResult, NotFoundResult, BadRequestResult] = ... def createAccount(account: Account): AnyOf[OkResult, UnauthorizedResult, ConflictResult] = ... def getEvents(): AnyOf[OkResult, BadRequestResult] = ... Since any method could return any combination of response types, I believe I need something more flexible. I don't think a sealed type would work in my scenario.
May I ask why the objection to nested `Either`s? Is it readability of the types? You can certainly alias the name to something more manageable, e.g. // pkg.scala package object pkg { type +[A, B] = Either[A, B] val + = Either } // Whatever.scala package com.my.pkg object Whatever { def getAccounts(): OkResult + NotFoundResult + BadRequestResult = ??? def createAccount(account: Account): OkResult + UnauthorizedResult + ConflictResult = ??? def getEvents(): OkResult + BadRequestResult = ??? } (See http://stackoverflow.com/a/39950511/20371 for this aliasing technique and http://jim-mcbeath.blogspot.ca/2008/11/scala-type-infix-operators.html for a short intro to infix type notation.) There's also a `scala.scalajs.|` (I believe that's the right classpath, someone correct me if I'm wrong) type that works like `Either` but is just up-and-down casting so I wouldn't really recommend it.
This sounds like what I'm looking for, thanks! Have you used Shapeless in scala.js? Any idea what size it is? I'll give it a try in a few minutes, just curious if you already had experience. I would prefer a lightweight solution, but I'd probably be fine with pulling in the whole library or pruning it down if it means I don't have to reinvent the wheel.
This comes up pretty frequently. It's coming in Dotty as Union Types. To me, another way to think of it is as an anonymous, ad hoc, sealed supertrait. I have wanted the same thing, for the same use case. The verbosity of today's workarounds is pretty unsatisfactory to me.
From my perspective, it's not really divided at all. Lightbend tends to focus on toolkits for systems architecture, supporting Scala and Java. The APIs of these projects tend not to exercise the most exotic Scala language features, probably for reasons of harmonizing between the languages. Typelevel tends to focus on developing abstractions built using the Scala core language features, often in advanced and innovative ways. Many, many teams rely on libraries from both within individual codebases. Put together, it's a relatively small but extremely robust ecosystem. I think there's more of a distinction between Lightbend's platform and Twitter's systems toolkits.
I think that what you really want to return is a shapeless `Coproduct` of the status codes as in: def getAccounts(): OkResult :+: NotFoundResult :+: BadRequestResult :+: CNil = ???
No magic. That's the big one for me. No annotations, no reflection, no "what's instantiating my class and how's it doing it". No "you can't customize this part". Everything is just plain scala code. Any directive you can click through in your IDE and see the actual implementation. Any commonality you want to factor out, you can, without having to wonder whether annotations are going to be applied correcty to method overrides or anything like that.
Can you please share the books and videos @paultypes recommended? Thanks.
I am partial to Finch but it is more a matter of personal preference. I have never done a huge amount of work with Akka HTTP. 
To be fair, nobody ever submitted a PR to scala-lang.org with a change to highlight Scala.js. And by nobody I mean even no one from the Scala.js team, so I am to blame as much as everyone else.
I don't know, I haven't used enough akka-http to really notice. 
[Akka Http is officially Spray's successor](https://github.com/akka/akka-meta/issues/27#issuecomment-245713756). As I understand it, it's basically a rearchitecture of the whole undercarriage to be built on Akka Streams, while providing a very similar high-level API. Performance was slower at first, but they've already demonstrated how dramatic improvements coincide with development on Akka Streams, so it's cool to see that work make an impact. Not sure what the latest performance comparisons look like. But probably the most important thing to note is that the ecosystem has made the shift over to Akka Http, and going forward, that's where the action is going to be.
A bit of confused. Why doing Haskell is lucky? Doing Scala is not lucky? I am wondering how many existing so called Scala lovers doing Scala just because not enough Haskell job in the market? And if there is Haskell job they will all jump. In my mind, if Haskell is really a good language, now it should be much more popular than Java and c#, however it's not. Why?
Do you think you could elaborate on how this would be used by a consumer? I'm trying it out in a unit test, but I'm not quite following what the best way would be to handle each result. This is my poor attempt to pattern match, but I assume there's a far more elegant way to handle each case: getAccounts() match { case x if x.select[OkResult].nonEmpty =&gt; { failure("Received OkResult") } case x if x.select[NotFoundResult].nonEmpty =&gt; { failure("Received NotFound") } case x if x.select[BadRequestResult].nonEmpty =&gt; { success } } Sorry if you already covered it, I'm trying to find as much documentation on Shapeless coproducts as I can, but it seems like easily digestible articles are hard to find.
The implicits can certainly be surprising to those unfamiliar with them, but they were there all along; they are standard Scala and standard Scala tools will work on them (IntelliJ doesn't work properly with them, but that's because IntelliJ doesn't work properly). You can do the same thing in your own code with Finatra or any library or none. What I mean by "no magic" is that everything is standard Scala and the ordinary rules of Scala apply, which in turn means things like "find references" work correctly. Once you use something based on reflection and annotations that's no longer true.
Scala Hamsters lib has a feature to accumulate and validate a sequence of Either operations : https://github.com/scala-hamsters/hamsters#usage (Validation OK/KO relies on standard Either types) You can also use hamsters monad transformers to deal with options of either in a for comprehension easily.
Are reflection and annotations not also part of the language? :) And I'm all for implicits, but Akka Http goes to soem pretty extensive lengths with them, and IntelliJ aside, the compiler even struggles to give informative feedback when you don't get it right.
This is one of the best programming books, period. Every Scala programmer should read it.
Why can't you just use a set?
Is it possible in Intellij to create ScalaTest run configuration that will run all suites in aggregate project, like simple "sbt test" in terminal does? [Here's my current main sbt file](https://github.com/oleg-py/mco/blob/sfx-ui/mco.sbt). Subprojects are specifying their own dependencies.
How do other, similar languages deal with this issue? Say, C#... They don't have type erasure. Is this only an issue for Java/Scala specifically because of the type erasure? Sorry, I'm still learning about JVM, and don't know a whole lot about .NET yet. :) Working on it though!
I went to check and noticed it's at a comparable price on bookdepository. No idea if they price matched manning on that one or if it's a long running deal.
Whenever I think I'm hot shit I read this book just to be humbled
I've read that it's possible to implement Try with resources in Scala. http://codereview.stackexchange.com/questions/79267/scala-trywith-that-closes-resources-automatically But I'm thinking that this doesn't necessarily play well with futures / tasks / promises. What would be the equivalent way to ensure that a resource is disposed of properly if there were futures being called inside that TryWith block? Or is there some other pattern that could be used considering that the author mentioned that Try is a monad?