Every programmer should read it :-) even not aspiring FP programmers, at least first half. From "junior dev" to "whitebeard architect". Just every programmer.
I don't think annotations with behaviour are part of the language - particularly if they're implemented via bytecode manipulation. The language specifies annotations sure, but not that they do anything (except for the ones in the standard library). Reflection... I don't know what the spec is, but it violates so many rules of the language as to make it practically impossible to reason in the presence of reflection. So I find it more productive to regard it as not part of the language. Implicit errors certainly could do with more work, mostly on the compiler side I think. I still think they're worth it - a cryptic compile-time error beats a clear run-time error most of the time - but yeah, they're not great and there is a legitimate trade-off here. 
I agree with all the criticisms of akka-http, especially getting the implicits right. We were training a few java guys to use spray, and they had that whole "scala is complex" mindset. I felt pretty dumb when I was struggling to figure out their unmarshallable errors when I was suppose to help train them in scala and spray. That's when we looked at Play and found it more straightforward--especially for newer scala developers. 
In a terminal where you have a sbt project start the program `sbt`. After sbt loads write ensimeConfig then press enter.
Hey, thank you for your reply. I got the following error after following the instructions given: &gt; ensimeConfig [error] Not a valid command: ensimeConfig [error] Not a valid key: ensimeConfig [error] ensimeConfig [error] ^ &gt; 
If you like Finatra, do Finatra! I really have no idea what it's like. &gt; How do you do exception handling, swagger support, embedded server tests, admin panel, metrics, request logging, filters, etc with akka http? those are things I care about and want to be super easy. Exception handling, metrics, logging, &amp; filters have all required some manual work, since the toolkit itself is fairly barebones. But with so many composable building blocks provided, I found it really easy. We haven't set up Swagger, so can't help you there, and not sure what you mean by embedded server tests. Admin panel sounds like crossing over into Play territory. &gt; can you replace the serializer with akka http? Yeah, totally: https://github.com/hseeberger/akka-http-json &gt; How are clients created for akka http, does it have utilities to make that easy? Do you mean for consuming other HTTP services? For the simplest interface, you've got http://doc.akka.io/docs/akka/2.4.11/scala/http/client-side/request-level.html#Future-Based_Variant, and you can peel off layers of high-level functionality if you need more control. &gt; what's the back compat story for different versions? The framework is *just* crossing over into non-experimental territory. That has less to do with production readiness than it does with the core teams assurances of compatibility, and that's something Lightbend takes really seriously. That's good enough for me, but each team will have to decide what works for them. &gt; I really wish that framework writers would just spell all this out so those of us who actually need to care about these things can just see it I hate to say it, but in Scala world, this is tough to come by. It's an RTFM environment, and TFM isn't necessarily written to put these details up front. But I will say that in my experience with Lightbend software, once I do RTFM, I've been nothing but impressed with how robust it is.
I'd argue Play is best for both. We use it to create HTTP interfaces for back-end services. I would say Play is even better suited for that because all it is url -&gt; controller in the routes file. Like you said, the request flow and rejections can become cumbersome in Akka-http depending on what you want it to do. In Play, it's straight forward.
It's all a matter of taste :D I haven't used Play in a couple versions, but I thought it was pretty great last time I did. I do think that being more of a framework than a toolkit, you lose a bit of the ability to abstract over things, like in the original article. But not everybody really needs all that.
Scalaz code got wrecked by the same individuals who copy/pasted all the bugs over to cats when they failed to take over ownership under a disguise of moral highground. If you need a FP library in Scala today, write it yourself.
AFAIK there's no nice way to pass resources directly between futures/tasks/promises. If the two don't need to interact I would use [scala-arm](http://jsuereth.com/scala-arm/) for managing the resources and just make sure never to start futures etc. inside the body of `acquire`/`acquireAndGet`/`foreach` (it would be possible to enforce this with [this technique](https://apocalisp.wordpress.com/2011/03/20/towards-an-effect-system-in-scala-part-1/), but I don't think I've ever seen a library that actually does that). If you need resources and async that actually interact, take a look at [fs2](https://github.com/functional-streams-for-scala/fs2).
That's awesome, I made https://solitaire.gg using Scala.js and Pixi, and it was really happy with how well it worked. I'll keep an eye on your facade project, I mainly just passed around js.Dynamic instances.
Fwiw, word2vec is not deep learning. It's a neural net, but a shallow one. Also, Spark's implementation of NN's is not great, and computation is slow. Not sure why you'd use that when there are better one's out there. 
&gt; Also they ban the use of scalaz and other heavily functional libraries. Out of curiosity, why ? Is there any kind of company that uses scalaz besides ? 
It seems to be a good compliment to Programming in Scala. E.g., has a slightly better explanation of what Odersky means when he says, "local, flow-based type inference" (i.e., that this can mean "across parameter lists"), and a little more emphasis on by-name parameters and how they provide lazy evaluation in Scala. No surprise, though, since the books have orthogonal goals. FPiS has a lot of exercises and exposition very reminiscent of other functional programming tutorials. It's a little dated now (e.g., no implicit classes) but it's still worth reading for those are interested and have the time. It would also be nice to see some discussion of dependent types in its style. Unrelated: [this review](http://typelevel.org/blog/2016/08/21/hkts-moving-forward.html) was what piqued my interest in the book. 
FPiS introduces a lot of concepts so i think a good follow up is any books going a little further on these topics. [Category Theory](https://www.amazon.com/Category-Theory-Oxford-Logic-Guides/dp/0199237182) by Steve Awodey is a very nice book to understand how functor/monads/freedom really works. After reading it, most of the tricks of Cats/Scalaz will make sense. The [Coq Art](https://www.labri.fr/perso/casteran/CoqArt/), especially chapters on propositions as types and (co)-inductive types clearly explains the ideas behind most of Shapeless magic and implicit wizardry. FPiS does give a good introduction to advanced typed-functional programming concepts, enough to develop a good intuition and use them efficiently. But there is no need for a follow up in Scala. To go deeper there are only domain-specific, mostly academic, books.
To expand on /u/oleg-py's answer, please see https://scalafiddle.io/sf/daR8GaG/0 I took the liberty of right-biasing the type — as is customary — so that's another difference from your original code.
&gt; And also in confusing the ever-loving daylights out of everyone that doesn't have extensive training in category theory. This is exactly the opposite. People do not go into Cats/Scalaz after an extensive training in category theory but they go into category theory after an intensive and often prolific use of Cats/Scalaz to better understand concepts at play.
As someone new to Scala, not looking to get a job in the industry for Scala anytime soon, should I be using Dotty?
No. Dotty is still in the very early development stages, meaning there may yet be features that will be included but are not even implemented yet, and features that exist in some form now that won't make the final cut. There's far too much variability in what "Dotty" means today to make it an effective target for learning Scala, even given a planning horizon of years.
Given the slow pace of scalac development over the past year or so I wouldn't be shocked to see production Dotty happen sooner rather than later (i.e. sometime during 2019). Really, it's looking more like 2008 than 2012 wrt to [scalac activity](https://github.com/scala/scala/graphs/contributors) which probably means the Scala compiler is no longer a high priority item at Lightbend with Dotty on the horizon. Basically, get 2.12 out the door; maintain it, but don't go full bore trying to fix present day Scala since it's already being fixed in its replacement.
Happy to answer any questions :)
I don't think that any of this is given, especially the "replace scalac with dotty".
That's why it's a good thing we have different libraries for the same theoretical concepts: the Scalaz family and the Cats family for structural concepts and the Finacle family, the Akka family and again the Sacalz family for distributed systems. There is no way the transission to Dotty will be painless (otherwise it would be pointless), and very likely some of these libraries will not survive. But at least there will be a chance one can switch to a different library fulfilling basically the same purpose. Not great, not easy, but at least possible. This should help to avoid the "network effect", keeping many people at Python 2.
&gt; It will be interesting to see how TypeLevel proceeds with the transition. Scalaz, Cats, Shapeless, etc. do indeed depend on "hairier" type system features, features which Dotty will need to provide (or sufficient alternatives) in order for TypeLevel to play ball wrt to a timely transition. Dotty makes almost everything in the Typelevel stack much _easier_ or simply _unnecesssary_. For example, Dotty has union (sum) types. Poof, there goes `Coproduct` from Shapeless, scalaz, and Cats, or at least they get dramatically simplified by having a typeclass that wraps the native type. For sure, a lot of the working around of scalac misfeatures such as the notorious [SI-2712](https://issues.scala-lang.org/browse/SI-2712) go away out of the gate. In other words, keep in mind that Dotty is strictly more powerful than current Scala, _and_ is a much cleaner, less buggy design. The Typelevel stack isn't taking advantage of scalac bugs and therefore in danger of being "corrected" out from under; it's implementing features that should have been in the language in the first place, and working around scalac bugs.
I am watching Scala JS and Scala Native both maintain JVM stdlib sets separately. I understand that there are several things that are not reusable between them, but is there any room for abstraction? I see issues like [this one](https://github.com/scala-native/scala-native/issues/287) and I get scared that an improvement on one side may not make it to another. Even if code can't be reused, can tests? Or maybe share a repo or something that lets one side know an update may be worth applying to the other? Just a thought... Edit: Actually https://github.com/MasseGuillaume/multi-platforms-javalibs appears to be doing yeoman's work
I think implicits in general are awesome. Implicit conversions, though, deserve their shitty reputation. 
They don't need to. I keep linking to [Using category theory to design implicit conversions and generic operators](http://repository.cmu.edu/cgi/viewcontent.cgi?article=2276&amp;context=compsci) for this reason.
This looks very cool but I'm wondering why in the custom formula section you had an ALGOL-ish let statement with a very LISP-y map statement.
Well, there is a number of orthogonal concepts, all of which work together to bring you nice ADTs: - **Pattern matching** - a powerful tool that allows you to deconstruct objects satisfying some conditions. Drop by first chapters of [The Neophyte's Guide to Scala](http://danielwestheide.com/blog/2012/11/21/the-neophytes-guide-to-scala-part-1-extractors.html) to learn more about how to use it with custom objects and checks. - **Case classes** give you a sweet pile of syntax sugar for making value objects - `copy` method, equality, a companion object with factory method and extractor for pattern matching. I've seen plenty of articles praising case classes for those things (and comparing it to Java), so just google if you need one. - **`sealed`** traits and abstract classes can only be extended in the same file they are declared. This arms compiler with knowledge about what descendants your type has, so it can warn you about ones you've forgotten in your match clauses. For a bit of that, its quirks and a bit about ADTs in general take a look at [this blog post](http://underscore.io/blog/posts/2015/06/02/everything-about-sealed.html)
Ascii vs not isn't really the issue - `⇏` is if anything clearer than `-/&gt;`. There are still a bunch of types in ScalaZ whose "official" names (i.e. the ones that show up in error messages) are non-alphanumeric - `\/` and `\&amp;/` come immediately to mind. (It looks like `~&gt;` has become the alias though? That's a great piece of progress. Or do I misremember and it was always like that?)
Using Scala code from Java should work fine yes. (It sounds like your problem is probably an SBT issue, which I can't/won't help with - just saying you're right that it should work).
You will need [at least] the Scala standard library on the classpath. If you do `show fullClasspath` in sbt you will see the full list of dependencies.
Let me highly recommend [sbt-assembly](https://github.com/sbt/sbt-assembly).
I get the same problem when using an `sbt assembly` built JAR :(
You're node definition does not align, in the case class you do first e then l and r, but in the match you do l then e then r. &gt; case class Node[T](e: T, l: Tree[T], r: Tree[T]) &gt; case Node(l,e,r) =&gt; Node(mapTree(l),f(e),mapTree(r)) You also didn't pass the function to the next maptree call, which is what the compiler is tripping about, so the case should be: case Node(e,l,r) =&gt; Node(f(e),mapTree(f)(l),mapTree(f)(r)) 
Thanks for pointing that out, however I still get error messages. Depending on whether I add : Tree[B] or not to l and r the errors differ, but they are still the same as explained in the post
I've seen this problem when I compiled code against the scala 2.10 library, but had the scala 2.11 library on the classpath at runtime (or vice versa). I guess make sure that the scala 2.11 library is what's in your runtime classpath.
&gt; I would love to call it leaf btw, but it's for school and the names are provided This is mildly infuriating to me, and I'm dyslectic.
Hello, we use SQS at work and make use of the AWS-wrap library here: https://github.com/dwhjames/aws-wrap You can use any library that you like to take your incoming Scala domain object and transfer it into a JSON string before placing it on the queue. Personally, I like Circe and JSON4S. Here's a little something to get you started. https://gist.github.com/calvinlfer/1dabf251bf4026a1fbc8b70ffd6396e1 We actually place this in actors, so we have a reader actor, a dead letter actor (for bad messages), a deleter actor, etc. It works really well as the others have mentioned. If you are using Play, Akka is already present and you are ready to go https://www.playframework.com/documentation/2.5.x/ScalaAkka
Perfect! Additionally that may be one of my favorite URLs.
An akka/rabbitmq-driven app works well. See https://github.com/objektwerks/akka.clusterx for an example. See the core subproject for specifics. The same github contains some other interesting akka-rabbitmq integration projects. The camel suggestion herein also sounds interesting.
Yep. Pretty much. It frustrates me a bit that Scala continues to be judged by how it is perceived to measure up against Java. Scala has a bright future beyond the JVM, which is proven by Scala.js, and I think we'll rapidly start to see the same in Scala Native. Whether the latter begins to make an impact in the Go / Rust space, we'll see. But this is where Scala's competition is, with the other progressive languages for systems and applications. But Java will remain a massive ecosystem on its own way beyond my horizon of foresight. It's not sexy, but it is tried-and-true, and very predictable. Java's competition is basically .NET. Lightbend was very savvy to supporting both languages, because that appeals to more risk-averse Java shops and more cutting-edge Scala shops. The overlap is not that great, but together, it makes their tech hit a very comprehensive cross-section.
SBT. :trollface:
All good points. But other languages are challenging Scala, like Kotlin; and in the non JVM space languages like Elixir, and to some extent Go and ES6. Scala's future is not guaranteed, assuming so is a little, well, presumptuous. 
&gt; We've chosen a message queue and processing the messages with actors sounds like a good idea. Can I ask what message queue? And I disagree with the latter claim. See [my other comment](https://www.reddit.com/r/scala/comments/59podo/where_to_start_message_queue_processor/d9b8gvv/) for an alternative.
So since Java added Lambdas it's the superior functional language? That doesn't make a lot of sense to me, Scala has a much richer type system allowing for you to do a lot more complex thing in it. Java is a great language because it's simple, Scala is a great language because it can do a lot of the same things Java can do, but also can do more complex things. I'd pick Scala if I had a specific case in mind, in which I felt it'd excel at. I think it's not useful to compare languages because people should be picking languages based on the language being the best for that specific use case, not because it's the hip cool thing to do. (Although people do that all the time) I also don't think anyone thought Scala was going to replace Java, but Scala has been a good catalyst for driving some of the features put into Java, which is nice.
SQS to begin with, we may switch to something else at a later date. The reason why actors makes sense for us is because each message will be an array of multiple objects that need processing and will have no impact on each other so we can fan that out nicely.
What about: def /!\ (msg: String) = System.err.println(s"Warning: $msg") ... if (ls.isEmpty) /!\ ("No files to process!") Also, something genuinely useful that I use all the time to add effect to simple expressions: implicit final class Andable[T](private val self: T) extends AnyVal { @inline def and(f: T =&gt; Unit) = { f(self); self } @inline def oh_and(effect: Unit) = self } Use it like: private var count = 0 def freshVar = Var("x$" + count) oh_and (count += 1) ... a =&gt; if (a.isTrivial) a else readVar(freshVar and (bindings += _ -&gt; a)) It's also very nice for debugging, as it lets you insert statements anywhere inside a big expression with minimal changes. Say you have `foo(bar(42))` and you'd like to temporarily print the value of `bar(42)`. You can now just add a bit of code at the right place: foo(bar(42) and println) Instead of something that requires way too many key strokes to write and revert later: foo({ val b = bar(42); println(b); b }) 
Hey there, Akka is simply a toolkit for building concurrent applications in a easy-to-think-about manner via the use of the Actor model and message passing. You can use it to define asynchronous boundaries between un-related tasks to get a lot of performance out of your system. Hope that helps 
https://github.com/Homebrew/homebrew-core/pull/6353
I dont remember Scala being in TIOBE on #13 place... didn't someone debunk it?
Also some improvements on `Future`: https://github.com/viktorklang/blog
Yeah, fair enough. Personally, I'd still use streamz with an [SQS Camel endpoint](http://camel.apache.org/aws-sqs.html) and do the M:N thing with fs2, but that's because I'm a scalaz-stream gearhead. Note that streamz supports Akka-Streams too, so you might still find some value in it, but then again, you might not. :-)
In your professional opinion, what do you think the odds are that this commenter understands the JRE 8 limitation, lambda factories, or even how futures worked in 2.11?
In my professional opinion it's 38.761%
I will certainly look into trying that out. I'm just worried about jumping into the deep end too soon. I've got the weekend to play with prototyping that out though. :D
Yes, [here](https://gist.github.com/anonymous/5df1f1f6c6b6ebbb4dc67b2bc4da4eae#gistcomment-1891917), as is also quoted in the article.
False! It's obviously 12.5%- AT MOST
Toxic! Scala community is so toxic!!11
No. It's only officially released when there is an announcement blog post on scala-lang.org.
I was sat there thinking for a bit, what does the /!\ operator mean at the def, but when I got to where you were using it I burst out laughing, thanks :D
A GitHub tag is even less of a proof than artifacts on Maven. ;) At least Maven is immutable. A git tag can be deleted and recreated. In Scala.js we actually do that sometimes, because our release testing procedure requires a git tag to be created. If the tests after that fail, we have to delete the tag. Once it's on Maven, though, you can't roll back. The only thing you can do if you discover a critical bug at this point is to never announce that release, and publish a new one.
Heh. Yeah, if you've got a job to get done and know Play! and Akka, the other suggestions are, I think, your best bet. If you haven't played with Akka Streams or fs2 and have the luxury of some experimental time, I hope you try 'em and enjoy 'em as much as I do. :-)
Maven is not immutable. You can overwrite any version in the repo with different artifacts. I may have done that once or twice to save my ass :)
And too complex. The Scala community is too complex!
Sure but you can't remove it. So putting an artifact name out there is a big deal
Thanks for sharing. Seems like the only option to expose my WSDLs is to use Apache CXF. There is a play-soap subproject but it's still wip as far as i understand. I found another one, play-cxf which has already been updated to support latest play framework, so i'll probably stick with that. Reactive kafka seems cool, i'll look into it. I have to learn akka and akka streams first. That will keep me busy for the next few months.
Even worse, some of external systems use FTP to send us data.
you can take a look at the [giter8 documentation](http://www.foundweekends.org/giter8)
It's a valid point. Scala.js and Scala-Native do not have the same level of maturity. For this reason, in the short term, they should work in isolation. In the longer term, we will find a solution to avoid code duplication.
So you have to deal with SOAP, FTP, and a message bus. This shifts my thinking from my previous response to using Apache Camel via [streamz](https://github.com/krasserm/streamz), which supports streaming to/from Apache Camel endpoints with either Akka Streams or fs2. Camel has endpoints for [SOAP](http://camel.apache.org/soap.html), [FTP](http://people.apache.org/~dkulp/camel/ftp2.html), [Generic JMS](http://camel.apache.org/jms.html), [ActiveMQ](http://camel.apache.org/activemq.html), [Generic AMQP](http://camel.apache.org/amqp.html), [RabbitMQ](http://camel.apache.org/rabbitmq.html), [Kafka](http://camel.apache.org/kafka.html), and many, _many_ more. So if you're planning to learn Akka and Akka Streams anyway, I suggest adding streamz to the list. Then you could use Play! to write, e.g. admin/monitoring dashboards etc. for your ESB.
Web crawler/scraper using fs2 streams https://github.com/KadekM/scrawler It's still in very early/explorational phase... but I've had some feedback that it's useful as of now... it's effect agnostic (um..if that's a thing) as of know (using only fs2 typeclasses), so as long as you can implement instances of them for your architecture it should be pluggable (it's not hardwired to scala.Future or fs2.Task or so...)
Here's something to check out: https://github.com/verizon
[Quasar analytics](https://github.com/quasar-analytics/quasar) is a fairly large application written in a purely functional style.
They have semantic differences in the language as well. vals are only evaluated once, where as a def will be evaluated multiple times. So for functions there might not appear to have much difference between them, and with scala 2.12 and Java 8 interop the lines get blurred further. If you havn't looked already this stack overflow does a better job of explaining then I am http://stackoverflow.com/questions/18887264/what-is-the-difference-between-def-and-val-to-define-a-function
Thank you for this. Actually, this points out a hole in my question. Really, there's three different possibilities! def even(x: Int): Boolean = x % 2 == 0 // Case 1 def even: Int =&gt; Boolean = _ % 2 == 0 // Case 2 val even: Int =&gt; Boolean = _ % 2 == 0 // Case 3 When I said "`def` a method", I was actually conflating the cases 1 and 2 together.
Right, because those you give a function and it needs to schedule that function to run. OTOH flatten is just fixing the type, it doesn't need to schedule anything, so it doesn't need an ExecutionContext. The point of the blog post is that previously even if you only wanted to flatten you would have to write flatMap(x =&gt; x) (or use identity), which would then require an ExecutionContext. So for that use case you no longer need one.
I'd look especially at [Funnel](https://github.com/oncue/funnel), our distributed monitoring system.
A functor is a structure preserving function which obeys the functor laws(identity and associativity). It doesn't matter if the function is implemented standalone, on the class itself, or with typeclass. Typically the typeclass approach is the preferred way to abstract over all things that are functors.
&gt; with `Nil` and `++`? `:::` actually, but you obviously get the idea. &gt; Is that the instance of `Monoid[List]` defined in scalaz or something else? That's the one. It's what makes it possible to pass a standard Scala `List` to a function like `Nondeterminism#aggregate` that has a `Monoid` type constraint.
I've also found http://stackoverflow.com/questions/19642053/when-to-use-val-or-def-in-scala-traits Which brought up even more questions. Honestly I don't know what the answer is as a beginner.
I am now developping with this kind of architechture base on container type and free monad... it rocks: https://github.com/Geographie-cites/micmac-scala. Am starting a lib to design out-of-the-box DSLs for side effect with free-monad: https://github.com/ISCPIF/freedsl
Hi, I'm the person who took the "official" release notes and extended/improved them. I'd be happy to hear your opinions, take suggestions, and – of course – snippets and contributions to close the last gaps in the release notes! The last few things missing: - ~~Code example for SI-2712 fix: http://get-scala.org/2.12#partial-unification-of-type-constructors~~ - ~~Description of cleanups around fields phase: http://get-scala.org/2.12#fields-phase~~ - ~~Text for migration of Scala build from Ant to SBT: http://get-scala.org/2.12#ant-build-replaced-with-sbt-build~~ - ~~Content for SBT – What is SBT, what does it do, cool features, important changes since 2.11, steps before SBT 1.0: http://get-scala.org/2.12#sbt~~ - ~~Content for Scaladex~~ - ~~Content for MiMa – What is MiMa, how does it help developers? http://get-scala.org/2.12#migration-manager-mima~~ - ~~Which IDEs and editors support Scala 2.12? http://get-scala.org/2.12#ides-and-editors~~ - ~~Dotty: http://get-scala.org/2.12#dotty~~
I would recommend finding an sbt file that works and then start building on it. I have a build file that I copy from project to project and update the obvious stuff (`scalaVersion`, `name`, `libraryDependencies`, etc...). Over time that file has grown more and more complex as I add custom tasks for things like DB migrations. Out of all things Scala, sbt has one of the highest learning curves.
Yeah, your feeling is right. SBT has a terrible design. It's kind of sad we have to use it because it has the console and incremental compilation...
Can you point me in the direction of a sample multi-module project that has an up-to-date sbt build file, that I can use as a starting point?
Perhaps not related to your documentation per se, but the layout of the site defeats natural word wrap and words disappear through the right side of the screen when displayed on my cellphone. 
I have similar feelings about `sbt` so I can't promise that this is the best way to do it, but here's a public project I work on that has a multi-module/project setup with dependencies between them, that works for me: https://github.com/fulcrumgenomics/dagr
I think sbt builds can be pretty simple, especially with the &gt;= 0.13.x versions, but... &gt; Why is immutability relevant - why should I care? This is a particularly good point. I feel as if this implementation detail led to some of the issues that initially gave sbt such a poor perception. And the reality is, user's don't really care about sbt's internals. From my understanding: they wanted the settings to be represented by an immutable data structure. But then they needed a way for parts of the data structure to refer to other parts of the same data structure at declaration/init time - so they had to have some overloaded operators that turned people off greatly. Eventually, they introduced macros (e.g. setting.value) to abstract over that. I think just using some controlled mutability and a little more explicit syntax would've avoided some of this stigma and complication. There are other issues. For example, I've been using sbt for years and I'm still not sure I understand scoping fully. But things are definitely getting better.
Sorry, but I think I'm going to have to remove this. It's an article advocating for people to use Kotlin, a competing programming language. That in itself would be fine, but the article isn't even comparing Kotlin with Scala, it's comparing it with Python, only mentioning Scala in passing. EDIT: Approved at the request of /u/naftoligug
Frankly, I quite like sbt and it's my favorite build tool together with FAKE. As for example, you can take a look at one of my projects: https://github.com/alexandrnikitin/bloom-filter-scala/tree/master/project let me know what you think ;)
Added content for IDEs/editors: http://get-scala.org/2.12#ides-and-editors
/u/joshlemer maybe keep it, it should remind us to pursue excellence in our community so we remain competitive 
sbt is not ideal, but I don't find it that bad, but that may be because of the countless hours I spend with different build tools for C. Although I do hate the cryptic dsl.
&gt; What are the other, older, multi-project .sbt build definitions? Why does it matter? And and there's a link the older flavors in the very next sentence: &gt; . See bare .sbt build definition and .scala build definition (later in Getting Started) for more on other flavors. Most of your complaints could be answered if you actually continued reading the in depth sections. Considering you're only on the 4th page, you might want to try reading a bit more. &gt; Seem to be missing some context here - when does it do this? What does it mean it "ends up with" defs - how, are they somehow left over? That's [explained later](http://www.scala-sbt.org/release/docs/Setting-Initialization.html) in the manual, but does that matter here? &gt; Each project is associated with an immutable map (set of key-value pairs) describing the project. Yeah, I don't know if that's the best analogy to start with especially since I don't think it reappears later in the manual. But it's not like saying SBT Keys are applicative functors that track initialization effects would answer any more questions. That said, if you really want to find out how keys work right now, why not read the whole section dedicated to keys. throwing your hands up in exasperation on page 4 either leads me to conclude you're looking for problems in documentation and are here to troll or you have severe reading comprehension problems.
See my other comment. Also, this way we can comment on it
Added example for SI-2712 fix: http://get-scala.org/2.12#partial-unification-of-type-constructors
I used SBT enough to reach for Gradle whenever I start a new project these days, unless I'm doing something _very_ small and straightforward.
"I think sbt builds can be pretty simple, especially with the &gt;= 0.13.x versions" True, right now my biggest problem with sbt is having a problem, google the problem, find a pre 13.x answer, scratch my head, try to make it work, try some more give up, try some more, try something stupid simple that isn't supposed to work, wonder why it works, feel stupid for searching for a solution. Maybe it's me, but sbt has so much baggage it might have been better to rename sbt 1.0, or even 0.13.x, to something else entirely. OTH, if sbt's documentation was actually usable (the advice to "find a working sbt file, expand on it" is good advice, though you might inherit pre 0.13 syntax) there would be little need to google answers. Right now it's a very dry iteration of how/why you can do this/that instead of what you have to do to make your build work. If the sbt documentation started out with example sbt files for most common builds and explained them line by line this would help an awful lot. Taking everything into account it seems sbt is an aquired taste, it's really awful when you start, then when your builds gets more complex you can't help but wonder about the things it is able to do with really simple build files. All in all i like it, but it's also a huge barrier to entry to scala, which is as good as any reason to hate it. (Now if only sbt files were just pure scala files , but with the direction sbt has choosen, that's water under the bridge)
Added description of field phase: http://get-scala.org/2.12#fields-phase
What is OP trying to achieve posting it to half a dozen reddits...?
&gt; We will leave Scala out and only compare Kotlin with Python Off topic.
Added Scaladex: http://get-scala.org/2.12#scaladex
&gt; Can't believe I'm wasting a Sunday doing this. I used to program for enjoyment, this feels like masochism. I can understand your frustration, as sbt requires more than a Sunday afternoon to fully grasp. Also your gripe seems to come mainly from the sbt documentation which, although it improved, is still lacking IMO. In the medium term, however, you will see that sbt is actually the best build tool available for Scala. It _is_ pretty declarative, but when you need it (and you will with non-trivial build), you will be happy to know that you can just inject a regular Scala expression, map and transform values etc. So I do recommend reading an introductory tutorial* about the basic concepts (settings keys and tasks), perhaps multi-project builds - you can defer that till the point until you need them - and just take a look at other people's project's sbt files. Make sure you look at current projects, because the syntax of sbt got refined quite a bit in the past two years, and so some of the scare with the cryptic operators is actually much less severe now with sbt 0.13 (and soon 1.0.0). (*) What would other users recommend as introduction? The "sbt in action" book?
Technically you are completely right. But just a hint: "what's the problem" and "it's just" it's not helping the OP to calm down. Actually it speaks for the Scala community that you don't get any heated responses. Don't get me wrong: you are not impolite and you try to be helpful. But the recipient might get a completely different massage than the one you wanted to send. I had a similar problem in the past, wanting to make a multi project Play 2.x project with sbt. Finally I got it working and the solution was quite elegant and similar to what you are posting. But the mostly outdated documentation and the missing architectural documents where not very helpful. Edit: typo
Try [https://github.com/shekhargulati/52-technologies-in-2016/blob/master/02-sbt/README.md](https://github.com/shekhargulati/52-technologies-in-2016/blob/master/02-sbt/README.md)
&gt; Considering you're only on the 4th page, you might want to try reading a bit more.... "only" on the 4th page of docs before OP can get anything working. Does no one see the problem here? 
Thank you for noticing, asshole.
Your last paragraph is really unhelpful
this post has some code in it -- https://engineering.linkedin.com/play/developing-play-applications-using-gradle
I often see what seems to be an idiom of using a companion object method like Option.empty instead of None or List.empty instead of Nil. Are these just considered clearer?
Okay, you need to expose SOAP as well. This help? https://www.trivento.io/how-to-expose-a-soap-service-with-scalaakka/
The new Scaladoc is very impressive. Thanks a lot to everyone working on that! 
It took me a solid 2 months to get SBT and I'm never, ever, ever going back to another build system. SBT's power is unmatched. Yes, you'll run into headaches and throw a couple f bombs but when did we start assuming that learning new pieces of technology was "easy"?
When I have a question about how to get something done in SBT, I often look at the Akka build. Both teams from Typesafe, so presumably if there is a better way to do something, they would have done it in the Akka build. That said, SBT warns that ".scala" build definitions are deprecated. I'll believe that when I see Akka quit using it. :) To me, creating .sbt files is weird. I'm old enough to remember that there needed to be a blank line between every line of SBT code and there had to be a blank line at the end of the file or it would ignore that line. A few months ago, I ran into a multiproject build using build.sbt files and nothing rendered correctly in IntelliJ. I converted it back to Build.scala and got back to work. When I started, the biggest argument for using SBT (when it was still called "Simple Build Tool") was so one could practice their Scala. This was odd to me because IntelliJ has never allowed one to "click through" to the source with anything related to SBT (the dependencies are not found in standard repositories). I think the biggest argument now for SBT is the plugin support for Maven is weak, and getting weaker. For it's part, Maven finally finished it's ten year "Polyglot Maven" quest and I'm not sure if anyone noticed. Things aren't much better on the other side. Anyway, some constructive stuff. I think there needs to be a video documentation for visualization of scopes. Maybe even a visual debugger using WebGL, but that might be asking too much. I'd guess such a tool would have saved me thousands of dollars worth of time, the aggregate costs through the Scala ecosystem must be huge. I don't know how to pay for it's development and I don't understand scopes well enough to describe how this would work. https://github.com/JetBrains/intellij-sbt probably has the guts of how to do this, though some of that has been imported into SBT since the last time I looked at the project. Another really important piece would be teaching and requiring SBT fluency for the Scala Specialization on Coursera. I just don't get that someone could learn all the amazing things about Scala and still be dead in the water to start a new project. There are people that could teach such a class, aren't there? Worst of all, eager folks that are just starting Scala for the first time are basically given some of the hardest tasks around before they can do anything. It's really important to the ecosystem that more people join, not less, and I wonder how many people aren't getting past the first step. Having been a FOSS developer for fifteen years and a "shareware" dev before that, I apologize profusely to anyone that's offended by my comments here. The fact that I'm not willing to step up and contribute to SBT makes the exact case that I have absolutely nothing to complain about, so please recognize my ridiculous opinions for what little opinion they have of themselves. But this discussion doesn't seem to end, year after year. It makes me weep a little inside every time it still comes up.
thats exactly how I feel. But then some very people I respect very much dislike it, so I question myself :)
Gradle doesn't even let you set the project's name (= Maven `artifactId`) in the main build file. The organization (= `groupId`) and version can be set there, but the name has to be set via a ridiculous properties file hack. Also, Gradle's website contains spooky advertising/tracking code, which doesn't exactly inspire confidence. Gradle sucks.
Gradle Gradle Gradle. SBT is an embarrassment.
&gt; "only" on the 4th page of docs before OP can get anything working That's not what OP said, and even if it were, it doesn't matter because OP is a troll at worst; unconstructively hyperbolic at best.
Do you mind explainning what is particular makes the design terrible? 
But how is it better than SBT?
The conference is on right now, so not yet.
&gt; when did we start assuming that learning new pieces of technology was "easy"? Well, that's not really the question. It's whether the technology needs to be that hard in order to do what it does. Developers only really care about writing their app. A build tool is an ancillary tool to get that done. Most of us are dilettantes at build; we learn (or copy and paste) the minimum of what we need to achieve whatever is required for that project, and no more.
no that doesn't work. and in fact you can see that link also directs to https://lampepfl.github.io/dotty/#getting-started
This is the only time I've ever needed to use it as well
Definitely, one build - one file, if the project is small and relatively simple. Take a look at for example circe or cats: https://github.com/typelevel/cats/blob/master/build.sbt Why not to put Docs related settings to separate file? Publishing settings? Project definitions and dependencies?
&gt; Yes, you'll run into headaches and throw a couple f bombs but when did we start assuming that learning new pieces of technology was "easy"? Actually if anything should be easy, it should be the build tool. Or at least it should be as easy as possible for the job that it needs to do. Every single user, whether they like it or not, are exposed to a build tool and without knowing it they literally hit a brick wall and then they just stop learning the language
Interesting, why did you guys choose Bazel over Pants? Caching?
well for play you can look into the playframework source code: https://github.com/playframework/playframework/blob/master/framework/build.sbt Actually it hides the (project in ...) with it's own. It uses `Project(id, base)`so basically a lazy val VARIABLE = project is basically the definition of a project everything else is just dependsOn or local settings via .settings(), it doesn't define ThisBuild settings and the root project is just for publishing the sub projects. However I somehow started to like the DSL. But it's true that the sbt documentation is really not really good. But I didn't liked the maven documentation also. While gradle is good I dislike the style of gradle.
Looks like someone got marketing goo mixed in with documentation. They should hire a good technical editor.
FTR if you like Gradle and/or Spring you can use them with Scala. (Concurrency is not built-in to Scala at the language level so arguably a little harder to get started with, but more flexible/generic as a result).
In addition to /u/domlebo70 's comment about type inference (which is certainly true: `someOpt.fold(Nil: List[Int])(List.apply)` is just annoying) I think some of it comes from the fact that not all collections are well formed ADTs like Option and List, so you **have** to use e.g. `Set.empty[Int]`. This means that using `List.empty[Int]` is more consistent with the rest of your codebase.
I second this. Some wheels have been field tested in the roughest terrain in Java, no need to reinvent and abandon all that work.
Thanks, will take a look at those.
How about this sort of video? https://www.youtube.com/watch?v=A2w8kBA22vo
For reference, the multi projects for Play are found here: * https://www.playframework.com/documentation/2.5.x/SBTSubProjects#Consider-the-following-build-configuration * http://www.scala-sbt.org/release/docs/Multi-Project.html and there are examples projects: * https://github.com/playframework/play-tls-example * https://github.com/playframework/play-isolated-slick
What did you use for generating case classes from XSD files? Is it open source?
The default build tool in scala is SBT. I use st3 myself and have a console open that runs sbt. With sbt you can simply do "~compile" or "~run" and whenever you save a file in st3, sbt will automatically compile or run your code. To get started with sbt go here and work 1.a to 1.d (should be really easy to do): http://www.scala-sbt.org/0.13/docs/Getting-Started.html I don't know if there are any good plugins for st3 and sbt but there might be. For example ensime (https://github.com/ensime/ensime-sublime) integrates scala and st3 but I think the setup is way more difficult than what I described above
There is a plugin called ensime that integrates scalac suppprt in st3. I haven't tried using it in a year or so. I recall that i wasn't able to get it working 100%. I found using sbt in a terminal with ~compile works well in practice. Esp when it's on a second monitor. 
Thanks a lot, this was really helpful! Regarding Maven: there are several books about it, so at least with "secondary literature" it's possible to find good documentation. My biggest problem with Maven always was the code quality of the plugins. With Maven I usually knew how it should work in theory, when the plugins often failed in practice. With sbt I sometimes have no idea why it's working, but it's all working reliable!
Thanks! I have to check this out, but at the first glance it looks very promising!
Thanks, I'm just happy to help to get the word out about all the cool stuff people have done since 2.11! :-)
Curious to answers to your (*) question as well. Im wondering if sbt is such a moving target that the sbt in action book is already outdated.
This is my experience, exactly. SBT's bizarre abstraction and unreadable syntax is a huge, frustrating obstacle to adopting Scala---especially because it's one of the first things you encounter when you start out. The core problem is that it was written as a Domain Specific Language but its abstractions have nothing to do with the Domain so it's incomprehensible to Domain Experts, and it's compounded by inhuman syntax. My test of a good DSL is that someone who knows the domain should be able to more-or-less understand code written in that DSL the first time they encounter it, and they should become productive at writing it in a few hours, at most. To do this, a successful DSL deals in concepts that the Domain Expert already knows, and the syntax should make it easy to deal with those concepts. In other words, experts should feel like the DSL is a completely natural expression of their expertise. SBT is a failure as a DSL, because Domain Experts trying to configure a build think in terms of "tasks" and "dependencies", not abstract concepts like "setting keys", and "immutable maps", "scope filters", etc. And it's made much worse because the punctuation-heavy syntax is not vanilla Scala, so the obscure concepts are placed even further out of reach. The central concepts of tasks and dependencies don't even get mentioned until [section "k"](http://www.scala-sbt.org/0.13/docs/Custom-Settings.html) in "getting started" and it's incomprehensible until you've read the previous ten sections. It's a huge investment to get anyone up-to-speed on SBT, and most people are so repulsed that they assume the rest of the Scala world is like this and give up on Scala entirely. Even though it's been two decades since I wrote a Makefile by hand, I can still remember the syntax today. I can't remember even the simplest syntax for SBT without having to look it up.
This type of question I believe would be better suited to stackoveflow I believe. However: val myRDD: RDD[(Int, (Int, Int, Int))] = ??? //Your RDD myRDD.reduceByKey{(x, y) =&gt; (x._1 + y._1, x._2 + y._2, x._3 + y._3) } 
I'm there too -- only took a little time to learn when I first started scala in '10. It is far easier to do build-tasky things that are slightly customized in than maven, I can code them in scala right in the build definition, has handy build task related helper classes, the plugin ecosystem is great, builds are testable, and the incremental compilation is great, and it is scala-&lt;insert platform-here&gt;-aware. The WAY it works takes some getting used to, and dependent tasks/settings are not so fun to figure out, but setting a setting in a command alias with reload is a pretty easy hack for most things. Could/should it be easier? Yep. It could simply not provide any of the build-task helpers and simply list a map of string alias to scala scripts, download your dependencies, and set up your classpaths in a map of variables available to your map of scripts. But then I think the build ecosystem would be even more fractured than it already is. For 95% of builds it is easy. For those other 5% (cross-build with subprojects against multiple versions of scala, with macros, manual library management, ugh) you need extra scripting on top of sbt, but I imagine you'd need whole other project structures generated for you to do that stuff in maven or gradle.
Well, I found the answer. Moving the implicit vals to an object of the same name has resolved it... object Genes { implicit val genesReads: Reads[Genes] = ( (JsPath \ "series").read[Integer] and (JsPath \ "set").read[JsArray] )(Genes.apply _) } 
AFAIK `Project` is the actual datatype used by sbt; the `project` method is merely a helper for convenience. You can use either to define your projects.
Part of the problem seems to be that nowadays DSL seems to be interpreted to mean pseudo-human-readable-language, instead of a language (i.e. syntax) specific to a domain.
Oops. How'd I miss the `=`? Sorry for the confusion about that. The `assembly` stuff is used by the [sbt-assembly](https://github.com/sbt/sbt-assembly) plugin to package both projects into a single jar. It may not be necessary for your use case. Glad to help.
It is not the only place you could have put it, but it definitely (usually) makes sense to have it in the companion object. To understand why and how this works, I can highly recommend http://stackoverflow.com/questions/5598085/where-does-scala-look-for-implicits 
That's a fantastic explanation as to why things go where. Thank you **very** much for the link.
I'd like to know more. I'm a Kotlin programmer (and a functional programmer from way back), and Scala doesn't look much different. I can't make any sense of that workable site.
I was trying ensime last week because I love sublimetext too, but I gave up after some errors, perhaps you'll be luckier. https://github.com/ensime/ensime-sublime OTOH you might want to try IntelliJ IDEA with SBT for a proper Scala dev experience.
As a new-ish Scala developer, I'm a little confused about the options for Scala for Android development. What options are available, and what do people see as the community consensus for usage? What libraries have strong support? What are the caveats or concerns for developing Android applications with Scala? Are there options allowing a strongly functional or FRP style with Android development? I feel like, as with Scala.js, this has an obvious answer that my lack of library knowledge has concealed from me.
I used to work at Twitter. I am very familiar with pants. Bazel is far cleaner to write extensions for. The build is reproducible, and we bet that Google's production build system was a better long term bet than Twitter's which is undergoing a rewrite of the engine.
IntelliJ would be a good idea. Scala is a fair bit more complicated than Java and a proper IDE will go a long way to help with programming in it. 
Plus they just made everything free for students... https://www.jetbrains.com/student/
use what you like, but no you can't underuse a language
This is probably not the recommended configuration any more, but FWIW I use eclipse (with the android plugin), maven and ordinary Scala, with the traditional Andoird UI libraries and well-known Scala libraries e.g. Shapeless. The main caveat I'm aware of is to be sure you have ProGuard working, because you don't want to hit the method count limit. The "standard" Android UI is not very functional-friendly at all, but one can clearly separate UI from business logic (good practice anyway) and gain the advantages of Scala in the latter. I'm not aware of any better options but it's been a while, maybe something has been written since I last looked.
I think deriving the monoid instance requires scalaz-shapeless or similar.
As the name says - scalable language, from micro to macro ;)
There's a Sydney based company who IPO'd recently, some great Scala developers. If I was looking for some quality Scala devs in Sydney I'd do some LinkedIn hunting ;) 
If you work with Java devs, and use Scala, you are going to have to consistently explain, defend and teach about every single choice made in Scala, the ecosystem, functional programming, generic programming, macros, immutability, combinators, very small parts of category theory, avoiding runtime di, implicits, typeclasses, and Java interop. FP is the big win, and FP with types and concurrency are the useful pieces. For that, you really only have Haskell and Scala. If you use Haskell, the build system is poor. But you won't have to fight every day over whether to use spring and JavaEE and how that's less magic than implicits you must write and bring into scope yourself. EDIT: To be honest - using Scala is worth it and microservices are a great use case, see /u/paultypes in this thread. But if you aren't equipped to defend its use against your colleagues, you are going to have a bad time (not with the language or libraries, but with your co-workers who are resistant to change).
Maybe you can find something here: http://scala-android.org/quickstart/
Great resource! Thanks!
Yep. Culture matters. Lately I've gotten on a "How do I map from stuff my colleagues believe to pure typed FP?" kick, and one thing that occurs to me is that nearly everyone thinks "Say what you mean and mean what you say" is a reasonable ethic to try to achieve. So I explain how "Say what you mean" means "types," and "mean what you say" is "eliminate side-effects." From there, it's reasonably easy to get to "Say what you mean" includes "I'm gonna do I/O" or "I'm gonna do concurrency," and "mean what you say" excludes anything you _didn't_ say. From there, you might be able to engage in the uphill slog of "and then you can reason about your code algebraically" and the like, but that's secondary, or even tertiary, instead of trying to _start_ there.
I got it working from a console by starting SBT with specific versions of the compiler bridge and dotty, like so: `env COMPILERVERSION="0.1-20161026-557d448-NIGHTLY" DOTTYVERSION="0.1-20161026-557d448-NIGHTLY" sbt` edit: and now it seems to have stopped working again. Weird.
[Rúnar can](https://twitter.com/runarorama/status/785558075545677826)!
All credit to Eugene
Initial Public Offering or "gone public". It's when a company switches from a private business to a public one. 
This post reminded me of Kmett's comment - https://m.reddit.com/r/haskell/comments/1pjjy5/comment/cd3bgcu. Aside - I've been working in Scala over 3 years, so not trying to attack it.
Except for the whole need 512 MB ram to start up a server thing.. For a true microservice, you could get by in Python on 1/4 of the memory. You will get 1/20th the performance, sure.. depends on your constraint I guess.
My development machine has 32 GB of RAM. My applications run on servers with upwards of 128 GB of RAM. 512 MB is nothing. On the other hand, the apps serve thousands of requests per second. The memory is nothing; performance is everything.
&gt; avoiding runtime di How do you choose to avoid runtime di?
&gt; SBT is a failure as a DSL, because Domain Experts trying to configure a build think in terms of "tasks" and "dependencies", not abstract concepts like "setting keys", and "immutable maps", "scope filters", etc. And this, I think, hits the nail on the head. 
Is it just me or does this seem out of place. Why would yahoo advertise like this? If its not yahoo, what would they gain with your resume?
Yes exactly it depends what you are doing. If you are going crazy microservices and have 100s of them, the difference between the min machine needing 512 ram vs 1024 or 2048 could easily double your hosting bill. On the other hand, microservices are a pretty terrible design pattern.
I like gradle. what did I miss? 
if that problem you described is all, it's hard to take you seriously 
https://safety.yahoo.com/Security/PHISHING-SITE.html says yahoo-inc.com is their official email. So it's definitely going to yahoo.
Is that the same general idea as Finch?
Is this vanilla scala or yscala?
It's probably legit, though Rodrigo here may get a referral bonus for putting your resume in if you get hired. I'd suggest you request half of it. ;)
You can adjust the initial/minimum/maximum heap sizes in that case, but if you have hundreds microservices running, your problems are not of the hardware kind...
Do you sponsor visas for people coming from Europe?
Sounds plausible. When I'm in extremist library-writing mode I'll sometimes use anonymous subclasses to avoid exposing types for them (e.g. https://github.com/m50d/paperdoll/blob/master/core/src/main/scala/paperdoll/core/queue/DestructuredHead.scala ), with the logic that it should compile to the same thing (anonymous classes are not very different from named classes at runtime); this sounds like it would result in something broadly similar.
shake is not a good build system for Haskell?
The format is overly flexible - groovy has dozens of ways to do the same thing - making it hard to read other people's build definitions. It's undocumented and can easily contain arbitrary code - ever tried to parse a `.gradle` file? (This matters for e.g. IDE integration). Ever tried to run an *untrusted* gradle build? Also it's slow for large projects - I've seen it take a minute or more just parsing the build definitions before starting any actual building.
Personally I don't see myself moving away from Scala in the foreseeable future. I really appreciate the whole Java infrastructure, especially the dependency management via Maven and Ivy, and I have never ran into any Java interoperability issues. I disagree that Java 8 has somehow caught up with respect to functional programming. Sure, lambdas are useful, but that is just a tiny part of the functional features that I find invaluable in Scala. Case classes, pattern matching, ADTs via sealed hierarchies (visitor pattern is *so* awkward), higher-kinded types, macros, immutable data structures etc. Once you have learned to use all that going back to Java or any similar language feels very limiting and frustrating.
I had a very simple play app in prod. With 512 MB XMX it would often OOM under very light load. Needed 1024 MB XMX to be stable. This is more likely a problem with Play over Java itself.. but in general, a Java app that is doing useful things and that has a ton of libraries loaded, needs a fairly hefty memory to perform well. Remember when using GC, you can only use 1/4 to 1/2 of your memory, the rest needs to be left around for the GC to perform well. So saying my app needed 1 GB of heap... means it may have only need 256 MB of actual memory.. but it takes a lot of empty room to run well.
I don't think so: &gt; servant is a set of packages for declaring web APIs at the type-level... After a quick look around, servant seems to have no meaningful Scala equivalent. 
Well for this exact case, I had the app in 2 versions.. Scala Play, and Python Django. Scala Play took 1024 for the JVM, could do something like 2000 requests / second per CPU. Python Django took only 65 MB of ram per fork, and I ran 2 forks (so 130 MB ram total). Did something like 300 requests per second per CPU. So approximately 1/10th the memory for 1/8th the max performance for this particular app. If this was some silly service that got a few hits a day, and you had 100s like it.. I could see a huge problem from the JVM memory footprint. You could help it a bit by dropping Play.. but what else is there.. no Scala web framework is that light weight..
There's another one? Used Cabal and stack with make, had problems with both, guess I'll have to learn about shake and give it a try. I want something like maven/sbt/gradle, and shake looks like its similar to what I want.
Hey, something I can do! I'll take a look.
A hypothetical Yahoo fork of scala. Akin to the existing forks: yjava, ynode, yphp, and ypython. Edit: Correct me if I'm wrong. I keep in touch with a former colleague that ended up at Yahoo and he mentioned his frustration with these.
How is scala performance on android? Does it also mean the whole scala lib has to ship with app? Or is it not really concern?
I just released the first version of a pure-functional embedded telnet server, which is sometimes nice to have when you don't feel like writing a web UI. https://tpolecat.github.io/tuco/ 
Joke response: Haskell.
Looks pretty amazing tbh, you declare your web api with your types, and it will generate your clients for you and looks like it's also a high level DSL for the server, thus you can probably use many different haskell http backends to serve your api, etc.
I'll be the first one to agree the JVM is oversold (in fact, I've said so explicitly on several occasions, including here). But the fact remains that it is a target, both for good reasons (e.g. awesome GC implementation) and for ill (because it's there). If you take "tooling" rather broadly, that's also important. "Here's a .war file to deploy in this bog-standard way" matters. "Here's an arbitrary binary with arbitrary dynamically-linked dependencies to deploy" is a guaranteed slog, and no, Go is not the solution. But I'd be open to the argument that [MirageOS](https://mirage.io/) is, or at least [ocaml-musl-static](https://github.com/ocaml/opam-repository/tree/master/compilers/4.02.3/4.02.3%2Bmusl%2Bstatic) is. But we won't be retraining 300 people on MirageOS/OCaml.
If you're looking for some more samples, here's one project I've been working on, its build.sbt is not the cleanest and contains some workarounds and some plugins you don't necessarily need; plus it compiles cross-platform Scala code, targeting both the JVM and Javascript, providing support for Scala 2.10, 2.11 and 2.12, compatible with Java 6, but having bits for Java 8: https://github.com/monix/monix/blob/master/build.sbt Another build file that I found useful to look at is the one in Cats, which has similar cross-platform needs: https://github.com/typelevel/cats/blob/master/build.sbt These are not simple projects, so the build files aren't simple, but there you go.
That would make sense, I have not done the multiple application per application server since 2006???? Or whenever it was cool to do that with Tomcat but before self contained Netty became the rage.
Although from reading this more it would appear that the type scrutineer fails to be sealed in this case preventing warnings from being emitted for this case match. You can find a bit more of what I believe is the same problem here https://issues.scala-lang.org/browse/SI-9398
Hmm, I don't think that's quite true, because the following *does* produce a warning: object Bug { sealed case class Foo(e: Option[Int]) def loop(t: Foo): Nothing = t match { case Foo(Some(_)) =&gt; ??? } } /* match may not be exhaustive. [warn] It would fail on the following input: Foo(None) [warn] def loop(t: Foo): Nothing = t match { [warn] ^ */ 
That issue is closed/fixed, though?
I didn't get a warning in this case either: scala&gt; :paste // Entering paste mode (ctrl-D to finish) case class X(b: Option[Int]) def f(x: X): Int = x match { case X(None) =&gt; 42 } // Exiting paste mode, now interpreting. defined class X f: (x: X)Int
Do you offer relocation? Visa help for europeans?
Yeah, I tried it in 2.12.0 final.
Thanks — yeah, apparently the case class needs to be `sealed` to receive exhaustiveness checks; e.g.: scala&gt; :paste // Entering paste mode (ctrl-D to finish) sealed case class X(b: Option[Int]) def f(x: X): Int = x match { case X(None) =&gt; 42 } // Exiting paste mode, now interpreting. &lt;console&gt;:14: warning: match may not be exhaustive. It would fail on the following input: X(Some(_)) def f(x: X): Int = x match { ^ defined class X f: (x: X)Int 
Thanks — yeah I wondered about that too, but note that this use of `Tuple2` does issue a warning: def f(s: Option[Int], t: Option[Int]): Nothing = (s,t) match { case (Some(_), _) =&gt; ??? // It would fail on the following input: (None, _) } but even using a sealed `Tuple2` replacement, this still doesn't: sealed case class Foo(e: Option[Int]) sealed case class Pair[A,B](a: A, b: B) def g(s: Foo, t: Foo): Nothing = Pair(s,t) match { case Pair(Foo(Some(_)), _) =&gt; ??? } but this does: sealed case class Pair[A,B](a: A, b: B) val h : Pair[Option[Int], Option[Int]] =&gt; Nothing = { case Pair(Some(_), _) =&gt; ??? // It would fail on the following input: Pair(None, _) }
I'd make a bug report then worse case they've already seen it and mark it duplicate. 
New CTO who wants to standardise on "safer" technology.
Hmm, no, the point was to 'close the hole' of case class automatic companion object `apply` methods so you can prevent your user from just instantiating a case class that violates your invariants, while _also_ keeping all the nice case class perks like pattern matching, `equals` and `hashCode`. E.g. the `Nat` example in the gist shouldn't accept numbers less than 1.
I can't imagine a tumblr backend written in a strong static typed language.
Ahh right that makes sense. Shame you have to fall back to visitor. As for the F, if it were just in the output type then yeah it would be easy to produce as part of interpretation, but I'm not sure how else to do it if the input to the case class itself requires that type F? Afaik, free monad doesn't abstract over the inputs? Say F is a spark data frame for example. The interpreter can't really do anything meaningful with a Double if it's actually expecting to do a filter operation on a DataFrame[Double] (if that makes sense?)
Usually the ADT represents a set of "commands", and the stream would be threaded through them by the interpreter. Bear in mind that `Free` isn't really a good fit for modeling collection-like things (I've seen them encoded as `NDet` in the "freer monads, more extensible effects" paper, but that doesn't sound efficient or elegant). I'd suggest making a custom ADT that you're confident represents the commands you want to represent first, and then see whether you can use `Free` to simplify it. The structure you want is a monad but it isn't just a monad; `Free` works well when you want to just execute a sequence of commands one after another in the obvious sense, but if you're branching and merging then it's a lot less clear how to apply it. Or maybe I'm just not experienced enough to know how to do it right.
Yep. Should've happened years ago, but better late than never.
Woo hoo
The name though... :S Now I need to port my Eithers to e.g. shapeless coproduct or similar types. Because changing it to be right biased is changing the semantics.
I've solved problems like this by making my algebra path dependant [like so](https://github.com/Milyardo/freeio/blob/master/src/main/scala/com/github/milyardo/freeio/FileAlg.scala). 
Yeah, I’ll update here when I get answer.
After reading, I still have some questions: * [Lambda syntax for SAM types](http://www.scala-lang.org/news/2.12.0#lambda-syntax-for-sam-types) section says: &gt; Thanks to an improvement in type-checking, the parameter type in a lambda expression can be omitted even when the invoked method is overloaded. But the given example also works in Scala 2.11.8: trait MyFun { def apply(x: Int): String } object T { def m(f: Int =&gt; String) = 0 def m(f: MyFun) = 1 } T.m(x =&gt; x.toString) * What does **result type** mean in this sentence: &gt; With Java 8 allowing concrete methods in interfaces, Scala 2.12 is able to compile a trait to a single interface classfile. Before, a trait was represented as an interface and a class that held the method implementations (T$class.class). &gt; Note that the compiler still has quite a bit of magic to perform behind the scenes, so that care must be taken if a trait is meant to be implemented in Java. Briefly, if a trait does any of the following its subclasses require synthetic code: defining fields ( val or var, but a constant is ok – final val without **result type**) ... Does anyone has any ideas? Thanks.
That is an interesting background! Thanks for the email.
[removed]
Lolwut, running sbt in any directory containing scala files will automatically build without even needing a build file. 
For a while the rubric has been not to use structural typing because of its effect on performance. Does the changing of structural calls to `invokedynamic` improve things significantly enough to challenge that rubric?
I also want to know the answer to this, structural types opens up a lot of really interesting new ways to design programs I think.
sorry this will get kinda meta but... but as someone who hadn't really learned another build system before i found learning sbt to be fairly easy. one great resource i'd recommend `sbt in action.` just started with the basics and worked my way up as i needed. i guess my point is to adopt the mindset of the beginner and do the dead simple basics.
[Slick](http://slick.lightbend.com/)'s just dandy, though it's an F(unctional)RM, not an ORM. There are also a couple other FRM's that I've seen recommended around here. Thinking with ORM's can be tedious and frustrating as a result of the [Object Relational Impedance Mismatch](https://en.wikipedia.org/wiki/Object-relational_impedance_mismatch). If you're really invested in using an ORM, it might actually be easier to find something super stable in Java, or take a look at some of the options on the [awesome scala list](https://github.com/lauris/awesome-scala), which is a great bookmark to have in general.
I see. That's good news for me, so I don't have to port anything, at least not immediately. However, having it right biased now means, one can use it in a for-comprehension and the right side is taken. To me this at least feels like a change of semantics. I think if I just have type A or B without any bias (i.e. one is "good" and the other one is an "error") then I should be forced to decide which side I want to use when putting it into a for comprehension. No?
If you have control of the source why would you use structural type instead of having a common trait ? Probably I'm missing something but I always tough/used this when I wanted to abstract over things I'm not fully in control of, is there another use case?
I have a hard time understanding why this is a problem for you. If the data types in your either do not have an inherent bias you shouldn't be using them in a for comprehension without specifying a left- or right-projection (with right-projection now being the default). Or you could put them in their own ADT/sealed trait.
That's a valid way to look at it, indeed, I think.
Here is milestone for 2.6 : https://github.com/playframework/playframework/milestone/37 
&gt; We use scala as a 'service layer' that is used by Java code. I've come to the conclusion that this is the wrong way around to do it. Better to do the migration from the top down; Scala code can call into Java during the migration period (and make sure it is a migration, not a permanent state of affairs), but not the reverse. &gt; Why not just automatically convert Integer to Int? Because that can NPE, so you want it to be visible in the code when it's happening. FWIW this is only a problem that happens on the boundary; once you're Scala-everywhere you just use `Int` everywhere and never have this kind of problem.
It's additional semantics, I think, but it only codifies what the library ecosystem had more-or-less already agreed on (in practice I see Either used for failure/success far more often than for an unbiased either/or). In practice having it unbiased just meant that some libraries would use left for error and some libraries would use right for error (at least until the consensus emerged); standardising on left-for-error is kind of arbitrary but it's better to have a standard than not. I kind of wish we could get a dedicated error-or-success type with names that were better suited for that use case than `Left` and `Right`, but I fear that ship has sailed; introducing one at this stage would only introduce more confusion as some libraries switched and others didn't. New languages will do better.
Even for that case I'd prefer typeclasses, though they do have a syntactic overhead.
Yeah I agree. However, this 'seems' to be not so big deal that I would get the attention of the whole team. Aside from that, I am not really a fan of Scala (using Slick which exposes a lot of scala stuff). Thanks for replying to my shitpost btw.
Well, I was venting anger. As this was/is making me significantly less productive. Part of it is probably bec I haven't really put effort to beat the learning curve... But it's really frustrating the my IDE (IDEA 15.0.2) doesn't tell this compile error as fast as it would in Java. Also, I played with Lombok this long weekend. And it was great. Removes a lot of code in Java. I was very productive. And you only need a dependency in maven. No plugins etc. .. I wish Lombok had a standard way to achieve it's 'hack'.
See my above comment
Shapeless records work for this kind of case. def stats(list: List[Int]) = ("length" -&gt;&gt; list.length) :: ("average" -&gt;&gt; list.sum/length) :: HNil stats(List(1, 2, 3))("length") Though I'd probably just define a `case class`. Make it private to the package if you're worried about namespace pollution. Classes are a lot cheaper (syntactically) in Scala than we're used to, so our intuitions about when it's appropriate to use them should shift.
&gt; You can still use it unbiased when that makes sense for you. That's also often my use case. Excluding union types, i.e. case object X case object Y def f: Either[X, Y] = ??? For what purposes/use cases are you using an `Either` that's not naturally right-biased?
Scala 2.12 requires Java 8, so from what I've read it seems you can not target Android with it until Android supports Java 8. At least that's what I've read from time to time over the last months.
&gt; Regarding the Records, don't you think that's kind of heavy handed when there's such a simple and performant solution now that doesn't require macros or even a library? I think Records should probably be built into the language, but then I think that about a lot of Shapeless. I tend to regard Shapeless as part of my "baseline" when working in Scala - I'm going to depend on it widely anyway, so it doesn't really matter whether something is built-in or in Shapeless.
Don't judge Scala based on Slick. Slick is a pain, and its error messages are cryptic. I feel you pain about boxed-primitive types like `Integer`. Sadly boxing and unboxing (and the boilerplate that goes with it) is par for the course on the JVM.
I'm with m50d: I'd look at some of the DB access options other than Slick, e.g. [Quill](http://getquill.io/) if you want to see how Scala can make things _better_, or [ScalikeJDBC](http://scalikejdbc.org) if you want to see how Scala can just make things _easier_. I'd also invert the Java/Scala relationship as early in your callchain as possible. Scala is a richer language than Java, so it's easier to have Scala call Java than vice-versa, which, as you've discovered, has API subtleties you're better off just avoiding. So, for example, if you're deploying a servlet, I'd have a look at [Unfiltered](http://unfiltered.databinder.net/Unfiltered.html) and its unfiltered-filter-async module, then, in your code, `import collection.JavaConversions._` to get automatic conversions between Scala and Java collection types, although there's still no automatic conversion between Java's boxed types and Scala's auto(un)boxing native types.
Here is my experience with lombok: When I was a java dev who barely knew what is Scala I wanted to get awesome features for "free": I've came up with the idea to introduce lombok into one of our projects(~500KLoC). The project took ~90 seconds to compile with maven on average. I've started to implement a new module using lombok and I've noticed that the compilation is now takes ~350 seconds. When I've "outfactored" lombok from the module the compilation got the good compilation speed again. I've barely used some features but it made the compilation speed terrible. Scala has a slow compilation speed but at least with incremental compilation and the rich typesystem you can get more out from it then from lombok.
Thanks! Yeah, I've dealt with tables with 50+ columns with Slick and compilation got a lot slower, and generated mapping class was yet another weird sorcery. Quill looks great.
Okay well how about nesting? This is something you can't easily do with just traits or case classes without defining huge numbers of them. It's a huge pain in the butt. With structural types: trait MyConfig { def api: { def interface: String def port: Int } def logging: { def level: String def format: String def logFile: File } def foo: { def bar: { def baz: List[Int] } def bazBaz: Char } } val myConfig = new MyConfig { val api = new { val interface = "localhost" val port = 8080 } ... }
I don't follow what difference the nesting makes? It seems perfectly reasonable to define that structure with nested case classes. 
IMHO, your best option is Play with Slick, using Flyway for the schema migration. * [Play Scala Example using Isolated Slick](https://github.com/playframework/play-isolated-slick) / [Project Download with ZIP](https://example.lightbend.com/v1/download/play-isolated-slick) There's also Anorm and a Slick plugin that integrates with Play directly -- I prefer to keep my ORM at arms length from the HTTP layer, but I know some people like it: * [Play Scala Example using Anorm](https://github.com/playframework/play-anorm) / [Project Download with ZIP](https://example.lightbend.com/v1/download/play-anorm) * [Play Scala Integrated Slick Example](https://github.com/playframework/play-scala-intro) / [Project Download with ZIP](https://example.lightbend.com/v1/download/play-scala-intro) And there are lots more example projects available on https://playframework.com/download. 
I think the solutions are to either compile Scala directly to Jayce IR (so create something similar to Scala.JS or Scala Native) or to bring back Java 6 backend to 2.12, which was supported up to 2.12-M4. But even if Scala 2.12 and further versions won't be ever supported on Android, Scala 2.11 is still much better than any possible future Java release.
The difference is an enormous syntactic overhead, which actually gets really out of hand if you have nesting *especially* when maybe at different points in the nested tree, different things may have the same name. Let me illustrate trait MyConfig { def api: { def interface: String def port: Int } def logging: { def level: String def format: String def logFile: File } def a: { def b: { def c: { def somethingInC1: Int } def d: { def i: Int } } def c: { // has the same name as a.b.c, but a.c is not the same as a.b.c def somethingInC2: Byte def somethingElseInC2: Byte } } } ... val myConfig = new MyConfig { val api = new { val interface = "localhost" val port = 8080 } val logging = { val level = "localhost" val format = "8080093ru943jf" val file = new File("...") } val a = new { val b = new { val c = new { val somethingInC1 = 1 } val d = new { val i = 2 } } val c = new { val somethingInC2 = 0.toByte val somethingElseInC2 = 1.toByte } } } verses... trait MyConfig { protected case class Api(interface: String, port: Int) protected case class Logging(level: String, format: String, logFile: File) protected case class A(b: B, c: A_C) protected case class B(c: A_B_C, d: D) protected case class A_B_C(somethingInC1: Int) protected case class D(i: Int) protected case class A_C(somethingInC2: Byte, somethingElseInC2: Byte) def api: Api def logging: Logging def a: A } val myConfig = new MyConfig { val api = Api( "localhost", 8080 ) val logging = Logging( "WARN", "% asdf %%% ...", "/some/file.log" ) val a = A( B( A_B_C( 444 ), D( 4 ) ), A_C( 0.toByte, 1.toByte ) ) }
I think you've made my case for me - the second example is if anything shorter, and could get a lot more so, since many of the newlines in the value definition could be dropped. (Also, make MyConfig itself a case class). The first example has shorter lines, but what determines readability is how much you have to scroll, so vertical space is usually what matters. 
&gt; but not the reverse Java code can call Scala code, but you have to not use an API that Java can't call easily, like singletons and operators. I would give a counterargument (not speaking from experience though), you can write higher-quality Scala code if you don't have to do all the interop in it like worrying about null. Actually the whole way of FP is to have pure code on the inside called by your side-effecting outer layer, which seems to suggest putting Java on the outside. But again I'm not speaking from experience, just pointing out another side.
Reviews welcome
How this is not the top-rated comment, I have no idea. This was massively helpful! Thank you. I was really getting tired of hearing everyone say "use Scalaz" and wanted a sane approach that uses native Scala. This is it. The Scalaz EitherT route adds enormous complexity in my opinion, and is completely un-intuitive.
&gt; you can write higher-quality Scala code if you don't have to do all the interop in it like worrying about null. No interop at all is best, but handling null is much easier with Scala calling Java (just have to wrap the call in `Option(...)`) than with Java calling Scala (method has to check all its parameters). &gt; Actually the whole way of FP is to have pure code on the inside called by your side-effecting outer layer, which seems to suggest putting Java on the outside. On the contrary, pure code in Java + effectful code in Scala works nicely - you have all the Scala tools available to control and manage your effects - whereas pure code in Scala + effectful code in Java puts you in pretty much the same place you were when using Java.
Is there any compelling reason to just release 2.5.x for 2.12? Or at least play-json? I'm not willing to wait weeks/months just for a handy library.
I haven't gotten any answer yet. Feel free to vote for receiving one ;-) https://issues.scala-lang.org/browse/SI-10019
&gt; The giant blob of code-in-one file that slick generates makes everything slower. That is a known issue with slick-codegen https://github.com/slick/slick/issues/906
Quote: "We are looking into supporting Scala 2.12 in 2.5.x (since the 2.6.0 release is several months away) but it's tricky since some of our dependencies might require updating to newer versions that may have breaking changes. Once we get it working on master (soon) I will take a look. Greg " https://groups.google.com/forum/#!topic/play-framework/Z7abcfZe2Kk
What you're seeing there is an exhaustive match warning on Option rather than Foo. You should get the same warning without `sealed`.
What about bundling JDK9 (or at least the JRE part) with your Scala "app"? It seems like a lot of work, but only has to be done once (you could put the whole whizbang toolchain devkit chaos into a Docker container and you can deterministically reproduce the Java9 JRE files each time, and maybe tweak the process later, if required). http://openjdk.java.net/projects/mobile/android.html
I think the problem is with the ```var row: Int = c - r``` line. What if `r &gt; c`? You'll end up with a case where `row` is negative, so `row` will continue to decrease and `row == 0` will never be true.
Thank you so much! I'm not sure how I missed this before. 
Thank you so much for taking the time to write this. I'll do as you say and report back if I manage to get it (and shower you with praise) :) 
&gt; The best solution, of course, would be if Android would just support Java 8 bytecode. Every time this pops up people should appreciate how cool it was having Google forking the Java eco-system.
I suffered so much with Pants. Yuck. Not enough docs. No community. Very little tooling. Sure it supports multiple languages, but at what cost and headache.
Even with `invokedynamic`, calls to structural methods are going to be significantly slower than virtual calls, it's still runtime reflection. Depending on your usecase, you might be better off using scala.Dynamic: http://stackoverflow.com/a/15799812/348497
For just microservices I would learn Go just because it's ridiculously easy to learn and you get the best performance for your effort also I mean you could really just stick with the standard library for everything but routing and using a db also it makes dealing with concurrency rather easily and you can do a lot with what you do in actors with just coroutines and channels. If you want to learn about functional programming and concurrency better than you would using Scala I would say learn Elixir just because it forces you to think functionally right off the bat and OTP &gt; Akka. TLDR: Learn Go and Scala Go is really really simple and effective, Scala is very powerful and flexible albeit messy. 
You can have multiple builds in SBT, ie where I work we often add git repositories as dependencies. Those source based dependencies are added as additional builds which are built first before building the project you're currently running sbt with.
I was impressed by the completeness of http://udash.io/
So basically this is saying "stop using play-json". Message received.
Oh, I didn't notice that I used some global sbt plugins. The dependency issues disappear now. Thanks!
The reason why scala doesn't use HM is because it doesn't work very well with OO and in the case of scala not having kind polymorphism that's kind of a big reason why scala has such good Java Interop. I don't disagree with what you are saying itself so much as the fact that I find too many people writing scala wish it were haskell when again Frege is always an option if you want a haskell dialect on the JVM. There are problems with scala but making it more like haskell is not the solution it wouldn't have spread so fast if it were a pure ML dialect on the JVM. In regards to leaving Scala and you want something more pure and you have a choice in regards to lazy evaluation and you get to keep the JVM use clojure I like it way more than I like scala but I ended up using scala more for interop, I admit I need OO for quite a few problems, and performance reasons. Clojure also has a solid concurrency story it's core library supports both STM (what haskell uses) and CSP(I actually like clojures implementation better than go's), lein is also wayy way better than sbt. Clojure has it's problems though. Also clojure supports Macros and Monads which is chill. 
In any case, this presentation by Adam Rosien is better, check it out: https://arosien.github.io/fp-and-algebras/#1
It has to be auto-generated; how else would titles like `De-structured by &lt;u&gt;pattern matching&lt;/u&gt;` end up in the final text...
I mean, it's not like Scala coders were going about using nulls everywhere (or anywhere much) before this....
I knew it read familiarly
&gt; I don't disagree with what you are saying itself so much as the fact that I find too many people writing scala wish it were haskell when again Frege is always an option if you want a haskell dialect on the JVM. Well, not realistically. E.g. I doubt there are many jobs writing Frege. &gt; There are problems with scala but making it more like haskell is not the solution it wouldn't have spread so fast if it were a pure ML dialect on the JVM. Maybe. It's hard to know what might have gone differently, and in any case the world changes; FP in general is a lot more popular/accepted than it was 10 years ago, so the optimal point for Scala may shift. &gt; In regards to leaving Scala and you want something more pure and you have a choice in regards to lazy evaluation and you get to keep the JVM use clojure I like it way more than I like scala but I ended up using scala more for interop, I admit I need OO for quite a few problems, and performance reasons. Clojure also has a solid concurrency story it's core library supports both STM (what haskell uses) and CSP(I actually like clojures implementation better than go's), lein is also wayy way better than sbt. Clojure has it's problems though. Also clojure supports Macros and Monads which is chill. I need a type system at least as good as Scala's, so there's no way I'd ever use Clojure. FWIW I dislike and avoid SBT, I stick to Maven wherever possible.
Nothing built-in, but you can make up your own thing like https://gist.github.com/paulp/e8df663712fe5455b433f5dd71c043c6 does to enable/disable plugins using `-D` flags
Does the difference go away with the typelevel fork and `-Zirrefutable-patterns`?
I would argue it more pushes the boundaries of what is possible. Everything it is doing is sensible (at least if you think that having your SQL properly typed is sensible, and there are also other libraries which do this, i.e. LINQ). The thing is that the way that Slick does is really pushing Scala's type system to its limits. LINQ is a baed off compiler extension afaik where as Slick aims to be a pure Scala library.
what kind of audience is this book aimed at? 
Your post is very hard to understand. Please try to improve your grammar. &gt; Do you need static typing out of simple preference to ML or do you need static typing for performance reasons. I need static typing because I find it makes me much more efficient when programming. Nothing to do with runtime performance. &gt; My point with Frege if such a large portion of the community truly wanted a haskell dialect on JVM which they do claim. Why aren't there a lot of active projects going on in Frege even though it's been around for about as long as scala has been popular, surely you guys must have free time to start writing more code in it if you want to write very useful haskell that bad. Um Frege is half the age of Scala (in fact it's about the same age as Idris); it didn't exist when I started using Scala. It doesn't have anywhere near the level of IDE/tool/library support that Scala does, and I simply don't think it offers a big enough advantage to make up for the lack of that ecosystem - I think it would be much less work to add Frege-like features to Scala than to develop the Frege ecosystem to the point where it could match Scala. I'm a full-time professional programmer, so I don't have a lot of free time to spend on programming; I might be able to justify spending company time improving the language we already use, whereas I certainly can't justify spending it on a speculative ecosystem for a language we might use some day. &gt; Why don't you use F# it uses hindley-milner, it works pretty well in Mono and it's functional first. Because it doesn't have higher-kinded types. And because there aren't many jobs using it. &gt; Honestly IMO people should stop trying to make scala into Haskell or otherwise your code is gonna look like bad haskell fanfic using scalaz or cats frivolously for no reason and crying about it later. When it's just scala and the beauty of it is just the freedom of choice which is it's greatest strength and weakness. Not my experience. Writing less-functional code is what tends to lead to "crying about it later"; purity always works out better in the long run.
Well, that's [astonishing](https://en.wikipedia.org/wiki/Principle_of_least_astonishment). Why are null instances not matched? Because `Null` is a bottom type?
Anybody using this in production? I'd love to listen to real life experiences.
Aye me too!
Because Kotlin is a terrible language compared to Scala (even if you're stuck on 2.11); much more complicated because of all its special cases, but missing important features (e.g. typeclasses, HKTs).
Maybe because at runtime, on the JVM, a null reference doesn't come with any type information. You need a reference to an actual object to know the class and interfaces it implements and make `isInstanceOf[Foo]` work.
Java's instanceof behaves the same way.
Absolutely. At a former employer we had a bunch of applications/services in production written using unfiltered. IMO it's a good example of a toolkit with composable primitives where the core is simple enough that you could reasonably re-implement it in hours (which indeed we had newbies do in a guided way as a part of introductory scala courses). Pure unfiltered gets a bit boilerplatey if you want to construct responses with reasonable status codes (that's where the extractor based pattern falls through), which is why people have built things like [directives](http://unfiltered.databinder.net/Directives+and+Validation.html) on top of it. The synchronous version on top of jetty/tomcat works without a hitch, while we struggled with the async variants. Lack of maintenance means that nobody has stepped up and fixed that. A better choice might very well be [http4s](https://github.com/http4s/http4s) which shares some of the general design.
What tools are available for profiling Scala code? [This](https://www.youtube.com/watch?v=N3PWzBeLX2M) is a tool I used in Go and am wondering if there is anything similar in Scala.
If you like the ML family but appreciate Go's fast compiles and statically-linked binaries, maybe consider [ocaml-musl-static](https://github.com/ocaml/opam-repository/tree/master/compilers/4.02.3/4.02.3%2Bmusl%2Bstatic)? I hope it gets updated to OCaml 4.04.0 soon; it's now a couple of minor dot revisions out of date. But it could be a not-crazy language to use that still compiles to static binaries very quickly.
Put together a Play application using Dagger 2 for compile time dependency injection: https://github.com/wsargent/play-java-dagger2
Do you want to write a clean-room implementation or translate directly from Reddit's source? Because if the latter, then you will definitely need to be able to read Python :-)
Thanks for response
Really great post
Scala and Python can be pretty similar. Reddit is conceptually simple but might be quite complex in its current form. How long is the current source code? Would it be better to start from an older version? I'm somewhat interested (though historically I don't have a lot of time to commit to this kind of project), but I'm pretty averse to Play.
Looking at "functional programming" jobboards, why do so many companies use Akka stack? Is FP really so unpopular in Scala? Or is really use case requiring Akka so big that it's a must these days?
Oh I didn't know that. I guess that's why the search functionality is bonkers. I'll keep that in mind.
Great point. Thanks
Reddit is awesome. But there are few things that you need to keep in mind. 1. Reddit is huge. 2. Reddit is old and hence it's design has evolved (not very nicely) to keep up with the world. its design can not be considered a great design from current perspective. 3. A lot of design decision in Reddit are to handle the scale and will be overkill for any new application. Also... you need to understand that building something similar to reddit is a monumental and non-trivial task. To put things in perspective, Reddit is multiple times bigger than StackOverFlow and https://nickcraver.com/blog/2016/02/03/stack-overflow-a-technical-deconstruction/ can give you an idea of how non-trivial building stack-over-flow is.
Shrug. I've yet to see a case where akka actors add any value, across several companies that adopted them (most of which eventually moved away from them). So while I'm not sure what's driving adoption, I'm pretty sure it's mostly something other than technical merit.
I though about a micro-services architecture for the different engines the application would need (scoring, voting, etc) but nothing really on the front end yet. This looks like a great candidate for modularizing the front end. Thanks
[removed]
lol might as well nosql this.
I agree that there are several possible ways to see this. Historical tidbit: The Scala solution was recommended strongly by Phil Wadler, and he got it from Peter Buneman, the pioneer of language embedded queries. When designing this, I did not have a preconceived notion what to do, so I bowed to authority :-) 
I'm sure they do, and I believe they mean it. But it's not because it's a good fit for their problem (sure it may be better than what they were using before), but because they don't know we can probably do a bit do better. Which has to do with people using FP stacks not blogging/talking at meetups about how good it actually is. edit: that's coming from someone who's used it extensively for everything, and was lucky enough to have capability to move away from them, and difference is much more pleasant codebase and happy developers
So does this mean there's a release? Is scalameta usable yet?
There are several answers to that * scala.meta syntactic API is rock-solid and has been pretty stable since 1.0 release in April. * scala.meta paradise (which powers the macro annotations in this post) is still under heavy development. We reached a big milestone last week where the scalac-&gt;scala.meta syntactic converter now has 99.8% coverage from a corpus of 26k source files. * intellij-scala merged this week awesome support for the new-style macros. You need to be on 2016.3 EAP with nightly build to try it out. We aim to release 1.3 later this week that will include the latest improvements in scalameta/paradise.
There is now an introduction page at the website: http://reactors.io/tutorialdocs//reactors/why-reactors/index.html
I have spent years writing high performance Java code for the HFT and financial markets, and benchmarking the same.
Even the simplest Scala programs seem to take a couple of seconds to run at minimum, which is irritating enough to outweigh the advantages of Scala (particularly when I might want to e.g. pass such a command to a `find -exec` to run it once on each file in some path).
Not OP, but the JVM has a relatively long start up period. This is due to a tradeoff where some work is front loaded so that a longer running app would be more optimized. If the app isn't long running, though, then that upfront work is all cost and no benefit.
To add to this answer, some JVM programs can be incredibly slow because of lack of ahead-of-time compilation. Short-lived command-line utilities don't profit much from JIT.
JVM startup time
I feel I should clarify my comment: Phrase "you can only use **1/4** of your memory ... for the GC to perform **well**" does sound crazy. It may be normal if you're talking about HFT, but HFT itself lies far from a normal JVM use case. Also proof request is absolutely legit IMO. Anybody can think, for example, that Java is slow comparing to C++, because it's a "common truth". But things may be different in reality. And lastly since I don't a have a way to check your biography I can't simply admit your words about your experience.
This is something I think about a lot. I would would love to make scripts/tools for my entire workflow in Scala, but the startup time truly kills it.
That diagram explains a lot, thank you! Also, Scalafix is awesome; I'm glad to see the groundwork is already being laid for migrating to Dotty.
&gt; To add to this answer, some JVM programs can be incredibly slow because of lack of ahead-of-time compilation. This answer does not apply to the execution of a `JAR`, i.e. `java -jar script.jar`, no, since there's only byte-code to run?
Agree. If native is an option use Haskell.
I think you're missing the potential for command-line utilities that are already written in Scala and could benefit from faster startup times + AOT compilation. Dealing with nailgun is a pain.
Fair point: it's surprising to me that "Haskell/OCaml is not attractive for us at all" but "I'm doing front and back webdev in Scala already," I guess. Given that, and that you have a need for CLI stuff, your case makes sense to me.
I've considered doing that but you're stuck with a whole infrastructure designed for non-blocking operation in a situation where blocking is what you want to do.
I agree with Ocaml being underestimated as a systems language but IMO (I am no expert in FP and my low level programming knowledge mostly comes from reverse engineering so I'm not one there either also I'm in my 20s which discounts me more) you can't have a pure FP language for say kernel programming because it inherently requires a lot of state and side effects. Anything in between yeah Ocaml would be great just because as an ML it's pretty fast, it's easy to be productive in, it's support for concurrency needs to improve for it to be used for what go is used for though. That's really the only thing I wished ocaml had that haskell has I'm not even that huge of a STM fan either. Yes I know about netmulticore. 
I'm particularly interested in implementing the kind of task often delegated to JNI in scala. Being able to drop to native code without switching languages, along with type safe region/memory management would reduce the barrier to entry for using JNI greatly. For example, SBT might benefit greatly implementing some tasks natively(ie, native file watchers with inotify, native process management, ncurses interfaces), and perhaps be able to fallback to the same code on the JVM if there's no platform specific extension available.
Scala.js is motivated by wanting a strong, statically typed FP language on top of Javascript, with tooling that doesn't suck, a category for which it currently has no competition. Personally even if I would do only frontend development, with no shared code with a backend, I would still want Scala.js. Because the only other JS compiler and ecosystem that's as mature and well supported by libraries and tools and not just another superficial and slightly broken JS transpiler is ClojureScript. This pragmatism that went into its design turns out it is valuable not only on top of the JVM. It's true that maybe things would have been better in some regards with some sort of FFI, instead of this direct integration with the host platform, because now we have to live with things like `null`. I know of js_of_ocaml or of ghcjs, but they suffer from tooling and an impedance mismatch with the host, while Scala.js took off in only a couple of months. And we language geeks often forget that we're in this to build stuff and it's not the experience that matters, but the final artifact. And in that regard Scala really delivers. As for Scala Native, I think you underestimate the effort that it takes to learn a new language, along with a whole new set of tooling. Scala.js proves valuable because there's now a whole ecosystem of libraries that are cross-compiled, thus developers can easily transfer their knowledge. If Scala Native ends up with the same level of support that Scala.js has right now, it's going to be awesome. It also has the potential to evolve differently versus OCaml. Consider how OCaml still doesn't do multi-threading. Surely it's awesome that OCaml has a very low-latency GC and has libraries for inter-process communications, but if you want memory sharing between OS-managed threads, you're currently out of luck. And even if they finally deliver that concurrent GC, along with a memory model, you then have a whole ecosystem that's not ready for it. Well, Scala Native isn't even a blip on the radar, but if it takes off, it's coming with multi-threading support from the get-go, simply because the whole ecosystem expects it. That said personally I'm not very optimistic about Scala Native, because the effort it will take to make it usable are probably huge, as now their authors can't simply bootstrap it on top of another mature platform. For example AFAIK they are using the Boehm GC, which is conservative, so you can have libraries that work fine on top of the JVM, but that leak memory or have terrible performance when ported to native, which isn't cool at all. But one can hope :-)
How will interop between native and jvm scala be handled? If I can seamlessly integrate native and jvm scala then this is great for me since I deal with a lot of low level stuff where memory control is very useful.
Well, I'll be patient then. Thanks for all the hard work!
Keep in mind that not all people using scala are doing functional programming. Haskell is not necessarily a drop in replacement for a scala program. 
I had to add a plugins folder and plugins.sbt in %username%\.sbt\0.13\ myself because the plugins folder did not exist after installing sbt. After adding the addSbtPlugin lines in that plugins.sbt it worked for me. 
I think the idea is that you will ultimately be able to use one language to write JVM, Android, web and native. From a code reuse perspective this isn't such a bad thing. Obviously it won't do all of those equally well. Can you give an example of what design decision only works for the JVM?
Nobody has mentioned the ability to write iOS apps. It might be a long shot as a lot of development will be needed to make the iOS frameworks available via facades is needed, but it's a possibility I like. Imagine sharing application code between Android (already possible but clumsy), iOS, the web (already possible with Scala.js), and the server (possible with Scala JVM and Scala.js on Node), in each case running as efficiently as possible. That sounds pretty good to me.
If anybody has a close experience: how much code is actually shared between frontend and backend in applications using Scala on both?
I tried scalajs-react and didn't like it. Somehow it just did not convey the simplicity and ease of use of react.js. I'm currently writing a scala.js wrapper for cycle.js, which I like more than react so far. In general I like working with scala.js very much. Once you understand how it interops with JS, it becomes a very productive environment.
I didn't say there are things that only work on the JVM, I said there are things the language does that reflect limitations of the JVM and/or desire for Java compatibility. Some examples: - special handling for `Array` - distinction between `AnyRef` and `AnyVal` - observable boxing - `null` - object initialization semantics (oops, NPE) - lack of general tail call elimination - universal `equals`, `toString`, `getClass`, `wait`, `notify`, etc. I could go on. None of these things would make sense in a clean-room implementation of a Scala-like language.
&gt; If scala.js could provide the guarantees that Elm does I'd probably give it another try, because I love the Scala language but scala.js has too much js still intertwined with it rather than just underlying it. This dichotomy is core to the design choices of Elm and Scala.js. Just as Elm was designed to hide JavaScript quite a lot, Scala.js was designed to interoperate with JavaScript. That design choice will not change, so I'm afraid what you're looking for will never happen in Scala.js.
This book is not officially available for free. Please support editors and authors by buying the books. And the link provided ask you to click on some ad-crap you likely don't want to click on.
Specs2 immutable acceptance specs are my proffered option if writing BDD style tests. Yes they are not plain text files. Cucmber sells plain text files as it's strength as anyone can write them. Past experience in cucumber tells me this generally isn't true. The only person in the end who read the Cucumber specs after creation are devs. For the devs the spec files are fragile and brittle, forced english, fragile regex matching, hard to search because of regex patterns. Also it works on mutation for the steps. You could have a step silently fail, a common one is people store the last HTTP response. A test could fail which is supposed to update this value you assert on, when you get to the assertion you might not be validating the HTTP response you think you just sent as something failed but the last previous successful response. Think of all the mutation issues you can have in software, cucumber works on this making it hard to debug when you need to. Spec2 immutable acceptance specs you can achieve the same plain English BDD style report which reads fluently and not as forced as cucumber. You can design your tests to be idempotent and take it further than Cucumber example based specifications by using Scala Check and use a property based tests. Not sure if ScalaTest offers an alternative to Specs2 Acceptance Style I've always used Specs2, it may and if it does I have no real preference if the mechanics are the same. I'm a big fan of BDD but avoid Cucumber at all cost, it starts out well but when your suite grows it's a world of pain.
Frameworks like ScalaTest and Specs are completely missing the point of "specification by example". The real benefit is to get non-technical people involved. In the best case they would actively write tests, and at least they would be able to read tests. Programming centric frameworks like ScalaTests or Specs2 will scare those people aways and will render the whole approach near to useless. Long story short: use Cucumber.
I think destructuring assignment is also confusing. More generally the language is bad at distinguishing between safe matching and unsafe matching. Maybe `val id: Type = ` is just a symptom of this general issue. But adding a type annotation definitely shouldn't change behaviour to the extent that it does.
Have you considered OCaml?
Agreed on if you are doing "specification by example" you should sit down with the stake holders and absolutely have a "shared understanding" . This is a process not a technical tool requirement. How you come to this "shared understanding" is up to the team. If the "Given, Then, When" format works then great, Cucumber isn't a part of that. I've seen "Given, When, Then" provided on paper, cards, jira tickets, I've even seen comic strips used instead of given then when and also seen people avoid given then when as it's to clinical and instead use something else more familiar, that's fine to. Non of this has a requirement on a test tool. The only requirement is to sit down with who you need to and come up with shared requirements in a language understandable by the team. The next step is making the requirements executable and report-able this is when the tools comes in. Specs2 allows you to take the specifications, make them executable and formatted as the language used by the team and published with the benefit the architecture promotes good maintainable tests. Using Cucumber delivering work becomes about using Cucumber in the teams I worked with, the point is missed. It was playing lip service only. Add to that cucumber's implementation it is fragile and prone to flickering hard to debug tests. It's a big investment, if it's worth it or not it's up to you. Take specs2, you have the same conversations, you share the feature somewhere however you store requirements in your company, on story cards, on a ticket system etc. You then implement the test in specs2 worded exactly as the story and publish the test report. Is this not specification by example or BDD? You had the same conversations and have the same outcome, a published executable specification. My previous company spent huge amounts of money on Cucmber consulting from the authors, run training courses etc. Cucumber had one advantage, it got dysfunctional teams working together. What we also observed is once the dysfunctional teams started to work together they eventually dropped Cucumber as the test suits became hard to maintain. What they did do though is carry on the process, sitting down together, drawing up clear requirements flashing out issues together, storing the results of the story session with the story then writing a test in a framework suited to the language being used but generated the same sort of cucumber report verifying requirements are met.
&gt; It's true that maybe things would have been better in some regards with some sort of FFI, instead of this direct integration with the host platform, because now we have to live with things like null. Actually, I think that having `null` is a good thing when dealing with platforms that have concepts of `null`, which happen to be both Scala.js and Scala-Native with c Also having null in Scala in reality hasn't really been a problem, in fact in some cases its useful because in idiomatic Scala code null is basically never used, so when it does occur its usually for very specific reasons (i.e. trait initialisation)
&gt; Scala has made a ton of design decisions that only make sense in the context of the JVM and Java compatibility. Actually a lot of people are misguided in this area. For example, people assume that Scala has subtyping because of Java interopt however if you watch Martin Odersky's talk, subtyping was a deliberate design decision (see this talk here https://vimeo.com/130882156 at around 10 minutes). It turns out if you want a decent module system you need a form of subtyping. In fact, the only real things that I can thing of which are done specifically due to JVM interopt and not an actual design decision for Scala are - `null` - Object `equals` - Synchronised by default (I think this is being changed in Dotty? May be wrong on this one) So all in all unless I have missed something, there isn't a lot. There are also some discrepancies, such as how auto boxing of primitives working differently in Scala vs Java, however you can put that into the "platform specific" behaviour box
&gt; special handling for Array Kinda irrelevant as scalac/stdlib tries to hide these things &gt; distinction between AnyRef and AnyVal Completely intentional and any decent language that cares about performance has this distinction. In fact, not having this distinction is **really bad for performance** as well as other things (have a look at Ruby) &gt; object initialization semantics (oops, NPE) Martin Odersky said in one of this talks that this is intentional. Trying to verify initialization order in these cases by the compiler is too hard and not one of Scala's design goals. You could argue that throwing a "null" is a Java thing, but the alternative would basically be something thats equivocally the same &gt; lack of general tail call elimination Only JVM specific, nothing to do with Scala. scala-native is going to have TCE and its not going to need any changes to the core Scala language tl;dr The number of **actual** design compromises (versus perceived ones due to ideological reasons) due to Java are actually really small (or they are crop up in very rare corner cases)
When did SQL become 'uncool'? I still don't get it.
I believe it doesn't have a large community/ecosystem, at least not as large as Scala.
I think this project is a long way from generating a library suitable for such purposes. It seems exe centric right now.
Yup, this would be my argument.
New to scala. I have completed twitter scala school. What should i do next to start learning in depth. I am not sure if am ready to tak martin ordersky course, thanks.
I'm not sure what's in twitter's course but I suggest reading _Programming in Scala 3rd Ed_.
The only way I know of generalizing over arity is with HLists and you need N+1 class instantiations to generalize over the arity N. Whereas with variadic type arguments you would need one instantiation. Not to mention a much nicer syntax.
If you have completed the entire twitter scala school you should be more than prepared for 'Function Programming Principles in Scala' course on Coursera (pretty sure that's the one you are referring to.) It's aimed towards beginners to both functional programming and scala.
Ammonite scripts don't seem to take too long -- I'm not sure if they do anything special scala doesn't do. 
I can recommend just going through sources of standard lib... or any lib you're using. You learn a lot by reading code written by pros. My usual aproach to language is, i.e. I use List[Int], I go to implementation and check it out... ahh abstract case class here, implementation there... I go back... I use myList.headOption, I go check how it's implemented, etc... I can recommend this as you very quickly get very good feel for the language (or any language)
&gt; The next step is making the requirements executable and report-able this is when the tools comes in. The main benefit of Cucumber is that the "specification" is test and documentation in one. If you talk to business folks and then translate what you've heard into code you will deviate from what you heard and since buisiness people won't look into code it will be catched much later. 
Find some real problems that you care about, and use Scala to solve them. At least, that's the only thing that's ever worked for me.
&gt; case Pull =&gt; Task { /* await on socket; toString */ } Better to use `Task.async` or similar and an async API if you can, but yeah that's the basic idea. &gt; Is my source is a stream of.. Pull &gt; But then again, how do I actually define source and sink ? Yep. The source is just `Stream.repeatEval(Pull)`. And sink is just an alias for a function from a stream to a stream of `Unit`, so `_.flatMap {s =&gt; Stream.eval(Push(s))}` will do for your `Sink[JMS, String]`. (I'm amazed there isn't a nicer alias for that operation? Maybe there is. I don't find the documentation very usable, unfortunately). &gt; What's the point of Stream abstraction if I'm waiting on soket in my interperter? Am I completely misusing all this? The reason for using `Stream` at all is that you get (possibly async) streaming without any queues or having to worry about backpressure. Instead the control flow will go back and forth along the pipeline; rather than worrying about whether to make your flow pull or push, it's both here. For a specific pipeline you could do that by hand (though an unfortunate Scala implementation detail is that if you do it naively you'll stack overflow). The advantage of doing it with Streams is that you can work with the ends or even the middle of a pipeline independently, even though ultimately the control flow of all these parts is going to be interleaved. And you have a library of sugar for common cases (e.g. all the collection-like operators like `map`). It's useful, but it's also not that big a deal. The actual iteratee pattern is dead simple, 10 lines or so and half of them are working around Scala's lack of tail calls rather than doing any actual logic (most of fs2 is taken up with sugar on top of it) and easy enough to work with directly. If you have time I'd highly recommend implementing your own basic iteratees and playing around with that, just to get a feel for what it does and how it works. (Also the documentation is terrible; a lot of methods have no comment at all. I'm making this sound easy because I've spent many days puzzling it out; don't blame yourself if it isn't obvious. Unfortunately the current code is the kind of library that you can only use if you already understand it). The reason for separating the AST (`Pull` and `Push`) and the actual interpreter is so that you can swap in a different interpreter (e.g. a test stub). If you don't need that, just use `Task` as your `F[_]` throughout, and define your source and sink using `Task`s. But it's nice to be able to run your real stream on a test interpreter rather than having to muck around with mocks to test anything. It also means you have a level of type-safety in that you know that this stream only does JMS things and not random other side effects, and if you accidentally try to plumb e.g. a JMS-related stream into a database-related stream then you'll get an error. (Of course you might *want* a stream that does both) &gt; As a side Q, why have you stopped looking into functional streams? I had a problem they were a good fit for, and I solved it with them. I've switched jobs since then and they're not as useful for what I'm currently doing (and my current client is a lot more conservative about which libraries/patterns they use).
This thread is surely dead, but just chiming in as another Eclipse user who would be sorely disappointed if Scala IDE was no longer developed. Eclipse is not pretty but by god it gets the job done. For me the killer feature is that I have one unified IDE that works across so many languages simultaneously. I have plugins for more than 8 different languages in my one eclipse install and dependencies across those projects and it all works together seamlessly. If there was no good Eclipse plugin for Scala it would truly put a dent in my desire to use Scala in future cross language projects (which is most of them these days).
1. Read Programming in Scala 2. Then Functional Programming in Scala 3. Take the coursera courses if available 4. https://www.scala-exercises.org/ do the libraries in here. 6. Make a hello-world project in sbt. 5. Make a TODO app in Play framework. 6. Write the same TODO app in akka-http with the templating library of your choice. At this point, you should know enough about scala for it to be useful for you on a day to day basis. Go forth and enjoy.
Scala.js Nothing in particular. I'm curious in which cases ability to reuse code on both sides comes in handy.
I'm glad you pointed Ammonite out, because I really need to give it a try. Li Haoyi is a wizard as far as I'm concerned. However, Ammonite is faster because it avoids SBT and [caches bytecode for previously-compiled scripts](http://www.lihaoyi.com/Ammonite/#ExecutionModel), but still has to spin up a JVM instance, taking 100s of ms. 
Is the jvm really that slow? I used to think it was, but if you run, for instance, maven (ugh), it immediately starts outputting information on the console. I know about the caching, but you can run scala scripts with just #!/usr/bin/env scala, but I wasn't sure if that did caching as well. Of course, you'll have some difficulties with dependencies if you go this route and skip sbt... 
I'm here with two of my coworkers repping Tapad, New York City, and the east coast!
Why not?
It is. I got "100s of ms" from the linked description of Ammonite's execution model. Here's a bit more about [the cost of the JVM from Ammonite](http://www.lihaoyi.com/Ammonite/#RunningontheJVM), which cites its startup time as "seconds". On my (admittedly oldish) work laptop, with HotSpot, default heap size and a larger project, it can take a second or two to boot. The JVM also uses a lot of memory and doesn't have great performance before the JIT warms up. It just isn't a great fit for scripting right now. And before anyone brings up Drip or Nailgun- at that point I'd rather just use bash or Python.
This is *awesome*. I really feel like this could be a gamechanger.
All sorts to be honest. Data validation often needs to be in both client and server. The model objects. Formatting functions such a date time stuff. More than you'd think.
Fair enough. 
I've always wondered, is there ever data validation that can't be performed on both? If so, how do you handle it and split it up?
Yeah sometimes you can't work out if something is valid unless you've got db access. In those scenarios the validation succeeds and I throw a bad operation exception when I'm returning the error.
I would love to switch to IntelliJ from ScalaIDE, but it's just far too unreliable at checking Scala code, particularly code that uses scalaz or cats. As a minimal example: import cats.implicits._ val foo = List(1, 2, 3, 4, 5) val bar = foo traverse Option.apply println(bar) IntelliJ fails to infer the types involved in the traverse, highlighting the line as an error, but it's correct scala code and compiles and runs fine.
I'm sure you've already got enough useful advice about the continuation but I want to append my method: 1. Collect the community projects in a group 2. Inspect their architecture and DSL. 3. Try to reimplement them from scratch. 4. Compare the code and improve yours based on what you can see in others' code. 5. Try to contribute in some of those community projects(no need for pull requests if you aren't sure what you're doing). 6. Try to implement something which isn't present yet. This way is a hard but it'll pay out because you'll need to understand a large variety of architectures and you may find your place in the community more quickly.
I'd an opensource alternative to m50d's jprofiler: [visualvm](https://visualvm.java.net/). I often use it, it's pretty simple. It's [widely used](https://zeroturnaround.com/rebellabs/top-5-java-profilers-revealed-real-world-data-with-visualvm-jprofiler-java-mission-control-yourkit-and-custom-tooling/) and has a [nice intellij plugin](https://plugins.jetbrains.com/plugin/7115).
Transformers readability problem is not that big of a deal. Type aliases and manual typeclass instantiation, if you want, will help you (I've [done this](https://github.com/oleg-py/mco/blob/cd9463c395c586477614527fe848c2ffcf627670/io/src/mco/io/files/package.scala#L14) in my personal project, and it's not bad at all, esp. since it's used throughout all my API) If a function has a type of `A =&gt; Task[B]` and only throws in chunks of code that are run only when `Task` is run itself (e.g. in `Task.apply` and similar methods), then it's a total function on its domain - a domain of opaque chunks of code that might result in a value of type `B` when run, possibly performing side effects (whew!). `Task` is something I'd avoid creating at all for as long as I can. `Task[Either[A, B]]` reads as something that can fail unexpectedly, fail expectedly, or result in a value of type `B`, and the code to handle all these cases won't be particularly nice, but it won't be too horrible (unless your `B` is stuff like `Map[C, Vector[Option[D]]`). But there are other options. For one, you can make your error ADT extend `Exception`. This way you can easily materialize `Task[Either[DomainFalure, B]]` from a `Task[B]`, or just pattern-match it separately from other exception types in the recovery function - as long as you follow the convention of failing with your own exception types. Anyway, choosing between `Task[Either[A, B]]` and `Task[B]` is just a judgment call that you have to make depending on your domain, experiments and experience. In that personal project I tried to fit a `Task` into my domain whilst doing some DI and ended up learning and using free monads, which was a very good choice - after all, if you want to enumerate your failures, why not enumerate your side-effecting operations as well?
IntelliJ doesn't conscript the scala compiler to provide the metadata? If not does that mean they basically write a compiler front end for every language they highlight?
I'm hoping this line: &gt; Also, you’ll see less of “red code”, for example when you’re using akka-http Means they've improved that - haven't tried it yet though :|.
Isn't scala short for scalable or scalable language? Scalae = scalable language scale? 
http://i0.kym-cdn.com/photos/images/newsfeed/000/131/399/fry.PNG
I'm very happy to see Scala.js explicitly being focused on. It's such an amazing technology once you get it up and running! I really believe it will enable us to build far more complex frontend applications with a fraction of the chaos and hardship from an untyped incoherent language like javascript. In a way, we can be build things that has never been made before, simply because we have better tools and structure. From my experience, if you take scala.js with scalatags+scala.rx+scalatags-rx, you almost have a complete package that is very close to what angular and react gives you -- while still being derived from dead simple principles. It's just functions returning html; there's no framework you have to learn! I think all SJS need right now is for someone to sew all of these nice libraries together into a killer package deal like React and Angular gives you; something that contains all the things you need right out the box (router etc) so that you can be making stuff within a minutes of discovering it! I think that's what angular and react does so well: they enable you to be up and running almost instantly. We need a library/framework/"bundle" for Scala.js that does the same!
Does Udash http://udash.io/ satisfy your wishes?
scalatimes.com
Yep. My argument is naïve. It really is a big deal to be able to use a plenty-good-enough language you already know everywhere you could reasonably want to.
It's one of the property-based frameworks, so more a competitor to ScalaCheck. ScalaCheck is very strangely architected and misbehaves under what seem like some pretty common use cases—so much so that Rúnar added a couple of new ways to lazily define properties so as to avoid bad initialization order bugs.
The example should explicitly assume an equal probability of having a boy and a girl, and absolutely should not round up. Also {amount -&gt; number} of kids per family. Cool library though. It's worth mentioning [something that offering similar functionality](http://spark.apache.org/docs/latest/mllib-statistics.html).
First of all, thank you for the feedback. [probability-monad](https://github.com/jliszka/probability-monad) is also great, Tyche was originally born as a fork but in the end I decided to build a separate project. I think the equal probability of having a boy or a girl is implied. Why do you think rounding to the nearest integer is a bad idea?
That makes sense; gonna fix it in the next push 👍 . Thanks again.
Scala is fast. Scala is good. Eclipse or intellij both work fine, depends in what you like. Game programming will work fine. I wouldn't do an fps or rts in scala, since it's hard to know how long something will take. But it should be doable for anything else. But honestly it'd be easier most of the time to use an engine or framework than do all of the hard stuff yourself. Big problem with scala on games is that memory might get out of hand if you don't really know what you are doing. You write a nice little one liner and you might be using a lot more memory than you expected.
http://benchmarksgame.alioth.debian.org/u64q/scala.html
I just visited this site tonight :). I think that's for an older version of Scala
Where did you see this?
Check out jmonkeyengine 
&gt;Scala compiler version 2.12.0 -- Copyright 2002-2016, LAMP/EPFL and Lightbend, Inc. &gt;java version "1.8.0_92" Scala 2.12.0 came out 10 days ago. It's bleeding edge. 
Should I learn Golang instead?
A smattering of interesting people I follow either directly working on Scala or extremely popular libraries/open source frameworks: * https://twitter.com/adriaanm * https://twitter.com/retronym * https://twitter.com/puffnfresh * https://twitter.com/djspiewak * https://twitter.com/timperrett * https://twitter.com/S11001001 * https://twitter.com/aloiscochard * https://twitter.com/jdegoes * https://twitter.com/eed3si9n * https://twitter.com/mpilquist * https://twitter.com/li_haoyi 
Can confirm Minecraft is still Java. Have written hacked clients for Minecraft in Java/Scala in the past.
I love Scala for games. Ive been in the game industry for 17 years now and have used lots of languages and lots of frameworks. If youre asking this question, its plenty fast for you. And it makes development a joy. 
No. Learn Scala.
and www.cakesolutions.net/teamblogs
I've not seen anything off the shelf. What I have seen and in some circumstances may be ok is an off the shelf CMS such as Wordpress / Drupal used and then an app in front read only querying the database for Wordpress, or using the rest API for Drupal. You get the admin backend and workflows from the off the shelf CMS and the view / rendering you can use what ever stack you want. As a quick easy win i'm 50/50, it can be acceptable in the right circumstances. Long term you have 2 systems to maintain and all the baggage of running a secured LAMP setup and keeping up to date on patches on top of the custom Scala deployment. It works with caveats.
It's fast enough. It's in the "high-performance JIT language with automatic memory management" bucket. But language speed is almost certainly the wrong question to be asking. IMO the best IDE is Eclipse/ScalaIDE, because its errors (in the problems view) are more reliable than IntelliJ's (more importantly, the *absence* of errors is reliable). But the UI does lock up for a few minutes every so often. So pick your poison really. In principle Scala is a suitable language for game development. In practice the library/tool support on the JVM isn't really there yet IMO. You might be better off with F#.
This is the "cake pattern". For testing you're supposed to instantiate the real UserComponent but mix in a mock implementation of `DatabaseComponent` and/or `DriverComponent`. Or factor out an interface and mock that. (Or more likely refactor the whole thing because the cake pattern isn't worth the maintenance overhead).
Baseline performance is the same as Java, which should be more than enough for your project. However, the actual performance will mostly depend of how you program it. Idiomatic Scala with immutable data structures, pattern matching, lots of recursion etc. will result in *a lot* of small short-lived object allocations which is not a great idea for a game project especially if you want to run it on Android. If you approach it with performance in mind, using basic mutable Java data structures for performance-critical sections, you will be fine.
twitter for one. also saw it in a logo for scala by the bay.
ah thanks. I wasn't sure Scala was Scalable before, now theres no doubt.
Yep. I thought I'm king of the hill in the OOP world. I hated it and was on verge of quitting programming... when by accident someone introduced me to FP and I've been hooked ever since (and enjoying every second of it).
It might not be exactly what you're looking for, but I have been using [prismic.io](https://prismic.io) for a project at work. It's from Zengularity, the same guys who created Play. It's a CMS backend, which means they expose a REST api which you can call from your application. 
"make certain classes of code easier / more maintainable", can you give an example that does benefit Scala, or an example that can benefit something analogous in Scala?
I'm currently developing a 2d strategic/management game using libgdx. While still in a early stage and considering I have no experience in game development, I would say that Scala is a good choice. I'm keeping a mutable state to be more in control of what happens under the hood and to adapt to libgdx while going pure functional for all the game logic. Jumping to a paradigm to the other without problems is a big added value because you can write complex logic in a few lines and at the same time you can fine-tune the data structures. I fear I should have gone for an mvc-like pattern where the m and v are imperative while the c is functional, but now it's too much effort and demonstrating the flexibility of the language is not the goal of the project. 
Alas, nobody can judge whether the function will throw or not by its type alone in Scala. For any type - `Int =&gt; Int`, `(Nothing, Nothing, Nothing) =&gt; Unit`, you name it, because I can write `???` as body and pass `null.asInstanceOf[...]` as parameters. None of these are nicely translated to mathematical reasoning, because throwing is a side-effect, and neither null nor type casting exist here, but it's still the case. Also, functions can throw `OutOfMemoryError` (which people don't care about most of the time) or `StackOverflowError` (which people cannot ignore, so they have to trampoline stuff). You can treat your `g` as non-total (because it throws for some values) or not a function in mathematical sense (because it has side effects). Whatever fits your line of reasoning better is good enough, and I prefer the second one. From API design standpoint, if you have a function of type `A =&gt; Task[B]`, everybody would expect it to be total, not throwing until `Task` is run. Same for any error-handling applicative functor (Scala `Either[Throwable, A]`, `Try`, `Future`, Scalaz `Throwable \\/ A`, Cats now-deprecated `Throwable Xor A`, Monix `Coeval`, `Task` and `Observable`), and if you expect your function to fail in some cases, and expect user to handle the failure, you'd better use one of those. Or ban invalid values using something like [refined](https://github.com/fthomas/refined). Also, for evaluation-controlling things like `Task` it will be expected to have no side effects at all. Comparing `Task.now` and `Task.apply` is comparing eager vs. lazy evaluation. They are equivalent *in the absence of side effects*.
&gt; In principle Scala is a suitable language for game development. In practice the library/tool support on the JVM isn't really there yet IMO. You might be better off with F#. It depends on what you are talking about when you mean "game development". If we are talking about AAA or AA games which have a focus on graphics, then Scala (at least on the JVM) I wouldn't call for game development suitable due to performance/memory/GC reasons. Also at least until Dotty's deep linker is released (which will features such as fusion to remove a lot of intermediate objects), idiomatic Scala code is probably not what you will be seeing. These are some of the reasons why languages like C++ (and hopefully Rust in the future) dominate. Scala-native should help a lot here however
The type `A` is generic, meaning it is applicable to any other type passed in at the call site. It's an example of [parametric polymorphism](https://en.wikipedia.org/wiki/Parametric_polymorphism) `toList("asdf")` means A is a String in that case. `toList(4)` means A is an Int, in that case. `toList(RedditUserObj("runT1ME", 10, "/r/scala")` means A is type of my custom RedditUserObj. If you come to #Scala on IRC (Freenode) there's a REPL in the chat along with a lot of other friendly folk that can help explain and code this a bit with you in real time. :) 
Without brackets A would be interpreted as regular type. If A were to be auto generified, you'd have a bad time wondering why your Stirng parameter doesn't have its methods.
scalaz and shapeless have been in every scala project I've worked on in major banks. Some don't like it for bizarre reasons, but they are too useful to avoid.
Also, how else would the compiler tell the difference between the generic type `A` and the (hypothetical) concrete type `A`?
Speaking of ad-hoc, lightweight record types, have you seen SML's (or Elm's) record types? You can make the structures up on the fly and the member field names actually become part of the type. Incredible. As they say, an elegant weapon from a more civilised age.
If he needs to use mutable data structure for performance reason, isn't he better off using Java or C++ instead. 
`Task.now` takes a pure value, which `{ num / denom }` is not, as the curly braces signify. 
&gt; Alas, nobody can judge whether the function will throw or not by its type alone in Scala. Strictly true, but we assume `A =&gt; Task[B]` won't throw, because [its whole _raison d'être_ compared to scalaz's `Future` is to catch exceptions](https://github.com/scalaz/scalaz/blob/v7.2.7/concurrent/src/main/scala/scalaz/concurrent/Task.scala#L16-L19). Which brings us to... &gt; Comparing `Task.now` and `Task.apply` is comparing eager vs. lazy evaluation. They are equivalent _in the absence of side effects_. Exactly, and throwing is the granddaddy of effects (mutation being the great-granddaddy).
I was on some projects at Kixeye that used it. We had a complete backend in Scala that was very fast, and very robust. Because of our heavy use of Option, we didnt have one null pointer crash. Ive worked on prototypes for Scala front ends. With one I got 20k units moving around a map. 
You could model your message to the "monitor" as a request (include a Promise object with it). It would be the monitors obligation to either complete the promise or indicate a failure. Attach both the results displaying function and the Utils.showPrompt / input gathering function to the promise using "andThen" such that they execute in the correct order. EDIT: You could also model the entire thing as an Akka FSM and have the FSM itself do the input polling after the appropriate state transitions. I wrote a buffered TCP client using this method. http://doc.akka.io/docs/akka/2.4/scala/fsm.html
Compared to the strongest (practical) use case of the other language.
Then none really. Because every language has a case where it's more fit for. The better question would be what is the best use case for Scala (where it's better than any other language).
True. Maybe compared to what the other language is typically used for.
In my mind Erlang, C++ and Haskell are the ones that have real uses cases where Scala really doesn't fit well and thus they can be better for their uses. For all the other ones if I would be the one to pick I would always take Scala over them.
If you really want to do something with it if present and not if not, then `foreach` does that. But note that idiomatic Scala (and FP in general) generally tries to avoid side effects in favour of computing values, so it may be worth seeing if you can figure out how to replace `doSomething()` with that approach, at which point a sensible value for in the `None` case will probably become apparent (and you can probably replace the match with a `fold` or `foldLeft`).
Thank you. Here, you have mine.
Type theory still makes my head spin, it's definitely not a free lunch. Still, I'm in the same boat as you, the reward for proficiency makes it so worthwhile.
I find it weird that so many found scala to be strictly better than clojure. I would never tell anyone to use scala over clojure, I'd say try both and use both.
It's a linguistic insult to all scandinavian speakers. skalæ? ska æ ka? æ skjønn itj. Also to add something useful to my shitpost, does anyone have any hot intel on when videos will be released?
Have you considered writing a blog post about this massive refactoring with more details?
Right, IMO it'd make more sense to show how many % of voters think that scala is better than each language.
It's not just a typed language. Any less powerful type system (e.g. java) would leave you in a world of pain also. Honestly, this and option types make scala worth it alone. 
The 'default' is the JVM. [scala.js](https://www.scala-js.org/) is quite mature. [scala-native](https://github.com/scala-native/scala-native) is work in progress but I've big hopes for it.
Are you me?
What do you mean by, "as the curly braces signify," Paul?
Well, it makes the point a bit overly-identified. `{}` delimits a block, i.e. something that will be computed. The difference between them and parenthesis is explained pretty well [here](http://stackoverflow.com/questions/4386127/what-is-the-formal-difference-in-scala-between-braces-and-parentheses-and-when). But really, as always, we should look at the signature of what you're calling. [`Task.now`](https://oss.sonatype.org/service/local/repositories/releases/archive/org/scalaz/scalaz_2.11/7.2.7/scalaz_2.11-7.2.7-javadoc.jar/!/index.html#scalaz.concurrent.Task$@now[A](a:A\):scalaz.concurrent.Task[A])'s signature is `def now[A](a: A): Task[A]`. [`Task.delay`](https://oss.sonatype.org/service/local/repositories/releases/archive/org/scalaz/scalaz_2.11/7.2.7/scalaz_2.11-7.2.7-javadoc.jar/!/index.html#scalaz.concurrent.Task$@delay[A](a:=&gt;A\):scalaz.concurrent.Task[A])'s is `def delay[A](a: ⇒ A): Task[A]`. See the difference? `Task.now`'s argument is passed by value. `Task.delay`'s argument is passed by name. `num / denom` is not a value, regardless of whether you put it between `()` or `{}`; it's just that `{}` makes it very explicit that you aren't passing a value; you're performing a computation (that, in this case, is not pure) and passing the result of that computation (if it succeeds).
Similar story for me last week. I wanted to switch from [this](https://github.com/mauricio/postgresql-async) postgres driver to [this one](https://github.com/alaisi/postgres-async-driver). I did it in a three step process: 1) traitify/abstract existing driver use, 2) write conforming impl for new driver, 3) remove leaky abstraction pieces just there to support the refactor. Took very little time. The week prior I did similar by changing all Scala futures to Monix tasks. Scala and tooling of course make all of this quite easy (but a good test suite never hurts!)
An oldie but a goodie: [Option Cheat Sheet](http://blog.tmorris.net/posts/scalaoption-cheat-sheet/)
Leaving out the port number just means "use the default port". The way to do it would be to run it on port 80 instead of 8080 if that's possible.
Yeah, the point of it is substantially the same as for scala.js: bring the power/pleasantness of scala to another environment with an existing ecosystem. If no-one else is doing it, I won't start it until...probably ever. 
Yeah that does not seems like a good practical solution rather than compiling to the target language/bytecode.
Wait, your IDE actually works!? What kind of black voodoo are you using? I chase compile bugs in my sbt terminal on 2nd monitor, then goto-file goto-line :o intellJ fails for anything semipolymorphic. I am also not disparaging dynamic languages, hell I reached for python ocassionaly, and I never worked with large enterprisey system in dynamic language, so im in same boat. JUst dunno if they grep alot.
My needs are somewhere between a monolithic enterprise site and a blog. Like the middle ground. Of course I'm basing this off of what my prospective client is aiming for. Feature wise I could go either way. Mostly just trying to choose between tech and since there were no requirements on it and I actually am a Scala dev that likes Scala I was thinking it would be great to use Scala without too much reinvent the wheel syndrome. Since there isn't too much on the Scala front to use as an example I might end up going .NET or Rails based CMS depending on a couple parameters I'm still waiting for. It's that weird spot where they need a good bridge between features that could fit anywhere between the monolith or the sparse. 
Does the UD in your username have any particular meaning (asking as someone that gradded from a school known as UD)? I'm pretty sure there are a couple out there right now that sort of spin a CMS as a PAAS type of thing. I've no experience with them. The couple I've stumbled upon usually don't make it clear as to whether they offer an interface I can tie into my app or if I'll have to do my own that hits their API. 
Nope, DNS won't help, it does not deal with port numbers. You either have to run it on port 80, or run something else on port 80 that then forwards all traffic to 8080 (what's called a proxy). 
I don't have an answer for you, but that is interesting. Note that the function should eventually complete, but for some reason it takes a lot longer. The combinations method is equivalent to itertools.combinations_with_replacement, not itertools.combinations. Also, the combinations method returns an iterator; converting the range to a stream does effectively nothing from what I can tell. This line of Scala: (0 until 30000).toSeq.combinations(2).size https://github.com/scala/scala/blob/v2.12.0/src/library/scala/collection/SeqLike.scala#L155 https://github.com/scala/scala/blob/v2.12.0/src/library/scala/collection/SeqLike.scala#L207 is roughly equivalent to this line of Python: sum(1 for _ in itertools.combinations(list(range(1,30000)), 2)) https://docs.python.org/3/library/itertools.html#itertools.combinations_with_replacement I don't think the .size is the bottleneck, since all it does is lazily increment a count: https://github.com/scala/scala/blob/v2.12.0/src/library/scala/collection/Iterator.scala#L932 https://github.com/scala/scala/blob/v2.12.0/src/library/scala/collection/TraversableOnce.scala#L105 I suspect CombinationsItr.next is (for some reason) a lot slower than the equivalent Python generator. Not sure why.
Im not doing hardcore typelevel. Just basic stuff from cats, reasonably polymorphic.
Time is not important, but if compiler gives u enough errors that is! :)
It's pretty good. Checkout sangria-scala.
Run, for example, nginx on port 80 and let it route via domain name (reverse_proxy)
The UD in my name is for an old gaming community I used to run a good while back. Usually it'd be SeerUK, but alas, that was taken! I've seen a couple like [prismic.io](https://prismic.io/) and [contentful](https://www.contentful.com/). Out of the two I think I preferred contentful, prismic's editing experience let it down IMO. I also am mainly interested in something self-hosted, as if I were to try sell something built on one of the PaaS solutions it'd be a lot more difficult to convince the client it wasn't going to just randomly disappear at some point.
Thanks for tip! Though im quite happy with my workflow
Interesting. Out of curiosity, it what sense do you mean polymorphic?
Particularly when requirements are thin on the ground, I prefer to use very modular, self-contained technology, and rely on being able to mix-and-match components easily and refactor mercilessly as requirements are clarified. If I were in your shoes, I'd strongly consider the combination of [http4s](http://http4s.org) for your service definitions and routing, its support for Play's [Twirl](https://www.playframework.com/documentation/2.4.x/ScalaTemplates), and [Doobie](https://tpolecat.github.io/doobie-0.2.4/00-index.html) for database handling. Look at [this](https://bitbucket.org/da_terry/scalasyd-doobie-http4s) ScalaSyd presentation for an example of how nice it is to use http4s and Doobie. Now, instead of slinging JSON with [Argonaut](http://argonaut.io), look at the [http4s examples](https://github.com/http4s/http4s/blob/v0.14.11/examples/src/main/scala/com/example/http4s/ExampleService.scala#L35-L38), which show how easy it is to render a Twirl template as your response. Then I'd consider how to (safely) support uploading custom Twirl templates and define routes to them. Then I'd add features from there on demand, e.g. adding an embedded template editor, support for something like [Bootstrap](http://getbootstrap.com/), etc. Does this make sense?
type polymorphism like ``` def foo[A[_]: Monad, G[_]](...) ```
Types are a powerfull tool if you use them. When people first move to scala, they don't use the type-system enough. When you start writing functions for F[_] : Monad instead of for Future,list,etc, is when you really start to benefit.
Thanks to your eloquent breakdown of types I now understand everything about them and how to efficiently apply them. Even two year olds can understand basic types. The square block goes in the square hole, no shit. What takes time is understanding stuff like higher kinded types, and after understanding higher kinded types work you can start getting into libraries like shapeless for abstracting over creation of type constructors and typeclasses. It's not like you need a phd, but grossly oversimplifying and then adding a backhanded insult to other language (well, apart from php, php deserves all the shit it gets) just makes you look like a tool.
Specific blogs (usually) as long as they're technical. Technical fora like here and SO. Ordinary websites. Just nothing that allows general anonymous-ish posts - no pastebin/Facebook/twitter/tumblr.
Yeah, self hosted is generally preferred to me. even if I'm working on a subscription service I'm now tied to this platform staying around for a core part of my application.
Fast compilation speed is just what i looked for, compilation time with Binding.scala is excruciating. Does this library work on JVM (for universal rendering)?
We haven't tried server-side rendering but it should be possible in theory. Apps are written in plain scala.Xml. The only js specific part is the DOM mount logic which is ~150 LOC (https://github.com/OlivierBlanvillain/monadic-html/blob/master/monadic-html/src/main/scala/mhtml/mount.scala). I suspect the trickiest part would be client-side loading of the server-side rendered html. You also need cross-platform event handlers.
I share your experience, I think one of the most pleasant things in Scala is that you can do major refactorings and still be sure that if the things compile (well, and your unit tests pass) that you probably haven't introduced many things that need fixing afterwards. This makes it also a great language for experimenting, because you can change a design rather quickly, something that is virtually impossible in a dynamic language. And in the middle, you can throw in some `???` and fix them at a later point.
It's not as easy as implementing a SingleMountPoint in Binding.scala :) I just replace the server generated dom with a client generated one on load, not the most effective way, but it works. Event handlers are handled with a macro (I don't need them on a server side)
My use case is that I'm writing a converter for ML models trained using Spark.ML into PFA (Portable Format for Analytics). I currently do this by setting up converters that satisfy a trait that specifies how to extract out schemas, as well as the collections of cells, user-defined functions, and actions that need to be taken; I then store these in a case class for some further analysis before handling JSON output. If there's another way to think about structuring this, I'm certainly open to suggestions and would appreciate any pointers you could provide.
After your little rant I don't think you're in a position to ask me why I'm mad.
So you seem to have Many different Source types and One output type. That is you have a function: def toPFA[A](a: A): PortableFormatAnalytics Is that correct? In this case, I would define a typeclass and an instance for each type: trait Portable[A]{ def toPFA(a: A): PortableFormatAnalytics } object Portable{ implicit object Class1Portable extends PortableFormatAnalytics[Class1]{ def toPFA(a: Class1): PortableFormatAnalytics = doTheStuffToConvert } implicit object Class2Portable extends PortableFormatAnalytics[Class2]{ implicit def someTypeInClass2ToStringForPFA(a: TypeInClass2):String = definition def toPFA(a: Class2): PortableFormatAnalytics = doTheStuffToConvertClass2 } } Then, group all your implicit conversions that you need for each specific one inside the individual instances, either by putting them in various package objects / standalone objects (modules) and including import statements in the instance body, or by defining them directly there. This keeps them from polluting the imports of all your files that use the converters, and allows you to tightly scope your implicits, while allowing you to write generic functions to handle all your converter types cleanly: def doStuffWithConvertable[A: Portable](a: A) = { implicitly[Portable[A]].toPFA(a) } If you want to be able to control your implicits in scope in tests (you should), define an apply that takes the conversions that you wish to use, and places them in your instance: def apply[A](conversion1: T =&gt; U): Portable[T] = new Portable[A]{ implicit def TtoU(T):U = conversion1(T) def toPFA(a: Class2): PortableFormatAnalytics = doTheStuffToConvertClass2 } } or new up instances on demand with test imports implicit portableInt: Portable[Int] = new Portable[A]{ import testImports.tToU def toPFA(a: Class2): PortableFormatAnalytics = doTheStuffToConvertClass2 } } 
I guess I'm just lucky, but I've had almost 0 problems with sbt when not cross compiling. Most application projects its name, scalaVersion, itSettings, org, releaseplugin, librarydependencies, assembly plugin, and maybe macro/simulucrum. Sometimes it's multi-project with the above. That's not difficult. What were you trying to do?
I've come to a similar conclusion that most type magic belongs with library authors. I.e. in my day to day code I don't often find the need to jump to crazy abstractions. The work isn't abstract/general enough.
does it work with external js libraries which change the dom? Or will these break it?
Agree with the other replies to this, if you have to ask, Scala is going to be very difficult for you to learn, but it's an example of a very good programming language. Go is not a good language (terrible type system, no type parameters), but it is an excellent runtime (very fast GC, real green threads, very good concurrency, very fast compile time, very fast runtime performance). You can learn both, which is going to be a challenge, but you'll learn a lot and learn to appreciate the differences of each.
How does Go have a terrible type system?
I hate it when tutorials don't match the latest versions. There's nothing that'll kill my enthusiasm for trying out a new language quicker than when the examples don't work. Thanks for doing this!
Check out this issue too: https://issues.scala-lang.org/plugins/servlet/mobile#issue/SI-8627
I don't know the details of those things. It just seems strange that you'd want to convert from a lot of different types to a single type. Maybe it's correct for your use case. My other piece of advice would be not to go overboard on implicits. That kind of conversion sounds like the kind of thing that would be very reasonably handled with an explicit conversion method. (Again I'd structure this parallel to the structure of the types - the converter for a top-level type calls converters for mid-level types which in turn call converters for low-level types).
Could you elaborate if possible?
I'm through the first two chapters and I'm thoroughly enjoying the book. Thanks!
I'll remove the videos -- they're out of date.
People use specific collections, sure. But people who have tried to write collections using the partial-implementation traits have, as far as I've seen, recommended others not to do that. Likewise people who have tried to leverage the `CanBuildFrom` infrastructure. It's extremely hard to design a language standard library at the best of times, and Scala use has come on a lot in the 6(?) years since 2.8. The collections library we have is not, I think, the one that anyone would write today. Parts of it are good, but *the structure and hierarchy specifically* is probably best regarded as an experiment with a negative result.
There are a number of inconsistencies like this one in the Scala collections, which were introduced in Scala 2.8. My understanding is that there is not much interest from the Scala maintainers in fixing this kind of issues at this point because there is a plan (starting with Scala 2.13) for a new collections library which will hopefully learns from the past. [Strawman proposals](https://github.com/lampepfl/dotty/issues/818) have been requested and there are a number of those out there already.
This might be of help: http://www.lihaoyi.com/post/MicrooptimizingyourScalacode.html Edit: In addition - http://www.lihaoyi.com/post/BenchmarkingScalaCollections.html
The examples work fine -- he was following the video tutorial, which we forgot to update. It's now been removed.
For most part `la.sliding(n)` would work. Just the edge cases seem messy. `GroupedIterator` that might help.
It was not meant literally. It was a tongue in cheek comment. The stdlibs collections are overall very useful, but it's hard to argue they aren't designed in a fairly convoluted manner.
Thanks, I think I understood what you said (there seems to be a lot of "if this, then that" when it comes to AnyVal). So is `AnyVal` even worth it? I've been using it, as I said, like I use `newtype` in Haskell (as a compile-time-only type) but given the (what I think) extensive list of cases where it just ends up behaving like a common class, should I not bother with them? Have I been misusing them?
You probably do not need to know *JavaScript* as a language. But you will soon discover that you will talk to JavaScript libraries at some point, and those libraries will have peculiarities that are JavaScript-specific. Say you're writing Scala/JVM. You don't need to know Java, but it's likely you'll use Java libraries at some point. To understand those libraries, you'll need to know about `null`, use-site variance, enums, and things like that, which you wouldn't necessarily learn if doing Scala only. Analogously, to be able to precisely understand how to correctly use JavaScript libraries, you will need to know *some* things about JavaScript. For example, the existence of `undefined`, or union types, etc.
Your development will be done in Scala, however, as sjrd mentioned, you will most likely want to use some existing JavaScript libraries. If there already exists a facade for it, good for you. However, when you want to create a new one or fix an existing one, understanding JavaScript is a pre.
FP in Scala : https://www.manning.com/books/functional-programming-in-scala Advanced FP in scala: https://gist.github.com/jdegoes/97459c0045f373f4eaf126998d8f65dc Typelevel blog : http://typelevel.org/blog/ Principle of least power: http://www.lihaoyi.com/post/StrategicScalaStylePrincipleofLeastPower.html The key thing is to: 1. Define applications as groups of pure functions as much as possible. Use typeclasses when you can't. 2. Restrict your types to be only as specific to what the function using them uses: def usesFuture(eventuallyInt: Future[Int])(implicit ec: ExecutionContext): Future[Int] = eventuallyInt.map(i =&gt; i + 1) The above only uses `map`. It doesn't use anything else from the `Future` interface, so `Future` isn't required. It ties you to using Future whenever you call it, which adds requirements to the function (that `ExecutionContext` implicit) in order to call it. Instead, use `Functor`, which is loosely the interface that defines map: def usesFunctor[F[_]: Functor](eventuallyInt: F[Int]):F[Int] = eventuallyInt.map(i =&gt; i + 1) This means that the function can take anything that has a functor instance (any collection type, `Option`, even `Function`). Why is this less power instead of more? My interpretation: when you call this function, you can only do Future-esque stuff with it if you passed a `Future` to it. It only gaurantees that you can get something back that you can call `map` on. It doesn't require that you pass an argument to it that needs more functionality than it uses. The body of that function is now more constrained, and less powerful. 3. Make your code as testable as possible without including mocked contextual information. A function can only act upon the arguments it receives. Don't do this: trait NotOk{ val x: Int def adder(y:Int): Int = x + y } object NotOkImpl extends NotOk{ override val x = 5 } Instead, do this: object Ok{ def adder(x: Int, y:Int): Int = x + y } Why? Because you can fully understand what adder does just by looking at the function itself, without looking at the rest of the class. This case is simple, but you can imagine an abstract def that calls another abstract def that calls another ad infinitum, all of which are instantiated when you do the Impl object and 'inject' everything. 4. Separate the logic (your pure functions) functions from your pipeline (io performing) functions. Don't do: def talkToTheDatabaseThenCallApiThenWriteFile(db: Database, api: Api, file: File) ... File.write(if(dbReturn.contains(5)){callApi(dbReturn)} else{ emptyApiResponse}) .... Instead, write stuff like this: def run(program: (argumentType) =&gt; File, argument: ArgumentType) .... def talkToDB(arg:argumentType): DbResult = ... def evaluateAndDefaultResult(result: DBResult): DBResult = ... def talkToApi(res: DBResult): ApiResult def evaluateAndDefaultApiResult(apiResult: ApiResult): ApiResult = ... def writeFile(apiResult:ApiResult):File = ... .... // in main val pipeline: (argumentType) =&gt; File = talkToDB _ andThen evaluateAndDefaultResult andThen talkToApi andThen evaluateAndDefaultApiResult andThen writeFile run(pipeline, mainArg) Why? because if you do that the cost of changing what one part of your program does is as simple as changing or inputting a different function in your pipeline, and understanding what it does is as simple as looking at the order of your pipeline. You'll end up writing curried functions to inject commonly used elements (Configuration values, database connections, api clients, etc), but it will stay clean. You probably don't want to have talkToDB made from fifty other composed functions, but you get the idea. This means that your code does nothing until you call it, and you only call it in one or two places, in main. You can probably compose into stages, etc, but you get the idea. The constrained types you use help you to line up your pipelines, and signify what a function possibly does by its signature. Is this constraining? Yep. But it keeps things organized and flexible. Interop with java or frameworks usually means you make a builder object that takes a pipeline that executes in the function of the instance that java calls into. The rest of your code stays clean. You'll pull your hair out less because who can't follow function calls? You'll write less test code, etc, you'll rely less on magic. Sometimes you will have situations where some inteface requires an unconstrained type. You almost always can get out of it with Traverse and Foldable. Cats and Scalaz are your friends. Read them, read the book, and use types.
Thank you, that was an inspiring read. Will take a look at that book.
I apologize. My goal wasn't to make you remove the videos but to supplement them. I personally felt it was a great tutorial!
I use Slick as my database interface. I use Slick codegen from SBT to auto generate all my table and row classes. I run it whenever I do a migration, and keep the generated file in source control. I adapted some code at http://bit.ly/1RxU2h9 to my needs. For migrations, I use Flyway, which is really easy. I made an SBT task that creates a blank migration file, so that my migrations are always lexically sorted in the correct order. I don't really like working with SBT. But it does the trick, and I only have to wrestle with it occasionally. I'm an IntelliJ user, and I think it's fantastic, and it's constantly improving.
I start up IntelliJ IDEA, and go to the project in iTerm 2 and start up SBT from the command line. I never rely on IntelliJ to do any build tasks, and always type it in. Database Migration is sbt-flyways. I believe you can do database fixtures with it as well, by running a Flyway JdbcMigration with your seed data. Docker integration is sbt-native-packager. Elasticsearch index creation / ingestion I don't know about. Microservice architecture, it depends on what you mean. If you want a REST API with JSON and a database built in, then you probably want [Play with Slick](https://github.com/playframework/play-isolated-slick) -- it has everything packaged for you and you can download it as an [example project](https://playframework.com/download). (Disclaimer: I am on the Play team.) If you want microservices in the sense of "it never goes down and doesn't have to have strict consistency", then I'd look at [Lagom](http://www.lagomframework.com/) which is an "industrialized" Play with Akka Cluster backed by Cassandra, using CQRS and event sourcing, and with service locators for talking to other microservices, etc.
EBS could be your friend here.
I spend 3 hrs setting up my project structure, gradle, jdk, sdk, etc. and then realise I could have finished this project in the same time if I chose just about any other language. Then I start again in that language.
I am using Emacs with Ensime support using scala layer in [spacemacs](http://spacemacs.org). I only miss Intellij evaluate expressions feature in debug mode.
And then repeat the cycle for couple times and realize mistake is on your side, and pursue other career, right?
I'd start with changing type of first parameter to `List` - that way you wouldn't have to call `toList` and `mkString` so often. Then I'd consider different approach to reading ngrams: * read first ngram by reading n chars from string, * construct next ngram by removing first char from previous ngram and appending next char from input string. Switching from recursion to regular vars and while loop may be also beneficial even though less scala-ish.
http://demo.akkapaint.org/
This is one of the main questions I have had since I started looking into Scala and Play more. In Symfony doing quick common tasks with the CLI is so easy. This extends to far more than just the ones you've mentioned there. Bundles provide their own commands too, and you can write your own. Maybe you want to make one to do things like create a user, or clear the application cache, print out some debugging information, etc. The only suggestion I've had for this kind of thing is to provide some kind of management API, you could then just call endpoints that perform these tasks for you. If you wanted to, you could even build a CLI app with another language (like Go, or maybe even PHP) to call these endpoints for you. Coming from Symfony, this is the biggest missing piece of the puzzle, and something I _really_ miss.
You will find out in process :)
Nah, I'm pretty successful and have a fulfilling career :) Scala has far too much overhead. If you want to go functional, probably Scala is not the best choice. Anything you get out of the syntax you're going to lose in bloat. 
Oh, I honestly did not expect normal response. Sorry for being dick on my side, I thought you're just troll. I agree Scala has much overhead - but personally my brain has learned to parse/ignore it. But yes, it is cognitive overhead :(
Thx for the links. I already watched the talk of /u/tpolecat. This is why I asked the question, because I think the things done in your linked blog post have been probably done already in a more generic way. The blog post is very nice though!
Don't get it... Could you provide some link?
[Elastic Beanstalk](https://aws.amazon.com/elasticbeanstalk/) it's great for low traffic but high compute intensity sites like this because you only pay for the cycles you use.
That is sbt-server, aka sbt-next. It's not out yet.
&gt; I've tried looking it up, but can't find much. Do you have any other information about it, or how it might solve those problems? Eugene's post is the canonical source: http://eed3si9n.com/sbt-server-reboot 
and your cpu executes assembler, so there's no escape from assembler!
I use Flyway for migrations. I run sbt in a container attached to a docker composed network, which gives me a sandbox of things like Consul, Kafka, MySQL, etc.
I hadn't thought of running SBT inside a container. Interesting idea!
Here's the image I created: https://hub.docker.com/r/jimschubert/sbt-scala/
Totally depends on language, framework and build tool. In Java I mostly develop test driven in the IDE and run only the tests of one class or package. When I think I'm finished I run all tests in the IDE an finally build and run the whole project in the console and test it manually. In scala, especially with Play, I switch between continuously running tests and the application in SBT in the console. SBT is not easy to configure, but super easy to use and I don't see how the IDE could make that even easier.
Well WebAssembly and asm.js are a thing now.
Can you please link to which "Firebase Java SDK" you're using? Also, the definition of your `User` and the `Decode` instance Finch needs for it would be helpful. I suspect that the answer to your question is: import beans.BeanProperty then annotate each field of `User` with `@BeanProperty`, then replace: val userSnapshot = snapshot.getValue() with: val userSnapshot = snapshot.getValue(classOf[User]) but I can't prove it yet without more information. **Update:** Your comment says `User` is a `case class`. You'll almost certainly need to make it a plain `class` with `var`s and the `@BeanProperty` annotations on them. That is, you need a `class` with a nullary constructor and getters and setters for the fields for the `.getValue(classOf[User])` API to work. This will almost certainly affect your `body.as[User]`, too, likely forcing you to write a custom `Decode` for it.
Im on a same boat as you. In my perspective, dynamic typings gives you ability to "not-solve-some-problems-right-away". It gives you ability to change quickly code without needing to fix structure on all other places. So shipping fast. Sure, the software is broken more than it's not, but then it must not be their priority. I don't see it as benefit (unknowingly introducing bugs to get that 1 feature running), but some do I guess.
How does lift compare to play?
It would be more useful if you could give some reasons to why it sucks?
The creator of Lift answered a similar question - http://stackoverflow.com/a/12428316/409976.
Is the framework bad or is the person bad?
Does every single stackoverflow question have to be closed?
OK, that gets the errors down to: 1. could not find implicit value for parameter decoder: io.finch.Decode[fb.User] 2. not enough arguments for method as: (implicit decoder: io.finch.Decode[fb.User], implicit tag: scala.reflect.ClassTag[fb.User])io.finch.Endpoint[fb.User]. Unspecified value parameters decoder, tag. 3. not found: value Firebase `Firebase` is presumably a `FirebaseDatabase` that you've constructed. The other errors are because there must be an `io.Finch.Decode[User]` implicitly in scope for your code to compile. If you could provide those, I can test my theory that `User` just needs to become a JavaBean so you can use `.getValue(classOf[User])` on it, which will also necessitate revising/replacing the `io.Finch.Decode[User]` instance.
When will there be a ScalaJS example project using Dotty? ([like this one](https://github.com/smarter/dotty-example-project)) I would try to implement it myself, but right now even the sjsSandbox in Dotty itself is broken: https://github.com/lampepfl/dotty/issues/1574
Disclaimer: Playframework Contributor. This post is super biased. I mean he talks about security and how important it is to bake it into the framework. Unfortunate he later talks about CSRF. Actually I don't need CSRF at all, CSRF only applies to authentication via Cookies. Well I might be a little bit biased as well. Well the real reason I didn't used Lift (before I started working with Play at all), was that lift looks really tied to the view portion of a web app and I dislike this idea to have a web framework focus on that part. Also I somehow prefer the way Play! is, while coming from a Django background. I mean my company relies heavily of SPA (perfect fit for internal clients), while we need to actually rely heavily on postgres and it's feature's (so no ORM at some queries) were we need a framework that lets us to do all the things. Edit: TL;DR his post reads like lift is the holy grail of web frameworks, which it isn't neiter is play
It's a Category of Categories and Functors. Where the one object in our Category of Categories is the Category of Types and Functions.
Sure, if we take a subcateogry of Cat with one object that is Scala types (with morphisms as functions), and arrows pointing back to itself (endofunctors from ScalaTypes to ScalaTypes) it looks like a monoid. But it's not the 'endofunctor' category, right? 
The endofunctor is the arrow in the Category of Categories and Functors., it's not a category itself.
Yeah, I'm with you. So it's a bit inaccurate to say "*in* the category of Endofunctors". The category of Endofunctors would be Func(Scalatypes, ScalaTypes) and there'd be a lot of objects in there. 
I'm just learning Scala, and have been trying to understand monads (and functors and so on). From a practical, rather than theoretical point of view, what do they get you? I'm making sense of higher order types and I can see that they're an additional layer of abstraction where you can write code, but do the properties like associativity have any practical effects? Does the compiler know about these properties and use them to generate more efficient code? Apologies for the off-topic question, but this is a question I needed to ask somewhere and it would have been worse in another thread :-).
I'm in the same boat. I've done a bit of work in Scala despite knowing nothing about category theory. I like the type system and I use it as best I can to reduce bugs. But despite having no background in this (electrical engineer), I do want to understand this stuff and articles like this don't really help that much. What people like us really need is the practical version of the theory that relates it to common examples. I think the book Functional Programming in Scala gets a lot of this right, but I still come away being confused whenever we dive deep into the "monads are just a category of monoids..."
At the beginning of this article I link to another one I wrote which might be what you are looking for
I looked at that one, thank you. It's the sort of stuff I've been reading for a few days. I've also read Functional Programming in Scala. What I need to know next is what I actually get if I can code something as a monad. If I train myself to think about programs in this higher order way, what cool things happen for me? It's entirely possible this is something nobody has the energy to think about after they've grokked all the category theory stuff :-).
Of course, for just some examples out of hundreds you can check this papers: * https://hal.archives-ouvertes.fr/hal-01118918/document * https://hal.inria.fr/hal-01099220/document * https://arxiv.org/pdf/1506.04182v1.pdf * http://jasss.soc.surrey.ac.uk/18/4/9.html We use it for very large scale experiments (understands millions of jobs) on very unreliable environment (understand a world wide computing grid, EGI) since several years. This software has been many time battle tested.
This is very interesting. Are there any potential security concerns around allowing random internet strangers to join your cluster?
`for`/`yield` doesn't check if you're working with a monad in any theoretical sense, it just desugars to `flatMap`, `map`, and `withFilter`. You'd write your implementations of those functions to be monadic, but there are definitely counterexamples (wish I could remember one for you offhand).
Good question.... For RnD, there might be some, for production not so much yet. We are in the process of working with a small french companie that might intergrate OpenMOLE in production. Also we plan to fond a startup in the comming years to monetarize this software.
If you want to try this software without installing it, you might go here: http://demo.openmole.org. Then you can click on the little cart to install example. It is a very raw first version of the OpenMOLE demo, it is wiped out and reset every 2 hours and it has not been designed to support multi-user but it can give you an idea of how it works.
It's worth saying that if you write `for`/`yield` with types that do not conform to the monad laws, you will get some unpleasant suprises. E.g. what would you expect `x` to be here? val x = (for { x &lt;- List({}, {}, {}) y &lt;- Set({}) z &lt;- List({}, {}) } yield {}).length
I work with maven and eclipse, contrary to most of the community here, but it works very well for me. In my current position I'm less involved with deployment etc., but previously what I did was: * Index creation etc: If there's a maven plugin I'll use that, otherwise I'll make a submodule with an executable that does it (just an `object` with a `main()` method). If it only ever needs to run from trunk then I'll make a jenkins job to do that, but usually I end up just building an executable jar as part of the release process, deploying as part of deployment, and launching it via rundeck. Running it locally is either right-clicking in eclipse or using a command-line like `mvn exec:java -pl :indexcreator` * Database migrations: I use liquibase via the maven liquibase plugin - this one I've left in jenkins so far (with maven profiles for stag/prod/dev or blue/green/dev), though again no reason it couldn't become a normal executable released as part of the normal process. Again, running locally is a maven invocation from eclipse (via right clicking on the project) or the command line. I autogenerate migrations (locally) based on my hibernate-annotated entities using `mvn liquibase:diff`. * I don't know what you mean by "database fixtures". If you're talking about setting up in-memory databases etc. for tests, I just invoke liquibase in code with my real changelog; to insert test data I just use my normal code for inserting data. For the production databases I have a philosophical objection to putting "static" data in the database; IMO the production system should run correctly on an empty set of database tables, if some data is "hardcoded" (even if it changes from release to release) then I'd prefer to just have it in code * I haven't used docker (most of the advice I've seen is to make limited use of it where it doesn't really do anything other than run a process (i.e. no funky networking etc.), but I already use the maven shade plugin to create executable jars that can be run with just `java -jar ...`, so I don't see what value docker is supposed to give me). I run a manually-triggered release on jenkins using the maven release plugin (it's tempting to have it automatically triggered on any commit to master) which uploads the release to nexus, and the release triggers a deploy to either an integration-testing instance or to current-staging. Actual deployment just consists of https fetching the jar from nexus with particular credentials, which pretty much anything can do; I've variously used rundeck, puppet, fabric, heroku, and in one job a slightly different approach of having the release build a `.deb` (which included a short script to launch the application and a service configuration so that it would be a boot-started service). There are probably newer approaches, and I'm not an expert on this side of things, but it doesn't matter much because nothing here is particularly coupled: jenkins can trigger just about anything, and just about anything can get you a machine with a JVM installed, https fetch a jar and invoke it via `java -jar`. This ends up being quite a few pieces but it's evolved that way organically. In the very early days you can do everything with local maven (and your prod machines can just have a git checkout and do `mvn exec:java` to run the executable), then you can do releases but still with local maven, then you can introduce jenkins and it can do everything to start with (e.g. it can run your deployment commands rather than separating that into rundeck, you can use its artifact archiving capability rather than nexus) and you can gradually separate out pieces as you need to to keep your builds simple and maintainable.
Looks pretty good. A few minor concerns: Categories are not sets in the usual mathematical sense of the word "set". This is tedious but important. The second half feels a bit too informal for something that's all about formalisms. I've seen any number of posts that sketch out the monads-are-monoids equivalence (I've even written a draft of one myself), but if the definitions are really about the laws then the post should really have a proof of the laws (in both directions, so as to demonstrate equivalence). There are a couple of cases of slightly awkward English phrasing, particularly missing pronouns (e.g. "associativity law is" rather than "*the* associativity law is"). Nothing that's outright confusing, but enough to be noticeable.
In this configuration, I am basically giving an access to my cassandra database - it is not secure. I am not hosting there anything important though (It was created for education purpose). Also there is a performance problem - if shards are in different part of the world, sending data through the Internet is slow (so some shards (in akkapaint - rows) are loaded faster then others) and shard rebalancing can take a while. All nodes should be in one local network with the fast connection between them (again, in akkapaint it was all done for science :))
&gt; Do I only get the ability to use for / yield if the thing I'm using it on is a Monad? Yes. Another name for "for-comprehension" is "monad-comprehension." &gt; In the ScalaDoc, I note that Semigroup must satisfy associativity. I have no idea whether that's enforced by the language or it's just a forlorn hope. The trait defines the associative member, but I have no idea what that does at all. Yeah, the laws can't be enforced by Scala's type system. So if you implement, say, your own `Monoid` instance, but aren't so sure about your operator's associativity, you may want to take advantage of the [ScalaCheck bindings](http://eed3si9n.com/learning-scalaz/Functor+Laws.html) to test that the relevant laws hold. One benefit of constructing `Free` monads is that they're guaranteed to be monads, and if you interpret them into, say, `Task`, `Task` is tested by the scalaz team to ensure the `Monad` laws hold. So you already have that confidence.
Yes indeed, it is about a fw and not a person. Ref shadowfriend, i did not know the maintainership was passed on. I must admit that encounter has put me off and i have not looked at it much afterwards (i don't want to go into the details of what the discussion was about, but it had to do with some of the strategy of web/rest applications. His reaction (or lack thereof gave me little confidence). I will check where things are going and perhaps have another look. However most of my needs are now fulfilled by akka-http*) *) i know might be apples/oranges.
I think http://www.lihaoyi.com/hands-on-scala-js/ does not assume much of a JS background.
If you are finding yourself creating lots of similar methods within each controller, you may want to abstract out the core functions into an object and take a higher order function to do the inner work. If you can give an example of these boilerplates, I can help to understand the abstraction.
Scala in general takes more time to grasp, because it is also a functional language. The functional-programming style is very different from imperative style languages, such as java or many common programming languages used today. And although scala does allow both imperative and functional style programming, the full benefits of scala come from its functional part. Me personally, I usually like to read books about a new programming language I want to learn, because it also gives you great insight into the language. I have found Martin Odersky's Programming in Scala a big help. He's also the one who created Scala, so he gives a lot of insight about the language. But most importantly, don't give up. Keep trying, keep learning, and keep growing. Scala may seem intimidating compared to java, but after some time and practice you will get the hang of it. It just takes time.
&gt; the controllers all make a similar call to a service, the service name and method can be derived from the controller name That seems your controllers have something in common and should not be just "controllers" but have more sphisticated types. Please don't use naming for something like this! You can leverage the power of the scala typesystem to help you avoiding mistakes. Can you give some very simple (pseudo-scala-code like) example of the different types and names we are talking about and how they work together? Then we will try to figure out how your requirements can be modeled without relying (only) on naming but additionally by using the typesystem. 
So we have a total of around 50 apis to create- all with separate inputs, and different json outputs. The services serve to allow dependency injection, mostly, as literally just a step through from controller to connector. I.e getNames(age:int) in the controller, first some validation on the input, then it's passed into a model that's sent to the service, the service uses its implementation of its respective connector to contact an external service. The response from this service is mapped into a second model (two models per api, request/response) sent back through the service and delivered to the user from the controller. The example is very off, but it's to that kind of level - each call to an external service is entirely independent, and has to be constructed individually. Essentially it's an interface for that existing system spoken to by the connectors, although it replaces the input output types from xml to json I'm not sure the scala type system can quite sort this - each controller is for its own URL from the routes file, and has to form something unique, as well as authorisation levels may place restrictions on the user as to which apis can be called
Hi, I am getting the Scala adapter to the Fly Objectspace to compile under 2.12. See https://github.com/fly-object-space/fly-scala Fly is an Object Space server that is specifically written to provide lightweight object based messaging between computers running on a network. The server is written in C with binaries for Linux, OSX, Windows and Solaris, and a Java client.
"We gloss over the mutabile/immutable distinction" 🤔
&gt; However, compilation times + file size became an unavoidable concern in my experience writing a medium sized app with Binding.scala. The comparison is not fair, considering Binding.scala provides far more features than monadic-html. Binding.scala's compilation is very fast if you use Binding.scala with Scalaz's syntax instead of `@dom` syntax or `Binding` block. Slower compilation is just the cost of the power of `@dom` syntax. Also, Binding.scala's file size is very small if you don't need to incrementally update partial DOM. Some Binding.scala users did write the naive data-binding code that always updates entire DOM like https://gitter.im/ThoughtWorksInc/Binding.scala?at=581b6367eed0c3125f30d57b However, I suggest you use `@dom` instead of Scalaz's syntax for most cases. Unlike monadic-html, which always updates entire page, `@dom` generates sophisticated code in order to update the minimal part of DOM corresponding to the change on source data.
You are right, Binding.scala has more features. I still think Binding.scala is the best choice if you must have HTML syntax + strong type-safety + low-boilerplate `.bind` syntax. Also, `Vars` offer an efficient way to handle reactive mutable sequences, which is a super common use-case. Monadic-html does not have a `Vars` abstraction. To improve performance, we're investigating a virtual-dom/precise-binding hybrid approach instead using pure Scala.js. I admit I have not tried Binding.scala without `.bind` or `@dom` syntax. All the examples in the docs (last time I checked) use `@dom` and `.bind`. In the end, we're debating different trade-offs. The main objective with monadic-html is to support fast incremental compilation without compromising on the XHTML syntax (clearly stated in [readme](https://github.com/OlivierBlanvillain/monadic-html)). In my quick (maybe naive) benchmarks, monadic-html also pays significantly fewer bytes per line of XHTML (modulo initial size of scala-xml) compared to Binding.scala's `@dom` syntax. We're still in really early days of UI libraries for Scala.js. Binding.scala has definitely pushed the frontier and monadic-html learned a lot from Binding.scala. I hope we can continue to innovate in this area. BTW. I'm not the author of monadic-html, Olivier did all the work behind the implementation. We work at the same place and occasionally discuss these things over lunch breaks.
&gt; Unlike monadic-html, which always updates entire page This is incorrect. We need to update the readme to clear up this (very important) point. If you look at [this part of the implementation of the mount function](https://github.com/OlivierBlanvillain/monadic-html/blob/master/monadic-html/src/main/scala/mhtml/mount.scala#L20-L35), you see it actually attaches callbacks `Rx`s, such that when their values are updates, the `mountNode` is only executed for what's further down the tree. Which means that in the following example: val a = Var("1") val b = Var("1") val c = Var("1") val view = &lt;div id={a}&gt; Two variables, {b} and {c}! &lt;/div&gt; Changing `a`, `b` or `c` will result in the minimal DOM update, which should be the same that Binding.scala is able to provide using the `@dom` macro, and React manages to compute using virtual DOM. ...but we don't support sequences at the moment. As /u/olafurpg said we plan to implement some *targeted* virtual DOM on top of the correct approach to get the best of both world :) 
Sounds like something that could perfectly well be done generically, though I don't know Play well enough to know whether it's possible in Play. For each API you need what, a type (nested case classes or records), a (possibly automatically derived?) XML format and JSON format, an authorization level, an input URL and an output URL? One can certainly write a function that takes those things and forms a suitable route - I could write one in Spray/akka-http, though I don't know how helpful that will be to you.
But the current structure of the project is about the separation of concerns and apis, using a controller per lets retain control over each individually 
Love it! Will use it
Thanks! If you have issues/feedback feel free to open an issue on GH.
The common bits are more the structures, the names of methods etc. I'm hoping for templates to just run it and fill in the functionality 
See also: https://github.com/LPTK/Boilerless
Very cool (I missed this when looking around for ready-made options). I think the difference here is that I'm only trying to support the basic (but frequent) case of `case object`s used to encode java-like enums with minimal complexity and footprint, while Boilerless is more comprehensive.
Thanks! We are looking to do monthly releases going forward.
Thanks for the correction. Will make that fix along with a few other fixes/changes to the site content. The site will also have links to gitter, a google plus community and some videos going forward.
How big is the team?
&gt;Scala Meta. Another major plugin improvement is support for scala.meta. IntelliJ IDEA supports new-style macro annotations and provides coding assistance for scala.meta quasiquotes. Does this mean that we get autocompletion from expanded macros without having to [re-implement the macro](https://blog.jetbrains.com/scala/2015/10/14/intellij-api-to-build-scala-macros-support/) ? [EDIT] It actually works!! Although the IDE froze a couple times, and forced me to restart it, it's very promising. The IDE offers autocompletion of whatever gets generated by macro annotations ! Hurrah ! I'm not sure how I feel about the expand feature. It's really cool, but I thought it was gonna a read-only expansion allowing to visualise the behavior of the macro. Instead, it basically rewrites the annotated AST. ctrl-Z works though. I guess it's really gonna help people avoid freaking out when they see macros being called. Cool stuff :) 
not sure if this answers your question, but in this talk it was previewed: https://www.youtube.com/watch?v=-l7pV0sFq1c He's expanding the macro directly inside the editor, so I'm pretty sure that you also get autocompletion for it
I meant about this `construct next ngram by removing first char from previous ngram and appending next char from input string.` 
I would hope that they would go with something similar to https://gist.github.com/djspiewak/2ae2570c8856037a7738 It would make making your own collection types easy. Till then it's Scalaz or Cats if you want to implement your own collection types, as the inheritance heirarchy keeps getting in the way in the current collections library, which Zeiger's sticks with.
No, sadly, since scala.meta != macros (afaik scala.meta only works on the JVM now, so no scala Js), and regular scala macros don't work yet... (and their language API for the plugin is horrible)
A small remark on platforms supported by scala.meta. While it's true that there's no Scala.js version of scala.meta, that's not a problem for macros. The thing is that macros expand inside the Scala compiler, and the Scala compiler runs on the JVM - both when compiling into the JVM bytecode and when compiling into JavaScript.
W2 or C2C?
I haven't, but FWIW- garbage collection time is bounded by the size of the live set, not the amount of garbage. Analysis into the kind of fragmentation patterns beyond that trivial observation are inherently specific to the given application.
Has that proposal been realized into a library?
A factor of 10 is about what I'd expect by switching from reflection non-reflection code, so that sounds like a plausible explanation.
Is there any work towards making the Scala compiler self-hosting on Scala.js and Scala Native? I hate having to run a non-JVM tool as part of a build process, and I can't imagine JS-based people are any more enthusiastic about having to spin up a JVM to build their javascript.
If I remember correctly they use [offheap buffers](https://mechanical-sympathy.blogspot.be/2012/10/compact-off-heap-structurestuples-in.html).
The "expand macro" feature is incredibly handy when debugging macro bugs. Line numbers in stack traces reference the expanded code. Also, I've used "expand macro" to manually fix a bug in the expanded code, run tests against the manual fix and then solve the problem generically within the macro.
2.12 support should be coming soon, https://github.com/scalameta/scalameta/pull/553 was merged 9 hours ago.
Nice ! Now we just have to cross our fingers for SBT to upgrade to 2.11 in a nearish future. It's sad to see such great effort on scalameta indirectly undermined by the slow progress of the build tool ... EDIT : no offense to the SBT maintainers, I really appreciate the effort being made there too 
I would love to see SBT upgrade to 2.11, fingers crossed indeed :)
That's great news, my knowledge may be out of date. Whelp, time to rewrite my macros in scala.meta then.
["I got 99 problems, so I used code generation. Now I have 100 problems."](http://xkcd.com/1171/)
No sophisticated reasoning - just a number I've seen thrown around, and it seems to align fairly well with my experiences of replacing reflection with non-reflection.
What would they hate more: spin up a JVM, or get a compiler that even 3x slower than the already slow normal Scala compiler? We've done some work on self-hosting Scala.js, but there's little practical use on the horizon, so we're not pushing much in that direction.
Very instructive. Thanks.
And also: https://github.com/lloydmeta/enumeratum This one integrates with Circe's generic derivation for JSON support and much more.
Something that we call semantic API, i.e. the ability to resolve names, calculate types, etc - everything that requires typechecking. As a result, the only supported flavor of new-style macros is macro annotations. Def macros require semantic APIs and, as a result, are impossible to write with the current version of scala.meta.
scala.js is moving into the exactly opposite direction, the idea would be that you don't need any js build tools in the future (which in my opinion is the better direction, but I guess everyone can have a different opinion on this)
In my macro annotations i user type parameters and arguments, would that be affected by the fact that scala.meta can't resolve names and calculate types? I pretty much use it to get a case class, and list it's members with their types and create derived case classes.
AFAIK it's only for Java. A Scala plugin update might be needed.
&gt; But given that functional programming virtually eliminates bugs People have some weird ideas about functional programming. Properly following immutability and functional programming principles does eliminate some classes of bugs but it does insert its own ones. And still doesn't protect you from the hardest bugs which are bugs in the actual logic not a bug in implementing the logic or writing it down.
Is totality checking possible? My gut intuition tells me that it's not possible in general.
If you use c.typecheck, then you won't be able to express your macro annotations using scala.meta. Otherwise, you most likely will. If you can share your code, I can take a look and provide a precise answer.
That's true in the general case. For example, even Idris' totality checker is conservative. In Scala, it's really a matter of coming up with a general means of catching non-fatal exceptions and lifting them into some monadic context. For example, scalaz offers a `Catchable` typeclass that all monads I know of implement, so constructions in that monadic context are total (e.g. `Task.delay(x)` returns a `Task` even if `x` throws). But this doesn't sidestep your point: _I_ know it's total; the compiler doesn't. If I were really ambitious, I might use Isabelle to prove it.
performance is way worse for me, anyone else has the same problem?
It's not only for Java. C Code and JavaScript works as well. It needs to be activated tough. But Scala still does not work :(
Sure, thank you. This is the concerning part: http://pastebin.com/9p2gX1BY But i don't think it matters much, i have a lot of def macros that work in conjunction with these macros, so i'll have to wait for it to be implemented.
See this one: https://circe.github.io/circe/
"DecodingFailure(Attempt to decode value on failed cursor, List(El(DownField(f1),false,false)))". Can't say I can show that to API users. decodes null to None, ignores unknown fields. From first look, I can't find how to customize that Decoding null to None can be fixed by copy-pasting existing implicit conversion and modifying it a bit. Can't find how this library deals with case classes at all. How to configure policy for missing fields? Anyway. I need clear error messages and not that HList.toString
Have you looked at Play-Json? It offers a lot of what you're asking, except Option handling is not to your specification, but I'm pretty sure it is easy to write your own formatter. 
I do not want to parse json AST to case classes manually, nice DSL is nice but not really helpful. Also, isn't Play-Json missing functionality on detecting excess fields in json object?
If you already use VIM then the setup time isn't that complex. * Add an SBT plugin to your global .sbt * Install the vim plugin * run `sbt ensimeConfig` in your project * Inside vim, run the command `:EnInstall` Now try it out. `:EnType` will tell you what type it is, `:EnDeclaration` will take you to the declaration of the variable or function. The EnType from what I've done is accurate. Going to declaration is great and works for open source projects at well. I'm able to go into twitters finagle and scala's collections for example. I will say that I keep IntelliJ ok hand too for a few things here and there. If you make the jump to ENSIME you'll basically trade one set of frustrations for another. But I love working in VIM and ENSIME is great for what it is. Edit: Formatting
To be honest I haven't exactly checked all your requirements, but http://argonaut.io should cover most (if not all) of them. There are many ways to use it, for example conversion to and from case classes can be done effortlessly using shapeless, but you can also customize how your classes are encoded.
It has macro functionality to create mappings, all you'd have to do is tailor certain parsings such as Option(null) into Some(null). As for detecting excess fields, no I don't think it supports that out of the box. 
I see what you mean, ensime has real drawbacks. But for some reason just scrolling in Intellij ramps up the cores to 60%. Not sure what I'm going to do. btw. ensime works in neovim (I just used it)
I'm the maintainer of ensime and I'd recommend that you read our documentation before trying out ensime, to understand our philosophy. Ensime is not designed to be, nor does it intend to be, another IDE. To use ensime effectively you must be kind of person who loves to hack your system. If you care about indexing time, ensime can give you the power and freedom to make it as fast as possible. But be aware that nobody is going to fix your bug reports or implement the features you request, but we will help you to do it instead. That is the fundamental difference. We empower, we do not support. I personally find that I am far more productive in ensime that I ever was in IntelliJ, and there are less errors. And when there are problems, I stand a chance of fixing them myself. Most people who complain about ensime are the kind of person for whom ensime is not designed, so ask yourself if you want to hack your editor to give you an advantage or if you want to use the same as everybody else. 
It *can* fail on excess fields if you write a custom decoder, but doesn't by default since that's the opposite of what most people want since it makes it more difficult to extend an API. The error object you posted is can be operated on programmatically to potentially recover from a failure rather than something you'd put up on a UI directly. On the other hand, all the info you'd need should be captured in the object's toString representation. It's there anything in particular that isn't clear?
Did you send any fully reproducible bug reports or PRs to fix the problems you were seeing? ensime is not backed by a corporate entity and exists only because of passionate contributors. Nobody is putting a user journey story board together, only issues that personally affect the contributors are addressed. It is very liberating.
If you think it can be improved, we'd be happy to help you improve it.
&gt; I got tired of atom's resource management. Personally I've found Atom way to under powered. Sure, it's written in JS and running on Chromium, which is cute, but opening a large Java/Scala project in the editor just led to repeated failures as it couldn't keep up. That was last year, perhaps they've made major improvements since.
Maybe you can do something with https://gist.github.com/reactormonk/35de0c3d6c7c429617131213b62dc92a &gt; it can be configured to return failure if input json contains fields not present in case class (required for parsing requests at server) You should be able to do that with some work on https://github.com/alexarchambault/argonaut-shapeless/blob/master/core/src/main/scala/argonaut/derive/MkEncodeJson.scala#L88 - you'll want to return a tuple of the encoder and the name of the field, so you can later check if there aren't too many fields in there.
&gt; Did you send any fully reproducible bug reports or PRs to fix the problems you were seeing? Yes, mostly it was either ignored or I was told to implement it myself. &gt; It is very liberating. Not really, since I don't like neither python2 nor coffeescript... If you develop a plugin then do it or not. Implementing it halfway is the worst. Btw, it'd be nice if the ensime api would be more documented for plugin developers.
I've been using it for Java and Scala and haven't noticed any significant slowdowns. Performance of what exactly? Compiling? Editing?
Great to hear! The Vim team did a great job of getting core functionality in place and you probably came along at a time where feedback was very important for core stability. But we need more contributors to bring it to the next level! Would you be interested in implementing the feature that you want the most?
&gt; That is because nobody is going to implement it for you. You must do it. If you don't want it this way, then ensime is not for you. The problem is that creating not working software isn't a successful software development method. &gt; The API is exceptionally well documented with docs, tests and examples. Can you truly say this after reading the contributor documentation, watching the conference videos, and reading the api and tests? Wow, I thought the "contributing" section was unrelated... My bad, if I'll need ensime I'll start with that, thanks!
It can generate the parsers/serialisers for you through a macro: `Json.format[YourCaseClass]: Format[YourCaseClass]`. By default it parses a `null` as `None`. You can overwrite this behavior by providing your own implcit `Reads[Option[T]]`and not importing the default one. I would argue that you are incorrectly designing your API if you need this, at the very least you shouldn't use `Some(null)` but rather make a `Some(value)|Missing|Null` ADT. It doesn't check for superfluous fields. You'll need to write a macro for that or use reflection. You can create your own `Format` which uses the default case class format and reads the JSON as a map to implement this check. 
&gt; We are the latter, and we are all about liberty... Well, I would call it "lazyness" instead of "liberty". But I've never met with such a dev model... &gt; not giving people something for nothing. If you want something in exchange then change the license and ask for something in it.
Your suggestions are exactly my thoughts! Lovely write up. 
Whoops, I initially read that as 'made easy problems hard' ... Freudian thought-slip?
Every situation is different, of course, but having a consumer of a data format ignore new fields is fairly standard. Imagine that you want to upgrade the data format so that the client can send a new field over. If you have a consumer reject messages with unknown fields, then you have to guarantee that the data producer and consumer upgrade at the exact same time or else they can't talk to each other, usually meaning there will be some down time while you wait for depots to finish or connections to be rebalanced. If the consumer can ignore fields it doesn't need, then the producer can be upgraded first and then the consumer without downtime. Providing good error messages for your REST API is a great idea, but expecting the library to provide that directly is not reasonable. The audiences are different. The library is producing errors intended for you as the developer with exposure to the inner workings of the code. It's a reasonable expectation to have you use that to format a response to your audience based on that. A library can't know, for example, if you want a localized version of the error for your audience.
Definitely not for me, I guess.
Switch between Neovim and MacVim
https://en.wikipedia.org/wiki/Robustness_principle "Criticism" section sums it up nicely. Doing contract testing in large, old system is quite hard to achieve - much harder than finding well-behaving json parser. It is easier to not to break than to fix, isn't it?
Can also used play-json-extensions https://github.com/xdotai/play-json-extensions. It provides macros to use case class &gt;22 fields (it happens), provides defaults values (from case class def) and some more tricks.
Imagine you have an API which takes a JSON object with a single field called "foo". Now you want to add a new field called "bar". Scenario 1: * The consumer is updated first. =&gt; Requests not containing "bar" are rejected. Since no clients have been updated, the service is non functional. * Producer is updated to include "bar". =&gt; Service is available again. Scenario 2: * Producer is updated to include "bar" =&gt; Consumer ignores the new "bar" field, but since it wasn't updated it wasn't using it anyway. * Consumer is updated to include "bar" =&gt; field is recognized and passed to new functionality which uses it. Scenario 1 requires downtime, scenario 2 does not. If you want to remove a field, then it's the same process in reverse, where you update the consumer to ignore a field and then update the producer to stop sending it, otherwise you'll have a period where the service is nonfunctional. There *are* ways around that, but with their own caveats: 1. you can only add optional fields to the schema and consumers ignore any fields they receive that they don't need. With this scheme the producer and consumer can be on different versions of the schema long term without interruption of functionality. * Mostly seen with tech where there is an explicit schema which can be versioned, shared, and encode default values for missing data, like Protobuf or Avro, less common with JSON. * Once fields are added to the schema they are not removed, though a producer may decide to not send it. Instead old consumers rely on the specified defaults. 2. If you want to add a new required field, or a new optional fields that drastically changes the meaning of the message, you create a new endpoint on the consumer and deprecate the old one. Depending on the lifecycle of the producers and how quickly the schema is changing, though, this can lead to very rapid churn through endpoints, and each one will likely have a lot of code duplication. &gt; Also, imagine server accepts some optional field "field". If client mistypes it, e.g. "feild", server will happily accept such request. Correct. This is a tradeoff of using an extensible data format, which most are these days. On the other hand, if your building an API then expected user is a computer rather than a human so it's reasonable to expect that the requests will be consistent rather than open to one off human error. I feel your pain on that one though; I like my programmatic to programmatic interactions to be as strict as possible since there's usually only a few ways that things can be right and essentially infinite that they can be wrong. It's one of the reasons to use a strongly typed language like Scala in the first place after all. But there's a very big difference between what is reasonable when defining a library API where it's good to make it nonfunctional/stop compiling if there's a misuse vs a remote API which necessitates some leniency to ensure no downtime.
&gt; I use ensime emacs and beyond type search hanging a lot when working on macro heavy files, I don't have any problems with it. See? The problem is that it only works in emacs - if the installation succeeds. &gt; Completion and implicit identification works better than intellij, and error checking as well. That's where I need to disagree - the presentation compiler isn't as good as intellij in handling code completion, refactoring and error checking. Well, refactoring is surely less powerful and the error checking may fail just as in intellij sometimes. &gt; and there is 0 intellij equivalent to inspect type at point [The instructions are here](https://confluence.jetbrains.com/display/IntelliJIDEA/Working+with+Scala+Show+Type+Info+Action).
I call your "development method" lazy, because you tell people to implement *your* project *themselves*. Yes, it works in emacs - *sometimes* - but I and a lot of other developers don't care about emacs and with this attitude you could call it emacs-scala instead of anything else. Nowadays, I use neovim with scaladocs and intellij+ideavim instead of vim-ensime because it involves far less headache - and you can't deny this. And please, don't brag about your project because I've **wasted** more time in it reporting issues and trying to make the installation work than actually using it. Also, the memory consumption almost equals to intellij's and the project setup takes more time - and more problem. Do you know how many issues I've reported to code editors, IDEs and scala projects so far? 0. Do you know how many issues I've reported to ensime related projects? At least 20. I didn't want to tell you but this "DIY" method created one of the worst quality project for scala. That's why I think it's somewhat fair from you to tell that you're "not giving people something for nothing." but you should change the name from "ensime" to "emacs-scala" since it doesn't work properly in other editors. For vim, one could just use [eclim](http://eclim.org/) simply. But idevim is ok so no problems for vim. The atom and sublime ports are pretty much useless. You've also put VSC [on the list](https://ensime.github.io/editors/) but it's pointless since you don't support it at all.
DOT was proven sound, so I think you can call that fixed.
Soundness of DOT doesn't necessarily translate to soundness of Dotty / Scala with the presence of null values (either explicitly, which could be forbidden, or through uninitialized variables, which is unavoidable). The soundness hole demonstrated by the first snippet was also present in Dotty. (The site seems to be broken; I can't look at any other the other snippets, it always shows the first one)
Meanwhile actual software engineers using these languages still don't give a damn.
&gt; Will they ever allow anything that's impossible without them? This isn't true, heterogenous lists for example cannot be implemented without using dependent types.
DOT is sound because it doesn't have nulls. If you extend it as was originally done in Dotty, it becomes unsound. Scala already had provisions for dealing with inconsistent types (which are required for this soundness hole) by preventing you from instantiating them. The caveat with this strategy is that Null is a subtype of such an inconsistent type, so you can use null as a value of that type without having to instantiate it.
Not everyone in the community are experts. I, for instance, have no idea why this is important, or what it entails in a real life scenario. Not saying it's not important, just saying it's way over my head. 
&gt; Those same devs [...] were spending a lot of time trying to find errors that IntelliJ was reporting that weren't really errors at all I think anyone familiar with IntelliJ Scala will take the error reporting with a grain of salt. It's not that big of a problem. When IntelliJ gets too many things wrong, you can disable the inspection for the file, or use the magic "jaded" comment `/*_*/` marker to tell IntelliJ not to inspect the rest of the code. You still benefit from the nice reporting for files where you're not doing ninja/hardcore stuff (which can be most of them in some projects). Also, although I always have an sbt terminal at hand, I find it very nice to run/debug from the IDE, and IntelliJ will run your correct code even if it's red. 
Author of Boilerless here. Thanks! But would you expand on what you mean by footprint? The annotations seem to expand to the same code. If you're talking about project size, the respective numbers of lines of code for Itemize and Boilerless for the core macros code, as given by `cloc`, are 302 and 350. Not much of a difference :-P 
This attitude explains the quality of software out there. Imagine if civil engineering researchers found out that cement had a fundamental flaw and their models were wrong in certain circumstances and the engineers were all like "eh, most bridges don't fall down, nothing to care about".
Implicits are resolved at compile time. Since during compilation the compiler doesn't know which subclass of `AComponent` you have, there's no way for it to resolve the right `Writer` for it. One way is to make all subclass of `AComponent` implement a `toJson` method and just call that (typical OO style). I'm doing this for some of my backend code to convert arbitrary exception into JSON
The unsoundness here required the use of null to construct a type which otherwise had no members. I think as static typing moves towards the dependently typed end of the spectrum, there is still a place for features that allow the type system to be circumvented (whether it is casts or null) for cases where it is difficult to prove something in the type system but it has been proved outside of the type system, and also for the case while you are working on the type proof and want to check some parts before you complete the entire program. Languages designed specifically to be dependently languages have features explicitly advertised for this: for example, Coq has the admitted tactic which lets you treat any proposition as true without proving it. Often it is easier to test code is correct (i.e. show that for some inputs, the output meets some predicate) than proving it (for all inputs, the output meets some predicate), and so it is actually useful if the language allows you to temporarily do something unsound during development. If you think of casting, throwing exceptions and using null as only being for Java interop, and carefully check Java interop code to make sure exceptions or null don't escape into the rest of your Scala codebase, then the unsoundness is less of a problem.
That is actually what I ended up doing. Had to rewrite a bit of old code, but in the end it got it done. Thanks for the help!
imo play has more to it then templating and I also use it for these kind of things
I don't get the "minimal" argument. Are you worried about the size of your artifacts? You don't have to use Twirl -- there's a REST API which uses JSON directly. https://github.com/jeffhorton/play-rest-api-to-db
Check the 0.15 documentation of http4s, there's a lot more there. 
I'd guess by minimal op means something that makes less decisions for user, so more of a library than framework... (i.e. user doesnt want to have or use guice)
but it's there... so is play-json I think. I don't mean it's a bad thing, and having a framework is good for ease of mass adoptation (i.e. node.js), so by all means Im happy we have Play... but I can understand when someone wishes to have something "minimal".
https://github.com/http4s/http4s/pull/661 When this gets done, I'll have mini christmas. correction: freaking grand christmas clarification: nothing against scalaz, it's awesome, I wouldn't care if I was sole developer... 
[removed]
There are a lot of critical bugs in this release, including fully freezing the IDE every few minutes when editing the code. I got tired of doing `kill -9` and had to get back to work so I rolled back to 2016.2. You'll need to give it a month or two for them to fix the critical bugs that should have been tested before the release.
I use akka-http extensively at work and I love it
Cool. That's nice to hear. I often hear a lot of people bashing Akka for being too "java'y", and (ironically) too little typesafe. It's nice to hear some good experiences with it. I really like how akka http is (well) documented!
http://http4s.org/docs/0.15/ ? I don't want to be harsh on something that I don't pay anything for, that's open-sourced and created purely by selfless good deed. ...And I hate writing documentation as much as the next guy, but when it comes to a library/framework, good documentation is crucial. Otherwise, I just have to guess/trial-and-error my way which takes ages. (from personal experience, actually). I mean the library is (probably!) super nice and everything, but how would I know when I can't use it? :p Ie. there's nothing in the documentation there on how to do the most basic thing of all things: serve an index.html file. I had to trial and error for hours with something that I found it the source code called `StaticFile`. Kinda makes me feel like I'm the first person in the world trying to use this library.
Software is fundamentally different from civil engineering. I can fix massive structural issues with software without creating any noticeable impact to users which is not possible with a bridge. We don't need to be super thorough up front or on fundamentals because change is easy to address. 
Well it depends what you are building. It's hard to get your money back if it's a trading platform etc. I agree most software can just be patched but sometimes you need tools to build things that are mission critical - then things like soundness matter.
I guess it might be worth asking, whether you would prefer a good library that has a good core foundation, but poor documentation, or a poorly architected library with average documentation?
I don't actually think the anology is really apt. Actually in engineering, very few things are formally proven (mainly because its pretty impossible to do) and so the attitude is far more about emperical reasults rather than theoritical ones. That doesn't of course doesn't mean that there isn't any rigor or proof in engineering. What it does however mean, is that the proof is closer to "we are going to model the properties of various materials and provide enough buffer so its high unlikely that anything bad will happen" (which is very pragmatic/emperical in its outlook) rather than trying to prove that a bridge may never break. If you combine this with other variables (i.e. economic costs due to materials available) you will see that the two approaches are actually very different. Also trying to prove correctness in languages which are practical to use are almost always feasibly impossible. Dotty for example doesn't try to prove correctness in its entirety, it can only prove the instantiated values are valid, and Martin goes into detail as to why this is so in this talk https://www.youtube.com/watch?v=_YER2g8Y3Bc
Actually, I actually did. Yea I found those methods, but I still spent an obscene amount of time of trying every possible combination of "." "./resources" "../frontend" "../frontend.index.html" etc etc all while moving files from folder to folder in hope that eventually they'd match. After a good hour or two I eventually cracked the right combination of folder, path syntax, etc. Sure those are mistakes because I'm a "silly noob", but that's exactly why I want good documentation with concrete examples - so that a complete noob can get hello world of index.html working before diving into the deep end of the pool. Rightfully, some time would be saved if I had a better understanding of where sbt/maven/jvm wants me to put my static files. It sure is very different from node where you can just say ../frontend/index.html at that's where it'll find it. Java has some complicated resources system which I'm sure is easy enough once you're familiar with it
For what reason would you favor akka-http? I'm not for or against it, but simply curious the reasons for which you prefer it.
whats the next best alternative to intellij for scala development these days? 
&gt; Java has some complicated resources system which I'm sure is easy enough once you're familiar with it It's a fair cop. If you aren't familiar with the JVM ecosystem at all, there's a bunch of stuff we more-or-less take for granted. For example, if you want to use http4s' [`StaticFile.fromResource`](http://http4s.org/api/0.14/index.html#org.http4s.StaticFile$@fromResource(name:String,req:Option[org.http4s.Request]\)(implicites:java.util.concurrent.ExecutorService\):Option[org.http4s.Response]) to serve, say, "frontend/index.html", then you'd have src/main/resources/frontend/index.html in your source tree, and say `StaticFile.fromResource("frontend/index.html")` in your code to get an `Option[Response]`. This is the best approach if you expect to pack up your code _and your HTML files_ in a ".jar" or ".war" archive for deployment. You'd probably want to stick with `StaticFile.fromFile()` if you literally wanted to serve a single file fron a filesystem, although at that point it might be worth looking at `FileService` to serve a directory of static files.
Probably if there was, lets say, only akka / slf4j. But what you showed is that it's pretty minimal, that's cool. It probably invalidates any "minimal argument" for usage of other, you are right about that. I had old info :) Do I have to use controllers with Play? How about routes file? Is there example that would spin the rest backend without that stuff?
Always better than other way around :_)
is that database blocking the current thread, looks like it..?
I couldn't for the life of me get `.fromFile` to work even though (I felt) I tried every possible combination - even absolute (`Users/drfisk/dev/projectname/frontend/index.html`). Thankfully, fromResource works nicely now. It's like you say, the way to do it if you want your html bundled with your jar
&gt; It's funny because I've been working with Scala from nearly 4 years now I thought you were a newbie? &gt; I remember what a huge hassle it was for my team (of 8) to get the jvm resources thing to work. I won't defend `java.io` as being a well designed API, or the kind of io api Scala should have. However, your struggles with `java.io` and `ClassLoader`s undermine your point that you need more or better documentation. Every aspect of using both these APIs is extremely well documented in every form you could imagine. Perhaps documentation isn't the root problem, but seems like easy scapegoat. &gt;I guess it's time to spend a few weeks solely inside sbt This problem is completely unrelated to sbt, and I don't understand how it is suddenly involved in this discussion.
We've just inaugurated an art exhibition that has Scala all over the place. There is an eight channel video installation, the material of which has been recorded and algorithmically processed with Scala; they run from Raspberry Pis using a player written in Scala; there is a projection-mapped video installation with live video that processes an IP camera feed using Scala and OpenCV bindings for Java; and there is a 48-channel real-time sound installation that processes sounds picked up by microphones in the room, using algorithms written in Scala. The exhibition is a collaboration, the other digital systems involved are programmed in Fortran. The video mapping software was written in Pure Data/GEM. A few pictures: https://twitter.com/sciss_de/status/803041305874010112
&gt; I'm actually a huge fan FP; it sure is a clean &amp; nice way of coding. If you don't have to use side-effects, then why on earth would you. But we have side effects, by all means! We actually promote them so high that usually they have special monad for that (IO monad in haskell, in scala it's usually Task). And we make them happen in very controlled manner. That's how much we care about side effects! You don't have to use monad transformers though (well, kinda... it's good to know as they are useful sometimes even for local computation instead of whole monadT based architecture) - check Free Monads. (https://www.youtube.com/watch?v=M258zVn4m2M, http://degoes.net/articles/modern-fp, http://degoes.net/articles/modern-fp-part-2) &gt;Side-effects are bad when used all over the place, but when a (side)-effect is obvious, such as when making a Http request to another service, it's not hard to understand what's going on. The problem is side-effects where you don't expect them - not side effects in general. Understandability is just one aspect though. I agree, sometimes it can be obvious there is effect (i.e. when I see Future) Problem is that side effects don't compose. You have your side-effecty API, I can't reuse it in my new computation, that I don't want to execute those effects right away... If I have Task[...] based API, I can compose them, jam them with other Task[..] api, and then execute it at single one place. Sometimes the benefit is larger, sometimes it is smaller. But it's always there. I understand your distate with Monad Transformers, and being worried of taking it too far though. Best of luck in your journey :-)
It's legitimate to have a non-covariant class inherit from a covariant one, as long as it remains covariant with respect to the parent interface. trait Supplier[+T] { def supply: T } trait SupplierAndModifier[T] extends Supplier[T] { def modify(input: T): T } `SupplierAndModifier` is a legitimate `Supplier` and legitimately covariant *as a `Supplier`*, but if you're calling `modify` then that part is not covariant. What you're discovering with your example code is an unrelated misfeature. You should have got a warning on the `case x: MyCons[Any]` that the generic parameter would be erased at runtime - if you build with [modern scalac flags](https://tpolecat.github.io/2014/04/11/scalac-flags.html) you should not be able to make your code fail in this way.
I agree with allowing casting where necessary (and would even say that the language should offer a more concise syntax for it than `.asInstanceOf`), but I think it's valuable to have casting always look like casting, and soundness in the absence of explicit casts. (I'd extend this as far as e.g. deprecating `Option#get` in favour of an explicit cast to `Some` when you need that)
Yes. JDBC is blocking, and neither Doobie nor http4s (can) do anything about that. What http4s does, of course, is ensure that `HttpService`s and its `Request` dispatching are handled on different threads.
OK, that's weird. I'll have a go at cobbling together a shot myself later in the day. :-)
Circe works fine in akka-http with Heiko Seeberger's json library (the name escapes me at the moment). Take a look at Macwire for dependency injection. 
It's fewer operations. In the original code you were reading n chars starting from every char to create ngrams. This way you need to only read one char for next ngram.
Macwire + kleisli arrow for dependency injection
Thank you for enlightening me
Just out of curiosity, what did you mean by &gt; MLey style of Python? 
OK, here's what worked for me. By the way, if you're coming from a Ruby/Python/node.js background, you may want to install [Ammonite](http://www.lihaoyi.com/Ammonite/), which is a very nice REPL for Scala. It still doesn't come up as quickly as, e.g. node, but it's plenty fast enough to improve my quality of life significantly. Here's the transcript of my session, given that I have an "index.html" file on my desktop: psnively@Ragnarok ~$ amm Loading... Welcome to the Ammonite Repl 0.8.0 (Scala 2.11.8 Java 1.8.0_31) @ import $ivy.`org.http4s::http4s-core:0.14.11a`, org.http4s._ import $ivy.$ , org.http4s._ @ StaticFile.fromString("/Users/psnively/Desktop/index.html") SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder". SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. res1: Option[Response] = Some(Response(status=200, headers=Headers(Last-Modified: Mon, 28 Nov 2016 17:08:38 GMT, Content-Length: 138, Content-Type: text/html))) @ Just to be triply-sure: @ res1.get.bodyAsText.runLast.run res2: Option[String] = Some( """ &lt;html&gt; &lt;head&gt;&lt;title&gt;Paul's Page&lt;/title&gt;&lt;/head&gt; &lt;body&gt; This is a page that Paul has made. Let us rejoice and be glad in it. &lt;/body&gt; &lt;/html&gt; """ ) @ That last bit is a bit of a mouthful: `.get` the value of the `Option[Response]`, `.bodyAsText` to get a `Process[Task, String]` of the `Response`'s `.body`, `.runLast` to get the last (and only) item in the stream if it exists, which gives me a `Task[Option[String]]`, and `.run` to run the `Task`, giving me the `Option[String]` with the contents of my "index.html". So this works like a charm, which leads me to think maybe you literally did use `StaticFile.fromFile`, meaning you first constructed a `java.io.File`, and somehow that went bad.
[ScalaIDE](http://scala-ide.org/download/milestone.html), based on Eclipse. It has a different set of flaws compared to IntelliJ, but it's good, if decidedly unfashionable. IntelliJ is pretty dominant now though; hopefully we won't end up with an IDE monoculture in the Scala world. :(
Yes, you absolutely can use Circe. The "akka-http-json" library which brings those integrations is well maintained and just-works™. We may even consider bringing it into the main distribution of akka-http.
They'd need a good technical editor, yes, but sadly "immutability" is *not* marketing goo. You want to understand what a build file does in general, you need that. See also https://www.reddit.com/r/scala/comments/5a6muj/sbt_makes_me_want_to_give_up_scala/dajeoe2/
That's good to know, but doesn't address my main question, which is why would I involve actors at all over, say, just executing a future on a thread pool? 
To be precise, you won't see any actor at all when interacting with Akka HTTP. You will however, see streams a lot, as they're first-class-citizen in Akka HTTP - connecting up through all the layers from TCP through HTTP into Source[MyData,_] etc. Streaming as first class is something we bet on in Akka HTTP's design basically - and it's strictly more powerful than just a Future[_]. Server is Flow[HttpRequest, HttpResponse, _], a HttpRequest contains an HttpEntity of course, and that again is a stream: Source[ByteString, _] which we can accept as Source[Person,_], which you could directly connect to other streams etc. Google for one of my recent talks if you want to learn on the rationale and compositional benefit there. Hope this sparks your interest, happy hakking :)
Hi, VERY biased creator of nd4j here. Nd4j came out of an attempt to use the various ndarrays in java and we tried using net lib and the like as "backends" here: http://nd4j.org/backend.html Over 2014 we tried using various jvm libraries in java. None of them were fast or worked very well. Net lib java also isn't really being maintained anymore and doesn't even use gpus. We are commercially backing nd4j and use it in our own production customers. We switched from using backends to just using javacpp after a while since double/float arrays cause a lot of overhead. The only reason we even needed double/float arrays was due to net lib java, after we got rid of that we switched to pure pointers (which are actually better than nio bytebuffers) Dl4j itself is an extreme use case for a matrix library. 1 of my biggest problems with the whole jvm ecosystem is having ANY code in java is HORRENDOUSLY slow. We tried for 6 months in 2015 with our own java based fork join implementation with various operations to see what would work and as it turns out, you can't beat good ole SIMD and raw vector instructions. We have seen literally a 10x speed up from our java implementation. Deep learning is very computationally intensive and has forced us to surface optimizations that breeze may not have been forced to look for, we will continue pushing speed where necessary. Everything we do in java is off heap via javacpp: http://github.com/bytedeco/javacpp We also have cuda work and the like, this all happens via libnd4j: https://github.com/deeplearning4j/libnd4j This allows us to integrate natively with cuda,mkl and the like at the c level, an since everything is off heap via pointers we don't have jvm overhead to worry about with memory allocation. Nd4j also has its own built in memory management for cuda. I'll also throw out there that we have 1 unified blas interface for cuda and cpu as well. We also plan on doing distributed backends and the like as well. Nd4j has its backend interface like the opexecutioner,blaswrapper and the like that allow you to implement a "backend" so in theory you could do a lot of optimizaitons. Nd4j also has a parameter server now which allows us to send matrices around on the network. We are going to continue to invest in documentation and the like but welcome any help. Please come in to our gitter channel if you are interested in any of these things: https://gitter.im/deeplearning4j/deeplearning4j The things we DO need to add yet: sparse support complex support we are 99% done finishing out our cuda lapack implementation now. opencl implementation These above features are all nice to have, but as a 16 person startup we have to be careful about what features we invest in. Every feature we implement comes as a cost for us - eg: we have salaried engineers who work on this. We try to implement community features where we can but this stuff is a bit extreme and would be very expensive for us to implement it. We are very ROI driven, but are open to pull requests if people are interested. That being said, we definitely haven't pushed this as much as we should. I hope this helps. 
Thanks for clarifying! 
Not sure I'm completely following this, but you might try making a statement case class so you can actually parse a syntax tree out of the thing, then just evaluate each node of the tree. Not important if you are always evaluating the operations in the given order, but then your tree is just a linked list and it might still be easier to reason about. Each statement node in the tree would be an operation plus the inputs, and the inputs can themselves be statement nodes. https://en.wikipedia.org/wiki/Abstract_syntax_tree
Cool, that might be it. Thanks!
any recommendations for a 2-year scala dev? 
If you want to be able to parse to a *specific* `HList` type then you need to actually know the specific type at compile time. If you know what types you actually have then this can be feasible: type StandardPipeline1 = VertexOperation :: InOperation :: InOperation :: HNil type StandardPipeline2 = OutVertex :: OutPipeline :: HNil def handle(json: JValue) = json.extract[Query] match { case sp1: StandardPipeline1 =&gt; sp1.foldRight(...) case sp2: StandardPipeline2 =&gt; sp2.foldRight(...) } But if you need to handle the general case then you need a type that represents the part you know at compile time: that this is a type-aligned queue with an unknown number of elements. Make your type something like `Operation[In, Out]`, so `VertexOperation` is an `Operation[ScalaGraph, GremlinScala[Vertex, HNil]]` (and the `operate` method is part of the definition of `Operation`). Then the structure you parse to is just a type-aligned queue `Queue[Operation, Input, Output]` (where presumably you know what the `Input` and `Output` have to be), using something like [this queue type](https://github.com/m50d/paperdoll/blob/master/core/src/main/scala/paperdoll/core/queue/Queue.scala) - if you'll give me a day or so I'll pull that out into its own library and release it to maven central, since this isn't the first time I've had it come up as the solution to a problem. A free monad as /u/paultypes suggests is effectively a specialization of type-aligned queue as I understand it (it's a type-aligned queue of Kleisli arrows, possibly with the Coyoneda trick). It will work but it's more powerful than you need, and therefore less clear and debuggable - AIUI your pipelines are always a sequence of concrete steps that directly connect to each other, rather than having arbitrary functions in between, so it would be nice to expose it as such and have pipelines that you can view and decompose without having to run them. I mean just the fact that you can `println` a `Queue` (disclaimer: friendly `toString` method not yet implemented, so it will print as the tree structure it's represented as internally rather than the linear structure it semantically represents) is a big advantage over `Free`, which prints as `Suspend(FirstOperation, &lt;function1&gt;)` or similar. To parse JSON to such an aligned queue you'll have to fold along the json list, passing the "current" type through and checking that the type matches the input type to the next thing that you're parsing and erroring out if not. But that's what you want to do anyway, right? i.e. if the submitted JSON is a pipeline that doesn't fit together (the output type of one operation doesn't match the input type of the next one) then that should be an error as early as possible, i.e. at JSON-parsing time.
I know I wanted to use cats for one of my projects but it was missing `Leibniz` (which is not hard to write and I have in fact written myself on one occasion, so I suppose I could contribute one to cats) and also it didn't seem to have as comprehensive a SI-2712 workaround as ScalaZ (there was also a minor feature missing from `MonadPlus`). Also in any case I can't do releases against cats until doobie does.
Just a few thoughts on: &gt; **http4s** &gt; &gt; _cons_ &gt; &gt; * Maintained by 2 people. One appears to work for Twitter, so you're not out of the Twitter Bubble. * Locked in to scalaz, although that is changing (but won't be done for a long time) * Despite opining for the removal of state, FP in scala has a lot of it. I'm newer to Scalaz/Cats, but from information scattered throughout the web it seems that there was some huge fight between Scalaz devs, causing the community to split into the Typelevel/Cats camp and the Scalaz camp. Then recently, Scalaz was added to the Typelevel project, but then withdrew. How can one trust scala's pure FP ecosystem when it's core community can't even get along? * Does documentation exist for this project? I thought that was one of the major reasons for the Typelevel project?? 1. I'm not sure how http4s falls into the "Twitter Bubble" in the sense, say, Finch does, as it doesn't rely on the body of alternative-to-the-standard-library Twitter code Finch does. (NB: I make no judgment of whether that's good, bad, or indifferent, just that http4s and Finch are very different in this regard). Also, if you're concerned about Bryce Anderson working for Twitter, how about the fact that Ross Baker works for Verizon Labs? 2. Progress on [ÜberPR #661](https://github.com/http4s/http4s/pull/661) is actually quite good. "Won't be done for a long time" is unfair, unless your idea of a "long time" is just months. :-) 3. "Despite opining for the removal of state, FP in scala has a lot of it." I have no idea what to make of this. http4s is _emphatically_ a scalaz(-stream)-based library and is purely functional. `HttpService`s are, strictly, a `Kleisli[Task, Request, Response]`, `EntityBody`s are a `Process[Task, ByteVector]`, the various HTTP-related types are immutable, etc. It's hard to be more pure than http4s is. "I'm newer to Scalaz/Cats, but from information scattered throughout the web it seems that there was some huge fight between Scalaz devs, causing the community to split into the Typelevel/Cats camp and the Scalaz camp. Then recently, Scalaz was added to the Typelevel project, but then withdrew. How can one trust scala's pure FP ecosystem when it's core community can't even get along?" I'm honestly not sure I understand the concern. Whether you choose the scalaz ecosystem or the Typelevel ecosystem (already a false dichotomy—there continues to be huge overlap in both contributors and projects), both are quite healthy and vibrant. For one thing, Verizon Labs employs about half the maintainers of each of scalaz and Cats, although all of our FP code is scalaz-based. My rough estimate as to when Verizon Labs will convert its entire codebase to Cats is "never;" YMMV. 4. As discussed elsewhere, http4s' documentation needs work, but if you're at all familiar with the scalaz(-stream) ecosystem, it's very usable as it stands (and is being heavily used). It's a [Typelevel incubator](http://typelevel.org/projects/) project, so no one's claiming it's up to where one would expect a top-line Typelevel project to be. I mean, you can certainly make an argument that I'm biased, although I've worked extensively with Spray before and have preferred FP approaches in general long before http4s existed. But to be honest, your "cons" don't add up to much. I'll give you the documentation one, but even that is mitigated by how straightforward http4s is to use given what documentation there is, the [examples](https://github.com/http4s/http4s/tree/v0.14.11/examples), the [ScalaSyd example](https://bitbucket.org/da_terry/scalasyd-doobie-http4s) I keep linking to, the [Gitter channel](https://gitter.im/http4s/http4s), etc. As for scalaz vs. Cats, http4s will continue to be available using scalaz indefinitely, and it'll be nice when it's available for fs2/Cats too. So I find the choice very clear, but there's no question there's a large element of selection bias to that. For example, the ScalaSyd code, which combines http4s, Doobie, and Argonaut, works as seamlessly as it does because they're all based on scalaz. But then, that's part of the point: choose the right foundational abstractions and build on them, then more things are likely to work together easily. So e.g. Finch may be purely functional and fast, but it appears to be based on Cats apart from fs2, so it's not at all clear how to integrate it with, e.g. Doobie. Doobie SNAPSHOTs are based on Cats 0.8.1; even Finch Milestone releases are based on Cats 0.7.2. I look forward to all of these things evolving, but it'll be a while—by which I mean a year or more—before the Cats/fs2 ecosystem is production-ready.
3.1-M1 / M2 are released also against cats :) 
The way I see it there's no reason `.asInstanceOf[Some[A]].x` shouldn't compile to the same thing that `Option.get` does - both have the same semantics of "the `x` field of `Some`, otherwise throw an exception".
Super annoying how some of the titles are being truncated underneath the video thumbnail because of the "scala.bythebay.io: [author]" prefixes.
But most of the time these aren't patterns in Scala - in the sense that you don't repeat structures in the code. There isn't a "singleton pattern" in Scala, there are just singletons - there is no repeating pattern to different singletons in Scala, because you don't need boilerplate to define singleton-ness. Patterns are missing language features, and while the article claims all languages have missing features, it would be nice to see this backed up by examples of patterns you actually do need in Scala. (interpreter as implemented in the example is sort-of a pattern, but you can often factor out any repetitiveness with Free-like structures to the point that interpreters just look like functions and no longer have any commonality with each other).
&gt; When I press Alt + = I get the type information(IntelliJ IDEA CE 2016.1.4). If you don't you should either check your keyboard shortcuts or report the issue to jetbrains. On this code, with my cursor on `Every` I get nothing. On `Good`: Good[String, Every[ErrorMessage]]("Hi") In IntelliJ IDEA 2016.2.5 Build #IC-162.2228.15, built on October 14, 2016 JRE: 1.8.0_112-release-287-b2 amd64 JVM: OpenJDK 64-Bit Server VM by JetBrains s.r.o I get: Good[G,B] On the same code, in ENSIME, with my cursor on `Every`, I get: class org.scalactic.Every (companion) class org.scalactic.Every[T] --------------------------- ++ (GenTraversableOnce[U]) =&gt; Every[U] ++ (Every[U]) =&gt; Many[U] +: (U) =&gt; Many[U] /: (B) =&gt; ((B, T) =&gt; B) =&gt; B :+ (U) =&gt; Many[U] :\ (B) =&gt; ((T, B) =&gt; B) =&gt; B addString (StringBuilder, String, String, String) =&gt; StringBuilder addString (StringBuilder, String) =&gt; StringBuilder addString (StringBuilder) =&gt; StringBuilder apply (Int) =&gt; T collectFirst (PartialFunction[T, U]) =&gt; Option[U] contains (Any) =&gt; Boolean containsSlice (Every[B]) =&gt; Boolean containsSlice (GenSeq[B]) =&gt; Boolean copyToArray (Array[U], Int, Int) =&gt; Unit copyToArray (Array[U], Int) =&gt; Unit copyToArray (Array[U]) =&gt; Unit copyToBuffer (Buffer[U]) =&gt; Unit corresponds (Every[B]) =&gt; ((T, B) =&gt; Boolean) =&gt; Boolean corresponds (GenSeq[B]) =&gt; ((T, B) =&gt; Boolean) =&gt; Boolean count ((T) =&gt; Boolean) =&gt; Int distinct Every[T] endsWith (Every[B]) =&gt; Boolean endsWith (GenSeq[B]) =&gt; Boolean exists ((T) =&gt; Boolean) =&gt; Boolean find ((T) =&gt; Boolean) =&gt; Option[T] flatMap ((T) =&gt; Every[U]) =&gt; Every[U] flatten (T &lt;:&lt; Every[T, Every[B]]) =&gt; Every[B] fold (U) =&gt; ((U, U) =&gt; U) =&gt; U foldLeft (B) =&gt; ((B, T) =&gt; B) =&gt; B foldRight (B) =&gt; ((T, B) =&gt; B) =&gt; B forall ((T) =&gt; Boolean) =&gt; Boolean foreach ((T) =&gt; Unit) =&gt; Unit groupBy ((T) =&gt; K) =&gt; Map[K, Every[T]] grouped (Int) =&gt; Iterator[Every[T]] hasDefiniteSize Boolean head T headOption Option[T] indexOf (U, Int) =&gt; Int indexOf (U) =&gt; Int indexOfSlice (Every[U], Int) =&gt; Int indexOfSlice (Every[U]) =&gt; Int indexOfSlice (GenSeq[U], Int) =&gt; Int indexOfSlice (GenSeq[U]) =&gt; Int indexWhere ((T) =&gt; Boolean, Int) =&gt; Int indexWhere ((T) =&gt; Boolean) =&gt; Int indices Range isDefinedAt (Int) =&gt; Boolean isEmpty Boolean isTraversableAgain Boolean iterator Iterator[T] last T lastIndexOf (U, Int) =&gt; Int lastIndexOf (U) =&gt; Int lastIndexOfSlice (Every[U], Int) =&gt; Int lastIndexOfSlice (Every[U]) =&gt; Int lastIndexOfSlice (GenSeq[U], Int) =&gt; Int lastIndexOfSlice (GenSeq[U]) =&gt; Int lastIndexWhere ((T) =&gt; Boolean, Int) =&gt; Int lastIndexWhere ((T) =&gt; Boolean) =&gt; Int lastOption Option[T] length Int lengthCompare (Int) =&gt; Int map ((T) =&gt; U) =&gt; Every[U] max (Ordering[U]) =&gt; T maxBy ((T) =&gt; U) =&gt; (Ordering[U]) =&gt; T min (Ordering[U]) =&gt; T minBy ((T) =&gt; U) =&gt; (Ordering[U]) =&gt; T mkString (String, String, String) =&gt; String mkString (String) =&gt; String mkString String nonEmpty Boolean padTo (Int, U) =&gt; Every[U] patch (Int, Every[U], Int) =&gt; Every[U] permutations Iterator[Every[T]] prefixLength ((T) =&gt; Boolean) =&gt; Int product (Numeric[U]) =&gt; U reduce ((U, U) =&gt; U) =&gt; U reduceLeft ((U, T) =&gt; U) =&gt; U reduceLeftOption ((U, T) =&gt; U) =&gt; Option[U] reduceOption ((U, U) =&gt; U) =&gt; Option[U] reduceRight ((T, U) =&gt; U) =&gt; U reduceRightOption ((T, U) =&gt; U) =&gt; Option[U] reverse Every[T] reverseIterator Iterator[T] reverseMap ((T) =&gt; U) =&gt; Every[U] sameElements (Every[U]) =&gt; Boolean sameElements (GenIterable[U]) =&gt; Boolean scan (U) =&gt; ((U, U) =&gt; U) =&gt; Every[U] scanLeft (B) =&gt; ((B, T) =&gt; B) =&gt; Every[B] scanRight (B) =&gt; ((T, B) =&gt; B) =&gt; Every[B] segmentLength ((T) =&gt; Boolean, Int) =&gt; Int size Int sliding (Int, Int) =&gt; Iterator[Every[T]] sliding (Int) =&gt; Iterator[Every[T]] sortBy ((T) =&gt; U) =&gt; (Ordering[U]) =&gt; Every[T] sortWith ((T, T) =&gt; Boolean) =&gt; Every[T] sorted (Ordering[U]) =&gt; Every[U] startsWith (Every[B], Int) =&gt; Boolean startsWith (Every[B]) =&gt; Boolean startsWith (GenSeq[B], Int) =&gt; Boolean startsWith (GenSeq[B]) =&gt; Boolean stringPrefix String sum (Numeric[U]) =&gt; U to (CanBuildFrom[Nothing, T, Col[T]]) =&gt; Col[T] toArray (ClassTag[U]) =&gt; Array[U] toBuffer Buffer[U] toIndexedSeq IndexedSeq[T] toIterable Iterable[T] toIterator Iterator[T] toList List[T] toMap (T &lt;:&lt; (K, V)[T, (K, V)[K, V]]) =&gt; Map[K, V] toSeq Seq[T] toSet Set[U] toStream Stream[T] toTraversable Traversable[T] toVector Vector[T] transpose (T &lt;:&lt; Every[T, Every[U]]) =&gt; Every[Every[U]] union (GenSeq[U]) =&gt; (CanBuildFrom[Vector[T], U, Vector[U]]) =&gt; Every[U] union (Every[U]) =&gt; Every[U] unzip ((T) =&gt; (L, R)[L, R]) =&gt; (Every[Every[L], Every[R]] unzip3 ((T) =&gt; (L, M, R)[L, M, R]) =&gt; (Every[Every[L], Every[M], Every[R]] updated (Int, U) =&gt; Every[U] zipAll (Iterable[O], U, O) =&gt; Every[(U, O)[U, O]] zipWithIndex Every[(T, Int)[T, Int]] type (scala.Function1.T1) =&gt; scala.Function1.R --------------------------- trait scala.PartialFunction[A, B] --------------------------- andThen ((B) =&gt; C) =&gt; PartialFunction[A, C] applyOrElse (A1, (A1) =&gt; B1) =&gt; B1 lift (A) =&gt; Option[A, Option[B]] orElse (PartialFunction[A1, B1]) =&gt; PartialFunction[A1, B1] runWith ((B) =&gt; U) =&gt; (A) =&gt; Boolean class java.lang.Object --------------------------- != (Any) =&gt; Boolean ## () =&gt; Int == (Any) =&gt; Boolean eq (Object) =&gt; Boolean equals (Any) =&gt; Boolean getClass () =&gt; Class[?0] hashCode () =&gt; Int ne (Object) =&gt; Boolean notify () =&gt; Unit notifyAll () =&gt; Unit synchronized (T0) =&gt; T0 wait (Long) =&gt; Unit wait (Long, Int) =&gt; Unit wait () =&gt; Unit class scala.Any --------------------------- asInstanceOf T0 isInstanceOf Boolean On `Good` I get: type (org.scalactic.Good.G) =&gt; org.scalactic.Good[G, B] (companion) I don't know about you, but one of these gives me information that I can use to further develop what I'm working on, and one doesn't work on the inner type `Every` and merely repeats what the return type of the function call is -- and doesn't even indicate that it is a function that I am calling. Oh, also, in the information window that ensime's inspector pops open, I can jump to the definitions by using jump to source. I can recursively inspect the types in the information screen by navigating to them and hitting [ENTER]. Intellij gives me less information in answer to my query about the code. &gt; And they most probably never will since main features are either really broken or DIY. Unless you want to work on them. I use emacs. If you use sublime, enable the features. The sublime/vim ports never existed before somebody implemented them. Just as an information dialog similar to what is available in ENSIME never will in Intellij unless I were to add it to the scala plugin. That's the way open source projects work. It's fine to use Intellij, but I know how to use a tool that gives me better information than that IDE provides, so I use that tool to be more productive. FWIW: Intellij's debugging is better than in ensime. It is nicer out of the box to develop build.sbt files in. It is nicer to work with for worksheets as opposed to the scala console repl. It does have nice method extraction features. Renaming a class moves the file, which is nice. There are lots of nice things about it.
Language features are still language features - my classes look like classes, my types look like types, my functions look like functions. But I consider any patterns in what I've written a sign that I'm missing some commonality I should have factored out. E.g. rather than having a parallel hierarchy of DTO classes, maybe I should derive them using Shapeless. If I've got similar-looking pipelines in two parts of the code, maybe I can rewrite that as one pipeline with two monads. Code should capture the unique essence of the problem - it should be all information, no redundancy. Of course I do end up with patterns. Sometimes I can't figure out the common part. Sometimes there really is a language deficiency (e.g. lack of kind polymorphism). But I do regard patterns in my code as a code smell, and work to replace them. 
&gt; Intellij gives me less information in answer to my query about the code. I think you can configure it. Btw, by pressing Shift twice you can search in everything. &gt; Unless you want to work on them. I use emacs. If you use sublime, enable the features. The sublime/vim ports never existed before somebody implemented them. "Implemented". &gt; That's the way open source projects work. So FOSS = force contributors to implement almost every main feature and fix every critical bug? &gt; It's fine to use Intellij, but I know how to use a tool that gives me better information than that IDE provides, so I use that tool to be more productive. Unfortunately, refactoring, code completion, macro and error highlighting in the presentation compiler will never be on the same level. I use 'raw' neovim nowadays and I only start intellij when I visit a new part of a codebase. 
raising the level of abstraction and factoring out redundant code to eliminate boilerplate doesn't mean you don't have patterns, it just means you've eliminated boilerplate. for example "rather than having a parallel hierarchy of DTO classes, maybe I should derive them using Shapeless" -- deriving classes using Shapeless it itself a "pattern" (is that a missing language feature, too?). you can always find a higher-level pattern that low-level patterns fit into or are embedded in. I think my conception of the word is wider than yours which seems to be more centered on GoF-style recipies. I haven't surrendered the meaning of that word to the GoF and hope others wouldn't either. 
&gt; deriving classes using Shapeless it itself a "pattern" (is that a missing language feature, too?) Yes, absolutely! And it does tend to have common parts that can be factored out (as in e.g. the `Typeclass` type class). &gt; I think my conception of the word is wider than yours which seems to be more centered on GoF-style recipies. I haven't surrendered the meaning of that word to the GoF and hope others wouldn't either. If the word is to be useful rather than misleading then its meaning should correspond to its plain-English meaning, which to my mind implies not just a similarity or a single point of contact, but a repeating structure. (And note that the article itself defines a pattern as something that isn't represented by a helper method, class or other abstraction.)
Follow-up: I've released my type-aligned queue as a distinct paperdoll-queue package at https://bintray.com/lmm/maven/paperdoll/ , and I've got the process of getting it into maven central rolling.
It was already posted on [haskell subreddit](https://www.reddit.com/r/haskell/comments/5fj4v1/do_you_like_scala_give_haskell_a_try/) but this apparently should go for /r/scala so I reposted.
Common patterns in Scala include typeclasses , dependency injection (in it's various forms), and apply in a companion object is often a factory method. There are probably others but those are the first to come to mind. You don't *have* to use either but you don't have to use any design pattern for that matter. Edit: add example. Also, to say that some design patterns can be replaced by features (le.g. azy replacing double check kicking), it may be that some are just made easier by the language (object for singletons). For other patterns, there may not be enough of a return on making it a feature to offset adding complexity to the language.
Definitely I would not use Haskell as my main language however I think *trying* is never wrong. Meanwhile, some features in Haskell are *really* superior that even Prof. Martin Ordersky jokes that "Scala is a gateway drug to Haskell".
The library argument, however, may be an important one. As Scala is on the JVM we can use all the Java libs, too. Yeah, you don't want to use most of them, but sometimes they are hard and expensive to write yourself. Not sure about the haskell ecosystem, but I bet has less to offer. That being said, I feel like IF you have learned Scala and its pure functional side to the point where you are tempted to learn Haskell then Haskell is probably practical enough for you to start being productive quite fast.
&gt; Well, I use Scala because it's the most Haskell-like language that I could get paid to write :). Hehe, so true. &gt; I'm not sure the point about "no conflicting implicit conversions" is true–my compiler will certainly throw an error if I import two instances of an implicit ordering for my types. To me it feels lacking to not be able to define multiple type class instances for my types and use them in different contexts. At least I heard that you can only define one type class instance per type and that these are global.
IIUC it goes like this. In Haskell parameters don't need parentheses or brackets and are separated with space not commas. The parentheses here are just for precedence/grouping. So it's like `case class Node[a](x: a, y: Tree[a], z: Tree[a]) extends Tree[a]`
Typeclasses are a good example (though by no means missing from all languages). Dependency injection I don't think there's a clear consensus on - the cake pattern is definitely a pattern, but many Scala folk reject it, I think precisely because of its patterniness.
I don't care about the JVM per se. I care about availability of tooling (IDEs etc.), availability of *memory-safe* libraries (i.e. not just an FFI into a C library where you're one unchecked `+` away from an RCE vulnerability), and occasionally the ability to reason about performance (which seems impossible in the presence of laziness). I don't know why Haskell tooling should be worse than Scala, but it does seem to be so. While I'm sure the Haskell library ecosystem is improving every day, last I looked there was no SSL implementation available (just bindings to OpenSSL), the only image (png etc) reading libraries were native bindings - basic things like that. Laziness seems to be what makes Haskell Haskell, and I think it would keep me away from the language even if the my issues were resolved (I'm very much interested in e.g. Idris).
I also feel that `implicit` is more flexible; the only complaint is that it's not specific to type class and its resolution rules are difficult.
Well for starters you have a mixture of absolute and relative paths in your path specification. You need a slash before opt and usr to ensure it's not looking for them in your editor's working directory. Clean that up and test again.
use homebrew: http://sourabhbajaj.com/mac-setup/Scala/README.html
You wouldn't and shouldn't. The akka-http developers chose to build their library on top of akka for whatever reasons of their own, and no doubt that decision slows down their development, but that's their problem; at the user level you just use it as a normal well-typed library and it works exactly as you'd expect.
&gt; Despite opining for the removal of state, FP in scala has a lot of it. I'm newer to Scalaz/Cats, but from information scattered throughout the web it seems that there was some huge fight between Scalaz devs, causing the community to split into the Typelevel/Cats camp and the Scalaz camp. Then recently, Scalaz was added to the Typelevel project, but then withdrew. How can one trust scala's pure FP ecosystem when it's core community can't even get along? Because you can look at the code and see that it works? The community issues are real but they don't get in the way of doing productive programming with the relevant libraries; you don't have to agree with a given author's politics to be able to use their library.
From my perspective the issue here is that Play is a framework. You don't have control over starting point of your app (you can't simply start it from main method of your object) and it's not obvious how to combine it with other parts of your application. For example I have component that executes scheduled background jobs. With akka-http I write main method that starts this component, then launches web server, then blocks main thread. This is the normal way of structuring my code, I don't need to make some special rituals. With Play I can't do that in a straight way - I need to google some workaround.
I've found that Scala makes using Java libraries much nicer than, say, Clojure. Typeclasses make it really easy to add functionality to a type without having to completely wrap it in a subclass.
The description I gave is fairly close to the definition of a design pattern: "In software engineering, a software design pattern is a general reusable solution to a commonly occurring problem within a given context in software design." &gt; `Free` is a useful type, but it's not much of a pattern because it really is just a type. You don't have to implement it, you can just use it. Many patterns can be generalized to the point of being put into a library, and the stronger the type system the easier it is to do so. Patterns reference the conceptual construct than the implementation.
&gt; I feel like I should be able to shoot off logs, metrics, etc. without FP purists saying that my code is no longer referentially transparent or "reasonable" and that I should wrap everything in a monad. &gt; Actually, from reading some of your posts, it seems you've moderated your stance on this? Logs are not (usually) observable to the program, and don't affect its output, so the log-generating function can still be considered referentially transparent? If so, I'm glad you added much needed formalism to my vague intuition. Honestly, I'm surprised that thread got as long as it did, and by the position some folks took in it. I don't feel like I moderated my stance at all! On the contrary, I linked (repeatedly!) to the definitions of "purity" and "referential transparency" [here](http://blog.higher-order.com/blog/2012/09/13/what-purity-is-and-isnt/). If you accept those definitions, then logging, by which I and everyone else means "emitting output that may be informative to _someone else_ but has no effect on the program," is referentially transparent, full stop. No further debate is required. Or possible. &gt; I prefer to default to strictness with optional laziness. I guess this isn't a constraint of FP since OCaml can do it. I just find it odd that users of Haskell frequently admire their ability to algebraically reason about their code (e.g. one of my favorite "features"), yet cede their ability to reason, locally about its performance. As a long-time OCaml programmer and now Scala programmer, I'm totally with you. I can't help but notice that Idris is strict, too. So good points—if people are taking "pure FP" to mean "logging is a side-effect and all FP must be lazily evaluated," those are some misapprehensions folks like me should try to address. Thanks for the feedback!
&gt; (you can't simply start it from main method of your object) You can do this by embedding Play into the main method of your object: https://www.playframework.com/documentation/2.5.x/ScalaEmbeddingPlay &gt; component that executes scheduled background jobs You can do this by binding the component as an early singleton: https://www.playframework.com/documentation/2.5.x/ScalaDependencyInjection#Eager-bindings If you look at the sample projects at http://playframework.com/download they are good for showing how Play applications work out. The [play-scala](https://github.com/playframework/play-scala) project has examples of binding components for you.
Would it be possible to write that up as a "basic concepts of http4s" for the [http4s docs](https://github.com/http4s/http4s/tree/master/docs)?
That's a great idea. Let me set aside some time this weekend for that.
I prefer not throwing because in that case I'm just using ordinary functions and values, not an extra language keyword (`throw`) with special semantics.
&gt; So FOSS = force contributors to implement almost every main feature and fix every critical bug? Yes, this is *exactly* how they work. Who is there except the contributors to do this? Do you think there is a magical customer support team behind every FLOSS project to fix your bug reports? (which incidentally, I've been unable to find despite your claims to have opened 20+ such tickets). You're expecting everybody to make the world a better place for you to live in, and you don't want to contribute to that better world.
I think there are different learning styles here. Personally if you'd given me the all-or-nothing approach that is Haskell 6 years ago I'd've quit programming. Whereas in Scala, 6 years ago I was writing code that looked very much like Java, and now I write code that looks very much like Scala, but I've been able to remain productive every step of the way.
I'm not at all convinced that we need subtyping as such. A bunch of recent popular languages don't have it (even not-especially-functional ones) and seem to be doing fine. And I don't want macros, real or otherwise, except perhaps as a tool for doing development and prototyping of the language itself.
I found all the tickets you raised https://github.com/search?q=stevendobay+ensime&amp;type=Issues four of them have been closed by volunteers, and the 5th is fixed in the Google Summer of Code feature branch. It is quite clear from all your reports that you did not read any documentation. You're a troll.
According to Martin, subtyping (or some form of it) is actually needed if you want to implement a proper concept of modules. If you go to this talk https://vimeo.com/130882156, he explains why at around 11:00. He goes on to say that in other languages (like OCaml/SML) they actually have a limited form of subtyping, they just call it Signature Ascription or Signature Subsumption.
Since when does a user need to read every documentation to install a software? Why are you such an asshole? Edit: just think about the scala's or any other language's compiler and library - most issues and features will be fixed by the insider team/group and not by external contributors. No FOSS project says that "do it yourself, you stupid cunt!". Edit2: And how is that I don't read the documentation when the bugs I've reported on that account were **present**?
&gt; Lack of real macros. Template Haskell and scala macros seem about equally bad, and I wouldn't want to use either of them unless I had no choice. 
I guess John Carmack and Tim Sweeney aren't real game programmers? https://web.archive.org/web/20130819160454/http://www.altdevblogaday.com/2012/04/26/functional-programming-in-c/ https://www.st.cs.uni-saarland.de/edu/seminare/2005/advanced-fp/docs/sweeny.pdf
I can't/won't watch videos I'm afraid. In any case I'm not sure I fully understand the notion of modules in the sense that gets hyped.
I'm using Akka and Apache Camel and Neo4J database together in OSGi, I have not pushed for a while so the project is slightly out of date. https://github.com/PhilAndrew/JumpMicro
"Are using," yes. "Are satisfied with," no. Both have come out very strongly in favor of both functional programming and static typing, while acknowledging that: 1. The FP language they'd like to write games in doesn't exist yet. (Tim Sweeney has at least gone on to design [λℵ](http://www.leafpetersen.com/leaf/publications/dtp2013/lambda-aleph-overview.pdf), which clearly follows from his POPL 2006 presentation). 2. There are good reasons why Haskell, in particular, is not that language. Having been in the game development industry—twice–in my career, I can assure you, the relevance of OOP to game programming has been wildly oversold.
ehcache.xml looks like &lt;ehcache xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xsi:noNamespaceSchemaLocation="../config/ehcache.xsd" updateCheck="false"&gt; &lt;!-- This is a default configuration for 256Mb of cached data using the JVM's heap, but it must be adjusted according to specific requirement and heap sizes --&gt; &lt;defaultCache maxBytesLocalHeap="256000000" eternal="false" timeToIdleSeconds="120" timeToLiveSeconds="120" overflowToDisk="false" maxElementsOnDisk="10000000" diskPersistent="false" diskExpiryThreadIntervalSeconds="120" memoryStoreEvictionPolicy="LRU" /&gt; &lt;cache name="controller-cache" maxBytesLocalHeap="256000000" eternal="false" timeToIdleSeconds="120" timeToLiveSeconds="120" overflowToDisk="false" maxElementsOnDisk="10000000" diskPersistent="false" diskExpiryThreadIntervalSeconds="120" memoryStoreEvictionPolicy="LRU" /&gt; &lt;cache name="document-cache" maxBytesLocalHeap="256000000" eternal="false" timeToIdleSeconds="120" timeToLiveSeconds="120" overflowToDisk="false" maxElementsOnDisk="10000000" diskPersistent="false" diskExpiryThreadIntervalSeconds="120" memoryStoreEvictionPolicy="LRU" /&gt; &lt;/ehcache&gt;
Anything interesting between scala 2.12.0 -&gt; 2.12.1 ?
That sounds to me like a very good idea - using things where they're strong at. 
Just quick bugfixes as far as I hear. PS. Your nickname is suspicious :)
I saw once on Miles Sabbin Twitter a new heuristic for implicit search that made the search complexity linear or something like that (I can't remember). Any news on that? I thought it's gonna make it to 2.12.1 for whatever reason... does anyone has info on that ? That would be huge for me :) &gt; PS. Your nickname is suspicious :) Haha, then mission accomplished :D
The general point he was making is the actual concept of modules (or at least the way he sees modules in the design in Scala) is actually a form of subtyping and that other functional languages which have modules (such as OCaml and SML) do use subtyping to represent their module systems (albeit they don't call it subtyping) Modules in this sense is about creating a structure (or in this case a Java interface), having it unimplemented (to a certain) and then being able to instantiate this structure (at runtime or compile time) with an implementation without having to deal with namespace clashes There is an overview of the module system in OCaml here https://caml.inria.fr/pub/docs/manual-ocaml/moduleexamples.html
Isn't that just polymorphism? I agree that we need to be able to separate interface from implementation, but that's not subtyping unless the implementation gets its own type. I mean fundamentally SML does have perfect type inference, so even if you say it has something subtyping-like, there's a fundamental distinction between what SML has and the kind of subtyping that prevents proper type inference. Or am I missing something?
What for? If for fun - it's okay. If for a real-life projects in production - no-no. Cabal is PITA, maintenance of packages on hackage is terrible, documentation either doesn't exist or outdated or unreadable, reading the source code of stuff with N layers of monads and monad transformers causes severe brain damage. Ain't event taking lack of IDE support. Scala has it's own problems, but you can use Eclipse or IDEA, you can use tons of libraries that either well-documented, or it's not that bad reading through source code (not talking about beasts like ScalaZ, Cats or Spray).
second this, it's hard to read stacktraces from Scala, but if it doesn't even lead to the line of code that caused that exception - oh, boy, you're screwed.
I would recommend a DB of some kind. Even something small like an H2 would work or mongo if you want a document store. In each of those instances there are great libraries for handling persistence such as slick or squeryl or mongos Scala library. You can even use a Java library like Hibernate if you are more comfortable with that.
&gt; You are aware that the "insider" maintainers of the scala compiler and library are actually paid a salary to do that, right? And? They're still insiders. And there are people not getting paid but still heavily contributing and taking part of the development. &gt; Projects like ensime are 100% "external contributors", there is no "insider team/group". "100% external contributors" doesn't exist, except for projects which fell from the sky. The ensime-atom team seems like a 2-individual "team". The ensime-vim "team" seems to be @ches only. I'd the temptation to contribute there but python2... Definitely against my interest.
Do you mean persist, or do you mean serialize? Those are two different things.
What I want is to be able to load an object I have been using at runtime again even if the application crashes in the meantime. I have a loop in which a new state is computed at every iteration. And at every iteration I want to store the object to save the state. After the application crashed or has been shut down regularly I want to be able to start it up again and work with that object again just like I left it. I don't care how this happens. It doesn't even have to be particularly fast. In ruby I would just write Marshal.dump(object) or even simply object.to_yaml And save that to the disk. Then later read it using `Marshal.load` or `YAML.load`. My main concern here is how to do that without writing boat loads of code. It's a rather large and complex object consisting of instances of many different classes. 
Alternatively, if you really do want to manage storage/retrieval yourself, then maybe [BooPickle](https://github.com/ochrons/boopickle) is for you.
Does this work with arbitrary classes or just with case classes?
It can derive instances mechanically for case classes. In the general case you have to define an instance.
This is exactly the use case for akka persistent actors, although that might be a little overkill for your project.
Wow this how expected it to work :-) thanks a lot. What is swapped around maybe it's too late here but can't find it? 
Oh you mean the order in the constructor? 
Mh I'm actually already using akka actors anyway and the object is the state of an actor. So I think this might make sense. Thanks for the pointer!
Yep I solved it minutes later, not in an elegant fashion (by overriding with explicit implementation for each) but I have this habit wanting understand why. I had a similar brain bug when I saw the source for S scala.Boolean 
Maybe. Maybe not. Consider ["Immediate mode OpenGL is gratuitously imperative. Keep in mind that the approach described above isn't functional; it's an imperative program abstracted over Haskell's IO Monad."](http://lambda-the-ultimate.org/node/913#comment-8834) — Tim Sweeney Interestingly, here Tim is arguing _against_ wrapping imperative code in a monad, and _in favor_ of an actually pure approach! **Update:** To be clear, I personally suspect that you would indeed probably have/need something like an imperative framebuffer under the hood, and would treat it very much like how Haskell treats [unboxed arrays](https://wiki.haskell.org/Arrays#Unboxed_arrays), for performance reasons. Above that, sure, I'd put a nice monadic API.
Thats a good habit :) it should be rule of thumb :)
Prehaps you're right, but prehaps you're not. No point in arguing. If I were op I would not expect a solution, as that would take away all the fun, I would just want a hint on what I'm doing more. Sure, I'm judging OP's expectations based on "how I would expect it", which is bad, but you are doing same thing.
What's your problem? OP asked **why** is this happening. I've answered it. You've posted an answer AFTER me. pipocaQuemada also posted an answer. If you can't handled your anger than get out of r/scala.
try guru.com though it won't be the highest of pays.
I'm not sure, and I don't use Slick, so I might be wrong. Since `TestTable` is exposed by `TestModel`, and `TestTable` derives from `Table`, you also have to make sure that `Table` is reachable by anybody who would use `TestModel`. I'm guessing that `Table`'s full name is `databaseProfile.api.Table`. But that's not a normal namespace path; that's a path from an object. In order for `Table` to be accessible from the outside world, that root object has to be available to the outside world. But `databaseProfile` is a private field; nobody can see it. Try defining `TestModel` like this: class TestModel(val databaseProfile: JdbcProfile) That might be enough to satisfy the compiler. 
I just looked around; [here's the tweet](https://twitter.com/milessabin/status/779298833981435904), but I didn't see any updates since then. That's a large and much-needed improvement; hopefully it works out and lands soon.
Awesome! Most important thing: don't let yourself feel alone and at sea. Hang out on Gitter channels, IRC, mailing lists, ask questions here... two things I've been repeating a lot lately: 1. No one is born knowing this stuff. 2. Learning it is akin to working toward a black belt in a martial art: you have to put in the time, it takes discipline, and the payoff is mastery of both timeless knowledge _and_ the discipline to acquire and maintain it, both of which are invaluable for your future. And thanks for the kind note!
OK, let's break it down. What's the error? &gt; private value databaseProfile escapes its defining scope as part of type TestModel.this.databaseProfile.api.Table[testing.Test] Why is `databaseProfile` `private`? Because... `class TestModel(databaseProfile: JdbcProfile)` Constructor arguments are `private` by default. &gt; part of type TestModel.this.databaseProfile.api.Table[testing.Test] This is pretty straightforward. You wrote: `class TestTable(tag: Tag) extends Table[Test]` and, as the error says, `Table` here is `TestModel.this.databaseProfile.api.Table`. But the default protection for `class TestTable` is `public`. Your `public` `TestTable` extends a `private` `Table`. Oops. :-) Your workaround provides a `public` `JdbcProfile` as part of your `TestModel` `class`, so there's no longer an issue with the fact that you expose `databaseProfile` as part of `TestTable`'s type.
I recommend volunteering if you want to save money.
My [`attemptRepeatedly`](https://github.com/Verizon/funnel/blob/0074e1d44da2d35c8103cd8fdb9998ce792907a9/core/src/main/scala/Monitoring.scala#L629-L646), without question, sits at the top of a steep learning curve with scalaz-stream. It's only three lines of code, but I'd suggest that each line has its own distinct character. The first is the hardest to understand. The second is the most magical-seeming. The third is obvious, _given the first two_. `step` is probably obviously going to be an `attempt` of some kind, because we want any `Throwable` as a value, hence `Process[Task, Throwable \/ A]`. It's handy that there's a variant of `attempt` that lets us do something with the `Throwable` in context; we take advantage of that to log it (or whatever `maskedError` does). The part that's maybe hard to understand at first is "if the `step` succeeds, `kill` the retries `schedule`." The subtlety here is that an `append`ed `Process` only runs if the `Process` it's `append`ed to succeeds. So `step` is a `Process[Task, Throwable \/ A]` that, if it emits an `A`, also kills the `schedule`, _or_ if it emits a `Throwable`, also logs that `Throwable` without killing the `schedule`. There. That's easily 75% of the battle. I _love_ `retries` because it shows off functional streaming's power so well. Want to "do something" periodically? Just `repeat` and `zip` it with a stream from the `time` module, like `awakeEvery`! If you want it to try periodically forever, that's all you need. If you want to give up after a while, make one of the streams finite, e.g. `awakeEvery(1.hour).take(3)`. Once you have streams of _effects_, then you can have "streams of time passing." And do, with scalaz-stream. It's awesome! So the last line just means what it says: `(step ++ retries)` is the stream of... a `step` and any `retries` that happen, keeping in mind that a successful `step` `kill`s the `schedule` and so `retries` will be truncated at that point. The upshot is that `last`, then, will be either the first (and only) successful `step` or the last failed one, and the `flatMap(_.fold(...))` idiom just turns our `Process[Task, Throwable \/ A]` back into a `Process[Task, A]`, which is what we had coming in. It's _simple_, in the sense that each line has only one interpretation, but it is definitely also _dense_, in the sense that each line relies on having formed a pretty solid understanding of scalaz-stream's semantics. It's an investment—one that I think can be fairly argued is only worthwhile because: 1. What you learn is so solidly based in principle—it'll stay learned (not change out from under you). 2. You're also relying on the scalaz-stream/scalaz-concurrent ecosystem elsewhere in your program, so introducing this mode of programming and reasoning isn't some mysterious one-off in your system. I hope this helps a bit! 
You're going to have to make a choice. There is a clear tension between doing something you like (Scala) and making money (everything else). Scala is niche, finding Scala jobs that will meet your financial and geographical requirements is very unlikely, unless you're willing to relocate and the visa constraints on that relocation are feasible (did you notice that every single thread that starts with "Hiring Scala developers" starts with a comment "Remote possible?"). You want Scala, you're going to have to move. And have very little wiggle room on the compensation. Period. You want money? You're going to have to be flexible on the technology and be ready to accept Javascript, Java, C# or PHP. That's the sad reality. The upside? You might be able to work remote and if your resume stands out from the rest, you might be able to command pretty high rates/compensations. Good luck! 
Check out the recent talks by Greg Pfeil on Matryoshka, which is a recursion scheme library for Scala. Talk source is [here](https://github.com/sellout/recursion-scheme-talk) and if you google there are some videos.
I would ask this question on a Spark forum or on the Spark gitter channel if you don't get an answer. I don't use Spark so I can't help, sorry.
Transformations like map and filter don't compute anything (yet), they just return a new RDD describing how to do the computation. Actions like collect and foreach actually compute something, resulting in tasks being scheduled on workers and a result being returned to your driver. You can verify this by playing around in a spark shell.
Thank you.
Thank you.
&gt; Ha! How things change and yet stay the same. 10 years ago the complaint was that there weren't libraries for everything yet, and so it was likely you had to write your own bindings. So we rolled up our sleeves and implemented bindings for everything. And now the complaint is that some of the libraries are mere bindings, not native implementations! Well if your competition is Scala or OCaml, they're not standing still either. &gt; I'm not too convinced that reimplementing everything natively is a good time investment compared to fixing the C libraries and benefiting the bindings in every language That's assuming the C libraries can be fixed, be known to be fixed, and remain fixed. Which in my experience of using bindings is not the case.
I was actually interested in people's explanations as to "why" it was happening. So, personally, I was getting a little frustrated with people essentially saying "switch val's to def's" without a strong explanation. So I appreciate some people actually answering the question by explaining the problem, and I appreciate some people taking it a step further by providing the solution. I think you just need to calm down. Ironically, you're the one being pedantic.
I'm glad it seems like it might be helpful! I should expand on one bit: you mentioned that it wasn't clear when/whether to use `onComplete` etc. For some reason, I managed to side-step that whole issue. I think maybe because the line of my thinking went something like this: 1. I want to do `p` over and over again. That's obviously `p.repeat`. 2. I want to do that according to `schedule`. That's `schedule.zip(p.repeat).map(_._2)`. 3. Oops, that fails on the first failure of `p`, so I need `schedule.zip(p.attempt.repeat).map(_._2)`. 4. This is getting unwieldy, and I need to distinguish between the first try and the retries anyway, so let's break it down into `val step = p.attempt` and `val retries = schedule.zip(step.repeat).map(_._2)`. That makes good sense. "A `step` is an `attempt`, and there could be more than one `attempt`." 5. Doing that makes clear that the ultimate line should be `(step ++ retries).last`, except that leaves me with a `Process[Task, Throwable \/ A]`, so let's add the `.flatMap(_.fold(Process.fail, Process.emit))`. 6. OK, now all I need to do is stop retrying, conditional on a `step`'s success. Again, this was the (surprisingly, maybe) hard part. I finally stumbled across [`Process#kill`](https://github.com/scalaz/scalaz-stream/blob/release/0.7.3/src/main/scala/scalaz/stream/Process.scala#L319-L323) and realized that `append`ing `kill`ing the `schedule` to `p` in `step` would do the trick, because, again, the `append`ed stream will only do its thing if the stream `append`ed to succeeds. So, a few more notes in honesty: 1. This is a summary of a process that actually took days at the time. 2. I'm forgetting, and therefore not mentioning, the conversations with Paul Chiusano, Rúnar Bjarnason, Tim Perrett, and no doubt others that informed this implementation. I understand it perfectly _now_, but this was very early on in my use of scalaz-stream. 3. There were indeed other implementations, including Paul's gist, before, and yeah, they all had issues of one kind or another. There was an earlier version in Funnel that "worked," except in the case where there was a failure that was later recovered from, the recovered `p` would run twice! Some of my colleagues were OK with this. My stance was that the user's expectation would be that `p` ran exactly 0 or 1 times, period, the end. I got a bit obsessive about it, which amused Tim and led to the final implementation you see now. :-)
There have been Haskell compilers for the JVM but the last ones are serious attempts backed by some community/companies committed to his maintenance. [Frege](https://github.com/Frege/frege) is standard Haskell 2010 intended primarily for being a thin layer of functional programming over the existing JVM libraries. Pretty mature. [Eta](https://github.com/typelead/eta) is newer and thus less mature but it is intended to recompile any GHC library to the JVM as well as use any native JVM library. It is evolving very fast. There are game examples and some (toy) bindings for spark. I hope that this may capture some interest in the Scala community. There are some haskell libraries that may be available in the JVM soon, and may be called from Scala and Java (and viceversa). There are intersting times ahead!
&gt; Citation needed. Rust in particular looks like a reasonable general-purpose language. I wouldn't personally say that Rust is completely a generic purpose language, at least in the sense that it has a similar aims that C++ does in regards to allowing completely control over memory which does complicate the language quite a bit in usage (learning how Rust does memory management isn't easy although its obviously really powerful once you know it). Honestly though you can fall on either side of the fence, general purpose programming is a very loose definition. In our company people have tried to use Rust as a general purpose language and ended up regretting it (mainly because of having to learn how memory management works, which is almost always an overkill unless performance/reliability of memory usage is paramount) Go's was created for a niche area, which is basically backend webservers/CLI tools with the specific aim of lowering entry to programming as much as possible (hence its "simple" design) 
Game programming (at least if we are talking about AA and AAA games which push graphics) are one of the most difficult types of systems you can program. This type of programming literally covers every paradigm of programming while still having to be ultra performant. The last part, i.e. "ultra performant" is why the "purely functional" approach is probably not going to take hold in game programming. Note that this doesn't mean that you can't program subsets of the game in FP, or use a looser principle concept of FP (similar to how the new Dotty is designed), but a lot of the concepts when you start pushing purely functional programming often directly conflicts with clarity around performance and memory usage. Laziness for example has this problem, but even stuff like HKT's are really hard to encode in a generic manner without introducing boxing (Rust is actually having this problem now). Then you also have the fact that a lot of the purely functional datastructures are hard to encode in languages without a GC because then you have to deal with things like cyclic references and free pointers. For this reason, you actually probably wouldn't wrap even imperative code in a monad, or at least a monad that properly obeys the monad results (have a look at Rusts `Result`, its not really a proper monad and this was again done due to performance reasons). Rust in general is actually a very good example of a language which really starts to demonstrate the limitations of purely functional programming if you really care about performance and predictable memory usage, which unfortunately is the case in high tier game programming. Of course there are some areas in game programming where performance isn't an ultra high concern, i.e. business logic in the actual game (such as where Lua is being used right now) where there can be a case for using pure FP, but so far its a very pragmatic mindset, there are just different priorities.
&gt; For this reason, you actually probably wouldn't wrap even imperative code in a monad, or at least a monad that properly obeys the monad results (have a look at Rusts `Result`, its not really a proper monad and this was again done due to performance reasons). I think this is a serious error in judgment, but that's admittedly predicated on a language's having robust support for reusing stack frames (so-called "tail-call optimization," a term I won't use because of the implication that it only matters for performance when it doesn't). Otherwise you end up with the need for trampolining that you find in, e.g. Scala. &gt; Of course there are some areas in game programming where performance isn't an ultra high concern, i.e. business logic in the actual game (such as where Lua is being used right now) where there can be a case for using pure FP, but so far its a very pragmatic mindset, there are just different priorities. With this thought firmly in mind, let's perhaps revisit some specific observations from [Tim Sweeney's 2006 POPL presentation](https://www.st.cs.uni-saarland.de/edu/seminare/2005/advanced-fp/docs/sweeny.pdf): &gt; * When updating 10,000 objects at 60 FPS, everything is performance-sensitive. But: &gt; * • Productivity is just as important &gt; * • Will gladly sacrifice 10% of our performance for 10% higher productivity Improved dev team efficiency is money in the bank—almost certainly well above 10% return. &gt; * Solveable: &gt; * • Accessing arrays out of bounds &gt; * • Dereferencing null pointers &gt; * • Integer overflow &gt; * • Accessing uninitialized variables &gt; &gt; 50% of the bugs in Unreal can be traced to these problems! At the very least, it sounds like a `Maybe` monad would help a lot, _even if it cost 10% of runtime performance_, per the earlier note. re: Integers, you probably don't want me to just copy-paste the whole presentation; see the slide "Analysis of the Unreal code." tl;dr 90% of integers in Unreal are array indices, and 90% of for-loops are either comprehensions or folds. "Concurrency in Numeric Computation" estimates that 80% (!) of Unreal's CPU budget could be parallelized using `STRef` style monadic protection of mutable state. "In the future, we will write these algorithms using referentially transparent constructs." "Concurrency in Gameplay Simulation" says "~2-4X STM performance overhead is acceptable: if it enables our state-intensive code to many threads, it's still a win." The overall thrust here is that _not_ writing a game engine functionally is leaving enormous amounts of CPU on the table, because they basically have one thread that does all the stuff that can't realistically be parallelized (e.g. pretty much all gameplay simulation), one heavyweight thread just for rendering, and a pool of 5-6 dynamically-allocated worker threads. So I dunno. Here's the primary architect of the most widely licensed game engine in the world saying, in essence, "the performance profile of our engine isn't like what you think, and the valuable trade-offs are also not like what you think," and his proposed solutions are a combination of pure FP, an effect system, lenient evaluation, Software Transactional Memory, and dependent types. And he's more than willing to trade off runtime performance against productivity. Keep in mind that that's also money in the bank for Epic: most of their money comes from their licensees. Anything that helps their licensees helps Epic. As for Rust, it seems `Result` is a perfectly good monad (given cursory investigation; please correct me if I've misunderstood). What _does_ seem to be at issue, as I think you're referring to, is that [it's tough to make generic `Monad`s in Rust as it stands](https://m4rw3r.github.io/rust-and-monad-trait), which is certainly something that would be nice to see resolved eventually.
well there is also the `-Yopt:l:project` which might work for libraries.
Thanks, the wiki page is indeed what I missed. I will try `-Yopt:l:project`.
&gt; Libraries could provide a classpath-optimized artifact for those users who want to make use of it, but that has all the difficulties of ensuring a consistent classpath and would result in yet more proliferation of artifacts; we already have ones for each Scala major version - do we really want "2.11-opt" and "2.12-opt" versions to deal with as well? There's no reason for the code to be different, right? Couldn't it be simply a different maven artifact under the same groupId/artifactId/version? That would be invisible most of the time.
It's not the types that are causing this but the values; your `Up`/`Down`/`Left`/`Right` effectively form a circular datastructure, which are naturally tricky to work with in immutable-first languages for obvious reasons. https://wiki.haskell.org/Tying_the_Knot has a bit on one general solution (laziness, which has to be explicit in Scala - others have outlined this approach by using `def`, `lazy val` and/or by-name parameters). But when you encounter this problem it's usually a design issue and I'd recommend first looking at other ways to structure your code; for example, maybe rotating clockwise and anticlockwise should be first-class concepts (objects in their own right) that know how to transform one direction to each other.
Thank you very much! Sad that my IDE and I myself both missed this. *grr* makes so much sense! :)
Nevertheless thanks for your input
Writing a pure Scala-based client for Prometheus monitoring: https://github.com/fiadliel/prometheus_client_scala Prometheus - https://prometheus.io/ - is a reasonably good monitoring ecosystem, with time-series database, instrumentation clients, alerting, etc. They usually recommend the Java client for JVM applications, but my first interactions with this involved a `NullPointerException`. Obviously the next step was to write my own. At this point, the API is nearly at the point of stability, but recommendations welcome at this point before there are many users. It includes a basic client (no dependencies), protobuf format support (requires proto 3.0 library), and can export a few statistics from JMX. And Scala.js support because... why not? Support libraries for: - Play 2.4/2.5 (Filter for monitoring response times) - FS2 Effect (e.g. `fs2.Task`) syntax - scalaz Task syntax - Monix Task syntax
Thanks
Agreed, there could be a tooling solution. Might be nice as a plugin.
It may help to correlate this with the explanation in _Programming in Scala_: [Type Parameterization](http://www.artima.com/pins1ed/type-parameterization.html). The link is for an online version of the first edition of the book. In particular, read the section on [checking variance annotations](http://www.artima.com/pins1ed/type-parameterization.html#19.4), which has an annotated example. &gt; As a somewhat contrived example, consider the following class definition, where the variance of several positions is annotated with ^+ (for positive) or ^- (for negative): &gt; abstract class Cat[-T, +U] { def meow[W^-](volume: T^-, listener: Cat[U^+, T^-]^-) : Cat[Cat[U^+, T^-]^-, U^+]^+ } Your second case refers to how the positions of `Cat`'s type parameters are classified when they are in parameter position or return type position. Notice that the position classification of `listener` is `^-`. Therefore the position classification of the type parameters for `Cat` are `^+` for the first parameter (it's annotated with `-T` so it's flipped from its enclosing classification), while the second parameter position is `^-` (it's annotated with `+` so it maintains its enclosing classification). Similar reasoning applies to the return type. The outer `Cat` classification is `^+`, so its type parameters maintain their annotations and the first is in `^-` position while the second is `^+`. Then the inner `Cat` (the first type parameter of the outer `Cat`) is handled exactly the same way as for the method parameter above since it too has `^-` classification. I don't think the two cases are talking about the same thing since the first only references the "enclosing clause" while the second references the "enclosing type" in its entirety. I'm _pretty_ sure your first case is therefore only referencing the method type parameters, `W` in the example, which is `^-` because it's the opposite of the enclosing clause, which is `^+` since the clause itself is at the root of a class. If we applied the first case to the example above uniformly to all type parameter clauses and not just to the method type parameters, some of the variance classifications don't line up. Specifically, the second `Cat` type parameters would be exactly opposite of what they are. So actually I think the first case is missing a word in its description and should be "The variance position of a _method_ type parameter. . .". That would fully reconcile the spec with the description in the book and more accurately differentiate between the two cases. I'd love if someone more familiar with the spec could comment here.
With angular, react or something else? 
Yes, transforming all the params into an instance of something to then call a method on. So I'm cooking down all of the different params into something normalized, which will be used as constructor args for a different object.
First of all thanks for your reply. One thing, &gt; The outer Cat classification is ^+, so its type parameters maintain their annotations Do you mean this in a way that, if it was ^- would they swap or something? Because as I understand, they way it works is, for example when you have SomeType[Type1, Type2] the inner positions inherit the variance of the outer position(generally). That is if SomeType[Type1, Type2] as whole is + or - then the inner Type1 and Type2 will have the opposite sign. Now of course depending on the variance annotations of SomeType positions of Type1 and Type2 may change/flip. ------------------------------------------------------------------------------- Now after reading again the rules, I think the difference comes on that the first rule talks about "Type *parameters*" while the second for "Type *arguments*". Meaning that the first one applies more on definitions like meow's [W] or for example on things like an inner generic class, for example: class Outer[A,B] class Inner[C,D] on the C and D position, while the second one, on things like the example from the book. Also one more thing, as English is not my native language translating clause bring up many different words with many different meanings what is *exactly* the meaning of clause under these contexts?
Wouldn't it be more simple to just put the demo on the page instead of having everyone request it?
Ah, I think we're on the same page now!
Everybody edit your build.sbts now and do crosspublish! There is no excuse not to build against 2.11 &amp; 2.12 anymore! : )
word2vec itself is a shallow neural network.
The reason they didn't make it explicit is more likely that Monad is a swear word as far as the majority of Spark developers are concerned: https://github.com/databricks/scala-style-guide#chaining
This is a demo i made for people on Gitter/Twitter that I thought was neat enough to share. Ammonite exposes a lot of its API to you, and you can use it to do a lot of things like swap out the front-end that's taking input for a whole new one, or pass in extra input-filters you can use to implement custom hotkeys. Not many people know about this stuff or use it, but it's there. In this case, it lets you implement a "presentation REPL" entirely in user-land, by substituting in a custom front-end that you can pre-load code strings into, and registering a filter on `" "` that loads the next code-string into the prompt, editable and ready to use, when you press &lt;spacebar&gt;. You should be able to paste this into any Ammonite REPL (or put it in your predef.sc) and have it work without external plugins or anything. All the relevant code is in that snippet, so if you want to change the hotkeys or add additional logic you can do so by tweaking the linked code.
And still no Play version for 2.12
FS2 is not a library for testing code... or prehaps I have been terribly misusing that testing libary :O
You need a version of a library for _any_ version of Scala 2.12.x, so if an author has already published for 2.12.0, there is no need to publish again for 2.12.1, 2.12.2 etc.
How does it compare with Scala.Rx?
Yeah, unfortunate that such a high profile framework is lagging behind mainline Scala. At first it was Play 2.6 will support 2.12, but given that 2.6 release is several months away they've been kind of scrambling to backport 2.12 into 2.5 branch. It's [close now](https://github.com/playframework/playframework/pull/6691) but still not finished. To be fair they've been investing tons of development time into bringing Play Java to parity with Play Scala, an ironic turn of events if you know the history (i.e. original creators of play more or less ditched java in favor of a pure scala based web framework).
Yes, it is, had to quit reading it -- very, very, very distracting.
Let me see what I can do. 
1. Hm it looks like you're adding the akka *source code* to your classpath ... try the one without `-sources` in the name. Artifact naming is confusing, sorry. 2. You really want to be using sbt to do this.
Slick is lagging too? I thought Play was gonna be the only one holding me back...
I'll save you some time since this is what the Ensime people will tell you to do: Go through the troubleshooting guide and do everything it says, no matter how irrelevant it sounds. Then if it still doesn't work open an issue on GitHub. 
I debated that, but since i'm not dealing with the source directly I figured I would have a hard time creating a reasonable issue ticket. They seem to be geared towards issues that result in software tests, and "clicked install on ensime-atom plugin" likely won't cut it for their needs over there. I will go through the troubleshooting guide carefully, but will likely move on with my life after that.
No harm filing a ticket But yes I also gave up.
The program does a mathematical calculation (specifically, it calculates Pi using an infinite series). This can be done using many threads to increase speed. Basically I need to create a bunch of threads that do a specific amount of the work, and then wait for them all to finish and do math with the results. 1. Spawn `n` threads, each doing their own work 2. Wait for them all to finish, collect results 3. Display result to user
No, that's not the issue. The issue for me is that I don't actually know the best way to go about using threads in Scala, since I have barely used it (and, quite frankly, don't particularly like it). If I create a list of Futures, each running their respective operation, how do I then sum up the results of each? I have gotten that much, so far. `val results: List[Future[Double]] = (1 to n) tabulate { /* set up threads */ }` Now, say these have finished their work. How do I go about adding up all of the `Double`s returned by them?
I only have a single _.scala file which could be placed anywhere (e.g. Desktop) - hopefully, that won't be a problem. I will download SBT and try your solution. I will write you when done! Thanks :) 
I guess they're getting closer: http://slick.lightbend.com/news/2016/12/05/slick-3.2.0-M2-released.html But yeah, it's unfortunate that it's lagging so far behind. 
For these small kinds of "Scala scripts" you might wanna check out Ammonite, which allows you to easily import ivy dependencies and even other scala scripts into a scala script, which doesn't even require an object Foo extends App {...} http://www.lihaoyi.com/Ammonite/#ScalaScripts
It has downloaded stuff (e.g. Maven) for 10 minutes but now it is kind of working. [info] Loading project definition from /Users/MYNAME/Documents/Studium/Scala/Actor/project [info] Updating {file:/Users/MYNAME/Documents/Studium/Scala/Actor/project/}actor-build... [info] Resolving org.scala-sbt.ivy#ivy;2.3.0-sbt-2cc8d2761242b072cedb0a04cb39435[info] Resolving org.fusesource.jansi#jansi;1.4 ... [info] Done updating. [info] Set current project to hello_actor_test (in build file:/Users/MYNAME/Documents/Studium/Scala/Actor/) [info] Running HelloActorTest Alive and waiting... I am really sorry to annoy you with that. I am so helpless. How can I "send messages" now? A straight input of "Hello" or smth like that doesn't work? 
You can use `tabulate` as an alternative for constructing a range, it's a member of the companion object on List so you would do: val results: List[Future[Double] = List.tabulate(n) map Future(foo) You probably want to wait for all of those futures to complete, so you can use [sequence](http://www.scala-lang.org/api/current/scala/concurrent/Future$.html#sequence[A,M[X]&lt;:TraversableOnce[X]]\(in:M[scala.concurrent.Future[A]]\)\(implicitcbf:scala.collection.generic.CanBuildFrom[M[scala.concurrent.Future[A]],A,M[A]],implicitexecutor:scala.concurrent.ExecutionContext\):scala.concurrent.Future[M[A]]) to do that: val result = Future[List[Double]] = Future.sequence(results) Now you have a single future that is the result of all other futures joined together.
 Await.result(Future.sequence(results)).sum sequence makes List[Future[Double]] into Future[List[Double]] Await.result waits till its done and unwraps the Future part. sum is self explanatory.
Right; for a task like that you probably want to do a bunch of `val x = Future { ...}`, using `for`/`yield` (and `Future.sequence` etc.) to combine `Future`s / compose successive functions. Then at the end you either `await` your final result future, or do something reactive with it in the UI via `onSuccess`/`onComplete` etc. While you can use a custom execution context to run your tasks on a particular number of threads, the default (which will run one per CPU core or possibly slightly more, I forget the details) is likely best for a CPU-bound task like this. (Also note that often the coordination overhead is higher than the value derived from using threads - if you're doing this seriously then make sure to benchmark a serial implementation too.)
Thanks, your answer in combination with another was very useful :D
Nope, by default there's no logging of every message is done for you. You can define that behaviour in the actor though, like I did in the other example: class HelloActor extends Actor { def receive = LoggingReceive { case any =&gt; println("Received: " + any.toString) } }
Give Scala some time, it may grow on you.
I'd like to help, having once got it to work before with atom, but for some reason having fired up atom for the first time in while, I don't have an `Ensime: Start` command even though the package is up to date with apm. If you have any questions using Ensime using vim or emacs I'd be of more help.
That doesn't sound like the usual experience. I work in a team of about 20 devs, most of whom use intellij with scala, and heavy use of libs like scalaz and shapeless. It certainly shouldn't be indexing every time you start. If you can, its worth using the latest Intellij EAP and scala eap plugin.
Unfortunately, nothing will be printed. :/ [info] Running HelloActorTest Alive and waiting... helloActor ! "test" helloActor ! "nothinghappens" That's why I am wondering as well. 
Have you tried invalidating your caches?
Better yet, I'd suggest: `Future.sequence(results).map(_.sum)`. The type of this expression is `Future[Double]`. In other words, you can use it in combination with other `Future`s and not block `Await`ing the result. Depending on the rest of your program, this can mean the difference between scaling indefinitely and thread-starvation. Generally speaking, avoid `Await`.
ok - definitely not normal behaviour. Its hard to know what to suggest other than reinstall, and deleting all the old config/settings files.
Did you figure it out?
A `Coproduct` is a sum type. It's necessary to encode it, as scalaz and Shapeless do, because pre-Dotty Scala doesn't have sum types. `Codata` is explained pretty well [here](https://github.com/slamdata/matryoshka). The most obvious example of "codata" is an infinite stream: it keeps generating stuff, forever. Unfortunately, none of the streaming APIs I'm familiar with actually models streams that are expected to be infinite as codata and streams that are expected to be finite as data. That's a shame, because often (most of the time, so far) I actually want to model a service as codata, i.e. it's expected to run forever. But with, e.g. scalaz-stream, I have to put some thing at the end of the stream that logs an error, like "You shouldn't be here," or something. It's kind of annoying.
You are correct, 'co' just means, turn the arrows the other way.
What do you get from Coproduct that you don't get from a sealed trait hierarchy? I understand them fine, I just have never run into a reason to use them over the standard sealed trait. 
You can combine multiple free monads with nested coproducts. http://perevillega.com/understanding-free-monads#adding-logs http://degoes.net/articles/modern-fp http://stackoverflow.com/questions/21395407/combining-free-types/21395817#21395817
For Shapeless, I'd take a look at [this table of operations on HLists/records/Coproducts/unions/Tuples/products](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.1.0#operations-on-hlistsrecordscoproductsunionstuplesproducts). Generally speaking, Shapeless uses `Coproduct`s as part of its overall approach to generic representations of types, by which I mean, `Generic` is literally a `Coproduct` of `HList`s, and much of Shapeless' ability to morph among various types is facilitated by this representation. To give a concrete example, I used Shapeless' records to define a bunch of types representing tables in a database. I then defined the `Coproduct` of all of them. I wanted to write a test that would confirm that they are all correctly insertable into the database (i.e. that the Shapeless records and the .sql schema are aligned). So I used [`ToHList`](https://github.com/milessabin/shapeless/blob/shapeless-2.2.5/core/src/main/scala/shapeless/ops/coproduct.scala#L1024-L1028) to get the `HList` of the `Coproduct`'s elements, and used [scalacheck-shapeless](https://github.com/alexarchambault/scalacheck-shapeless) to construct random instances of the `HList` (i.e. random records to insert) and insert them. The only thing that was a bit surprising was that I had to write my own instance of `Arbitrary` for Shapeless' `FieldType` in the version of scalacheck-shapeless that I had to use at the time—more recent versions of scalacheck-shapeless provide such an instance. Anyway, once I did that, I had tests that I don't have to change when I define a new database record type and add it to the `Coproduct`, which is nice. That said, this pushes the machinery for inductive implicit lookup in Shapeless _hard_, and I look forward to Miles completing the work on improving the compile times of that sort of code in the future eagerly.
&gt; I'd advise avoiding akka Could you elaborate on why that is please? Do you mean in general, or just for this use case?
I advise avoiding akka-actor in general. I don't think it offers anything that's remotely worth the cost of losing type safety (their typed offering is immature and they have scrapped previous attempts at the same thing), and I see a lot of people and organisations using akka for no good reason.
Would typed actors resolve these issues then?
Sure, but you can do that with a sealed trait too.
Have you used maven, gradle, ant or any similar tool? The scala community pushes SBT for reasons I've never understood (it's hideously complicated for no good reason as far as I can tell), but all the other JVM build tools work fine with Scala with a little bit of configuration.
What would you suggest instead? Just `Future`s? Spark/Spark Streaming/Flink?
@m50d makes a very experienced suggestion. Futures and Promises are enough for most use cases, and if you want some shared mutable state then an Akka Agent will suffice.
Plain `Future`s for the 99% case where they're adequate. fs2 for the cases where you really do have tricky interlocking resource management. Spark for when you really do need distributed.
We use an internal framework. Which is bad idea. What is avro so great for ? We are always getting problems with it because of schema registry not synchronised. We also hacked it from every part. - We thought indexing in schema registry sucked (one id each time a new subject is created), if the schema is down you lose the index and you can't deserialize the data anymore. So we override it with a map of string -&gt; schema. - We wanted inheritance and found a hacky non useful way to implement it without breaking compatibility with avro. - We don't trust backward compatibility so we don't use it (just add new fileds without deleting previous ones). I don't advice to use avro. If you have any experience using avro, please share it.
I've used it previously with Ruby. It's good because it provides validation, and you can detect that sender and receiver aren't using the same schema. I've used gems to distribute the schemas. I'm not a fan of using a server to serve schemas dynamically except for things that are a general acceptor (i.e. take this stream of things and put it in a table; take this stream of things and transcode it to another format). Because avro is self describing, it's not really necessary either. Avro also has good support in a bunch of systems (e.g. redshift, hive, kafka) which is why of the space of things like it, I choose it. As to inheritance - don't think of inheritance. Use composition in this space.
+1 for avrohugger and avro4s - great libraries I've used both for Akka Persistence: https://github.com/calvinlfer/Akka-Persistence-example-with-Protocol-Buffers-serialization/tree/avro
&gt; At first it was Play 2.6 will support 2.12, but given that 2.6 release is several months away they've been kind of scrambling to backport 2.12 into 2.5 branch. It's close now but still not finished. There's no backport to 2.5.x. That PR is for 2.12 support in Play 2.6.x, the master branch. Source: am committer.
Seriously?? So no 2.12 support until Play 2.6; that's ridiculous if true, Play's the only major project that's lagging behind wrt to 2.12 support.
Play 2.6 is scheduled for Q1 2017 -- please see the roadmap: https://docs.google.com/document/d/11sVi1-REAIDFVHvwBrfRt1uXkBzROHQYgmcZNGJtDnA/pub
Thanks, roadmap looks great (particularly ditching Guice as default DI) but I have to imagine there's going to be some backlash from the community over lack of 2.12 support in 2.5.x There are always delays, Q1 could very well extend into Q2; why not invest the time into 2.12 support for 2.5.x now and then switch gears to 2.6?
Thanks Martin!
I don't get it. Could you please explain, Paul, what the gist does?
Really enjoyed (and learned a lot at) LambdaConf last year, even though I feel my own presentation was a bit of a botch. Definitely recommended!
This seems really exciting! Interesting though that it effectively abstracts over the inputs in the _output_ of the method. Which I suppose is always possible, but it seems a bit counterintuitive in typical usage to complicate the output type this way. Makes me wonder if there's perhaps a way to design a syntax that's as brief, but puts the parameters on the input side, kind of like the context bound syntax. Like maybe `def f1[=&gt;Transactional](x: Int): Int`. Maybe there's a better symbol for it. And really getting out of my depth, but perhaps then you could combine this feature with context bounds, if for some reason you preferred your context bound to desugar to an implicit function instead of an implicit parameter list.
All of the approaches other than `scala.Enumeration` add heavy run-time overhead, due to generating two JVM classes for each enumerated value and three JVM classes for the enumeration itself. For the weekdays example, that means the JVM has to load 17 different classes, whereas the Java equivalent would generate only one. Scala really needs a dedicated `enum` language feature that compiles to Java `enum`s. The extreme inefficiency is just unacceptable.
didn't look through that perspective to be honest. But enumeratum claims to be pretty efficient through some benchmarks: https://github.com/lloydmeta/enumeratum#benchmarking
But unless I'm misstaken, this goes to "solve" verbosity in an example that shows abstracted-over implicit parameters so it misses the point. We need to be able to abstract over implicit parameters for different reasons; are you saying that `dynamically´ solves all of them?
&gt; Interesting though that it effectively abstracts over the inputs in the output of the method. Which I suppose is always possible, but it seems a bit counterintuitive in typical usage to complicate the output type this way. I don't think it is counterintuitive at all. You're expressing in your output, that you have an input that's still unsatisfied.
The article neglects to list the option of simply declaring a Java `Enum`. IME that's the best approach in JVM Scala (which is probably most Scala at present): you get a very lightweight syntax for the declaration, a proper type with no erasure issues, and exhaustiveness checking.
&gt; it effectively abstracts over the inputs in the output there is nothing new there, that has been already possible in scala for ages: type F = Int =&gt; Int def f: F = _ + 1 def g: F = _ * 2 the only novelty is that `implicit` will now be part of the type signature
Anyone here?
seems like the whole repo is gone?
If your enumerations are really there for decisions, they have no methods tied to them, then why not just use Symbols?
I stepped into some solutions using symbols actually, but as far as I know (I think I never used Symbols in my code) they lack several of the properties referred, like exhaustive pattern matching, no?
Need to use math context like: case class Test(value:BigDecimal) object Test { val roundingMode = BigDecimal.RoundingMode.HALF_EVEN val mathContext = new java.math.MathContext(0, java.math.RoundingMode.HALF_EVEN) def withMathContext(value:BigDecimal):Test = { Test( BigDecimal.decimal(value, mathContext).setScale(2, roundingMode) ) } } 
You're right. Weird. Maybe it was moved somewhere else? I'll try to find it again when I am not mobile.
The big difference is that Play isn't a library -- it's a framework. It pulls in and builds on top of a bunch of other libraries. Those libraries are optional -- you can run Play with only Akka, Guice, SLF4J if you're down to the core -- but they still have to all work if people pull them in. The good news is that this isn't a spectator sport -- you can contribute to Play and help get Play 2.6.x out that much faster as a result. Community contributions are always welcome and a key part of ensuring that documentation and use cases get sanity checked.
Yeah, "csv" isn't really a complete format, or you could say it's a family of formats - at that point you just have ask for a more specific, well, specification of what kind of file you're getting. 
But the problem though, the really, really frustrating problem, is that the most used software to generate csv changes behaviour depending on the timezone, the locale, the currency the system is configured for. And, I swear, what it generated the previous time, just to spite coders. It wouldn't be nearly so bad if data science and ml didn't appear to have agreed on csv as the de factor standard... 
just add: ``` resolvers += Resolver.sonatypeRepo("snapshots") ``` to your build.sbt and plugins.sbt
Nah, I tried that first, no luck. (Also play docs provide exactly that string.)
I haven't the faintest of how these would be implemented on the JVM, but Rust/Swift-style enums would be swell. Third-party libraries and sealed trait/abstract class hierarchies are nice, but enough for what (I think) should be a first-class language feature.
What about [this shapeless enum example](https://github.com/milessabin/shapeless/blob/master/examples/src/main/scala/shapeless/examples/enum.scala). It's just a `sealed trait` with`case object`s/`val`s.
No, you're right, it's just Play; Slick has a [2.12 release](https://groups.google.com/forum/#!topic/scalaquery/03Y2_Cs2rIE) now.
No. We are all at the conference, busy with networking and listening to the talks. 
That generates 9 JVM classes: one for `trait WeekDay`, one for `object WeekDay`, and one for each of the instances of `WeekDay`. Same problem. Not as bad as it would be if the values were `object`s, but still bad.
The `throw` keyword provide the same ability to construct arbitary type as `null` ``` lazy val x: X = ???; val y: x.A = 1; val z: String = y ```
I had a great time last year. Love the fact that it's not too big and not too small, most sessions had anywhere from 20 to 60 people so it's easy to go up to the presenters afterwords and start chatting with them. The hallway track is great too, some really amazing off the cuff chat &amp; whiteboarding between various Scala folks. I recommend it. 
It looks like we're both wrong: [Strings are encoded in UTF-16](https://docs.oracle.com/javase/8/docs/api/java/lang/String.html). No argument that the io packages default to the OS encoding for file I/O.
You can definitely build some sort of web app in Scala/Play in one month with your background in Java/Python ... Try to use some sort of eventsourcing, don't do CRUD :-( Also, some of the thing that people talk on this reddit (type level programming etc.) can take years to master.. 
1 month should be plenty to get something working. That's more-or-less how I ended up learning Scala. I spent 3 months instead of 1 month, but part-time instead of full-time, so it's probably a similar amount of time overall. I ended up with a toy photo-sharing website. My advice would be: don't try too hard trying to learn the "fundamentals" of Scala. Pick some dummy Play website, crank on it for the month, and focus on the website you want to build. Feel free to copy-paste code you don't understand, write messy code you're not proud of, and whatever you need to do to get your website working. You'll be forced to pick up some portion of the fundamentals anyway in order to make things work, and learning fundamentals to build something is easier to keep up than learning fundamentals for the sake of learning them
Writing Scala is like performing surgery with scalpel in each hand. You never did it before, there will be lots of blood around till you get hold of it. But still best way to learn it is probably to perform surgeries (so try to build something), and don't be scared of too much blood all over the place. You will figure it out along the way. Come here and ask questions. Or stackoverflow. Or gitter. Go for it :)
that's also the solution I found most pleasant. have you found any problems using it?
I started learning Scala a couple years ago for a new job. Syntax is easy enough to pick up. The real challenge for me was learning to think in the functional paradigm. As u/hyperforce said, You can program in Scala the way you programmed in any other language (I like to say I was "writing C++ with Scala"), but much like Python you get the most out of it when you adapt to its way of doing things.
No, I am right! The link you provided is about the String class, so the **internal** representation of unicode. That defines the code units to be 16 Bit (``Char`` type). The OP has the problem that he have to *decode* the contents of a file from the *correct* encoding. Java assumes here the default encoding of the underlying platform - not UTF-8 in general what you have assumed and I would appreciate. I will provide links if I am in front of a pc. Sucks from Smartfone 😉
First, let me recommend using either the [Scala plugin for IntelliJ](https://confluence.jetbrains.com/display/SCA/Scala+Plugin+for+IntelliJ+IDEA) or the [Scala IDE](http://scala-ide.org/) (for Eclipse) if you don't already. If you install the Scala IDE, be sure to give Eclipse at least 2G of RAM (people always seem to forget this, then complain about the IDE). Second, consider installing [Lightbend Activator](https://www.lightbend.com/activator/download), which gives you access to and dirt-simple installation of a template from which to start your project. I'd then seriously consider using the [Play Scala Seed](http://www.lightbend.com/activator/template/play-scala) template to get you going. Also keep in mind that as far as building goes, this is all centered around a tool called [sbt](http://www.scala-sbt.org/). So you'll need to learn just a bit about it as well. If you use the Activator template, you'll have short-cut quite a bit of that—the project will be set up correctly, package correctly, etc. without you wasting too much time on the aspects of the Play! docs or sbt docs or various plugins etc. so you can concentrate more on what you're building. As others have said, please don't hesitate to bring questions and comments. :-) Hope this helps! **Update:** I always forget: if you use Activator, the `activator` binary _is_ sbt. In other words, you neither get from the installation, nor need to install yourself, "sbt" separately. Just substitute `activator` every time someone says `sbt` as far as the command line goes.
Hi Paul, We've refined the Play seeds so you don't need to download Activator now. There's a packaged version of the scala starter project that includes sbt: https://example.lightbend.com/v1/download/play-scala And you can start the scala seed (which has hello-world and filters but nothing else) using `sbt new`: `sbt new playframework/play-scala-seed.g8` All the projects are available in all their forms from: https://playframework.com/download 
That's great news. Thanks for letting me know!
Really? Is it _that_ much overhead? I don't think I like the idea of a dedicated enum feature. If we can achieve the same with the simple building blocks we already have, ie plain old ADT / sum-types, why introduce a completely new construct? Aren't enums really just a sum type whose leafs don't take parameters (case objects)? I think it's the *perfect* encoding of it. And macros helps you skip the manual boilerplate'y mapping to&amp;from string. Also, to what extent does that overhead you're referring to matter? I don't doubt that it could, but there's probably dozens of others places where Scala's encoding of things to the jvm is very inefficient (ie every closure?). Isn't avoiding ADTs and Enumeratum a little premature optimization? EDIT: What I would like to see though is Enumeratum out-of-the-box so to speak. For instance if scala shipped with a "@enum" annotation that basicly did the exact same thing as enumeratum, that would be super-nice! Enums are so common that you shouldn't need a 3rd party library for it (like Option)
If the "@enum" annotation I described above was added to the language, perhaps Scala could automatically just encode it as a java enum as an optimization, while still _conceptually_ be a ADT / sum-type with case objects? That way, you would avoid introducing a new language keyword while still being optimized for the platform where it matters (JVM (as opposed to native/scalajs)
As others note, it actually sounds perfect. I was just poking around the [gRPC-Java](https://github.com/grpc/grpc-java) site and considering how to make this reasonably nice with [fs2](https://github.com/functional-streams-for-scala/fs2). Might be an interesting weekend project sometime.
I played with that in my implementation. Biggest issue is that the `unapply` method for pattern matching needs to live somewhere, but you also want to avoid the class overhead in simple cases. However, this could be addressed by adding more special-casing in the compiler. In the end I settled with the bring-your-own-syntax approach. So people can add `@enum` and use a Java enum-like syntax or put it on ADT definitions. Both ways keep their respective existing advantages and disadvantages, `@enum` just deals with the necessary rewrites to make things look like valid enums to the JVM.
I recently experimented with ScalaTest async testing. And in my limited testing, it works well, saving a tester from writing a lot of Await.result(future, n seconds) code at the end of every async test method. For an example, see: https://github.com/objektwerks/akka.streams/blob/master/src/test/scala/stream/StreamTest.scala Just envision an Await call at the end of each test method.
Developers are used to asking how something WORKS because that helps them figure out how to USE it. It's just that in this case, SBT works in a complicated way, and so we forget the importance of getting stuff done. I never learned how Maven works, I just followed good examples of how to get stuff done. I doubt you can even easily find documentation on how Maven works - whereas how SBT works is the first thing you find. I'll write an article about this problem of 'how it works' vs 'how to use it' later on. Even the 'how to use it' documentation falls flat on the belly by overloading the reader with too many concepts at once. Which is like trying to solve a multidimensional linear programming problem when you could have intelligently reduced your dimension to 1. In the meanwhile I came up with this article. https://www.scalawilliam.com/essential-sbt/ - Aims to help solve the problem a bit. Comments/feedback much welcome, I'd love to make this a nice useful resource for newcomers. No nonsense, from zero to TDD to Docker.
To me doesn't happen to me as often if I use the 'fork := true'.
Here you are: https://github.com/sbt/sbt-avro/pull/29 And yes, avro4s *looks* great, but as I say did not work for me.
Interesting. Looks similar to the [eff monad](https://github.com/atnos-org/eff). 
Now we need some guidance on why Freedsl vs. eff vs. Freek vs. FreeR vs. ... I will say, it looks like the community has spoken, and monad transformers are dead (or at least dying).
Give a try to Quill or Doobie, depending on your use case. My experiences with Slick were ok-ish. It caused a lot of headaches, but worked. I'm happier with Doobie though.
There are a number of sample Play projects that can do this for you. I'd start with play-isolated-slick project, which will put Slick into the backend and give you Flyway for the evolutions and build on pg-slick: https://github.com/playframework/play-isolated-slick You can also download play-isolated-slick from https://playframework.com/download as an example download and it will come with SBT embedded (rather than doing a git clone, it'll be a zip file). There's a description of how to put Play together with Slick from the backend step by step: http://pedrorijo.com/blog/play-slick/ Also checkout https://github.com/nemoo/play-slick3-example I wrote up a guide to using Play as a REST API that might be useful in general for structuring async code from a persistence backend: https://developer.lightbend.com/guides/play-rest-api/ and Jeff Horton generalized this to a MySQL backend using Play Slick: https://github.com/jeffhorton/play-rest-api-to-db/ If you want to go more advanced, you can use Boilerplay, which puts together Silhouette, Scala.js and postgres-async -- admittedly not react.js and Slick specifically, but it gives you a good idea of the more complex frontends working with Postgres. https://github.com/KyleU/boilerplay Hope that helps! 
As always, let me suggest building your API with [http4s](http://http4s.org) instead, and using [Doobie](https://tpolecat.github.io/doobie-0.3.0/00-index.html) to talk to PostgreSQL. There's a great example of using both [here](https://bitbucket.org/da_terry/scalasyd-doobie-http4s).
If you're referring to the Fork/Join thread pool, it was removed from Scala, it's now implemented in the JRE by oracle.
Have a look at this tutorial, hope it may help you: http://pedrorijo.com/blog/play-slick/
&gt; https://github.com/oedura/scavro - Resulted in unresolved dependencies for me I use this one in our analytics stack. What are the unresolved dependencies? The maintainer of scavro has been responsive in the past. Have you considered opening a github issue?
seconded
I'm very confused about how echoing statements into an SBT file could possibly help anyone use SBT.
Thank you!
Thanks thats _exactly_ what I was looking for
&gt; I need to study them both more closely. Then Eric's recent talk should be of interest for you: [Practical Eff monad for microservices](https://skillsmatter.com/skillscasts/8981-practical-eff-monad-for-microservices).
Appreciate your feedback, thanks.
Appreciate your feedback, thanks. I'll see how to improve it.
I see people criticizing usage of cat/echo/sed. You can understand those commands simply as add this line to this file or this file should look like this etc. For example result of using following two statements for conveying information should be same. echo 'sbt.version=0.13.13' &gt; project/build.properties and Add 'sbt.version=0.13.13' to project/build.properties file. This comes with disadvantage that reader should be familiar with cat/echo/sed and advantage that you can copy paste execute commands on terminal. Both are fairly minor. Advantages of usage of cat/echo/sed for me, personally, are * Easy to read and parse for my brain. Simple, elegant, occupies less storage. * Can still understand task and do it in my own text editor/IDE. * Easy to copy and get required text parts from article. So, personally, I like it. 
If you have specific issues post back, but otherwise it should be as simple as following the documentation. https://www.scala-lang.org/download/install.html
Shapeless uses a more powerful version of them, if I remember correctly. 
&gt; is anyone really using Symbols? No, at least not me, and I haven't seen it anywhere except perhaps in the Scala compiler. The single tick syntax is bad and not supported by many lexers and syntax highlighters, I don't see any real advantage over String. Should be removed IMO.
This is really nice. I actually like how it works entirely from the command line, so people don't have to worry about getting an IDE set up (which is pretty non-trivial for Scala.) It goes through a lot of use cases, which makes it relatively easy for people to get a broad overview and pursue other sources for depth if they want to, later. Plus it's really easy to scan and find things you didn't know–for example, I didn't realize how easy it was to dockerize an app and run it.
I use them all the time for singleton typed string literals. Their original purpose, creating an string interned by the compiler, isn't of that much use, the JVM won't allocate multiple instances of equal strings.
A lot of DSLs use them. json-lenses for spray-json uses them https://github.com/jrudolph/json-lenses
&gt; which is pretty non-trivial for Scala How is it non-trivial for scala?
I've seen ~10 newcomers to Scala, most of whom were moderately to very experienced devs, try to set up IntelliJ and SBT. In each case, it took them several days to get everything up and running correctly. Part of this seems to be poor documentation (especially with SBT), part of this seems to be weird bugs in Intellij that can screw up syntax highlighting for no discernible reason. (Other programming languages might be equally bad, I don't really have the experience to tell.)
Absurdly easy - actually just install sbt and that will get all the bits you need, assuming you already have the jdk. 
As far as _what_ goes, check out [eventuate](http://rbmhtechnology.github.io/eventuate/).
Care to elaborate?
My complaint is that this pattern seems to require wrapping every output type of every method where you apply it. This seems like it distracts from what the method _actually_ returns when called in practice, with the implicit value(s) applied.
Previously discussed here: https://www.reddit.com/r/scala/comments/565ncn/the_rise_and_fall_of_scala_dzone_java/
or `.futureValue`, `whenReady` (from `ScalaFutures`)
Agreed. I enjoyed this tremendously and, being a math guy, everything seemed to like up. Though I'm technically an algebraist, not a category theorist. ;-) 
&gt; Why there is no Domain Driven framework available for Scala/Java? It's a good question -- the general answer is that domain driven frameworks, by their nature, are driven by the domain in question, and so I think it's hard to build something generic that is outside of that domain. What you end up with is the utilities -- the persistence, resource lookup, recovery and consistency management. [Lagom](http://www.lagomframework.com/documentation/1.2.x/java/WhatIsLagom.html) is the Lightbend implementation of those utilities, written for Java and Scala using CQRS / ES -- however, it does not handle the domain directly, as you still have to put together the ubiquitous language yourself. Here's the classic DDD cargo tracker in Lagom, for example: https://github.com/lagom/activator-lagom-cargotracker
Yes, Scala macros are weird and hard. I think I had seen a presentation where somebody who worked on the compiler said that they basically just exposed some of the compiler's internal state, and he didn't seem convinced that it would go very well. I think `scala.meta` is a reaction to the current state of macros. I haven't yet used `scala.meta`, but if the macro paradise is causing headaches, it's probably worth trying. As for your specific problem, for the small amount of macro work I've done, I try to fully qualify all class names including the `_root_` prefix. You could see if that helps.
Guessing from your requirements you might be able to use the shapeless library for what you need to do, however it depends on what exactly you wanna do and how it will be used. However, if you *can* do it with shapeless, I would strongly suggest to try it! Can you provide an example of a java class / POJO and the case class that you want to have generated from it?
&gt; For example Monad has to obey these three monadic laws, and Monoid has some laws of his own(just as a Functor does). You may treat this as a homework, to prove if they hold :) I've seen three or four variants of this post, none of which ever manage to prove the laws, at least not in both directions. They all "leave it as an exercise". One direction is easy, but the other seems to need some extra non-obvious assumptions - I saw someone try and point this out, and I hit the same issue myself. At this point I no longer believe the claim. Monads aren't actually just monoids in the category of endofuctors. If you think they are, prove the laws.
I think no-one's bothered to write it. It's a shame. You could do it all in code with Shapeless or similar - write your domain objects as case classes, derive the database definitions in terms of doobie or similar, the json protocol using spray-json-shapeless and the HTTP routes in terms of http4s or some such. All the pieces exist, so it really should be a one-liner. But no-one seems to have quite put it together.
If you are doing a blocking call inside an actor, one option is to wrap the call in a Future with a different executor and then pipe the result to the actor.
Ah I see, yeah I can agree with that. Then again, this solution is nice in that it solves the problem in the "Scala" way, which is elegant in terms of consistency. There isn't anything special about implicit function types, the main difference is that you can use `implicit` in type aliases
Check this http://reactore.com/repository-patterngeneric-dao-implementation-in-scala-using-slick-3/ 
Alternatively, you can put the actor itself on another dispatcher instead of using the default dispatcher 
I'm not sure what you mean by "both directions" here.
The two directions are proving that the output of `fromMonoidToMonad` obeys the monad laws provided that its input obeys the monoid laws (in the appropriate category), and proving that the output of `fromMonadToMonoid` obeys the monoid laws provided that its input obeys the monad laws.
I don't know about the article being referred to, but does [this](http://stackoverflow.com/a/3870310/5431135) work? It seems to me you just replace "Hask" with "Scal."
That defines the monad laws in a non-standard way to match the monoid laws, and in any case doesn't bother to actually prove the equivalence.
Well, it's a sketch. It sounds like you really do want to go all the way back to Mac Lane. Which is fine, but I don't think even most people who care so much about the subject need to carry it that far.
There was someone on this subreddit a few months ago trying it and hitting the problem - wish I could find the link. It's the fact that there are several posts covering exactly this part and none actually covering the laws that bothers me.
Blocking is a hint to the executioncontext that you will be blocking. It can then, if necessary, start another thread. This prevents deadlocks if all the threads managed by the EC are busy and end up waiting for each other. However not all implementations will do this, and I believe the default one will eventually reach a max number of threads. The Monix library has a cancellable Task with timeout that avoids this problem. 
I've never found much use for property-based testing - it seems to me that any property you can formalize well enough to use it with is probably one that you should prove directly in the type system. But certainly testing is better than nothing.
&gt; Should be removed IMO. I agree -- every language feature has to carry its own weight, and I haven't seen anything that makes them that more compelling than Strings. Scala is already a complex enough language.
Scala's type system isn't expressive enough to prove the monad laws hold. Neither is Haskell's. You can do it with [Coq](https://coq.inria.fr/cocorico/AUGER_Monad), though, and even go [farther](https://www.irif.fr/~sozeau/repos/coq/misc/shiftreset/GenuineShiftReset.html).
Which is something I now regret. I should have used Strings and will most likely switch to that in shapeless 3.0 or possibly before.
Ah...but all the libraries for scala that do that choke on my perfectly valid avro. 
I think fixing those libraries will be a better path in the long run than macros.
Can confirm. I'm a new Scala dev joining an existing Scala team. 
&gt; I use them all the time for singleton typed string literals. Could you expand on what you mean by that?
&gt; So in cases where this is the meaning you want, that's when you use Symbol. What advantage do you get from this?
We've used Slick in a major project, and I've got mixed feelings. It's really impressive in its design. But it can also be quite cumbersome and the learning curve is steep, if you're not accustomed to working in I/O monads. I particularly dislike working in tuples all over the place when I used joins. I recommend giving it a shot, especially if your needs are relatively simple.
I think many people/companies use Actors without giving any thought about why. A client I am working with right now uses actors throughout their code base and even sending dozens of messages to different actors within an actor's `receive`. They are basically using actors like they are simple method calls. I can't imagine how the app will stand up under any serious load. 
Ah I see. I will try that. 
What makes you regret it?
I mean that's all your opinion, so stating it as though it is fact is very arrogant and reflects very poorly on the /r/scala community. And I am sure many of the people on this sub aren't all that bad.
&gt; Scala's type system isn't expressive enough to prove the monad laws hold. Isn't it? We have generics, we have virtual functions, we even have dependent types (via a clunkier encoding than some languages, but we have them) - what part is missing that you would need to encode this kind of proof?
I can't tell you what the point is. You have to decide that for yourself.
How would you derive classes to Slick entities with shapeless?
following your and others feedback I decided to include some more information on a follow up: http://pedrorijo.com/blog/scala-enums-part2/ your feedback is very welcome :) 
Seems like when you want to build stuff with location transparency, atomicity by default, and a concept of lightweight workers that actors are a good choice. I'd say avoid actors unless you really really know that you need them.