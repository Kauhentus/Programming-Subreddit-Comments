Is there a `val`missing in the parameter lists for classes?
This actually has a pretty simple solution: You want to record every the first derivative of the signal changes sign. To measure the peak to trough height, you need to know both the minimum and the maximum. To know where the peaks are, you just need to know it's a maximum, which is just anywhere the data goes from increasing to decreasing. I think you should be able to do this with something like a simple fold operation or a foreach and a little bit of state. 
The peak measurement is simple enough as you say, what I'm struggling to understand is how I can start to "record" the data of a potential peak, but after a specified number of max samples bail out and send the data as a "drift" value rather than the peak itself. So if the data stream comes in, the program monitors for samples exceeding the threshold. Once it is found, it starts to take that data as a possible peak. If the samples drop below the threshold again within a maximum window size then that is a peak and it is sent along for further processing. Otherwise if the samples stay high then the "peak" is discarded and a drift value is sent along to another function. I understand I will have to split the streams, but I am just having trouble thinking of how to implement this kind of thing. I can't think of another "generic" example to look at to adapt.
Noticed the benchmark was old. updated one here for json serialization https://www.techempower.com/benchmarks/#section=data-r14&amp;hw=ph&amp;test=json&amp;l=8vmtxb Also the test was for `{"message":"Hello, World!"}` i wonder if it makes difference for more complex json ? Also are they using the default's?. Would akka htttp be faster for json using protobuf.? 
Personally I find all the Scala testing frameworks overcomplicated and stick to plain JUnit. If you find you're getting value from something fancy then by all means use it, but don't feel like you have to, and particularly when you're getting started it can be a good idea to stick with something you're familiar with.
You can dynamically access a field of a class instance by its name via reflection, but I don't think you can access a local variable by name like that. But why do you even need something like that? It sounds like you want something like a Map.
Good catch, the plain adapter needs a val to access the `base` at the end. Fixed.
I am already trying out Reason/OCaml and the build times are freaking insane, and the tooling support in VSCode is also ridiculous compared to Scala (instant auto complete, no typing errors, just works out of the box)
I have and they have actually solved an issue quite recently, its actually surprising but submitting bug reports does have an impact!
I don't think comparing Scala and languages like C/C++ is useful. You don't solve problems with Scala that you would normally solve with C++, and those problems are quite naturally harder to get right because you can't afford the safety net of a managed and highly abstracted language due to performance and/or memory constraints.
sbt already runs test classes in parallel (unless you've disabled that) but there is the ParallelTestExecution in scalatest (http://doc.scalatest.org/3.0.0/index.html#org.scalatest.ParallelTestExecution) that can run tests inside each class in parallel. Read its documentation though as it's creates a new instance for each test. To be honest though, 4 minutes is on a fast side for a medium sized scala project.
You cannot do this in general, and in cases where you can you shouldn't. Programs should be invariant under rename refactoring and this kind of thing breaks that invariant. What are you trying to do?
I created an issue for a case like that, and they "fixed" it by not colouring any calls like that red even when there is an actual error.
This should do something like that. Given a List[Future[_]] get a Future[List[_]] with only the successes: Future.sequence(futures.map { _.transform { case Success(s) =&gt; Try(Some(s)) case Failure(_) =&gt; Try(None) } }).map(_.flatten) 
Which did you try so far?
Nothing :-)
I am confused as to what you’re asking. There is a Producer API from Apache, do you want something that wraps around that?
Could you please provide me the link. THanks
I suggest you use the cats testkit since http4s pulls in cats anyway. This pulls in scalacheck and scalatest and sets up a bunch of reasonable defaults for you. Unfortunately you kind of have to dig to figure out how to use it.
Username checks 
There are connectors for [monix](https://github.com/monix/monix-kafka), [fs2](https://github.com/Spinoco/fs2-kafka) and [Akka Streams](https://github.com/akka/reactive-kafka) Those are for respective streams, can't tell if that's useful to you or not
dude can you do some googling yourself pls? when u get stuck, then post here with more details.
So this is the link to their Javadoc: http://kafka.apache.org/0110/javadoc/index.html?org/apache/kafka/clients/producer/KafkaProducer.html They have a brief example there on how to use it. When I first got my feet wet in Kafka, I used this example code: https://github.com/mapr-demos/kafka-sample-programs MapR does a great job in their ReadMe for how to get it running! 
Here you go https://typelevel.org/cats/typeclasses/lawtesting.html This is just about law testing but you can also write normal tests here. See the other cats tests for examples.
&gt; Slick (somewhat reluctantly) Why the reluctance, and what are your thoughts on Quill?
Put them in src/main/scala 
Yes but i have other modules in the same project. How do i do a multi module project? 
Could you share your files on GitHub or somewhere, so we can have a look and see what’s wrong?
https://github.com/jacktri/StockTrader
&gt; How do i do a multi module project? http://lmgtfy.com/?q=sbt+multi-project
Electron? Really? It's not just not native but most applications developed with it end up being bloated and have terrible performance and latency. Also, if not native why not just recommend [scalafx](http://www.scalafx.org/)?
I don't think there will be one. Cpp is not compatible with most languages and that's why bindings are needed for it. GTK+ can be easier to connect but is harder to use. There is also [nuklear](https://github.com/vurtun/nuklear) - if I'd want scala native to have a nice GUI library I'd go with that.
Never seen Scalafx before thanks for pointing it out. Why Electron? Well firstly I don't care much about bloat. As for performance millions of users don't seem to have a problem with Slack, Atom and Discord. Personally I'd rather use Electron and take advantage of being able to build essentially a web app since I already have those skills, than spend time learning a Java library.
Now home with my laptop. Can't find my GitHub password, so have a diff instead of a pull request. This is set up so you can use Authenticator from Trading, but you can't use Trading from Authenticator. diff --git a/Trading/src/main/scala/com/jack/Trading.scala b/Trading/src/main/scala/com/jack/Trading.scala index 170b1c7..d4ada92 100644 --- a/Trading/src/main/scala/com/jack/Trading.scala +++ b/Trading/src/main/scala/com/jack/Trading.scala @@ -1,9 +1,7 @@ -package main.scala.com.jack +package com.jack object Trading { - def main(args: Array[String]): Unit = { - println("Hello, world!") - } + def main(args: Array[String]): Unit = Authenticator.main(args) } diff --git a/build.sbt b/build.sbt index fc99730..32dd882 100644 --- a/build.sbt +++ b/build.sbt @@ -3,4 +3,11 @@ name := "StockTrader2" version := "0.1" scalaVersion := "2.12.4" - \ No newline at end of file + +lazy val Authenticator = project.in(file("Authenticator")) + +lazy val Trading = project.in(file("Trading")) + .dependsOn(Authenticator) + +lazy val root = project.in(file(".")) + .aggregate(Authenticator, Trading) 
You need to use .dependsOn and .aggregate() to put your projects together. See https://github.com/playframework/play-scala-isolated-slick-example/blob/2.6.x/build.sbt as an example.
&gt; Why Electron? Well firstly I don't care much about bloat. We - average people - do. Average desktop users only have around 4gb of RAM and most of it will be drained by chrome. Average developers have like 8-16gb of RAM. No need to sacrifice it for nothing when there are other *important* applications which have higher needs. &gt; As for performance millions of users don't seem to have a problem with Slack, Atom and Discord. Are you serious? Both slack and atom are despised and everyone on every forum I've seen so far is complaining about them. Btw, don't you find it ridiculous that atom with a few plugins consumes more ram than intellij while having worse typing latency? &gt; Personally I'd rather use Electron and take advantage of being able to build essentially a web app since I already have those skills, than spend time learning a Java library. So, are you telling me that you'd rather make your users' lives worse because you're too lazy to learn how to use a GUI? Quality is more important than webdevs' comfort.
Never heard of nuklear before, thanks!
Constructor parameters are not vals by default. You can either add the `val` keyword before each parameter for them to be accessible, or declare the class as a `case class`. Case classes have constructor parameters as fields by default, amongst other things. You are right however about t4 having type IntSet instead of NonEmpty. That being said, a non-empty set will stay non empty after incl or union. You can override the return type of both methods in NonEmpty to propagate the non-emptiness to t4.
I'm trying to get Scala set up for a Coursera course on Ubuntu, and I've followed their instructions by installing open-jdk 1.8, sbt (sbt about says v1.0.2), and IntelliJ Idea. I've set up an sbt project with a HelloWorld Scala worksheet in src/main/scala that just says "Hello, world", but when I try to evaluate the worksheet, I get the error &gt; Internal error: Scala instance doesn't exist or is invalid: version unknown, library jar: /home/&lt;my username&gt;/.ivy2/cache/jline/jline/jars/jline-2.14.5.jar, compiler jar: /home/&lt;my username&gt;/.ivy2/cache/org.scala-lang.modules/scala-xml_2.12/bundles/scala-xml_2.12-1.0.6.jar followed by a lot of other lines. Is there a setup step I'm missing? The project seems to point to Java v1.8 in the Project Structure dependencies.
&gt; Let's wait and see, it's substantially worse in some regards and fails to address some of the pressing issues we will face in the near future. Which problems does dotty not address? Or is it basically stuff you didn't mention?
1. First verify that your projects compile correctly with SBT on the command line. Make sure the project compiles and the modules see each other as you expect them. 2. **Downgrade your IntelliJ plugin to version 2017.2.7.** See [this bug](https://youtrack.jetbrains.com/issue/SCL-12702) for more information. In short, it is currently not possible to import SBT project into IntelliJ.
The amount of language additions, new keyword proposals etc. makes it way bigger than Scala 2, and the approach of extending the language for every tiny issue is slowly approaching C++' level of language design quality. That's just one of the issues, not even touching the poor quality of the language additions itself. Not addressing the issues Scala has with its collections API is probably one of the larger problems that should have been fixed, instead of trying to invent more reasons for new keywords ... Plenty of other things too. Development of Scala/Dotty has become too disorganized to retain any kind of quality standards we previously had.
The amount of language additions, new keyword proposals etc. makes it way bigger than Scala 2, and the approach of extending the language for every tiny issue is slowly approaching C++' level of language design quality. That's just one of the issues, not even touching the poor quality of the language additions itself. Not addressing the issues Scala has with its collections API is probably one of the larger problems that should have been fixed, instead of trying to invent more reasons for new keywords ... Plenty of other things too. Development of Scala/Dotty has become too disorganized to retain any kind of quality standards we previously had.
Whatever you choose, I suggest test thoroughly. Writing well-behaving Kafka consumer is no simple. We did it manually and it took us long time to handle all corner cases (topic pause/resume, overflow, sudden cluster restart, error handling...)
I'm having issues understanding why akka backpressure kicks in when I'm reading an endless http stream. Here is my question on stack if anybody has some ideas: https://stackoverflow.com/questions/46868519
Consider carefully if zookeeper is the right solution for you if you want to use it for service discovery. Zookeeper is consistent in face of network partitions, for service discovery you usually want something available. You might be better off with something like Consul. 
AFAIK the macro paradise plugin (the thing that allows us to run macros and macro annotations) runs straight after the parser (before the namer and typer). Alternative? You could write your own compiler plugin and run it after the typer. Not sure it's worth the pain though.
Why when I use Kafka I have to use Zookeeper? How they connected to each other? 
Those two are basically married. Much of the partition metadata is saved in zookeeper. At this point I believe it's a requirement. 
Thanks for the response! I see that including the &gt; val keyword works and now the field is accessible. Given that incl and contains as implemented work is it fair to assume that constructor ensures that elem is a created as a private field (even though this is not a case class as defined)?
Have you ever thought of just taking some time and reading through documentation? In all of your posts you have showed absolutely no effort of trying to solve things on your own. You expect someone to give you a detailed step by step guide to achieve what you want but that's never going to happen.
If you want something that's built for microservices explicitly, then use Lagom and use Kafka for the message broker API. Leveraging Lagom will mean you only have to go with what's provided and don't have to build up the theory from scratch.
Semantically, the constructor parameters are available in the whole class body, but are not private fields of the instance. However, they are indeed implemented as private fields, but they are not available at the language level. ``` class Foo(bar: String) { def print(other: Foo): Unit = println(other.bar) } ``` Doesn't compile: `not found: type Bar` On the other hand, a `private val` is accessible from another instance of the same class. ``` class Foo(private val bar: String) { def print(other: Foo): Unit = println(other.bar) } ``` This version compiles just fine.
I have already read plenty of doc and blogs but wanted to know, your experiences with microservices.
Zookeeper is a requirement for Kafka. You can't just switch it out for Consul.
I think the OP wants to use zookeeper for service discovery of the OPs services, not for Kafka’s uses.
If your tech stack contains ZK already (as dictated by kafka), and if you can make it sufficiently suitable to your needs, there is no reason to add another moving part.
Did I say otherwise?
Correct. Zookeeper is required in order for Kafka to function.
If I would use kafka, do I need http rest? The communication between microservices will be over event bus via messenger, then http rest would be unnecessary ? 
Another alternative, which might or might not work for you, is to make the macro annotation generate calls to a proper macro def. The macro def will execute later, once some of the type checking has already been done. As an example, you can transform something like: @myannot class A { def foo(x:X):Y } into something like: class A { def foo(x:X):Y = myMacro(...) } and then into: class A { def foo(x:X):Y = { ... } } 
Great work!
Hope this helps: https://finagle.github.io/finch/user-guide.html#params If you think there's anything missing in the docs just feel free to open an issue (or even better - submit a PR).
Thanks!
Have you read "Programming in Scala, 3rd edition"? Excellent resource and it definitely gives the fundamentals (w/o concentrating on particular libraries).
I get how defining a Param works, but I can't find any example of using it with an endpoint or acting on the result
There are some examples in the cookbook (https://finagle.github.io/finch/cookbook.html#defining-custom-endpoints). Try searching for `param`.
Sadly finch doesn't have as good docs or user support as, say, Akka Http. This makes it difficult to create anything of value using Finch. At least from my experience
&gt; IntelliJ seems incapable of resolving many of our implicit conversions There is a setting for how deeply it searches for implicits, raising it usually fixes those issues... at the cost of editor performance/responsiveness. Also from my experience if an implicit conversion chain is too hard for an IDE to understand, it's also very likely too hard for a human to REALLY understand and should probably be simplified and/or made more explicit. 
Hey there, I have never encountered that error, but here is how i set up my scala envirement. Intellij and the scala plugin comes with its own Scala and sbt. so if you plan on only using Intellij you do not need to install anything else. If you want to use sbt in your project make sure to create a new sbt project and not a scala projet. to get the scala runtime, compiler and repel as command lines go [here](https://scala-lang.org/download/all.html), choose the scala version you want and download .deb installer, and install that. to install sbt use follow this page http://www.scala-sbt.org/0.13/docs/Installing-sbt-on-Linux.html 
It's the update from sbt that caused this. You probably updated sbt-scalajs at the same time. That's what caused the deprecation warnings to appear. See the release notes at https://www.scala-js.org/news/2017/09/01/announcing-scalajs-0.6.20/ Now, the "bad option" error you get is most likely because you added that option *also for JVM projects* in the same build. That's wrong, because JVM projects don't understand that option. You need to make sure that the option is only applied to Scala.js projects. If you have `crossProject`s, for example, make sure to put that setting only in `.jsSettings(scalacOptions += "-P:scalajs:sjsDefinedByDefault")`.
Maybe just build it if you find it that you need it. I don't think anyone's going to be able to tell you one way or another who isn't familiar with your project. I will say though that every system I've ever built has benefited from having HTTP endpoints solely for administration and debugging. 
Interesting point! 
If you don't want to spend too much time you can always go for "Scala for the Impatient 2nd edition".
Proper row polymorphism (like in [Purescript](https://leanpub.com/purescript/read#leanpub-auto-record-patterns-and-row-polymorphism) for example) that worked on both case classes and structural types would be nice to have in Scala. It could replace macros in many cases.
Have you looked at utest? It seems quite reasonable
 paramOption ("foo") In an endpoint, you add it to your lust of parameters
I'm aware of it, haven't tried it. I agree with almost everything lihaoyi wrote about testing, but fundamentally utest is still a macro that I don't think I would get enough value out of to justify using. (Also my IDE already has JUnit integration).
It's in the sbt.bat script in C:\Users\me\.sbt\preloaded\org.scala-sbt\sbt\1.0.2 Can't remember if it is at the top level our in bin. Something somewhere put quotes around the version. 
No .bat file in either. 
Even microservice advocates largely recommend [starting without microservices](https://martinfowler.com/bliki/MonolithFirst.html). I think this is especially true in Scala, because microservices solve an isolation problem that you don't have in Scala, and a scaling problem that you won't have in Scala until later than you would have it in a scripting language. You don't need a http server or anything until you do. Find an actual problem and start solving it. When you start to have trouble scaling, then you can start worrying about the architectural things that companies with billions of users are doing. But the most important thing is to build a small piece that does something useful first. &gt; A complex system that works is invariably found to have evolved from a simple system that worked. The inverse proposition also appears to be true: A complex system designed from scratch never works and cannot be made to work. You have to start over, beginning with a working simple system.
Right, but ZK is fundamentally unsuited to service discovery, because it's consistent rather than available. So it's unlikely it will be sufficiently suitable for those needs.
My experiences with microservices are that should avoid them if have any choice whatsoever. Especially in the context of a nice statically typed language like scala, since the more you microservice your solution the less help the compiler can likely give you about your pieces being connected correctly.
found the a sbt.bat file in C:\Program Files (x86)\sbt\bin, the quotation marks are gone and the path is correct but problem is still there. &gt;...&gt; sbt &gt;Error: Unable to access jarfile Copying runtime jar. The filename, directory name, or volume label syntax is incorrect. Error: Unable to access jarfile "C:\Users\me\\.sbt\preloaded\org.scala-sbt\sbt\1.0.2\jars\sbt.jar" Java HotSpot(TM) 64-Bit Server VM warning: Ignoring option MaxPermSize; support was removed in 8.0 [warn] No sbt.version set in project/build.properties, base directory: C:\some\sbttest [info] Set current project to sbttest (in build file:/C:/some/sbttest/) [info] sbt server started at 127.0.0.1:4782 
Curator has a discovery recipe lib that I believe caches the state of ZooKeeper on connection loss. It's not ideal, I agree, but for many uses ZooKeeper is a great all-purpose coordination service.
What are the entry points to your system? How does data enter your system and how does it leave? If you're building a system that is primarily CRUD, you may be over-engineering it from the start. 
ZooKeeper is an interprocess coordination system. Kafka internally uses ZooKeeper to keep track of partition assignments and replication state.
Wow it's pretty cheap too. I know it's written by Odersky, but do you think it would be better than [the free Underscore](https://underscore.io/training/) book?
Scalastyle is a style checker that's mostly subsumed by [WartRemover](http://www.wartremover.org/) and [compiler flags](http://tpolecat.github.io/2017/04/25/scalac-flags.html), but it can still be helpful to check method length, capitalization rules, and things like that. Scalafmt is the code formatter you want to use. 
Thanks for the suggestion.
I got the same error in IntelliJ when I upgraded from Scala 2.12.3 to 2.12.4, or possibly because of a Scala plugin update. Try changing to Scala 2.12.3 and reimporting your sbt-project
it looks like it started sbt. Have you tried sbt new in that directory yet? It may actually be working. If you set a sbtVersion in project/build.propeerties, it may just work, ddespite the error lines. In the script, the error and copying lines are separate: if not exist "%java9_rt%" ( echo Copying runtime jar. mkdir "%java9_ext%" "%_JAVACMD%" %_JAVA_OPTS% %SBT_OPTS% -jar "%rtexport%" "%java9_rt%" ) set _JAVA_OPTS=!_JAVA_OPTS! -Dscala.ext.dirs="%java9_ext%" As for fixing the error, I'd go to the sbt gitter chat and ask about this. Does that file (C:\Users\me\.sbt\preloaded\org.scala-sbt\sbt\1.0.2\jars\sbt.jar) exist? I typically run sbt on windows from git-bash, and know that there have been some problems with minGW. Might want to try that.
what do you mean by "branching out to cover platforms other than java"? im new to the language.
As you can imagine it's pretty hard (yet possible) to compete with Akka's documentation for a variety of reasons (think of people getting paid to write those docs). If there is any particular piece of Finch's docs that are incomplete/missing/misleading, feel free to point it out in the [Gitter channel](https://gitter.im/finagle/finch) - there are people who are willing to volunteer their personal time to make it better.
[removed]
Scala is no longer JVM-only: it runs in the browser and Node.js (or any JavaScript environment) with [Scala.js](https://www.scala-js.org/), and can also produce native executables on multiple platforms with [Scala Native](http://www.scala-native.org/en/latest/). These new targets are completely independent from the JVM.
We used Scalariform for a while, but then switched to ScalaFmt since it supports 2.12. Our needs were pretty simple - just formatting strings containing Scala code - so the APIs were pretty identical (`String =&gt; String`, basically). For more complex things, the APIs are likely different, but I suspect for most projects, 2.12 support will be the deciding factor.
I can only say positive things about the underscore stuff since you are looking for web-development, go for essential play
Scala.js compiled to JavaScript and scala-native compiled to native code via LLVM, though with varying levels of coverage of the JVM Scala'a features.
Scala can be cross-compiled to [JavaScript](https://www.scala-js.org/) and [native binaries](http://www.scala-native.org/en/latest/) (using [Scala Native]). While Scala Native is still in its experimental phase, Scala.js has been quite stable for some time and is preparing for its 1.0 release. The scala.* package root (except the `reflect` package) are generally well supported by these "alternative" platforms or pending implementation, but it doesn't cover basic things like I/O. To overcome this the authors of for instance Scala Native implements façades for things like `java.io.InputStream`, but they have to do it under the java. package root as this is what Scala utilises under the hood. Aside from superficially weird looking imports in an application not targeting a JVM, it also means that there is no way for a host platform to offer a compliance guarantee, as even a very basic application interacts with the java.* namespace
Thanks for the info! I wonder why this is being done? I don't know if it is completely analagous but python has a bunch of implementations, like jython, ironpython etc. but they can be a real pain in the neck because they are behind the standard cpython so running python code with a different interpreter is often not as simple as just using the different interpreter! Libraries will be missing and there will be special platform-specific syntax that doesn't work with all interpreters. I just glanced at Scala native and it has low level primitives like pointers and c arrays and I think as soon as you start using those your "Scala code" might become "Scala+ code" and it loses portability. Do you all see this move to multiple platforms as being reasonable as you might lose many libraries and also lose portability? Is there any chance that competing standards will weaken the community, or will it make people happy by providing more options? Will peoples familiarity with the jvm scala doom the other implementations, kind of like jython? ( the last jython release was in 2015 for python 2.7, but now the "standard python" is already at 3.6! I don't know if it's dead but it is at least lacking alot of functionality and it is way behind).
&gt; my impression is that there are already a million different front end tools, I don't know why there ought to be another one. Well, the reason I'm here is that I think Scala's the best language going. And even if it might not be your first choice on the front end, if it's your first choice on the back end then there's an argument that being able to share code between the two is better than having to duplicate things between two languages. &gt; For server/desktop applications, do you think Scala Native is needed? Some people think they need more precise control over memory layout and/or GC pauses than is possible on the JVM. I am... dubious that these requirements are anywhere near as real as people think they are, but if people think they need it and they're willing to work on it in Scala then why not? &gt; I don't know if it is completely analagous but python has a bunch of implementations, like jython, ironpython etc. but they can be a real pain in the neck because they are behind the standard cpython so running python code with a different interpreter is often not as simple as just using the different interpreter! Libraries will be missing and there will be special platform-specific syntax that doesn't work with all interpreters. I just glanced at Scala native and it has low level primitives like pointers and c arrays and I think as soon as you start using those your "Scala code" might become "Scala+ code" and it loses portability. There's tighter integration between the implementations in Scala-land, so I think this is likely to be less of an issue. We also have a better-coordinated packaging/publishing situation, where all the libraries are built in the same place and follow the same standards and it's clearer which libraries support which platforms. So I think/hope we can avoid some of the pitfalls Python has hit. &gt; Do you all see this move to multiple platforms as being reasonable as you might lose many libraries and also lose portability? Is there any chance that competing standards will weaken the community, or will it make people happy by providing more options? Will peoples familiarity with the jvm scala doom the other implementations, kind of like jython? ( the last jython release was in 2015 for python 2.7, but now the "standard python" is already at 3.6! I don't know if it's dead but it is at least lacking alot of functionality and it is way behind). I think it's very unlikely it would harm JVM Scala directly, though I'm slightly worried about the impact on the tool ecosystem (I can't stand SBT but a lot of things seem to be being more SBT-oriented lately, and I think part of that is that the Scala.js/Scala native cross-build toolchain only exists for SBT). If there are people who find these things useful, let them work on them; if not, they'll die. I get the sense that Scala.js is established enough that it will sustain itself for the forseeable future; I'm less confident about Scala native.
&gt; though with varying levels of coverage of the JVM Scala'a features. Both Scala.js and Scala Native support 100% of the Scala language features. What might not be supported is all the Java *libraries*. (hence, the OP's proposal, I guess)
thanks for guving such a thoughtful answer to a somewhat silly question
Your guess is accurate :) While I've had some issues with platform incompatibility between Scala/Scala.js due to linking I don't know how much of a problem this poses when implementing a new backend; perhaps it's not a big problem? 
Bit topic here. Just one person's opinion: &gt; why this is being done For Scala.js, it's pretty clear: - We need better than JavaScript on the browser. - As is the case with Node.js, so-called isomorphism (using the same language on the client and on the server) has benefits. In particular if you have a lot of existing pure Scala code you can reuse on the client; you can share case classes, data models in general, and algorithms. (As an aside Scala.js interop with JavaScript is amazing.) For Scala Native: - This enables fast-starting command-line tools. - There is a potential (as of yet unrealized) for more efficient iOS and desktop apps that do not require the overhead of a VM. - There is potential for a faster (or at least faster-starting) Scala compiler (I heard that prototyping of this has happened). In both cases, I think that it is a good idea to try to be less dependent on a single-vendor product (the Java Virtual Machine and its SDK). &gt; they are behind the standard cpython so running python code with a different interpreter is often not as simple as just using the different interpreter As far as the language is concerned, both Scala.js and Scala Native use the standard Scala compiler (up to the point of code/intermediary language generation). So far the track record has been great to support the latest versions of Scala. (Keep in mind that Scala.js is way more advanced than Scala Native, which is a more recent project.) For Scala.js in the browser, the loss of portability comes more from the fact that you run in a different environment: browser APIs do not make sense on the server, for example. So there is no problem there. If you opt for Node.js as a new server environment running Scala.js, you evidently won't be portable to a JVM-based application. But you will be portable everywhere Node.js runs, and there is a huge Node.js ecosystem. I believe that few people have done this so far. For Scala Native, you will still be fairly portable if you use widely-available C libraries. Again, that will not be portable to a JVM, but if you decide to use Scala Native, the alternative is probably to use C/C++, Rust, Swift, or another language where portability would probably we worse anyway compared to the JVM. Most pure scala libraries just cross-compile (or with minor changes) to Scala.js and Scala Native. This inludes things like Shapeless, parser libraries, test frameworks, etc. Libraries which specifically depend on certain features of the runtime will not work without possibly major changes, it is true. &gt; Will peoples familiarity with the jvm scala doom the other implementations It's hard to tell for Scala Native, but for Scala.js it doesn't apply. The competition there is plain JavaScript, Typescript, and possibly other client-side languages. Clearly Scala.js and especially Scala Native will have to show that they are viable in the long run. I am very confident about Scala.js, and as you can tell from the above I for one am very enthusiastic about both. 
Nor all of the standard Scala libraries. For example, scala.concurrent.Promise still fails to link in Scala.js.
Flying Saucer is used for the HTML-to-PDF step - the others are for the data-to-HTML template step. It supports the [CSS Paged Media](https://www.smashingmagazine.com/2015/01/designing-for-print-with-css/) spec for headers/footers, margins, numbering. This is pretty useful, but that HTML won't be usable as a regular web-page - browsers don't support any of that. It supports most of CSS 2.1 well. One big omission in that it doesn't support `box-sizing: border-box` - setting widths plus borders/padding is difficult, and some modern CSS frameworks won't work. I also had to use FS-specific overrides for 'show table header on the next page'. Some other HTML-to-PDF options: - Chrome's print-to-PDF e.g. Electron, Selenium - If you can make a printable web-page, you can have exactly that output. No Paged Media support. - [Prince](http://princexml.com/), supposedly the best Paged Media implementation - commercial license needed if it's for a business - iText - the old, non-commercial versions are about the same as FS. I couldn't get enough of a license to run the newer ones. - WebKit renderer - PhantomJS, Wkhtmltopdf - Vivliostyle - Apparently based on e-book formats. - [printcss.rocks](https://print-css.rocks/) - some other alternatives, some Paged Media examples
Probably due to [these imports](https://github.com/scala/scala/blob/6ac6da8b61a3a427089a166c7802a940eac71064/src/library/scala/concurrent/impl/Promise.scala#L18-L19), which underlines the problem.
Sorry, my apologies. I need to do data-to-html and then html-to-pdf. Need to fill the data (html template) with some fields, hence, the need for something like twirl, thymeleaf or scalate. :) Thank you for the very in-depth answer
That doesn't seem right: I use `scala.concurrent.Promise` with Scala.js.
 webasm combined with scala.js would be an interesting target platform instead of scala native. given the manpower i cant see native ever being competetive against rust etc.
`scala.concurrent.Promise` most certainly *does* link on Scala.js. It's pervasive. Of course `Await` does not link, because that uses some Java libraries behind the scenes that are not, and *cannot* be, supported on the JavaScript platform.
Well it required quite a bit of effort to port those libraries the first time around, but they are at least in part reusable. For example Scala Native copied a bunch of the JDK classes from Scala.js. It's not a big problem. It just requires a significant amount of man.hours the first time.
And this is pretty much the reason I sometimes hate maintaining OSS software. Users like that, with no manners but a hugely inflated sense of entitlement.
For the data-to-HTML template, my main concerns are static checking and reusability. I want the template and all references inside it to be compiled in advance - no reflection and not 'when files are referenced'. You really don't want it to fail on *some* inputs or partway through a batch in a conditional/dynamic typed section. Who's going to be writing the template? If you need a web designer to be able to read it, looking like HTML/XML may be easier to teach. Otherwise, use one that's as close to code as possible - it's much easier to factor out parts into real functions and collection methods than to use template-specific "loop tags" and include-files. Twirl compiles with real types to real functions, and lets you make typed inline functions. The other two don't look quite as good for reusability or static checking. Since it uses template files instead of pure code, you'll want to find a syntax highlighter. I don't know if there's real IDE autocomplete support. For an extreme option, there's (ScalaTags)[http://www.lihaoyi.com/scalatags/] - the template is just code, so you get full IDE support, and you can use real Scala loops/conditionals: table(`class` := "small", for(thing &lt;- things) yield tr(th("X"),td(thing.x)) ) Plain scala-xml will also work in the IDE, but it won't enforce using real HTML tags/attributes that exist.
Scalariform also supports 2.12, and is about 10X faster than ScalaFmt, although the latter is certainly the future (Scala Meta based approach blows Scalariform's lexer/parser strategy out of the water). wrt to speed, IIRC the author ScalaFmt said something along the lines of scalafmt is slow due to enforced line limits (vs. Scalariform which lets lines flow to the end of the universe).
&gt; Scalariform also supports 2.12, and is about 10X faster than ScalaFmt, although the latter is certainly the future (Scala Meta based approach blows Scalariform's lexer/parser strategy out of the water). Cool, good to know. If perf becomes a problem, we'll switch back. Scalariform definitely *didn't* support 2.12 a few months ago when we switched to Scalafmt. 
I can think of a couple other advantages of Scala Native: - Faster startup time, and potentially, run-time performance for one-off tasks. If it gets to the point that Scala Native is truly seamless to use, it could make batch processing or on-demand invocation of processes faster. Could a native `scalac` be faster than JVM? - Simple distribution. Sometimes, I need to make tools for non-technical people to use. To the extent that I can give them something they can download and double click to use, so much the better. But in any case, it's pretty awesome that it was even possible with [such a small number of people](https://github.com/scala-native/scala-native/graphs/contributors) making more than a dozen commits. &gt; I think it's very unlikely it would harm JVM Scala directly, though I'm slightly worried about the impact on the tool ecosystem (I can't stand SBT but a lot of things seem to be being more SBT-oriented lately, and I think part of that is that the Scala.js/Scala native cross-build toolchain only exists for SBT). Sigh. Agree.
I realize /u/ebruchez made the same points slightly lower.
&gt; Simple distribution. Sometimes, I need to make tools for non-technical people to use. To the extent that I can give them something they can download and double click to use, so much the better. This actually should be solved already due to modularization efforts done in java9 allowing you to bundle the parts of the jvm you need and your code into one executable using jlink and distribute that. (well once scala/sbt properly support the modules) See https://steveperkins.com/using-java-9-modularization-to-ship-zero-dependency-native-apps/#.Wes5Y7ucK4g.hackernews
Why not, though? Scala Native has a more mature language and much of the preexisting ecosystem. Rust's approach to memory management is really interesting, but it's hardly required. Assuming parallelism is eventually addressed in Scala Native, what else is missing?
That will be very cool! Yeah, for this use case, I don't consider binary size to be a major issue.
&gt; though I'm slightly worried about the impact on the tool ecosystem (I can't stand SBT but a lot of things seem to be being more SBT-oriented lately, and I think part of that is that the Scala.js/Scala native cross-build toolchain only exists for SBT) Honestly, the core team of Scala.js simply does not have the manpower nor the expertise to build plugins for the other build tools. It is up to the community to write and/or maintain those. For example, [pants has support for Scala.js](https://github.com/pantsbuild/pants/tree/master/contrib/scalajs). Note that, since Scala.js 1.x, the [Scala.js sbt plugin](https://github.com/scala-js/scala-js/tree/master/sbt-plugin/src/main/scala/org/scalajs/sbtplugin) is really small (less than 1,000 lines of code). And virtually all of that is glue code between sbt and the Scala.js linker/js-envs (which are published as separate sbt-free artifacts). It should be very easy for someone who regularly uses another build tool to write a plugin for Scala.js.
Scala and Rust are not competitors. They have completely different use cases. They are as different as Java is different from C++.
Agreed it points out the need to have a clear division between what's expected to be included in and what's not. On the other hand, it's only the implementation that is dependant on Java, not the API, so I'd expect the platform to provide an appropriate implementation.
We already have the template in XHTML. I was thinking of using some converter (from XHTML to another format that can be used as a template to other engine) or changing it by hand if needed and I have a FE developer that can help me with that so I can focus on the service. So, in principle, having a single static structure (around 400 lines of XHTML) that needs let's say 10 fields changed when I want to render the document would be feasible quite easily with both twirl, scalate or thymeleaf, right?
I disagree, in both regards. C++ and Java *are* competitors, as well as rust and scala-native. I can agree the overlap is not 100%, but my estimate would be 80% of overlapping fields where they do compete.
Dependencies - Nd4j - for linear algebra - DataVec - matsim No other optimization library is used, just vanilla gradient descent. 
Would be interesting to se .NET core as a backend 
&gt; You may not share your solutions to homework, quizzes, or exams with anyone else unless explicitly permitted by the instructor. This includes anything written by you [Coursera Honor Code](https://learner.coursera.help/hc/en-us/articles/209818863-Coursera-Honor-Code)
many of the phd backed developments of scala end up orphaned. my criticism of scala is balancing expectations. i dont see native being one of those given the the relative small performance gap compared to running on a virtual machine. rust in comparison is specialized for native with much larger backing.
rust is definitely a competitor to the jvm for web services. in container based deployments the jvm bring a lot of inefficencies and complexity compared to binaries. most user interfaces now are based on html5 combined with web services. more functionality is being pushed into these html5 based interfaces. thats where i believe webasm plays a role.
Vim
You do not need to take a course to have access to assignments because they are available online, you can just take them from GitHub , write the solutions in your favorite language and put online.
I far prefer http4s, but that is mostly because of rho. Easily being able to add swagger docs (and use swagger-codegen) is awesome! 
I never even really thought abouy the iOS thing, of course it doesn't matter if it doesn't work. But it would be nice to have an alternative to Xamarin, and it sounds like Scala Native will be a much better solution to the problem.
ZooKeeper supports read-only mode even in the face of partition failures: https://www.reuters.com/article/us-google-pixel/googles-latest-iphone-rival-off-to-a-rocky-start-idUSKBN1CS2P6 https://medium.com/@Imesha94/network-partitioning-in-zookeeper-90596a1c0b42 
Read-only isn't really enough; in the case of a network partition you want split-brain behaviour (unlike almost all other use cases for this kind of system) where new instances on both sides can still register themselves on their side of the partition. 
they had one and deprecated it.
if the old java service already contains this functionality? why would you not just take that part? in this way, you should not get any surprises using a different library.
It sounds like they are moving away from "Java/Scala (Legacy API under Play Framework) " toward Node!
[removed]
More like, gave up on it indefinitely
I changed scalaVersion in build.sbt from 2.12.4 to 2.12.3, which is the version displayed by `sbt about`.
This seems like a terrible fit for someone who wants to develop in Scala. Come maintain our legacy api while we move to another technology rendering your skills and interests obsolete.
That operator is actually XOR, not the exponent - so the computation you're doing is really (x^2 XOR 2). In general I think it makes sense for logical operators to be evaluated last, as you typically want to group the computations around them. For doing exponent, you want to use the `math.pow`function.
Unfortunately, if destroy isn't working, `Process` doesn't provide thou with a way to stop a loop. Java's ProcessBuilder.start returns a Process that can kill the subprocess via its destroy method. 
Take a look at [NuProcess](https://github.com/brettwooldridge/NuProcess).
Thank you! You've saved me a lot of work digging around, and probably every other person who will ever google this error.
Your unmatched parentheses is triggering me.
Add that its in Vancouver and I sure hope the compensation is worth it.
OCD problems. Cheers !
You don't understand the purpose of a assignment, do you ? At least make the repo private.
[removed]
&gt; in container based deployments the jvm bring a lot of inefficencies and complexity compared to binaries. What kind of complexity ? If we are talking about docker, just install a JVM and use that image everywhere. It isn't more complex than installing JVM on your dev machine. 
https://github.com/danfickle/openhtmltopdf
Sounds nice in theory, but in practice it made more sense to run the exact opposite way. All the indirection just didn't buy us anything, but made life harder for users. Who is going to design, develop and maintain them? Scala can't even properly maintain its existing "standard library". There is no way such independent, alternative scala.* libraries won't turn into a complete disaster. We already had these well-intentioned additions to the standard library times and times before. Plus, you will need implementations for java.* anyway, because that's what all the existing code uses, either explicitly or implicitly. Also, since the SLIP committee was dissolved, and the SPP committee basically said that they won't work on additions to the scala.* namespace, but only outside of it, scala.* is de-facto unmaintained anyway. If you want to improve things, start by stopping the compiler from adding everything in java.* to Scala's global scope.
Hi, thank you for the reply. I'll take a look on that. 
The idea behind this project is to show how to use ND4j - an excellent library for linear algebra, to implement machine learning algorithms. They are plenty solutions in other languages on GitHub, I could not find any solution in Scala. At the end of the day, I think that our goal here is to move this world forward, and I believe that by sharing machine learning knowledge I definitely doing it. 
You are not moving this world forward by giving solutions to other people. You are doing the opposite actually. If you want to demonstrate how to use ND4j you could have been making your own problem to solve and write a blog post about it. Plus: "other people do it, so I can do it." Well... No, you are just breaking the honor agreement just like they did.
Migrating old monolithic application (10 years old easily) to several micro services. The application is on a different platform and we are lucky to have the code. We are writing 100% in scala and most of it pretty functional so keeping that is not an option. Also, we will make some changes to the templates so it is inevitable. 
re: learning curve I never got it. Scala was the second language I learned, the first being Java and I found it a breeze. So I'm not so sure where the problem is. Are people jumping into Shapeless and Monad Transformers at day 2?
`**` is commonly used as a symbol for exponentiation in languages where `^` is used for XOR. I would prefer Dotty remove all operator precedence - IMO it's too much of a special case relative to how much value we get out of it. I suspect that we won't see any change as it's too bikesheddy an issue for any approach other than "keep things as they are" to work.
Scala was the second language to me as well. Java being the first. I think is partly towards that people think Scala as a better Java and try functional libraries first. I didn't find scala complicated at all. Sure it takes time to learn but in no way it is unnecessarily complicated. I am glad that my viewpoint is matching here.
IntelliJ IDEA
I actually recently switched to Http4s too because Finch was using the Twitter stack that would keep using JUL for logging. Rho isn't that useful because it's still far behind in terms of compatibility with the newer versions of Http4s that uses Cats and Cats' IO Monad. I have a lot of other code using Cats, and that's why I don't want to go back to Scalaz and have to have them in the same project.
1) I don't think the author's original intentions are relevant, and whatever Odersky may have said in 2013 (I can't/don't watch videos) the original design of Scala smells like it was intended as a "better Java". Certainly Scala does compete in those segments, whether it wants to or not: it's an option for a "better Java" language, and it's an option for a "Haskell on the JVM" language, and reasonable people might pick it in either or both roles. 2) I think there genuinely is more general-purpose stuff you can do in Scala, so there is more to learn to reach the point where you know all the general-purpose things. The trick is that those things are genuinely useful and other languages simply don't have them. So after 1 year of Scala you're as productive as you were after 1 year of Java/Python/... - but there's still another 9 years' worth of stuff that you can keep learning and keep becoming more productive with. But it's easy to mistake that from the outside as "Scala takes 10x as long to learn". 3) Functional style feels natural even in Java, there's just a lot of frustration to it - you end up expanding out by hand and duplicating things that you know are "really" the same code. But it's still worthwhile, IMO - I think a lot of the functional principles are just good code principles taken further. 4) I've never really "got" Reactive, or what people seem to use "reactive" to mean. It doesn't feel functional to me. Too many "magic" concepts that you have to understand as if they were language-level fundamentals, which is the opposite of what I want. I'd rather achieve the same thing in a pure-functional way with something like fs2.
cheaters always find a way to justify their shady acts
re: learning curve IMO what you learn in Scala, comes in handy later on, since you don't need to rely on so many frameworks (bringing countless annotations etc.). So, you invest more at the beginning but profit later on, whereas in e.g. Java you invest less at the beginning and have to learn A LOT of stuff in the form of frameworks later on.
Totally agree with the other guys, the purpose of an assignment is to test your understanding and validate a knowledge, you're not only discrediting the formation, but you're also not helping peoples by giving them the solution. If your really want to help them, write an exercise instead
How would the precedence be decided then?
No precedence, simple left to right evaluation (right to left if ending in `:`, mixing `:` and not in the same expression is an error) like any other function. 
Some general comments speaking from my own experience: - If you're used to thinking in a OOP way (from C#, Java etc.) learning Scala will feel very natural and almost like a revelation. Actually it's a much better OOP language than C#, Java, OCaml, Kotlin etc. The hard part is rather learning the purely functional concepts like type classes, HKT's, category theory etc. - If you want to do mainly pure functional programming, Scala is not the best language out there (mainly because of the lacking type inference and syntax). Haskell, PureScript, Eta etc. are better alternatives (however the tooling and eco systems might be somewhat lacking compared to Scala). - IMO, in general Scala does compete with Haskell, Kotlin, Java, C#, C++, Rust, Go etc. Basically you can implement the same applications in all these languages so you should choose the language that best suits your requirements and personal preference. However for certain application areas Scala can't replace C++ or Rust for example. - I generally use a kind of impure functional programming style which I find works extremely well in Scala.
An addition to your list of options: http://www.athenapdf.com/ - based on Electron.
Really interesting read. I really dig the breakdown of exactly what the design goals are of record types in a language with subtyping. It's sad, though, that we're still so far away from a fully baked solution here. There are so many times in Scala where it's quite painful to work around the fact that you have to describe intermediate states of data in a process on their own instead of relative to the endpoints. If I want to pass a `Person` and an `Address` together as a unit, I either have to tuple them up, which can get ugly/unwieldy in some situations, or make some new `PersonAndAddress` case class. This is a contrived scenario, but as Odersky says, it's common in database situations. But my point is, these aren't really niche scenarios. For whole classes of applications, this is the fundamental operation. I'm really looking forward to a day when `case class` is simply a special explicit case of a more fundamental and flexible record type.
Some comments: 1) Scala was never designed to be an upgrade to Java "Scala was never designed to be a better Java" is just a poor excuse for not fixing some of the painfully obvious issues and dismissing any consideration whether Java might do something better than Scala. Have a look at the mess with annotations, enums, and collection interop. There is no reason to ship these things in such a broken state for years. Realistically, to be a better Java, Scala would need to work on the abhorrent mess that is its documentation. That's not going to happen. So yeah, in that regard Scala is not a better Java. 2) Learning curve Scala has a huge learning curve, largely due to two reasons: - The language is unnecessarily complex. - Documentation is very poor, most stuff is either missing, outdated or incorrect. - Tooling does either not work reliably, or not at all. There is no reason why it has to be this way, except for people not caring about it. It's the classic "I spent ten years learning the language, why should you have it easier than me?". No opinion on 3) and 4).
 &gt; "Scala was never designed to be a better Java" is just a poor excuse for not fixing some of the painfully obvious issues and dismissing any consideration whether Java might do something better than Scala. I don't think so. From the beginning, it was always Java -&gt; Scala interop and not the other way. With that said, Spark/Akka have Java APIs and they work quite well. &gt; Scala has a huge learning curve, largely due to two reasons: Maybe it was a mess in the beginning, but today it has improved a lot. As I said, it is not the language that has the learning curve but the paradigm. If you are already a seasoned functional programmer, I don't think it will be that difficult for you to pick up. &gt; The language is unnecessarily complex. I don't get this point. There are certain limitations with the JVM, but other than that I don't think it is unnecessarily complex. Perhaps you can give examples to back it up? &gt; Scala has a very unwelcoming environment for new users. I have to partially agree on this. Some of the frameworks do not have a knowledge level. For example, I found Slick to be pretty complex at the beginning so I decided to go with JDBC. There are certain frameworks which is definitely not for the beginners e.g Scala JS. They are require a solid understand of the language. &gt; Documentation is very poor, most stuff is either missing, outdated or incorrect. That can be said even for Java and other frameworks. But for the most part I would say it is not beginner friendly. They are mostly like reference material rather than a guide for newbies. &gt; Tooling does either not work reliably, or not at all. SBT works ok. Intellij is pretty good though the compiler is not. Always use SBT to run and do not rely on the Intellij compiler for advanced usage. It is not as good as Java, but at the same time it isn't bad to the level where it is unusable. With that said, I think the scala community could use some free materials. I really wish "Programming in Scala" was free even though the book is well worth the money. 
Hi, I may be interested, I am living in Spain, would it be possible to work remotely?
This is my personal effort to learn Category theory and apply it in scala. I know there are a lot of resources about Bartosz Milewski book, but you can see why I think this may be helpful for others: https://github.com/elbaulp/Scala-Category-Theory
I wish scastie was this fast.
&gt; Spark/Akka have Java APIs and they work quite well. I think the fact that Scala libraries require separate APIs for Java supports the statement that interop is quite poor. &gt; it is not the language that has the learning curve but the paradigm I disagree with that. There are tons of completely unnecessary things Scala throws at you for no discernible reason at all. &gt; Perhaps you can give examples to back it up? - implicit lossy widening conversions are wrong, broken and will never work - implicit resolution has been broken in contravariant cases for such a long time that all libraries have just abandoned using contravariance where it would have made sense - compatibility across minor versions has been abandoned with 2.12 - growing, not shrinking, number of ways to express the same things - collections are a complete mess, fundamental design issues have not been resolved despite 4 redesigns/revisions (&lt;= 2.7, 2.8, 2.9, 2.13) - the way identity (`eq`) and equality (`==`) exist in the type hierarchy doesn't make much sense - tons of useless symbols like `: _*`, `#::`, `/:`, `:\`, `!!&lt;`, `###`, `#&amp;%`, `#||` - enumerations are beyond broken - shimming Java types by sub-classing them has been am overall design failure - having close to 400 things in the global namespace (start your REPL and press tab if you don't believe me) - a huge chunk of the packages in the standard library have not worked out (collections, io), are of poor quality (beans, io, xml, reflect), or shouldn't exist at all (parser combinators, text, util) &gt; That can be said even for Java and other frameworks. Scala is on another level. Java at least manages to document its own keywords and core concepts. Try finding "implicit" or "context bound" in Scala's glossary. The glossary isn't the only part of Scala's documentation that hasn't been touched for the last 5 releases. Nevertheless, other languages having bad documentation should not even be an acceptable excuse. &gt; SBT works ok. I recently worked on migrating to SBT 1.0. I have never seen an instance where so much API has just disappeared form one version to another without any kind of documentation. &gt; Always use SBT to run and do not rely on the Intellij compiler for advanced usage. I wonder which quality standards we have to make this acceptable. This is not acceptable. This is not normal. I have three different IDEs installed (ScalaIDE, IntelliJ and Ensime), and it's often the case that none of them work without an excessive amount of fiddling.
Thanks. I have not worked as deeply as you have mentioned. You have mentioned some very valid points. I am waiting on someone who is qualified to answer these.
Hi there, not for this position I'm afraid but you can see the full range of our remote roles [here](https://functional.works-hub.com/job-board?query=remote&amp;utm_source=Reddit&amp;utm_medium=post&amp;utm_campaign=Edmund&amp;utm_content=remote)
Thanks!
Simon Ochsenreiter has a huge gripe against the Scala designers ever since he failed getting hired by the Scala center and I dropped out as his master thesis advisor because of his abrasive behavior. Don't let him pollute this group. My policy is that I refuse to be active in the same threads as he is because I cannot stand the bile he spreads. Simon is a student (not sure he ever finished). Don't believe him if he tries to act like an expert. 
I have great respect for you Martin, but I also read Simon's points and see a lot of truth in them. Someone can spit bile through his words and still be right. Such a person is often the hardest kind of person to listen to, even if listening to him would be beneficial for all parties.
How'd it turn out? Is sbt actually running and the error spurious?
I'm having trouble finding comprehensive documentation on things like `native-image` (or is it `aot-image`), can you point to any? I am most interested about shared lib and windows support.
Thank you for all the help! The sbt.jar file exist at that location. r@DESKTOP MINGW64 /c/sbttest2 $ sbt [warn] No sbt.version set in project/build.properties, base directory: C:\sbttest2 [info] Set current project to sbttest2 (in build file:/C:/sbttest2/) [info] sbt server started at 127.0.0.1:5564 sbt:sbttest2&gt; I have never used scala before, but it seems sbt works? The problem has to be in my example project. It's for a class and I'm not the only one this problem, so I'm sure someone will figure it out. \Scala\example&gt;sbt run Error: Unable to access jarfile Copying runtime jar. The filename, directory name, or volume label syntax is incorrect. Error: Unable to access jarfile "C:\Users\u\.sbt\preloaded\org.scala-sbt\sbt\1.0.2\jars\sbt.jar" Java HotSpot(TM) 64-Bit Server VM warning: Ignoring option MaxPermSize; support was removed in 8.0 . . . [error] C:\path\example\Main.scala:1:8: not found: object akka [error] import akka.actor._ [error] ^ . 
There is work being done on [enum integration](http://dotty.epfl.ch/docs/reference/enums/enums.html) and [documentation gaps](https://scala.epfl.ch/projects.html)
Any available resources for starting with Scala? The supplied examples for java are pretty good, but some pointers for scala would be even greater...
I'm using Graal .29 for macOS, downloaded from [OTN](http://www.oracle.com/technetwork/oracle-labs/program-languages/overview/index.html). I don't see Windows binaries available on the site. I believe the tool was called `aot-image`, but has been renamed `native-image`. I haven't found much online documentation, but there's a help page (`native-image -help`). `native-image` is also how Graal AOT compiles the R, Ruby, JS, python, and node executables included in the build. They are all quite fast and can [interop with each each other](https://github.com/graalvm/examples/tree/master/fastr_javaui). There's even a repl included that lets you switch languages dynamically (`polyglot --shell`). It only works with JS + Ruby right now.
Just a few corrections, because there are some claims I don't want to stand: - I offered my contributions on documentation irregardless of any kind of employment. In my opinion it's disingenuous and disappointing to see that a proposal from years ago to work for the Scala Center is now offered as a reason for ending my contributions. I left due to the way contributors are treated in Scala. I wasn't the first one to leave, and I certainly won't be the last one. - The renewed effort to improve documentation came as "pick anything deemed valuable and I'll do it". Multiple people showed a complete lack of interested when I talked to them in private at ScalaDays about how issues with documentation can be adressed, then later acted like they were open for contributions when I raised my concerns in public. I think these are valid reasons to be unhappy about such disrespectful behavior. - I decided not to go forward with my master thesis proposal due to advice from multiple grad students at LAMP/EPFL. The angry mail sent to my university was therefore months late, and assumed a situation that ceased to exist quite some while before it. I think there might be an opportunity to improve the communication between different parties at LAMP, but that's not my business. - I finished my master thesis, which had a topic unrelated to Scala, and left university. - I'm not sure whether the argument-from-authority is helpful. Personally I try to evaluate ideas based on their merit, not based on their origins.
Our Scala API code is here fwiw: https://github.com/deeplearning4j/ScalNet
It isn't documented or supported at the moment - we're using it to build native images for tools within GraalVM at the moment, but others are free to experiment. We can help with questions in https://gitter.im/graalvm/graal-core though.
We have a bunch of Scala notebooks with tutorials here: https://github.com/deeplearning4j/dl4j-examples/tree/overhaul_tutorials/tutorials
People who are looking for such repos are more likely those trying to learn how to solve it a different way (after they'd solved it themselves), or using different languages/tools, which is especially true for things less known than scikit or matlab, like Scala + Nd4j. Eventually, those people could benefit more than potential cheaters unable to cheat. Besides, the course is very popular, there are literally hundreds solutions out there and everyone knows that. It's all about discipline.
Very nice to see that they are improving compile times - I'd like to see if runtime performance will improve as well as things move towards Java 9.
Jason keeps delivering these 5-10% speedups with every release! The optimizations to generic signatures and the erasure phase are especially interesting. This is very impressive considering that many people thought a while ago that all practical performance gains in the scalac codebase had already been found.
A few of the compile speed improvements we're delivering stem from improvements to the performance of the library. But more work is needed to select a set of runtime benchmarks to track and tune against. That said, we are using benchmarks to drive the collections redesign slated for inclusion in Scala 2.13 ([Example](https://github.com/scala/collection-strawman/pull/271))
That's not giving away the fact that Coursera is making an effort to give credit to their formation and having more and more solutions available publicly ruin these efforts as potential recruiter will be more and more likely to think peoples cheated Also, the argument "Other broke the honor code, so he can too" isn't what I would call a valid arguments To finish, "People who are looking for such repos are more likely those trying to learn how to solve it a different way" is a total assumption from yourself, not a fact. However "It doesn't help those who haven't enough discipline" is a fact. 
Keep up the good work! :)
That's great! How soon typelevel scala 2.12.4 will be released?
&gt; Jason keeps delivering these 5-10% speedups with almost every release! Now if only SBT were to follow suit :\ Seems that with every new Scala release all of the optimization work goes out the window in the face of SBT's absolutely dog slow file change detection (this is particularly bad in applications with many subprojects). While it's nice to have faster clean builds, incremental builds are laggier than ever.
In the long term, attracting new contributors to the community is far more important than fixing any particular set of specific issues. It's vital to draw a line and ban people who are unable or unwilling to avoid upsetting others, even if it means missing out on some contributions in the short term. (Indeed I'd say a failure to do so has been a repeated problem with the community, and the biggest thing holding Scala back).
I wouldn't advise listening to Simon on the whole, though there are some genuine issues here. &gt; implicit lossy widening conversions are wrong, broken and will never work They're what happens in virtually any Algol-family programming language, including Java. Programmers expect them. Scala has always been a compromise between the correct and the practical. In any case they're an edge case you rarely encounter. &gt; implicit resolution has been broken in contravariant cases for such a long time that many libraries have abandoned using contravariance where it would have made sense True as far as it goes, but not a large use case: subtyping and implicit-heavy programming styles do not have a lot of overlap. Literally no other programming language supports implicit-like functionality and subtyping (Ocaml is working on it but we'll have to see how that turns out) and there are edge cases between the two. It should be fixed, but it's not a huge issue. &gt; compatibility across minor versions has been abandoned with 2.12 A broad statement that I can only assume is referring to the decision to make some cases that are compile errors in early 2.12 versions have correct behaviour in later 2.12 versions, which is hard to see as a problem. &gt; collections have a lot of issues, and fundamental design issues have not been resolved despite 4 redesigns/revisions (&lt;= 2.7, 2.8, 2.9, 2.13) Very broad and subjective. Scala 2.7 is older than many programming languages, and 2.9 was not a substantial redesign (I ported code from 2.8 to 2.9). Really we're talking about having a major redesign in the 2018 release when the last major redesign was in the 2010 release; that's not an unreasonable rate of change. &gt; the way identity (eq) and equality (==) exist in the type hierarchy doesn't make much sense True as far as it goes, but a minor edge case you rarely encounter. &gt; tons of cryptic punctuation like : _*, #::, /:, :\, !!&lt;, ###, #&amp;%, #|| Mostly specific library methods rather than language issues. `/:` and `:\` are I believe actively deprecated (certainly they're discouraged in favour of `foldLeft`/`foldRight`); the various # methods are in streams which I'd advise never using. There is a problem in some parts of the culture with overuse of symbols, but it's not a language problem; best thing is to avoid using libraries that result in unreadable code, as determined in code review. &gt; enumerations are beyond broken Yes they are. Don't use them, use Java `enum` instead. &gt; a huge chunk of the packages in the standard library have not worked out (collections, io), are of poor quality (beans, io, xml, reflect), or shouldn't exist (parser combinators, text, util) Most of which have now been moved out of the standard library. &gt; Java at least manages to document its own keywords and core concepts. Try finding "implicit" or "context bound" in Scala's glossary. The glossary is just an example -- it isn't the only part of Scala's documentation that hasn't been touched for the last 5 releases. Yes, the documentation is in a pretty bad state. I'm not going to defend SBT - I don't use it and don't advise anyone else to; I use Maven which works great. Likewise IntelliJ - I've tried to make it better by reporting issues, some of my employers have been paying customers, but the "fix" for any given issue seems to just be to break something else; I have no confidence in their team's ability (or, if you want to get into Kotlin-conspiracy-theory territory, willingness) to fix their Scala support, and even if they accepted external contributions I wouldn't work on their paid product for free. I use Eclipse and have found its error reporting via the "Problems" tab is perfect (people on this subreddit frequently claim it has errors but are never able to point to examples); I'd advise others to use Eclipse too, though it does have serious performance issues (the UI occasionally just locks up). I try to investigate those when I can, but it's not easy. For what it's worth the overall IDE experience is, to my mind, better than many languages, and the performance issues in Eclipse seem to be a fact of life for Eclipse in general rather than anything Scala-specific. There is much that could be improved there, but I assume not cheaply, and while the Scala community can do our part there are much bigger users of Eclipse who really ought to be contributing on these fronts.
Windows support is non existent right now in aot, because it can only generate ELF files, unless you install the ubuntu-bash on windows thingy, you're out of luck.
great, thanks!
From C:\path\example\Main.scala I can tell that your project isn't set up correctly for sbt. Your [project structure](http://www.scala-sbt.org/1.x/docs/Directories.html) for sbt should look like this: src/ main/ resources/ &lt;files to include in main jar here&gt; scala/ &lt;main Scala sources&gt; java/ &lt;main Java sources&gt; test/ resources &lt;files to include in test jar here&gt; scala/ &lt;test Scala sources&gt; java/ &lt;test java sources&gt; So, `Main.scala` should go in C:\path\example\src\main\scala\Main.scala Your build.sbt file should be at: C:\path\example\build.sbt And needs to include all the basic settings: name, organization, scalaVersion, version. You also need to define your libraryDependencies there to pick up akka: libraryDependencies ++= Seq( "com.typesafe.akka" %% "akka-actor" % "2.5.6", "com.typesafe.akka" %% "akka-testkit" % "2.5.6" % Test ) 
I agree with this post. From what I've observed, most of the respected members of the Scala community are super nice and non-confrontational. This is generally great, but it means well-meaning people who inadvertently step over the line don't get nudged back, and may not even realize that they are causing general unhappiness. You also sometimes see outright trolls coming in, e.g. to this forum, repeatedly/intentionally being inflammatory over a long period of time before being dealt with. While I'm all for free-speech, I think a somewhat firmer moderation stance, both here and elsewhere (e.g. gitter) would benefit the community as a whole.
I mostly agree with your point, I was just trying to play devil's advocate. Maybe it'd be better if the author published something similar to demonstrate ML in Scala, not the exact solutions to the course.
It would be interesting to also see a comparison with the Java alternative, where one exists
It would be interesting to also see a comparison with the Java alternative, where one exists
is there an easy way to compare compile times between versions? say, how does this version compare to 2.11.8?
could add that for people struggling with grasping category theory and all its fuzz I'd recommend how to bake pi (https://www.amazon.com/How-Bake-Pi-Exploration-Mathematics/dp/0465097677) which explains all of this with analogies to baking cookies. 
Scalafmt + intellij/CI works wonders 
https://scala-ci.typesafe.com/grafana/dashboard/db/scala-benchmark
&gt; Why the reluctance Note: this is just my personal opinion. Slick is cool, and allows for lots of type-safety, but has a few drawbacks: * Compilation error messages are obtuse in the extreme; without following examples closely, it's hard to know how to use the abstractions you're given. * Slick code clobbers IDEs periodically (both Eclipse and IntelliJ in our experience) * The internals make it hard to factor out common operations. In particular, we had some simple queries that only differed on the table (`select foo from foos where id = ?`, `select bar from bars where id = ?`, etc). We were able to parameterize on the table only via some rather gnarly type aliases with several bounds and underscores. On the one hand, it was cool that this worked in a type-safe way; on the other, the resulting code was hard to write and requires a paragraph-long explanatory comment. (Of course, I may just have Done It Wrong! :) &gt; Quill I've followed Quill off and on for a while now. We chose Slick because it was typesafe, and also popular and thus google-able. Also, Quill's macro-based approach made me want to wait a bit for more people to bang on Quill. It's been a while, so I should look back into it. Our database needs are (for now) fairly simple, and other things are higher priority, but I'll give Quill another look when it's time to review the data layer again.
Improving the way Scala treats its contributors was one of the motivations I had to consider working "from the inside". Of course it's hard to attract and retain contributors if perfectly fine bug reports get answered by correcting the reporter's grammar, for example. If contributors, whose native language might not even be English, get criticized for using "must" instead of "should" in a sentence in a bug report, despite the message itself being perfectly clear, this might cause a further increase in the lack of diversity. I think this is deeply concerning and just one of many examples. I also believe that many of Scala's quality issues are caused by the failure to retain contributors: It is not surprising that design and implementation issues keep getting reinvented, if both the person creating the issue the first time, as well as the person fixing that issue have left the project.
what happened in sept 2016?
Thank you!
We're still looking for people, but thank you to everyone who's gotten in touch so far!
As a completely ‘out there’ suggestion, you could try pandoc which does html to pdf via latex.
This comment has been removed for reasons regarding personal privacy at the request of an individual who had been mentioned in the comment.
Not only that but sounds like a security hole waiting to happen 
The article only reference an "old Scala system". Is the new system also written in Scala?
Yes! Sorry if that was unclear. This is part of a series, so more details about implementation are coming.
We're tracking the overall issue as https://github.com/sbt/sbt/issues/3527. We're shipping a workaround https://github.com/sbt/sbt/pull/3626 in 1.0.3, which is imminent. https://github.com/sbt/sbt/pull/3634 (also in 1.0.3) is also relevant, as it fixes an accidental infinite looping issue; the fix for which I expect would improve performance.
&gt; In July 2015 when we switched to the new implementation of the bytecode emitter and optimizer (“GenBCode”). In August 2016 things deteriorated further when we moved responsibility for desugaring fields to a dedicated compiler phase. Shortly after, as this phase took responsibility for desugaring nested objects, we hit rock bottom, with compile times of 2.5x the baseline. &gt; &gt; In October 2016, we pieced together what had just happened: the new bytecode emitter was emitting synchronized slightly differently to Scalac 2.11 and Javac, and while it was technically valid it prevented JIT compilation. The effect of this was drastically amplified later when the reworked nested object translation changed the granularity of the methods that compute the value; whereas previously the synchronized block was in a small method that was only during object initialization, now the synchronized block had been inlined into the getter method called on every subsequent access. Every access to such an object ended up running through an interpreted method! from http://developer.lightbend.com/blog/2017-06-12-faster-scala-compiler/index.html#backsliding-in-the-2-12-milestones
i posted this in r/java, but in java 9 you can also enable graal as the default JIT: https://www.reddit.com/r/java/comments/76ss8k/how_to_use_graal_as_a_jitc_in_java_9/
The ticket with the specifics is here: https://github.com/scala/scala-dev/issues/139 I haven't tested, but I recall reading there's some basic support in the latest versions of scala and sbt.
besides that it does not support JEP-261, yes.
This isn't the 'AOT' that you may have heard of already in the JVM. It's a different 'AOT'. It's not restricted to ELF files, but it still doesn't work on Windows, that's true.
Thanks, but none of the above addresses the fundamental problem of Sbt being slow in detecting changed sources across subprojects. The issue I'm describing has nothing to do with `~` modes or macOs (Linux here). Obviously I'll give 1.0.3 a try as soon as it comes out, any improvement will be most welcome. Thanks for pushing the library forward.
Feel free to open an issue detailing what you'd like sbt to do, so we can discuss it and track it (and not forget about it xD).
You can search for configs on github: https://github.com/search?utf8=%E2%9C%93&amp;q=filename%3A.scalafmt.conf&amp;type=Code Here is what I'm currently using: style = defaultWithAlign project.git = true maxColumn = 120 unindentTopLevelOperators = true danglingParentheses = true spaces.inImportCurlyBraces = true rewrite.rules = [ RedundantBraces, SortImports ]
If you don't want to fight and have a large team, use the intellij config.
Mainstream compatibility is targeted for 2.13, scheduled for early 2018.
How does it work with dependencies? Do you need to build a fat jar first?
Wonder if there's a headless way to download Graal, without OTN Licence Agreements and the like.
It's a good book, and it covers the creation of an app from scratch. The only drawback is that it explains the how but sometimes not the why. So if you don't understand something you would need to resort to other sources for clarification. In general it's a good book to get the foundations of how to implement a web app in Play. 
The biggest problem seems to be that the IDEs support for the new runtime format is rather poor. There is a currently lot of weirdness even when trying to work on vanilla Java projects. Eclipse shipped Java 9 support in the latest dot release, but it isn't where it needs to be yet.
I set up a sound installation that runs from seven network'ed raspberry pis and a computer music system I'm developing in Scala: https://octodon.social/@sciss/98874699194010939 Now I'm finishing a paper that includes an analysis of how that piece changed with regard to a prior version from 2011. I have been playing around with Scala Meta to create a graphical representation of the two code bases: https://imgur.com/a/S0Vfg
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/LLJjqm3.jpg** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dp0d2ed) 
Still suffering here on Linux -- i.e. no change wrt to incremental builds and slow file change detection in multi-subproject builds regardless of using `-Dsbt.watch.mode=polling` or not. Literally 5 second delay before requested task kicks off. I wonder what Ligtbend's clients (who presumably deal with very large applications) do to work around the obvious (to me) issue that sbt simply does not scale as project source dependencies grow. In the past I've been able to work around the issue by publishing artifacts for stable (rarely changing) parts of an application, but in the current project (Play + Scala.js) there are a lot of moving parts so source dependencies makes sense (though in reality it's a major productivity drain to incur a 5 second delay + compile time for the simplest of changes).
FWIW, we moved from SBT to pants and it was a good move. Pants has its faults, but, as a company we’re happy we did it.
fyi: this is rabbit from alice in the wonderland
confirmed https://www.disneyclips.com/imagesnewb/images/whiterabbit2.gif
Amazing
And the rabbit is late, hence the lede to "for the Impatient"
Quite sad. Especially that I really enjoy SBT. Several performance regressions, preventing me from migrating to 1.0 so far.
How is the TDD in Scala+pants?
Yup, I just use `sbt-assembly` and then `$ sbt assembly` and it works fine!
This talk was amazing; even though I kinda got lost after around ana and cata :). Anyone know where I learn more about similar topics?
Acceptable. We use the `test-changed` goal to only compile and test the parts of the code that changed. It's much faster than a full compile obviously. Nothing like sbt's console but, still better than the previous situation.
http://blog.sumtypeofway.com
It's a fabulous spot for detail, nonetheless. 
There's examples in Haskell as well
I made a [flatpak](http://flatpak.org/) bundle containing an SBT+OpenJDK8 runtime. It can be downloaded from [here](https://gitlab.com/stevendobay/flatpak-sbt).
*sees title* I bloody hope so. I started learning it a week or two ago out of curiosity
&gt; Don’t ever do that. Other than the runtime overhead, this has the ironic side-effect that, because mistakes are easy to make, it’s liable to crash your application as soon as you enable debug logging, How is `logger.debug("string {}", foo)` different from `logger.debug(() -&gt; "string " + foo)`? Both have runtime overheads and are lazily evaluated.
Plenty do, if the bugs are low impact our hard to fix. 
The article was actually interesting, but has absolutely nothing to do with the title. It was about setting up some re-usable logging functionality in Java8 vs Scala.
That fucking web page is fucking weird. It must be fucking javascript.
Weird how? Works perfectly for me.
I hope we can discourage the click-bait titling. I for one don't look forward to "Single mom chooses Scala, you'll never believe what happens next!"
i didn't pick the title
i think it loads a linux vm ported to js, and then runs the play framework in development mode to render the site client side.
Working on the architecture for a back-end application using Play, so far I built a `JsonController` that let me write methods that expect a JSON model and computes a JSON model in case of success, it uses Scalactic and a simple monad transformer to do error handling without exceptions (similar to Either) allowing to use for-comprehension syntactic sugar. This lead me to write controllers as simple as: ```scala class UsersController @Inject() (userService: UserService) extends JsonController { def create() = async { createUserModel: CreateUserModel =&gt; // def create() = async[CreateUserModel, UserCreatedModel] { createUserModel =&gt; val result = for { createdUser &lt;- userService .create(createUserModel) .toFutureOr } yield UserCreatedModel(createdUser.id, createdUser.email) result.toFuture } } ``` Also, I use the power of scala type system to get results and error translation based on the models. Feedback is appreciated. see: - [JsonController](https://github.com/AlexITC/crypto-coin-alerts/blob/master/alerts-server/app/com/alexitc/coinalerts/controllers/JsonController.scala) - [UsersController](https://github.com/AlexITC/crypto-coin-alerts/blob/master/alerts-server/app/com/alexitc/coinalerts/controllers/UsersController.scala).
Is your assignment requesting you use Spring? **Dependency injection** doesn't necessitate a **dependency injection framework** like Spring or Guice; the act of passing a dependency to a component *is* dependency injection. Whether dependencies reside in XML or plain code they still need to be declared. The practical difference is that code is easier to refactor and won't compile if some dependency is missing or incorrectly instantiated. All Scala projects I've seen use this approach as a lot of effort is often put on statically proving that the application can actually run after it's been compiled. MacWire solves the wiring of components during compile time but I've never used it so I can't say if its worthwhile. It does look kinda neat from the examples on github though. One last small nitpick. Since you're declaring your gameEngine as a `var`, you can actually drop the `setGameEngine` method and just assign it with `someGameView.gameEngine = g`.
You're using setter based dependency injection. He probably wants to see constructor based dependency injection. You can do constructor based dependency injection without using Spring or another runtime DI framework like Guice, and inject components by hand. You can check out Play for some examples: Check out the [Guice example](https://github.com/playframework/play-scala-starter-example/tree/2.6.x) for run time injection, the [Macwire example](https://github.com/playframework/play-scala-macwire-di-example/tree/2.6.x) for compile time injection, and the [compile time DI example](https://github.com/playframework/play-scala-compile-di-example/tree/2.6.x) for dependency injection without a framework. You can also read [DI in Scala](https://di-in-scala.github.io/) for more details of Macwire.
Does your instructor understand Scala? I don't entirely understand someone recommending Spring for Scala... But maybe I'm just inexperienced. Dependency Injection really just comes down to Inversion of Control, and making it so your classes dependencies don't rely upon hard coded instantiation. In order to keep code organized, classes (or external libraries) whose sole responsibility is to configure dependencies seem to be called 'modules' (at least in Guice, which I have the most familiarity) It's by no means actually necessary for it to be loaded from an external file, or at runtime even, it just helps the extensibility and configurability of your applications.
This has absolutely nothing to do with moms.
Can we leave single moms out of this. They already have their hands full.
Although its kinda easy to blame SBT here, the real issue is stemming from Java. The real problem is that Java's file watching service (both `nio` and `io` variants) are terrible. This is a long standing problem (and there is even a bug report on OpenJDK which is still open about this). The `nio` file watch service works great on Windows, but its terrible on Linux/Mac. There is a ticket about this on SBT to use a file watching service which hooks onto native code (that should work much better), see https://github.com/sbt/sbt/issues/3527 and other related tickets 
I want to contribute an algorithm to MLlib. Any suitable algorithm you want to see implemented? Any ideas?
implement a scala macro that, given a piece of scala code, determines whether the program will finish running or continue to run forever.
i don't know anything about this title in particular, but usually the quality of most packt books is abysmal. they once approached me to write a book for them offering me nothing other than a few printed copies and "the pleasure of having my name on the cover of a book" (their words, not mine)
... I meant an algorithm capable to be implemented as part of (Apache) MLlib: https://spark.apache.org/mllib/
Full disclosure, I work for Azul. I have to disagree with your rather sweeping statement that anything more than 100ms pause can't be fixed just by switching to Zing. We have many customers that have had multi-second (even multi-minute) pauses that have disappeared when they switched to Zing. I'm not claiming we can solve *all* GC related problems but many we can.
Full disclosure, I work for Azul. I have to disagree with your assessment and would like to see some proof that only 0.001% of applications cannot be easily tuned for GC to meet defined latency SLAs. We have many customers who have spent a lot of time (and money) trying to eliminate GC pauses through careful tuning and even trying to code to reduce object allocation. Using Zing has solved their problems quickly and easily and at a cost they're very happy with. We don't claim to be able to solve all the problems of GC; if you don't have enough memory or processing power in your machine for the profile of your application no amount of tuning or recoding will eliminate GC latency.
&gt; that should work much better As per linked item in github issue I'm already on Play 2.6.6 + Sbt 1.0.3, no difference at all wrt to file change detection lag -- remains horrendously slow. In an application consisting of 30kloc spread over 650 files it is absolutely mind boggling that detecting which file(s) have changed takes a minimum of 5 seconds. Visualvm shows that majority of cpu time is spent in `sbt.io.Hash.apply()` and `Log4j2-TF-1-AsyncLogger[AsyncContext]`. I'd expect file change detection in a project of this size to take at most 200-300ms.
Sure. I spent 6 months working hand in hand with Azul and for my application, Azul made our app significantly slower. People are welcome to try it, but I think most people would be better served by tuning their GC settings FIRST within the realm of CMS/G1.. and look to a specialty provider like Azul when they are tapped out of options. Obviously as an employee of Azul your view will be different ;) Don't get me wrong, I love Zing. I do caution against assuming it will just be magic.
Sure. I spent 6 months working hand in hand with Azul and for my application, Azul made our app significantly slower. People are welcome to try it, but I think most people would be better served by tuning their GC settings FIRST within the realm of CMS/G1.. and look to a specialty provider like Azul when they are tapped out of options. Obviously as an employee of Azul your view will be different ;) Don't get me wrong, I love Zing. I do caution against assuming it will just be magic. 
&gt; Also, the Halting Problem is unsolvable... I think that was the point of the joke.
Really? You are saying that you had personally tried Zing in an application that actually had such GC pauses and it didn’t get rid of them? You still had 1 second or half second pauses after applying Zing, and Zing actually made you 1 second or half second pauses even worse? In the entire history of Zing, I am not aware of a single case where GC pauses of such magnitude remained after applying Zing (and using recommended settings). Zing systemically reduces *ALL* GC stalls to well below OS artifacts (where scheduling and paging delays typically dominate). It certainly never makes them worse. The only exceptions have been cases where people refused to use recommended settings. E.g. where the heap size was somehow artificially constrained to a point where not enough memory was provided to keep up with ongoing application throughout. With Zing, this is always solvable by increasing the heap size to accommodate increased throughput without incurring GC pauses. It works because larger heaps have no downside costs, and no larger pauses to worry about. And for both Scala and Akka specifically (which is the original question, I believe), both of which tend to idiomatically make use of generous memory allocation under the hood, Zing has been a great way to eliminate the pausing artifacts most people see when running on CMS/G1. Sure, telling people they should re-write their application on top of something that doesn’t pressure the poor garbage collectors on HotSpot into annoyingly pausing occasionally is one way to go. But solving the problem cheaply and quickly with a GC that doesn’t complain or pause, so they can move in with their Scala work without having to port their code to C++, seems to make sense to most people who actually consider the cost alternatives...
The simplest answer is to try it. Zing has a free trial you can download straight from the Azul site, and it drops in with a simple change of your JAVA_HOME. Turn it on and see what it does for your specific application.
You don't have a real problem to solve here. If your instructor just wants to see you using Spring XML then the easiest way to pass might be to use that. Otherwise I think you need to get clarification about what the realistic requirement is. XML is often a bad idea in Scala even for cases where it would have been a reasonable idea in Java, for reasons similar to those described in http://dirtsimple.org/2004/12/python-is-not-java.html
Yes, yes I am. In fact the bigger problem is that you guys rewrote the JIT compiler to with your GC engine. So even though you made the GC pauses the ~same (to maybe a tad better) compared to CMS.. you made our happy case between the GC pauses ~20% slower. That 20% slower increased backpressure of our app, causing up to 5x increased latencies. So even if you got the the GC part PERFECT and made the GC time 0, our app was literally 5x slower with Zing over CMS. This is not a matter of not using reccomended settings. I had Gil Tene providing the settings. If your boss gave us the wrong settings you might have other problems. You might want to ask your PR bosses if you want these details being made public? I doubt Gil would be happy about this getting public.
This *is* Gil... ;-) (that last comment you had replied to above) And I'd be happy to openly discuss a case where a 1 second or half second GC pause remained after you had applied Zing. Since we literally don't know of one internally, perhaps this will be the first report we hear of, and I'm happy to discuss it here if you want, including how to get rid of it. Note that I'm referring to the pauses themselves, which is what the question was about, and what your answer (specifically the "If you are seeing something like a 1 second or even a half second GC pause, you have other problems that you can't just "fix" with Zing" parr) above said Zing doesn't solve. Speed comparisons are orthogonal to wherever or not the pauses are gone. And Zing's JIT'ed code has gotten dramatically faster in the past year or so. Especially on newer processors.
Oh sorry!! I'm not very skilled at English (sorry for that, too), and didn't knew that was a joke ^_^''
Agreed. I tech reviewed a book for Packt once and my review told the editor that the book was such a broken mess that I didn't think it could possibly be salvaged with the current authors. My recommendation was to simply not publish it, and if they were going to publish it against my recommendation, to please not include my name anywhere in it, including the acknowledgments. The editor responded by asking me if I wanted to help rewrite it. I declined. Packt is garbage. 
I must be lucky, then; about half of the tech books that I've bought in recent years have been Packt because most of them are in the Amazon MatchBook program, and I don't always have time to wait for a physical copy of a Manning book to arrive before I dive into the e-book. Out of those Packt books, I've never noticed any obvious errors or omissions, but then again, I've stayed far away from anything from them with less than a 4-star average rating on Amazon. Sad to hear that their content standards are so lax.
Well I'm not gonna lie, this particular book actually looks pretty good at a glance. I still stand by generally hating Packt though. I think they're a quantity over quality publisher that just floods the marketplace with books that have a very short shelf-life.
I think you're hitting https://github.com/sbt/zinc/issues/433, feel free to comment on the issue to bring more attention to it.
The fix is apparently [here](https://github.com/sbt/zinc/pull/371), but the PR is targeted for Zinc 1.1 :\ I don't understand how this isn't a high priority/fix immediately item, who isn't affected?
https://pbs.twimg.com/media/DNY7NqOWkAEtADW.jpg:large thoughts?
Don't curse pakt publishing. At least they release books on subjects I need to learn. Other publishers are so slow to bring books to the market. For example look at the fate of the book https://www.amazon.com/Play-Practice-Building-Reactive-Application/dp/1491916087/ref=sr_1_1?ie=UTF8&amp;qid=1509401429&amp;sr=8-1&amp;keywords=play+in+practice I added this book in my wishlists like 2 year ago. the publish date keeps moving till eternity. I don't know if the author is just sleeping and has lost interest.
If some outstanding optimization happens, I would expect one of few things: change of assumptions (then old code is a different use case and cannot be directly compared), better algorithm (this could be copied), fuckup in slower code (can also be fixed), biased benchmark (shows only the cases where one code is faster). So I would expect Scalaz 8 if this is so much better than eg Monix then next versions will close the gap. But I will wait for more results. This guy is over enthusiastic about Scalaz so I take whatever he says with a grain of salt.
i believe it was cancelled already. this used to be the book's page: http://shop.oreilly.com/product/0636920035718.do
Orielly is not the only one. See this one https://www.manning.com/books/grokking-functional-programming This book is in MEAP for 4 years now. Fuck Manning.
Probably because zinc is low on manpower.
&gt; the quality of most packt books is abysmal This is true in my experience, and the incredibly high pricing compared to other publishers really makes me wonder how they stay in business. Packt easily wins the award for worst tech publisher. That said, after taking a risk on this book, I was pleasantly surprised. The editing standard still isn't what you'd expect from other publishers, but the content is solid and the writer does a great job regardless. I'd highly recommend this book for anyone ready to move on from Programming in Scala. Some of the topics are important but difficult to pick up in the wild, so I really appreciated having all the information in one place. I can only guess they made this one free to try to improve their image. People should take advantage of it in any case.
This is the interesting part of the debate: https://twitter.com/jdegoes/status/925114030573973505 It has to do with map whether to catch in map/flatMap. John doesn't, which still shouldn't violate the monad laws, as you can't throw before you get an argument, so any reference or inline lambda would behave the same, I think. For java interoperating functions, I'd prefer for flatMap to catch, but forcing users to use attempt, instead is, I guess, more performant and explicit. It just feels a little leaky to me to have to catch manually, but not 6300x leaky.
I remember purchasing this when it first came out. About a year into it I received an email saying the deadline would be extended and was asked if I'd like to swap it for anything else. I'm sure if you email Manning they will refund you.
[removed]
I just wanted to share this here. This is why I love Scala, elegant API designs for data structures.
No, it doesn't. My instructor only recommend because he thought that I can improve my implementation. Thanks so much for the tip! I'll refactor that.
Nice. In the examples, what is the difference between syntax `light |+| washing |+| drying |+| standby` and syntax `a | b | c | d | e`? Doesn't the latter also use the fact that `Set` is a monoid? In general, do you know good implementations of `Map` (not `IntervalMap`) that also allow merging values like that? I wish Scala's standard `Map` allowed us to do it and did not just "forget" previous bindings by default (as in `Map(0 -&gt; 1) ++ Map(0 -&gt; 2) == Map(0 -&gt; 2)`).
True, the main point is that it isn't comparing apples to apples. It means that the Scalaz 8 task is even more unsafe/incorrect than its competitors, even though Scalaz is one of the few libraries that puts precedence of correctness/safety over everything else. Nothing wrong with this, but claiming "you should never throw exceptions" is not really going to cut it in Scala land, so I see a lot of people just not using Scalaz 8 Task (or even worse, using it improperly). Ironically even Scala standard `Future` appears to be safer in this respect. In any case its not being helpful that he is selling the Scalaz8 IO Task like some magical snake oil. Its trading performance for correctness (which is fine, but don't try and hide this). In any case due to what is said here https://twitter.com/djspiewak/status/925115696903843840, it appears that Scalaz 8 Task is also going to have severe issues in any situation where you have an external thread controlling your async computation that is out of your control (i.e. putting computations onto a UI thread, having a dedicated thread for receiving messages etc etc).
The provided monoid does the union on set. It will be called [`zipByKeyWith`]( https://github.com/scala/collection-strawman/blob/47e5e14e5679be386df5f8c232ad3c21246e92b7/collections-contrib/src/test/scala/strawman/collection/decorators/MapDecoratorTest.scala#L9) 
&gt; The provided monoid does the union on set. Your answer is a little cryptic. What provided monoid? Where does it come from? Anyway, my question was about the syntax. Can I also write `a |+| b |+| ...`, and if so why have two different syntaxes? &gt; It will be called zipByKeyWith Great that we'll get that in the standard library!
Here is mine: https://github.com/pathikrit/scalgos/blob/master/src/main/scala/com/github/pathikrit/scalgos/IntervalMap.scala
&gt; claiming "you should never throw exceptions" is not really going to cut it in Scala land Depends which part of Scala land. There are production codebases that avoid throwing exceptions, that enforce that the codebase doesn't throw via wartremover. It's eminently doable.
I still use Scalariform, despite its warts and slow development. Last I looked into Scalafmt, it lacked a lot of the rules I liked. But I'm probably due to have another look. 
Disclaimer: Publishing this as an sbt-plugin was simply the fastest way to get a hotfix-candidate out the door. This isn't a permanent fix to the SBT watchservice issue. Things may be broken, it might not work for you (it seems to be working for me at least) or something else may be off. When the issue is fixed in trunk this plugin should go live on a farm.
It is, but often you have to interact with some java code that throws deep in its bowels, and WartRemover won't catch that use case AFAIK. Rewriting everything in scala correctly isn't always a productive option, especially at smaller organizations that don't have the throughput to do so. Having your IO catch for things that are already side-effecting means that you don't have to manually account for these things, and can handle the error in one place, at the end of the world. Handling errors is boilerplate that makes using IO extremely convenient in java interop cases, where you are using IO to wrap your java call. Sure, we can all go out and write our own Free implementations for every effect that happens, but I'd rather use IO as the catchall here-be-dragons that it was intended to be.
I wonder whether the benchmark test the same thing (in the sense of "all the code _does_ the same thing") or the same code (in the sense of "all the code looks the same"). I guess it is the latter, as `Future`'s execution model is (luckily) very different from the libraries that came after it.
&gt; Having your IO catch for things that are already side-effecting means that you don't have to manually account for these things, and can handle the error in one place, at the end of the world. For an unplanned exception in a Java library you call, there isn't usually anything useful you can do at the end of the world other than log it and alert the programmer - and you can do that equally well in your uncaught exception handler. &gt; I'd rather use IO as the catchall here-be-dragons that it was intended to be. I don't think there's any value in talking about intent (and if we want to have a catchall here-be-dragons I'd really rather it wasn't called "IO"). How many use cases it will or won't cover is what matters, not which one it was originally designed for.
I remember at some point such results were already posted by John de Goes and Alex Nedelcu (Monix author) asked about benchmark code, so that he would figure out the reason and optimize. John responded that the code will be published later. I don't know how it ended but I would expect Alex to close the gap with Monix soon after this benchmark would be published. Additionally discussion suggest that this code is faster because it doesn't catch. So I guess it's a trade off with security. It should work if none of your functions uses exception driven error handing. Slightly differing use case.
&gt; even though Scalaz is one of the few libraries that puts precedence of correctness/safety over everything else It's not as if Task's inclusion went in uncontroversially, or even was able to make it in to scalaz 7 without Tony Morris's ouster from the project. Hence issues like these: * https://github.com/scalaz/scalaz/issues/1401 * https://github.com/scalaz/scalaz/issues/1086 * https://github.com/scalaz/scalaz/issues/659
Fair enough. We get some exceptions due to api limits, and retry on particular errors, and route others elsewhere to be analyzed, but that could indeed be handled by a global handler (and it is, it's just inline in our codebases). Like I said, 6000X performance improvement is *worth* a little leakage as long as it conforms to the laws. Not catching in Future makes it unlawful in scalaz land, so it is a little incongruous if it doesn't conform for performance benefits. I still think intent matters -- if it doesn't cover the intended use-cases, it's buggy. Not catching automatically is slightly less surprising in scalaz IO because IO extends Catchable, currently, and that explicitly states that ambient exceptions are caught by attempt, and fail should be wrapped in attempt. flatMap(attempt(javaCall)) isn't horrendous at any rate.
He wasn't wrong about going slow ...
Interesting. Do you have any examples of a project I can see?
[removed]
All lawfulness is only for a particular subset of possible functions - e.g. almost every lawful equivalence in any implementation is violated if one of the functions is `Thread.currentThread().getStackTrace()`. Scalaz takes the position that `throw` is illegitimate and lawfulness is only defined for a fragment of Scala that does not include it (the "scalazzi safe subset").
tldr; use `Option` properly..
I'm really confused by this question, do you just want to run some other main on your classpath? Or are you trying to transition from unmanaged dependency to a managed one?
blogspam
nice try pakt
Presently, I'm literally running a "java -jar dependency.jar -arg_a -arg_b -arg_c..." from my main's directory, and I'm looking to move away from that, be it by running its' main from sbt or otherwise.
Didn't they switch back to sbt 0.13 behavior (polling) on Mac os x in sbt 1.0.2 because of this?
They did in 1.0.3, but it doesn't seem to have helped much.
Yup, at this point though its whatever is practical or not. `Thread.currentThread().getStackTrace()` is pretty much either never called, or if it is then its part of logging (which is one of the few things that is in the "not lawful but don't care about box" Throwing exceptions (in general) is very common in Java and rare in Scala (but also done and throwing exceptions in Scala is not considered non idiomatic, although its always possible to make a style guide of no exceptions) The point is though even with `Wartremover` you can't guarantee this, and a lot of cases of throwing exceptions are Java libraries (or Scala wrappers over java libraries), case in point IO related stuff, which scalaz will almost end up using, you will get exceptions
I think you can try `coursier`.
Already am using coursier. Does it include some magic functions for this?
WatchService on MacOS has resolved in sbt 1.0.3 https://github.com/sbt/sbt/releases/tag/v1.0.3
Yea, it's gone. It was replaced by the new courses that are part of the Scala specialization. When I did that specialization last year, I expected Akka at least to be mentioned in the parallel programming course, but that wasn't the case either.
The course is no longer present on Coursera. However, all the relevant videos are still present on YouTube (just search principles of reactive programming scala) if that helps.
I believe the videos you're looking for are on Roland's site. https://www.reactivedesignpatterns.com/ 
To be honest, you'd be better off learning about Rx or Akka by reading more up-to-date blog posts. No offense to anyone who put time into developing that course, but the end product wasn't as good as the introductory Scala course. At least, that's the impression I remember having ~4 years ago when I took it.
What about Linux?
Not exactly sure I understand your setup but does it work include the dependency in your build as and then to simply use `runMain`? See http://blog.ssanj.net/posts/2016-03-02-how-to-run-a-specific-main-class-with-parameters-through-sbt.html
It’s not resolved, it’s a workaround - it is back to polling now
It's "solved" by using the old watchservice from the 0.13 version. The problem with this is that it is doubly polling — the watchservice first polls all paths to see if there's something new, and another thread is polling the watchservice to see if it has something new to report. For all but small projects this is not performant. This plugin uses a native implementation that discovers changes nearly instantaneously. It is still polled by that other thread (it's a pretty weird architecture), but at least the changes will be discovered quicker.
This was a scratch-my-own-itch experiment. I'm not running Linux so I won't be able to fix it. Theoretically, it could be solved in the same way as I've done it: by wrapping a native implementation in a SBT-compatible layer.
Not to sound glib, but I recommend educating your team. Shapeless uses techniques that may be unfamiliar to you, but it's not magical and shouldn't be scary. It's the standard way to do these things in Scala. I suggest you check out Dave Gurnell's [free book](https://underscore.io/books/shapeless-guide/) and his Scala World [talk](https://www.youtube.com/watch?v=Zt6LjUnOcFQ) which might help your team overcome some anxiety.
One option in the first instance might be for your team to have a single ShapelessUtils scala object, into which you put all the shapeless-related functions you develop. Most of my shapeless stuff emerged from a copySO-paste-tweak kind of workflow. IMO you just need to see a lot of this sort of code to see how it works; then you absorb the concepts by a kind of osmosis. If the code is in one place then people can see the possibilities more easily, and evolve them as necessary. Of course at a later point you can refactor as appropriate. If it's purely typeclass issues, see: * https://github.com/mpilquist/simulacrum * https://gitlab.com/fommil/stalactite 
I agree. I just don't see a lot of enthusiasm so far. (I'm relatively new to the team, though).
I'll look at stalactite, thanks for pointing it out. I'm familiar with simulacrum, but AFAIK it doesn't really contain anything that would allow me to derive typeclasses generically like shapeless does.
Then it's a perfectly fine workflow. I don't see any problem with running the published jar directly.
I'll explore this option. Thanks!
Who's to say HList and Generic aren't some of the "scary" parts?
It seems Java (and C# too) is gradually turning into a bad version of Scala. I've totally lost interest in the language which IMO never will become useful, but any improvements they make to the JVM in the [Valhalla project](http://openjdk.java.net/projects/valhalla) like value types, specialization etc. will of course be good for other, better languages running on the JVM.
I don't share your pessimism. I am glad that these useful improvements come to a broader audience, even if at a glacial pace. Similarly, I'm glad at the success of Kotlin, even though it competes with Scala.
It's just too little, too late, and re-using `switch` for pattern matching is just awkward (`case`is fall through by default and it's a statement, not an expression). Some fundamental flaws of Java off the top of my head: - No proper local type inference (WTF, all "modern" languages except Java has this!) - The variance notation is just utterly painful to use - Limited type system with no support for HKT, type members etc. - Nothing similar to extension methods, type classes or implicit parameters etc. It's just a bad language built on a broken foundation. At least Kotlin is step forward in language design, and I could possibly see myself using it professionally (but I would choose Scala over it any day).
hindsight is 20/20.
And Dotty (Scala 3.0's working nane) is Scala's pragmatic use of said hindsight!
Honestly I can live without local type inference. The rest is really annoying though.
It's too little too late for Scala devs, but not too late for all those Java devs. They won't care about "but, but, we had data classes 10 years before Java!".
For Scala to benefit from Valhalla, preparations would have needed to be started already. Just look at `Option`. To turn it into a value type, you would need to a) introduce a new type of deprecation warning, b) replace the remains with something aligned to Valhalla, and as a bonus, c) re-engineer things in the backend to unbox one layer of `Option[A]` with a non-nullable element type A to `Null|A`, which in turn requires support for `Null` and deprecation of everything being nullable by default. Additionally, it would be very smart to get in touch with the developers of Valhalla to sort out the issues around identity and equality in a fashion helpful to Scala (which makes Scala's `==` nearly overhead free _if_ the semantics in the bytecode are speced properly). There is a good solution to that, and it would solve the issues raised about `eq` years ago at the same time. Nothing of this has happened.
I wouldn’t say I was too lazy to learn a GUI. I’ve used a bunch of different ones and implemented my own from scratch in C for video games where there is no GUI library available. My feeling is that as a developer my time is better spent on what differentiates my applications from others. For you maybe that’s building a native app that is super fast and uses less memory. For me I want an easy way to build developer support applications with lots of features that feel professional. I’m a backend developer and I run slack alongside IntelliJ and both compile and run tests all day. I have never seen slacks memory use be an issue, nor it’s cpu for that matter. The biggest offender is often twitters website or IntelliJ background processes. 
Yes, it's a complex problem (which I don't fully grasp). Universal equality and `null` are really the biggest warts in Scala (and they can't really be fixed while still retaining "nice" Java operability). It makes me sad to see that Scala's equality semantics are [still being discussed](https://contributors.scala-lang.org/t/can-we-get-rid-of-cooperative-equality/1131) today. These are non-issues (besides floating point equality of course) in Rust, Haskell, PureScript etc.
&gt; It makes me sad to see that Scala's equality semantics are still being discussed today. Yes, saw that thread after someone sent a link and asked for comment. Do you know this feeling when you have to take breaks from reading, because the thoughts are just so ... incoherent? Shout out to Scott Carey who brought some sense back into the debate. There is a nice, pretty obvious solution to all of this, and Scala could even get it basically for free. But that would amount to getting in touch with Java devs before the design is done, because Java devs have exactly the same issues with specialized generics.
I've stopped following the Valhalla debate as the design ideas were all over the place. When/If it materializes to something useful I hope the Scala devs are ready for it and wont be standing there scratching their heads on how to make it work in Scala. They've already wasted a lot of time implementing half-baked solutions like specialization, miniboxing, value classes etc., so I hope they get it right this time. I'm not overly optimistic though.
&gt; When/If it materializes to something useful I hope the Scala devs are ready for it and wont be standing there scratching their heads on how to make it work in Scala. That's why it's instrumental that Scala figures out what it needs, and talks to the people designing Valhalla, Otherwise I can guarantee you that Scala won't be ready for it (it isn't, just look at the compiler, and how much stuff would need to be rewritten), and they will end up having to work around a design that might be close to Scala, but having just enough mismatch that bridging the gap will be extremely costly and time-consuming in itself. Just what happened with traits/default methods, when people realized they needed to keep all the boilerplate static forwarding stuff. (It only looks slightly nicer in Java 8 due to a different, unrelated feature.)
I have to side with your team here and disagree with tpolecat. Shapeless is one way to do things in Scala, but using Scala doesn't mean you have to use Shapeless, or Catz, or Scalaz, even if you want to use functional programming techniques. In addition to your team's concerns about scary / magical / far-out code, you also have the practical considerations of transitive library dependencies with these libraries -- if one project uses one version of Scalaz and another uses a binary incompatible upgraded version of Scalaz, then you can't use those two projects together. This gets especially hairy when you have code that you export as library dependencies, because now everything has to be in sync. If you're doing this in domain code i.e. not a library you're exposing for framework use then you can use Shapeless as an implementation behind an API and keep it in a sub-project with no library dependencies exposed to the other sub-projects. That way you can minimize your dependencies, and ensure that you can swap out Shapeless with something else without rewriting the entire application, which is something that has happened with teams using Scalaz.
&gt; My feeling is that as a developer my time is better spent on what differentiates my applications from others. For you maybe that’s building a native app that is super fast and uses less memory. And here is the problem: it's not about being super fast or over-optimizing for memory but for the app to have reasonable latency and don't leak the memory like crazy.
I agree and disagree with you. I agree with the idea that if you need to use Generic, then "just use Shapeless" is the way to go. But I wouldn't oversell the extent to which typical programmers are going to be able to fully understand the way those abstractions are implemented under hood in any reasonable amount of time.
Here is a list of threads in other subreddits about the same content: * [Plot easily plotly graph through a scala-js facade. https://github.com/mathieuleclaire/scala-js-plotlyjs-demo](https://www.reddit.com/r/programming/comments/7ad62a/plot_easily_plotly_graph_through_a_scalajs_facade/) on /r/programming with 1 karma (created at 2017-11-03 01:41:38 by /u/mathieuleclaire) ---- ^^I ^^am ^^a ^^bot ^^[FAQ](https://www.reddit.com/r/DuplicatesBot/wiki/index)-[Code](https://github.com/PokestarFan/DuplicateBot)-[Bugs](https://www.reddit.com/r/DuplicatesBot/comments/6ypgmx/bugs_and_problems/)-[Suggestions](https://www.reddit.com/r/DuplicatesBot/comments/6ypg85/suggestion_for_duplicatesbot/)-[Block](https://www.reddit.com/r/DuplicatesBot/wiki/index#wiki_block_bot_from_tagging_on_your_posts) ^^Now ^^you ^^can ^^remove ^^the ^^comment ^^by ^^replying ^^delete!
I don't think kotlin competes with Scala, if anything it competes with Java by improving the language faster. Scala on the other hand is a very different language.
&gt; shapeless is one way to do functional programming things in Scala I don't think when tpolecat meant "these things" he meant functional programming. I think you've completely misunderstood the the context here completely. The problem is the /u/PoseidonInChains wants to work with dependant types and type level computation. If you want to work dependent types in Scala(which is orthogonal to if you're programming imperatively or functionally) then shapeless is the "standard way" of doing this. That said, shapeless works around areas where the language is lacking, unlike Scalaz and Cats, I think there's pretty much universal consent that much of shapeless would be better as language features. When working with shapeless you're working at the boundaries of what actually works well with Scala, which is where the idea that it's "far-out" comes from. &gt; But there's also the problem that a team has turn over, and new hires need to be brought up to speed -- which means every new hire needs that education and ramp up time. You may not be at the company as long as your code is, and the team may go on to work on other things. Meanwhile, that code is still there. I think the problem with this argument, is once you're in the domain of working with dependant types, trying to do it without shapeless, absolutely without a doubt will hurt maintainability. If you're going to argue against working that domain entirely, we don't know if the requirements of what /u/PoseidonInChains domain makes that reasonable to do or not. &gt; if one project uses one version of Scalaz and another uses a binary incompatible upgraded version of Scalaz While shapeless does have some runtime, most of the library is really just solving types. &gt; If you're doing this in domain code i.e. not a library you're exposing for framework use then you can use Shapeless as an implementation behind an API and keep it in a sub-project with no library dependencies exposed to the other sub-projects. That way you can minimize your dependencies, and ensure that you can swap out Shapeless with something else without rewriting the entire application, which is something that has happened with teams using Scalaz. I'm not sure how this argument couldn't be applied to literally any library and is helpful in any way. It's just stating the obvious. The the most important questions with on if to use shapeless is: * How well do you want to leverage types in developing your application? * Are you comfortable with the idea that much of shapeless tied to the implementation of the complier and may be replaced by language features someday. * If macros weren't experimental would you use those instead?
So right now Slack is using 1% CPU and 60Mb memory and as a user I cannot tell the difference between the electron app and other apps such as Skype which is using 184Mb and as far as I know is native. 
&gt; Maintaining code is roughly 90% of the work. Indeed, and by using shapeless you can make this easier by removing boilerplate and adding more precise types, so your code is more likely to be correct and stay correct as it evolves. &gt; shapeless is one way [...] but it's not the "standard" way Shapeless is the standard way to do generic programming that abstracts over arity in Scala; i.e., `HList`, `Coproduct`, `Generic`. If you need this stuff you're not going to be able to do it yourself in a way that approaches the functionality and reliability of shapeless. You'll be reinventing a lot of very spiky, bee-infested wheels. &gt; you can use Shapeless as an implementation behind an API Indeed. Shapeless is often confined to typeclass derivation, which is generally transparent for the end user.
Well I have to agree with tpolecat. Nobody's talking about functional programming here. It's about automatically deriving an HList from a case class and then doing interesting things with that HList. Fact is if you want to do those things, and use those HLists in a nontrivial way you won't have much choice but to use those "scary" techniques of Shapeless. If Shapeless is too scary then generic derivation of typeclasses will be too scary.
 &gt;To the second point: shapeless is one way to do functional programming things in Scala, but it's not the "standard" way -- there are several functional programming libraries out there. I'm not really asking about functional programming in general. My reason to use shapeless would be specifically automatic typeclass derivation for arbitrary case classes. As the relative dearth of actual answers to my original question indicates, there doesn't really seem to be any alternative. I guess I'll try and do a bit more convincing while addressing the maintainability concerns more explicitly.
Well put. Precisely what I would need it for. And no: I'm definitely not going to attempt to implement the wheel here. 😉
&gt; So right now Slack is using 1% CPU and 60Mb Nononono - that's not slack - or not all of it :D Slack has multiple processes just like chrome. Most people report around 1-2gb ram and sometimes it leaks and consumes all your RAM. Just think about it - running a headless chrome with a nodejs server and consuming only 60mb - isn't that suspicious?
It says it only works on Fedora and CentOs, is there a reason for this? I'd imagine it shouldn't be too different to make it work on other Linux distros.
Do you have a reference to this sanity-restoring discussion?
Sooo, it's like closed-source Spark notebook with deeplearning4j-first, did I get it right?
Right now initially deployment is targeted at centos. It's not due to any particular reasons. You could easily run it in a container. We'll add more platforms here very soon. 
Effectively: we've just not yet done enough testing on all the variations of linux yet, so we don't advertise the others. We just want to be clear where our testing efforts have gone so folks don't hit surprise bugs, etc. More linux, win, and macOSX supporting (officially) coming soon.
Well, partially. There is also a model server, and then a context system integrated into the notebook system that allows us to track different variants of notebooks in a group, called a "workspace". The interesting mechanic that I'd point out here is how simple it is to take the model from a notebook, and have it treated basically as a "database table" (metaphorically) in the model server, and then connected via REST to an external application. Each of those steps on their own are not mind-blowing, but when you put them all together in a suite, its something more akin to "Visual Studio .NET + backend infra" --- but focused on this generation's of deep learning applications. The other factor is that we're quickly adding support for more libraries beyond DL4J, with python-based notebooks in workspaces being added soon that work seamlessly with the rest of the system. We hope you'll give it a shot and see what you think.
It's a ton more than that. Managed model server means experiment tracking, an api for model feedback (basically users can say "I got this wrong") , it's also a process runner for applications ( we will expose this a bit more later on). The target analogy is "on prem AWS" closer to a mix of collab with the notebook and other applications. Right now, the "coding portal" is zeppelin, but we also have other applications upcoming. The first major "app" is the model server though. A notebook is not a model server. A big pitch for this is a 2 sided work flow: both running models in production via model import (tensorflow and keras initially) and also being able to run distributed training with spark and a managed gpu cluster. One point people often miss is gpu management. A managed spark/gpu cluster with an admin interface with zero setup and model import is the major goal here. The bits are there in dl4j already for gpu resourrce management already, making that consumable with no setup as well as having a first class spark integration (which already works and is in production today) will help make these resources more consumable for folks. It's a lot closer to the managed ML offering that google and microsoft are going after but targeting on prem spark clusters and managed mkl/cuda connected to your cluster for running neural nets.
Sure, why not. I once played with Spark notebook, but I see it now as more of a playground for designing big data playground that ML might just be one use case of. Had I been developing some ML application something more ML-centric SKIL could be a good call. I understand you are part of the dev team? Out of curiosity - how much of a vendor-lock in should I expect? ;) I mean: if I wanted to test models with SKIL CE and then translate them into Spark + DeepLearning4J or Akka Stream with DeepLearning4J would it be a terrible rewrite or just few changes in model? I am asking, because I am one of those paranoic guys, that want to feel that going premium is a conscious opt-in, not something I am forced to.
So (simplifying) I should not consider this closed-source notebook, but more of a AWS-like platform for ML where I could use open source stack, but with closed interface to manage cloud and test models simultaneously? That's surely an interesting idea. :)
How is this better than Jupyter scala ? Why is it closed source ?
It's a lot more than a notebook. You have whole model tracking built in to it, you have model import with built in model serving, distributed cpu/gpu management. You don't get any of that with just a notebook. A notebook is just the interface to the built in managed environment. You can think of it as a hybrid between google cloudml and a managed notebook environment with dependencies. The goal is to have 1 place to put your models and have an environment for people to collaborate as well as put things in production. As for why it's closed source: Most of the bits are there in dl4j out in the open source. You can think of this as a cloud service we're giving out for on prem deployments. We'll be putting this out there as a cloud service as well with AWS integration and the like coming up.
Yes perfect!
Hi, I cloned your repo from GitHub and imported as a STB project, but I have an error saying "Cannot resolve reference bindAndHandle with such signature". As you properly can guess I know very little about Akka 
&gt; No proper local type inference `var` will come to Java in March 2018.
Hi! I think it should be a bug in IntelliJ IDEA. Please change the following line in the RESTServer.scala to the following: From: val route = new TodoRoute().route To: val route: Route = new TodoRoute().route 
I got it! 
Everyone's on the various Gitter channels, here's [scala lang](https://gitter.im/scala/scala) to get started; there are many more.
I think interesting discussions went down quite a bit since the mailing lists were closed down, especially the scala-internal one and the contributors forum is very different from it: scala-internals was all about "this is a problem, and here is how I'm going to fix it", while the contributors forum is largely people having ideas, but no intention of implementing them. There is still some activity in Gitter channels, but it is spread wide and far, and finding anything in them is rather challenging. Overall, there seems to be a visible loss of activity and mind-share due to recent events. So yes, I think there is no central place to discuss Scala-related things where people can look for topics and participate in discussions.
I think that most of the people are learning Scala nowadays. Personnally, I haven't found anything that deserves to be published here, as I said in another post, mainly because I'm learning the true functional side of Scala (which, IMO, is the most interesting one). As soon as I master Scala &amp; functional programming, sure I'll be publishing new ideas I find or any interesting stuff. Maybe a lot of people thinks the same, am I wrong?
recent events such as ? Or are the "recent events" just the closing of the mailing list ?
IRC: #scala@freenode
I don't know if there is the _one_ blessed forum, but there are also these now: - https://contributors.scala-lang.org/ - https://users.scala-lang.org/ 
Have you checked twitter? If you follow some top scala guys and watch responses, you'll see that the circlejerk is quite active actually.
&gt; So yes, I think there is no central place to discuss Scala-related things where people can look for topics and participate in discussions. There's pretty decent activity in - https://contributors.scala-lang.org/ - http://users.scala-lang.org/ Just one example from past 24hr https://contributors.scala-lang.org/t/upates-to-scala-concurrent-future-wrt-breaking-changes/1281 &gt; Overall, there seems to be a visible loss of activity and mind-share due to recent events. It's almost as if u/simon_o has an agenda to spread negative rumours around Scala. You regularly contribute many insightful technical comments about the compiler and language design, but FUD spreading comments like this is not one of them.
If you're looking for talks, /u/know_not_much is really dedicated and posts all the talks he can find in https://www.reddit.com/r/ScalaConferenceVideos/
&gt; There's pretty decent activity in Nevertheless, I think both the quantity and the quality have taken a substantial hit compared to the old mailing lists ... which is exactly what I said above. &gt; there is no central place to discuss Scala-related things You listed multiple places. _Q.e.d._ &gt; It's almost as if u/simon_o has an agenda to spread negative rumours around Scala. And what would that be? It doesn't make sense to engage in conspiracy theories just because someone has opinions one doesn't like to hear.
My opinion is the exact opposite of tpolecat's here. So the "standard way of doing things" is to live with super-slow compile times due to avalanches of code vomited by recursive implicits that went wild? I think we must do better than that! I get about 2000 lines / sec compile speed on average for all code I am writing. How much do you get? If it's significantly less than that, blame the libraries you are using. 
I think the whole Kotlin story had a substantial impact on adoption and mindshare. If a Java dev looking for a better language who visits both the [Scala homepage](http://scala-lang.org) and the [Kotlin homepage](http://kotlinlang.org), will likely pick the latter one, based on the information provided and how it is presented.
This is really good advice, I always forget about this.
To be honest I never thought Koltin and Scala have much to do with each other. I always viewed Kotlin as sort of a "blue collar" programming language, made for large legacy projects that will have loads of hands working on them and must be free of bugs (e.g. bank software). Whilst Scala is more of a "startup language", made for ambitious projects that have to accomplish complex tasks (e.g. code that can easily scale to hundreds of machines) with minimal effort and with whatever coding style the authors wish.
[Edited from a former post where I missed some nuance] I don't quite share tpolecat's view here. It's true that shapeless is a fairly established way of doing certain kinds of generic programming in Scala. But it does come with significant costs. It often leads to very hard to understand code and to super-slow compile times due to avalanches of code vomited by recursive implicits that went wild. I think we must do better than that! I get about 2000 lines / sec compile speed on average for all code I am writing. I.e. clean-compile of a 40'000 line project with a warm compiler: ~ 20 seconds. How much do you get? If it's significantly less than that, blame the libraries you are using. So, while I would agree that shapeless is a standard way of doing generic programming, I would disagree that generic programming as a whole is already the standard recommended way to write Scala programs. In fact my opinion is we have a long way to go still until I would recommend it as a practical solution in most cases.
Yes, I am the product manager for SKIL re:vendor lock-in: so I'd put it similar to how you'd look at using a distribution of Apache Hadoop; Each distro (CDH, HDP) has its own "fingerprint" of different Apache components (+more) in the distro, and its all baked together such that it all "just works". While technically its still (mostly) open source, you are still investing integration / app-dev resources into building on that fingerprint. Really, you are created your own form of lock-in that way with every variant of "open source" infrastructure. It's just a different form of lock-in than we say w the previous generation (Oracle, etc), and typically lower in price. If you look at the market, there have been no new enterprise infrastructure companies that do not have some sort of open-core component to their model. Now, wrt SKIL, what you'll see is that for each version we'll publish a "DL4J-compatibility version" (what its built on, uses internally) and then notes on what else other patches are in the version (Cloudera does this with CDH). So its very much in that model, and if you took a Spark job (for instance) on CDH today, and then moved it to Apache Hadoop, you'd have to do some re-compilation (and possibly more, header changes, etc). So it's basically like that. We definitely want to be compatible w the open model / lib formats in the market. SKIL is targeted at having Keras, TF, Caffe, and more interop (first model server support, then workspaces) in the near future, so having any sort of "lock-in" on DL4J and then open-compatibility on the other libs just really wouldn't play right. So I think you are valid to ask those questions, and to continue to do so and keep shops like Skymind honest on that front. We mean for SKIL to be more like how you treat "a RDBMS", in that its a part of your core (connected) infrastructure for "getting things done", as opposed to keeping you locked in a garden. Trust is part of that equation.
&gt; To be honest I never thought Koltin and Scala have much to do with each other. That's true for those who know Scala, but it's not what people who want to learn a new language know after visiting the webpage. Scala fails to communicate clearly and answer important questions these people need to know to make an informed decision.
Thanks for a great answer! I really appreciate your openness :)
&gt; The KotlinConf recap is a good example of how the creators avoid the mistakes Scala makes. How is that an example? I don't connect the first part of your sentence with the second. Almost everything that they write in the recap has analogous efforts in Scala, from MOOCs to Scala Center, to improved APIs, to Lightbend demos, ...
Well... how would you put what scala does into a few paragraphs though ? Personally I had to read pragmatic Scala before I realized half the awesome coding patterns that could be implemented easily using Scala. To this date if someone would ask me why I like using it my answer would be very vague and along the lines of: "Because it magically allows be to write less code that is more expressive, prettier, runs faster and catches more bugs at compile time" but I couldn't pin point an exact reason as to why and I don't think the reasons I like it are necessarily the reasons other people do.
&gt; How is that an example? I don't connect the first part of your sentence with the second. _experimental support for multiplatform projects_ Kotlin is acknowledging that different platforms exist. Scala has and is still fighting tooth and nails against that. _compiler now rejects binaries compiled with earlier pre-release versions of Kotlin 1.2_ Meanwhile, Scala still doesn't even record the version number in its classfiles. [Bug report](https://issues.scala-lang.org/browse/SI-3554) from more than 7 years ago. _Coroutines are fully ready to be used in production_ Meanwhile, what's the status of scala-async? scala-pickling? scala-parser-combinators? _we will provide the necessary migration tools_ Meanwhile, the Scala rewrite tool has been "just around the corner" for close to 4 years. _support for iOS development with Kotlin/Native_ Kotlin is answering the questions people have. _you need an IDE to be productive with any language_ Meanwhile, Scala shipped major releases without IDE support. I'll stop here, and I have covered only half of their announcements. &gt; "I find that website color scheme nicer than the other" I think nobody made that point. _Statically typed programming language_ _for modern multiplatform applications_ _100% interoperable with Java™ and Android™_ _Build Applications For JVM, Android, Browser, Native_ That's what people see without scrolling. It clearly answers - what is Kotlin? - what's the purpose? - can I use it? - where does it run? For comparison: _Object-Oriented Meets Functional_ _Have the best of both worlds. Construct elegant class hierarchies for maximum code_ _reuse and extensibility, implement their behavior using higher-order functions. Or_ _anything in-between._ - what is Scala? A UML design application? Some framework like Spring? Some library like Hibernate? - why would I want to have both worlds? - Aren't deep class hierarchies an anti-pattern today? What does Scala different? - What are higher-order functions and why do I need them to implement class hiearchies? - _Or anything in-between._ If the homepage doesn't care, why should I? If we are extremely charitable, we can also include the "Scala runs on..." bits, despite them being below the fold. I think we all know how much drama it took to get even _one_ additional platform mentioned. We shouldn't be proud of that.
I agree with you that Scala has many unfortunate design decisions. I am fully aware of it's flaws, and I actively try improve on them ;) You announced your departure from Scala a year ago (https://soc.github.io/six-years-of-scala-development/departure.html). I'm glad that you found Kotlin and are enjoying it. I also think Kotlin has a lot of nice things going for it. I question your motivations for sticking around in r/scala. Your comments mostly fall in the category of "have negative opinions, but no intention of helping to improve things". It's exactly comments like yours that make people avoid online discussions.
&gt; Scala has and is still fighting tooth and nails against that. Look, it's really useless to try to discuss with you on an objective level.
I'm not claiming that this is even close to perfect,it isn't, but it might have been a good start for a discussion: http://i.imgur.com/olprcP6.png
&gt; Look, it's really useless to try to discuss with you on an objective level. It really feels like you have decided to disagree with every point I bring up and discard any evidence, examples and facts to do so. You are perfectly fine to do so. I just don't think it contributes to a useful discussion. Cheers. 
When I see things I can fix, I fix them; if I can't fix them, I at least point them out. I think this whole attitude of "if you have criticism, keep quiet and leave" is really counter-productive and one of the reasons many problems haven't been tackled by anyone.
It's almost the #1 rule of online communities: that the people who most loudly announce their departure are the ones who are never going to leave =P
As for activity on this subreddit, it's been the target of a several years long troll campaign[1] that I think has suppressed much newcomer activity. I keep hearing most activity is on gitter these days, which is quite unfortunate, as I personally don't think gitter is all that great a platform for that, and don't really use it myself(I think I'll make a conscious effort to change that). As for talks, there's a dedicated subreddit for scala talks in the sidebar, it's actually quite active there. Props to /u/know_not_much for aggregating all those videos. That said there really are kind of too many scala subreddits, I think consolidation should be considered. 1. This campaign seems to have subsided recently, the timing of which I find too suspect to be coincidental. The campaign has really died more or less since since the announcement that android was adopting kotlin. Kotlin has been astroturfed a lot on reddit for a while now, which is fine. The trolls on this subreddit, and to a lesser extent /r/programming and hackernews, isn't however. Strangely, I've seen no reason to suspect Jetbrains is doing it. I wouldn't be surprised if the campaign was being lead by some spurned or burnt out Scala developer, of which there is no supply of for some reason.
That seems a bit... ahm, conspiracy theory like :p Would you any concrete evidence of these ? And if so why would the moderators simply intervene ? 
I have departed from the development of Scala itself, as well as libraries in support of that. Just as written in the link. Sometimes it makes sense to click on links before forming an opinion.
It could be that most Scala devs are so productive, they don't spend near as much time as Java devs in forums looking for ~~trouble~~answers or for ~~Groovy~~Koitlin.
Somehow Reddit hasn't become the place that the Scala community interacts. I don't think that's unusual: different communities somehow end up congregating in different places, for no apparent rhyme or reason. There are people outside of reddit... As others have mentioned, the mailing lists https://users.scala-lang.org/ and https://contributors.scala-lang.org/ get a moderate amount of traffic. One thing that might be surprising is how much activity there is on the project-specific mailing lists: places like https://groups.google.com/forum/#!forum/play-framework and https://groups.google.com/forum/#!forum/akka-user. These project-specific lists are much more active than the "generic" Scala mailing lists. As others have mentioned, the chatroom https://gitter.im/scala/scala is very active. What others haven't mentioned is how active the project-specific chatrooms are: https://gitter.im/scala-js/scala-js, https://gitter.im/typelevel/cats, https://gitter.im/akka/akka, https://gitter.im/spark-scala/Lobby are all very active. If you're working on a particular facet of Scala and want to find like minded people to ask for help or discuss things, going to those project-specific chatrooms will probably yield the best results. Generally I think the Scala community is broad and somewhat fragmented, and the breakdown of how the sub-communities have formed mirrors that. Web-devs using Play framework have little in common with those designing digital circuits with Chisel, data scientists running ETL jobs on Spark have little reason to talk to front-end developers making websites in Scala.js.
&gt; Agreed. I consistently find Packt books to be terrible quality. packt is definitely bad and i had similar situation with reviewing one of their books... honestly the programming book industry in general is pretty bad right now.. any greenhorn can write a book about anything, most of these books to turn out to be slightly better than web tutorials on all kinds of random stuff, and in some cases just inaccurate information..
It's true that there was some trouble with some accounts, which seemed to be operated by same person (judging from their history of advertising the webpages, etc.). As correctly mentioned, that seems to have died down since Kotlin won on Android.
Wow, that recap is impressive. I've always been impressed with the quality of the products from JetBrains, and Kotlin seems to be no exception. What they lack in theoretical knowledge certainly is compensated by engineering skill and user satisfaction. The Scala team should certainly take notice and learn a thing or two.
To be honest that's mostly true. I mean, one of the nice things about Scala is that it allows for completely unrelated quality projects to be designed using it. Come to think of it I'd probably be happy to just stick to the spark and akka channels :p Is there on for scala compile time programming ? That would be a true blessing, it took me hours of reading to understand how to create some simple __LINE__ and __FILE__ macros.
Evidence of what exactly? That trolling is happening? That they're organized? Or that someone is behind them? I'm not making any claims of the last one to be specific, and am skeptical of anyone who claims to know who's behind it. As for evidence of the trolls, many accounts have since been deleted or suspended, but there are a left few like: https://www.reddit.com/r/scala/comments/5up7vr/its_time_to_talk_about_sbt/ and https://www.reddit.com/user/titanthinktank01 The absurd trolls like these are easy to spot, they're meant to grab attention and wrongfoot. In the comments of these trolls posts however are frequently are the more subtle dissenters, who only appear when one of these trolls (somehow?) makes it to the front page. As for evidence they're organized, I think it's hard to quantify that they are, especially without pointing to a specific organizer. I think however, once you start looking at them as whole it becomes apparent. * They never post in each other's threads. * They took turns posting some troll post about SBT once a month. * They carry the same themes of anti-intellectualism, academia is bad for some reason. This fits in with the more subtle troll's main argument that scala is too hard to learn or not pragmatic. About three years ago, someone posted a thread detailing exactly how the sock puppet accounts work together, the trolls immediate changed tactics after that. Searching for that post is worth a as well.
&gt; Is there on for scala compile time programming https://gitter.im/scala/contributors is probably about as close as you're going to get. Basically everyone who's done significant compile-time programming will be there. That number of people is small, so you may not get sub-minute responses, but it's your best bet &gt; That would be a true blessing, it took me hours of reading to understand how to create some simple __LINE__ and __FILE__ macros. If you had asked on the gitter channels, someone would probably have pointed you to https://github.com/lihaoyi/sourcecode :)
You want lihaoyi’s sourcecode project for file and line macros.
Well, I wouldn't say those are troll accounts, maybe they are just not extremely intelligent individuals who are angry at Scala being adopted in their organization (and possibly making them redundant). To say it's an organized "strike" or even more and organized strike by JetBrains to make Kotlin more popular seems a bit far-fetched. Though I'd think some basic moderation would be enough to remove posts and ban users like the ones mentioned above. I'ts not exactly hard to write a bot that auto deletes posts which contain "lol" and warns moderator about harsh language. As for Kotlin being adopted for Android, to be honest I can't see why a anti-Scala campaign would be needed for that to happen. Google could just as well adopt Scala, but I fail to see why Android development would be such a strong point of content... I mean, it's a rather, ahm, mundane field. If anything a "blue collar" language like Kotlin seems much more fit for the job of creating iterative applications that have some minimal degree of quality enforced into them.
sourcecode is what I used as a reference, but I dislike using that kind of 'black magic' without at least understanding part of it...
Trolling is an inherent problem of Reddit, and is has been used too often in /r/scala as well, which is why I'm not surprised that many people have no interest in spending time here but wander off to other channels.
To be honest I'm very unhappy with Reddit. I come here from time to time to spot interesting links or for shamelessly promoting my own projects. I'm actually a long time user, going back 9 years at least, I have an older username that sounds childish so I gave up on it. But Reddit is a very aggressive place. Don't get me wrong, in terms of sub-reddits, I think the Scala sub-reddit is one of friendly ones thanks in part to its moderators and because many of us really are friendly. But there's always this one guy that out of self-entitlement trashes other people's work and it only takes one or two instances to break your heart. Somebody below mentioned the #Scala IRC. Same story — civil, helpful, but every once in a while .... 
&gt; Well, I wouldn't say those are troll accounts, maybe they are just not extremely intelligent individuals who are angry at Scala being adopted in their organization (and possibly making them redundant). I can't tell if you seriously believe this or are being facetious. &gt; To say it's an organized "strike" or even more and organized strike by JetBrains to make Kotlin more popular seems a bit far-fetched. I didn't say that, and even went out of my way to state I think see no evidence Jetbrains has anything to do with it. &gt; Though I'd think some basic moderation would be enough to remove posts and ban users like the ones mentioned above. I'ts not exactly hard to write a bot that auto deletes posts which contain "lol" and warns moderator about harsh language. I don't think it's fair to blame targeted troll campaigns on the moderators. They do remove and report a lot of stuff, which is why many of the old account have been suspended by reddit admins. Also think about that for a second, a troll campaign so targeted the **reddit admins** had to hand out bans on a sub with about 10k subs at the time. That should give you a huge clue about how bad it was. &gt; As for Kotlin being adopted for Android, to be honest I can't see why a anti-Scala campaign would be needed for that to happen. True, there's a little bit a context left out my first post, the long time suspect of the troll campaign was a well known kotlin blogger and author of a kotlin build tool(explains the fetish these trolls have with SBT). The google thing is evidence that the campaign is run by someone who is a kotlin proponent, who probably stopped because in his mind kotlin "won".
:-D
they could replace their whole style guide with a single line: "just pretend it is java"
Great! Compile times are Scala's major issue right now. Waiting for project to compile is irritating on normal CPU and makes Scala nearly unusualness l unusable for big projects on low voltage CPUs (seen in most modern notebooks).
The whole Spark is Scala "just pretend it is java".
Yep, agree with Alexandru. I keep an eye on Reddit and the forums but Gitter and Twitter are the most active and most helpful.
It avoids the mistakes Scala makes by doing less. That cuts both ways.
The tl;dr is that it's required if you're using cats, which relies on improved type inference that's enabled by the flag. Daniel Spiewak wrote a [short novel](https://gist.github.com/djspiewak/7a81a395c461fd3a09a6941d4cd040f2) about it if you want more detail.
I think you run the risk of looking like your tasting sour grapes when you recently leave a community for a competitor, and then come back and extrapolate your anecdotal experiences into the failure of said community. It may be true or untrue, but the interpretation should not surprise you.
In my experience Dave Gurnell's book makes shapeless about 100x more accessible. Might want to buy a copy for your team. I spent a lot of time trying to figure shapeless out, and then the book came out, and I was just like "oh". Also Circe was a great way to introducing my team to how cool shapeless is. 
Short answer: it's for better type inference when multiple type parameters are involved and they need to be inferred in multiple steps, usually due to the use of higher-kinded types (which appear in many functional libraries). For example, it allows a `Function1[Int, Int]` (with two type parameters) to be passed to something expecting `F[_]` (with only one type parameter), by using partial application. This is _sort of_ treating `Function1[Int, Int]` as `Function1[Int][Int]` (with two, single type-parameters) so that they can be split apart. Splitting them apart lets `F[_]` be inferred as `Function1[Int][_]` (where `F := Function1[Int]`). Then the other `Int` can be applied "later" when `F` is actually used in something like `F[A]`, letting `A := Int`. Without `-Ypartial-unification`, the conversion from `Function1[Int, Int]` to (approximately) `Function1[Int][Int]` is not done so `F` could not be inferred, resulting in a compilation error. Long answer: probably best to read up on the history of [SI-2712](https://issues.scala-lang.org/browse/SI-2712), [it's (partial) fix](https://github.com/scala/scala/pull/5102) by Miles Sabin, and [Daniel Spiewak's explanation](https://gist.github.com/djspiewak/7a81a395c461fd3a09a6941d4cd040f2)
I actually believe the functional part of Scala and libraries such as scalaz are the reason many people are discouraged by the language. as powerful as they may be, they are incredibly arcane to the average developer and it is unlikely that the syntax and paradigm will ever be adopted by a large audience. Haskell is probably better for most uses when it comes to hardcore functional programming, and it never took off with the public. Scala offers the possibility of much more conventional coding, a la Java, just like kotlin, and that's where a larger audience is probably going to be interested. The fact that kotlin is becoming the de facto language for Android is a testament to that.
What competitor?
Have you tried using Spark in Java? I have, and it's pretty bad. Thankfully Spark's Scala API doesn't pretend it is Java.
The specific examples I piinted out are all doung _more_: - Better documentation - Better communication - Better beginner experience - Better IDE support - Better migration tools - Better marketing 
Ok, here we go, sorry for the late reply. First, to understand the issues that are involved, this mail from Paul Phillips from 2013 is very instructive: https://groups.google.com/d/msg/scala-internals/12h2TgDFnDM/Sq-EYi7VD7IJ These are the issues we have: - `equals` can be slow in generic contexts - having `eq` only on `AnyRef` is very cumbersome: - You have to explicitly decide whether you can or should make your traits "universal", this is a large technical debt, because once you defined an interface and forgot `extends Any` you can't add it wihtout potentially breaking all users of your interface - Scala's `equals` methods are littered with pattern matches against `AnyRef` that should not be necessary (and will be harmful when when value types/specialized generics ship) - You have a tons of type bounds `&lt;: AnyRef` just to recover `eq` - deciding whether Java interfaces are "universal" traits happens in a very ad-hoc way in the compiler 
Well none of those things are features of a programming language/compiler, which i find odd in this context. Some of them i agree with, and others i don't. That being said, all of these arguments can be made by Java about Kotlin with certainty. It seems a bit odd that you're making them to me now about Scala, because if they were enough to base a decision off of, we would both be using Java instead of these languages. What i was trying to impart is that Scala as a language and compiler does more than Kotlin. And that Kotlin has avoided language warts by providing less capability.
Kotlin &amp; your interpretation of how many posts you thing you see on a mailing list equating to the demise of the Scala language. 
Oh I understand the general issues; we've debated them in the past! At the time, you were unhappy with current proposals so I was interested to see this new development.
&gt; Kotlin How did you come up with that idea? I certainly never said such a thing, neither is it true. &gt; your interpretation of how many posts you think you see on a mailing list equating to the demise of the Scala language You don't like one point I made, fine. But what about all the other ones? Are they also all "anecdotal"? I think this approach of cherry-picking one example one disagrees with, and then summarily dismissing all other evidence quite irrational (as I already wrote somewhere in this thread).
&gt; Well none of those things are features of a programming language/compiler, which i find odd in this context. This is what I wrote two comments above: "substantial impact on adoption and mindshare". I'm not talking about language or compiler quality here, but, as mentioned, adoption and mindshare. Language and compiler quality have pretty much _no_ impact on language adoption. All the things I listed _do_ have an effect on adoption, and this is where the Kotlin team did a much better job.
I think the current proposal goes completely in the wrong direction. Scala has suffered from years of picking "fast" over "correct", seeing this happen _again_, in complete ignorance of knowledge we had 4 years ago is kind of sad.
I have always been disappointed with reddit scala community. There is only one mod who is active currently as far as I have seen - /user/joshlemer and I have to say that we need much more active moderation. The anonymity is not a good thing at all for a tech community and people to be abusive/sarcastic most of the time and the least constructive. I have found discussions in hacker news to be of very high quality, but that comes with lower user activity. The scala gitter channel is really good. You get responses faster there. But it is a chat tool, and not a discussion forum. I honestly feel that reddit is becoming bad by every passing day. One bad experience can ruin the way you look at reddit. I have been there and I no longer respect reddit. But I lurk around just to see what people are talking about. But be warned that there are some really vile accounts that can pop up and spew hatred in this reddit. Some are troll accounts and there are some who are so self obsessed with quality that they will rant and rant and rant and claim all others less intelligent. Scala is less noisy and it has always been that way. But many large enterprises have Scala as part of their backend now and has pretty decent enterprise adoption. Kotlin, Swift, Go all became famous because of Google and Apple. So there is high possibility that about 30-40% of it is just noise and only the rest is driven by actual production usage. I will post another discussion on we can improve the scala community in general and some of the alternate viewpoints. 
The imminent unification of this stack around cats 1.0 is really exciting. I was writing a not-too-complicated application involving some http client stuff and writing to a sql database and decided to try out FS2/Http4s/Circe/Doobie to get some experience with doing pure-functional IO. I originally found it quite annoying getting these different pieces to fit together with latest stable releases. But just recently they all have release candidates around cats 1.0 with everything using the cats IO monad, and all of my issues just disappeared. I am not sure I'm completely convinced of the benefits of this stack over something else, but the increasing cohesion is a huge stumbling block removed.
&gt; Language and compiler quality have pretty much no impact on language adoption. They do for me. But then again my goals for/with Scala is not adoption, but actually producing software. Sans those compiler features, I have no motivating factor to move to a new language, or trying to move others to move with me. 
This sub is fairly low traffic. The only thing really approaching a central forum was the scala-user mailing list before some people insisted on moving it to a different platform for reasons that were never really clear. Since then traffic fell off a cliff. The reason is fairly obvious. Everyone has an email address, and it's very easy to drive by a mailing list for a random query and get a usable experience. Put sign up requirements in front of it and you raise the barrier just high enough to be not worth the trouble, and you lose half the people to the signed up platform they prefer (SO or gitter). My observation in ~7 years of following scala is that the community such as it is exists solely due to heroics from a small number of great independent people, in spite of EPFL and Lightbend. Those organisations really could learn a lot from how other projects benefit from engaging people.
https://www.reddit.com/user/cbeustwatch/submitted/ 
&gt; How did you come up with that idea? https://www.reddit.com/r/scala/comments/7aisiw/the_scala_community_or_the_lack_thereof/dpabq0o/ Your here praising Kotlin for being a better Java, and actively discussing your departure from Scala, and are praising Kotlin actively, so I made an assumption. Feel free to correct me if you aren't using/support Kotlin here. &gt; You don't like one point I made, that's perfectly fine. But what about all the other ones? Are they also all "anecdotal"? Yes, by definition. 
Language quality can be an important issue for individuals, but not on the overall figures. Most people don't have the option to pick their own language. Adoption is hype-, marketing-, luck- and network-effect-driven. You want to have general adoption, because every single user means there is one person more who might discover issues in the compiler, in the standard library, in other libraries you might also use, in IDEs, in other parts of the tooling, or in the documentation, and reports them. Software you are also using, even if you do something completely different with it.
Disregard the "Java" part, it's the case for any dev who checks out both languages and tries to make a decision given the information presented to him. I think saying that Kotlin got many things right in the marketing/documentation/communication/etc. department, that doesn't make me a Kotlin user. Even if someone was a user of language _X_, why would this be a reason to dismiss his/her opinion? Scala's issues aren't solved by improving its best parts, but addressing the bad parts some people don't wan to acknowledge. People from the outside can often contribute good points in this regard. To make it clear: I'm not a Kotlin user, but that shouldn't prevent anyone from having a look at non-Scala languages and note what these other languages get right. Of course Scala is a better language than Kotlin, but a language is not solely defined by its current position in a spectrum. What also matters is the direction in which the language moves, and at which velocity. I would certainly not recommend Scala to new users. Not because of where the language currently is, but due to the direction it is moving and the velocity with which it moves into that direction.
&gt; I have to say that we need much more active moderation Do you have something specific in mind? I do remove posts that are abusive / insulting / trolling, but many posts arguably fall in a gray zone and I try to give the benefit of the doubt whenever I can. 
There are things that make adoption more likely, things that make you code faster/better, things that make you successful after you deploy your code, and things that make your code cleaner/easier to maintain. All of them are important; all of them affect adoption and longevity. C++, if looked at by your measuring stick, is very unattractive, but has maintained adoption over 30 years because it's super efficient. If it and Java had equal performance, it would die tomorrow. 
Fair enough.
I'm not sure I'd agree Shapeless is not magical. Some days it feels like a sufficiently advanced technology.
That looks like one guy sockpuppeting. Pissed off ex-Lightbend employee, maybe? Dude really seems to have a bone to pick with their tooling/ecosystem.
Or math majors.
One thing that I didn't see suggested below was hiring Math majors. I imagine that the amount of training to get a Java dev up to speed with Scala is comparable to the training to get a Math major up to speed with (functional) programming. Don't expect them to pick up Java as quickly, though. 
At CJ Affiliate, we use Scala for high-volume distributed systems (in addition to data pipelines--the two kinda go hand-in-hand) as well as for micro-services. We still maintain legacy systems in Java, but basically anything new we build is in Scala, Clojure, or Haskell (up to team preference) on the back end.
I’ve noticed the same thing. I was surprised to notice that the Haskell community, which I always assumed to be quite small, seems much more active. One example being a video of a talk published both in the Haskell and Scalaconferencevideos subreddits, had 3 upvotes on the Scala post, and 70 upvotes, plus 19 comments on the Haskell one. I’ve also noticed the quantity of posts is much higher on the Haskell subreddit. On the Functional Programming slack group, there are a few Haskell channels, almost all more active than the Scala one. Someone mentioned in another comment, how arcane Scala libraries are, compared to the Haskell ones, for example. I’d tend to agree and add that in my experience I started to learn Scala and ended up learning Haskell in the process, and realising how this mix between OO and functional works both in favour and against Scala. In favour in the sense that it feels somewhat familiar to OO developers, which are certainly the majority out there. But it also forces this awkward syntax for functional things that are very elegant in languages such as Haskell, that don’t have this constraint of having to cater for OO. This, in my opinion, makes Scala the perfect gateway into FP, for OO devs, but it also pushes them away towards other languages with a less arcane syntax.
https://github.com/shawjef3/Harmony might help you if you want to use some scalaz with your cats.
But it doesn't differ in language features from Java -- it is pretty much syntactic sugar as far as the language goes. The type and documentation claims remind me of groovy. Other than gradle, nothing much came of that and I predict the same from Kotlin. The really scary jvm competitors (from a scala perspective) are eta and clojure.
You do a very good job at that but you are not doing this full time right. I was talking about the frequency of moderation. There are some cases where I saw some users abuse and then delete their comments in some time. I don't think mods can see deleted comments. It would be great if they are addressed soon as possible so that you can see that users who seemingly behave good are actually abusive. 
There is a lot more to moderation than deleting spam: a moderator, just like in an offline forum, can shape the discussion gently, towards a form that they want it to be: whether in a 20 minute interview, an hour-long panel, or an online forum. The question, then, is what you want /r/scala to be. As many people here have stated, apart from the explicit spam, there a are a lot of pretty toxic posts and toxic posters in this forum. While it may seem strange to actively police tone and other things, giving everyone the benefit of the doubt is just an active a decision: one that drives away good people like /u/alexelcu or /u/tpolecat, and I'm sure many others who would be valuable contributors to discussions here. You could conceivably draw the line at "comments must be kind and courteous" like the [Rust code of conduct](https://www.reddit.com/r/rust/comments/2rvrzx/our_code_of_conduct_please_read/) does, rather than "comments must not be obvious trolling". I think the majority would agree that is a reasonable standard to uphold, in which case there are countless comments that cross the line. More active moderation doesn't mean you need to ban more people or delete more posts: even just gently nudging people when they step over the line (where-ever it is drawn), with the authority that comes with being a moderator, is enough to get people to fall in line. This is something non-moderators cannot do: the people who will be most vigorous in such discussions are often the most toxic, and the discussion ends when all the reasonable people have left the room and the toxic ones remain. Even good people sometimes need a nudge when they cross the line, just as a reminder that a line exists. If you take a more active role in moderation, there will undoubtably be some initial noise and protest. But I think you are a reasonable enough person that you'd make choices that the silent majority broadly agrees with, and if done well could do wonders to improve the level of discourse in this forum and possibly attract and retain many community members who would otherwise be driven off. If you want people to help moderate, I'm sure there will be volunteers, and you'd be reasonable enough to pick sane ones.
Thanks! 
I have programmed with Android and I don't think kotlin's popularity is due to the language but largely due to Google. Honestly I don't know why Google choose kotlin. But the Android space is very limited for the full ability of a language to be expressed. It is just a bunch of API methods and it's better that way. Trolls are humans after all so they die down after they get tired of stuff. I don't think kotlin has anything to do with that.
Related: The Play framework provides helpers for managing actors with their DI system. [Docs Here](https://www.playframework.com/documentation/2.6.x/ScalaAkka#Dependency-injecting-actors). Looking at the source may also provide some inspiration. Unrelated: The footer of the blog still has `Copyright © Your/Project/Corporate Name 2017` from what I'm guessing was the original template.
to be honest, i couldnt stand large java projects either but i havent yet seen the relative slower-ness of scala (havent done large proj yet). also, modern ultrabooks are now getting quad cores (yay)
You are still looking at it from a perspective of a Scala person who already knows all of this. Try to look at it from the perspective of someone who doesn't have this information, maybe only heard from a colleague about other languages on the JVM, or from Google's Android announcement.
I dont understand the original decision to wait with it until there is java friendly api... why do we need java friendly api in zinc?
I tried sbt 1.0.3 today, still ~30% slower for both full / incremental compilation for my project. Not sure why, maybe cos it has around 20-30 modules.
Same here. Moving to sbt 1.x slowed our build times by 20-30%
I read this with the hope that it would be landing soon, only to realize that it in fact already landed in sbt 1.0; not much has changed due to this [unmerged PR](https://github.com/sbt/zinc/pull/371) :\ Disappointing to see all the gains thrown away by yet another anchor. Imagine adding a simple `println` statement and seeing the target source recompile kick off *immediately* rather than after some inexplicable delay. We're on the verge of solving a huge long standing problem, please make your voice heard in aforementioned PR -- would be huge to get this backported to sbt/zinc 1.0.x
Not an expert here, but isn't this code kind of smelly? I mean Akka actors are based on Erlang actor system. There you are not keeping actors alive - you send a message to them, they (might) respond and die. So instead of e.g. passing messages to and from between 2 actors and thinking how to prevent memory leaks, wondering when actor should die etc, you just let them be created and die on demand. Other thing that I dislike it runtime reflection - in Scala I hardly ever see the need to use it. Here author replaces built-in tools for referring actors with external solution - I would like someone more experienced with Akka to tell me if injectors wouldn't break if e.g. I started using Akka clusters. Even if not, wouldn't using built-in tools be better? Does it make sense to run injector instead of e.g. writing a utility function? 
The likely cause is slow hashing, see [this PR](https://github.com/sbt/zinc/pull/371). Visualvm shows most time is spent in `sbt.io.Hash$.apply`. Not so helpfully this anchor scales with the number of modules (i.e. gets worse). On the plus side once this gets sorted out we might actually be able to type `compile` and see the build kick off more or less immediately.
From Google's perspective, it looks like a language with different enough syntax that can help them win court cases should Oracle come calling again about Davlik-flavored Java. Certainly makes sense there. I'm trying to look back to what attracted me to Scala when I first started. I was working on an xmpp MUC plugin to facilitate collaborative whiteboarding. It was written in Erlang, and I was new to Erlang. I looked for an actor library on the jvm so that I could understand the concepts of the actor model in a familiar context. That led me to Akka, which got me into scala. It was the concurrency primitives and immutable pattern matching with easy java interop that initially hooked me. Dumping the need for runtime DI and a whole host of EAP patterns pulled me farther down the rabbit hole. HKT and implicit parameters sealed the deal. So much in the java world is using annotations to add functionality to your types. Here's a GENERIC way of adding functionality to somebody else's types (and your own)! Goodbye adapters and proxies and compile-time annotation transformations. Hello code that is readable inline without jumping through the debugger. My path to Scala was through a library I was reading to accomplish a specific task. That's also how I picked up Python, Ruby, ActionScript, Haskell, etc. I'm lazy, I first look to see if somebody else has done it at all, then in my language of choice. If it's core to the application, like operational transformation, or scaling a chat server using actors, I'll switch languages to use it. With scala, I got unique features that are clumsy to implement in Java. Finals. Local type inference. Lambdas. Compile-time DI. Default methods. Singletons. Immutable Structs. An expressive type system. And I got access to java libs. I didn't want access to Scala from Java - because Scala superceded Java in every way and added useful features. Why write part of my application (and scala IS an application language, primarily) in Java? If a java dev needs to use my library, I'll write an opinionated interface for her that takes away all the late decisions that Scala enables, and they'll be happy. Categorical FP just made my code more reusable and maintainable once I discovered it. Changing behavior without destroying old behavior was mostly possible with the correct abstractions (map, flatMap, fold, sequence, handleError, combine and pure can pretty much do everything). But that was used sparsely till my third year in the language. Before that, it was still immutable code, I just ad-hoc created the things I needed when I needed them; I knew of this abstract lib that did some of what I needed, but I only needed one thing from it. Well, no, turns out I was shaving yaks and everything I was doing was in Scalaz already. Scalaz documentation is sparse, so that leads to Cats nowadays, when you have to teach others the basics of FP. I teach them FP first, now, so they can skip the two years of wasted yak-shaving, later. They are confused. They are beginners, they are supposed to be confused. I'm the teacher, I'm supposed to unconfuse them. Because I teach a subset of the language features now, they learn faster. They grumble about the language more though, because now they are using it instead of just "Scala: the syntax parts". We get fewer bugs as a net result, and can add features quickly without introducing new bugs. By basic FP in scala I'm not even talking about limiting types to Functor or MonadError. I'm talking about write your interfaces to return F [Abba], use something that implements map/flatMap/async/sync/error handling for your F in your implementation. Super basic stuff. Review will check that you conformed, and the team will help you correct it if not. General griping about language features I've USED in the past: That web front-end I wrote in coffeescript because the syntax was terser comes to mind when I see Kotlin vs. Java. There's no there, there. ES5 and 6 subsumed it. If it was in typescript instead, it might still be in use. As Sussman once quipped, "Everyone seems to be obsessed with syntax." But mere syntax changes tend to get moved into the host languages almost immediately (as soon as the committees can convene). Because they don't change semantics, they are easy to implement. So the child language dies, and you have 10,000 lines of legacy code nobody wants. Scala's local inference and pattern matching will eventually be in Java. Lambdas already are. Lazy evaluation and val probably won't ever make it. Null/ Optional/Monads are forever broken in Java. Language implementors are largely concerned about adoption. Adoption comes from ergonomics, some, but usually it is task driven. The language has a lib or makes modeling some part of the problem easier. However, for the longevity of a language, retention is more important. The newbies that do one project in Scala that like the syntax but leave because they can't call scala list for each in a for in loop without .asJava were never going to stay in Scala. Eventually, they'd look at code that we as a community enabled to be written like Java because of adoption rates and say - "this language is just like Java, with a smaller community, and weird functional programming cruft that the majority of the community doesn't use anyway because it's not like Java, why am I writing in a language that does nothing but add cruft to a language I already know?" - and they'd all switch back to Java 10.
To your first point, actors _may_ be one-and-done, but that is by no means to “usual” behavior, just like long-lived actors aren’t “usual”. I commonly use them in both ways, but one-and-done is almost always anonymous. To your second point, there’s absolutely nothing wrong with using injection. In fact it can help encourage best practices of using actor providers rather than hard-coded actor creation logic. This is especially helpful when unit testing. 
Agreed. The inward look at other platforms that Scala has is one of the bigger mistakes I think. Additional platforms have always been treated from as "and here is a new platform for our existing users to which they can compile to" and never as "hey, users of platform X, we have a better approach of writing software for you". Imagine the adoption rate if even 0.05% of all JavaScript users considered Scala.js. Kotlin nailed that with Android, will do the same with JavaScript, and will probably do the same for Native. As Java adopts language stuff from Kotlin and Scala, the gaps in terms of language capabilities will grow smaller. This means that other differences will be much more important in the future. Things like support for multiple platforms, and I think Kotlin will win this, because they can ship a language with an IDE that supports their language with seamless interop with Java, JavaScript and Native code. You can already see it how they slowly put together all the connected pieces: https://blog.jetbrains.com/kotlin/2017/11/kotlinnative-ide-support-preview/
Well, I guess it's a matter of habits. Personally I see now runtime reflection as "unclean" way of dependency injection - costly, implicit, unprovable to work on compile time... I have nothing aginst DI, I am all for it! I am seeing Guice as a red flag that would make me consider leaving project.
That’s a little extreme, but whatever floats your boat. 
There's also a somewhat active functional programming group on slack (functionalprogramming.slack.com). Though it's not just scala, the scala channel is pretty active and quick to respond.
A lot of this seems like the author just prefers Java style syntax - which is fine obviously - just a tad dangerous to take some of the advice here at face value. Scala offers a lot of powerful abstractions to help you reason about your code. Typically in spark you can write your application in whatever style you want, and only worry about efficiency in the parts of the application that run on large amounts of data. For those parts - sure - optimise as much as you want, but not using Try, Option or any other standard scala control flows under the guise of performance will just make your code as harder to reason about. Main point is to know what runs on your driver vs. executors and how frequently those things are called in order to know when you need to optimise.
Not using Ubuntu (using Arch), but I’ve moved to neovim, one of the reasons being the ability to easily load python 2 and 3 plugins simultaneously. I did manage to get `ensime-vim` to work, following the instructions on their website, but it’s a bit flaky. For example on the project I’m currently working on, which uses sbt, it sometimes provides autocompletion, other times it just stops doing it. Then it recognises that I I’m using play, and that I have slick on the project, and can even go to the declaration of methods on those third party frameworks/libraries, but then, for some reason it keeps failing to acknowledge Circe, for example. Also it makes my vim extremely slow at times. This being said, it was the only Scala plugin for vim, I could find that has some smart functionality, like contextual suggestions on autocomplete, show type signatures, semi-automatic imports, go to declaration, etc...
Nice. Have you ever run into the scalac error that I mentioned?
No, I don’t use syntastic, I use Ale because Ale is asynchronous, so it can do linting and syntax checking as you type.
This looks great. I'm not using NeoVim or Vim8. Have you seen any issues switching to NeoVim?
[removed]
No, not really, when I did it, I just copied my vim config file over, and it worked. I’ve also set up a symlink so when I type `vim` it actually runs neovim.
Found this library, which is really nice to use. It also has a slf4j module. What kind of logging framework would you recommend?
Important : (very easy) migration guide from 1.x to 2.0 : https://github.com/scala-hamsters/hamsters/blob/master/README.md#1x-to-20-migration 
[There are differences](https://neovim.io/doc/user/vim_diff.html). Some defaults have changed, certain features have been thrown out and there are also new features what vim is picking up slowly.
So i switched last night, and I've already removed it lol. I went ahead and swapped syntastic or ale as soon as I had nvim working. The reason I ended up abandoning it was because of the behavior of `esc` while the asynchronous linting was happening. It seems like when it detects an error, it disables to ability to: * either use `esc` at all (instead of `Ctrl+c`) * or it just hates that I've remapped `Caps` to `esc`. Not sure exactly which one it was, but that bothered me enough to abandon it.
That is probably related to those plugins. I've used nvim with various async plugins and I've Caps mapped to Esc too. Which version you've used?
To clear up some pervasive FUD in this thread: 1. As measured by type safety, totality, algebraic / operational laws, and resource safety, Scalaz 8 IO is the most safe and correct implementation of an effect system for Scala. 2. My choice in IO to assume that the user is writing pure code does not make the library "unsafe" or "incorrect". We pervasively assume in Scalaz that "types do not lie" and "users write pure code". If you want to write impure code and expect Functor's map method to catch your exceptions, don't use Scalaz. 3. Thread shift is not only possible in Scalaz 8 IO, but trivial — a single line of code. Any statements to the contrary are incorrect. 4. Scalaz 8 IO's higher performance is *not* due to not catching exceptions on map/flatMap. This is another rumor. It's due primarily to fewer heap allocations, runtime optimizations, and clean generated JVM bytecode.
Whatever version is in 16.04
I don't remember nvim being included in it. You can check it [here](https://packages.ubuntu.com/xenial/allpackages) but there is no match.
Wow, that memory utilization graphic is malevolently misleading. The actual difference is 700KB vs 600KB, which is not relevant in a Scala app and the graph is cut off at 590KB making the difference seem massive.
That's how you do graphs in 2017! 
i havent had much like with the vscode plugins, ended up using scalaide which i'm quite impressed with how far it's come...
Check this out: https://github.com/dragos/dragos-vscode-scala that looks promising since it is ensime. ScalaIDE is of course an option if there are no good solutions for your simple use case with VSCode but note that scala plugins also work with intellij idea community edition (meaning, free) so you might prefer that to eclipse.
&gt; To clear up some pervasive FUD in this thread: Let me first say something, you are making claims that Scalaz IO is 6300x faster than x or 195x faster than y without actually publishing any code (even a PR). Code carries its weight in gold much more than words. People have a right to be suspicious in this regard, just like if someone goes and says that "Scalaz is 100x slower than x" without actually showing any code. Also I am going by what is said in the twitter thread, again if you are annoyed that people are spreading FUD, this is because you haven't (as far as I am aware) actually shown any code at all. Addressing the points which are worth addressing &gt; If you want to write impure code and expect Functor's map method to catch your exceptions, don't use Scalaz. Except that you don't have a choice in this. Exceptions are non local, if they get thrown they bubble up. Any kind of IO in Scala can throw an exception (reading from files, http requests, etc etc) because they typically use Java functions under the hood which do this. Unless Scalaz has implemented the complete Java ecosystem from scratch without exceptions this claim is meaningless. The biggest use of `IO` is also going to be biggest source of exceptions, which probably means if I am going to use a referentially transparent pure FP solution, I would * Either use Monix `Task`, which handles everything including exceptions to stack safety to make sure its completely correct * Use the new Scalaz8 IO and manually handle exceptions myself, most likely getting stuff wrong in the process &gt; Scalaz 8 IO's higher performance is not due to not catching exceptions on map/flatMap. This is another rumor. It's due primarily to fewer heap allocations, runtime optimizations, and clean generated JVM bytecode. If this is the case then the claim of it being 6300x faster than x or 195x faster than y is going to completely down the drain once the library is published, because as people said the other libraries will just copy these techniques and then the difference will dwindle tl;dr If you don't want people to be suspicious or to spread "FUD", then just publish the code (even if its not ready for release). You make the situation worse by going on public channels making these claims without having any code
&gt; Try, Option or any other standard scala control flows under the guise of performance will just make your code harder to reason about. Well if you **really** care about performance then using `Try`/`Option` is less performant than the alternative 
It’s a textbook way to misrepresent results. Quite popular these days.
To be frank, although I agree with your points (wrt to Kotlin) its not an apples to apples comparison, and I think this is the problem with Scala trying to interopt really well with the JVM. Essentially, Kotlin's job is **much easier** than Scala's. Kotlin is just a slight syntantic wrapper over Java with minimal runtime adjustments, which makes Jetbrains job much much easier than EPFL/Scala center's job. The further you get from the JVM as its intended to be used (while also trying to interopt with the JVM) the harder the job becomes. And this is the problem with Scala right now, idiomatic Scala is very far from how idiomatic Java looks like, and a lot of Scala's problems (and hence a lot of Scala's effort which could otherwise be used for marketing/tooling and the other things you mention) are due to this. I mean all of these issues which Scala has have roots with JVM/Java interopt in one way or another * Corner case syntax with eta expansion amongst other things due (JVM/Java overloaded methods, not having lamdba support until recently, supporting idiomatic style Scala code while calling JVM) * Lot of the issues with numbers and corners in the type system when dealing with different number types due to support JVM's number system * Issues with `AnyVal` or zero cost abstractions because the JVM doesn't have a concept of value types * A non trivial amount of issues with SBT is due to "java ecosystem", everything from `ClassLoader` leaks to JVM's model of requiring huge amounts of memory to Java's greatly lacking IO library * The `Any`/`AnyRef`/`AnyVal` hierarchy and its issues/corner cases are due to interopting with Java's object model (i.e. `Object`) * Having to support Java's object model with stuff like `.toString`/`hashCode` and synchronized also introduces a lot of corner cases when it comes to performance. * Scala loses a lot of its performance benefits on the JVM because the JVM has no proper concept of immutability. Also because the JVM works with `methods` as a basic construct, a lot of really powerful optimisations are very difficult to provide if you want to interopt with JVM unless you want to do whole program optimization. Global `TCO` is a very good example of this * Collections feel like they are decapitated in a lot of ways (again due to Java interopt). One of the main reasons of `CanBuildFrom` was because of Java's exceptional handling of `Array`. Performance (even with mutable barebone datastructures) is quite bad due to co-operative equality. Having no control over memory in JVM means that immutable datastructures are slower due to reasons of cache locality. Complex type hierarchy is also due to having to support a subset of Java's collections (i.e. iterators, iterable) * Dependency management/building is much harder in Scala because everyone has an expectation of dynamic libraries which is carried over from Java (dynamically loading Jar's). Having this while maintaining binary compatibility (which is necessary because Scala is so far removed from the JVM so it has to have its own non trivial runtime) is the main cause of pain for a build tools right now. Statically compiled languages with source dependencies (Go/Crystal/Rust) completely avoid this because they either don't have dynamic libraries at all or do via a simplistic C ABI runtime, which is very different from Scala's "everything is public" ABI. * Having these stdlib issues which languages like (Go/Crystal/Rust) don't have because those languages only care about source compatibility, so its easy for them to update/upgrade/maintain the stdlib without breaking so much code in the wild while expanding the main language * The above point causes a lot of leakage because into other platforms (Scala.js/scala-native) because they also use SBT, which means they inherit a lot of its flaws * Ontop of all of this, Scala also inherits all of the flaws of Java/JVM stdlib, i.e. the crappiness of `DateTime` (we now have like 5 date API's that we need to support in Scala). Then there is `IO` and a lot of other things as well Kotlin pretty much has none of the issues (or most of them with the other ones being completely trivialized). As of late, I am of the opinion that Scala would be a beautiful language if it was designed from the scratch, completely without JVM in mind. The language itself can evolve without having to worry about breaking binary compatibility so much.
&gt; As of late, I am of the opinion that Scala would be a beautiful language if it was designed from the scratch, completely without JVM in mind. I think the biggest issue is the feature fairy problem I described a while ago. Quality will be poor as long as people inventing/adding new features are not responsible for maintaining/repairing/deprecating them. You can see this in action when looking at many of the new language extension proposals. There is a _lot_ you can do to improve language quality, just by avoiding to repeat and reinvent the same mistakes over and over. Nevertheless, _I_ care a lot about language quality, but frankly, that's a topic that is sadly completely irrelevant if you look at language adoption and success: People don't care whether Kotlin picked a much easier problem to tackle than Scala. They see one language that understands that tooling, communication, marketing and documentation is important, and another language which doesn't feel that it is necessary to improve anything at all because "every developer already knows Scala".
It wouldn't be inappropriate if there was a control, illustrating the memory consumption for whatever he's benchmarking if the did no logging at all.
&gt; Java Features Missing from Scala &gt; The following Java features are missing from Scala. If you need the following, define them in Java instead. &gt; Static fields um...
&gt; People have a right to be suspicious in this regard, just like if someone goes and says that "Scalaz is 100x slower than x" without actually showing any code. I don't care if people are suspicious. I don't care if people question the benchmark or even claim it's impossible (in fact, please do!). I do care when they make factually incorrect statements about the JVM and functional programming. &gt; Any kind of IO in Scala can throw an exception (reading from files, http requests, etc etc) because they typically use Java functions under the hood which do this (this is even disregarding stuff like OutOfMemoryError). The statements you are making are not even wrong, they don't make sense. Worse, they actively mislead beginners who are trying to understand functional programming and effect monads. I strongly recommend reading a book on functional programming such as haskellbook.com. In lieu of that, here's my brief explanation: In an `IO` monad, effects are captured as pure values. These effects may include, among other things, indeterminism, and partiality (including exceptions). Once imported into `IO`, these effects become pure values and may be reasoned about using equational reasoning. As an example: def read(is: InputStream): IO[Int] = IO.sync(inputstream.read()) As you know, `InputStream.read` may throw an exception. In this example, the effect has been imported into `IO`, which now makes `read` a pure function. Given the same input, the new version of `read` will always return the same output—which is, an immutable data structure that describes the effects of interacting with the specified input stream. Any useful effect monad in Scala will support importing impure code, precisely because Scala is not a pure functional programming language. This does not violate any laws, nor is it incompatible with any aspect of pure functional programming. In an ideal world, of course, the standard libraries would be pre-wrapped so you did not have to perform the import yourself, but that's a relatively minor implementation detail. All effect monads, whether Scalaz IO or Monix Task, support importing impure effectful code. That is not the issue. It has never been the issue. The issue is that the definition of `Functor`, `Applicative`, and `Monad` include functions `map`, `point`, and `bind`, respectively. These functions have type signatures equivalent to the following: def map[A, B](fa: F[A])(ab: A =&gt; B): F[B] def point[A](a: =&gt; A): F[A] def bind[A, B](fa: F[A])(afb: A =&gt; F[B]): F[B] These functions have precise definitions, laws, and semantics. Both `map` and `bind` are higher-order functions. The functions you pass to these higher-order functions must be pure functions. If they are not pure functions, the laws cannot even be stated, let alone checked. The necessity of these functions being pure does not limit **in any way** your use of effectful, exception-throwing Java and Scala code, because effectful code is imported into the `IO` monad. All usages of `map`, `point`, and `flatMap` will be in your application code (not in third-party code), which is entirely under your control. Other code from the imperative Java and Scala worlds will not even know how to work with functors, and would not be able to provide the guarantee of determinism and totality necessary for these functions to behave lawfully and meaningfully. The idea that you make functors "safe and correct" by requiring they "catch exceptions" in `map` and `bind` is beyond wrong; it's meaningless. Any "functor" instance so implemented is **by definition incorrect** and **not a functor**. Not only would such an implementation not make your code "safe", but it would actively encourage *unsafety*. As stated before, the fact that functions you pass to `map` and `bind` must be pure does not in any way limit your ability to interact with and safely use effectful Java and Scala code. All effect monads in Scala have this ability and it's precisely this ability which makes them useful. This importing of external impure code is unrelated to the purity requirements that all higher-order functions in a pure FP library will have. As an example, the `map` implementation for `List` in Scala does not catch exceptions. If you pass a partial function to `List.map`, the behavior is undefined, but it will likely include crashing your program or putting it into an undefined state. This is not a bug that needs fixing. If you don't want to blow your program up, then don't pass impure functions to higher-order functions like `map` that require pure functions. In fact, if you want to program functionally, then stop programming using exceptions. Import exceptional code into `IO` and use return values, error monads, and the like for your own error states. It really is that simple. &gt; If this is the case then the claim of it being 6300x faster than x or 195x faster than y is going to completely down the drain once the library is published, because as people said the other libraries will just copy these techniques and then the difference will dwindle. Scalaz contributors are quite used to having their code copied into other libraries. 😀
I've been struggling to find an active Scala discord for a while. I've tried the functional programming channel, but it's hard to get answers from more than 1 scala person. THANK YOU for mentioning this gitter.
Scala does not allow you to define static fields - http://docs.scala-lang.org/sips/pending/static-members.html - https://gist.github.com/lrytz/80f3141de8240f9629da
I just didn’t see that as a feature that was intentionally missing, now I see that it could make sense from a JVM point of view 
Yep, everything clicks together nicely now and it's a joy to work on, and to use. We're really happy with the way things are going.
&gt; Scalaz contributors are quite used to having their code copied into other libraries. 😀 I ❤ this world :)
It is nothing if not an endless source of entertainment. 😀
Pathmatchers are part of the server-side dsl? Why are you not using the routing syntax then?
Open sourced this - SparkPlug- Spark package to "plug" holes in data using SQL based rules https://github.com/indix/sparkplug
So you can use it in maven.
&gt; I think the biggest issue is the feature fairy problem Scala is suffering from (that I described a while ago). &gt; Quality will be poor as long as people inventing/adding new features are not responsible for maintaining/repairing/deprecating them. This is the point I am making though, as soon as you decide to "interopt with Java" you open up the can of worms which you call "feature fairy problem". If Scala decided not to interopt with Java at all it would be completely different, but if you decide to interopt with Java people have expectations that the interopt works well in most cases. While I agree with most of your points, I think you are also being too harsh against the EPFL/ScalaTeam/developers, the task they have is enormous, much greater than what the Kotlin guys have. They didn't choose release of these features which you say have quality issues, they came from the design of the language (providing JVM interopt).
It looks a lot like cats and scalaz which support scala.js are considered more standard. What's the point of this library compared to cats and scalaz ?
If you just want `HList` and `Coproduct`, you can write your own definitions and work with them - the basics are like 5 lines each. You'll have to reimplement the utility methods you use, but frankly they aren't that discoverable and don't save you that much code - I often find it's easier to work out what I want to do by writing an explicit recursive derivation than by trying to find the shapeless helper and figure out the right implicit constraints that it needs. (The shapeless example code is helpful as far as it goes, but since the examples all define a type and use it immediately you can never see which implicits you actually need if you want to call that function inside a function). But if you need Generic then there's nothing for it but to use Shapeless. That's some scary macro magic; frankly it's amazing that it's even possible for a library to do that (really the functionality should be built into the language - but we are where we are).
Hi, You can see cats/scalaz as libs for advanced Scala users, and Hamsters has a lib for intermediate users. The point of Hamsters is to be smaller than Cats (and scalaz), really easier to learn, with a really easier to read source code (if you want to understand how to implement a monad transformer for instance). Of course the trade off is that it's a lot less powerful than cats/scalaz. 
&gt; Scala has suffered for years from picking "fast" over "correct" Fast is also a form of correctness, especially for something like equality which almost always going to be in code hotpaths 
Id guess majority uses sbt with scala. Why optimize for for small % ? Sure release it later; but i wouldnt hold on for years because of that
The [feature fairy problem](https://news.ycombinator.com/item?id=14478460) is not related to the JVM: &gt; The problem with feature fairies are that they create more problems than they solve, and never volunteer to fix them. &gt; Feature fairies like to get credited with completed features, but never with the defects associated with their contributions. Therefore they will usually play dumb when a bug happens, or an incident is declared, and make someone else clean up after them while they implement the next feature. &gt; So after a couple of years, you have someone credited with a lot of features, and a team of people that have been cleaning up after such person. The duct tape fairy is now a 10xer, a rockstar whose time is very valuable therefore needs to be paid more, even promoted, even though this person is responsible for wasting 90% of the engineering payroll in fixing trivially avoidable defects. &gt; The way to prevent that is to leave a trail of evidence that can link commits to bugs. When an incident happens, make sure to identify the commit id causing the problem and put it directly in the ticket. Make it very clear where the defects are coming from and who they're coming from. &gt; Never volunteer to clean up after a feature fairy. By the time you do this, the feature fairy marked their task as complete and from the eyes of management you would be wasting your time working on a completed task. Rather than doing that [...] It's the approach of throwing features add a language and expecting 10 other people to clean up after them. The core problem is that the people who invent the features never have the opportunity to learn from mistakes and avoid them -- and never need to, because fixing their stuff is other peoples' job. So you get the new feature proposals with glaring design mistakes that are well-known to people who did the maintenance, but not to those busy inventing new stuff. JVM interop is the least of Scala's problems. Interop _could_ be much better, but isn't, largely due to a lack of interest. But that's really not the topic here.
Being correct is a prerequisite of making it fast. Doing wrong things even faster is not a useful benchmark.
&gt; The above point causes a lot of leakage because into other platforms (Scala.js/scala-native) because they also use SBT, which means they inherit a lot of its flaws Care to elaborate? I have no clue what you're talking about.
&gt; Being correct is a prerequisite of making it fast. This depends on your definition of correct, if your definition of correct is being fast then its circular logic
&gt; The feature fairy problem is not related to the JVM: The thing is, they **are**. The responsibility here (or what you are stating wrt people adding contributions without attribution to responsibility for the bugs that the features) are features carried over from JVM/Java. If you are writing a language that targets the JVM, either you 1. Completely ignore the "Java" part of the JVM and treat the JVM like you would treat LLVM, i.e. another bytecode/VM which you target or 2. You emit bytecode/methods/etc etc so it interopts with the Java ecosystem, i.e. Scala functions/methods can easily be called within Java and profilers/debuggers work with Scala functions seamlessly. If you do #2 (which is exactly what Scala does), you have suddenly created thousands and thousands of "tickets" in producing a product which is compliant with the JVM/Java. These tickets don't have a clear responsibility because its interopt. If the problem space for your language design is trivial because its just a "nicer Java" (case for Kotlin, and beforehand stuff like Lombock) then all of these tickets are pretty either much either already handled by definition or are trivial to solve. Example point, corner case handling wrt named parameters with function overloading wrt typeclasses (such as magnet pattern) + erasure wrt default parameters with implicits/explicits. In Scala this is very hard, because the extra features Scala has (named parameters/typeclasses and implicits/explicits) introduce a huge number of corner cases. Now you can claim this will is "feature fairy", but Scala having implicits/typeclasses is **part of the core design of Scala**. So assuming we have to interopt with Java, using your reasoning we either don't have these features in Scala at all (in which case Scala is just a better Java) or we support these features along with all of the corner cases it brings with it. If we didn't have to interopt with Java, we could just simply choose not to implement function/method overloading/default parameters, and we don't care about how stuff gets erased because we have complete control of the process. &gt; JVM interop is the least of Scala's problems It isn't, what I have listed is the tip of the iceberg, and almost the majority of common problems that Scala people have either directly or indirectly related to JVM/Java
None of the issues I have in mind are related to interop.
Leakage was the wrong word, what I mean is that Scala.js/Scala-native, even though they compile to targets that have nothing to do with Java (Javascript/native executables), they have to deal with/interact all the Java related things, either directly or indirectly. Direct things are * Classpath/resources etc etc (all of this is JVM related stuff which has nothing to do with Javascript/native executables) * Using "wrong" encodings (there are very strong arguments that default encodings for modern languages should be UTF-8, iirc scala-native is using Java's version of UTF-16 because of Java interopt) * Needing to implement some forms of reflection because certain libraries require it (i.e. akka) even though its a conflicting goal for backends like scala-native. * Scala-native not having nice ways of working with numbers (i.e. Signed/Unsigned Int) because Java has no concept of Signed/Unsigned Int, and by default Scala is using what Java provides in this regard. Indirect things are * Having to implement interfaces such as `java.io`, even though these interfaces are outdated and not idiomatic Scala, and in some cases don't even make good design sense for other targets (mainly because these interfaces are badly designed since they were designed like 20 years ago) * Scala.js/scala-native having to conform to and generate `.class` files even though this is strictly just a JVM specific thing (afaik this is so that tools such as MIMA still work, but targets which don't have concepts for dynamic loading of libraries while maintaining binary compatibility i.e. scala-native shouldn't even need to take this into account). * I suspect that a lot of reasons for the slow building of Scala.js projects are also general issues due to SBT, and a lot of reasons for SBT being slow are also due to how Java handles things (i.e. memory leaks due to how ClassPath jar handling is dealt with, SBT startup time being linked to JVM startup time, having to do a lot of very non trivial hacking with `ClassLoader` to try and optimize things) The general summary of what I am saying, is that these targets need to have a "java view of things" even though they have nothing to do with java
Except that this is not correct, have a look at the Dotty issue tracker which is creating a new Scala compiler from scratch, a huge amount of these corner cases (as is being revealed now that things are being done from scratch) are either 1. Actual Java/JVM issues 2. Were designed badly, but the reason why they are designed badly is because of trying to interopt with the JVM in the first place. i.e. `CanBuildFrom` is a typical example of this, we need to pass along `Manifest`/`TypeTag` to match how Java treats `Array` (which it does in an exceptional manner wrt to the rest of the language). We now know that there is a better way to handle collections rather than `CanBuildFrom`, but one of the main reasons they were designed this way **is because of JVM/Java in the first place**
how does it compare to intellij ? 
- implicit resolution has been broken in contravariant cases for such a long time that many libraries have abandoned using contravariance where it would have made sense - implicit lossy widening conversions are wrong, broken and will never work - compatibility across minor versions has been abandoned with 2.12 - growing, not shrinking, number of ways to express the same things - collections have fundamental design issues that have not been resolved despite 4 opportunities for redesigns/revisions (&lt;= 2.7, 2.8, 2.9, 2.13) - tons of cryptic punctuation like `: _*`, `#::`, `/:`, `:\`, `!!&lt;`, `###`, `#&amp;%`, `#||` - enumerations are beyond broken - having close to 400 things in the global namespace (start your REPL and press tab if you don't believe me) - a huge chunk of the packages in the standard library have not worked out (collections, io), are of poor quality (beans, io, xml, reflect), or shouldn't exist (parser combinators, text, util) Please tell me if you need more examples, I have another 30 or 40.
&gt; implicit lossy widening conversions are wrong, broken and will never work Java related - i.e. Expectation for Scala numbers to support widening in the same way that Java does, except that Scala also has to support type inference, implicit conversions (which Java doesn't even have a concept of) &gt; compatibility across minor versions has been abandoned with 2.12 If you are talking about binary compatibility, this is inherited from Java/JVM (having dynamic dependencies with loadable jars + scala runtime). If Scala didn't even target the JVM/Java and only cared about source control compatibility (OCaml/Go/Crystal/Rust) this isn't even a problem because it can't occur &gt; growing, not shrinking, number of ways to express the same things Mainly false, Dotty is removing a huge number of ways of expressing things, look through their tracker/scala contributors. Things which are being removed include - `forSome` (not sound in Dotty's type system) - More general cases of existential types (again not sound in Dotty's type system) - Structural types (in current scalac it adds turing completness to the type system, plus almost no one used it and it added a lot of corner cases with reflection) &gt; collections have fundamental design issues that have not been resolved despite 4 opportunities for redesigns/revisions (&lt;= 2.7, 2.8, 2.9, 2.13) Already talked about, not repeating myself &gt; tons of cryptic punctuation like : _*, #::, /:, :\, !!&lt;, ###, #&amp;%, #|| Lot of this is deprecated already, no point of talking about this &gt; enumerations are beyond broken Again JVM/Java related, i.e. having to produce enumerations which conform to how Java expresses it in bytecode while it still being idiomatic Scala. Also being solved in Dotty &gt; having close to 400 things in the global namespace (start your REPL and press tab if you don't believe me) the `java` namespace is the main culprit here, at least the scala namespace is fairly curated (both in how it gets included in the compiler and the fact its much smaller). Also there is an effort to reduce the size of the scala namespace, i.e. xml/json is now being removed into a separate library. People are talking about the same wrt to concurrent &gt; a huge chunk of the packages in the standard library have not worked out (collections, io), are of poor quality (beans, io, xml, reflect), or shouldn't exist (parser combinators, text, util) All of these are either related directly (beans, reflect) or indirectly (collections, io) to Java/JVM stuff, and has been talked about before.
Hum, some of what you say is true. There are some misconceptions, though. &gt; Classpath/resources etc etc (all of this is JVM related stuff which has nothing to do with Javascript/native executables) If you are talking about the compile-time notion of classpath, I don't see a problem here. For Scala.js and Scala Native, the notion of classpath is only a compile-time summary of your library dependencies. Any statically typed language should have such a thing. I don't see how classpath are any worse than a bunch of `-I` flags to gcc, or any other information that you have to give to a compiler to tell it where the static types of your dependencies are. &gt; Using "wrong" encodings (there are very strong arguments that default encodings for modern languages should be UTF-8, iirc scala-native is using Java's version of UTF-16 because of Java interopt) If Scala Native were alone, it would indeed make sense to use UTF-8 by default. However, the ability to *cross-compile* code across platforms with the same semantics is very important. Therefore, it is not so much interop with Java than platform-independence with Scala/JVM and Scala.js that makes Scala Native choose UTF-16. (There's no such thing as *Java's version* of UTF-16; it's the standard UTF-16 -- except if you're talking about `DataInput/OutputStream`s, but that's very narrow.) &gt; Scala.js/scala-native having to conform to and generate .class files even though this is strictly just a JVM specific thing This is for a lot more than MiMa. You have IDEs, separate compilation, etc. And in particular it is for macros. Indeed, since the compiler runs on the JVM, it uses the class files to execute the macros, even when compiling for Native or JS. Even if all the tooling of all the Scala ecosystem used something platform-independent (let's say .scalasig), we would still need the .class files for macros. &gt; targets which don't have concepts for dynamic loading of libraries while maintaining binary compatibility i.e. scala-native shouldn't even need to take this into account Binary compatibility has nothing to do with dynamic loading. It has to do with *distribution*. Because Scala libraries are distributed (on Maven) as compiled artifacts, it is *those artifacts* for which compatibility is essential to avoid dependency hell. Since Scala.js and Scala Native follow a similar distribution model, they have a similar notion of binary compatibility as Scala/JVM. For Scala/JVM it translates into run-time errors. For Scala.js and Scala Native, it translates to *link time* errors. But in both cases it is related to distribution, not dynamic loading. A language whose ecosystem uses a distribution model based on sources (e.g., JS with npm) has a separate notion of "binary compatibility". In such an ecosystem, source compatibility == binary compatibility. This is not necessarily *better* than binary compatibility. As I explained somewhere recently ([here](https://contributors.scala-lang.org/t/a-guide-on-binary-compatibility-need-your-input/1089/2?u=sjrd)), binary compatibility is easier to achieve in Scala than source compat is. Therefore, it is a *good thing* that our model is based on binary compat rather than source compat.
&gt;&gt; having close to 400 things in the global namespace &gt; the java namespace is the main culprit here There are 400 things _without_ counting the `java.lang` import. That comes on top of the 400 things. This would have been easily verifiable, just like all the other points I made. The rest is pretty much flat-out wrong too, but I realize I can't reason people out of positions they haven't reasoned themselves into. Is there anything that _isn't_ Java's fault in your mind? I give up.
&gt; If you are talking about the compile-time notion of classpath, I don't see a problem here. For Scala.js and Scala Native, the notion of classpath is only a compile-time summary of your library dependencies. Any statically typed language should have such a thing. I don't see how classpath are any worse than a bunch of -I flags to gcc, or any other information that you have to give to a compiler to tell it where the static types of your dependencies are. The issue with working with a `ClassPath` is that the scope of the problem is very large, i.e. its much larger compared to what you strictly needed. GCC `-I` flags are actually a lot easier to reason with, and a lot more performant compared to how classpath handles things &gt; If Scala Native were alone, it would indeed make sense to use UTF-8 by default. However, the ability to cross-compile code across platforms with the same semantics is very important. Therefore, it is not so much interop with Java than platform-independence with Scala/JVM and Scala.js that makes Scala Native choose UTF-16. (There's no such thing as Java's version of UTF-16; it's the standard UTF-16 -- except if you're talking about DataInput/OutputStreams, but that's very narrow.) Sure, but this is coming out of Java/JVM in the first place. If Scala didn't target Java/JVM its highly likely it would have just picked UTF-8 since its the better default to have. I mean its also going to be interesting how Scala native will handle targets like iOS with stuff like `NSString` &gt; This is for a lot more than MiMa. You have IDEs, separate compilation, etc. And in particular it is for macros. Indeed, since the compiler runs on the JVM, it uses the class files to execute the macros, even when compiling for Native or JS. Even if all the tooling of all the Scala ecosystem used something platform-independent (let's say .scalasig), we would still need the .class files for macros. The point I am talking about is that we are even considering/talking about `.class` files. `.class` comes from Java, its nothing specific to Scala apart from the fact that Scala chose JVM to interopt/target as a first class platform. &gt; Binary compatibility has nothing to do with dynamic loading. It has to do with distribution. Because Scala libraries are distributed (on Maven) as compiled artifacts, it is those artifacts for which compatibility is essential to avoid dependency hell. Since Scala.js and Scala Native follow a similar distribution model, they have a similar notion of binary compatibility as Scala/JVM. For Scala/JVM it translates into run-time errors. Well it actually does, If you have dynamically loaded jar's you need to have binary compatibility otherwise you will have issues loading a `.jar` compiled with Scala 2.12 in an application that has a Scala 2.11 runtime. The point I am making, is that if you have worked with languages like Haskell/OCaml/Go/Crystal/Rust (pure Rust without linking to C), these errors are basically non existent, which is the central thing I am trying to get at &gt; A language whose ecosystem uses a distribution model based on sources (e.g., JS with npm) has a separate notion of "binary compatibility". In such an ecosystem, source compatibility == binary compatibility. This is not necessarily better than binary compatibility. As I explained somewhere recently (here), binary compatibility is easier to achieve in Scala than source compat is. Therefore, it is a good thing that our model is based on binary compat rather than source compat. Its may not necessarily better (this is highly debatable because languages like OCaml/Haskell which have very high bar when it comes to correctness use this model), but the point is its a hell of a lot harder to work with wrt * The compiler * Maintainers of libraries * Users of libraries To be clear here, I am understanding why all of this is done. I am not trying to criticise the people here that are putting countless hours of talent and hard work into the Scala ecosystem, the point I am trying to argue is that all of this "baggage" (I don't know if this is the right term?) is due to Scala's original design goals of having **strong** interopt with JVM
&gt; The rest is pretty much flat-out wrong too, but I realize I can't reason people out of positions they haven't reasoned themselves into. Is there anything that isn't Java's fault in your mind? I give up. You can't claim things are wrong when there are ongoing discussions about why the decisions are made, and in almost all of the cases its directly or indirectly due to Java (or expectations wrt Java).
IMHO, choosing a statically typed language has huge long term benefits when it comes to maintainability (not just refactoring). Scala has the benefit that you can share code between client (Scala.js) and server (JVM). There are other statically typed languages (TypeScript, PureScript etc.) that provide the same benefit by having a JavaScript backend that enables running in Node.js.
I'm currently developing a **validation DSL** for data pipelines, that would enable the developers to quickly test the end-to-end functionality and also make it part of their build/CI. **Source code:** https://github.com/jetprobe/jetprobe **Documentation:** https://jetprobe.com **Validation DSL example:** https://jetprobe.com/docs/writing-validations/ 
Web assembly library. https://github.com/shawjef3/webasm It has a binary codec, and I'm working on the text codec.
Very cool! I have a corpus of ~2.5 million LOC with semanticdb in https://github.com/olafurpg/scala-experiments if you're interested in running your analysis on other projects :)
There are countless of examples of both. I think it comes down to which tradeoffs work for you. There's definitely not a right answer. I suspect that since your audience is /r/scala, you're going to get a lot of folks suggesting using Scala, for all the reasons that Scala is a great platform for back-end development. That would be my suggestion too. So I guess I'll try to provide a couple counterpoints: - Node has a far larger ecosystem - Node has far more developers, if you need to recruit - Assuming you're definitely writing your front-end in JS, you won't have to context switch I guess that's about it. Do whatcha like!
&gt; Which one is better if we need to refactor into micro services in future? I don't think there's a lot of difference if you do need to refactor into microservices - but Scala will make it easier to not need to refactor into microservices, by letting you solve the same problems in easier, less invasive ways. &gt; I never maintained any project for long time, are you seeing any advantage with scala over nodejs in back end in long time? Yes. Once you get experienced with Scala, "if it compiles, it works" is real, and that makes it much easier to refactor, which then compounds into better maintainability. Just being able to fearlessly rename fields has a huge value over time.
I just posted this in the previous thread. Hope it's fine posting here now. Sparkplug - https://github.com/indix/sparkplug Spark package to "plug" holes in data using SQL based rules 
I realize that this is probably not the exact question that is being asked, but you can run Scala on Node.js with [Scala.js](https://www.scala-js.org/). There are some third-party type facades for Node.js, for example [here](https://github.com/scalajs-io/nodejs). If you prefer Node.js APIs and ecosystem relative to the JVM, and still want to use Scala, it is possible.
&gt; GCC -I flags are actually a lot easier to reason with, and a lot more performant compared to how classpath handles things This just does not sound right to me. I've had a really hard time dealing with `-I` flags in C++ projects, and never had any issue with classpaths. I also think your claim about performance is completely unsubstantiated. &gt; .class comes from Java, its nothing specific to Scala apart from the fact that Scala chose JVM to interopt/target as a first class platform. Correction: apart from the fact Scala chose the JVM *to implement its compiler*. The interop with Java has nothing to with it. If Scala had chosen to have crappy interop with Java, it would still have its compiler running on the JVM and we would still have .class files. &gt; Well it actually does, If you have dynamically loaded jar's you need to have binary compatibility otherwise you will have issues loading a .jar compiled with Scala 2.12 in an application that has a Scala 2.11 runtime. The point I am making, is that if you have worked with languages like Haskell/OCaml/Go/Crystal/Rust (pure Rust without linking to C), these errors are basically non existent, which is the central thing I am trying to get at You are making a false reasoning. You say *if* we have dynamic loaded jars, *then* we need bin compat (and I agree with you so far) but then you use that sentence to claim that Scala having bin compat issues is *because of* dynamic loaded jars. This is a false reasoning, since there are other causes for bin compat issues. And as proof: Scala.js and Scala Native have bin compat issues, despite having no dynamic loaded jars. I will not repeat myself. I already explained that bin compat has to do with the distribution model. Whatever format is distributed in your ecosystem, that format is the level of bin compat you have. I guess Haskell doesn't have bin compat issues because they distribute via source? We could, in theory, distribute Scala libraries as sources, and we wouldn't have bin compat issues. We would have other issues, though, such as much more fragile source compat and totally uncontrollable compile times. &gt; the point I am trying to argue is that all of this "baggage" (I don't know if this is the right term?) is due to Scala's original design goals of having strong interopt with JVM And I strongly disagree with you, for all the reasons I have pointed above (and I would argue that my being the author of Scala.js gives me a pretty unique perspective on the topic). Your post has not changed my mind a tiny bit. If mine didn't change your mind either, then we are both stuck in our respective opinions, and I will not try any further.
&gt; You are making a false reasoning. You say if we have dynamic loaded jars, then we need bin compat (and I agree with you so far) but then you use that sentence to claim that Scala having bin compat issues is because of dynamic loaded jars. This is a false reasoning Yes, because both platforms distribute compiled bytecode in maven jars. &gt; I guess Haskell doesn't have bin compat issues because they distribute via source? We could, in theory, distribute Scala libraries as sources, and we wouldn't have bin compat issues. We would have other issues, though, such as much more fragile source compat and totally uncontrollable compile times. This is what I meant, binary compatibility is an arbitrary saying that produced bytecode (whether its JVM or its assembly) must conform to a specific structure. With JVM, there is a proviso, which is that the same bytecode that JVM produces is also bytecode that is loaded dynamically, and this is how almost all Java/Scala programs are compiled. This is with comparison to Clojure (which is also JVM however does source control distributions because of the maintenance nightmare, however clojure is in a nice spot because its not statically compiled) WRT to Haskell and other languages (which is where I am coming from when I say these comments, its with the other competition out there) - Haskell: Entirely source based. - OCaml Same as Haskell, except that as a bonus, the OCaml compiler is basically instant, it compiles most programs in 200-1000ms. It compiles the entire OCaml (bootstrap) in 5 minutes - C/C++ Also entirely source based. They don't really have package managers, but its impossible for said languages to distribute binaries in a generic way because compiler flags are non standerdized, especially with C++ you would literally have thousands of permutations for different binaries you would have to publish. - Rust: Same as C/C++ but there is a package manager (Cargo), this is also source based - Go Also entirely source based Note for the above languages there is an "abi" or "binary compatibility" but these aren't distributed, they are compiled and stored on the local machine (for obvious performance reasons). So yes you can argue that the dependency management and binary compatibility is strictly orthogonal, the point I am making is that on JVM this really isn't the case at least if you do things the maven/ivy/Java way (which doesn't statically link everything, instead it loads Jars) which is what Scala does. In any case, the claim that these languages have terrible issues with compile times are largely untrue (at least in comparison to Scala and from a general user perspective). It is definitely true that first compiles take time, but again its not like something that Scala doesn't have to deal with. Languages like C++ and Haskell (when using a lot of GHC extensions) have compile times that also mirror Scala. Wrt fragile source compatibility, it doesn't seam to be an actual issue in practice. &gt; And I strongly disagree with you, for all the reasons I have pointed above (and I would argue that my being the author of Scala.js gives me a pretty unique perspective on the topic). Your post has not changed my mind a tiny bit. If mine didn't change your mind either, then we are both stuck in our respective opinions, and I will not try any further. I guess we have to agree to disagree. I am saying this from the perspective of trying out the competition (currently its OCaml/Reason/Bucklescript) because of my frustrations with Scala/SBT. I am just reporting the areas where they are far ahead of Scala and the reasons why.
I was thinking of writing a long reply, but this guy explains it much better than myself https://twitter.com/alexelcu/status/927201775291166720 For this reason alone, Scalaz8 IO is useless for me unless Scalaz also provides a completely pure implementation of the Scala/Java ecosystem. Scala is not Haskell, it is not completely referentially transparent from top to bottom, treating it as such is going to create endless headache for end users and this is nothing that Wartremover can fix. I would have better ways to spend my time then debugging `IO` which would never finish because something, somewhere (and yes that means outside of my code) throws an `Exception` ;)
I added a little main stub, so could try to run it with your code-base: https://github.com/Sciss/Citarj2017Code/#requirements--installation
Agreed. I'd definitely draw the line before attempting to reinvent Generic. I guess the sane thing is to do some more advocating for shapeless next time the opportunity arises.
Hi nice project! , your readme.md says: "User Doucmentation" 
Can I ask as someone who is just browsed through the basics of Akka Actors - aren't one-and-done Actors a hit on performance if the GC needs to clean them from time to time (assuming a lot of messages being sent)?
In my experience, Eclipse and IntelliJ have similar amounts of problems, just different types. I've always preferred Eclipse to IntelliJ, and I want to vote against the current (de facto) IDE monoculture, so I use ScalaIDE.
The idea is to generate webasm from Scala code?
Thanks. Fixed it.
Yes and no. One and done is used every time you use the ask pattern for example, and that performs quite well, up into the 100s of thousands of messages per second realm. But to get in the high millions you need to move away from it. The key is that actor creation is incredibly cheap. Like the difference between processes and threads cheap. 
Thanks for the post. I'd be interested in seeing if I could get this deployed in an emr.
At this point it’s art.
Ongoing discussions are not indicative that an issue is still worth discussing. Some people still argue that the earth is flat, and no amount of evidence can change their opinion. See this thread.
Any key-value store with multi-key transactions... Last time I checked that would be none of key-value stores. Most implement atomic ops on a single key, and if they could build on top of that it would be an intriguing platform.
BerkeleyDB JE does that, for example.
From what little I see on Berkley DB it’s a single master multiple replicas DB. Yes, if you don’t have to partition your data across network you can easily implement transactions.
If you have any questions regarding the tutorial feel free to ask! 
Funnily enough, the IRC's were not mentioned. #Scala and #scalaz on Freenode are incredibly active (moreso than many of the Gitters), and are extremely helpful to anyone looking to form actual community, as opposed to just asking questions.
A very opinionated article: - "Scala represents the symbiosis of Java and C #", not really - Yes, Scala is more complex because it has many features which Kotlin lack. For the features that both languages share I feel the learning curve is basically the same, and the syntax is very similar. - Null safety: `Option` is convenient to use, but, yes, when dealing with Java API's Kotlins static null checks are useful (one of the few things I miss in Scala). - "Scala has problems with the syntax of the infix and postfix operators". Some examples please. - I don't agree that Scala has stagnated (look at Dotty). How is it more stagnant than Kotlin? Of course once you release v1.0 of a language you don't want to break existing code willy-nilly. - Compilation speed: it might be true that Kotlin compiles faster, but some benchmark numbers to back this up would be nice. A comparison with Zinc would be interesting. 
Am I the only one who thinks that this so called "vote" is a clickbait and trolling?
[removed]
Stopped reading at: &gt; Scala represents the symbiosis of Java and C # 
Why????
I agree with /u/know_not_much mostly because there has been a slow but steady flow of posts comparing Scala and Kotlin that basically repeated the same (imo mostly flawed) arguments to make the point that Kotlin is the future and Scala is too hard. These posts get regularly posted in here and if the first two-three of them were insightful now the impression that I get is that this is just FUD.
Null checks are useless on the jvm outside of a monadic or continuation context. https://www.reddit.com/r/scala/comments/32wct7/wouldnt_it_be_great_to_have_null_checks_in_scala/cqf9vvt
This looks like it would work really well with lightbend-emoji: https://github.com/lightbend/lightbend-emoji/blob/master/README.md
Scala: Not convenient functionality for Null Safely. Wut?
&gt; Partially applying a function means creating a new function by pre-filling some of the arguments to the original function. That's not what it is. You confused it with currying.
Cool. Can we have anchor links ?
I thought that is exactly it. Currying is taking a function with n params and returning a function with 1 param which then returns another function with 1 param and so on until all n arguments have been passed, no? 
you are correct, kellysmith has them confused
I would love to see some projects where all these libraries are used together. I did something a while back when trying to understand Free Monads here: https://github.com/calvinlfer/free-monads-functional-web-apps I know tpolecat had a nice bitbucket repository too although I can't seem to find the link :-(
hey tpolecat, are there any example repositories where all these libraries are used together?
No, the author is a toolkit provider for apis that must be as close to identical as possible in scala and java. The purpose of the style guide is to ensure that users in Java don't get left out because some feature is trivially easy to implement by using some scala feature that isn't available in Java. As far as correctness goes, if you want compile-time correctness, then Spark probably isn't your thing. There are other ways to achieve what Spark does, and probably in a safer manner. They just are far easier to implement in Scala/Haskell and won't be easily callable from java.
[removed]
&gt; One technique I've employed is creating an anonymous class that implements the trait, and stubbing out the dependencies. This is what I’ve been doing too. Doesn’t seem gross to me. If you want to avoid making an anonymous subclass, you could always make a concrete non-anonymous subclass (or object) but in the end it’s basically the same
Please post an example. It doesnt have to be the real class, just enough to show us the structure of what you’re testing.
Ah I didn't realise this was literally the style guide for contributing to spark. In that case a lot if this makes more sense. I do wonder why bother with scala if the intention is to write code as if it were Java though. Curious what you're referring to when you say there are spark like things out there that are more about static correctness? The main challenge with any data processing framework is that you can't push data correctness checks to compile time. Best you can do afaik is what spark does with datasets which is to say "assuming the correct dates format as input we can reason about what we do with this data".
Put your logic in the companion object and test that. The #1 Scala best practice IMO is getting rid of mutable state. You shouldn't need to test a trait.
Even a pure function, I like to test, when it isn't very trivial.
How is mutability / immutability related to the need of testing?
Is there a way for SBT to check conflicting runtime dependencies ? ie logger 1.0.0 % "runtime" and logger 0.9.0 % "runtime"? If they were compile-time it would get checked and error would be reported...
really, really nice. I have to finally checkout quill on my next project (coming from slick)
You may get some bias answers here but the correct answer is Scala.
You can push everything except parsing errors to compile time, and wrap the parse in ValidationNEL. You can't prevent a parse error. But you might handle a parse error by ignoring or reporting invalid input for deletion, etc. As for better options than Spark, I'm referring to traditional data processing jobs attached to Kafka queues using type safe languages to process the streaming sources / take your pick of stream processing library -&gt; fs2/monix, etc, or plain old hadoop map reduce, summingbird, etc. We're doing Kinesis, iteratees, fs2, and s3 at work, and we reliably process a very large amount of data in a pseudo-streaming fashion without spark (though I reccomended it in the beginning for ease of development and training). Using SQL to process things at that scale is great, but with Spark you are hiding a lot of things behind things that have functional interfaces that are inherently side-effects. Beyond safety, Not being able to inline one spark program into another means that you cannot compose them from smaller, reusable units into a larger whole. There is some outside scheduling you have to orchestrate to run jobs - multiple spark jobs that depend on each other are all special snowflakes that require special ways of triggering the dependant jobs. So, while it may look functional, with map, filter, etc., an RDD is not. It's halfway there. To go all the way, it would need a result type To wrap success and failure, and an unsafeRun at the minimum. To do that, you have to resort to some other abstraction, and interpret it into Spark usage using a Free or Tagless final style. It's notoriously difficult to abstract, though, so ymmv. Apart from Rdds, there are other means of storing and interacting with your data, such as roll your own CRDTs, CassandraDB, HBase, etc. The point is that Spark is a wonderful tool, and it will make your life easier most of the time. It isn't the only tool, though, and it could have been written in a functional style, which would make it a bit more extensible. But it wasn't. So when you want thatnn you have to look elsewhere. 
You can new up a trait. val toTest = new MyTraitUnderTest{ // overridden mocks /stubs go here } 
As an interested reader, it doesn't really seem fair for you to take your ball and go home when mdedetrich has taken the time to substantively address your concerns. I've seen him around the subreddit and know him as a smart person - writing him off like that is not a good look. And as someone who doesn't know anywhere near as much about Scala as the two of you, it makes me assume that he's right and you have no answer.
Looking at concepts from type theory encoded in javascript is completely hilarious! Thanks! :D
&gt; [`eq`] also compares the bits (and the type) of the value. This causes surprising results with floating point numbers, were equivalent values can have different bit representations. If you just compare the bits, NaN might `eq` NaN but it also might not. I fail to understand how defining `eq`for value types addresses the problems of `equals`. Every implementation still has to manually check for comparisons against incompatible types and against null. And you still have the problem that `(A == B) != (B == A)` if A and B have different `equals` implementations. The goal is for `3 == "asdf"` to be rejected by the type system. 
What are you trying to do exactly? 
He has addressed exactly none of my points. That's exactly why I'm going home. Opinions can either be based on reason or on ideology. The main difference is that if you hold opinions based on reason, you are able to name specific evidence that would change your opinion. I'm relying on facts for every opinion I mentioned, but based on his replies, I think it is clear that no amount of examples, evidence or facts can change his. Just to pick one example, implicit lossy widening conversions: - Java creators call it a mistake. That's a fact. - The person who added it to Scala was unaware of that. That's a fact. - Languages after Scala have wholesale abandoned implicit widening conversions. That's a fact. - Scala itself wants to restrict conversions that convert between unrelated types. That's a fact. - Since Java was created, no one was able to come up with an approach that doesn't have glaring corner cases and issues. That's 20 years of evidence. - No one is able to explain how the scheme is supposed to scale if Java ever adds more numeric types after value types are introduced. My opinion is based on following all discussions on Scala's mailing list, reading every ticket across Scala's three bug tracking systems, reading every commit ever made to Scala, spending 5 years on fixing the language, carefully examining the approaches of every mainstream language, as well as Swift, Rust, OCaml, D, Haskell, SQL and a few others, and having an actual implementation based on what I'm saying. How can you change my opinion? Show me an implementation of implicit widening conversions that isn't full of corner cases, holes and puzzlers. His opinion? "But it's Java's fault ...!" Just to be clear, there is a huge difference between "the JVM forces us to do this" and "we just copied what Java did, because we didn't know better back then". Nothing of what I just described is forced upon Scala, as evidenced by other languages running on the JVM, which completely discarded the concept. &gt; it makes me assume [...] Don't assume, don't believe anything anyone has written. Think for yourself and come to your own conclusions based on facts.
I left out whether `eq` on floats should use the equivalent of `doubleToLongBits` or `doubleToRawLongBits`, because my text was already to long and I thought it was fairly obvious. `eq` addresses some of the issues, because we don't need to rely on boxing anymore to sort out equality, and have a new fast-path that will make equality comparisons substantially faster in a success case. The point is that with a sane definition of identity and equality, combined with specialized generics, the JIT will have a better chance of eliminating a lot of the code in [BoxesRunTime](https://github.com/scala/scala/blob/2.13.x/src/library/scala/runtime/BoxesRunTime.java) at runtime. That's eliminating the whole reasoning why it is suddenly supposed to be necessary to break a lot of code and make semantics worse just to improve `==` performance. The other problems you mention are basically unfixable if you want to retain Java interop. I make no claim of improving anything here, I just want to argue that making things even worse is not the right approach. Dotty's proposal in this regard has failed.
dude, java ecosystem is huge too, and scala can access all java libs. plus it is actually multithreaded
I think it's disingenuous to say that the change was made strictly to improve `==` performance. &gt;&gt;&gt; dotr Starting dotty REPL... scala&gt; val x: String = "Asdf" val x: String = "Asdf" scala&gt; val y: Int = 1 val y: Int = 1 scala&gt; x == y 1 |x == y |^^^^^^ |Values of types String and Int cannot be compared with == or != Versus &gt;&gt; scala Welcome to Scala 2.12.4 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_121). Type in expressions for evaluation. Or try :help. scala&gt; val x: String = "asdf" x: String = asdf scala&gt; val y: Int = 1 y: Int = 1 scala&gt; x == y res0: Boolean = false The core problem sure seems fixed to me. Sadly `1 == 1.0` remains true despite violating the substitution property of equality but that's really a separate issue.
[This one](https://github.com/pauljamescleary/scala-pet-store) looks pretty good.
Immutability certainly makes testing easier, as does a static type system, but there's definitely still a need to test in any non-trivial project. 
&gt; I think it's disingenuous to say that the change was made strictly to improve == performance. No, these are two separate things, with different issues: The proposal to change equality is bad, the Dotty thing with multiversal equality just doesn't work.
My mistake!
Depending on the nature of the trait you may end up testing it by creating an anonymous class (no, that's not bad at all) or indirectly by testing the class(es) you've mixed the trait in.
You can often rework a trait's functionality to be a conventional class that whatever uses that functionality can have as a member, rather than something that has to be mixed in. Composition over inheritance :P.
I guess you _could_ access the Java ecosystem, but by and large, that would negate much of the benefit of working idiomatically within Scala. It's a plus, especially in the old days, but now I'd say it's a minor plus. Multithreading is cool and all, but I'm not sure how much it matters for most microservices as long as your system is fully async. If you run as many copies of your Node service as you have cores, you're probably going to have roughly the same benefit. Of course, if a paradigm like actors or streams models your service well, I think that's a good reason to go with Scala.
no, it's a rather major plus still. being able to write cuda stuff using scala and jcuda is very nice. being able to use apache commons is very nice. there are a lot of nice libraries and software that don't have "idiomatic" scala equivalents in the java ecosystem, and the beauty of scala is that you can use them, and hide them away to the point that you can end up using them in an idiomatic way if you want. scala's extremely flexible in that it's procedural/object oriented/functional, and you can use that flexibility to ease procedural object oriented java libs into functional use styles. 
Author of Caustic here. Every major SQL database supports multi-key transactions, and so do a surprising number of NoSQL databases like RocksDB, CockroachDB, and Cassandra to name a few.
Yeah but SQL transactions are kinda heavy weight in distributed scenario. Also when did Cassandra started to support it? I mean I could swear it didn’t just a year or two ago. A link to docs would be most appreciated. Also it may at prohibitively high cost in some of those. Aaaand RocksDB is just a storage engine that doesn’t do distribution in its own IIRC.
Cassandra transactions can involve multiple keys as long as they do not cross partitions. https://docs.datastax.com/en/cql/3.3/cql/cql_reference/cqlBatch.html
How would you know if it did cross though? Making sure your partition key is the same is super limiting.
Yeah I suppose you wouldn’t know. I was just listing it as an example of a key-value store that supports multi-key transactions, albeit in a very limited capacity. I don’t think its possible to implement a *transactional* language as robust as Caustic on top of a key-value store that doesn’t support multi-key atomicity. However, Caustic programs will still run on non-transactional key-value stores, although they will, unsurprisingly, lose all of their transactional guarantees. In other words, you can still run Caustic programs on non-transactional key-value stores but they will be vulnerable to race conditions.
The point is I guess that a limited multi-key transaction is about as good as no transaction if we look for guarantees. So that leaves *some* NoSQL db, though I’d be super careful about those and SQL. SQL can be quite slow when combine transactions across partitions as well. Also I bet the biggest reason to run Caustic is transactional guarantee. I just wanted to warn that multi-key transaction is a very costly operation ( if supported at all) on all distributed systems. Which would threaten scalability of Caustic.
Thanks for your recommendation! We have switched to lightbend-emoji! 
One of the ways I’m trying to address this is by implementing atomic multi-key transactions over key-value stores with single-key atomicity via some form of Two-Phase Commit, Paxos, etc. You are totally right, it will always be an expensive operation in any distributed systems. But so will any form of coordination in a distributed system. Do you think that distributed locks and semaphores will be significantly more performant? There will always be a price for safety in a distributed system, and I believe that Caustic pays a reasonable one.
If there's any situation in which replacing `producerSettings` with `producerSettings2` changes the behavior of your program, then yes, it breaks referential transparency. Such a situation is when the instance that you're creating is mutable or if any of the wrapped references (e.g. `StringSerializer`) are mutable.
a bit of a tangent, but how many here are familiar and use scalatest's [DiagrammedAssertions](http://doc.scalatest.org/3.0.0/index.html#org.scalatest.DiagrammedAssertions)? imho it is scalatest's best and most underrated feature. sadly, it is not even mentioned anywhere in the website documentation (other than its own scaladoc page)
It’s always about implicit vs explicit. Performance usually benefits from being explicit, safety and correctness from implicit guarantees. I’d have to try Caustic to have any idea if performance is acceptable, also it would need a baseline. Your distributed counter could be a decent example, though it won’t be sufficient. All in all, I believe that Caustic is the move in the right direction - runtime must do the heavily lifting if we are to make distributed computing accessible to average programming. 
Why not uTest (https://github.com/lihaoyi/utest)? It has pretty much the exact same design (minimal testing framework with no crap)? In any case, not trying to defend specs2/scalatest completey, but one thing that I find that these microtest framework lacking is the area of matchers (honestly this is the only reason I use stuff like specs2). In the majority of cases when I am testing something, its often not asserting something is true/false or if it exists, its rather "does this deeply nested value/type satisfy this requirement" and if it does not, then I want a nice diff of the expected value vs the real value (this matters if you have deeply nested case classes)
I mentioned utest in the article. At that time it had a small issue with displaying errors and Li Haoyi also has some API opinions I disagree with — and the effort of starting my own was really low, due to how awesome SBT is in this regard. Truth is I don't need the library to be popular in order for me to use it, since it's so close to "FunSuite" and the maintenance is really low. I do think that ScalaTest or Spec2 do a lot of really cool things, however I disagree that the complexity cost is worth it. I just want something usable and that I can port around whenever a new target appears. As for diffs and nested values, I understand, but then you only write tests once — after which they run repeatedly, forever. So I prefer long term maintenance. I might introduce diffs in the output of `assertEquals`, but it hasn't been a pain thus far.
I might be wrong but here it appears that StringSerializer might not be mutable, but doesn't override equals. As such if code uses any comparison that would use equality check (e.g. comparing ProducerSettings) then RT is broken even with immutable refs and structures.
Referential transparency != equality tests being possible. Any two references `x` and `y` have to be "equivalent", not equal. For example these two functions are equivalent: ```scala val f = (n: Int) =&gt; n + 1 val g = (n: Int) =&gt; n + 1 ``` We can reason about them, since it's math we can see that for any input they generate the same out, however we cannot programmatically test them for equality.
I like the philosophy here, however I still see one unnecessary complication: test("should be") { assertEquals(2, 1 + 1) } This clearly has method-like semantics but I cannot call it like a method. Why not just use methods? In JUnit this would be: @Test def shouldBe = ... Since test suites are objects this also makes it super easy to call tests manually, for example in the REPL.
Well I know those concepts are not the same. I just think that if I use equality check inside a function, and it is broken then, well, function will be broken as well, but broken RT will be one of symptoms.
Yeah uTest's error reporting and CLI got a lot prettier recently, but for years it was in pretty bad shape, as were the test-defining macros. Can't blame you for writing your own library; I actually poked through your source code recently when fixing uTest issues when wondering why your SBT integration was working correctly and mine wasnt :P
I can't answer for alex, but for uTest, the reason I didn't go with REPL methods is because of nesting. I use helper methods *very* aggressively in my tests to DRY up the logic, which means my tests often end up looking like this: val Check = new Check(9999) 'primitives { 'Unit { * - Check((), "()", "undefined") } 'Char { * - Check('\n', "'\\n'") * - Check('a', "'a'") } 'Byte { * - Check(123.toByte, "123") * - Check(-123.toByte, "-123") } 'Short { * - Check(123.toShort, "123") * - Check(-12345.toShort, "-12345") } ... } 'misc { 'Nothing - intercept[Exception](Check(throw new Exception(), "")) 'Null { Check(null, "null") Check(null: String, "null") Check(Seq("look!", null: String, "hi"), """List("look!", null, "hi")""") } 'Either { Check(Left(123): Either[Int, Int], "Left(123)") Check(Left(123): Left[Int, Int], "Left(123)") } 'Options { Check(Some(123), "Some(123)") Check(None: Option[Int], "None") } ... } 'collections { 'Iterator - Check(Iterable('1', '2', '3'), "List('1', '2', '3')") 'Array - Check(Array(1, 2, 3), "Array(1, 2, 3)") 'Seq - Check(Seq(1, 2, 3), "List(1, 2, 3)") 'List - Check(List("1", "2", "3"), """List("1", "2", "3")""") 'Vector - Check(Vector('omg, 'wtf, 'bbq), """Vector('omg, 'wtf, 'bbq)""") 'Buffer - Check( mutable.Buffer('omg, 'wtf, 'bbq), """ArrayBuffer('omg, 'wtf, 'bbq)""", """WrappedArray('omg, 'wtf, 'bbq)""" ) ... } It effectively gives me many of the benefits of [table-driven tests](http://www.scalatest.org/user_guide/table_driven_property_checks), and let's me smoothly move my tests along the spectrum from "small number of big examples" to "big number of small examples", without needing to jump between two totally separate APIs like you have to do in ScalaTest. The flip side is that you end up with enough cases in one file that you end up needing nesting to organize it. If I didn't care about nesting, I would have definitely gone with the annotation-def syntax that JUnit does.
♥️ I also looked at your source when building Minitest, since uTest was first, had to start from somewhere and looking at ScalaTest wasn't feasible.
In addition to what Li Haoyi said, I didn't want annotations because I wanted to avoid _reflection_, which was a problem on Scala.js. Now if annotations work on Scala.js, that's fine, however Scala Native is coming and maybe others who knows and reflection is always a problem that I'd like to avoid.
Does the API of `ProducerSettings` guarantee that it is comparable? If not, my own opinion is that in the basic case, one has to be careful with relying on behaviour that is not part of the API.
&gt; I didn't want annotations because I wanted to avoid _reflection_, Using annotations does not force you to do runtime reflection, you could probably use something like macro annotations instead. &gt; I also like to write sentences as test names and have some freedom there You could always write "def `my long test name` = ..."
Never experimented with macro annotations, that’s an interesting idea.
Never experimented with macro annotations, that’s an interesting idea.
Couldn't you use nested methods with annotations?
&gt; As for diffs and nested values, I understand, but then you only write tests once — after which they run repeatedly, forever. So I prefer long term maintenance. I might introduce diffs in the output of assertEquals, but it hasn't been a pain thus far. Honestly I think we are writing different types of tests. If we are talking about testing basic functionality of libraries (such as Monix) I can see where such an approach is beneficial. My earlier was however in context of integration testing (which we use specs2 for at work). In this type of testing * Testing does break because services sometimes break their API. When the stuff breaks I do want to see a diff of what is going on. Very good examples of this are breakages in JSON, particularly if you map JSON to case classes (i.e. Circe) * We aren't just testing that things basic values. We often need to do a specific type of assertion deep down in a nested structure. i.e. if an API returns a type of tree and we need to test that it is balanced, or a list has a certain amount of elements *and* its of a certain type, all of these kind of assertions are much more easily solved with matchers. * When you are testing for `Future`/`Task`, you want handy utility functions to easily unwrap the inner value If we didn't these have matchers (i.e. using something like uTest or miniTest), we would basically have to implement a lot of these matchers by ourselves. I don't think we are disagreeing here though, as programmers we are meant to use the write tool for the job. For Monix I can see how something like specs2/scalatest is very heavy. Also I do heavily agree about the whole "putting English into our code". This stuff I don't really like (although at work we do use the `immutable.specification` which outside of matchers keeps this to a minimum)
Annotations in Scala can be compile time construct, they aren't always reflection based (this is actually true of Java as well). See https://docs.scala-lang.org/overviews/macros/annotations.html and https://docs.scala-lang.org/overviews/reflection/annotations-names-scopes.html
I develop purely functional layer atop of Akka Persistence and Akka Cluster Sharding https://github.com/notxcain/aecor. We use it at work and polish each iteration, it takes some time though.
I'm not sure if there is an automated way of checking that, but I like the [dependency graph plugin](https://github.com/jrudolph/sbt-dependency-graph) for manual debugging.
We do write different tests. I did encounter the problems you’ve been facing as well, due to ending up with these giant values representing state. At some point I might do diffs.
Couchbase too, via N1QL indexes.
Indeed, but the disease here is reference equality, as in general the concept of "universal equality" in OOP languages is a terrible idea. So if you're interested in FP, you might want to checkout the Eq type-class from Cats, see: https://typelevel.github.io/cats/typeclasses/eq.html
Alexandar Prokopec gave a talk on a similar topic : https://www.youtube.com/watch?v=B72a1D2xvFs
I king of use, wart remover would complain otherwise.
I started with a small library to add prometheus metrics to http4s at work today, as we started using http4s :) https://github.com/yannick-cw/http4s-prometheus
Instances in Scala are difficult to understand, how to translate into FP. 
The simplest definition of Referential Transparency IMO is "If replacing expression x by its value produces the same behavior, then x is referential transparent". And here is the demonstration: import cats.effect.IO def f(a: Unit, b: Unit): Int = 5 val x: Unit = println("hi") // hi x: Unit = () // Same result but different behavior: f(x, x) // res0: Int = 5 f(println("hi"), x) // hi res1: Int = 5 f(println("hi"), println("hi")) // hi hi res2: Int = 5 def g(a: IO[Unit], b: IO[Unit]): Int = 10 val y = IO(println("hello")) // y: cats.effect.IO[Unit] = IO$1225339887 // Same result and same behavior: g(y, y) // res3: Int = 10 g(IO(println("hello")), y) // res4: Int = 10 g(IO(println("hello")), IO(println("hello"))) // res5: Int = 10
With that part about DSLs the author instantly got more respect from me. Programming is not English language, old programming languages that were a bit much like English have consistently failed, because you need to be exact with wordings that are harder to remember because you use words instead of salient syntax (like curly braces).
Can this be put into the sidebar under Scala Libraries -&gt; Functional Programming
&gt; Couldn't you use nested methods with annotations Yeah you could, but then you both lose the "call them from the REPL" property, and add a huuuge pile of complexity in the macros required to transform them. So we're back in the same place, just with different syntax &gt; or if you want to be able to call them, nested objects with methods inside them? Yes I could, but that would lose another property I like: that the different method calls do not share the variables defined in enclosing scopes. We could potentially solve that by making intermediate wrappers `def foo = new { def bar = new {... }}`. This is something I've never thought of, and while structural types are gross maybe is worth a serious look regardless
`f(println("hi"), x) // hi res1: Int = 5` breaks RT because, of side effect printed text to console not? 
You are completely ignoring the fact that Scala is designed to be backwards-compatible with Java. That's one of the stated goals of the project. Given this goal, &gt; Nothing of what I just described is forced upon Scala.... ... is simply not true. It _is_ forced on Scala by its own goal of being backwards-compatible with Java. &gt; ... as evidenced by other languages running on the JVM.... Can you give an example of a JVM language which has a goal of being backwards-compatible with Java and does not do widening?
&gt; Can you give an example of a JVM language which has a goal of being backwards-compatible with Java and does not do widening? Kotlin val d: Double = 1 The integer literal does not conform to the expected type Double Ceylon Float f = 1; Specified expression must be assignable to declared type of f with strict null checking: Integer is not assignable to Float
I have to say I'm really looking forward to implicit function types.
Will be interesting to see in practice whether they clean up signatures and improve readability, or encourage devs to add even more implicit stuff to methods that should never had anything implicit in the first place.
I think some articles about reactive programming used these "marble" diagrams which I found quite nice to look at. Maybe not exactly what you are looking for, but maybe they can serve your requirements, too?
The thing I'm looking for covered standard Scala collections.
The names are pretty much identical, that's why I suggested them.
I've found it! https://superruzafa.github.io/visual-scala-reference/index-en.html
:-) This is really nice, never saw this page before!
The problem with implicits is the problem
Scala.js handles annotations for tests (at least for JUnit) with a compiler plugin, an SBT plugin and a reimplementation of the JUnit runtime ... it works, but it is not very straight-forward to get your head around ... especially writing your build config if you want to support three versions, 2/3 platforms and varying, platform-specific implementations. (Implemented Scala.js support for TestNG, which used annotations in a more elaborate way.)
Originally Cats forked off of Scalaz more or less to be more beginner friendly, and I suppose Hamsters is taking it a step further than Cats...
I don't really know what to think of this new feature. The argument in the beginning of the presentation is that functions are good abstractions because everything happening is explicit. Then the presentation moves on to present implicit functions as a magical ways to pass parameters around. It seems to me that it introduces a trade off to make code easier to write in exchange of complexity at reading time.
Indeed, and he has a habit of this. I had to come to read the comments here, because of the headline: &gt; Plain Functional Programming Oh, good! &gt; by Martin Odersky Oh, hahaha, right.
A wise man once said: @tpolecat "Constantly amazed at the complexity and nonsense people will embrace just to avoid passing arguments to functions." 7:47 AM · Mar 1, 2016 
The difference is that with implicits, the parameters are fixed statically, and tooling can reveal them It's analogous to type inference -- imagine the following conversation: A: Static types are great, they reduce complexity because you know the type of each variable A: However this results in "type all the things" which becomes very verbose. This is solved by type inference. B: Wait, didn't you just say you want to know every variable's type? Doesn't that defeat the purpose? I actually hear this often from Java programmers who don't like Scala's type inference because they're used to always seeing the type in the code. I can't say there's no room for that argument, but personally I think type inference means having your cake and eating it too -- the types are there but they're implicit. Similarly, I think implicit parameters are a way to have your cake and eat it -- the parameters are there (i.e., statically) but they're implicit. There are actually two ways type inference and implicit parameters are related beyond this analogy: 1. They're sort of duals: Type inference means you specify a value and let the compiler fill in the type; implicits means you specify the type and let the compiler fill in the value (of course with the implication that the type is specific enough to select a value). 2. As Odersky mentions here, the combination of types and parameters is of greater benefit than the sum of the benefits of each in isolation. Types mean whatever you make explicit can be statically verified. Functional programming means all your assumptions (external dependencies) are made explicit. It's the combination of the two -- statically verifying your external assumptions -- that's really powerful. So types and parameters arguably have a synergistic relationship. And both of them can be left to the compiler to infer.
Letting the compiler fills in the parameters seems to make the code harder to read and makes it harder to understand the flow of information. Maybe it is just a tooling issue and IDE should show where implicit parameters are passed around to help read the code.
Anyone knows what editor did he use ?
Visual Studio Code with the [Dotty Language Server](http://dotty.epfl.ch/docs/usage/ide-support.html) enabled.
Don't use runWith. Use the 'to' combinator to connect the Sink. Now you have the blueprint/graph which describes how to run the graph but you have not run it yet. At the end of the program (end of the world), materialize the pipeline with a call to run. You could wrap that in an IO so IO { graph.run() } and then run the IO at the end of the world via unsafeRunSync (forgot the exact name). The main point I'm trying to make is to delay the execution of side effects until the very end.
FYI creating that ActorSystem is also side effectful since it allocates thread pools and does a bunch of other stuff.
VS Code with the Dotty presentation compiler.
Wow, this is really cool. Thanks for sharing!
Again, I think that's subjective. Many people feel the same way about type inference. IntelliJ does show such things. Ctrl-Shift-P on a method call show implicit parameters being passed. Ctrl-Shift-Q shows implicit conversions being applied. The bad new is that IntelliJ's type checker is not always right. The good news is that it knows this and shows candidates besides fit the one it thinks it's right. 
Agree.. you gain having to type a couple of times on the keyboard but loose ~200% testability.
I think the end result is that both the reading and writing becomes much simpler. The argument of capturing effects with the implicit function types is that they avoid the accidental complexity you get with monad combinators, `Free` etc. thrown in to solve a problem for which they were essentially not designed, plus requiring you to rewrite the way the method body is structured. If I read `def readAge: Possibly[Configures[Int]]` that's much better both for the author and the consumer of a library. And nothing is magical BTW.
implicit resolution is a key property of Scala that takes a way a lot of stupid work from the programmer. You could make an experiment, take a code base and fill in all the implicitly passed parameters and contexts explicitly; I'm sure you would end up saying "no thanks, that's horrible". Think Java.
How do implicit functions adversely affect testability? In both Scala 2 and Scala 3 there needs to be an implicit in scope regardless of whether or not you explicitly type `def foo(implicit x: ImplicitX) = ...` or `def foo: ImplcitiX = ...` at definition site.
Sorry i don't know what happened it should have been readability. I wrote it on my phone and it probably autocomplete to a word i have been using before and i did not pay attention.
Good question, we'll find out soon enough -- Scala 3 seems not so far off, maybe a year or two at most from now it will be in the hands of implicit function type (ab)users ;-)
Thanks! I will start using these two shortcuts. M
Yes, it does. That's the whole point.
The funny thing is that the purely functional solutions are concretely more complex than the algebraic effects. This is explained very cleanly in the presentation because Monad's are not commutative. You can't easily go from A[B] to B[A], and you end up writing a huge amount of plumbing/bindings to satisfy stuff like lifting values into your types and passing them around. I find it somewhat funny that purely functional programmers (especially people that code in languages like Haskell) go around claiming that their style of programming is composable and boilerplate free, and then you see pages fill of bindings because monad transformers have a n^2 penalty where n is each monad on your stack. Eff does sound like a better solution, but also have problems of its own. At least if you are talking specifically about effects, implicit function types is actually less complex then Kleisli or any of its alternatives 
New to scala. Spent a long time the other week trying to wrap my head around currying and that example summed it up for me nicely. 
Great! Just a few errors, though: - Semigroup is incorrect. It must be closed under associativity and arbitrary products. What you've defined as a semigroup is actually a magma. - Foldables are anything that has a fold. They implement either *fold* or *foldMap* using the underlying monoidal structure of the type *in a way that terminates*. Saying "An object that has a reduce function that can transform that object into some other type." is sort of.. not detailed enough. Also, using *foldLeft* in the implementation is circular. - Seeing the signature for PLens will be useful. Otherwise, gg.
This doesn't really help you now but there are some plans to make this part of the [2.13 collections](https://github.com/scala/collection-strawman/issues/155)
Great comment. Maybe you can do a pull request there.
I think the "dual" argument falls flat a little when you look at things closer. With type inference you provide a typed expression and the compiler uses the result type to infer missing type information. With implicits, you invoke a function/method/constructor without providing values and the compiler infers the values for you using lexical scoping rules. They don't quite seem like duals to me. To me implicits seem like a mini compile-time DI framework built into the compiler. What I like about macros is that if you want to, you build something more powerful like MacWire assuming sufficiently powerful macros. 
@emilypil Thanks for your kind feedback! I will study and fix it based on your advice :-) 
&gt; The funny thing is that the purely functional solutions are concretely more complex than the algebraic effects. This doesn't make any sense. I'm going to assume by pure functional solutions, you mean Free Monads. But those also also algebraic effects. So I don't get how algebraic effects can be more complex than algebraic effects. &gt; This is explained very cleanly in the presentation because Monad's are not commutative. Monad's don't commute, but you don't have to use Monads. You can use aglebraic coproducts with Applicatives and Functors as well. &gt; You can't easily go from A[B] to B[A], and you end up writing a huge amount of plumbing/bindings to satisfy stuff like lifting values into your types and passing them around. Funnily enough, effect lifting was left out of Odersky's talk about implict functions. If you have a function that is `Configured` and you want to use it another function that contains `Configured` as an effect, but also other effects, how do you lift configured into that larger effect? &gt; I find it somewhat funny that purely functional programmers (especially people that code in languages like Haskell) go around claiming that their style of programming is composable and boilerplate free, and then you see pages fill of bindings because monad transformers have a n2 penalty for bindings where n is each monad on your stack. I think that's exactly why people are moving trying to not use Monad transformers. &gt; effects does sound like a better solution, and I am suspecting that algebraic effects might be a different/more limited version of effects. If by algebraic effects you mean implicit functions, I'm not sold that implicit functions are algebraic effects yet. Though I do see the value they add over the Reader Monad specifically. But what if you didn't use Reader as a Monad? Why can't you just limit yourself to Reader's Applicative instance? If the language had a syntax for applicative comprehensions as good as monadic ones, I'm not sure if there would be a significant difference between the two. However you'd get a lot more use out of an Applicative comprehension than just implicit functions.
It's true that type inference operates on expressions, and implicit search will not insert arbitrary expression, only named values, but I think there's still something of a duality... but it doesn't matter... &gt; I think it's funny that people have so many problems with the "magic" of type inference and implicits, but are completely ok with the magic of runtime DI frameworks, autowiring, classpath scanning, annotations, and even AOP. It feels like hypocrisy to me. I wouldn't call it hypoicrisy. I think it's that they don't get that implicits are actually instead of that, that it's possible to get rid of that complexity. The average programmer's reaction is going to be "programming has enough complexity, seriously, you want to add more?" What they're missing is that we're not adding complexity but moving the exsting complexity, from somewhere unmanageable to somewhere that we can manage statically -- and abstract away to a large degree. Complexity is part of life, the question is what tools can you capture it with.
Cheers, and feel free to pm if you have questions
That's cool.
Great stuff! One observation: Maybe it's a case of the mondays for me, but the code example for "Closure" and the explanation of it doesn't seem to match.
Monads in general don't commute because effects in general don't commute. Suppose we combine nondeterminism and logging; should we get multiple copies of the same log message, or multiple logs with one message in each, or a single log trace? You can't answer that in the general case, because all three answers are correct in some contexts and incorrect in others. I'm super enthusiastic about finding good ways to represent those effects that do commute - whether that's applicatives (which naturally commute), some weaker extension of applicatives in the direction of monads (arrowchoice?), free coproduct style, final tagless style, or something else. There is a lot of good research and experimentation happening and I'm confident we'll find a good approach sooner or later. In the meantime, yes, doing all your lifting explicitly is costly, but less costly in the long run than having it happen implicitly where a reader can't understand it. I don't know what the ideal solution is. But it can't possibly be a special-case language builtin. That's the road that leads to checked exceptions, to all the almost-but-not-quite reasonable language features that work almost the way you expect, but you can't reason about them and you can't replace them. Building monads into the language is a good idea - they may not be the ultimate solution to everything, but they're a useful building block in many cases, and crucially they're well-understood and standardised at this point. Building an effect system into the language is a terrible idea when we're so far from having a clear consensus on what a good effect system would look like. This is something that should be left to libraries and macros, and if and when the dust settles and there's a clear consensus on the right way to do it then maybe building it into the language would make sense. (I don't/can't do videos, would be happy to read text on the subject)
It does break RT, because the first line and the second line are not equivalent. (At least, for most use cases, printing "hi" is not equivalent to printing "hihi"). You can only talk about RT if you have a definition of equivalent, so the meaning of RT can be different in different domains (e.g. if you're working in cryptographic code where all operations have to take constant time, then you'll use a different definition of RT from the one people use in most "regular" code). But in practice the things we care about are similar enough in most use cases that we talk about "RT" as if there was a single common definition.
Just don't think about instances; don't use reference comparisons. Some kinds of things (values) can be compared directly for equality. Other kinds of things can't be compared directly (e.g. functions) and nothing good will come of trying to use `==` on them; you have to reason about their equivalence without comparing them directly.
Effects do not commute, but the *capabilities* (or permissions) to perform certain kinds of effect do commute. This system with implicits is essentially modeling a capability-based effect system, which is why it naturally commutes.
Right. I see that style as giving up most of the advantages of functional programming (where you work with plain values and can inspect them, compare them for equality and so on). Something that you pass in a bundle of magic handles to and it calls them at certain points is more procedure than function; I might even say it's a very OO way of doing things.
There are differences between types and sets. Most type systems are nominal while relations in set theory are based on structure. This means an object typically has one specific type, while in set theory it can be a member of many different sets. The closest you can get to modelling sets with types is to use union types which are supported in Dotty. Note that union types are not the same as sum types in ADTs.
How is that different from HoF where you pass a function as argument (like for example monadic bind/flatMap)? An object (in OO programming) is basically a record of functions.
HOFs only play nice with pure functions. A record of pure functions is not a problem; the big flaw of OO is not that you pass around functions, it's that you pass around functions with an unknown entanglement with state, possibly distant or even global state (the banana/jungle problem). And the very nature of an effect handle is the same thing.
I am trying to use cats effect shift function to run the code asynchronous. The function implementation: def asyncSendMsg(producer: KkProducer)(record: KkRecord): IO[Either[String, RecordMetadata]] = { val BlockingFileIO = ExecutionContext.fromExecutor(Executors.newCachedThreadPool()) for { res &lt;- IO.shift(trySendMsg(producer)(record)) } yield (res) } def trySendMsg(producer: KkProducer)(record: KkRecord): IO[Either[String, RecordMetadata]] = IO { try { Right(producer.send(record).get()) } catch { case e: Exception =&gt; Left(e.getMessage()) } } My question is, how to use cats effect shift function? Thanks
@emilypil I didn't know about magma. Now I knew "a semigroup is an associative magma." I updated some topics w/ your comments. Thanks. 😀 
Maybe look at the differences between the generated eclipse project files?
Scala :)
Hi, thank you for commenting. I am learning Category Theory right now, as I mention in the post. I don't totally understand what you mean. Is incorrect then to think of objects as sets, in the context of The Category of Sets? Bests.
I'm not referring to category theory (which I don't know very well), just the difference between [set theory](https://en.wikipedia.org/wiki/Set_theory) and [type theory](https://en.wikipedia.org/wiki/Type_theory). While they share many similarities and can describe similar relations, they are not the same. There is also correspondence between [type theory and category theory](https://en.wikipedia.org/wiki/Type_theory#Relation_to_category_theory), but I don't know very much about that.
There are more points, if you'd like to discuss, or I can just give you a list of sections whose definitions and implementations you should revisit 
Suppose that I have a trait defining a method: trait MyTrait { def f(): Result } Then, I want to write different implementations, one returning `Result` and another one returning `Future[Result]`, is there a simple way for modifying my base trait in a way that it will let me write the two classes implementing the same trait? I suppose that scalaz or cats have something and I would love to not require them, thanks.
shout out to scalaIDE! I use it and love it! I use it with scalafx too, is there a basic repo that I can pull and try? Also do you have the same ide on both machines? I'd also peak at the generated project files like /u/m50d mentioned
Hello there, Have you tried using an abstract type ? trait MyTrait { protected type ResultType def f(): ResultType } class MyTraitWithResult extends MyTrait { override protected type ResultType = Result override def f(): Result = New Result } class MyTraitWithFutureResult extends MyTrait { override protected type ResultType = Future[Result] override def f(): Future[Result]= {} }
Be that as it may, `var`s and exceptions are not going away from Scala. They might as well be controlled to some degree. Scala will never be a purely functional language. It is not striving to. There are other languages that fill that space. Scala however tries to reconcile OO with FP, and from that point of view, an effect system, such as the one being designed here, is likely a step in the right direction. People who use Scala to do FP will not use implicit capabilities, just like they don't use `var`s. That's fine by me.
What is it you're trying to do? If your two classes return different things, why do you want them to have a trait in common? One useful technique that might be what you're looking for is a higher-kinded type parameter: trait MyTrait[F[_]] { def f(): F[Result] } Then you can have a `MyTrait[Id]` (where `type Id[A] = A` - for some reason this isn't built in, but both cats and scalaz have it, or you can implement your own) for the one that returns `Result` and a `MyTrait[Future]` for the one that returns `Future`. And you can put typeclass constraints on `F` that let you put some implementation code in `MyTrait`, e.g. you can require `F` to be a `Monad` and then you can write helper methods that use `for`/`yield` to compose a couple of different methods that return `F`s.
`var` and exceptions are necessary for interop and to provide a migration path from Java. Does the proposed system really control their use? What I saw the last time I saw text seemed like the opposite: it gave more ways for a function to have surprises in, which is already the biggest problem with Scala.
&gt; Does the proposed system really control their use? The plan is that eventually, yes, they will. &gt; var and exceptions are necessary for interop and to provide a migration path from Java. In your world, maybe. In mine, definitely not. I use them very often in regular Scala code that does not interact with Java nor evolved from migrating from Java.
Where did you get the idea that Ensime is no longer being maintained?
I never used it, but based on how Future works, maybe try to make blockingFileIO implicit .
one use case would be to have a base trait and write a blocking and non-blocking implementation, this might work, thanks.
one use case would be to have a base trait and write a blocking and non-blocking implementation, this is sweet, thanks.
&gt; one use case would be to have a base trait and write a blocking and non-blocking implementation What's the purpose of the "base trait" though? What do you gain from having a common trait as opposed to two completely separate implementations? (Part of what I'm driving at is if you want to be able to reuse code between the two implementations, you're probably going to need to use scalaz or cats, because you need the concept of a monad to be able to combine two different `F`-like results)
The gain is to not write a base trait having the same methods but different result twice.
I guess, I just don't see much value in pulling out commonality when you're not actually making any use of it. (Do you even need a trait in this case? What's it saving you over just having the two implementations? That would be even less repetition)
Make sure the build definition doesn't have any absolute references, or references to things like `JAVA_HOME` that may be defined on one machine but not the other. JavaFX is not on the classpath by default so there's *something* in the build to hack it in, and that could be your problem. As for Eclipse not reporting an exception or something, dunno.
what would it be for you to make use of it?
Well I'd tend to pull out a trait either because I had multiple possible implementations and wanted to swap them out, or because I had some common implementation that I wanted to reuse (i.e. a method in the trait definition that calls some abstract methods that are implemented in the subtypes).
http://ensime.org/maintainer/
The capabilities to perform effects can be called coeffects. Tomas Petricek from the F# community has done a lot of work formalizing the notion of coeffects and how they interact with effects. http://tomasp.net/coeffects/ Among other things, a formal coeffect system combined with an effect system could be extremely powerful, lifting hardware (coprocessors and sensors, etc.) and software capabilities (OS and driver APIs) into the type system, and ensuring their uses are inherently safe. I've made some vague notions of writing a SIP to introduce a coeffect system into scalac or dotty, but I'm pretty out of my element when it comes to compiler design. 
Its looking to appoint a new maintainer but there has been commits on all its repos since the above announcement so its definitely has not been abandoned. Its open source and active to me. 
Thanks to both /u/alexelcu and /u/lihaoyi for their recent contributions in this area. My experience is a little weird; I started my path with programming in languages with an emphasis in data analysis, and Scala was really the first general purpose language I used for anything more than data analysis (currently doing a lot of back end work on play framework). When I started doing general purpose programming, testing always seemed like a *huge* complexity nightmare, with so many styles, matchers, mocking frameworks, etc. I eventually learned to love simple asserts, and I'm glad to see much more emphasis on simplicity in testing. These libs are a breath of fresh air. 
in fact, I have multiple implementations that are swapped in some cases, the higher kinded type was what I was looking for, thanks.
&gt; Effect lifting was left out of Odersky's talk about implict functions. If you have a function that is Configured and you want to use it another function that contains Configured as an effect, but also other effects, how do you lift configured into that larger effect? Unless I am missing something, it just boils down to implicits which means you will have access to a value of the type `T` which you can then manually lift, although I wouldn't really call it lifting in the conventional sense &gt; If by algebraic effects you mean implicit functions, I'm not sold that implicit functions are algebraic effects yet. Though I do see the value they add over the Reader Monad specifically. But what if you didn't use Reader as a Monad? Why can't you just limit yourself to Reader's Applicative instance? If the language had a syntax for applicative comprehensions as good as monadic ones, I'm not sure if there would be a significant difference between the two. However you'd get a lot more use out of an Applicative comprehension than just implicit functions. Even if you used the `Reader` monad in an applicative way, its not really going to solve all of the issues. It will fix the commutative issue, but you are still going to be using dedicated syntax just for applicative and its still going to be more verbose. The issue is still that you aren't using the *simplest* tool for the job (as per the theme of the video) 
&gt; In the meantime, yes, doing all your lifting explicitly is costly, but less costly in the long run than having it happen implicitly where a reader can't understand it. Could you expand, I really don't see how its more costly in the long run? &gt; I don't know what the ideal solution is. But it can't possibly be a special-case language builtin. Its not special case, its just an extension of `implicit`'s. Scala already has implicit's (and its a core function of the language), its just there was a limitation that you couldn't abstract over implicit functions. Now you can, and actually the rules to allow this are incredibly simply (its just currying of implicit functions) &gt; At least if you are talking specifically about algebraic effects, implicit function types is actually less complex then Kleisli or any of its alternatives. In the video, no code related to actually parsing the config needed to be altered to apply configuration in a safe way, where as with `Kleisli`/`Reader` you need to place such related code into a for comprehension (assuming you need to compose various configs around). Since capability (or effect?) system is just using implicits, you are only modifying the argument signature to allow an extra parameter, but there isn't any lifting. 
If you need to write performant critical code, `var` is necessary. `Exception`s also have their use (albeit they really should be used exceptionally). Which also goes to a second type, using either `Reader` monad or `Kleisli` has pretty big impacts on performance, this solution just boils down to parameter passing
I have a Scala project in IntelliJ that consists of about 7 different sub projects (they're all their own microservices). Each microservice has it's own suite of tests, which consists of multiple test files (for example, userService has tests under localAuthenticationSpec and externalAuthenticationSpec). I have two questions related to testing: 1. Can I create custom configurations of these tests, so only some are run and not others? For example if each microservice has two test suites, I want to run only the first one from each. The reason for this is that the second suite in each microservice is really a bunch of integration tests that reaches out to external systems, and is thus unreliable, but I don't want its failures to affect my overall build procedure, which runs all tests, but aborts if any test fails. I know I can create a script that only runs the required tests, but I was wondering if I could create an sbt task for it, like `sbt testUnit` and `sbt testIntegration`. 2. Can I create an IntelliJ test configuration that runs all tests? Through the terminal I'd just use `sbt test` in the backend directory and that would recursively search for all tests and run them serially. I could create an sbt task that just runs `sbt test`, but that wouldn't give me a report of what tests succeeded and failed.
&gt; And the very nature of an effect handle is the same thing. Not really, I mean an effect system can allow you to pass around state implicitly but its not a requirement (nor does it actually encourage it). You can actually do a purely functional solution to Odersky's config sample in the video, you would use implicit functions instead of `Kleisli` but everything else would be purely functional (the use of `Exception` was just a demonstration that you can control `Exception`'s in a typesafe way, but it wasn't necessary for the problem
&gt; The issue is still that you aren't using the simplest tool for the job (as per the theme of the video) I don't think is helpful, you don't just get to assert whats simple with no common agreement on what that means. What is more simple? Odersky's rules on implicit function resolution? The associative law when applied to Kleisli triples? The proof that Kleisi triples compose may be non-trivial, but applying the law is as simple as it gets. &gt; but you are still going to be using dedicated syntax just for applicative and its still going to be more verbose. I'm not sure that's an assertion you can make without a hypothetical applicative comprehension syntax in mind. Especially given the monadic syntax already is no more or less verbose than using implicit functions.
I would be interested to see that purely functional solution with implicits functions instead of `Kleisli`. As a side note, I think picking exceptions for his example was a bit unfortunate. It's basically reinventing (a weaker version of) checked exceptions.
I would have to disagree. I'd rather have an abstraction that I can give a good name to than having the same signature all over and having to plug the same parameters in everywhere. And it's not about typing either. It's about capturing repeating patterns in the code as a separate concept. I certainly see the potential for abuse, but I still think it's really useful idea.
Well, as always there will be a fair amount of abuse, but I don't think that makes it a bad idea.
&gt; Could you expand, I really don't see how its more costly in the long run? Sorry, I should've justified this more. In my experience confusion over how two different effects interact is a major source of bugs. &gt; In the video, no code related to actually parsing the config needed to be altered to apply configuration in a safe way, where as with Kleisli/Reader you need to place such related code into a for comprehension (assuming you need to compose various configs around). Sounds like they're simpler at the point of use, but it would then be more complex to read and see what was happening? I'd like to have a visual distinction between calls that have an extra effect and calls that don't - I think that's vital for readability.
I'd argue that config when used this way is still hidden global state - it would be much worse if it was mutable, but it's still not ideal. I suppose you could use this system to pass around plain old values, but in that case why not just pass them around as plain old values? If it's sold as an "effect system" people are going to expect to use it for non-value effects.
Today I released version 1.02 of SlideMight, a data merge utility for Microsoft PowerPoint: www.slidemight.com. SlideMight supports among others nested iterations for slides and tables; images in tables; markdown text input and syntax highlighting. The program has been developed in Scala with: * [ScalaXB](http://scalaxb.org/) for XML processing * [ScalaFX](http://www.scalafx.org/) for the GIU * [SubScript](http://subscript-lang.org/a-simple-gui-application/) for the GUI controller * [Scrimage](https://github.com/sksamuel/scrimage) for image processing * [JSONforS](http://json4s.org/) - JSON parsing in Scala * [MoultingYAML](https://github.com/jcazevedo/moultingyaml) - a Scala wrapper for SnakeYAML * [Nashorn](openjdk.java.net/projects/nashorn) - JavaScript interpreter * [PrismJS](http://prismjs.com/) - JavaScript package for syntax highlighting * [ph-css](https://github.com/phax/ph-css) for CSS processing * [Validator.nu HTML Parser](https://about.validator.nu/htmlparser/) * [Tagsoup](https://github.com/orbeon/tagsoup) HTML purifier * [FlexMark](https://github.com/vsch/flexmark-java) - Markdown parser 
I just went back to the website and saw it's been updated to work with SBT 1.0 now, so that's good news!
I work on an web service for Amazon Lab126 that's used for distribution and development of hardware. A bit hard to show off, but I think it's cool. Built on the same libraries used to build AWS itself! There actually a lot of Scala use at Amazon. Scala, especially Akka, is used in a variety of places. One of the strengths of Scala has been smoothly integrating with Amazon's Java ecosystem and SOA framework. So smoothly that, well, if you've used Amazon.com or AWS then you've used a Scala developed system probably without notice. If you are interested in joining Amazon's Scala community I have a job opening. Prior experience is Scala is nice, but not required. We are happy to teach. :-) * https://www.amazon.jobs/en/jobs/585197/software-development-engineer
Wow, Tomas's website is amazing, I wish all papers were presented like that.
I would also argue that code using regular vars and loops can be more clear than pure code, in certain contexts of course — and if it's properly encapsulated (aka the function / class / component is pure), then it doesn't matter. Encapsulation in OOP is key, the irony is that only with a blend of FP you can have it 😎
It's very good for Scala that Java adopts more and more of the low threshold features of Scala such as local type inference, case classes and pattern matching. It means, people will be exposed to these things and have an easier foundation for learning Scala. He didn't talk about native-interop, fibres, continuations; is there some Scala development team members in contact with these projects? These are unique opportunities to get the things right so Scala can benefit and have its own fibres and continuations.
It sounds like Java is picking up with new language features which used to filled by other JVM languages. If the other JVM languages do not keep up with new distinguished features, they might lose their appeal.
So basically java is adopting scala features? But still i do not understand why add 'var' and no 'val' (i assume it will be 'final var')
in scala, `val`, `final var`, and `final val` mean different things.
Yes you are right, but i was talking about java version, there is an explanation in my comment
It depends on your testing library. If you're using scalatest, create custom tags and tag your tests. You can then decide at run time what tags to run. [Tags](http://www.scalatest.org/user_guide/tagging_your_tests)
&gt; It's very good for Scala that Java adopts more and more of the low threshold features of Scala such as local type inference, case classes and pattern matching More likely it's a direct reaction to the threat of Kotlin that Java is adopting Scala's features. Kotlin's already copied much of Scala's syntax and looks [poised to take off](https://trends.google.com/trends/explore?q=%2Fm%2F0_lcrx4,%2Fm%2F091hdj,%2Fm%2F03yb8hb) in the coming months; Java needs to evolve now. What Scala gets out of it is validation of language features, which, like Haskell, doesn't draw mainstream adoption. Maybe with improvements in Dotty adoption will increase, but nothing like Go, Swift, and perhaps Kotlin.
after the founder of the project stepped down, the project started out to show lot of issues. As a end user its more important the basic features should work. When you point they expect you to solve it and send a PR, IMHO this is very arrogant
1. sbt has built in support for integration tests, run as `sbt it:test` - see [the docs](http://www.scala-sbt.org/1.x/docs/Testing.html#Integration+Tests). 2. I haven't used your setup precisely, but there's an sbt tool window that allows you to run tasks for each project. You may be able to just select "test" for your root project there.
Anyway thanks.
I think his point is that in the world of types, `true` appears in `Bool`. But in the world of sets whose members are values found in the scala programming language, `true` is in `{true, false}` and `{0, 1, true}` and `{"hello", true, 8}` etc. These sets aren't types in scala, unless you're using some form of union type of literals. Which is available in Dotty. But your post wasn't particularly formal and was just a way to get people thinking across domains so I don't think it matter too much. Your understanding of category theory in the post seems fine.
Its clear to me now. Thanks.
&gt; I don't think is helpful, you don't just get to assert whats simple with no common agreement on what that means. What is more simple? Odersky's rules on implicit function resolution? The associative law when applied to Kleisli triples? The proof that Kleisi triples compose may be non-trivial, but applying the law is as simple as it gets. Actually it is, because with `Kleisli` * You need to lift values into a monad context so they can be used properly in for comprehensions (even though you are not dealing with any form of sequencing) * You need to alter all of the returning types of all of your Config values to work with `Kleisli` * Much higher complexity when you need to compose Kleisli with other values because of the above (composition problem) With the implicit function solution, you don't have to do any of this. This is what I mean by simpler. The rules for implicit function resolution are actually very clear in this context (as detailed in the video)
&gt; I would be interested to see that purely functional solution with implicits functions instead of Kleisli. As a side note, I think picking exceptions for his example was a bit unfortunate. It's basically reinventing checked exceptions. The purely functional solution just wouldn't use any exceptions, i.e. you wouldn't have a `Possibly` and instead you would just work with `Option`.
&gt; but in that case why not just pass them around as plain old values? If it's sold as an "effect system" people are going to expect to use it for non-value effects. As detailed in the video, this is not scalable and introduces huge amounts of boilerplate
&gt; Sorry, I should've justified this more. In my experience confusion over how two different effects interact is a major source of bugs. As said here https://www.reddit.com/r/scala/comments/7cadtj/plain_functional_programming_by_martin_odersky/dprcy1g/ This is going to be possible. Afaik it will use phantom types &gt; Sounds like they're simpler at the point of use, but it would then be more complex to read and see what was happening? At least from what I have seen, the organization is actually far simpler to read vs using `Kleisli`. &gt; I'd like to have a visual distinction between calls that have an extra effect and calls that don't - I think that's vital for readability. You mean at call site or in definition?
&gt; This is going to be possible. Afaik it will use phantom types I'm sceptical when I haven't seen any design for how this is going to work and it doesn't seem like it would be possible (again just going by what I've seen written previously, I can't/don't do videos). When you compose two operations that use monads and they don't align you have to explicitly lift them. When you're composing two function calls that take effect handles as implicit parameters, how would you ever not be able to just pass them in whatever order? But reordering them actually changes the effect interaction in very important ways. &gt; You mean at call site or in definition? At call site. I really like the `&lt;-` versus `=` distinction you get with the monad approach - it's subtle and doesn't take up much space, but still immediately visible.
I am new in Scala and wrote following code: def createProps(host: String)(config: List[KkConfig]): Eval[Properties] = { val evalProps = Foldable[List].foldRight(config, Later(new Properties())) { (a: KkConfig, b: Eval[Properties]) =&gt; a match { case ClientId(value: String) =&gt; b.map((p: Properties) =&gt; { p.put(ProducerConfig.CLIENT_ID_CONFIG, value) p }) case Acks(value: String) =&gt; b.map((p: Properties) =&gt; { p.put(ProducerConfig.ACKS_CONFIG, value) p }) case Retries(value) =&gt; b.map((p: Properties) =&gt; { p.put(ProducerConfig.RETRIES_CONFIG, value) p }) case BatchSize(value) =&gt; b.map((p: Properties) =&gt; { p.put(ProducerConfig.BATCH_SIZE_CONFIG, value) p }) case LingerMs(value) =&gt; b.map((p: Properties) =&gt; { p.put(ProducerConfig.LINGER_MS_CONFIG, value) p }) case BufferMemory(value) =&gt; b.map((p: Properties) =&gt; { p.put(ProducerConfig.BUFFER_MEMORY_CONFIG, value) p }) } } evalProps .map(p =&gt; { p.put(ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, host) p }) .map(p =&gt; { p.put(ProducerConfig.KEY_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArraySerializer") p }) .map(p =&gt; { p.put(ProducerConfig.VALUE_SERIALIZER_CLASS_CONFIG, "org.apache.kafka.common.serialization.ByteArraySerializer") p }) } What makes me confuse is the `new Properties()` object. With every recursive call `foldRight`, I insert a new key and value into `Properties` object, I change the object every time. p.put(ProducerConfig.CLIENT_ID_CONFIG, value) I want to know, if it is functional or not, because I put something into object with every recursive call. It is the code overkill? Thanks
Ye, I've watched the presentation more carefully now. For the configuration case I think the implicit parameter solution works well as it doesn't require any side effects, but as you say, for modelling effects it would require passing implicit parameters that are actually side effecting (mutating state, throwing exceptions etc.). So it's not pure.
There is also project valhalla which adds value types. I am thinking that these are a direct response to what Kotlin is doing right now. If java itself does most of the things then I would definitely not choose kotlin. Scala on the other hand is completely different and these features should help in better bytecode generation.
I don't know if people use languages like Scala (or others in the Lisp and ML families) for specific features. Personally I trust that the people behind the Scala language generally understand what's come before; that they make well-informed, well-researched choices; that they aim for sound correctness guarantees, often with proofs along the way; that they land on the right approaches more often than not, as seen by others following suit in time. Could one say the same thing about Java, C#, Python, Go, etc? I don't know about that.
From which Scala version does SubScript fork? From today's perspective, would it be interesting or better to use macros or a compiler plug-in?
&gt; What are the first things an experienced Scala programmer would run into that have no equivalent or good alternatives? Higher Kinded Types.
Functional is a spectrum rather than an absolute, but this isn't very functional since you're still mutating the object; likewise the `Eval` isn't actually buying you much because you're doing all your operations inside it, whereas the point is that you can partition off impure work and keep most of your code pure. I'd suggest you first interpret the config into a pure, immutable value, in code that just uses pure immutable values, and then only form the `Eval` at the last moment (if you even need it at all?), something like: def propMap(host: String, config: List[KkConfig]) = (config.map { // We can write a pattern-match directly as a function literal, rather than a =&gt; a match { ... } case ClientId(value) =&gt; (ProducerConfig.CLIENT_ID_CONFIG, value) case Acks(value) =&gt; (ProducerConfig.ACKS_CONFIG, value) ... } ++ List((ProducerConfig.BOOTSTRAP_SERVERS_CONFIG, host), ...)).toMap def evalProps(host: String, config: List[KkConfig]) = // assuming you've imported scala.collection.JavaConverters._ for the .asJava // _ works like "p =&gt; p" in case you haven't seen it before Later(new Properties()).map(_.putAll(propMap(host, config).asJava)) This way `propMap` is a pure function in the most simple, obvious sense: it takes simple values as input and outputs simple, immutable values that can be compared for equality. You can test it by just checking that when you call it with particular inputs you get particular outputs, and all of the logic is there. `evalProps` is less functional - while it's still technically pure in that it returns an `Eval`, in practice you can't really test `Eval`s since the only thing you can do with them is run them. But since this function is only plumbing, errors should be less likely and it should only need a small amount of integration testing, whereas you can focus most of your test efforts on the pure part. (Modifying a `Properties` object isn't such a big deal that I'd worry about the impurity of it - in practice you could probably just modify it directly and not worry. But this is a good example to show the kind of technique you should be using to deal with more cumbersome, less testable effects like accessing a remote web API) 
No higher-kinded types (and everything they enable e.g. no monads, no recursion schemes), no way to handle "record"-style types generically, no type-level programming.
I am a frontend dev working in a Scala environment, and all the Scala stuff is quite confusing to me (though the devs are a great help). I would say im an intermediate JS developer, and I am wanting to learn more Scala. What resources would you recommend? Some are quite off putting as they mention X amount of programming experience etc.
In addition to HKT (which is probably the biggest obstacle): - They both lack do/for-notation for monads (although in Rust it might be possible to solve it using [macros](https://github.com/TeXitoi/rust-mdo)) - Their systems for ad-hoc polymorphism (traits/protocols) are less powerful than Scala's traits + implicit parameters (but at least Rust disallows orphan instances which avoids some issues) - Rust has very limited support for existential types, not sure about Swift - Other limitations in their type systems 
Could someone please outline what this enables?
`list.lift` returns a `Int =&gt; Option[A]`, so `list.lift(index)` is short for `list.lift.apply(index)`
&gt; Personally I trust that the people behind the Scala language generally understand what's come before; that they make well-informed, well-researched choices; that they aim for sound correctness guarantees, often with proofs along the way I don't think this has always been the case in the past, just look at the recent debates about changing the equality semantics, the specialization attempts etc. However, it's true that the basis for Scala's type system has been quite thoroughly researched, especially in Dotty. This is the strong point of Scala IMHO. &gt; Could one say the same thing about Java, C#, Python, Go, etc? Rust is a good example here. The main motivation behind the language is safety, and I would consider it a safer language than Scala (no nulls, no race conditions, no universal equality, saner implicit conversion rules etc.). The Rust compiler team take soundness problems in the type system very seriously as it might lead to safety issues at runtime.
English is a creole
I agree. Maybe "Lisp and ML families" doesn't quite encompass languages like Rust or Cyclone, but I mean to include those as well.
I think it means we're getting closer to polymorphic functions. trait Test { def work(fun: List[A] =&gt; A): Unit // that's not possible, can't use existential A } trait MyList { type Out } trait Test { def work(fun: MyList =&gt; MyList.Out): Unit // I guess this works in Dotty now? } 
is /r/scala the /askreddit of programming metaphysics?
It might be worth looking up some functional techniques in JS - being comfortable with map/filter/etc. and the functional way of doing things will help make Scala more accessible. In terms of the Scala side of things I'd say the list in the sidebar is as good a place as any. (I like the look of Atomic Scala, I can't really recommend anything from experience as the closest thing to a Scala book I read is *ML for the Working Programmer*, which probably isn't the best place to start)
Ontop of this, its also highly unlikely that Rust will get proper HKT's because for certain usages of HKT's you need to box, and one of the core design principles for Rust (which is never going to change) is zero-cost abstraction Rust may get HKT's at one point, but if they do it will likely be a much more limited version than what Scala has
I don't know much about Rust, but in general I think Swift is pretty good as a functional language. It definitely has some limitations compared to Scala though To add to what other people have already mentioned: * Swift doesn't let you specify the variance for your own types. I believe they're all invariant. * Swift doesn't have much built-in support for non-strict evaluation/by-name parameters. * Swift's collections aren't as easy to use in an immutable way as Scala's. Also, I think they do a more naive linear-time copying, but I may be wrong about that. * There's nothing like `copy` in Swift, so you'd need to implement it yourself for each class/struct. I think the common pattern is to create a new reference to a value type (which creates a copy), and then mutate the copy. * Swift's `if` and `switch` are statements rather than expressions, and don't return anything 
&gt; There's nothing like copy in Swift, so you'd need to implement it yourself for each class/struct. I think the common pattern is to create a new reference to a value type (which creates a copy), and then mutate the copy. Swift semantics are really straightforward on this: value types are always assigned by copying. There is no such thing as a reference to a value type. Even an inout parameter is copy-in copy-out. The implementation, of course, may be different. The optimizer may choose to pass immutables ("let") as either copy or a reference. The built-in container and string types use copy-on-write internally to avoid unnecessary copies. But semantically, it's all by value. To get a mutable copy, just assign it to a "var". Yes, it's disappointing that if/switch are statements. 
I gave dabbled with that stuff, but mostly just doing codewars stuff, so I have a basic understanding of some of those JS features. There is a copy of atomic scala floating around somewhere in the office so I could give that a look. Most of the guys here recommend oderskys book or the big red book. But I think they might be too advanced to dive into
Right, what I meant was that doing something like var newThing = oldThing newThing.foo = "bar" isn't as convenient as this val newThing = oldThing.copy(foo = "bar") The Scala version has a number of benefits: 1. It's a single expression rather than two 2. I think it's just a little clearer about what's going on. The fact that value types are copied on assignment is known to experienced Swift developers, but not exactly obvious from looking at the code 3. `newThing` is immutable in the Scala version 4. The Swift version requires that `foo` is a `var`, which may or may not be what you actually want. Any instance that's stored in a `var` can have its `foo` mutated, even if the only context that you want it to be mutable is when you're creating this copy 
another piece of hot garbage brought to you by knoldus. do they realize how much they embarrass themselves always publishing such low quality content?
It's defined on PartialFunction, which Seq extends
I think this post should be helpful: https://www.reddit.com/r/scala/comments/6quqk2/if_someone_asks_me_about_how_to_learn_and_start/
Care to elaborate?
Thank you very much
And now polymorphic function values?
Together with implicit function types, that could be a good substitute. I hope we can eventually write things like: class C { type T } def baz(f: implicit (t: C) =&gt; List[t.T] =&gt; List[t.T]): Int = f(new C{type T = Int})(List(1,2,3)).head baz(ls =&gt; ls.reverse) // 'polymorphic' lambda
&gt; They both lack do/for-notation for monads (although in Rust it might be possible to solve it using macros) There are a couple issues with do-notation, if I remember correctly. Manish Goregaokar mentioned [conflicts with affine types](https://www.reddit.com/r/rust/comments/6lf7z5/rusts_2017_roadmap_six_months_in/djtq1nm/), plus that it doesn't mesh well with imperative control flow. I'm curious if algebraic effects are a solution, however. Also, [this thread](https://www.reddit.com/r/rust/comments/6lf7z5/rusts_2017_roadmap_six_months_in/dju5bcd/) by /u/Rusky was pretty enlightening.
FWIW, Rust is in the process of getting "generic associated types" (also called "associated type constructors") which can be used to simulate HKT.
I remember perfectly losing maybe half an hour looking for a f*#king **List[T].get(index: Int) : Option[T]** which I never found and then doing the length-check/apply dance with shame and then cursing some unknown programmer who was certainly cursing another unknown programmer at the exact same time (if one of the two read this: hey bro', how's your curse?) And look, thanks to this article I know I can use "lift" from PartialFunction. Thanks to the author of the article for this little moment of rejoice. PS: I would still prefer a good old "get(idx)", even if it's just an alias to lift()
I tend to agree. I worked 5 years on deprecating and removing bad ideas from the language and the standard library. My prediction at that time was that it would take another 4 to 5 years to get the language to a state where one doesn't have to semi-frequently ask "this will never work, why are we doing this?". This fundamentally changed around 2.12, when the speed with which new bad ideas were introduced overtook the speed at which bad ideas could be deprecated and removed.
I might just be thick, but could you maybe revise that to show how you accomplish something that isn't possible today? I don't get what `implicit` does there or why I'd want to write that. 
I have to wonder, for an average programmer, would any of these answers make any sense? I worry that Scala suffers as a community because we fail to explain our language well. 99% of devs I know would probably say, "why bother with Scala; I don't know what any of that is anyway". And then by the time they understand what they're missing, they're already invested in another Scala-ish language.
Fair point!
lift also works for Maps.
Say you want `baz` to take a lambda that can transforms a `List[T]` _for all_ possible types `T`. The way to do it now makes the call-site very ugly: trait ListTranformer { def apply[T](ls: List[T]): List[T] } def baz(f: ListTranformer): Int = ListTranformer(List(1,2,3)).head The call site: baz(new ListTranformer { def apply[T](ls: List[T]) = ls.reverse }) There are ways to make this lighter, using compiler plugins like [this one](https://github.com/TomasMikula/pascal), but it's less than ideal. Libraries like Shapeless allow to abstract over the `ListTranformer` bit, but don't solve the verbose call-site problem AFAIK. Now, path-dependent types with abstract type members can be used to encode parametric polymorphism. By quantifying at the term level on an object with an abstract type, you indirectly quantify over that abstract type. With implicit function types + dependent function types, we could write a lambda whose type is dependent on an implicit parameter that does not even appear explicitly. We get nice polymorphic lambda syntax, and we can write `baz(ls =&gt; ls.reverse)` or even `baz(_.reverse)`; i.e., in full form `baz(implicit (t: C) =&gt; (ls:List[t.T]) =&gt; ls.reverse)`.
Type-class derivation? I love that I can just define rules for some basic types and then generate class that would handle more complex cases in compile time with type-safety and stuff. Also all those tools like macros, shapeless and libraries build on top of them - while I don't usually have to use some features directly, the fact that they exists allow libraries to build upon them and give me nice API where tons of boilerplate or checks could be just generated basing on case classes I defined. So kind of like I wouldn't notice lack of those features immediately, but sooner or later I would notice then there are no libraries allowing me to generate some boilerplate by compiler. (As opposed to runtime reflection a'la Java, which will compile happily and then blow up once you start application).
&gt; another piece of hot garbage brought to you by knoldus. do they realize how much they embarrass themselves by always publishing such low quality content? Funny how you blatantly abuse anonymity. Just because you know stuff does not mean you can abuse people who don't know it. You are the exact kind of reason why people don't actively participate in the scala reddit forums. Don't be a self-styled quality expert speaking for the whole community. There are people of different knowledge levels here. If you disagree, the least you could do is to disagree with reason, let alone be a jerk.
Good point. These features may enable Scala gurus to write some magic libraries that are very easy to use. But how many programmers that just want to get the job done actually use them directly? Having those magic libraries available is definitely a benefit for them, but in a more indirect way. 
The problem comes because there is no widely accepted concept of what makes a language functional. If you want a pure functional language then go for Eta. But it is pretty new and not sure how big the community is or support for it. But this will be a huge learning curve. In my opinion it easily takes more than six months for someone who is competent in OOP to fully transition into FP style thinking. I may be understating the time required here. If you want a mix of OOP + Functional then go for Scala. I think this is better since you can code in both paradigms and that leaves the developer for design choices. Scala has proved that multi-paradigm design is indeed possible and works well. If you want something that is easier to learn than Scala/Eta then stick with Java itself. JVM has radically changed how it is going to develop new features. Do check out Project Amber and Valhalla. 
I think he meant the Case Class generated .copy()
Thanks a lot. Mixing Scala with Java, it is difficult to do it pure. Sometimes also confusing, how to do right. Thanks a lot again. 
I think your tutor wants you to remark things like: val s = numberList.reduce(_+_) from Scala vs: double sum = 0; for(int i = 0; i &lt; numberList.size(); i++) { sum += numberList[i]; } from Java. But you'll need a relatively good understanding of Scala &amp; FP to find cases like this for yourself.
There is no `buildProps`? `propMap` returns a `Map[String, String]` (I assume all the `value`s are already `String`s? I don't know this `KkConfig`, was just going by your code).
I understood that it only offered a limited subset of what you can do with HKT, no?
[removed]
Finished Europe and Central Asia ? why didn't you split this region option. You should have also not merge manager and engineer roles
Well, the question was asked to the scala subreddit, answers are going to be expressed for an audience of scala programmers. https://philipnilsson.github.io/Badness10k/escaping-hell-with-monads/ gives a good concrete example of how one feature lets you be more economical with syntax - many modern semi-functional languages offer most or all of the ad-hoc solutions from that page. But the real value comes when you operate generically on these things, which would take an even bigger example. I mean, ultimately the selling point of Scala is supposed to be that it scales up to large codebases. By definition that's going to be impossible to demonstrate in a small example. In small codebases plenty of languages are the equal of Scala these days, which is a sign of progress and consensus in language design. But it's always going to be hard to convince people of the advantages of features that only really show their value in large codebases, even though a good language for large codebases is what we all ultimately want.
Define a class with some final fields, hashcode, equality and toString. Vs. A case class in Scala. 
That's clearly a plagiarism from a rather old and much more complete article: https://pavelfatin.com/scala-collections-tips-and-tricks/
That's clearly a plagiarism from a rather old and much more complete post: https://pavelfatin.com/scala-collections-tips-and-tricks/
&gt; Funny how you blatantly abuse anonymity says the guy who literally is named "[john doe](https://en.wikipedia.org/wiki/Ivan_Ivanovich_\(Vostok_programme\))"
Or numberList.sum
&gt; says the guy who literally is named "john doe" You dug up that crap? Lol. And I didn't abuse anyone. Its you who is playing here. First comment and you can only retort to find alts in username handles.
When it comes to length there are some features you could use: * case classes vs manually written classes with getters, setters, overriden equals and hashcode * pattern matching vs if-else chains * Option, map for, getOrElse instead of using null for empty value handling * map, flatMap, reduce, foldLeft, drop, dropWhile, take, takeWhile, etc instead of for with mutable result * creating and passing functions instead of using factories, builders, strategy patterns I think we could find other examples as well. Thing is it is quite biased way of proving anything. With Java 8 you get Stream API, Optional, then there is Vavr, and with Lombok you get some of the case class properties (surely accessors, I don't remember about hashcode and equals). So I guess it would be 1 page in Scala, 1.5 in Java 8, 3 pages in Java 7 or older. That metric itself doesn't tell much, so you might also consider other things where "Scala does better". First of all, none of libraries and extensions so far improved Java's type system. In Scala you get: invariance, covariance and contravariance when it comes to parametric types. You can put constraints on types: `List[A &lt;: Pet]` can be `List[Dog]` or `List[Cat]` but not `List[Waterfall]`. In Java such things are more difficult to achieve, and surely less present in codebases and libraries. You can have multiple inheritance via traits, Java allows only multiple interface implementation (though with default methods interfaces kind of act like traits). If you need you can use Higher Kinded Types or path dependent types. Also you are able to use type inference to limit places where you need to put the type explicitly. Scala's standard library provide a lot of immutable data types to use. Together with Futures they provide common language in which Scala libraries can talk to each other with no issues when it comes to concurrency - in Java I actually never saw someone using Future, and hardly ever I met someone using ThreadPool. Which mean that async, something that in Scala you are doing naturally and what virtually all libraries use for IO operations in Java is something done by Certified Senior Java Developers (ok, I'm joking here, but not that much). In Scala synchronized would be something that you would see inside some library's internals not all over the place. Other things I can think of ATM would be e.g. Either with for-comprehension for error handling and circuit breaking (instead of early return/exceptions), compile-time reflection aka macros instead or runtime reflection, type-level programming (take a look at how Circe turns `case class Test(s: String, i: Int)` int `Encoder[Test]` which can serialize class to JSON and `Decoder[Test]` which would attempt to deserialize String into Test or show you error list). FP shines where you create data transformation pipelines (as opposed to passing data unchanged to and from), so maybe something like webcrawler? Use some libraries for fetching data, parsing XML and extracting some content and compare how Java does this and how Scala does it. If you haven't used FP yet you will probably not use FP to its fullest but you could show it to someone and ask for opinion. Few iterations with Java and Scala programmers and you should start noticing differences in mindset.
Rust has this with `[#derive(...)]`.
&gt; You dug up that crap? i knew that, i'm not ignorant of the russian space program. &gt; I didn't abuse anyone nor did i. all i said is that they are far from being the best resource around, under any metric. &gt; There are people of different knowledge levels here are you a beginner learning scala? awesome, congratulations, and welcome to the best language ever. but, please, do yourself a favor and learn from better sources. /u/niktrop linked to a much better post. knoldus blog is to scala much worse than w3schools ever was to web. i'm here to protect the innocent.
All hail the protector of the innocent. No, I am contesting the way you put forth your opinions, not whether your message was correct or not. &gt; nor did i. all i said is that they are far from being the best resource around, under any metric. Is there any rule to put only the best materials. If then, who decides what is best? Can you explain why its bad, so that the innocents here can protect themselves from Satan.
&gt; Is there any rule to put only the best materials. is there a rule one cannot express their opinion about the quality of such material? https://i.imgur.com/HbVeZ6t.jpg
You still haven't expressed what is wrong with that post. Maybe you didn't have any. &gt; is there a rule one cannot express their opinion about the quality of such material? There is, its called expressing without being a jerk. https://imgur.com/a/QvRNz
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/7E5kWnN.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20dpuq26m) 
go fuck yourself
&gt; its called expressing without being a jerk. something that you clearly cannot do
&gt; something that you clearly cannot do. "hey, look, that guy is being a jerk. you know what i can do to fix the situation? i can be a worse jerk!" So, you accept that you are being a jerk. Thats a first. I dont see how I am being the jerk now. Anyone who questions your opinion is a jerk I see.
This is completely macro based though, isn't it?
&gt; you accept that you are being a jerk is english not your first language? **you** said i'm a jerk, i'm quoting you. is quoting now considered an admission of guilt? do you want me to compile a list of all the personal insults you made? from your first comment alone: &gt; Funny how **you blatantly abuse anonymity**. Just because you know stuff does not mean **you can abuse people** who don't know it. You are **the exact kind of reason why people don't actively participate in the scala reddit forums**. &gt; Don't be a **self-styled quality expert** speaking for the whole community. There are people of different knowledge levels here. If you disagree, the least you could do is to disagree with reason, **let alone be a jerk**. not say the many wrongs you are saying. i'm not abusing people who don't know. knoldus is a professional consulting scala firm, they are not a teenager learning their first language. or, maybe, you are just agreeing with me that they as a whole company know nothing about me. you are so self-contradictory: first, you acuse me of anonimity, yet your username is john doe. now, this: &gt; Anyone who questions your opinion is a jerk and you resort to call people a dick so, anyone who question a post quality is a jerk (you explicitly call me that!)? another self contradiction. you are no better than what you like to acuse others for. you said mu original comment wasn't constructive. how constructive have been all your personal attacks against me, mr. self-contradiction? enough, i'm blocking you and your stupids lies. bark all you want.
&gt; is english not your first language? you said i'm a jerk, i'm quoting you. is quoting now considered an admission of guilt? There you go, from the moment you have started the conversation you are in the attack mode. I questioned asking how it is bad and you immediately retorted to something else. &gt; not say the many wrongs you are saying. i'm not abusing people who don't know. knoldus is a professional consulting scala firm, they are not a teenager learning their first language. or, maybe, you are just agreeing with me that they as a whole company know nothing about me. Again, my first question stands. You can disagree and point out that the examples are wrong, but how you point out is the difference. I called out not to abuse by saying "Hot garbage" because that is abuse. I don't see how it isn't. And it isn't any use to anyone. If you think that the post is bad then make a counter argument, put in a constructive comment. You did nothing of that sort. &gt; Funny how you blatantly abuse anonymity Yeah, note the keywords here. There is a difference between using and abusing. Just because you are anonymous doesn't mean you can talk like that. &gt; you said mu original comment wasn't constructive. how constructive have been all your personal attacks against me, mr. self-contradiction? I am calling out your hypocrisy. I asked you an opinion for which you made no reply at all. I didn't make any personal attack. Don't lie and cry victim now, this is an age old strategy. &gt; enough, i'm blocking you and your stupids lies. bark all you want. Great. I'll see you around. Guess ill be the protector of the common folk from people like you. To anyone reading this thread, this is how you shouldn't behave in online forums. Disagree with opinions and be respectful in your comments. 
&gt; numberList You can use `reduce` in Java 8, so this comparison is unfair now.
I post it here https://stackoverflow.com/questions/47303017/what-is-the-value-type-of-the-map/47303500#47303500.
Commit volume is a poor metric, since a high number of commits might just indicate a poor design that requires a lot of code changes to do anything. (Or might not). I don't know of anyone using either in production. I don't think iOS is such a big market, particularly among JVM-oriented people who would be the audience - indeed I think fast startup bash-style scripts, while much less glamorous, are probably a bigger market.
I don't have access to stack overflow where I'm working
&gt; Commit volume is a poor metric, since a high number of commits might just indicate a poor design that requires a lot of code changes to do anything. (Or might not). More likely they're simply making a huge amount of progress both in terms of Kotlin Native and tooling support (watching Breslav's iOS [live coding session now](https://youtu.be/3Lqiupxo4CE), pretty impressive). &gt; I don't know of anyone using either in production. True, but it's looking more and more like Kotlin Native will be production ready well before Scala Native (again, correct me if I'm wrong). &gt; I don't think iOS is such a big market, particularly among JVM-oriented people who would be the audience Echos of Scala dropping the ball on Android support, which Kotlin opportunistically picked up, and are now using as a launch pad for all of their other platform targets. Kotlin is definitely in the [hype cycle now](https://trends.google.com/trends/explore?q=%2Fm%2F0_lcrx4,%2Fm%2F091hdj,%2Fm%2F03yb8hb), TBD if that translates to mainstream adoption.
&gt; Commit volume is a poor metric, since a high number of commits might just indicate a poor design that requires a lot of code changes to do anything. (Or might not). More likely they're simply making a huge amount of progress both in terms of Kotlin Native and tooling support (watching Breslav's iOS [live coding session now](https://youtu.be/3Lqiupxo4CE), pretty impressive). &gt; I don't know of anyone using either in production. True, but it's looking more and more like Kotlin Native will be production ready well before Scala Native (again, correct me if I'm wrong). &gt; I don't think iOS is such a big market, particularly among JVM-oriented people who would be the audience Echos of Scala dropping the ball on Android support, which Kotlin opportunistically picked up, and are now using as a launch pad for all of their other platform targets. Kotlin is definitely in the [hype cycle now](https://trends.google.com/trends/explore?q=%2Fm%2F0_lcrx4,%2Fm%2F091hdj,%2Fm%2F03yb8hb), TBD if that translates to mainstream adoption.
I've made use of it for a few quick tools, and lot of popular libraries are supporting it. If I were to try is use it in production, I'm not sure how I'd package it or deploy it. Sure I can build something for my machine, but what if I want to cross build for Windows, Linux and OSX? Maybe this is where one of those containerization solutions like docker that all the cool kids use can help. In the mean time, as far as I can tall Kotlin native is no better in this regard. If there are issues with scala-native at the moment I think being on 2.11 still prevents a lot of less mature projects from adopting it. It's also quite hard to search for projects that do support it(it's 2017 and sbt still has no online library search api/plugin? I think I'll go file a feature request for that finally).
&gt; Echos of Scala dropping the ball on Android support, which Kotlin opportunistically picked up, and are now using as a launch pad for all of their other platform targets. Well, indeed, but it remains to be seen how well that will work out for them.
&gt; Well, indeed, but it remains to be seen how well that will work out for them. If past is prologue, exceedingly well.
&gt; More likely they're simply making a huge amount of progress both in terms of Kotlin Native and tooling support (watching Breslav's iOS live coding session now, pretty impressive). I just watched this now, I have to say its pretty impressive considering how young the project is. Have to hand it to Jetbrains, they definitely know how to do tooling/user experience well
I sense that Scala has split into too many directions simultaneously; 2.13, 3.0 (Dotty), Scala.js, Scala Native, collections redesign, etc. And given a individual contributor wants to generously participate in any particular one of these, two directions will give them strong pause; Dotty and the collections redeign. Why? Because each will likely cause severe impacts to and implementations, designs, and ultimately architectures themselves. For someone considering spending their fairly scarce spare time helping any of these, they are left imagining a huge "setback" for their specific and limited participation. They become reluctant to create something NOW if they only have to wait a year or two and the large impacting thing will be out, and they can start from there. So, they wait. And before you "should" them with your reasonable, rational, and cogent arguments, remember that this isn't a rational choice. It's a nebulous procrastination to protect their precious and scarce leisure time enjoying their passion to contribute to be an impact. So, "should" don't work here. Only attraction and collaboration work here. I know. I am speaking from a personal place. I am one of these individuals. 
Notably, while commit volume isn't a good metric, number of committers is, especially for small numbers. It's a huge jump to go from 1 primary committer to 5, and indicates that the project won't go on hiatus when one guy has a paper to write, or graduates and gets a job doing something else. (Many of my own projects do poorly here; I've been trying to hard to find substitute maintainers, but haven't been totally successful)
&gt; Seems Scala Native has lost some steam of late wrt to commit activity. Because the main author, @densh, has been writing a paper for the past few weeks. The deadline was on Monday. You can expect the commit activity to start anew before long. &gt; There's really only one primary contributor (the author) with some part-time-ish contributions by a Scala Center staff member. There's about the same for Scala.js, yet it's consistently delivering and is ahead of Kotlin JS, despite the latter having been "designed from the start", supposedly. I think in the medium term, Scala Native will definitely reach maturity before Kotlin Native.
&gt; it's 2017 and sbt still has no online library search api/plugin? https://index.scala-lang.org/search?q=*&amp;sbtVersions=1.0 You're welcome.
They're certainly not as direct, but they are equally general: http://smallcultfollowing.com/babysteps/blog/2016/11/03/associated-type-constructors-part-2-family-traits/
&gt; they definitely know how to do tooling/user experience well Yup, Scala's achilles heel is tooling (Sbt and Scala IDE are standouts in this department). To be fair, Lightbend is a small company compared to Jetbrains, and the EPFL, while it provides free research, is a revolving door of graduate students, some more talented than others.
&gt; I sense that Scala has split into too many directions simultaneously; 2.13, 3.0 (Dotty), Scala.js, Scala Native, collections redesign, etc. And given a individual contributor wants to generously participate in any particular one of these, two directions will give them strong pause; Dotty and the collections redeign. IMO you are confusing "work packages" and "directions". Scala 2.13, Dotty and the collections redesign are all going in the same direction. They are different work packages on the same line. The collections redesign is on the path towards 2.13, which is itself on the path towards Dotty. Scala.js and Scala Native are going in another direction: that of making Scala available on more platforms. However they definitely do not oppose each other. On the contrary, together with the JVM they make Scala one of the most portable real-world languages on the market.
&gt; or graduates and gets a job doing something else Case in point: Dmitry Petrashko, graduates, gets a job at Stripe and voila, [Dotty commits, bye bye](https://github.com/DarkDimius). The same will probably happen if Lightbend/Scala Center elects not to hire [Sébastien Doeraene](https://github.com/sjrd) (what a tragedy for Scala.js that would be).
&gt; Because the main author, @densh, has been writing a paper for the past few weeks. Right, that's the problem, juggling academic requirements with OSS contributions is a serious challenge. Jetbrains' employees have no such restrictions. EPFL is a godsend wrt to kicking off amazing projects, but seeing them through to completion (maintaining/evolving) often requires paid staff at some point. Speaking of, as a Scala.js user one hopes that Lightbend/Scala Center come to their senses and hire you before you too leave for industry work :\
I'm sorry, I didn't know that.
I really want to write a Jack Audio client, and perhaps even a minimalist SuperCollider kind-of server. I think those would be great use cases. Alas, I lack the time resources. If anyone is interested in such a (longer term) project, get in touch.
I wonder if one could just use Maven again; for example [OpenCV](http://search.maven.org/#search%7Cga%7C1%7Copencv), there are CPU architecture dependent jars as well. Wouldn't that work?
&gt; To be fair, Lightbend is a small company compared to Jetbrains Couldn't they get a bigger player onboard for this project?
I was actually looking into hacking a client from sbt's shell to use that.
Not if it keeps building with SBT it can't
So how does this address my general contention? Your comment feels like a tangent or deflection from my central point and direct experience.
BTW, before you respond, please be aware of my personal context. Not only did I found (in 2011/Jan) and run the Dallas Scala Enthusiast group here in the Dallas/TX/USA, I have started a company based on Scala/Akka/Spark SaaS, deployed it to ASW, and invested hundreds of thousands of dollars betting on Scala technology. So, I didn't come to my opinion on Scala from a bias of favoring a different technology. I sincerely and deeply appreciate, value, and admire Scala and Odersky. I am eager to see Scala continue to become more successful. If anything, I am _too_ biased towards Scala.
BTW, thank you so much for leading the charge on Scala.js. I deeply appreciate your dedication and work. So much so, I recently took a Google Polymer framework using the GoogleMaps API and got it up and running with Scala.js so I could write as little JavaScript as I possibly could. The goal is to do as much of the UI app in Scala as is possible and as little JavaScript as is possible. SO, I cannot thank you enough for your efforts to make my life so much more pleasant. I hate Hate HATE JavaScript and all of its surprises.
I wholeheartedly agree with "as a Scala.js user one hopes that Lightbend/Scala Center come to their senses and hire you before you too leave for industry work"!
I know there are a few tutorials out there that describe the process, but this is fairly recent and comprehensive; I learned that I should upgrade my sbt knowledge (still using `pomExtra` and XML instead of `scmInfo` and `developers`).
TBH I am not sure myself. There's probably something wrong happening somewhere (whose fault it is? I don't know) if: * your experience is to be set back because you see many projects going into opposite directions * while all those projects are actually collaborating and all pushing Scala towards more greatness. Do you have an idea how we could counteract the sentiment that you are experiencing?
What makes you folks think that Lightbend and Scala Center are the only (or even best) avenue for me to pursue a career that would allow me to keep doing Scala.js?
&gt; https://www.amazon.jobs/en/jobs/585197/software-development-engineer Interesting to hear. If I wanted to exclusively do Scala, what is the chance that can happen? As in, I won't end up being palmed off onto Java projects eventually.
I don't think its going to be an issue with Dotty. Dotty has enough core contributors that it shouldn't really be an issue, its also going to hit critical mass at some point
&gt; I don't think its going to be an issue with Dotty. Well yeah, Lightbend Scala compiler devs will take over maintenance/development in the long-term, but in the near-term they're down 1 developer due to Dmitry's exit (though I guess he'll still contribute in some way via Stripe OSS projects). It's more the not-fully-blessed projects (like Scala.js) that have a murkier future if the original author is forced to move on to other things (i.e. making a living).
That's what Scala Center is, funded by corporate board members (Twitter, Morgan Stanley, Verizon, etc.); they vote, along with 2 community members (Bill Venners and somebody else) where resources should be allocated. Scala Center's budget is enough for what, at most 4 or 5 full-time staff? Compare that to 40 full-time engineers now working on Kotlin, Kotlin Native, and Kotlin JS.
&gt;&gt; I don't think iOS is such a big market, particularly among JVM-oriented people who would be the audience &gt; Echos of Scala dropping the ball on Android support, which Kotlin opportunistically picked up, and are now using as a launch pad for all of their other platform targets. Some people have never understood that the main purpose and benefit of supporting new platforms is that it enables whole new ecosystems of developers to pick up Scala for their purposes, not solely allowing existing Scala/JVM devs to target another platform. Frankly, I'm kind of surprised that the maintainer of Scala on Android hasn't quit yet, considering the disinterest and disrespect he continues to receive from the Scala project.
&gt; is that it enables whole new ecosystems of developers to pick up Scala for their purposes, not solely allowing existing Scala/JVM devs to target another platform Very good point. &gt; I'm kind of surprised that the maintainer of Scala on Android hasn't quit yet Apparently the latest version of Android has at least partial Java 8 support; maybe there's a glimmer of hope yet for Scala on Android. Though like Scala.js it's definitely not a Lightbend priority.
I think the hope for Scala.js users is that you'll be able to work full-time on the project rather than on the side as, for example, Eugene Burmako is doing with Scala Meta at Twitter. Maybe a deep pocketed Scala.js client will hire you like what happened with the Elm author. At any rate, given what an oustanding OSS project Scala.js is, it would be a shame to see you forced to work on something else and have the project suffer as a result.
It doesn't have to be anyone's priority except for those who want to work on it. The problem is not that people don't care, it's that they don't even care about them not caring, blocking contributors who care about it. "Not-invented-here? -- Then we don't care!"
First, why would you not use Swift for iOS apps? It's likely faster and more stable, has good vendor support, and has strong feature parity with Kotlin. Second, Scala and Kotlin do not provide the same functionality. If i'm writing Scala code, I am not going to switch to Kotlin because they rammed a compiler to native out sooner. Scala is not simply a better Java.
Is your contention that Kotlin isn't in for some real growing pains in the next 2 years? Java is going to get Project Amber, and it's going to take a lot of shine off the Kotlin apple. Scala, in the meantime, will have their world class type system and real functional programming capabilities to differentiate themselves. Kotlin is going to innovate sooner than later (read: breaking changes) or die. 
That would depend very heavily on the team. Some teams have large Java codebases and use Scala only for, for instance, analytics via Spark. Other teams do pure Scala service/library development. For my team, in terms of languages, 100% strictly Scala is difficult. We spend about 80% on new feature dev in Scala. Our customers are not just Scala developers so we have products requiring: 1. frontend development with ruby/ecmascript/html/css. Minimal, but can't skimp on quality. 2. Service development in Scala. All new features are done in Scala. 3. Migrating Java code to Scala. If it's broke: Replace. If it won't scale: Replace. Looked at you funny: Replace. 4. DynamoDB and Postgres for DB. Strictly speaking, these have query languages. 
\&gt;wrt to
I couldn't say much about Scala Native, but being a tech lead of Kotlin/Native could say that JetBrains invests heavily into both language and platform. Now my team has 8 full time developers, and we're working heavily on making cool native application development platform (compiler, runtime, IDE, libraries). One of the most important idea behind Kotlin in general is that ecosystem is what's required in modern development, not just a cool language, or sophisticated compiler (although we have both ;)). And building it requires manpower and commitment.
I don't see what area kotlin/kotlin native is targeting 1) Android. Sure Kotlin is the monopoly here particularly when Java 8/9 cannot come to android since they have their own JVM 2) Ios. This is not going to be an easy one. Apple is targeting Swift and it is heavily promoting it. I don't think they will focus on Kotlin. Remember that Kotlin became famous for Android since Google supported it. Without native support from the company, I don't think it will become a viable language. 3) Desktop apps. With the whole world moving towards the web and with Web assembly. The general idea of desktop apps is dying. If native performance is brought to the web. The whole idea of desktop apps will be fading away sooner. 4) Web apps/ General backend application development Kotlin is more similar to Java than it is to Scala. With Java adding many features pretty quickly. It will be interesting to see how it goes. Remember that Linkedin chose Java 8 over Scala since they want to unify their infrastructure. That gap is huge when compared to Kotlin vs Java 8. So I see many companies choosing Java over Kotlin here. Again time will tell. 5) System software I can see Rust making a huge impact on this area. But recently the PostgreSQL database team did an evaluation of Rust and chose to stick with C since it is proven and withstood the test of time. It will be very interesting to see what kotlin can do here. Since Kotlin is the closest to Java, people who are familiar with java will chose kotlin native depending on its maturity. Scala native does not directly compete since it is much more different than Java. I guess kotlin native vs scala native is still the same as kotlin on the jvm vs scala on the jvm. It is a battle of paradigms and not just languages. 6) Transpilers targeting Javascript Scala js is much more mature than Kotlin JS right now. But as I said above, in the coming years, I can see Javascript itself going away. 
So then it's _not_ what Scala Center is, a bigger player. A bigger player might be Intel or I don't know what company would have great interest in Scala compiled to native code.
There is a subreddit dedicated to kotlun. Would be very kind of you and other JetBrains employers to stop implicit Kotlin advertisments in Scala subreddit. Ty. 
Um what??? I am trying to understand the stance of both the languages. Where did you see in the post advertising kotling? In fact I am questioning it more.
&gt; One of the most important idea behind Kotlin in general is that ecosystem is what's required in modern development Indeed, and Jetbrains is doing an amazing job so far bootstrapping this process. But my questions would be: for how log can they keep this up? I'm pretty sure that currently Kotlin is not pulling its own weight. And with the new direction Java is taking, they would have to accelerate the development on all fronts.
Kotlin also has a better story going with Spring 5 . Interestingly they've chosen the areas where Scala doesn't do well. (as opposed to Big Data, where Scala is used very often)
Anyway thanks a lot for your help.
The article has a problem with a link - "SBT Getting Started Guide" - has an extra dot.
Honestly, who cares about Kotlin? It's a vastly different language, and I don't know why people keep posting about it in this sub. I would even argue that the target audiences don't overlap much. Nowadays, not many people in their sane mind would pick Scala as a better Java. You pick Scala if you want functional programming and an expressive type system. You don't have that in Kotlin at all. &lt;fanboy hat on&gt; Anyway, Scala will prevail as it's a better language, and Kotlin will either fade away as Java gains proper features like pattern matching, or solidify as merely the language for Android.
I'm not following much because I find a boring and superfluous language. I can see that they pushed to Android, where Scala didn't make much waves. Otherwise, the only way it could become useful is if they manage to get WebAssembly support before Scala. I haven't worked with WebAssembly yet, so I have no idea how important that is and how fast it will replace JavaScript as virtual machine. I would also guess that for high performance apps in the browser, people might prefer to turn to Rust (?)
Yes.Got to give them credit there. But with Java itself giving a lot of these features natively, how much of current kotlin features matter? Will it be that much of game changer?
&gt; Honestly, who cares about Kotlin? It's a vastly different language, and I don't know why people keep posting about it in this sub. This was my view. People were saying tooling is better, but with VS Code + Language server protocol coming for Scala, it will be better than Intellij. &gt; I would even argue that the target audiences don't overlap much. Nowadays, not many people in their sane mind would pick Scala as a better Java. You pick Scala if you want functional programming and an expressive type system. You don't have that in Kotlin at all Agreed. From a neutral perspective, the language itself does not seem to have any direction. Scala's foundations are pretty solid, Kotlin just seems like wrap all nice things and then sell it. May be we see this aspect because we have worked somewhat extensively with scala. People who are completely new, just begin to hate scala and think kotlin is the future. &gt; Anyway, Scala will prevail as it's a better language, and Kotlin will either fade away as Java gains proper features like pattern matching, or solidify as merely the language for Android. Even from a non fan boy perspective, this seems true. Java is fast catching up. They will never be like scala, not that they cannot be, but java as a language has its root in OOP and not FP.
&gt; but with VS Code + Language server protocol coming for Scala, I think it will be better than Intellij I think that's wishful thinking. I tried out Dotty in VS Code on the weekend. I didn't dig deep, but other than syntax lighting it basically couldn't do anything. It will takes years for anything to come close to the productivity of IntelliJ. Personally, I would also always favour a snappy native/AWT GUI than a JavaScript container. I have a fast laptop, but I can still see how the menus are rendered in VS Code. I think it wants to appeal to a generation that things everything is as bad as web applications and have forgotten that desktop computers can perform much better.
Depends if Java implements these features well. Case classes and pattern matching proposals look mediocre in my opinion 
Scala center is designed to facilitate open source development and the community, its not designed to be a corporate workhouse working on products in the same sense Intellij is. Its not a completely accurate comparison as well, because Intellij happens to have paid products which provide them with a lot of revenue
At this point, Kotlin will very likely have very good cross platform support (native/JS/JVM) so it will have still a much stronger selling point than Java. There is also stuff like co-routines which Kotlin will support on every platform
&gt; This was my view. People were saying tooling is better, but with VS Code + Language server protocol coming for Scala, I think it will be better than Intellij Even with proper support for VS + LSP, Intellij is miles ahead in the functionality it provides (from an IDE perspective). Everything from inspections to extracting methods. &gt; Agreed. From a neutral perspective, the language itself does not seem to have any direction. Scala's foundations are pretty solid, Kotlin just seems like wrap all nice things and then sell it. May be we see this aspect because we have worked somewhat extensively with scala. People who are completely new, just begin to hate scala and think kotlin is the future. This is somewhat detracting from the central point which is that tooling/ecosystem/usability matters as much (if not more, depending on who you ask) as language design. You can theoretically have the nicest designed language, but its never going to get used if it doesn't have all of the other mentioned things
&gt; Otherwise, the only way it could become useful is if they manage to get WebAssembly support before Scala. They already have, see https://youtu.be/3Lqiupxo4CE
I don't fully agree with your analysis. 1) Considering that Google is backing Kotlin I think in a few years it will be the dominant language for Android. 2) Kotlin will be a viable alternative for iOS just because of the fact that people want to be able to easily port their Android apps to iOS. But Swift will also continue to grow. 3) Totally agree. I think even heavy desktop apps like AAA games will eventually move to the browser. 5) Yes, Rust will continue to grow and gradually replace C and C++ on the system level (over a **very** long period of time). Neither Scala or Kotlin native are direct competitors in this space. And IMHO Rust is just a better language than Kotlin. 4 &amp; 6) Choosing the same language for backend and frontend definitely has some advantages. Scala is very mature in both areas and the best choice right now IMHO (even compared to other languages like ReasonML, PureScript etc.). I don't think Kotlin will gain much traction here.
In context, we have had a lot of trolling and sock puppets with spam accounts spreading FUD and advertising Kotlin in Scala, so some people are naturally somewhat suspicious
I understand the mentality, I just don't share it, that's why I said I'm quite unpassionate about it. Apart from that I challenge the assumption that they take "what works best". But then this is Scala forum, I would bet that almost everyone here uses Scala because it works best for us and let's us do things that can't be expressed in Java or the Java-with-Scala-syntax that is Kotlin. I don't even know what cross-platform support is; I work on desktop platforms, and for me Scala is cross-platform, because I can give my applications to people that work on Linux, Mac, or Windows, and I can run them on a Raspberry Pi as well... I even experimented with Scala.js, although I'm not much of a web person. So YMMV.
I did. There is nearly nothing Scala related in your post. The whole thread should be moved to Kotlin subreddit and debated there.
&gt; Even with proper support for VS + LSP, Intellij is miles ahead in the functionality it provides (from an IDE perspective). Everything from inspections to extracting methods. Yes but atleast we have an alternative. My point was that now Kotlin is done by the same company, it will be good if we have alternatives. I hope that lightbend/scala center invests more time into IDE/tooling. High time its done. &gt; You can theoretically have the nicest designed language, but its never going to get used if it doesn't have all of the other mentioned things I was more worried about people choosing Kotlin just because of the hype created by google and of course tooling. At the current state, tooling by Intellij is not that bad. But certain advanced libraries such as ScalaZ/Cats have issues according to users who have posted here. &gt; You can theoretically have the nicest designed language, but its never going to get used if it doesn't have all of the other mentioned things Fully agreed. But is the situation so bad right now that people are turning away from scala because of tooling. The reason I am asking is because I have not worked with libs in typelevel ecosystem and others where they use advanced syntax and Intellij is pretty bad at that. 
I will get only Kotlin related optimistic comments there. I want constructive comparison against scala which I am definitely not going to get there.
Interesting. I have not delved deep into how they are implemented in Java. Will take a look.
[removed]
I can understand. But I never promoted Kotlin which was /u/Dobroff argument. I wanted opinions on Kotlin and related stuff from a Scala developer's perspective. I think having different perspective is important. 
The coroutines is an interesting example, because I was excited years ago when the continuations plugin came to Scala; but after a while you can see the limitations. Are coroutines really that useful, when you have to propagate special annotations or provisions throughout the code base? I might be wrong, but from a brief glance Kotlin has the same limitation here as for example, [storm-enroute coroutines](http://storm-enroute.com/coroutines/) in Scala. As a counter example, in SuperCollider you have coroutine support baked into its virtual machine, so you can 'yield' from anywhere at any nesting level (you will get a runtime error if you're doing that outside of a routine body, but that's not relevant for the API). I think it will be really useful if coroutines where transparent in the virtual machine, so you could do a yield inside any function you pass to any method. Not sure about Kotlin's implementation, but in storm-enroute, you can't even yield from within a for-comprehension. So it will be more interesting to see how Java 10, 11 (?) might bring continuations support directly to the JVM. Right now, coroutines seem yet another marketing buzz, a 2016 version of async/wait. Is anyone using this except in rare cases?
&gt; Honestly, who cares about Kotlin? It's a vastly different language, and I don't know why people keep posting about it in this sub. I think C++ developers had pretty much the same opinion about Java when it was created. If you told them back then that 10 years later half their jobs (and half of everyone else's jobs) would be in Java, they would have laughed you out of the door. The fact that Java is moving again means that fewer Java devs are looking for "better X" to start with. This hits Scala way harder than Kotlin, because Scala never bothered to get adoption from other ecosystems, while Kotlin aggressively branched out to other platforms. The existence of Kotlin further reduces the amount of adoption Scala can get. &gt; You pick Scala if you want functional programming and an expressive type system. You don't have that in Kotlin at all. Try to look at it from a Java dev perspective, not from a Scala dev perspective. Most people don't start out with "I'm unhappy with Java, I need a functional programming language with an expressive type system". Kotlin is not going after the 1% of Scala devs, they are going after the 99% of the non-Scala devs. And if Java devs compare Kotlin and Scala they see that Kotlin has documentation, tooling, compiles to the JVM, JavaScript and Native, and has official support from Google. Language feature-wise Kotlin claims null-safety and 100% Java compatibility, while the features that Scala enthusiasts often point out (higher-kinded types, typeclasses, context bounds) don't seem to be important enough to even mention in Scala's documentation.
does it have fast autocomplete?
It had some sort of autocomplete, but half-assed. For example, you can't type `Con&lt;tab&gt;` and expect to get `Console`, but you can write `Console.pr` and get `println` etc. It seems all really basic and not at all comparable to IntelliJ. I also didn't figure out how to jump to symbols, and I didn't see any possibility to build the project at all other than run sbt separately from the terminal.
&gt; Is there any work being done to address, for example, iOS support? Don't hold your breath, I believe Denys specifically stated iOS support is a non-goal. A lot of people want to see a native scalac (it's already been done, just not published yet), maybe a native build system, native low-footprint micro-services, native scientific libraries ... realistic goals that appeal to existing Scala developers, not some mythical code re-use between servers and mobile platforms with completely different memory management semantics.
&gt; My prediction is that Kotlin will become the go-to language for a lot of cross-platform development (if you consider how fast every organization that is offering this is bought out Don't you think that is a little over-estimate. I don't think it will ever replace Swift/Objective C on iOS. Regarding native code, I think Rust is way better than Kotlin (Opinion I got from some of my Rust dev friends). &gt; while the reduced adoption of Scala will stretch the limited resources of the remaining contributors even thinner Considering that Kotlin didn't aim for Scala's grounds such as Big data/FP on JVM, how is it going to affect it? 
I think passing around plain old values is simpler, for example: https://github.com/enpassant/miniatures/blob/master/src/main/scala/plainFP/Config.scala "If we have to pass all these config parameters" (video at 20:22). I think this is a design flaw, that is passing unnecessary state everywhere. For example, readName method depend on Config object (unnecessary state of Config.age). There is a very good talk about it ("clumsy input") by Ken Scambler: https://www.youtube.com/watch?v=EaxDl5NPuCA&amp;feature=youtu.be&amp;t=500
&gt; As people mentioned Kotlin aimed for the remaining majority of Java devs who didn't switch mainstream to Scala. Yes, I said exactly that. That's where Scala got its adoption from.
The comparison with C++/Java doesn't make sense. First of all, their relation is not akin to Scala/Kotlin. Second, today we have C++ and Java, and both have their areas of use. I don't understand where the anxiety with Kotlin comes from. What is being taken from us? It's just another language originating on the JVM, that yes stole a lot of syntax and features from Scala, but it will not make Scala less useful nor threaten its existence. If at the end of the day, there is a crowd that wants to code their Android apps in Kotlin, then why not? It's important that Scala moves forward, and it does so, and independent of the economic forces or pretentions of Kotlin.
&gt; You can theoretically have the nicest designed language, but its never going to get used if it doesn't have all of the other mentioned things I don't think it's always as important as you make it to be. For example, look at Rust. For the longest time it didn't have a proper IDE or proper IDE features. Yet the sound language design solving actual problems made it popular. Together with Mozilla's modest backing this created a huge hype, and a vast community formed. (And no, backing by a big company is not everything, otherwise we'd all be coding in Dart by now.)
&gt; All this war or battle rhetoric, I don't get it. They are just programming languages. There are also a lot of questionable percentage numbers in your post. What "battle rhetoric" are you talking about? All I'm saying is that if you have a pie A, B and C, with X getting a slice of pie A and Y getting a slice of pies A, B and C. If pie A gets smaller, X is "hit" harder than Y. Disregard the percentages if you like, it's simple cake math.
I understand your position, I am just saying that people are suspicious around here (and historically for good reason)
and you will get only kotlin related pessimistic comments there. if you want constructive comparison, try asking in /r/programming
&gt; I have a fast laptop, but I can still see how the menus are rendered in VS Code That's weird. I have a 2-year old high-end mac, and VSCode is just a breeze to use. But maybe that's because I only use it on small projects (Latex, Dotty prototypes, small C++ projects). Is it that it gets bad when projects get bigger?
&gt; But certain advanced libraries such as ScalaZ/Cats have issues according to users who have posted here. We we need a good IDE that uses the actual Scala compiler infrastructure for the presentation, and does not try to reimplement the entire compiler (that's the problem why IntelliJ will never stop putting wrong red squiggly lines).
I think you are confusing their tooling success with the language. Visual studio was one of the best IDEs and may be still is, but C# as a language is not as good as Java in terms of adoption. The CLR once was aiming to be cross platform and the Mono project didn't really work out well. C# on linux is with .Net framework is still a dream. So I don't think we should base our assumption on a company's success with tools and languages. While I see the future is optimistic for Kotlin, they are doing this because they want to spread out on the market. Considering the IDE market is now coming up with VS Code, Eclipse Che and the likes, I think it is only a matter of time until they become as good as Intellij. So they are clearly expanding and doing the right thing. &gt; Yes, I said exactly that. That's where Scala got its adoption from. I think you misunderstood what I said, I was trying to say that people who have adopted scala now will never go to Kotlin just because of tooling. With that said, how much impact do you think developers would have? Considering the concepts are all the same and syntax are similar, I don't think developers have to re-learn anything. 
I haven't done a real project yet, so don't know what happens when the project gets bad. All I can see is that a GUI rendered through JavaScript sucks big time.
I am not sure of that. But I will definitely post it in /r/programming just for a different perspective.
&gt; I was trying to say that people who have adopted scala now will never go to Kotlin just because of tooling. Again, Kotlin doesn't care about the 1% of Scala users, they care about adoption from the 99% of Scala users. For them, tooling makes a big difference when picking a language.
&gt; Yes but atleast we have an alternative. My point was that now Kotlin is done by the same company, it will be good if we have alternatives. I hope that lightbend/scala center invests more time into IDE/tooling. High time its done. True, my point is that it will take a *loooooong* time before its even comparable &gt; I was more worried about people choosing Kotlin just because of the hype created by google and of course tooling. At the current state, tooling by Intellij is not that bad. But certain advanced libraries such as ScalaZ/Cats have issues according to users who have posted here. Well its not really hype, it does have much better tooling (and also much better support for Android). Intellij for Scala is *okay*, and I say *okay* because 1. It uses a ginormous amount of memory, probably due to Intellij having to cache all type information (which in Scala is massive due to how complex its type system is). 2. Doesn't really work with dependant types/other more uses of Scala (i.e. scalaz/cats/shapeless routinely have issues in this regard) 3. Because of the complexity of inferring types (which is needed for everything, from completion to rename to refactoring), the GUI gets locked frequently and in general Intellij gets really laggy, particularly when you have lots of files open. At many times I just turn on Power Saver mode to not have this issue. 4. SBT integration needs a lot more polishing, frequently I have to uninstall/reinstall the plugin because SBT decides to use locks and it sometimes puts Intellij in a bad state None of these issues exist with Java, nor do they with Kotlin (afaik). Onto SBT, there are a lot of issues with SBT which people have been talking about for a while, not going to regurgitate it here I guess it depends on what you mean by "not that bad", but there is a significant difference 
&gt; don't seem to be important enough to even mention in Scala's documentation That's because it just makes sense intuitively, without requiring an explicit name and a weird encoding (like in your Kotlin video). It's part of the beauty of Scala :\^P You can have type aliases like `type T = ...`. Now, like other members, you can leave them abstract and implement them in subtypes. In addition, type aliases can naturally take parameters. So there you have it, higher-kinded types `trait A { type F[B] }`.
WRT to co-routines on Scala, the main issue is that it was macro based rather than being a compiler plugin (or even better part of the actual compiler). To have actual good support for co-routines, it needs to be part of the compiler. The only real exception in this regard would be something like LISP due to homocinity I am not really aware of how co-routines work in Kotlin, but these were the issues wrt Scala &gt; You can't actually compose useful programs with coroutines; not only can you not use coroutines inside functions that are not themselves coroutine contexts, you also can't use (from what I read) a coroutine function in place of a regular function. This isn't entirely true (and is also probably an issue with the implementation). You would be interested to see this blog post and video on the subject, its very enlightening http://blog.paralleluniverse.co/2015/08/07/scoped-continuations/. Also wrt to Scala, this isn't any better with respect to `Task`/`Future`, if you use either `Task` or `Future` inside a normal function (and you want to compose on it), you then have to alter the flow and the return type of the function &gt; Besides, out of curiosity - do Kotlin coroutines work in JS and native? They are meant to yes, at least from what I have heard
I think you are ignoring things like Cargo, which is probably (apart from Opam) one of the best package managers you can have. Cargo is much much much better than SBT, both from a performance and usability perspective (and this is also taking into account how complex systems level programming is wrt compiler flags and toolchains)
We are kind of going around in circles here, in the example in the video this works, but when your context (or config in this case) explodes, then the number of parameters that you pass explodes. To deal with the parameter explosion you often have to resort to higher level abstractions, which are not simpler
I can't tell if you are serious or kidding.
VS Code is not the same as Atom, its actually really performant. This is because many parts of VS Code (at least the performance sensitive parts) are written in native code, and the entire ecosystem (i.e. VS Code plugins) are designed to be async to prevent blocking the UI.
&gt; WRT to co-routines on Scala, the main issue is that it was macro based rather than being a compiler plugin (or even better part of the actual compiler). This is _not_ an issue. The fact that it's implemented as a macro simply shows how great the macro system actually is. From a user perspective, there is no difference. The difference here is that storm-enroute uses whitebox macros, so that breaks presentation compilers ability to render correctly the types. But I really wonder if that's just laziness, or one could not write a better version that uses blackbox macros. &gt; Also wrt to Scala, this isn't any better with respect to Task/Future, if you use either Task or Future inside a normal function (and you want to compose on it), you then have to alter the flow and the return type of the function Yes and no. You are right of course because you have to reflect that in your types. No because coroutines are handled specially, both in Kotlin and Scala, because they must entirely transform the program. This goes away if it was a feature of the virtual machine to suspend execution.
I don't have that experience at all. It's less sluggish than IntelliJ for me. Maybe it depends on the OS.
&gt; I didn't dig deep, but other than syntax lighting it basically couldn't do anything. This is incorrect. See http://dotty.epfl.ch/docs/usage/ide-support.html for the full list of features implemented and their status. If something on this list doesn't work as expected please open an issue or give us a heads up on http://gitter.im/lampepfl/dotty. &gt; It will take years for anything to come close to the productivity of IntelliJ. I bet we'll have something usable much earlier than that ;). You can follow along at https://github.com/lampepfl/dotty/issues/3360 to see the list of things we're implementing. And if you're interested in the design approach we're following, have a look at http://guillaume.martres.me/ide_paper.pdf or http://guillaume.martres.me/talks/scala-symposium-17/#/ (no video online yet)
From what I remember there is a Scala center project aimed at making Intellij use the LSP (which sbt will be providing at some point in the future, for both Scala and Dotty) so that this doesn't end up happening.
Not many people need all three of those. Two is normal. And the JVM is cross platform by itself. I think cross domain might be a better term. Project loom will add continuations and fibers to Java. Project amber adds type inference and better lambda support, data classes, etc. Valhalla will reduce or remove boxing and improve data locallity in a big way making things much faster I reckon. Java isn't going anywhere. In five years it will be faster and more popular than it is now. In short and in my estimation; You are not going to beat Java at general purpose OOP on the JVM. If you don't do that youre not going to get the niche developers on native and Js as a bonus. 
&gt; It had some sort of autocomplete, but half-assed. Yes, that's a known issue, and I promise that it will be fixed soon enough ;). &gt; I also didn't figure out how to jump to symbols Right-click on some text -&gt; Go To Definition &gt; I didn't see any possibility to build the project at all other than run sbt separately from the terminal. Yes, build tool integration is very lacking right now. My hope is that once we're done [switching to sbt 1](https://github.com/lampepfl/dotty/pull/3441), we can provide proper sbt support by using the new [sbt language server](https://github.com/sbt/sbt/pull/3524).
&gt; Cargo, which is probably (apart from Opam) one of the best package managers you can have. Are you kidding me? I had so many problems with Opam and OCaml's toolchains. It installs things globally, which is idiotic – when I wanted to switch from one project to another I had to change the OCaml version _globally_, recompile the whole ecosystem, and then it failed because in the meantime a library added an operator `.&lt;` which is already used to mean something by the MetaOCaml compiler plugin. I had to fiddle with old library versions to find again a configuration that worked. Seriously, what is better than SBT here?
&gt; This is not an issue. It actually is, a lot of expressions and things that break the co-routines plugin in Scala is due to limitations of the macro system. Whitebox macros are also either going to be removed or going to be severely restricted (and this in turn may call co-routines altogether unless it gets transformed into a compiler plugin) &gt; BTW, the old continuations compiler plugin suffered from the same issue. But I really wonder if that's just laziness, or one could not write a better version that uses blackbox macros. This is my point in that it should be part of the compiler &gt; Yes and no. You are right of course because you have to reflect that in your types. No because coroutines are handled specially, both in Kotlin and Scala, because they must entirely transform the program. Yes, my point is that this is a limitation of implementation, not the theory. I.e. if you watch the video I posted earlier, the guy debunks a lot of common misconceptions (especially from people who are heavily into functional programing) wrt coroutines/parallelism/concurrency. &gt; This goes away if it was a feature of the virtual machine to suspend execution. For example, you can call xs.flatMap inside a method that receives and returns a Task. You cannot do such thing with coroutines. Yes, which is why the Quasar plugin for Java uses JVM bytecode manipulation for this suspension. If your continuations are part of the core compiler, you can transparently add this suspension support to be part of the runtime. 
&gt; This is incorrect. See http://dotty.epfl.ch/docs/usage/ide-support.html for the full list of features implemented and their status. Ok, sorry if I sounded harsh. Don't get me wrong, I appreciate the project, but it is really in its infancy. Not being able to look up a symbol from a library means, for me, that the feature of looking up symbols is de facto absent. &gt; I bet we'll have something usable much earlier than that ;) Hurray! Fingers crossed. &gt; I've recently asked a student at EPFL to make an LSP plugin for IntelliJ: http://github.com/gtache/intellij-lsp Oh that's great, I will follow that project. My dream would be a light-weight "embeddable IDE" that I could drop into my own projects. IntelliJ Platform is way over the top for such a scenario.
&gt; which is already used to mean something by the MetaOCaml compiler plugin fork. Well yes, you are using a forked version of the compiler. Cargo and Opam are source based package managers, so they are meant to work with the any version of the compiler. If you are using forked compilers with different syntax, then yes this is going to break
Ok, perhaps I have to test it more. My first encounter was that my guts rebelled against me, being used to a really great AWT/Swing based platform (IntelliJ). People give Swing/Java2D a bad rep, but it is actually a responsive and robust thing. (Yes, programming Swing can be annoying, but so is HTML ;)
&gt; Not many people need all three of those. Two is normal. And the JVM is cross platform by itself. I think cross domain might be a better term. This is debatable. Tools like XMarin and now Kotlin with Android have shown how powerful this is. Its not that people need all 3 things, its that you open yourself up to a much bigger market. If you are developing an Iphone app, you suddenly now have access to C# developers. &gt; Project loom will add continuations and fibers to Java. Project amber adds type inference and better lambda support, data classes, etc. Valhalla will reduce or remove boxing and improve data locallity in a big way making things much faster I reckon. Java isn't going anywhere. In five years it will be faster and more popular than it is now. In short and in my estimation; You are not going to beat Java at general purpose OOP on the JVM. If you don't do that youre not going to get the niche developers on native and Js as a bonus. Right, and this will take 5-10 years. By this time, Kotlin will have the advantages which I expressed before.
VS Code is a lot more responsive than Intellij (I am talking about lightweight Java projects in Intellij, not Scala ones which tend to at some point bring it to a crawl)
With SBT this would have not been a problem. The rest of my points stand. Installing dependencies globally is madness. I shouldn't have to disrupt the build of other projects because I use a different library version in the current project. 
&gt; We need a good IDE that uses the actual Scala compiler infrastructure for the presentation, Scala IDE does just that, spurious errors (red squigglies) are quite rare. The underlying code, however, is mixed bag of Scala 2.8 to Scala 2.12 (read: convoluted mess with loads of mutation). The log is filled with myriad caught exceptions that may or may not be fixable. It's also on the way out (in maintenance mode, likely dropped by the time Dotty lands), leaving IntelliJ (we hates it) as the sole full blown IDE. We'll see how VS Code evolves over the next couple of years, I'd be fine with a solid-ish editor (sans spurious errors) that includes full autocomplete, hover-view-type, click-through-to-type, built-in code formatter support a la *scalariform* or *scalafmt*, and decent search/replace with regex support.
I'm not talking about the costs of the presentation compiler parsing - which, as I had written, is basically absent from the current Dotty plugin except for syntax highlight (no inspections whatsoever; if I turn off inspections in IntelliJ, it's also blazingly fast). I'm talking about the UI as such. Ok, perhaps the text editor rendering is not so bad. It's just the tiny details and latencies that give me the impression that it is not as robust as a native desktop application.
&gt; I even experimented with Scala.js, although I'm not much of a web person, and I tinkered with Android before I got bored of "smart" phones. So YMMV. Scala.js has issues, I use it frequently at work. The main problem is compile times, for doing actual design work for UI, you need ultra fast turn around (i.e. if you edit a single digit representing pixel width, you want to refresh the browser instantly to see this change). Even with Scala's incremental compilation, this turnaround is really slow, especially when you start using scalaz/cats and wrappers like scalajs-react. In any non trivial sized project this really starts showing. `fastOptJs` in one of our projects alone takes like 15-20 seconds. Kotlin will have the upper hand in this regard because its compiler is much faster, although personally I am exploring OCaml/Reason in this space (which basically have almost instant compiles. OCaml can compile the official compiler in 5 minutes, to put things into perspective)
&gt; Whitebox macros are also either going to be removed or going to be severely restricted (and this in turn may call co-routines altogether unless it gets transformed into a compiler plugin) As I said, that is the actual problem with the implementation now. From thinking about it for a bit, I didn't see why it shouldn't be possible to show the types correctly in a blackbox macro.
Again, thanks for your efforts, I hope the project matures.
Yes this is what I was talking about (which is why I mentioned Intellij with Java because it doesn't grin the UI to a halt). VS Code has very responsive UI, its completely async down to the core and critical parts are written in C++ (afaik). Its also written by guys who have lots of experience in desktop apps (Microsoft)
Yes, I know. Alas, I find Eclipse even more ugly than Atom based editors. They should have ditched SWT a decade ago. I'm still sad that Netbeans didn't go anywhere, I think it was a really great platform, at the time not much behind IntelliJ.
You're welcome! And don't hesitate to give us feedback, it's really useful to know exactly how people are using your software and what issues they run into.
&gt; With SBT this would have not been a problem. Yes, but with binary dependencies it opens up 10x more issues, i.e. have a look at https://contributors.scala-lang.org/t/alternative-scalajs-scala-native-distribution-mechanisms/1166 Maintaining libraries in Scala is **really** painful because of binary compatibility. Due to shortcomings with SBT, I have actually have to resort to using environment variable workarounds &gt; The rest of my points stand. Installing dependencies globally is madness. I shouldn't have to disrupt the build of other projects because I use a different library version in the current project. Which version of Opam were you using?
I can understand, there has been a lot of trolling here recently. But I really couldn't see how I was promoting Kotlin. Sure, my post didn't have any scala specific content, but I didn't intend this to be a feature comparison post but rather than what the community thinks of my opinions. Trolls can change There are a lot of experts(language committers) here who could share their views and I believe that this is one of the strengths of this sub. 
&gt; Maintaining libraries in Scala is really painful because of binary compatibility. The binary compatibility problem is real, but I think it's more of a problem with the Java platform than with build tools. Hopefully Java modules provide a good solution? Obviously, libraries should not have to work with different versions of the libraries they depend on than the versions they have been compiled and tested with. &gt; Which version of Opam were you using? `opam --version` give `1.2.2`, but the problems I encountered may have been on an older version?
&gt; The binary compatibility problem is real, but I think it's more of a problem with the Java platform than with build tools. Actually its not just Java, if it was it would be a lot less painful. Scala actually has its own concept of binary compatibility, so with Scala we actually have to deal with 2 layers of binary compatibility, both at Java level and at Scala level. This problem then gets even worse with Scala.js and Scala-native (which also have the Scala notion of binary compatibility and their own version of binary compatibility respectively). This is how you get these crazy matrix's &gt; Which version of Opam were you using? I am fairly sure this is solved with Opam 2, i.e. go to https://opam.ocaml.org/blog/opam-2-0-preview/#A-few-highlights Mainly &gt; Compilers as packages: This brings many advantages for opam workflows, such as being able to upgrade the compiler in a given switch, better tooling for local compilers, and the possibility to define coq as a compiler or even use opam as a generic shell scripting engine with dependency tracking. In this regard, such packages can actually depend on a specific version of a compiler (even MetaOcaml) so you wouldn't have this problem.
Of course I don't disagree, I was just trying to provide some context to the comment that was originally being made
&gt; Alas, I find Eclipse even more ugly than Atom based editors And on Linux I find IntelliJ a gruesome site ;-) Not to worry though, you'll have IntelliJ with Dotty support; everyone else will have to make do with something less than an IDE (from your list, debugger will be the most missed).
I have not seen any constructive discussion in /r/programming
[Meanwhile](https://blog.jetbrains.com/kotlin/2017/11/kotlinnative-v0-4-released-objective-c-interop-webassembly-and-more/).
Hah, I'm on Linux, and I love IntelliJ ;) But yeah, I guess IDEs and editors are really "personal" issues that get to one's skin, that's why we're all so passionate about them.
&gt; that's why we're all so passionate about them. Same goes with languages to some degree. We can build similar applications in Java to what can be achieved in Scala, but the experience would be rather more dull and unpleasant.
&gt; organise/clean imports Does IntelliJ do that right yet? I disabled it because it really did not understand Scala imports, especially related to imports from local objects and stratified package declarations. I even have to go to my file browser when I want to move files around the package structure, otherwise IntelliJ tries to refactor them and the imports and always messes up (didn't find an option to keep IntelliJ from doing that!).
&gt; Scala seems to be the only exception here. If you are going to have binary compatibility than make sure your bytecode is ultra stable (i.e. Java) else you cause a lot of pain. Isn't this what TASTY was supposed to fix? I haven't been following the progress on that front.
Yes, with few exceptions: - it doesn't remove greyed out imports if they contain renamings (doesn't break compilations) - in certain cases, when you have red squiggles, it can result that types used in the code marked errorneous are not considered to be used (rare) 
I would disagree here, though. There are applications which are simply not feasible in Java that are possible in Scala.
Language development by itself will unlikely ever be financial success on its own. What's nice for JetBrains, is the fact that we can (and do) sell tooling, so direct monetisation of language is not required from us. Kotlin/Native allows us to enter new markets where nicely toolable language (Kotlin is designed with tooling in mind, after all) is desired and JB tools would be a natural tooling solution then. 
I have looked at kotlin a few times, it's interesting, but it's not scala. Ultimately i use scala because it allows me to use "fancy" features like macros and a touch of functional programming (sometimes forgetting vars exist). The main reason i'm looking at kotlin is a frustrating one: tooling. Right now i'm using two editors: intellij with the scala plugin for complicated things when i need ide like features (though it's cripled beyond reason, and very much not a pleasure to work with) and sublime (without things like ensime, ensime is a constant try and restart pray i get it to work for one highlight/refactoring, then restart again cause it broke), just basic scala highlighting) for simple text wrangling. Ironically it's also the reason i'm skeptic of kotlin, for me intellij has a proven track-record of delivering broken things (2 year old reported bugs/issues are left ignored as can't be fixed (the shared source root problem) and false negatives are as bad as ever). Me myself i'd sooner use rust instead of kotlin native and plain js/typescript/purescript when i need to work in a browser client. I think dotty has the potential to be a game changer for scala for two reasons. Firstly dotty linker https://d-d.me/talks/scaladays2015/#/26 (i hope these sheets from 2015 are still actual) has to potential to make scala more than viable for andriod where bytecode size and emethod count come at a premium. These optimizations will hopefully carry over to scala js and native as well, allowing one to make a scala server and client (js the webclient, scala jvm for android clients, native for ios client) based on a single codebase (where the client codebase can be glue to a more platform native client). But for this to pan out, 3rd party projects (the sbt-android project, a future ios implementation/bridge) are needed, and must become part of the scala eco system, i'm not sure it'll happen, there is potential, but it developing this way is currently not the way of least resistance) The second, probably more immediate benefit that comes with dotty is the language server and vs code plugin, if it can deliver most ide like features it will be a huge blessing to the entire scala eco system. But seeing kotlin mentioned as a scala alternative is troubling, because it really isn't, it's more scala light. Yet the more topics like this get mentioned the harder it will be to change this perception, which makes that scala does not only have a tooling problem, but also a perception problem, pushing it more and more in a certain niche. Still before it's worth it to work on scala's perception problem tooling must improve, my sbt files have comments like "i don't know why this has to be here, but without it things break" and it might be a testament to my stupidity, i'm afraid it's just as big a testament to sbt's obscure rules/scope/configuration system. And unfortunately i don't see dotty helping in that regard.
&gt; some mythical code re-use between servers and mobile platforms with completely different memory management semantics. !
Java does android fine, and android in completely unreleated to JS and native applications. The reality is that people are far more likely to be using javascript to write their iphone app than they are to use kotlin to make their web app. Support Kotlin and make it better, but don't run around with blinders on.
Sure, that's why I said "similar", much like Kotlin can provide poor man's Type Classes and HKTs via reflection hacks.
&gt; 1) Considering that Google is backing Kotlin I think in a few years it will be the dominant language for Android. Well, Google is also backing [Flutter](https://flutter.io/faq/#who-makes-flutter) which uses Dart although I'm not sure how popular it is compared to Kotlin.
Hi folks, I think that my experience is valuable here. I consider myself, both, Scala and Kotlin developer. I work as a software engineer in one of the biggest Scala companies in the UK; I landed in this job (as a South American immigrant) 'cause my experience and knowledge in Scala. I owe Scala a lot. I love Kotlin, and I have contributed to it from the very beginning, I'm one of the few persons in the world with five years of Kotlin experience (I'm the creator of funKTionale, one of the functional libraries for Kotlin, 29K downloads per month). I also contributed to the Kotlin support for Spring 5, and I was the original author of RxKotlin, now maintained by other members of the community. So, I'm profoundly invested in the Scala's future, my job depends on it, and any change affects me... I'm also invested in Kotlin, from a purely personal perspective. JetBrains does not pay me in any way (Does some stickers and t-shirt count?) nor I'm a sock puppet account. And to be honest, I don't believe that anyone is being paid by JetBrains to come here to troll this forum, such accusations are preposterous. If there is any incident of trolling in the past or present is due to fanboyism a problem that also exists here. Now to address the original points: 1) Android. Yes, the war is over, Kotlin will reign supreme here for a long time... but, Google can still try to attract iOS developers to its community. Recently Google clone the Swift's GitHub repository in its account. 2) iOS. Just for enthusiasts, Apple will not support Kotlin. But **right now** is possible to have projects with both targets (Android and iOS) with a single code base. &gt; Remember that Kotlin became famous for Android since Google supported it. Without native support from the company, I don't think it will become a viable language. Kotlin didn't become famous in Android because Google support it. Google support was just the official confirmation, but the language was heavily used by many, many big companies (including Google itself) before that announcement. 3) Desktops apps. Do you remember when cloud ides were in fashion? None of them survives. Not all applications are possible to move to the Web due to security constraints and others. Being said that, I don't see a huge use of Kotlin for desktop apps outside the JVM (there is TornadoFX, a nice DSL wrapper over JavaFX) as right now Windows isn't supported yet in Kotlin/Native 4) Web apps/backend. Spring Boot is miles ahead of Scala in adoption, and Pivotal invested a lot in Kotlin for Spring 5. They also have support now for Reactive applications. I don't have yet tried and compare it with Akka/Play, but I see how it can be adopted by the Java community easily. Kotlin also has other frameworks such a ktor and http4k 5) System software. I agree with your statements. Just for hobbyists 6) JS. If your backend and Android code are already on Kotlin, it makes sense to write your web code in Kotlin too. Recently I did a lot of web work in TypeScript and is, indeed, very nice. For me, it makes sense for TypeScript to be successful than any other language right now. Now, what advantages have Kotlin over Scala (I reckon that anyone here is aware of Scala awesomeness) * The language itself is easy to pick and learn but is deep enough if you want some language nerdiness, e. g. Coroutines. There is even a proposal to add a form of HKT (by one member of the Scala community none the less). Those features will take a while to appear in Java * Related to the first one, The language is more straightforward to parse, therefore is easier to create tools around it. IntelliJ support at this point is almost on par with Java. There are less refined plugins for Eclipse and NetBeans too. * Gradle (with and without Kotlin DSL) is nicer than sbt. * Java interoperability is straightforward. Kotlin Collections are Scala collections with a pretty façade (and I don't expect them to rewrite the entire library anytime soon). Kotlin enums are Java enums and so on. It just works. And it works with the whole Java ecosystem. From a Java Developer perspective, it looks awesome * Binary compatibility between versions. I repeat, **Binary compatibility between versions** * Marketing is way better. As /u/simon_o pointed in other threads before, compare Kotlin &gt; Statically typed programming language for modern multiplatform applications 100% interoperable with Java™ and Android™ Now official on Android Build Applications For JVM Android Browser Native and Scala &gt; Object-Oriented Meets Functional &gt; Have the best of both worlds. Construct elegant class hierarchies for maximum code reuse and extensibility, implement their behavior using higher-order functions. Or anything in-between. Scala says nothing, is a word salad. Which problems does it resolve? What do I want to use this? What is anything in-between? Where and how I can execute this? I do think that, if adequately addressed, this competition will (and is already) create a weapons race that at the end will benefit both communities.
&gt; Because of the complexity of inferring types (which is needed for everything, from completion to rename to refactoring), the GUI gets locked frequently In a good IDE, no matter how much work needs to be done in the background to get proper language support, the UI should never freeze. I think VSCode implements this pretty well: even if a language server blocks or crashes, the UI is still responsive because communication with the language server is always asynchronous.
To be honest I don't really understand the appeal of Kotlin. Scala gives some tangible benefits over Java (monadic for-comprehensions, FP via Scalaz or cats, type-safe automated serialization libraries via macros). What does Kotlin have over Java other than nicer syntax?
It is not enough. What's really needed is replacing jars/class files as the primary distribution algorithm in Scala altogether. So you need a module format, that includes types trees, but also versioning, dependency and linking information. If compilation was built around that, these modules could be distributed, and code could be generated from these modules for whatever backend the user is using.
&gt; The language itself is easy to pick and learn but is deep enough if you want some language nerdiness, e. g. Coroutines. There is even a proposal to add a form of HKT (by one member of the Scala community none the less). Those features will take a while to appear in Java As much as you have some points, here is some contradiction. Either the language has some "nerdiness", then it will be hard to pick up and learn or it won't, then it's probably not as expressive. So you can either say Scalas "nerdiness" is useless or not worth it or you say that its features are implemented in a bad way and Kotlin does it better. Otherwise Kotlin is either not as expressive (I think that's it) or it is equally hard to pick up (seems like that could happen with all the HTK and typeclass proposals). But that is not necessarily a bad thing! So actually... &gt; From a Java Developer perspective, it looks awesome ...this makes me *not* want to try out Kotlin. I hope you are wrong, because this is not a compliment to language design.
But there are lots of languages that are totally practical for large codebases. And actually, I think that a lot of Scala's benefits are advantageous to small codebases. To me, what makes Scala different is that it's pretty good at not taking shortcuts to provide a feature that scratches a specific itch. Instead, it tends to try to find generalizations, which should ideally combine flexibly with other features. That tends to result in the language being fertile ground for the exploration of all sorts of patterns and abstraction of those patterns into libraries. I wrote my first message because I think we suffer a bit in this community from a certain level of insularity, and it ultimately harms the accessibility of the community to newcomers. I want to challenge us to change that.
If we came to the Kotlin subtext and derided Kotlin the time, and pointed out that your language was simple syntax sugar over Java, and that Java 8 plus some minimal libraries (which already exist) would obviate the need for your great tooling altogether, how would you respond? We don't because Kotlin isn't a step to fix the bad parts of Scala or Java. It isn't even really a language. It's a macro library on top of Java with a library and a marketing department. Google chose Kotlin because there is 0 learning curve, the apis don't need to change, and your syntax keeps them from being sued over copyright infringement. We don't care enough to troll. But your users abbr community love it. That's enough for me to say that I don't ever want to be involved with the language. Scala users fight with each other over what we think is best for the language. We don't troll each other. There isn't a vein of antintellectualism in Scala like in other programming communities.
I don't understand why you replied to my comment. Where did you see me supporting Kotlin. I have been a Scala developer for a very short time, mainly Java. I just wanted to understand why the so called Kotlin Lang is better than Scala. I invest my time in learning Scala so I was just curious. See my history of comments on Reddit. I have been active in the Scala community. I have not made a single post on Kotlin community. There are too many kotlin trolls here and the community is so pissed off that anyone talking about kotlin is considered as a troll? I am not one of them and at least read my Reddit community history to understand.