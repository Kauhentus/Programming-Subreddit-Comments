Actually this saying came from hospitality, and this statement &gt; The Majority of people are rude under normal scenarios. Isn't actually true.
Thanks for the response. That looks easier to grasp, I think. Would the library also support multiple assertions in a test block?
I think the largest impact this will have is on the SBT roadmap. They have to support modules in order to get along with Java 9. That said, it'll be a while before Java 8 isn't supported anymore by major libraries. Lightbend most assuredly has this on their roadmap and will attempt to support it.
An important takeaway from the talk. "You don't need to be a FP master to use scala". This is something that everyone should keep in mind. Scala code can be both OOP/imperative and FP and its just fine as long as they play well with each other.
There are two answers to that question: - You can always have multiple tests in a test block. Each test runs independently: the surrounding block is run once per test, which is a bit expensive, but avoids inter-test interference - You can assert multiple things in a single test. Currently, we only report the first exception. It used to be `assert` with multiple expressions failing would wrap them up in a `MultipleFailures` exception and throw that, but we never really fleshed out that feature. We *could* re-implement that and properly show the contents of each of the exceptions thrown in a single assert, if people would find that useful.
Yeah... Nah. 
To be clear, we are talking here about JavaEE and not Java.
You don't have to use ConductR. You can use sbt-native-packager and deploy where ever you like. I would use it to deploy using docker/kubernetes using it: https://www.lagomframework.com/documentation/1.1.x/java/Overview.html#deploying-to-other-platforms http://developer.lightbend.com/guides/lagom-kubernetes-k8s-deploy-microservices/ 
&gt;&gt; spoon feed your documentation to random dudes on the internet who feel like you owe them something, and don’t know how to use a browser. &gt; And in the end he says that "applicants need not apply" – so he apparently just wrote this to vent a bit and to express his views on things. Q.e.d. PS: Maybe you should think what it says about a community if people feel that the only safe/reasonable/... occasion to voice their opinion is on their way out.
As someone who has written hundreds of ScalaTest tests and supported multiple teams through their writing of ScalaTest tests, this fixes alot of the pain points I've had over the past two years. Will be using uTest for my personal projects and trying to get my team to switch to this from ScalaTest.
Yes Twirl works really well. Especially if you're working with a designer because they like to work with all the regular file formats like HTML CSS and JavaScript. The only difference is that the HTML has a scala extension and will include some scala code. If you're not working with a designer I'd recommend udash as it lets you write the whole front end as scala including the CSS and HTML content 
Is it really not possible to write Java EE in Scala? I know you can write Spring in Scala.
Sam Halliday says his opinion all the time (which is completely fine), so I'm not sure what you mean. It appears that you want to make this about the Scala community as a whole but ... why? 
It is possible, but everyone is discouraging that approach and nobody is trying or advocating that approach. See [this discussion](https://www.reddit.com/r/scala/comments/6lrumr/using_spring_with_scala_bernhard_wenzel/) And this quote: &gt; The problem is that Scala can't be learned alone. One required to understand and feel all the environment and ecosystem to fully understand what Scala is. So, in my opinion, that is quite bad idea to use Spring with Scala.
&gt; What if I write just `(project in …).settings(…)` with no `def` or `val`? The `project` macro will fail the compilation. You can use `Project.apply` instead in those cases (e.g `Project("foo", file("foo"))`).
Are you using one of them?
He's clearly pretty frustrated with his experiences. That said, it doesn't make them invalid. I think sometimes inexperienced programmers expect spoonfeeding - there are many "please do my work for me" questions in /r/learnprogramming, in intro level college courses, or in mailing lists for popular projects with a lot of newbies (Spark comes to mind for me). I imagine ENSIME also has many newbies because of its broad appeal - anyone who prefers a text editor over IDE. Its not necessarily something wrong with the ENSIME community or Sam, it is possible that the userbase for this kind of project is just more demanding.
I agree. Maybe they have a purpose, but I find that ScalaTest's FunSuite is perfectly good and easy to read. test("name") { assert(something) }
I don't use lagom, but for akka I use kubernetes/sbt-native-packager
Latest version of Web logic three 3 years ago, Jetty on some current projects. The biggest problem I have with JavaEE is the threading model, which is much less scalable than the rector pattern used by alternate frameworks like Netty or Mina.
The problem with @fommil is that he's arrogant *and* lazy: when I called his "development method" lazy that they don't want to fix *major* bugs(they just tell you to fix it for yourself or wait for GSoC) which make his product useless I was called a self-entitled asshole. Reading the docs? How about using your own project and checking out how many bugs there are? I know it's not fair to compare ensime to an IDE but I found it better to just rely on unix tools or just use intellij than to use such an instable tool as ensime. At the end of the day *you'll spare system resources and time*. And he's talking about how bad is it to "encourage privileged behaviour" but when I was talking to him he acted like he's the next Steve Jobs or something.
&gt; People are rude, arrogant, expect you to spoonfeed them, and will then turn around and shit all over you because your hobby project doesn't perfectly solve their completely different use case. Oh, and how about the case when you don't solve major bugs just let others do the hard parts and you make an annoucement like "it's a 'hacker' tool, you need to 'hack' on it, noob" or something like that and when people call you out for a half-assed, buggy experience you just call them assholes? Now, that's ensime and fommil for you.
Spring works fine with Scala. I still haven't warmed up to sbt yet though. I want to like it but it seems like it was made up on the fly with basically no planning. This is backed up by the fact that even minor releases are syntax incompatible with previous versions. The syntax is cryptic and over all it's hard to learn.
&gt; No, I mean what's your use case for an Option/?-like type at all? Every time I give an example of a nested use you say you can use Seq[T] or Either[KeyNotFound, T] instead of ?[T], which is true as far as it goes, but it's just as true for non-nested uses. As I've told you a hundred times, ?[T] is supposed to exist for optimization(if don't have zero-cost abstractions) and it'd work pretty good for most of the use cases of Option. &gt; That's a completely backwards way to think about it. Awkward, convoluted code is precisely when you most need the language to stay predictable and consistent. Wrapping everything into each other and use high-level and "convoluted" constructs like monads already gives you a lot of awkwardness. And our solutions are all predictable. &gt; Right, so it isn't a sum type. Well, then nothing is a sum type because everything is a compiler thing. &gt; I prefer the ScalaZ implementation final case class Empty[A]() extends Maybe[A]. The standard library implementation does behave equivalently in all reasonable code, so one can argue that it's an implementation detail, but fundamentally the use of Nothing is a performance hack and not a style I endorse (indeed I'd say it's more in line with what you're advocating - the use of Nothing is there to reduce memory usage and allow faster comparisons). So, you prefer creating more useless pointers... &gt; Wtf? What does that mean? If I write class MyClass is that a "new null"? No, it's just a plain old Scala class. `case object None extends Option[Nothing]` is not a hack which is supposed to be a new null? &gt; Almost all ordinary classes in Scala can, at least in theory, be null at runtime. String can be null. UUID can be null. Date can be null. Seq[Int] can be null. If you write a class MyClass then that can be null as well. There's nothing special about Option here, and making a non-nullable replacement just for Option is effectively zero progress towards fixing this, unless you're planning on writing non-nullable replacements for every other class in existence, one at a time. What's the use case where ? helps with the general problem? Is this the first time you've heard about nullable types? Option is not a solution for null - it's just an expensive treatment. In pure scala, you can't be null-safe. With ?[T] and with the typesystem's support you'd be. &gt; Plenty of languages don't have pointers, you just... don't put them in the language. Implementations may use pointers, but those are an implementation detail. A language that needs to interop with C will have to have ways to handle C pointers, but that doesn't mean allowing pointers in the language proper. Are you serious? Did you know that in `val x = "abc"` x is a pointer? &gt; Right, but if you're going to be creating wrappers and checking nullability in any case, then you can just have the wrappers represent anything that's nullable on the Java side as an Option on the Scala side. So whether you use Option or ? makes no difference to how safe it is. Option can't guarantee null-safety on scala's side: since null is a hack it should be treated specially. &gt; You're not thinking this through. How can the typechecker tell whether a generic function is safe to pass ? into or not? As I've said: forbid nesting. Done. &gt; If you have some def foo[T](x: T): T you have no way of knowing whether foo is going to form a T? somewhere in its body. You might even compile against a version of foo that doesn't, but then you run against a different version of foo (library upgrade) that does. Type errors come at compile-time. You'll be ok. &gt; So either you get very surprising random breakages of your program, or you can't use ? types in generic functions at all, which means you can never have a Seq[T?], you can never have a function (value) that takes or returns a T?, which in turn means you can't ever use any higher-order functions like map/fold/filter... you'd lose all the point of using Scala in the first place. There are languages with nullable types and they're fine. &gt; What if you don't realise it needs to be a ? inside until later? It's easy to switch code from Either to Option because they're both lawful monads and so lots of functions are written generically and will work correctly with either of them. But you can't write code that works with both Either and ? because you can't tell when it's going to result in nesting ? at which point everything goes wrong. Sorry, 1. it should be `Either[KeyNotFound, T]` and not `Either[KeyNotFound, ?[T]]`; 2. if you introduce nesting at one place then you'll need to update the usage at the "end of the code" anyway.
Why the distinction?
https://code.facebook.com/posts/300798627056246/relicensing-react-jest-flow-and-immutable-js/
Great timing, thank you. Though I would still like to know what people use in production and why. 
I had an experience working in such project. In my case spring was used only as dependency injection tool and was so unnecessary, as entire application was built using cake pattern. There is a saying in my country that "better is the enemy of the good". I mean that spring is probably the most that can be squeezed from limited Java syntax, and other frameworks too, but considering alternatives in Scala, they appear to be much better and far more elegant when learned to use: twirl template engine for PlayFramework compared to jsp, slick compared to any java solution (i know it's not ORM, but many argue that this is another advantage), actually usable scala-js compared to gwt Those are the few i happened to use and scala alternative is significantly better. 
https://ima.org.uk/membership/becoming-chartered/chartered-mathematician-designation/
ScalaTags by itself would be too low level to build a dynamic UI (not comparable to React at all), you would want some other library, possibly based on ScalaTags.
I've used scalajs-react (the older version, we never got the chance to upgrade to the latest API--the dangers of technical debt). Anyway, while Scala is great on the backend etc., I wouldn't use it (i.e., Scala.js) on the frontend any more. Unfortunately I simply spent too much time on the edit-compile cycle waiting for compiles (and then bundling) to finish. You really, really need the frontend feedback loop to be as close to instant as possible. That's why I'm looking seriously at other stuff nowadays, which I won't mention here but you can ask if interested or just google my handle, you'll easily see what I've been upto.
What you don't understand, Matthew, is that ensime is not (and never has been) about you or any customer. It is about empowering users with Free Software, not a single promise more. ensime is not a company, you are not the customer, you are not right. You are not as important to me as my unborn child, who is far more deserving of my attention. I don't know why you have chosen to insult me in such a public way. Others have been able to understand my exit note perfectly well: I leave it to them to explain it to you as I have no interest in your understanding of the world. I'm just another burnt out contributor who is being pissed on and seriously regretting ever trying to help in the first place. If the Scala community wishes to burn it's contributors and label them toxic as they bow out, then the community will get exactly what it deserves. People like me don't really care about the opinion of people like you, and we will continue to do what we do best regardless. I'd like to clarify a very important point: ensime is not seeking a maintainer. Had you read the post correctly you would realise that all users are the maintainers now.
Do you mainly use Play or what other HTTP routing, authentication, session, etc libraries do you use?
*Do you mainly use Play* *or what other HTTP routing, authentication, session,* *etc libraries do you use?* ______________________________________________________________________________ ^^^-english_haiku_bot
Oh you're this guy who spends all his time on reddit trolling people. Yeah, I remember you. You seem to think I owe you something. But I do not. It is people like you who have caused me to give up on maintaining ensime. I want you to know that whereas the opinion of Matthew and others in the contributor community causes me great frustration, your opinion has always caused me to laugh. Your expectations are ludicrous and disconnected from reality. Everything you say only strengthens my argument, you're living proof of the entitled user who completely misses the point of free software. I genuinely feel sorry for you: the realisation of the power that I gained from Free Software was transformative, you have not (yet?) realised how lucky you have it.
I'm not sure I buy the 'uTest only gives you _one_ way to write a test' argument. ScalaTest and specs2 also allow you to [choose one style](http://www.scalatest.org/user_guide/selecting_a_style)--as simple or complex as you're comfortable with. In this context, uTest is just another choice among the existing ones. Ultimately, I still have to choose. And ScalaTest's [RefSpec](http://doc.scalatest.org/3.0.1/#org.scalatest.refspec.RefSpec), though JVM only, is hands-down my favourite for its KISS approach. I symphathise with the 'matcher pollution' argument, but it's also essentially an argument against abuse of implicits polluting the namespace. Still, I do mostly stick with ScalaTest's `assertResult` and `assert`. And your smart assert looks really cool. The one thing that I ultimately judge a test library by is, how does it format assertion failures for the user to understand? Does it make it easy, or does it force me to diff the output 'by eye'? Here's an example from Facebook's Jest: ● array › is equal expect(received).toBe(expected) Expected value to be (using ===): [1, 2, 3] Received: [1, 2] Difference: - Expected + Received Array [ 1, 2, - 3, ] Notice how it prioritises the user's time. This is the kind of detail I appreciate.
I think it's fair to say that many people are afraid to speak up in the scala contributor community about the pressures and expectations that they face. Especially when it comes to code of conduct matters. However, I have never been one to shy away from honesty so it would be uncharacteristic of me to need an exit note to express what I feel. Nothing in the note is different to what you can read elsewhere. Now, rather than me being terse on issue trackers, there will be silence. Decide for yourself which is better. The reason why I say nobody need apply is because there is nobody to apply to. Who are you going to ask? Not me... I'm gone already.
&gt; You really, really need the frontend feedback loop to be as close to instant as possible Sure, this is a pain point, but Scala.js turnaround time is actually much faster than the backend (Play) in my experience. Being able to code in the same language across the board, sharing code seamlessly between client/server is a real nice-to-have. Bucklescript indeed looks amazing, but the thought of diving into an entirely different ecosystem and rewriting recently completed Scala.js app is not at all appealing at this time ;-)
Rewriting for the sake of rewriting is bad, fair enough 😊 I'm actually not sure nowadays that sharing code is all that valuable. I mean, sure, I can theoretically do that with any language that has a JS transpiler along with its usual VM or native compiler, but I don't know that it'd be a reason to stick to a single language everywhere. With something like Apache Thrift, I can define my types and services once, and autogenerate domain/client/server code for almost all languages I'm interested in. And so I can get to work with something like Akka HTTP on the backend and BuckleScript/Reason on the frontend, or whatever my preference is. Best language for the job on each end, without having to drag one along with the other for the sake of code sharing.
I... huh, [yeah that's about right actually](https://i.imgur.com/MCVmA3y.png)
As a Scala noob I'd just like to give a shoutout and big thanks to the kind folks working on doobie and fs2 and cats for their patient help! Y'all the real MVPs. 
I just use scalaz and scalatags.
&gt;when I called his "development method" lazy that they don't want to fix major bugs &gt; which make his product Do you really think that Ensime was *his* product? Btw, what is his development process? Please, be detailed.
&gt; when I called his "development method" lazy that they don't want to fix major bugs(they just tell you to fix it for yourself or wait for GSoC) which make his product useless I was called a self-entitled asshole. Well, that's a bit harsh. Ensime is open source software, but it's not a "product" in the sense of e.g. Visual Studio Code - no one is being paid for fixing a bug. I don't know if he was rude in his interaction with you but it's not such a radical opinion. I just paid some money to the developer of magit, a git interface, so that he can afford to spend his time working on a tool I depend on. 
Every project in sbt needs to be uniquely identifiable. So you want to derive that id from the name of the val. What should the id (and base directory) be for a project created like the below? def createProject = project
You might derive the ID from the name of the folder it's in, and allow that default to be overridden if necessary: // id = "foo" (project in file("subprojects/foo"))… // id = "bar" (project in file("foo") named "bar")… As for what to do if someone says `project` and nothing else, you might take that to mean the root project.
&gt; Do you really think that Ensime was his product? Well, he was the harsh developer when I criticized it. &gt; Btw, what is his development process? "Fix it yourself, we don't care but it works, even if it doesn't".
At last fall I've tried ensime in atom and sublime and *literally* nothing important was working in them. Rename-refactoring was supposed to work in vim but it was one-file only - which is useless. Despite their claim, it didn't work in neovim. The emacs version was unstable and it often failed to start - only local renaming worked. The type-popup on the values often showed nonsense. When the build configuration changed or when I didn't call ensime's exit functionality and just exit from the editor I needed to regenerate the entire ensime config and the ensime cache - these are already enough reason to lable ensime as not ready to release to the public. When I've reported this they said they'll fix it but they didn't do anything. I assume most of them only used ensime for a little time and then abandoned it. Half a year later they said the rename-refactoring was fixed in GSoC. I criticized what they do and call their method lazy as they don't put much effort in it. fommil was enraged.
Twitter realized that years ago. Look at their projects - they utilize simple yet powerful parts of the language barely touching FP and complex types.
&gt; Oh you're this guy who spends all his time on reddit trolling people. Yeah, I remember you. You're trolling me right now because you're trying to blame me for the "stress" with ensime's development when we've only "talked" with each other once - and you couldn't take my critiques. Also, where did I troll someone, darling? Or is that trolling when I call out software with a lot of bugs? Do I not have the right for free speech? &gt; You seem to think I owe you something. But I do not. You don't and I've never said that - you just advertise your unstable software as a "hackers' tool" and that's unfair to the users. False advertisement is still false advertisement - even if it's "free" software. &gt; It is people like you who have caused me to give up on maintaining ensime. I want you to know that whereas the opinion of Matthew and others in the contributor community causes me great frustration, your opinion has always caused me to laugh. Well, if someone calls out your buggy software and literally the only thing you do is "laugh" and go on a trolling crusade then I'm sure I don't want to use your software or work with you ever. Free software != be irresponsible. &gt; Your expectations are ludicrous and disconnected from reality. Well, you either work on a software properly or don't - if this is "disconnected from the reality" you should think about it more. I wasn't asking YOU to fix the bugs I've found - I've asked others. But you're the one who was throwing around excuses about "free software" and "hacker editors" etc. about not fixing major bugs. *I love free software*, but people like you are the reason it's not widespread - because you don't care about quality, you just tell the users to fix it themselves(when it's clearly not cost-effective) or just to go away. Calm down. &gt; Everything you say only strengthens my argument, you're living proof of the entitled user who completely misses the point of free software. I genuinely feel sorry for you: the realisation of the power that I gained from Free Software was transformative, you have not (yet?) realised how lucky you have it. This sounds like big piling piece of pseudo-religious jerking - spare me, please. Free software is software. Software supposed to work as you describe it in the documentation. If your software can't do the *most important things from its mission* and people critize you for it then think about the critiques instead of going defensive. 
Deriving the id from the base name of the specified base directory sounds interesting. But that would (by default) make sure that a project's id and a project's base directory are consistent, it does nothing to ensure that the val name (i.e the compile-time identifier of the project) also matches.
LOL ^ this guy. Idobai, with open source software, you give away your code, not your time. $20 bucks says this guy wasn't a bountysource donor.
Do you know why bucklescript / ocaml compiles much faster than scala.js. I would of thought ocaml also has syntax quite different from javascript also.
Yes, we do the software is visible here: http://demo.openmole.org.
Well, if your software is so bad that the most important stuffs don't work then you don't give away anything but headache to the users. But of course, you can all play victims and preach about "free software" after your garbage software are called out... &gt; $20 bucks says this guy wasn't a bountysource donor. Why would I support broken software?
&gt; Why would I support broken software? So that someone can afford to take the time to fix bugs? You just complained about Ensime because no one would fix the bugs for you. 
&gt; So that someone can afford to take the time to fix bugs? If they don't care about their **own** software as much to fix critical bugs then why would I support them? Before I support certain developers I usually check out if their software works at least and they really care about it. &gt; You just complained about Ensime because no one would fix the bugs for you. Nope, I complained about ensime because it's broken but someone advertise it as "hackers' tool" and preaches about free software like it's an excuse for no quality. If you don't care about your software then say that.
&gt; This is backed up by the fact that even minor releases are syntax incompatible with previous versions. This is the problem with Play framework
&gt; ?[T] is supposed to exist for optimization(if don't have zero-cost abstractions) and it'd work pretty good for most of the use cases of Option. So what do you believe those use cases are? Because any time I come up with an example, you tell me I didn't actually want `?`/`Option` for that use case. &gt; our solutions are all predictable. They're not. If I have a function signature like `def doSomething[A, B](f: A =&gt; B, a: A): B` I have no way to know whether that works the same way when `B` is a `?` type or not). &gt; Well, then nothing is a sum type because everything is a compiler thing. `Maybe` is a sum type because it's a, well, sum of two legitimate types, `Just` and `Empty`. No compiler magic, just plain old Scala classes. (Likewise for `Option`, though as you've pointed out `None` makes use of some questionable features - but they are still standard Scala features that any plain old class can use). &gt; In pure scala, you can't be null-safe. With ?[T] and with the typesystem's support you'd be. How? Show me how `?[T]` makes Scala more null-safe than it currently is. `?` doesn't and can't make java interop null-safe, and Scala without java interop (and I guess with wartremover, if you want to insist) is already null-safe in practice. &gt; Are you serious? Did you know that in val x = "abc" x is a pointer? Edit (somehow missed this the first time): No. It may be implemented as a pointer, but that's an implementation detail. At JVM level it's a reference, but in well-behaved code it will behave as a value. &gt; As I've said: forbid nesting. Done. &gt; Type errors come at compile-time. You'll be ok. No, think about what you'd have to do to implement that. It's completely impossible, and this goes to the heart of the problem. As a trivial example, imagine something like: // version 1 of library.jar class Wrapper[A, B](f: A =&gt; B) { def apply[A](a: A): B = f(a) } // application code, separate jar def fetchUser(id: Id): User? = ... new Wrapper(fetchUser).apply(...) // version 2 of library.jar introduces a cache class Wrapper[A, B](f: A =&gt; B) { private[this] val cache = mutable.Map[A, B]() def apply[A](a: A): B = map.get(a) match { case null =&gt; map.put(a, f(a)) apply(a) case b =&gt; b } } The application code is safe when it's compiled, passes all its tests, the new version of the library is compatible with the old so it's a drop-in replacement at runtime - and then in the rare case where `fetchUser` returns `null`, the code breaks completely and silently (going into an infinite loop). &gt; There are languages with nullable types and they're fine. They lack Scala's selling points though. They're inherently more cumbersome to use than Scala and always will be. &gt; if you introduce nesting at one place then you'll need to update the usage at the "end of the code" anyway. You have to change the ends but not the middle, that's the whole point of using generics. But with `?` you can never just change a generic parameter to be a `?` type, you have to go through every single line of the intervening code to check it's never put inside a `?`.
&gt; So what do you believe those use cases are? Because any time I come up with an example, you tell me I didn't actually want ?/Option for that use case. I tell you that because you're trying to force nesting where it's inappropriate - because nesting is rarely useful. &gt; They're not. If I have a function signature like def doSomething[A, B](f: A =&gt; B, a: A): B I have no way to know whether that works the same way when B is a ? type or not). Then show me a function like that which is not predictable. null exist for a long time and code using null could be still predictable. &gt; Maybe is a sum type because it's a, well, sum of two legitimate types, Just and Empty. No compiler magic, just plain old Scala classes. (Likewise for Option, though as you've pointed out None makes use of some questionable features - but they are still standard Scala features that any plain old class can use). Empty is compiler magic - the typechecker's magic. And T | Null is a legitimate sum type too. &gt; How? Show me how ?[T] makes Scala more null-safe than it currently is. ? doesn't and can't make java interop null-safe, and Scala without java interop (and I guess with wartremover, if you want to insist) is already null-safe in practice. Enforcing to make T to ?[T] if you can pass null will make it null-safe. java interop can't be solved without wrappers. &gt; No, think about what you'd have to do to implement that. It's completely impossible, and this goes to the heart of the problem. No, it's not impossible, check out languages with nullable types. Meta-information can exist in libraries see: macro libraries. &gt; As a trivial example, imagine something like: ...The application code is safe when it's compiled, passes all its tests, the new version of the library is compatible with the old so it's a drop-in replacement at runtime - and then in the rare case where fetchUser returns null, the code breaks completely and silently (going into an infinite loop). What you're showing me here is incorrect because map.get should return with Either[KeyNotFound, User] - and you can't use nesting anyway because the typechecker would see it: its type signature would be ?[?[User]]. &gt; They lack Scala's selling points though. They're inherently more cumbersome to use than Scala and always will be. Scala is harder to use than it could be and it has major performance issues. &gt; You have to change the ends but not the middle, that's the whole point of using generics. But with ? you can never just change a generic parameter to be a ? type, you have to go through every single line of the intervening code to check it's never put inside a ?. No, the compiler needs to go through them.
How do you avoid duplication without code sharing? For example, reverse routing, form validation, typed identifiers (value classes), domain model, etc. I don't think code sharing is merely convenience, it unifies the application, everything, including the build definition, lives under one roof. In the case of Scala/Scala.js it just so happens that the development experience is laggy; were this not the case you'd very likely not mix front and back ends. Perhaps in future Dotty will reduce development lag. Obviously achieving Bucklescript turnaround times isn't in the cards, but a 2-3X speedup would make a huge difference. Anyway, I'm watching Bucklescript, with Reason ML cleaning up OCaml's crufty syntax it does look appealing, enjoy. p.s. oh, forgot about HKTs and type classes on the front end ;-)
&gt; I tell you that because you're trying to force nesting where it's inappropriate - because nesting is rarely useful. `Map#get` is literally textbook use case for `Option` or `?`, but you're saying it should return `Either` instead. So it seems you don't believe there are many use cases, which means this probably shouldn't be a language-level special case &gt; Then show me a function like that which is not predictable I already did, with my two implementations of `Wrapper`. From the outside they both have the same interface. &gt; Empty is compiler magic - the typechecker's magic. What are you talking about? `final case class Empty[A]() extends Maybe[A]` - nothing magic there, it's a plain old Scala class. &gt; Enforcing to make T to ?[T] if you can pass null will make it null-safe. Or just ban `null` from your own code (using Wartremover if you really need the compiler to enforce it), and then you're equally null-safe. &gt; java interop can't be solved without wrappers Exactly. So `?` doesn't help. &gt; you can't use nesting anyway because the typechecker would see it: its type signature would be ?[?[User]] No, because that type never appears explicitly in code. All the typechecker can see is `?[T]` - and then, far away, in a different jar, the code calls a generic method with `?[User]`. Which of those two things is the typechecker going to ban? Ban either of them and you make `?` pretty useless, but if you don't ban either then you have the nesting problems.
&gt; Map#get is literally textbook use case for Option or ?, but you're saying it should return Either instead. Map#get would be better with `KeyNotFound | T`. Most languages throw exceptions btw. &gt; So it seems you don't believe there are many use cases, which means this probably shouldn't be a language-level special case. What? &gt; I already did, with my two implementations of Wrapper. From the outside they both have the same interface. But the 2nd version won't compile for the reasons I've told you. &gt; What are you talking about? final case class Empty[A]() extends Maybe[A] - nothing magic there, it's a plain old Scala class. If it's a class but when it's an object it is a hack. However, if it's a class it's even worse for the GC... &gt; Or just ban null from your own code (using Wartremover if you really need the compiler to enforce it), and then you're equally null-safe. Scala libraries will still be there. &gt; Exactly. So ? doesn't help. 1. It can make scala null-safe; 2. it improves performance and decreases memory consumption. On the other hand Option without zero-cost abstractions are almost useless and only appealing to those who don't care about performance. &gt; No, because that type never appears explicitly in code. All the typechecker can see is ?[T] - and then, far away, in a different jar, the code calls a generic method with ?[User]. If Map#get returns with ?[T] and then you pass fetchUser(Id): ?[User] then it's pretty obious what will happen - you know, we can see generic types from libraries too and we can see more with macros. &gt; Which of those two things is the typechecker going to ban? Ban either of them and you make ? pretty useless, but if you don't ban either then you have the nesting problems. Ban both of them and the code will be better. ?[T] doesn't fit the use case for map#get.
&gt; I'd like to clarify a very important point: ensime is not seeking a maintainer. Had you read the post correctly you would realise that all users are the maintainers now. I seriously would like to use ensime for my ide-type-of-project, but the main obstacle is that almost no documentation exists. For example, at some point on the website, you are referred to http://ensime.org/server/ for details on the server protocol, but that page is virtually empty. This of course is a major problem of almost all voluntarily run open source projects. For example, I have just started documenting my SoundProcesses project that has been going on for seven or so years, and I notice how opaque it must be for anyone except myself. This is a crazy amount of effort, probably as much as writing the actual code. So if you want ensime to be sustainable, it will be important the documentation is there - how do I write a language client from scratch, how is the code base organised etc. - then you have much greater chance that other users can meaningfully keep developing the code.
thanks for all the work, don't forget that happy users are the quiet ones, the ones that are using ensime every day with their job to hack away, and are generally happy about yet. Of course, ideally, they'd be supporting you and helping with code, but as you can see now with children, usually it's not so simple to work out.
&gt; If it's a class but when it's an object it is a hack. Much less of one than nullable types, since the object version behaves exactly like the class version as far as any well-behaved external code can tell. &gt; Scala libraries will still be there. Very few of them use `null`, and those that do will still be there if you introduce nullable types. If you're going to go through the effort of rewriting libraries that use `null` it would be better to just remove `null` from the language. &gt; If Map#get returns with ?[T] and then you pass fetchUser(Id): ?[User] then it's pretty obious what will happen But I didn't call `Map#get`, I just called `new Wrapper(fetchUser)`, and `Wrapper` makes no mention of `?` in its external interface. The whole notion of composition is that I should be able to understand the combination by understanding the two things separately, but your `?` undermines that: you can't combine two things unless you understand every internal detail of the two things, because they might interact differently depending on those internal details. &gt; Ban both of them and the code will be better. So you can't form `?[T]` for a generic type `T`, and you can't pass a `?` where a generic type is wanted? That makes `?` a really second-class type, really not usable in substantial codebases or reusable library code.
&gt; I think it's fair to say that many people are afraid to speak up in the scala contributor community about the pressures and expectations that they face. Especially when it comes to code of conduct matters. I'm sure this is true for many people, but I just felt that it isn't true in your case, as suggested by Simon. Anyways, thanks for your contributions to free software. I read that you are about to become a father, so enjoy the time with your family. 
Thank you, /u/fommil! I really have come to appreciate the work you have done for the community with ENSIME. I admit, I have been playing around with potentially contributing for awhile now but I always felt a bit intimidated by the idea and felt worried that I would be good enough. Because of this, I'm going to get involved and see how I can help. Losing you is a blow to the community, but hopefully this will shock more of us out of complacency.
Scala.js compiles slowly because Scala compiles slowly. The Scala.js-specific part of it is fast in comparison to the shared part. Scala compiles slowly because its typechecker has a lot of work to do. It may be that OCaml's typechecker is much faster because there is an intrinsic reason in the type system that makes it easier to compile. But I'm only guessing.
Yes, a few reasons. First, the OCaml compiler has to do way less than the Scala compiler--it doesn't have to do implicit search in various scopes, or method resolution through an inheritance hierarchy, etc. Also it doesn't have to do forward lookups because all names must be defined before they can be used. Secondly, the BuckleScript part of the compilation, after the OCaml parsing, typechecking, etc., is also very simple because of the almost 1-1 correspondence between OCaml and JavaScript semantics: modules-modules, functions-functions, arrays-arrays, tuples-arrays. Finally, another huge time save is that BuckleScript doesn't have to do any linking: it just spits out modules 1-1 corresponding to OCaml input modules. A module bundler like Webpack or (my favourite) the ES6 bundler Rollup does the next part. Or if you're deploying to node, you don't even need to bundle since node natively supports 'require'-type modules and will load them at runtime.
Go fuck yourself stupid troll, I know you're just a freshmen without a job who's trolling everyone around. You haven't done anything in your life besides posting bullshit on scala's ask-anything and "show-off" threads.
&gt; Much less of one than nullable types, since the object version behaves exactly like the class version as far as any well-behaved external code can tell. No, they're not because the class version have the generic type and the object version is always Option[Nothing]. &gt; Very few of them use null, and those that do will still be there if you introduce nullable types. If you're going to go through the effort of rewriting libraries that use null it would be better to just remove null from the language. If you remove null from the language the compiler and the standard library won't compile because it's used so much. &gt; But I didn't call Map#get... Doesn't matter. See: macros. Type erasure is indeed an enemy here but with reflection and macros we can fight it. &gt; So you can't form ?[T] for a generic type T, and you can't pass a ? where a generic type is wanted? That makes ? a really second-class type, really not usable in substantial codebases or reusable library code. Yes, you can use it as a generic type. Also, Option is already a third-class type which wastes resources. If you don't care about system resources then this discussion will have no fruits.
Yes, some duplication is inevitable 😊 but as I mentioned, I can at least autogenerate my domain types and service template from an interface description language. I'm looking forward to Dotty as well, but I actually don't mind OCaml syntax, it feels sparse and clean compared to ... but let's avoid flame wars 😉 OCaml functors let you encode HKTs and typeclasses ... of course with the caveat that you manually pass in the type ultimately.
&gt; OCaml functors let you encode HKTs and typeclasses ... of course with the caveat that you manually pass in the type ultimately. Have you tried using OCaml functors for this kind of applications? You're probably going to need first class modules too at some point, and in my experience the syntax is very unwieldy and verbose. Until modular implicits are here, I think the experience is not great.
I'm a newbie at Scala, but I think that SBT is always mentioned because is the official building tool for Scala. I don't catch what is the madness you're pointing to. And what has Rust to do with all this? What is the part of the Scala.js tutorial where you got stucked?
 If 1000s of people are able to make something work that you can't, perhaps it's user error?
&gt; It may be that OCaml's typechecker is much faster because there is an intrinsic reason in the type system that makes it easier to compile. But I'm only guessing. OCaml's type system is extremely regular and well-behaved. There are no implicit parameters (at least currently), no implicit conversions, no overloading, no implicit subtyping-based coercion (almost). Most importantly, there are no cross-module cyclic dependencies: if you want the definitions in two different files to refer to each other, you'll have to manually write an explicit interface for one of these files. This is not as big a problem as one may think, in a very parametric language like ML. It also forces some good design practices. 
I did not understand what you're doing on r/scala after you've left with a storm but I've left scala too not so long ago and now I see... Btw, the community was always shit and it's usually shit everywhere, don't expect anything else.
This isn't specific to ScalaJs, but: If you are using a more powerful language, and paying for its compile time, you need to be using the features it provides to prove correctness, raise abstraction, and generate code at compile time. That means using the type system, separating execution from the description of the program, macro and code generation, etc. These tools can help to mitigate the need for keyboard smashing. Separating encoding from execution in particular can allow you to output a data-type representation of what your code should do when interacting with a ui, leaving the interaction between the browser and your logic as a separate interpreter for that encoding, where you wire up external libraries that you mock out and test that your code calls the mocks appropriately. This should keep the need to run experimental hack - compile - load - rewrite cycles to a minimum. The reason you do that in raw js is because the language is not sufficiently expressive enough to not do it that way. I understand that react is a great tool in js to limit unnnecessary rendering in the browser, however, for data model transformation, you'd be better off writing your own template rendering as you would in a server application, and managing your own component updates. If it were me, I'd use something like (scala.rx)[https://github.com/lihaoyi/scala.rx/blob/master/readme.md] to manage the interpreter that outputs and responds to dom changes and to manage the client-side model. Couple that with a decent dom integration like Snabbdom-scala and you have a testable before running it application. Note that after the initial compile, incremental compilation makes testing cycles short. For after your unit test and compile time stuff, a full integration test suite on the client with your compiled app outs necessary. This runs on your fully compiled app, acting as a user. The time saved by simple engineering solutions and feature use of a compiled language over hacking is what you are buying when you use a language like scala. You have to pay for that in compile time and learning curve - but often the easiest (most-familiar) implementation does not buy you enough productivity to be worth using the language. It's not meant to be try rinse repeat - it's meant to stop that cycle at the compile stage.
I have. In fact I've even [used it in Scala](https://github.com/yawaramin/scala-modules). It's about trade-offs. The functor syntax is verbose, but the rest of OCaml is sparse and elegant. Given the overall picture, OCaml still wins in terms of succinctness.
&gt; However, I have never been one to shy away from honesty so it would be uncharacteristic of me to need an exit note to express what I feel. Nothing in the note is different to what you can read elsewhere. One thing I found interesting is that the people who don't want that honesty are more often than not looking for new ways to keep escalating the situation. It's never "we disagree with each other, let's just leave it at that" it's "I'll keep antagonizing people withe wrong opinion until they are gone, regardless of the damage caused to the community".
&gt; No, they're not because the class version have the generic type and the object version is always Option[Nothing]. Well-behaved code can never observe that distinction though. `None` behaves exactly like `Empty[A]` for any `A`. (Don't get me wrong, I don't like the use of the magic `Nothing` type, but it's a relatively minor issue because it's properly encapsulated, it can't ever affect unrelated code) &gt; If you remove null from the language the compiler and the standard library won't compile because it's used so much. Sure, but that's equally true if you made the language and compiler track nullability and require any value that's ever `null` to have a `?` type. &gt; Doesn't matter. See: macros. Type erasure is indeed an enemy here but with reflection and macros we can fight it. Using reflection on all generic code paths would cause a much bigger performance problem than a handful of extra object instances ever has. It's not like macros - macros are expanded where they're used. Being able to pull out code into independent functions that can be understood separately is utterly fundamental to the very idea of programming. &gt; If you don't care about system resources then this discussion will have no fruits. I care about resources but I care more about correctness and maintainability. The cost/benefit for `?` just doesn't stack up: either it isn't used enough to be worthwhile, or you disallow using it in a generic way which makes it too limited to be worthwhile, or it's used widely in which case nesting will happen in surprising places and cause surprising failures.
&gt; Sure, but that's equally true if you made the language and compiler track nullability and require any value that's ever null to have a ? type. Yep. You know - ?[T] is just my "theory" for scala, right? We are not going to have that. I'm not going to work on the scala compiler. I'm not working with scala right now. &gt; Using reflection on all generic code paths would cause a much bigger performance problem See: macros. &gt; than a handful of extra object instances ever has. "Handful", yeah... &gt; It's not like macros - macros are expanded where they're used. Being able to pull out code into independent functions that can be understood separately is utterly fundamental to the very idea of programming. Macros can access the AST. &gt; I care about resources but I care more about correctness and maintainability. The cost/benefit for ? just doesn't stack up: either it isn't used enough to be worthwhile, or you disallow using it in a generic way which makes it too limited to be worthwhile, or it's used widely in which case nesting will happen in surprising places and cause surprising failures. Cost: almost 0. Benefit: getting rid of Option's overhead. I see we disagree strongly.
So you're saying you did the tutorial, bit didn't use the tool they mentioned (SBT) and it didn't work? I'm shocked.
You know that you've hit mainstream when you get random rants completely devoid of any technical argument. Thank you for that!
😁
What do you mean by 'data model transformation' and 'managing your own component updates'? Your descriptions, if I understand correctly (including 'Separating encoding from execution'), sound like exactly what React already does. (Scala.rx is marked as experimental, btw.) Ultimately, you are saying that it's not necessary to reload your app all that often while you're developing it because you're thoroughly testing its behaviour with type-level proofs and unit and integration tests? That sounds great--but it all adds to my edit-compile-test cycle. I'm still not saving any time, in fact it looks like I'm adding more time to each iteration to wait for those tests to finish.
&gt; In fact I've even used it in Scala Scala has modules (and path-dependent types) as one of its core functionalities, so that's not surprising.
Yes. I have used scalajs-react, scala diode with Lagom micro services framework. Shared code across ui, gateway and micro services is a great value add. Coupled with play json derived codecs library for json parsing, the code reduction is really significant. Sure turn around time may be an issue, but ability to use full ide for ui development is a great plus.
if the bastards are gona censor my posts and comments then TO HELL WITH SCALA, since it dont work anyways.
The lessons I learned from the documentation in Scala is that documentation shapes the community. It's not that you have poor documentation because people don't care about it, it's that poor documentation acts as a filter which pushes people away who care about good documentation, leaving only people who don't believe that documentation is important. Given the stance of people in charge, it's unlikely to ever change. ENSIME didn't cause this situation, but it suffers greatly by the environment created by Scala.
I think this is the same troll as /u/sbtisabandonware with a new account and persona.
&gt; You know - ?[T] is just my "theory" for scala, right? We are not going to have that. I'm not going to work on the scala compiler. My point is that there's no realistic path to improving Scala's null-safety where `?` is substantially helpful. The only possible case for it is the performance one. &gt; Macros can access the AST. The macro can access the AST where it's invoked. Not the AST of every function that block calls. That AST probably doesn't even exist if you're calling a library function (at that point we only have the compiled jar). &gt; Cost: almost 0. I see introducing language-level special cases as a huge cost. `?` wouldn't just be a library type, it would have to be in the language spec, it would have to be special-cased in the compiler, the typechecker, the macro system, IDEs or any other such tools... &gt; Benefit: getting rid of Option's overhead. But in all my examples you've said `Option` should be replaced by something with more overhead. Making `Map#get` return `Either[KeyNotFound, ?]` would be more overhead than having it return `Option` as it currently does. Passing around `User` instead of `Option[Car]` would be more overhead, as would using `Seq[User]` instead of `Option[User]`.
I have to disagree. Of course, it is valid to ask all of these questions but would anyone really do that? I doubt that. When a newcomer sees code like this, he can without any problem read it, he probably won't understand how it works under the hood, but he can still understand the purpose. And he can as easily modify it. Without any knowledge of the dsl it is extremely easy to add/remove/modify the test case. I agree that having DSLs tends to be harmful for newcomers but IMHO it does not apply here. Btw are we talking about someone not familiar with DSL or with scala? "How do you find the definition of any of those symbols?" Why not just ctrl-click it in decent editor?
&gt; What you don't understand, Matthew, is that ensime is not (and never has been) about you or any customer. It is about empowering users with Free Software, not a single promise more. ensime is not a company, you are not the customer, you are not right. You are not as important to me as my unborn child, who is far more deserving of my attention. The customer here is people using the software. I assume the software is being made for people to use? I am not even talking about rights, you don't have obligations to do anything since you are not being paid for it. I am talking about peoples expectations. &gt; I don't know why you have chosen to insult me in such a public way. Others have been able to understand my exit note perfectly well: I leave it to them to explain it to you as I have no interest in your understanding of the world. The intention wasn't to insult, apologies if it came across that way &gt; I'm just another burnt out contributor who is being pissed on and seriously regretting ever trying to help in the first place. If the Scala community wishes to burn it's contributors and label them toxic as they bow out, then the community will get exactly what it deserves. People like me don't really care about the opinion of people like you, and we will continue to do what we do best regardless. I can sympathise with the way you feel, but I suppose we have different fundamental viewpoints. As you said, you created the project because of your believe of empowerment of free software, I create software because I want to produce something that is useful for end users and these things aren't necessarily the same goal. Its unfortunate that Ensime got the feedback that you describe, but often these situations happen due to expectations. For a tool that is meant to help users, at least in modern day software development programmers have expectations which are quite high in this area (regardless of if they pay for it or they don't). In the case of IDE's/Editors, people often expect for things to "just work", and in the case of Scala this is unfortunate because the current state of scalac and its tooling is not the best I thin this wasn't easy for Ensime to achieve at all (hopefully this will improve with Dotty). I am personally of the opinion that something like Ensime should be officially part of the scalac compiler where they have the proper resources to deliver something that meets expectations &gt; I'd like to clarify a very important point: ensime is not seeking a maintainer. Had you read the post correctly you would realise that all users are the maintainers now. I already know this, also I don't see how this is relevant for anything
&gt; OCaml syntax, it feels sparse and clean compared to ... Syntax-wise neither language is beautiful, each carries significant syntactic cruft that would not exist with the benefit of hindsight. &gt; OCaml functors let you encode HKTs and typeclasses In Scala type classes entail a fair bit of boilerplate at definition site (compared to Haskell), but at use site they're a joy. This alone keeps me in the Scala/Scala.js fold, lag-driven-development notwithstanding ;-) When we arrive in the Dotty land the landscape may change for the better. 2019 or 2020 should be a good year.
You've got to be kidding. There is a huge amount of documentation, including videos, about the protocol, and a chat room. I suspect you missed a link somewhere.
That's intentional. The val name shouldn't matter, just like val names don't matter anywhere else in Scala. Nor, for that matter, should it even be required to stuff it into a val unless it's going to be referenced somewhere else in the build definition.
The ensime website is very clear that it is not a project seeking users, it is a project that is only interested in being accessible to contributors (and users who are willing to learn). In this regard, it has been a massive success. However, the prevalent belief in the software industry is that free software exists for the end user, a customer, as you mistakenly believe... it is this entitled attitude that zaps the will to continue out of maintainers. Your other points are so confused, and I have no interest in educating you further, here ends my interest in this thread.
This idobai guy is complaining about ensime-atom, one of the editors I have never even used far less contributed to. I have no idea why he feels it is my software or why I should fix it for him. ensime-atom is demonstrably not broken, as many people use it. Indeed it's about to get a rewrite thanks to community sponsorship, maybe in scalajs, but definitely using the LSP. I have spent a lot of brain cycles arranging this, it's extremely unfair to say I don't care or that I am in any way lazy. Sure, I'm not giving up my Friday night with my family to fix it, but I don't want to be that guy. ensime-server/sbt/emacs (the ones I contribute to) are demonstrably good quality: I use them every day. I am only interested in fixing the bugs that affect me, but I've always been keen to help anybody who wants to fix anything that's broken.
We'll, now now :-) I agree to is a jerk but I'm sure the world is better in some way for his existence, even if it is not evident on github or Reddit.
just FYI, ensime is not related to doobie, fs2 or cats ;-) We do however depend on scalaz and I would love to rewrite the server to holistically embrace the pure FP paradigm and fs2.
Maybe you can be more specific. This used to be a huge problem but it's getting better because many libraries/blogs/websites now use [tut](https://github.com/tpolecat/tut) or a similar tool to typecheck their documentation to ensure that it works. So there's really no excuse for example code that doesn't work.
For clarity in the build it's nice that both the compile name and the runtime name match. That way you don't need to remember if it's "libfoo" in build.sbt but "foolib" in the sbt shell, or the other way round. If you want to name them differently Project.apply allows you to - it's just a convention.
Why assign them to a val at all?
I can't comment about production use, but I'm a fan of Vue.js and put together a facade for it a little bit ago that I use for myself... Maybe you'll find it helpful as well? If others here have production experience between Vue and other options I'd love top hear about them, too. https://github.com/massung/scala-js-vue
"JetBrians" made me laugh
Shit now I'm dangerously close to wanting to become an ensime contributor
You feel no shame, do you? After raging on various subreddits, getting yourself kicked out and deleting your comments, you're the last person I want to hear this. You're a hypocrite here on so many levels... Also, you're asking for a github account [and yet...](https://github.com/kpws).
I'm surprised that you find the edit-compile cycle too onerous. (Of course people differ on how much they're willing to tolerate.) We follow a one-class-per-file (or as close as possible) and if you're using sbt's "watch" mode (e.g. "~ fastOptJS") we rarely see compile times in excess of 1-3 seconds if you're just tweaking minor things. (Of course if you're doing cross-cutting changes, you're in for a little bit of pain.) I don't think we've done anything particularly special to achieve that. One thing that I found to *really* help compile times was to add explicit type signatures for all public "component" symbols. If you do that, I believe it's much easier for the compiler to know when changes in code propagate out from a given component.
You're condescending and a lier. ensime-server wasn't working properly at all: rename-refactoring was only working in local(current file), startup often failed due to unknown reasons, the server wasn't stable enough for build config update or for an unexpected shutdown, the type-hints often showed false information. **I didn't ask YOU to fix it: I've asked others if they've time or are they planning it and they said YES. I only called your "development method" in a reddit comment lazy for waiting others to fix bugs while you are the "maintainer".** I don't know about the state of ensime now and I don't care. Your stupid excuses that it's a "hackers' tool" and your license won't make you immune to critiques. And for the clients: no, it wasn't just ensime-atom: neither ensime-sublime, nor ensime-vim nor ensime-(neo)vim nor emacs were working properly(maybe the latter). With neovim it never worked. ensime-atom/sublime lacked the most important features thus making the plugins useless. With vim only rename-refactoring "worked" - only for the current file. The emacs client was unstable and the previous issue was present here too but sometime the code-completion worked.
Yes exactly :-)
&gt; My point is that there's no realistic path to improving Scala's null-safety where ? is substantially helpful. The only possible case for it is the performance one. If you've an enforced nullable type then ?[T] can help in null-safety not just with performance and memory-efficiency. &gt; The macro can access the AST where it's invoked. Not the AST of every function that block calls. That AST probably doesn't even exist if you're calling a library function (at that point we only have the compiled jar). We can get every information in all libraries, we just need the libraries to store meta informations what macro libraries already do - the reflective calls would be invoked by the compiler at compile-time. &gt; I see introducing language-level special cases as a huge cost. ? wouldn't just be a library type, it would have to be in the language spec, it would have to be special-cased in the compiler, the typechecker, the macro system, IDEs or any other such tools... Don't make it that big, nulls are everywhere, ?[T] would just try to limit the usage of null. &gt; But in all my examples you've said Option should be replaced by something with more overhead. Making Map#get return Either[KeyNotFound, ?] would be more overhead than having it return Option as it currently does. How? And btw `Either[KeyNotFound, ?]` is invalid, I've shown you this: `Either[KeyNotFound, T]` which has the same cost and this: `KeyNotFound | T` which is the cheapest. &gt; Passing around User instead of Option[Car] would be more overhead, as would using Seq[User] instead of Option[User]. Why would Option[User] cost less than Seq[User]? And why would you assume that a user has only one car?
Yes, that's what I'm saying - it's a tradeoff. We try to model things so that they won't compile or can be run separately so that we can get something out of the extra compile times. I'm not particularly concerned about the experimental status of that particular library - there are others, including rx scala (RxJava) that model similar frp concepts. React is also the same idea, except that it is dynamic under the hood. The thing that I'm interested in is that the frp model used is statically compiled and type safe. That way I don't have to worry that all my pure transformations and tests are invalid because of some dynamic state in the model business logic. I can integrate with a dynamic library, but it takes some of the compile-time guarantees away and requires more integration (user simulation) testing, which in turn requires a full cycle. This saves you from the write a few lines - full compile - open in browser step for everything except for the browser event - render integration. And That should be handled by your library. So you only have to test user scenarios, which you can automate with Selenium, etc. This means that most of the stuff you would be verifying by hand gets verified by tooling, starting at the compiler. The full cycle is still long - but you are usually only working on a small subset of the app at a time, in isolation. If you don't code in this way, and want to code interactively, you just need to use a dynamic language. Scala will never compile fast enough to do interactive js coding like raw js builds do. Though most js builds today take a long time on large apps themselves.
Is @kpws your shadow account? Because his personality is matching yours and the way he shows of his "love" is suspicious... But it may not be true, because [his github](https://github.com/kpws) is pretty much a freshmen's account and he's just a zealot troll(still kicked from r/atheism after the flamewars?). I understand you like to play the victim and like your ass licked clean with cluless people after you shit over reddit from time to time but don't you ever read your comments? ensime is unstable af and you're trolling those who criticize it. Free software here or there, you wasn't helping anyone. Oh, you didn't see my github(you did, but I moved its content) so I'm not a developer? Well, what a magneficient measure! It's not like people have something like a job or there are other VCS hosting services...
&gt; The ensime website is very clear that it is not a project seeking users, it is a project that is only interested in being accessible to contributors (and users who are willing to learn). In this regard, it has been a massive success. And also appears to be its biggest problem. I wouldn't have considered it successful from the point of view it actually working to a sufficient degree to the editors I tried it with. I submitted bug reports and tried to be helpful and a fair bit of the time what I received in return was patronising attitude. I also considered contributing before however at the time I find the project too inpenedtrable &gt; However, the prevalent belief in the software industry is that free software exists for the end user, a customer, as you mistakenly believe... it is this entitled attitude that zaps the will to continue out of maintainers. This sense of entitlement that you believe in is a false one and it also appears to be the reason you are burned out. People generally don't contribute to projects not because its a license or because its "free software" or for other religious reasons, people generally contribute to software because its ultimately useful for them. Otherwise all that happens is that you only get a few contributors maintaining a massive project, and those contributors either burn out or the project dies. &gt; Your other points are so confused, and I have no interest in educating you further, here ends my interest in this thread. It would do a lot of wonders if your attitude was a lot less patronising, I don't really need to be "educated"
Yes, I do code interactively at least at the beginning when I'm just setting up my app and don't want or need to set up a whole set of unit and integration tests for user scenarios. This is why I'm using something that gives me type safety as well as instant compiles. I don't know what you consider a large app, but the Facebook Messenger team report that they can do a full build in about 2 seconds for the Reason (BuckleScript) part of the code, which is a few hundred files: https://reasonml.github.io/community/blog/
People have high expectations of a piece of software that is meant to replace some of the functionality from an IDE. &gt; I think sometimes inexperienced programmers expect spoonfeeding - there are many "please do my work for me" questions in /r/learnprogramming, I have to say, at least from personal experiences and also from reading issues on ENSIME, this isn't entirely true. Very few people were asking in a manner of "please do my work for me". I have submitted basic bug reports (to ENSIME and other places) and I think ENSIME was one of the only projects where I felt like I was being patronised because I didn't read through novels of documentation when basic functionality wasn't working. At the end of the day, attitude matters a lot more then people think. I have personally zero problem in contributing to projects that I use in my spare time (and I do so all of the time) but the mentality there really put me off
Yes, I follow one-class-per-file as well, and also annotate types on public members. I usually see ~4--6s on `~fastOptJS`, so I keep `~compile` going (~1--2s) and only generate the actual JavaScript when I need to inspect my changes. This is not even mentioning the sbt startup and dependency resolution times every time I want to come back to my project after working on something else. In contrast, with my BuckleScript workflow the incremental rebuild to the JavaScript bundle is ~1s.
This is a great example. Over 6MB of js though? Yikes
&gt; Oh, you didn't see my github(you did, but I moved its content) so I'm not a developer? Well, what a magneficient measure! It's not like people have something like a job or there are other VCS hosting services... You *literally just* insulted another user because of their GitHub account ... &gt; I understand you like to play the victim and like your ass licked clean with cluless people after you shit over reddit from time to time Jesus ... do you kiss your mother with that mouth? 
Been using ensime-emacs for a little over a year. Aside from occasional trouble when the server version and the elisp version didn't match (because I use spacemacs, which is not, technically, fully supported, and follows its own update rules) it has worked pretty well overall, allowing me to work better in Scala within emacs.
It's common to want a reference to the project, for instance for aggregating or dependsOn reasons. However why only vals of type Project are considered and not expressions of type Project is probably historical from the days of the Build trait, where you'd define each project, and then defined the seq of projects with an override (iirc).
I haven't used ensime for more than a year with emacs. According to the "rumours" someone fixed the rename-refactor issue in GSoC. Does code-completion work? Do you still need to regenerate the configuration after build-config update and occasional shutdowns?
&gt; LOL ^ this guy. Idobai, with open source software, you give away your code, not your time. $20 bucks says this guy wasn't a bountysource donor. I'm pretty sure he actually pays at least $20 (30€ w tax) a month now for his scala ide/editor. I do, because all the open source tools didn't worked when I started scala. but I would've probably spent my time/money more useful if they would at least have a experience that wouldn't render them as garbadge. (not talking about ensime in particular, because I basically only tried it once, with no luck)
&gt; You literally just insulted another user because of their GitHub account ... First, that user(who happens to be a troll) was asking for my github profile as a proof that I care about FOSS. If that scum runs here to call me a shit because he didn't see my github account then he deserves it. Btw, he deserves it anyway because he's a radical atheist/scala-zealot constantly raging everywhere and he NEVER makes any argument besides "this is stupid" or "you are stupid". New on r/scala? &gt; Jesus ... Isn't that true btw? Each time the guy comes here he attacks and insults everyone with **valid** critique and then plays the victim. Now he wrote a blog post playing the victim. Did he ever try to help anyone with any issue? I doubt that. As others say he is always condescending. But since ensime is famous he can get away with everything thanks to those 10 emacs fans "using" his software. After all, the scala community is still not immune to PR. 
I realize this is a troll, but here's a couple of Scala.js / React apps anyway: * https://github.com/ochrons/scalajs-spa-tutorial * https://github.com/Daxten/bay-scalajs.g8
&gt; If you've an enforced nullable type then ?[T] can help in null-safety not just with performance and memory-efficiency. There's no safety advantage over just removing `null` (and covering the use cases with option-like types) though. The reasons Scala has `null` are Java interop and backwards compatibility - but those same reasons make moving to enforced nullable types just as hopeless as enforcing complete avoidance of null. &gt; nulls are everywhere, ?[T] would just try to limit the usage of null. They aren't that common in user-level code, and while having `null` at the value level adds some complexity, I suspect a `?` type would add a lot more. Just as supporting checked exceptions is a lot more work for the tool ecosystem than supporting unchecked exceptions. &gt; Either[KeyNotFound, ?] is invalid, I've shown you this: Either[KeyNotFound, T] I used the kind-projector syntax out of habit, sorry. I meant the same thing you do. &gt; which has the same cost I would think slightly more - `Left` can't use the singleton hack that `None` does, and even compared to `Empty` it's got an extra field (and if we're not using singletons then we have the `KeyNotFound` instances consuming memory as well). &gt; KeyNotFound | T which is the cheapest. Not really on the current JVM - you could save memory by representing it as `Object` at runtime but at the cost of making all method calls dynamic. You're also opening the door to nesting problems again. &gt; Why would Option[User] cost less than Seq[User]? If the Seq has specialization for length 0/1 then that means a lot of subtypes so the methods are less JIT-friendly, if the Seq just contains an array then that has overhead compared to `Some` just containing a field. &gt; And why would you assume that a user has only one car? Maybe they're only allowed to register one car for their parking space, and we're storing the details to check. Again, if you don't think this kind of thing is a common use case, then why is it a big deal whether we use `?` or `Option` to represent it?
I am currently using Play in my private projects and akka-http at work, mostly for microservices. When it comes down to authentication i did not have to use anything advanced yet (At work i was working on sort-off public API), so can't tell you anything valuable. Play provides session cookie by default, it is signed using server secret, quite simple to use. Authentication in Play is usually done by action composition, you can learn more here: https://www.playframework.com/documentation/2.6.x/ScalaActionsComposition#authentication
Hm. It's unfortunate that compile time is so opaque. It's incredibly hard to tell what's taking how much time :(. (We have sort of an "opposite" problem to yours: CI build are taking absurd amount of time...) ... and you're right: It's more on the order of 2-5 seconds for me (just did a little coding session to confirm :) ); of course it depends a bit on hardware, etc. My computer at work is a little faster than the one I have at home.
Only used rename-refactor once (a long ago, I think it was on the same file while I was checking how to use ensime, so that one might have been broken all along as far as I didn't use it). Code completion has always worked well for me (after indexing). Have never needed to regenerate the configuration unless I added extra dependencies that needed indexing (not sure if it might be automated though, usually I don't add many new libraries after the initial setup)
&gt;Sure, this is a pain point, but Scala.js turnaround time is actually much faster than the backend (Play) in my experience. Being able to code in the same language across the board, sharing code seamlessly between client/server is a real nice-to-have. We use scalajs-react for a frontend project at work and the turnaround time (i.e. inc compile + `fastOptJs`) is around 5-10 seconds. For the same reasons I can see why people have two thoughts about recommending it, at least if you are an actual frontend developer doing UI work 
&gt; Only used rename-refactor once (a long ago, I think it was on the same file while I was checking how to use ensime, so that one might have been broken all along as far as I didn't use it). That's why I said that feature doesn't work - one-file refactor is not appealing at all and a waste of time from ensime's developers' side. &gt; Have never needed to regenerate the configuration unless I added extra dependencies that needed indexing (not sure if it might be automated though, usually I don't add many new libraries after the initial setup) Updating scala version, ensime version or accidentally closing the editor before the ensime-server can also kill your ensime cache.
&gt; There's no safety advantage over just removing null (and covering the use cases with option-like types) though. The reasons Scala has null are Java interop and backwards compatibility - but those same reasons make moving to enforced nullable types just as hopeless as enforcing complete avoidance of null. Then why nobody wants to enforce the removal of null? Each time I've proposed WartRemover.Null as a general I got sent/downvoted to hell. Outsiders also hiss on Option constantly. &gt; They aren't that common in user-level code, and while having null at the value level adds some complexity, I suspect a ? type would add a lot more. Just as supporting checked exceptions is a lot more work for the tool ecosystem than supporting unchecked exceptions. It's about safety, of course it'll introduce "issues" until the ecosystem gets used to it. &gt; I would think slightly more - Left can't use the singleton hack that None does, and even compared to Empty it's got an extra field (and if we're not using singletons then we have the KeyNotFound instances consuming memory as well). But if we've sum types then we don't need Left or Right, just the value. KeyNotFound is supposed to be a plain singleton object. &gt; Not really on the current JVM - you could save memory by representing it as Object at runtime but at the cost of making all method calls dynamic. You're also opening the door to nesting problems again. Tag the value because it's supposed to be tagged anyway. &gt; If the Seq has specialization for length 0/1 then that means a lot of subtypes so the methods are less JIT-friendly, if the Seq just contains an array then that has overhead compared to Some just containing a field. Chances are high your data-query mechanism can only return with Seq[User] which is capable of containing more than one result. &gt; Maybe they're only allowed to register one car for their parking space, and we're storing the details to check. Again, if you don't think this kind of thing is a common use case, then why is it a big deal whether we use ? or Option to represent it? It's a big deal for you, not me. I've only came up for ?[T] to reduce the overhead of Option. I also know about its shortcomings.
ClojureScript + Reagent? - hot code reloading (maintaining state) with Figwheel for instant feedback - clear code - works with React Native Pair programming tutorial: https://youtu.be/wq6ctyZBb0A One of the best kept secrets in web development.
I've heard great things about it. How is integration with the npm ecosystem, and how are compile times?
Notably, Ctrl-Click wony work here, because it's a magic stub syntax recognized by the Tests{} macro, so it's implementation is empty D= Not to say we couldnt at least put some useful scaladoc hints though
The concept and philosophy of servlets is decent - it’s meant to be a low level request/response primitive that’s used as a fundamental building block. The rest of the AbstractBeanPersistenceEntityAnnotationDrivenServiceLoaderFactory mess is utter dogshit, and should be recognized as the job security/sales obfuscation effort for IBM/Oracle that it is. When everything in your platform is essentially a java.lang.Object that gets resolved by runtime reflection via annotations you need to shit or get off the pot and admit that you’re writing something that is little more than JavaScript with static type assertions that apply to primitives. 
for some weird reason, they use fastOptJS. And no gzip.
Even if it was true, how are companies supposed to migrate from Java EE applications to Play/Lagom ones? Throw everything away?
Glad that yours is the most upvoted comment. Edit: reading now the torrent of bile below. Jesus. I cannot imagine the complexity of supporting 5 text editors, 4 build tools intersecting with dozen versions of the Scala compiler.
&gt; Then why nobody wants to enforce the removal of null? Each time I've proposed WartRemover.Null as a general I got sent/downvoted to hell. I can't speak for other people. Most of the codebases I've worked on lately (including professionally) have used wartremover or equivalent. I'm not sure we're in a position to remove null entirely from Scala just because Java interop is a big part of the value proposition for some people. &gt; Outsiders also hiss on Option constantly. Not any that I've seen. &gt; But if we've sum types then we don't need Left or Right, just the value. You mean union types, not sum types. As I said later on, I can't see how to implement that efficiently on the JVM. &gt; Tag the value because it's supposed to be tagged anyway. Tag how? Isn't that exactly what `Left`/`Right` are? Or are you proposing changing the JVM itself to use tagged references or something? &gt; It's a big deal for you, not me. I've only came up for ?[T] to reduce the overhead of Option. Adding special cases to the language is a big deal for me, as it should be for everyone, even - especially - if those special cases are rarely used.
https://github.com/search?q=org%3Aensime+mdedetrich&amp;type=Issues comments on 5 tickets, all fixed by us or closed because you didn't provide information. In many cases I personally helped until you had it working. Hedefalk has been very patient with you and fixed no less than 3 bugs that directly impacted you. You are so ungrateful and wrapped up in your own world of entitlement that, YES, oh my god, you do need to be educated. It has gotten to the point that when I see your name in an issue tracker or gitter chat thread, I disengage because you are such hard work. There is only so much patience a reasonable person can have for this, and if that makes me "arrogant" then so be it. I'd rather be arrogant and have time with my family than reach the end of my life and say "why, oh why, did I give up my life to try to be tolerant of Matthew... he never even listened"
Integrating Node modules is first class, see https://clojurescript.org/news/2017-07-12-clojurescript-is-not-an-island-integrating-node-modules. It includes Google Closure compiler optimizations. Compile times are fast when you do a non-optimized build. Under a second. And also the Figwheel hot code reloading usually takes under a second. See for example this demo: https://youtu.be/pIiOgTwjbes If you do an advanced build (aggressive dead code elimination and minification) compilation is slow. For my project at work (1.5KLOC) it takes a minute. 
I mean this with all sincerity Idobai, I think you need to speak to a medical professional. Your paranoia and aggression is not healthy and may point to a chemical imbalance. If that is the case, your behaviour is not your fault.
According to your question "using scalajs UI libraries in production", I don't know the usage of Binding.scala in private. However, I do know there are a lot of open-source projects written in Binding.scala, though I don't know if they are in the term of "in production" * [Granblue Raid Finder](https://github.com/walfie/gbf-raidfinder/) - A mobile game tool * [CITE Application](https://github.com/cite-architecture/CITE-App) - An end-user environment for working with data in the CITE environment—browsing and analyzing texts, viewing objects and images, visualizing graphs of scholarly data. * [word-cloud-generator](https://github.com/emanresusername/word-cloud-generator) - A browser extension to create word cloud Both Granblue Raid Finder and word-cloud-generator have huge number of users, though those users do not care about which UI library is beneath the application.
/u/fommil Thank you for all the burgers :) Hack the Tower hacking sessions on Ensime were legendary. And most of all thank you for showing me the one and only right way of developing software - Emacs way.
I use [scalajs-react](https://github.com/japgolly/scalajs-react) in production, in fact I'm the author of the library. If you're interested, there are [slides online here](https://github.com/japgolly/learning/tree/public/talks/20170913-ScalaSyd-ScalaJsReact) of a presentation I did on scalajs-react recently; a good chunk of it should provide insight to your question why I chose and use Scala.JS &amp; React.
You talk about paranoia when you got everything personally when I was criticizing your dev method... Dude, I don't value what you do and how you do it. I don't value you as a person either because you're an arrogant moron. Just because you've revived an old project and let others do what you want don't make you a super-developer. You are not special, you just lie and play the victim. No wonder why you wrote a rage-post...
&gt; I can't speak for other people. Most of the codebases I've worked on lately (including professionally) have used wartremover or equivalent. I'm not sure we're in a position to remove null entirely from Scala just because Java interop is a big part of the value proposition for some people. `Option.apply`, unless we need to pass the stuff. Then we can suppress the warning and it'll be obvious when doing reviews. &gt; Not any that I've seen. I don't think so, I've seen you many times talking with kotlin, c# etc. fans. &gt; You mean union types, not sum types. As I said later on, I can't see how to implement that efficiently on the JVM. Tagged unions are sum types. &gt; Tag how? Isn't that exactly what Left/Right are? Or are you proposing changing the JVM itself to use tagged references or something? Yep. I've imagination and the JVM limits us. &gt; Adding special cases to the language is a big deal for me, as it should be for everyone, even - especially - if those special cases are rarely used. Then why insist to use nesting?
SBT dont have any Technical info. its not like i can mention and say its a 404 error or something, since instead of giveing error codes SBT gives a endless list of things that no sane person can read, specially if even the hello world programs dont work.
IDEs are in Business of making billions by breaking back of Open source projects due to Jokers like you
yeap those like you affiliated with JETBRAINS. things work only for you since you get paid to not make things work, or to not document how to make them work.
So you believe people will put their energy in trying a SPA project when an simple HELLO WORLD dont work, when i say dont work it means i have followed all step and it just shows error, I AM TALKING ABOUT A HELLO WORLD PROGLKEM DAMNIT.
Definitely not closing the editor. Do it every day, and ensime starts just fine the next day. Updating scala version making the cache invalid probably is to be expected, though. Ivy cache also needs to be updated with that.
LOL, no one can build a company that has to rely on SBT
&gt; comments on 5 tickets, all fixed by us or closed because you didn't provide information. In many cases I personally helped until you had it working. Hedefalk has been very patient with you and fixed no less than 3 bugs that directly impacted you. Actually I spent a significant amount of my time diagnosing the issues with atom's backend with ensime with Hedefalk (the bugs which I reported), this was done over Gitter &gt; "why, oh why, did I give up my life to try to be tolerant of Matthew... he never even listened" &gt; You are so ungrateful and wrapped up in your own world of entitlement that, YES, oh my god, you do need to be educated. You honestly think that people reporting bugs is something to be considered ungrateful or entitled? Lets be clear here, I have no issue with Hedefalk, I actually spent a huge amount of time trying to get ensime working with atom (and by huge, I mean easily 20+ hours because I was having to debug ensime not working with a large project with mine combined with atom and this took a lot of time. All of this is public in the Gitter channel btw). I had no problem with this because at least I didn't feel like I needed to be "entitled" or "enlightened" for reporting issues. On the other hand, when I reported issues on Ensime (and I really do mean Ensime, this is the only project where I get this feedback), I got usually a combination of 1. Presumption I am doing something "wrong" even though ensime couldn't handle generating an ensime config for a standard `.sbt` definition. Just as you did a lovely job posting my github issues, lets have a look https://github.com/ensime/ensime-sbt/issues/138. We spent countless hours going back and forth debating that apparently my build.sbt was invalid (which ended up with the sbt guys stating that, it is indeed a valid build) 2. Another issue was closed without comment (I suspect this was because you couldn't reproduce but since you didn't even comment or even respond on how to provide a better diagnosis on it I had no clue so I gave up, https://github.com/ensime/ensime-server/issues/1541). If you left the ticket opened with possible a quick comment to docs (because at the time the documentation was sparse) I would have actually bothered diagnosing further. 3. https://github.com/ensime/ensime-atom/issues/177 (and others which is available on Gitter) is what I talked about before. Hedefalk was actually helpful on Gitter and provided me with how to diagnose issues with Atom &gt; There is only so much patience a reasonable person can have for this, and if that makes me "arrogant" then so be it. I'd rather be arrogant and have time with my family than reach the end of my life and say "why, oh why, did I give up my life to try to be tolerant of Matthew... he never even listened" So yes, thanks for listing my issues. It demonstrated that you appear to be the only person that has issues with bug reports. So either the entire software development community has an incredibly high tolerance for me in particular or that there something is wrong with your attitude. I am hedging my bets on the latter since you are literally the only person with this issue. P.S. Getting bug reports from users, especially if they are general issues where the software doesn't achieve the basic functionality that it advertised to provide (with ensime, this is actually working with `.sbt` definitions) is part of open source development. This is a blessing because you are aware of the prblems. The fact that you are "tolerating" this is probably more revealing than anything else, and explains a lot of the reasons why some people feel the way they do.
Nice article! I'm excited for the next one. 
This thread perfectly captures my experience of trying to discuss anything with you. You twist words, you write long rants, and you do not listen. You twist the hand holding and assistance I gave you in ticket 138 into something negative (and the *huge* amount of coding effect I have put into the scalaVersion problem), and you demand my attention to re-explain what you read when submitting 1541. Nobody ever said that raising bug reports was a bad thing. It's why our issue tracker is open and has a template. However, your ranting here in this very thread, making statements such as "the customer is always right" and insults such as "passive aggressive", "patronising" and "arrogant" show that you are not engaging with good will or best intentions. Indeed, the entire purpose of you starting the thread here on reddit was to try and initiate a personal assault against me. What were you trying to do, get lots of people to tell me that they think I'm an asshole and that they are glad I'm leaving, so I can feel completely depressed about all my contributions? Thankfully many good people have come out to try and explain things to you, which gives me hope that there is perhaps a silent majority of people who respect boundaries and want to write good code. I've blocked you from my personal account, and the ensime account. This is a temporary ban, because I think everybody deserves a second chance... I will reassess at some point in time. Right now I feel you are breaking our very simple rules of "Be respectful: do not demand the assistance or time of others" and "Be civil: don’t insult or threaten others". You're continuing to be personally insulting, it's very hurtful, and you clearly mean to do it. I wish you'd go and think about what that means for a moment, and also what it means for the scala community if the contributors are the ones who are burned at the stake.
Even if crashes and power outages are rare updating ensime cache was almost an every-day task - and it was slow and not granted to work most of the time. Of course, I couldn't use it at work because it was always having some problem but I've tried to make it stable at home(mission: failed). But it was a year ago and I'm glad there are people who don't go through all the issues...
I don't know what you're talking about. I've not used a Jetbrains product in years. 
But then why use Scala at all (on the jvm)? You are paying with longer compile times and unfamiliar syntax for simple sugar that is largely templated for you by existing tools in Java. Add early initializers, and it can actually be more difficult to code in class-based codebase. The standard library is nice, but as a library Guava already exists and Java streams take care of the stuff the standard library does with chaining sugar. Fluent interfaces are easy to write in Java, too. I have the same problem with this argument that scala without FP is worth it that I had with Rod Johnson - if you take away the FP, implicit classes, and typelevel programming from scala, you are left with syntax sugar over Java. Someone else could implement that as a simple set of expansions to java, and compile the java. You are paying too much for that small subset of features. Spend a few weeks learning the others, and your technology choice will pay back a bit more of the cost paid by compilation and technical risk in switching between Java and scala.
Jack Henry Twitter Verizon Lightend
&gt; if you take away the FP, implicit classes, and typelevel programming from scala, you are left with syntax sugar over Java That is what kotlin is exactly. It tries to be a better java, but it will sooner or later be irrelevant since Java as a language itself is getting modernized pretty quickly. I am convinced that for certain problems FP is better and for some OOP works well. The problem with real FP is that you focus on trying to write perfect code which is a fools goal. I think scala was designed on this concept i.e FP/OOP will complement each other rather trying to be better than one another.
Yes - that's exactly what I'm saying. I don't think OOP has much to do with FP from a business-logic perspective in scala. It is a way to build modules by composing stateless methods or of providing syntax sugar on top of typeclass instances. It also provides a left - right readable dot syntax for performing actions, and methods provide a boilerplate free way out abstracting things with type parameters that functions do not provide. I think one or two performance optimizations - memoization, and array operations, are easier to express as private vars on an instance, rather than some ST derivative, in scala because of eagerness. Maybe some simulations, or database pooling. Not fully convinced, partly because I haven't seen any really good non-imperative examples in the wild. Nobody really does encapsulated OOP that follows the SOLID principles. More people do pure FP than actually do more than imperative records with methods style OOP.
&gt; This thread perfectly captures my experience of trying to discuss anything with you. You twist words, you write long rants, and you do not listen. No one is twisting anything, this is all public information and I haven't misquoted anyone &gt; Indeed, the entire purpose of you starting the thread here on reddit was to try and initiate a personal assault against me. &gt; You're continuing to be personally insulting, it's very hurtful, and you clearly mean to do it. I wish you'd go and think about what that means for a moment, and also what it means for the scala community if the contributors are the ones who are burned at the stake. Honestly this is a case of the pot calls the kettle black. Did you even read what you have written? I mean you spent the entire thread saying that I was ungrateful, un-enlightened and that I need to be "educated". Heck let me requote what you said (which btw I had no idea originally that it came from you because you wrote it publicly on the main site which didn't have any author). &gt; being available 24/7 to spoon feed your documentation to random dudes on the internet who feel like you owe them something, and don’t know how to use a browser. If you don’t decorate your advice with salutations and graciously thanking them for trying out ENSIME, be prepared to be called arrogant, lazy and rude. My advice is to shut these people out of the project and not to tolerate them, but you will be ostracised by other groups in the scala ecosystem who wish to encourage such privileged behaviour. You will need thick skin to deal with both of these types of people. This is incredibly insulting to a big portion of the Scala community (or at least the people it was aimed at, which also appeared to include me) Believe it or not you are not the only person that has been insulted &gt; What were you trying to do, get lots of people to tell me that they think I'm an asshole and that they are glad I'm leaving, so I can feel completely depressed about all my contributions? I said it before, I honestly was trying to figure out why you said what you said. I was being courteous until here https://www.reddit.com/r/scala/comments/71pphu/new_maintainer_needed_ensime/dneh3ik/ where you made an "enlightened" comment that I need to be "educated". I didn't want to argue, nor did I want to insult. When I made my comments, I deliberately talked about Ensime generally to **not single out anyone** until you then responded and singled me out personally. &gt; I've blocked you from my personal account, and the ensime account. This is a temporary ban, because I think everybody deserves a second chance... I will reassess at some point in time. Right now I feel you are breaking our very simple rules of "Be respectful: do not demand the assistance or time of others" and "Be civil: don’t insult or threaten others". I think we both need time but after my experiences (which are unique to this project) I don't feel very encouraged to help out. I am not going to respond to you again because there really isn't any point. Best of luck in raising your new family.
I work at a company that is all scala and the reason you do scala is flexibility. For senior and experienced devs they can leverage more power of the type system, async first nature of scala, typeclasses, macros, pure FP. For those with less skill in those areas they write scala like better java (but still immutable first!). We get the best of both worlds where we can build powerful core libraries and services that are hard to misuse by juniors. 
My company Curalate also all does sbt, and we love it. Much better than our experience with maven 
I personally prefer the `test { ... }` syntax over `* - {}`for "anonymous tests". FWIW, Dotty may also change the infix parsing rules to allow line breaks before symbolic infix operators, causing the utest `*` identifier to parse as an infix operator applied to the preceding line. See https://github.com/olafurpg/scala-experiments/issues/3#issuecomment-266578054
Here's the step by step tutorial: * https://www.scala-js.org/tutorial/basic/index.html Also, you may have better luck on the scala-js mailing list, rather than a general purpose Scala forum on Reddit: * https://groups.google.com/forum/?fromgroups#!forum/scala-js
 MAVEN WAHT ?
Thats the same Tutorial, its not like there are 10s of ScalaJS tutorial out there and there cant be since people have to built one upon another, if we cant get past hello world we will have to try Rustlang so there wont be another tut out there. Only few will use Scala JS since it dont work as shown in the tutorial, and the reason is the same why scala mostly is useless i.e. SBT. and btw just because most of you have used Maven dont mean every Scala newbie is a JAVA programmer, we dont know Maven nor we care about Maven, we are just interested in Scala the language.
So ? Just because you dont know Nazis personally dont mean they didnt Gas the Jews,
If the companies really need to re-platform their insanely outdated and messed up legacy Java app(s) and are willing to hire a group of people who know what they're doing with Scala and are willing to protect them from incompetent and paycheck leeching Java devs, yes throw everything away once new and better Scala app(s) is/are ready.
If you want people to contribute directly with code it needs to be approachable. This means that not only does the code need to be approachable but also the documentation. The documentation but becomes much more important the more complex the project is, and ENSIME falls into this category. I mean I am still unsure what the underlying issue was, but (for example), if you supply a bug report to scalac, people don't expect you to read through ploths of documentation or to contribute directly since it's a language compiler. And this "handholding" which is negatively viewed on ENSIME is actually expected, you can't expect users of scalac to understand the complexity of the compiler just to submit a bug Scala didn't create this environment, it happens in communities where people mistakingly believe that code = documentation and where people are "too smart" in the code they produce. ENSIM unfortunately is solving a very complex problem as well
&gt; Option.apply, unless we need to pass the stuff. Then we can suppress the warning and it'll be obvious when doing reviews. Sure, which is what we do today when working with wartremover. In principle I'm all for putting the warning in Scala proper, sure, though it would make very little difference to me in practice - I'd still want to use wartremover for the sake of its other warnings, and in any case it's not something you can do by accident, so the warning isn't particularly vital. &gt; I don't think so, I've seen you many times talking with kotlin, c# etc. fans. Most of whom regard `Option` quite positively. I did see one extreme Kotlin fan claiming it has too much overhead, once, but I've never known anyone to complain about it as a language construct - quite the opposite. &gt; Tagged unions are sum types. Tagged/disjoint unions are semantically equivalent to the `Option`/`Either`-like types I've been advocating all along. `|` means the other kind of union, which is not a sum type. &gt; Yep. I've imagination and the JVM limits us. How do you imagine implementing this, and what semantics would it have at the language level? Code written in terms of `Option`, `Either` or shapeless coproduct is much more consistent with the behaviour of tagged unions than code written in terms of `?` would be. (For the record, if you're talking about something that's not implementable on the JVM - not merely more efficient in some other implementation - then you're not talking about Scala any more in any meaningful sense - at that point you might as well start from Haskell or something) &gt; Then why insist to use nesting? It's just the opposite: I insist that nesting shouldn't be a special case. `F[G[T]]` should work the obvious way for *any* types `F` and `G`, it shouldn't magically do something different for one particular type.
In Dotty they decided to use [the LSP](http://dotty.epfl.ch/docs/usage/ide-support.html) which as I understand it basically provides the same functionality as Ensime. LSP seem to have gained some popularity (Rust also uses it for example) so Ensime might become an unnecessary project in the future.
/u/olafurpg want to open an issue and reference this discussion? Then perhaps you, or someone else, could throw together a PR to do the deprecation and update =)
tbh the whole webpack-babel-npm-cycle thingie is not 0s either.
does scala js compiler use scala compiler? how does it work? Is there some presentation on pipeline or something ?
Done https://github.com/lihaoyi/utest/issues/127 I'm planning to port the scalameta/scalafmt test suites to utest once I find the time. Want scalafmt on native! The new utest reports also look nice :)
When you are doing local development its usually max 1's (and this if from a cold boot). If you are doing the incremental compilation version its basically almost instant Source: Work with UI developers who moved from Scala-js to plain ES6 Javascript (they also use the babel-npm-cycle lifecycle)
There's a presentation about the pipeline here: https://www.youtube.com/watch?v=nRswfBJL0dQ In a nutshell: the Scala.js compiler is a compiler plugin for scalac. It generates .sjsir files in addition to the normal pipeline of scalac. Then, there is an additional *linker* that gathers all the .sjsir on the classpath and links them into a unique .js file.
Yeah this is what I meant by the comment, achieving what ENSIME wanted to achieve was too much work for this point in time (considering the state of scalac/presentation compiler/SBT and the amount of different protocols ENSIME had to support). Also the stance that the ENSIME community had probably didn't help. This kind of functionality should be provided by the core compiler (since you need to share things like the typechecker anyways). Also you always get mismatches between scalac and ENSIME and you have to mess with things like ClassLoaders to separate out different Scala versions
It can even be higher, it depends on the libraries you use. If you are using stuff like scalaz/shapeless/cats it can get much higher (although I don't think that cats is as taxing as the other two because the cats team did a great job in not trying to stress scalac too much)
Hi /u/fommil, Congratulations on becoming a parent soon and best of luck on your future endeavors. When an open source project is no longer fun for you, just give up on it. As long as you're not getting paid and under contractual obligations, you don't owe anybody anything. It is my experience that maintenance of an open source project is a huge burden, therefore people don't rise to the challenge unless forced, just like people don't pay for stuff, unless there's scarcity. If people really need ENSIME (and I think they do, since it's a popular project), somebody will eventually pick up the maintenance burden, otherwise, if the project withers, then giving up on it was the right call anyway. Cheers,
OCaml's subtyping is explicit when liskov substitution is performed, and there's only one type system to infer. Scala has two type systems to infer, and true subtype polymorphism to deal with. Put another way, classes are bolt - ons with special compiler rules in OCaml.
ConductR (which is not strictly required to run Lagom services) is not free as in free speech (it's not open source), but for development and small setups it's free as in free beer: * The ConductR Developer Sandbox is available free for development purposes. * Use of ConductR for production purposes is free for 1 node, no license required. * Production use of ConductR for 3 nodes is free with registration. * Production use of ConductR for more than 3 nodes requires the purchase of Lightbend Enterprise Suite. 
I generally agree this talk, but in some regards he isn't entirely correct. For example with DI in play, they are actually moving away from Guice because very few people who do pure Scala code use Guice (and either `implicits` or subcut/macwire are better alternatives in Scala). Other than that it is a really good talk, if you work in a large company you can sympathise with a lot of the experiences that he has to deal with
I'm currently translating CorsixTH (https://github.com/CorsixTH/CorsixTH) C/C++ boilerplate/bootstrap code from C/C++ to Scala. It's something quite big, and don't know if I could done this someday, but I'm trying...
Nice! On a related note, we started an effort of translating to Scala the Haskell example code in Bartosz Milewski's Category Theory for Programmers. https://github.com/typelevel/CT_from_Programmers.scala Any contribution would be more than welcome! 
No license will make anyone immune to open critiques or justify lying in a democratic society.
&gt; Sure, which is what we do today when working with wartremover. In principle I'm all for putting the warning in Scala proper, sure, though it would make very little difference to me in practice - I'd still want to use wartremover for the sake of its other warnings, and in any case it's not something you can do by accident, so the warning isn't particularly vital. Beginners with no experience with safer languages will use nulls(they can always suppress warnings/errors) and code reviews aren't perfect. &gt; Most of whom regard Option quite positively. I did see one extreme Kotlin fan claiming it has too much overhead, once, but I've never known anyone to complain about it as a language construct - quite the opposite. Kotlin and c# fans don't need to be "extreme" to claim this since their language chose not to introduce Option. Any time someone comes up with kotlin or scala in an open programming forum, option and kotlin's way will be compared as I've seen. &gt; Tagged/disjoint unions are semantically equivalent to the Option/Either-like types I've been advocating all along. | means the other kind of union, which is not a sum type. Option and Either require classes for their cases, tagged unions require simple runtime tags(a field, literally) - there is no need to always provide such tags. &gt; How do you imagine implementing this, and what semantics would it have at the language level? The implementation is pretty much storing type-related parts of the functions' ASTs as meta information - this would also be useful to make type erasure less painful. We could also make scala its own runtime or make a new evaluator for it - like in haskell. I've already talked about the change in language semantics. &gt; Code written in terms of Option, Either or shapeless coproduct is much more consistent with the behaviour of tagged unions than code written in terms of ? would be. Then think about zero-cost abstractions instead - if we'd have more meta-information at runtime and could implement a new "runner" for the bytecode it'd be interesting. &gt; (For the record, if you're talking about something that's not implementable on the JVM - not merely more efficient in some other implementation - then you're not talking about Scala any more in any meaningful sense - at that point you might as well start from Haskell or something) We can implement almost everything on the jvm, only the required effort makes a difference between the goals. &gt; It's just the opposite: I insist that nesting shouldn't be a special case. F[G[T]] should work the obvious way for any types F and G, it shouldn't magically do something different for one particular type. null is magical which requires "sacrifices" at certain cases.
Interested in playing with bitcoin technology? I'm working on a library that interacts with a bitcoin node (bitcoind). A full node provides APIs for querying the blockchain, a local wallet, and the network. The GitHub readme shows some examples of what you can do. This type of library is useful for building bitcoin applications. As a start I'm hoping to provide full 1:1 parity between the bitcoind APIs and Scala APIs. Link: https://github.com/philwantsfish/scala-bitcoin-jsonrpc 
Out of interest, why you choose spire over breeze ?. I've not used either but was about to have play around with breeze at some stage. 
I have not looked at breeze at all yet. That might be an alternative. I'll look into it. 
Did you see [this](https://github.com/non/spire/tree/master/examples/src/main/scala/spire/example)?
Did you see the [user guide](https://github.com/non/spire/blob/master/GUIDE.md)?
Yes, breeze and deeplearning4s (nd4s) have more of a focus on vectors and matrices than spire afaik
*Yes, breeze and deeplearning4s (nd4s)* *have more of a focus on vectors* *and matrices than spire afaik* ______________________________________________________________________________ ^^^-english_haiku_bot
Bad bot
 That's what people write.
It seems like I didn't look hard enough at the stuff inside the repo itself. I will look at the user guide and examples you guys linked. Thanks! 
Some type-level programming stuff. Looking to find something like an HSet.
Do you mean that Int :+: String :+: HNil would be the same type as String :+: Int :+: HNil? I don't think that's possible
Yeah, that's what I was looking for
It's possible since A with B is commutative. Take a look at [TMap](https://github.com/cvogt/compossible/blob/master/src/test/scala/TMapTest.scala#L20)
&gt; Beginners with no experience with safer languages will use nulls(they can always suppress warnings/errors) and code reviews aren't perfect. What change (if any) are you suggesting and what difference would it make? &gt; Kotlin and c# fans don't need to be "extreme" to claim this since their language chose not to introduce Option. I've only know the extreme Kotlin fans to dislike it. Plenty of people like those languages and still think Option is a good idea. (Since Option is a plain old well-behaved type you can use it even in languages that don't have it as a builtin (I was using Guava's `Optional` before I'd even seen Scala), though obviously you get more out of it when it's used in the language standard library as well). &gt; Option and Either require classes for their cases, tagged unions require simple runtime tags(a field, literally) The class pointer is a single field as well. I assume you're thinking of the extra object instances, but they're only required for Java interop. Whatever implementation technique you're proposing for tagged unions, why not just compile `Option`/`Either` to that? &gt; The implementation is pretty much storing type-related parts of the functions' ASTs as meta information That's not enough. You need the tags at runtime. &gt; We could also make scala its own runtime or make a new evaluator for it - like in haskell. Right, but even if you have a non-JVM runtime, what's your implementation technique? Even Rust represents their `Result` in much the same way as `Either`; they have an optimization for `Option` (which I'd be very happy to see implemented in Scala) but that's all. OCaml's use of tagged values is widely regarded as causing more problems than it solves. &gt; I've already talked about the change in language semantics. But you've been inconsistent - nullable types and tagged unions behave very differently from each other. &gt; Then think about zero-cost abstractions instead - if we'd have more meta-information at runtime and could implement a new "runner" for the bytecode it'd be interesting. Eh, maybe. If you want to implement optimizations that's fine by me - it's not my area of expertise and not something I'm particularly interested in (I've never had a problem with Scala's present performance). I just don't want to see the language compromised at the semantic level.
The main difference between Spire and breeze/nd4s: Spire abstracts over the scalar type, so you can write generic mathematical algorithms without losing too much performance. Other libraries such as breeze are specialized for floating-point computations and offer proper linear algebra types; however, breeze is not well suited for abstract algebra. I have written a linear algebra library for Spire (github.com/denisrosset/scalin), but my focus is on exact computation and not floating-point approximations (so I don't recommend you use it if you care about speed/memory usage). 
[removed]
I missed that one, thanks! 
Can you please go to back to where you came from? Stick to node.js etc., please. Or even better, don't program. There are plenty of other jobs where one can be useful to society.
It should be doable by maintaining a sorted HList without duplicates, much like you could represent a set at the value level with a sorted list. There’s at least one [Haskell library](https://hackage.haskell.org/package/type-level-sets) which does it this way (it implements a type-level quicksort, but insertion sort should work as well). I would start by implementing a value-level set backed by a sorted List in the most straightforward way possible, and then rewriting it at the type-level, function by function, while switching from List to HList. You will need to define an ordering on types, as well as operations to sort and remove duplicates in a HList. You can take a look at the way [HList operations are defined in Shapeless](https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/ops/hlists.scala) as a starting point.
Hi. What are some good resources for Scala newcomers coming from Haskell, in addition to the regular tutorials?
Since this bears stating: of course you're fully entitled to step down, especially after all the work you're done, and you're given ample notice. I don't think that was an insult, it was a statement on how that comes across. Compared to past discussions, I gotta agree people expect spoonfeeding sometimes. Haskell Stack has hundreds of issues, and some turn out to be support issues. They often stay open without reaction on either side. What we don't do is berate the users for filing them. "Surprisingly", they don't insult us for berating them. &gt; Had you read the post correctly I've re-read the post, and that's not what it says on the tin. "Somebody will step up" is ambiguous. (It also doesn't say you're seeking maintainers as usual, so maybe the OP is misleading). If that's what you meant, you shouldn't go around questioning how one reads it. Well, you can, but better don't blame others if they get annoyed.
i am a Software Architect and an Phd in software interfaces, so you get lost please. And you want me to change my profession at this stage of my life ?
idobai, you're out of line. I think other people would have reacted differently to your reports, and that would be good. But no open source maintainer owes you (or anybody) anything.
Who the hell is deleting my posts from the main forum ?
I do not know what exactly you need it for but maybe you can user Allign to reorder Hlist e.g. from `Int :: String :: HNil` to `String :: Int :: HNil`.
Null does have methods from above, kinda. It's just that its implementation throws null pointer exceptions for anything. Is this useful? I'd argue no, but developers coming from Java often expect null to be a thing. If we could get rid of null its type in the hierarchy (which is by the way not part of Java's hierarchy if I remember correctly) would disappear and we'd be left with Nothing, which is uninhabitable and thus safe, in the sense that you'd never be able to receive an instance of it
That would be me, and you're heading the right way for a banning if you don't cut it out your language, and vapid shitposts. By all means you can post critically of Scala and associated topics like SBT and Scala.Js, but your one-sentence low-effort posts don't do anything but muddy the waters, piss people off, and insult the contributors. Next time please consider your tone and work on at least providing as much context as possible around what issues you're having, and what you would like to be done about it.
Since Dotty will have `trait`s with parameters, won't `abstract class`es be redundant, kinda?
You know what would probably help a lot? If github allowed maintainers to "silently close" a ticket... i.e. make it appear closed to the maintainers (and unsubscribed) but make the author think it's still open and just not getting any activity. I've never berated anybody for opening a ticket unless they have intentionally ignored the template. But I find that most users (e.g. Matthew here) react negatively to a ticket being closed. Actually if you look at all the tickets he's involved in that is the only thing that could possibly be taken in a negative way... in fact he was given lots and lots of help so I don't understand why he's become so insulting. I use my issue trackers as a memory board, a place to plan. Now that I've moved to gitlab I am seriously considering making them read-only to non-contributors. Bug reports only in the form of broken tests as a PR. When I see something that can't be acted on, it's just noise to me, and I want to throw it away. If it helps people psychologically to think that their ticket is open and somebody might help, then so be it, but I know for a fact that there are much more important things to be working on or (in the vast majority of cases) it's easily solved by following the troubleshooting guide. Re: misreading of the post. Actually I'm mostly annoyed that this thread was set up to just hurl shit at me. I wrote the post to let people know that I'm stepping down for family duties and I wanted to be honest with anybody who wanted to take over what that entails because I honestly wouldn't wish it on anybody, which is why I've not asked any of the very capable contributors. Basically heading up a Free Software project in this day and age is just not worth it... it's far more fun to be a contributor and work on stuff you like. Regardless, I've updated it to make it clear that I would not wish the burden of maintenance on anybody.
it's a known issue https://github.com/ensime/ensime-server/issues/1756 I basically haven't prioritised it because I have 64GB of RAM and my work projects are pretty small. However, now the 3.0 branch is cut and somebody could try to implement this ticket with fs2 or something. RAM usage could easily be &lt;512MB for the largest of projects.
I did something sort of like an HMap to prototype HList-based i18n if you wanna get some (kinda-crappy) inspiration https://gist.github.com/joshlemer/07a156b6dd8f4c44e9a12c2c7e245d2c
Try replacing `analyticsService.getData(lesson.id)` with `Future { Thread.sleep(1000) }`. You will see the body of the traverse still finishes almost instantly. The body is starting each asynchronous Future and returning. The final `yield`block won't execute until after **every** Future is finished. Below will give better timings for the work being done: val startTime = System.currentTimeMillis for { data &lt;- Future.traverse(lessons) { lesson =&gt; val startTime2 = System.currentTimeMillis for ( f &lt;- analyticsService.getData(lesson.id) ) yield { println(s"Future took ${startTime2 - System.currentTimeMillis}"); f } } } yield { println(s"end ${startTime - System.currentTimeMillis}") data } Note, I moved the `startTime2` and change it to a `val` to avoid different threads writing to it.
I applied the `Future { Thread.sleep(1000) }` change but each Future executed takes longer than the last. (Similar results with leaving `analyticsService.getData(lesson.id)`). The result is interesting but I'm not quite sure what I can do to improve this. Future took -1000 Future took -1001 Future took -1000 Future took -1001 Future took -1001 Future took -1001 Future took -1001 Future took -2001 Future took -2001 Future took -2002 Future took -2002 Future took -2001 Future took -3000 Future took -3001 Future took -3002 Future took -3002 Future took -3002 Future took -4000 Future took -4001 Future took -4002 Future took -4002 Future took -4002 Future took -4002 Future took -4002 Future took -5001 Future took -5001 Future took -5002 Future took -5002 Future took -5002 Future took -5004 Future took -5004 Future took -6001 Future took -6001 Future took -6001 Future took -6002 Future took -6002 Future took -6002 Future took -6002 Future took -6002 Future took -6002 Future took -6002 Future took -7001 Future took -7001 Future took -7002 Future took -7002 Future took -7002 Future took -7003 Future took -8001 Future took -8001 Future took -8001 Future took -8002 Future took -8003 Future took -8003 Future took -8005 Future took -9001 Future took -9001 Future took -9001 Future took -9001 Future took -9002 Future took -9003 Future took -9003 Future took -9005 Future took -10002 Future took -10003 Future took -10003 Future took -10003 Future took -10005 Future took -11001 Future took -11002 Future took -11003 Future took -11003 Future took -11003 Future took -11003 Future took -11003 Future took -11005 Future took -12002 Future took -12002 Future took -12002 Future took -12002 Future took -12002 Future took -12003 Future took -12003 Future took -13002 Future took -13002 Future took -13002 Future took -13003 Future took -13003 Future took -13003 Future took -13005 Future took -14003 Future took -14003 Future took -14003 Future took -14004 Future took -14004 Future took -14004 Future took -14004 Future took -14004 Future took -14004 Future took -15002 Future took -15003 Future took -15004 Future took -15004 Future took -15004 Future took -15004 Future took -16002 Future took -16003 Future took -16003 Future took -16003 Future took -16004 Future took -16004 Future took -16004 .... Future took -62601 Future took -62601 Future took -62601 Future took -62601 Future took -62601 Future took -62601 Future took -62601 Future took -62600 Future took -63597 Future took -63598 Future took -63598 Future took -63599 Future took -63601 Future took -63601 
You're running into the limits of your threadpool. Look into increasing the max number of threads.
it's not max 1's. ``` [info] webpack: wait until bundle finished: /ui/ [info] Date: 2017-09-27T07:58:41.142Z [info] Hash: c40dda49eeb708416ee1 [info] Time: 27546ms ``` this is our angular 2 cold compile our hot lies on the 6 seconds. currently we migrated from ES6 JavaScript + Closure Compiler to that and the closure compiler was quite fast, also 6 seconds on hot. However with babel/webpack and others we took a 20 seconds hot compile time. Currently JavaScript is really slow once your codebase grows. Of course everything below a 100k loc is probably fast, however the same codebase in Scala isn't that big since you have way more abstractions and basically ScalaJS is as fast as JavaScript/TypeScript to ES5. Of course when we could emit plain ES6 and only use minify it would be faster, but we are sadly not quite there.
Just putting something in a `Future` doesn't make it async - the reply below saying that you're hitting the limits of your threadpool is correct, but if you're just going to add more threads you might as well not use a `Future` at all. You should find an async way to do what `analyticsService.getData` does (e.g. if it's making a HTTP request, use akka-http client or similar).
There is a LSP for Scala, it is based on ENSIME. It is getting merged into ensime 3.0. I helped pay for it. I spent a lot of time fundraising for it. I did the technical architecture for it. But sure, listen to Matthew here about how my stance is not helping. He's Jesus Fucking Christ after all.
shapeless doesn't provide a set-like data structure, but it does provide operations on HLists which support set-like usage: you can constrain an HList type argument to have no duplicates, add and remove elements, permute, align and merge in various ways. If you'd like help for your specific scenario you should head over to the shapeless [gitter channel](https://gitter.im/milessabin/shapeless) ... there are lots of people there who can help you out.
Regarding the multiple verbose type definitions: disagreed. My implementation requires: * a trait (Door) * two implementations of that trait (Opened and Closed) * two methods (close and open) The phantom types implementation requires: * a trait (DoorState) * two implementations of that trait (Open and Closed) * a class (Door) * two methods (open and close) "My" implementation requires less boilerplate than the phantom types one, even if you don't take into account the type and implicit parameters. I don't understand your point about proceeding in any order. You can absolutely call Door.Opened.close().open().close(), or any valid combination thereof - just like you would with phantom types. The only orders that aren't supported are closing a closed door or opening an open one - and I thought that was the entire point of the exercise?
/r/haskell
Thanks Denis, I hadn't seen Scalin, good to know about that option too. Spire is great, and I was also looking at your Smala symbolic library the other day. Apprectiate all your work on these things.
You don't have to use SBT - I still don't. Scala works fine with Maven where the syntax is clear and everything is documented and backward compatible.
&gt; "My" implementation requires less boilerplate than the phantom types one, even if you don't take into account the type and implicit parameters. The problem is that your approach gets quadratic if you have multiple different aspects of the state that can happen in different orders. Like, suppose the door can be open or closed *and* locked or unlocked (let's assume a lever deadlock - so the door can be locked closed or open) *and*, I don't know, clean or dirty. Then you don't want to have to create trait implementations for all possible combinations (`CleanClosedUnlockedDoor`), but the normal solution to that is to only implement a subset of the states, which then forces users to do things in a particular order (maybe some users prefer to clean the door and then open it, others prefer to open it and then clean it).
Wow, Smala. Beware of it, I should have known better when I wrote the thing. It's a gigantic cake pattern mess. We surely can do better!
Like /u/m50d said. Try modelling the pizza example with your method.
&gt; Java as a language itself is getting modernized pretty quickly ha ha ha, oh wow
shorter syntax, case classes, immutability, type inference, pattern matching, tail call optimization, to name just a few of "better java" features still worths the effort. Yes you can try to do that in Java with libs and tools but sometimes it just no possible and in others the result is not pretty or acceptable. Working in Java, even java 8 for people that know scala, and know how much simpler things can be is a pain. I agree that in this case you could use kotlin, but if you have to move from java, at least go to a language that give more flexibility in the long run. 
&gt; simple sugar that is largely templated for you by existing tools in Java. Templates in tools can write code for you but they can't comprehend it for you, and as a project matures you spend more of your time comprehending existing code than writing new code. &gt; The standard library is nice, but as a library Guava already exists and Java streams take care of the stuff the standard library does with chaining sugar. Up to a point. The syntax is still more cumbersome, and Java doesn't have the tools to allow you to manage the interaction of streams with other effects (e.g. async, database transaction boundaries) in a nice way. &gt; I have the same problem with this argument that scala without FP is worth it that I had with Rod Johnson - if you take away the FP, implicit classes, and typelevel programming from scala, you are left with syntax sugar over Java. To my mind the best part of Scala is never having to use magic annotations, and while implementing effects as libraries might require advanced FP, using them doesn't. You could even regard those as part of the language, in which case it's simply a language that can move much faster than Java. &gt; Someone else could implement that as a simple set of expansions to java, and compile the java. No doubt, but I don't think such a language could succeed, if only for social reasons.
Here's what you can do, general idea 1. Write your codegen tool as a seperare project (i e subproject of your multiproject build) normally with main entry point etc 2. In your plugin, the task should just run your codegen tool main, as if it was any other java binary. With arguments where to output stuff etc Your codegen tool can then be used (again just like any other binary) from your build agent (apply evolutions-regenerate schema-publish artifact) or other places 
I know. I still use Maven too.
Im on phone but if its unclear or u have further questions feel free to ask... i did this before and it worked well But maybe someone diminishes it for being bad then perhaps there are better ways
As /u/fromscalatohaskell said, your table generator needs to have its own entry point. It doesn't have to be its own project, but it makes it easier if it is. You would then create a Task that you can use to run the generator. You are correct to be concerned about the library version you are using for the table generator -- There is a big difference between slick 3.1 and slick 3.2 code generation. The slick example of sbt custom table generation is [here](https://github.com/slick/slick-codegen-customization-example). Have a look at that -- don't worry about the customization itself, but it'll show you haw the task system specifically related to slick works in sbt. If this is your first project using sbt, you're certainly jumping into the deep end of the pool. 
You're the one who is out of line: [check out this comment of mine](https://www.reddit.com/r/scala/comments/71pphu/new_maintainer_needed_ensime/dnemfi1/?st=j83fjkp0&amp;sh=f015ba57). When I've raised my concerns about the state of ensime on *reddit like a year ago* and provided **valid** critique he got mad and personal - he visited my issues on github and wrote that I'm "rude" for the entire ensime team. But I've never talked to him before - and he never wrote on my issues. I didn't even know who he was. I thought it was the original author who revived ensime but no. This guy think he saved the world and that everyone is asking help from him when it's definitely not true - he's waiting for others to do all the hard work. That's why I called his dev method "lazy". But it doesn't matter because he plays the victim and lies when he wants and he'll get away with it because people think he's supporting 5 editors when he just maintain**ed** a wrapper over the presentation compiler and scala-ide/refactoring. Just look at his comment he made to someone else: [here](https://www.reddit.com/r/scala/comments/71pphu/new_maintainer_needed_ensime/dnfohot/?st=j83fo9cm&amp;sh=58b74395) - he's just a self-entitled asshole.
&gt; What change (if any) are you suggesting and what difference would it make? Typesafe nulls = typesafe nulls. &gt; The class pointer is a single field as well. I assume you're thinking of the extra object instances, but they're only required for Java interop. Whatever implementation technique you're proposing for tagged unions, why not just compile Option/Either to that? I've no idea how to implement that on the JVM. We can't really implement anything on it because no one really has any access to the "mainline" project(of course it's OSS, but maintained by a company). &gt; That's not enough. You need the tags at runtime. No, we don't - only the typechecker needs to know if there could be a nested ?[T]. Runtime tags would be pretty powerful, though. &gt; Right, but even if you have a non-JVM runtime, what's your implementation technique? Even Rust represents their Result in much the same way as Either; they have an optimization for Option (which I'd be very happy to see implemented in Scala) but that's all. OCaml's use of tagged values is widely regarded as causing more problems than it solves. Nope, structures - especially wrappers - don't really exist in Rust - that's zero-cost abstraction. I'd be happier if the JVM would have that instead of all the half-assed feature it has now. &gt; But you've been inconsistent - nullable types and tagged unions behave very differently from each other. A typesafe nullable type is a tagged union, but it doesn't need the tag because we know if it's null then it's null. &gt; Eh, maybe. If you want to implement optimizations that's fine by me - it's not my area of expertise and not something I'm particularly interested in (I've never had a problem with Scala's present performance). It depends what you do but it's not good enough compared to the competition. &gt; I just don't want to see the language compromised at the semantic level. It's already compromised: it's not sound and have a poor support for typeclasses.
&gt; Nope, structures - especially wrappers - don't really exist in Rust - that's zero-cost abstraction. Traits are still boxed, as far as I can see `Result` would have to behave like that. &gt; only the typechecker needs to know if there could be a nested ?[T] The typechecker can't possibly know that, because it doesn't know what will be on the runtime classpath. &gt; A typesafe nullable type is a tagged union, but it doesn't need the tag because we know if it's null then it's null. You do need the tag for the nesting case, if you don't have the tag it will behave like a non-tagged union (duh). &gt; It's already compromised: it's not sound and have a poor support for typeclasses. No language is perfect, that's not a reason to make it worse. (Though for the record the current soundness issues are less severe, and the typeclass support much better, than for most competitors, especially in practice)
if you get frustrated or loose many days or hours trying to get things to work and still nothing, make sure to create 10 blogs about it on 10 different websites, because what we have here is an conglomerate that believes deleting critics and their post will make SBT better, these psychos always tell me to describe the problem in more details, when the problem is nothing else other than SBT.
[removed]
&gt; Traits are still boxed, as far as I can see Result would have to behave like that. Traits are descriptors, not structures but I don't think they're preserved. &gt; The typechecker can't possibly know that, because it doesn't know what will be on the runtime classpath. We were talking about encoding meta-information about the types into libraries which would be enough. Also - we could just load the source code of the libraries. With the latter, many issues of type erasure could be treated easier(with proper compiler support). &gt; You do need the tag for the nesting case, if you don't have the tag it will behave like a non-tagged union (duh). We've dropped nesting like weeks ago... If you want to tag them then you'll loose all the benefits. Choose: zero-cost abstractions, nullable types, no-care-about-performance. &gt; No language is perfect, that's not a reason to make it worse. (Though for the record the current soundness issues are less severe, and the typeclass support much better, than for most competitors, especially in practice) Not being sound is far worse than having a nullable type. Also, the typeclass support is terrible since it's far more complex than in any FP language. I'm not into monads, but typeclasses are very flexible abstractions and a better approach would be appreciated.
If you're writing mostly static content I would suggest using something like Jekyll or Hugo where there are a decent number of customizable themes, and the layouts are fairly simple. Bringing Scala/SBT into that seems like overkill IMO.
Sbt docs - the getting started guide works as a tutorial for the scala build tool http://www.scala-sbt.org/1.x/docs/index.html 47 degrees scala exercises will get you started learning the std lib, cats, shapeless, and more https://www.scala-exercises.org Tutorials on the two main FP libs http://eed3si9n.com/learning-scalaz/ http://eed3si9n.com/herding-cats/ For making Free/tagless final programs that don't suffer as many performance penalties http://frees.io Neophytes guide to scala http://danielwestheide.com/scala/neophytes.html A good online book I've been reading is Functional Programming for Mortals https://leanpub.com/fpmortals You might also want to look at some Java tutorials, as Scala apps typically interact with some Java libraries , like logging, configuration, Java io/nio paths and files. If you are working with files, I highly recommend fs2 https://github.com/functional-streams-for-scala/fs2/blob/series/0.10/docs/guide.md as it makes that a lot nicer. 
Much appreciated for the input. I have a sub-project that I can run independently (a different main, etc) inside my project, living in the same codebase (however I can't run it as a task yet, thinking about it should not be too hard). Do you have any experience upgrading from sbt 0.x.y to sbt 1.0.0? I believe that would solve all my problems but just from the migration tutorial they published I can't fathom how hard it would be
Is there a way for sbt to read input from the console while its running. Often i build programs with multiple mains in same directory. sbt handles this and is aware allowing me to select which main program to run, but if one of those main programs requires polling the command line then i usually have to fiddle around and create a jar (with sbt assembly) and then run the program via `java -jar some.jar` instead. or use ammonite (again more fiddling around to get it working with that)
I started long time ago to code a Scala client for DynamoDB but did not find enough time / will to continue this tedious task. Thanks for pointing out there all the viable alternatives. Funnily I broke down my dynamo libraries in 2 parts: the AST and the client. If you are interested, you can check it out [here](https://github.com/lforite/dynamo-ast)
 I'm using scalatags with success. It is a library that can be easily combined with any rx stuff. Such wrappers will be just ~15 lines of code. 
&gt; We were talking about encoding meta-information about the types into libraries which would be enough. Also - we could just load the source code of the libraries. No, it isn't enough. You simply don't know what the run-time classpath will be at compile time. &gt; We've dropped nesting like weeks ago We dropped it because you said you were in favour of tagged unions. &gt; Not being sound is far worse than having a nullable type. But not being sound *and* having a nullable type is worst of all. &gt; the typeclass support is terrible since it's far more complex than in any FP language Complex in what sense? Typeclasses in Haskell/Idris have language-level support that makes them slightly simpler at the point of use at the cost of complicating the language and making typeclass implementation code somewhat second-class. Expressing typeclasses in OCaml/F# is substantially more cumbersome than doing so in Scala. If anything that puts Scala right in the middle of the range of FP offerings.
https://github.com/lagom/lagom Mostly Scala. 
Use `runMain`.
Play is pretty heavy. Did you try akka-http?
Is this the usage of your app during compilation or at run time? 
This is a great post, really great idea combining Alpakka with Scanamo. 
During runtime
Nope, I'll give it a try, but it looks to me if you add some stuff like Slick, etc. it would be still 100 - 200 MB at best
Consider also [D](dlang.org) and [ReasonML](https://reasonml.github.io). They both compile to super lightweight native code just like Go. As for your Play app, have you tried profiling it?
&gt; Consider also [D](dlang.org) and ReasonML. Thanks, AFAIK Reason is still very immature. &gt; As for your Play app, have you tried profiling it Nope, do you think 400MB is unreasobable? 
That's a harder thing to diagnose. There's nothing really about the language itself that has it suck up tons of RAM (no more than Java at least). There's a couple of common things that I've seen in my experience: 1) JVM configuration. Sometimes the JVM makes it look like your app is taking up more memory than it actually is. I'd look into how yours is configured (probably in your SBT settings) and see if there are ways to play with that. Check out this thread for some clarity on a similar problem: https://groups.google.com/forum/#!topic/scala-melb/H_TvlL0foMc 2) Overusage of expensive calculations. Scala is really powerful and concise, and a common problem that can occur is a tendency to use these powerful items for too many things. Things like Reflection, collection transformations, etc. can be easily abused. Some reading material here: https://stackoverflow.com/questions/5901452/scala-vs-java-performance-and-memory http://www.lihaoyi.com/post/BenchmarkingScalaCollections.html https://stackoverflow.com/questions/41182727/measure-memory-usage-of-code-unit https://stackoverflow.com/questions/3644694/in-scala-or-java-how-to-get-how-much-ram-does-application-currently-occupy 
I definitely recommend learning Rust as it contains some really good ideas about ownership and mutation which makes system level programming much more safe. It's a good language to have in your toolbelt (especially if you don't know or want to learn C++). However, it's a much more low level language than Scala which means you have to think about memory management basically all the time (which isn't necessarily a bad thing depending on your use case). The Rust type system is decent but not on the same expressive level as Scala's, and the syntax is generally not as terse and a bit more "noisy". Both these areas are improving rapidly though. Another option might be [Scala native](http://www.scala-native.org) which basically lets you get rid of the JVM and compile directly to native binaries. It still requires a GC, but it has some more flexibility in terms of memory management. However, the project is still very immature and lacks a lot of functionality so expect some incompatibilities. D might be another option as well. In general I think learning a new language is time well spent even if you decide not to use it. You usually pick up something useful about software development.
It depends what it's doing. I don't know your use case 😊 ReasonML is just a syntax btw, but native OCaml is pretty mature--there is a package manager and build system, options to deploy using Docker, or just push out a binary. D is of course very mature and very cross-platform.
Yeah that's what I thought. But how practical is it in terms of writing an api web-server for example?
The table generator approach won't change from any 0.x to 1.0. You need to understand the Task concept in SBT if you want to ever do anything but tear your hair out and copy pasta. Load up the example I linked and play with it to understand what it's doing. The most common barrier to success in Scala and SBT is being impatient. Both require intentional exercise of mental planning. Think first, type less. Seriously. Understand the example then apply that to your code. The fundamentals you learn are going to help you in completely different projects and in ways you can't expect yet. 
I don't have any experience with that, but there are some web frameworks like [Iron](http://ironframework.io). Overall the Rust eco-system is growing and maturing rapidly since it's so popular in the open source community. [crates.io](https://crates.io) has over 11k crates which is remarkable considering the language has only been stable for about 2 years.
yes, should've known that by now :). `sbt "runMain progname"`
&gt; should of Did you mean should've? -------------------------------------- This is a bot account.
I already have the code done and working for both scala 2.10 version 3.1.1 and scala 2.12. It is not about the table generator, its about the scala compiler that sbt uses. I did the code by scratch so no copy pasta :D I will probably just upgrade sbt to 1 and use the task that invokes a sub-project turn into an actual code compiled in the context of sbt. Thanks for the input :D
Can you explain what you mean by “heavy” here?
Playframework has plenty of features, jdbc, DI, migrations etc. Not every web application needs them.
I really enjoyed using [rocket](https://rocket.rs/) framework. Reminded me of http4s and was easy to grok
While this is true, you don't have to leverage the features in your application. They won't take up RAM unless they are actually called or enabled. I consider Play to be much more like a toolbox; use what you need, leave what you don't.
Nice - I love http4s!
Love it. 
Did you do a heap dump to determine what's gotten so big? I've run play apps in fairly small containers in production many times in the past. It sounds like you're leaking something. 
I was a scala guy for side projects until rust hit stable. At that point I switched and have been working on web projects with rust since then. I've been working on a REST api for a while now and it's going very well! For database interaction and migration support, i'm using [diesel](https://www.diesel.rs) with postgresql. I'm able to authenticate with oauth2 through google (and adding facebook next). The web framework I'm using is Iron, but I'd recommend rocket (as others have) or [gotham](https://gotham.rs/) which seem to be updated more often. Iron is getting stagnant. This api is being hit by an android app which is deployed to the play store, but in alpha mode so it's private. For hosting I use a heroku's free hosting, which has been an amazing experience so far. Using [this buildpack](https://github.com/emk/heroku-buildpack-rust), I can literally run `git push heroku master` and viola, the code is pushed to heroku, heroku builds it, and if that succeeds, it runs the executable. For me, it looks like the web server takes up about 30MB of ram after just starting it. It may grow as it's getting used because I've implemented some in-memory caching, but I'm sure it'd stay below 50MB.
Removed for offensive / abusive language
&gt; No, it isn't enough. You simply don't know what the run-time classpath will be at compile time. Then believe that it's not enough. But we can store what we want. &gt; We dropped it because you said you were in favour of tagged unions. No, we dropped it to avoid nesting because you didn't like it that way. &gt; But not being sound and having a nullable type is worst of all. I don't know why you think it'd be so bad. We'd have proper null-safety *and* the possibility to use null. &gt; Complex in what sense? Both semantically and syntactically. &gt; Typeclasses in Haskell/Idris have language-level support that makes them slightly simpler at the point of use at the cost of complicating the language and making typeclass implementation code somewhat second-class. What?! How is typeclasses not just a second-class feature in scala? How using traits, implicit values and implicit classes for even the simplest case is not complicated?
/u/fommil Btw, I do like your CoC. Good luck with parenthood, I've got a couple myself and its both the greatest and hardest thing.
Are you actually using 400MB or is that just what the VM reserved? The JVM once it allocates system memory for heap, even if it's only used once doesn't give that memory back. If you're just running the JVM with defaults you may want to tune the memory settings of the JVM; if for some reason you care about the VM allocating that memory.
Run a heap profiler, and see what's gobbling up all that memory. Make sure you're using at least Java 8 and Scala 2.12.
If you don't mind dynamic languages, elixir is legit.
I'm curious what the API of such wrappers would be roughly, and whether they require re-creating Javascript DOM nodes from scratch every time (because that's a problem for any sizeable application). If you're familiar with jQuery and jQuery style web development, this is the kind of API that I would call too low level for big apps. I'm currently working on https://github.com/raquo/Laminar (note: github version is outdated), and while building a specific streaming API for the DOM is not very complicated, it's a couple orders of magnitude more than 15 lines. A bit hard to compare because I use a different underlying library instead of ScalaTags, but it's very similar.
I don't think so that he's leaking sth, all of our production system use 400+ MB
400MB of real memory? Is that actually used or just allocated? Just a nice GC report would go a long way... I can't tel you how many times I've had to deal with "OMG play is using ungodly memory, we need to find something else!" only to find out it just hasn't had reason to GC most of that away.
That sounds like a lot. Maybe it's Play (I prefer to use Spray for REST APIs, and Wicket for web UIs). Though as others have said, profile what's using your memory rather than guessing. (And as a very first step, what happens if you try just running with a smaller memory size set via `-Xms` and `-Xmx`?) If this is microservices or similar, you could consider using a Java application server to allow you to run multiple services in the same VM and have only one copy of a lot of the libraries - I used to do this with Tomcat, deploying several microservices as servlets in the same VM. Also be aware that as Scala is a generally safe language with good isolation properties, there's often much less need to deploy microservices; you can deploy a monolithic app instance while maintaining most or all of the advantages. Finally, I'd say it's worth having a sense of perspective on how much RAM is costing you versus how much your time is worth. 400Mb really isn't a lot in this day and age compared to a skilled developer. All that said, languages are fun and can help broaden your horizons. In terms of relatively mature Scala-like languages I'd think of OCaml, Haskell and F#, and perhaps Rust as you say. Maybe Idris if you're willing to look at something more experimental but with some really cool ideas.
&gt; We'd have proper null-safety and the possibility to use null. We'd have a magic type that doesn't behave like any other. That's costly. &gt; How is typeclasses not just a second-class feature in scala? How using traits, implicit values and implicit classes for even the simplest case is not complicated? Those are features that already exist in Scala; typeclass implementation is ordinary, first-class Scala code, whereas in something like Haskell the way typeclasses are integrated into the language means that how you refactor them is different and you can't always eliminate common code the way you'd expect. Traits are about as simple as a language feature gets (maybe not if we're talking about multiple inheritance, but you don't need that to implement typeclasses). Implicits are genuinely complex (though I don't see the need to draw a distinction between implicit values and implicit classes, they both work consistently with each other) but they're a language feature we'd already want for other purposes (e.g. extension methods, the magnet pattern).
well one can run play on appengine standard and it will work flawless with 128 mb because the smallest instance is only 128mb memory and it just works.
Ok, that's a clear example of why ohantom types can be a superior alternative to sum types. Thank you.
Crystal and kemal. 
I haven’t used akka yet. I’m still learning. I did google this. https://doc.akka.io/docs/akka/2.5.4/scala/cluster-usage.html Is that what you’re looking for?
Those are all modules. They get added in to Play, same way you would add akka-cluster, akka-persistence, akka-distributed-data, etc into Akka-HTTP. I don't see how Play is heavier than akka-http there. Even Guice DI is optional.
Go was designed to be limited. I've noticed all the go code i look at i can easily understand (that includes library code), i can also easily do complex things with it. I've learnt it in much shorter time than Scala (still learning). 
Well I could see Smala was kinda a first pass, though it was interesting to look through nonetheless. I also found an unmerged pull request someone wrote for symbolics in Breeze https://github.com/scalanlp/breeze/pull/582/files, which delegates to Symja for simplification and other functions. Symbolics depending on Spire might make more sense though, and that's what I'm experimenting with for a hobby/learning project of mine (though I just want a couple of functions rather than a whole library). 
Have you seen Colin Breck's articles? http://blog.colinbreck.com/integrating-akka-streams-and-akka-actors-part-iii There's also GearPump as well https://github.com/apache/incubator-gearpump 
That's a great answer, thanks!
I migrated (just to see how difficult it would be) one of the small services here at work from ScalaTest to uTest and here are some notes: * Documentation is very good, but in some cases outdated. Out of my head I can remember the 'Asynchronous Tests' and the 'Running code before and after test cases' sub chars; * Syntax is very nice and quite easy to use; * The migration was done quite successfully. Now that I know what to do, I guess the other services would be even easier to migrate; * Couldn't make uTest work with IntelliJ. I found an issue open with IntelliJ about this, but no one solved it... And it is open for 2 years now. In conclusion, I would totally talk to the rest of the team to start using uTest if it would work with IntelliJ. This is a big deal breaker :\ Do someone have a solution for this?
If you are looking for other languages I really enjoyed crystal lang https://crystal-lang.org/ with the little time I spent with it Like Go, it builds optimized LLVM native builds. Its also really fast, and its strongly typed (although it favours inheritance/structural typing rather than nominal based typing). It also has proper macro support which hygenic macros that work directly on the AST. Unlike Go Crystal is also really expressive so you don't really end up writing lines and lines of boilerplate. In regards to Scala, it suffers the same issue that Java applications tend to suffer. For one thing, the GC really favors "allocating a huge amount of memory at the start". Then there are really large dependency trees with an overuse of classes and objects which all allocates memory from the heap. There is also an overreliance in using the JIT rather than AOT (which also tends to remove potential memory allocation)
Curious as to why you want to know.
I don't want to out more fuel on the fire here but it seems like you have issues understanding what I said before so let me re clarify. I don't have a problem with tickets being closed, this happens all of the time for a variety of reasons. I had an issue with closing a ticket without leaving a single comment (whatever you want to argue here it leaves a terrible impression on the project). It's also the only time this has happened to me (yes I am being completely accurate here). The other tickets I have already commented about earlier, there is no point in repeating myself here again.
Uh, putting the work of ENSIME into the official compiler is what I have been saying the entire time
Say I have 3 case classes that all have one common property, say id. Without inheritance or significant modifications to the case classes, is there any way for me to write a function that takes generic type T, and access the id field of an object of type T? This field will have the same type in all 3 case classes.
One difference is that abstract classes are interoperable with java. 
Yes! This is the typeclass pattern. It's useful for _ad hoc polymorphism_, where you can associate new behavior to existing classes without modifying them at all. The catch is that it can be a little heavy on the syntax and code bloat. It can also be a little difficult for people to wrap their minds around the first few times they see it. First, the classes we cannot or do not want to modify, with no inheritance case class A(id: Int) case class B(id: Int) case class C(id: Int) Next, the trait representing the "typeclass" - the behavior you want to associate to `T`. Implementations of this trait know how to extract an id from an instance of `T` trait Id[-T] { def id(t: T): Int } Then the implementations for each type you care about. Implementations should be found implicitly. They do not need to be implicit themselves if they are bound to an implicit variable, e.g. `implicit val aid = AId` implicit object AId extends Id[A] { override def id(a: A): Int = a.id } implicit object BId extends Id[B] { override def id(b: B): Int = b.id } implicit object CId extends Id[C] { override def id(c: C): Int = c.id } Finally you can write your generic method, requiring the associated behavior implicitly. def id[T](t: T)(implicit ev: Id[T]): Int = { ev id t } And this will work for each type for which an instance of the typeclass can be found. val a = A(1) val b = B(2) val c = C(3) println(id(a)) // prints 1 println(id(b)) // prints 2 println(id(c)) // prints 3 That's it!
Perhaps raise a ticket with the IntelliJ Scala plugin guys? They tend to be pretty responsive; I know they've tried to add support before, and did ask for feedback to see if people were using it
This should probably go to https://contributors.scala-lang.org/ if you really want to have it as a part of standard lib.
I would rather treat this as a *temporary/incomplete/etc. fix* for [that bug](https://github.com/scala/bug/issues/1570), since it's just a workaround, not improvement.
I think it's enough, but also I'd recommend the book "Scala for impartient" by Cay Horstmann. IMHO it's a better choice.
I found Alpakka and Akka Streams quite useful indeed for easily scanning through datasets, but when you go a little bit further, such as performing joins for example with multiple sources, it becomes quickly a burden. This is the reason why we use larger frameworks instead (Spark, Flink, ...).
The typeclass approach is great but I don't get how people can do things like, have a list of things that have that typeclass, but not necessarily the same one. Since each element in the list could have a different instance of typeclass, one cannot just use like List[T: Id] 
Atomic Scala is written for people who have never programmed before, and it doesn't cover functional programming at all really. But it will familiarize you with syntax and basic constructs. If you already have some programming experience I recommend flipping through *Programming Scala* (2nd ed.) by Dean Wampler. But really the course is for total beginners in Scala so I think you'll be ok without any prep.
oke, I did it earlier and I find it not for total beginners . Some exercises are very hard 
Great! I have to read it.
You're right that you cannot directly do that with the common data structures since they're all homogeneous and require the same type of element. So there are a few approaches depending on what you really need. If all you need are the values that you can extract from a typeclass, you could be eager about it and just create, say, a `List[Int]` with `id(a) :: id(b) :: id(c) :: Nil`. If you need to be lazy but you only need the behavior from the typeclass and don't really care what the types are, you can also erase the type information by creating an object that carries the necessary value and its typeclass instance along with it, to be invoked later. Something like this: sealed trait Identifiable { type T def ev: Id[T] def value: T final def id: Int = ev id value } object Indentifiable { import scala.language.implicitConversions implicit def apply[T0](_value: T0)(implicit _ev: Id[T0]): Identifiable = { new Identifiable { override type T = T0 override val ev: Id[T] = _ev override val value: T = _value } } } You won't be able to determine what `T` is from an `Identifiable` instance alone, but because of the abstract type it is known that _whatever_ `T` is, it's the same `T` for `ev: Id[T]` and `value: T`. So you can create a `val ids = List[Identifiable](a, b, c)` and then get the ids later, e.g. with `ids foreach { i =&gt; println(i.id) }`, or by using the previous method, e.g. `ids foreach { i =&gt; println(id(i.value)(i.ev)) }`. If you need to be lazy _and_ know the distinct type of everything in the list then you can use a heterogeneous list, an `HList`, from something like the `shapeless` library. That'll allow you to summon the distinct typeclasses later since all the types of each element in the list are tracked. I haven't had a strong need for this in my own code so I can only speak to its existence :D.
Make the types more explicit, use tagged unions and make a `List[A \/ B \/ C]`. A type class instance for the union can be derived correctly applying the right type class instance for each element. The typeclass instnce for `\/` would look something like: def disjunctionId[L, R](leftId: Id[L], rightID: Id[R]): Id[L \/ R] = new Id[L \/ R] { override def id(disj: L \/ R): Int = disj match { case -\/(left) =&gt; leftId(left) case \/-(right) =&gt; rightId(right) } } If `A`, `B`, and `C` had some common supertype `D` you'd do something similar where you'd write a type class instance for `D` to type test for `A`, `B`, or `C` and dispatch to the correct instance. def dId(aId: Id[A], bId: Id[B], cId: Id[C]): Id[D] = new Id[D] { override def id(d: D) = d match { case a: A =&gt; aId(a) case b: B =&gt; bId(b) case c: C =&gt; cId(c) } } Using the first example above to turn a `List[A \/ B \/ C]` into a list of IDs would look something like this: def a(id: Int) = -\/(-\/(A(id))) //Some smart constructors to help us lift A,B,C into tags correctly. def b(id: Int) = -\/(\/-(B(id))) def c(id: Int) = \/-(C(id)) val xs = List(a(7), b(5), c(1)) val abcId: Id[A \/ B \/ C] = disjunctionId(disjunctionId(AId, BId), CId) val ids = xs map(abc =&gt; abcId id abc) Type class instances like `abcId` often use implicits to be derived automatically so in the end, using typeclasses is type safe, generic and resuable, and less verbose the similar object-oriented dispatch pattern(the Visitor Pattern).
I would love to read it but, 1) its long 2) examples are in c++ which means it is waiting in my Pocket for some better time ;/
There is hope https://github.com/typelevel/CT_from_Programmers.scala
You could use structural typing. (Although it's not very fashionable anymore)
You are doing God's work!
It's probably your jvm settings. The jvm uses a lot of memory if it's available, but if you give it a lower limit it should work just as well (only with a little more/earlier GC). A viable alternative would be Elixir, which even runs on embedded systems just like on full-blown servers. 
Was it ever?
Great thanks so much.
That's wonderful, thanks :)
Thanks a lot!
Good question. I think everyone starts out using it when they learn Scala. It seems like a useful feature! But then people find out that that it uses reflection, and reflection is bad right? There's a discussion of it on the Dotty issue tracker, where Selectables have structural types: https://github.com/lampepfl/dotty/issues/1886
You'll be arrogant and lazy next, just you wait and see.
But I had thought that since 2.12 it doesn't use reflection?
Have you tried this guide: https://www.lagomframework.com/get-started-scala.html ?
I downloaded the example online auction, looking at the code and can not configure how should I use the framework.
Have you seen https://www.lagomframework.com/documentation/1.3.x/scala/UnderstandHelloScala.html ?
If I write my recursive function (not tailrec) by hand, is it automatically not stack safe? Does scala/jvm do nothing in this regards? Will it explode for "too many recursions" on stackoverflow? Do I always need to employ trampolining?
&gt; recently, we had a thread with lots of harassment, bullying, abusive comments, insults, offensive language, and overall unnaceptable behaviour. the mods did nothing about it: no comments were removed and, afaik, no violators were banned or suspended. honest question: why? don't we have a code of condut for this sub? don't we care about the quality of the discussion and the community we are fostering? u/kpws, do you realize how hypocritic is this from you or you're just about to roll your next trolling crusade? No mods taking "action"?! When you were one of the ppl trashing others? I mean *I'm not innocent* - I don't watch my language and sometimes I get personal but looking at your scheme - get to r/programming or r/scala, trash ppl, *and delete your comments* - this is an eyebrow-raising comment from you. I don't know what's your purpose here but it doesn't seem to be good. Remember when one year ago you came to this subreddit and started trolling? There was a funny post from twitter when someone related some scala experience to some god-thing somehow and you started trashing god and the people who asked you to calm down - plenty of us thought you're just joking but your comment history was full with extremist anti-theism(I've no problem with someone being atheist/religious or whatever) - are you still banned there? Because you were not just mean or insultive - you were full of *hate*. And that behaviour didn't stop. Of course, a few months ago you started to compliment certain people(probably for karma) but that's all about your "good deeds". I'm not sure but one of us here holds the @titanthinktank and @sbtisabandonware accounts and I feel their behaviour match yours(I can't prove it, I don't work at reddit; btw, who exposed Cedric's 20 accounts? we need you!). Btw, when did you start to care about the quality of discussions here? You often just post some nonsense on the sticky posts and then delete it in a few minutes. Most of your comments at r/programming and r/scala are either saying obvious stuff or just condescending/hateful nonsense. Of course, people can change but honestly, it's like @yogthos complaining about script language users... Edit: someone wants moderation? Alright, nice idea however, if you're a shameless troll then don't try to play the victim. Anyone remember that guy who started to learn scala 1-2 years ago and often raged on this subreddit(someone named like John Reese or similar)? He made like three accounts with similar names because he'd -100 karma then each time he tried to be nice. Probably this is what's happening with kpws but it's still hipocrisy.
if your recursive function ends with a call to it self, scalac will try to turn it into a while loop, the annotation @tailrec [throws a compiler error](https://i.imgur.com/ECa9a7L.png) if the function was not compiled into a while loop. If your function is not tail recursive, it will fail in about 40K calls (not sure of this number, i think i read it somewhere). But you can use one of these two JVM options to increase the stacksize : -ss Stacksize to increase the native stack size -oss Stacksize to increase the Java stack size
You're such a lier... Of course, you *always* remove all the evidence and now you deny it. &gt; You are confusing me with someone else. Nothing you say makes any sense: Is that why you're deleting most of your comments? Because how "nice" you are? You don't expose details - so, it can't be for privacy reasons... &gt; I never trashed no one, quite the contrary, I was one of the few supporting /u/fommil. So, am I a no one? &gt; All I did against you was ask if have really ever supported any open source project, either financially or through code contributions, or were just saying it when you said "Before I support certain developers I usually check out if their software works at least and they really care about it". You're trying to make it more charming, but that wasn't how you asked. You've attacked me and started to "protect" fommil for the karma. &gt; Your answer was "Go fuck yourself stupid troll, I know you're just a freshmen without a job who's trolling everyone around. You haven't done anything in your life besides posting bullshit on scala's ask-anything and "show-off" threads." oh, and btw, i am in no way related to https://github.com/kpws Probably that's not your github account but your reddit account is still used for trolling purposes. There's no other "kpws"-like account from r/scala who constantly trolls around. You've said without a github account I'm a no one - then where is your github account full with "contributions"? &gt; And by that you obviously mean: "Go fuck yourself stupid troll, I know you're just a freshmen without a job who's trolling everyone around. You haven't done anything in your life besides posting bullshit on scala's ask-anything and "show-off" threads." we get it. Oh, so you're different? Then why do you delete your raging comments? Don't play the victim, I know who you are. &gt; all i said back then was "there is no god", really the epitome of offensive and "fuck all believers, are you all stupid"? And what was in the other threads? Like calling everyone "retarded sheeps" and wanting to "exterminate" these sheeps? So, you ARE that troll. &gt; I was never banned from /r/atheism. It's been ages since i last posted there. For sure? And btw, you asking for moderation after your shitfest there is ridiculous. &gt; I almost never post or comment at r/programming But when you do... you delete them because others would know what to expect from you. &gt; you need a mirror. go back and read you own comments. who is mean, "insultive" (sic), and full of hate here? You are the real troll here, the one who falsely accuses and tries do demean every and single one who disagrees with you even in the slightest. You're full of shit. **You delete your comments to hide your shitty behaviour.** I don't. You're an absolute hypocrite. &gt; you make false accusations against anyone you see. Like against who? I'm accusing you with trolling and hipocrisy. &gt; Your word are devoid of any value. **"Look at me! I'm not full of hate!"** - kpws Edited.
Hey zero, I totally feel your frustration! I too, am trying to learn lagom and there just aren't a whole lot of good examples beyond the overly simple 'hello world' example. Here is a list of some of the samples that I'm using for reference, I hope they help. Also, full disclosure, I work for lightbend and I can tell you that we are working very hard to improve upon the examples and learning environment for this new technology! lagom-scala-chirper: https://github.com/purijatin/lagom-scala-chirper.git online-auction-scala: https://github.com/lagom/online-auction-scala.git reactive-roulette: https://github.com/andrei-l/reactive-roulette.git Also, these are not full projects but some super handy recipes to do some common web-like things like adding CORS filters, and doing authentication. lagom-recipes: https://github.com/lagom/lagom-recipes.git
&gt; first, yes, to me and because of your behaviour, you are less than one to me now. second, i did not trash you even once. i never attack you, you were the one attacking everyone out of rage. You talking about behaviour... Please, spare me from your hipocrisy. Be honest once. &gt; yes, that is exactly how i asked. i do not doubt, though, that that was not how you read it. **Then why did you delete it if it was so "nice"?** &gt; i never said anything like that. quite the contrary, you were the one saying "his github is pretty much a freshmen's account". do you suffer from mental confusion? don't you know the distinction between what people say and the voices inside your head? are you out of your medication? dude, seriously, go back to your pills. Don't try to run away from the shit you've said - I DID call out that account and I call you out too since you're a lier and a troll. &gt; i never, ever, said anything like that, here or anywhere else. do you want us to trust your perturbed mind to correctly and precisely remember something you think someone else said over a year ago? really? Yeah, I remember stuff from years ago because I'm not small child. Is that hard to believe? Why did you delete those comments then? &gt; i don't deny i'm an atheist, i don't deny i've said "there is no good" a couple times on reddit in general and once on /r/scala in particular. but never, ever, did i call anyone "sheep" or say "exterminate" even once, i assure you. Yes, I certainly trust you after you can't stop lying - even now. Edit: oh, and btw you're not an atheist - you're an anti-theist. And not just the regular one but the one who goes to internet sites to call everyone stupid sheeps. You like to tell people how they or their words don't worth anything("your word devoid of any value", "stupid sheeps" etc.). &gt; my shitfest? my? MY? you can remember comments i supposedly made over a year ago but can remember what you yourself wrote last week? you have a pretty inflated sense of self, don't you? I DO remember what I said - I told you I don't watch my language but I remember **a troll like you**. &gt; your words are void of meaning and value, they do not offend me. Because you don't respect anyone. You've only defended fommil for the karma. *You've no credibility because you delete all your comments*. &gt; you are only able to see the worse in a person, and you go through great lengths to see it in the wort possible way. On r/scala, yours, fommil's and the @titanthinktank accounts are the ones I don't respect. Wanna know why? Because of all the lies and trolling. &gt; i say something you disagree with, i'm the ultimate troll. Nonono, that's not how it works - *you troll, you get downvoted and you delete your comments*. That's why you're the ultimate troll. You usually remove your "good" comments too if they're in the same thread with the raging comments to hide yourself from others. &gt; i say some that there is no way you perverted mind is capable of distorting into something bad, and i just "started to compliment certain people(probably for karma)". karma for what? to go to heaven? a heaven i don't believe exist? oh, no, you mean "reddit karma", don't you? even more useless yet. Don't deny that reddit karma doesn't matter to you - that's most of your posts' and comments' reason. Oh yes, once you've "protected" someone(without context of course) and now you're a saint? &gt; that's it, you and your attitude are beyond despicable. i'm blocking you. yell all you want, it won't ever reach my eyes again. Yeah, go along: lie to everyone, troll freely and if you play the victim enough, someone will believe you. 
And of course: he started to call me crazy because I remember his trolling crusades and started to belittle my word and ignore the fact that he hides his "ugly side" to look good - and then he removed his comments... Following the scheme all the way, huh?
&gt; you are right, steven. i'm the troll here. i'm the only one who offends everyone else. I've never said that you offend everyone - you offend a few people. But you hide it to look "credible" when they look at your comment history. **You said you don't care about karma and that you're "nice" - then why do you remove your comments?** &gt; you are always right, nothing you ever do is ever wrong. your personal offenses are not offenses, they are just "language". Then go ahead and debunk my arguments. I'm only rude to astro-turfers, trolls, liers and fake-victims. &gt; you complain about my deleted comments, yet you deleted your own github account. what was there that you do not want us to see, steven? Because I don't need it and I *respect gitlab more*. Their service is better IMO and they're more friendly to developers. I don't want to support a monopoly. No one should.
Pretty sure the @tailrec annotation throws an error, not just a warning, when it cannot perform tailcall optimization.
You're a moron.
&gt; There are plenty of folks out there who use Spark for such purposes, but I like to work without the need for bulky things like Hadoop clusters. I wasn't aware a Hadoop cluster was required. IIRC also, with the Spark/Cassandra connector, it runs the code on the Cassandra instances themselves which would improve performance. The solution in this blog would have to transfer every single row over the wire, correct?
I [posted](https://www.reddit.com/r/scala/comments/6x024c/bootstrapping_the_web_with_scala_native_part_1/) a blog post with roughly the same title a few weeks back, so I just wanted to give a heads up on what new content is in the talk. Most of the code shown is available [on github](https://github.com/rwhaling/dinosaur), some of it hasn't been merged yet, but will be soon! If folks have time to watch, I'd be happy to hear your thoughts and feedback. Basic introduction to Scala Native How POSIX sockets work (in Scala Native) Why writing servers is hard A minimum viable HTTP Server Going faster with FastCGI An unconscionably shameful netcat hack Integrating with LibUV Performance numbers -- "Faster than node?"
What bullshit? I didn't see any call-out about any bs from you. What was it? That since I don't have a github account I worth less? Or that if I don't show the bills about payments for FLOSS projects then I'm a liar? Or that not funding projects which doesn't even work makes me a scum? There wasn't any "call-out" - only trolling from you and fommil.
Two errata from the talk: 1. I forgot to mention that exclamation mark is the dereference operator *facepalms* 2. For the performance numbers: the blocking-FastCGI implementation, I used Scala Native behind a simple Golang proxy server that is also in my repo. For the LibUV-FastCGI implementation, I used Scala-Native with Nginx only. The numbers quoted are preliminary, but I believe them to be representative; I will be publishing my data and Gatling simulations to the repo soon, with the next blog post.
There are pro's and cons of every approach. Doesn't spark load the entire table in memory? I don't want to double the memory load on my production server just because I am running a data load operation. Plus installing something on production serves requires endless battles with operations / networking and other teams who just have one objection or the other. With this approach the only thing to be careful about is not to hit Cassandra too hard and the throttling feature of akka streams is very handy for that.
Was Scala thought to be extensible and then there were added new libraries, or was Scala designed to be functional from the beginning? Because in the book "Programming in Scala" by Odersky, Spon and Venners there isn't much functional programming.
&gt; you are so contradictory. How? Did you actually read my comment or just jumped right in to write more bs? &gt; you take the slightest criticism as the ultimate offense, I don't get mad about criticism or insults. I call you out here for being a hypocritic troll and playing a victim. &gt; yet you trash and bash everyone at will, for no reason. How so? I called you out for being a hypocritic troll - that's a pretty good reason. You can delete all your comments but it won't wash away your lies. &gt; fommil was only responding to your numerous attacks. but in your head, trolls are the others, never you. fommil had the first blood. After I've forgotten ensime and didn't even knew him I wrote about how sad is the state of ensime. He tried to defend it by calling it a "hackers' tool" or something like that but I knew that most of the bug fixes came from the outside and I called his dev method lazy - that's why he's mad and he *hates* those who report issues(he never wrote on any of my issues). Since then, I don't value his opinion at all because he lied that I only reported fake bugs but then he admitted some of them received a fix. There is more about this and you can read about it in the other thread.
I've read the first edition of Programming in Scala and it's more like a specification about the language. It gives you a good ground on designing libraries. The **Sca**lable**language** was designed to be a hybrid language mixing impure functional and object-oriented features. Implicits have been added later to the language which help to implement typeclasses(with traits) - those are the foundations of *purely* functional programming - if you're interested in that then checkout the scalaz/cats libraries and their documentation. 
Well, hopefully you're not assuming that programming rooted in category theory as the definition of FP, but the functional parts of scala were set up in a way that resembled a nominal version of the ML module system, after implicits came then all the typelevel projects came in and the haskell like style of doing things became dominant among scala devs, who try avoiding OO. Apart from having an object system resembling ML modules, scala has always had pattern matching, tailrec, lambdas , HKT, higher order functions, partial functions, etcetera. 
Interesting stats! I wonder how well this simple Java-backed scala map performs: @specialized class JavaBackedMutableMap[K, V] extends collection.mutable.Map[K, V] { private var jMap: java.util.Map[K, V] = new java.util.HashMap[K, V] def +=(kv: (K, V)): JavaBackedMutableMap.this.type = { jMap.put(kv._1, kv._2) this } def -=(key: K): JavaBackedMutableMap.this.type = { jMap.remove(key) this } def get(key: K): Option[V] = if(jMap.containsKey(key)) Some(jMap.get(key)) else None def iterator: Iterator[(K, V)] = { import scala.collection.JavaConverters._ jMap.asScala.iterator } } If it performs just as well as the java mutable map, I wonder why it wasn't implemented this way.
I've been an ensime user for... years? I contribute what I can. I certainly never complain! I've fixed a few bugs have a monthly donation set up. Ensime is great software. I feel lucky to have it. I'm grateful that @fommil spent so much of his energy making it a reality. I am barely able to maintain my own (crappy) projects, let alone take it over. But I will still contribute when I can. And, worth mentioning it, merging other people's code can sometimes be almost as hard as writing it!
I indulged you. I read your comment. It didn't help. Also, you misspelled lier (liar). Oh, you're also really toxic. Please try and talk less.
^ dude sees the community as shit... but actually is just seeing a reflection of himself
There is the `JMapWrapper` which is pretty much that. /** Wraps a Java map as a Scala one. If the map is to support concurrent access, * use [[JConcurrentMapWrapper]] instead. If the wrapped map is synchronized * (e.g. from `java.util.Collections.synchronizedMap`), it is your responsibility * to wrap all non-atomic operations with `underlying.synchronized`. * This includes `get`, as `java.util.Map`'s API does not allow for an * atomic `get` when `null` values may be present. */ case class JMapWrapper[A, B](underlying : ju.Map[A, B]) extends mutable.AbstractMap[A, B] with JMapWrapperLike[A, B, JMapWrapper[A, B]] { override def empty = JMapWrapper(new ju.HashMap[A, B]) } And its super trait trait JMapWrapperLike[A, B, +Repr &lt;: mutable.MapLike[A, B, Repr] with mutable.Map[A, B]] extends mutable.Map[A, B] with mutable.MapLike[A, B, Repr] { def underlying: ju.Map[A, B] override def size = underlying.size def get(k: A) = { val v = underlying get k if (v != null) Some(v) else if (underlying containsKey k) Some(null.asInstanceOf[B]) else None } def +=(kv: (A, B)): this.type = { underlying.put(kv._1, kv._2); this } def -=(key: A): this.type = { underlying remove key; this } override def put(k: A, v: B): Option[B] = Option(underlying.put(k, v)) override def update(k: A, v: B) { underlying.put(k, v) } override def remove(k: A): Option[B] = Option(underlying remove k) def iterator: Iterator[(A, B)] = new AbstractIterator[(A, B)] { val ui = underlying.entrySet.iterator def hasNext = ui.hasNext def next() = { val e = ui.next(); (e.getKey, e.getValue) } } override def clear() = underlying.clear() override def empty: Repr = null.asInstanceOf[Repr] } 
You might be seeing effects discussed [here](https://contributors.scala-lang.org/t/can-we-get-rid-of-cooperative-equality/1131).
Well for one, the @specialized annotation is used sparingly in order to keep down the size of the standard library binary. @specialized is not a 'free' performance enhancement, for each generic parameter that you specialize the number of cases it generates grows exponentially.
&gt; == Construction (create collection from 1e6 fixed int -&gt; int pairs) &gt; &gt; 906 immutable.HashMap I've noticed that Scala's immutable Maps are constructed in a simple, but very inefficient, way. Basically if you call Map(1 -&gt; 1, 2 -&gt; 2, ..., n -&gt; n) then a series of n intermediate Maps are created. It would be more efficient to use a mutable internal structure during building and then transfer/convert it to the immutable Map once building is finished. What method are you using to construct the immutable.Map. Are you using a Map.apply(…) or Map.newBuilder?
I would be surprised if @specialized does anything useful when wrapping a Java generic, what do y'all think?
Thank you! What is the best paper book that explains that?
Such a pity, such a good technology and the docs are bad. Thanks a lot, I will try.
You are absolutely correct, i corrected the post with a screenshot.
Is there a plan to improve any of this is 2.13 collections revamp?
See also: http://www.lihaoyi.com/post/BenchmarkingScalaCollections.html There are also a few optimized collections, but not for Ints I think. See mutable.AnyRefMap and mutable.LongMap.
Yes, I am basically using HashMap(tuples : _*), and it basically performs the same as constructing the map one by one. I'll try the builder, thanks! But still, even the access is kind of slow.
Lagom was written to appeal/sell to Java developers, if you are coming from Haskell https://github.com/http4s/http4s may seem more at home. With Future, don't use it. Some alternatives: * https://static.javadoc.io/org.scalaz/scalaz_2.12/7.2.15/scalaz/concurrent/Task.html * https://monix.io/docs/2x/eval/task.html 
Try Akka-Http for REST components
https://www.amazon.com/Functional-Programming-Scala-Paul-Chiusano/dp/1617290653
Just want to throw my two cents in here. http4s is a good mention for functional programmers, but it's not a great comparison. Lagom is an opinionated, reactive microservice framework and http4s is a minimal http service library. There really isn't much of a comparison to Lagom in scala; one is either using it or building their own services/frameworks from smaller components (like http4s + alpakka Kafka streams + Cassandra client usage). Also, a blanket statement on "dont use Futures" is just short sighted. Sure, you might design your own code base around scalaz or cats, but these libraries interoperate with Futures for a reason: you'll be using plenty of libraries that leverage Futures and you'll need to know how to handle them properly. Some good information: https://github.com/alexandru/scala-best-practices/blob/master/sections/4-concurrency-parallelism.md http://twitter.github.io/effectivescala/#Concurrency
I’m currently enrolled in that course. Most of the examples they teach can be found in “Programming in Scala (3rd ed)”, cause the course instructor co-wrote it. 
Suppose, I created a microservice with lagom, say a simple hello microservice, where can I use functional paradigm in code? What about Play framework? It is functional? Which microservices framework should I use?
Holy sheez, i just read about this lagom, and guess what its using Play, so i guess it must be for PLAY, which means its for the CONFORMIST MVC SLAVES
Also -- cats-effect is a great way to interact with Futures that also has its own internal async and shift operations: IO https://github.com/typelevel/cats-effect
&gt; I indulged you. I read your comment. It didn't help. Did you actually read the comment or you just tried to find material for shit-talk? I believe I know the answer. Btw, are you the new mini-troll? Or are you just butthurt because I said ensime is garbage? Well, here is the thing: ensime IS garbage. It's conceptually bad but the implementation is worse. I doubt it became better over the last year, especially if its developers are assholes like you and fommil. &gt; Oh, you're also really toxic. Please try and talk less. How about you take your own advice then? It's not like you're respectful at all. You didn't even try to understand my point - you just wrote some low-effort comment. Well done!
^ dude thinks he's funny when he writes some low-effort comment... but actually he's just a butthurt no one.
Play and lagom aren't inherently functional at all. They work, and have large user bases, but they are primarily imperative. They can be really overweight frameworks, but there's enough built-in functionality to make some things easy-ish. That said, all your code that interacts with the framework can be written in a functional style, and you can treat the framework as the edge of the world (sort of). You won't really have a lot of control over the interfaces the framework expects, but running `unsafeToFuture` on cats-effect `IO` and `IO.fromFuture(someFutureApi).shift(myThreadPool)` can get you into a functional context where you can have more confidence in your code being correct. It is a little tedious, as you tend to have several "programs" running around in your codebase, but it is definitely doable. There isn't a "functional microservices framework" that I know of. If you want a functional stack, you want to go with [http4s](http://http4s.org/), [cats-effect IO](https://github.com/typelevel/cats-effect) + [fs2](https://github.com/functional-streams-for-scala/fs2/blob/series/0.10/docs/guide.md) or [scalaz streams](https://gist.github.com/djspiewak/d93a9c4983f63721c41c) and [scalaz IO](http://eed3si9n.com/learning-scalaz/IO+Monad.html), [doobie](http://tpolecat.github.io/doobie/) for any sql database clusters. You will have to model many of the other services as data yourself, but that's easy enough - modeling any effects can be done with http://frees.io/ or [Eff](https://github.com/atnos-org/eff), but I tend to use simple tagless-final on its own with `IO` as my `F[_]` of choice now. Look into [Simulcrum](https://github.com/mpilquist/simulacrum)/[Machinist](https://github.com/typelevel/machinist) for typeclass boilerplate generation. For managing service discovery, infrastructure, and others, I've had pretty good luck with just wrapping an `IO` context (`Future`, `Task`, `IO`, pick one you are comfortable with) around the various java libraries available for such things over the years. Sure, you have some impure code out there, but it isn't anything you wrote. It surely is more productive in the short term than developing principled libraries from scratch that do little more than talk to an elastic search cluster or a logging framework. Best of luck!
I have some material available here in the form of videos https://www.reddit.com/r/ScalaConferenceVideos/search?q=lagom&amp;restrict_sr=on&amp;include_over_18=on See if it helps you in finding something beyond HelloWorld.
By the way, since `HashMap#get` returns null if the key is not found, you could use `Option(jMap.get(key))` instead of the if-else.
DyanamoDB is a huge pain in the ass to work with!
However, someone might have actually put null as the value at that key right? In which case we would return the wrong answer None
I would say that scala doesn't try to be purely functional, and most libraries represent that. It tries to marry both worlds in a productional manner. Of course there are libraries / users which are more functional then others. Look at scalaz Task for example if you want more "predictable" concurrency (in your words, I find Future fine as it is). 
I thought, that I could take advantages of FP when I learned haskell and apply the concept to scala. I am confuse, lightbend motivate on they website to using scala but most of they code are not functional. It is a little bit odd not? 
There are few different reasons: #### Cost of Correctness Scala's `==` does more work than Java's `equals`. This is the right thing to do, and combined with efforts to properly clean up `eq` and cooperation in the Valhalla design, this has the potential to get equal or close to the performance of Java. This is not going to happen. #### Inefficient by Design Consider List.fill(1)(100).map(_.toString).filter(_.startsWith("3")).head which touches every single element two times, builds two intermediate datastructures, just to return a single element in the end. This is a hopelessly inefficient and flawed design, which causes a lot of other issues as well related to re-usability, modularity and general usability of the API. This is not going to be fixed. #### Performance Bugs due to Complexity The whole collections API does not only consist of a strict, sequential implementation, but also iterators, views, parallel collections and Streams. Combined with the depth of the inheritance tree and the extensive redirection inside the implementation, it is hard to figure out which implementation is actually called and whether that implementation is implemented correctly and efficiently. To have any fighting chance to reign in on implementation complexity, the data structures, the description of operations on them, and the execution of those operations would need to be cleanly separated. This is not going to happen. #### Shared Default Implementation There are implementations of collection operations almost at the top of the collection hierarchy, above the mutable/immutable distinction. They pretty much require to be overridden almost everywhere, as a shared implementation can either be focused on mutable collections (and therefore incorrect on immutable collections that expect that data cannot be changed) or be focused on immutable collections (and therefore inefficient on mutable collections), but never both. This might be fixed, but at the cost of breaking most third-party implementations of the collection API.
True, but I can't think of a legitimate reason of using a literal null in a scala code base. It would be better to make it clear why there is a difference between no value and null with a more complex type than `Option[V]`. (maybe [Some, None, FileNotFound](https://www.google.fi/url?sa=t&amp;rct=j&amp;q=&amp;esrc=s&amp;source=web&amp;cd=2&amp;ved=0ahUKEwj6svSgnNXWAhXBYpoKHXp9A_AQFggrMAE&amp;url=https%3A%2F%2Fthedailywtf.com%2Farticles%2FWhat_Is_Truth_0x3f_&amp;usg=AOvVaw09uzVqEes_EbHxrqQ6G-ha))
To use lagom, do I have to know about akka first? Should I read the akka in action book first before start using lagom? 
Scala allows you to program in an OO or FP or OO-FP hybrid style, with or without mutability. So libs/frameworks are written in a variety of styles.
It is not odd. It's by design (whether good or bad is not the topic of our discussion). There's a concept of [levels](http://www.scala-lang.org/old/node/8610) in Scala. The approach is to enable "scalable" teams -- basically you start out coding almost Java-like and progress to being able to apply all the typelevel and functional concepts you see in many scala libraries. Scala itself enables functional programming but does not force it upon you. Lightbend is not in the business of creating functional programming tools, they are in the business of garnering consulting contracts and selling commercial web products. The customer base that uses java and java-like scala is much larger than the customer base that uses FP scala. Thus their projects reflect that -- play and lagom and akka. These projects use some FP style, but usually hide it behind a decidedly imperative api to attract consumers that don't know (or even necessarily want) pure FP codebases. A large part of the community supports a wide variety of FP tools and libraries that are purely Scala-centric, but Lightbend products are explicitly marketed as dual use Java/Scala projects, and their programming style reflects that. All that said, I find that pure categorical scala programming using typeclasses and encoded effects enforces a reasonable and usable subset of the larger Scala language footprint that ensures software is well-defined, encapsulated, testable, and thus more maintainable than the wild-west of OO/FP scala employed in the Lightbend products, which feel an awful lot like Spring/J2EE projects. That said, I use play WSClient, json, and iteratees in some codebases at work and, like I said, wrapping them in a context tends to hide most of the practical problems with them when doing FP. They aren't always very lawful, but they do tend to operate efficiently and with proper interface design the use of them doesn't really leak that much, making them easy to replace when the team finds an issue with them or when changing designs.
I am migrating a spray application to Finatra. I really like the "feature testing" feature of Finatra. Really makes it possible to do "test first" approach. Another great thing about is performance and very succinct and clean syntax. Compared to Spray, You can write endpoints which don't look like Christmas trees because of deep nesting of http constructs. Before selecting Finatra I had also considered Http4s, but I found the documentation to be really scarce and I was getting repeatedly stuck. 
At work, we evaluated a number of these frameworks recently. We own some services which also just expose JSON over REST. We went with Finatra. He's my rationale for why we didn't go with any of the other frameworks you mentioned: We didn't look at Play too much because we we looking for a library rather than a framework, and we weren't using SBT at the time. For akka-http, there were some reason it might be a good fit; we have used Spray in the past, and currently use akka and akka-streams, and it's supported/backed by Lightbend. However, although we found it readable, it found it hard to write the code (implicit heavy DSL, and lots of custom concepts in the docs). Also, it didn't provide any metrics. For http4s, it was OK, but nothing compelled us to use it. We're mostly doing FP with the standard library, so it's cats/fs2 foundations weren't interesting to the team. For Scalatra, it's nice, but built on top of java servlets which doesn't support asynchronous responses which was a requirement for us. (We don't want to use a thread per request.) For Finatra, it's nice, built on top of Finagle which we have experience with (Finagle HTTP client). It has metrics out of the box. We found in the most pragmatic of Finagle/Finatra/Finch. But it's definitely less principles than others. The built-in JSON deserialisation is with Jackson and uses reflection rather than typeclasses, for example. For Lift, for people use that anymore? It had some interesting ideas, but I didn't even realise it's being maintained.
I'm not sure that's helpful. Here's my recommendation on how to pick which framework to use. It you're new to Scala or just want a framework to be productive with, use Play. If you like the akka/reactive ecosystem, use akka-http. If you're into the functional/typelevel stuff, look at finch or http4s.
Why didn't you just migrate from Spray to Akka HTTP?
+1 for play to just get things done. It's a framework it has lots of stuff you probably want. Database evolutions, json serialization...
Many people in my organization are infatuated with Finatra because "twitter" is running it. I personally like Akka HTTP more but I wanted to move quickly rather than get into a endless battle of the Frameworks.... (in the end all frameworks do the same thing). Anyway, it has great performance, very clean code, no DSL nonsense, good documentation and my favorite feature testing. So I am quite happy that I went this way.
Yep. Play scales better when you start needing features you haven't thought of, eg changing context path, URL generation, etc.
Inefficient by Design: Can't this be fixed by using iterators? Isn't this just an argument of lazy vs eager by default collections Performance Bugs due to Complexity: Isn't this already being fixed by the ongoing collection redesign? Shared Default Implementation: Isn't this also being fixed by the ongoing collection redesign? Also, are there really any third-party implementations? Isn't nobody doing this currently because of the problems mentioned in 'Performance Bugs due to Complexity' and 'Shared Default Implementation'?
I've worked mostly with Play and Finatra. If you go with Play, you are probably find anything that you need, it has plenty of users and its well maintained, its simple and you can start being productive fast. If you go with Finatra, you might not find all things that you need at some point of the time, it has great features and documentation, it is well maintained, it has a good DSL (in my opinion), and you might need to invest more time to get productive, once productive it would be very easy to follow your own patterns to get things done easily. None of these frameworks are pure functional but practical (again, my opinion), personally I prefer Finatra and I would recommend to do some examples in both and take the one makes you feel more comfortable with (I did this while I was in your shoes).
Lightbend doesn't really do FP. The libraries they work on use functional ideas here and there but and you can't reason with them in the same way you reason about Haskell code. This is a huge improvement if you're coming from Java but disappointing if you're coming from Haskell. Look at the llbraries from [Typelevel](https://typelevel.org/) (some were mentioned above) if you're interested in doing FP in Scala.
&gt; There's a concept of levels in Scala. The approach is to enable "scalable" teams -- basically you start out coding almost Java-like and progress to being able to apply all the typelevel and functional concepts you see in many scala libraries. How does this work out? The company I work at might be the biggest user of scala and I've been trying to encourage my team to try it over python because. We have tons of support for it. but there's a bit of resistance because they're unfamiliar and I think intimidated by some of the features the language offers. They can write oo python and occasional java. 
How long ago were you looking at http4s? I considered it for a project last year, but decided against it because of the sparse documentation. However, it's improved significantly since then. I just starting using it in a new project.
Have you considered what kind of abstractions over sockets connections that can be used at "zero cost" with Scala-native?
It works out well with good guidance. However, going from Python (and occasional Java) to a decent level of Scala takes quite some time and not everyone is able to do it - some don't have the motivation and for some the concepts are hard to grasp. Still, from a company and personal perspective it's worth it.
It works out fine.But if python works for your team, , why switch? Rewriting and retraining has a cost. Deployments for the jvm are entirely different than python, too. I used to do both but the robotics project that was primarily run on python dissolved about a year ago. The features are mostly helpful. The quick guide to easy mixed lower application level scala - 1. Don't use var. val or def only. 2. abstract scala classes and final class/case classes only. Don't extend classes, you'll run into early initializer hell eventually. 3. Use abstract classes instead of traits and provide implementations in them. 4. Build static groups of functions in objects as modules. 5. Learn map, flatMap, and fold(left/right). These are your Swiss Army knife My opinionated additions for new scala teams. This is optional; but you'll have better luck this way: 6. Injections occur at the method level, not the instance level. 7. Use a single Environment to hold injections, and make it an implicit parameter on your methods. 8. Provide a trait for your environment that has all your abstract injections as abstract methods. In the companion of that object, provide an implicit instance with your default injections defined. You can override it in tests by defining an implicit mocked/stubbed/test instance of it. 10. Don't throw. Define your abstract classes as generics on F[_]. All public methods return the generic F[ReturnTypeOfMethod]. In your concrete instances of the class, extend your abstraction and fill in the F with Future or cats/scalaz IO. ONLY USE ONE type in the entire codebase to replace F. That means only Future or IO. Don't mix them. Once you are in the context, you stay it until you get to the last line of your main, where you may want to exit the IO you chose. The above is easy enough to follow and makes for a pretty comfortable codebase, even for new teams to scala. The higher-kinded F[_] everywhere will make some people balk, but it is so that you don't end up with IO [Future[Try[Either[Error, Result]]]] out of the gate. You want one F[_] container type that can be run asynchronously or synchronously and handles errors thrown by java libraries. That pretty much narrows it to Task, IO, or the standard library's Future. After you've mastered making modules that way, and building programs with flatmap, and doing implicit injection, you'll want to start making the environment object be actually specific to the methods it gets attached to because who wants god config objects? At that point you are ready to switch to full FP and can learn typeclasses and tagless final, adts, the works. Your programs will already be close to tagless final programs already. You'll also want to start using more of cats and doing more specific data encodings. You'll get there quickly enough - but adjusting to 1 - 5 is harder than 6 - 10. Adjusting to full FP from there is really easy - it's mainly learning to read FP and FP api docs. Thinking in values rather than in processes is different. 
Play is an MVC , so if you love slavery go on do it. And look at the rest comments, none of them are programmer, so none of them are using ScalaJS the real deal tech, since these are just blind followers, for their salaries they are ready to do anything their bosses tell them to follow, THIS IS HOW AN ENSLAVED ORWELLIAN WORLD LOOKS LIKE.
Thanks everyone for your answer it was really helpful, i'll settle with play (since i'm a beginner) and dig later into finatra and finally http4s/finch when i'll be me more comfortable with the language &amp; fp.
Obvious troll is obvious. But you'd've been much more convincing if you hadn't forgotten to mention that all these overpaid-enslaved-wannabe-programmers eat a baby every millionth request served by their foolish framework, which really is the shocking part.
If you aren't doing html web templating over your service, or real-time sockets, play is way too heavyweight. Circe + http4s is just a webserver, routing library, and json library. If you can read an api, you can run and test it with raw compile time safe scala. No special testkit/fake application/injection module management knowledge required as there is for canonical play applications. It isn't any easier and adds a lot of unnecessary boilerplate/ceremony to everything without much in return if you are doing a simple rest service. I think most people use play because it generates the routes from the routefile, and has a prescribed way of doing everything, including application code organization. For migrations, flyway is fine on it's own and hooking it up to your app is a couple lines of code https://flywaydb.org/getstarted/firststeps/sbt 
The proliferation of different execution approaches grafted on to the sides of the collection API is one of the big reasons why everything is such a mess, not a solution. Why bother fixing collections if you can just add another, buggy one that lacks support for some operations? (iterators) Better add another buggy, slow implementation to fix it! (views) Then let's have completely different thing like Streams, which is a completely separate approach but living inside collections, so that nobody can ever rely on any collection method being safe to call without stack-overflows, out of memory errors or hangs. How does this work if one dares to combine them? Pretty much not at all. Combine some stream with e. g. views and you tend to end up with something that is more eager than Stream or views on their own. How are people to supposed to implement 5 different execution approaches correctly, if they can't even do it for one? The new collections design is a grand exercise of not understanding the mistakes made in the existing design and repeating all of them.
I’d point out that play uses aka-http under the covers. If you find you need to move off of play later, you’ll have many fewer surprises by at least considering it as your migration path. 
I know there was some website, with scalajs, where we could interactively explore AST scala generates? Maybe through scalameta or something... I can't find link to it..does anyone know?
&gt; Lagom was written to appeal/sell to Java developers, if you are coming from Haskell https://github.com/http4s/http4s may seem more at home. No it wasn't, its a framework for microservers not a library. Whether Java or Scala developers use it is largely irrelevant &gt; With Future, don't use it. Some alternatives: * https://static.javadoc.io/org.scalaz/scalaz_2.12/7.2.15/scalaz/concurrent/Task.html * https://monix.io/docs/2x/eval/task.html This is also largely irrelevant to the complaint, and also completely irrelevant to how Lagom is designed
&gt; But if python works for your team, , why switch? Rewriting and retraining has a cost. Deployments for the jvm are entirely different than python, too Sometimes it seems to not work heh. We maintain a lot of internal tools that need to be reliable. Thousands of lines of python is hard to refactor without types. Uncaught exceptions in multi threaded apps cause issues. Scala is also the main language, so we would get to reuse production ready libraries, and get support for tooling from the company. Thanks for the detailed response!
&gt; going from Python (and occasional Java) to a decent level of Scala takes quite some time and not everyone is able to do it Hmm I guess my thought was that was with an ide imperative scala wouldne be to crazy to get the hang of. Maybe I'm off with my judgement
Meanwhile, somebody already created an issue: https://youtrack.jetbrains.com/issue/SCL-12660 Nice!
Here's a curated list of [Scala beginner tutorials](https://reactdom.com/blog/scala-books).
Thank you! 
Your welcome! :) Let me know if you have any questions.
Servlets have supported async responses for a while. I have used servlets with akka, not by choice though. https://docs.oracle.com/javaee/7/tutorial/servlets012.htm
&gt; Use abstract classes instead of traits Why?
Is akka-http "easy" to use ? because i saw many people complaining about the complexity and documention of it.
https://blog.buildo.io/exploring-scala-ast-in-your-browser-dc0b1fb743e0
take a look at scala.meta :) https://scastie.scala-lang.org/o7QQYwENR16D3hjBJSEldw
Basic services are fairly easy, but it does get more complicated fairly quickly. But if you’re interacting with an actor system from a service endpoint, I honestly think you can’t beat it for interoperability
You will have a rough time trying to interpret imports. All they tell you is [prefixes of] symbols that have been brought into scope. They may be relative or path-dependent and may be unused, and they may not be classes. If you're trying to figure out which classes refer to other classes you might do better using something like [ASM](http://asm.ow2.org/) to inspect the bytecode and find all the references. This has the advantage of working for any JVM language.
Yep, I'm fully aware of that. But I'm not looking for the perfect tool right now. A rough estimation would be a good start. 
Use scala-meta for parsing scala sources, building a set of import statements should be pretty straight forward.
[removed]
Fwiw, here's the DL4J site: https://deeplearning4j.org/ Here are the repositories: https://github.com/deeplearning4j And the Gitter community: https://gitter.im/deeplearning4j/deeplearning4j
awesome work. thumbs up bro
As would loading up the bytecode in ASM (likely easier) and it would be accurate.
Yeah, since looking at bytecode is language independent, I'd be surprised if there isn't already a tool where to analyze usages with a given classpath.
Not sure if you mean it as an abstraction for http, but if you mean as an abstraction to just sockets there is java.net.socket implemented in Scala Native already. 
Take a look at https://github.com/lihaoyi/acyclic This resolves dependencies between the files of your compilation run; any dependencies, e.g. fully qualified access, and not just imports. Default instructions are for SBT, and it just checks for dependency cycles. But it can be used anywhere you can use scala compiler plugins (e.g. command line, bazel, gradle, ...), and you can mangle the code to do whatever you want with the dependency graph (dump to JSON, dump to dotfiles, etc) or to restrict the dependencies to just imports if that’s what you wish acyclic’s dependency-tracking code is copy-pasted from the Zinc incremental compile plugin, at some point in the ancient past. I personally have a fork of this that dumps my project inter-file dependency graph as a dotfile I can `| tred | dot -Tsvg &gt; graph.svg` for easy viewing. Only took an hour or two to mangle the existing code to make it do that, so you should be able to do similar things without too much difficulty.
Simple enough indeed for getting started. This visitor pattern kicked off a nice trip down memory lane! It still requires to get a good deal of details right though, but once done it's at least reasonable correct. Thanks for the pointer.
Binary compatibility - traits that change members require all things using the trait need to recompile. Abstract classes don't. This is critical for interfaces. &gt; If you plan to distribute it in compiled form, and you expect outside groups to write classes inheriting from it, you might lean towards using an abstract class. The issue is that when a trait gains or loses a member, any classes that inherit from it must be recompiled, even if they have not changed. If outside clients will only call into the behavior, instead of inheriting from it, then using a trait is fine. -- ["To trait or not to trait"](http://www.artima.com/pins1ed/traits.html#12.7) &gt; We can also use a sealed trait in place of a sealed abstract class but there are binary compatibility advantages to using abstract class. A sealed trait is only needed if you need to create a complicated ADT with multiple inheritance. - [FP in Scala for Mortals](https://leanpub.com/fpmortals/read) 
HashMap(tuples) uses the builder too, and the builder is actually the part that's slow because it makes all these intermediate maps. In other words, using the builder directly probably won't make much difference because it's where the slow part is!
sbt isn't a package manager, it's a build tool. Every compiled language has one. You can tell sbt how to compile pretty much any structure but it's easiest to use the defaults. You can also use scalac directly (good luck).
Literally all of your posts are to r/scala and almost all of them are abusive in some way. I'm sorry that you're so mad at the Scala programming language, but take this trash somewhere else.
I think you chose well. Play is great, and you aren't settling :). We use Play in production and it has been a great experience. 
Thanks bro. 
I don’t think it’s that dire. Scalafix will now remove unused imports, after that you can use scalameta to pull the imports and ask them for their fully qualified name which is all that is needed. Now that scala.meta is backed by a semanticDb you can pull real types for all symbols.
How would the parser know the difference between calling a method on object foo named bar with variable baz, and passing three variables named foo, bar and baz? It gets even worse when you consider stuff like post fix ops. If the answer is to only allow values directly and not any expressions, why not in this specific case when you can use expressions everywhere else. IMO comas exist exactly to answer those questions. Removing them seems stupid and a lot of work for little gain.
&gt; It's so common that I managed to convince them to merge an less footgun-y alternative, which uses varargs to require commas. Notably, [uTest](https://github.com/lihaoyi/utest) uses macros do accomplish the same thing without commas. I don't know if I agree-with/understand your proposed solution, but I agree it sure would be nice to have some better, "standard" way of doing this...
This is true. Still though, it's a good means to chunk through a massive data set without consuming tons of resources. Spark and flink both have quite a bit of resource requirements to run big data sets through all those complicated joins. Also, I believe you could turn the Alpakka stream into a Spark streaming application to get all of their fancy APIs if needed.
How does this affect their commercial support? Edit : NVM. Found this HN thread in which they have answered a lot more questions - https://news.ycombinator.com/item?id=15403112
&gt; How would the parser know the difference between calling a method on object foo named bar with variable baz, and passing three variables named foo, bar and baz? Because they're separated by line breaks, just like statements in a normal block are. The rules for continuance of lines would be the same. &gt; Removing them seems stupid and a lot of work for little gain. I don't think calling the idea "stupid" adds anything of value to the discussion, and it's pretty rude.
Hmm, very interesting that you're using macros to do this. I mean, as long as that generalizes to the same effect, that seems like a reasonable way to go. Also glad you brought up the issue of testing. That reminds me of another instance: [specs2's immutable spec style](https://etorreborre.github.io/specs2/guide/SPECS2-3.9.5/org.specs2.guide.Structure.html#expectations). It's really easy to accidentally only have one working assertion when you think you have several.
To clarify what I mean, the [`build.sbt`](https://github.com/lihaoyi/utest/blob/master/build.sbt) file for uTest has this near the beginning: name in ThisBuild := "utest" organization in ThisBuild := "com.lihaoyi" scalaVersion in ThisBuild := "2.12.2" crossScalaVersions in ThisBuild := Seq("2.10.6", "2.11.11", "2.12.2", "2.13.0-M2") updateOptions in ThisBuild := (updateOptions in ThisBuild).value.withCachedResolution(true) incOptions in ThisBuild := (incOptions in ThisBuild).value.withNameHashing(true).withLogRecompileOnMacro(false) //triggeredMessage in ThisBuild := Watched.clearWhenTriggered releaseTagComment in ThisBuild := s"v${(version in ThisBuild).value}" releaseVcsSign in ThisBuild := true The `.sbt` processing turns that into a list of settings passed into some invisible method. I'm saying why not have the ability to write methods that would take data defined in this way? The `settings` call at the end of your file could become something like: lazy val root = project.in(file(".")) .aggregate(utestJS, utestJVM, utestNative) .settings { publishTo := Some(Resolver.file("Unused transient repository", target.value / "fakepublish")) publishArtifact := false publishLocal := () publishLocalSigned := () // doesn't work publishSigned := () // doesn't work packagedArtifacts := Map.empty } It's a seemingly small change, but if I'm not mistaken, the ability to write data structures this way motivated the concept of the .sbt file format in the first place.
implicit function types of dotty fixes this! https://www.scala-lang.org/blog/2016/12/07/implicit-function-types.html
&gt; if I'm not mistaken, the ability to write data structures this way motivated the concept of the .sbt file format in the first place. I've never heard that. I think it's 1 or more of: * interactively set settings in the shell and `session save` them; * less boilerplate (no imports, no extending a trait with an object); * no need to look up a plugin's FQCN to have its keys in scope.
"imperative Scala" is not what I mean by "decent level". ;)
https://github.com/scalameta/metadoc has an sbt plugin to generate a static site to browse scala sources with jump to definition/find references, demo http://scalameta.org/metadoc/. You can use the same data to analyze which classes reference other classes, a good place to do that would be here https://github.com/scalameta/metadoc/blob/08753bc8397a48ebf73d1464136961f3099f3eb7/metadoc-cli/src/main/scala/metadoc/cli/MetadocCli.scala#L169, parse `document.contents` into a `scala.meta.Tree` and collect the `(Defn.Class.name, Defn.Class.ctor.paramss)`. I'd love to include that visualisation as part of metadoc if you're interested in contributing ;) Metadoc uses http://scalameta.org/tutorial/#SemanticAPI, you can also use that directly if you prefer. Add the semanticdb-scalac compiler plugin, enable -Yrangepos and analyze the persisted .semanticdb files in the META-INF/semanticdb directory in the classpath.
have you tried this https://pityka.github.io/nspl/ 
well since it still made for web, won't it be easier just ot use some simple JS library?
Wait...how?
That's an interesting question. First, I should caveat that I'm not a high-performance networking expert; this project was only aiming for adequacy, not "world's fastest webserver" As I understand it, the C++ and Rust communities use "zero cost abstraction" to refer to techniques that emphasize compile-time specialization of generics rather than virtual method dispatch. This makes a lot of sense in a typical OOP program that manages its runtime state by allocating and accessing objects. With performance-driven network code, your data is originating from the physical network interface, and high-throughput designs focus on "zero-copy" IO. At the extremes, this means bypassing the kernel altogether, and configuring the NIC to write directly into a userspace ringbuffer. [Netmap](http://info.iet.unipi.it/~luigi/netmap/) is a good example of this technique, and I like [this article](http://highscalability.com/blog/2013/5/13/the-secret-to-10-million-concurrent-connections-the-kernel-i.html) also. Although I don't take it to that extreme, there are little things that make a difference. For example -- I try to keep packed binary data intact in buffers as much as possible, and parse it lazily, rather than copying everything into a ParsedRequest object or something. This turns out to make a lot of difference, as I've been measuring it. If there's a catch, though, it's this: mid-tier web server performance doesn't really matter that much. Everything bottlenecks at the database anyway. Unless you're writing a packet filter, like the second link above, it's probably unnecessary. This will probably change as we shift to using in-process persistent memory rather than external databases, though, which will be a very, very exciting time. *Update* I asked on the Scala Native gitter about the implementation details on zero-cost traits. Here's what I got: rwhaling 09:11 Someone on Reddit asked me about "zero-cost" abstraction -- I think meaning Rust/STL style static dispatch, and I was a little fuzzy on the answer. densh 09:15 Strictly speaking we don’t have this at the moment. Scala Native is closer to Go than it is to Rust/C++. rwhaling 09:16 That's about what I thought. Methods on object do compile down to static methods, though, right? As do CFunctionPtrs? densh 09:17 Yep! Writing code in certain style (i.e. avoid virtual dispatch, don’t use generics, zone allocation where appropriate) does lead to Rust/C++ level of performance but it’s not idiomatic Scala any more.
Thanks for the helpful context! I hadn't thought of those things. But I still think the motivation I identified clearly is part of it, too. I'd suggest that the main feature of the file that *every* SBT user encounters is the concept of statement-like creation of the root setting's list. I've yet to see a `Build.sbt` with no top-level settings at all. &gt; interactively set settings in the shell and session save them; Yeah, my idea would only make this kind of thing more flexible! You could save session settings for particular subprojects. &gt; less boilerplate (no imports, no extending a trait with an object); &gt; no need to look up a plugin's FQCN to have its keys in scope. We don't go through nearly so much trouble to avoid these things anywhere else I can think of in the language ecosystem. Why are they so onerous in a build file? I'm much more likely to have repetitive boilerplate throughout the many files of my project code than in my single build structure. I guess my point is, which of the features of the SBT file could be captured by language features that would actually be reusable throughout your Scala codebase? My focus here is on "concurrent statement blocks", but I could see trying to generalize the other features you identified, too.
"Runs on the JVM or in the browser with minimal dependencies."
my point was that if you're already using scala.js - it wouldn't be a problem to connect one JS library, and there are plenty of those for data visualization
Ok so let's assume that no other newline problems arise and that all is well there. Can you use vals in these blocks, if yes, are they ignored, and why just vals then? If vals are ignored, can you also call methods that return unit? If that's ignored, can you call methods that return some value, but you don't care about that value and only call the method for its side effect? If at some point above you say no, and that thing is not ignored and would create a type error or similar, why? All of these are things are things you can do in most other things enclosed in curly braces. (The exception is for, where val syntax is not allowed, and you have to assign even methods that return unit to some value, for example _, but in for it is clear which value is what). Let's look at the idea of excluding an element with if. Normally in Scala, if `if` doesn't have an else statement after it, what would have been that else branch returns unit. So why wouldn't that rule apply here? As pointed out below, implicit functions can actually solve this problem in many cases. Let's look at how you could get syntax similar to SBT as an example. //These are not defined here as that's not the core of how this works case class Settings(entries: Seq[DslEntry]) sealed trait DslEntry sealed trait CanUseDsl { def entries: Seq[DslEntry] def addEntry(entry: DslEntry): Unit } type DslSyntax = implicit CanUseDsl =&gt; Unit trait Key[A] { def :=(a: A)(implicit canUse: CanUseDsl): Unit = { canUse.add(???) } } trait SeqKey[A] extends Key[A] { def +=(a: A)(implicit canUse: CanUseDsl): Unit = { canUse.add(???) } def ++=(seq: Seq[A])(implicit canUse: CanUseDsl): Unit = { seq.foreach(+=) } } def settings(createSettings: DSLSyntax): Settings = { implicit val canUseDsl: CanUseDsl = new CanUseDsl //Just imagine the internals of CanUseDsl createSettings Settings(canUseDsl.entries) } //Later settings { Key1 := "Foo" Key2 := "Bar" //Works with if statements as it's the method call that does the job, not the if(expression) Key3 := "Baz" return value //We can use a for loop to unpack our stuff as you said would be cool for (myVal &lt;- myList) Key4 += myVal }
Martin had this in one slide at Scala Days 2017 Kopenhagen: table { row { "Row 1" } row { "Row 2" } } which is what you are looking for I guess? The implementation details are in the slides which I don't have at hand atm EDIT: https://youtu.be/9lWrt6H6UdE?t=3416
thanks...
This would be a good example program.
I would say that `val` and other definitions would be disallowed. They'd have to come from an enclosing sequential-mode scope. You'd kind of have to choose between sequential and concurrent mode. It gets rather subtle and confusing (a la SBT) when you try to mix the two paradigms. I'd say each line's expression would work just like any other Scala expression. More curly braces could be used to use a standard [sequential] block for an expression. Someone *could* choose to do something side-effectful, but that would be kind of defeating the purpose. But it's clearly not a Scala principle today to try to impose limits there. There's precedent for using `if` elsewhere, in the case of guards in `case` and `for`. This would simply be another context where `if` has different semantics. Thanks for the example with `implicit`s. That's pretty compelling from the standpoint of the API experience I had in mind! My only hesitation is that I don't see how that would work without relying on side-effects. That's not a deal-breaker at all. But I think one of Scala's most impressive accomplishments is in showing just how far you can go without side-effects, in a language that still feels not so different from Ruby. That's one of the things that's so impressive about SBT, complaints aside.
Ok, it is then kind of sad that the builder is so inefficient; having the whole data at hand should make it easy to construct the optimal structure directly. I would expect a mature language to have these cases handled nicely - this alone could save quite some $$$ on hosting fees globally.
Ok, so that makes more sense to me. /u/Katrix400 showed how it works. I replied above.
We're going to keep on supporting Deeplearning4j etc., bundled in an enterprise distro called SKIL, the Skymind Intelligence Layer. Its like RHEL for deep learning. Development on all the OSS projects will continue at the same pace. We'll just be working within the framework of Eclipse to help their members figure out how ML fits into their stacks. 
&gt; If you aren't doing html web templating over your service, or real-time sockets, play is way too heavyweight. Circe + http4s is just a webserver, routing library, and json library. Like [this](https://www.playframework.com/documentation/2.6.x/ScalaEmbeddingPlayAkkaHttp#toolbar)? Embedding play also has the advantage of having code reload and, eventually, use other features if you need. It is also possible to use flywaydb with Play, like demonstrated here: https://github.com/playframework/play-scala-isolated-slick-example And, if you want to use Circe, take a look here: https://github.com/jilen/play-circe
It's honestly an area I find lacking in the scala ecosystem and a big reason that data scientists tend to use things like R and Python in place of scala. As you mentioned breeze is one option. Another one I've seen lately is doodle: https://github.com/underscoreio/doodle I'd love to see now focus around these kinda of tools!
&gt; I've yet to see a Build.sbt with no top-level settings at all. Then you have probably never seen a multi-project `build.sbt`. Multi-project builds avoid top-level setting definitions, because they apply to the "root" project, which is almost never what one wants. See for example https://github.com/scala-js/jsdependencies/blob/master/build.sbt, or the build of pretty much any repository under the Scala.js GitHub organization.
I'm not saying you can't use these things *with* play. I'm saying that using these things without play is bebeficial unless you are truly running a server -side rendered dynamic website. If you are doing server side rendered forms applications, it's great. Most people don't do that anymore (they use the server to serve some rest/tgraphql endpoints, and the main app is static html with js doing all the dynamic content work. Play is overwrought to serve (even complicated business logic ruled) stateless json responses.
Touché. But do you see my point? SBT still *does* support the top-level statement collection syntax, and it's still widely used. Basically, I'm saying it proves this sort of DSL functionality is desirable enough to exist, and unless there's something so special about build files, why not figure out a way to bring it out of build file purgatory? 
Can you clarify why putting something in a Future doesn't make it async? I thought that was the entire point of them. Or do you mean that it doesn't necessarily guarantee that it is run asynchronously?
Completely agree. The Scala language offers huge advantages over Python/R for data science, however without visualisation tools people aren't going to use it (or, not exclusively anyway). Piggybacking off Javascript or Python visuals would seem to be the best bet right now.
Thanks. Keep up the good work.
Ok, my bad then.
Awesome. Can't wait to try this out today. Edit: I'm upgraded. Can't say that I see a ton of speed benefits but SBT 1.0 has much better logging and I'm glad that I'm able to upgrade my dependencies to their newest, 1.0.x compliant versions.
Awesome, Play was the last dependency holding me back from finding out how rough around the edges sbt 1.0 really is ;-) Not expecting much change (yet) in the laggy code-change-reload cycle, but at minimum can start ditching legacy scala 2.10 code in my builds. Onward and upward; thanks to Play team and contributors for getting sbt 1.0 out the door much faster than expected.
I ran into this problem also when trying to make my dsl look a lot less like code for some non technical users. I must take a look at your solution in uTest I can probably adopt it too. 
i just upgraded! now to get play working with java 9!
That was super quick, nice job Play team!
It(sbt) works pretty well, actually. There are a few sbt plugins that haven't updated yet. 
Depends on what you mean by "working". After upgrading the thing that is most broken in sbt (huge lag in multi-subproject builds), persists. Have 30 subprojects in current app; it's pretty painful, even in a warm vm tasks like `run` are unbelievably slow, literally waiting 5 seconds before *anything* even begins to happen (that's the overhead of sbt finally figuring out that the only change was a `println("foo")`). Over the course of days and weeks this kind of constant lag is a serious productivity drain.
Sounds like a college assignment to me.
Please share how far you got.
Are you talking about this issue: https://github.com/sbt/sbt/issues/3527 And Play has [its own file watcher](https://github.com/playframework/play-file-watch) which uses a native API for Mac OS X instead of polling. Are you experiencing the delay in Play apps?
I’d suggest looking into Apache Zeppelin. It’s rather similar to Jupyter notebook but specific to Spark. Very importantly, it has in notebook graphing. Obviously this lacks the sophistication of a dedicated package like matplotlib (which I use for production figures), but it does a huge amount to show me the basic shape of my data. 
Take a look at Spark's implementation.
Afair this also is on Coursera's Scala Course.
&gt; which uses a native API for Mac OS X On Linux (Fedora 25), although the linked issue has at least one Linux user affected (i.e. problem may not be platform specific). &gt; Are you experiencing the delay in Play apps? Absolutely, the delay is far and away worse in Play than in Scala.js, likely due to shallower dependency graph in the latter. While Scala has gotten faster (as of 2.12.3), SBT has gotten even slower picking of code changes, so we're at a net negative in terms of productivity gains. Rapid code-change-reload turnaround is crucial, there *must* be a way to avoid extraneous delays. [This project](https://github.com/jrudolph/sbt-optimizer) may be helpful wrt to seeing where on earth the time goes.
Do you have any open source project which broadly follows these guidelines ? I'd like to see this in practice.
Let me guess, you’re going to post one of these articles for every single backend service possible
[removed]
You might be interested in finagle and finch which are both functional in nature. Travis Brown also has a library called catbird which bridges the gap between cats and twitters ecosystem. 
Climbers? Scalafornians?
Steppers. Scalafarians.
Scalanators?
But using the vararg-splice syntax `xs:_*` means that you're (implicitly) allocating ALL your elements into a big array (wrapped in a `Seq`), then passing that array to the constructor for the map to be created. I've noticed this being a performance problem before. For a related reason, for example `0 :: Nil` is much faster than `List(0)`! – the latter creates an array for the `0` in vararg position... Thus I think you would be better off using the builder. Let us know the numbers if you try it!
Scalars?
Scaleros. Scalars.
Scalinist ahah. I'm adopting that :)
Here is a compiled version: https://gist.github.com/MasseGuillaume/e2381a992410840d4425f83b1a07cac9 | Proposed Name | Comment | Author | |-------------------------------|--------------------------------|--------------------------------------------------------------| | Escalators | | [Will Sargent] | | Scalars | (pronounced "scholars") | [John Page] | | Scalabradoodle | | [Heather Miller] | | Scalabrador | | [Heather Miller] | | Scalobsters | | [Someone] | | Scally | (like Sc-ally) | [Heather Miller] | | Scaliberator | | [Heather Miller] | | Scalinists | | [Bodil Stokke] | | Scalator | | [Justin Kaeser] | | Scalawag | (with Scala&amp;Crossbones) | [Justin Kaeser] | | Stairwinder | | [Justin Kaeser] | | Scoder | | [Justin Kaeser] | | Scaladores | (meetup in Sao Paulo) | [Justin Kaeser] | | Scalamari | | [Victor Klang] | | Scallama | | [Loïc Descotte‏] | | Scalawags | | [Albert Chang] | | Scalibur | | [Bernardo‏ @scenesinthecity] | | Scalifragilistico Espialidoso | (Approved by Mary Poppins.) | [Juan Méndez‏] | | The Scala Holla | | [Chris Davenport‏] | | Scaldersky | | [Jim O'Flaherty‏] | | Scalava | | [Jim O'Flaherty‏] | | ScalaWalla | | [Jim O'Flaherty‏] | | Scaldesky | | [Jim O'Flaherty‏] | | Scalator | | [(((bendthewheel)))‏ @freakphase] | | Scalacious Crumbs | | [(((bendthewheel)))‏ @freakphase] | | Scalaphane | | [Jim O'Flaherty‏] | | Scalites | | [Jim O'Flaherty‏] | | Scalamanders | | [Francois Armand‏] | | Climbers | | [Ramin_HAL9001](https://www.reddit.com/user/Ramin_HAL9001) | | Scalafornians | | [Ramin_HAL9001](https://www.reddit.com/user/Ramin_HAL9001) | | Scalafarians | | [justinpitts](https://www.reddit.com/user/justinpitts) | | Steppers | | [justinpitts](https://www.reddit.com/user/justinpitts) | | Scalanators | | [Ramin_HAL9001](https://www.reddit.com/user/Ramin_HAL9001) | | Scaleros | | [pcp_or_splenda](https://www.reddit.com/user/pcp_or_splenda) | * From: https://twitter.com/heathercmiller/status/916279184724516864 * From: https://www.reddit.com/r/scala/comments/74v7yo/we_need_a_good_name_for_scala_programmers_scala/
Masochists?
Scalactites
I always liked scalawags... There used to be a podcast with the same name about Scala
I've used `Scalatypes` for a few years.
Scalafists?
Scallops?
Scalamari is great. Now who can draw one?
Scala programmers
Scalalaladingdongs.
Scalactites.
I don't think "we" need a name. 
Was going to post this. (Thankfully as an ops guy I only part of Scala I ever see is stack traces if one of the devs makes a bubu... 😅)
Scalarchist?
Scalaists? Scalaistas?
- Scalista (like a Barista); possible mascot: [Luwak / Civet](https://www.craftbeveragejobs.com/the-worlds-most-expensive-coffee-kopi-luwak/) - Scalandro (like a Malandro) I also liked Scalactites and Scallops. More possible mascots: - [Purple Pig-Nose Frog](http://news.nationalgeographic.com/2017/08/purple-frog-new-species-discovery-india-monsoon/) - [Jerboa](https://www.youtube.com/watch?v=NduZGe_Ekr0) - [Cats, of course](https://www.boredpanda.com/funny-poorly-drawn-cats/)
Video linked by /u/sciss_: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Cute jerboa, Arab Rabbit Cute Animals](https://youtube.com/watch?v=NduZGe_Ekr0)|Animal Farm|2017-01-29|0:01:26|213+ (98%)|17,098 &gt; Cute jerboa, Cute Animals, Arab rabbit --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/sciss_ ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=do1lkws\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
Scalars is clever for two reasons: 1) the pronunciation matching that of "scholars" is a welcome homonym. 2) the spelling matches that of the mathematical term, of which those of us in machine learning often deal with. 
Seconded. Scalars also are extra applicable because they are individual values themselves which is a nice representation of the individual (valuable) developers. No one person is a matrix!
I agree.
Dickbutts
Hasn't been mentioned yet, but Scallion could work, though it might make sense to change the Scala logo from red to green if the name were to stick.
Scalafari live, babylon system, dread.
Scaladores, the group from Brazil, reads like the Portuguese word "Escaladores" and it means "climbers" in English.
There's an unofficial mascot, Scala Cat: https://scalacat.net/ ^^
Finch is built on top of Finagle. I've understood it to be a functional wrapper around Finagle with as little overhead as possible. You could absolutely build microservices w/ Finch. Unfortunately, I don't believe Finch fully supports Websockets. 
Scalars. (•_•) ( •_•)&gt;⌐■-■ (⌐■_■)
Oh I just came up with a term for this bullshit. Syntactic diabetes. Scala doesn't have syntactic sugar, it has syntactic diabetes.
I mean, if you're looking for help, this is a good place. But people will not respond kindly to profanity filled rants. Not sure what you were hoping to accomplish here.
I just upgraded to Play 2.6.6 with Java 9 without any real problems. For my particular Play project I just needed to switch to SBT 1.0.2 and add the two lines below to ~/.profile JAVA_OPTS='--add-modules java.xml.bind' export JAVA_OPTS
Go read a book. 
The bracketed types are type parameters and allow you to generalize a function. Depending on the context they could be the return type or the type of the arguments. Here's the relevant docs: https://docs.scala-lang.org/tour/polymorphic-methods.html
Never mind, [I found my answer](https://docs.scala-lang.org/tour/polymorphic-methods.html) by accident, and now I'm ever more mad. It's literally just generic methods, but instead of using the java standard of angle brackets&lt;&gt;, the assholes who designed the syntax decided they knew what was best and changed it. My point about scala having syntactical diabetes still stands though.
Please resubmit this thread without the profanity
Yes, the syntax is different than Java because it isn't Java.
Clearly. Java is a readable language.
For addTransitive it is designating the argument s is a Set of tuples where the first component of the tuple is of type A and the second type B. The return type isn't specified but is infered as Set[(A,B)].
Do you expect spoken languages to use the same syntax as English? Its like you are trying to learn Spanish and are complaining about ¡. 
The reason Scala uses square instead of angle brackets like Java and C++ is to avoid ambiguity since method names can contain angle brackets. Indead it isn't the only language to define type parameters in that way.
Future guarantees that the block is ran concurrently not asynchronously. This post does well to describe the difference: https://codewala.net/2015/07/29/concurrency-vs-multi-threading-vs-asynchronous-programming-explained/ If you don't have access to a async driver you can look at the `blocking` tag. This will temporary increase the threadpool, but that may not be what you want if you're working with a fixed connection pool.
Could your comment be a proof that majority of them are Germans?
At least I am.
There is a finagle-websocket package that you can use. 
Please no. Scala developers must not finish like JavaScripts developers, calling themselves ninjas, working on a MacBook at Starbucks to show-off more skills than they have.
I am not, but I agree with him
is finch production ready?
Obviously you should run your own tests, but its a fairly thin wrapper around finagle, so you get all of the twitter metrics, monitoring etc... Its also performant (around 95% of finagle's throughput is the latest claim), though performance isn't everything. Beyond that, its well documented (which counts for a lot) and has IME been a pleasure to work with 
Considering how much of a circejerk is our community, I guess sth like `scalasturbators` with hard, erect Scala logo as mascot would convey the message the best. But `scala programmer` or `scalar` would be also fine.
Hascalators
could you please explain more about finagle? And finch is the wrapper of the wrapper?
I would start by reading the Finagle docs, then Finch. I think you'll learn quite a bit from their docs. It is pretty well documented.
what does version with M2 mean?
what about metrics, services discovery, etc it is free?
This information is in the docs but short answer is finagle takes care of a lot of platform related things you’ll want (zipkin tracing, stats, things like Time budget and retry back off, circuit breaking, etc)
The last question, I am trying to create helloworld endpoint with finch but the compiler complains about the dependencies: [warn] Note: Unresolved dependencies path: [warn] com.github.finagle:[finch-module]_2.12:0.16.0-M2 (/Volumes/Dev/finch/helloworld/build.sbt#L8-11) [warn] +- default:helloworld_2.12:0.1 [error] sbt.librarymanagement.ResolveException: unresolved dependency: com.github.finagle#[finch-module]_2.12;0.16.0-M2: not found [error] at sbt.internal.librarymanagement.IvyActions$.resolveAndRetrieve(IvyActions.scala:331) [error] at sbt.internal.librarymanagement.IvyActions$.$anonfun$updateEither$1(IvyActions.scala:205) [error] at sbt.internal.librarymanagement.IvySbt$Module.$anonfun$withModule$1(Ivy.scala:229) [error] at sbt.internal.librarymanagement.IvySbt.$anonfun$withIvy$1(Ivy.scala:190) [error] at sbt.internal.librarymanagement.IvySbt.sbt$internal$librarymanagement$IvySbt$$action$1(Ivy.scala:70) [error] at sbt.internal.librarymanagement.IvySbt$$anon$3.call(Ivy.scala:77) [error] at xsbt.boot.Locks$GlobalLock.withChannel$1(Locks.scala:93) [] at xsbt.boot.Locks$GlobalLock.xsbt$boot$Locks$GlobalLock$$withChannelRetries$1(Locks.scala:78) [error] at xsbt.boot.Locks$GlobalLock$$anonfun$withFileLock$1.apply(Locks.scala:97) [error] at xsbt.boot.Using$.withResource(Using.scala:10) [error] at xsbt.boot.Using$.apply(Using.scala:9) [error] at xsbt.boot.Locks$GlobalLock.ignoringDeadlockAvoided(Locks.scala:58) [error] at xsbt.boot.Locks$GlobalLock.withLock(Locks.scala:48) [error] at xsbt.boot.Locks$.apply0(Locks.scala:31) [error] at xsbt.boot.Locks$.apply(Locks.scala:28) [error] at sbt.internal.librarymanagement.IvySbt.withDefaultLogger(Ivy.scala:77) [error] at sbt.internal.librarymanagement.IvySbt.withIvy(Ivy.scala:185) [error] at sbt.internal.librarymanagement.IvySbt.withIvy(Ivy.scala:182) [error] at sbt.internal.librarymanagement.IvySbt$Module.withModule(Ivy.scala:228) [error] at sbt.internal.librarymanagement.IvyActions$.updateEither(IvyActions.scala:190) [error] at sbt.librarymanagement.ivy.IvyDependencyResolution.update(IvyDependencyResolution.scala:20) [error] at sbt.librarymanagement.DependencyResolution.update(DependencyResolution.scala:56) [error] at sbt.internal.LibraryManagement$.resolve$1(LibraryManagement.scala:38) [error] at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$12(LibraryManagement.scala:91) [error] at sbt.util.Tracked$.$anonfun$lastOutput$1(Tracked.scala:68) [error] at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$19(LibraryManagement.scala:104) [error] at scala.util.control.Exception$Catch.apply(Exception.scala:224) [error] at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11(LibraryManagement.scala:104) [error] at sbt.internal.LibraryManagement$.$anonfun$cachedUpdate$11$adapted(LibraryManagement.scala:87) [error] at sbt.util.Tracked$.$anonfun$inputChanged$1(Tracked.scala:149) [error] at sbt.internal.LibraryManagement$.cachedUpdate(LibraryManagement.scala:118) [error] at sbt.Classpaths$.$anonfun$updateTask$5(Defaults.scala:2353) [error] at scala.Function1.$anonfun$compose$1(Function1.scala:44) [error] at sbt.internal.util.$tilde$greater.$anonfun$$u2219$1(TypeFunctions.scala:42) [error] at sbt.std.Transform$$anon$4.work(System.scala:64) [error] at sbt.Execute.$anonfun$submit$2(Execute.scala:257) [error] at sbt.internal.util.ErrorHandling$.wideConvert(ErrorHandling.scala:16) [error] at sbt.Execute.work(Execute.scala:266) [error] at sbt.Execute.$anonfun$submit$1(Execute.scala:257) [error] at sbt.ConcurrentRestrictions$$anon$4.$anonfun$submitValid$1(ConcurrentRestrictions.scala:167) [error] at sbt.CompletionService$$anon$2.call(CompletionService.scala:32) [error] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [error] at java.util.concurrent.Executors$RunnableAdapter.call(Executors.java:511) [error] at java.util.concurrent.FutureTask.run(FutureTask.java:266) [error] at java.util.concurrent.ThreadPoolExecutor.runWorker(ThreadPoolExecutor.java:1149) [error] at java.util.concurrent.ThreadPoolExecutor$Worker.run(ThreadPoolExecutor.java:624) [error] at java.lang.Thread.run(Thread.java:748) [error] (*:update) sbt.librarymanagement.ResolveException: unresolved dependency: com.github.finagle#[finch-module]_2.12;0.16.0-M2: not found [error] Total time: 1 s, completed Oct 8, 2017 3:51:25 PM the sbt file looks as following: name := "helloworld" version := "0.1" scalaVersion := "2.12.3" libraryDependencies ++= Seq( "com.github.finagle" %% "[finch-module]" % "0.16.0-M2" ) What am I doing wrong?
Scalars has a kind of obvious mascot animal: owl. 
&gt;method names can contain angle brackets Why tho. Method names shouldn't look like strong passwords.
I don't use finch but I'm guessing '[finch-module]' is not meant to be used literally but is meant to be replaced by the finch module you want to install.
To define operator like methods. I agree that it can be misused, but if you are defining a type where `&lt;` makes sense and it's definition clear, why not have the language support it?
&gt; Define your abstract classes as generics on F[_]. How about defining just the methods as generic and leaving the abstract class monomorphic? Is there any disadvantage to that? 
It’s not the HTTP layer that defines a level microserviceness. It’s about domain modeling and autonomy.
Indeed! I'm dying to make my perfect test framework (which will be inspired by, and similar to in many regards as @lihaoyi's μTest) and I realised that I need this feature to make it happen without hacks. I'm looking forward to Dotty!
finagle is a protocol agnostic framework which abstracts the concept of a "Service" into things like "Client" and "Server" stacks. Frameworks like Finch and Finatra provide a nice web framework on top of Finagle. Most of what you'll consider for microservices will likely be on the client side. The server can be any language/framework you want. That said, both Finch and Finatra benefit from the Finagle stack implementation, so you can reuse the same services on your clients and servers (e.g metrics and tracing or custom additions, also finagle-mysql adds SQL traces). You can check out the starter Finch server generator I contributed to Swagger Codegen A little swagger.json and you'll get a stub server that you can begin adding logic to. Fair warning with Finch, when I looked at it for work, I had a lot of issues with implicit conversions for json serialization using argonaut and circe. I would add Java 8 types or custom types and compilation would fail because JSON serialization is handled at compile time. I don't know how well Finch handles non-JSON content types, because I never got that far into using it. My team at work has been using Finatra for over a year. I really like it. It supports JSON via Jackson, and Thrift. Some things are less intuitive, like getting a health endpoint required by our internal infrastructure to write pain text "ACTIVE" took longer to figure out than I thought it should. I don't recall the problem we encountered, unfortunately. Other than that, I haven't had many issues. I did struggle trying to get custom exceptions mapped into my own types, but while I was working to figure it out, a new version of Finatra was released with support for that use case. I've gotten great feedback and quick responses from devs of both.
Forgot to mention, it's Finagle that provides things like retries, budgets, client side load balancing, and all that stuff you generally want in a microservices architecture.
At my work place, we’re using akka, sparkml, finatra, Apache Juneau, Apache streams, to name a few. 
If you're going the Framework route, I recommend Play. It has a huge user base, tons of documentation, and can be very friendly to newcomers. Finch is also a good choice here, though this is based on the Twitter ecosystem which has a lot of controversy around it (e.g. the Twitter async object "Future" competes with the standard "Future" from the scala standard library). If you'd like to embrace functional programming and the Typelevel community, many users have gone to http4s. Though I personally don't recommend this for a new user as documentation is sparse, relatively speaking. Still, it is an excellent lightweight library for REST applications. I recommend at least poking through the codebase / doc. Akka HTTP is the backend of the Play framework, so if you want a "library" instead of a framework, this is a good choice. It can be a bit complicated with larger use cases though. Also, as a backend developer with a Python background, I would highly recommend taking a look at Apache Spark's Scala SDK. It can give you a great side by side with python code approaches and may be a good dip into the waters of Scala for you. 
I think the only library that should be mandatory knowledge is Akka. Depending on who you end up working for, you might need to be familiar with either Scalaz or Cats, and maybe Shapeless. Pretty much everything else depends on what work you end up doing.
Since we're here. Finch 0.16-M3 with Scala Futures syntax support has been just released: https://github.com/finagle/finch/releases/tag/0.16.0-M3
&gt; scalawags Someone posted this on twitter: https://en.wikipedia.org/wiki/Scalawag
**Scalawag** In United States history, scalawags were southern whites who supported Reconstruction and the Republican Party, after the American Civil War. Like the similar term "carpetbagger," the word has a long history of use as a slur in Southern partisan debates. The opponents of the scalawags claimed they were disloyal to traditional values of white supremacy. The term is commonly used in historical studies as a neutral descriptor of Southern white Republicans, although some historians have discarded the term due to its history of pejorative connotations. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/scala/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
I strongly disagree with the learning Akka part. IMO Akka is way overused and tends to mislead developers on using the wrong technology for their problems. Unless you need high concurrency tool, don't learn Akka. It's better to learn some FP-ish libraries such as Cats / Scalaz, which tends to solve (help to solve) much more general programming problems. From my personal experience, Akka looks shiny at first sight because the granularity level provided by actors seems quite natural, and the base concepts quite easy to learn. But past this point, it looks like it introduces way more issues than it solves. Once again, if you don't need highly concurrent apps, do not use Akka ! I believe that 90% of backend devs, depending on the nature of their work of course, can be achieved without Akka.
Would you recommended finatra over finch?
Why should I use finch over finatra? What are the advantages of finch? 
Scalanauts
Memory is becoming less and less an issue. Though some of us still do have only 4GB of RAM (not upgradable). On these machines IDEA is a pain, but vim works very well.
Lagom.
Have you looked at [Lagom](https://www.lagomframework.com)?
I found this is my gists. Hopefully this is useful for somebody.
&gt; We plan to address the valuable reviews made to SIP-29 on inline/meta in a new proposal, so that SIP-29 can be rejected err, think that *accepted* was meant here, no?
SIP-29 will be superseded by a new proposal, so rejected was intended here. I admit the wording is a bit confusing.
Yeah, I would. Finch is lighter weight and uses more functional programming. Finatra is a lot more like other Sinatra clones (Scalatra, Javalin, express.js) so I feel like there's less ramp up. In either case, you'll want to understand Twitter's implementation of Future really well. You'll also want to work through some examples of Finagle use. There's a Finagle Name Finder example on GitHub which I point new devs on my team to. SoundCloud engineers have some good intro videos on why they moved to Finagle. I've used http://functional.tv in the past as well, but it looks like it just points to YouTube directly now which seems harder to filter the videos.
ah, ok, thanks for clarifying.
- Have a sound base on the language. Scala as a language is very extensible. Understanding the theory behind FP is very helpful. - Learn the concepts first. For example the Gossip protocol behind Akka, Raft consensus etc., Libraries are just implementations of these concepts. - Play is the closest comparison to Django, but there are a lot of fundamental differences between both. - Spark is a great data analysis platform. It is a single platform upon which you can prototype and also take it to production without rewriting stuff. A backend dev job is a very broad term. Startups stick with tech stacks such as Django because they are faster to prototype in. Scala and the libraries in the JVM-Scala land take time to learn and its worth it. 
So the typesignature of your example record would be (Long, Map[String, Any]) at least if those are supposed to be string keys. So that's what you should get int your MyDataBuilder. I couldn't really try it out lacking your input data but on a glance your flatten wouldn't result in tuples. But maybe there's a way to this all together better. Can you tell us some more about the Data and what you want to do with it? Having to use the Any type can have some bad effect because it might let slip through data that you have not intended to be processed by this. The other issue if you represent highly irregular json in a DF is that you will get a messy schema with many nullable values which can make it hard to work with. 
[Some people would say that there is no need for such thing](https://www.youtube.com/watch?v=LDW0QWie21s) as Scala already has mattern matching and foldLeft. After a bit of thinking I have to agree: what do you use? Dooby, Slick, Cassandra? What is your event format? Custom case classes, protobuff? Once you remove all specific use cases, there is not much common part left. Just use whatever event/message format you want to use, foldLeft with pattern matching over it, and the only thing left for "framework" would be ensuring that operations are idempotent and you save the offset of last parsed event... which you could have easily achive with whatever DB you want and possibly sth like Kafka if you don't want to store serialized events in SQL DB. But that's just my $0.05.
yes that's the current type signature. The data is a sequence of events that I wish to store in a Dataframe structure which will eventually be used for reports etc. Example of the data is on the stackoverflow link How would I pattern match on a Map[String, Any] ? What other data type could I use instead of Any ? Perhaps building a case class that includes all possible values in the json ?
Not a big fan of this statement. While direct use of Akka Actors tends to be discouraged nowadays, Actors serve as the backbone for several key libraries/ecosystems (e.g. Spark, Play). Its good to understand what they are and how to control them. Also, Akka Streams is a very viable toolset for developers to learn. 
I just wanted to share my personal experience, I have seen so many applications built on top of Akka for no reasons, whereas a plain Play / http4s / Finch... would have sufficed. I just wanted to highlight what I believe the right path for a new learner. Don't get me wrong, it's always important to understand the tools we are using, but it does not mean we should build our first apps the same way ! I found Akka very good at promoting itself as the key library for solving all the problems, whereas it might not be the best fit to do simple webapp. 
There are a couple. [Lagom Persistence](https://www.lagomframework.com/documentation/1.3.x/scala/ES_CQRS.html) has already been mentioned. Another high level one is [fun.cqrs](http://www.funcqrs.io). A bit more low level ones are [Akka Persistence](https://doc.akka.io/docs/akka/current/scala/persistence.html) (which is leveraged / wrapped by the aforementioned ones) or [eventuate](https://rbmhtechnology.github.io/eventuate/). 
Came here to mention Lagom. There really isn't another competing "framework" in this area. Though Lagom is pretty new and can feel limiting considering its opinionated bias towards Cassandra / Kafka, and the documentation is surprisingly sparse here (I say surprising considering how well Play is documented. All in due time I suppose.). Their workflow also leverages Cassandra _as the events source_, which may or may not fit your use case. These isn't bad design by any means, but it is an opinionated one that won't fit all use cases. If you're looking to use other DB technologies, such as CouchDB, Elasticsearch, Redis, etc., it may be best to just craft your own data-flow. Personally, I have a Play application that writes to AWS Kinesis as an events source, with downstream Kinesis consumers updating the object-states in Couchbase (among other data-endpoints for non-API purposes). Couchbase serves as the source for Reads. 
Akka is in no way a backbone for Spark. Akka dependencies were removed in favor of doing RPC using Netty. https://issues.apache.org/jira/browse/SPARK-5293
I'd be interested in the issues it causes. I see quite a few post saying negative things about akka yet no good examples of why. Its complicted yes because it can do a lot of things, theres no shortcuts here you have to read the docs / books. Does this imply the docs could be improved I think yes. A list of how to / cookbook style Q and A's should be created.
I am not going to start a fight here but just few things: testability, typesafety. But I agree that it might be me not investing enough time to learn another tool. Just saying that most of the time Akka is not needed. We can for sure disagree on this point :_)
Interesting, I stand corrected. Its been a little while since I played with Spark.
I think Bazel is pretty neat, but the lack of Java 9 support and maven_jar's inability to download transitive dependencies makes it difficult to switch.
also of interest if using akka-stream: https://github.com/krasserm/akka-stream-eventsourcing
https://github.com/strongtyped/fun-cqrs
I have been using Scala professionally for 8 years and have never used Akka; and I'm very active in the community and know very few people who do use it. It's certainly interesting and it's very powerful, but it's a specialized low-level tool that requires a great deal of skill and practice to apply correctly. By all means dive in if you find it interesting, but it's not mandatory in any sense.
I wrote a tool to make it easy to manage external maven dependencies [Bazel-deps](https://github.com/johnynek/bazel-deps) It makes the transitive maven issue a pretty solved problem. Java 9 isn’t a concern for me at the moment.
Cay Hortsmann (the author of Scala for the Impatient) also wrote a number of Java for the Impatient books. Joshua Bloch's Effective Java is considered a must-read by many people. I personally like Peter Sestoft's Java Precisely, it's short and clear.
Typed Actors should prove to be quite a game-changer here.
Scaladins - like rpg Paladins we sometimes are on a holy crusade, and we are multi class (oop and functional) 
If you have no knowledge of Java, then I suggest any well rated introductory Java 8 book on Amazon. Once you have a solid grasp of Java fundamentals, then Josh Bloch's Effective Java (3rd edition coming out in next month or so) is the next step. Enterprise Edition Java is not part of the core language and most likely is not needed unless you are in a J2EE shop.
Amazon has a wide selection of books on the subject of grief and coping with loss.
Akka persistence allows you to create CQRS type applications. 
I know what event sourcing and cqrs are but do not know how to start designing them, that's why I am asking here. How should I start? 
when fun-cqrs would be ready?
I think implementing DDD is often recommended. But for simple example with pseudocode: events := getYourEvents() mapEvent(state, event) = event match { case EmployeeCreation(data) =&gt; createEmployee(state, data) case DeleteEmployee(data) =&gt; deleteEmployee(state, data) } events.foldLeft(initialState(), mapEvent) With that you sequence of events will be translated into function calls that change state. That's it. In more advanced case, your state might be just database with tracked version, functions can have side effects changing database, getYourEvents might be a stream fetching data from Kafka, and initialState() keeping track of last processed offset. To make things truly useful you would have to guarantee that functions you call for events are idempotent and offset of already processed events stored somewhere. This way of stream were restarted it would continue work with no risk of performing some operation twice. Start with example where you foldLeft over some fixed data, and when you grasp it, add some side effects and see how things change. As for CQRS try "Implementing DDD" for learning some patterns. They are more about how you design things than some one way of encoded in a library or framework.
Effective Java is great, but it takes a little experience working with the language to understand its rules. I would try starting with building a Java 8 app using Dropwizard or another similar library.
Isn't the Cake pattern a discouraged approach nowadays?
Not crazy exciting, but I've been having fun making a Twitter client in scala using scalafx and monix. http://codeninja.blog/2017/scala-twitter-client/ 
Sorry - I'm not in the position to advocate for Finch over Finatra (or any other way around). As people already mentioned, you should run your own tests and look at the docs/examples/blog posts/talks/ to figure what technology is a better fit for you.
Good idea. Here is a quick example program showing usage of semanticDb to anti-alias renamed imports. Full instructions are in the readme, short instructions are clone the repo and run "sbt analyzer/run". https://github.com/ShaneDelmore/sbt-semantic-example/blob/master/analyzer/src/main/scala/Main.scala Let me know if I can clarify anything.
In both map and flatmap the functions you pass them are not callbacks, so there is no callback hell. I may have misunderstood your question.
I have not encountered callback hell in Scala since it is not common for libraries to ask for a callback function. One (related) instance where I found map/flatMap super useful is when using Futures. Things like asynchronous http request are much easier when handled with Futures + map/flatMap.
Futures are what come to mind most easily. Instead of def getBlerg: Future[Blerg] = { val blergPromise: Promise[Blerg] = Promise() fooFuture.onComplete { foo =&gt; barFuture.onComplete { bar =&gt; bazFuture.onComplete { baz =&gt; blergPromise.complete(Try(toBlerg(foo, bar, baz))) } } } blergPromise.future } with map/flatMap, it's def getBlerg: Future[Blerg] = { for { foo &lt;- fooFuture bar &lt;- barFuture baz &lt;- bazFuture } yield toBlerg(foo, bar, baz) } since the `for` desugars to fooFuture.flatMap { foo =&gt; barFuture.flatMap { bar =&gt; bazFuture.map { baz =&gt; toBlerg(foo, bar, baz) } } } 
this is awesome
Uh, your in for a world of disappointment. Holy crap! Even if you're fairly weak at Scala, you're going to hate Java. It's like you're going from enjoying a comfortable luxury car to a damn used a$$ gocart with bald tires that badly needs servicing. While it's true you can get from point A to point B _eventually_ with Java, is it worth considering suicide several times a day while you endure the misery of the journey?! Best of luck to you. You're going to need it.
so as far as just the pattern matching it would be like this: https://scalafiddle.io/sf/miNrgAI/0 now I'd rather have a case class for every possible event type and then decode each event into its matching case class. Later this might allow you to do something like this df.map( row =&gt;{ row match { case x:CaseClass1 =&gt; ... and exhaustively pattern match over your whole catalog of caseclasses. You'll have to try if this is possible with a dataframe I don't have a Spark installation at hand to try this out.
A lot of jobs around me use EE, so if you have any recommendations on that, they'd be useful too.
Thanks for the "Java Precisely" rec, that looks really promising!
I am trying to understand finch code, but could not configure it out, what does it mean. Consider following code snippet: object Server { def main(args: Array[String]) { Await.ready(Http.server.serve(":8081", div.toServiceAs[Text.Plain])) } // We can serve Ints as plain/text responses since there is cats.Show[Int] // available via the cats.instances.int._ import. def div: Endpoint[Int] = post(path[Int] :: path[Int]) { (a: Int, b: Int) =&gt; Ok(a / b) } handle { case e: ArithmeticException =&gt; BadRequest(e) } } I do not understand this part of syntax: { (a: Int, b: Int) =&gt; Ok(a / b) } handle { case e: ArithmeticException =&gt; BadRequest(e) } } it is an anonymous function? Thanks 
Hey there, The bit of code at the end contains two anonymous functions, post(path[Int] :: path[Int]) { (a: Int, b: Int) =&gt; Ok(a / b) } this bit of code means that the function post has a second argument list, that takes an anonymous function, lets call it F, F takes two Ints, a and b, and returns an instance of OK(a / b). but what if b == 0 ? then the operation a / b will throw an ArithmeticException. so comes this part of the code: handle { case e: ArithmeticException =&gt; BadRequest(e) } which catches any exception thrown by the anonymous function F that we passed to the function post, and if that exception is of type ArithmeticException, handle will return an instance of BadRequest.
Hey there, The book Thinking in java by Bruce Eckel, it is one of my favorite programming books of all time (right after C++ primer), it's not very chatty and it's pretty detailed. can i ask you in which country/city you're looking for a scala job?
Oh tbh I naturally started developing it like this, it seemed intuitive, and only later I found out about the official pattern when I started googling some issues. You got any sources so I can look into that?
[A good article about it](https://philipnilsson.github.io/Badness10k/escaping-hell-with-monads/)
Read [Chapter 2 of FP in Scala for Mortals](https://leanpub.com/fpmortals/read) for some more examples, including how to handle nested options/eithers/lists. 
Cake has definitely its place. It's the right abstraction for strongly coupled components that mutually depend on each other. It's true that one generally prefers loose over strong coupling, but sometimes strong coupling is the most natural way to express things. For instance, in the `dotc` compiler, the cake pattern is used for parts of a context that each transitively depend on the whole context, but that factor out specific concerns. 
The first major problem is that in your concrete type, `F` will be the expected type, rather than the type that fills in `F`: scala&gt; trait F{ | def f[F[_]](a: Int): F[Int] | } defined trait F scala&gt; new F{ | override def f[F[_]](a: Int): F[Int] = Option(a) | } &lt;console&gt;:14: error: type mismatch; found : Option[Int] required: F[Int] override def f[F[_]](a: Int): F[Int] = Option(a) This will be true even if you define your abstraction as a module using `object` -- `Option` will never be `F`. It's possible to do this with type constraints, but at that point you lose the idea of it bieng 'easy': scala&gt; import cats._ scala&gt; import cats.data._ scala&gt; import cats.implicits._ scala&gt; import cats.syntax._ scala&gt; trait F{ | def f[F[_]:Monad](a: Int):F[Int] | } defined trait F scala&gt; new F{ | override def f[F[_]:Monad](a:Int):F[Int] = a.pure[F] | } res3: F = $anon$1@f75dd08 scala&gt; res3.f[Option](5) res5: Option[Int] = Some(5) 
Using the global context implicit for injection -- see the [dotty project](https://github.com/lampepfl/dotty/blob/3c45d43b5d9b900e19f5c65e00a35310af5a7ed9/compiler/src/dotty/tools/dotc/core/Annotations.scala#L71) and [the Context definition](https://github.com/lampepfl/dotty/blob/3c45d43b5d9b900e19f5c65e00a35310af5a7ed9/compiler/src/dotty/tools/dotc/core/Contexts.scala#L36). The [demo app created in FP in scala for mortals uses the tagless final (`F[_]`) F-algebra style](https://gitlab.com/fommil/drone-dynamic-agents/blob/master/src/main/scala/algebra.scala) and the [implementation](https://gitlab.com/fommil/drone-dynamic-agents/blob/master/src/main/scala/interpreters/dronefs2.scala#L35): . There are also F-algebras used in [47 Degrees' Scala Exercises](https://github.com/scala-exercises/scala-exercises/blob/57a761fbdbbddcdf1a117c202c9a5b88378f0e04/site/server/app/com/fortysevendeg/exercises/services/interpreters/interpreters.scala). Most open source scala projects avoid var if possible already. Hope that helps. 
Notably, if you avoid circular dependencies, cake traits are no more strongly coupled than any other code: each trait can be instantiated and used independently, you just need to fill in the relevant abstract members. This is no different from passing in arguments to a function or class constructor. You can achieve this by having the cake traits depend/inherit only on the abstract-members/traits they actually *need*, rather than having every trait extend/self-type the `EntireCake`. You can also use the acyclic compiler plugin to force yourself to do so. After modularizing the cake traits, what’s left of the cake pattern is just a convenient way of automatically wiring up a member needed by one trait with the member defined by another, based on the member’s name. This is not unlike the way point-free function composition automatically wires up different functions’ arguments based on their position, or implicit parameters wire up different functions’ args based on type signature. Whether that is useful or not is debatable, but you can definitely build cakes without creating strong coupling via circular dependencies
A bunch of Scala.js stuff, but right now working on my reactive UI library https://github.com/raquo/laminar because I don't think React.js and Scala mix all that well. There are links to my other related projects in its README. Specifically, I'm currently implementing a standard TodoMVC app using Laminar to see what it's like to use my library, and let me tell you—that's a really good exercise. I've already introduced new helpers and drastically changed the API of my library to make it easier for users to compose their components with less boilerplate (didn't publish any of this yet, that will be v0.2). To anyone who's developing their own UI library, I would highly recommend implementing a TodoMVC app as early as possible. The requirements are very minimal, but they necessitate using a big chunk of your library's API surface. And because the requirements are set in stone, you can't subconsciously ^(or consciously) avoid use cases that are hard or impossible to implement using your not-yet-battle-tested API.
That's really great! What are your future plans about development of Quill?
I would avoid imperative (step by step, tightly controlled execution semantics) definitions, regardless of using vars outside of an `IO` context, if only because refactoring via inlining and the tight coupling that results from using unwrapped types. You definitely want some `IO[A]` type around the outside of your returns, so you can control execution, centralize error-handling, and separate the concerns of how your program runs from what it is supposed to do.
What's the breaking changes in 2.0?
Play framework is heavy, and for most part unnecessary. I think Finch is a great framework, unless you really don't want to use Twitter ecosystem. If I wasn't going to use Finch, I would turn to http4s, and for those who even hate that because of Scalaz dependencies, there is Akka HTTP.
IMO, there are multiple ecosystems that I'd be interested in. My personal preference is: Finch, Featherbed, Circe, Cats, Shapeless, Simulacrum. There are more tools available that are backed by Twitter like Finatra, which would be a good replacement for Finch. But some people also prefer: Http4s, Shapeless, Simulacrum, Scalaz. I'm not a fan of TypeSafe (now Lightbend) stack. Or Akka, which I also think is a TypeSafe (Lightbend?) backed now. However, there is one TypeSafe product that I like, and that is Slick, which is an FRM for relational databases. I think that comes in pretty handy if you're a backend developer. Also, if you're going to spend time on Akka, I think the most important part should be the Akka Streams, that are similar to Reactive Streams implementation in other libraries.
I've been using Finch in production at work for almost a year now, and I'm very happy with it so far. Of all the HTTP server libraries that I have used so far, I believe that Finch produces the cleanest, and most maintainable, code. The code base is constantly improving, and it's always good to keep an eye on things. I also like the integration with Circe, which makes writing REST APIs very easy.
Completely disagree with the Play comment. Play being "heavy" is a huge misnomer. You don't have to import the large majority of Play modules into your project. I feel like it gets a bad rap because it's advertised as a Framework. If you actually use it you'll realise that you really aren't importing some massive artifact.
Okay, I admit, that was a very bad explanation on my part. Well, yes, Play is modular and thus not too heavy. However, I think the biggest strengths of Play come out when you start using features that aren't very common (e.g., template rendering, web sockets using actors, contexts, sessions, and a ton of other stuff). For building something much simpler, which is usually the case, it's far easier to write more maintainable code using Finch or Http4s.
I would agree that, for a _functional_ programmer, Http4s is the way to go. Even said as much in my OP. Play is more imperative in its approach. That said, as someone that has used both Http4s and Play for both simple/complex projects, I find it quite easy to write maintainable code for basic CRUD applications in the Play framework. And considering I work with more imperative programmers (PHP / Typescript shop), Play tends to be easier to teach to others. For newcommers that have no Haskell experience (like OP), functional programming is typically much harder to pick up. It might be easy for an experienced Scala/Haskell programmer that has had time to use Scalaz, Cats, etc., but for just about everyone else, these concepts are pretty foreign. I know it took me quite a while to even _try_ to pick up Monads. TLDR: what's "easier" tends to be defined by the developers rather than the library.
[removed]
I think the next big thing would be a migration and code generation mechanism. There are a few other features like upserts that we should work on in the mid term as well.
Does Quill support Redshift?
Very interesting project! Thank you for sharing.
Suppose, I have two finch application, how to communicate to each other?
It's possible that it works using the redshift jdbc driver and the postgres dialect. It might need minor changes though, pull request are welcome :)
Cool... I remember wanting to try Quill but ran into the Redshift problem... dialects are slightly different because Redshift doesn't support a lot of the Postgres data types (e.g. UUIDs are strings).
Oracle tutorials are pretty good and updated. Thinking in Java is good, but I don't think it covers java8
Wasn't dotty and future instances of scala use TASTy, which is ship the entire source code with each .class? I that's the case, you could say scala is not very interested.
Since REST APIs seem to be the most common use case for Finch, I use Featherbed (https://finagle.github.io/featherbed/) for communicating between micro services.
By migration do you mean something like scalafix rewrites? Lke they did in Cats: https://github.com/typelevel/cats/issues/1791
Someone may be still have the requirement. One of my customer uses scala on big data development, they use our tool to protect their work.
But I looked at post function, it does not seem it has a second argument.
I think he means database schema migrations.
The idea with TASTY is to provide it with libraries etc. For an actual runnable application it doesn't make much sense. By default it will probably be created but you should be able to just remove it (or hopefully configure it not to be generated) as the data in it is used during the compile phase not when running the program.
You're using `finch-module` directly. It's just a placeholder for the module, like `finch-core`, `finch-circe` etc. You can see a list of all the modules for Finch here: https://github.com/finagle/finch#modules
Let's be honest, the map/flatMap Paradise isn't real. Each of the monadic alternatives to ad hoc abstractions seem great in isolation, as they are shown in the article. But the dirty secret is that there is no easy way to mix them together. And in practical programs, you will definitely want to, precisely because each of them alone is so good at it's own task. 
Just a slight nitpick. Http4s (and circe) is moving to a cats/fs2 implementation. If you mix cats/fs2 and scalaz you can end up in some bad situations (even if you use something like shims which helps ease the differences between the two ecosystems). My recommendation is that if you go http4s that you migrate your scalaz code to use cats/fs2. It can be painful at first, but most paradigms port over pretty easily.
From what I read some time before, sure it's an AST, but it will even keep the comments in. As for the removing it part, I thought reflection would eventually rely on it.
No, database migrations to maintain the schema. 
Anyone know which IDE is most common for Java, intellij ?
&gt; I looked at post function, it does not seem it has a second argument. The `post(...)` call returns an [`EndpointMapper`](http://finagle.github.io/finch/api/io/finch/syntax/EndpointMapper.html) which has an `apply` method. Methods named `apply` can be called just by using parentheses or braces. So `post(...) { ... }` calls `apply` on the returned `EndpointMapper`. In this case the `apply` that matters is the one taking a [`Mapper`](http://finagle.github.io/finch/api/io/finch/syntax/Mapper.html). "But I'm passing a function, not a `Mapper`", you might say. And you'd be correct if it weren't for the implicit conversions in the [`Mapper` companion object](http://finagle.github.io/finch/api/io/finch/syntax/Mapper$.html). Because [`Ok`](http://finagle.github.io/finch/api/io/finch/Outputs.html#Ok[A](a:A\):io.finch.Output[A]) returns an `Output`, that makes `(a: Int, b: Int) =&gt; Ok(a / b)` a function returning an `Output`, so Scala can implicitly create a `Mapper` for you from that function. &gt; And how to know, where can I use handle function? That `apply` method called above returns an [`Endpoint`](http://finagle.github.io/finch/api/io/finch/Endpoint.html). That class defines the `handle` method. So you can use `handle` on any `Endpoint`.
I'm working on a process monitor that sends alerts via text message, email, and slack when the process meets some kind of failure condition. It's similar to deadman's switch or cronitor, but allows more flexible failure and alerting conditions such as a particular string appearing at a certain rate in stdout/stderr, exceeding a memory limit or run time, etc. It works well as an entrypoint in docker containers and Cron jobs. The command line app is written in go, but the server side is scala using grpc, Doobie, monix, and scalatags. If anyone would find something like this useful, please hit me up. I'm building this for myself but I'd like to know what features might be useful to others. 
Monad transformers are kinda the solution to that.
Or eff in Scala. 
I largely used the cake pattern because I wanted this library to be a bit DSL-like, so you can write an explicit piece of code like: ``` val bp = new Nodes[State with Order] with Hierarchy with Directed with AdjacencyList with Signal with Feedback with Flow with IO { ```
Ah, right. I prefer sticking to Cats over Scalaz wherever possible. How do you think Http4s do against Finch?
Recently, I wanted to learn how to use Scalameta, so I wrote a [small tool that searches source files for function signatures](https://github.com/Technius/siggy). It's been fun writing the tool, since Scalameta is quite pleasant to use. I'm not quite sure what to do next, though, so submit an issue or a pull request if you're interested.
Take a look at [Shapeless's Align](https://stackoverflow.com/questions/29242873/shapeless-turn-a-case-class-into-another-with-fields-in-different-order). 
"Zero known bugs" seems like a strange brag to me. Surely no one releases with "known" bugs, right?
Good joke :P
My team at Artsy built an event sourcing application on Akka Persistence. Although, we're in the process of replacing Akka Persistence with simply using Slick, and storing our events as serialized JSON lists, relying on explicit row locks for atomic validate-and-store operations. For us, this is fine, because our throughput is pretty low. It's tough to make a recommendation without knowing about your needs. Akka Persistence is a pretty solid place to start, though.
The term is fat jar. [sbt-assembly](https://github.com/sbt/sbt-assembly) is the tool to build one. 
A few years ago I got [proguard](https://www.guardsquare.com/en/proguard) to work well enough that I could write an Android app in Scala. It's not Android-specific so with the right configuration it should be able to strip out the unneeded parts from your jar.
Sadly as of now Scala (for the JVM anyway) does not have a linker, therefore you can't automatically remove runtime specific part that your application doesn't need. I believe this will come with Scala 3 ( dotty ) which does not have a precise ETA. You can however build fat jars.
I vouch for this. Experienced simillar situations
well the jvm now has a linker since j9 via jlink and modules.
Early Scala certainly didn't feel purity-oriented; functional aspects were a feature but in the early days they were one among many. It felt more like a bag of random extensions to Java that sounded useful (e.g. there was a lot of emphasis on XML literals in early marketing). As people started using it and building libraries it became more apparent that the functional-oriented side of Scala was the most useful part.
Oh that's great :D
Looking at the EndpointMapper class, it expects two parameters: class EndpointMapper[A](m: Method, e: Endpoint[A]) The code, that I have showed above, the parameters `m: Method, e: Endpoint[A]` never have been passed somewhere. What is the difference between class EndpointMapper[A](m: Method, e: Endpoint[A]) and final def apply(mapper: Mapper[A]) ?
&gt; The code, that I have showed above, the parameters m: Method, e: Endpoint[A] never have been passed somewhere. They're defined in the body of the `post` method you called: def post[A](e: Endpoint[A]): EndpointMapper[A] = new EndpointMapper[A](Method.Post, e) &gt; What is the difference between class EndpointMapper[A](m: Method, e: Endpoint[A]) and final def apply(mapper: Mapper[A]) Well one's a class and one's a method. They're very different, such that we can't really compare them. Can you be more specific?
Well, if the style naturally permits circular dependencies where other styles don't, that seems like a disadvantage; most styles can produce good code when used with discipline, the difference between a good style and a bad style is the extent to which it absorbs the discipline burden.
Sorry, I've got it, I am so stupid. Thanks so much. I thought finch is most functional, but it isn't not? 
I don't know enough about Finch to answer that, I've never used it. 
Some of the examples of libraries that are trying to use Functional Programming design to improve code quality, IMO, would be: - Doobie for database access - Slick: I haven't used it in a while, and don't remember how functional it is, but I think it competes with Doobie - Http4s: For HTTP servers and clients - Finch: Like Http4s, but more around Twitter's ecosystem - Circe: For JSON parsing
But a fat jar doesn't purge the classes (and members of classes) that are never used.
Do you think it would also purge extras from the Java dependencies?
You can use monad transformers like [here](http://eed3si9n.com/herding-cats/monad-transfomers.html).
Doobie, Monocle, circe, fs2, shapeless, Discipline. Scalacheck, ReactiveMongo. I use all of them in production projects. Whether or not something is fully functional only mildly concerns me. It can always be wrapped in a functional IO context. What concerns me is whether or not my code is functional. I do a lot of streaming data processing, with parallelism. Monoid, Applicative, and Monad are very important concepts in my work. While we have the ability to replay the event stream for up to two months back, a major logic error that makes it into production requires us to replay the events from backup, and that is expensive to do. FP and types and modeling have contributed to the feature delivery efficiency we need to prevent waste when processing the amount of data we handle. We don't use Spark because of the Architects at our client, and we are very careful not to load all the data into memory at one time and how we distribute load. There are VERY specific and arbitrary business rules for processing this data as well. FP is an abstraction. Abstractions exist to allow you to not worry about the things the abstraction takes care of for you. They literally should make programming simpler - Either simpler to verify correctness, as is our use case; or simpler to write by hiding implementation details (the way IO handles thrown errors and thread-pools). The second is achievable via OOP. The first is not. FP is my default abstraction. Some things are easier to express as a class and have a low risk of behaving incorrectly, so we express them that way. Memoization is one such example from scalaz. Only experience will tell you when something is better one way or another. Default to FP, as it is principled, and unwrap as needed.
Sure, I understand that FP is an abstraction. I am not saying that a library that is not purely functional should not be used, it's just that I'm curious who is writing functional code in Scala. Besides, functional code is usually (to a certain extent) easier to integrate with rest of the functional code.
Check out the 6 Part series on Intro to FP in Scala. Just great content. 6 Part series on Category Theory.
I'd say that slick is functional in many ways but has very little in the way of interpo with the rest of the scala functional programming world. 
Slick is very functional, as far as I've used it. The core abstraction is basically an IO-ish monad for building up miniature database programs, and then finally using `db.run` to execute them.
I've just finished a mini side project to visualize fetches of hacker news stories from their API, using Udash web framework http://justinhj.github.io/2017/10/11/hacker-news-api-3.html 
Shouldn't Scala be able to do this since Scala.js is able to?
ScalaJS effectively generates JavaScript, and there are many tools already to minify JavaScript and purge functions that are not in use. Remember Tree Shedding in Dart Programming Language?
Agreed. I had a lot of fun using Slick, and specially how the queries are generated, I prefer it over Doobie. The lack of interop with other FP libraries is not very encouraging though.
I was about to name some libs (doobie, eff, cats, ...) but then I realized that they are all part of the typelevel stack. So www.typelevel.org is a good place to start. 
Oh I thought that ScalaJS pruned the tree before the stage where JS is created.
Umm... Maybe it does. I'm not a ScalaJS user, but I assumed from the generated JavaScript that it must be possible to do something like that.
Well there's a `@JsExport` or similar annotation that seems to tell the compiler that "this needs to be produced in JS", aka, "don't prune here or anywhere this depends on". So I thought that it must be doing this well before conversion to JS.
What I do is that instead of building a big fat jar, I use the normal *publish* and **assembly** process that keeps your code and your dependencies separate. This means that once you push all your deployment to a server you can easily use scp, rsync to just deliver the deltas (your code) an not the full fat jar.
Akka Persistence allows you to implement write side and Akka Persistence Query can help you with making projections for read side. And the read side can be implemented with something else. Slick, Anorm, plain database driver API etc.
I had the same struggle and I decided to make my own example with Akka. Here it is: https://github.com/BranislavLazic/akka-cqrs-activator
Akka Http and Akka Streams. Oh boy. That's sone really nice stuff.
&gt; this I use this library to get cats type classes for DBIO in slick https://github.com/RMSone/slick-cats. Then I can use nice stuff like cartesians for example.
That's not going to help, my 'deployment' is releasing on a download site for people to install on their Minecraft servers. So looks are very much important.
Yes the Scala.js linker does that. It's able to do a better job before JavaScript is generated because it knows more about the types of things. My hope is that this will be generalized to Scala-JVM. That would also be great for Android development.
But not really functional in the sense of FP, are they? 
I was really looking forward to finding a library like this. I was afraid I might have to write my own if one wasn't available.
&gt; I personally think Cats will encounter more growing pains and don't agree with some of the technical decisions it's making Just out of curiosity. What are the technical decisions do you not agree with in Cats ecosystem?
I ran into a problem and had to revert, but can’t figure out what could be causing it. Basically hot reloading doesn’t work in dev mode anymore for me. I’ll make a change and it will compile and look like it restarts, but the code hasn’t actually changed...it’s like it’s using a cached version of the code or something. Anybody else notice this? It’s super frustrating. 
well somewhere the aes key needs to be provided, so there is not that much additional protection...
[removed]
What do you return when working with collections? Do you stay on Iterable as long as possible and 'materialize' to concrete data structures later on, when required (i.e. by needing to know size, or sematics)? Do you return it because of 'principle of least power'? Or do you rather return always `Seq` or something else? Mostly question is in regards to `Iterable` vs `Seq` as return type. When creating data, that a `Set` because of nature of problem and it was taken care of, I would not return Iterable...
I'd like to see them factor or out strong vs weak typing. C is statically typed but the your system isn't very strong. A lot of conversions are done quietly, which is one of the main reasons ADA is more safe. I think strong vs. weak typing might be a dimension that's highly correlated with functional languages, because a lot of them are strongly typed.
&gt; Why the interpreter has to be outside ADT? It doesn't. You can do both ways, and they have different tradeoffs (one lets you easily add more AST nodes, one lets you easily add more interpreter operations) &gt; Is there any name for what I have developed? It's just a normal interpreter, classic [Interpreter pattern[(https://en.wikipedia.org/wiki/Interpreter_pattern).
**Interpreter pattern** In computer programming, the interpreter pattern is a design pattern that specifies how to evaluate sentences in a language. The basic idea is to have a class for each symbol (terminal or nonterminal) in a specialized computer language. The syntax tree of a sentence in the language is an instance of the composite pattern and is used to evaluate (interpret) the sentence for a client. See also Composite pattern. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/scala/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.27
Thanks. I was probably misled by conference videos. I have seen literally dozens of these with external interpreters and no single one with the classic one. Also it was probably too long since I read about GoF patterns last time. My bad.
Clojure is dynamically typed. That was one of the dimensions the study looked at. 
What you might want to do is changing List for scala.collection.Traversable. You only rely on .reduce and .mkString.
But it's also strongly typed. 
I just never found an easy practical guide where common things like Option Future Task are being used
&gt; C, C++, Objective-C, Php, and Python are associated with a greater number of defect fixes while Clojure, Haskell, Ruby, and Scala are less likely than average to result in defect fixing commits. How does Ruby end up in the latter list?
It cheats the metric because defects simply aren't fixed. ^^^(/s)
And .map, but that's there, too. Is Traversable similar to Traverse in Scalaz?
it was pretty much at that point I stopped reading. the few ruby projects I have worked on (inherited) were buggy messes. one wouldn't even run on anything other than a 2012-Macintosh (I still no idea why that was, I ran away after two weeks of bug fixing)
I've only done a little Ruby, but that doesn't surprise me. Especially with Rails -- so much "magic" going on that you never really know what's happening.
I have it. It's a decent book but rough around the edges. It's a good pre requisite for the red book
You didn't specify what type is configuration and what exception you get, and our crystal balls are sadly in repair.
For the mascot, I was thinking something related to a koala: what about Skoala? (Scala + Koala) Or it could be a proper noun like Skala (A female koala :P) At least it would be cute! :)
Exactly my point, those are two different (and often confused) dimensions. And I think strong typing has a significant influence on bug levels.
That was my point, static vs dynamic isn't the same as weak vs strong.
I disagree with the methodology. I constantly boast in my commit messages about how my code doesn't contain any errors or bugs.
I have this book the book you mention. However I like this one a little better https://leanpub.com/fpmortals
I would say at this point it's too large to query as json and still get reasonable performance. I would import it into something like Elasticsearch and go from there
&gt; Elasticsearch Ah, I'll google it. But are my assumptions correct in that it's not an organized json list yet so my path would be: organize data from eventvariable into a "list" -&gt; then query for specific variables of interest by doing something like a sql query? Is that possible if let's say I was interested in nestedeventlognamevariable then jsonnestedvariable2, jsonnestedvariable3 which I know exist for ever row? 
You would probably only import the data into it. Without organising. Then you can query on the database (it's slightly different from SQL, but not too difficult) and I think you should be able to do the things from your second question
&gt; One should take care not to overestimate the impact of language on defects. While the observed relationships are statistically significant, the effects are quite small. Analysis of deviance reveals that language accounts for less than 1% of the total explained deviance. I saw this study a couple of days ago and was wondering when it will pop up. The finding is nice/fun but not that relevant.
http://deliveryimages.acm.org/10.1145/3130000/3126905/t7.jpg here you go.
I don't see strong or weak typing in there?
Your questions has been answered, but here is some additional advice to your code: `def execute(i: Row): Boolean = elems.map(_.execute(i)).reduce(_ &amp;&amp;_)` While this works, I like the following better because it makes the intent much more clear and has most likely better performance: `def execute(i: Row): Boolean = elems.map(_.execute(i)).forall(_ == true)` Also, try to avoid primitive types like String and Boolean. If you have some code which is using those types in a very limited, private scope it is fine. But when exposing such types as how you do it in your `Rule` trait, then you should go with one of the three options: The simplest one is type aliases: `type ExecutionSuccess = Boolean` or `type RuleDescription = String`. Then you can use them and write `def describe(): RuleDescription` which is helpful for those who use the `describe` method later on. The second one is wrapping your primivite types in case classes: `case class RuleDescription(value: String) extends AnyVal`. This makes it impossible to mix up different kind of types. On the other hand it introduces some boilerplate into your code. The third option is type tagging / tagged types. You can google this for sure. You will have little to zero boilerplate *and* complete typesafety *and* best performance but you will need to learn about Scalas typesystem in depth.
They use type checking: Static = Strong, Dynamic = Weak
Thanks for hints! In fact, the implementation I wrote above was re-written from my head, as I didn't have access to original code and, as a side effect, simplified a lot. We don't use Booleans to express success/failure for the reasons you have mentioned. For descriptions, I cant immediately see the value in using stronger types but I will definitely consider it in the future. 
&gt; For descriptions, I cant immediately see the value in using stronger types but I will definitely consider it in the future. If you don't really use them much, like only for debugging purposes, go with a type alias. This is just one line and will just make it more easy to read the code - and if you change your mind in a few month and need a more specialized type instead of a String, you will have less work with replacing all the `String`s with your new type. :)
I have this great resource saved: https://gist.github.com/d1egoaz/2180cbbf7d373a0c5575f9a62466e5e1 It lists many resources for learning Scala and FP in particular. In fact, it does **not** recommend you start with the "Red Book", because it's too steep of a climb if you're just starting out. I can definitely recommend [Functional and Reactive Domain Modeling](https://www.manning.com/books/functional-and-reactive-domain-modeling) by Debasish Ghosh. It's a really fantastic book that teaches FP in Scala from the ground up, and also happens to teach Domain-Driven Design (although it claims the opposite way :)) Good luck! 
I would look at the mutable hash-based maps, either those from scala.collection.mutable, or the standard java collections through the Scala converters.
Hi i actually need mutability but thread-safe hence TrieMap. Thx for suggestion
I was also thinking about https://github.com/findify/scala-packed
This looks like an interesting approach. I'd like to hear about you experience using it, if you try it out.
&gt; I would say at this point it's too large to query as json and still get reasonable performance. I primarily do frontend webdev and the idea of a 1GB JSON file nearly made me fall out of my chair, recoiling in horror.
Java has ConcurrentHashMap with is mutable and thread safe.
I'd think about whether there is any common structure between the URLs you are sharing. If some share the same host and/or part of the path then you should be able to use some tree like structure so save memory.
Same here, worked on a ruby project developed by someone else and it impossible to figure out the workflow. And there were no unit tests, poorly named variables, and heavy use of meta programming in ruby, and no logging!
You may want to read about the expression problem, it's related to what lihaoyi was alluding to in his remark.
Depending on your use case, and actual trie data structure might be useful.
hi thx its a good idea.
but is it actually memory efficient ? :D
Ok i will try to come back to this once i have something. Sadly this project offers only basic structures i would need to implement my own mutable thread safe map on top (and i didn't wanted to waste time with that). Also not sure if the project is going to be alive in the future
How much memory is "more memory than it should"? I built a million-entry Object-&gt; Object TrieMap, and according to VisualVM, the retained size was a little shy of 110 million bytes. Since the size of an Object() is 16 bytes, 32m of those are our keys/values, leaving us 78m, or an overhead of about 78 bytes per object. (As it's a tree, I'm guessing this overhead will grow logarithmically as more entries are added and the tree gets deeper) In comparison, a java.util.HashMap() with a million object-&gt;object entries had a retained size of ~93m bytes, or an overhead of 61 bytes/object.
Yes. That's a [Radix tree](https://en.wikipedia.org/wiki/Radix_tree). I've seen some implementations in Scala, but I cannot make any recommendation (I never tried them).
At this size, perhaps just using lucene might solve your problems. Gets you a trie, optionally goes to disk, thread safe. Not very scalactic though and somewhat heavy.
In addition to this - simply wrapping a computation in Option won't catch the exceptions underneath. Try is the monad you would want for that. 
Doesn't that mean the same thing as 'Allowing implicit conversion'?
You can add a file called "rootdoc.txt" to the root of your package hierarchy, but sadly that's about it.
I'm not sure this is entirely correct. You also have to account for every element being wrapped in a `BasicNode` and all the nodes (`CNode`, `SNode`, `INode`, `MainNode`, ...) that are allocated between the data and the root node. &lt;Insert rant about Scala's sad trail-record in dumping non-reviewed student code into the standard library here&gt;
Since your JSON is a gig, that means you have 500,000,000 characters. Java, and this scala, Strings use Array to back them, and Arrays can only be Integer.MAX_VALUE in length. This is 2,147,483,647. So, you should have no problem setting your maximum heap size to 3G and just using any JSON parser to parse it, as long as you run it on a defect computer. To keep the memory a little smaller, you can stream all 800k using [circe-fs2](https://github.com/circe/circe-fs2/blob/master/README.md). All you need now is a case class representing your structure, or just use the Json output from circe and query it using (circe's data extraction)[https://circe.github.io/circe/cursors.html] in a map step after the parsing pipe from the fs2-circe read me, and it will pass on your data for you to your next step. Remember that the nested variables need to have the \" unescaped when you want to decode them as JSON. You can do that with fs2's flatmap. Once all your data is parsed to JSON, you can query it one item at a time, or fold it into the data structure of your choice. Quick, sloppy example, assuming the json is in a file io.file.readAll[IO](Paths.get("testdata/myjson.json"), 4096) .through(text.utf8Decode) .through(text.lines) .through(stringStreamParser) .flatMap { json =&gt; val cursor = json.hcursor val unescaped = cursor .downField("eventvariable") .withFocus( _.mapString( _.replaceAllLiterally ( """\"""", """"""" ) ) ).top Stream[IO,String]( unescaped .cursor.downField( "eventVariable" ) .through(stringStreamParser).map { eventJson =&gt; cursor.downField( "eventVariable" ).withFocus( a =&gt; eventJson).top } }.run.unSafeRunSync Disclaimer - I think that will insert the parsed JSON into the top level JSON, but you might have to play with it more, I didn't compile this. But you get the idea. You'll want to build this into a fat jar with (assembly)[https://github.com/sbt/sbt-assembly] and run with java -Xmx 3G -jar target/outputjarname.jar It should be pretty performant, and the cursors that come with circe are pretty easy to use. The tricky part will be getting the optional levels of nesting right, and getting them back into the original json top level. You might consider fs2 Stream.foldx methods for that. As for counting and querying, fs2 has methods like fold and filter that can help you do all that easily with the data extraction stuff on the circe cursors. Anyway, it's possible in pure scala to parse it efficiently and run the queries efficiently. If you want to re-use queries, you might consider looking at the fs2 pipes or just not calling run on the [streams transformation section of the fs2 guide](https://github.com/functional-streams-for-scala/fs2/blob/series/0.10/docs/guide.md#statefully-transforming-streams).
&gt; &lt;insert rant about Scala's sad trail-record in dumping non-reviewed student code into the standard library here&gt; Any plans to fix this that you're aware of? It makes me a bit paranoid to use it in production.
Possible options for you: - ConcurrentHashMap - synchronized java HashMap or more memory-efficient hash map with open addressing - string deduplication - if strings are the same, don't keep two instances in memory - use Array[Byte] instead of String - UTF-8 uses twice less space than Java's UTF-16 (Array[Char]) - Think on your data - do you really need it as-is? Can you normalize it somehow so it takes less space? Do you need to keep all that in memory? Stream processing or database with in-memory cache might save you. - compression. From simplest forms (replace http:// prefix with 0, https:// prefix with 1 and everything else with 2) to full-fledged dictionary-based compressors
Apart from broken promises made at conference talks? No.
quicklens - it is like Monocle but with much simpler notation (due to macros). 
I wonder if compile-time dependency resolultion viable at all. If we have class A that calls class B that calls C -&gt; D -&gt; E -&gt; F. And F needs XYZ to work. And I don't want to pass XYZ all the way from A to F. Why should ABCDE know about dependencies of F given they never change and configured only once? What if I want to test my dependency-injected module replacing pgsql DAO with in-memory mock? Compile-time DI won't make it easy as well.
Can you post some code? I think that would be easier to talk about something that can be compiled.
In generic case you do not pass the constructor parameters through the layers but the actual constructed object it sled if needed, or even better to pass the primitives such as connection contexts and so on to be used in place where needed being pretty much agnotistic to the logic implementation. That approach allows to reduce classes to objects with pure or IO bound functions which themselfs make your code natural transformation ready as next step towards taking controll over the codebase. (P.S sorry for mess and grammar mistakes: I am on the phone)
Here it is: class XYZ // when we start building A, we already have instance of XYZ def buildA(xyz: XYZ): A = ??? case class A(b: B) case class B(c: C) case class C(d: D) case class D(xyz: XYZ) 
Problem with contexts is that they are too broad: case class A(b: B, context: MyContext) //contains stuff not only for A but also for entire dependency tree of A. Meaning it is large and changed often. Introducing multiple contexts brings another problems. 
&gt; Why should ABCDE know about dependencies of F given they never change and configured only once? Well *something* needs to know how to instantiate F. What I tend to end up with is a parallel hierarchy of lightweight factories/modules/whatever-you-want-to-call-them; `A` knows about `B` and `AFactory` knows about `BFactory`. Which makes sense for separation of concerns. &gt; What if I want to test my dependency-injected module replacing pgsql DAO with in-memory mock? Compile-time DI won't make it easy as well. Yes it will, you just pass in your mock instead of the real one. It works fine.
Parallel hierarchy of factories is what Java people used before invention of DI. It has its problems - factories are static and hard-linked to each other so you can't replace single factory implementation if you didn't build it into design. For example, to mock single DAO your *top-level* factory must support that explicitly (optional parameter that takes alternative DAO instance). Where am I wrong?
You can do mixin-style compile-time DI, either with cake or with another approach ( I wrote a library for this: https://github.com/m50d/deliciouslie ). Then you can just swap out the DAO factory with the mock factory.
Rather than polluting the code with global implicits, may I suggest you use a Scala DI library like [Macwire](https://github.com/adamw/macwire) instead? It uses Scala Macros so everything is typesafe and validated during compile-time (unlike Java DI libraries that use Reflection during runtime). Dependencies are grouped into "modules" so you can easily trace dependencies, and can be easily mocked/stubbed for each specific test case. 
To me, declaring manually all dependencies in Layer seems too chatty. I don't like cake pattern or idea of combining traits in general - potential name clashes, complicated initialization order, performance issues (JVM don't like large cakes)
Example from their GitHub README: ` class DatabaseAccess() class SecurityFilter() class UserFinder(databaseAccess: DatabaseAccess, securityFilter: SecurityFilter) class UserStatusReader(userFinder: UserFinder) trait UserModule { import com.softwaremill.macwire._ lazy val theDatabaseAccess = wire[DatabaseAccess] lazy val theSecurityFilter = wire[SecurityFilter] lazy val theUserFinder = wire[UserFinder] lazy val theUserStatusReader = wire[UserStatusReader] } ` will generate: ` trait UserModule { lazy val theDatabaseAccess = new DatabaseAccess() lazy val theSecurityFilter = new SecurityFilter() lazy val theUserFinder = new UserFinder(theDatabaseAccess, theSecurityFilter) lazy val theUserStatusReader = new UserStatusReader(theUserFinder) } ` For testing, just extend the base module and override any dependencies with mocks/stubs etc, e.g.: ` trait UserModuleForTests extends UserModule { override lazy val theDatabaseAccess = mockDatabaseAccess override lazy val theSecurityFilter = mockSecurityFilter } `
That's a pretty big claim that should be substantiated. Space efficiency of the implementation is extensively discussed in this repository, including two academic papers. I would not qualify the code as "non-reviewed student code". https://github.com/axel22/Ctries
Same issue I guess - overriding dependency in top-level modules is easy but what if I want to override something in deeply nested module?
&gt; Why should ABCDE know about dependencies of F given they never change and configured only once? They don't. Only `F` (or in your code `D`) know about `XYZ`. Also, `buildA ` should rather be called `buildA+B+C+D` because it needs to build all of them. You can call it `buildA` if it only receives a `B` and builds an `A` from that. 
Yes, on a spectrum from allowing implicit conversion, between similar types to JavaScript where it always tries to run your code. C is somewhat weakly typed, it allows for a lot of implicit conversions and it doesn't check typedefs. It has some strong typing support when using structs. In Ada you need to be much more explicit with your type conversion to get your program to compile, but I find it helps you spot errors. I think some of functional languages positive effect might be a proxy variable for strong typing.
&gt; JVM don't like large cakes How many methods do you need to have a "large cake"? And how did you find out the JVM has problems with them? I'm currently using pretty big cakes (but trying to move away from them as much as possible), and the main complication I had so far is that the compiler takes forever to run after a change.
Oh yeah, I'm sorry I overlooked that.
https://www.scala-lang.org/blog/2016/07/08/trait-method-performance.html Compilation speed is one of the main points to avoid advanced Scala for me.
Renaming buildA to buildABCD does not solve anything - we still need to build a chain of A B C D passing XYZ along.
The renaming just shows that there is something wrong. You said: &gt; And I don't want to pass XYZ all the way from A to F But you don't have to do this. There is nothing that makes you passing XYZ "from A to F". See here: val xyz: XYZ = ??? val d = D(xyz) val c = C(d) val b = B(c) val a = A(b) Now there is no coupling between A and xyz. We can change D to work different (without XYZ) and A doesn't care. neither does B. No passing of XYZ anywhere.
Indeed, it will be either non-modular or non-flexible. How are you going to export a b c d and import xyz? Traits? It will be cake pattern. Functions? You'll have to pass in and return too much.
Export? You mean how they will be used? Well they are passed to whatever needs them. When you talk about "too much" I think there are probably different opinions. If a code change is probably changing something (semantically) I want to the compiler to make me look at this to make sure nothing goes wrong. To me this is rather a good thing, not a bad thing, even though I sometimes know for sure that everything fits but I still need to make the compiler happy.
Then read the source code. :-) To be clear: I don't have an issue with students writing code, and the code certainly surpasses usual academic standards (by actually compiling). But it's pretty clear that a process -- which allows code to be merged that is under-documented, leaks internal undocumented methods, largely misses any kind of comments that would allow maintenance by a person except the author himself and uses cryptic names pretty much everywhere -- is pretty broken. Not a single one of these issues was impossible to fix before merging it. Just like `scala.mobile`, `scala.dbc`, `scala.testing`, `scala.text` or `scala.util`. We are not talking about some isolated incident, but shipping whole packages which should never have been merged given the state they were in.
Because that's one of the design patterns built into the language already, as implicit parameters, and because putting your injections into a good trait that you could then mix into your classes anyway to solve the issue without macwire is not making the problem any easier to solve. Anyway, the correct way to do injection using implicits: In config.scala abstract class Config{ def db: DB ... } object Config { object DefaultConfig extends Config { override lazy val db = new Mongodb ... } implicit val defaultConfig: Config = DefaultConfig } In needConfig.scala object NeedConfig { def getUser(id:Int)(implicit config: Config): User = config.db.collection("user").find(BSONDocument("_id" -&gt; id) } In prod, we don't import Config at all, implicit resolution will automatically get it from the config companion. In tests, we can override: In NeeedConfigTest.scala class NeedConfigTest { test("should override"){ implicit val testConfig = mock[Config] //mock to set up a mockDB NeedConfig.getUser(2) should be mockDB.collection ("user").find ("_id" -&gt; 2) } } Now you can override anything you want, anywhere you want. The trick is to use the import keyword in the smallest possible scope, or to just use it in the main you want to behave differently. Imported implicits trump all others, so import should be your last resort to get implicits into scope. Declare them in companions, or redefine them implicitly, locally.
The numbers are straight out of a heap dump. Unless Scala has some weird way of hiding references from heap analysis, I'm reasonably confident in them.
Yeah, maybe I misread the source code then. Can you have a look and tell me your thoughts?
I think the lesson is "Java objects are big", and something as simple as an object that holds an array is going to cost you - in the same way that you need something like &gt;16 characters in a String before you're allocating more data than overhead.
Hey thanks you so much! I sort of grasping at straw right now since i just installed scala. Would you mind walking me through a little bit more/confirm the steps i go through as I'm lost, haha? 0. install scala 1. install circe-fs2 package 2. create a case class or use the pre-package ... for a map(?) after that i'm lost. 
True! Nitpicking: Shouldn't we also count the the duplicate length (field + array.length) and the reference to the array and the header of the array itself as overhead too?
I the article my aim was that of writing about native dependency injection techniques in Scala. I do not want to use an external framework. Anyway, I will give to Macwire a try. However, as far as I know, also Scala Macros are not viewed well in the community.
I cannot understand why the factory method `buildA` needs an object of type `XYZ` if the constructor of `A` does not require it. Anyway, if you need a method such `buildA` DI is not the answer.
Here’s something that I’m wondering about. I’ve heard quite a lot about how EitherT is much more sane than using just Either. I wonder what are the arguments behind this statement? I’ve read the description of EitherT in the cats documentation, several times, but as a scala neophyte ( ;) ), it didn’t really click yet.
How many packages do you have? Scala generates many class files as part of the JVM encoding of code structures that I would not worry too much about unnecessary package objects.
I tend to keep my values in concrete types e.g. `Vector`, largely for compatibility with ScalaZ but also out of a sense that concrete is better than abstract for data. Whereas functions I'd probably make polymorphic (in a typeclass-based way) straight away. So the code would look like a bunch of functions that operate on `F[_]: Traversable` or what have you, but then the actual values would be `Vector`s (or `Set`s or whatever is appropriate).
`EitherT` is mainly useful when you're combining multiple effects. The point isn't to use it where you'd use `Either`, it's to use e.g. `EitherT[Future, MyError, A]` rather than `Future[Either[MyError, A]]` so that it composes properly. When you're writing generic library code there's an argument for writing it in a transformer that the user can bring their own monad for, in the same way that if you're accepting a callback you should maybe accept a monadic one, because the use case might involve using a monad. There are other ways to do an "open" encoding of possible effects: Free coproduct style, or "final tagless" style. But for application code I'd say that's overkill, and you should stick with a single monadic effect stack unless and until you have a use case where you actually need to reuse the same code in different effect stacks.
Ha ok. I wouldn't worry so much then. The code of `TrieMap` has actually more comments than the `unordered_map`implementation in LLVM C++ stdlib. https://llvm.org/svn/llvm-project/libcxx/trunk/include/unordered_map
Actually you're tracking quite well! If you are brand new to scala, you need to read the [sbt getting started guide](http://www.scala-sbt.org/1.x/docs/index.html) to set up your project. That will tell you how to structure your project sources, install the dependencies, install the sbt assembly plugin, etc. Then, in your src/main/scala directory in your project, you can create a Main object. It looks like this: object Main extends App { //code goes here } Then, you can create a StreamJson.scala object. Follow the readmes and the example from the previous post. In it, I showed you how to read a file, and parse it to json in a streaming manner, including how to unescape and parse the nested fields in a streaming manner. map (lowercase) is a method on Stream that takes a function that takes a Json object and returns the output of your query or your transformed Json object. In the query case, the function outputs your nested field. In the case where you are changing the nested fields from escaped strings to Json objects, it is the Json object that was modified. flatMap is a method on Stream that takes a function that takes a Json object and returns a Stream of Json objects. The method will return a Stream of Json objects. If you read the fs2 guide and the circe documentation, it will be much clearer. They are linked from the readmes and the previous post. At lunch I'll post some gists that you can follow. You then use that StreamJson object in your Main object to do your work. If you follow my example, and the readmes, your stream.run call will output an IO containing your result. Calling unsafeRunSync on that in your Main will output your result or throw an error containing the stack trace to what failed. I recommend you start simple - just read the json file in the stream, and use the json.nospaces to turn it into a string and println(stream.run.insafeRunSync) to print it out in main. Then incrementally change the stream using map, flatMap, fold, and filter until the println shows what you want as a result.
Unfortunately it has the same weakness as other compile-time injections: does not work for nested configs. Imagine your Config injects mongoHost: class Mongodb(implicit host: MongoHost) And you want to call `endUser` with same Config but different MongoHost. And you can't.
Ahh, still on the installing scala stage and it's taking a decent bit of googling for the setup, haha. it's my first time doing this, not a dev and it feels like a puzzle piece, haha! and to confirm when you say class case it's sort of like a list i guess or overarching organizational structure i'm imposing into the unstructured son data? and map helps me do this instead?
A case class is a datatype class with the fields and types from your JSON object. You define it like this: case class Event(fieldName1: String, fieldName2:Int, nestedEvent: String) Circe has automatically derived json formatters that will convert Json into your case class instances for you. You can then modify and query them like you would normal java/scala objects. They come with automatic toString, hashCode, and equality methods, and can be destructured in pattern match statements. You access fields with `.`. You modify fields with copy, which produces a new instance containing all the same values as the instance you copied, but with the field specified in copy updated to the value you set. The original instance remains unchanged: val escapedEvent = myEvent.nestedEvent val updatedEvent = myEvent.copy(fieldName2 = myEvent.fieldName2 + 1) myEvent == myEvent println(myEvent) println(updatedEvent) myEvent match { case event@Event("test",_,escapedEvent) =&gt; unescapeJsonAsEvent(escapedEvent) } In pattern matches, `_` means to ignore. `@` will assign the full match to the name on the left hand side. A literal or existing variable will match only if the contents of the thing being matched at that field name are equal, and an undefined name will be assigned the value of the field on the thing being matched. The right side of the fast arrow will be the reuturn value of the match. You can see how it becomes easy to declare the things that must be equal to match your query, and extract fields from structures to perform actions on them using pattern matching. That's the power of case classes.
Absolutely nothing (sorry I just had to)
Yes, I can. And you already didn't listen because you defined the injection at the class level. They go on the methods. new MongoDb()(newMongo) If you defined it on the method, you will have 0 issues with nested implicits.
I think they're pretty amazing for domain driven design. You're even encoding requirements in your function signatures, which makes it easier to use APIs designed this way. Why would you say they're useless?
I guess the joke was kind of lost, it was a quote from a famous song https://www.youtube.com/watch?v=dpWmlRNfLck
Why wouldn't `override lazy val` work for deeply nested modules?
Now I feel bad, and I'm thinking about Rush Hour.
Can you explain in code? I don't understand how it is possible given `getUser` stays the same: def getUser(id:Int)(implicit config: Config): User 
Macwire offers two ways of composing modules: - via inheritance. It will be standard cake pattern with all the disadvantages. But we can override lazy vals) - via composition. Much better looking but no overrides for you!
I was going to say Bruce Springsteen - didn't realise it was a cover.
Just found out about quill.io. Not sure why I hadn't paid attention to it yet. It's pretty functional, is somewhat similar to Slick, and plays slightly better with other parts of the ecosystem. Doobie is still pretty great, but I miss the query generation in it.
OT, but the suggestion in the comments to remove the hell/beast/*ape code section is, IMO, a pretty good idea. I guess to each their own, but in no way would I describe that section as "funny".
I'm not sure I understand what your are getting at. Can you help me understand? Why does use of inheritance inherently mean cake pattern? If you are using composition to combine modules why can't you change the module inputs? Can you provide a code example of the problem? Possibly based on the code /u/DanielShuy presented?
I could agree on that and say that each particular case should be revised independently: the monolith classic layered design differs from composition-based design with it self nothing like microservice (single purpose service) design. As far as the article context touches the Play Framework which it self pretty much encourages developer to use the classic MVC paradigm implicitly bound to OO-style layered application design, I would take this assumption as a starting point. In general what I’ve seen so far people used to structure there Play applications this way: class UserController(userService: UserService) extends Controller { def getUsert = Action.async { userService.getUser(request.userId) } } class UserService(userDao: UserDao, userImageDao: UserImageDao) { def getUser(userId: Int): Future[User] = for { userModel &lt;- userDao.get(userId) userImageModel &lt;- userImageDao.get(userId) } yield User(userModel, userImageModel) } // here JdbcConnection represents what ever library you use to query data from the external storage class UserDao(jdbcConnection: JdbcConnection) { def get(userId: Int): Future[UserDbModel] = jdbcConnection.queryAsync(…) } // assuming some external image CDN or other dedicated image storage class UserImageDao(imageServiceClient: ImageServiceClient) { import marshalling.UserImageMarshaller def get(userId: Int): Future[UserImageModel] = imageServiceClient.get(…).map(UserImageMarshaller.unmarshall(_)) } Code above was significantly simplified in order to represent the idea and missing the widely used dependency injection annotations, traits, imports and so on. The responsibility abstraction layers we have there: - `UserController` - communication - `UserService` - business logic - `UserDao` and `UserImageDao`- data storage / repository Each layer transforms the model received from underlying performing respective operations to fulfil its business duty as well as to secure the abstraction not leaking any information out of the contracts boundaries. If we decide to bother ourselves to track the dependencies we’ll see something like that chain: ImageServiceConfig -&gt; ImageServiceClient -&gt; UserImageDao -&gt; | | -&gt; UserService -&gt; UserController JdbcConnectionConfig -&gt; JdbcConnection -&gt; UserDao -&gt; | If you for example following some TDD practices either maintaining Unit tests you’ll have to adjust the code above to write certain traits for each respective class and use those new traits for only purpose of mocking them. The further expansion of the functionality will also lead you to the increasing amount of mocks to maintain. And if that example will hit live eventually the one will notice some extra dependencies such as Execution contexts, marshalers/(de)serialisators and other stuff imported from package traditionally called `helpers`. Here I should perform an action which deserved all the shame it deserves and refer to _personal experience_ telling that the most vulnerable so most tests demanding part here is an actual piece of _busness_ logic: `UserService`. Rather different approach could be taken here to solve the problem: taking in IO bound operations anyway deserve proper integration testing using purposely dedicated environments, the `UserService` implementation could be build abstracted out of the actual sources of data but around data itself: // here CustomContext represents the instance or request level configured dependencies such as execution contexts, http clients, database connections, etc. class UserController(context: CustomContext) extends Controller { import context.implicits._ def getUsert = Action.async { UserService.composeUser(UserDao.get(request.userId), UserImageDao.get(request.userId)) } } object UserService { def composeUser(user: Future[UserModel], userImage: Future[UserImageModel])(implicit ec: ExecutionContext): Future[User] = for { userModel &lt;- user userImageModel &lt;- userImage } yield User(userModel, userImageModel) } object UserDao { def get(userId: Int)(implicit jdbcConnection: JdbcConnection): Future[UserDbModel] = jdbcConnection.queryAsync(…) } object UserImageDao { def get(userId: Int)(implicit imageServiceClient: ImageServiceClient, marshaller: UserImageMarshaller): Future[UserImageModel] = imageServiceClient.get(…).map(marshaller.unmarshall(_)) } Fist of all I should point that solution above is pretty subtle and serves only concept demonstration purpose. Though the idea behind it is to separate data dependent logic and IO operations by substituting the actual _data providers_ dependencies with _data handlers_ dependencies. The most notable part here is the _business logic_ method signature: def composeUser(user: Future[UserModel], userImage: Future[UserImageModel])(implicit ec: ExecutionContext): Future[User] You could see it stoped being an IO bound operation any more at the same time started being data source agnostic, enabling you to test it with pure models passed directly to the method itself and assert the result with no need of mocking intermediate layers between logic and data. Using the `Future`’s here I only wanted to represent certain level of _laziness_ which could be substituted as well with `Function` , `Option`, call-by-name parameters and any other way to define the “data which probably not there”. The one could wonder how to handle the controller tests as far as we couldn’t mock the data or service layer any more? The are at least two ways which I know about: - Wrap the IO bound low level dependencies into abstraction with a trait to be implemented in tests with fake, in memory data used internally or rather use the in memory implementations of the underlying services if present (like in-memory Cassandra instances and similar). - Replace the controller’s unit tests with black box tests to benefit from more realistic circumstances the tests take place into. Both ways have some pros and cons and should be considered in-place and nothing denies using both of them in the same project for different purpose. 
Hi all. I've asked a couple of times here and elsewhere, but I guess my question is too specific for general answers. I figure I'll give this thread a try: I would like to find out how to work with something like reactive streams to find and measure peaks in live data (to be processed and recorded off to the side). If you want more information I can expand on this here, or you can see my last thread in another subreddit [here](https://www.reddit.com/r/scalastudygroup/comments/6zsyn5/trying_to_understand_how_to_solve_a_problem_with/). Hopefully someone can point me in the right direction :)
Another thing I'd like to know: is there ever likely to be some sort of UI toolkit for native Scala? Or would it be feasible to use, say, QT cleanly with it? I'd love to see Scala used more for "end user" application development, but I wonder if it is more suited for backend or web development still.
Hi /u/saosebastiao, Maybe it is this problem: https://github.com/playframework/playframework/issues/7898 If, you can try one of our most recent nightlies to see if it fixes your problem. See this comment: https://github.com/playframework/playframework/issues/7898#issuecomment-335619184 And also the list of snapshots here: https://oss.sonatype.org/content/repositories/snapshots/com/typesafe/play/play-docs-sbt-plugin_2.12_1.0/ Let me know if this solves your problem and if not, please comment on the issue linked above.
Good God, y'all
C is memory unsafe. Weak typing is peanuts compared to that.
If you look at types from the perspective of actual *type theory*, having decades of experience, then dynamic languages are uni-typed. At this point *strong typing* is a meaningless marketing term really, because personally I can't consider a uni-typed system as being *strong*.
What if you want to depend on the DB directly and not on the whole config? Is that possible without changing the approach too much? 
Not as of 2.12, it doesn't.
Using native libraries from scala native is meant to work AIUI, though Qt is a big library that may not be the easiest to make bindings for. I would think using an existing native toolkit is far more likely than someone writing a dedicated toolkit in native Scala.
I would use Apache Spark for something like this, it may seem a little overkill but at least the JSON parsing would be fairly easy (after you determine a schema) and the operations required seem fairly standard for spark. Plus if the program is meant to be reusable it should scale absurdly well.
&gt; However, as far as I know, also Scala Macros are not viewed well in the community. This isn't entirely true (it depends on who you ask) Certain problems are impossible to solve without macros, and in other cases macros is what you need if you need to provide performant code and/or stuff like generic derivation from types (such as Shapeless) is causing your compile times to go through the roof
From what I know, Scala 2.12.3 should have better performance for the cake pattern wrt compilation, and also its being looked at in dotty
Thanks for the detailed explanation. I will look for Scala Macros as next learning topic :)
99.999% of apps can be tuned without spending thousands of dollars on a 3rd party JVM. Hire a consultant who really knows GC, and give them a week to tune your app. If still stumped, then go get a demo of zing.
&gt; without spending thousands of dollars on a 3rd party JVM instead, spend thousands of dollars on a consultant to maybe still have to buy the 3rd party in the end?
Have you priced Zing before? I suspect you do that before you compare the two :) 
This is spot on. I am amazed at how often this happens in my company. We decide to start writing scala (coming from php) and only a handful of people even make the attempt to learn about the runtime environment. Watching as some teams allocate 10GB of memory for an app that requires 150mb of live data and an unbounded limit for the system.. then complain when the app isn’t performing correctly. Take the time to learn how to tune your environment, your GC, figure out common pitfalls with the JVM, what is oldgen/Eden/survivor space, what GC should you use and how to tune it, etc. 
Edit post number two: What are your GC goals, and what are you current GC times? Zing can help bring STW down from say 100ms to 5ms. But careful tuning may be able to get you down to 10ms without zing. If you are seeing something like a 1 second or even a half second GC pause, you have other problems that you can't just "fix" with Zing.
I'm excited about this! The lack of 2.12 compatibility has held me from experimenting much with Dotty. Now I know I can bring in relatively recent packages in toy projects.
One of the, not the.
Nice! When do you believe you'd have the next chapter done?
Unfortunately I am working on my thesis, so I don't really have time, but I would like to write the next chapter in the next 3-4 weeks or so. 
Pierre Laporte has some good heuristics on this, although the slides are old: https://www.slideshare.net/PierreLaporte/pimp-my-gc
- Recruit java programmers, teach them scala. Recruiting is much easier with that in mind. - I've not had the tooling issues that you are mentioning. Intellij has been great for me. What are the details here? I've seen this typically when a library has competing implicits so this may be more of a code issue than tooling. - The velocity of developing a scala app, for me, has been a good experience. The type safety and functional approaches tends to yield far less bugs than other languages that I've used. And refactoring is a cinch. Again, not sure where your issue is with Refactoring; using the type system makes this easy as pie. I have no idea where you get the notion that JavaScript is easier to refactor. - Kotlin programmers are just as hard to come by as scala ones. I don't think that belongs in your list.
Most companies use IntelliJ IDEA these days rather than Eclipse. IDEA's presentation compiler doesn't have great implicit conversion support, but the way to get around that is to add an extra line to do the conversion: val foo: Int = intString and then work from there. Don't squish all your implicit magic together, because it makes it harder to read for developers as well. In fact, if you can avoid implicit conversions altogether that's probably best -- implicit resolution is a major cause of slow compiles. Recruiting, it's hard to say without knowing a bit more about your location and field. Putting your name out there can help. Are you going to meetup groups and being active in the community -- blog posts, helping out on mailing lists?
You might be interested in this study that shows that Scala has lower defect rates than the languages you specified as alternatives: https://jaxenter.com/programming-languages-defect-prone-report-138065.html Scala produced 12.9 K bugs to C#'s 50.7 K, and Java's 35.1 K. Of the low-defect functional languages, Scala came in 4th in fewest defects, but had the highest developer base at 1.9K. It also did its work with 5.3 MLOC compared to C#'s 27.7 MLOC, and Java's 19.1 MLOC. The upshot of all this is that scala is a much safer and more efficient language compared with your alternatives. All those fancy refactoring tools available with js and java seem to have produced more defects. So, while it may be harder and more expensive to find quality engineers who know Scala, and training other developers to use Scala effectively may take longer, it still makes economic sense to hire them and use Scala anyway, because you produce fewer defects in fewer lines of code with fewer developers -- your development time is not wasted on defect churn. Now, you are trading off initial velocity (initial hiring and training phase) for long-term velocity boosts of around a factor of 5 for C#, and 3 for java. If it takes you longer than 3X to train or hire quality scala engineers than it does to hire quality java engineers, it might make sense to choose Java instead. Also, if you are a startup, it makes sense to go with Scala over java and hire fewer, more experienced Scala engineers at a higher pay grade than it does to hire an army of java developers, because the Scala team will get more work done per engineer with fewer lines of code, because the numbers show Scala is more efficient than Java. The only thing that really matters is the correctness of the code and the verification done by the compiler. Speed of compilation means nothing if that fast compilation results in more incorrect code. Fast and incorrect is still infinitely slow, as it doesn't actually get the job done. You have to manage the trade-offs in engineering. There is no silver bullet. The slower compile times and more strict typesystem that it enables are there to prevent certain classes of bugs that cannot be prevented in other codebases developed by human beings. No matter how trivial a codebase is, it is unlikely that a single human truly understands all of it all of the time, under all conditions. Humans can only manage 7 +- 2 things at a time. Offloading some of the "proof" of the state of the program to types and other language features provided by advanced languages like scala, and advanced techniques in Functional Programming, helps (as shown in the study) to make development *more efficient* vs an imperative, or weaker typed programming languages. Now, to a human being that has not been exposed to stronger type systems and FP techniques before, that will be *additional* cognitive load until they have mastered the techniques through experience, which will make that individual less efficient for a short time. Nothing comes for free. As a company, you need to make the choice, with supporting data, which choice of technology makes sense for your product/market fit. If you live in an area where it is prohibitively expensive to find experienced Scala devs that can also lead a training effort for experienced devs, and consulting/remote employees are out of your price range, don't choose Scala because it's more efficient. 
Gotcha. Would you also consider showing how to write test cases for these?
Yeah, sure. I can do that! There are two scenarios in my head, one is with the default akka-http test kit, and an another one with dispatch. In my opinion both of them are really good libraries, however, dispatch is not a testing library, just a simple http client, so we have to use ScalaTest to be able to test with dispatch. What do you mean by testing, only the endpoints or the inner layers (save todo to database, get todo from database) too? 
Sure, let's take the example of using the config above again, and expand it to have two `Config`s: abstract class Config(){ def db: DB } object Config{ object DefaultConfig extends Config(){ override def DB: Int = new MongoDB } object AlternateConfig extends Config(){ override def DB: Int = new MongoDB(27013, "alternateHost.mongodb.mycompany.com") } implicit val defaultConfig:Config = DefaultConfig val alternateConfig: Config = AlternateConfig } Now lets say we have a repository, and a use case that gets Users from the default mongo, and one that gets client users from the alternate mongo. We can use the same repository as before, without any changes: object NeedConfig { def getUser(id:Int)(implicit config: Config): User = config.db.collection("user").findOne(BSONDocument("_id" -&gt; id).as[User] } And create another module that has `fetchUsers`, `fetchClients`, and `fetchUsersAndClients`. `fetchUsersAndClients` knows that clients must be called with the alternate config: object UserService{ def fetchUsers(id: Int)(implicit config: Config): User = NeedConfig.getUser(id) def fetchClients(id: Int)(implicit config: Config): User = NeedConfig.getUser(id) def fetchUsersAndClients(id: Int)(implicit config: Config):List[User] = { List(fetchUsers(id)) ++ List(fetchClients(id)(Config.alternateConfig)) } } No ambiguous implicits. Now, a much more likely situation is that you really want one `fetchUsers` method, but *two* configs. The solution is to use phantom traits (traits without any members) as a types on a generic `Config[A]` to make distinct config types so that the compiler can inject both unambiguosly in `fetchUsersAndClients`. You make the various methods generic on some type A and the compiler will figure it all out for you. Full example: sealed trait UserProfile trait Clients extends UserProfile trait Users extends UserProfile case class User(_id:String) abstract class Config[A](){ def db: DB } object Config{ implicit val defaultConfig:Config[Users] = new Config[Users]{ override def db: DB = new MongoDB(27013, "userHost.mongodb.mycompany.com") } implicit val alternateConfig: Config[Clients] = new Config[Clients](){ override def db: DB = new MongoDB(27013, "alternateHost.mongodb.mycompany.com") } } object NeedConfig { def getUser[A](id:Int)(implicit config: Config[A]): User = config.db.collection("user").findOne(BSONDocument("_id" -&gt; id).as[User] } object UserService{ def fetchUsers[A](id: Int)(implicit config: Config[A]): User = NeedConfig.getUser[A](id) def fetchUsersAndClients(id: Int)(implicit usersConfig: Config[Users], clientsConfig: Config[Clients]):List[User] = { List(fetchUsers[Users](id)) ++ List(fetchUsers[Clients](id)) } } There you go, multiple configs, automatically injected by use case, no external library needed, compiler verified, and the only thing beyond non-generic methods you need to understand is how to use substitution to insert `Clients` | `Users` for `A` as needed to read the code. Intellij and ENSIME will even tell you which implicit declaration you are using in each instance (assuming your mongo lib of choice looks like above. I compiled this, replacing `DB` with `String`and the `getUser` body with filling the string from the implicit. We use this pattern at work, and it works well. We use it to have different runtime profiles that change the behavior of an app for different deployments, similar to how you would use a Spring profile.
Yes, although often DB is an external library type, which means you have to use shapeless or scalaz [Tagged types](http://www.vlachjosef.com/tagged-types-introduction/) to decorate the external library type for injection when you have two or more different injections. It's much easier if your injection class is a wrapper around the external type, because you don't need an external library to differentiate the two/more implicitly provided instances from each other. See my full example [here](https://www.reddit.com/r/scala/comments/76p1ej/resolve_me_implicitly/dohzfwc/).
If you're using akka-stream as your reactive streams implementation, you might look at [`Flow.sliding`](https://doc.akka.io/docs/akka/current/scala/stream/stages-overview.html#sliding) or [`Flow.grouped`](https://doc.akka.io/docs/akka/current/scala/stream/stages-overview.html#grouped). Though they operate slightly differently both will divide the stream up into windows you can scan for peaks. You might also be able to come up with a more incremental approach tracking relative increases and decreases and saying the stream went up enough between elements [i, n] and down enough between elements [n, j] then you might have a peak somewhere between [i, j].
I think using scalatest would be pretty solid. 
TODO apps is where slick really shines
Yeah starting with Slick 3 it's much more functional. It was a bold move that has really paid off for users I think.
Hi, thx for pointing out my options i am still considering also scala-packed (i would still need to make a mutable map out of the PackedMap), i just don't have exactly the time to try everything. Your 3. point, right now i am using TrieMap and the key information is in the "key" :D so there are no duplicits. Compression and other hacks are welcome :)
An intuition (which holds for monad transformers in general) is that `EitherT[F, A, B]` is equivalent to `F[Either[A, B]]` but it lets you forget about `F` temporarily … you can pretend it's plain `Either` for a while, which means you get short-circuiting behavior if a `Left` is encountered. This is nice if you want to compose a bunch of these things in a `for`-comp for instance. When you're done you get the `.value` out and you're back to `F[Either[A, B]]`.
You are correct that the tooling situation for Scala is unforgivable, and I think the survival of Scala is in the balance as a result. If things don't improve in Scala 3 I think we will see people leaving for Java and Eta. Having said that, I think Scala is still the best JVM language at the moment and it's worth the trouble for the expressiveness it affords. I have found that using a text editor like Atom with sbt in a nearby terminal is the a reliable (but primitive) tooling setup. 
&gt; . . .Clojure, Haskell, Ruby, and Scala are less likely than average to result in defect fixing commits It's interesting that Ruby made it in here. 
Parser combinator library looks simmilar to shlex at a quick glance, but I'm not familiar with shlex 
`text.split("\\B")` does it for me
Hopefully there will one day be a "recommended" toolkit or bindings that work easily without having to have too much translation code going on. Thanks for the response.
Perl, too! It's an interesting study. Go also appears to be low in defects.
Thanks for the tip! I haven't looked at akka-stream (it wasn't available when I first started to look into this). Would it be possible to use something like takeWhile to take values of a stream greater than a threshold work with some sort of "bailout"? Basically I have two options when the threshold is exceeded - either the values drop back within a specified number of samples (a peak - this needs to be kept and passed on to the next stage) or the values remain high for longer (this would indicate a drift and another piece of code needs to be called to send an adjustment to the output). Would this need some custom stage? 
Go doesn't surprise me.
And even if IntelliJ is not following everything you do on the type level, you can always disable the squiggly lines and reap all the other benefits. Notice that IntelliJ still _compiles_ code that it mistakenly underlines. Quoting a [previous comment](https://www.reddit.com/r/scala/comments/62ndwf/what_do_macro_cats_shapeless_etc_users_do_about/dfp3d21/?utm_content=permalink&amp;utm_medium=user&amp;utm_source=reddit&amp;utm_name=frontpage) of mine: &gt; I [...] disable error reporting for problematic files only. &gt; I still think IntelliJ is a net win, for: instant variable/field/class renaming; finding definitions, usages and overridden versions of any declarations in a keystroke; indexing the whole code base so I can instantly jump to any declared class/object/method; the nice grepping capabilities; showing scala/java-doc; auto-complete; etc. &gt; You can even still get correct type information from a shortcut in many cases, and get at least approximate type info most of the time.
 &gt; val str = """1 "2 3 4" 5""" str: String = "1 \"2 3 4\" 5" &gt; str.split('"').toList.sliding(2,2).map{case hd :: tl =&gt; hd.split(' ').toList.filter(_.nonEmpty) ::: tl}.flatten.toList res0: List[String] = List("1", "2 3 4", "5") 
Why not?
Statically typed and very, very simple.
What about carrying the (de)serializer with the commands? final case class GetItem[T](key: String)(implicit val deser: ByteStringDeserializer[T]) extends Cache[T] cache match { case g @ GetItem(key) =&gt; // use g.deser // etc }
The potential issue with `takeWhile` is that it'll cancel the stream the first time the predicate returns false. I don't think that's what you want. I'm not sure if that strictly needs a custom stage. You can detect whether it's a peak or a drift and pass on elements like `Peak` and `Drift` for the downstream to handle.
Ah, I think I understand (though it will take me some reading to learn how to implement it). Thank you very much for your help!
If I was serious about building a product, as opposed to picking a fun language, I'd use java. Assuming it's a web app: Spring MVC/Spring boot, hibernate, Postgresql. There will be more candidates, but you'll have to be more selective. Getting talented people, and simplifying the business requirements are way more important than language choice.
thanks, very informative
But the method GetItem has to be generic right? otherwise every time I write a case class (Bar, Baz) I will have to come and update the definition of GetItem[T].
I don't follow. It's still generic, it just summons the serializer when you construct a `GetItem` and makes it available when you interpret that instance.
One example i know on top of my head that breaks intellij is shapeless discriminated unions. They get shown with errors for me but compile and work perfectly fine.
IMHO in every enterprise context, where people pick Java.
Kotlin is much easier to pick up than Scala (at least in my limited experience). So training Java devs to use Kotlin is cheaper than training them to use Scala properly. But Kotlin also feels like Java++ rather than a fully different language like Scala.
Maybe because of the culture's strong emphasis on tests?
&gt;and IntelliJ seems incapable of resolving many of our implicit conversions, coloring red half of our codebase which compiles fine using SBT Have you created an issue on their bug tracker?
From my experience I would have to disagree. The language choice is absolutely crucial for the long term cost of a software product. Choose the wrong language and you will be spending huge amount of time and money on maintenance which could otherwise be spent on developing new features.
It's true, but I have used Slick for more complex applications (joining 3-4 tables in a query) and it worked like a charm. I have to admit, it is easier to show the advantages and benefits of Slick by creating a simple example.
Thanks for linking this. Amazing. 
&gt; How can you build a reasonable case for using Scala in a software development team that may include average programmers? We use scala because we believe hiring average programmers that you can't train into excellent programmers is a mistake. 
If I remember correctly this is a still unresolved problem in shapeless. If I'm not mistaken if you split the same thing into separate instructions then it should work as expected: val tmp = polyFun andThen polyFun val result = tmp andThen polyFun I vaguely remember this being a problem for `compose` too.
Agree. Considering that user issues have never been taken seriously, it's unlikely that the tooling situation will change. It's true that user might be unable to figure out the _reasons_ for their issues, but users are usually dead-on describing the _symptoms_ they experience. As long as user feedback is summarily dismissed instead of trying to figure out where they are coming from, things won't improved. Examples: - Users: "Scala is too complex" - DON'T respond with lecturing them about Scala's number of keywords or the number of lines of Scala's grammar - Remove corner-cases, improve documentation - Users: "Scala's tooling is bad" - DON'T respond with "well, actually ..." - Stop releasing major versions without IDE support - Users: "Scala has too many features" - DON'T keep adding more features - Stop adding more features (D'Oh) - Users: "Scala is breaking compatibility in minor releases" - Stop breaking compatibility in minor releases (looking at you, 2.12.x) - Users: "Major versions are not compatible, libraries need forever to release new versions compiled against new major versions" - Stop releasing jar files with classes - Introduce a module format that contains - A typed AST - Information required by scala.meta - Linking meta data including - dependencies on the JVM, and information to create Java 9 module files - linking information for Scala.js - linking information for Scala-native - Build a tool that takes the AST and can generate the appropriate artifact for the platform and version the user needs during compilation
While you raise some good points, Scala is to some degree saddled with its past, so neither the wholesale removal of features, nor the notion of magically make tooling great are plausible off the bat. Dotty is moving in a positive direction, but I'm skeptical that it will solve all the issues. We'll probably get a much faster compiler (at least 2X speedup compared to present day Scala), which in itself would be a pretty big win (since that's the other major complaint aside from tooling, slow builds). On the tooling front, apparently TASTY can be used for the Java 9 modules approach, as well as providing a common structure for non-jvm targets like scala.js and scala native. Maybe CBT will gain mindshare, or Scala Center's current work on SBT results in ultra fast file change detection that finally deliver the promise of fast incremental builds (that alone would be huge). I wouldn't expect any sudden transformation, 2020 before any real change is realized, small incremental steps until then.
&gt; so neither the wholesale removal of features It worked perfectly fine during my tenure. Deprecated procedure syntax, octal literal syntax, view bound syntax, abstract methods without return types, double literals with no digits after the dot etc. And that's not even looking at the substantial amount of removals in the standard library. &gt; nor the notion of magically making tooling great are plausible off the bat. ??? I'm not proposing "magically making tooling great", I just suggest that maybe it would be smart to not release major versions of Scala without IDE support. I think that' a very realistic goal. &gt; [Dotty] Let's wait and see, it's substantially worse in some regards and fails to address some of the pressing issues we will face in the near future. &gt; I wouldn't expect any sudden transformation, 2020 before any real change is realized, small incremental steps until then. Pretty much everything I wrote could have been implemented and shipped 5 years ago.
Your interpreter has to be able to interpret any `Cache[A]`. So you have to ensure that the only possible `Cache[A]`s are the legitimate ones that you can serialize. As /u/zzyzzyxx suggested, you could carry the serializer inside the `Cache[A]`, though at that point I'd question how much value you're getting from using a free monad rather than a regular monad.
I see Scala as a safer (and ultimately more expressive) Python/Javascript rather than as a more expressive Java/C#/Kotlin. From that perspective, the tooling isn't any worse and the much higher safety (i.e. many fewer tests needed) makes up for the build times. (Though FWIW I find the "Problems" tab view in Eclipse is reliable, so I just go by that rather than error highlights, and rarely need to clean compile)
Simon, regarding your java interop comments - The way you describe it, you would be able to pass all scala collections to java collections if they implemented java Iterable. But that means that all collections have to be mutable, as Iterable defines `remove:void` which should remove the current element from the underlying collection. Requiring a call `toIterator` to interop in the way you describe is perfectly fine, though. Making comparable unchecked would make for great java compatibility, but out would also be possible to compare apples and oranges right? That's probably a mistake. A toJavaComparable that new ups a type of your description that delegates to the parent comparable is acceptable though. 
&gt; and I think the survival of Scala is in the balance as a result. With some very large companies invested in Scala (Twitter comes to mind), what do you think might happen in that case? Would they end up also switching their huge code bases to another language?
Remind me again what `\B` is supposed to do? 
https://github.com/milessabin/shapeless/issues https://stackoverflow.com/
The approach given by /u/zzyzzyxx worked perfectly for me and my whole sample is working now. /u/m50d are you suggesting that there is a better way? In the end we need to be able to do useful things with the types which come into the interpreter and in order to do useful things we need the implicits associated with those types.
That's a good point.
The idea of the Free monad is to separate the declaration of the operation you want to perform as a value from its implementation in the interpreter. It seems to me that if you're including the serializer/deserializers in the `GetItem`/`PutItem` values then you've already put most of the implementation in there, so I'd be inclined to put the whole implementation in those and do away with the separate interpreter entirely (i.e. have an abstract method on `Cache` to execute). Though I guess the code support for doing this maybe isn't there - maybe `Free` is still the most lightweight way to implement it?
It’s probably the opposite to what you are looking for because you said “native” but I think using scala.js with electron is a nice way to go 
In real world usage what I use EitherT for is when you’re dealing with a number of calls that use say Future[Either[A,B]] as you need to at each step handle getting the future out and then getting the value out of the either. You end up with nested code. EitherT is a Monad transformer. It lets you reach inside the future and then the either at the same time. If you have a chain of things calling functions that return future either it is a lot neater and easier to read. I did a blog post on this http://justinhj.github.io/2017/06/18/future-either-with-cats.html
Do you have a lot of concurrency in your applications? Do you read and write mutable state from more than one thread? If so, reading up on the memory model of the JVM and stuff like memory consistency and happens-before relationship may help (greatly) argue in favor of functional programming, and functional programming is considerably easier in Scala in many ways. For instance, the way that Java went about implementing function was fairly light-weight for a variety of good reasons, which means that they do not really have function types as such, and that they have a lot of interfaces for functions with not always that light-weight syntax. Combined with primitive types, and what is much simpler in Scala ends up being [much more heavy-weight in Java](https://docs.oracle.com/javase/9/docs/api/java/util/function/package-summary.html). And this is just one aspect. Java 8 is a great step forward, but it still leaves a lot to be desired. Scala also provides a lot of abstraction ability, which has the potential to (though potential is very much not the same as realization) handle various concurrency issues much better (see for instance [scalaz](https://github.com/scalaz/scalaz)). .NET has its own memory model, I am not very familiar with it personally. I do not have any experience with Kotlin, though on a different level I am wary of having both the main development tool and the main programming language come from the same company (I also think that having Eclipse (/Netbeans?) as a viable competitor is a healthy thing for software companies and developers - potential vendor lock-in is incredibly bad). And there have definitely been incredibly strange pro-Kotlin posts about on this subreddit and elsewhere. Go I likewise do not have experience with, though one aspect that they seem better in is in regards to their "green thread"-like system, in which you have to worry much less about "reusing" threads than in Java, Scala or (I believe) C# (I do not know how Kotlin stands here, and whether their variant of coroutines are similar or much less capable than Go's variant - a "green thread"-like system is entirely non-trivial to implement). But in Kotlins favour, it does on IntelliJ at least I believe have very good tooling.
&gt; that means that all collections have to be mutable [No.](https://docs.oracle.com/javase/8/docs/api/java/util/Iterator.html#remove--) And by the way, Scala is certainly not the language that should complain about inventing interfaces with random, required-to-implement methods in it&gt; &gt; To implement a concrete set, you need to provide implementations of the following methods: &gt; &gt; def contains(key: A): Boolean &gt; def iterator: Iterator[A] &gt; def +(elem: A): This &gt; def -(elem: A): This &gt; but out would also be possible to compare apples and oranges right No, that's not how it works.
Can quoted text have escaped quotes? This sounds like CSV with space for a delimiter. If so you could use opencsv or similar. If you want to use parser combinators to have full control over parsing, fastparse is a nice library. Another approach is to write a recursive function or two `List[Char] =&gt; Seq[String]`
I think you have a very good point, though I also think it depends on which languages you choose between. If you choose between Java and C#, there would likely not be large differences between general approaches, features and abstraction level and which applications they are typically used for, though there would be large differences in their eco-systems. On the other hand, choosing between Java and C++ for web applications would likely make Java the much, much better choice, both due to the language itself (among many things, C++ does still not have a (good) module system) as well as the eco-system and momentum (AFAIK C++ is definitely not a common choice when building common web apps).
You may have seen that Twitter is working on their own toolchain with a simplified version of Scala. So they may end up driving the language at some point. Big companies make their own weather so they have a different set of rules I guess.
To evaluate the long-term viability of a language it is also important to look at adoption, not only existing users. Existing Scala code won't stop existing, but without a minimal rate of adoption, there will be no new projects happening. If you consider that Scala really never bothered to market the language to a wider audience, not to JavaScript (despite the existence of Scala.js) and not to Android developers (despite the existence of Scala-on-Android) and probably not to native developers (despite Scala-Native), this pretty much only leaves Java developers. Concerning Java developers, Scala is now competing with Kotlin for adoption and mindshare. Some uninitiated Java developers might look at both languages and conclude: - Kotlin has great tooling, Scala has not. - Kotlin has understandable documentation, Scala's documentation is rife with jargon and some parts haven't updated for 4 major releases. - Kotlin supports Android development, Scala doesn't. - Scala has some features they have never even heard about, and the website doesn't make it clear why they should care. This will be an uphill battle for Scala.
Soooo scala-packed is not working for me :/ from what i see its quite unfinished, some methods look like this override def +[V1 &gt;: B](kv: (A, V1)): PackedMap.this.type = { ??? } And this is totally killing it, to create an instance i need to have a instance of a basic collection, something like this (from readme) // build a packed map val map = PackedMap( (0 to 100).map(i =&gt; s"key$i" -&gt; RootFoo(NestedFoo(i.toByte))): _*) so then i tried PackedMapBuilder that worked, but it wasn't essentially better then TrieMap I always filled it up with unique Strings (an url with a increasing number suffix) and key Unit Anyway both TrieMap and PackedMapBuilder crashed on 10 000 000 strings with java.lang.OutOfMemoryError: Java heap space In my monitor i saw about 2GB memory used, but i didn't investigate further... Ill try something else (i wish someone would tell me that i am just making some obvious mistake)
&gt; We'll probably get a much faster compiler (at least 2X speedup compared to present day Scala) Right now speed is on par with scalac, and I don't see a magic 2X speedup coming in the near future. It's possible that we could figure out multi-threading however and that would massively help, we'll see :). &gt; (since that's the other major complaint aside from tooling, slow builds) It'll be interesting if we can figure out how much of the slowness is due to people (ab)using expensive macros rather than coming from the compiler itself. Projects like https://github.com/scalacenter/scalac-profiling and of course the rework of the macro system (http://scala-lang.org/blog/2017/10/09/scalamacros.html) should help. &gt; On the tooling front, apparently TASTY can be used for the Java 9 modules approach Not sure what you mean by that. Right now there's basically zero connection between TASTY and Java 9 modules. However, TASTY is certainly helpful on the tooling front, it's already being put to good use in the [Dotty IDE support](http://dotty.epfl.ch/docs/usage/ide-support.html), you can find some details on how this work in http://guillaume.martres.me/ide_paper.pdf &gt; as well as providing a common structure for non-jvm targets like scala.js and scala native Scala.js and Scala Native still benefit from having their own intermediate representation distinct from TASTY, since they have very specific requirement not covered by it, however this IR could be generated starting from TASTY instead of starting from sources.
Far as I know you cannot analyze the structure of a Free monad anyway because of the sequential nature of monadic operations (Free applicative however can be analyzed.) I think the real reasons to use a Free monad, regardless how much implementation baggage you have to carry on your commands, is to support alternate interpretation of the same code, composition of algebras, and channel any DI through your interpreter. There may be others, but these are the primary reasons I prefer Free over direct interaction with an effectful stack.
There are reasons to use `Free` other than program analysis. You might interpret into `State[DataStore, A]` for instance, and may wish users of the API to not have direct access to the `DataStore`; or you may want to have multiple interpreters for various back ends. Constraining the effect is a reasonable thing to want to do.
I would make the instance a normal data member, and maybe make it implicit on the smart constructor. Case classes with multiple arg lists have weird semantics.
What kind of weird semantics? I don't write case classes this way usually, and haven't inspected the byte code or anything, but I'm pretty sure that what I've written is almost exactly what you suggest. That is, all the constructor parameters from both lists are bound to data members, and the implicit parameter list becomes part of `apply` in the companion object.
I think all you want is list foreach { _ onComplete callback } Or you can use `onSuccess` and `onFailure` depending on your needs.
I tend to do this by first turning the List[Future] into a Future[List] with Future.sequence, and then mapping over the results: Future.sequence(myFutures, 30 seconds) map { _. map { r =&gt; myCallback(r) } } 
Most of what you've said here is fairly disappointing, particularly that build times are only on par with present day Scala. I thought that some of the primary motivations for Dotty were significantly improved build times, and possibility of improved tooling as a result of reducing duplicated language features (i.e. more than one way to do the same thing). What then, aside from some new language features like union types, and streamlined ADTs via `enum` shorthand, will compell current Scala users to make the switch to Dotty?
Not sure how would this work
Thanks for the follow-up! 
Only the elements of the first parameter list are considered for `toString`, `equals`, `hashCode`, and `unapply`. In this case the `ByteStringDeserializer` is a typeclass so it must be uniquely determined by the type and it will probably be ok, but in general it can get you in trouble so I prefer to avoid it altogether. So if we have final case class GetItem[T](key: String, deser: ByteStringDeserializer[T]) extends Cache[T] We would almost always have a matching smart constructor like def getItem[T](key: String)(implicit ev: ByteStringDeserializer[T]): Free[Cache, T] = Free.liftF(GetItem(key, ev)) which constructs the `Cache` and lifts it into `Free`. 
It works because in both cases, the values are still wrapped in a Future. In the first one individually, in the second case the list itself might not have been realised, I.E the list is there, but its computations might be there or not. So for this purpose List[Future] or Future[List] is the same.
What about turning your interpreter object into a class with the expected ByteStringDeserializer passed as a parameter (implicitly or not) ?
Exactly 
That's not quite true. The `Future[List]` will fail if any of the futures that are passed into the sequence fail. With `List[Future]` you may have some that succeed and some that fail. OP wants to execute callbacks for each future separately, so converting to a `List[Future]` only works in the case that all of the futures succeed.
True. I wonder if they all should be in the same list in that case. There’s a few operations that you can’t do on it , because they’ll result in failure for everything. 
Literally 30 seconds of Googling: https://stackoverflow.com/questions/5050682/get-scala-variable-name-at-runtime
I think the more sound type system in Dotty will benefit everyone in terms on better type inference and less type level bugs. TASTY will lead to better library compatibility and possibly whole program optimization. But it will not be a huge step for mankind.
&gt; Kotlin has great tooling, Scala has not. Really? For example, I don't really see a huge difference in features between the IntelliJ plugins for Kotlin and Scala. Yes, the Scala plugin has some problems with implicits and macros, but these are features Kotlin doesn't even have. &gt; Kotlin supports Android development, Scala doesn't. You can certainly develop Android applications in Scala. &gt; Scala has some features they have never even heard about, and the website doesn't make it clear why they should care. I really don't see how having more (well-designed) features is a downside. Developers can learn to use more advanced features like implicits, higher kinded types etc. after spending some time with the language.
Yes, I was thinking mostly about choosing C or C++, which I today consider almost always to be the worst alternative (and I'm a very experienced C++ programmer). But there are also huge benefits in choosing a language with a powerful, functional type system (like Scala, Haskell, Purescript, Reason/OCaml) over a more impure, imperative language (like Java, C++, C#, Go, Javascript). Languages like Kotlin and Rust would be placed somewhere in the middle (they are more one trick ponys at the moment).
How long does your test suite run? And on which external services does your test suite depend?
Hi all I am new in scala world and try to use http4s to create a service. I wrote a service and want to write a test for it. Would be `ScalaCheck` the right choice? THanks 
At present it runs for a bit less than 4 minutes. I can see a dependency on scalatest, scalacheck, and sbt-coverage. Not sure what else test depends on.
&gt; compell current Scala users to make the switch to Dotty? Should have added, "instead of switching to another language". Basically, if the primary pain points haven't been addressed, then the appeal of Dotty (and it is appealing wrt to language design and features) loses some of its strength. OCaml/Reason ML/Bucklescript, for example, will look quite interesting when modular implicits land (presumably by the time Dotty arrives circa 2020). And while the language holds no appeal for me personally, Kotlin has fast builds and far better tooling support. Having worked with Scala for 6 years now the major issues haven't improved significantly over time: sbt is still horrendously slow and obtuse; builds are still slow, even incremental builds are extremely laggy compared to other languages. It's just an ongoing hassle, this despite the obvious power of Scala the language that keeps most of us in the fold.
&gt; presumably by the time Dotty arrives circa 2020 Hopefully Dotty will be ready much, much faster than that.
Apart from what phazer99 said, you can have a look at http://dotty.epfl.ch/docs/ for a more complete picture of what's changed so far. Tooling is also something we're taking seriously but haven't talked much about until now, for example Dotty IDE support is based on the [Language Server Protocol](https://github.com/Microsoft/language-server-protocol) which means it's not tied to a specific IDE. For now we're focusing on Visual Studio Code since it's the reference implementation for the LSP, but it should be really easy to get everything working just as well in various editors (see http://langserver.org/). Since many Scala developers are familiar with IntelliJ, I've been working with a student this semester to bring the LSP to IntelliJ: https://github.com/gtache/intellij-lsp. This means getting real compiler diagnostics in IntelliJ and no more false errors because scalac and the IntelliJ scala plugin typechecker disagree on something.
Modular implicits will provide similar functionality as type classes and implicit parameters, right? That was the main thing I found really missing in current Reason ML which otherwise looks nice. Another option I've considered is Purescript which is a great language with nice libraries, but the editor support is really lacking compared to Scala (basically it's a buggy and featureless Atom or VS Code plugin). So, at the moment I would still choose Scala.js and IntelliJ for client side development.
I think LSP combined with IDE-mode in the Scala compiler is a good choice, provided it can reach similar functionality as the IntelliJ plugin (in terms of refactoring, suggestions, debugging etc.). Anyway, it seems to be the default solution to get basic IDE support for new languages today. VS Code certainly feels much more lightweight and configurable/modular than IntelliJ (let's not even talk about Eclipse :) ). And it has good support for JavaScript debugging which benefits Scala.js. Do you support JVM debugging in VS Code with the Dotty IDE?
testQuick only works with triggered execution (`~testQuick`), it doesn't work across sbt invocations.
&gt; Do you support JVM debugging in VS Code with the Dotty IDE? The LSP does not specify a debugging interface, VSCode uses a separate protocol for this and a Java implementation was released recently: https://github.com/Microsoft/java-debug. I've managed to quickly prototype a Dotty Debug Server on top of that: https://files.gitter.im/lampepfl/dotty/8NRb/Screenshot_20171013_194920.png. Evaluating Scala expressions in the debugger will be more challenging but I have some ideas on how to achieve that.
That I know. I'm looking into replacing calls for "./sbt test" with "./sbt testQuick".
I think testQuick relies on zinc (incremental compiler) cache to work. You can maybe use https://github.com/romanowski/hoarder to cache zinc generated files and then run testQuick. 
I'll give it a go. Thanks!
&gt; [tooling] The tooling situation has certainly improved, but the increase of project complexity has completely outstripped any tooling improvements. As an example, I have a project where none of the three IDE systems work (IntelliJ, Eclipse, Ensime). IntelliJ's tooling is in fact so bad, that a substantial amount of developers just deactivate its type checking and use IDEA as a glorified editor. &gt; You can certainly develop Android applications in Scala. Sure, but then you are completely on your own. Scala has never supported Android, and in addition to that 2.12 dropped support for Java bytecode &lt; Java 8, so you are stuck on an old compiler targeting an unsupported platform. &gt; I really don't see how having more (well-designed) features is a downside. Developers can learn to use more advanced features like implicits, higher kinded types etc. after spending some time with the language. The point is that most developers will never do that, because they will (rightfully) pick Kotlin instead, given the information the respective home pages give them.
why do you think that 4 minutes is slow?
I tested it and yes, same problem with `compose`. Looks like a bug. I think the second level of `andThen` / `compose` nests the `HList` so you end up with `(SomeType :: HNil) :: HNil`, which doesn't match the value you want to give it.
My understanding is it only executes the tests that failed on the previous run.
I've done that. the post is the opposite: get a name as a string from a variable.
[removed]
Since you guys are already on 0.5 with 6 week rolling releases, 1.0 will certainly land far sooner than that; the question is, how long will it take for the ecosystem to migrate to Dotty? I suspect much longer than the sbt 0.13 to 1.0 migration. Maybe scalafix will make most migrations relatively painless, we'll see. I'd be happy with a 1.0 in 2018 if Dotty team can swing it ;-)
&gt; Modular implicits will provide similar functionality as type classes and implicit parameters, right? Yes, implicits without implicit conversions. &gt; at the moment I will probably still stick with Scala.js Sure, Scala.js is awesome, but Bucklescript does complete builds of entire projects in 200ms, which is of course insane. Tradeoffs on either side, but if Dotty doesn't deliver significant improvements I could see jumping ship to OCaml.
It sounds to me like you're trying to dynamically create variables. If so, there's definitely a better way avoiding that or you want to use a dynamic language like Python as you mentioned yourself. Why would you want to do that anyway? What's a use case?
This looks really cool and addresses a need I've been worrying about lately. As a side note, I can't believe how frustrating the dependency injection is with Play. This is like the fourth time I've come across something useful but can only be used with Guice. I'd love to be using macwire because even though it's using macros it is still way less "magical" than Guice...but every time I try, I run into a million problems like this. 
Fair enough! Thanks for your thoughts. I tend to think of case classes as sugar for "standard" classes, letting the compiler generate the boilerplate for me so I can get the syntax/semantics I want elsewhere. So to my mind case classes don't have any special semantics of their own and using multiple parameter lists this way is a fairly natural way to get the semantics I want where everything in the first parameter list is what makes two instances equal while everything in other lists is "auxiliary" in some sense, and only necessary for the class' behavior.
You might consider [scala.Dynamic](http://www.scala-lang.org/api/current/scala/Dynamic.html), but of course, you give up type-safety.
I'm glad you liked it, the base for this project is to be able to build request scoped objects (objects that are created on each request), its been difficult to me to get this working on filters (see discussion: https://groups.google.com/forum/#!topic/play-framework/avyOWGCXE4o). Also, seems compile time DI could not be painful, Greg got request scoped objects working using it (see https://github.com/gmethvin/play-scala-compile-di-example/blob/requestscope/app/MyApplicationLoader.scala). I would love to get request scoped objects working on filters and then, create the compile time plugin, lately I've been quite busy to give it another try. P.S: You might also want to take a look to OpenTracing. 
Why?
I don't think there really is a "right" choice. Try Scala Check and see if you like it.
Folks have been asking to make CI faster, and currently ./sbt test takes the majority of the CI's time.
Can't say I'm up to the task, so have an upvote in the hopes you get good candidates from here.
Looks like a great opportunity. Good luck!
I really don't understand the question. Can you explain what you're trying to do in more detail?
say, I have a variable called foo, I want to call foo.func. But foo is not known (for some reason) at run-time, I only know a string valname="foo". I want to derive the reference to foo from this string.
this works for the specific case, but doesn't work on the general case op described
well I would think that 4 minutes is fast enough. hm, normally sbt would only consume the most time if your build is really really big and you barley have tests or your tests are super fast, but the compilation of your project takes long enough, but that's mostly on cold builds. 