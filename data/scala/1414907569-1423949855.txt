ScalaKata is getting sponsor by Typesafe. I'm investing my time in this project instead. The new evaluation engine is more reliable. What are you missing from Codebrew ?
I find it hard to take the opinion of someone seriously when they say that "scalaz is a library for programmers who wish the were using Haskell" while simultaneously stating they're actively trying to not learn category theory. Also the whole there's no idiomatic Scala argument is hand wavy. I've never seen anyone whose made this argument actually articulate what those numerous patterns are, and if that's really more than other languages. For example in Java, in order to create in instance of an object you could use any number of patterns like: - The Factory Pattern - The Builder Pattern - The Object Pool Pattern - The Singleton Pattern - The Prototype Pattern The idea that in any general purpose programming language there's one way, or even only one idiomatic way to solve a problem is false.
&gt; ScalaZ takes advantage of the OO aspects of Scala and in some ways it combines the best of Haskell with the best of OO That doesn't match what I've learned from Scalaz devs and users. Seems like an accommodating sentiment designed to ward off arguments. Pretty much anything OO built into Scala that has leaked into the design of Scalaz that I can think of has been a tragic problem. Cf. Variance What has worked best in Scalaz is what it has most faithfully emulated from Haskell. (Not comment about Scala in general!) There *is* a paper which frames initial and final encodings by Wadler. It could be argued that 1980s/1990s OO was better at final encodings at the time than FP (which was better than initial), but languages like Haskell excel at both now. (polymorphism, Typeclasses, tagless final, etc.) &gt;"scalaz is a library for programmers who wish the were using Haskell" That only applies to some Scala programmers I know, but I will say that the Scala programmers I know who are *happy* with Scala are much less likely to use Scalaz. A reasonable rigorous survey measuring this could be fun. &gt;while simultaneously stating they're actively trying to not learn category theory. Some people (not necessarily t'author) have a weird relationship with their identity as a programmer such that if it gets tainted with any math or rigor they suddenly become ivory tower and are incapable of getting "real work" done.
She's awesome.
I have tried using slick in a large scale project. With all its bugs, inconsistencies and missing featurea it was a nightmare. We turned to scalikejdbc, which is a breeze in comparison, partially due to simplicity of the lib. It offers the power of raw SQL, strongly typed. Seems like Slick shares the attitude of Typesafe towards Scala, but as a side project all the problems are greatly amplified. It is borderline unusable, seems almost abandoned(?!). Major issues and inconsistencies should be fixed before a flashy new version (even more buggy) is released...
&gt; Some people (not necessarily t'author) have a weird relationship with their identity as a programmer such that if it gets tainted with any math or rigor they suddenly become ivory tower and are incapable of getting "real work" done. Well the opposite is true as well. I am looking into OSS projects that I either star or that people I follow star on GitHub. Out of curiosity last week I just went into some Haskell libraries of well-known guy ekmett. Call me ignorant, but if that is not some fine celebration of circle-jerk, I don't know what. Second, mathematics is not just category theory. People should be reminded of that. All the fine research into data structures is a lot about maths as well. So is machine learning. So is geometry and computational geometry. To name a few.
&gt; I think if you see each of her statements in context, it is very balanced. Balanced in some non-existent debate of pros and cons of scalaz. &gt; She says she is not trying to tell people to learn category when teaching functional programming, because she doesn't want to constrain the audience to mathematicians. Only mathematicians learn category theory, and the subject isn't a 400/500 level computer science course most people could have learned in undergrad. Automata theory, Set theory, and abstract algebra are also only for Mathematicians as well, because Computer Science isn't a subset a Mathematics. &gt; Re idiomatic styles. Again, she makes the Perl joke, then says Scala suffers from this much less. That makes the argument even more hand wavy, not less.
I think you are mixing up the interviewer and the interviewee here.
Everything that keep your code and SQL code well separated, es. MyBatis (which have Scala binding, google 'scale mybatis').
I don't really see how MyBatis is different from Anorm. You write SQL and hand-code functions to map rows to Scala objects.
&gt; Anorm Mybatis can works as ORM if you need it: define your Mapper and it will convert back and forth object and SQL; if you don't need objects it will work with simple map.
Squeryl. I really like that it builds an AST for my query and only builds the SQL out of that AST. I've wrote several extension methods that operate on it. That allows my DB-related unit tests to be executed on HSQL, while the DB in production is Postgres, and still be certain the test is working. For example, HSQL has no support of JSON data type and queries, which we use in Postgres - but I do not care, since (slow and inefficient) implementation over varchars works for the unit testing purposes. I do not care much for Scala-ishness if the code, as long as it is functional. Have not come across any limitations as far as the support for relations goes.
My opinion is that in any language, any code that deals with RDBMS is bound to be not-so-great in the best case scenario. With this premise, I believe that slick is not such a bad library: * It doesn't try to hide the fact that you are dealing with databases and in fact, when you join, you get a result-set as if it was coming from the database. * It maps your case classes to database tables without the horrors of lazy-proxies and auto-magic queries * It supports any database-side convention for columns naming * It supports plain-SQL if you need to handle some very-complex use-case that the DSL can't express On the other hand it is not exempt from flaws: * Good luck with multiple left-joins - basically there are so many limitations that many times you're better off making multiple queries in different Futures and joining them manually * Good luck with MySQL - sometimes the kind of query that Slick generates can't be optimised by the crappy optimiser used by MySQL * Dependent types are the perfect path to madness: if you try to make your code run against multiple databases (e.g. MySQL in prod, H2 in test) you will discover how unpleasant dependent types can be All in all, if you can deal with these limitations slick is not bad at all.
What is your preferred way of accessing a database? You don't mention if you want everything typesafe and abstracted away or if you're more of a "close to the metal" person. It will be easier to give suggestions if you give a few examples of libraries that you've used and enjoyed (in other languages).
That's a complete non-answer. What features of the Entity Framework accomplish what you're trying to do. Also don't assume people have any idea what the entity framework is.
Does it support Scala case classes?
would you happen to know if it is possible to use the color mode in sbt console, and if yes, how to do that?
Does anybody know if scala-swing is deprecated? Looking at maven central http://mvnrepository.com/artifact/org.scala-lang/scala-swing the latest version 2.11.0-M7.
Most important is proper support for relations, lazy and eager loading and automatic parsing of results of join queries.
That's still not an answer. -What do you want to do? -How do other frameworks satisfy that need?
I haven't had the chance to use it in a real project yet, but [jOOQ](http://www.jooq.org) looks pretty nice.
I don't think that talking to a troll will help me in any way. People who used Linq2Sql, ActiveRecord or EF know what I'm talking about.
Posting as a top comment because it's a general recommendation but answers your question: &gt; I'd prefer something more abstracted that is simple to use for simple tasks. Something like Microsoft's Entity Framework. Check out [mapperdao](https://code.google.com/p/mapperdao/). I used it for a non-trivial project and it does the job pretty well. As with any ORM the closer you get to automagically providing the major of functionality the harder it gets to deviate from the ORM's limits but mapperdao does a good job for somewhat-more-than-simple cases. From my experience working with it: Pros * Type-safe abstraction and mapping plain domain classes (no dependencies) * relationships (one-to-many vice versa, many-to-many, class hierarchies) * DSL is sql-like &amp; includes joins * low-level queries * transactions with good configuration * cross-db support and external entities (did not use in my project) * lazy loading * keys are highly configurable Cons * **entities are wrapped in magic objects** -- you don't get plain domain objects back, they get wrapped so you can update them like active records. Not a problem unless you rely on a library that does some automation with typeOf in which case everything is f'd. (nightmare with json4s) * updating has to be done with aforementioned magic objects * tons of configuration is great but anything outside what is offered requires modifying library code -- no room for extensions To be honest it's a well maintained, very clean library that is opinionated but does what it sets out to do very well. As long as your architecture doesn't require anything super complicated and you do separation of concerns well it's a good fit.
I use the postgresql-async library with Postgres 9.3 and write my queries by hand. My models get an "apply" overload that builds an object from a result row so mapping query results is easy. After using ORMs for years I decided I liked this way better. It feels like more work up front, but now I can just write my data access layer correctly and not have to worry about figuring out *how* the abstraction works because there's always something that doesn't work the way I want it to. I also don't like the idea of my schema being automagically generated nor of being uncertain what is happening when I need to make schema changes. For me that is something I like to rigidly control.
I use Tiramisu, which is basically Anorm plus a few extra features. Basically it's a simple wrapper that lets you combine query and parameters into a single object: val query = "SELECT * FROM articles WHERE status = ? AND a.user_id = ".sqlP(status) val extraClause = user match { UserById(id) =&gt; " ? ".sqlP(id) UserByName(name) =&gt; "(SELECT id FROM users WHERE name=?)".sqlP(name) } val finalQuery = query + extraClause It was born out of frustration with Anorm - keeping a list of parameters straight is annoying. https://github.com/stucchio/Tiramisu 
Slick in my opinion is only choice. If you seriously want control your DAO layer and avoid ORM ineffective relations in scalable enviroment, slick gives you a lot of space and tools to do that. Remember, premature optimization is root of all evil (ORM lazy loading and caching )
Yeah. Can only see it happening if I get very bored and need to look like I'm doing something :)
No, the group-id changed: http://search.maven.org/#search|ga|1|a%3A%22scala-swing_2.11%22
Put this in ~/.sbt/0.13/something.sbt: initialize ~= (_ =&gt; if (ConsoleLogger.formatEnabled) sys.props("scala.color") = "true" ) 
How much time will take you to upgrade it to Scala 2.11.4?
I use Hibernate. It's not at all idiomatic or exciting but it works. 
&gt; maps, arrays, strings, numerics, booleans, etc. That's the problem right there. In Scala useful types are preferred. Map[String,Any] doesn't make for useful structure. Even lifting that Any to some GADT like JsonNode isn't very useful because you can't generalize methods in a way thats type checked and safe.
My goto is https://github.com/json4s/json4s It can parse json in case classes, making it type safe. And you can generate that here: http://json2caseclass.cleverapps.io/ which is pretty convenient. It also parses fields, and can pretty easily serialize into json as well
A `Map[String, Any]` really only makes sense in a dynamically typed language. Heterogeneous dictionaries are common in those languages, but they kind of undo the purpose of a statically typed system. So deserialization can become frustrating in statically typed languages, because it emphasizes a boundary where a structure becomes typed, whereas in a dyn. language that typing occurs at the very last moment when you use a value.
&gt;A Map[String,Any] is a common and useful data structure for modeling a lot of data You *can*, but it's not preferable. Think of it this way, by adding a little bit of typing, (which already exists in your head), you're getting unit tests for free. Any isn't a useful data structure, so you'll want to cast it eventually, and if you can cast it to two or three different types, there's a lot better ways to support that (pattern matching on an ADT). If you want more help or don't see the usefulness, give me an example of when you'd want a Map[String,Any] *and* how you'd use it. 
My current favorite idiomatic Scala json parser is rapture.io: https://github.com/propensive/rapture-io
I've expressed this in a few other comments, but it really required some thought on my part about how to accept the features that scala is expressing as a language and not to fight it. In Ruby/Clojure/Python, I will often work on a heterogeneous map because it makes sense. The basic types supported by JSON map to basic types supported by those languages, and there is no need to incur the overhead of wrapping it with an additional type. As a nominal example, a JSON response from a web service returning a person record would commonly return what would be a Scala Map[String,Any]. {"name": "So and So", "age": 25, ...}. In dynamically typed languages, there may be no reason to create a type for this, where in Scala it seems that the idiomatic solution is to use a product type.
JSON parsing is such a common operation that I use it when digging into a new language to help me understand how to idiomatically perform common tasks. In this case, I think I've just been fighting Scala's type system instead of embracing it while learning the language. I will check out Kryo just because I find serialization formats interesting though!
I will check it out. Thanks for the recommendation and your insights.
Even in cases where you don't want to map to a product type with a specific domain(like `Person(name: String, age: Int)`) using a more strongly typed product like tuples(`(String, Int)`) or HList(`String :: Int :: HNil`) is still preferred to Any, and not much more overhead.
The problem with json parsing in scala (or any statically typed language) is that you often wind up doing double duty when marshaling to/from json/scala types. Why? Well, a common pattern is to query a relational datastore whose schema has been mapped to scala types, which means your queries return scala types based result sets. Now, you do some filtering, sorting, etc. on the query result\* and then send it off to the client. Wait, no, you don't do that, you first need to marshal the scala types query result to json, which, for complex cases (i.e. real world), requires you to do double duty on a task that is extremely straightforward and boilerplate free in dynamic languages. Personally I just use json where unavoidable (e.g. client-side library requires it), or where the use case is straightforward/has minimal boilerplate, and do the bulk of the work server-side, leaving client-side to handle ajax, initial form validation, and UI transitions/effects. Could see this being less of an issue when server-side is just a router handling requests that ship json results directly to client (e.g. NoSQL datastore or something like Postgres' json interface). Not yet a believer in going all-in on the client, however, types are useful ;-) \* since you can't do any meaningful/powerful operations on json
Anorm is being phased out from Play (created by authors of the same), not exactly a vote of confidence in its favor. Squeryl *does* [support scala 2.11](https://groups.google.com/forum/#!topic/squeryl/SIqrPPiHRm4), and has *excellent* relations support. Sure, it has more reflection based magic than say, Slick, but overall is a very solid query DSL in scala land. Slick absolutely has support for relations, might not be as closely aligned with sql semantics as Squeryl, M$ Linq offerings, etc., but does the job, and has been improving with every release (async support on the way, for example). If you're looking for a more straightforward type safe query dsl without having the oh-no-scala-I-don't-get-it-everything-sucks reaction, maybe look at JOOQ.
This is perfect. I was trying to find a library that could serialize/deserialize a case class with one line but after looking at Play's JSON and something else I gave up hope.
Despite pitched as a serialization library, https://github.com/lihaoyi/upickle has worked tremendously well for my uses. It generates its typesafe converters on the fly so there is no prologue. It is using https://github.com/non/jawn internally so performance should be on par with jackson or better.
In Play Json all you have to do is declare an implicit in your companion object: case class User(name, email) object User { implicit val userFormat = Json.Format[User] } This adds the User type to the list of supported types (all base types are there already) so for example you can do val userFromNick: Map[String, User] = someJson.as[Map[String, User]] ...and that works, I don't think it's super complicated. Why do you have to declare a userFormat? Because if we don't do that, we have to do introspection and this is prone to runtime errors. The Play Json helper works with macros, so if something goes wrong (includes a class that can't be serialized, cycle, etc.) you know it at compile time. Also I believe it much saner to force the developer to think 3 seconds if he needs direct conversion from the case class or a custom serializer. Because, you know, realizing in prod that introspection of your "blog post" class serialized the author (user) with his password and expose it to the REST API is not great. ** That said, sometimes you don't want to bother with case class and just need to retrieve info from your Json. That's closer to the "Ruby&amp;Python" approach. In this case, you can just use JsValue as is, it's pretty straightforward: val authorEmail: Option[String] = (json \ "author" \ "email).asOpt[String] or if you're sure it's there: val authorEmail: String = (json \ "author" \ "email).as[String] ** So in short the reason why there is more to the Json library than Python or Ruby, is because there is a very powerful type system. You can choose to ignore it and manipulate JsObject directly, but using serializer you get a very powerful validation. Instead of having to do null check everywhere (Python or Ruby), declaring the serializer (the read actually) allow you to describe how you want the json to be formatted in order to be deserialized. Then either you get an Option, or a very clear error message about what field is missing and where in your json. 
Support for 2.11 isn't advertised on Squeryl site so I didn't know about it. It doesn't support eager loading of relations and no matter what I've tried it fails to use a `case class Post(title: String, author:Option[User])`. Slick doesn't seem to support these kinds of classes very well. Async would be pretty awesome but as far as I understand it means ditching JDBC because a proper non-blocking driver should use the same file-descriptor array as the HTTP server.
While manipulating Map[String, Any] doesn't make much sense, you can perfectly stick with the AST class corresponding to a Json element. In Play Json that would be JsValue: https://www.playframework.com/documentation/2.3.x/api/scala/index.html#play.api.libs.json.JsValue You can treat it as a Json object: json \ "attribute" As a Json array: json(2) ...And where you're at the object you need, you can convert it to the type you need: json.as[Int] In short you can get a leaf this way: (json(0) \ "foo" \ "bar").as[Int] If you're not sure it's there you can just use asOpt at the end, and it will work even if it fails at the first call because a JsUndefined will be propagated to the end. In a dynamic language you would have to test for null at each step. Also, beyond the "philosophical" problem in manipulating Map[String, Any], you'll have to do cast everywhere and that much less elegant that the helpers above. 
Beat me to it: https://github.com/propensive/rapture-json
&gt;At this moment there are at least 6 json libraries for scala, not counting the java json libraries. All these libraries have a very similar AST. This project aims to provide a single AST to be used by other scala json libraries. Congratulations! Now there are at least 7 json libraries for Scala. http://xkcd.com/927/ (Sorry for being cynical.)
One note ... Kryo works great, but it's not designed for backwards compatibility (schema changes etc.) and isn't suitable for storage/archiving. It's great for across the wire serialization (network protocols, temporary caching on disk), but runs in to problems once you expect to keep the serialized information around. Unless you hand code your own serializers it won't handle missing/added fields. 
...and that information was good for about a day. Now (if you use my runner, and I think if you use the other one) the location for that file is ~/.sbt/0.13.6/plugins.
I personally really like `liftweb-json`, because it can parse everything, from nested case classes with optional fields to recursive structures (trees). If you want to use json with Proguard (on android), I'd go for `Argonaut`, as it works without reflection.
And working with JsValue directly is not close enough to dynamic languages?
Actually, I arrived at your answer after thinking about the problem myself. I think the way you put it is actually a really approachable answer. Thanks for acknowledging that this process seems overly cumbersome in Scala, but there are foundational reasons for why that is.
Well, lift's JSON does that, it parses case classes on the fly. https://github.com/lift/framework/tree/master/core/json &gt; myJson.extractOpt[MyCaseClass] &gt; myJson.extract[MyCaseClass] // throws exception if can't parse The parser supports Option-al fields, too.
After trying out a few, I usually go for the Play JSON library. It can handle the basic types "automatically", you just need to declare implicits, etc. You can import Play JSON into an sbt project without importing all of Play. If you're using Spray IO, for example, there is an import that provides Play JSON interop for creating your HTTP responses, so you can write your api-serving server in Spray and use Play's JSON library.
Just because it hasn't been mentioned yet, I thought I'd throw in [Son of JSON](http://nxt.flotsam.nl/son-of-json-ii) (source on [github](https://github.com/wspringer/sonofjson)) which is a new, small library that seems to be designed for ease of use.
You'll still have to do that for things with more than 22 fields, since that's the limit of scala's case classes, but that's not the end of the world.
Don't miss the linked talk it is really interesting. An alternative scala implementation is also presented here: http://notes.langdale.com.au/Transducers.html 
Not that it's the only, but certainly worth to take a special place, Akka is quite an advantage.
The type system. Node.js is unityped and golang lacks abstraction (no generics).
&gt; Because if we don't do that, we have to do introspection and this is prone to runtime errors. I have used Lift-JSON quite some time, and almost never seen any such runtime error. This seems like a very theoretical problem to me.
You should look at [Play](https://playframework.com) and [Akka](http://akka.io). Also, you need to define "real time" very carefully -- it means [something very specific](https://en.wikipedia.org/wiki/Real-time_computing), and no web framework alone meets that criteria.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Real-time computing**](https://en.wikipedia.org/wiki/Real-time%20computing): [](#sfw) --- &gt;In [computer science](https://en.wikipedia.org/wiki/Computer_science), __real-time computing__ (__RTC__), or __reactive computing__, is the study of [hardware](https://en.wikipedia.org/wiki/Computer_hardware) and [software](https://en.wikipedia.org/wiki/Computer_software) systems that are subject to a "real-time constraint", for example operational deadlines from event to system response. Real-time programs must guarantee response within strict time constraints, often referred to as "deadlines". Real-time responses are often understood to be in the order of milliseconds, and sometimes microseconds. Conversely, a system without real-time facilities, cannot *guarantee* a response within any timeframe (regardless of *actual* or *expected* response times). &gt; --- ^Interesting: [^Strategy ^video ^game](https://en.wikipedia.org/wiki/Strategy_video_game) ^| [^Real-time ^tactics](https://en.wikipedia.org/wiki/Real-time_tactics) ^| [^Real-Time ^Multiprogramming ^Operating ^System](https://en.wikipedia.org/wiki/Real-Time_Multiprogramming_Operating_System) ^| [^Real-time ^computer ^graphics](https://en.wikipedia.org/wiki/Real-time_computer_graphics) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cltrcud) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cltrcud)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I'll assume that you meant javascript instead of Node.JS, because the other two you mentioned were languages and not frameworks. I don't know much about GoLang, but I heard a guy say once that it was similar to scala, but with C syntax... But take that with a grain of salt. I doubt they're that similar. As for advantages over node: * [Correctness](http://www.reddit.com/r/scala/comments/2jacyc/scala_the_case_for_correctness/) * Concurrency (not async... I mean multiple threads) * Conciseness * Type system (means finding most of your problems before you have problems) * The Java ecosystem can be a single .war/.jar file, rather than having to go through making a docker or deploying all your code followed by bower/npm install * Pattern matching * Pretty syntax for anonymous functions * Play framework, if you want to hit the ground running with MVC * Spray, if you want a build-your-own style framework * Allows the creation of ASTs which make using libraries much more expressive * Speed. It's atleast one order of magnitude faster than javascript 
This might be a minor thing, but generally I think Option.fold is a prettier solution than map().getOrElse().
The actor model by definition has unbounded indeterminacy. It's the exact opposite of a real time system.
You could probably use extractors a bit more, not sure if you think something like this would be "prettier": def insertPhone(phone: Phone) { val (refresh, ref) = phoneCache(phone.ipAddress) match { case Some(lastRef @ Phone(_, Some(lastMac), _, _, _)) =&gt; phone match { case Phone(_, Some(mac), _, _, _) =&gt; (!mac.equals(lastMac), phone) case _ =&gt; (false, lastRef) } case _ =&gt; (true, phone) } if(refresh) broadcastPhones phoneCache(phone.ipAddress) = ref } EDIT: Also, im not sure you need to use a mutable map, the immutable versions share their underlying structure with their updated copies and I wouldn't imagine this map updates that often. def insertPhone(phone: Phone): Map[String, Phone] { val (refresh, ref) = phoneCache(phone.ipAddress) match { case Some(lastRef @ Phone(_, Some(lastMac), _, _, _)) =&gt; phone match { case Phone(_, Some(mac), _, _, _) =&gt; (!mac.equals(lastMac), phone) case _ =&gt; (false, lastRef) } case _ =&gt; (true, phone) } if(refresh) broadcastPhones phoneCache.adjust(phone.ipAddress, ref) }
What do you mean by "often" it doesn't update every second, but it updates several times throughout the day. Sometimes several hundred. Whenever we receive orders, we plug phones in to the provisioning station, then this thing does it's work, then they're unplugged. The phoneCache is just a representation of what is currently plugged in.
Unless I'm missing something, you're making this a little more complex than it needs to be: def insertPhone(phone: Phone) { val currentMac = phoneCache.get(phone.ipAddress) flatMap {_.macAddress} phoneCache(phone.ipAddress) = phone.copy(macAddress = phone.macAddress orElse currentMac) if(phoneCache(phone.ipAddress).macAddress != currentMac) broadcastPhones() } 
The only issue with that, is that if the mac address from phone is None, that means that the version, provisioned and phoneType will be overwritten. There are times that the phone will not give a proper response, and so all I'll know is that the phone is *there* but I won't receive data like the mac address, or it's provision status. In that case, I'd want to retain all of the old data that's in the cache and ignore the insertion. BUT if there was nothing in the phone cache anyway, then go ahead and insert it, because that means that nothing was there before. Now we can alert the client that a new phone has connected, we just don't know any details on the device yet.
It would be fine using the immutable version. As a test you can create a map of junk using a range: object ScalaProject extends App { val start = System.currentTimeMillis var z = (1 to 400000).map(i =&gt; (i -&gt; i * 2)).toMap val mapCreated = System.currentTimeMillis for(i &lt;- 1 to 400000) { z = z.updated(i, -i) } val mapUpdated = System.currentTimeMillis println(mapCreated - start) println(mapUpdated - mapCreated) println(z(10101)) } In this example on my machine I could update all 400000 elements in the map, each time creating a new shallow immutable copy, in less time than it takes to create the original map (probably due to creating hash buckets). Here's the output I got: 350 254 -10101 But as you can see, it can do millions of updates per second to this simple map. It can do it because it doesn't copy the whole map, just the element that changes.
Javascript can be fun, but it's also diarrhea. It doesn't even let you know if you passed in too many or two few arguments to a function.
For Node.js it's simpler language, larger community and probably better designed libraries.
&gt; Concurrency (not async... I mean multiple threads) There are libraries that expose libuv's thread-pool to Node programs.
As a note, a lot of things have made learning this harder, first with the move to activator, the changes to the Scala library, and using Homebrew, which IDEA still seems to ask me for help finding Scala/SBT libs. Your tips and advice are appreciated.
Ask on the Play mailing list?
My apps work good w play 2.3.6 and Scala 2.11.2 and ij ultimate 14. Try the demo of ultimate? $200 well spent.
I'm using the community edition with the Scala/SBT plugin and it works great with my Play 2.3 app
Play totally takes time to understand. It is time well spent though IMHO, as it lets you make future apps really quick. First few play apps are a lot of work though...
Do you mean finatra, rather than Sinatra?
Doh! Meant [Scalatra](http://www.scalatra.org/)
Thanks :)
one thing to note..Play for Scala covers Play 2.2 ..things changed a bit with 2.3 and for example you no longer use the play command they introduced activator. As far as I know I don't there is book that is for 2.3. 
Thank you! I still want to learn Play, but I took a second look at Scalatra after your recommendation, and I must say that I like the look of the Sinatra-like DSL (which is a first exposure for me). It looks like a really good framework for building simple APIs. I'm more of a fan of lightweight and adding modular plugins, so maybe I'll have to pick up a copy of the Manning book on Scalatra. As a side note, I have noticed that people seem to have a love-fest with Play. That's great! I think Play is a cool framework, and I'm really interested in learning it. But it seems like people don't want to admit that the documentation is disproportionately light (how did the authors of the Manning "Play For Scala" book get the knowledge to write the book in the first place?!). It seems like every time I Google an issue I encounter with Play, or my IDE, or some combination thereof, there's virtually no information. Coming from the PHP world, it's unheard of to not find a litany of (at the very least) Stack Overflow Q&amp;As on virtually every issue I encounter. So it's taking some adjustment. Also, I might take the plunge on Ultimate; the trial was very nice, and I liked the extra features. I'm mostly sold. :)
Thanks, I'm still optimistic, but definitely leaning on the community for support and help.
There's hope for me yet!
Thanks, I prefer to know that it's just my experience and not everyone's, since that means I can probably adjust something on my end.
Please don't use json4s. It works and that's great, but as soon as it doesn't you're going to have a shit time trying to contribute to the source to fix an issue. You can't properly import from an ide, you can't run one test at a time, you can't attach a debugger. Tests are in their own module, not in the one where the thing they are testing is. All of the extraction logic takes place in one mammoth file 'Extraction.scala' and all serialisation in one other file. It's implemented as a series of If else statements and clunky pattern matches. The project is also poorly managed. Whats in the master branch is not the current release, and features are different for the same library version on a different scala version, and the documentation is terrible. I submitted a PR for a feature, and then noticed it was already in the 2.10 branch, but not in master. My pr was merged! Now the same version of the library has the same feature but a difffernt name based on your scala version! Maybe if we all stop using it the project will die and I can sleep knowing no innocent scalas are being injured. 
ScalikeJDBC and Anorm are both similar in goals. I like the ScalikeJDBC dsl just a little bit beter. 
If you want to use Activator you should be able to import the sbt projects into IntelliJ. (or for that matter, import any sbt project) 
Thanks!
Thanks!
How did you import your project? I just open build.sbt file and waited for dependencies to be resolved
I ended up figuring it out. It was in build properties, and it was specifying an SBT launcher that was 0,12,0, not ,4. I think idea was complaining, not necessarily the project itself...
The MVC part is quite easy to understand but for the plain old multiple-form application I'd rather use Rails which is more refined and has way more add-ons. Play is more useful for modern single page applications with server pushes but understanding how to properly use all the tools at your disposal (iteratees and actors) takes some time.
forwarded from http://www.cakesolutions.net/teamblogs/this-week-in-scala-03/11/2014
I would stick to: brew install scala brew install sbt Within IntelliJ set Scala home to: /usr/local/opt/scala/idea I believe typesafe-activator is meant to be a learning platform. You can still use it, but I would use the individual Scala packages with IntelliJ.
larger community? =&gt; javascript community != node community better designed libraries =&gt; According to who?
I disagree, first because you can determine quality through metrics, code quality and known issues (bugs) and second because Play is a way better MVC framework than Express 
Bugs and metrics like test coverage tell only a part of the story. If a library has bad API it's bad, no matter how good its code is. PS. Express is not an MVC framework.
Have you seen QueryDSL or jOOQ? 
Yes and didn't like either with scala. Neither fit well into functional coding in my opinion. 
Thanks, I don't think I set my Idea Scala home to usr/local/opt... I was going through Cellar. I guess that makes sense since brew probably updates the symlinks, eh?
You will get many numbers of free tutorial from the websites If you want a quality of that then purchase it from intellipaat like me. http://redd.it/2lny0i
What is the practical benefit to this kind of programming?
Platforms with a garbage collector are only suitable for soft real time apps. In this regard Scala is more suitable than both because the JVM has the best mainstream garbage collectors. I was lucky to have worked on a platform that was participating in real-time bidding for serving ads. We were receiving ~ 30,000 requests per second, served by 10 to 30 dynamically scaled c1.medium instances on AWS. The whole thing was built in Scala and it worked great. It wasn't always easy - we had to pay attention to memory usage patterns, we had to cut down on requests to external services, we had to profile the shit out of everything, but the JVM in combination with Scala made it possible to build a rock solid platform in a team of 3. Node.js is not even in this game. Go has the advantage that you can leverage stack allocation, but the JVM has better optimizations, better profilers, better libraries and better garbage collectors. 
&gt;Also, could I get some advice on the right way of using actors? http://akka.io/ &gt;it'd also be useful if you'd give me reasons why Akka is much better to use with Scala than with Jav Because everything is better to use with scala. Java syntax sucks.
Hmm, I'm more looking for pearls of wisdom for programming concurrent applications in Scala. Stuff that would be immediately obvious to an experienced Scala programmer. For example, as someone who only knows assembly, you might learn python and immediately write iteration over a list by iterating over an index, but in python you would use a foreach loop. Stuff analogous to that. Something like, never use threads in Scala, you can achieve anything concurrent that you want with actors. (I don't know if this is true, but it's the kind of stuff I'm looking for) Basically, anything that is fundamental and the accepted best practice for writing concurrent applications in Scala. Thanks!
What you're looking for doesn't exist. There is no always.
Well, of course there isn't an always. But there are statements which are true 99% of the time. Like, you would never do indexed iteration of a list in Python unless you require the index, or if you're not accessing all elements of the list. Basically, I'm looking for advice that you should follow unless you really know what you're doing and have a specific reason for going against that advice. Best practices for using actors, etc.
Maybe read up on erlang. Akka takes a lot of inspiration from it, so it might give you more material. 
You should read the original Carl Hewett paper on Actors. http://arxiv.org/abs/1008.1459
There is a lot of material out there that you can search for in regards to actors and other concurrency and distributed computing abstraction, such as [these slides](http://kachayev.github.io/talks/kharkivpy%230/#/27) which discusses concurrency and different concurrency abstractions in Erlang, Scala and Clojure. The actor model does not necessarily make all kinds of concurrency easier relative to other concurrency approaches, given that one of its primary goals is to support distributed computing. For instance, the actor model does not in general guarantee that messages arrively in a timely manner, or at all, due to its distributed nature, and applications using actors should be built according to this assumption. Conversely, concurrency abstractions like futures and promises are generally not assumed to be distributed but local, and they are assumed to always give a result (either some value or an exception in case of failure) if their task finishes (if timeouts are used, the task will always finish in some way). The drawback with futures and promises is that the are not very useful for distributed computing, since they are not based on events or messages and thus partly would have a lot of overhead in regards to distributed communication, and partly would have issues with resilience (persisting the whole program state is not in the general case a viable approach, while persisting the events or messages that lead to the current state tend to be both viable and efficient in the general case). Do note that it can be useful to combine different approaches. For instance, Akka has guides on how to use futures together with actors. As for programming languages, it is possible to implement actors in any general-purpose programming language, though certain languages such as Scala and Erlang tend to support it better than others. Erlang has actors built-in (and its virtual machine is designed with actors in mind, giving it some useful properties compared to other virtual machines like the JVM), while actors in Scala are implemented as user-level libraries and uses Scala's focus on generality and flexibility to ensure that the libraries are flexible and concise to use (compared to Java, pattern matching is one example of a feature that makes code more clear and concise when working with actors). Other useful features include the general focus on immutability in Scala (since it is important in the actor model to avoid any sharing of mutable state between actors).
In general, I think it helps exploit what properties can be expressed in the type system, and thus what can be expressed in a type safe way. It also supports dependent typing to some degree, as seen in languages like Idris and Coq. As a concrete example, I think it is useful for implementing abstractions like heterogeneous fixed-length lists, which are basically more flexible tuples. Some nice things about heterogeneous lists is that you only need to define them once overall to get support for all arities, while for the current implementation of tuples in Scala they have to be hard-coded for each arity. It also means that there isn't any maximum arity, which is different from the default tuples in Scala (the maximum arity is currently 22).
It should be noted that understanding this is not at all required for developing effectively in Scala - it is mostly if you are interested in this kind of thing and want to learn more about it. And being able to program at the type level is pretty cool :). That said, there are some really interesting stuff that you can do in it, and you may want to learn about some of them later on if you find that you could use that stuff. Miles Sabin has created the [Shapeless](https://github.com/milessabin/shapeless) project, which implements heterogeneous lists as well as other stuff. As for the default tuples in Scala, they are likely to be sufficient for 99.9% of cases where a tuple is needed. It comes up in regards to things like code generation and cases in ORMs where you have more than 22 database columns (see [this link](https://issues.scala-lang.org/browse/SI-7099)).
Thanks a lot, what you mentioned was really helpful!
Assuming ones would want use HLists (or HMaps) instead of class instances on a large scale (as i.e. in clojure much is modeled simply as plain maps). How would that influence performance and memory consumption?
anyone see the error? sealed abstract class HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] } final class HCons[H, T &lt;: HList](val head: H, val tail: T) extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] = f.apply[Head, T#Fold[U, F, Z]] (head, tail.fold[U, F, Z](f, z)) } object HNil extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z) = z sealed abstract class HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] } final class HCons[H, T &lt;: HList](val head: H, val tail: T) extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] = f.apply[Head, T#Fold[U, F, Z]] (head, tail.fold[U, F, Z](f, z)) } object HNil extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z) = z sealed abstract class HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] } final class HCons[H, T &lt;: HList](val head: H, val tail: T) extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] = f.apply[Head, T#Fold[U, F, Z]] (head, tail.fold[U, F, Z](f, z)) } object HNil extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z) = z sealed abstract class HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] } final class HCons[H, T &lt;: HList](val head: H, val tail: T) extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] = f.apply[Head, T#Fold[U, F, Z]] (head, tail.fold[U, F, Z](f, z)) } object HNil extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z) = z sealed abstract class HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] } final class HCons[H, T &lt;: HList](val head: H, val tail: T) extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] = f.apply[Head, T#Fold[U, F, Z]] (head, tail.fold[U, F, Z](f, z)) } object HNil extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z) = z sealed abstract class HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] } final class HCons[H, T &lt;: HList](val head: H, val tail: T) extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z): Fold[U, F, Z] = f.apply[Head, T#Fold[U, F, Z]] (head, tail.fold[U, F, Z](f, z)) } object HNil extends HList { def fold[U, F[_, _ &lt;: U] &lt;: U, Z &lt;: U] (f: TypedFunction2[Any, U, U, F], z: Z) = z 
4h drive :o. I think you should save it for December 10. I invited the guys behind [wolfe.ml](http://wolfe.ml). We average 30 persons.
I see this argued for as a major strength of scala constantly, but coming from python it strikes me as a weakness instead. I'm sure I'm doing it wrong, but I see type "safety" as a compiler limitation to be defeated -- an inability to handle flexible data. Care to help me understand its benefit?
This was fixed in 2.11: https://issues.scala-lang.org/browse/SI-7296 Case classes can now have &gt; 22 fields.
If it was a compiler limitation, Scala would be unityped. It is *much* easier to make a unityped language than a language with a more powerful type system.
This meetup was actually last night. Did any of you guys go? If so, what did you think?
 phone.macAddress.foreach{ addr =&gt; val needsBroadcast = phoneCache.get(phone.ipAddress).map(_.macAddress != addr).getOrElse(true) phoneCache(phone.ipAddress) = addr if(needBroadcast) broadcastPhones() }
By favorite editor, do you mean IntelliJ? import myopia
&gt; IDE support is better but still not 100% My experience with the eclipse plugin is that it has only been getting worse and worse. More phantom compiler errors, more problems with the formatter destroying my code, no improvement in any refactoring tools (none work), less clear error messages, code completion crapping its pants more often. I've been at this for about 4 years now. At the start with the eclipse plugin, I figured, ok, I understand, this is going to take time. 4 years later, and plugin is putting roadblocks in my way more and more often. I'm getting the distinct impression none of the developers of the plugin actually use it for themselves.
:) or [Scalakata](https://github.com/MasseGuillaume/ScalaKata)
By IDE support I meant IntelliJ. We will not talk about eclipse.
I wanted to share this book that I bought recently with the community. I've only had it a week and it has helped me tremendously in learning functional programming. I'd consider myself a novice in scala but it's starting to make me me feel like an expert. NOTE: this is NOT an affiliate link; it's just a plain link to amazon
I'm about halfway through this book. The first half alone is worth the price of admission. If you've struggled with understanding functional constructs or thinking about solving problems in a functional manner, this book will do trick. The way it does so is by being very exercise oriented. The book is only 300~ pages but takes a while to finish due to the focus on difficult yet well balanced/rewarding exercises. If you take your time and get through all of the exercises, you *will* have a solid grasp on the core functional concepts. The exercises are very carefully crafted in a way that they are just challenging enough to get you putting significant effort into solving them, yet not to the point of frustration. The author did a good job of avoiding the pitfalls that come with writing exercises from the point of view of someone that already deeply understands the concepts. Better yet, you don't need to know any Scala to read this book. Some C#/Java/etc. knowledge is good enough. I've picked up enough Scala through reading this to parse/write Scala somewhat effectively. I'm currently on the second half of the book, which covers the bigger picture of functional development. It has far fewer "A ha!" moments since the majority of the bite-sized functional concepts are covered in the first half. The second half is more about putting your knowledge to use by designing small "libraries". Towards the end of the book, more advanced topics like monads/monoids are covered. I wish all programming books were written this way. 
spam
&gt; I'm getting the distinct impression none of the developers of the plugin actually use it for themselves. Eclipse itself is fine. But the scala plugin? I repeat: &gt;I'm getting the distinct impression none of the developers of the plugin actually use it for themselves. 
hard to trust man who's written books about SOA governance and ESB's..
I literally just searched for and found this book today. My company has safari books and this happens to be on it. Started reading and isn't bad so far. 
Anyone have a feeling for how this compares to Odersky's *Programming in Scala*? I've been working my way through that book on and off, but it's a bit slow-going.
I bought it directly from Manning: http://www.manning.com/bjarnason/ They regularly have 50% off deals. Keep an eye on their Deal of the Day and you can likely get this within a month or two for 50% off easy. (of course that's only a bit cheaper than the amazon price, and if you've got prime, it doesn't even matter!)
Yep, awesome book :) It has very "hands on" approach (*lot* of excercises) and is quite light on theoretical side of things. It is bit elusive on FP terminology until the last part. On first two parts it keeps mentioning that recurring patterns seen in excercises might have some common abstractions. The last part names and discusses these abstractions (monoid, monad, etc). Personally I would have preferred to have bit more on theoretical side and perhaps short informative briefing about monids, monads, etc at the beginning of the book. It is also worth pointing out that the book is about learning FP and basic know-how to write functional libraries. After reading the book one should be well equiped to *reason* how to write real world applications using FP but it does not explicitly discuss about it.
This job offer sounds quite nice. Unfortunately for me, I am probably much too "enterprisey" for such a setting. Btw. how to you keep your employes up to date? Do you send them to trainings (tech or also soft skills)? To conferences? Self education? Training on the job?
Thanks for pointing that out. Although I own a Kindle, I only buy ebooks that are available in all three major formats.
I worked through much of this book during the middle revisions EAP (early access) period. The first half was really enlightening. The final book is several revisions ahead of where I last saw it, and based on the other positive feedback, it seems like they cleaned up a lot of the editorial issues. If you feel like you have a basic understanding of monads (mapping/flatmapping over lists, options, and maybe promises), this book is a good spot for extending that knowledge. It's also great for the basics on those topics.
HLists give you really nice transformations over tuple-like data sets. You can't concatenate or map over standard Scala tuples, for example. They also form the basis of interesting data types like Records (which are kind of like strongly-typed named tuples). They let you define functions that abstract over arity. They can greatly reduce boilerplate in a lot of situations. In fact, they were inspired by a paper called Scrap Your Boilerplate, which is highly worthwhile to check out.
&gt; Last time we posted we had a lot of interest and amazing candidates How do you track applicants that comes from Reddit? Anyway it looks quite nice! you will get my application shortly.
We are a small team, so we don't really have any sort of formal training structure. We do get conferences and other learning materials expensed though (we are actually in San Francisco for react conf right now). We also have a 10% learning time / experiments policy. 
Thanks :)
We use recruiterbox, which tell us where you came from. We also have the usual google analytics tracking we can use to stalk all our visitors :)
Is this a remote/telecommute job? Thanks
&gt;have lots of experience relocating people from different countries and will do so if you decide to join us. I guess no.
How about this: def updateMap(phoneCache: Map[String, Phone])(ip: String)(phone: Phone): Map[String, Phone] = { def updateNew(m: Map[String, Phone])(currentPhone: Phone)(newPhone: Phone): Map[String, Phone] = { val currentPhoneHasMacAddress = currentPhone.macAddress.isEmpty val newPhoneHasMacAddress = newPhone.macAddress.isEmpty if(currentPhoneHasMacAddress &amp;&amp; newPhoneHasMacAddress) m else if( !currentPhoneHasMacAddress || newPhoneHasMacAddress) m + (ip -&gt; phone) else m } phoneCache.get(ip) match { case Some(p) =&gt; updateNew(phoneCache)(p)(phone) case None =&gt; phoneCache + (ip -&gt; phone) } } But, what should the **else** behavior be?
what advantages does this have over mockito? I'm very fond of mockito's spy feature and pretty much require it for any mock implementation. Does this have something similar?
Sounds like a great opportunity to meet Zoe Deskennel! i'm dabbling with my own startup ideas at the moment, but maybe a few months down the line :)
We do have a workcation policy that allows you to telecommute for 3 weeks at a time, but we like to get to work with you for a few months before you do this, because this reduces a lot of miscommunications that come from working remotely. If you're a perfect fit, we can consider a completely remote job. 
They're actually really good complements to each other. Programming in Scala is about the *language*. I treat it more as a reference book. FPiS is barely about the language, other than higher kinded types and for comprehension, you're barely using the language to explore these functional concepts. There is almost no mention of the standard library, of inheritance, variance, implicit conversion, existentials, while loops, etc. This is a book about *how* to program, and the language they choose happens to be scala. 
Often the person who can do the task with the most ease volunteers. We try to make it a thing, so every other friday we get together and just churn through those types of tasks. 
Just going to quote from a previous answer :) &gt; We do have a workcation policy that allows you to telecommute for 3 weeks at a time, but we like to get to work with you for a few months before you do this, because this reduces a lot of miscommunications that come from working remotely. &gt; If you're a perfect fit, we can consider a completely remote job. 
Thanks for the application!
Anyone have any experience of using this over mockito? I have used mockito a lot in the past few years and has a lot of annoying warts. Null pointer exceptions happen *alot* if you mess something up and are hard to debug. I would love for this library to be a lot safer and informative than Mockito. 
You can try code farlaunch50 on manning for this book.
&gt; The interview process will be quite casual. We will ask you to solve &gt; real problems over a live coding session, no random theory puzzles. &gt; Of course, knowing how to apply data structures or advanced &gt; algorithms on a real world problem would be a nice bonus. Sounds nice. Good luck! ISTR you posted here some time back about a job, looks like you're trying to repeat that success! :-)
This an A-mazing book. I can't recommend it enough - in fact, this is the only book I've seen that explains FP concepts without offering you 'the sky and the moon'. :-) 
&gt; We do have a workcation policy that allows you to telecommute for 3 weeks at a time, but we like to get to work with you for a few months before you do this, because this reduces a lot of miscommunications that come from working remotely. &gt; &gt; That's fair, but unfortunate. I've been working remotely full-time on a Scala project for about a year and a half. If I lived near Vancouver, I'd probably apply.
~~Invalid link and an SSL error. Nope.~~ Edit: Link is working now. Thanks /u/lat3ralus_ !
"Voxxed is currently undergoing a bit of maintenance (ie. scaling scaling scaling) and will be offline for a few hours." https://twitter.com/voxxed/status/532958059669499905
Gotcha, thanks.
Ask again next year...!! I've been working as a Scala developer for a year and a half but at the same time I'm trying to finish the last few courses in my degree in Montreal. After that's done, we're already planning on moving to the western half of the country!
Someone in a chat room said this was out, and since I'm interested in learning Scala and coincidently functional programming too, I bought it from Waterstones. I haven't heard of it before now but since I've read everyones' reviews I'm quite excited!
&gt; I know it is possible to code using Mondas, Functors, Trampolines etc. s/Monda/Monad/ ;-)
Mondas are just mondoids in the category of enodfunctors...
Depending on what you mean by "real-time", none of your three choices may be correct.
I personally prefer using ScalaMock over mockito, because: - it has (IMO) better and more readable syntax - it's fully typesafe (unlike Mockito) - has better support for various scala features (e.g. repeated parameters; it allows function mocking) - ScalaMock has awesome error reporting: &gt; Unexpected call: &lt;clientMock&gt; TestTrait.oneParamMethod(3) &gt; &gt; Expected: &gt; inAnyOrder { &gt; &lt;dbMock&gt; UserDao.getUserById(123) twice (called once - UNSATISFIED) &gt; &lt;clientMock&gt; Client.doSomething(123, "foo") once (never called - UNSATISFIED) &gt; } &gt; &gt; Actual: &gt; &lt;dbMock&gt; UserDao.getUserById(123) &gt; &lt;clientMock&gt; Client.doSomething(123, "bar") I also don't like to repeat myself - so I prefer expectation-first style (http://scalamock.org/user-guide/mocking_style/) over record-then-verify (which is used by Mockito). ScalaMock supports both mocking styles, but in the first one I just write: &gt; (mock.getUserById _) expects (123) returning Player("Bob", age=32) And in mockito I would have to write: &gt; when(mock.get(123)).thenReturn(Player("Bob", age=32)) &gt; ... &gt; verify(mock).get(123) // &lt;- breaks DRY rule &gt; verifyNoMoreInteractions(List(mock)) // &lt;- cumbersome and easy to forget 
I think there is no object spying support in ScalaMock. Of course, you can forward calls to real implementation using `onCall` and mock/stub other calls but if you need real object spying, you should report a feature request at https://github.com/paulbutcher/ScalaMock/issues
What I am missing from the Scala collections framework: It should be easy to plug-in a NumPy or a CUDA/OpenCL backend and let it handle the operations. Something similar to Slick, where the API gathers the operations and sends them to the backend (in the case of Slick: the database backend) for processing.
Dotty's a long way off, if current 18 month release schedule holds it will be on the scene start of 2019 at the earliest O_o Curious to see if Paul Phillips' Policy gains traction in the interum; if he starts accepting pull requests things could get interesting. Not sure about the Typelevel fork. In 4 years time more than likely there will be Java 10 and JVM enhancements for future Scala to benefit from, but until then incremental improvements to the language is the name of the game...
https://encrypted.google.com/#q=sudoku+solver+scala ?
You are right. There is Breeze and it works quite well. What I wanted to say with my original comment: I would wish there was a more generic collection framework, that would include [Breeze](https://github.com/scalanlp/breeze), [Slick](http://slick.typesafe.com/) or even [RxScala](https://github.com/ReactiveX/RxScala) as special cases. It could consist of some generic interfaces, a plug-in infrastructure for optimizers or pre-processors and different back ends that should share a common structure. The interfaces should enable monadic reasoning, express hints for parallelism and an extensible infrastructure for high-level operations (e.g. grouping). The optimizer / pre-processor should do additional compile time checkings and high level optimizations, depending of the back ends, e.g. de-sugaring, dependency analysis, simplifications. The idea behind it is, that it should avoid excesses in type level programming. The backends would then kick in during runtime, make fast numeric calculations, execute database queries, or process asynchronous events. The big advantage for the framework users would be, that they could easily reason about "collection like" / "monadic" frameworks, because they would all share the same core. The advantage for the framework developers would be, that they could reuse the extensible collections framework. With that it would be hopefully much easier to add, for example a collection implementation that abstracts LDAP or that runs queries on a graph database. 
I have it. However, since I assume this is either for a school project or potentially for project euler. I'd recommend you still try to implement an algorithm. The way I did it, is actually very simple. You have a sudoku puzzle (implemented with your favorite data structure). All you have to do is: - find all numbers that can be inserted into the next empty field, this'll give you a new 'puzzle' for each potential candidate - repeat recursively on all new puzzles This should return a list of all possible solutions for the original puzzle. Puzzles that have no more candidates, will just return an empty list. Any clarifications, I'd be happy to help, but I'd recommend you try to figure it out on your own. It's a useful exercise.
I would prefer this as a third-party collection. I get little nervous when we pile on too much functionality into something.
I think of it similar to LINQ in .NET: Provide the building blocks with a simple implementation for in-memory collections. Add the rest as third party libraries.
Thanks for your useful reply :) Could you elaborate on the first bullet please? Or maybe give me some code snippets so I would have something to start building on? I tend to find it difficult to start off from scratch, but once I get things going it's okay. Thanks.
https://github.com/pathikrit/scalgos/blob/master/src/main/scala/com/github/pathikrit/scalgos/games/Sudoku.scala
Thanks, I will have a look at it :)
Lookup the `scala.collections` hierarchy. There are traits there for a bunch of semantics. Just extends `Iterable&lt;A&gt;` or `TraversableOnce&lt;A&gt;` or what not, implement a few methods, and you get all the maps and filters that you need.
It's the right thing to do for Scala. With no formalized core, it's really hard to achieve simplicity and reason about language extensions, especially with a rather advanced type system. I don't see how it should hinder development on the existing compiler and bundled libraries.
Hmm.. ok, let's see. I'm home now... :) Ok, let's say you have a sudoku puzzle Vector[Vector[Int]]. (puzzle(x)(y) would be the element) Each vector would then represent a row. Ok, so for example you would have something like 100500400 400300006 007041023 ... x 6 What you do now, is find the first 0. Then find ALL the possible candidates. The sudoku rules are pretty basic, numbers can't be repeated in the same row, square or column. So in our example, let's say the position 0,1. We see that we can squeeze in numbers (2,3,6,7,9) in the first row on that position, for the square it would be (2,3,5,6,9) and the column say (1 .. 9). Ok, now check for all items that appear in all 3 sets (2,3,6,9). Those items can then be inserted into your sudoku puzzle. Now... well, now you have 4 puzzles! And you just repeat this on all of them and then flatten the result, which will yield even MORE puzzles. However, those puzzles that won't have any more possibilities will end up being removed, as if you figure out that you don't have any candidates, you'll just return an empty list of puzzles. Some pseudocode def findSolution(p: Puzzle): List[Puzzle] = { if puzzle has no empty element: List(p) else: candidates = findCandidates for first empty val newPuzzles = for { c &lt;- candidate p &lt;- replace first empty element with candidate } yield findSolution(p) newPuzzles flatten //we need to make sure to return a list, and not a list[list[puzzle]] } So you need to implement replace, findcandidates, make it more Scala, and then you should have it. Could be a bit wrong here and there, but that's the basic idea. 
It is not flexible enough. They basically force you into a certain model, which works well if you want to do replicate the collection's eager (in the sense of "build a temporary collection after every step") computation model, but is completely useless for everything else. Neither database queries, reactive streams, "transducers" etc. can work with the API in `scala.collection`.
That is quite easy to explain: all three of them share the same basic concepts: filter, map, flatten, grouping, etc. All three can profit from the same basic optimizations: combining of subsequent filter/map operations, eliminating of intermediate object creation, etc. Slick and CPU processing share another common property: for advanced optimizations they both must create an intermediate abstract syntax tree for the operations they should perform. They then use that tree to create the code that will then perform that actions. It would be nice to have a common framework for this. LINQ already tries to solve that problem, so at least one could borrow some ideas from there. 
Thanks for all your help. I have some guidelines and some function definitions that I have to stick to. If you want I can pm you the guidelines just in case you want to have a look at them :) With your help I managed to understand the approach I will have to take. Thank you!
Is it published on a Maven repository yet?
Awesome presentation. Question about scala 2.12 and SAM support: Li mentions that with SAM one will no longer need to do something like, `val click = (e: Event) =&gt; ...`, saying that the `e: event` will no longer be necessary. Confused, what then will scala closures look like with SAM support, just, `val click = (e) =&gt; ...`?? Kind of a drag about the file size, seems to plague every static-compile-to-js approach. Sounds like scala 2.13 collections overhaul will help with the bloat. If only the scala overhaul project was closer to now than 2020, argghhh ;-)
Please don't upvote this troll bait. Not only does no one say the quote in the title, but the guy asking the question has the answer in his question. If you need more than 22 columns, use HList instead of tuples, which have no (practical) limit.
Nice. :)
Um. The pattern matching example can be rewritten like val result: Option[String] = person.contactDetails match { case Some(Some(Some(street))) =&gt; Some(street.capitalize) case _ =&gt; None } Pattern matching can match into nested structures.
Nah, bruh. You're forgetting the case class constructors. To do it your way, you'd need this mess: val result: Option[String] = person.contactDetails match { case Some(ContactDetails(Some(Address(Some(street))))) =&gt; Some(street.capitalize) case _ =&gt; None }
Dude ... judging by your post history, you have a sudoku solver to code from scratch in Scala. I have no idea what the requirements for your project are, but I guess you could embed your List of List in a case class and define the toString for it. In any case, that's the kind of things everyone WILL expect you to be able to find the solution for alone. That's like, an Object-Oriented programming 101 question. What have you tried before asking this question on reddit ? 
For your info, we do not get any lectures on the actual syntax of the language hence all these silly questions. I know logically how to do things but I can't seem to find how to code them in scala since I did not get a good background on the basic syntax and since I have a deadline I have no time in learning everything from scratch.. I tried to use the map function to find where there are zeros and replace them by _ and print the rest of the elements but I do not even know how to print the lists one under the other.
&gt; I can not use any libraries or software packages.... What's this about?
The character generically used in ASCII systems to represent newlines is '\n'. That's how you do in most languages. Printing a List of Integers (as a single line) as I suppose you'd like them to appear would be something like (Fonctional Programming style) : def asString(l : List[Int]) = l.map(x =&gt; if(x == 0) "_" else x.toString).reduce(_ + " " + _) With that, you should have all the basic info you need to print your matrix. That said, I'm curious of what your background as a programmer is. You can use imperative programming in Scala, and would have been able to solve this using for loops and variable assignments, provided you know how to perform a newline when dealing with Strings. 
`grid.map(_.mkString("\t")).mkString("\n")` `mkString` method interspenses the elements of collection with a given separator, so `List("a", "b", "c").mkString(", ")` is `"a, b, c"`. BTW it's better to use arrays for matrices, something lik `val grid = Array.ofDim[Int](9, 9)` 
[**@nescalas**](https://twitter.com/nescalas): &gt;[2014-11-17 20:19:00 UTC](https://twitter.com/nescalas/status/534440590403207169) &gt;The Northeast Scala Symposium returns to Boston in 2015! We'll be at [@DistrictHall](https://twitter.com/DistrictHall) Fri &amp;amp; Sat Jan 30\-31. Capacity is ~200. RSVP details soon. ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2msnlz%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
I believe you're missing an important point, here: it's not just a *library* that you can depend on in your POM file. You need a deeper integration with the compiler, how to run the code and unit tests, etc. As a matter of fact, we *will* publish to Maven starting from 0.6.x, but that does not mean you'll be able to use it in a Maven build straightforwardly. See also this SO question: http://stackoverflow.com/questions/26512750/how-to-use-scala-js-from-maven
Thanks for the clarification. Would love a scala.coffee compiler but that may be asking a bit much at this stage in the game ;-) Looking forward to 1.0 -- scala.js is very much on the radar here, client-side generated code is asking for trouble, and I've found it on more than one occassion...
If you need a 9x9 grid, then List[List[Int]] does not seem to be the right type. scala&gt; val x: List[List[Int]] = Nil x: List[List[Int]] = List() 
What do you mean by "scala.coffee compiler", exactly?
That's fine. I didn't expect it to be straightforward; I expected to write a Maven plugin for it. But if it's not published to a Maven repository, I can't use it at all.
I think it's a good question. There's a couple things you could do. one thing is to map the option and apply to the state monad. Something off the top of my head val state = (firstName %= "BLAH").flatMap(_ =&gt; lastName %= "LNAME") persons(idx).map(state(_)._1) 
I mean that rather than generating javascript the compiler would generate coffeescript. GHCJS for example has an extension that compiles directly to coffeescript. Doesn't make much sense in the context of writing client-side code in scala.js (since it would be Scala either way), but in terms of parsing the generated output, coffeescript is far easier on the eyes. Also, perhaps the coffeescript approach would help in trimming down javascript file size; could pipe output to GruntJS or similar client-side build tool to do the compression, which, in my experience tends to be extremely fast, in part because it's decoupled from the running sbt process.
Whilst these are nice tips I kinda see lots of nested options as a bit of a smell that the model isn't being designed very well. Just make a sealed trait to represent the various types of your "User" (i.e PersonWithAddress, PersonWithoutAddress) and then the pattern matching becomes much easier. 
You're not supposed to parse the generated output: there are source maps to get you to debug directly your Scala code. Only compiler hackers need to read the generated JS, and that means mostly me; and I find JavaScript to be much more readable than CoffeeScript. For size, we do a lot ourselves (which is very fast), and then we pipe the generated JavaScript to the Google Closure Compiler (only for production, takes a few seconds). I very much doubt we can get anywhere near as small with a CoffeeScript-based approach, let alone smaller.
For building simple APIs you can also use Spray IO, which is a lightweight http server/lib built on Akka. You can then bring in whatever tools you need with sbt.
I've found that in practice, even though you're expecting a map of differing types, it's usually well defined what data you're expecting. To update a user I always expect a (possibly optional) name, age, birthday, etc, and in this case I really want a case class rather than a map (or an array of case classes). This gives me named members with the benefit of static typing.
I only have Scala for the Impatient, as it was suggested to me by a friend. I haven't really dug too far into it. Would this book be a precursor, a side-companion, or something else entirely?
Does Spray supersede Play, or will they work together?
I recommend posting your questions to StackOverflow and linking to those posts here. If your question involves programming, try to include an example with the minimal amount of code needed as a starting point for somebody else to help you. Include a short discussion of what you expect the code to do and where the program's diverging from your expectations.
I have certain guidelines I have to stick with and I am just stuck in one particular function. I can explain in pm if someone is interested to help.
It sounds like it might be homework. If you do post to Stack Overflow, make sure to tag it as such. 
I also use nested map (flatMap) calls, but imo the for expression is a lot cleaner and I will start using it more.
I for one ~~welcome our new overlords~~ would love to see some performance characteristics/comparisons.
would be cool a comparison with vertx, seems to have similar approach, I think than in a near future I could change vertx for colossus if it has a faster and more active development 
slides available here: http://wheaties.github.io/Presentations/Scala-Dep-Types/dependent-types.html#/ don't miss the vertical slides
But then you still have to manage the global instance of `Service` by hand.
Right. I'm just commenting on the usage, not the particular implementation.
But now you have broken encapsulation. Say I'm calling your method `operationThatNeedsService` and you force me to know your implementation detail (that you use a Service). All I want is a result for this operation and you're forcing me to find out how I can pass you a `Service`. Things get worse if you suddenly decide you need another dependency, say a `Log`. Now, not only do I need to find one and give it to you, but so does every class in the stack frame between you and me. These kinds of dependencies should be hidden from callers: @Inject Service service; operationThatNeedsService() = { ... } Now, callers are completely shielded from your dependencies. Adding a `Log` is a two line change in your class and nowhere else. Another added benefit is that now that your dependencies are managed by an external facility (a DI container), you also don't need to worry about their lifecycle or being able to substitute them for various configurations. I find that this ease of use far outweighs the violation of referential transparency. 
&gt; broken encapsulation More like, using DI containers obfuscates how your system works. Dependencies should not be hidden from the system! I have worked with too many systems where people think encapsulating everything is some kind of virtue; until things go wrong and then no-one knows how anything works. Not to mention that unit testing these things now becomes more complicated then just call the service with a different (i.e stub) instance. Newing up things shouldn't require some DI container. If it does it probably means you're modeling your system wrong or it's simply too big. 
Didn't read yet. What do you guys think about it?
check out ["Experiment: A Reactive 3D Game Engine in Scala"](http://www.hnwatcher.com/r/1239224/Reactive-3D-game-engine-written-in-Scala)
https://github.com/vmarquez/purebomberman Is my tiny little 'pure functional' game. It's very...slowly turning into a blog post. It might give you some ideas. 
I've been doing gamedev in Scala for around 3 years now (3D with my own engine on top of LWJGL). I gave a talk to my local Scala group around 18 months ago: http://michaelshaw.github.io/game_talk/game.html#/ Events are my primary method of abstraction these days. In terms of mutability ... I use a "hybrid" approach, if it's easy and won't impact performance significantly things will be kept pure. I keep a close eye on GC .... and anything that affects gameplay is made nasty/mutable. 
The page has this error printed in console, and I got these messages before too. How do you fix it? "Uncaught java.lang.ClassCastException: 5663.2002 is not an instance of java.lang.Integer"
I haven't read this article yet, but the author gave a live-coding talk at Pacific Northwest Scala a couple weeks ago and it was great. Scala.js looks really promising, and the author has many good examples on his Github. EDIT: I've started reading it and it's great so far. Worth reading 100%.
Best /r/scala post in ages, thank you.
_Proper_ doesnt exist. Experiment with techniques. Find good fast ways to build an engine, thats half the fun. Theres lots of places to experiment here. I built an RTS engine that could handle around 50k active units on a 6 core machine. If you add in all the semi active units (ie cities that build things over multiple minutes), it grows to 200ish k. For calculating collision and such, the various processes got an immutable view of the world. This allowed the frame to process multiple units simultaneously. 
What's the point of this library, scala has pattern matching as a language feature. Why not just use that.
John Carmack talks a bit about it in this talk (starting at 2:10): https://www.youtube.com/watch?v=1PhArSujR_A From Scala Days 2014: https://parleys.com/play/53a7d2cde4b0543940d9e561/chapter0/about
Machete don't test
"What's a good book on Scala for someone without a Java background?" is a good question. I don't have an answer, but Odersky's functional programming Coursera doesn't assume Java.
I second Scala for the Impatient. I haven't looked at Atomic Scala but I've heard good things.
This book is amazing. It is a great way to learn functional programming, but it doesn't go over many features of Scala.
Sometimes I dont understand the upvote dynamics here...
I second Scala For The Impatient. I don't have any Java experience, and this book got me up to speed very quickly without having to know Java first. 
So you can simply use play-json in a separate app. It works just fine as a standalone library. To use with SBT, you can add the resolver: resolvers += "Typesafe repository" at "http://repo.typesafe.com/typesafe/releases/" To your SBT project and then include libraryDependencies += "com.typesafe.play" % "play-json_2.10" % "2.3.6" Or if you must have maven central, they've got a milestone release published there, and it looks like 2.4 will be published to maven central. libraryDependencies += "com.typesafe.play" % "play-json_2.10" % "2.4.0-M1" It also depends on what kind of JSON you're consuming. For our case, we used spray-json, because it was super easy, define case classes, and fill them with stuff. [Or so we thought.](https://github.com/rackerlabs/repose/blob/master/repose-aggregator/components/filters/openstack-identity-v3/src/main/scala/org/openrepose/filters/openstackidentityv3/OpenStackIdentityV3Handler.scala#L140) So many nasty .get and .maps. Turns out the JSON contract was very very very optional, and so our spray-json case classes contained a whole lot of Option[Thing] which became a nightmare to consume. We're eventually going to refactor it to use json path, or maybe [json-lenses](https://github.com/jrudolph/json-lenses) (Although json-lenses is now behind spray-json a bit, since the parser is rewritten for the latest spray-json) A better solution would be to just Xpath out things, and if we get nothing, there's nothing to do, or if we get something we do stuff on it. Which would be the same solution as if we used all the optionals, but we could nest things better I think. Either way, that needs a bit of refactoring. There's a way to [traverse a JSON structure](https://www.playframework.com/documentation/2.3.x/ScalaJson) using Play-json as well, so I think if we get a chance to refactor what we've got we'll use this. I don't see anything in here about dealing with nothing coming back from the select though. Some experimenting is probably necessary. Or maybe something like [jsonpath](https://github.com/gatling/jsonpath) which can do things pretty quickly as well. This kind of turned into more of a braindump of the scala json-y things I've dealt with recently, heh.
To add to this, if you're using Spray IO and you want to return JSON http responses, there's a convenient import that allows it to handle marshalling/unmarshalling of Play json! Simply: import spray.httpx.PlayJsonSupport._ And you can return Play json objects in your Spray routes. I'm using Play's json libs in my Spray app and it's great.
What do you mean by managing the instance? If the entire object is referentially transparent, then there is no managing to do. Unless you mean passing around the instance. If that's the case, then you could use a DI framework. 
I think that's the spray demo Jan Machacek put together for [Philly ETE](https://www.youtube.com/watch?v=rmrhJpvzd5s). Didn't he hand-roll that JSON parser? You picked a pretty fucked up code demo to get started with building a RESTful service on, man. Pieces of my brain are still dripping into my socks from when I studied that code. Play is a mega-framework for making fun model rockets. Spray is a micro-framework for making deadly nuclear reactors. Approach it with a hazmat and a spotter.
http://letitcrash.com/
Coursera progfun (by the man himself, Martin Odersky) is good, more so due to the programming assignments where you get to write some code.
`play-ws` is a separate library now, there shouldn't be any problems with using it.
Yes, you can use Play-WS and Play-JSON in a non-Play application. It's a decent solution.
The Activator template I posted is the "client" half of the spray demo you posted -- I see what you mean about having grey-matter in your socks after watching the presentation... The template above is a bit easier to grasp, though. It just pipes the analysis output directly to the console, rather than routing the results through another HTTP front-end. Thanks!
I'll definitely check it out when I have time, thanks for pointing that out. Grasping the client first might make grasping RESTful/reactive services a little smoother (a little). I was actually holding on pretty tight until he started triple-currying functions, then I just threw my keyboard.
I think that lightweight in the context if Akka refers to the threading/process model: http://en.wikipedia.org/wiki/Light-weight_process More to your original point, I haven't had issues running Akka apps that use less than 512mb of ram, but I don't know how well they would run on a system with that much ram. Also, have done any memory profiling? There are a lot of layers in that stack so there could be a hidden bottleneck somewhere.
Haven't tried profiling, it's probably worth the extra $5 a month to not have to do that. Don't know why I posted, I know there's no easy button. Just venting, I guess.
If you are learning scala, I'd recommend to learn Haskell first and then scala.
Everything is relative. For a framework that runs on the JVM in 2014, it IS lightweight. If you need this app to run reasonably well on a 512MB droplet, I'd be picking a different stack entirely... ALSO, Digital Ocean droplets have NO SWAP by default. Meaning if you overflow the 512MB of RAM, your server will crash. That's trivially easy to do with any stack once you add in a database, caching, etc.
Awesome. That's helpful. I've noticed that happens during SBT refreshes for a few minutes and then it resolves all the symbols... Usually. My current challenge however might be a little bit more peculiar. I've noticed that the templates themselves have odd behavior when working with inline JavaScript. I don't normally employ this tactic since I prefer modular code, but I'm doing something quick to test Facebook API calls, and then just scrapping it. In a Scala HTML file, all the JS code inside script tags seems to not be recognized/highlighted. Is there a way to add JS support in IDEA to those templates? Also if I format the code, it just sets all the text to 0 indent because it doesn't know what it is. It seems to do that with the HTML tags too. All in all, the formatting across the board seems very wonky! Many thanks!
now if only it was visually useful i click one one and the endpoints are too small to read, would also be nice when you clicked one it stayed clicked so you can at least zoom in to the others to see what they are...or list them somewhere... i dunno :(
You're right, switching to Node for this project.
maybe you have a massive monitor or this works better in your browser? but if i highlight one and dependanies show, how do i see where the red line goes? if i zoom in its no longer on the screen if i zoom out its super small; basically i have to remember where a dependency is on the circle and hope i selected the right one from the 10k ft view to see what the actual dependency is
done
Thanks! I just finished reading Atomic Scala and it was absolutely great! None of those Java references and it was straight to the point! I am going for Scala for the Impatient right now, it seems great as it was suggested by the authors of Atomic Scala in the end!
Cool thing about the JVM is you can restrict the memory the JVM consumes when yous start it, just limit the JVM to 256/384 megs and develop from there.
He added the [MIT license](http://en.wikipedia.org/wiki/MIT_License) to the [README.md file](https://github.com/lihaoyi/scala-parser/commit/0ae66ff17614d37c9458b1732a319035ae902d0c#diff-04c6e90faac2675aa89e2176d2eec7d8)
Great work! Do you have any idea, how parboiled2 deals with error handling / error reporting? In the past I worked with xText (antlr backend) which has a very nice feature: In the case of an error, it inserts artificial tokens until the parser recovers. The artificial tokens are marked with an error message. This allows the parser to yield useful results in text files that are currently edited. With parser combinators I could find no easy way to reproduce this kind of error recovery. Do have any idea if or how parboiled2 allows this? Or is there perhaps a superior error handling mechanism in parboiled2?
Wait what? Not sure if serious ...
My project (play v2.3.5 + scala v2.11.1) runs on Raspberry PI with 32 MB RAM. You just need to run it as prod mode. It is based on true story.
You do know that IntelliJ has a free version...?
I had already looked at your slides, thank you for making those available! What sort of things do you keep mutable?
I meant the latter. You can of course use a DI framework but to me it seems like an unnecessary abstraction over something that was never meant to be to begin with (i.e. singletons in Java).
Thank you. It was a bit hard for me to understand, as he didn't provide a lot in the way of examples, but some interesting ideas
I don't think the world is sold on JS runtimes yet, but this definitely seems to have some promise. I use Play Framework and love it. What would be really fascinating is to see a Scala web framework on the client-side, or better yet, a framework that spans the boundary between client- and server-side, kind of like Meteor.
@minibox ?
Personally, I use specs2. I don't have any particular allegiance toward it, though. My previous employer (a Scala Days sponsor) used it. I kinda like the idea that it runs tests in parallel.
production
Definitely use ScalaCheck. It does property-based testing, which actually finds bugs. Traditional unit testing is actually not very good at this ;-) You can use it standalone, or integrated with ScalaTest or Specs2 (they're largely equivalent, nobody seems to feel strongly about either of them).
ScalaTest, because it works. I don't feel very strongly about this matter, though.
In Banana-RDF, we started to use [zcheck](https://github.com/InTheNow/zcheck), "A wrapper around scalacheck and scalaz's Speclite". That is basically the only test framework that supports Scala-JS.
I really like scalatest. But I haven't really tried specs2
I can't find much documentation on it. Any hints from your site? What's your experience with it? Greatest since sliced bread or mainly room for improvement?
While you are obviously (hopefully?) joking, your post has its merits. Testing in production is very important when done right: Monitoring live data, injecting (well isolated!) test/measurement samples in a controlled way and re-checking production samples are very important but often overlooked techniques! 
I have used Spray as an HTTP client to make calls to HTTP based web services, where all of them return data back as XML. You should be able to use whatever JSON library you wish, spray is more or less orthogonal to that in the sense that you can extract the message body from the response and feed it into the parser. I don't have a JSON example, but perhaps something like this can point you in the right direction if you want to use Spray: import akka.io.IO import akka.pattern.ask import spray.can.Http import spray.http.HttpHeaders.RawHeader import spray.http._ val origin = sender() val requestXml = BBUtil.display(billingId, BBUtil.dateNow, BBUtil.transId, username, password).mkString val contentType = ContentType(MediaTypes.`application/soap+xml`) val messageEntity = HttpEntity(contentType, requestXml) val headers = RawHeader("SOAPAction", "\"\"") val httpRequest = HttpRequest(HttpMethods.POST, Uri(endpoint), headers::Nil, messageEntity) val display = for { httpResponse &lt;- (IO(Http) ? httpRequest).mapTo[HttpResponse] } yield httpResponse display onComplete { case Success(response) =&gt; { val elem = XML.loadString(response.entity.asString) //response.entity.asString gives you the body of the message val responseMap = BBUtil.parseResponse(elem) origin ! responseMap } case Failure(t) =&gt; //log it, printStackTrace, or handle the error somehow } 
not joking :) what better beta testers than my users? [– *Just push it to production. It will fail, but testing is only about writing tests, not real code. If it breaks, fix it! TDD is for pussies!* --Erik Meijer] (http://reaktor.fi/blog/erik-meijer-software-eating-world/)
zcheck's SpecLite is only [one simple file](https://github.com/InTheNow/zcheck/blob/master/shared/src/main/scala/zcheck/SpecLite.scala), just like scalaz's version. I didn't need any documentation to get started. The example might help. The rest is just scalacheck. We are currently porting the tests in Banana-RDF from Scalatest to zcheck to get Scala-JS support. This is pretty straightforward, just tedious, as we never rely relied on the DSL craziness in Scalatest, which doesn't bring much. `check` and `must_==` are mostly what we need.
Also, miniboxing still doesn't solve the ClassTag infection issue :\
Unless they've replaced the config syntax while I wasn't looking, I'm sticking with Maven. Fuck everything about that eldritch monstrosity.
Stairway to Scala Applied https://parleys.com/channel/539ae880e4b0543940d9e4bf/courses Free sample of books: https://typesafe.com/resources/e-books https://soundcloud.com/typesafe Scala For Beginners http://workday.github.io/scala/2014/01/09/scala-for-beginners/ http://www.scalawags.tv/ Parleys.com - Scala Days 2014 https://parleys.com/channel/53a7d269e4b0543940d9e535/presentations BoldRadius https://www.youtube.com/channel/UCfdBy0ki3qq-2ULBoIT93ZQ http://boldradius.com/blog http://reactive.xploregroup.be/blog http://danielwestheide.com/blog/2012/11/21/the-neophytes-guide-to-scala-part-1-extractors.html
I highly recommend this free programming course by M. Odersky: https://www.coursera.org/course/progfun
Scala is a language and SBT is a build tool. If u r not sure about SBT, I am sure u can still enjoy Scala with maven or gradle or even ant. 
Ah great. So it is indeed just that one file. Thanks for the information!
There are Scala plugins for both. I'm using [gradle](http://www.gradle.org/docs/current/userguide/scala_plugin.html) and it's fairly straight-forward as opposed to sbt. For instance a baisc build script (build.gradle) looks like this: apply plugin: 'scala' version = '0.1' ext.scalaVersion = '2.11.4' repositories { mavenCentral() } dependencies { testCompile 'org.scalatest:scalatest_2.11:2.2.0' compile "org.scala-lang:scala-library:${scalaVersion}" compile fileTree(dir: 'lib', include: '*.jar') # to include jars from ./lib } compileScala { scalaCompileOptions.additionalParameters = ["-feature", "-language:implicitConversions"] }
i'm a noob too just getting started. im trying to write a parser for a language. is just extending regexparsers a good enough idea for BNF stuff?
Using a grammar to generate well-formed Scala (aka parseable Scala) should be possible. [People do something like it to test some of Haskell's own IR, for template Haskell]. But fundamentally that does not scale: most well-formed Scala programs are not well-typed. So you really want to generated well-typed programs, not merely well-formed. That is possible too, but rather than using the grammar, you need to the the grammar of type derivations for Scala's type system as the generator, and then extract the resulting assuredly well-typed term from that.
I vote for `scalatest`, it was the most nice to use. // Some personal notes. I also had experience with `specs2` (in some cases it replaced real problems with NullPointerException (?!)). And I also used `utest` a bit. That last thing is a small library that supports ScalaJS. Unfortunally, it's very immature and some bugs don't get fixed at all. Hence the vote -- scalatest.
As a sort of reverse of this, there is a Haskell program called Djinn that takes a type and generates a program of that type. It is pretty cool. https://github.com/augustss/djinn
That's not good enough for me, I'm afraid. Unless the build file is purely declarative, like Maven's POM is, it's a step backwards and I'll have none of it.
Genetic Programming here we come :)
Great, but how is this more "straight-forward" than version := "0.1" scalaVersion := "2.11.4" libraryDependencies += "org.scalatest" %% "scalatest" % "2.2.0" % "test" scalacOptions ++= Seq("-feature", "-language:implicitConversions") ?
There is no `%%%`, only `%` which concatenates the parts of an artifact, and `%%` which does the job for you of integrating the Scala-Version in a dependency module ID.
http://www.scala-js.org/ I believe they use enrichment.
Fair enough but, personally, I still have some major issues with sbt: - Why sbt supports two build syntaxes/files? (build.sbt &amp; project/build.scala) - Why weird operator syntax in build.sbt (':=' vs traditional '=') - Multi-module build is not possible with normal build.sbt (I think) - Still some symbolic soup (%, %%, :=, ++=. +=) That said, sbt is a good choice as long as things can be kept simple (only build.sbt with minimalistic symbolic soup (%, %%, :=, ++=. +=) I think the latest sbt version now finally allows to omit empty lines in .sbt files, which is nice :)
Many of these points are obsolete, though. &gt; Why sbt supports two build syntaxes/files? (build.sbt &amp; project/build.scala) I think this is historical. The `.sbt` simplification was introduced at a later point (with the switch from sbt 0.7 to 0.10 if I remember correctly). Now there are many people arguing that this was not a good idea, and while I like `.sbt` I can understand these arguments. But... I think now some of the awkward things that make `.sbt` non-standard Scala code are removed, e.g. the requirement to have blank lines between assignments. So my wild guess is we will see `build.sbt` versus `project/Build.scala` disappearing soon, because they become essentially the same. &gt; Why weird operator syntax in build.sbt (':=' vs traditional '=') The reason is that `=` cannot be overloaded but is a language construct in Scala. It is reserved for variable assignments. &gt; Multi-module build is not possible with normal build.sbt (I think) It is possible now to define multi-module builds in `.sbt`. &gt; Still some symbolic soup (%, %%, :=, ++=. +=) Of course a matter of taste, but I think `:=` is easy to understand, and `+=` and `++=` absolutely reflect standard Scala collections method conventions. The indeed awkward `&lt;&lt;=` kind of stuff has been replaced by more straight forward macros that allow composition using the `.value` method on settings keys. The only really new syntax to learn thus is `%` to compose artifacts. I don't disagree with you that sbt can get hairy as soon as you want to do non-trivial things, but then in 99% of the cases you do have trivial build files.
For the latter, [InSynth](http://lara.epfl.ch/w/insynth) could probably be re-purposed.
Why not sir
Thanks for insight! Just tested a multi-module .sbt project and it seems to work great! But the syntax is not that intuitive... (yeah, I read the manual but just for making a point): error: not found: value foo foo := project great... another try 'val foo := project' and now it says: '=' expected but eof found. So this time it requires standard Scala syntax: 'val foo = project'. From end-user perspective "= cannot be overloaded" is a poor excuse. Having a two different incompatible assignment operators is just f*****. But I guess the sbt is approaching a point where the number of these syntaxical "surprises" gets bearable... :)
BNF describes context-free grammars, not regular grammars. 
&gt; From end-user perspective "= cannot be overloaded" is a poor excuse. Having a two different incompatible assignment operators is just f*****. That may be the case, but there is little the authors of sbt can do about it. Make propaganda for scala-virtualized ;) there you can assign the meaning of everything from `if` to `=`... BTW I agree that the `project` call is totally non-intuitive. I don't even try to understand what it is doing, I've set it up once working and now I just copy+paste ;)
doesnt look like it works on windows ah well; love that he rips on emacs so much and barely has a usable editor LOL &gt;That would be great! I have lots of documentation plans (which I will be expediting now that there are more than zero users), but it's hard for me to assume the perspective of a new user, as I suffer from the curse of knowledge. the curse of knowledge!
http://blog.codacy.com/tag/scala/
&gt; love that he rips on emacs so much and barely has a usable editor LOL Where does he rip on emacs? 
is this position still available? 
This is an awesome ad. Would definitely apply if the timing were better.
I would change "arbitrary" to "some", but otherwise looks fine!
Are you the author? The code I've seen so far is not too Scala-like. The project would benefit from borrowing more tricks from others. For example, I looked at your scaled.impl.Utils class. override def emit (value :T) :Unit = try { super.emit(value) } catch { case t :Throwable =&gt; log.log(s"Signal.emit failure [value=$value]", t) } It would be better to use NonFatal like this: case NonFatal(t) =&gt; ??? Also, this style screams Java to me: layout.setContent(if (text != null) text else "", font.impl_getNativeFont) layout.getBounds.getWidth I would've wrote Option(text).map(text =&gt; { layout.setContent(text, font.impl_getNativeFont) layout.getBounds.getWidth }).getOrElse(0d) And the inner function could use a separate name, of course. Whenever I see if(something != null) in Scala code I think it should be changed.
No, I'm not the author. I had a glance through the source code, and I was positively impressed by the API seemingly being fully documented with comments.
First, Options have cost, not in every application it could be ignored. Second, applying map for side-effecting inside closure isn't a perfect style either.
Types and curl ftw.
so.... Is spray not going to be a thing anymore?
I would like to warn people against using this version. I just found that the new caching mechanism is either buggy or doesn't work with current plugins. Both [sbt-updates](https://github.com/rtimush/sbt-updates) and [sbt-dependency-graph](https://github.com/jrudolph/sbt-dependency-graph) stop working.
I spent so much time learning spray! I quite liked the DSL
Finally The Tyranny of PLAY will be over.
This Cheeven is so sure that you will be surprised that there are no links to help us know how to do that Hows that ?
Props to xeno_by and densh.
The Reactive Programming course on Coursera is also excellent.
Is the JSON library based on Play's or just inspired by it? It looks quite similar.
To be fair, the gradle version only added 10 more lines and has more features that make polyglot programming easier (mainly because sbt is mostly for scala). It's easy to compare trivial setups, but when the project gets complex how will sbt fair against gradle? Sbt is improving and I can't wait to see how well SBT 1.0 comes out. 
Is anyone else having issues checking out? My phone keeps seeing "There was a problem loading the login page." 
Any recommendations for this book? 
Its okay if you like ORiley books. Dean knows his stuff.
[direct link](http://guides.co/g/how-to-learn-scala)
I can't really comment on your complaints, but I recently completed the Coursera course [Functional Programming Principles in Scala](https://www.coursera.org/course/progfun). The weekly assignments were an exceptionally good learning tool, for me anyway.
There's a big collection of tutorials in Typesafe Activator you might find useful: [http://typesafe.com/activator/templates (http://typesafe.com/activator/templates)
You should buy Dean Wampler's book, Programming Scala. It covers 2.11: http://smile.amazon.com/dp/1491949856
The stairwell book is also a great reference. I realize it's not exactly what you're looking for with regards to learning the language, but it's a fantastic reference. http://www.amazon.com/Programming-Scala-Comprehensive-Step---Step-ebook/dp/B004Z1FTXS/ref=sr_1_2?ie=UTF8&amp;qid=1417997922&amp;sr=8-2&amp;keywords=scala+programming
The most effective way of doing unit testing in Scala is with [Scalacheck](http://www.scalacheck.org/), which does property-based testing and **actually finds bugs**. You can use ScalaTest or Specs2 as an organizations mechanism, and for tests that are not easily expressible as invariants. They are largely equivalent and I have never seen anyone argue strongly for one or the other. A good resource for this kind of question is the #scala channel on FreeNode IRC.
I built [ScalaKata](http://scalakata.com/index) where you can learn scala interactively. I'm not the best person to write the content, so if /r/scala could help me I would really appreciate that. The [content](https://github.com/ScalaKata/TryScala) is available for anyone to modify on their computer. The engine is [open source](https://github.com/MasseGuillaume/ScalaKata) and [easy to install](https://github.com/MasseGuillaume/ScalaKata#distributions) via Docker or sbt plugin.
I really, really wish I'd seen that before I went and grabbed [this old thing.](http://www.horstmann.com/scala/index.html) Edit: So I decided to drop the $20. I haven't had time to read the whole thing yet but I can recommend the first hundred or so pages that I have read.
I learned using Scala Koans and suffering through code others had developed. http://www.scalakoans.org/ The koans were helpful but I think I would have been happier without the suffering.
To be fair, Scala makes the most sense if you come from both a Java and Haskell/ML background. From what I've found, the docs and related articles are good but scattered. For instance, this [FAQ about implicits](http://docs.scala-lang.org/tutorials/FAQ/finding-implicits.html) explains their mechanics pretty well. The common libraries from what I've seen also have good docs and related articles. Play for instance has a pretty solid tutorial to help you get started (plus activator stuff). Scalaz has the Learning Scalaz blog series and cheat sheet. Plus the actual scalaz scaladoc is actually helpful once you understand the library a bit. Also tangentially related, but from what I've seen and experienced, if you're working in Scala with others and seeing more experienced people's code frequently, the language (and even its heavier parts) come more quickly. Functional Programming Patterns in Scala and Clojure is a good book to get a feel for the language as well if you're interested. It's more supplemental than a primary Scala resource though. 
Hello. If u know about maven or gradle, it should be fairly straightforward to find the relevant plugins to handle Scala. 
&gt; For instance, this FAQ about implicits explains their mechanics pretty well. It seems a bit dated, since [view bounds are deprecated](http://stackoverflow.com/questions/4465948/what-are-scala-context-and-view-bounds/4467012#4467012), but you are right.
at ScalaX now! thanks for this interview ;)
Cool tool for a bird's eye view on the Scala world
I think it is because I was deploying in prod mode. Think that would cause the issue?
At my organization, we use ScalaTest to provide syntactic sugar for JUnit. We mostly use the assertions, writing code like: class FooTest extends ShouldMatchersForJunit { @Test def testFoo { foo should equal(bar) } } Our existing build tools and infrastructure (Maven, Bamboo, etc) work with JUnit test and output files, and when we switched to Scala, we needed to do so class by class and test by test, not all at once. ScalaTest is a *big* lib, with lots of features. We only use a few, but it works well.
tbh I don't have the time to read through a magazine-length interview when I'm at work so these are perfect...
Here's a pretty hefty example of our usage of ScalaTest on the opensource project I work on: https://github.com/rackerlabs/repose/blob/master/repose-aggregator/core/core-lib/src/test/scala/org/openrepose/core/services/logging/LoggingServiceImplTest.scala We're also running it with a JunitRunner, and it fits into all the build tools and infrastructure just fine :)
You have brought up an interesting question - does Option have a cost or not. I have ran a benchmark to test it and I am certain that in this situation it does not. Here is the JMH benchmark code: https://gist.github.com/voronaam/fbda8059a6aa36caa6ed Here is the result: Benchmark (strValue) Mode Samples Score Error Units o.s.MyBenchmark.testNull 4 thrpt 15 84314649.298 ± 1203713.827 ops/s o.s.MyBenchmark.testOption 4 thrpt 15 83276054.167 ± 574030.725 ops/s o.s.MyBenchmark.testNull null thrpt 15 158563487.854 ± 2074024.325 ops/s o.s.MyBenchmark.testOption null thrpt 15 165543753.295 ± 2113093.244 ops/s There is no extra cost in replacing if(value == null) with Option(value). As for the state in map(), I agree, but I have zero experience with JavaFX and do not know how to do the operation in question without side effects. So I copied the code from the original file. I agree it is not a good style, however.
I first learned scala with this intro: http://www.scala-lang.org/docu/files/ScalaByExample.pdf It's not a full language guide but it has everything to write a useful app and not fall into "Java that compiles slowly" trap. Once it was referenced from the main docs page, not sure why now it only reachable with Google.
Why not generalize the sorting to be on the (key, value) tuple? Is there something about the underlying data structure that's specific to sorting on one or the other?
Hey guys, I've been told tickets have just gone live for our Scala eXchange 2015! The first batch of super-early bird tickets are going at *£95*! Follow this link to book now: https://skillsmatter.com/conferences/6862-scala-exchange-2015 
http://www.scalatimes.com/
&gt; I have to ask, how tough is it to run scala, or play scala, projects with them? I work on a large-ish multi-module Scala project built with Maven (~30kloc, ~30 modules). It works great. Setup was as easy as using Maven for anything else - not a breeze, but definitely not hard either. There's decent documentation. Maven is not my favorite, but it's much more sane than SBT. I have no idea about building Play apps with Maven, though.
&gt; what you want from a testing framework I want the framework I use to make me coffee in the morning, promote goodwill among men, and save my marriage.
The (relative) priority is provided by the `Ordering[B]`. That, in turn, could derive the correct priority from some field in the value. Similarly, a regular `SortedMap[A, B]` uses an `Ordering[A]`, which could derive the correct priority from something in the key.
I do and it works just fine, but I must admit that I run SBT in a term and use Emacs solely as an editor, not as an IDE as some people do (with something called Ensime, I believe). So, no code completion, no inline error highlighting, no "simple" keyboard shortcut to run my test cases... The only advanced fonctionality I use is contextual help, through Dash on OS X. I'll be honest though - while this is great for quick scripts or simple bits of software, as soon as I find mysel with more than a few classes, I fire up IntelliJ.
Still there, under "older socumentation." http://www.scala-lang.org/documentation/
try to look this recent presentation https://skillsmatter.com/skillscasts/6000-ensime-the-other-ide
I do the same with vim and sbt ~test in a second window. Have learned that from Derek Wyatt's videos and think its pretty genius.
How is this different from the TreeMap already in the SDK?
[Not true at all](http://alarmingdevelopment.org/?p=562): &gt; I have now switched for all of my development work to our as yet unreleased version of the Scala plugin for Eclipse. That’s after 20 years of emacs. And I am not looking back. 
One of my coworkers uses emacs on his mac. I find that I still prefer intellij. Whatever floats your boat.
I write a lot in emacs using ensime. Still use intellij for large refactors and debugging though.
the interesting part for me is a bit down: "Yes, that's right, we are relying on null for the None case while the Some case is the value itself :-) But this is completely typesafe as it never leaks outside of the abstraction. The trick is that Null is a subtype of Any. And you can note that that there is no wrapping involved."
Somebody has already mentioned my talk - https://skillsmatter.com/skillscasts/6000-ensime-the-other-ide Overall I think Ensime is good addition for Scala development on Emacs - it gives you a lot of the goodies you find in a full IDE whilst bringing those into Emacs (my personal favourite are the red squigglies and the full semantic highlighting). The base Scala mode uses regex highlighting which works ok for Java but reallly struggles to give you enough for Scala. As I say in my talk Ensime has gone through a recent revival, a lot of work has gone in the last few months, and more is happening as we speak - so please do raise issues, talk on the mailing list etc)
As per my other comment - Ensime adds most of these features to ensime (with more coming), so please give it a try :)
Sam and I spoke to Martin at the Scalax - we (the Ensime) team are trying to bring him back into the Emacs fold ;)
Are you using any Vimscript to do it automatically, or is it just manual selection, copying, ALT-TAB, pasting? 
I'm also curious if/how you have integrated the REPL with Vim. It sounds awesome to be able to "stage" a snippet of code in the REPL and "import" it into a bigger Scala-project in Vim (or any other editor really)
OK, let me rephrase that for you then, sir: "I know a guy who USED to..."
I'm using the Conque plugin to run the REPL inside VIM so I get syntax highlighting and can paste back and fourth. I've written a macro to take whatever I selected, go to the REPL window, enter 'paste' mode (so I can paste multiple lines of scala w\ breaks), paste my highlighted code and hit enter. http://www.vim.org/scripts/script.php?script_id=2771 Here's an image of my screen http://i.imgur.com/Cu0p0YA.png
Why are query parameters futures? How long can it possibly take to extract a parameter from an HTTP request?
I just started learning Scala 10 days ago - and I am happy to report that I am already very productive, using Emacs/ensime, doing both my coding (with auto-completion!) and debugging from within Emacs. A big thank you to the awesome people behind ensime.
Why not use monad transformers and just lift? 
No, because what should it do in this case: `setCell[(Unit, Unit)](null, 0, ((), ()))`? It does make some sense to use a type class in this situation, though.
It looks similar I agree. I wrote that module, but I've never seen the Play's variant before. Probably, it's just a common sense on how should the JSON API looks like.
Couldn't the compiler complain only when the template instantiation makes no sense? In your example, "null.createCell()..." would cause a compile time error, because there's no method "createCell" on type Null. Unless you are saying that in Scala, the code inside generics must be able to work with any type T passed into them, even type Null. Is this what you are saying? Also, since I haven't seen typeclasses yet, I'd really appreciate a gist - there's no better way to learn a construct than to see it solve a problem you have!
Scala's generics are like Java's, not C++'s. They are erased, not instantiated. Typeclasses let you do something similar to instantiating them. [Here is an example.](http://danielwestheide.com/blog/2013/02/06/the-neophytes-guide-to-scala-part-12-type-classes.html)
If a member is mutable don't use case classes, because you will inevitably fall into a trap with the equality definition. 
A type parameter `A` is (and cannot) be resolved at compile time; that's why it's a parameter. If your underlying API doesn't have a generic `setCell[A]` method but only a number of overloaded methods for given types, you will need a pattern match like in your code above. There is nothing wrong, though, in packing that match expression into your auxiliary `setCell` method.
Also, watch the talk with slides here: https://skillsmatter.com/skillscasts/6095-a-skeptic-s-look-at-scalaz-gateway-drugs-a-practical-exploration (sign-up required but worth it! Gives you access to loads of other Scala Exchange recordings too!)
It's wrong to claim such a thing, cause you can confuse people, yes Try and Future implementations fail on left unit law, but it works for bind/flatmap operations which more important in general
The only trap I am aware of, is caused by concurrency issues when vars are updated while the generated methods are called. Are there other kinds of problems ?
how so? 
Yes, if used as constructor parameters, equality changes, so you run into problems with `==` and usage as keys in sets and maps. If used as members that are not constructor parameters, different instances will be aliased through their (wrong) equality.
Yes I agree, but that's a general problem with mutable objects used as Set/Map keys, not something related to case class. (lots of java programmer experience it...)
More talks to come! Check [PNWS conference site] (http://pnwscala.org/2014/index.html#schedule) for full list.
I wrote a non-compilable Scala generator (for dvorak problem sets), might be a useful starting point: https://github.com/pkinsky/dvorak
I found the Effective API Design talk insightful, especially if you've done some REST API implementation before. It helped me rethink a lot of my own design decisions.
I signed up, but the video won't show, it says "Because of its privacy settings, this video cannot be played here." Where CAN it be played?
Make sure there is an akka_actors jar in your project build path. The actor classes are not in the core jar which may be related to your problem. Sorry, I can't provide you with a step-by-step beyond that.
Quite similar to something I wrote: https://github.com/pathikrit/dijon but now I just use rapture.io
[Here](http://www.slideshare.net/Odersky/scalax) are the slides from Odersky's scalaXchange presentation; a large chunk of the interview concerns his proposal of using typed trees as intermediate format for storing Scala code. __Edit__: And Seth Tisue put together [some notes](https://gist.github.com/SethTisue/5f2c8f694978268698fd) that are useful as time pointers into the video.
While this had a lot of grammar and spelling mistakes, it's a pretty good example of how to do this in scala for someone coming from haskell like myself. 
For printing interpreter, I'd rather use the Writer monad to accumulate the structure into Writer's state. Using println inside natural transformation is very ugly.
Yeah, dijon seems very similar indeed. rapture.io is bloated. 
Have you done any benchmarking against Jackson and other JSON libraries?
Actually, yes. I forked an existing performance comparison repository and executed the tests. Results can be found from here: https://github.com/milankinen/json-scala-parsing-performance-tests
Easy to use and fast is a good combo...
Was [jawn](https://github.com/non/jawn) considered as a backend for parsing? It seems to have pretty nice performance characteristics
Do you mean adding the jar files to the build path? I did that. I had import akka.actor._ at the top of the code.The error for that line left, but I still got an error when deckaring a variable of type ActorRef.
I might be able to help with this question. I've made a large production apps in play and scalatra+angular and I've been playing with spray. If you give up play you lose a lot of the templating (unless you mix it back in via a sbt plugin). There are also more add-on frameworks built around play. However, if you are writing your frontend as an angular app which is making ONLY (or nearly only) REST calls to your backend server, I bet you'll like spray. It is cleaner than play, and smaller (no mountain of netty underneath). Also very nice interop with akka.
I had same dilemma in the past and went with Spray because Play was too heavy for me. My simple app didn't even fit into Heroku slug. Plus now Spray became part of Akka (called akka-http). As punkgeek said you can still use Play templating engine via sbt-twirl plugin. It works with Scala 2.11 as well.
I completely agree with /u/punkgeek -- if your angular app is going to be making mostly REST calls you're better off using a more lightweight framework. However I would suggest [Scalatra](http://www.scalatra.org/) over Spray -- Scalatra isn't as lightweight as Spray but it does provide some really useful services so you don't have to reinvent the wheel such as [authentication management](http://www.scalatra.org/2.3/guides/http/authentication.html), [integration with json4s](http://www.scalatra.org/2.2/guides/formats/json.html) for easy marshaling to/from case classes to JSON, templating via [scalate](http://www.scalatra.org/2.3/guides/views/scalate.html), and easy deployment either standalone(using an embedded jetty server) or with Heroku, etc. Also supports [akka](http://www.scalatra.org/2.3/guides/async/akka.html)! I'm currently building an app using Scalatra + Angular and, other than some routing annoyances, it's been a joy to work with.
Thanks for posting this. I have updated the front page with a link to the video recording of my presentation last week at the Scala Exchange in London.
Did you mean `val`s? Can you give a concrete example?
Thanks for all the hard work! 
How does it compare with IntelliJ with the Scala plug-in?
So many exciting things are happening in the Scala ecosystem, I'm very happy to be part of it!
Fuck sign-ups. Add the following to the source of any page of https://skillsmatter.com/: &lt;iframe allowfullscreen="" data-progress="true" frameborder="0" height="390" id="vimeo-player" mozallowfullscreen="" src="//player.vimeo.com/video/114652174?api=1&amp;amp;title=0" webkitallowfullscreen="" width="640"&gt;&lt;/iframe&gt;
Meh, the excitement passed after 2.10; then the roadmap turned to molasses. We've got a long wait before even 2.12 (1 year), 2.13 with new collections is 2 1/2 years away, and 2.14 (AKA Dotty, Don Giovani, Scala 3) is fully 4 years away. Perhaps Akka, Play, Scala Meta and other projects will evolve in the meantime, but the language itself will be fairly static for the near term, despite the warts... 
I am pretty excited about the Dotty project. A few years will pass very fast, but this is the stage where decisions are made and ideas presented, such as the AST persistence.
Fuck sign-ups even more! http://youtu.be/UFW791AKhDE
&gt;[**The Binary Compatibility Challenge [0:00]**](http://youtu.be/UFW791AKhDE) &gt; [*^benwaffle*](https://www.youtube.com/channel/UC-mQ2YoACdW5zmeC6DGoxhw) ^in ^Science ^&amp; ^Technology &gt;*^0 ^views ^since ^Dec ^2014* [^bot ^info](http://www.reddit.com/r/youtubefactsbot/wiki/index)
Great! Thanks for your work! P.S. a note about the download page: it has some tricky JS that does not always work:( http://scala-ide.org/download/sdk.html I had to read the JS source of the page, extract the prefix/suffix and concatenate them to get a valid URL. I'm using some browser plugins though, but most of the web sites are okay with them.
Can someone summarize the main point of the video. I couldn't be bothered to sign up.
TL;DR The feasibility of embedding typed trees as compile-time annotations to allow on-demand recompilation of third party libraries
Not everyone can update compilers every time a release happens. 
Once a language gains enough traction and users it has to slow down. It's a good sign :) Innovation in libraries and other addons and tools promotes stability without hampering progress. 
Well again with skillsmatter videos even after signing up I still can't see the top-secret video because of "privacy settings don't allow it to be played here". Linux/Firefox. Maybe I don't have the right plugin (Flash?).
Can't apply for the job, but damn that's cool!! Another reason to like 3dr, you guys do good work! :)
Can't wait to hear or see some more about the work you're doing with Scala specifically.
Sure - we use scala in both server and client code. For instance this webapp: www.droneshare.com is an AngularJS frontend talking to a scalatra+akka server. One of our GCS clients is almost entirely scala [github here](https://github.com/geeksville/arduleader/).
Rain check?
Any possibility for remote work?
I really enjoyed this presentation. Leif did a lot of legwork testing out all these tools. Definitely worth watching.
Ahh, this would explain TypeSafe giving away one of your drones over the summer. http://typesafe.com/blog/go-reactive-activator-contest-scala-days-edition
Likewise, I'm only pointing out that while Dotty is 4 years away, Haskell, OCaml, F#, C#, and heck, even Java, will evolve significantly during the same period. Meanwhile, Dotty in the end is just righting the ship; there's nothing revolutionary in the works in terms of new features. What we'll get is faster compilation, better tooling, type inference, and fewer corner cases/warts to deal with -- all wonderously welcome, but 4 years is a long wait.
Unification of type constructor parameters and type members as well as the introduction of union types is far more than "better tooling, better type inference". http://www.cs.uwm.edu/~boyland/fool2012/papers/fool2012_submission_3.pdf That's far more revolutionary than Java adopting closures sixty years after they were invented.
Other than the introduction of union types (which Ceylon, for example, has had from day 1), the unification of type constructor parameters and type members will lead to exactly this: better tooling, better type inference ;-) There's a reason the core Scalaz devs took to Twitter after the Dotty project was announced; in some ways Dotty will *reduce* functionality of current day Scala. Anyway, I'd love to see practical improvements like a right biased Either, or Zeiger's comprehensive comprehensions proposal make their way into the language, but Scala has to tow around its legacy, the price of success I guess.
&gt; which Ceylon, for example, has had from day 1 Only that Ceylon is the real kitchen sink product. Give me a break, there is no research or even document that explains why its type system is anywhere near sound. Of course, you can trust Gavin King that he put the nails into the right place, I personally prefer that people do actual academic (yes) CS research before they implement these things.
&gt; Anyway, I'd love to see practical improvements like a right biased Either, or Zeiger's comprehensive comprehensions proposal make their way into the language, but Scala has to tow around its legacy, the price of success I guess. Scala isn't towing around any legacy, as evidenced by all the work cited that's under way. Just because they aren't working on what you want them to, doesn't mean they've stopped innovating.
wow! That's an amazing coincidence. I should send them a note!
Possibly, but it would be a little trickier...
Sure it is, they cannot bias Either since it will break existing code; that is the very definition of towing around legacy. The for comprehension issue may not be important to everyone, but for anyone using Slick it is, what a hideous mess, aggregation nightmare with groupBy/sortBy/count/sum and friends ;-)
Paul, there is a lot of literature from journal paper to PhD thesis. I think this is a fundamental and qualitative difference to for example https://github.com/ceylon/ceylon-spec/issues. Your opinion on the state of Scala is well known. 
Either is a class in a library. Change it for whatever you like. It will be made superfluous precisely when union types are in place.
A lot of literature, which buys you as much correctness as does the spec. You're the one who brought up language soundness: there are dozens of examples of unsoundness in scala's type system. Can you offer as many in ceylon's? But sure, let's pick on ceylon because they don't offer a document full of "lies and wishful thinking" as someone else put it recently. Very classy and truth-seeking to dismiss these facts since "my opinion is well-known". You prefer your beacon of correctness to be unfalsifiable, so keep pushing those goal posts around and protect that investment.
A spec which is known to br wrong is a better state than having no spec; at least it means someone somewhere has thought about it. Similarly for type system soundness. I'd classify the state of many other languages as "not even wrong". There isnt any idea what things should do except a short list of contrived examples. Nobody has thought about feature interactions or edge cases. (Most of Scala falls under the former group, though SBT falls under the latter)
https://github.com/leifwickland/static-analysis-skeleton https://github.com/puffnfresh/wartremover http://stackoverflow.com/questions/22617713/current-state-of-static-analysis-tools-in-scala http://stackoverflow.com/questions/9516943/is-there-a-coding-standards-enforcement-tool-for-scala 
Ugh, sorry. This kind of thing makes me crazy and it makes people give up on Scala. So, perhaps try the instructions for creating an app with just sbt here https://www.playframework.com/documentation/2.3.x/NewApplication (scroll down) or maybe try the "Offline" download on the Downloads page (which one would assumes includes the entire internet). As for installing sbt I recommend ignoring the instructions on the website and using https://github.com/paulp/sbt-extras instead. It is unfortunate that the official instructions for basically everything associated with Scala are wrong. We're trying to improve this but are not doing a very good job so far. 
http://pastebin.com/8ESu3iPK I tried increasing the timeout and this happened.. I doubt it's correctly created the app though right..? All those errors don't look good..
OK, so that exception means that somewhere Java is making an HTTPS request that is failing because the JVM does not trust the SSL cert being presented. Make sure you add a self-signed cert to your JVM's cacerts file. You want to import a signed primary certificate or a CA cert: https://www.sslshopper.com/article-most-common-java-keytool-keystore-commands.html
Can you give me a bit more information on how to do this? I feel like i'm doing it wrong.
I went last year and it was great. Highly recommended.
nice talk, t.y. for sharing.
&gt; A spec which is known to br wrong is a better state than having no spec That's not clear at all. I don't agree with it, but it's way into the realm of opinion regardless of one's position on it. &gt; I'd classify the state of many other languages as "not even wrong". There's no bar so low that many other languages won't come underneath it.
Scala is faster than Go?
IMHO it's a weakness if you want to whip something up (which is, IMO, something where python excels), if you want to make something sustainable it's great.
Maybe I'm missing something, but the author doesn't really make an argument for why the cake pattern is bad beyond emphatically asserting that it is terrible and linking to one article that is tangentially related to some warts that may arise in the cake pattern. There isn't even a comparison of what his code would look like using the cake pattern so it is hard to tell if it makes things better or worse...
I could not find a good summary about why it is considered harmful by some, and I did not had the patience to explain it in great detail hoping for readers to know about the issue. You can find more information by googling for the "Bakery of Doom", the issue is when path-dependent type comes into play and you have to put everything in the cake then to do anything. What I present in the blog is very simple, just the "traditional" way of linking stuff (but using implicits) the only twist is the at the last layer with trait stacking. Maybe if you explain how you are dealing with such problems today I could extrapolate and tell you if you could benefit from anything in that post. Cheers!
Both of those languages are in the same speed category. Which one will be faster depends on multiple factors. Also, both have garbage collection which can be avoided by careful object allocation and avoiding certain library features.
we should be able to use JQuery or other JS wrappers in Scala, or else Scala is of no use on the web.
There's nothing wrong here, an idle dispatcher when having not received any messages after a period of time(default can be looked up in reference.conf) will shutdown(because there are no messages to dispatch to actors. why keep them running?).
How are you creating your actors? It's possible you aren't creating multiple dispatchers, but without seeing code, we don't know.
I just rerun SBT eclipse and refresh the project. Seems to work. I find the intellij SBT support nicer however 
Thanks for your answer!
This comes from a someone who delivers production enterprise code daily and in several different languages... The Scala community is vibrant and its use continues to grow but measuring that growth is complicated. Fewer questions posted online are a function of it's similarity with Java. If you know how to do something in standard Java you know how to do it in scala even better. Ther is often little point posting a question that is Scala specific except in the more FP specific areas and let's face it FP is relatively straight forward after some initial learning curve issues. A better place to look for activity in the scala space is around SBT and other tool chain areas. You'll see a fair amount of activity because it's still a pain point and evolving. Other indications are areas where Scala is being used that is indicative are the development of Spark, and other Apache projects just as examples. Here is the more important point to be made. Your are more likely to have to learn many languages today then ever before. Here is a list and learn them well... Java, Scala, Haskell, C#, JavaScript, C to name just a few. Polyglot ism is the new norm. The more the better, it separates out the mere code monkey from the professional software engineer.
I managed to get maven to work with Scala IDE (Eclipse) and it was a major hassle, you need to get an archetype that builds with your version of scala and make sure to only include dependencies from your version otherwise you will run into cross compile issues (or you can just play around with the pom.xml to get the above which is what I did). 
Baw. Not actually an alternative to TeX. Unless someone knows of a good HTML → PDF converter?
This looks more akin to Twirl than to Markdown; Markdown abstracts away all HTML in favour ASCII-markup. This project on the other hand seems very deliberate in letting the user specify exactly the result they want, go with a predefined abstraction like the `sect`-example, or create their own. I think it looks pretty neat actually. It looks more of a marriage between plaintext and [XML-]transforms than a templating language.
youtube/mediagoblin anyone?
Yes, looks like a (much) better version of Twirl templates.
I'll be honest, and say that open-in-chrome Cmd-P has been by go-to technique for HTML to PDF conversion...
Added a few paragraphs about [Why Scalatex](http://lihaoyi.github.io/Scalatex/#WhyScalatex)
Turns out I botched the readme; the correct SBT plugin snippet is ``` addSbtPlugin("com.lihaoyi" % "scalatex-sbt-plugin" % "0.1.0") ``` If anyone tried it and it didn't work, please try again sorry!
Thanks :) So in its current shape it is Not a replacement for Twirl due to missing external parameterization of templates if I understand things correctly. Is this something that is planned for the future?
If someone wants it, then sure. My current plans are to use it to replace all my hand-crafted `readme.md` files, so I can stop worrying about having broken links or stale TOCs =P One step at a time
Thanks for the write-up!
heh, yes, unfortunate that option is when you're tasked with protecting the site owner's content o_O, it's the wild west out "there" ;-)
Why call this Scalatex when it has nothing to do with TeX? If this is the case, then the name is just plain misleading.
lol the funny guy trying to pimp rust...
Great work. As spurious_interrupt wrote, the name "Scalatex" is misleading. Maybe you could use "Scalatext" instead; your document already mentions it once.
&gt; Scala is a language with a very sophisticated type system. It is even said to be the "poor-man's prolog". ... which seems to imply that Prolog has an even more sophisticated type system than Scala... 
I saw you [tweeted](https://twitter.com/li_haoyi/status/549610173417807873) about [Scalite](https://github.com/lihaoyi/Scalite#scalite). That looks great as well. Will you start a Reddit topic on Scalite?
The first version is doing extra work so it's not very surprising: it is first creating the zipped collection and then iterating once more as it sums the items. For better performance you can use a fold or, better yet, a recursive method: def dotProduct(first: Array[Double], second: Array[Int]): Double = { require(first.size == second.size) @tailrec def recurse(i: Int, sum: Double): Double = if (i &lt; first.size) recurse(i + 1, sum + first(i) * second(i)) else sum recurse(0, 0) } 
Wow, thanks i knew it was because of zipping i just didn't know any other way to do it.The tailrec solution is awesome I'm still learning scala but you helped me a lot :)
Happy to help, enjoy your learning experience :)
What happens if you say `first.view zip second`?
For small arrays the tailrec is a lot faster at arrays around 1000-2000 it's the same as imperative 
You can start one if you really want =P
Half full or half empty? 5x slower than imperative Java/Scala often means 10x faster than imperative Python and maybe 3x faster than imperative Javascript. Given how much work my company gets done in Python, be sure the slowdown actually matters before spending effort optimizing =P
&gt; Well .view certainly helped but it's still around 4x slower than the others.Not exactly sure what view does in this case? Does it create the zip tuples lazily? Yes, view makes your collection operations lazy. A good way to think about collections performance is that any transformation done on a concrete class (like something more specific than an iterator) will manifest a new collection, even if you are only using it transiently/via chaining. So either use a view, use an iterator, or be mindful. It's a subtle thing but now you know!!
Yeah I agree but for me this and another tweek reduced my data load time from 13 hours to 1.5 :-) 
Thanks this kind of subtle insight I always lag when learning a new language :-) always glad to hear 
Ah ok =) makes sense then 
It does special hashing on a large data set :-)
Did you find anything related on this? 
I wish someone could post it on a no sign up site 
Scala is always about making it compile. Way less time spent on tracing some subtle bug due to share mutable state, way more time on "how do I make this stupid method compile".. when it compiles, it tends to work right ;)
How are you microbenchmarking? using caliper or similar? It is super hard to benchmark on the JVM correctly.
I'm not sure I'm quite over the gap yet but what's brought me this far is probably unhealthy levels of enthusiasm coupled with trial-and-error. Truth be told it took a while, but we started out on different terms. I started learning Scala the same week I started learning C-sharp for a new employment some 3.5 years ago. Digging into the now a bit dated second edition of [Programming in Scala](http://www.amazon.co.uk/Programming-Scala-Martin-Odersky/dp/0981531644) was for me a timely decision as my hobby helped me in my professional work. Scala and modern C-sharp have some similarities in that they use high level abstractions to process collections. Things like map, flatMap, filter (Select, SelectMany and Where in C#) are commonplace and the times I reach for foreach, let alone a lowly for-loop, are easily counted. There are some details that differ in how collections are handled: .NET has them lazy by default and everything end up an IEnumerable&lt;OfSomeType&gt; whereas Scala is mostly eager. Both variants have pros and cons but I must say I prefer .NET here, it feels like the "more functional" way of doing things and also interestingly enough the way Java 8 has decided to do it. A lot of people like to argue about this, which is a good thing as it means we'll see development in both aspects. ___ Anyway, the message that I am trying to convey is that you need to know *how* it works, and *why* it works, before you can understand why it's slow. That Scala runs on the JVM by default doesn't mean its constructs are equal, no matter how similar they may seem. Scala's for-comprehensions, for example, are not analogous to a vanilla Java `for` or even foreach. Rather, they are literally a way of expressing `flatMap`, `map` and `filter` in a more linear fashion. They are functional and carry an overhead I'll agree with both the enthusiasts and the pessimists and say that Scala gives you more than enough rope to shoot you in your foot. Maybe unfortunately so as we are much more likely to screw up spectacularly while transitioning from one language to a seemingly similar language, as we are a couple of years down the road. ___ To round off, getting over the gap is as much about taking in as it is about letting go. It **is** an investment in spare time: a worthwhile investment in my experience. Finally a few tips: * Use the REPL to explore snippets of code; * Use worksheets in either IntelliJ or Scala IDE to explore slightly longer pieces of code, unless you're comfortable with copy/pasta; * Try to get a good grasp of Scala's type system; learn to love higher kinded types; * Do not be afraid of implicits; * Daniel Westheide wrote [an excellent guide to Scala](http://danielwestheide.com/scala/neophytes.html). It is quite brief; there's also * [Twitter's Scala school](https://twitter.github.io/scala_school), used internally I imagine. It might be coloured by how Twitter uses Scala; * Look/ask on [StackOverflow](http://stackoverflow.com/questions/tagged/scala) if you have concrete problems; it helps the knowledge base grow and be accessible in a beautiful way; * [Google the heck out of everything](https://www.google.se/#q=scala+what+are+higher+kinded+types) Sorry for the rant! addendum: Yes! I feel I am more productive in Scala compared to both Java and C#, even for bigger projects. The ability to try ideas and flesh out code is much faster once you get used to how the type inference works (and doesn't work in some instances)
Reading The Little schemer will do wonders in your understanding of recursive functions and higher ordered functions. 
I just wish it wasn't so complicated to include scalajs into, say, a Play framework project.
Ok thanks I'll add it to the list :-) 
To be honest I saw caliper at around 1 am but was to tired to try. So I just timed and averaged multiple runs. Do you recommend it? For profiling I used jprofiler it had a few day trial. 
Nice solution thanks , 2 quick questions regarding &gt;first.view.zip(second).map { case (a, b) ⇒ a * b}.sum 1. In that line does the map do some typecast that's why the "case" is needed? 2. Is there any reason particular reason you used Seq ? Sorry for the stupid questions :)
using case allows you to pattern match on the tuple(since zip produces a list of tuples). behind the scenes it's using a partial function that is only defined at Tuple2. essentially, if prevents you from having to unpack it manually: col1.zip.col2.map { tup =&gt; val (a, b) = tup a*b } You could do something like tup =&gt; tup._1 * tup._2 it's just kinda ugly.
profiling distorts your results. you cannot do it at the same time as a benchmark. Caliper is good, yes you should use it to compare the 2 things.
I only did the profiling to find the function that is the most time consuming the benchmarking was done at different runs, thanks.
Risk is if you have some functions called a lot for a short time, and others called a few times for a long time per call.. profile will distort your "bottleneck" to be the many short call functions, even if they are indeed short... think of adding a constant overhead of 1ms to a method call, which method will appear slowest?
For this kind of situation, I usually go full-java-mode and rewrite everything in while-loops and arrays and mutable state. FP be damned, I want my 5x speedup =P e.g. [This kind of code](https://github.com/lihaoyi/scalatags/blob/master/js/shared/main/scala/scalatags/Text.scala#L141-L173) which actually did give a 5x speedup over it's super-elegant map-flatmap-blah predecessor
More specifically, if it's done on a strict collection, it'll result in a whole new collection being computed. Most collections are strict, but views and iterators aren't.
Yes. That should have skipped the costly part of your computation. I wonder why it wasn't enough... I'm also curious as to whether 2.12 will do any better. IIRC, it will implement lambdas like Java 8 does, hopefully improving performance.
That flexibility is why I love Scala. Python enthusiasts often say that they can write in high level Python initially and drop down to C when needed. Why bother thinking in two languages when you can do it in one? I write in high level functional Scala first, test everything to make sure my logic is sound, then rewrite in low level Java-style where needed.
1. While rco's explanation is correction I would rather say it is a short form of the following pattern match, which may feel more intuitive: `map( _ match { case (a,b) =&gt; a*b } )` Eventually though, you should learn what partial functions are and how they apply here. 2. I used sequence because we do not modify the arguments and `Seq` is immutable. If you do not use immutable data structures then there needs to be reason for that. Immutable data is the default. And actually there is a small error in the `dotProduct2` function, because here an `IndexedSeq` is required, as we use specific indices of the lists. It could have been the case that `a` and `b` have `O(n)` index access, which would've been really bad. (But it isn't; they are actually indexed) 
Another [nice project](http://www.reddit.com/r/scala/comments/2qmuur/scalatex_typesafe_programmable_documents/) by lihaoyi. A suggestion: to get rid of most of the remaining parentheses you could support a comma as separator between method name and the first parameter. E.g., println, "Hello" 
Comma makes it feel like " println and string literal 'Hello' ", maybe any other not-so-commonplace-special-character without semantic meaning would be better.
Sounds cool (just thought I'd mention that considering the lack of comments ☺).
+1 on this. I had already written some nontrivial Haskell and was using Scala (and recently Scalaz) at work and in my free time. But so far FP in Scala's exercises have really been honing my understanding. It doesn't pull any punches either.
It's worth noting that this: first.view.zip(second).map { case (a, b) ⇒ a * b}.sum Should be equivalent to this: (for { (a, b) &lt;- first.view.zip(second) } yield a * b).sum That is, you were already doing the pattern match implicitly in the way you constructed your `for` generator.
&gt; in NYC *sigh*
I've bumped into this problem too. I haven't found a good solution to wrapping `[]`s and `()`; for now this only gets rid of `{}`s ^_^
Hi Molly, I notice the opening is for a senior developer. How many years experience are you looking for?
Remote work possible?
Came here to say that. My theory is that he has multiple personalities, each responsible for one cool project, and they successively take over his body every 6 hours, allowing the others to rest. 
Look up Scala Koans (on my phone, can't link).
On the one hand I think everyone could get used to this new asymmetric use of the comma. On the other hand it would be better if there would be no need at all to get used to it. Maybe the colon could get this additional use: println: "Hello" I would prefer this over the comma, and I think there would not need to be a severe collision with the colon as an operator symbol, if the colon would be required to immediately follow the method name.
To add few more points about our work at GettyImages. Our utopian dream is to have a central Source of record system for hosting all image, video and audio information, which is what we are developing. Since we receive updates from various systems (internal and external) we use event sourcing and to guarantee message ordering we use akka cluster singleton / sharding. Our video processing service, our http layer (spray http) and our message orchestration/business logic service are all in scala. We use micro services architecture, so that helps in rapid development. All our new systems that we are building are all in scala and we have been using scala for over a year and half now. Just as FYI, we are currently investigating/prototyping image analysis techniques for face detection, recognition, auto key wording based on content of the image and few other automated analysis all in scala too. So lots of things to go around if anyone is interested.
hey ninja_coder, I just added a new comment about how and where scala is used in our system, hope that helps.. :) http://www.reddit.com/r/scala/comments/2qus05/scala_enthusiast_check_out_the_team_at_getty/cnad84f
awesome!
Nice work, but sweeet baby jesus, why? When the great typographic demiurge has blessed us with brackets?
Here is the link to [Scala Koans](http://www.scalakoans.org/). This looks quite interesting and the timing is perfect as I am bringing other developers to Scala right now. Thanks for the tip!
Its like if Python and Scala and a deformed baby
here you go: [scala-wallpaper](https://github.com/OlegIlyenko/scala-icon/blob/master/scala-wallpaper.jpg)
Why not just make your brackets look prettier?
It seems to imply that you don't need a mainframe to use Scala
Is there any chance of this supporting a more xml-based "JSX" style templating? I like the library, but I've never been fond of these kind of abstractions around HTML - I'm much faster working in native HTML directly, and it's a lot easier to migrate frameworks in future if needed.
[made just for you](http://imgur.com/5mEm2CN) Edit: I'll setup paypal for donations later
The scala community is lucky to have lihaoyi among us. On another note he makes me feel guilty about my laziness and procrastination, but thats ok because I think it's beginning to be motivating. :D
Seconded. The authors are into for real, so there's no handwaving or cutting corners.
Maybe you can make fetish clothing with it.
I use Lift and all I needed was a bit of asset management in SBT. If I didn't use Lift, I'd use Scalatra. I don't know much about Play, sorry.
You mean the CSV allows commas within the comma-separated fields? Are they escaped or something?
Unless your goal is to write a cvs parser, use a library. For instance, http://commons.apache.org/proper/commons-csv/
&gt;Wouldn't finding a host and installing the JVM on it be harder than just deploying a simple binary file with the front-end? What does this even mean? &gt;As I've heard learning scala is one of the hardest jobs for a programmer :/ Scala is a complex language. It's not particularly hard though. If you want to learn scala, you should. But there's nothing about your project that would make scala any better or worse than anything else. Depending on what exactly your "mathematical equations" are, you might just try python and numpy.
Scala is very good with both JSON and MongoDB, the JVM is a trivial install these days. Scala is not hard in general if you've already got functional programming under your belt. Scala is arguably a stronger functional language than Go.
I don't do a lot with math functions in my programs but afaik this is the best library out there: https://github.com/non/spire. Yeah I guess it's technically "harder" to have to deploy a jvm than a simple binary but it isn't like it's rocket science or takes more than 2 minutes. Once you have your program done just package it up with [this](https://github.com/sbt/sbt-native-packager) and as long as they have a jre installed you just run it. You're probably going to spend a good amount of time learning scala for what I'm not sure is that much benefit; plus you'll be introducing a completely new language / platform into your job that nobody else is familiar with. As for json and db stuff there are excellant libraries (scala4j and slick/anorm respectively). edit: derp json4s not scala4j
For formulae, check out scala spire. I don't know if it will help you at all without knowing more of your project, but the examples there might help. For JSON, check out argonaut. There are a lot of choices, but this one should save you some steps. if you're working with existing JSON. If you are planning on simply serializing and deserializing your data internally, there are macro based libraries that can completely automate it in (most cases) - check out Pickle project or uPickle. As far as Mongo, take a look at Slick. I don't know specifically what your complaint about the type system is (Regarding your past experience), but if you are de-serializing Very Large Numbers with Argonaut, in order to write them to a DB, that should be easy enough. If your number exists in some other serialized form, such as a CSV file, or user input, or something else, then maybe Parboiled2 would be a good option. I can say that with the type system, it's a whole lot easier to guarantee that you have accounted for bad input than without it. As far as the calculations themselves, scala is literally named for being a "Scalable Language". You can make the language you want to work with for the type of problem you have. And finally, because it's most likely that for any specific project, one or more of my recommended libs is wrong for your project, here's a [very big list](https://github.com/lauris/awesome-scala) which includes everything I mentioned and more. I'd be interested to know more about what you're doing with numbers, and what you find as solutions.
Whoa, that library for JSON seems so natural, even more natural than Go, I could say! My complaint about the type system was for Go language, I do not know how the Scala type system is, but I could tell it is good from all those libraries. But to be honest, I could say that I just got bored of using Go and just want something new. That list is just.. I don't know. I mean, it has everything I could think possibly think of, from HTTP to Databases..etc, thanks man! 
Well go doesn't even have generics so the type system in scala is far superior (imo).
Ah so basically, I have access to every library those Java folks use, right? If so, well, I could say it is useful but I don't know. As you've mentioned, it won't feel natural. :/ As for hating the language for complexity, I guess after learning C++ and spending a good time working on it, I doubt I would hate any language for its complexity, unless Scala pulls a Haskell on me...
Scala is probably not the best choice for number-crunching, straight Java is better. Classic algorithms are all about loops, and with `break`, `continue`, `--` and their friends Java code is more elegant. Though you can write the number-crunching parts in Java and high-level control parts in Scala.
I think Haskell is easier than Scala because it's more streamlined.
For python you can implement the math-intensive parts in [Cython](http://cython.org/), or in [C++](http://en.wikibooks.org/wiki/Python_Programming/Extending_with_C%2B%2B). If you have more than 1K customers concurrently, then you should focus on Scalability, Stability, Ease of Deployment (because you want to update your software, right?) and so on and if you need performance just start a new instance on a different server. And of course implementing math formulas means you need to be correct, and that's something where you can get a lot of help from a good type system. Finding a host is as simple as [this](https://www.leaseweb.com/bare-metal-server).
Loops exist in Scala. Tail recursion can be optimized into a loop, and any loop can be written tail recursively. Using @tailrec you won't really notice any significant slowdowns. You are correct that it may be easier for a novice to reason about a traditional for or while loop, but with a little elbow grease tail recursion becomes natural and reasoning about it becomes easy as well. The lack of a natural break and continue should not be a reason to discredit Scala. 
State is the accumulator argument in a tail recursive function. In trivial cases it could be as simple as two numbers (e.g. index and sum so far if you're summing an array) in other cases it could be a bunch of data structures. &gt; A noticeable advantage of tail recursion is it allows you to preserve immutability, which is a cornerstone of maintainable code. I don't think switching from `x+=1` to `loop(x+1)` will make code more maintainable. 
Functional approach perf analysis: allocate a new array of tuples able to contain first and second (min length) copy to this new tuples array for expression then iterates through this new array and allocates yet another array that holds the result of the a * b operation. Finally, another iteration through the list occurs with the sum operation (I believe this results in yet another array being allocated) This is a LOT of array allocations and memory accessing/modification for maybe 3 pure operations that you could have inlined. The imperative approach just iterates through the list once and does a multiply and add. This literally maps to a single assembly instruction (madd) once the byte code is translated for the native platform. No additional arrays are allocated and memory is touched once, sequentially. MUCH faster. I'm surprised by how often zip is used as shorthand for 'access two items from two lists at once'. I've seen the same thing in Python as well (sum(map(mul, first, second)) or sum(a * b for a, b in zip(first, second))) and it's a bit surprising how inefficient the result is despite it being succinct and obvious. Is there a list of Functional Programming antipatterns like these somewhere? When you're learning it's really not obvious doing it this way is so bad for performance.
The hard part about Haskell IMO is the syntax. It's just really hard to get used to
It helps you with dimensional analysis. If you implement physics formulas, for example, you get it for free. An angle is in radians represented by a double, but while in Java you would have to box-unbox it all the time in Scala you get it with primitive types because the compiler does that for you.
Well, yeah, it's kinda more convenient not to have all those `double` and `Double` and `int` and `Integer` around but I don't think it has anything to do with correctness. I don't really understand what "dimensional analysis" means. If you mean ensuring that everything is measured in proper units (something like `def force(mass: Kg, accel: MS2): N = mass * accel`) that would be pretty awesome but I haven't seen this kind of type checking implemented
This was originally a slide in a presentation of mine, which goes to show many of Scala's features: https://plus.google.com/103744906976128830230/posts/6M8DsKgdQ8y?pid=6100780037159514370&amp;oid=103744906976128830230 Could be used as a desktop wallpaper.
The exercises in *Scala for the Impatient* are very good especially at the beginner/intermediate level, and provide a nice overview of not only FP basics but the standard Scala library. I would suggest buying yourself a full copy of the book and working through these exercises to fill in the gaps around what the FP-oriented Scala books will give you. Personally (FWIW), I had taken the Coursera Scala FP course twice before I got around to doing the exercises in *Scala for the Impatient* and felt that the exercises did help round out my knowledge of the core language.
There are a fair number Scala libraries too, as others have pointed out. I'm just saying that worst case you might end up with some code that looks more like Java. Some Java libraries will seem perfectly natural. Some may feel more imperative than you'd prefer. Some will use Design Patters that look silly in Scala, like using a Builder to make up for lack of named arguments in Java.
http://matheusdev.tumblr.com/post/60350025622/scala-units-of-measure-with-value-classes http://www.squants.com/ Scala is awesome (check [value classes (SIP-15)](http://docs.scala-lang.org/sips/completed/value-classes.html)) ; )
great to see this project is still going
I couldn't run the binary on Linux, so I did the following: $ mkdir -p src/main/scala $ mkdir -p src/main/resources $ mv src/ucesoft src/main/scala/ $ mv resources src/main/resources/ $ mv roms src/main/resources/ And added this `build.sbt` file: scalaVersion := "2.11.4" lazy val enc = Seq("-encoding", "ISO-8859-1") scalacOptions ++= enc javacOptions ++= enc javaOptions in run += "-Djava.library.path=lib" mainClass in (Compile, run) := Some("ucesoft.c64.C64") fork in run := true Then `sbt run` succeeded. There is another issue on Linux that the audio line in doesn't support volume, so I had to change `DefaultAudioDriver.scala` as follows: private[this] val volume : FloatControl = if (dataLine == null) null else try { dataLine.getControl(FloatControl.Type.MASTER_GAIN).asInstanceOf[FloatControl] } catch { case _ =&gt; null } def setMasterVolume(v:Int) { if (volume != null) { val max = volume.getMaximum val min = volume.getMinimum / 2f volume.setValue((v / 100.0f) * (max - min) + min)//-10.0f + 0.1f * v) } vol = v } I could load my favourite game back then, Giana Sisters, but somehow the joystick emulation with keyboard didn't work, so I could get as far as seeing the first level and hear the music :) __EDIT__: In `ControlPort.scala` for laptops that don't have keypad section of the keyboard: private def getKeyMask(e:KeyEvent) = { import KeyEvent._ e.getKeyCode match { case VK_NUMPAD8 | VK_W | VK_UP =&gt; 1 // up case VK_NUMPAD2 | VK_S | VK_DOWN =&gt; 2 // down case VK_NUMPAD4 | VK_A | VK_LEFT =&gt; 4 // left case VK_NUMPAD6 | VK_D | VK_RIGHT =&gt; 8 // right case VK_NUMPAD9 =&gt; 9 // up+right case VK_NUMPAD3 =&gt; 10// down+right case VK_NUMPAD7 =&gt; 5 // up+left case VK_NUMPAD1 =&gt; 6 // down+left case VK_NUMPAD0 | VK_CONTROL =&gt; 16 // fire case _ =&gt; 0 } } Now stuck with Katakis L:-O
This is awesome! I love seeing Scala employed in alternative sectors like this.
As of Java 8 you even get support for bundling everything together, instead of doing it on your own, aka fat jar. http://docs.oracle.com/javase/8/docs/technotes/guides/deploy/self-contained-packaging.html#BCGIBBCI
Ouch, one can see _windows_ binaries included in the repo..:( https://github.com/abbruzze/kernal64/tree/master/Kernal64/lib
Agreed, a collection of HList is a pretty much a Table structure already.
Why use paypal, bitcoin is much better. Have a coffee on me :-) /u/changetip
Very interesting project. It's a shame that I couldn't find the documentation. For example, In the online demo there is an `@induct` annotation, which I assume that forces Leon to use inductive proofs and avoid some problems with recursion, but I can't find any reference to it. Are there other annotations like this?
It's unclear if this author knows Akka has typed actor references, and the fact that Akka actors are a FSM has little to with the type safety problems of receive. EDIT: Akka's typesafety problems begin and end with the mutable actor system hierarchy the actors are deployed to. If akka's actor system was immutable, such that actor addressing could be type checked the type of messages an actor can receive could be type checked as well. 
How would it know? Note that we are dealing with `MbArray` here not a native Java `Array`, and as far as I know `length` (even if declared as `val`) is never a field in the byte-code.
Yes, as length is an abstract method it can be problem if Hotspot can't inline the concrete implementation. Length should really be a val in the MbArray class as it's constant.
~~No it doesn't, typed actors don't have a become() method.~~ EDIT: You weren't refering to typed actors. become() doesn't have much to do with it either. It's because making assumptions about a type of an actor is making an assumption about it's state.
Who, of all the users of akka, has seen `become` causing actual havoc? Who, of all the users of akka, has used `become` for great good? Many type system debates end up being about theoretical issues that *may* happen, but don't in practice. Edit: It's clear that `become` is a giant hammer that you shouldn't use for small nails -- but it seems super useful for runtime-reconfiguration of actor systems for instance.. Edit2: It's also clear (or should be) that actors ARE state and therefore need to be treated with care. See this `malloc` implementation in erlang: the `malloc` function is just a `spawn` https://gist.github.com/kaeluka/2cf8cab07c459d39af40
I'm curious: if an actor wanted to change its behavior at runtime, couldn't it just spawn children with the different behavior and forward its messages to the appropriate child at runtime? Why break type safety over this feature? And, yes, unfortunately I've seen many people abuse 'become'. We all know using Scala and its ecosystem is mainly an exercise in restraint. Unfortunately, most teams - most developers - don't have it.
I'm pretty inexperienced with Akka, but I've been pretty happy with some of the state machine behavior that `become()` helps with, as well as the more recursive flow that results. However, I have run into the runtime roulette that is involved as well, and to be honest, it brought back some PTSD from when I had to use Ruby for work. I should probably use Typed Actors and the FSM module, but I just haven't had the time to explore them in detail. 
&gt; I'm curious: if an actor wanted to change its behavior at runtime, couldn't it just spawn children with the different behavior and forward its messages to the appropriate child at runtime? Performance primarily. Overhead of an additional actor, plus possible context switching as the message is being passed. You also then have to make sure you're done with the existing actor and its messages before you switch to the new actor, otherwise you essentially introduce a race condition.
Akka's testkit is also robust enough to help you test any issues with message handling. They also provide the FSM trait if you're using significant amounts of become(), so you can properly test handling in specific states.
Mmmh... Unless the applicant happens to live in the same country as this company (which is not disclosed, neither is the name of the company, two big red flags right there), such a position is guaranteed to be illegal from both a labor and tax law perspective. The compensation terms are also very vague, you get 100% of the money you asked for if the project completes, but there's plenty of ways to work around this kind of vague phrasing. 
&gt;he Akka receive method is typed that weakly because the abstraction has to be able to hold over the network (where we lose types and have no walled garden) So we can agree it's less good than SOAP though, eh?
&gt;He writes the whole article like he's not in control of his own code, He may not be? Have you ever worked on a team? This sounds like an argument for dynamic languages by a guy who only works on tiny projects by himsefl? 
Why do you need tests to avoid mindless errors? The compiler should take care of at least some of those for you. That's his complaint, and it's valid.
Yes, if typing guarantees are your sole concern and you want RPC then SOAP does achieve this somewhat. SOAP achieves this at a horrific cost though. Trade-offs and all. Edit: Honestly though if we're talking some generic "better" I would consider building something with Thrift (or something similar) "better". I know it's not a huge difference in some ways, but it's hard to form a sentence with SOAP being better than anything without getting a sick feeling. 
The best thing I could find to exist is the "An Overview of the Leon Veriﬁcation System" paper on the website. Documentation would definitely be nice, though.
When I searched a solution for the same problem, I found that webjars is something like most common way to do this. But when I've spent few days to integrate webjars into my workflow, at the end I finally decided to throw away an idea to manage frontend dependencies with sbt. Main reason is inflexibility. It allows you to rapid install some libraries, but become pain when you want to customize these libraries, for example include only specific parts of bootstrap. As well as I think modern frontend development has very strong, well-suit tools for building and dependency-management and the only thing I can advice you is to split your frontend and backend development process. It's different areas, different tasks with different tools. Webjars are still pretty nice if you just want to quick install and check libraries on some experimental project and don't care about output size, performance and customization.
&gt; d. It actually makes your program safer, since if someone sends you a message of a type your actor doesn't know about, it is ignored and logged. .....I think you missed his point. 
&gt; I'm working with very large teams, which is when this stuff starts to break down. Work with better teams. Use some guide lines or do some code reviews. Most of your issues can be prevented with code reviews and tests. &gt; If you want, pretend that Foo is a case object, and then someone later changes it to a case class that takes a parameter. When this change is made, the compiler cant warn you that somewhere else someone that used to be sending a case object Foo is now sending a Foo.type Um, yes it can. Case object will only match case MyCaseObject =&gt; Case class will match either case ExtractClass(param1, ...) =&gt; case msg: ExtractClass =&gt; What the compiler won't catch is actor ! CaseObject actor ! CaseClassBecauseYouAreSendingTheCompanionObject The second one occurs only if you declare something case class Blah() which is deprecated for a reason.
What you're looking for is [sbt-web](https://github.com/sbt/sbt-web/blob/master/README.md).
I'm beginning to wonder if a lot of people commenting have even used akka. When using receive, which is a PartialFunction[Any, Unit], you don't just grab an any and cast it. You pattern match on its type: def receive = { case msg: TypeA =&gt; //do stuff case ExtractTypeB(par1, par2) =&gt; //do stuff } The messages coming in to the actor are type checked. The only place you lose type checking is the interface between two objects. Which is easily type checked through defining the messages your actor handles. object MyActor { object Messages { case class DoThing1(par1: Int, par2: Double) case class DoThing2(par1: String, par2: Option[File]) } } Users of your actors now know which types your actor works on, and passing in any other type will not result in the actor handling it.
I think that's exactly the point: using the network isn't sufficient justification to give up types, is _definitely_ not sufficient justification to give up totality of business logic, and is no reason whatsoever to force the introduction of side-effects.
I would avoid Bower. It's very barebones and they haven't really spec'd how to use Sass/Less with it.
There is a large difference between compile-time and runtime type checks. Compile-time checks are the major benefit (IMHO) of a statically typed language... &gt; It actually makes your program safer, since if someone sends you a message of a type your actor doesn't know about, it is ignored and logged. I want these issues to be compile errors, not log messages.
&gt; I want these issues to be compile errors, not log messages. As others have mentioned, this is a tradeoff due to akka being more than simple actors, and limitations within the JVM (there's also the complexity introduced if you want to handle more than one type of message). Akka's solution to this is providing a robust testkit. For people doing TDD and CI, this is pretty much just another step in building your application. If you really want compile time checking, and don't mind increasing code complexity: object MyActor { sealed trait MyActorMessage def apply()(implicit factory: ActorRefFactory): MyActorWrapper = { new MyActorWrapper(factory actorOf Props(classOf[MyActor])) } } class MyActor extends Actor {} class MyActorWrapper(ref: ActorRef) { def tell(msg: MyActorMessage)(implicit sender: ActorRef): Unit = { ref.tell(msg, sender) } } Now you can only send it messages of a certain type.
 &gt; Just because they've worked on scalaz doesn't make them a good team. Depending on your opinion of scalaz, that could actually make them a bad team. You realize that makes "work with better teams" useless advice, right? "Depending on your opinion..." OK, my opinion is that letting the compiler tell me when I'm wrong is, without exception, preferable to letting the runtime. scalaz is a tool that dramatically helps accomplish that. scalaz-stream does that for networking. scodec does it for serialization. etc. &gt; But code reviews and tests are inadequate amirite? Yes. &gt; Or _gasp_, communicating a contract change to the rest of your team? Which we do... among other ways, _by having incorrect code not compile_.
&gt; Working on scalaz says nothing about them as a _team_. I didn't say it did. You seem to be free-associating a lot. &gt; Depending on your opinion of scalaz (in regards to usage, documentation, tests, examples), you could infer that the team is ineffective, given that it has taken 7 major iterations and numerous bug fixes to provide a usable api of types that works as intended. scalaz's evolution, given the fundamental level of types it addresses and the evolution of the Scala language itself, has been _remarkably_ successful. scalaz 7's primary focus was, in fact, usability, addressing lessons learned from _using_ scalaz 6. &gt; Because of the opinion that testing is inadequate. Yes, that would explain the [ScalaCheck bindings](https://github.com/scalaz/scalaz/tree/series/7.2.x/scalacheck-binding/src/main/scala/scalaz/scalacheck) and the thousands and thousands of [test cases](https://github.com/scalaz/scalaz/tree/series/7.2.x/tests/src/test/scala/scalaz) included in scalaz. We're done here, because I don't waste my time with people who move goal posts and argue in bad faith.
&gt; The point is that you can't "prove" program correctness with a compiler via type checking. This is your fundamental error.
Is there an easy way to check?
Go into your terminal then run `dig scala-sbt.org`, it should show what your DNS server is set to and whether it is resolving the site properly.
&gt; As long as you believe that a compiler will prove your program does what it says it will do with type checking, there's no point in even considering you anything beyond a functional programming academic. Apart from the naked fact that I've never held an academic position and have a career spanning over three decades, that is... &gt; The real behavior of programs isn't in the interaction of types, it's in the logic and state of the program. The logic and state of the program is expressed in the types. &gt; This is especially the case of you have any performance constraints and have to introduce mutability to deal with underlying architecture limitations. It's entirely possible to introduce [mutation in an implementation while maintaining a referentially transparent interface](https://apocalisp.wordpress.com/2011/03/20/towards-an-effect-system-in-scala-part-1/). It's even already in [scalaz](http://docs.typelevel.org/api/scalaz/nightly/index.html#scalaz.effect.STRef), and has been for years. There's even a nice [snippet](https://github.com/tpolecat/tiny-world) showing how ridiculously easy it is to turn stateful, mutating, whatever code into a referentially transparent API. &gt; At the point you can have the compiler check your logic, you have introduced the same behavior as your tests (and most likely a similar syntax!). The problem is testing all cases. ScalaCheck helps, by generating a bunch of random test data. But remember, the key construct in ScalaCheck is [forAll](https://github.com/rickynils/scalacheck/wiki/User-Guide). The advantage of types is that they're _genuinely_ forAll. That is, the type checker _is_ a proof checker, by the [Curry-Howard Isomorphism](http://en.wikipedia.org/wiki/Curry–Howard_correspondence). So when we tame state, making it monadic, we really _are_ making it possible to prove things using types without sacrificing mutation for efficiency in the implementation.
&gt; The logic and state of the program is expressed in the types. No, without such an explosion in types that the program is no longer maintainable, and possibly not performant from a resources perspective. val bytesSrc = AddableBytes(...) val bytesSrcNoHeader = AddableBytes(...) val bytesDst = AddableBytes(...) val totalBytes = bytesSrcNoHeader + bytesDst //whoops, program is not correct, hope you have a unit test &gt; That is, the type checker is a proof checker, by the Curry-Howard Isomorphism. So when we tame state, making it monadic, we really are making it possible to prove things using types without sacrificing mutation for efficiency in the implementation. And this is why I call you an academic. Dependent on architecture, vm, or even use outside of this isolated area, you may be sacrificing efficiency. This is a result of compromises due to imperfect tools at all levels. You don't have to hold an academic position to be an academic. You just have to hold the belief that theories and postulates supersede real world results. Which is why you somehow think a referentially transparent interface can address performance constraints.
Your DNS seems to be fine. I don't know what the problem could be though, I'm not an OS X expert. Can you access the site using the IP directly (192.30.252.154)?
&gt; The former is, perhaps surprisingly, not an issue in practice, stemming from identifying commonalities and abstracting them into types that are frequently reused. This is exactly where libraries like scalaz are helpful. I just showed you a place where types cannot prove correctness, without a further explosion in types (and possibly memory overhead). &gt; It's even trampolined, so it's stack-safe. The "architecture or VM" issues are existential, having nothing to do with whether you use scalaz's effect system or not. But it does have a gc impact. You either have problems where throughput and latency are not concerns, or you have resources to be wasteful in regards to those concerns. Maybe that's why you see "architectural constraints" as being purely in code, with no regards for hardware or external systems. Either way, you and your team started with a pedantic blog post because someone failed to communicate a type change, and you didn't have tests to catch it, and have since only continued your holier than thou belief that somehow types solve everything and scalaz actors are amazing, as long as you don't need things like remoting, clustering, or state changes on a performant level.
You should drop this back as a PR onto the repo - its really useful.
I can get to that link on my mac, now what?
I really don't know what's wrong then, the site isn't actually offline. Are you behind a proxy or VPN of some sort? You can also try later somewhere else with a different connection.
Nobody ever said "typed RPC is impossible", not anything even close. The network is untyped, to raise types from the byte streams requires checking/validation/effort/frameworks. Sometimes it requires schemas, sometimes it's self describing, sometimes it requires unholy amounts of xml. The point is that it doesn't come free (it's trade-off city), and comparing Akka to Scalaz actor is not particularly worthwhile when Scalaz actor doesn't attempt to solve the network problem. 
I can't see how the type of Any makes this easier. The message wrapper carries the actual type information - the type must exist on both sides and if the definition differs its a de-serialization error. Yes it can ignore messages it cannot process but how is that doing you a favor?
We were talking about scala. But in regards to coq &gt; to state mathematical theorems and software specifications Pretty sure that sounds like incorporating tests into compilation. What's the difference between a compiler that runs your tests and a build process that compiles and runs tests?
It wraps failure-based side-effects in the Attempt[T] type. edit: Apparently those are just the encoding/decoding failures, and the IO is in that other library you linked me to, with the requisite side effects.
I don't think it was me, but what other library do you mean?
I'm sure I'll regret this, but: that's not what it is at all. It's a proof assistant. You write theorems (types), and construct proofs of those theorems (functions), which it checks (type checking). In other words, it proves program correctness with a compiler via type checking. It's just that its type system is unusually powerful. Another (maybe better, for programming) example is [Idris](http://www.idris-lang.org). Scala's type system's expressive power is on par with these—it has dependent types and the type system is even Turing complete—but taking advantage of the fact is _much_ uglier than it is in Coq or Idris.
I think he meant me, and scalaz-stream. Because he wasn't trolling, I was being nice and not telling him he's still wrong. :-) 
scalaz-streams i think?
https://coq.inria.fr/tutorial-nahas Pretty sure that looks like unit testing. The only difference? You're testing logic with a specification rather than output values. Essentially you're writing logic (the proof) twice. But hey, if you're really stuck on the fact that there's a difference between a compiler running tests, and a build system compiling and running tests, I'll just leave you to type your types. 
&gt; Pretty sure that looks like unit testing. But it isn't. &gt; The only difference? You're testing logic with a specification rather than output values. That's not the only difference. A better example is this [quicksort](http://mattam.org/repos/coq/misc/sort/quicksort.html) in Coq. It stably sorts a list of any ordered type, there's nothing that even remotely looks like a "unit test," and you'll never see a failure to stably sort a list of any ordered type in the extracted code. The difference is that types are _actually_ universally quantified instead of faking it with forAll in property-based tests, so when a proof is obtained, you really do have assurance that the code is correct. An easier-to-follow example might be [Verified Networking Using Dependent Types](http://www.simonjf.com/writing/bsc-dissertation.pdf), in Idris. It describes how to do TCP/UDP networking in Idris, with guarantees of both correct resource (socket, etc.) and protocol use at compile time—do it wrong, and your code won't compile. Again, nary a "unit test" in sight. &gt; Essentially you're writing logic (the proof) twice. This doesn't make any sense at all. &gt; But hey, if you're really stuck on the fact that there's a difference between a compiler running tests, and a build system compiling and running tests... If you can't tell the difference between types and tests at this point, I obviously can't help you. &gt; I'll just leave you to type your types. Most of my types are inferred. I generally only need to type them when I want to enforce a stronger property than the most general satisfactory type, which is what inference gives you, represents. This works out well, because the correctness I represent explicitly is propagated through the rest of the program by type inference. This approach is described very well [here](http://okmij.org/ftp/Computation/lightweight-dependent-typing.html#Lightweight): &gt; This style has three ingredients: (i) A compact kernel of trust that is specific to the problem domain; (ii) Unique names (capabilities) that confer rights and certify properties, so as to extend the trust from the kernel to the rest of the application; (iii) Static (type) proxies for dynamic values. I'm explicating in some detail, not because you'll understand—you won't—but again, for the benefit of other readers.
&gt;&gt;No, they aren't. A lemma is a type, specifically a subtype of Prop, short for "Proposition": &gt; Seriously? Yes, seriously, but once again you _cut out the context_, where I used Coq interactively to show the type of an example lemma from Coq's standard library. That type is Prop, and the type of Prop is Type. I also provided a handy link to Adam Chlipala's chapter on Coq's Type Hierarchy, in which Prop lives. I'm beginning to think it's possible that you _don't actually know_ that removing context, then linking to random definitions completely out of context, constitutes arguing in bad faith. &gt; Yes. It's called reading the scaladoc, the tests, or anything else. But for some reason that's not sufficient with you for akka. Yes, when the compiler could be enforcing what I'm reading, it's not sufficient. &gt; But reading the RFC is. And hoping no one punches in 15 instead of 16. Because code reviews and testing are inadequate. The difference remains that in the code under discussion, the "16" is part of a _type_, i.e. the _specification_ of the code. The upshot is that your _tests_ can indeed confirm that the _specification_ is correct. "Code reviews and testing are inadequate" because you can't test the entire phase-space of your program in any but trivial cases—most interesting programs' phase-space is infinitely large. So we use _types_ to express universal quantification (i.e. cover an infinite number of cases), and _tests_ to express existential quantification (i.e. there exists some foo satisfying property bar under some set of conditions of interest). &gt; The scalaz test suite doesn't help your case. Apart from contradicting your claim that scalaz developers don't believe in testing, that is. &gt; Just because you have lots of tests doesn't mean you have good tests. Scalaz has lots of tests because it has lots of classes. Feel free to demonstrate that scalaz's tests are of poor quality. &gt; How does it "work better"? And if I'm doing rpc, I already have scrooge/finagle/thrift. I urge you to follow the "[rationale](http://oncue.github.io/remotely/#rationale)" link in the documentation. &gt; I rarely do rpc though, since it moves you more towards a monolith. I'm not a fan of RPC myself. Remotely is a reasonable compromise, particularly as a replacement for REST+JSON, which is the dominant use-case it replaces. It has some nice circuit-breaking support, monitoring support, is purely functional, and makes good use of [scodec](https://github.com/scodec/scodec) for serialization/deserialization. It uses the type system to distinguish local vs. remote computation, so you can't accidentally chew up network resources by using a remote computation when you don't mean to, or have a "local" computation fail because the network is down, etc. Remotely has some features to help reduce the coupling issue, e.g. round-robin distribution over Endpoints, but I do suspect this is where the most future work lies.
It seems he like pattern matching with 'match' and 'case' too much. val (fullname, address) = person match { case p =&gt; (p.firstname + " " + p.lastname, p.street + " - " + p.city) } could just be val (fullname, address) = (p.firstname + " " + p.lastname, p.street + " - " + p.city) (just some ideas for part 3)
That's still technically pattern matching, you're just inlining the expression.
Where does `p` come from in your inlined version?
Sure, but afaik the purpose of the article was to show the pattern matching on tuples, and this is just a small example of how it works. So just imagine a situation where you have a function that returns a tuple: def generateQuestionWithAnswer() = ("question", 42) so instead of doing this val questionWithAnswer = generateQuestionWithAnswer() val question = questionWithAnswer._1 val answer = questionWithAnswer._2 you can do this val (question, answer) = generateQuestionWithAnswer() Isn't it better? Edit: code formating
 import person._ val fullname = s"$firstname $lastname" val address = s"$street $city"
Thanks for your input, the idea came from /r/swift originally. I searched /r/codereview for swift and scala and there was only one result for scala. Rather than try to force myself on code review I found that /r/codecritique mod was open to letting me be a mod and help try to revive. it. It's a catch 22 on whether you should try and change a sub via brute force content or start your own. 
Ah, ok, now it made sense.
Dude, you just showed me a new Scala trick today. I didn't know you could import instance fields into the current scope. Have my humble upvote, sir.
If it is against rules to submit a link to one's own blog, please let me know, I don't post much. This was my first project in Scala. I'd love comments from experienced Scala devs. The code was written specifically for the blog and to learn the basics of Scala. Naturally it isn't a production system.
Looks like Scalatra wants do be deployed in a servlet container / jetty. This one uses netty / akka so is standalone, which was what I needed. I found the route anotations etc quite easy and straightforward to use.
Sounds good. Thx :-)
What does this have to do with Scala?
It has everything to do with Scala('s type system) in relation to another language (Avail). If you aren't curious to explore alternative ideas, then yes, my post isn't of interest to you.
Can you explain the difficulties of using scala to have a 'strong relational algebra'? 
Ah, right; sorry, I brainfarted. Thanks!
soundcloud also recruits people from all over the world and sponsors their worker visas, you might want to consider that as well. 
http://www.meetup.com/Play-Berlin-Brandenburg/
This article is lacking examples when promoting Avail in comparison to Scala, else imo it is meaningless to post it here. 
Excellent! Thanks for sharing :)
I reference shapeless' HList but don't show Avail's version. Indeed, it is lacking concrete examples. I forgot to mention that Avail's tuples are effectively extensible records and are dependently typed by default.
Idris is a brilliant language and I've considered using it. I just happen to prefer multimethods over functions. I also like Avail's pragmatism: you can still mutate stuff (but in a very disciplined way and without resorting to Uniqueness Types).
Definitely! Thx 
One suggestion for you: if you replace the abstract base classes with sealed traits you get free compile-time checking of pattern-matching exhaustiveness. 
http://docs.scala-lang.org/overviews/parallel-collections/overview.html http://docs.scala-lang.org/overviews/core/futures.html http://akka.io/ http://spark.apache.org/docs/latest/index.html edit: added futures/promises, also scalaz library provides futures and actors as well
Thank you! I shall take a look at this :) I've used a bit of the actor system. 
First of all, can you qualify why you think you're sure your code would go faster with parallelizing? It's very easy to be wrong about that and a lot of code that I review on a daily basis would benefit much more from simple algorithmic optimizations (let alone the fact that some of it is simply not parallelizable by design). 
You should use postgis if you're trying to query about location. http://postgis.net/ https://github.com/tminglei/slick-pg Also I'm pretty sure Float doesn't give enough precision to store lat/long, depending on where you're getting it from. You might be overflowing. If you can't even do what you want in pure SQL, you should start there and worry about slick afterwards. Also, ask on stackoverflow. Way more traffic.
I'm not a big fan of using natural language, but it can be easily done in Avail. If you care to look beyond the surface appearance of Avail you'll discover that it is very well designed.
Right, since the poster specified MPI, they might be looking at non-BigData style HPC problems (which is also quite broad). So futures are out, parallel collections may or may not be out, actors are definitely out, spark is probably out (well, it could be a streaming problem). 
Why are futures out in programs that don't involve Big Data?
Why the indirection with `ItemLike`? trait Item { type Key } class IntItem extends Item { type Key = Int } class StringItem extends Item { type Key = String } def get[T &lt;: Item](e: T#Key) = ??? trait Compiles { get[IntItem](0) get[StringItem]("") } trait CompilesNot { get[StringItem](0) } 
Ah yes, we had that variant as well, but then you aren't forced by the compiler to actually specify the type parameter (class LongItem extends Item compiles just fine). Though it wouldn't compile if you tried to use such a class :)
* http://www.scalajobz.com/jobDetail/54b58e9de4b0ec362121dfd7 * http://www.scalajobz.com/jobDetail/54b58e97e4b0ec362121df74 * http://www.scalajobz.com/jobDetail/54b43ac1e4b0de91096e92d9 * http://www.scalajobz.com/jobDetail/54b43ac1e4b0de91096e92d7 * http://www.scalajobz.com/jobDetail/54b43ac0e4b0de91096e92d5 * http://www.scalajobz.com/jobDetail/54af7378e4b0094e1a4a19cc * http://www.scalajobz.com/jobDetail/54af7378e4b0094e1a4a19cb * http://www.scalajobz.com/jobDetail/54acca95e4b0a86f07c888e9 * http://www.scalajobz.com/jobDetail/54acca95e4b0a86f07c888dd * http://www.scalajobz.com/jobDetail/54acca95e4b0a86f07c888dc * http://www.scalajobz.com/jobDetail/54ab716be4b0f69b86383ea5 * http://www.scalajobz.com/jobDetail/54a76f82e4b0efce4e4470d4 * http://www.scalajobz.com/jobDetail/54a768cde4b01701cfefc488 * http://www.scalajobz.com/jobDetail/54a768cde4b01701cfefc47f * http://www.scalajobz.com/jobDetail/54a60f92e4b0b18b2bd2fd53 * http://www.scalajobz.com/jobDetail/54a4b9dde4b069bb19359185 * http://www.scalajobz.com/jobDetail/54a36475e4b09f83dc2e691e * http://www.scalajobz.com/jobDetail/54a36473e4b09f83dc2e68e8 * http://www.scalajobz.com/jobDetail/54a36473e4b09f83dc2e68e7 * http://www.scalajobz.com/jobDetail/54a36472e4b09f83dc2e68df * http://www.scalajobz.com/jobDetail/549a02b2e4b09c6309d2bf56 * http://www.scalajobz.com/jobDetail/549a02b1e4b09c6309d2bf4b * http://www.scalajobz.com/jobDetail/5498af20e4b0d12d757ec899 * http://www.scalajobz.com/jobDetail/5498af1ce4b0d12d757ec889 * http://www.scalajobz.com/jobDetail/5494a5dee4b0ae2cf9c3c567 * http://www.scalajobz.com/jobDetail/5493495be4b0f9ba88f86784 * http://www.scalajobz.com/jobDetail/5491053dc2ee3322ac1eef79 * http://www.scalajobz.com/jobDetail/54910534c2ee3322ac1eef73 * http://www.scalajobz.com/jobDetail/548f3f04e4b032158251ca89
I not sure if I follow, apply[T] is just there for syntactic convenience, IntItem in that example subclasses Item "normally".
Amazing how the 99%ers are ignoring this most important Scala Framework, most people are gona be CHEAP by default since in evolution Genius is one and then he proliferates his gene among the population after 100s of 1000s of generations, But i am afraid the sheeple / Morons will be killed by the Singularity way before that, so its different now, its time of the Think Tanks, our Era will soon render the 99%ers DEAD.
I'm an expert in Scale, fish Scales.
Nope, haven't rolled our own. We banned Scalaz because it made it "too easy" for us to write code that we didn't take the time to fully understand as a team. The ban was a reaction to our experience. I think we'll go back eventually and look at where we can simplify our code with Scalaz features. The key is teaching the concepts to new hires w/ no FP experience - that has to stay manageable. But, RE monadic programming - we're still using monads in the std library, no?
&gt;But, RE monadic programming - we're still using monads in the std library, no? You aren't able to abstract on them though
&gt;he first thing we did was ban Scalaz from our codebase. I realize that’s a controversial decision for some people but I’m not making a comment about the quality of the library, community or similar. Scalaz made the learning and readability curve way too high for us. I find this peculiar. Scalaz should make code *simpler* to understand. Why? Because it encourages (and empowers) you to write referentially transparent functions. This helps because I don't even *have* to understand my coworker's library aside from type signatures. The interface really doesn't lie. Now there's one caveat, if you are familiar with Scalaz pre 7.0, then there is less controversy with your decision. Pre version 7, (I don't think) there wasn't a requirement to have a non symbolic method name. What this means is you could see a lot of weird symbols all over the place, and yes, that can hurt readability. Version 7 now mandates that every symbolic method have an alternative, and I think a style guide requiring non symbolic methods is acceptable. But I mean seriously, did you guys roll your own Sequence, NonEmptyList, EitherT? 
Why no non-trivial folds?
scalaz.core isn't nearly as hard to wrap your head around as Spring that's ridiculous. tbh once you understand using for-yield with Option you're well on your way to being productive with monads in general, which when combined with scalaz can help your code greatly.
well, we've gone through the exercise quite a few times, and it has turned out to be harder. do you have any data on the cost (time, effort, etc...) of teaching FP concepts to people?
&gt;Yup, we were using 6 and the symbols made things even more unreadable. It added cognitive load for me though, wasn't the sole cause of it. Oh! Well then, I get what you're saying. The cognitive load may not be worth the extra productivity. However, scalaz 7 is a lot different IMO and attempts to address this issue. I am sympathetic to your position, but also love how much scalazc can do for everyone. Maybe a good compromise would be "scalaz use must be justified for each particular concept" along with "no symbolic methods". 
I like that. maybe it's time for me to give scalaz 7 a shot....
I don't have hard data, but run FP courses regularly and often have 20 people in the classes. There is no doubt a cost, as this stuff is very alien for traditional programmers, but people who want to learn pick it up pretty well. We've generally found that people with less experience are the easier to teach, people who try and compare this to their existing knowledge do worse, because it is very different. 
I was interested to compare this style with the style I've been developing on my own (working solo). For lambdas, instead of this: list.map { x =&gt; (x, x) } I've taken to writing it like this: list.map { x =&gt; (x, x) } or this: list.map { x =&gt; (x, x) } Because sometimes I want to write this: list.map { case (x, y) =&gt; (y, x) } And sometimes I want to write this: list.map { case Some(x) =&gt; (x, x) case None =&gt; (0, 0) } Another small benefit is that it makes partial functions look more like match expressions.
we actually write the last partial function style a lot. I added an issue on Github for adding that style: https://github.com/paypal/scala-style-guide/issues/6
Got it. I'd love to see a sample of your materials if you're willing to share.
Thanks. I know you invited pull requests, but I felt awkward submitting a PR for somebody else's coding style document. It was a good read. Thanks for sharing. 
It's an admonishment to avoid non-trivial folds *specifically* on `Option`. We use `fold` to useful ends on other collections, but this particular entry came from a discussion about which way we should switch on an `Option` type. I was the dissenting opinion in that conversation, preferring `fold` for its elegance, and I lost. Frankly I'd prefer even more the `opt some { ... } none { ... }` style offered in Scalaz, because then both the outcomes are clear and the code is quite elegant. :) disclaimer: I work with arschles
I would say it definitely is, and you can add [scalaz-stream](https://github.com/scalaz/scalaz-stream) to the "should investigate" list. A bunch of guys (not me) at Verizon OnCue wrote [remotely](http://oncue.github.io/remotely/), our open-source Scala RPC system, around it and [scodec](https://github.com/scodec/scodec), and it works really well. BTW, we have the same educational issues you do, with an engineering org of ~100 developers. It's real, but it's also surmountable. You do have to pick your battles, and it helps to have built stuff like remotely, which ends up being used by every engineering group, and serves as both real-world sample code and as an example of the kind of architecture and API that's enabled by tool choices like scalaz, scalaz-stream, and scodec.
Let me just add that the conversations can get quite philosophical quite quickly. As an example: I had a REST API's base URL in a String, and used a JSON parser that represents missing values as Options (of course). The API in question can optionally return a magic cookie (not to be confused with an HTTP cookie!) that, if it is present, needs to be sent back on successive calls to the API. I chose to implement this along the following lines: var maybeCookie: Option[String] = None ... val q = (List(baseURL) ++ maybeCookie.map("foo=" + _)).mkString("&amp;") This was definitely challenging for my C++-speaking colleague. I ultimately broke out the `.map()`, `++`, and `.mkString()` calls into separate `val`s for readability, but I didn't abandon the approach, because it doesn't introduce the cognitive burden of conditionals, the possibility of edge cases involving mutating the URL's representation or not, etc. In other words, it has no failure modes, and the way I justify the various benefits of statically-typed functional programming generally is in reducing failure modes—in other words, in writing correct software, which everybody is ultimately on board with. But going so far as to deliberately attempt to avoid conditionals is admittedly rather far out for the overwhelming majority of working developers.
[right here](http://clojure.org/getting_started)
Here: https://www.playframework.com/documentation/2.3.x/Home
Aren't programming courses, for people who can already program, obsolete? This is a totally serious question. You might say that's absurd, because the freely-available documentation and exercises are obviously not up to snuff so people are going to be wasting too much time struggling with bad docs and exercises... well then people should write better documentation and exercises and Google should make it more trivially discoverable! It's not inherently unsolvable. I taught myself the vast majority of my programming knowledge by self-directed learning and on-the-job learning (itself mostly self-directed). Of course it's also very possible that I'm not only atypical (I know that I'm atypical in terms of how much I read) but inevitably so in the relevant respects.
I admire your fervor. To be fair, are you going to do it in other JVM languages after Scala? Like Clojure?
&gt; We had to lay off one of our Senior Scala Developers Care to share the reason why?
http://javatoscala.com/
When you say from scratch...you mean like, from scratch? 
Like I used com.sun.net.httpserver.HttpServer. Does that count?
I'm using it heavily - I've ported the entire front end of my website from being a bunch of Play templates to being a single integrated client with Scala.js. I can't claim it's trivial, and the impedance mismatch is real - if you use a lot of JS libraries, as I do, you often need to put some real effort into writing strongly typed Scala facades over them. But the end result is a thing of beauty: far more comprehensible than my old JS code, much more robust, and I am betting far more maintainable. The cost was significant - about four months all told. (Albeit part because the real client pushed me to build a real API, which resulted in a lot of back end improvements.) But I believe the investment will pay off handsomely, not just in having better code in the front end, but by having (via libraries like Autowire) a much tighter and cleaner integration with the Scala back end...
@greenrd love how decide to deprecate on twitter because we presented this at all, but are still willing to try to grab some karma by posting it here. I'm really disgusted by your twitter comments. here you make a comparison of this to "brogrammerish talks": https://twitter.com/greenrd/status/556001219182088192 you then go on to clarify that by "brogrammerish" you are equating this to man putting "soft-port pictures" into their slide-decks: https://twitter.com/greenrd/status/556221453410922497 I find the fact that you compare these two things at all disgusting. I'm TOTALLY AMAZED that you can be sending dozens of tweets about this, trying to defend you position that Kelsey (and I?) need to be less feminine about how we are presenting this material, because what the fuck, first of all, you are assigning a gender to a talk about property based testing???? You are claiming to see a link between the oppression that women might feel when seeing a "soft-porn" image on a slide deck, and what you feel when looking at these images? So what is your actual point? that these images might drive some men away from the industry? Are we really worried about that? You decide to try to discourage a female developer from doing what she is doing? by calling her too female? Seriously, what the holy fuck? What are you really thinking? "This is a male dominated industry, I understand that perhaps part of that is that we intimidate women by objectifying them. I see that this woman is trying to teach us about scalacheck, but she is being feminine. I should tell her to be less feminine, she should know better" Do you also criticize dudes for being to masculine? can you point me to where you do that? or do you just criticize women? Also, its fucking pure gold that you think that our presentation of this material might be harmful to the scalacheck project in general: https://twitter.com/greenrd/status/556197981444403201 but you still want to post the link here, without commenting on it, I guess to try to grab some "karma" from this site... 
I don't think this post is about genders at all. Yours -- yes. The pictures -- are not. The percentages just correlate with gif-s about magic that you can find (as I think).
The scalajs homepage has a list of libraries and tools. I know there are facades for the DOM API, jquery, react, and angular. I'm not sure how done each is though.
There are a fair number of facades out there, but the ecosystem is evolving rapidly. I haven't published any of mine yet, but that's mostly because I haven't worked through the process yet (I'm newish to the open source world) - I expect to publish ones for jQuery UI's Dialog and Sortable sometime soon. It's worth noting, though, that writing facades on an ad-hoc basis is pretty easy. I have several that I haven't bothered to get into publishable shape, but which I whipped up in order to use various JS libraries. Writing a facade for a few entry points of a library usually only takes a few minutes once you know what you're doing. 
At Scala Days 2013, the scala.js demo required a 12mb download of the Scala std libs, anyone know if this has been resolved?
I haven't yet, but I plan to, for basically two reasons: 1. I'm working by myself on a side project I eventually hope to launch and sell, and it's in the "other people's money" domain, so correctness is crucial. So no dynamically-typed nothing anywhere. Since the back end will be a Scala API around [Alfresco](http://www.alfresco.com/community), the front end might as well be in Scala, too. 2. Continuing from 1), I expect to use one of the Scala.js compatible FRP systems to have my SPA and my back end interact in (soft) real time. Unfortunately, none of them seem to support this use case out of the box, so I'll have some work to do. :-)
&gt; I find the fact that you compare these two things at all disgusting. Well, they both put people off... &gt; I'm TOTALLY AMAZED that you can be sending dozens of tweets about this, trying to defend you position I'm really more trying to defend myself! It's a big Twitter pile-on and pretty much everyone is criticising me and laughing at me. &gt; that Kelsey (and I?) need to be less feminine about how we are presenting this material I'm not trying to tell you what to do. I'm giving you some feedback. What you choose to do with that feedback is up to you. It's a tradeoff: the current blog post will probably be great for some women, not so great for some men, and fine for some other men who don't mind that kind of stuff. &gt; because what the fuck, first of all, you are assigning a gender to a talk about property based testing???? Perhaps this is a cultural difference. Where I grew up, it was very important for straight males (which will be of course the majority of the readers of that blog post in all likelihood) to avoid being seen as too feminine or interested in feminine things. Perhaps in 2010s Silicon Valley or wherever you are, things are very different and much more "progressive". But yes, absolutely, the talk as presented in that blog post has a very feminine vibe to it, just as it would have a very masculine vibe to it if was full of pictures of tanks and guns or something like that. &gt; You are claiming to see a link between the oppression that women might feel when seeing a "soft-porn" image on a slide deck, and what you feel when looking at these images? ~~No. No. Nopety nope. Not everything is about feminism, oppression, or a comparison to feminism. What I was trying to say had nothing to do with feminism or oppression. Zilch. It's about marketing.~~ EDIT: OK, I see what you mean now. But like I said before, this is about the fact that both cases are about one gender being deterred by the actions of someone of the other gender, it's not a case of me trying to draw some kind of "moral equivalence" between the two, not that there's anything morally wrong with your presentation of course. &gt; So what is your actual point? that these images might drive some men away from the industry? I've already explained to you in a tweet that that's not my point. &gt; What are you really thinking? "This is a male dominated industry, I understand that perhaps part of that is that we intimidate women by objectifying them. I see that this woman is trying to teach us about scalacheck, but she is being feminine. I should tell her to be less feminine, she should know better" Basically yes. If she's intimidated by that kind of comment, I probably need to recalibrate what I think of as intimidating. &gt; Do you also criticize dudes for being to masculine? can you point me to where you do that? or do you just criticize women? Nope, just women. &gt; Also, its fucking pure gold that you think that our presentation of this material might be harmful to the scalacheck project in general: No, you misunderstood, that wasn't my point. My point was that it was bad marketing because many men would probably just click the close tab button and not read it. Thus posting the link here does no real harm, except to my karma. &gt; but you still want to post the link here, without commenting on it That is totally normal on this site. Reddit is a site for sharing things you have read, hence the name, "read it", or reddit for short. Only a vanishingly small proportion of subreddits require submission statements from the submitter. &gt;, I guess to try to grab some "karma" from this site... I've got plenty of karma mate, just check my stats, I don't need more. I was curious to see how many upvotes it would get.
For building your scala server / scala web framework I suggest to have a look at Akka Http - it's almost ready. You can learn a lot about scala features, streams from the code. If you need bare minimum you can use akka http core component from there and build your stuff on it.
Nice project. I wonder why having two types of file composers, `foo/'bar` (Symbol) versus `foo/"bar"` (String). The latter is familiar from sbt, whereas the former just looks odd to me. I thought nobody was using the Symbol type at all in Scala, as it provides usually no advantage over String. IMO, Symbol should be removed from the Scala library.
&gt; Of course, the downside to using an exception for this is that it isn't type safe. But unless Scala ever supports real union types, there's no clean way to avoid that. Yeah I don't care; my target level of safety is "not Bash", not "ScalaZ" =P &gt; So? Regular method-call notation is also of a fixed length (specifically, one paren before the parameter list, and another paren after it). Yeah but you can `cd!wd` so that's only one additional character rather than 2 =D =D =D (I clearly have not thought this through. I still think it looks much nicer though!) &gt; I see. Well, java.nio.file.Path can be used like that, too, so why not do so? I'm doing something interesting with Ammonite, in that *there is no implicit current working directory*. You have to explicit convert relative paths to absolute paths in order to do anything useful with them, e.g. via `wd/relpath`. `java.nio.file.Path` is based on the old-style unix way of doing things, where you can use a relative path or absolute path where-ever the hell you want and it'll magically prepend the `cwd` for you. My experience with this is that it makes everything very fragile, which is why I'm doing something different. That's why `Path` and `RelPath` are different incompatible types. Thus `java.nio.file.Path` isn't the data-structure I want. It is in fact exactly the data structure I don't want, contains a whole lot of logic I don't want, and I'd just be fighting/hiding all of it anyway. Better to just start with a `Seq` =P 
&gt;Yeah I don't care; my target level of safety is "not Bash", not "ScalaZ" =P Ha! Well then, an exception it is! Still, I really really really want union types. :( By the way, in case you're wondering: No, throwing lots of exceptions actually isn't slow. What *is* slow is `fillInStackTrace`. That's why `ControlThrowable`'s supertype `NoStackTrace` disables it. &gt;(I clearly have not thought this through. I still think it looks much nicer though!) It um, kind of looks like Ruby. I don't like Ruby… &gt;I'm doing something interesting with Ammonite, in that there is no implicit current working directory. Ooooh. Well, that's interesting. That explains it, too. But if we're going to do that, then can we please have a nicer syntax? Some lovely string interpolation goodness, like: path"$cwd/../folder/file" All those damn apostrophes and quotes everywhere are unnerving. D: This would be much less noisy. Also, it would save characters. Think of the characters!
&gt; This would be much less noisy. Yeah I've thought about that. To me it looked significantly uglier though, not sure about you =P
Significantly uglier than apostrophes everywhere?!
Yeah `path"$"` is 6 characters, would need a path 6-segments long before it makes up for it's verbosity!
I think you might have overcomplicated it http://pastebin.com/P7Q72UAT This is how I did it. It's a bit more verbose than it needs to be because I did the other ones as well, but they're not included. I'm happy to talk you through the code if you don't get it
&gt;That's entirely what I don't want. Paths are not strings, and shouldn't look like strings! =P They are their own data structure you can do some operations on, but they're not strings. Hmm. Good point. &gt;Where I couldn't get it to work is how someone would splice in dynamic content into it? Yes, that's why it would be insane. :)
To be fair, a lot of _Scala_ developers' first instincts about `Option` don't include appending them to a `List`, or even necessarily `.map()`ing over them. `.mkString()` doing nothing with a 0- or 1-element `List` is probably also a bit subtle at first. Yes, thinking about the "shape" of the data is bread-and-butter FP, but the point is our colleagues haven't learned FP yet. 
As kingcub says, they've done a lot of optimization, so the standard block is now much smaller. Even more important, the compiler now includes a linker that does aggressive dead-code elimination, so the final result is generally just the code you actually need, plus a couple hundred k for that standard block. 
Pardon my ignorance, but could you detail the issues with using Java.io.file, and explain the right way of accessing files? Thanks!
&gt; the current blog post will probably be great for some women, not so great for some men, and fine for some other men who don't mind that kind of stuff. What kind of attitude is this presuming what is great "for some women" and "great for some men"? So because I'm male I have a predisposition about whether I like animated GIFs or not, or what? Unfortunately your new comments makes this Reddit as ugly as the Tweet stream.
Ah awesome didn't know about "grouped". Yah was combining the lines into 4 element lists since the "numbers" are always 3 lines with a blank line.
I tried it out but abandoned it because it would be far too much work to write wrappers around all the libraries I need to use. It's also a pain to integrate into, say, a Play framework project. Scalajs needs to build as it's own separate sbt project and you need to wire its build into your main project. Common libraries need to be compiled for both Scalajs and Scala on the jvm.
It is definitely possible to build Scala code without SBT. Gradle has fairly decent suppprt for building Scala, or you could always just use scalac manually. It's been a while since I used SBT, so I don't remember all of its features, but one is that it will figure out the right version of libraries to work with your version of Scala (to avoid binary compatibility problems) where Gradle doesn't.
I had that too def toPipes(a:String):String = { val nums = a.map((a:Char) =&gt; Integer.parseInt(""+a)) val output = (0 to 2).map((i) =&gt; nums.foldLeft("")( (accum,current) =&gt; accum + number(current)(i) ) ) output(0) + '\n' + output(1) + '\n' + output(2) } A rule I use when making scala code is only start using classes and inheritance when you feel there's no other reasonable option and otherwise use the simplest data structure possible. Generally I find this leads to shorter and more legible code. This is certainly a personal rule rather than a widely accepted one. What you have is a great start though.
Google 'viewducers'. Josh Suereth is working on an implementation of transducers that could replace collection views eventually.
(Mostly. Look at there generated code. Lot of ugly corner cases. But still an awesome start)
Play integration requires the paid version of IntelliJ and not the community edition. Which are you using?
actually I think it's more like that : SBT is indeed the build tool. It is launching the various build stages your app needs rather than compiling directly. Stages include resolving dependency (download) and compiling. It will run when needed scalac for scala sources, javac for java source, plus pretty much any kind of sources as SBT has a plugin mechanism. Play, is a framework that provides amongst other things, SBT plugins. It is a superset of the SBT commands that will add all the behaviour necessary for the "play workflow" : touch a file, reload the page in the web browser, play handles everything. Activator, again, is a superset of Play. It provides even more functionalities to create and manage your application. Personally, I use intelliJ to code only and run activator on the side. So compilation is handled outside of the IDE. I'm doing that because the latest version of IntelliJ isn't able to load correctly an SBT project generated with activator. To load my project, I use activator gen-idea and load it as an IntelliJ project.
Ultimate :)
Found it: https://github.com/jsuereth/viewducers
I do not have any big issues with intelliJ. To debug I use the the socket mode instead of the In-memory mode (never managed to make it work, which is a shame because a lot more efficient) I do indeed run activator with the debug port option, both to run my server or to debug my unit tests. I believe it is activator -jvm-debug=9999 &lt;your command&gt; I don't know if you already debug like that, if you do not, you have to configure the execution of a "remote debug" (same dropdown that configures running a program). 
I thought views were on the way to being deprecated?
Maven works too.
Anybody know why Scala doesn't benefit more from the parallelization? Could the dataset really be too small (297 MB and 229 MB tables)?
Note that integration with Play! has been improved dramatically, thanks to this sbt plugin: https://github.com/vmunier/sbt-play-scalajs It does all the wiring up for you :-) It's for Scala.js 0.6.x, which is currently in RC1.
If you look at the table "Execution Time of Each Step in the Workflow" it becomes fairly evident. The phases taking up all the time are "Join" "reduceByKey" and "sortByKey" which are not parallelizable. If you look at the chart all of the parallelizable steps shrink to almost nothing with the addition of more cores. If you chose a larger dataset you would likely see more benefit from the parallelization, but you would still see the non-parallelizable steps taking up a vast majority of the time.
When?
I know I shouldn't feed the troll, but: Yes, it really is valuable to encode as many of your requirements in types as you reasonably can, so as to preclude entire categories of bugs before your code even runs.
 &gt; It counts for everything, because I don't get up there and do that because I enjoy hearing myself talk. :-) But in this instance, we need to thank Amanda, who really put herself out there in a big way! Indeed, she seems like an amazing individual! I hope both of you turn up on a speakers list again in the not too distant future.
I find it confusing that the author of the post works (is payed?) in the team of another programming language. I hope it's not a corporate style at Avail to blame where you worked 7 years, is it?
Currying is used in the standard library in cases like that. For example, `fold` in `Option`, `Future` and `Traversable`.
Yaa Vote me down you RETARDS, that wont change the FACTs , will they.
I don't want to nit-pick but the implementations are different. The scala trie: http://infoscience.epfl.ch/record/169879/files/RMTrees.pdf The clojure trie: http://lampwww.epfl.ch/papers/idealhashtrees.pdf
Awesome!
Just put Scala on your LinkedIn profile and the recruiters will find you fast! 
Here is a nice list of Scala/Akka/Play (and some Java) jobs: https://typesafe.com/subscription/typesafe-together/our-customers-are-hiring
meetup.com You won't find job-listings there, but you will find meetups, where people are very interested in hiring scala developers.
It seems to be random each time. Is there an easy way to disable it? And yeah this is just the Scala shell.
how can it be that pypy's "Join" and "reduceByKey" do benefit, but not scala's?
So this explains why it only happens when I use fsc to compile as opposed to scalac? Could you please elaborate on what the process is listening to by any chance? Thanks
i don't get it: how are they addressing the fact that "become" / finite state machine behaviour of actors make type-checking hard? 
That's great, thank you! I'll keep an eye out for you folks.
&gt; Just put Scala on your LinkedIn profile and the recruiters will find you fast! I've done that, but I've only gotten sporadic messages, and most of them weren't very relevant. My profile is pretty sparse though (my current job doesn't know I'm looking, and I'm wary putting too much personal info on social media). Can you suggest any tips for using Linkedin effectively during a job search?
Thanks, that's helpful! Actually, it's less helpful than I thought - it requires paying Typesafe.
You can simplify this (or, better, keep `Future` at the top so you stay out of this mess) with `.sequence` from scalaz. Or you can write it yourself. [FPiS](http://manning.com/bjarnason/) discusses this (traversable functors) in some detail. In any case: scala&gt; val a: Future[Option[Future[Option[List[Future[Option[String]]]]]]] = Future(None) a: scala.concurrent.Future[... scala&gt; a.map(_.sequence) .join // like "flatten" .map(_.sequence.join.sequence.map(_.sequence)) .map(_.sequence).join.map(_.map(_.join)) res42: scala.concurrent.Future[List[Option[String]]] = ... There may be a way to do this in fewer steps but I don't want to look at it anymore. 
Ya if future is at the top this is easy. Sadly its not that uncommon that a Database call (future) returns an option, and that option, if defined, requires another database call that is a future of an option... and it devolves from there. Reading link now...
Seriously, map those to usable types. Your final return should be something of the type Future[AResult]. You can go through that many layers, but turn it into something usable along the way. flatMap is your friend.
Once you get fut of opt of fut of opt.... You need to start throwing awaits in to get out the inner futures :(
You do not. scala&gt; val x: Option[Future[Option[Int]]] = None x: Option[scala.concurrent.Future[Option[Int]]] = None scala&gt; x.sequence.map(_.join) res43: scala.concurrent.Future[Option[Int]] = ... 
I assume that sender isn't always sure in what state receiver is, especially if it sends message to a remote actor. So in compile-time it's much harder than in runtime.
the mechanism behind the Option monad transformer might seem a bit complex (it is certainly unfamiliar enough to confuse everyone the first time they see it) but USING them is pretty basic. All OptionT does is wrap your Future[Option[A]] and 'peel out' the value whenever you use it in a for comprehension or map over it. I gave a presentation a bit on this recently. https://speakerdeck.com/vmarquez/using-scala-futures-the-functional-way
It's kind of boring but for each future call I'm doing something like this to avoid embedded type levels : def fa: Future[Option[String]] = Future(Some("a")) def fb(a: String): Future[Option[String]] = Future(Some(a+"b")) def fc(ab: String): Future[Option[String]] = ... val composedAB: Future[Option[String]] = fa.flatMap{ case Some(a) =&gt; fb(a) case None =&gt; Future(None) } val composedABC: Future[Option[String]] = ... Doing this I can continue composing my Future[Option] types without pain with a flat typing level. But I will look a closer look at scalaz, it could be better option indeed, but I'm afraid to scare the rest of my team with scalaz transfomers.... Edit: just read the FutureO article you mentionned, it seems pretty good to me, why did it not fit your needs?
I realise that the following is not quite as elegant as a monad transformer, but it's also immediately understandable and seems to fit your requirements. Don't pay attention to the horrible, horrible database scheme implied by my choice of methods, I just needed to find a quick series of calls that emulated what you appear to be trying to achieve (nested calls to database, any of which might not return a result). def findId(login: String): Future[Option[Int]] = Future.successful(Option(1)) def findName(id: Int): Future[Option[String]] = Future.successful(Option("Robert")) def findFriends(name: String): Future[Option[List[String]]] = Future.successful(Option(List("loicd", "tpolecat"))) for { id &lt;- findId("TunaBoo") name &lt;- id.map(findName).getOrElse(Future.successful(Option.empty)) friends &lt;- name.map(findFriends).getOrElse(Future.successful(Option.empty)) } yield friends More knowledgeable people than me will correct me if this is wrong, but I do believe that if you take this approach and abstract it all the way (notice how each line in the for-comprehension repeats the same pattern? can you abstract this? can you maybe use a type class to do so?), you get the appropriate monad transformer.
Value classes are currently boxed in generic environment, ie Array[Meter] is Array[BoxedMeter]. Same applies to more complicated collections. So, it won't help you with boxing\unboxing if your bottleneck is in collections. Though we have a person starting to work on this in Dotty, no promises though - we're just experimenting around this. As well as auto-value-classing everything that could be value-claseed without loss of semantics(eg if one doesn't call System.IdentityHashcode, etc) 
Yes with scalaz + sequence. I do not think I want to bring scalaz into my codebases.
I would often need the results from 1 level to get to the next level... if I just wanted to peel back 3 Future[Option[]] it worked great, but when I needed the result of the first to go into the function that makes the second, it still was thorny
This is I think a good solution if I only need to do it 1-2 times. It might get annoying to do 1000 times as a codebase grew... Option monad transformer may do better as a "write some complicated code, but make life easier everywhere else" style fix. 
Any method that would return a Future[Option[Future[A]]] can be refactored to return a Future[Option[A]] instead.
_.flatmap { case Some(x) =&gt; x case None =&gt; Future(None) } Or something close to that...
Or just _.map( _.sequence ).join
Also forgive the phone autocorrect on "for matters". Should have been "formatters" 
What about something like this? I'm using fa result into fb, into a FutureO def fa: Future[Option[String]] = Future(Some("a")) def fb(a: String): Future[Option[String]] = Future(Some(a+"b")) val composedAB: Future[Option[String]] = (for { a &lt;- FutureO(fa) b &lt;- FutureO(fb(a)) }yield b).future You can also do the same with scalaZ optionT : import Scalaz._ import scalaz.OptionT._ val composedAB: Future[Option[String]] = (for { a &lt;- optionT(fa) b &lt;- optionT(fb(a)) }yield b).run
K let me look at my real use case. I think the problem is when I start missing seq in... something like: for { a &lt;- f(_) =&gt; Future[Option[A]] b &lt;- f(_) =&gt; Future[Seq[B]] c &lt;- f(_) =&gt; Future[Seq[C]] d &lt;- b e &lt;- f(_) =&gt; Seq[D] f &lt;- f(b) =&gt; Future[Seq[E]] g : Opt[C] = c.find(_) h : Seq[E] = f.filter(_) yield (d, a, e, g, h) This is the full extend of my actual code which made me cry. So futures and options MIXED WITH Seq MIXED WITH Future[Seq]. Guess I should have put the full yuck in my problem.
WDYM? Paying for what?
Ive tried to summarize different options here : http://loicdescotte.github.io/posts/scala-compose-option-future/
Blame? There is no payment involved. I've just joined the Avail team two weeks ago. FYI, the Avail Foundation is a limited liability corporation. This is because the IRS no longer awards non-profit status to organisations that develop, deliver, and support open-source software. Now *that* is confusing for me as an European to understand.
yes, linuxfr discuss it
Idk how to do this with scalaz lenses, but with monocle it's pretty easy
How would one do it with monocle then? I looked into monocle, too, but then decided against it for some reason and went with scalaz.
def NZD = NewZealandDollar
That is a lot of extra complexity, but you can define a union type: http://www.chuusai.com/2011/06/09/scala-union-types-curry-howard/
Thats actually a really neat trick which might be useful in some frameworks/libraries. You can't store the import transformation as a value can you? That would solve the problems. aka define the method as add, have an alias tranformation list somewhere, import that, then all of a sudden you can use + which has effectively renamed the function. I mean it seems great, but having to rename java.util to ju in every single class might get rather cumbersome. But then again, i guess it might be a decent workaround. Give the methods/classes neat names but then symbolise them on import. The only issue here is that the conversion is almost hidden in the imports. But I will definitely use this in the future. I guess I could use some nifty live templates to simplify the import renaming if I do it a lot. 
Yeah, technically none of what i mentioned would actually be Aliases without compiler magic. They all would work the same way, just duplicate the implementation while maintaining different names. But again that would have issues like I said, especially when it comes to a type safe equality check. Yeah I agree with you. not adding keywords is one thing scala does well, id rather not have this feature than have it but sacrifice a keyword. Let's be honest, some scalaz symbols are kind of bad, but they do clean up code a little bit sometimes. I mean I don't really think a name that is under 5 characters needs to be symbolised unless its something like add which makes more logical sense as an symbol. I don't really understand why ScalaZ has the o and oo unicode symbols for map. And i sorta get the idea behind the Macaulay culkin operator... But really |@| isn't the worst symbol in scala history, there are some pretty bad ones hidden away. Im more meaning for logical solutions. Unicode has a lot to offer, especially when looking from a maths/logic point of view, disjunctions/xor/lessThanOrEqualTo/logicalNot all have symbols that make life a lot easier, although I don't recommend anyone use symbols all the time. I completely agree that over use can cause bad smells, and that the use cases are limited. Especially when it comes to readability for maintainers. For example you need to know that both add and + refer to the same function and don't have separate definitions. I mean for a simple case like that with one alias it seems fine, but if you give the masses ideas, who knows what will happen
Import aliases are generally meant for deconflicting identifiers locally. If you're writing a library want a alias you can share you can use a type alias. Type aliases must live within some static scope so people ususaly define them on objects, more specifically package objects. src/main/scala/mypackage/currency/package.scala pacakge mypackage package object currency { type NZD = NewZealandDollar } /src/main/someotherfile.scala import mypackage.currency._ val x: NZD = new NewZealandDollar x match { NZD =&gt; "NZD" } x match { NewZeallandDollar =&gt; "New ZealandDollar } Type aliases however cannot alias packages like local import statements can. So you do end up having to alias packages like java.util every where they're used.
monocle does not support state yet. However, flicken code sample should satisfy your use case.
What is the difference between Akka Streams and Spark Streaming? http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala.html?_ga=1.216139477.236979883.1420499516 https://spark.apache.org/streaming/
You can't see the job postings without a Typesafe subscription. Unless I'm missing something.
Thanks for taking the time to provide such a thoughtful response. Off to the supermarket to replenish my salt supplies ;)
Why'd it have to be MongoDB? The rest of that stack is pretty sane.
You do not need a subscription to see the posting, but you need one to post a new job opening. Full disclosure: I work at Typesafe.
Well that at least solves one of the problems! Thanks heaps.
For that part: &gt; some compiler magic that made converted all instances of NZD to NewZealandDollar at compilation If your methods operate on the union type, it won't matter if the user used NZD or NewZealandDollar class.
&gt; Microservices exist Microservices have existed* Also, not AKKA but Akka. :)
&gt; Microservices exist Thank you :)
Nice article. I dont like spray nor Mongo much though. I prefer simpler stuff like xitrum and postgres or Cassandra.
Commercial experience in Java and hobby project in Scala will be OK?
I have experience working with large scala code bases. Sent you a PM.
Lol
We haven't written much yet actually. Trying to put a good team together first. 
We are looking for people who have worked on a large project. We have a bunch of people who have Java or C# who are transitioning already
Well if the pay is good and you are wanting to learn a language, why not sign up for an early stage company in that language?
Cake pattern. Cake pattern *everywhere*.
"Could I just import lwjgl stuff and use it in scala?" yes. ;) You might want to just use unmanaged dependencies if the sbt plugins give you problems (had some problems when I was last using them). http://www.scala-sbt.org/0.13/tutorial/Library-Dependencies.html#Unmanaged+dependencies Once it's imported just follow any java tutorial but use scala syntax.
Almost every project is looking for contributors. Usually it works like this: you find a an issue, leave a comment that you're willing to work on it. Project maintainers often offer you help and elaborate the issue. Just look thought the Github issues of the projects you use.
I was looking into this a few weeks ago, https://github.com/storm-enroute/macrogl MacroGL uses the modern way to do OpenGL but this requires you have some understanding of the modern way to do OpenGL, so if your looking for simplicity, this is not as simple as it can be as you need to think in terms of shaders and things, which is the new way to do OpenGL. Otherwise, find a game engine in Java or yes lwjgl is a good way. I looked at JMonkeyEngine but found its not really what I wanted, lwjgl is at the right level of abstraction to give simplicity if I'm in a hurry to program something.
Nice, I just havn't learned any Scala yet :/. I don't understand how to use that macrogl though, not much of a guide in it.
Yes! Would like contributions in [abandon](https://github.com/hrj/abandon). I had mentored one person last year. The main area where I spent time with them was in teaching scala basics. How familiar with scala are you?
[SubScript](http://www.subscript-lang.org) could well use more contributors; there are now only 2 so you could make a significant difference. [Here is the Github repository](https://github.com/AndreVanDelft/scala). BTW Last month the talk "Reactive Programming with Algebra" at the [Scala Exchange](https://skillsmatter.com/conferences/1948-scala-exchange-2014#program) was about this project; next month I will give a similar presentation at [Lambda Days](http://www.lambdadays.org) and in May at [LambdaConf](http://www.degoesconsulting.com/lambdaconf-2015/).
Cool, good to know. Something appears to have changed; I clicked the link again, and can now see job postings. Thanks!
It is brought up several times in the comments, for what that's worth.
FYI: It *seems* like if you have previously contacted Typesafe and view that page, Typesafe sales guys will spam you. I hope that's not what's happening, because it's really annoying. The upshot is that it got me to switch from Ghostery to [uBlock](https://github.com/gorhill/uBlock).
I'm developping [ScalaKata](https://github.com/MasseGuillaume/ScalaKata). It's a repl like tool for scala that let you code in your browser with all the advantages. It's a mix of scala compiler and html/css/js. I need help on creating content such as introduction to scala, introduction to fp, introduction to lib xyz, etc.
I guess with 37 commits, it's a fairly young project. But then these are common structures: https://github.com/mpilquist/Structures/tree/master/core/src/main/scala/structures - a monoid is a monoid, a functor is a functor, ... If you look at the source code, it's quite clean and readable: https://github.com/mpilquist/Structures/blob/master/core/src/main/scala/structures/Functor.scala &gt; Type class that describes type constructors that support a `map` method which adheres to the laws described in [[structures.laws.FunctorLaws]]. &gt; &gt; The name is short for "covariant functor". 
Where and when is it? How much does it cost? 
Source.fromFile.getlines() will return an Iterator over Strings. You can use functions like map( x=&gt;???) to process each line individually, which functions similarly to your lambdas in the python. The problem you have is that you need to take multiple lines together, and you've just split into single-line units. One (more advanced) option is to look at how the Source object (which is an Iterator over the characters in the file) and see how they make an Iterator over the lines, and use that as an example to make an iterator over multiple lines, delimited by "\n&gt;". Then you get each entry being a string of "header\nsequence", and you can map{substr=&gt;val x = substr.split("\n");(x(0),x(1)}. A bit trickier, but pretty clean overall. Another option is to use something like: val lines = Source.fromFile.getLines(). val linePairs = lines.zip(lines.drop(1)) // this now has tuples of each line and the next line linePairs.filter(pair=&gt;pair._1.startsWith("&gt;")) The zip will get you pairs of lines with the next line. Unliked grouped(2) it will give you every line twice, once in the first position of the tuple and once in the second position of the tuple. The filter eliminates the ones you don't want. These are both functional ways of doing things. The first is more work, but is probably more efficient, and to me seems "cleaner". The second doesn't take more than the API, but may make unrealistic assumptions about your fasta. Learning to *think* of functional solutions to problems was my biggest challenge to learning functional programming. You get it with practice, and sometimes I still just cop out, use a locally scoped var and while loops, and put in //TODO: make a functional version that isn't so ugly Good luck! edit: formatting
Exactly what I was looking for. Thank you so much!
 @tailrec def parse(hdr: String, seq: String, v: List[(String, String)], i: Iterator[String]): List[(String, String)] = { catching(classOf[NoSuchElementException]) opt i.next match { case Some(s: String) if s.startsWith("&gt;") =&gt; parse(s.drop(2), "", (hdr, seq) :: v, i) case Some(s: String) =&gt; parse(hdr, seq ++ s, v, i) case None =&gt; (hdr, seq) :: v } } println(parse("", "", List(), Source.fromFile("/fasta.txt").getLines())) EDIT: ..updated to use Exception methods EDIT: ..and if you introduce a case class you can make it even neater.. case class Fasta(hdr: String, seq: String) { def ++(s: String) = Fasta(hdr, seq ++ s) } object Fasta { def apply() = new Fasta("", "") def apply(hdr: String) = new Fasta(hdr.drop(2), "") } @tailrec def parse(f: Fasta, v: List[Fasta], i: Iterator[String]): List[Fasta] = { catching(classOf[NoSuchElementException]) opt i.next match { case Some(s: String) if s.startsWith("&gt;") =&gt; parse(Fasta(s), f :: v, i) case Some(s: String) =&gt; parse(f ++ s, v, i) case None =&gt; f :: v } } println(parse(Fasta(), List(), Source.fromFile("/fasta.txt").getLines()))
I'm on the bus! ~30min from Boston coming from Mtl! I'm going to do some bouldering tonight (rock climbing without a rope :o) at [Rock Spot Climbing](http://www.rockspotclimbing.com/about-rock-spot/facilities/#toggle-id-4). I will be there around 8PM.
Nothing in Scala is easy , its Easy only for the Language developers and the framework developer, Easy for guys like David Polak. The primary problem is acute lack of IDE, so for example, we dont have a menu that says, create a Empty Web Project or Swing project or Command line or Service project, These things are needed for Large Scale Enterprise Projects but Scala is made by Academic. Worst part is the SBT, SBT has no inklings with IDE, we have ZERO options in IDE to add dependencies and if you mention dependency, they will think about DEPENDENCY INJECTION.DI IS WHAT THEY CALL To INHERITANCE POLYMORPHISM AND NEVER CARE TO MENTION IT. SINCE MOST OF THEM ARE FROM JAVA WORLD. ITS SICK SICK SICK. EVEN WORSE IS THEY BAN GUYS LIKE ME . SO NOTHING THERE EVER GETS FIXED.
They Dont get the fact that they need to get an C# Equivalent IDE for Scala to beat C# its one way traffic ;-)
I'm still very much a beginner but one of the tricks I've picked up came from a definition of functional programming that was "programming without assignment." I just started trying to eliminate assignments from my code and it just started getting much cleaner and easier to think about. So to sum the elements in a list I might have once though to: def sum(in: List[Int]): Int = { var list = in var acc = 0 do { acc = acc + list.head list = list.tail } while (!list.isEmpty) acc } I eventually began to see this as a simpler approach def sum(in: List[Int]): Int = { def sumImpl(acc: Int, list: List[Int]): Int = { if (list.isEmpty) acc else sumImpl(acc + list.head, list.tail) } sumImpl(0, in) } Once you start to see problems in functional terms like that, the functional tools become really useful def sum(in: List[Int]): Int = { def sumImpl(acc: Int, newVal: Int) = acc + newVal in.foldLeft(0)(sumImpl) } And yes I know that could be simplified with an anonymous function def sum(in: List[Int]): Int = in.foldLeft(0)(_ + _) but I'm trying to give an example that would work for more complicated logic. 
Squeryl not approached, unfortunately. But a nice overview anyway.
I'm not familiar with Python, but I'm assuming that `yield` works like it does in C#. If that's the case, then you probably expect the equivalent Scala code to also produce a lazy collection. Here's perhaps the most direct translation: def chunkLinesCombined(lines: Seq[String]): Stream[(String, Seq[String])] = { lines match { case Nil =&gt; Stream.empty case headerLine +: tl =&gt; val (bodyLines, restLines) = tl.span(! _.startsWith("&gt;")) val filteredBodyLines = bodyLines.map(_.filter(ch =&gt; !ch.isDigit &amp;&amp; !ch.isWhitespace)) (headerLine, filteredBodyLines) #:: chunkLinesCombined(restLines) } } Streams are lazy sequences that can be built up using the #:: operator. Although you usually build Seqs from right to left (i.e. you start with the empty list and prepend elements until you have the list you want), you build Streams from left to right (i.e. you start with your initial element, and append a stream which contains the subsequent elements). This code looks at first glace to be recursive, but it's actually not. The right hand argument to #:: isn't evaluated immediately; it will only be evaluated as the stream is traversed. For this reason, if you want to print the output of this function, you probably want to do something like `chunkLinesCombined(allLines).toList`. Stream's `toString` stops traversing (and, thus, generating) the Stream after one element. This means that, from the caller's point of view, this function is as lazy as it can be. If you call ~~chunkLinesCombined(allLines).first~~ `chunkLinesCombined(allLines).head`, the algorithm will NOT traverse every line in `allLines`. It will eat the first header row, all child data rows, and then will look at (but not consume) the next header row. The amount of data that the caller consumes determines the amount of data that this function consumes. I think this is identical to the Python implementation. For an algorithm like this, I prefer to explicitly use Streams (instead of just using the normal collection operations like `map` and `filter`). Your goal is to combine adjacent lines into groups of lines. Operations like `map` and `filter` only let you examine one line at a time, whereas building your stream "manually" lets you examine and consume as much of the remainder as you like. Finally, the above function is given its strange name because it combines two responsibilities: chunking the input lines and massaging the data lines. Here's another implementation that splits those responsibilities: def chunkLines(lines: Seq[String]): Stream[(String, Seq[String])] = { lines match { case Nil =&gt; Stream.empty case headerLine +: tl =&gt; val (bodyLines, restLines) = tl.span(! _.startsWith("&gt;")) (headerLine, bodyLines) #:: chunkLines(restLines) } } chunkLines(allLines).map { case (header, lines) =&gt; (header, lines.map(_.filter(ch =&gt; !ch.isDigit &amp;&amp; !ch.isWhitespace))) }.toList This ends up being significantly longer, because we need to unpack our tuples, massage our data, and then repack the tuples. But if you need to process the data lines differently in different contexts, this approach lets you reuse more code. Ultimately, you know what you need your code to do, and so only you know how best to factor the code.
Using parser combinators is a nice functional way of solving your problem. Here is a small FASTA parser that a wrote two years ago. I still use it... https://gist.github.com/paradigmatic/3437345
Another solution occurred to me. def chunkLines(lines: Seq[String]): Seq[String] = { lines.tails.flatMap { case hd +: tl if hd.startsWith("&gt;") =&gt; Some((hd, tl.takeWhile(! _.startsWith("&gt;")))) case _ =&gt; None } } The default case actually covers two possibilities: one being when the tail is empty (the last element in the sequence returned from `tails` is the empty sequence), and one being when the tail starts with a non-header line. I didn't have a system to test it, but I expect it is just as lazy as the more explicit versions given in my parent response (assuming that the input is actually a Stream).
Thank you! The Akka HTTP docs are a little thin still, this is a great resource.
https://www.gonitro.com/au/about but I think they are only offering jobs in Dublin/SF
Atlassian is using it. They also host scalasyd where they get a very healthy attendance. Why not attend and have a chat to people. 
Fairfax have just rolled out a major bespoke publishing system built with Scala/Akka.
Just for the record, @tixxit and I later worked on a miniboxed version of the Optimistic (Re)specialization example: http://io.pellucid.com/blog/optimistic-respecialization-attempt-6 And it gets the same performance as the last attempt with idiomatic Scala code, no classtags and no casts :)
Stack Overflow Careers has an ability to search for company pages with a tag that might yield a couple more options: http://careers.stackoverflow.com/companies?searchTerm=scala&amp;location=Sydney 
In more depth implies you already know something. Can you be more specific on what you are looking for to learn? You could try to make a Play Framework project if you like programming for the web. You could try an Akka project if you like distributed and/or parallel systems. You could simulate a financial exchange: http://falconair.github.io/2015/01/05/financial-exchange.html You could do some code to operate on arduino: http://stackoverflow.com/questions/5701591/talking-to-arduino-from-scala 
/r/programmingprompts
Yep this is a good one, as an example try and create a board game like Monopoly. Start small and get the basic rules, iterate until you have a game with 1-8 players working. Then you could look at adding scaling by adding support for multiple concurrent games; and then you could look at how you would scale to say a few hundred concurrent games happening in parallel. 
What kind of project are you doing with Spark? Been wanting to practice with it.
I guess thats the question. Is it a function..or isnt it? How should I think about it. It sounds like extending function is pretty rare
Maybe it can issue some sbt-commands on files change (I didn't look into the source carefully, I don't know).
I am in a similar boat. I use Java 8 and I'm very comfortable and happy with that. I bunch of the functional, less ceremony, immutable structures stuff, and actor implementation drew me to research Scala. However, I approach things very much from "how can my _business_ use this", and as I was learning Scala, I very much found the vast number of features (and with it vast complexity) and consequential different ways of doing something to be a great detraction. I immediately saw that Scala was (perhaps) a great lone wolf language, but not terribly well suited to used in a business - at least, not without a great deal of effort going into writing a style guide that dictated what features were allowed to be used, and which were not. This would have a flow on to code reviews (making sure that the style guide was followed). When I saw Kotlin then, I quite liked that they had deliberately kept the feature set manageable. I've not done anything with Kotlin, but I'm interested.
Thanks again. Useful (but sad) information. Yesterday I've started test project with [spray-websockets](https://github.com/wandoulabs/spray-websocket) and for very simple tasks it seems to work. Althought I already noticed some bugs.
Which bugs did you notice? We are also using this ws implementation in an internal project.
What is your position on remote work with periodic visits?
Don't stress it. If you were a few versions back read the newest and upcoming release notes. Unlikely anything you could cram would change the interview.
Scala does not offer any significant advantages or disadvantages specific to game programming. Any game can be written in Scala. I don't think there are game genres or types that would somehow benefit from being written in Scala. I'm assuming you are making your first steps in game programming so here is some general advice to help you getting startet: ***** *This got a bit longer than intended and doesn't really answer your original question. __TL;DR:__ Pong, Breakout or Tetris are good starting points.* ***** **Start simple.** Even if you have the best idea for a totally new and awesome game, it probably won't be well-suited to be your first game. Start with something that has one or two simple core mechanics (bumping a ball around, running, jumping, etc.). This makes it easy to focus on getting things done and learning new things. You don't necessarily need to come up with your own idea either. For learning purposes it is perfectly fine to copy existing games. Pong, Breakout and Tetris are great exercises. (Just don't maket them as your own idea.) [**Start small.**](http://youtu.be/UvCri1tqIxQ) Even a very simple game can be quite a lot of work. The video I linked explains very well how to avoid that. It basically boils down to: Develop a prototype rather than a game. Strip it of everything that is not fundamentally important for your game. Fancy art, hordes of enemies and tons of levels aren't necessary to make a game. Of course, if you have a prototype and decide it's quite fun, you can always extend it. If you have any more questions about game development, head over to /r/gamedev. (As always, be sure to read the sidebar before posting).
Awesome, thanks guys!
what's a typeclass? whats the difference between a function and a method? what's a closure?
As a member of CBA's Scala presence I have to say that this statement is entirely ungrounded. We have around 60 people committing scala code, ranging in skill level from junior developers through to world class functional programmers in the core engineering team. Our use cases range from simply loading data through to machine learning pipelines. We have been delivering Scala code into our production clusters for 18 months now. You can take a look at some of our code at https://github.com/CommBank/ 
My companies uses scala in a functional manner, but we hire developers from all backgrounds for it. If we tried to hire only people that had read FP in Scala (we have a bookclub for it right now) we wouldn't have hired anyone.
Thanks for taking time out to answer what might seem stupid to others. :)
Practice whiteboard coding. It takes practice to be good at it and is't somewhat different of a skill than what you do all day as a software engineer. It's even better if you can do it with a friend -- she doesn't even need to know scala, just general programming, to run mock interviews for you.
But when I try to implement it in case class, I get the following then: case class Building(position: Vect2, hp: Int) extends Damagable { //Error:(24, 40) type mismatch; // found : abstract_type.package.Building // required: Building.this.type // override def withHp(hp: Int) = copy(hp = hp) // ^ override def withHp(hp: Int) = copy(hp = hp) } 
Isn't `self.type` just the singleton type, meaning `moveTo` would only work if implemented in a mutable way? Returning a modified copy will cause mismatched types.
"Explain the Reactive Manifesto." - really? Explain a vague, opinionated set of requirements to hypothetical app on a technical interview?
This is how you get good people. Hire the ones that you think can learn the tools you use, regardless of what they used before. A good programmer is a good programmer.
How about: trait A { type Self &lt;: A def foo: Self } class B extends A { type Self = B def foo: Self } 
To implement Building which returns a new value of the "same" type, instead of being path dependent, you must define a type to assert they're the value you're returning is the nearest common type between the self type, and your Trait. if you define a type member like so: type T &gt;: self.type &lt;: MyTrait You assert T is some type that is a super type of self.type, but also a subtype of MyTrait. Implemented like so: gives you what you're looking for: Welcome to Scala version 2.11.0 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_25). Type in expressions to have them evaluated. Type :help for more information. scala&gt; :paste // Entering paste mode (ctrl-D to finish) trait Moveable { self =&gt; type T &gt;: self.type &lt;: Moveable def moveTo(pos: (Int,Int)): T = self } trait Damageable { self =&gt; type T &gt;: self.type &lt;: Damageable def takeDamage(damage: Int): T = self } // Exiting paste mode, now interpreting. defined trait Moveable defined trait Damageable scala&gt; :paste // Entering paste mode (ctrl-D to finish) case class Building(position: (Int,Int), hp: Int) extends Damageable { type T = Building override def takeDamage(damage: Int) = new Building((1,2),damage) } val b1 = Building((1,2),5).takeDamage(5) // Exiting paste mode, now interpreting. defined class Building b1: Building = Building((1,2),5) scala&gt; We also retain the functionality of the previous example: scala&gt; :paste // Entering paste mode (ctrl-D to finish) class WorldUnit extends Moveable with Damageable { type T = WorldUnit } def doCombat[DM &lt;: Moveable with Damageable](obj: DM) = obj.moveTo((1,2)).takeDamage(5) def doStuffWithUnit(obj: WorldUnit) = doCombat(obj) val unit1 = new WorldUnit doStuffWithUnit(unit1) // Exiting paste mode, now interpreting. defined class WorldUnit doCombat: [DM &lt;: Moveable with Damageable](obj: DM)obj.T#T doStuffWithUnit: (obj: WorldUnit)obj.T#T unit1: WorldUnit = WorldUnit@288a4658 res0: unit1.T#T = WorldUnit@288a4658 scala&gt; EDIT: I should add this this constraint, unlike the singleton type isn't the same as an F-Bounded type. Methods returning T can return any type which satisfies all of the bounds. For example, if I subclass Building with Room like so: class Room extends Building { type T = Building } Returning a `Building` from `Room` is valid. Because `Building` is between the lower bound of `Damageable` and the upper bound of `Room.this`
Ta. Do you have a link to the ticket - I'll add my comments to it and see if I can provide additional debug info for them.
Are you on InteliJ 14? Mine works fine.
I'm using Scala-IDE and it is a lot slower than idea 14 (and less features).
The only super-annoying thing I've noticed since IntelliJ 14 is the plugin insisting on auto-inserting unit as a return type as I'm writing the code for a new method: def foo: Unit = { }
I guess that's because `def foo { }` is deprecated.
I think the deprecation was added before 2.11 (but hidden behind -Xfuture, until there is official tooling support to automatically rewrite existing source code). If I remember correctly, the reason for this was a) reduce unnecessary syntax sugar for things which are against the idea of the language b) remove the confusion caused for people learning the language.
So, What's the difference?
The first one dispatches both futures simultaneously, the second waits until the first future is complete before dispatching the second future.
[Interesting discussion on the relevant GitHub issue here](https://github.com/slick/slick/issues/1052)
Same here. Most recent update (1.3.2) has been most noticeable. Even something as simple as a copy paste in the same document lags for a bit.
I culled mine down to the following, didn't make a huge difference. - Coffeescript - CSS - Database Tools - EditorConfig - Git Integration - Groovy (Needed for Play it seems?) - Guicy - HTML Tools - Java Bytecode Decompiler - Javascript Intention power pack - Javascript Support - LESS - Play Framework - Properties Support - QuirksMode Support - Task Management - W3C Validators - YAML - ZKM-Descramble I think I may have found part of the issue though. I deleted my IDEA project folder and recreated it by importing via SBT Import, then manually modified the project structure to get rid of the "-build" projects, and ignore 'project' and 'target' folders, which it was erroneously seeing as source folders. This seems to have made a big difference - I think the problem may have been that it was seeing temp and dist class and jar files as part of the project. Whenever I change branches the SBT plugin seems to want to keep recreating the incorrect project structure again, so I have to keep manually trimming it back again. I also upped my heap size to 2G - since it was regularly hitting the default 768m and getting stuck in GC pauses. It's still slow, but vastly more usable now.
Our questions are usually of the form: here's a business problem that can be solved with software. How would you approach it?
It's not just about the money. That it is not open-source anymore can be a pain. Suddenly I don't have as many problems with the idea of Typelevel forking Scala. edit: I'd still prefer that they don't. Typesafe's [view on this](https://github.com/slick/slick/issues/1052#issuecomment-71229451) is appropriate. I wasn't aware (when I posted this comment) that they were transparent about this decision.
`def foo { }` is deprecated but `def foo = { }` isn't, right? So shouldn't the IDE be correcting `def foo { }` to `def foo = { }` instead? Leaving out `Unit` for trivial one-liners is still the recommended style, right? 
&gt; It's not just about the money. Ya, its really about having to talk to someone who controls the purse strings and having a mildly frank discussion about a trivial amount of money. &gt; That it is not open-source anymore can be a pain. MS-SQL is not open source either. All the free open source db's have free open source drivers through slick. &gt; Suddenly I don't have as many problems with the idea of Typelevel forking Scala. This does not actually have anything to do with Slick's monetization strategy.
Slick is only a very small offering in Typesafe's portfolio. If you go to Typesafe's website, you will need to search a bit to find any reference to Slick. It isn't even really branded as a part of the Play+Akka+Scala "reactive platform". I thus fail to see how this relates in any way with the Typelevel forking of Scala, unless this is just your way of expressing some sort of subliminal anger against Typesafe, or against for-profit software vendors in general? Surely, you will be able to explain.
How about now? 
You can spin up Azure SQL instances for $5
I really don't get the sudden uproar here - they announced that they were going to do this in 2013.
Please try 1.3.3 RC: http://blog.jetbrains.com/scala/2015/02/05/scala-plugin-1-3-3-rc-is-available/
Eh what? ... Not sure if this is serious or just making fun of the uproar itself.
The sky is falling! The sky is falling!
I'm more free-software-minded than most, but this is ridiculous. If having worked on some open-source software once means that a company is required to keep working on it forever, I can tell you how many companies will keep doing open-source: Roughly zero. Also, they don't demand "to be paid for putting it back". It's still there. They discontinued their open source development/support for one proprietary database. If you want continued services from them, get a contract or keep using their free stuff. It's as easy as that.
Absolutely right! sorry for the missing part !
If this is how typesafe wants to get paid - fine by me. They need money. I don't use paid databases when I can help it. Companies that do won't mind the small extra bill. Seems a win/win 
Hope so.
The type `Movable with Damagable` doesn't have concrete definition of T, it only has a set of type bounds. The type `WorldUnit` however has concrete definition of `WorldUnit`. You could try defining `moveAndThen` like so: def moveAndThen[A &lt;: Moveable with Damageable { type T = A}] 
I've updated the scala plugin to 1.3.2.21.EAP which I'm hoping is the same as 1.3.3RC. I'm not able to follow the steps to use the old implicit conversion search as the scala settings page [refuses to load](https://i.imgur.com/7MlFCw5.png). Editor performance seems about the same so far.
Well, azure does have a free tier that gives people the equivalent of about $50 a month -- so you could say the same. The article is talking about MS-SQL driver, not Postgres. 
&gt; If it's such a pain to get the money to pay for the driver, how did they get the money to pay for SQL Server in the first place? I've written software in bureaucratic environments, so I can provide a possible explanation. Often big, expensive DB installs (a mondo Oracle or MS cluster, say) will be a centralized resource shared by the whole organization or a large chunk of it. It's very possible to be part of a small team that uses such a DB install but mostly makes its own decisions regarding compilers, VMs, libs, etc. It's also very possible that while the parent organization might have zillions of dollars to spend, your team might not, or the bureaucratic hoops to jump through to get dollars spent on a Typesafe license might be too onerous. I currently work with hospitals that have giant Oracle installs. Any software I write that runs at those hospitals needs to run against Oracle, and it's too much of a hassle to get anyone to pay for the paid Oracle driver. We just use Squeryl instead. It's a flawed project, but most of the time it just works.
&gt; when they have to talk to accounting for 30 seconds to get the money to pay for software? If only it was 30 seconds. 30 weeks would be a good guess at some of the places I've worked.
...why? It is clearly not being maintained to the same level.
[Nerd rage!](http://imgur.com/sh6f0y6)
I guess that's the point: the Typelevel compiler is a conservative replacement. I actually don't _want_ a compiler that changes willy-nilly. The Typelevel compiler has explicit goals of being pull-compatible with the Typesafe compiler, a syntactically conservative extension, and generating bytecode that can be used with the Typesafe compiler. None of those goals is furthered by rapid-fire inclusion of changes to the compiler. So as long as someone is testing the pull-compatibility and bytecode compatibility at each release, the Typelevel compiler being more stable than the Typesafe compiler is a _feature_ rather than a _bug_.
Nothing to do with stability - I am not advocating using the bleeding edge compiler, just that these forks don't seem to have much development effort behind them. I see what you mean though, thanks for explaining!
this whole situation leaves a sour taste...sure i want people to make money, but for a db abstraction in 2015? this all seems backwards..but whatever their choice.
/u/void_fraction, that's not an effect of the for-comprehension but of the `val` assignment, correct?
I still have the same problem with that version. Attempting to copy a snippet of code (about 15 characters long with nothing special in it) freezes IntelliJ for 15-20 seconds.
How would one model this using typeclasses?
&gt; I am, however, extremely concerned about this "bait and switch" tactic of having a Free Software stack and then making necessary core components proprietary. When did a driver for a proprietary DBMS become a “core component” of a “Free Software stack”?
They modularized the sbt code. I really hope someone will come with a Maven plugin.
* This book: [Functional Programming in Scala - Paul Chiusano and Rúnar Bjarnason](http://www.manning.com/bjarnason/) ** [Exercices on github](https://github.com/fpinscala/fpinscala)
Depending on what you enjoy it might be fun to solve the Euler exercises without using mutable state (i.e., no var's and no collection.mutable's) and compare your solutions to other Scala or Haskell ones. This depends on how much you like problem solving and programming in general though, it could get boring pretty fast.
Josh Suereth talked about this at Pittsburgh Code &amp; Supply's Scala meetup last month. They're really cool!
This would be my type class approach to the problem: http://scastie.org/8057 EDIT: Fixed a small error: http://scastie.org/8059
I still can't switch to Functional thinking and use set of tools which it provides. So I have Java programs, written in Scala :)
Did u find that coursera scala course useful? I was planning to start that to get familiar to its functional programming side but I want sure if pick that or maybe a book
My rule about such prototypes is that I don't consider them until they implement operations like `groupBy`.
Let's desugar the for comprehension: for { a &lt;- getA() b &lt;- getB() } yield (a, b) becomes getA().flatMap( a =&gt; getB().map( b =&gt; (a,b) ) ) this makes sense if getB() requires the result of getA(), but since it doesn't sequencing them like this causes getB() to only be called *after* getA() completes for no reason. The val assignment before the for comprehension causes the underlying async actions behind getA() and getB() to be dispatched in parallel, instead of in sequence.
oh that's great. did you get any certificate also?
I haven't paid for verified certificate. I have only PDF file aka "Certificate of accomplishment", but it is useless
come play in /r/dailyprogrammer. it's a good forum, great community, and a great way to see the same problem solved by various languages and paradigms. plenty of us have been learning FP (i used it to get decent at F# last year, this year i'm focusing on scala) so you'll be in good company. i hear what you're saying about writing Java that scala can run, it takes time to break the mindset. it took me a while to break from python to FP, so it can be done. 
For my opinion the best scala book is a [Scala Cookbook](http://shop.oreilly.com/product/0636920026914.do) 
&gt; So I have Java programs, written in Scala :) It's okay to start this way. But you should have an open mind and be aggressive to seeking out better, more functional ways of doing things. Don't settle for the fact that your Scala looks like Java. Aim for it to look more Haskell-y (I guess).
I've been looking for a typeclass and compile-time based JSON serialization for Scala that could also seamlessly interop with Java. I'm okay with the typeclasses using reflection as a last resort though (I'm currently using Gson which just uses reflection by default). Sadly, it looks like this library [doesn't interop with Java well](https://github.com/scala/pickling/issues/60).
There are 81 [open issues](https://github.com/scala/pickling/issues) in the library, with no comments, labels or milestone assignments. Of course, every project has its fair share of issues, but radio silence doesn't inspire confidence in the stability of the release. Edit: Not trying to discourage the project; rather, would like to encourage more communication.
Yup, just another instance of the sad fact that Typesafe is more interested in releasing libraries so they can [write research papers about them](http://infoscience.epfl.ch/record/187787/files/oopsla-pickling_1.pdf) than actually creating useful products. 
read only the chapters that you do not know
hm.. no, thanks for hint!
akka-http is basically spray 2.0, and eventually spray as a separate project will cease to exist.
Regarding the "minor changes": If I'm not mistaken, most of it is ported and working in the early releases, but one of the most interesting part (for me) of Spray, spray-routing still isn't ported. And I'm not sure how that (spray-routing) will work into the Java/Scala interchangeability requirements of Akka because spray-routing is heavily dependant on implicits and type-classes.
http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0-M2/scala/http/routing.html#routes Pretty similar still
As someone with only cursory scala and sbt experience, can someone give an example of the problems outlined in this blog? 
His main objection, by my read, is that it's hard to learn and acts as a barrier to entry if you need to learn SBT before you can do anything in scala. I don't necessarily agree with that position, but SBT isn't exactly easy to understand.
Agree with you .
For a "hello world"-sized to small build you would specify: * one file **build.sbt** with your build definition; * one **projects** folder containing..: * * the file **build.properties**; * * *zero or more* .sbt-files; * * *zero or more* .scala-files. .sbt files are written in an archaic DSL with plain Scala mixed in while .scala-files use plain Scala only. The more-or-less mandatory build.properties file contains the one line *sbt.version=whatever.you.want* and nothing else. * The build.sbt *can be* responsible for defining the build. It resides in the root directory of your project; * You can also define the complete build in .scala-files. These files will then have to reside inside the project-folder; * .sbt-files in the project folder declare the *project*-project (yes); essentially they are used for loading sbt-plugins like Scala.js; I find the .sbt-DSL confusing at best. The idea is basically to assign values to predefined task-keys, either as literal values or by pulling values out of other tasks or build-time constants. Until recently (sbt 0.13.7) you were for whatever reason forced to separate each of these build statements with a new-line (only in .sbt-files mind you). Sbt boasts about how it uses Scala for its build definitions so I've always found this behaviour strange since Scala itself doesn't have this issue with blank lines (or lack thereof). In short, the build is spread out over several files and directories. The system is really powerful but too much to take in by far, in my humble opinion. 
Yeah, I'm going to go a little further than this and say SBT is complete crap. I mean, I don't know what it's like under the hood, but I do know it doesn't matter, because the configuration syntax is an utter abomination. Even the XML soup that Maven forces me to write is way better. Build definition should be simple and purely declarative. “This is a Scala project with GAV `com.example:foobar:1.0`. Here's a list of dependencies. I want the build to produce a binary JAR, source ZIP, and Scaladoc ZIP, and I want them all published in such-and-such repository. How you actually make that all happen is your problem, but here's a list of plugins you should use to get the job done.” Scripting should happen in script files and/or plugins, not the main build file. Gradle doesn't accomplish this, either, by the way. Even setting up a basic project seems to involve putting actual code into the build file. It's also got some serious weirdness to it, like how the `group` and `version` of your project are configured in `build.gradle`, but the `name` is read-only, defaults to the name of the folder the project is checked out in (WTF?) and can only be set in `gradle.properties` (WTF?!?!?). This is completely batshit insane. I don't even *want* to know what else Gradle does horribly wrong; that's already far more insanity than I can handle. Anyway, I've written up some specifications for a build system like the one I described, but I unfortunately do not have the time to actually implement them… Edit: It doesn't help that SBT appears to be surrounded by zealous cultists that refuse to see its flaws. Goddamn, that's irritating.
Thanks, that was exactly what I was looking for.
You can set the name of your artifact in build.gradle with 'baseName'.
The problem is that not a word of it is true. mkdir test &amp;&amp; cd test cat &lt;&lt;EOF &gt;App.scala object MyApp extends App { override def main(args: Array[String]): Unit = println("Hello, world!") } EOF sbt &gt; run This will compile and run the hello world app. A less trivial application will have a file, probably called "build.sbt," that looks more like: organization := "com.my-organization" name := "product-name" version := "x.y.z" scalaVersion := "2.11.5" resolvers += "Scalaz Bintray Repo" at "http://dl.bintray.com/scalaz/releases" libraryDependencies ++= Seq( "org.scalaz" %% "scalaz-core" % "7.1.1", "org.scalaz.stream" %% "scalaz-stream" % "0.6a" ) Somehow, `:=` for assignment, `+=` for appending one, `++=` for appending a collection, `%%` for "add the Scala version to the artifact name," and `%` for "delimit the components of a Maven/Ivy artifact specification" are just too much for people. Seriously, ignore the critics of sbt. I've long since lost count of the issues in Ant, Maven, Gradle, whatever that simply don't exist in sbt, and contrary to the sort of response your question elicited, sbt's power scales very well—all the way from literally not needing a project specification at all to multi-module, multi-artifact projects such as [Akka](https://github.com/akka/akka). sbt doesn't get _nearly_ enough credit for enabling exploratory Scala programming, either: sbt &gt; set scalaVersion := "2.11.5" &gt; set libraryDependencies += "org.scalaz" %% "scalaz-core" % "7.1.1" &gt; console scala&gt; import scalaz._, Scalaz._ import scalaz._ import Scalaz._ scala&gt; Start working through [Learning Scalaz](http://eed3si9n.com/learning-scalaz/)... Note that I didn't bother creating any kind of project definition; I just decided I wanted to explore an API or work through a tutorial or something. sbt is brilliant; very easy to get started with; and scales well to major, industrial-strength projects.
IDE support for the project build files would be a serious nice-to-have, as without it SBT is exceedingly difficult to discover/learn. I believe there is support now (via sbt-eclipse for Scala IDE users) for single project builds, but for multi-project builds ("sub projects" in sbt land) I've never been able to get it to work, IDE just spews out spurious errors. Being able to click through to SBT docs for a given Task/Setting/Property, and hover-mouse/infer-type would speed the learning process up by an order of magnitude I suspect. As it stands I just wind up blind coding, `reload`ing in sbt console and seeing what happens, which is a very slow process, *so much wasted time* On the plus side, once you get a handle on things SBT becomes an incredibly powerful build tool, and you learn to actually like it ;-) Haven't tried 0.13.7 or latest version of sbt-eclipse, perhaps things have already changed for the better (goes to see if things are better...)
Isn't that exactly what sbt does? 
You don't have to understand how it works to use it. Simple SBT projects are in fact really simple. All the new syntax you need to understand is a couple of assignment operators and the library version definition that you simply copy-paste from each project's instructions. I can't fathom how anyone can consider this more complex or harder to understand than Maven's XML, if you already know Scala.
SBT files can and should be purely declarative and are so in all simple cases, and even in complex ones if you bother doing the separation. Using Scala does not mean you should be doing imperative programming or altering the external world directly. It exists so you can write complex settings and tasks on a known language and *integrate* them with SBT's rules and ecosystem. If you want you can paste a giant blob of code in there, but it's not recommended and not at all the best way to do it. I'll give you a real-world example. This is the build.sbt from a web application I'm doing. It has an above-average complexity for SBT since I have integrated Heroku deployment, .env file loading, LESS, a custom source folder, GIT branch display, a task for uploading artifacts to an S3 bucket. Yet there is not a single line that is not a simple variable assignment or an import of other settings. All the custom logic is in .scala files. import play.PlayImport.PlayKeys._ import org.flywaydb.sbt.FlywayPlugin._ import com.typesafe.sbt.SbtGit._ import com.typesafe.sbt.less.Import.LessKeys name := "myapp" version := "0.1-SNAPSHOT" scalaVersion := "2.10.4" resolvers ++= Seq( Resolver.mavenLocal, "MyApp" at "http://myapp-maven.s3.amazonaws.com/", Resolver.sonatypeRepo("releases"), "Flyway" at "http://flywaydb.org/repo" ) libraryDependencies ++= Seq( "org.scala-lang" % "scala-reflect" % scalaVersion.value, "com.github.nscala-time" %% "nscala-time" % "1.6.0", "org.postgresql" % "postgresql" % "9.3-1102-jdbc4", "org.sorm-framework" % "sorm" % "0.3.15-18", "ws.securesocial" %% "securesocial" % "3.0.0-M2-2", "com.amazonaws" % "aws-java-sdk-s3" % "1.9.15", "org.flywaydb" % "flyway-core" % "3.1", "org.webjars" % "bootstrap" % "3.3.2", "org.webjars" % "jquery" % "1.11.2", "org.webjars" % "momentjs" % "2.9.0", "org.webjars" % "font-awesome" % "4.3.0-1", "org.webjars" % "slider.js" % "17.0", "org.webjars" % "spin-js" % "2.0.0-1", ws, cache ) lazy val myapp = (project in file(".")).enablePlugins(PlayScala, SbtWeb) /* Project settings */ unmanagedSourceDirectories in Compile += (baseDirectory.value / "project/shared") /* Play settings */ routesImport ++= Seq( "controllers.Pagination", "controllers.Pagination._" ) includeFilter in (Assets, LessKeys.less) := "*.less" excludeFilter in (Assets, LessKeys.less) := "_*.less" /* Console settings */ initialCommands in consoleQuick := Seq( "import models._", "import controllers._" ).mkString("; ") initialCommands in console := Seq( "import models._", "import controllers._", "new play.core.StaticApplication(new java.io.File(\".\"))" ).mkString("; ") /* Migration and environment settings */ dotEnvOverride := false flywaySettings /* Heroku and Git settings */ herokuAppName in Compile := Map( "testing" -&gt; "myapp-testing", "production" -&gt; "myapp" ).getOrElse(git.gitCurrentBranch.value, "") herokuJdkVersion in Compile := "1.8" showCurrentGitBranch /* Custom repository settings */ mavenS3LocalPath := Path.userHome / "maven-repo" mavenS3Bucket := "myapp-maven" mavenS3CredProfile := Some("myapp") 
SBT made a couple of major aesthetic errors early on that turned people off from it. It's still dealing with this "sbt hate" meme even tho it's resolved most of those issues. That's why people can make these "sbt sucks. Am I right guys?" blog posts without a single concrete example to back up their claims except fluff like "It's hard to explain to people" and "it just doesn't feel right". The mistakes, in my opinion, are: * Operators: I remember my 1st experience with sbt was a frustrating one. The projects I was reading used these cryptic operators like &lt;&lt;= and %% and I couldn't google them. This was a horrible 1st experience but I'm happy I stuck with sbt and they resolved some of it with nicer syntax. I later learned that the special dependency syntax was needed because all the settings I was making were rolled up into a single sequence of settings, and two values of the sequence depending on each other needed to be expressed through this function...I think... Honestly, 5 years later and I'm still not sure on that explanation. And I'm definitely not sure on WHY having things as a single seq of settings was so important and useful that they offloaded these operator monstrosities to the end user. And I'll never understand why many developers in the Scala community lack the empathy to understand how off putting these operators they casually toss around are to an end user. Let this be a lesson to library developers: There's a 99% chance that your library isn't special enough for me to bear the cognitive load of memorizing the semantics of your library's &lt;***&gt; operator (or whatever you pulled out of your ass). And doing that x3 different libraries is not a pleasant experience. * Enforced blank lines between settings: Once again, 1st impressions are important, and when you bump into this issue almost immediately, it causes you to associate negative feelings with sbt. And once again, it's another one of those decisions that I don't think was explained to the public very clearly. I think it was to allow you to modify/add settings from the console more easily? * Too much flexibility: ".sbt" files or ".scala" files? "Project" case class or "project" macro? In addition to these seemingly arbitrary choices sbt lets you make, the build definition gives you full access to Scala with very little abstraction. This can be daunting and, initially, my usual practice of "learning by example" didn't work very well because almost everyone's project looks significantly different. * Blurred lines: Sbt's build system and build definitions are both described in Scala (as opposed to something declarative like XML + imperative like Java). To some there's simplicity in this unification. To many (that I've interacted with) it's hard to keep track of where things start and end. I've witnessed many exasperated winces as I explained the "build of the build", why plugins go here instead of there, etc. Issues 1 and 2 have been fixed (even tho a lot of projects still use the ugly overloaded operators). Issue 3 is still a problem. In the end, people's issues with modern sbt are overblown or based on older preconceptions and group think. Most of the time you just have to set "name", "scalaVersion", and "libraryDependencies" in "built.sbt" and you're done. It's not that hard, anymore.
&gt;he doesn't understand that the .sbt file creates a List[Setting[T]] from which a Map of key/value pairs is constructed by merging the contents of all the .sbt and .scala files in the project definition Yes, you said that last time. It was irrelevant then, and it still is.
With this style is it possible (or could it be possible) for the multiple sbt files to share a namespace? It would be nice not to have to define these repeatedly. 
Excellent post. One more thing: .5. Magic convention sprinkled in. One opens one's first .sbt file, and it starts with "import Dependencies._". There is no Dependencies in sight. Is this a magic sbt feature, or is it something the project defined? Oh, look, by convention sbt imports all .scala files from project/ directory, and there is a Dependencies.scala in there. Now combine #3 and #5, and the sbt files that I get to see contain no explicit dependencies. Instead, they invoke functions from Dependencies.scala, which functions actually do the libraryDependencies. This leads to a frantic switch from .sbt to Dependencies.scala, trying to figure out which modules are actually imported, and which are dead code (or used elsewhere?).
Absolutely. It's very common for a multi-module project to share settings, including a set of common dependencies. See [multi-project builds](http://www.scala-sbt.org/0.13/tutorial/Multi-Project.html) for details.
It's _entirely_ relevant that you ask for _exactly_ what sbt gives you, and claim that sbt doesn't give it to you.
OK, that's fair, so my apologies. I think I read: &gt; For a "hello world"-sized to small build you would specify... as prescriptive rather than descriptive. &gt; I find the /project-build thing more confusing than necessary... I'm not sure what you're referring to here. &gt; the DSL convoluted... This is honestly the part I can't get my head around. For 90% of projects, there are half a dozen keys (`organization`, `name`, `version`, `scalaVersion`, `libraryDependencies`, `publishTo`) to be aware of, and half a dozen methods to set them (`:=` to replace a value; `+=` to add one; `++=` to add a list; `%` between strings building a `ModuleID`; `%%` between an organization and artifact name if you want the non-bugfix part of `scalaVersion` appended to the artifact name for you automatically). There: a one-paragraph sbt cheat-sheet covering easily 90% of all projects in the wild. &gt; and the fact that you're given several options to specify the exact same thing arbitrary. Someone expressed a desire to have named fields in their `libraryDependencies`. $ sbt &gt; inspect libraryDependencies [info] Setting: scala.collection.Seq[sbt.ModuleID] = List(org.scala-lang:scala-library:2.10.4) `libraryDependencies` is a `Seq[sbt.ModuleID]`. Google "sbt.ModuleID" and the first two results are sbt API docs for it. Both show that it's a case class. Scala case classes can always be constructed by their name with named arguments, a rudimentary bit of Scala knowledge. That took about five minutes of research after reading the question to answer. The only thing that _might_ be considered a leap is knowing how to use `inspect`, but that's learnable either by using `help` in sbt or reading the [reference manual](http://www.scala-sbt.org/0.13/docs/Howto-Inspect-the-Build.html), especially the heading "Display the description _and type_ of a setting or task." Personally, I don't bother using `ModuleID` explicitly because I find the `%%` and `%` methods so much more convenient, especially since sites like [mvnrepository.com](http://mvnrepository.com/artifact/org.scalaz/scalaz-core_2.11/7.1.0), which are first-Google-result sites for, e.g. "scalaz maven repo," include an sbt tab to copy the dependency from. &gt; Of course you can learn to use it and define powerful mechanisms with it, but it could be much simpler. No, it really couldn't. I was critical of your post because you seemed to be claiming that you _have to_ have multiple folders, multiple files, etc. even for simple projects. I gave proof by demonstration that this is false. When I was asked about named components of dependencies, I answered with information available by reading one paragraph of documentation and doing one Google search that provided the answer in the first result. So maybe "not a word of it is true" is a bit too strong, but you seem to be ignoring the sbt uses that are literally trivial enough to type into my shell to avoid typos, then paste directly here, and to be doubling down on claims of difficulty that were demonstrated to be false. So I'm in a bit of a quandary here. I suppose I have to leave it to others to judge, if not the veracity, then the reasonableness, of our claims. 
I actually looked into making a declarative DSL for SBT. I ultimately gave up trying to make sense of SBT's internals, though. Considering I had to figure out a fair bit about Maven internals some years ago, that's saying something. Maven is incredibly poorly designed and incomprehensible. SBT somehow managed to be even *worse.*
You've got that, `mkString`, something about `java.io.File`, a `getOrElse`, a bunch of `import`s, a `lazy val` (WTF?!), etc. That crap does *not* belong in the main build file.
&gt; mkString I could have written the string inline, it would just look worse. &gt; something about java.io.File That won't be parsed by SBT, it's just a list of Scala statements to prepare the console. It's configuration data, in the configuration file. &gt; getOrElse Again, it's configuration data. It's mapping from a git branch to a Heroku application name. I could have split it into a Scala file but it would make no sense to do so, it would be half boilerplate and repetition. The problem with your reasoning is you assume configuration information can only be plain data, but that's not true, it can be logic as well. The difference is semantic, not just a matter of using a key-value syntax for one and programming the other. You can move the logic away, but you cannot eliminate: by adding excessive restrictions you actually only make things more cumbersome and force separation of things that semantically belong to the same group. 
&gt;That won't be parsed by SBT, it's just a list of Scala statements to prepare the console. It's configuration data, in the configuration file. Hm. Fair enough, although I think it probably should go in an external “console startup script” file or something. &gt;The problem with your reasoning is you assume configuration information can only be plain data, but that's not true, it can be logic as well. It clearly *can* be; that's what SBT already does. That doesn't mean it's a good idea, however. I sure don't like it. &gt;You can move the logic away, but you cannot eliminate Nor do I want to. I want to *move* it, into separate script files and/or plugins. I want the *main* build file kept clean and simple, so that it can be understood at a glance and edited without fear. For instance, consider the `maven-release-plugin`. This thing does automated editing of `pom.xml`, namely editing the project version and possibly the dependency versions. Is there any way to do this sort of editing reliably on an SBT build definition file? What about making a GUI (of the checkboxes-and-text-fields variety) for editing SBT builds? With Maven POMs, that already exists, precisely because the POM is in a pure-data language (XML).
&gt; I actually looked into making a declarative DSL for SBT. Hilarious, since it's _already declarative_.
You're wasting your time arguing with someone who either _doesn't understand_ that sbt's project definitions use a declarative (referentially transparent) subset of Scala, or _does_ understand but is arguing in bad faith. Either way, I suggest we leave him weeping, wailing, and gnashing his teeth in the corner.
When copy/pasting, I usually felt uncomfortable because I didn't know which file to put the snippet in, or what sbt "style" it assumed, and whether or not the styles can be mixed. I think this will be less of a problem eventually, as the new mult-module style is adopted (scala within the ".sbt"), *assuming* there's not yet another change of the recommended style!
&gt; For instance, consider the maven-release-plugin. Have a look at [sbt-release](https://github.com/sbt/sbt-release). Also note that sbt is a well defined API, so of course you can programmatically rewrite settings. If you want to overwrite an existing .sbt source file, well you'll have more effort. For example, said plug-in requires you to define a separate `version.sbt` file. Looks reasonable to me.
&gt; Immutability by default is a great way to reduce bugs. But not that great to reduce memory leaks...
I'd say immutability usually means more memory churn—more objects allocated and deallocated—but less chance of memory leaks. Leaks are about allocating resources but forgetting to deallocate them. It's easier to forget to free resources in mutable code because state is more complicated.
For a scala-js project with a couple of scala-js libraries I saw output around 150 Kb, a couple of months ago. Didn't compile it recently, though, because my full-time job is server-side and spare time was spent with my family. Recent scala-js announcements say that output was a bit reduced in the releases 0.5.6 / 0.6.0 IIRC.
&gt; Machine editing of such a thing would involve complex tools similar to the automated refactoring functions in modern IDEs. However, I dare to suggest that outputting machine edited sbt build files (beyond the simple example of what the release plugin does with version.sbt) is a quite esoteric scenario. As I said, you can always have tasks that produce settings directly input to the sbt processor. As such there is no reason why, if you really need to have machine generated values represented as text, you couldn't embed them in any other format, i.e. plain old property list...
Also, here's a great talk from last years Scala eXchange about moving from a Java to Scala mindset, well worth a watch. https://skillsmatter.com/skillscasts/5835-bootstrapping-a-scala-mindset Enjoy :) (need to register as a member to view but it's well worth it)
And those cases are all of the cases. Because of the immutable mania Scala is 5 times slower than java at collections with the fact that scala uses pretty good compile-time optimizations.
&gt; collecting like a boss :)
Not really: in a GC world, leaks mean holding on to resources longer than you need, thus preventing the GC from kicking in. Immutability doesn't help at all with leaks. 
&gt; and the library version definition that you simply copy-paste from each project's instructions. One of my complaints, or things that I would classify as barriers to entry, is that these quickly become out of sync. There are lots of projects out there that do not build docs as part of a release which means that you end up with instructions that don't necessarily match up with the latest release. Or they don't re-build sample code for each release which means the sample code and correct settings start to drift apart (becomes an issue if you're doing anything more complicated than a version string). Even if a project manages to keep all their documentation in check with each release you still have other projects that have your version strings in THEIR examples, so now you've got to figure out if it's safe to use the newest versions of libraries and the dependent docs just haven't been updated or if you really need two versions, and now I'm getting a build error because the old version doesn't exist any more.
Was it straightforward to write a Chrome Extension in Scala.js? That seems pretty interesting!
Wow, nice! Thanks for the info, I'm a newbie at Scala but I'm really liking it's domain versatility: java compatibility allows scala on android, IOS (roboscala), and domains like game dev (libGDX). And Scala.js fills the rest, with even browser extensions being possible!
If you have a generational GC (which you should if you're sane) then mutability also creates more work for the GC since it needs to keep track of references from older objects to newer ones.
Say you have a Java interface "Addable" interface Addable&lt;A&gt; { public A add(A that); } You could define some static method somewhere called multiply: class Somewhere { static &lt;A&gt; A multiply(Addable&lt;A&gt; x, int times) { A out = x for (int i = 1; i &lt; times; i++) { out = out.add(x) } return out; } } In Scala, you can skip the boilerplate and do this: trait Addable[A] { def add(that: A): A def multiply(times): A = { var out = this for (i &lt;- 1 to times) { out = out.add(this) } out } } (Ignore the fact that this doesn't handle 0 -.-) It will be implemented the same way (the class defines an add method but if they don't define a multiply method, a static method is called instead), but the advantage here is you can easily drop in a more efficient version of multiply to your Addable trait. And multiple inheritance is solved thanks to ```extends X with Y, Z,...```
Basically... Use inheritance when you have an is-a relationship: I.e. Programmer is-a Employee Traits allow for code reuse across disparate classes: Employee implements hasPhysicalSize, motorcycle implements hasPhysicalSize And interfaces are more used as a contract when writing code, than a method of code reuse. If you set up interfaces to outline your project before actually implementing anything. Then everyone can code against the interface because it won't change, but the implementation can.
At one point, they did have Scala for .NET. They lost the maintainer however, and no one picked it up. And just because .NET is the platform of choice doesn't mean you can't use Scala. Since it runs on the JVM it will run anywhere.
&gt; As for a .net backend for Scala, it was tried, failed and it's now abandoned (and considered close to infeasible because of the fact that .net has reified generics). Do you have a source for that? I'm fairly certain it was an issue of maintainership and certainly not because of reified generics(a feature that would aid in porting to the platform, not hinder it).
Documentation on the subject is pretty easy to find, [here is one example](http://stackoverflow.com/questions/27100623/recent-announcements-by-microsoft-and-the-state-of-scala-net): &gt; the Scala .Net effort was abandoned sometime in 2012, as I understand, mostly because of no interest from Typesafe and difficulties to marry the Scala and the CLR generics. And you are wrong about reified generics: it's equally well known that reified generics considerably cripple interoperability with other languages, which is why erasure was such a smart choice to make for Java. 
&gt; Documentation on the subject is pretty easy to find, here is one example[1] : That example doesn't demonstrate anything, it's just some guy rambling on stackexchange, making up stuff about things he clearly doesn't understand. For example: &gt; Project Valhalla which talks, among other things, about possible inclusion of reified generics in JVM That's not what Valhalla aims to implement, it aims to implement value classes and specialization of generics.
&gt; Scala runs on android, IOS (through roboscala) Ha, interesting, I didn't know about that. https://github.com/roboscala
Traits are basically Scala's workaround for the JVM not supporting multiple class inheritance (which is **not** evil, by the way).
&gt; The implementation part provides a has-a. I think that just adds to the confusion. Even if you cleave the two uses of traits into two groups, inheriting from the trait always provides an is-a relationship between the subclass and the trait. 
&gt; inheriting from the trait always provides an is-a relationship between the subclass and the trait I'd say if you are using traits like this, you haven't understood traits. Inheritance is an implementation detail of the (very important) has-a relationship.
That's why I talk about functional composition. Traits don't really fit the standard UML concepts, without having to force them into the is-a mode with multiple inheritance.
The company I work for was fully committed to the .NET platform, and after playing with F# for a bit, I and two other developers convinced them to develop new software in Scala. I actually think even despite the disparate platforms we're getting a significant productivity boost over F#. The language is just missing too many essential features (type classes, etc). 
It was both. Reified generics essentially lock you in to a particular type system. [Here](https://groups.google.com/forum/#!topic/scala-language/y77XxLY2yrE) is some recent discussion aoubt the difficulties.
But it's not really forcing. They **are** multiple inheritance. Heck, when I was writing up my epic novel of a comment elsewhere in this post, I jumped into the REPL and learned something. I had always known that traits could declare abstract vars and vals, but I had never realized that they can also define the storage for them. Try it: make a trait with a var and give it a value. Then make a subclass. The var is available and assignable. Traits are very capable. I think that from Scala's point of view (not the JVM's point of view), mixing in traits is essentially the same as having multiple inheritance.
Traits provide a way to do functional composition and currying in a way that is more familiar to people used to OO programming. * Abstract defs = unbound functions, either as a parameter or as a function to curry * Abstract var/val = unbound parameters, or values to complete a curry with * Defined defs = bound functions * Defined var/val = bound parameters The defined object is then equivalent to a higher order function that can be called. Vars can either be thought of as a mutable function, or an unbound parameter. If you think in OO, its multiple inheritance. If you think in FP (which Scala is primarily based off of), it's an alternate syntax for composition of functions. [edit]Given your novel of a response, you view it as multiple inheritance because C++ has colored your vision with OO. Just think of the abstract parts of a trait as inputs to a lambda, while the defined parts are bound inputs.
Personally I wouldn't write desktop real-time games in Scala. Because GC wouldn't make users happy and because there even is no OpenJDK on windows.. Other than that, Scala seems like a nice language to do stuff, games including.:)
You compose traits by inheritance. Traits describe capabilities, not an is-a relationship: `class Human extends HasName with CanTalk with Ordered[Human]` is not a `HasName`, it is a human that is capable of giving his/her name. `Human` is not a `CanTalk`, it's a human that can speak. `Human` is not an `Ordered[Human]`, it is a `Human` that can be ordered. "Composition" is what traits are doing, and "inheritance" is how traits are doing that.
The documentation is quite good and novice friendly. Have you seen this: https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#hlist-style-operations-on-standard-scala-tuples The underlying implementation is not novice friendly ofcourse - it relies on macros to transform HList &lt;=&gt; Tuples
Very exciting and good luck! one comment - the hour is a little early for people outside the perimeter :) There are a lot of great Scala devs in the Alpharetta Area that would love to join but will skip due to the rush hour commute 
Thank you. Yeah, I hadn't seen it / couldn't find it. My bad :/
Like I said, we must have learned this differently. I agree that we're composing here by inheriting. But I didn't learn "HAS-A" to be synonymous with composition. If we assume that the typechecker is checking IS-A relationships, then any inheritance from a trait establishes an IS-A relationship. Compare this to private inheritance in C++, which composes via inheritance WITHOUT establishing a publicly visible subtype relationship. But as for your example, I would definitely say that Human IS-A HasName, Human IS-A CanTalk, and Human IS-A Ordered[Human]. You could mentally translate those trait names to something more like Human IS-A ObjectWithName, Human IS-A ObjectThatCanTalk, and Human IS-A ObjectThatCanBeOrderedAgainst[Human]. And those make sense to me. If you still think I'm off my rocker, I'd love a link to a more detailed discussion of your interpretation of IS-A vs. HAS-A. 
&gt; Hilarious, since it's already declarative. Kind of. In practice, SBT is declarative *and* procedural. (Yes, I know it's all referentially-transparent, but I've seen plenty of SBT files that effectively script up whatever complex settings changes they're applying, rather than simply declaring them.) Build tools will always suck, I fear, because builds for real systems are always giant, hairy problems with a lot of necessary complexity. I've had the misfortune of trying to contort Maven into scripting up some integration tests (start app server, deploy war, run tests, stop app server), and it sucked. But I also just set up an SBT build for a two-module Scala.js project, and it was very painful, largely due to SBT doing too much magic on my behalf. In a past life, I wrangled GWT Maven builds; even that was easier than making SBT build a Scala.js project. There is no silver bullet.
Scalaz has this too though, and I don't do scala without scalaz. :) 
AnyRefMap is pretty amazing for those use cases.
Fill out some missing entries in Rosetta Code. http://rosettacode.org/wiki/Reports:Tasks_not_implemented_in_Scala
that's a good one, http://www.infoq.com/presentations/scalaz-introduction Has a good talk on some stuff, there are a few others out there. I also recommend coming to the freenode IRC channel #scalaz. There's a REPL bot so you can ask questions and get realtime help. 
&gt;Wednesday, December 3, 2008 This shit is WAY out of date. Manifests are deprecated. http://docs.scala-lang.org/overviews/reflection/typetags-manifests.html
We are using Scala in some projects in Melbourne's lab of IBM Research.
I'd pay to see this as a recording or watch live remotely. I don't live anywhere near SF :(
While the "shit" is indeed out of date. I don't think that `Manifest` is already deprecated. But `ClassManifest` is: http://www.scala-lang.org/api/current/#scala.reflect.package
There probably will be.
Don't scalaz's futures provide something similar?
I think one difference is the `.await`, which works kind of like scala-async's `await(...)` in that it lets you treat future values almost as though they were synchronous within the `Future` block, and presumably does some kind of CPS transform to make this non-blocking.
feature vectors for ML. very similar to that example. im going to be doing vector comparisons using L1 norm. but I also need type safety in the construction of the "vector", so instead i just use case class. 
&gt; I guess what I should have said was that it was harder than it needed to be. I don't doubt that in the slightest! &gt; Maybe it's no longer the case, but the requirement to have blank lines in a config file in the mid-20-teens is/was jarring and kind of amazing, especially given that Scalac cares a lot less about whitespace than SBT does. I may hand wave this away too much. It annoyed someone enough that sbt 0.13.7 abolishes it, at the expense of using a custom parser instead of the built-in one. I wouldn't have made that trade-off. In fact, I'd accept a bet that it will bite them later. BTW, I'd also feel differently if _indentation_ mattered. &gt; In the end, this will all probably shake itself out. SBT reminds me of the bad old early days of Maven in the 2000s, when IDE support was bad or nonexistent, documentation was poor, and good conventions hadn't been established. All of that got better for Maven, and it will likely get better for SBT in a couple of years. I was just re-reading the sbt Changelists, and I think you're right. I'm struck, for example, by the number of things I feel "I couldn't live without" now that were only introduced in the 0.13.x series... but I've been using sbt since the 0.7 days. :-) So it will be nice to see where we are in a couple of years.
many thanks. exactly the type of answer i needed. im not sure what you mean by facade though. do you mean create a class then create the array from the class? one constraint i have is that one of the arrays are sent over network, and the ones to compare to are constructed by database query. so i need serializability
The above is either bad, or naive advice. You don't need to create a Facade, you can `toList` and array to copy it to an immutable list at any time. `toStream` will create a stream that memoize values as their evaluated to avoid the upfront cost of copying, but then you risk inconsistency if the array is mutated while evaluating. Consider using Spire for numerical evaluation, this library allows you to abstract over many kinds of numbers(Semigroups, Rings, Monoids, Fields, etc) while still remaining performant, such that you need not worry about which representation of a real number is most efficient, only the capabilities of the algebra you want to work with. You can further performance with miniboxing, which will then allow you to specialize methods which use primitives to avoid the cost boxing and unboxing. Alot of computational method in Spire already do this, but you'll need to implement miniboxing yourself for your methods though.
This brings us perilously close to having the same problem that Java checked exceptions have. Scala doesn't enforce checked exceptions for a reason. Anyway, in order to do what the article proposes properly, we need real support for union types. `Either` is awful.
One of the main difference between stateless-futures and scala.concurrent.Futures is that with s-f you compose a set of async operations and then evaluate them later, whereas with s.c.F you compose together and transform async values. (There are other differences too, like the approach to threading.) The two approaches—async operations and async values—are closely related. They can actually be combined. You can compose together asnc operations which you evaluate to produce an async value, which you can then transform using async operations, which can be evaluated to produce another async value, … and so on. I think it would be useful to have some sort of async operation data type, similar to s-f Futures, in the scala.concurrent library. This data type would need to integrate with the existing Futures of course.
I think union types are the sum type equivalent of tuples. So you can say ```def f(x: Int): (Int | String)``` And f will return either an Int or String and you can branch based on a type check later.
He says in a thread about the most compile-time library in the ecosystem. 
I'm really not sure. I asked him the same thing.
`Either` is boxed (meaning very high memory usage and GC load), and the syntax for examining it is atrociously bad (`case Right(Right(Right(Left(e)))) =&gt; ...`).
Sorry, but I don't see how parallel collections are relevant to described issue.
I have not gone down this hole. What is a filled execution context? Why is it not an unbounded queue ? How many futures till it dies?
What you said does not make any sense. As far as I know, there is no synchronous code in my example. Code you suggested for sure is not equivalent. To start with, blocking {} causes creation of any number of additional threads.
Usually number of threads in execution context is limited. It could be changable depending on current load, but generally nobody makes it unlimited. Imagine you created 10 000 Futures (using Future.traverse or because there is really a lot of requests) but there is only 100 threads in execution context. In this case only 100 futures are running simultaneous, and (10000-100) are waiting.
It depends on what your futures are doing. If you fill up an execution context (e.g. threadpool), you can prevent the EC from expanding if using a library like akka. More importantly, if your futures return a large amount of data, you can overload the jvm.
&gt; you can prevent the EC from expanding if using a library like akka. By controlling the number of active actors? Or does Akka's default EC?
I assume he means the heap. If you have a 4 gig heap and have 5 threads return a 1gb future at once you would oom. If you limit to 3 threads at once you would be fine.
You can think of \\/ as a special case of union types. The general case is [Coproduct](http://eed3si9n.com/learning-scalaz/Coproducts.html).
&gt; I don't think those advices are either bad of naive. Creating an immutable copy is not only slow (when the number of features and instances is high) but could let you to bad surprises. As you said nothing will prevent the array from mutating. Streams comes with an overhead and the memoization memory footprint can be bad for large dataset. So a facade seems a logical choice... That's exactly what List and Stream already are, facades, the only other option is to use a View, which neither copies, nor memoizes, but is not immutable in any way. What would writing your own possibly do that these three don't do already? &gt;1-D regular arrays are the most serious choice for high performance computing because: 1) The memory footprint is minimal; 2) they don't need miniboxing/specialized because they natively are; 3) They allow very fast access, because the data is contiguous (that increases CPU cache hits a lot). Miniboxing and specialization are orthogonal to using arrays, other than using them will allow you to use Arrays anywhere you use any other collection, without letting the JVM's runtime representation of them prevent you from doing so.
Yep. You can also death spiral it with excessive gc due to the bringing back of the data overloading the system, which prevents you from handling it, which causes it to fall out of new gen, which increases gc times, which prevents you from handling it... Makes the system unresponsive due to the load, and then if you're heap dumping, unresponsive then.
Akka uses a message to expand the thread pool. If all threads are dealing futures, you can't expand the thread pool. If handling your response requires additional execution in threads, you can lock your threadpool.
Yes, I saw that. It's incomprehensible gibberish unless you have formal training in category theory, which I don't. That is useless to me, and to most programmers.
That is because said tools *suck.*
You say that _utterly without a basis in comprehension_. Seriously, you have no contribution to offer here. Why not go take up a suitable hobby, maybe basket weaving?
Don't feed the troll.
&gt; Akka uses a message to expand the thread pool. If I understand correctly, each Akka actor is mapped to a thread in the thread pool. Isn't it up to the programmer to decide how many actors to spawn in the first place, and thus, controlling the thread count? Unless I am misunderstanding what you mean by "expanding the thread pool"?
That adds a superfluous type parameter, a superfluous implicit value parameter, I'm guessing that `match` doesn't have an exhaustiveness check, and the implementation of `∈` is, as I said, incomprehensible gibberish. I'd much sooner do without union types than add such inelegance to my code. [Ceylon-style union types](http://ceylon-lang.org/documentation/1.1/tour/types/#union_types) or GTFO.