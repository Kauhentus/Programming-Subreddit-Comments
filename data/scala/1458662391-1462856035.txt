I would check out Dean Wampler's talk on Big Data: https://www.youtube.com/watch?v=AHB6aJyhDSQ
To be precise, no functors aren't homomorphisms. As functors need an additional constraint that takes, identity function to identity function. Which is not really necessary when we consider homomorphism of categories. http://math.stackexchange.com/questions/405459/homomorphisms-vs-functors
I find the predef Map problematic since it breaks the whole generic scala.collections.Map interface. Why force the interface to also be an implementation? And while we're at it, why not have an immutable LinkedHashmap or make the toMap() preserve ordering if the source implementation happens to be a LHM! It's crazy that mutable ListMap doesn't preserve ordering while immutable ListMap does. Really the idea having to pass maps around as a mutable.Map or immutable.Map or collection.Map is silly. Why not make collection.Map the immutable interface, have mutable.map extend it with mutable methods and then can the special immutable interface that adds no value except to create hell for developers by making it a Predef!
Thanks! Any good tutorials that you can point to.
Right. Isn't the implication that all functors are homomorphisms, but not all homomorphisms are functors? [This](http://math.stackexchange.com/a/405479) articulates the notion formally. Of course, we're missing the point that my comment, even if correct, is tongue-in-cheek, in the "a monad is just a monoid in the category of endofunctors; what's the problem?" vein. Even in libraries like [scalaz](https://github.com/scalaz/scalaz) and [Cats](https://github.com/typelevel/cats), you'll search in vain for representations of "homomorphisms" and "the category of Scala programs." The ha-ha-only-serious aspect of my comment was that [in the category of small categories, functors can be thought of more generally as morphisms](https://en.wikipedia.org/wiki/Functor), and since "the category of all Scala programs" seems to be a [small category](https://en.wikipedia.org/wiki/Category_(mathematics\)#Small_and_large_categories), our "homomorphisms" are just "morphisms," and without loss of generality we call them "functions" and sometimes talk about "sets of values" or, even more rarely, "sets of functions."
If you really care about startup performance, Python is currently the best runtime on AWS Lambda, with in my experience at least ~2x faster start times than Node. Hopefully in the future AWS Lambda adds more runtimes with better startup times, such as golang or even a native runtime. A Scala-&gt;native compiler could really excel here in the latter case.
Variance, higher kinded types and how Scala is rewritten as Java would be a good start. I find that underscore.io has a lot of great links on these things.
&gt; Seems like the browser you are using is not actively supported Oh well... sorry for using Firefox.
I like Lisp for machine learning, that's pretty much it.
http://eed3si9n.com/learning-scalaz/ is a good resource. 
Umm... that's not advanced functional programming. Monads, Arrows, Haskell, scalaz. Tell me three different types of monads. Implement them and show me map/flatmap and do/yield notation.
I'm a stupid 22 year old, so I don't know stuff, but do you do this for free as like a volunteering thing (spare time endeavour) or are you paid to do ScalaTest?
That is retarded. I know Scala well and I have never worked a job (other than Subway) and just finished college and no one will hire me due to lack of experience. Honestly, you could just ask for a "junior functional programmer" or even a "functional programming intern" and it would be easier to teach them Scala than it is to teach functional programming to a Java developer. You'd be amazed to find that some young programmers actually know the language already and just need that experience. I mean there aren't a lot, but if you extend your job search to people who are out of state, you might be amazed. I was just rejected by a company looking for a junior functional programmer because they found someone else with a solid knowledge of Scala plus more experience. The Amazing part about it was that the guy who interviewed me said that he wasn't expecting to find novice Scala developers - he thought he would have to train them.
check http://www.nescala.org/#what
Serious question - why hasn't that many large systems/projects been built using Haskell in a corporate setting?
Even though I'm not a scalaz guy, I don't like my happiness to be based on someone's unhappiness. Or at least, I don't wanna say that haskell is unuseful. Still, I'm happy that Scala is doing well.:)
As far as I know ScalaTest is a side project of Bill Venners.
Could you give some examples? I'd be interested to hear
Well I guess to clarify, our project uses a lot of existing Java code and Java objects. We aren't writing anything in java now, but we certainly are using java. Java 8 translates well into Scala I think.
Most corporate developers are oo Java devs. Scala is a huge change for them, haskell is not even realistic.
This definitely helps! Thanks!
They are asking 4 years of experience. If you just finished college let's say 4 years you can consider you have 2 years of experience. Don't be intimidated by the experience requirement. It says that you need to be passion to learn new technologies. This is the attitude you should strive for. My advice would be to contribute to open source project (or start one yourself). Let's pick a random open source project: Spark. Scan the issues for low hanging fruits and fix them (for example this one https://issues.apache.org/jira/browse/SPARK-10681).
[Galois](http://galois.com) solve hard/complex problems using Haskell. Take a look at [cryptol](https://github.com/GaloisInc/cryptol). It's a language built on top of Haskell to implement crypto algorithm ([SHA1](https://github.com/GaloisInc/cryptol/blob/master/examples/SHA1.cry))
Lack of frameworks, poor compile times, poor performance (this tends to go away in highly concurrent, internet bound distributed systems), inconsistent performance due to lazy evaluation, no good IDE (strongly typed languages like Java tend to benefit from an IDE) and most importantly, no backwards compatibility. I mean Haskell has some frameworks, but not nearly as many industry ready ones as Java. The performance isn't always bad, but C/C++ can run much faster. Haskell defaults to lazy evaluation and lazy evaluation supposedly hampers optimization and causes profiling to be less consistent. The auto-complete is crap and the IDE isn't nearly as good as Java. Finally, and most importantly, is the ability to gradually jump into it. C programmers could gradually incorporate C++. Java developers could gradually incorporate Scala. 
What good is it anyway if it is not using your production data storage? Same could happen that your test passes here but your prod db is configured differently? 
Didn't someone post that knowing spark shared a strong correlation with the highest paying programming jobs? With that said, if you want to guarantee yourself job opportunities the most important thing you can know is how to develop software as part of team. Experience is key. I'll take a high school graduate with a proven track record and a good word from a reference I trust over a newly minted graduate student any day. 
You will more than likely be interviewing for a low to mid level job. Those types of positions will not require (in an interview at least) that you fully understand the language and you're perfect with it.
Yeah I understand that. They'll most likely test me on Algos and Data Structure questions.
I'm new to Scala and functional programming. Please help me solve this: http://stackoverflow.com/questions/36190535/forward-reference-extends-over-definition-of-variable-in-scala
apply on x.ai! I can't guarantee that we'll hire you, but we do data science on scala, and we are building a robot, not a boring analytic tool for finance. As most scala shops do on NYC and elsewhere 
Are you hiring any intern?
The answer is that you'll be more fine. Where are you from? My best advice to you is fill the Hadoop gap if you have any (if you focused on spark like me then you probably don't know too much about hive, what is a namenode, or writing a mapreduce job) It might make you want to tear your eyes off after working with spark but will triple your employability. Source: I'm a 10 years plus java dev who gone scala then Apache spark and got several job offers as a data engineer and all were a huge pain to get because I didn't know Hadoop much (I have code committed into Apache spark and worked with it before version 1). I'm also a part time grad student and live in the US. Edit: typos 
These are good questions and I'd love to see them generate some good answers. You might be able to help speed that up though, by thinking up and presenting some concrete example scenarios.
&gt; no backwards compatibility. Even though this answer was downvoted, I think this is major point that people gloss over. Haskell essentially doesn't have a stable ABI, it basically breaks every 6 months or so (when a new GHC comes out). For a statically compiled langauge, this a pretty big deal because it means all of your library dependencies need to be compiled whenever GHC bumps its version and for larger companies, this can create pretty big headaches when you get into tooling and build chains Which gets to me second point, Haskell is still treated as a "research" language, so there wasn't any real emphasis that is put on tooling and stability in terms of libraries and build systems. Its only up until recently that Haskell has implemented sandboxing (via cabal) through builds, before that developing in Haskell on a large scale (context of large scale here is lots of developers) would be really painful especially since Haskell didn't have a stable ABI (compared to the Java ecosystem, which had a backwards compatible ABI that only changed once every few years). From a language design perspective, this gets compounded even more. New GHC releases tend to add new extensions to the language, which popular langagues pick up and use. This means that, as a company, if you want to use a library that has a `{-# LANGUAGE SOMEEXTENSION #-}`, you need to upgrade your GHC, which as mentioned before is painful due to no stable ABI. Then there are the obvious points, which has been mentioned before (like not having a real usable stable IDE). Haskell has a different set of priorities which means that the developers it will target (and hence be suited for) will always be much smaller than Scala (and much much smaller than other "mainstream" languages). This doesn't mean the language is bad, but its always going to lag behind in this regard.
Scala developers are actually in really high demand right now, and according to the latest stackoverflow survey they are one of the highest paid languages right now for people in your (and mine) age bracket. A lot of companies have started to use Scala in their backends, and since they have started scaling their teams they are looking for Scala developers (and there aren't that many people Scala developers). In my opinion its not a bad idea at all, however it might be advisable to at least learn a bit of basic Java/Go/Python/Ruby as a fall back in case you have issues with looking for work (you shouldn't though)
I think the [Elm Architecture tutorial](https://github.com/evancz/elm-architecture-tutorial) is the best introduction I know of to using immutable data to handle state - Redux takes a lot of clues from Elm. In Scala there's [Diode](https://github.com/ochrons/diode), which attempts to create an Elm/Redux-like framework, but I've found it a lot more verbose/less elegant than Elm (disclaimer: I've never actually tried to build anything with Diode, just read through the documentation).
Yes state must evolve and, what's more, your program will have side effects if it influences its environment at all. The goal in FP is to tightly control state change and side effects while keeping most of the code functional. If you are doing something like redux architecture, which centralises state evolution, you might find the idea of a Lens useful. See Monocle https://github.com/julien-truffaut/Monocle for a sophisticated implementation. This solves the nested state update problem you describe. Each part of the application is concerned with one part of the state only. A Lens "focuses" the whole state to one part. 
&gt; like in Symfony, they're just strings, but in PHP that's not a problem... You mean it silently converts non-integers string to zero and you're just not aware of the problem unless you happen to see it? &gt; and also that because the input is provided as a Map, everything is an option, which means commands need to have a lot of extra code to account for that - even if the developer knows the input should be there because of parsing and validation. That sounds really off. Please provide examples.
HiveQL is often needed anyway if you use Spark SQL, so this is not lost. 
I had actually been taking a look around Diode earlier too, but I did manage to make my own extremely lightweight implementation of a "Redux-like" architecture. The only problem was that at it's core it still has to use a mutable `var` for when the state changes. I'm still trying to poke around Diode to see if it has the same issue.
Interesting! I didn't know that. In this case, the default should have already been handled before the command is even run as it's currently implemented - it would have done something like output the help for the command you're trying to run, so this is a slightly more succinct way of handling the current implementation at least. I still can't shake the feeling that you should be able to do something like: class FooCommand extends Command { def execute(input: InputModel, // ...): Unit = { println(input.bar) } }
I got offers eventually, but at least two of them were downgraded to mid level from senior because of my missing Hadoop background. Spark seems to be "the future", but many companies still have more classic Hadoop ecosystem, I would have been getting much better offers if I had Hadoop experience.
Very neat!
examples of java devs learning scala or dogma?
I am a java dev learning scala, so dogma please :)
&gt; And sometimes it's really ok to throw caution to the wind and just use the (gasp) var keyword. Life's too short to try to make every single program into a functionally pure masterpiece. I don't know about "masterpiece," but there is no problem whatsoever (well, I mean after learning how, of course) with doing pure FP in Scala, and there is no valid use-case for `var`.
That's a more straightforward reply (the code is). Why didn't you respond with that?
Not `var` per-se, but mutability in general. There are times when it's appropriate. For example name one real-world cache implementation that's functionally pure. It's not done because the performance would be horrible. Or more abstractly, what about `lazy val`? Sure the compiler treats it as immutable, but the code it generates is definitely stateful (it uses a lock and then mutates a local field). *Someone* gets to write the mutable corner cases. In a perfect world, it's the compiler doing all of that. But sometimes the burden does fall on you, and in those cases you take your medicine and do what you need to. But yes I agree as much as humanly possible it should be avoided.
Thanks! I think I'll have to take a look though learning scalaz. I'm not in any rush to learn FP / Scala, so I this should be good :) - it's just for personal projects at the moment, hoping to start using it professionally when I feel ready for it.
Yes, absolutely. One of the major reasons several of us are adamant about being 100% clear about the definition of referential transparency is that it is about _interfaces_, not implementations. Let's take `STRef` as an example. You'll see that it does, indeed, have a [`protected var`](https://github.com/scalaz/scalaz/blob/v7.2.1/effect/src/main/scala/scalaz/effect/ST.scala#L15) for its value, and modifying the value [mutates it in place](https://github.com/scalaz/scalaz/blob/v7.2.1/effect/src/main/scala/scalaz/effect/ST.scala#L22), as does [writing it](https://github.com/scalaz/scalaz/blob/v7.2.1/effect/src/main/scala/scalaz/effect/ST.scala#L28). The types just ensure that the `var` reference doesn't leak, and these mutations are done monadically, as described [here](http://eed3si9n.com/learning-scalaz-day16). If you keep scrolling down, you'll see that `STArray` does exactly the same thing: [mutates in place](https://github.com/scalaz/scalaz/blob/v7.2.1/effect/src/main/scala/scalaz/effect/ST.scala#L79). But `STArray` is, again, referentially transparent. &gt; Someone gets to write the mutable corner cases. In a perfect world, it's the compiler doing all of that. But sometimes the burden does fall on you, and in those cases you take your medicine and do what you need to. Sure, but again, there's never a need to make the _interface_ non-referentially-transparent, and the odds are good that _you_ don't need to write a referentially-transparent mutating reference or array—it already exists.
Lucky you! But I gotta say, it's _awesome_ to use on the job! Again, toss questions my way, and have fun with it!
Wow! Thanks for writing this up for me. So, I've been trying to get to grips with a few core concepts of FP in Scala like Monads already, but I'm not sure what you mean by "define an algebra", do you have any examples of this? Are there any open source FP Scala applications that you'd recommend looking over the source code of?
map(key) works without returning an Options and by this point you know the thing's in there. And casting to int is just .toInt. case class Input(args: Map[String, String], opts: Map[String, Option[String]]) class FooCommand extends Command { ... def execute(input: Input, ...): Unit = { val bar = input.args("bar") // just do something with bar ... } } http://docs.scala-lang.org/overviews/collections/maps
So this can like wrap sound files right? I mean change the pitch and stuff like that? I'm sortoff working on a hobby [game](https://github.com/jappeace/gdx_ai_gamespace/) in scala and this sounds useful for that. For example you could create from 1 gunshot mp3 file a whole range of variations to give a more realistic feel without having to many mp3 files.
This should [do the trick](http://danielwestheide.com/blog/2015/06/28/put-your-writes-where-your-master-is-compile-time-restriction-of-slick-effect-types.html), splits read only slave connections from read-write master connection based on current Slick `Effect`
I have my undergraduate in mechanical engineering, but I started programming in Java, Python and Javascript ~1.5 years ago. About 6 months ago my company switched me to software development full time due to some of the work I have done. I am just starting to learn Scala and am really interested in the Functional style. I'm almost done with Martin Odersky's online course and have read a lot of, "Functional Programming in Scala" by Chiusano. I am curious what the Scala job market is like - I do not have a formal CS degree and am mostly self taught. How much of an obstacle will that be to finding a good (likely junior) job position?
Yes in almost all scenarios the server is a local instance, although there are others where remote or networked makes sense (e.g. networked performances). It is also possible to create an in-process server using JNI or JNA, some people have experimented with this I believe for Java or Clojure or Android.
I will definitely check that video out. Thanks again, that has cleared up another piece of the puzzle for me! Earlier today I also bought [Functional Programming in Scala](https://www.manning.com/books/functional-programming-in-scala) as I heard it was good. So, I have plenty of material to get through for now I think! :) Thanks again!
As both are using h2 (just in memory for test, but in file in production) this does not really apply here. Also, although I am a big fan of unit tests, integration tests do make sense :)
I like that book. We are in the same boat. Speaking of open source projects, check out this SBT project I made: https://github.com/JohnReedLOL/scala-trace-debug If you're a beginner, this library is super helpful because you can trace the execution of your program. Instead of pressing Ctrl-F to find print statements, you can click on them and it jumps to the location of the print statement in your code. Finally, it can print expression, so if you do this: Debug.assertExpression{ val someVal = 2; 1 + someVal == 4 } It will print this: { val someVal = 2; (1).+(someVal).==(4) } -&gt; false" in thread main: at path.to.file(Main.scala: 33)
&gt; Source: I'm a 10 years plus java dev who gone scala then Apache spark and got several job offers as a data engineer That's all the HR people look for is 10 years as a Java dev. Java and functional Scala aren't even related languages (like the way C++ and Java are related). I don't know if I want to do Apache spark or Hadoop - I just love design. I just want to grab a piece of paper and a pencil and spit UML and specs and documentation.
How does someone who is 22 with no internships, a 3.0 GPA, and no work history get a job as a Scala developer? I mean I know the language well enough to feel comfortable writing implicits and monads and macros, but 99% of the jobs I apply to they throw away without even giving me an interview. p.s. I don't ever use a debugger because I wrote (and use) this: https://github.com/JohnReedLOL/scala-trace-debug Please support my notions of getting a job by using my tool. Side side note: what I really want to do is grab a pencil and paper and put out UML's and documentation all day. How does one become a designer?
Chicago scala devs? We certainly exist... but everyone that I know is already comfortably employed and not actively searching.
Fair enough :) Just curious. 
&gt; odds are good that you don't need to write a referentially-transparent mutating reference or array—it already exists Fair enough, that's a good point.
There's a few nice libraries for dealing with async HTTP, one of which I have used is [play ws](https://www.playframework.com/documentation/2.5.x/ScalaWS)
&gt; Scala positions at my current job for the last year. We have never asked anything beyond basic coding questions and we ask fizzbuzz/letter count/string reversal every single time. &gt; &gt; Seeing as the OP is just exiting college they will more than likely not be interviewing for anything above either a junior and low mid level dev position. If he was interviewing for a senior dev position then yeah they would probably need to show the ins-and-outs of the language, but for a new college grad I am a new college grad and I know the ins and outs of the language. I showed the manager how to implement a Monad in a job interview. But they hire other people instead. How on earth are you supposed to get anything done if all you can do is fizzbuzz/letter count/string reversal? I mean do these young developers just sit on their ass and scour the code base for bugs to fix?
[removed]
In a job, you're not designing new products from the ground up very often. How many times do you need to design Uber, for example? You're mostly going back and forth between incremental changes to the product, putting in new features, and bug fixes. New features can require some design work. And some organizations actually take the time to explicitly plan that out. But a lot of places just sort of launch headlong into it and see what comes out. And call it 'agile'. 
I know what you feel. Scala's type system kung fu really lacks good (enough) introductions. My short recommendation list: * [Type level blog](http://typelevel.org/blog/); * [Shapeless overview](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0) Not a general type system thing, but Shapeless is kind of cornerstone of Scala type level programming, so must-read; * [Apocalisp blog](https://apocalisp.wordpress.com/2010/11/15/type-level-programming-in-scala-part-8c-klist%C2%A0zipwith/) I think most of articles are good, but not for newbies, for me it feels more like "short notes for future me". Hard to understand, but interesting. I'm linking one article, but whole blog contain lot of cool things about Scala type system; * Travis Brown wrote [some posts](https://meta.plasm.us/posts/2015/07/11/roll-your-own-scala/) related to type kung fu, you may find them useful; * Just few more articles I liked: https://blog.codecentric.de/en/2016/02/phantom-types-scala/ http://dcsobral.blogspot.ru/2009/09/type-safe-builder-pattern.html; I hope that will be enough for a beginning. However, if you're more like newbie in Scala and FP I can agree with /u/wik about famous Coursera FP course and also can't recommend enough this book: https://www.manning.com/books/functional-programming-in-scala (best FP introduction I've seen (not related to languages)) One notable thing about Scala type system/type level programming is that there's [quite small](https://twitter.com/OweinReese/status/705425158748643328) bunch of people (bunch of cool people!) advancing it and writing articles about it, I don't know wether it good or bad, but you can just follow them and study all this interesting stuff.
http://akgupta.ca/blog/2013/05/14/so-you-still-dont-understand-hindley-milner/
I need to learn this "agile". I don't understand how you can make anything that isn't crap without planning. Like even if I'm going to be writing a little jar file tool or something small, I always start with a pencil and paper. Like maybe I don't follow the UML specs exactly (I sometimes make up my own symbols and use those) and maybe I'm not 100% sure what I'm doing so I skip the Javadoc until after I finish to give things time to solidify, but I've never made anything that wasn't a disorganized, non-cohesive piece of gobbly gook without planning it out on paper beforehand.
&gt; Does this mean every time I see `a method b` it could be either `a.method(b)` or `method(a,b)` No. There are values and there are types, and for any location it can be only one or the other. method(value) method[Type] val value: Type etc. Note that Scala (unlike I think SmallTalk?) does not have an equivalence of `method(a, b)` and `a.method(b)` (I think it would be cool if it had...). This is only the case for types so that `A &lt;:&lt; B` is made possible.
Actually, I'm not sure that does clear it up. `&lt;:&lt;(A, B) == A&lt;:&lt;B`, no? And `&lt;:&lt;` is a globally available Type/Class in PreDef? So the question, is it a method on `A` or some other method or constructor or something still holds, no? (I appreciate your help here)
It would be `&lt;:&lt;[A,B]` because `&lt;:&lt;` takes two type parameters. Because of syntactic sugar, you can write a type constructor that takes two parameters in infix form, but you are still constructing a *type* not a value. This can be a little confusing, bit at the end of the day, your end result is a type. The only reason this exists is so that you can some (fairly simple) type level computation.
Woah now, pump the brakes. I didn't say it wasn't crap! Seriously, though, agile in practice can be a lot of different things. At its worst, there is no real planning and you do end up with garbage. But done well, it's certainly not 'planning-free software.' You'd be surprised, though, at how many software products out there are pretty horrible under the covers. Many (maybe most) industry codebases are absolutely disorganized gobblygook. The thing is: in the world, you rarely have the chance to set static requirements for software. The thing you design today will in six months be tasked with doing something no one had considered during the design phase. So you have to be flexible. Even design doesn't save you from creating a mess. 
I like this resource, although it is still a work in progress: http://ktoso.github.io/scala-types-of-types/
&gt; "Hello World 1".trace // 1 line of stack trace I don't know, but I have usually two possibilities: - either I don't know where something goes wrong. Then I wouldn't know where to add the `.trace`. And if I knew, well then there would be no purpose of `.trace` because I already determined where my location is, and I would name it `s"Hello World: $this"` or something similar. - I want to know how something lead to the call of `"Hello World"`. Then sure, a stack trace may be useful, but almost certainly I will want to inspect the state of everything that leads to this. And then I simply need a full blown step debugger like IntelliJ. 
Ah, so `::` really is an example of where I thought ambiguity might arise. I'll look out for it.
Sorry, I edited that last comment. But yeah, if you understand what I said, you should be able to use this tool for debugging along with a debugger. If you have a really solid understanding of the code base, you can use that along with this tool to PROVE that you don't have bugs (at least on paper).
&gt; These exist, too. But they're less common and pretty competitive. And you still will have to be flexible. People aren't going to give you money to do something simply because it's something you want to do. You have to think about how you can provide value to them as they define it. ^ This is EXACTLY what I am good at. I have a problem like "I want a debugging tool to allow me to trace flow and prove that a section of code is correct". And then I do research and implement it. If the problem is "I want a library that allows me to abstract away everything that I need to simulate a card game", I first do research into the problem domain and then I give them some code. And not just like crappy code but like super clean, intuitive, cohesive, maintainable code. Code that I can prove has no bugs in it (at least on paper). I know I won't get that as my first job, but it's a dream. But yeah, if the opportunity arises where you need to find someone who could in the future be used to write (or to work with people who can write) that kind of code, please mention me. johnmichaelreedfas@gmail.com . Or just email me for fun.
You're in highschool again
Something not commented on by others yet about the operators being methods is that it allows you to create partial applications of them and pass them around. For example: scala&gt; val inc: Int =&gt; Int = 1.+ f: Int =&gt; Int = &lt;function1&gt; scala&gt; f(3) res0: Int = 4 This can be useful for function composition and mapping. scala&gt; val times2: Int =&gt; Int = 2.* times2: Int =&gt; Int = &lt;function1&gt; scala&gt; List(1,2,3) map (inc andThen times2) res1: List[Int] = List(4, 6, 8) Keep at it. Even if you don't end up using Scala, there's a lot of new ways of approaching problems it exposes you to. Much in the same way Lisp does with the whole "code is data" paradigm. 
Never heard about Spire before, thanks. Gonna look into it.
I have no idea what your resume looks like or what your experience is, but if you're not getting callbacks I would look there first. 
Actually, since I will be using this tool, can you make sure it works? Just add that line in the README to your sbt file and see if it works please
Yeah, really cool to see so many answers. Thanks all!
No, but reading about higher kinded types and why you'd want to do that in a vaccum is much less useful than seeing an example of say, a Traversable instance. 
I agree higher kinded types are hard to understand without examples, but I don't think Scalaz makes a good educational resource in that way. 
Sure but you said "Chicago seems not to be a hot spot for Scala developers" ... I guess it depends on your definition of hot-spot. If it means that it's easy to hire good ones, then I'd expect that the demand for scala devs would be less than the number looking for work. If there are many open scala positions and not enough people to fill them is it a hot spot for scala jobs, but not a hot spot for scala devs? In conclusion I don't know what hot spot means.
One of the biggest things to get out of shapeless isn't just how to *use* it, but also how all of the generic operations are implemented using recursive implicits. Once you understand that, you can write a lot of useful and generic code with HLists/Coproducts as your base.
Thanks for the answer, it helps
This is the route I unintentionally took. I learned Haskell first but then got a job at a place who was moving to Scala from Java. The Haskell gave me a good base and now we use scalaz etc and take a more Haskell-like approach to coding in general.
Great answer, thank you
Python is great for many things. Here is my list of when to use which Use Scala when * you need to do something in spark that is not available in python * you want to deploy code in a Java servlet container * you need to (or find convenient to) use Java code for interacting with parts of the system * writing a feature of an existing Java system * use other Apache projects natively such as Lucene, Prediction.io, mahout, etc. Use Python when * you are exploring data * creating visualisations * working with others in a notepad * need to do a quick and dirty REST service Option #3 experiment with groovy, it is a JVM language but looks a lot like Python (although a few significant differences), so theoretically you get the best of both worlds (assuming all the awesome analytics packages have equivalents). So relating to machine learning - it depends on the context. The above is an opinion and is certainly incomplete and likely flawed, so take it with a pinch of salt
I wrote a quick [blog post](http://alexk307.github.io/scala-parsing/) about this a bit ago. Hope it helps!
&gt; One of my favorite aspects of this approach is the ability to abstract errors by either exposing them to "userland" by returning them in my algebra, or by "deferring to the interpreter" and let the "target" monad handle it. This is especially nice when working with Task since it handles exceptions nicely. Exactly: you can decide what's application-relevant and what's not. We make the same call (let `Task` handle it) a lot, especially when implementing `FreeC` around some exception-happy API. &gt; Honestly, the only downsides I've found using scalaz (7.1.3) Free monads are that I had to write some boilerplate due to 1) Coyoneda being separate from Free. I think scalaz 7.2.x's Free monad also gives you the Free functor though? Yeah. [Here](https://github.com/scalaz/scalaz/blob/v7.2.1/example/src/main/scala/scalaz/example/FreeUsage.scala)'s the new usage example. I hear this implementation is more efficient, but haven't yet used it myself. &gt; 2) poor higher-kinded type inference from scalac Yep. I've certainly had to `liftFU` more than I should. &gt; 3) FreeC not having all the helper functions it could have. Interesting. What are some examples, if I may ask?
Yep just suggesting an alternative. 
thanks for the alternative, but i don't like some stuff in argonaut: * the need to add 'extends Serializable' * the number in 'casecodec&lt;n&gt;' also, you only speak about very very very simple parsing, you don't even mention how not to have snake case names ('first_name' in Scala?)
Is there any documentation about what is this?
Yeah the case codec thing is definitely annoying. Ah yeah, probably should've used camel case. It would work with either way.
for the 1st question, the problem was on how to read the nested json object. The answer was provided in SO http://stackoverflow.com/a/36215248/4398050 2) that's something new to me. thanks ! Are there any other adapters? if instead of DateTime I wanted to convert the Long to a case class Identifier(id: Long), how could I achieve that? Going did into the posts, they seem really cool, thanks
Don't know about any documentation, but this has probably to do with this: http://event.scaladays.org/scaladays-nyc-2016#!#schedulePopupExtras-7571 Since scala.js is also in the sandbox folder this is probably for testing the compatability or whatever of dotty and the two projects, so that dotty can be used to compile projects targeting js or native deployment? 
To work with JSON and case classes I'm using the Circe library (http://circe.io). However, you would have to create your own custom Encoders and Decoders to be able to parse long to DateTime format. You can do that using JodaTime like other people have mentioned. Circe, by the way, is a heavily modified fork of Argonaut and can be used with Play Framework using `play-circe` dependency.
Shouldn't `Order` be a part of `A` like haskell? data Person = Person { firstName :: String , lastName :: String , age :: Int } deriving (Eq, Ord) Why is it passing in as an implicit parameter?
It's not about being able to make A TOOL. It's about being able to create something that does not already exist or to take something that already exists and make something out of it. Steve Jobs didn't create the first mouse, but he created something out of the first mouse. I was recently watching a show called Ink Master where people made custom tattoos given certain constraints. I mean yes people will pay for a good tattoo and they want less infections, but it takes something to be able to get a piece of paper and a pencil, draw out the concept for a new tattoo, and then make it. You have to be creative to create stuff. That same ability to be creative and to create stuff can be applied in different ways. Maybe you create and run the repo for a library that other people are using. Or maybe a framework. Even if you didn't write all the code, you are the one who does the original layout and foundation and other people kind of fill in the gaps. And if you leave a really good foundation, other people will be able to kind of expand upon and borrow idea from what you made. A lot of people took the idea of the mouse and keyboard after Steve Jobs did. Maybe he didn't do every little detail and maybe there was another mouse beforehand, but he had the idea of using the mouse, it was a good idea, and his implementation of the mouse with keyboard ultimately set the standard for personal computers. A solid house is built of a good foundation. Not everyone is creative. Not everyone can create stuff. Take a second look at what I did. Say you have this... https://github.com/JohnReedLOL/scala-trace-debug And you also have the IntelliJ debugger (or even the ammonite shell) which can modify/execute source code in real time. Now I didn't make IntelliJ, but I know that I can put calls to the stack-trace-debugger inside the source code at the location of my breakpoints and backtrace the flow that led to each of those break points in the code. Or maybe I will use the ammonite shell and make calls to stack-trace-debugger at its breakpoints so I have access to not only the values of all the variables in the vicinity of the bug, but also an idea of where the bug came from or even what must not have been true for the bug to happen. So now instead of just knowing what the value of this variable is, I know what the value is and also how I got there. I just took something that exists and made it better. That's what it means to be creative. Not everyone is creative. If you give some people a pencil and paper you don't always get something cool and new and useful or even elegant and beautiful. Maybe you get a layout that will be easier to maintain, easier to read, easier to fix, simpler, and ultimately faster and even less vulnerable to security holes. Maybe you will get crap. People who do the high level thinking don't start by thinking "what do I do to stop this particular optimization from not happening", they think "how do I make this good" and work from there. It's about abstract, high level thinking. And not everyone has that. Some people are content with concrete, low level thinking and working on things that already are instead of creating things that are new. As a person who does hiring, if you don't take that into account, you are retarded. Seriously. Vanilla junior developers make vanilla senior developers and ultimately they don't become really good at designing, creating, and building things that are new. You want people where you can say "our code base is a pile of crap. Bug are everywhere. It takes forever to fix things. It's so messy, no one understands what is really going on. Make it not suck." and they can refactor it into elegance. You want people who actually can come up with solutions to problems that are new or different. I mean I understand that no one likes debugging and you don't want older developers to be wasting their valuable time doing monkey work, but some people, even at a younger age, are naturally very creative and can do/build/design/solve a lot more than monkey work.
You understand I'm the same guy from the other conversation we're having? Where in the world did all this anger come from? You've fantastically misunderstood what's going on here if you think there's any reason at all to start calling people 'retarded.' That's just fundamentally out of line. You gave me your email and asked me to recommend you to jobs and then called me retarded in the immediate next comment. This is bad strategy. You've upset me. I've been polite with you, trying to be helpful. And you've just been incredibly rude. Maybe wait until you've had one actual job before deciding you know what's important for hiring. What I'm trying to explain is that no one is going to hire you to do things simply because they're things _you_ want to be doing. They're going to hire you if they think you can help them out. I know this may be surprising to you, but people know what they want and need much better than you do. Stop telling people what you think they should want and start paying attention to what they do want. I challenge you to show me anywhere where I said that creativity or skill aren't valuable. I said explicitly: the jobs you're looking for do exist, but they're competitive and rarer. The people who I've had the good fortune to work with are quite creative and inventive. They've written books and founded companies. But they're not whining prima donnas who refuse to do the parts of the job that aren't fun. We don't hire anyone at all just 'to do monkey work.' That's some false-dichotomy bullshit. We _do_ hire wildly smart, good natured people who are willing to help out as needed. No one is too good to work on annoying things. In my current company, we have this wildly awesome, distributed, arbitrarily wide (for literally all practical purposes) bitmap indexing tool that queries against a gargantuan dataset and returns set operations fast enough that it powers user actions for the front-end without any caching. We may move to open source it. And you know what the guys who who wrote that thing do sometimes? They fucking fix bugs. We didn't hire someone to go sit in a tower and just write that one thing. Why would I stand in line for the roller coaster and hire you to ride the ride for me? The things you don't like doing are the things everyone doesn't like doing. The things you want to do are the things everyone with any talent prefers doing. Why do you think you get to skip past everyone else and leave that dull stuff for the rest of us lowly, uncreatives? _Of course_ you compared yourself to Steve Jobs. Because you have a debugging tool, you're Steve Jobs. Got it. Like I mentioned before --- though less bluntly --- I'm confident that you're having trouble finding work largely because you're unpleasant. &gt;My GPA is pretty bad (I can be twice as productive as friends of mine who are doing things like interning at Google, but they get better grades and are much better at following orders). When you say shit like this you sound just like a thousand twerps --- each of them special snowflakes --- applying to each of the jobs you're apply to. All of them too good to work on things that people actually need done. If you're not one of that sort, I strongly encourage you to stop presenting yourself like one. No one is trying to make you some cookie-cutter automaton, grey and sunken in a basement factory somewhere. But if you can't demonstrate that you are willing to try, at all, doing anything apart from exactly what you want to be doing, then no one is going to want to work with you. Because they've all worked with people like that before and they all leave giant messes for everyone else to clean up, always so sure that they're the only person who knows anything. It's a huge red flag. 
A few quick thoughts: - code looks quite good for a first attempt - much better than mine :-) - I would suggest avoiding default values for case class fields if you can, they can lead to mistakes during refactoring. Sometimes they offer enough benefit for the cost (less safety), but often they don't. - filter+map is better done with `collect` and a `PartialFunction`, e.g. `collect { case (Some(option), index) =&gt; option -&gt; index }` - corollary to the last point, try to avoid "unsafe" calls that could throw exceptions if you made a programming mistake - `.get` on an option, `.head` on a list, `.asInstanceOf` on everything, etc. There is usually a safer way to do it, pattern matching or reasonable use of types like `Option`. - `.reduce` is also potentially unsafe, if there are no values it will throw. Consider a safer possibility, like `.reduceOption`. - While you're using `Stream` here because it's what the library uses, I assume, be very careful of that particular type of collection, as if you hold a reference to a particular point in the Stream, everything from there onwards cannot be garbage-collected. It can work well, but there be dragons. There are safer options for streaming in third-party libraries, which try to offer fairly guaranteed bounds on memory usage.
Yeah and then you would use: final def sort[@sp A&lt;:Ordered:ClassTag] to mean that A is a subtype of Ordered instead of final def sort[@sp A:Order:ClassTag] which means that A has an Order instance in "implicit scope". They're similar in some ways but different. Note that Haskell doesn't have "subtypes" as far as I know.
&gt; The people who I've had the good fortune to work with are quite creative and inventive. They've written books and founded companies. Yeah, that's exactly what I hope to do. For example, look carefully at the url in the package name. info.collaboration_station. The package name is supposed to be unique, something that reflects a URL that you own. Type it into the web browser, you get nothing. But wait. The underscore in the package name is actually a dash. collaboration-station.info is actually a url. A url that leads to a company that I would like to found! That being said, I am queer and being the creator of a company like the one reference by that url is not something a lot of employers would be crazy about
&gt; In my current company, we have this wildly awesome, distributed, arbitrarily wide (for literally all practical purposes) bitmap indexing tool that queries against a gargantuan dataset and returns set operations fast enough that it powers user actions for the front-end without any caching. I created and implemented a way to get rid of all page refreshes on my web page without in any way affecting the HTML/CSS that the web crawler sees or needing any crawler specific directives. I reduced the loading time for the front-end significantly with minimal extra work, little to no additional coupling added into to the templating engine, and I maintained effective search engine optimization with no page refreshes regardless of what web crawler is indexing your page. No prerender.io necessary. &gt; And you know what the guys who who wrote that thing do sometimes? They fucking fix bugs. I fucking fix bugs. Mostly my own bugs, though. I feel like if I make a bug, it's my fault and fixing it is like "punishment" for making a mistake. &gt; Why would I stand in line for the roller coaster and hire you to ride the ride for me? I'm talking about those undergrad interns where they don't do shit other than fix bugs. That is EXACTLY what I did not want to have to be doing all day.
&gt; Why do you think you get to skip past everyone else and leave that dull stuff for the rest of us lowly, uncreatives? Of course you compared yourself to Steve Jobs. Because you have a debugging tool, you're Steve Jobs. Got it. Actually, I used to kind of do used to create audio porn and I'm intent on starting a female friendly company that features audio porn. http://collaboration-station.info/ is just a front for www.eroticahub.com which is just a temporary page containing just the frontend. I am intent on revolutionizing the porn industry by making it friendly to all genders and sexual orientations. Scala was just my choice of language for the backend. &gt; My GPA is pretty bad (I can be twice as productive as friends of mine who are doing things like interning at Google, but they get better grades and are much better at following orders). I used to make popular pornography that had an 85+% female audience. I don't need a 4.0 &gt; When you say shit like this you sound just like a thousand twerps --- each of them special snowflakes --- applying to each of the jobs you're apply to. All of them too good to work on things that people actually need done. If you're not one of that sort, I strongly encourage you to stop presenting yourself like one. I am sorry, but getting a 4.0 GPA just was not a priority &gt; Like I mentioned before --- though less bluntly --- I'm confident that you're having trouble finding work largely because you're unpleasant. Yes. I am unpleasant. I have bipolar disorder &gt; No one is trying to make you some cookie-cutter automaton, grey and sunken in a basement factory somewhere. But if you can't demonstrate that you are willing to try, at all, doing anything apart from exactly what you want to be doing, then no one is going to want to work with you. Scala was not something that I wanted to do at first. I thought the language was full of syntactic frustration. But I did it for the backend. &gt; It's a huge red flag. I'm sure that being involved in any kind of porn, much less female and sexual orientation inclusive porn, is a red flag. If you believe that porn is evil and you don't understand what needs to go into creating something that is sexually appealing to women (more so than men), I am a walking red flag.
Ignoring the fact that this is obviously early days, if this allows native binaries to be built from Scala code would it still allow you to use Java libraries? Or would you have essentially a separate infrastructure with the same language? Forgive my ignorance.
In addition to what Duralumin mentioned, there are some simplifications. If you have a sequence of rows and you wish to capture the first one as the header, you can use `splitAt(1)`. Also, you can zip things directly without indexing (to zip your handlers with the row contents). Here’s an example that parses a CSV file (naively) and applies a string handler to each column according to the header names: scala&gt; type StringHandler = String =&gt; String scala&gt; val config = Map[String,StringHandler]( "col1" -&gt; (x =&gt; s"*$x*"), "col2" -&gt; (x =&gt; s"[$x]") ).withDefaultValue(identity[String] _) scala&gt; def applyHandler(fx: (StringHandler, String)) = fx._1(fx._2) scala&gt; val csv = "col1,col2,col3\ndata1,data2,data3\ndata4\n\n,," scala&gt; val parsed = csv.split("\n").filter(_.nonEmpty).map(_.split(",")) scala&gt; val (header, rows) = parsed.splitAt(1) scala&gt; for (cols &lt;- header; handlers = cols.map(config); data &lt;- rows; paired = handlers.zip(data); handled = paired.map(applyHandler); result &lt;- handled.reduceOption(_ + "," + _)) println(result) *data1*,[data2], *data4* PS. You’re using `initialObject: () =&gt; T` and `initialObject.apply()` so it’s getting re-evaluated for every row, creating unnecessary blanks. You can simplify down to `initialObject: T` and pass a single `new Product("", "")`, since it’s immutable. Also, depending on the semantics of your application, it may be better to use a fold instead of composing with a reduce.
I was referring to fast food as a place, not as a substance. fast food restaurants are a place where creativity isn't exactly valued. I really need a job
[Pickling](https://github.com/scala/pickling) is most promising, but I had some issues with double references. Its not stable.
I would guess the same restrictions scala.js has will apply to native as well: http://www.lihaoyi.com/hands-on-scala-js/#DeviationsfromScala-JVM (especially the section about "Library Differences") Please correct me if I'm wrong.
That's what I suspected, thank you.
I looked down a bit futher on the site: http://www.lihaoyi.com/hands-on-scala-js/#AvailableJavaAPIs And it seems the Java libs are ported versions to scala. So native could maybe reuse them. https://github.com/scala-js/scala-js/tree/99753a5a4dd77439923477cab8f7d080a3ad68da/javalib/src/main/scala/java
Thanks for the advice! See my reply to /u/Duralumin above.
Thanks for the reply! I suspect what I should be doing to fit in properly with `kantan.csv` is either implementing my own `RowDecoder`, or first parsing the header to get the column indices corresponding to each field of the case class, then passing these to a `RowDecoder.decoderAAA`. There might even be an existing `RowDecoder` implementation that I'm missing!
One more question. Say I have this code: final class implicitTestClass[A](val a: A) { def &lt;&gt;&lt;&gt; [B](b: B): String = s"$a + $b" } implicit def implicitTestFunc[A](x: A): implicitTestClass[A] = new implicitTestClass(x) Then I say, `println(1 &lt;&gt;&lt;&gt; 2)` How do I know `&lt;&gt;&lt;&gt;` is not a method on `1`, because without knowing about my implicit function def, which is very possible, couldn't it easily be method? Or am I misunderstanding something. It seems ambiguous.
And how does `1 &lt;&gt;&lt;&gt; 2` get converted to `implicitTestFunc(1)&lt;&gt;&lt;&gt;2` and not `&lt;&gt;&lt;&gt;(1,2)` like I would expect. Scala you crazy!
**First tip**: don't worry about all the ad-hoc rules you're learning about. Just see it, and move it. Don't even bother trying too hard to remember it, if it's important you'll see it often enough to remember. If you still bump into weird stuff, just ask on https://gitter.im/scala/scala and someone will sort it out for you. It's totally ok to not fully understand. You can definitely write useful code people will pay you for without total and complete understanding. ---------------------------------------------------------------------- **Second tip**: the weird special cases you pointed out are, in fact, weird and special. - The fact that infix operators between **terms** are trivially the same as method calls on objects is unique to Scala AFAIK, though Ruby/Python lets you overload them with a bit more work so it's not actually that special. - The fact that infix **types**, on the other hand, are actually top-level-names in scope, rather than property-of-left-hand-thingy, is much more like how C#/F#/Haskell do their operator-overloading, and is *entirely inconsistent* with how infix **methods** between **terms** works. The way infix operators in **pattern matching** (e.g. `val a :: b = myList`) works is again more like C#/F#/Haskell than it is like Ruby/Python. The fact that methods with end with `:` are right-associative is also stupid and unnecessary. - You will find other things that are inconsistent or ad-hoc and weird, like the fact that the *capitalization of your identifiers* matters in pattern matches, but not anywhere else. Similarly, wrapping identifiers in back-ticks matters in pattern matches, and not anywhere else, and the list goes on... *Nothing you have learned in the past could prepare you for this*. There is no logic to derive these things from first principles. And that's totally ok, it means you can stop being frustrated, switch off your brain, and just roll with it for a while until you get used to it. Stop thinking so hard! ------------------------------------------------------------------------------------------- **Third tip**: it gets better. While the list of special cases in the Scala language could go on for a page or two, the list of special cases in something like Javascript or Ruby or Java is *endless*. How many different ways have you seen Java methods bound to each other via reflection, XML, bytecode-weaving or annotation-processors? How many ways have you seen people "instantiate objects" in Javascript? How many times have you seen methods on some Ruby object you have no idea where they came from? It might take weeks or months to get really comfortable, but after a finite amount of time you **will** get used to all this weirdness, and that's it. My experience is that after **years** working in Javascript, you still end up getting surprised when you look in the innards of jQuery or React and see the weird things they're doing mangling prototypes or monkey-patching objects or other things. You can make progress, but you never get *proficient* with all this magic, because the magic is created by the library writers and is infinite. With Scala, the list of language-weird-thingies is long-but-finite, and even the list of compiler-bugs is finite, so it doesn't take too long to get used to all the Scala-specific weirdness there is. Of course, library-level weirdness will always be there (e.g. SBT...) but that's the case in any language/ecosystem.
`1 &lt;&gt;&lt;&gt; 2` never gets translated to `&lt;&gt;&lt;&gt;(1,2)`, this only happens for types, e.g. `Int :: String` is actually `::[Int,String]` if `::` is a type constructor (class, trait, type alias) that takes two params About the ambiguity - the compiler first tries to find a direct method and if it fails, it looks for an implicit conversion which would provide that method. It may be confusing when reading Scala in vanilla text editor, but IDEs (or at least IntelliJ) help a lot here with appropriate highlighting and tips.
I might oversimplify stuff, but if you use https://github.com/tototoshi/scala-csv there is a nice function called allWithHeaders which already parse the headers and create a map from column header to values on each rows. Based on this, I think the read csv to case class can be implemented easier : https://paste2.org/JUspWVyb
Very good! Thanks for sharing. I hope to see more in the future ;-) Cheers
For a much more complete overview of the subject: http://blog.originate.com/blog/2014/06/15/idiomatic-scala-your-options-do-not-match/
Not a question (but not really worthy of its own topic) the [new scaladoc](http://www.scala-lang.org/files/archive/nightly/2.12.x/api/2.12.x/index.html) is up on nightlies, if anyone is interested. I filed a few SI issues but then noticed there is [this thread](https://github.com/scala/scala-dev/issues/84) that seems to be accumulating ideas. Anyway, it's worth a glance.
I know what you're referring to, but you're answering a question I didn't ask. I didn't say: where in the world is creativity not valued. I said: where _did I say_ creativity isn't valued. As in: you charged me with poor practices because I don't value those things. I was challenging you to support your claim and show me where I indicated I don't value those things. If you _really_ need a job, then I'd recommend listening to the advice I've been trying to give you instead of calling me names because you don't like it. 
About 2.12, [here](http://www.scala-lang.org/news/2.12-roadmap/) says it was meant to be ready this January
I've been doing the Coursera MOOC and reading a few books to begin learning Scala, and I'm interested in getting started on using the Play framework. There are a lot of resources for learning it out there...does anyone have any favorites/recommendations? I find I learn best from video tutorials if there are any available.
[removed]
So someone makes a utility that they find useful and takes the time to document it and release it here and he gets smart ass responses. Some constructive criticism would be a much bigger help than "buy intellij" or telling him to just use a "fucking logging library". If you don't find this utility useful then just don't use it, you dont have to shit on the guy. This is Scala not the fuckng UFC.
Scala without GC? That would be cool. Then add rust style lifetimes and make it run on WASM and id be really happy :)
I am trying to use Akkahttp and can't get it to work properly. How do I print the request im sending and the response I received to debug it? This library is difficult....
Is there a lightweight scala web framework that: 1) lightweight, doesn't require 1gb heap to start a hello world 2) does only one thing - web, no orm, no security, no template engine, ... 3) async event-driven 4) distributed as a single jar, so I can use it in my environment, with my tools, with gradle/maven (no sbt)
Due to demand for the ability to integrate this tool with a logger, all calls to Debug.trace, Debug.assert, etc. now return a String that can be passed into a logger. To use this feature, try "libraryDependencies += "scala-trace-debug" %% "scala-trace-debug" % "0.1.4" (version 0.1.4) You can disable printing to standard out and standard error via Debug.disableEverything_! This will still return a String that you can pass into a logger. Note that Debug.nonFatalAssertOff_! only prevents non-fatal assertions from printing - they still return a String containing what they would have printed if they were on (just like Debug.trace does when you do Debug.traceErrOff_!). In addition, all the add-on methods available through implicit conversion still return the object they were called upon so that you can use them inside an expression. See README: https://github.com/JohnReedLOL/scala-trace-debug 
Due to demand for the ability to integrate this tool with a logger, all calls to Debug.trace, Debug.assert, etc. now return a String that can be passed into a logger. To use this feature, try "libraryDependencies += "scala-trace-debug" %% "scala-trace-debug" % "0.1.4" (version 0.1.4) You can disable printing to standard out and standard error via Debug.disableEverything_! This will still return a String that you can pass into a logger. Note that Debug.nonFatalAssertOff_! only prevents non-fatal assertions from printing - they still return a String containing what they would have printed if they were on (just like Debug.trace does when you do Debug.traceErrOff_!). In addition, all the add-on methods available through implicit conversion still return the object they were called upon so that you can use them inside an expression.
Why not just use Rust today then? And I must tell, Scala absolutely cannot live without GC. All code that exists in Scala relies on GC, even the ScalaJS part.
Nice article, but how is it really related to Scala? :/
Maybe scala and scalability sounds the same for him.
Yet another illogical FUD. 
I hadn't heard of circe before, but it looks pretty neat. I'm glad to see that they care about performance.
this is a satire right?
Read carefully what he wrote (comments, articles). This is like reverse FUD to the community - he's **trolling** other communities like insane fp junkie. He's doing more bad than good.
Akka http is pretty lightweight. Can run it right from a main method.
I found this example useful when I was first starting out with akka http: https://github.com/ArchDev/akka-http-rest
Another example of Scala community infected with SICK NASTY PEOPLE. We need to heal. To heal we need to purge or let Scala and Haskell die on it's own.
That's good to hear, how do you plan on improving your project from here?
Oh, actually, getting the raw source code in a macro appears to be totally possible. sourcecode.Text[T] inside of the debug-prints library has this... case class TextT object Text { implicit def generateT: Text[T] = macro Impls.text[T] def applyT: Text[T] = macro Impls.text[T] } object Impls { def textT: c.WeakTypeTag(v: c.Expr[T]): c.Expr[sourcecode.Text[T]] = { import c.universe._ val fileContent = new String(v.tree.pos.source.content) val start = v.tree.collect{case tree =&gt; tree.pos.startOrPoint}.min ... } Where v.tree.pos.source is the actual file corresponding to the source file of this position. __________ Also, there are a few BIG things, mainly related to performance. Performance wise, if it is possible to get the file name and line number and what not without getting a stack trace, then it might be possible to remove the call to "Thread.currentThread().getStackTrace" not only for when no stack trace is printed, but also for when a stack trace of length 1 is printed (by formatting the info to make the meta data look like a stack trace). Then on top of that, if the Debug.trace macros can be made to substitute an empty expression or an expression containing an empty string in case a specific command line option is provided (like -Doption=foo), the entire overhead of the function call can be removed when the command line option is provided and the logger will effectively print an empty string. I don't like to focus on performance optimization until the very end, but as soon as all the functionality is solid, I think that optimizing performance is the next step.
The syntax `_.nonEmpty` is just a short form for something like `x =&gt; x.nonEmpty`, so takeWhile is only taking one parameter.
Oh I see, that makes sense, but who is calling `takeWhile` 's inner functions? It seems like takeWhile only defines some inner function and variables without invoking it 
Think of `takeWhile` as... a façade. `takeWhile` creates a new `Iterator`, and that is its return value. So we have a value which represents an iterator, but takes some of its behaviour from its "parent" iterator. The variable `tail` represents the first `AbstractIteratorInterface` that you mention in your post. The new definition of `hasNext` delegates to `hasNext` and `next` in the parent, and modifies the result appropriately. Because the behaviour of `hasNext` requires access to the next value of the parent, but multiple calls to `hasNext` in a row should be idempotent, the `next` value is cached, so that it isn't taken from the parent iterator multiple times. The driver of the iterator is then the `foreach` call: def foreach[U](f: A =&gt; U) { while (hasNext) f(next()) } This will keep calling `next` until `hasNext` returns false. This calls the iterator from `takeWhile`, which in turn calls the iterator from `continually`.
&gt; The Open Source tool for monitoring applications running on the JVM. 
`takeWhile` returns a new `AbstractIterator[A]` and implements those methods so that you can call them on the Iterator you get back. They don't get called as part of `takeWhile`. 
It's not directly instantiating an `AbstractIterator`, it's actually instantiating an anonymous subclass of `AbstractIterator` containing the implementation it provided.
Ah, good catch, thanks for taking the time to explain these concepts, I really appreciated it.
thanks for explanation :)
Yeah, keep at it and you won't be unemployed for long. Good stuff! 
This library is based entirely on akka streams. I highly recommend learning about akka streams first and how to use them and materialize them. Once you get that down, everything else is straightforward. 
I'm a little late to the conversation, but if you want bite-sized problems to solve, you can use exercism.io to play with the language. Also, I have taken to using scalatest to play with syntax since I can get a passing test and then change things around to see if I understand different formulations of the same solution. Learning any new language introduces a challenge, especially when it's a big shift like going from OO programming to functional. I made the shift by jumping to lisp, so I ripped the bandaid of in a totally different way. There are times it sucks, but it's worth the effort. 
The title isn't accurate, and therefore miss-leading. What's being dropped isn't support for *.scala build files, but rather the `Build` trait (with which you defined `projects`, optionally `rootProject`, etc). Support for *.scala build files (in `project`) is NOT being dropped.
&gt; If you place the following in a .sbt file, then you can't set the settings for mainDatabase/secondaryDatabase in the sbt repl without extra ceremony I don't follow what extra ceremony you're referring to.
You don't have to worry about updating. SBT is dead on arrival. The next change might as well remove support for all of SBT from SBT.
In my own build scripts I almost completely gave up on `build.sbt` and replaced them with `project/*.scala` only approach. As a matter of the fact I only intend to use `buils.sbt` for adding module-specific dependencies which would be annoying to specify in config shared by all modules. This change is really against how I try to organize me code into small manageable pieces, instead of big blob of build config monstrosity :/
There is syntax highlighting in GitHub: https://github.com/sbt/sbt/blob/1.0.x/build.sbt
Although tooling can be improved, IntelliJ already supports the .sbt format. There are some known issues, and therefore it can improve, but some find it to work "well enough".
I don't understand why you think you need to put everything in one file because you're using the the sbt DSL.
Have you tried using or contributing to CBT? Simple alternative for small projects. https://github.com/cvogt/cbt
&gt; Scala will die off SOON, RUST WILL KILL YOU ALL ARROGANT MONSTERS Rust? You mean a half-baked system prog lang could be competition for a high-level lang like Scala? The rustians are really arrogant...
Because from I saw, that's what we eventually end up with. Few 30 or so LOC utilities with some common values and a giant file where everything is smashed together.
Maven?
Language Specific: * Asynchronous vs Synchronous * Difference between var, val, lazy val * Advantages of Scala compared to Java * What is a Scala map? * What is Scala collect()? * Difference between object and class * Give and example of a trait and when are they best used? * How do you append to a list? * Difference between mutable and immutable and why does Scala prefer immutability? * What do you like about Scala? What do you dislike about Scala? Coding: * FizzBuzz * String Reversal * Count letters in given string * Find the in-order successor of roots value in a binary search tree Take home coding: * Create an application that can determine which is the winning hand between two poker hands * Create an application that can calculate the convex hull of a given set of points General: * What did you learn yesterday? * What do you enjoy about software development? * Have you had a moment is software development where you wanted to change professions? * What is your favorite programming language and what do you hate about it? edit: formatting
&gt; I don't follow what extra ceremony you're referring to. With the above code code, if you put it into a `build.sbt` file (instead of a `*.scala` file), you can't actually set the settings for MainDatabase/SecondaryDatabase in the REPL, they aren't visible in the REPL scope. For example, to do `set flywayUrl in MainMigrations := "stuff here"` in the REPL, it wouldn't work in the `build.sbt` version, it does in the `.scala` version. This is to do with the weird corner cases in scoping that I have been talking about.
&gt; making the coexistence of two different ways of writing a build file a great annoyance. Whenever I had issues, it was with the `.sbt` version. The `.sbt` version only worked flawlessly for completely trivial circumstances, but when you do more complex things, people tend to resort to `.scala` &gt; .sbt has minimum ceremony and is visually apparent (like .gradle which is also not called .groovy; unlike ant and Maven which both use .xml which I find not cool; well Leiningen uses .clj...). I don't see how any of this is relevant, the `.scala` wasn't that much different to the `.sbt`, apart from adding a couple of extra lines to define an object that extends `Build` and project (the project part could have been simplified even further, or considering the intention of this pull request, be removed altogether which actually would have made the `.scala` version even more similar to the `.sbt`) When it came down to it, the extra verbosity in the `.scala` version was just for defining an object and the `project` constructor, and since the intention of this pull request is to remove the `project` part anyways, it would have removed that anyways
Use the collections API to implement some more complicate functions. Write functions like map, sum, reduce, filter with respect to one another
Defining configs in sbt files and using them from the repl works fine for me, you may just be running into a bug.
I discussed this in the sbt gitter channel, and it was implied that the limitation in that scenario was intentional (for some reason) tbh, I don't 100% understand what the issue is as I am not that familiar with SBT's internals, but that is an example of "corner cases" which I came across that I was talking about
Whenever I have issues, it happens that stuff in `project/Build.scala` is opaque and difficult to understand. You don't know what crazy kind of methods, extractors and all the operators that people despise about sbt have regularly gathered in these files, often copied and pasted from StackOverflow or other projects, without understanding why they work the way they work. Ever since I migrated everything to the new macro system and `build.sbt`, life has gotten much easier for me. I challenge everyone to conduct a statistics, e.g. over GitHub projects, and see the proportion of `build.sbt` versus `project/Build.scala`. My estimate is the latter is mainly used by old projects that have never migrated and don't want to mess with their files because they don't really understand what is going on inside `project/Build.scala`, and a very few power users who are perhaps abusing the system, instead of dropping in one or two plug-ins.
An [updated release scheduled](http://www.scala-lang.org/news/2016-schedule/) has been published, and the milestone planning is on [github](https://github.com/scala/scala/milestones). So currently, you can expect a first release candidate by end of June this year.
I'm undecided on my opinion, I haven't hit anything I can't do (and abstract in a reasonable way) with SBT files. What I do know is that I hate most things to do with configurations and configuration value lookup ordering, and I would suggest as an alternative approach above, that the two Flyway setups above could be done as two projects instead. Not because it's supported by `.sbt` files, but I just think it's less likely to cause mistakes down the road. (case in point: people running `docker:publish` when they haven't added sbt-native-packager to their build, and getting the default `publish` behaviour rather than an error...)
Thank you! I kept looking for something like `dispatcher`, but wasn't finding it. I'll read up more on the Akka Typed link.
You can copy and paste the contents of [AkkaBuild.scala](https://github.com/akka/akka/blob/master/project/AkkaBuild.scala) into build.sbt, and it works just fine.
If I remember the course correctly, `Set` in this assignment isn't `scala.collection.Set`, but rather `type Set = Int =&gt; Boolean` so a `Set` is a function from Int to Boolean (basically contains(), the core operation on sets of ints). Here, union() returns a function from Int to Boolean - a `Set`. As for where x comes from, it's a param to the returned function: val both = union(s1, s2) both(42) // "x" is 42 Also, remember that the result of `union()` is the expression to the right of the =, that is, everything right of def union(s: Set, t: Set): Set = So the result is (x: Int) =&gt; s(x) || t(x) A function from int to boolean.
&gt; no new Set is created Yes there is. In this case a `Set` is a function from `Int =&gt; bool`. A `Set` accepts any `Int` and returns whether or not that `Int` is in the set. So to create a new `Set` you can create a new function `Int =&gt; Boolean`. That's what `union` is doing. It accepts two functions and returns a new function that calls each of the parameter functions. The syntax you are using (`... = (i: Int) =&gt; ...`) creates an anonymous function and returns it. Maybe it'll be clearer if you see a version with a named function. type Set = Int =&gt; Boolean def union(s: Set, t: Set): Set = { def union_impl(i: Int): Boolean = { s(i) || t(i) } union_impl } That is equivalent to your code - you just create `union_impl` as an anonymous function. &gt; But how does the function determine which x's to test? Hopefully it's clear now that it'll test any `x` passed in to the function later Full example: @ type Set = Int =&gt; Boolean defined type Set @ def union(s: Set, t: Set): Set = { def union_impl(i: Int): Boolean = { s(i) || t(i) } union_impl } defined function union @ val even = (i: Int) =&gt; i % 2 == 0 even: Int =&gt; Boolean = &lt;function1&gt; @ val odd = (i: Int) =&gt; !even(i) odd: Int =&gt; Boolean = &lt;function1&gt; @ val all = union(even, odd) all: Int =&gt; Boolean = &lt;function1&gt; @ even(1) res5: Boolean = false @ odd(1) res6: Boolean = true @ all(1) res7: Boolean = true @ even(2) res8: Boolean = true @ odd(2) res9: Boolean = false @ all(2) res10: Boolean = true
Most of the folks on in the #Scalaz IRC (freenode) channel (but not all, such as myself) are very familiar with Haskell. I'm sure they'd be happy to answer your question. /u/_swish_ 's link is a great resource for people coming from any language to Scala, but it will look extra familiar for you. :) 
Don't :D
If you want to learn Scala, the best reference book is Odersky's: http://smile.amazon.com/dp/0981531644 Dean Wampler's book is very good and more accessible: http://shop.oreilly.com/product/0636920033073.do Finally, if you want the full on FP experience, then you probably want: https://www.manning.com/books/functional-programming-in-scala If you're looking for a functional programming library on top of Scala (which is not at all the same thing as Scala the language), there are a number of options available, but they are constantly shifting -- last I heard, [cats](http://typelevel.org/cats/) and [shapeless](https://github.com/milessabin/shapeless) are being actively worked on.
cats is great, but fyi, Scalaz is actively being worked on too. 
&gt; An optimal solution for the graph-coloring problem is not trivial. Absolutely. I had two hours to do that one (I had to use a website that times your work), so I went with brute force. The place I was interviewing at was interested in seeing whether I could code at all ([lots of people have trouble even writing FizzBuzz in an interview](http://blog.codinghorror.com/why-cant-programmers-program/)), if my solution worked, and how nice my code looked, so brute force was fine.
I've contributed to scalaz, and it's been a good experience.
Nice, may I ask what does your job entail? Are you writing convex solvers? I know my professor mention some financial companies uses QP, SOCP, and SDP for modeling trades.
I work at an analytics company doing big data. The question was more to figure out if a candidate is able at find an optimal solution (non-brute force) to a math heavy problem.
I agree. As a new user, I find sbt kind of funky and like this scala file better
I can give you a little Scala for Haskell programmers. flatmap is "&gt;&gt;=". This is how you make an algebraic data type: sealed trait ADT {} final case class Case1() extends ADT {} final case class Case2() extends ADT {} final case class Case3() extends ADT {} ^ final means it has no subclasses. "sealed" means that it has a finite number of superclasses all in the same file. Sealing allows for better pattern matching because the number of subclasses is known to the compiler. case classes are like regular classes, but everything in their constructor is immutable by default and they come with a copy method. Scala is a MUCH messier language than Haskell. Read a book. It will teach you syntax. A good book is "Programming Scala, 2nd Edition" and "Functional Programming in Scala". The first is more syntax, the second is more Monads and Monads and more Monads. Scala is really just a fusion of Java with Haskell, with some syntactic sugar for design patterns and rarely used features for library writers. If you know Java and Haskell and can memorize syntactic sugar, you should be fine. Weird features often times you can google or catch with the compiler flag 
&gt; Side question: My only "gripe" with Akka is that all type safety is gone with the receive method for Actors. I know you said *receive*, but if you’re looking for type safety when *sending* (tell, ask) you can use value classes to type-check messages: case class TypedActorRef[MessageType](val actorRef: akka.actor.ActorRef) extends AnyVal { import akka.pattern.ask def !(message: MessageType) = actorRef ! message def ?(message: MessageType)(implicit timeout: akka.util.Timeout) = actorRef ? message } Thus instead of using an ActorRef directly, wrap it in a `TypedActorRef[Blah](actorRef)`, so that the compiler limits sending to Blah messages.
Our community is mostly using gitter for chatting. Here are some notable channels: * [scala/scala](https://gitter.im/scala/scala) * [scala/slip](https://gitter.im/scala/slip) * [scala/center](https://gitter.im/scala/center) * [lampepfl/dotty](https://gitter.im/lampepfl/dotty) And of course there are many more library-specific channels.
Thanks, got it :-)
FP Slack has a Scala channel http://fpchat.com/
Ho ho
Southbutt
Yeah I was only illustrating a “one-liner” (almost) for sending the initial messages. For the return path, there additional considerations like Failures, timeouts, etc so it’s not so trivial.
Don't what?
Actually the name's change to Lightbend from Typesafe could have been today... That was really foolish.
You know something is deeply wrong when such a blog post must have an "aprilfools" tag prominently attached to its top...
No experience yet but I love the idea because it gives Scala a solid alternative platform. One drawback you forgot is that the JVM is still way ahead in terms of performance than JavaScript VMs.
Good one!
While there's not much downside to using scala.js on node, and some have done it before, most just use the JVM when they can. Here's a tangentially related [article](http://underscore.io/blog/posts/2016/03/21/serverless-scale-summit.html).
We should have a moratorium on creating new JSON library.
&gt; Klang plans to invest his energies to “get the check mark square root character thingy included in UTF-8" -- &gt; Unicode Character 'SQUARE ROOT' (U+221A) (added in Unicode 1.1.0, June 1993) Now *that* is efficiency.
The jvm also has threads among other apis that node cannot provide
What data structure should I use to specify the names of my dependencies?
I agree that this a citation was needed. See SupplementalComment's link for some data. From a more theoretical standpoint Lars Bak, the original author of V8, HotSpot (the JVM's JIT), and the Dart VM, cited performance as a reason for introducing the Dart language and the Dart VM. In his (needless to say very informed) opinion, JavaScript is much harder to optimize than Java or Dart. His and his team's original performance improvement for the Dart VM over V8 was about twice faster if I remember well (and I assume that they wanted to go beyond that eventually). He talks about all of this in [this 2013 talk](https://www.youtube.com/watch?v=huawCRlo9H4). My takeaway from that talk and others is that making JavaScript as fast as more static languages like Java is very hard, although maybe not impossible. In the end it might depend on how much engineering effort is invested into each type of VM.
I was just wondering about the status of 2.12. Good to hear.
When can we expect to be able to start using it?
&gt; Scala Center itself cannot amicably decide on centre or center, recognize or recognise, standardize or standardise, advertize or advertise, optimize or optimise. So for 2.13, scalac will accept all alternate spellings under the setting -Ynot.
They should just initialize with a pass to map s -&gt; z in all cases. Since that would include regex's and matches as well, all runtime matches would be backward compatible. /z
:)
Yeah, long overdue feature but nice to have finally 
I have no experience with running scala.js on node, but if someone needs fast startup time, for example on Amazon Lambda, this could be interesting.
I've been reading some novice-tier books on Scala and Haskell and noticed that both "for comprehension" in Scala and "list comprehension" in Haskell are meant to express the same idea. However, due to default laziness of Haskell and default non-laziness (eagerness?) of Scala, let fib = 1 : 1 : [a+b | (a,b) &lt;- fib `zip` (tail fib)] works, and val fib: Stream[Int] = 1 #:: 1 #:: (for ((a,b) &lt;- fib zip fib.tail) yield a+b) doesn't. When I try to take the third Int from `fib` Scala will make an attempt to fully compute the "for" part of *fib*. Is there any way to prevent this from happening?
Yes, very active
Or at least it may necessitate someone writing an alternative front-end. I haven't looked at CBT yet, but I just get this felling that it will have a tall mountain to climb to fully replace SBT.
You could do it like this: val fib: Stream[Int] = 1 #:: 1 #:: fib.zip(fib.tail).map(pair =&gt; pair._1 + pair._2) fib.take(10).foreach(println)
Oh, that's awesome. I'll definitely try. Thank you!
This may be just be an artifact of your MWE (minimal working example), but in case it's not: don't mangle the success and failure cases of `add` into `String`. It should be as simple as def add(create: CreateSupplier): Future[Supplier] = { val supplier = Supplier(UUID.random, create.firstName, create.lastName) conn.db.run(suppliers += supplier) } Then the calling code can still access the success and failure cases in a type-safe way. The code in the initial post mashes both success and failure into what might as well be indistinguishable strings. If you don't want to actually handle the error (which is fine!), leave it in the `Future`. Play's global handler will do a reasonable thing: log it and return a `500` response code.
This is the wrong direction. How is it that Scala, in its pure form, is apparently well suited to do *everything*, aside from describing its own builds? The `.sbt` layer is too clever by half, and it's a shame to see the team doubling down on it. I don't think I'm being hyperbolic by saying that this is the sort of thing that propagates the reputation of the language and ecosystem not being accessible. I think the problem with SBT is a microcosm of the problem with Scala -- it's not particularly useful as a meta-language. SBT is as complicated as it is because it's an attempt to model a mutable "build language", with scoping and such, as data in Scala. It's super awkward, because you have to simultaneously comprehend your build on the Scala value level, the Scala type level, and the SBT machine level. And with the `.sbt` file having slightly different semantics, you have that to understand as well. Unfortunately, I think it's all too easy for insiders of the ecosystem to underestimate how complicated it is to pick up.
Thanks! But isn't for comprehension syntax supposed to boil down exactly to the `map` call?
Thanks for the observation on the original post. Even in PHP I don't like catching Exceptions during regular inserts and let the global error handler take care of it. I've cobbled this application together from many different blog posts and documentation pages, I even forgot that I still had that there (and I don't like it because I don't fully understand what it's doing yet). My problem then is that I don't know the return type of `conn.db.run(suppliers += supplier)` in order to typehint `def add`, it doesn't seem to be `Future[Supplier]`; what is it? I imagine this only performs the insert, throws exceptions, and maybe returns the newly inserted row; there's probably an additional operation I need to run to return the row as a proper Supplier object.
Evidence: there are many tabular data interfaces "making it hard to make a choice. It turns out that the situation is similar if not worse when it comes to JSON libraries in Scala." http://manuel.bernhardt.io/2015/11/06/a-quick-tour-of-json-libraries-in-scala/ Why do people get so obsessed with endless variants of parsing JSON in Scala?
My advice would be to check out the Coursera course *Functional Programming Principles in Scala*. It is an amazingly well done course, taught by the creator of Scala, Martin Odersky. That's how I got my start, and I know a lot of others did the same.
PowerPC processors are RISC and have SIMD, but they call it altivec.
Even from a Python background it shouldn't be an issue. I do think that Scala is a good place to go, and Martin's Coursera course is the best route. But if you are from Python you should have a solid understanding of Object oriented programming, so the functional parts would be the hard part to move to, just like if you were from Java (jdk 8 lambdas withstanding).
I would second the Functional Programming in Scala book recommendation. I also found these quite helpful. http://scala-exercises.47deg.com/index.html
My background was primarily Java and Python. I recommend Functional Programming in Scala or Scala for the Impatient.
However it didn't really teach you anything about Scala itself, it sort of assumes you'll go learn what you need on your own. I wouldn't recommend fpis to someone with less than say a few months of paying around in Scala. After having chosen it as the book for a reading club to bring non-Scala devs on the team up to speed on functional programming, I can also say from experience that it is not a good place for beginners to start.
Ooops, right. In this case,we've created the supplier so you can just return that: val supplier = Supplier(UUID.random, create.firstName, create.lastName) conn.db.run(suppliers += supplier map (_ =&gt; supplier)) Were the database generating part of the object (e.g., an auto-increment id) Slick has a `returning` combinator. See the [docs](http://slick.typesafe.com/doc/3.0.0/queries.html#inserting) for details.
Yup you are right! I fixed it. * The solution was to [pass in the ActorSystem as a parameter](https://github.com/shehaaz/AkkaWordCounter/blob/master/src/main/scala/wordcounter/AkkaWordCounter.scala#L129). * [Don't name the Listener and Router Actors let Akka do it](https://github.com/shehaaz/AkkaWordCounter/blob/master/src/main/scala/wordcounter/AkkaWordCounter.scala#L133), so it will be unique * [Keep count of the number of files processed](https://github.com/shehaaz/AkkaWordCounter/commit/cd41a809fea38ab3215f91c892ec08245e98a84d?diff=split#diff-abd6ad6b59a22ce5db6e19ad0dd7cfafR144), so you can terminate the ActorSystem when everything finishes. Read more here: [Do I need to re-use the same Akka ActorSystem or can I just create one every time I need one?] (http://stackoverflow.com/questions/10396552/do-i-need-to-re-use-the-same-akka-actorsystem-or-can-i-just-create-one-every-tim)
I just did a push with that. I passed in the ActorSystem that created the incrementor Actor. It is basically killing itself from the inside! :P [encapsulated the file incrementor commit](https://github.com/shehaaz/AkkaWordCounter/commit/b34cb43763f494054e1f6787e7f486b55a78031d#diff-abd6ad6b59a22ce5db6e19ad0dd7cfafR105)
I recommend Bruce Eckel's [Atomic Scala](http://www.atomicscala.com/) for you. Eckel is a long-time programming language writer, with books on C++, Java, and Python under his belt. Recently, [he's been greatly influenced by the simplicity of Python](http://bruceeckel.github.io/2015/08/29/what-i-do/) and wrote _Atomic Scala_ to try to teach Scala as simply as possible. The book uses a strategy of small chapters ('atoms'), easy wins, and no assumptions about your knowledge of other languages to teach. Also, you can download a pretty large sample and check it out totally free. As to good coding style, I would recommend Twitter's [Effective Scala](http://twitter.github.io/effectivescala/). In fact that page links to Twitter's Scala School tutorials, which are also excellent.
I went through the book and pulled up where each of the concepts are covered: * Class - Page 4 * Case Class - Page 7 * trait - Page 25 * Companion objects - Page 32 * packages, imports, namespaces - Page 18 * implicit conversions - Page 108 * multiple class constructors - Page 30 * for-comprehensions - Page 59 * lambdas, closures - Page 24 * what exactly `_` is - Page 8 * Generics and (co/contra/in)variance. - Page 28 These concepts aren't mentioned but not really covered * abstract class Page 30, as a footnote, links to another resource for more info on the subject * A description of the data types and collections found in the standard library. There is no indexed description of standard datatypes, however you reimplement some standard library types in the lessons. Infact the first lesson in data structures reimplements `scala.collection.immutable.List`. Concepts not taught at all * while loops - functional recursion is emphasized as instead of imperative control structures * Value classes * Package Objects While I won't argue that it doesn't teach you every facet of language there is, that's not what OP was asking for, nor the objective of the FPiS. I think your characterization that you can't learn the language from the book is without merit.
Okay but come on. Can you really count this &gt;Note that the Function2 interface (known in Scala as a trait) has an apply method... Function2 is just an ordinary trait (an interface) provided by the standard Scala library as covering traits? And are you going to say with a straight face that this: &gt;There’s a trick to add infix syntax to any type using implicit conversions. We won’t discuss that here since it isn’t that relevant to what we’re trying to cover, but if you’re interested, check out the answer code associated with this chapter. counts as covering implicit conversions? I am not knocking the book -- I think it's a marvel and have learned a lot from it. But it is not a book about Scala, but don't take my word for it, from the very first sentence of the preface: &gt;This is not a book about Scala. Like I said, I've personally tried to help total Scala noobs (but still CS grads and/or experienced devs) through the book, and all of them made it to chapter 6 at best. You can call them lazy, but I do remember many times having to explain how Scala works to fill in the gaps left by FPiS, and even the extremely highly motivated among them feeling like they don't know the language enough to continue. So this is why I don't recommend it to beginners wanting to learn Scala anymore. 
&gt; You have to manually construct the Some(uuid) case from a UUID. Well yeah, but as you are making a new supplier (you didn't specify the UUID of an existing supplier) it should have a UUID to be valid. As it's a UUID you can safely choose a new random one. &gt;control limited to the add method of your service. Well yes, but I don't see why passing in a CreateSupplier is better then passing in the fields needed to create a supplier? Alternately, wouldn't it be better to have a Persisted trait or something that adds the UUID when known? So you could pass in a Supplier through your JSON responses, forms, etc while building, pass it to your database service once validated, and get back a Supplier with Persistence that is backed by the database with an ID? At this stage it's just changing the name of things, but it seems neater and more reusable? &gt; It gives up control over the parameter generation. For v4 UUIDs specifically, that doesn't matter too much. But in the general case, there may be some heavy-weight, side-effecting logic for parameter generation (e.g., Twitter's Snowflake for k-sorted ids). As projects evolve, it's common to find several service-generated parameters that further separate the domain model from the create template. I've not come across that previously, Thanks. 
Kamon is cool and all, but why does anyone here care about Kamon stumping for ByteBuddy?
This is an old project (2013), but looks nice and is the first time I heard about it. Wiki-Links are broken, but I found paper and slides on author's new homepage: - http://www.cse.chalmers.se/~atze/papers/padl131.pdf - http://www.cse.chalmers.se/~atze/papers/padltalk.pdf 
I'm trying to come up with a way to hash scala functions. That is, I want to be able to generate a hash for a function that is consistent between runtimes if the function hasn't changed, but is different if the logic has changed in any way. Anonymous scala functions will each generate their own .class file. It'll be similar to the classname which will be something like "package.Main$$anonfun$2" And you can get a handle to that and hash the bytes just fine. However, this only goes one level deep. if this val nested = (x:Int) =&gt; x + 1 val f = (x:Int) =&gt; nested(x) + 1 is changed to this val nested = (x:Int) =&gt; x + 2 val f = (x:Int) =&gt; nested(x) + 1 Then the class file for nested will change, but the class file for f will not. I'm trying to figure out how to find out what the class file for nested is if all you have is the reference to f. I've been trying out using the ASM library and so far I haven't gotten what I want. In this example nested will have a class name something like "package.Main$$anonfun$1" and f will have a class name like "package.Main$$anonfun$2". Starting with f I know its classname, but traversing it with ASM class/field/method visitors all I'm getting is "nested$1" instead of "package.Main$$anonfun$1" like I would want. Anyone got any ideas?
I assume you're talking about macros? As far as I can tell, macros will give you the AST for whatever is in the macro expression, but not for whatever it references. That is, if you have: val f = (x: Int) =&gt; x*2 val res = someMacro{f(5)} someMacro will only know the AST for the expression "f(5)", it won't know "x*2". If that's incorrect I'd be very curious to know how to get the full AST which includes references.
Create a separate `SupplierDTO` object to use with Slick. Your DAO can 1. accept a `Supplier` (or `CreateSupplier`) from the service 2. turn it into a `SupplierDTO` 3. persist that `SupplierDTO` 4. build and return a `Supplier` to the service The `SupplierDTO` might have ugly things like `Option[created_at]`, `Option[updated_at]` for the database supplied fields, but at least they won't leak past the Slick-specific parts of your code.
That, and the type system.
- Why did you choose to call the operators `==*` and `!=*` instead of the more common `===` and `!==` - What advantage does your library provide over ScalaUtils (http://search.maven.org/#search|ga|1|scalautils -- webpage seems gone: http://www.scalautils.org/ -- perhaps now it's called Scalactic? http://www.scalactic.org/ -- or SuperSafe? http://www.scalatest.org/supersafe)
Perhaps load the class of the function into a class-loader and hash the byte array, like so: https://stackoverflow.com/questions/2036108/convert-class-object-to-bytes#2036139
Could you use the `scala.math.Equiv[A]` typeclass here instead of a new one? Every typed Scala library seems to reimplement it 😊
Thanks for the feedback! Honestly I am learning a lot! I will take a look at your code and try to compare the time vs. Actors. I think my implementation will be slow because of the Listener streaming the results. Do you think using the Stream API is better to send bytes over gRPC? http://doc.akka.io/docs/akka/2.4.3/scala/stream/stream-introduction.html
Scalactic is all you need for the custom equivalency.
Not to nitpick (heh), but pretty sure value classes require the wrapped field to be public....
Oh! I didn't even know `scala.math.Equiv`. Never seen it used. Well, this typeclass is for a different purpose (as clarified in README just now) but it's a subset of `scala.math.Equiv`.
Cheers :D That snippet's cool but a problem I had (which you also have with that snippet) is how do you know `A`s can be compared using `==`? After my data classes started getting large and deep that became a complicated question to answer. Now I just have the `UnivEq.derive` macro everywhere so I can safely rely on `==` working for a whole data hierarchy, and I know the 3 or so cases where it doesn't and shouldn't hold (for those 3 cases I use a `Equal` typeclass instead).
Yeah that used to be the case in Scala 2.10 but it changed in 2.11.
Do you mean because of macros that check data and its dependencies? That happens at compile-time only and if it call checks out, the generated code (which is what makes it to the JS) it just a single call that univ-eq is proved. JS is tiny, no parsing required.
I was doing Python before starting Scala, several years ago. Some quick tips: - "yield" in Scala, along with for comprehensions, work differently than in Python and will be a source of confusion (spoiler: Scala's for comprehensions are much, much better ;-)). But as a word of warning, when you see for comprehensions or the "yield" keyword in Scala, assume that you know nothing about it and work from there. - Scala is expression oriented, whereas Python is statement oriented. Never use "return" in Scala, the compiler will help you get your expressions in order. - get familiar with Scala's immutable data-structures and their operations, because that's the default. No more fiddling with your data-structures manually, learn about map, flatMap, filter and foldLeft instead. - OOP techniques in Scala are fairly similar to what you have in Python. Both support multiple inheritance for example. In Scala you've got "traits" and everything is an object. Functions are first class though and in Scala you'll do a lot with closures expressed as anonymous functions. - you'll hear about some fancy techniques, like the Cake Pattern. Like in other languages, if it smells bad, it's probably because it's rotten. Common sense is universal, so use it. And yes, don't use the Cake Pattern or other such bullshit. - in Scala you'll see emphasis on asynchronous programming. Get familiar with Futures / Promises. But avoid actors, at least while you're a beginner. And keep in mind that in spite of its original marketing, Scala is not about actors. - Python is dynamically typed. This means that it can afford to do some tricks at runtime, some "meta programming" when needed. Scala does a lot of things at compile time instead. In Scala embrace its statical compile-time nature and reject techniques that rely on runtime reflection / introspection. - You'll get tempted to use the "Any" (and isInstanceOf/asInstanceOf) coming from a dynamic language. Try to resist this urge and in case of trouble ask more experienced people about how to avoid using "Any". - Most importantly, if you see Scala libraries working with "Any", avoid them like the plague. Yes, avoid Scalatra or other libraries inspired by Ruby. It will bring you nothing but misery. - "Functional Programming in Scala" is an awesome book, but heavy and it teaches you about functional programming and not Scala. It's amongst the best FP books ever written. BUT it's not about Scala. So if you're just learning the language, getting the hang of things and so on, it might not be as useful as you think. It's a fun book though. If you ever read it, don't skip the exercises. Hope this helps. Cheers,
I just had a look at `scala.math.Equiv` in more detail. Unfortunately I'd never be able to use it as an `Equal` replacement because of this: https://github.com/scala/scala/blob/v2.11.8/src/library/scala/math/Equiv.scala#L42 If I tried to compare data that can't be compared, I'd want a compile-time error so I could either change my logic or make the data comparable. This would just silently and incorrectly roll on.
Argh. Yup, you're right. That instance is really awkward. I was just today thinking it'd make much more sense to have an `Equiv[A: Ordering]` there instead.
How the heck do I make an http request? The premise is simple, more of a script. Hit https://www.reddit.com/.json, pull in some post data, do some of that oh so fun FP on comments and things. The problem is ... every library for JSON parsing or http seems to be either depreciated or abandoned or full shit like `~&lt;::&gt;` 
&gt; where is this provides a proof that the underlying types' .equals implementation correctly defines the equality. How does it do that? From what I'm seeing [here](https://github.com/japgolly/univeq/blob/b4b637d5e6b651f097fd1c04751ed24c90a1aa88/univeq/shared/src/main/scala/japgolly/univeq/UnivEq.scala) it looks like there's no checking at all. Perhaps rather than "proof", you mean "assertion"?
What you're seeing there are just the axioms. Non-axiomatic proofs are provided via macros. [Examples](https://github.com/japgolly/univeq/blob/master/univeq/shared/src/test/scala/japgolly/univeq/external/DerivationTest.scala).
Scalaj-HTTP and uPickle work great from scripts. haoyi-Ammonite@ load.ivy("org.scalaj" %% "scalaj-http" % "2.2.0") haoyi-Ammonite@ import ammonite.ops._, scalaj.http._ import ammonite.ops._, scalaj.http._ haoyi-Ammonite@ val resp = Http("https://api.github.com/repos/scala/scala").asString resp: HttpResponse[String] = HttpResponse( """ {"id":2888818,"name":"scala","full_name":"scala/scala","owner": {"login":"scala","id":57059,"avatar_url":"https://avatars.githubusercontent.com/u/57059?v=3","gravatar_id":"","url":"https://api.github.com/users/scala","html_url":"https://github.com/scala","followers_url":"https://api.github.com/users/scala/followers","following_url":"https://api.github.com/users/scala/following{/other_user}","gists_url":"https://api.github.com/users/scala/gists{/gist_id}","starred_url":"https://api.github.com/users/scala/starred{/owner}{/repo}","subscriptions_url":"https://api.github.com/users/scala/subscriptions","organizations_url":"https://api.github.com/users/scala/orgs","repos_url":"https://api.github.com/users/scala/repos","events_url":"https://api.github.com/users/scala/events{/privacy}","received_events_url":"https://api.github.com/users/scala/received_events","type":"Organization","site_admin":false},"private":false,"html_url":"https://github.com/scala/scala","description":"The Scala programming language" ... haoyi-Ammonite@ val parsed = upickle.json.read(resp.body).asInstanceOf[upickle.Js.Obj] parsed: upickle.Js.Obj = Obj( ArrayBuffer( ("id", Num(2888818.0)), ("name", Str("scala")), ("full_name", Str("scala/scala")), ( "owner", Obj( ArrayBuffer( ("login", Str("scala")), ("id", Num(57059.0)), ("avatar_url", Str("https://avatars.githubusercontent.com/u/57059?v=3")), ... If you want tiny libraries to deal with HTTP and parse JSON without rubbish like async or reactive or monads, these are what you're looking for
Thanks for this, just what I was looking for! I definitely started looking into Scala because it seemed to be a good fit for asynchronous programming. My primary focus is on streaming analytics, distributed computation, and data mining, and, while Python is well-suited to some of these tasks, its weaknesses come through when trying to scale. Looking into Scala, frameworks like Akka, Finagle, and the like are very appealing. I'd like to lean on Scala for high-concurrency and storage applications, but stick with Python for other things like deep learning and natural language processing. I can't see deeplearning4j/s or similar really replacing Theano/Tensorflow for me. I've looked into Scala libraries for nlp, and it seems like Python has a leg up there as well. Python's weaknesses really become apparent in the context of memory management, threading, and applications that spend a lot of time inside Python's GIL. I initially looked into other solutions like porting some of my stack to Cython, but in the end, I think jumping into another language like Scala will be better. I think it's important to leverage the strength's of different systems, rather than stick with one unifying framework and trying to patch its weaknesses. 
For me, the best place is to keep implicits for type conversion is the companion objects of the appropriate classes. Or keep them separately in a stand-alone object (with nested objects), so you need to import them when needed. And keep those imports as close to the code that uses them, as possible (using some extra {} to limit the scope really helps)
&gt; I have definitely seen them abused (and I have abused them myself at times). Can you articulate what you consider an abuse to be?
Things like using implicit parameters in situations where the type has a very small scope and should probably be passed explicitly instead of declaring `implicit val ...` the line before calling the function. Or things like this: implicit class Logger(a: Any) { def printErrLn() { System.err.println(a) } } That implicitly allows printErrLn() to be called on any type. Or implicitly converting types where it would not be obvious that those types should be implicitly converted. Just general bad design using implicits
Because it is poorly typed. I think there are useful ways to add functionality to specific types using extension methods. However, I think there are better ways to design the kind of functionality that could be used on Any type. This is a bit of a slippery slope argument but I feel like adding extension methods to every type could get pretty nasty pretty fast and developers should really think about whether it is even useful, or just easier, to design things in that way.
**Implicit "don'ts"** * As /u/Milyardo said, don't create a conversion that doesn't **always** apply * I'd advise against requesting implicit parameters of extremely general types, like Int. Int @@ Timeout or something is fine though. * Be careful of how you name implicit vals/defs. For typeclasses, it's a standard practice to preface the identifier with the type the instance is for. So don't do implicit val order: Order[MyType], do implicit val myTypeOrder: Order[MyType]. The reason for this is variable name shadowing can mess with things. For example: https://gist.github.com/anonymous/28d1e1cc19f7f1896e6251d5cb9857ac **Implicit "dos"** * Typeclasses are generally good * Recursive implicits when combined with shapeless/other generic structures are generally good and can solve things that are impossible otherwise * Extension methods are generally good * Don't be afraid of Unapply **Implicit grey areas** * Canonicity or not for typeclass instances. Tags/AnyVal newtypes vs multiple implicits but only (locally) importing the correct one. I prefer the former but I've had people use the latter and it's been equally fine.
Have you tried [scala pickling](https://github.com/scala/pickling) ?
What non-IDE do you think is best to develop with in Scala? I'm having some issues with Intellij and am exploring using something like Sublime Text instead, but I'm curious if anyone else has any opinions to offer.
This looks really cool, I can't find the project on github though, do you have a link?
How do I speed up a build? My company has a large monolith project and s build even with zinc server takes 5 minutes. Is there anything that can be done, since this kind of turnaround time is insane 
Looks alot like Screeps. Are there any plans to host MMO type game multiplayer mode?
Take advantage of the incremental compiler as much as possible. Only do a clean build when you are creating the artifact to deploy to the server. You could also try using nexus or artifactory to bring the dependencies into your network to speed that process up as well.
There are some differences to Screeps. In terms of the gameplay, CodeCraft is geared towards short, fast-paced 1v1 matches. Also, the AI code is always executed by the clients and not the server. This makes it much easier to support additional languages and also allows you to use all your usual tooling, CodeCraft is just a library dependency. But it does make it difficult to support continuously running games like in Screeps. A multiplayer mode is already in the works. At the moment I envision it mainly as ranked matchmaking for 1v1 games. In principle there is nothing to prevent you from running games on large maps with many players, but I suspect performance/scaling issues would prevent a true MMO mode without substantial changes.
my biggest problem: scala/sbt is fairly slow to compile, and implicits make everything even worst. I saw a talk by odersky (can't find it...) about dotty, saying that a single line of code (using shapeless - so many implicits used) took 7 minutes to compile...so be careful 
Does anyone have experience trying to use sbt's triggered execution in conjunction with Vagrant shared folders? I can't seem to reliably get sbt (which is running on the guest OS) to pick up changes to the code I'm making on the host OS.
How exactly did you come to the conclusion Scala.js isn't production ready?
I'd say it is, when it reaches v1.0, no? Definitely debatable, though!
Just to elaborate, what people most like about node is the ease of defining web services using express framework. Using spray routing is similar but more powerful, safer, and far more scalable. If you have a simple back end that you can finish in two weeks it doesn't matter what language you use. If you are working on something substantial then node will bite you in the ass after a while. I spent over a year on a serious node.is back end. It's great at first and gets more and more horrible as time goes on. Scala is the other way round.
I'm suddenly having GWT flashbacks. Anyway, I haven't seen too many cases where the same logic should be applied on both the server and the client. Data validation is probably the most common case, like their example shows. Maybe sharing Scala code into a Node or mobile browser project is the next best use case? Good luck to them!
Hello! Would you consider a remote position for the right candidate?
Being able to program Scala instead of Javascript is in itself an use-case in my view. I haven't had the opportunity to use Scala.JS for anything meaningful yet, but I'll certainly try to if I have the chance.
Looks really nice with one exception, the fact that Var is mutable if I understand that correctly.
Hi, 80,000 Scala/Akka/Play/Spark developers and hiring executives visit Lightbend's website and we have a "Our Customers Are Hiring" section that gives JPMC access to all of these qualified candidates. Call us to see how and Good Luck!
Hi. :) If you have the right skill set, we can certainly discuss several options.
Thanks, that's really useful to know!
Yeah, I am in!
Me!
The first after 3 years of Scala Italy :)
Lots of things wrong with the characterizations the "reader monad". &gt;Some people argue that the reader monad can replace the functionality of other dependency injection mechanisms. I say that’s not entirely true. While the reader monad is a great functional tool, in my opinion, if used as a DI technique, it performs best in conjunction with object-oriented DI mechanisms. The problem is that when you declare dependencies in method signatures, as it is done with the reader monad, you can’t separate dependencies of concrete component implementations from their interfaces. Take a look at the following example: err, what? Parameterize it and there you go. 
By "manually" I assume you mean without using some flavor-of-the-month DI syntactic sugar. To me it seems that DI annotations only further obscure issues of order of initialization, which in the best case may depend on implicit rules of the base language concerning initialization. If the base language itself provides syntax which can express DI, I think I'd rather read code that uses that, than code that uses some annotation to achieve the same effect. But using "lazy" doesn't really define a localized and explicit order of initialization either. In that case the order is determined at run-time, according to the order in which the lazy items are referenced. That works as long as "on-demand" initialization of dependencies suffices. But it also means that a system may be up and running for some time before a dependency gets initialized. If an error occurs in such a late initialization, it may be a surprise to the code referencing the dependency. 
This is not the cake pattern all over again. Don't downvote based on title like I nearly did.
&gt; err, what? Parameterize it and there you go. Thats the entire point, he is saying that he doesn't want it parameterised. What he is asking for is something thats not possible while being purely functional, his argument is that he doesn't believe dependencies injected by DI should expose themselves in method/function parameters.
“Unfortunately, many teams have been burnt by the Cake Pattern and are looking for other solutions, often returning to more or less involved DI libraries.” — As someone who's exploring using the cake pattern, I'm curious as to what he means by this. Does anyone have a similar sentiment to his and care to share?
This looks incredibly compact. I understand that binding.scala inherits most of its characteristics from scala.js, but are there some special caveats when mutating synced data from concurrent threads in the backend?
I had a similar problem with the Akka version used inside Spark. I was however able to fix this without shading (which I considered too): http://stackoverflow.com/questions/35578732/java-lang-nosuchmethoderror-akka-actor-actorcell-addfunctionref/36443230#36443230 As for SLF4J: I set it to "test, provided" in my build.sbt and had no problems so far.
Just apply for the mid-level jobs. Good teams hire for attitude and desire to learn, not for a list of checked tick marks. You'll figure out who's good and bad quickly.
Just apply for mid level jobs anyways. There isn't that much difference in responsibility in a junior and mid level developer outside of perhaps being able to work more autonomously. So be prepared the emphasize that in your interview. Also, it may just be your location, a quick search for junior positions on Indeed in my area(Washington, DC) revealed about 100 positions, I did not find my own place of employment on the list which is looking for Scala developers at all skill levels, so I don't believe it to be comprehensive.
I'd message the author and ask what they use it for.
Umm... mid level jobs still ask for 2-4 years of experience. I never fixed a bug for anyone other than myself at any point in my life. Java and Python have plenty of jobs and internships listed with zero experience requirement what so ever. When I say "entry level" I mean like internship or first job ever.
What are you talking about? I have never had an internship or a job other than fast food. I never fixed a bug for anyone other than myself at any point in my life. When I say "entry level" I mean like internship or first job ever. 
You dont nessecerily have to know the language the firm code in, in order to get hired as a intern/junior dev. All programmers have been where you are right now, but what all professional programmers have done at some point, is to just let go of that anxiety and fake it till you make it. So who cares if they program java or python and you code Scala, they don't expect you to know it from the beginning anyway, what they expect you to do is to go home and read a book about it. 
That's retarded. If you hire a bunch of Python programmers to do a functional backend in Scala with someone with a Haskell/Erlang background and tell the Python programmers to "read a book", they will probably suck and it will probably take several months before they cease to suck. Heck, if you take seasoned Java programmers with no functional background what so ever and no understanding of any of the features they will still probably suck. Do employers seriously waste 1,2,3,4 months just getting people up to speed?
Yup, this is so true. My DI usually is either cake pattern (I have no idea what cake pattern was until it was described to me), with a combination of implicit + lazy vals. Sometimes I use macwire to work with the really complex cases.
This is really good, why isn't it popular?
This really should be baked into the language...
FWIW, this and more is already in [Shapeless](https://github.com/milessabin/shapeless/blob/shapeless-2.2.5/core/src/main/scala/shapeless/package.scala#L53).
Definitely not. It's preferable to be able to express it in a very little library code. This is a good example of the fact that Scala really is a small, simple language. Not as small and simple as it could be—Dotty's better that way. But you already have type-bound constraints, so all you need is a way of expressing negation at the type level. The concept to master is that `=&gt;` and `&lt;:&lt;` both model logical implication, so `=&gt; Nothing` and diverging implicits when `&lt;:&lt;` holds both model logical negation. The Shapeless link I posted in this thread uses both: diverging implicits to implement `&lt;:!&lt;` ("not a subtype of") and `=&gt; Nothing`, `with`, and De Morgan's law to implement `|∨|` (this type or that type, without boxing like `Either` or `\/`).
Using diverging implicits like this is a hack.
And ensuing over thinking on HackerNews: https://news.ycombinator.com/item?id=11465672
If you mean this should be a part of the standard library, I might give you that, but having negation built into the type system as a special case only serves to complicate the language.
Holy gobbledygook. Even if you're right that it's not really a hack, I'd still never understand why without some serious formal education.
`A` *is* `String`, and therefore also a subtype of `String`, when it gets instantiated in `fooString`.
No, at definition, `A` is abstract type bounded between `Nothing` and `Any`. `String` is a type which can satisfy those bounds, but those bounds are not a `String`. At call site, String is applied to A, which meets those bounds of `Nothing &lt;: A &lt;: Any`.
Why would you use mysql over postgres =\
I did this as Q&amp;A on SO: http://stackoverflow.com/questions/36535605/how-can-i-have-a-negation-type-in-scala
Sorry for being factitious earlier. But, I would highly recommend picking up the [Red Book](http://www.amazon.com/Functional-Programming-Scala-Paul-Chiusano/dp/1617290653).
Only Americans do that
Hmm. My company's DBA chose mariadb as primary db. So I have to use many mysql &amp; maria database :-( I also. like postgesql. 🤗
Thank you
Check your blogpost: double paste Thanks for sharing!
Mysql is much faster in simple tasks. In some cases it is better/cheaper
That was only somewhat true like 10 years ago. And even if that were the case, that's not a very good reason to choose a database. You're eventually going to have to do more than simple tasks and then you're screwed. Also, please tell me how it's in ANY way better or cheaper. http://grimoire.ca/mysql/choose-something-else
&gt;Try-Catch is the OG of error handling, but it’s the sensible thing to do often times. What does this even mean...
I'm a good chunk into the red book, but unless something changes drastically in later chapters, it's more focused on functional programming rather than type level programming. Something as fundamental to type level programming as type lambdas are just mentioned as an aside. Many common patterns and techniques are not examined at all. If you have any better book suggestions for learning type level programming in Scala, I would be eager to hear them.
I don't think you are yet at the point of truly leveraging Scala to better handle errors. For example: - Option is great for when something may or may not be there. Don't use it for errors though. I think you get that - Just don't use exceptions. They aren't pure, and can't really be conveyed in the types, nor composed. - Don't use Try. Again, it doesn't convey the error type properly. - Don't have errors extending exceptions. Just use a value type, constructors fromException etc - Prefer Scalaz Disjunction (or whatever the cats one is if you are a cool kid) - Leverage ADT's and what the sealed keyword provides For more information have a look at these links: - [Designing fail fast error handling](http://underscore.io/blog/posts/2015/02/23/designing-fail-fast-error-handling.html) - [Life without stacktraces](http://blog.charleso.org/life-without-stack-traces/#1) - [Error Handling Without Throwing Your Hands Up](http://underscore.io/blog/posts/2015/02/13/error-handling-without-throwing-your-hands-up.html)
Yes, `Var` is not pure functional. What's the problem?
IMO, production-ready ~= your code does not break when you upgrade your Scala.js version. Or if it does, it was after a long time of deprecation warnings. (of course defining "long time" is also hard) By that definition, Scala.js has been production-ready since 0.6.0 in February 2015. No code has been broken since then so far. And breakages intended for 1.0.0 have been in deprecation since 0.6.5 in August 2015.
That usually results in unhelpful error messages, though.
Thanks for these tips. I am still pretty new to the language and was just trying to cover some basic techniques. I'll use some of the information and tips you provided in the near future and update my post. Thanks a ton, always appreciate the Scala community for their insight and helpful tips.
Learning one language and then finding a series of jobs that use that language is only a practical way to go for languages that have massive usage, like Java and C#. I'm sure that with hindsight, you would have checked Scala demand before investing a lot of time into learning it, as opposed to skills that are easier to get that first job with. I strongly believe learning a language like Scala is a great career investment, but it may not have minimized time-to-first-job. I wouldn't get down about it, because your Scala skills will eventually come in handy, once you build some work experience. As someone who has led Scala teams, I would rather frankly rather hire someone who is an accomplished programmer with a strong interest in learning Scala than a person with Scala experience but no track record. I'm sure many would feel the same way. So, the way I see it, you have three choices. - You can keep trying for an entry-level Scala gig. That's going to be a tall order. - You can find ways to build proof of your Scala skills through independent work. To many places who are hiring, accomplishment in open-source work is on par with accomplishment in paid work. There are lots of great projects out there to contribute to in the Scala ecosystem. - You can learn a language that has better employment on-ramps, like Javascript. As an aside, reading your responses throughout this page, you should consider putting some work into how you present yourself. Someone dropping a "that's retarded" in normal, public conversation would be a red flag many places.
Some of the comments here https://www.reddit.com/r/scala/comments/3f5jzx/what_should_i_know_about_java_infrastructure/ could be helpful
Given what I have seen of `scalac`'s speed when resolving implicits, could anyone who uses the typelevel stack heavily and shapeless in specific comment on how long your code takes to compile? How has that scaled as your codebase has grown?
*Here's the Urban Dictionary definition of* [***OG***](http://www.urbandictionary.com/define.php?term=og) : --- &gt;Original gangster --- _someone who has been around, old school gangster_ --- [^(about)](http://www.reddit.com/r/autourbanbot/wiki/index) ^| [^(flag for glitch)](http://www.reddit.com/message/compose?to=/r/autourbanbot&amp;subject=bot%20glitch&amp;message=%0Acontext:https://www.reddit.com/r/scala/comments/4e8gln/the_beauty_of_error_handling_in_scala_beginner/d1yfwh8) ^| ^(**Summon**: urbanbot, what is something?)
There was a thread a little while ago that might help. It was about a Python dev wanting to pick up Scala as well. Might be some tips worthwhile there: https://www.reddit.com/r/scala/comments/4d6cv2/has_anyone_learned_scala_from_primarily_a_python/
Aside from learning new tooling, getting used to a different set of libraries &amp; documentation, waiting for the compiler, and being more verbose due to types, will be some wrinkles compared to Python.
I'm surprised at the absence of mention of [sbt-sonatype](https://github.com/xerial/sbt-sonatype), which allows closing a repository from within SBT. Do you not know of it, or do you have reasons to avoid it?
It's probably worth skimming through Java fundamentals when learning Scala. Just enough to be able to interop with Java libraries.
thanks!
Scala.js doesn't compile Java at all but compiles pretty much any Scala code. The approach taken so far for Java libraries is either to convert Java to Scala (sometimes with help from tools like [scalagen](https://github.com/timowest/scalagen)) or to write replacements from scratch. Along these lines, @jducoeur has started a [pure Scala implementation of HOCON, suitable for cross-platform use](https://github.com/jducoeur/shocon). 
Well, you need to start somewhere. It's a cliche, but it's true. Huge movie stars tend bar or wait tables before they hit it big. You have to settle for starting with HTML/JS/CSS (or anything, really) code monkeying before you can climb up to mid-level Scala.
It's very hard to quantify the trade-off, if any. The explosive compile times of the past are pretty much gone I think. In any case you're gaining more polymorphism (so you have less code to compile) and more type safety (so you have less to check at runtime, thus less code to compile, and also fewer bugs to fix). So for me it's certainly worth it.
I should note that replacing heavy overloading with shapeless actually sped up doobie's compilation time. So as always, "it depends".
It's the tooling that has me most worried, actually. Maven, ant... what is the "compiling" of which you speak?
Atomic Scala takes a pure-scala perspective IIRC - it didn't exist when I was learning but I like the look of it. 
I went from C to scala and I didnt have much trouble with knowing little of java. I used the book functional programming in scala to learn, which had a fairly brutal learning curve, but not because of missing knowledge of java. This may not hold if you're looking at a more mutable style closer to java though, so my advice may not hold for your use case.
I didn't know about it thanks
I understand that. But what do those statements have to do with one another? It's the OG, BUT it's the sensible thing to do? I don't understand the but.
Hi, I'm with Scala for 6 months coming from PHP. Train with FP structures and learn about Scala type system... It will make the difference!
I'm starting work on a scala.js project doing visual dataflow programming for audio synthesis / signal processing (like Max/MSP or pure data ([image1](http://www.kx1.us/sites/spacefillingcurve_net/programming/maxmsp/mandelBTS2.jpg), [image2](https://flossmanuals.net/pure-data/ch040_wireless-connections/_booki/pure-data/static/PureData-DataFlow-sendreceive1-en.png)). So basically the user can add and wire together pre-defined nodes (which can be sound generators, transformers, filters, etc.) directly to the audio graph. These nodes would have an `Audio` type, but there would also be nodes with, e.g. `Float`, which could be wired up to the parameters of an audio node (or whatever else). The issue that I'm having is that I would like to be able to have nodes of all different types (i.e. nodes which produce and consume streams of `Int`s, `String`s, etc.), but I cannot figure out how to allow the user to wire these together themselves at runtime. So the user might try to wire the output of A to the input of B, and if they are found to both be compatible, type-wise, they could connect them, otherwise they would not be able. I suspect reflection/type tags might be the answer, but it looks like this isn't supported by scala.js. Anyone have any ideas?
That's already a feature in scala 2.12. EDIT: https://github.com/scala/scala/pull/4673
Not that I dislike python at all, but I don't understand why it is used here?
I assume there is a closed set of Node types which the user can define? Why not use a sum type and pattern match on the value?
Scala for the impatient is a good book to read through. 
No, because it doesn't rely on pattern matching on types (AKA typecase). It's just another example of Scala giving us a type equality constraint, `=:=`, and wanting to negate it, so Shapeless again just introduces ambiguous implicits in the case when `=:=` holds when it's not wanted. The tl;dr about Shapeless is that it looks at types through the Curry-Howard lens, then uses scalac, and implicit resolution in particular, as a kind of Byzantine version of Prolog, to do logic programming at the type level. Negation as implying divergence takes a bit of getting used to, but if you work through The Little Prover or learn Coq or Idris, you won't be able to avoid it. :-)
I'm not sure this title helps to show that Scala is simple ...
Wouldn't something like this work? case class Node[In, Out]() { def connectInputToOtherNodeOutput[OtherIn](otherNode: Node[OtherIn, In]) = null def connectOutputToOtherNodeInput[OtherOut](otherNode: Node[Out, OtherOut]) = null } val int2String = Node[Int, String]() val stringToChar = Node[String, Char]() val bool2Double = Node[Boolean, Double]() int2String.connectOutputToOtherNodeInput(stringToChar) // compiles int2String.connectOutputToOtherNodeInput(bool2Double) // doesn't compile
I'm from a PHP background and I learned with the Coursera courses. It's pretty thorough and no knowledge of Java is needed, although it does make comparisons with Java from time to time.
A sum type in scala is encoded using a sealed trait and case classes. sealed trait Foo case class Bar(n: Int) case class Baz(name: String) When using a sum type the compiler can reason about exhaustiveness when pattern matching(if you've matched every possible value and didn't miss a case). Solving this problem generically can be done with [shapeless](https://github.com/milessabin/shapeless) or with typeclasses, though I'm not convinced it needs to be generic(you haven't indicated if user defined types would be something you'd like to support).
Nice work! Thanks!
I'm excited to see this. Anyone know if the actual presentation is online anywhere ?
Yeah I'll second one /u/ItsNotMineISwear said. IntelliJ hands down top choice. But I have ensime with emacs setup and it's quite nice. I just rarely break open emacs anymore.
You mean using a typeclass instance to resolve a static singleton? No, at that point you might as well just use a static singleton (`object`), the indirection isn't buying you anything. 
Then why is it called "Academese to English"?
It's a title Heather Miller uses similar presentations presentations, like this one on [dependent types](https://www.youtube.com/watch?v=ptCvn4-lyXM) in Scala.
I don't think so. The issue is that the nodes are connected at runtime.
At Kifi.com we use Angular and Play and I love it :)
Domlebo70's tips are good, but unfortunately we're stuck in a world of exceptions until scala is divorced from the jvm.
Hi, can you pls explain what you meant with your points 2,3,4 in more detail? 
Getting the same error here. (which i "fixed" by publishing a local version from the v0.2.0 tag)
People also persist in confusing "simple" and "familiar." Scala is quite simple (has a very few, highly orthogonal, primitive concepts). Scala is not (necessarily) very familiar, unless you come to it with prior experience in the ML family (which I'll stretch and include Haskell in), as I did.
If I'm working on a project that's using Scala 2.11 and I find a library that I'd like to use, but it hasn't been compiled for 2.11 yet (and isn't being actively maintained), what options do I have?
Yup, downloading it now, thanks. 
The future Scala native should be perfect for these use-cases as well.
If it is on github, fork it and update it yourself
Yes it can! And those will be included in defaultWithAlign in 0.2.1, see [#155](https://github.com/olafurpg/scalafmt/issues/155).
&gt; but it hasn't been compiled for 2.11 yet It's most likely a legacy|abandoned library. I'd recommend to seek for an alternative or ask it here.
I tend to use `val`s for small utility functions that do not require boxing, as I like the "ignore parameter name" syntax: `val twice = (_: String) * 2` Other than those, it's usually `def`s all around unless I want to put focus on order of composition: https://github.com/melezov/Sluggifier/blob/master/src/main/scala/hr/element/etb/slug/Sluggify.scala#L43 
Windows is fine. Easier than Linux at setting up sbt. 
sudo pacman -S sbt Wow, so difficult. 
Slick is pretty close to SQL semantics, so - as other people have noticed - how would you approach this in SQL? Your `Persons.withDishes` is an equivalent of: SELECT p.id, pd.value, d.name FROM person p JOIN person_dish pd ON p.id = pd.person_id JOIN dish d ON pd.dish_id = d.id which will return the data in the same shape as a SQL query: a flat 'table' with attributes from all joined tables. If you want to make it hierarchical - either do it on the application side, or split your queries into _two separate parts_. Option 1 (one get-them-all query a'la SQL, post-processing done on the application side): val query = Persons.withDishes.map{ case ((person, dishPerson), dish) =&gt; (person, dishPerson, dish) }.filter(_._1.id === yourId) .result val result : Future[Option[(Person, List[(DishPerson,Dish)])]] = db.run(query) .map(_.groupBy(_._1) .mapValues(_.map { case (p, pd, d) =&gt; /* select what you need */ (pd, d) }) .headOption) The code is unchecked. :) Option 2 (two queries): val action = for { person &lt;- Persons.all.filter(_.id === yourId).result.headOption extraData &lt;- person.map(p =&gt; DishPersons.all.filter(_.personId === p.id).join(Dishes.all).on(_.dishId === _.id).result).getOrElse(DBIO.successful(Seq())) /* I don't remember the types here, but they have to match */ } yield person.map(p =&gt; (p, extraData)) db.run(action.result.headOption).map(_.flatten) I don't have my project in front of me to confirm that the exact syntax above will actually work, but you should get the gist of it. 
You might want to highlight which lines changed, as I had to diff the code to notice the improvements. The change looks good. You might want to discard the lastValue when the refresh completes successfully to let it be GC'd. It sounds like it works well, but if you want to test it then [Awaitility](https://github.com/jayway/awaitility) would be a good fit. I wrote ConcurrentLinkedHashMap, so its nice to see that's still found useful. Since then this work has matured, with [Caffeine](https://github.com/ben-manes/caffeine/wiki/Refresh) being the current iteration. That has built in [refresh](https://github.com/ben-manes/caffeine/wiki/Refresh). There are some [refinements](https://github.com/ben-manes/caffeine/issues/56) [pending](https://github.com/ben-manes/caffeine/issues/7) that I should finish and settling on the API changes. Feedback would be welcome.
Bollocks. This is how you set up sbt on Linux, using paulp's script: curl -s https://raw.githubusercontent.com/paulp/sbt-extras/master/sbt &gt; ~/bin/sbt \ &amp;&amp; chmod 0755 ~/bin/sbt (plus making/adding `~/bin` to `$PATH` if you haven't done so yet) Getting started with Scala on Linux is super simple.
&gt; A def defined method is reevaluated every time it is called &gt; A val functions is evaluated once at the point of definiton What do you mean by that? 
You can use [Ammonite](http://www.lihaoyi.com/Ammonite/#Ammonite) on Linux, if you like this style of learning.
Ammonite isn't really ready for everyday use IMO, or at least i found quite a few unintended behaviour. But you can use scala repl under windows too. 
I was thinking about using Scala with Jupyter for one-liners.
Wonderful use of Old English.
Just curious: Is the 22 limit ever a (real) problem?
&gt; Slicks groupBy is much closer to what SQL does, in that it needs some kind of aggregation function - sum,min,max, etc.. False, it's a meme that leads to end user pain such as OP's, your's, and literally anyone who has ever wanted mixed aggregate and non-aggregate data in a query result. As of SQL99+ the requirement to flatten the result only applies when the query result is non-deterministic (e.g. `select sum(a.num), b.* from A a, B b where ... group by a.id`). If, however, one appends say, `B` table's primary key to the group by clause, then the query result is deterministic and you can *freely* mix aggregate and non-aggregate data in a *single* query. Having used Zeiger's most excellent ScalaQuery since 2011, the transition to collection based groupBy and sortBy in Slick, and the pure syntactic tuple soup pain that that inflicts on the user (not to mention performance impact of needing multiple queries to simulate the blindingly simple SQL99 step above), I can only lament when wonderfully elegant new comers to the query dsl landscape like [Quill](https://github.com/getquill/quill), follow Slick's lead in this regard. 
IntelliJ IDEA renders nicer fonts on Windows. Other than that, there's no difference so use the OS you're most familiar with.
original generation i believe
I mostly agree. But I do think exceptions has a few use-cases still. While I agree that some 3rd-party library or a functional small module of your system should be explicit about it's possible failures and use a ADT or Either/Disjunction/Or/Xor/Option, I think that exceptions are very pragramatic inside your top-level production code (or "imperative shell" if you will). For example, when receiving a http request from the end user, there's a million things that could be wrong. Throwing an exception up to the top-level error handler is very pragramatic imo and is much harder to "fuck up". It also saves a potential ton of boilerplate. At least I have yet to see a non-overcomplicated alternative way of doing this that doesn't require every top level method to be annotated with every possible thing that could go wrong...
Best to develop in an environment that resembles the most popular deployment environment, so you should only develop on Windows if you intend to mostly deploy to Windows. Another factor: most command-line tools work much better on Linux or Mac; many do not exist for Windows or they don't work properly. Cygwin is more trouble than it is worth. All this may change in 6 months when Canonical provides GNU bash support for Windows 10.
That's not really terrible though. I'm pretty sure shapeless could help you out here if you're worried about it. 
I don't think that exist a valid way to diff in ~~git~~ gist. All the credits should go to the original spray impl. I only added the lastValue to the entry. Original: https://github.com/spray/spray/blob/release/1.3/spray-caching/src/main/scala/spray/caching/LruCache.scala Thanks for the tips. I didn't notice that was doubling my memory usage. 
As if anyone who hasn't used scala before knows where to find that. And as a long time scala user, I don't even know about it really, except for hearing it on occasion. For that matter, setting up sbt on Linux and Mac a multitude of times, I have never done that, and probably never will. 
Pacman isn't setup by default in any Linux, for that matter, never really heard of it until now. Only yum, apt-get, dpkg, etc. Once again, no ease. 
Why the use of macros for logging is more interesting that pass by reference? Everybody know that this could be bad in production logger.debug(s"the value is ${bigValue}") Library like https://github.com/typesafehub/scala-logging create a wrapper that uses macros to rewrite it to: def debug(message: String): Unit = macro LoggerMacro.debugMessage if (logger.isDebugEnabled()) logger.debug(s"the value is ${bigValue}") Why not use a more functional aproach by simple receive msg by reference? def debug(message: =&gt; String): Unit = if (logger.isDebugenabled()) logger.debug(message)
Eh, adding things to the path for your home directory with your ~/.bashrc is really easy. And I'd say the advantages linux gives you in terms of filesystem behavior, and a more powerful shell (granted windows 10 and bash!) is probably worth a slight amount of difficulty installing SBT.
Things work a little more nicely on Linux, but not by enough that it's worth switching systems for if you're unfamiliar with Linux. I use Eclipse for everything in any case, so day-to-day Scala development is exactly the same on Linux or Windows. 
I do, for one. Arch is 9th most popular on Distrowatch, Antergos is 23rd, and Manjaro is 6th. A fair number of people use Arch or its derivatives and anyone who claims to know anything about Linux should probably know that pacman exists.
I like the run methods given by scalaz's Task. Having to use an object outside of Future called Await was unnatural when I was first learning how to use Scala's Future.
As always "it depends" ... but as a rough guideline I suggest you use methods by default because method types are much more expressive, and use functions when you must (i.e., when passing as an argument or returning as a result). You can construct a function that delegates to a method via η-expansion, as described in this [tiresome blog post](http://tpolecat.github.io/2014/06/09/methods-functions.html).
Disagree, at 9th most popular, it's not worth knowing about.
Anyway, back to the original post: The platform doesn't matter; use whatever you're familiar with, ignore the XXX platform is better trolls. sbt and sbt-javacv make it really easy, it's as easy as putting the following in project/plugins.sbt: addSbtPlugin("org.bytedeco" % "sbt-javacv" % "1.6") With sbt setup, you now have access to the javacpp opencv bindings (they aren't quite the standard opencv bindings, but work just as well). Import the project into IntelliJ with sources (in the SBT import dialog) and you can now browse the entirety of the API. The platform you choose doesn't matter, once you have sbt setup.
That still unnecessarily allocates the closure needed to do the logging even when the message isn't going to be logged. The macro approach avoids all allocation.
That's not correct - almost everything on the slides is missing from Java. Specifically: * Bottom types (Nothing, Null) * A parent of all value-classes (AnyVal) * Abstract type members * Declaration-site variance * Existential types
You can highlight lines, it's really slick. https://gist.github.com/sisso/0309e0677da4e60b4044#file-expiringlrucachewithasyncupdate-scala-L110-L115
I certainly think there's room for improvement, and Dotty looks like it offers quite a lot of that. But Scala, today, really is a simpler language than, e.g. Java or C++. I'm continually surprised by the extent to which Java developers, in particular, either _forget_ or for other reasons _gloss over_ the unbelievable complexity of the language, and how it tends to show up by the rapidity with which any non-trivial Java project becomes an unmaintainable spaghetti mess. The day-to-day experience really is night and day. To offer just a couple of examples that I find telling: I don't use an IDE with Scala because I don't need to: it's sufficient just to have code completion and relatively quick access to ScalaDocs, which I have thanks to EMACS and ENSIME. More significantly than that: I literally cannot recall the last time I used anything that could be called a "debugger" on a Scala program, and I've been doing Scala professionally for five years. It's unfathomable to think of using Java again without using a debugger. So I'm afraid I have to stand behind what I wrote: Scala is _different_ than what most people are used to, and there is a _learning curve_ with such an orthogonally-designed language. That's not the same thing as "complexity."
I hear what you are saying. But I contend that in the case of an http request, where, yes, a million things can go wrong, you actually do want to capture that in a type. And you DO want to be explicit with the type, at the very highest level. You don't need to annotate with every possible thing that can go wrong - you just need to achieve *totality* and close your types. sealed trait SomeError case class Error1(path: String, userId: Int) extends SomeError case class Error2(somethingElse: String) extends SomeError case class EverythingElse(e: Exception) extends SomeError Every possible error is captured here. It's basically just checked exceptions, but pushed into values we can compose and manipulate nicely. Can you perhaps give me an example of some gnarly code with lots of boilerplate?
The Department of Redundancy Department is redundant.
Would it be weird if I go there alone and if I do not know much about Scala ? I'm in Montreal so... It doesn't really say on the website if you have to be a scala guru or just scala-curious to addend the event.
Thank you for the info!
Unbelievable!
I classify all of that except implicit resolution as problems with the standard library and the challenge that any _highly orthogonal_ language presents in determining what combination of features to use when to solve your problem. You certainly can avoid them by using a _strictly less powerful_ language. But it remains a category error to conflate a questionable standard library and many different tools with which to solve your problem with a _complex language_.
The first rule of tautology club is the first rule of tautology club. 
I mean, it's in August. I have my "Programming in Scala - Second Edition" book right next to me. Didn't have the chance to read it yet. Now I got a good reason.
Starting with 2016.1 IntelliJ bundles a JRE with font patches on OS X and Linux. So there shouldn't be much difference anymore.
Variables mean to apply to the whole user session should be in ~/.profile or ~/.bash_profile.
Like always great job ;) 
Conference organizer here (so, I'm clearly biased :-)). Last year, we had many people new to Scala attending. Even if you can't fully grasp all talks, it is the best place to be to ask questions, talk to the speakers, and meet other people that are learning the language, just like you. You might be surprised how welcoming the community is. I can't tell you what level the presentations are going to be: we just opened our Call for Proposals, so not even us know it yet. But this year we learned our lesson and are asking in the CFP about the talk level: intro, intermediate, advanced. You will know what to expect before you go. If you register before May 20, you can vote on the talks that interest you the most. It is part of our philosophy to let the community select the talks they want to see. Finally, as it was already mentioned in another comment, looking at the [2015 talks](http://scalaupnorth.com/2015.html) can give you a good idea. In particular, [my talk](http://www.youtube.com/watch?v=V08s4AfVQY4&amp;list=PL-ziwLLJ3XaL1R3JkxxFn6psZQWZOIBJx&amp;index=5) (double bias! :-p) may motivate you to pick up that staircase book. I hope to see you there. Come say hi to us.
Lets tests it. https://www.diffchecker.com/zlrhfxsg
`.get` here is returning an `F[_]: Monad`, which is as safe as it gets.
That looks like a pretty impressive project, clearly you know what you're doing! Maybe reach out to some of the consultancies, like Cake Solutions. They're always looking for people with a strong command of the language. &gt; Also, there is a difference between how I talk to other people my age (on the internet) and how I talk to someone who is older. I don't know what your age is, but I'd just be aware that you're not necessarily only communicating with people your age, but you may well be communicating with people who know where entry-level gigs can be found. And even when it comes to people your age, you never know who might be insulted by careless choice of words.
I think this could be a great resource if done well, but there is a huge amount of subtlety involved so it will be challenging. You should probably read every post on the [Typelevel Blog](http://typelevel.org/blog), in particular Stephen Compall's serial novel about type members and type parameters starting [here](http://typelevel.org/blog/2015/07/13/type-members-parameters.html).
This is a hugely important fix for those of us who do functional programming with scalaz/Cats. The tl;dr is that the `Unapply` trick should now be unnecessary, and hacks like `.sequenceU` can go away.
People who'd like to play around with this can find a version of Scala 2.11.8 with this fix backported, an SBT project for experimentation, and instructions for use with their own projects [here](https://github.com/milessabin/si2712fix-demo).
No, none taken at all, thank you for this! I'd ideally like to take a slanted approach of this in a lenses of what I described above, contrasting some concepts against Java, but also keep this in mind that I'm going for basically "I already know how to program in Java, what can I practically get out of Scala" I think the question has been asked by Java people more than once what they can get out of Scala and it's type system from a pragmatic sense, and I'd like to give concrete examples of how it can do a lot of really powerful things for you. Hopefully that makes sense.
And I also figured that if this idea didn't pan out at least people would point me to some awesome existing sources and I'd just end up with some a lot of reading to do. :-) 
Our code base consists of ~250kloc of pure Scala. We are using Play, Akka, akka-streams, Slick, and scalaz, among others. When we moved from Java to Scala, 3 years ago, compile times drove us almost mad, although our code base was maybe only 10% of now. Today, I don't even have a conscious perception of Scala compile times anymore. I attribute this mostly to incremental compilation with zinc (and maybe that I slowly got used to it). But also a complete build on Jenkins takes only ~15mins (with zinc enabled).
I would love to see good guidance about the topic. I have seen most of the resources mentioned in the other comments but still can't quite get a hang of the more advanced topics. What I would prefer is a "clever ways to implement XYZ using scala's type system." instead of another list of features.
is that really supposed to be a *case* class ? I mean, is that going to be pattern matched ? Otherwise one can pretty easily go with a regular class with `val` fields.
Someone deep into the comments posted this gist as a mini-blog post explaining the fix with more examples: https://gist.github.com/djspiewak/7a81a395c461fd3a09a6941d4cd040f2
Thanks, this makes it very clear!
This makes me think maybe These should have a function of this type def mergeWith[T](f: (T, T) =&gt; T)(t: T \&amp;/ T): T Then this could be accomplished with a.align(b).map(mergeWith(f)) Without relying on the awkward fact that Options are in the collections hierarchy. It *almost* has it in merge, but that requires that f comes from T's Semigroup. Seems to me that merge should just call mergeWith. merge works perfectly for the linked SO question though since f is +
Getting proper support in intellij is good for the broader scala community.
This is not in contradiction to my comment. By the same logic, you could ask anyone on Twitter or Reddit or Gitter to up-vote any SCL issue. That doesn't make sense, nor does "nudging" JetBrains speed up the process.
That sounds great. Are you using the Web Audio API? I once started a similar project, but it's on halt now as I have no resources at the moment: https://github.com/Sciss/Cord - with the UGens loosely based on Pure Data and SuperCollider. Is your project Open Source?
I don't think it's horrible to "market" your ticket, if you think it's important. I didn't even know this was an actual problem. However, it doesn't affect me, and I think they'll get to it eventually.
That's not the same thing.
not my ticket. the important part is to reach people who are affected by it and don't know what they can do about it.
i'm not twisting anybody's arm here... and yes i could use other social media, not sure why you think i didn't. why wouldn't i use social media to attract attention to something i think is important/interesting? how is that different from posting links to GitHub projects you contribute to or articles/blogposts you like?
Scastie
why not just use `scala` itself? it has `:paste` mode that allows you to paste the code and execute it.
Hmm, but I want to share code easily, instead of having to copy paste multiple times when exchanging ideas on internet.
This is awesome, thanks for sharing this
It's not very pretty, but it does its job. I'm thinking about making a replacement that looks much better and more useful.
That's what Option[T].orElse is for. But that's doesn't solve the problem this post is attempting to solve.
It does, if you first flatmap the options to apply `f`: def reduce[T]( t1Opt: Option[T], t2Opt: Option[T], f: (T, T) =&gt; T): Option[T] = (for { t1 &lt;- t1Opt t2 &lt;- t2Opt } yield f(t1, t2)) orElse t1Opt orElse t2Opt
Check out /u/MasGui 's [Scala Kata](http://www.scalakata.com/)
Then don't be that guy. For one because many of us keep paying for licenses to IntelliJ IDEA only because of that Scala plugin. If the Scala plugin wouldn't exist, many of us wouldn't be Jetbrain's customers. And as paying customers, it's within our rights to ask for improvements to its Scala support. That's how a customer-vendor relationship works. If Jetbrains doesn't deliver, we might look for alternatives. And if we don't say anything, then they wouldn't get the feedback they need to improve their business and products. But then the other reason for why you shouldn't be that guy is because this kind of answer isn't helpful. It's not like anybody's going to start contributing now, just because of a condescending message on Reddit. And this particular project is a difficult one, after all we are talking about their own Scala compiler frontend. Those inclined to contribute are either already doing it, or are busy with other things. I could understand such a reply if the author was disrespectful to Jetbrains, because that's the only instance where this reply is acceptable.
Well, that's not what he wrote :). I find the `for-yield` approach less readable IMO.
I agree to vote up this tickets as a lot of people may not see this ticket however this is a good chance to let people know. As most people pay for the license and even more expensive for enterprise customers. I really hope Scala community could cooperate with jetbrains to make this much better just like Android studio.
A link for Scala highlighting issues is https://youtrack.jetbrains.com/issues/SCL?q=Subsystem%3A+%7BError+Highlighting%7D+state%3AOpen
There's also http://www.tutorialspoint.com/compile_scala_online.php
I interpreted it that way; how else would you use `orElse` to solve the problem? :-) And, I agree that in this case the for-comprehension isn't as readable as perhaps a `map2` might have been: `Option.map2(t1Opt, t2Opt)(f) orElse t1Opt orElse t2Opt`.
Why does it have to be associative? The merge definition doesn't seem to take advantage of associativity to me, but then again every non-associative function I think of seems silly to use with merge (subtraction, division). Maybe there's some intuition I'm missing. 
Type Projection and Type Lambdas...Or are those topics maybe out of scope for this? I can assure you, you would have at least one buyer if you were to write such a book.
Nope, I think they're something to add in, thanks for the suggestion! Also, anything I come up with would be totally free.
What are you so upset about? Why do trivial things turn so cantankerous so quickly on this sub?
As much as I understand the folks here who are put out by this, as someone who is affected by this and already voted on it prior to this Reddit topic, I'm kind of hoping it ups the priority of fixing this issue. Although, maybe it can be looked at from another direction. It could be that the real issue is that Akka HTTP's routing DSL (inherited from Spray) is too slick by half if the most advanced editor can't handle the most basic functionality of the DSL. On the bright side, the DSL gives us a very declarative, Ruby-esque way of designing a web service. But we get there through piles of implicits and extensive use of the magnet pattern. The result is that the IDE can't understand what's going on, type signatures are inscrutable, and when things are going wrong, the compiler's error messages are unhelpful. I'm a big Scala fan. But I'm starting to get discouraged by the complexity of things designed to look simple. Examples that come to mind are Akka HTTP, Akka Streams, Slick, Shapeless, and SBT. It feels like somewhere, the language is letting us down with the super-complicated patterns required to express simple APIs. And even worse, it seems each project exists in its own deep corner of the ecosystem. One would be forgiven for mistaking SBT, Akka Streams, and Slick code as being from different languages entirely. Of course, I do realize that much of this is due to the fact that Scala has been blazing a trail of proving that patterns expressible in dynamic languages can, in fact, be statically typed, and often with inference. Projects like these have been extremely impressive in this regard. But it also feels like people have convinced themselves that because the language has turned out to be capable of so much, that the core feature set doesn't need to be expanded, or that the tooling isn't in dire need of help. Take Shapeless, for example. It has largely smashed open the limits of dealing with TupleX and case classes. But without being more tightly built in to the system, when it goes badly, the errors I get are so obscure that I find myself ready to go back to the boilerplate I just scrapped. No disrespect intended to any of the people who put in unbelievable work on the compiler, the IDE tooling, or any of these great libraries. I realize that some of the progress is limited by compiler intricacies that the Dotty project aims to alleviate. But the frustration is real, especially as I try to get my organization more on board with Scala, evangelizing the strengths of the ecosystem.
The plugin is extremely straightforward to use. If there's any difficulty, it's usually because something is done wrong. 
https://github.com/JohnReedLOL/scala-trace-debug
How about [Jupyter Notebook](http://jupyter.org/) with Scala? There is [try it in your browser](https://try.jupyter.org/) option.
Why are people giving this the thumbs down? I think it's great.
It's the way that scalac renders PolyTypes ... this isn't something you'd normally see. It has been proposed as the textual representation for type lambdas if type lambdas ever became a first class language feature.
I'm new here.... Why wouldn't people just post questions in the sub? Or start discussion there?
Are you implying that, on my behest, people who are not affected by this issue will go through the trouble of voting for it, thereby artificially inflating its importance? Let me put your worries to rest, there's no way in hell any software developer will ever do something they don't feel like doing (nor do I expect them to) - I'm *not* a wizard, I don't hold that kind of sway over anybody... People who *do* vote for it, are the ones who would, in fact, like to see it fixed. Which is the whole point. I'll re-iterate my sentiment again, people who are affected by the issue I linked to have the option to vote on it. Obviously, I would certainly encourage other people to post links to issues *they* think are important. To, you know, push *those* issues up towards being fixed others. &gt; The votes are a signal as to what is important to users, and may help to prioritize fixes. Exactly. &gt; Why does this issue deserve to be fixed before those other tickets? I never said it's more important than other tickets. I'm not qualified to prioritize the whole ticket queue. &gt; it's valuable that people know that the bug tracker exists Yep, spreading that knowledge is the side-effect of the post.
&amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;I don't understand what is with the zero likes. I mean this thing is really convenient. No more hunting around for where you put your print statements. You can use it with a logger or with `println` to make it easier to __find__ your print statements (hence the method Log.__find__). &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;You can also use it to prove that a small program is correct by inserting inline assertions. You can disable these inline assertions with `Debug.fatalAssertOff_!` or `Debug.nonFatalAssertOff_!` . If you are using it in production, you can set the environmental variable `ENABLE_TRACE_DEBUG` to `false` and it should disable the assertions and get rid of all the output. If you insert calls to `.trace` or `.traceStdOut` inline throughout your code base, you can get rid of them in one click with Ctr-R (find and replace) `".trace"` with `""`. &amp;nbsp; &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp;With this library, I never feel the urge to use `System.err.println("foo: " + foo)` anymore. Instead I use `Debug.traceCode(foo)`. If the code is single threaded and I am worried about the overhead of getting a stack trace, I can do `println(Log.find(foo))` or `System.err.println(Log.find(foo))`. Bonus: I don't have to re-type the name of the variable in the print statement.
because you're spamming, you'd published like 3 post about the same thing in a few hours...
Probably because I've seen this posted a few times already. Certainly looks interesting but i don't seem to have the same pain point as you do (yet?) regarding debug statements.
sorry for the rude answer, your package is nice (I follow it on github) but you must not publish again and again the same tool on reddit expecting be aproved for the scala community, do your best and don't care what the other says.... 
ohhhhh
Yeah, I'm not 100% sure, but I think I'd be surprised by an outcome in which associativity _didn't_ hold, as you suggest.
Yeah. If you're ever confused about something, there is good Javadoc in the source code and you can just press Ctr-Space and scroll through all the available methods to read what pops up.
Well as an undergraduate student, I didn't get Logback in my projects. If I wanted Logback, I would have to copy-paste the entire Logback project into "Client-Server TCP Demo" and then zip it. [Scala Trace Debug](https://github.com/JohnReedLOL/scala-trace-debug) is the middle ground between System.out.println and Logback.
I very much like this idea! 
I think you may be squashing a few orthogonal concepts. Scala is still ultimately an object oriented language, in the sense of Java, where every value is an object and every operation is some object's method [1]. A function is nothing more than an `apply` method of an instance. Scala creates the concept of `FunctionN` interfaces to allow such values to be passed and returned, to implement higher-order functions. `def` and `val`, within the context of a `class`, `trait`, or `object` are two different ways of creating a method. `val` is for the special case of a method that takes no parameters and whose value is calculated and stored immutably at the time of instantiation. `def` can be used for methods with type and value parameters, and is not cached. I think the question you may be asking is whether it makes sense to use methods or functions stored in `val`s as the primary way of representing operations within an object. I'd say the answer is roughly that if the semantics of the operation are such that it is used as a method of the instance it belongs to, use method syntax. If it is intended as a function value, to be passed to another function, use function syntax. Note that these two things can be mixed together. You might have an object that has a method that produces functions. Basically a function factory. In this case, you'd probably use `def`, but the return type would be a function type (`=&gt;`). [1] Possibly except for `val` and `def` within a method's scope. Not sure how these are encoded.
Thanks, very nice to hear :)
Sorry
Yeah, it's pretty neat. Unfortunately, there is no `Option.map2` ... maybe the Scala standard library authors don't want to bloat it with applicative methods since they can also be done monadically. Of course, I couldn't resist doing it with scalaz: http://www.reddit.com/r/scala/comments/4f29ef/reducing_two_optionts_in_scala/d27buvq
Nice! Where is the Scala source code? I can only see some JavaScript and a compiled `lib/ScalaZen-assembly-1.0.jar`.
That being said, this isn't the same library it was. It used to be some piece of crap that no one would use because it didn't work with their logger. Now look at this: [Integration with logger 1](http://i.imgur.com/KijjzjD.png) ^ The `Log.find` method is designed to be used with a logger or with println. [Integration with logger 2](http://i.imgur.com/Ad5CaiI.png) ^ In addition, you can still use old methods with Logback, just disable output to standard out or standard error. It has an environment variable/compile option that should remove the calls to Log.find from the bytecode, so no overhead there, and you can still click to goto stuff in the logger. Plus it has the jar file name in the stack traces. 
golang for the win?
You should talk to Lightbend sales at https://www.lightbend.com/contact
Why not just post cost on website?
&gt; (basically using modules to force one-directional dependency between different layers of an application). sounds like you were intentionally making things hard on yourself--this is not a common android development pattern Also, one should never ever use apklib anymore, unless existing requirements demand it. Since you were using apklib, I assume that you don't want any library output at all, your build should have looked something like: val infrastructure = project.in(file(infrastructurePath)).settings(androidBuild).settings(libraryProject := true) val domain = project.in(file(domainPath)).androidBuildWith(infrastructure).settings(libraryProject := true) val views = project.in(file(viewPath)).settings(androidBuild).settings(libraryProject := true) val app = project.in(file(appPath)).androidBuildWith(domain, views) If you really did intend to publish aar artifacts, then it should have looked something like this: val infrastructure = project.in(file(infrastructurePath)).settings(androidBuildAar) val domain = project.in(file(domainPath)).androidBuildWith(infrastructure).settings(buildAar) val views = project.in(file(viewPath)).settings(androidBuildAar) val app = project.in(file(appPath)).androidBuildWith(domain, views) Editing views with the wysiwyg editor is useless, don't use it. (instead, tools like protify make developing resource files actually useful and straightforward) Debugging works fine however, create a run configuration that launches `android:package`, and do not run `Make`--it will build, install, run and launch the debugger automatically. Additionally, you can attach the debugger to an already-running process by using the "Attach Debugger to Android Process" command in IntelliJ (I have the keystroke rebound, you can find your keystroke for this command by using CMD-SHIFT-A/CTRL-SHIFT-A) For a while, any breakpoint that occurred on a lambda resulted in a crash, this was caused by JetBrains creating their new scala plugin with lambda-aware debugging, the bug has since been fixed (at least to some extent) [SCL-9575](https://youtrack.jetbrains.com/issue/SCL-9575)
I don't have a strictly-followed approach, but my guideline is if it can be implemented using only public members/methods of the class, make it a non-member function. If you want it to appear as a method for aesthetic/readability purposes, use an extension method via an implicit `AnyVal` class.
Is it OK to do macros without using quasiquotes? The type safety benefit doesn't seem worth it if the macro is simple.
Thank you for reply! Well, yeah. I am always hard on myself when it comes to my personal projects. (In job I usually follow established curriculum.) I will try your suggestions as soon as I can. Also I haven't heard about Protify before - I will surely give it a try. I think crashes might have been due to the bug you posted. I tried to debug right now and I connected successfully without crashes. Thanks again for your hard work!
The reason you don't have the same pain point is because you can actually locate your println statements. I can't locate anything. I can't locate where I parked. I have to do Ctr-F for all my println statements (sad, isn't it). With this I can actually locate everything.
&gt; make it a non-member function Where do you put it? Companion object, some other object?
I agree with katandkit. These are all partial solutions. Sure they work, but there are proven better ways. The REPL is terrible outside of simple one liners and super simply structure code. A gist is just static...great for sharing but not iterating on in progress code. Scala Kata is decent, but I hope he continues to improve it.
/u/tpolecat has been calling it 'bedazzling' and I quite like that. 
I watched the entire talk and it seems like SBT is the elephant in the room. Obviously SBT could be better, but the fundamental question of why anyone would use this instead of SBT is unanswered. Additionally, CBT has many drawbacks in comparison to SBT, and the new model (with no import/compatibility with SBT) means you have to create a new build for CBT, and the last thing I want to do is learn yet another build tool. So, are there any CBT experts that can present a compelling reason (preferably multiple reasons) to use CBT?
I can't tell you that our approach is best, but it works. All of our services have the ability to produce and consume events on our Kafka cluster. We have topics related to security (e.g. auth), ePHI (we handle healthcare data), notifications, and more. Each service gets to determine whether it listens to a topic. Kafka relies on Zookeeper, and that's (honestly) my least favorite part of this setup. Managing Zookeeper drives me nuts.
Working and working well are two different things. "Paste Mode" shouldn't be a "thing". Have you ever actually used a decent REPL like the one with Ruby, Erlang or Python? Scala has a ton of virtues but the REPL isn't one of them... edit: Also he's asking about something like "Go Playground". The REPL isn't that.
Use a typeclass.
do you think kafka may be an overkill for systems with not so many events? (on the other hand, a good event system would allow to have more events easily...) it seems that development cost is fairly low for adding new events/consumers right? what about the setup for kafka? is it a pain in the ass or was it simple?
The new Scaladoc does indeed look nice! Thanks for that. (Actually, I never really used the old one because it's so slow and strange. I might use the new one.)
Cool. Let me know when you're making releases then, or at least snapshots to Sonatype. 
I would always make it a method where possible. Constructors or if the object it "rightly" belongs on is third-party are the only cases where I'd go for a function instead.
Well there are a lot of things that just don't translate 1:1 so even if I tried to do something like that I'd end up with prolly 50% of the book not having equivalent Java code. I am coming up with it now and I wanted to partition the book by topic and then have parts for each topic that you could read or skip depending on how you feel about each part. Basically an outline: 1. Actual explanation of this concept and application all in Scala 2. If possible contrast to Java, if that helps 3. Performance or other pragmatic considerations And you can pretty much skip the things that don't suit you. I think #3 will focus more on pragmatic applications than performance, but I'm sure there are some performance caveats worth pointing out. How does that sound to you?
Can you give an example of a function that "rightly" belongs else where? Thanks!
Yes, that was absolutely the intent, Java is a second class citizen in this context. The reason behind this was because my co-workers were all java people, so I wanted to provide some resource to known topics to perhaps ease the learning curve.
I think a function usually belongs on its main argument. So e.g. if I'd defined a `MyTimeDelta` type and I wanted a function that added it to a joda `DateTime`, I'd say that method rightly belongs on the `DateTime`, so I'd probably make it a function rather than a method on `MyTimeDelta`. Does that make sense?
Hi there. This is Chris, the speaker. A few people felt the question why to use it instead of SBT was left unanswered. I am aiming for friendly co-existence of CBT and SBT. I tried to avoid direct confrontation in my talk in that spirit. I’ll try to explain what I like about CBT in comparison below. SBT is very powerful. It was a big step forward from the tools that existed before. SBT being the quasi standard in Scala-land gave us access to many useful plugins. My biggest pain using SBT on a daily basis is that it is not "simple". In my impression the causes lie in a number of things: * Multiple concepts of code depending on other code, rather than one unified one (libraryDependencies, .dependsOn, configurations). * A custom, complex task dependency graph, that is hard to work with because of it's "scopes", the monadic interface, a number of obscure operators &lt;+==, :=...., wiring errors only being detected during interpretation time (key X not found in scope Y) * Not using actual Scala, but a dialect (build.sbt) with some different rules * A magical way to create plugins * A custom shell with it's own rules and no good interop with other command line tools * A hard to understand implementation, that most people cannot contribute to CBT in contrast is much simpler * unifies all code dependency concepts into one, which simplifies so many things. * uses plain old methods as "tasks" and dependencies between them means just methods calling other methods. Customizing the graph works via methods overrides. And no need for a monad currently. * just allows build time dependencies with no need for a special “plugin” concept * works fast straight from your main shell and interops well with other tools (i.e. java -cp `cbt classpath`SomeMainClass) * has an easy implementation that even Scala beginners can contribute to This all pays off when learning and working with the tool. There may be advanced scenarios (which are unknown to me right now) that cannot be modelled with CBT’s model but could be with SBT’s more complex model. However, all of the projects I work on professionally and privately would be fine with simple model, so any tax for a more complex model means loss without gain. On top of all that CBT has a fast dependency resolver. SBT uses Apache Ivy, which we all know is pretty slow. SBT’s interactive shell has a startup time of several seconds, while CBT’s startup only takes a few hundred milliseconds. SBT’s startup time can force you to run multiple memory-hungry SBT instances at the same time for different projects. CBT runs one single instance in the background which you can connect to from multiple places. 
So let me get this straight: 1. Everything I can do in Java, I can do in Scala. 2. I can call Java code from Scala 3. I can create Scala objects from existing Java objects 4. Scala can be used in Java code (I haven't tried, don't know details). **So why would I ever use Java again?** Obviously if I need to work on existing code then fine, but other than that - why?
So far I have found only two reasons to have a `.java` file in a fresh Scala project, both rare. 1. Java's enums are different from Scala's and have their use cases, much of which can be replicated with other constructs like a sealed trait and case objects, but none of which result in the same byte code. 2. Disambiguating overloaded varargs calls. When calling into a Java class with methods like `foo()` and `foo(Object... args)`, the Scala compiler cannot tell the difference. My solution has been a small Java class with exactly the interface I need to call from Scala and let javac resolve the ambiguity.
There are many ways to "create your own monad." Some ways: 1. Free (or Coproducts of) 2. Monad Transformers 3. Write your own type F[A] and create an implicit Monad[F] yourself Free is the easiest to use imo and its uses are very general and therefore you can probably use it all the time. Runar's Reasonably Priced Monads talk is a good place to start learning about these. Monad Transformers allow you to nest monads cleanly. So if you ever find yourself using a Task[Option[A]] and having to nest for-yields, reach for OptionT, for example. Rolling your own is pretty uncommon in my experience, but it does happen. Basically, start thinking of a monad F[A] as an "A within F" or some other metaphor and you end up being able to leverage that. Often, a hand-rolled monad is at least partially inspired by other monads. For example, I've written a hand-rolled one that was a combination of reader and either, but with more custom types. Rolling my own was a bit less annoying than using transformers in that case.
If you're looking for JS code you won't see it. You're supposed to use Scala that will eventually compile to JS. It's a good idea to port the Three.js examples, it might take a while as the library is still under development.
When first learning Monads, I found http://blog.sigfpe.com/2007/04/trivial-monad.html to be quite helpful.
For those willing to read Haskell notation, please take a look at the brilliant and definitive monad tutorial by Phil Wadler: http://homepages.inf.ed.ac.uk/wadler/papers/marktoberdorf/baastad.pdf EDIT: Note that the "Monads are Monoids ..." explanation on the blog is not strictly correct, see my comment on the site. IMHO, this is actually quite a technical way to explain monads, the Phil Wadler paper should be easier. 
I've found two good reasons to: 1) You notice you can reuse an existing library method to make your code simpler. This takes experience, but sometimes you write six lines and then realise "hang on, that's just `traverseM`". 1a) If you have two similar methods in your code, look to factor out the commonality. Often the interface ends up being `Monad` or a related one. I gave an example at http://m50d.github.io/2013/01/16/generic-contexts.html 1b) If you want to use `for`/`yield` with your type at all, you might as well implement `Monad` rather than doing it directly - it's not any more work, and it's more reusable. 2) You notice some implicit statefulness or awkwardness around an API you've defined or are using. You can then use a monad to encapsulate/isolate the badness. In this case I'd look to tpolecat's tiny-world. 
What's a good workflow and filestruct for using Scala and SBT on a text editor and terminal? I've tried IntelliJ and Eclipse for building Scala apps for Spark, but it feels too heavy for me. I keep reading about these Scala devs who use something like Sublime/Vim/Atom and just a terminal to get the ball rolling. How is this done?
I suspect scalaz-stream/fs2 may help, but I don't understand your use case well enough to know. Can you explain what you're doing in plain Scala (no specs2, no guice)?
Lagom needs you to purchase a 'Lightbend Reactive Subscription' for production?
We say "enrich" at my shop.
Blog has very very little content. Basically nothing worth reading. It is about how codacy.com saves them time. For a better use of your 5 minutes, just go to codacy.com and read about it yourself ;) Seems cool, especially the scala support - not sure why such a dull blog.
Thanks! Helped a lot
This is just an ad. Get this junk off of here.
It could be abused, sure, but it would actually be pretty handy for JVM/Scala.js work.
This is awesome! I've been looking for a good aether alternative for a while now and this looks like it'll get the job done right!
How does this compare and contrast to using Java interop and [Resource Bundles](http://docs.oracle.com/javase/tutorial/i18n/resbundle/propfile.html)?
4th technically. They had .NET support for a little while.
Version 0.3 was released just now. It brings scala.js compatibility - so KS compiler can be used on a web page, compiled as a JavaScript library. Example page coming soon. Aside from that, lots of minor fixes, introduction of `process:` over user datatypes and `process: rol/ror` for circular shift transformations.
I hope it will be able to compile Java code as well so that we don't have to implement everything in Scala again
Called it (sort of =) ): https://www.reddit.com/r/golang/comments/4fmt7l/akka_actors_for_go_a_learning_go_experiment/d2a6q7u
And a talk about it at scala days New York (11th may). Only 20 days left. Looking forward to the video of the talk.
I'm creating a dockerfile at the moment and want to validate the file downloads. Oracle provides sha256 checksums for the java downloads, is there something like that for scala as well (md5, sha256, gpg, whatever)? Couldn't find anything on the download page for scala. [1] At the moment I download the archive manually, run it through sha256sum and copy &amp; paste the checksum into the file. Would prefer if the checksum was provided on the page when a new version is uploaded. [1] http://www.scala-lang.org/download/2.11.8.html
Cool. What's the plan for providing the libraries?
I haven't done the backwards trip, but I can only imagine I would thoroughly hate it. :(
&gt; and curse myself as I drown in boilerplate. Take into consideration the lack of a proper type system and the horrific architectures. &gt; Has anyone taken a job that has forced them to regress to java? Yes. &gt; What was it like? Terrible. I needed to live with a poorly designed architecture and the enterprise fizz-buzz. At the land of java everything is an Object - Object str = "..." is a common thing among the java people. They totally ignore typesafety and everything you like in Scala.
1. What does JIT have to do with ARC? 2. Why do you suspect that LLVM might use JIT?
It's got a website, it must be something serious! /s
There are projects already that can compile Java code to native, so I guess the question just becomes, how well does either solution interop with other native code? Worst case scenario is you just have to use SOA. 
Fair enough, just saying this will be the 4th platform they've attempted.
Your statement about type safety is not true amongst good developers. But extreme boilerplate (deserialization is tough, so lets use FooList instead of List&lt;Foo&gt;, and don't worry, we can use a code generator!) and horrific architectures (lets just wrap some service in a"proxy" class to use as a dumping ground for anything related to the service because there's too much boilerplate, and too little flexibility to make proper abstractions!) are painful. I have a great job doing really cool big things, but the brain drain that is design in Java has me looking for greater opportunities. 
~~ARC~~ ART is basically an install-time compiler, whereas a JIT is a runtime compiler. Security restrictions on iOS prevent a program from executing code from writable memory, ruling out use of a JIT. Generating code at install time could provide an avenue around that restriction. LLVM provides built in JIT functionality. In fact, Firefox uses LLVM for its fourth tier (longest compile time, fastest performance) JavaScript JIT. Given the strong type system of Scala, I expect Scala Native to stick with a traditional ahead-of-time compiler but something like ~~ARC~~ ART would be cool! Edit: Wow. Somehow confused ARC with ART on Android! Now I'm just answering a question no one asked.
I don't have any specific resources to point out, except that idiomatic Scala code tends to be allocation heavy (transformations of immutable objects instead of mutating stuff in place). Outside of that, what has been written for the JVM applies. There is support in Scala for [fast, generic arithmetic](https://github.com/non/spire). Specialization is only available in Scala code, but [has a few quirks](http://axel22.github.io/2013/11/03/specialization-quirks.html). Actually, I'm writing a [computation group theory library](http://github.com/denisrosset/alasc) in Scala. I found that the clarity brought by the type system allows me to write complex algorithms more easily than in Python or plain Java. I can also experiment with performance hacks and the robustness of the resulting code is backed by property checking (ScalaCheck is a godsend).
Apparently, with the gettext approach, you don't have to create an id for each text needed to be translated. Just write the text in English (or whatever your language is) and the proper text is going to be the "key" to identify the text. I rather like the gettext approach. 
Of course Rust is designed as a native language. But it has completely different trade-offs compared to Scala. You pay a lot of complexity and productivity for not needing a GC. It's also certainly not a cleaner language. Don't take me wrong, it's great that Rust exists and I use it were I really need it ... but damn, this thing is freaking complex. The lack of clean syntax, and not fixing the things that Scala fixed a long time ago adds on top of that. Rust is great but it has a completely different, much smaller niche compared to Scala.
I sometimes write Java because I'm adopting an existing Java library and I don't have enough time or it simply doesn't make sense to completely transition it to Scala. I can observe a few things - It's somehow annoying. You have to write a lot of boiler plate, all the niceties of Scala's runtime library are gone too. - But the IDE (IntelliJ) eases that a lot, by providing a lot of auto inspections and code folding - There are two types of Java code bases: Some that are very clean and easy to understand, probably easier than a Scala project by some random other person. And those that are hopelessly messed up, because of the Java way of thinking - Compile times are a breeze. Yeah, that's something we miss in Scala. So for contained libraries, I think it's ok to write in Java occasionally, but I wouldn't want to write any larger application with it. Every time I visit an old Java code base of mine, I get shivers.
All Scala-only projects should be possible to compile directly to binary. In theory at least.
Before my current job I worked a few years with scala. Some people think that scala is 'just less typing' but that's completely wrong. Scala allows you to model your programs significantly better leading to less errors and easier maintainability. The things I miss the most: * type inference * declarative generics * easy immutability by default: 'val', case classes, the scala library &amp; everything is an expression * pattern matching * sealed traits * language consistency (declare a method in a method, import anywhere, ...) Currently I use Xtend witch gives me halve of the above back. I would love to go back to scala but the circumstances don't allow it.
Granted, I didn't make myself very clear. There needs to be some form of compatibility layer that's common between the various Scala platforms. Scala.js for example reimplements a JSExecutionContext to work with futures in a javascript setting: https://github.com/scala-js/scala-js/blob/master/library/src/main/scala/scala/scalajs/concurrent/JSExecutionContext.scala Scala Native will have to provide something similar for a bunch of features to work, but it's up to that project to do so. Third party sources should be possible to recompile as long as they don't depend directly on Java-features. Maybe that's what you were saying all along :)
You might look at shapeless [coproducts](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#coproducts-and-discriminated-unions), which are equivalent to nested `Either`s but are much easier to use. You could then say type AnyError = LoginFailure :+: PostMessageFailure :+: ... :+: CNil 
Yes please, can we also use LLVM instead of the JVM for "regular" Scala apps.
Having started scala before java8 was released I was pretty sure id never go back however as of late ive found myself getting very involved in refreshing alot of my companies internal java modules/libs and updating them to use some of the more useful aspects of java8 where they apply and honestly its starting to grow on me again.
I haven't gone back to to a full Java project, and lament projects with mixed sources.
Dur. I confused ARC with ART on Android, which includes an install-time compiler.
Not fixing the things that scala fixed a long time ago? Like nulls? Like an actual syntax for typeclasses + sum / product types, instead of an idiom? Like a package manager that doesn't frighten newbies away? I'm not saying it's a perfect language, but there are definitely things about it that are cleaner than scala.
You can use scalaz's ValidationNel, if you can convert all your Errors to a common type (String often makes a lot of sense). The downside compared to /u/tpolecat s solution is that you'll loose type information of the error, unless you wrap it in a sealed trait.
Thanks, exactly what I wanted. :)
&gt; The lack of clean syntax, and not fixing the things that Scala fixed a long time ago adds on top of that. What things did Rust not fix that Scala fixed a long time ago? 
I'm not sure tbh - I think akka has no built in concept of this, but I might be wrong.
I strongly question that String is an acceptable super type.
While Akka doesn't have a native built in concept, a cluster is able to send messages to its neighbors. Im seeing that its possible to add such roles to actors and have a mediator actor handle the scheduling here from the inputs of other actors. 
&gt; Your statement about type safety is not true amongst good developers. Well, I've heard stories about good java developers...(ignore my ignorance). Java isn't a typesafe language you won't be able to reach the level of typesafety on average what we can achieve with Scala.
I worked on a Java project for a little while in between full-time Scala jobs. It was brutal, but I did get used to it and hated it less as the months wore on. I did write a little wrapper for java.util.List that added methods like the ones in the Scala collections lib, backed by the Java8 Stream API. That alone allowed me to trim the size of the codebase by 10kloc (25%), but it was a slog. You'll encounter cleanly organized Java codebases, and I think those would be "ok", especially with Java 8. But those are the exception, in my experience. In general, people do more of what the language makes easy, and less of what it makes hard. In Java, this means lots of mutable vars munged within loops within loops within conditionals. Sure, someone *could* have done it differently, but it was easier to go with the flow. TLDR: Java is soul-destroying. Don't take the Java job unless you feel *really* good about the codebase and the team. See if you can sign an NDA and look at the code before you accept the offer!
Without shapeless you're reduced to `Either[A, Either[B, Either[C, ...` or something shapeless-like that you build yourself.
You could create a case class that is built up as you add configs, then use a delimiter (maybe '-') then define the delimiter in the case class to copy the class with the new value? Does that make any sense? It would make your DSL look like: GET - "/users/" - myController - myHandler You would just need to make sure there are no same type arguments to the DSL.
I don't really know the rationale. I'd be inclined to just post questions any way you want - it's not like there's *tons* of activity here - though the mods might get pissy.
So GET would be a case object, or just some object with a &amp; method, essentially a fluent interface?
I was thinking it would be a constant of the case class that represents the Route. See the code I posted as a reply.
 The question is what did Rust introduced what Scala would need? Manual memory management? Ouch... Or the c++ish [operator overloading](https://doc.rust-lang.org/book/operators-and-overloading.html)? Yaayy... Or the ... what?
&gt; Like an actual syntax for typeclasses So much use of typeclasses without HKT... The language uses it like an average abstraction in OOP. &gt; + sum / product types, instead of an idiom? I don't remember rust having such things. &gt; Like a package manager that doesn't frighten newbies away? It does frightened me - cargo and the rust crates were absurd from the beginning.
The obvious advantage of Rust is higher performance and more low-level control. Rust's trait system is more powerful than Scala's, though other features give Scala a more advanced type system in general. /u/leroy_junkins is right that the problem domains of the two languages are mostly non-overlapping; I was just curious what specific problems he felt Rust left unsolved. 
There are the managed scripting languages, like PHP, Ruby, Perl, and Python, which have no JIT. If we're talking about managed AOT assembly compiled languages, the most popular ones are Swift, Haskell, Go, OCaml, and D.
The new implementation of Ruby is YARV which uses an interpreted internal bytecode, not a JIT. However, it does not write to executable memory at runtime, which is why JITs don't work on iOS. That's why Ruby works on iOS (see RubyMotion). Go allows fairly low level memory management, since the unsafe module allows you to do horrible things with pointers. It has less to do with the language semantics and more to do with the tradeoffs that language designers prefer. Usually, languages that are compiled to assembly ahead of time are intended to be closer to the metal, so they eschew managed memory.
What's an ugly URL, and why not just implement a new URL scheme?
It basically takes your `trait` name appended to your package name. I don't find that particularly attractive. 
very true.
Well it does vary per instance. The result of adding deepens on the two things you add. So if I could put it on the `DateTime` then I would. But since I can't, I probably would put it on that companion object. 
&gt; The ability to use pointers directly opens up a number of optimization opportunities that are simply not possible in Scala. Most of the time the VM SHOULD optimize your app, optimizing manually won't really give you anything in reality. &gt; Scala uses objects, which are less memory efficient than structs. Rust apps(like Servo) eats memory like a crazy(like the JVM) - I don't think it's that efficient. &gt; Many of the advanced features of it's collection library come with performance tradeoffs, whereas Rust always chooses performance over convenience. So basically - Rust is C++. I would like to see a performance comparison of Rust's and Scala's collections. &gt; Rust's traits can encode most uses of typeclasses... Yet, the devs have ignored the abstract hierarchy of collections - and of everything in the standard lib. That's why I thought I won't give more chance for Rust - it's uncomfortable at creating web, util and client apps. If the zero-overhead architecture and memory safety are the only things then what makes Rust better than [Nim](http://nim-lang.org/) for development of low-level applications? But whatever, I can't wait for Scala native... &gt; Implicits do enable more powerful functionality but they also come with an enormous complexity cost I hear it often but I've failed to see that "complexity" in practice - can you tell me your experience about it? &gt; Associated Items solve the majority of use cases and full support for higher-kinded types is planned for the future. Like planned for version 100.0? They're planning it for years and still nothing - this feature should be in the core of the language because of its large impact on library design. 
&gt; Yet, the devs have ignored the abstract hierarchy of collections - and of everything in the standard lib. That's only half true. Rust doesn't use any kind of typeclass hierarchy like haskell or scala+(shapeless or cats), but there is still a lot of generic code in Rust's standard library, such as the traits in `std::iter`. &gt; I hear it often but I've failed to see that "complexity" in practice - can you tell me your experience about it? In my experience, implicits are hard to understand and hard to teach other developers. Errors caused by implicits can be hard to track down because they sometimes appear far away from their true source. They complicate function signatures and make code harder to read without context (in a code review, for example) because they are, by their very nature, not explicit. Just last week, I lost two hours tracing down a runtime exception caused by initialization order of implicit variables (execution contexts and the like). Of course, implicits also enable many of the powerful APIs that make Scala awesome. &gt; So basically - Rust is C++. And everyone knows that C++ is the fastest language when push comes to shove. I'm not saying that Rust is better than Scala, just faster. For many (most?) problem domains, the tradeoffs Rust and C++ make for performance are not worth it. 
This is only half true, bordering on false. Heavy async IO will have much better memory profile than using native threads if all you are doing is waiting on "events" (i.e. waiting on a database transaction, waiting on a http call, waiting on session cache etc etc). If you are actually doing CPU bound calculations, then threads have much better performance. Async IO in rust was less flexible because it doesn't have as strong of a type system as Scala, so its painful for the same reasons that Async IO is painful in C++. But if all of your webapp is doing is listening to events from network requests (and is doing minimal CPU calculations), then you are going to find that you are going to blow a huge amount of memory if you use the one thread per request model
no macros ?
Thanks. This is what I went for.
Why do you care? It's not a part of your public, visible api, right? It's just there for the code to use. It's like caring how .class files are named inside a .jar.
Wrap them in your own types until Dotty: type SomeUnion = Int | String // not valid Scala becomes sealed trait SomeUnion case class IntMember(value: Int) extends SomeUnion case class StringMember(value: String) extends SomeUnion 
If the pay is good, the people smart, the project interesting, java 8 is... tolerable. 
Thanks! 
Rust's syntax is the worst part of the language by a long shot. I endure it for native performance with good tooling and traits. Can't agree on underscores, though, the consistency "argument" has been proven to be nonsense. It's certainly better than Scala using underscore to mean half a dozen different things depending on context.
I think lihaoyi was making a joke
Recently released http://udash.io provides typesafe RPC with Jetty and Scala.js out of the box. Definitely worth a look. The dev guide's part for RPC lives here: http://guide.udash.io/#/rpc
If you don't want to change your members to add them to your unions use something like coproducts from shapeless https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#coproducts-and-discriminated-unions
The [RFC](https://github.com/aturon/rfcs/blob/remove-runtime/active/0000-remove-runtime.md) for removing green threads details the problems that motivated the change. I recall benchmarks from the discussion at the time, but haven't gone searching for them now.
I just bought it today... geee... Thankfully, amazon is okay for a refund.
Perhaps you can get a special discount on the new eBook if you show them your receipt.
Good post. I like the discussion about algebraic structures and free objects. Some parts of your post were hard to follow because of the weird Scala pseudo syntax / notation you use. As an example the notation for `nat` felt weird to me at first. I would love to hear more on this posts' topics ;)
Looks good
For public APIs I personally always handwrite them. You don't want them suddenly to change, because the generator lib got updated or anything 😃
As Calavoow mentioned, this is not the functional approach. The two types you need are Product types (in Scala, the closest is like tuples or case classes) and Sum types (in Scala, the closest is like sealed traits). It you want to hold multiple fields in a single object, then you want a Product type (a single type that accommodates all combinations of those fields). For example (this is like a ‘named tuple’): case class Node(name: String, map: Map[String,_]) If your map values are ‘either string or map’ then you want a Sum type (a single type that accommodates all strings and all maps): sealed trait MapValue case class Str(value: String) extends MapValue case class Submap(value: Map[String,MapValue]) extends MapValue val myMap: Map[String,MapValue] = Map("a" -&gt; Str("aa"), "b" -&gt; Submap(Map("c" -&gt; Str("cc")))) scala&gt; myMap("a") MapValue = Str(aa) scala&gt; myMap("b") MapValue = Submap(Map(c -&gt; Str(cc))) You use pattern matching to extract the values (`x match { case Str(s) =&gt; ...; case Submap(...) =&gt; ... }`).
&gt; highly-requested syntax improvements Requested by whom? I have never seen a consensus that the language should have trailing commas, for example. I think the [fork by Paul Phillips](https://github.com/paulp/policy) has them because he loves them. I am undecided whether it's a good idea or not. Thousands-separators and binary literals could be done using [string interpolation](https://stackoverflow.com/questions/31275887/underscores-in-numeric-literals-in-scala). For example, Spire is providing literals for all of these, [rational numbers, binary and hex numbers, thousands-separated ints and longs](https://github.com/non/spire#syntax): import spire.syntax.literals._ import spire.syntax.literals.si._ i"1 944 234 123" // Int x2"10111" // binary Scala 2.12 cleans up the syntax by removing procedure syntax and view bounds.
&gt; Quick what's `10000000`. It's `1e7.toInt`. &gt; So frustrating for such an easy fix. Trailing commas are not a fix but a matter of taste and therefore not unambiguously a feature everyone would like. Also: val b = 1 :: 2 :: 3 :: Nil :)
Agreed I haven't seen a consensus on trailing commas either... but it does pop up on message boards from time to time. I'm in Paul's camp in that regard... not having them is an almost daily annoyance; it makes rearranging / adding to list defs very irritating. Underscores/binary literals are already supported in Java so they should be in scala as well imo. I forgot about Spire tbh... I've even used it in the past. It seems like a pretty big dependency to pull into a project just to have basic number literals... Good to know about procedure syntax. Views are gone entirely? Is there a replacement or just "don't do that sort of thing anymore"?
... wow yes 1e7.toInt is clearly a solution. How about 7465184531. And your second "example" doesn't work for anything other than a list. Thanks for your amazing contribution to the discussion.
Not sure I understand what you are referring to with "selected 3 zeros"... Also we must do pretty different types of programming if you never use numbers besides "benchmarks". &gt; Are you reading data structures from string No? I constantly have seqs defined all over my codebases... Is this not a common thing? Seems pretty necessary to me.
Not a regular problem for you maybe. Just because you don't use something doesn't mean it isn't a problem for other people. &gt; What makes Seq(1, 2, 3,) more readable than Seq(1, 2, 3)? Nothing... the problem isn't with one-liner data structures it's when you have multiple lines. As shown in my example. I pretty clearly explained when it's an issue.
&gt; So why would I ever use Java again? &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; Because Scala is hard. In school I learned C++. Going from OOP in C++ to OOP in Java was like a 6 week transition. That same transition would have been like 6 months to Scala. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; It's not just the concepts. The syntax can be confusing too. Like the irregularities in the whitespace syntax (i.e. `object function param` compiles but `object function param function` does not). Or the irregularities where if a variable ends in "\_?" or "\_!" you can't put it next to a ":" without a whitespace, but if it doesn't you can. Or the way that `def function1 = function2` doesn't create an alias, it creates an extra layer of function call. The fact that category theory books are hard to read. The way Scala programmers are often very terse - short variable names plus short code (with no Javadoc) plus syntactically sugared super abstract generics. The horrifyingly long generic function signatures in method declarations. The fact that people can't Google symbols and symbols often don't come with a Javadoc. &amp;nbsp;&amp;nbsp;&amp;nbsp;&amp;nbsp; If you find yourself in a situation where your team doesn't know any Scala and you have a lot of shit that needs to get written now, you might just use Java.
&gt; Not a regular problem for you maybe. Just because you don't use something doesn't mean it isn't a problem for other people. Look, I'm really trying to understand your problem. &gt; You literally cannot think of a single scenario when this is useful? val a = Seq( 1, 2, 3 ) val b = Seq( 1, 2, 3, ) Which one is easier to add a new element to? Too simple? Okay now merge them. Like this: val c = Seq ( Seq(1, 2, 3), Seq(4, 5, 6) ) or: val d = Seq ( Seq(Seq(1, 2), Set(3, 4), Seq(Seq(5, 6), Seq(7, 8)) ) vs val d = Seq ( Seq(Seq(1, 2, ), Set(3, 4, ), Seq(Seq(5, 6, ), Seq(7, 8, ), ) ) 
I think they're in direct competition here, intended or not. The languages are pretty similar and have very similar use cases. 
The result might vary, but the function doesn't.
Hi, I've published a first beta : https://github.com/scala-hamsters/hamsters
If you control the definition of the types you want a sum of, then absolutely, the sealed trait hierarchy is the shortest path, and there's nothing wrong with it. I was responding to the question about an "ad-hoc" sum type, presumably meaning given some set of types not forming a subtype hierarchy. Then, in Scala, you have no choice but to use some encoding of sum types, and sure, those encodings are relatively heavyweight. As an OCaml developer preferentially—and my Haskell-using colleagues feel the same, of course—Scala's lack of sum types and polymorphic functions is a common complaint. But we don't always have the luxury of controlling the types we want to sum, so here we are.
We have a huge java code base &amp; we use some frameworks like EMF that aren't scala friendly anyway. Mixing scala &amp; java files in a single module isn't practical, with xtend it's a piece of cake. Rewriting an entire module in scala is an unnecessary risk, xtend allows us to convert our existing java codebase very gradually. We don't touch working java code until it needs a fix, then we convert to xtend. 
&gt; The languages are pretty similar Except they aren't. Haskell is a language that heavily enforces referentially transparent purely functional programming where as Scala is a language that tries to blend modularity OOP principles with functional programming. There is a group of people that definitely use Scala like a Haskell on the JVM, but that isn't the intent or design of the language.
Ah that make sense, I was thinking about some sorts of `interface` to do this, but `case class` makes sense.
Thanks that is an awesome technique. In general is it safe to always use `case class` over `trait` for data constructing?
The author is dead, so to speak; languages compete in the field of what they're used for, not on what they were intended for.
That was tongue in cheek. I know Guillaume is a power user :) But I maintain, discussing macros in that book wouldn't make the slightest sense.
[Yes](https://github.com/milessabin/shapeless/blob/shapeless-2.3.0/core/src/main/scala/shapeless/coproduct.scala#L84). More generally, [yes](http://milessabin.com/blog/2015/05/27/shapeless-2.2.0/), since version 2.2.0.
&gt; Per my quote of your comment, why does the Scala "equivalent" using sealed trait Shape with case class ... children not conform to sum (discriminated union) types? Because the subtypes of the sealed trait are not disjoint: they're subtypes of the sealed trait. :-) So this is an encoding of sum types with subtypes. And again, it has the serious-in-practice limitation that you have to be able to define that hierarchy of types all in one place. Many times—most times—I need a sum of types I _didn't_ declare and that absolutely _do not_ have a subtype relationship of any kind. A good example is case classes generated from XSDs by scalaxb. More generally, sealed trait hierarchies do not have a categorically dual relationship with `Product`. Now, as with so many things, [with Shapeless it hardly matters](https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.1.0). Note that the table there was as of version 2.1.0; the current version is 2.3.0. &gt; Enumerations: types defined by giving the possible values directly Famously, no, witness the effort put into [encoding alternatives](https://beachape.com/blog/2015/02/11/enumeratum-sealed-trait-enums-for-scala/). &gt; Union Types: enumerated types which carry additional data with each value Union types are sum types, so again, no. They show up in Dotty, though.
Okay, didn't know of such details.
Then maybe you have a third reason :). For me, if all I needed as a single utility file I'd probably re-implement it in Scala. If I needed it again, I'd copy the Scala version. If I needed it yet again, I'd make a library out of it. If I needed multiple files I'd probably make a library straight away, especially if there was any interaction among the files. I guess I interpreted the question as more "when do you need to do something in Java" vs "when would it be convenient to have Java". I categorize copy/paste into the convenience bucket and not the necessary bucket.
I mean sure, it works. But if I saw that in somebody's code base I would nope right out of there.
Yeah his reply as a whole is interesting but his response to commas is pretty terse: "Probably won't fly.". Wonder why it's such a bad thing to him.
Also discussed in scala-debate: https://groups.google.com/d/msg/scala-debate/4-CE9Lpf6CM/UJrhS9cyYcgJ As was mentioned there, the SIP process is the way to do these things. And (my opinion), somebody who cares about the feature probably needs to drive it. &gt; We will discuss this in the next SIP meeting mid July Did this happen? (btw since the literal syntax can be pulled in by libraries, I don't see a burning need for them, e.g. scodec).
&gt; I now have 2 places I need to go find and fix because the last item in each list didn't have commas in them. Yes this example is a little contrived but I seriously run into this problem all the time. Oh, in that case Ctrl+V and , . I've never ran into this problem. But you can bring it to the compiler enthusiasts it won't make harm for us at any way.
Collections views are due for a replacement as well. It looked for a while like jsuereth's [viewducers](https://github.com/jsuereth/viewducers) was going to be the new implementation, but now a revamp of views may be folded into a larger reimplementation of the whole collection library.
No, the language needs none of these features, and I'm pretty sure no one is asking for them besides you.
 You might want to check [scage](https://github.com/dunnololda/scage) first, it wraps phys2d, lwjgl and slick2d.
Sorry if I didn't frame it right. Actually, I found out you can use libgdx with Scala
I wish I had known that Spire had those, I implemented them on my own a bit ago. It was nice to learn a bit more about macros, but not what I would call a fun experience.
&gt; I think it's good as is. You bring up this problem every week while it's mostly just a wildcard character... &amp;nbsp;&amp;nbsp;&amp;nbsp; I would still much rather see `list map (* 2)` &gt; The problem is that if you can't understand such a simple language(yes it is) like Scala then you are not a good programmer and you should go editing html files instead. &amp;nbsp;&amp;nbsp;&amp;nbsp; Define simple. If you mean like a tree (like lisp) and without "special characters", then Scala is simple. But that's not how your average person defines simple. To me simple is clean/intuitive. A = B, B = C, A = C. Simple. That being said, it takes more than "good programmers" - there are also good testers, good marketers, good planners, good library writers, etc. etc. And you might think that you're better than someone who just does art, but if you need art and you can't do art yourself, all the code in the world isn't going to make your art. &gt; Then look it up again because such low level optimizations are so unimportant. &amp;nbsp;&amp;nbsp;&amp;nbsp; It's not about the optimization. Languages are made for users, not for compiler devs. It's not about what is the most obvious thing from the point of view of the compiler. Lisp is probably more intuitive for the compiler but C is more intuitive for the person. &gt; And there are a thousands of monad tutorials out there. &amp;nbsp;&amp;nbsp;&amp;nbsp; There's more to category theory than monads and Scalaz is kind of old. If I'm going to try an FP library it's probably going to be cats. Seriously, that book is hard reading. &gt; These operators are so simple... What do you think: what can "+=" do? Or "++="? Any why would you use google for functions? It isn't haskell - go to the scaladocs after you read the intro/tutorial/manual. &amp;nbsp;&amp;nbsp;&amp;nbsp; This is a crappy argument. 1. lots of symbols like ~= and &gt;= aren't obvious, 2. people copy-paste things into Google and the appropriate Javadoc pops up, 3. half the symbols in sbt have a Scaladoc and the other half don't. &gt; def traceContents[A](coll: Iterable[A])(implicit tag: WeakTypeTag[A]) &amp;nbsp;&amp;nbsp;&amp;nbsp; This forces the user to extract the Iterable from the array/list/map/etc instead of just passing it into the print statement as is. Not going to fly. &gt; If you're going to put such nonsense scaladoc in your code your manager will kick you out. It's trash. &amp;nbsp;&amp;nbsp;&amp;nbsp; Not if you want users to use your library as a substitute for System.out.println and you target users are... everyone. &gt; I use implicits daily and I use libraries with implicits and I don't care about their location. &amp;nbsp;&amp;nbsp;&amp;nbsp; You will when you bump up the version number on Play framework and get "Implicit Not Found" in like 30 different places. &gt; If I could choose between a 5-member-half-happy-java team and a 2-member-Scala team I would choose the latter. &amp;nbsp;&amp;nbsp;&amp;nbsp; I have been in this situation and I ended up writing all the code along with one other person and I ended up producing an inferior project in the end (when put against a smoothly running team of 5). It's more than just writing code fast. You need good graphics and marketers and dev-ops and testers and loads of other things to make something good. So no, I would choose the smoothly running team of 5 doing a minimum viable product to present to a room full of people rather than the team of 2, even if the team of 2 can write code faster. &amp;nbsp;&amp;nbsp;&amp;nbsp; That attitude isn't going to get you anywhere. If there is anything that I have learned, it is that it takes more than one person to build a pyramid. 
Scala tries to be minimal for a functional object oriented language, you can write macros to add to the language. Think of Scala as machine code and extend the language yourself. 
Hi I'm thinking about this exact issue. Unfortunately this thread was not of much help. Java seems really daunting though -- as they say it is really verbose. It's been a month since your post. What did you decide in the end?
&gt;The typical and majority of Scala code in existence is very different to typical Haskell code. Citation? A lot of prominent libraries are quite Haskell-like, as are many of the large private codebases I've seen. (I mean they don't look like research paper Haskell, but I don't think most Haskell does either). &gt;They may compete in regards to their demographic (which is backend services), but then you could argue that Scala-native is competing with Go... I think that is true as far as it goes. But it's easy to make the case for why you'd want to use Scala-native rather than Go. It's much harder to show a compelling advantage over Haskell. 
It's not complete but a work in progress. Should handle nested objects too
cats-master : 1,8M hamsters-master : 92K I tried to make validation easier to read and to understand for beginners, and it relies on scala standard types like Either (no applicative, no cartesian syntax |@| ... ) . I think monad transformers are easier to understand too. I don't think there are some HLists in cats, so I'll compare with Shapeless for this one, and my implementation is way simpler than Shapeless HLists (so less powerfull too but not aimed at the same public).
My initial goal was to provide something useful to my team with validation, some simple monad transformers, and simple hlists. I've made a presentation of Cats and it was too complex for many FP beginners. If there is a patch that implies that structures become more complex, for example if you need to understand applicatives, coproducts etc. to use it, I will refuse it.
- For models and controllers, Slick is the recommended way for Scala, therefore a Slick models generator would be fine. - I'll keep an eye on it
https://github.com/slick/play-slick-codegen but, as you maybe thought already, it isn't maintained :), but everything used there still exists (slick-codegen), just the generated code would have to get updated. Since play is unopinionated, this can't live inside the framework itself, but a good maintained template would be nice I guess
Let's be honest, they are quite opinionated ... Slick is the de facto standard and therefore they should create a stable generator (inb4: but the Spring team got no generators, why do we have to make one ) 
Sounds like R. I've decided to go with Java, for legacy reasons. (If I was completely free to choose I would probably go with Scala as well.) So far Java is proving to be every bit as "verbose" as promised...
It's very possible to e.g. just use Validation from ScalaZ and ignore the rest of the library. Likewise just using HList from Shapeless. So that really doesn't seem like a compelling use case. Could you give some examples of what makes just using the equivalent parts from Cats too complex? &gt;If there is a patch that implies that structures become more complex, for example if you need to understand applicatives, coproducts etc. to use it, I will refuse it. As a potential contributor, you need a much clearer policy than "what I think makes it complex" - I don't want to put work into a patch if I can't be confident whether it will be accepted. Particularly since your views will likely change over time. I've seen a lot of people go down this path, and then in a few months they realise that all the complexity was there for a reason and they've just recreated ScalaZ. I count myself in that number too. 
IMHO, the fact that ScalaMock invokes the mocked ("super") class constructor makes it all but useless.
I wouldn't - I use vim sometimes but if you're happy in an IDE stick with that. You can navigate fast in vim but most of the time a mouse is fast enough, and the modal-ness of vim-style editing adds overhead. 
1. I don't really care enough about it, but `_` is basically the worst symbol to pick. 2. Eh? It was a deliberate decision to drop 100% Java compatibility in favor of simplicity and consistency. I'm not sure how this argument is still alive. 3. "the norm of dozens of programming languages" ... can you mention at least _one_ dozen of them, please? It's a pointless syntactic variation because now people can write code _with_ trailing commas and _without_. Sorry, I think I have enough existing code style/consistency problems to worry about.
&gt;In toPrintOutNullable: A, there is no space and in useStdOut_? : Boolean there is a space. That is because if you have _? or _! you have to add a space or it won't compile. Yeah, don't do that then. I think Java just disallows punctuation in identifiers entirely though, so it's not like you'd write that in Java. I agree that allowing such names is a flaw in Scala, but it's easy to work around by not doing it. &gt;won't compile if you factor out the closure like so: It will work if you use your tool to do the refactoring. You're right that this is non-ideal, but no-one knows how to do good type inference in the presence of subtyping, and it's hard to provide a migration path for most ordinary programmers without subtyping. &gt;the underscore can be confusing for people It can be. I find it much clearer than groovy's magic "it" or Haskell's magic "". And I think the conciseness is worth it - in Python or JavaScript writing `lambda x: x` or `function(x){` I really miss `_`. If your team agrees you could just always use `x=&gt;x` instead if you think that's clearer. &gt;Not to mention that there are 15 or so uses for underscore. But they all intuitively mean the same thing. &gt;You can't actually learn what the syntax means without also being exposed to concepts best practices. That being said, the syntax leaves a lot of room for bad practices so you really have to know what you are doing. Ideally I think that a programming language should be as intuitive and idiot proof as possible and Scala sacrifices a lot of that in exchange for more use cases. This would be fine if teachers in school spent six months teaching Scala syntax and examples so that Scala syntax was the norm, but they don't so you have to learn it on your own. Examples? The Scala syntax really is very simple (unlike e.g. Java where it's very hard to know where braces are optional and where they aren't). Whenever I've heard someone complain about the language syntax it turns out they really meant library semantics. &gt;Not for me it doesn't. I have a macro based stack trace handling library and I can't just factor out helper methods in places because if I use method assignment it adds an extra level of stack trace. Stack traces are meant to be a debugging tool. I would absolutely want that method in your example to show up in a stack trace, because otherwise how would I figure out wtf was calling the inner method when debugging? &gt;But if my team is using scalaz and/or cats now I need to read the book Category Theory by Steve Awodey If your teammates are writing code you can't understand, step up your code review practices. Frankly though I find that category theory is never necessary. Like, I guess category theory would maybe tell me what a Kleisli is, but I can figure out what it does by seeing it in use, no different from a Factory or a Widget or a Controller or any other library concept. &gt; ScalaTest and sbt Are awful and I would avoid them in favour of JUnit and Maven. That's not a reason not to use Scala though. Likewise even if you don't think implicits are worth it, you can just not use them and write Java-style code - the language does offer that possibility. 
Fact that last release was issued 1,5 year ago and last commit was made 1 year ago makes me feel suspicious about it. Also I'm fairly happy with specs2+mockito (it doesn't feel javaish at all). However, it'd be really nice to use macro-based lib instead of reflections-based. I hope some one will bring it back to mainstream soon.
&gt; Scala 2.12 cleans up the syntax by removing procedure syntax What's the source for this? http://www.scala-lang.org/news/2.12.0-M4/ doesn't mention it
i know for a fact that i need to pass in the type, and getRemoteValidator needs to set a type, but im not too familiar with doing this, do you have any examples perhaps?
&gt; This forces the user to extract the Iterable from the array/list/map/etc instead of just passing it into the print statement as is. Not going to fly. You're consfusing **Iterable** and **Iterator** : [sample](http://ideone.com/v4Nfq5). I thought a master like you would know such a mortal thing... &gt; I would still much rather see list map (* 2) I think /u/m50d and the rest of the community thinks [otherwise](https://www.reddit.com/r/scala/comments/4fbiqr/weekly_scala_ask_anything_and_discussion_thread/d2gh4sj). &gt; Define simple. If you mean like a tree (like lisp) and without "special characters", then Scala is simple. But that's not how your average person defines simple. To me simple is clean/intuitive. A = B, B = C, A = C. Simple. That being said, it takes more than "good programmers" - there are also good testers, good marketers, good planners, good library writers, etc. etc. And you might think that you're better than someone who just does art, but if you need art and you can't do art yourself, all the code in the world isn't going to make your art. Too sophisticated... &gt; It's not about the optimization. Languages are made for users, not for compiler devs. It's not about what is the most obvious thing from the point of view of the compiler. Lisp is probably more intuitive for the compiler but C is more intuitive for the person. If you don't know about something then read the SPECIFICATION and don't complain in public right away. &gt; There's more to category theory than monads and Scalaz is kind of old. If I'm going to try an FP library it's probably going to be cats. Seriously, that book is hard reading. scalaz maybe hard but not old... Anyway, read eed3si9n's tutorial, it teaches you more than just monads. &gt; This is a crappy argument. 1. lots of symbols like ~= and &gt;= aren't obvious, 2. people copy-paste things into Google and the appropriate Javadoc pops up, 3. half the symbols in sbt have a Scaladoc and the other half don't. What? From when does "&gt;=" isn't obvious? Have you missed elementary or what? "people copy-paste things into Google and the appropriate Javadoc pops up" - nobody stops you from copy paste. If a library developer choose to use an operator - he/she will introduce it. If you don't like it then go back to pascal. &gt; Not if you want users to use your library as a substitute for System.out.println and you target users are... everyone. We use "println" as a substitute for System.out.println. If I want to debug I'll use intellij's built-in debugger, if I want to log then then there is scala-logging or it I want to print something there is println. What does your library solve at all? &gt; You will when you bump up the version number on Play framework and get "Implicit Not Found" in like 30 different places. I bet you're copy-pasting code from everywhere without knowing what you write. I've used many play! versions and upgraded often but I've never seen such thing. &gt; I have been in this situation and I ended up writing all the code along with one other person and I ended up producing an inferior project in the end (when put against a smoothly running team of 5). It's more than just writing code fast. You need good graphics and marketers and dev-ops and testers and loads of other things to make something good. So no, I would choose the smoothly running team of 5 doing a minimum viable product to present to a room full of people rather than the team of 2, even if the team of 2 can write code faster. Sophistics again - why would the java team run smoothly? Do you know how many obsolete tools are in usage by only java devs? Do you know how awful code they write on the average? Do you know how hard is it to maintain an XXXLoC java-crap? Graphics and marketers - we were talking about a dev team with 2 scala and 3 java devs. Yet you're talking about the min viable product and fast code writing - you should know that scala is about writing valid and maintainable code and not about delivering thrash before deadline. &gt; That attitude isn't going to get you anywhere. If there is anything that I have learned, it is that it takes more than one person to build a pyramid. I've told you a few months ago - if you don't know something then retreat and learn scala silently instead of fooling around and complaining.
Great, ivy drives me nuts somethimes!
One way to make it really outstanding would be to support Scala.js. As a macro-based thing, it should be possible. A number of projects would choose it over any alternative if only for that reason.
This is awesome. Great job @MasGui
Thanks! It was harder than I tough. I was thinking of using Google's realtime api, but building your own is more fun!
There are *a lot* of CSV parsing libraries, one is bound to do what you want. The most likely candidate is [Delimited](https://github.com/tixxit/delimited): &gt; Delimited supports streaming parsing. You feed in chunks of data and it'll give you the rows as they are able to be parsed. If not, you can have a look at: * Java: Jackson CSV, open csv, univocity * Scala: kantan.csv, PureCSV, product-collections I'm the author of [kantan.csv](https://github.com/nrinaudo/kantan.csv) and I wish I could tell you it'll solve your issue, but it doesn't do partial rows - it'll let you treat CSV data as an iterator on values (lists, case classes, whatever you need), and you can go through the stream one row at a time, but it'll not stop in the middle of a row.
I am using akka streams since it has nice back pressure to make sure not too many things are in memory at one time. Might be worth a look.
You don't really need a whole cluster. You can run spark locally on your machine.
I took a position with java after using scala for a while. After a year, I am back in scala after teaching the team what we can do with it.
Cool, Delimited looks like it'll do exactly what I want -- thanks! &gt; kantan Yeah, that was one of the ones I looked at today, actually.
Glad to help, although bear in mind that Delimited is relatively obscure and I haven't yet had the time to add it to my benchmarks - no idea how it performs or how tolerant it is. For some reason I'm assuming it's really good, but I have nothing to back that feeling up. Cool that you stumbled on kantan.csv, would love some feedback if you have any!
&gt; it's very easy to put them in dropbox and get to a new machine and have your workspace 'set up' in a matter of minutes. &amp;nbsp;&amp;nbsp;&amp;nbsp; I do this too, lol. Netbeans allows you to place your project outside the projects directory, so I put my entire project in the /Netbeans folder and then when I need to use another computer I just turn it open and *bam* everything is there. Oh wait, you're talking about your vim settings. &gt; If your'e new(ish) to scala. &amp;nbsp;&amp;nbsp;&amp;nbsp; I started programming in Scala in September and now it's April. So no, I am pretty comfortable with Scala, lol. I have never lived without an IDE before though, lol. &amp;nbsp;&amp;nbsp;&amp;nbsp; I hate non-IDE text editors. I make so many typos and spelling mistakes without my IDE that I spend twice as much time fixing compile error typos than actually writing code (I actually glance at my keyboard while typing and only type with six fingers so having Ctr-Space is a lifesaver). &amp;nbsp;&amp;nbsp;&amp;nbsp; I was kinda just hoping that the vim plugin would prevent me from accidentally typing whitespace while perusing through the files because it has seperate modes for editing and not editing. &amp;nbsp;&amp;nbsp;&amp;nbsp; You know, the way I got into Scala was very funny. I got sick of typing the "final" keyword in Java and heard that in Scala I don't have to type "final String" I can just write "val" and I just made the language shift because of that, lol. I later found out about Monads and Functors and Applicatives and SBT and ScalaTest and Play and Reactive programming and Akka and Spark and was just like "this is way way way more than I bargained for... Oh well." &amp;nbsp;&amp;nbsp;&amp;nbsp; If I need to take my customization with me I think I'll just zip my entire IDE folder and put it on a thumb drive or in Dropbox. 
The design of the language itself is a lot more pragmatic than Scala, it also has a much larger ecosystem (Scala piggybacked of Java in the early days, which allowed it to develop more Scala only solutions which we have been seeing in the past couple of years, which will be easily transferrable to Scala native). Scala-native will also (hopefully) adhere to the same ABI compatibility that Scala-JVM will, which means it will have sane binary compatibility for its libraries, something that Haskell will never happen (being a "research language", it pretty breaks binary compatibility on every GHC release) There are other things as well, Scala right now is trying to simplify and reduce the library to make it easier to work with, where as Haskell is adding type extensions on GHC every year or so Honestly I could write 2 pages of this stuff, but there are a lot of differences between Scala and Haskell, it doesn't just boil down to "how well can Scala support pure FP"
Do write it if you get the chance - not in this little side thread, but a post about "reasons for Scala over Haskell" or the like would be interesting. I've met very few people who were using Scala for any other reason than the JVM support / migration path.
&gt; What does your library solve at all? [Scala Trace Debug](https://github.com/JohnReedLOL/scala-trace-debug) puts a clickable file location and line number on every print statement and you can jump forward and backward through the locations of each of your print/log statements in the source code, giving you a clear idea as to the overall execution of your program with almost zero runtime overhead. IMHO it is awesome for getting a feel for the execution of your code and it should be used all over.
&gt; My tool? How do you move out a closure into a separate variable with IntelliJ? Can you not just do "extract local" on it? &gt; For example I just saw Odersky do a course where in the example code he did "_()" - underscore followed by braces. I did not know you could do that. That's just using the ordinary `_` and the ordinary `()`, no? The syntax doesn't have that many special cases - most of the time you can mash any two features together and they'll do what you'd expect. &gt; I saw someone define a Monad from scratch and use for-yield syntactic sugar. I did not know I could do that. `for`/`yield` is slightly magic (very much worth it though). But directly comparable to Java's `for (ET element: container)`. &gt; I saw you do list map (2.*). I had no idea I could do that. `*` is just the ordinary `*` method on `2`. The call is just ordinary passing a function to `map`. Again, syntactically it's very simple and consistent. (If anything I suspect you got confused because the syntax is simpler than you were expecting - `*` isn't anything special (mumble precedence mumble), it's just an ordinary method with a funny-looking name, and `2` is just an object, so you can use it exactly like any other method). &gt; WHAT. I JUST SPENT SO MUCH TIME MASTERING THOSE TWO THINGS AND NOW I HAVE TO LEARN JUNIT AND MAVEN. Eh. That's just, like, my opinion, the wider community seems to disagree with me - certainly use what you'd like. But those are the things you'd use in Java anyway, so if that's the comparison you're making then it's (or it can be) the same. &gt; I was expecting to have to learn Maven because the Apache spark project is using maven but I thought ScalaTest was like the most intuitive thing since sliced bread. Fair enough. If you like it then stick with it. I find ScalaTest horribly, horribly confusing to read or reason about - I think it does far too many over-clever things and gets very little value out of doing so - but maybe that's just me.
&amp;nbsp;&amp;nbsp;&amp;nbsp; You know, the way you talk reminds me a lot of the guy who wrote the Lift framework. In a bad way. The fact of the matter is that out in the real world, a good deal of what is written is stuff that might never materialize for reasons other than the quality of the code and thus isn't worth beefing up to handle insane amounts of scaling and refactoring and modification. Scala kind of has the "high end" code market, but it falls behind in the "we need people to get this shit done on a budget now" market. A a good deal of the code that is written (minimum viable products, demos, transient web apps, startups, etc) just aren't the best place for Scala. &amp;nbsp;&amp;nbsp;&amp;nbsp; If I were doing a startup that might not materialize and I was on a tight deadline with a low budget, I wouldn't hire Scala developers. I mean I learned Scala and I think I'll use it for other things like data analytics and infrastructure stuff, but Scala isn't best in all cases. I wouldn't call it a complaint - more of an observation. 
Awesome! I want to build some scala/js client/server platform as well in the future. This is a nice reference, thanks!
 A few months ago you told us you've a team and such. Later it turned out you're 22 and unemployed. After you've deleted your troll account you came back to harass people (but without cursing, at least). Mate, just sit down and learn Scala on your own. Don't spam this sub. We don't need the your old-school bureaucratic java enterprisy views neither. It doesn't work. And if you don't think that Scala is good at high level apps - then just leave it alone. Sure, the haskell community won't accept you neither after your trolling there(too). Try the golang community - you'll just need to write excuses about the lack of generics...
Why would you want to mock a concrete type (here: class) instead of an abstract one (like, you know, a trait)?
You can use [fs2](https://github.com/functional-streams-for-scala/fs2) to not only parse your csv, but also process your transformation in a stream as well.
Also recommend Spark for this. Great csv parsing, automatic parallelization, etc. 
True, but I get shivers every time I look at old code, regardless of language. Even though your skills build over time, everyone else's do too, which gives the false impression that you're standing still. Only when you look at your old code do you realize how much you've improved.
Im looking to better understand `Akka Streams` along with `Reactive Kafka`. I posted an [SO](http://stackoverflow.com/questions/36851959/reactive-kafka-not-printing-messages) pertaining to using both, hoping someone more knowledgable than I am can help out. 
To mock 3rd party dependencies one has no control over? Bear in mind traits can have constructors, too: scala&gt; trait A { println("I'm trait") } defined trait A scala&gt; class B extends A defined class B scala&gt; new B I'm trait res0: B = B@60dc1a4e
What makes you think slick is the defacto standard?
The practice I've seen was having traits (without constructor side-effects) that your code depends on, with adapter classes implementing them in terms of the third party API. Makes me wonder whether ScalaMock supports structural types though.
Or use Mockito and not worry about maintaining all such boilerplate only to circumvent limitations in the mocking framework? Honestly, I really wanted to love ScalaMock. I tried. But with its current limitations, ScalaMock is pretty much broken for most of my real-world use cases.
Action.async ?
Well, I'd be doing that irrespective of the mocking library (assuming the project needs one at all - and not all do). It avoids direct coupling with a third party API.
It's not like it was a one-off that only happened to me - I was there for six months or more. Morris was consistently rude to a lot of people and never apologised (not that there's any way you can to an anonymous IRC participant who will probably not come back, but a couple of times people called him on it and he always brushed them off). Fundamentally there is something broken at the organisational level for him to still be allowed on the channel. And it spoils the whole culture - by the time I left a couple of other people were doing the aggressive socratic method thing - though I think it is overwhelmingly just him. 
Not a lot of thats, a lot of Succs and one that at the end. Peano numbers are defined recursively, e.g. 2 is S (S (Z)) and 3 is S (S (S (Z))). So 3 + 2 is calculated as S (S(S (Z))) + S (S (Z)) = S (S (S (Z) + S (S (Z))) = S (S (S (Z) + S (S (Z)))) = S (S (S (Z + S (S (Z))))) = S (S (S (S (S (Z))))). Which is the representation of 5.
&gt; That's by design - they have different semantics. Yeah I know, it was not a criticism. Hamsters validation is not a validation in the same way. It's far less powerful, but more adapted for beginners. It' just "you have a few Either, you want to retrieve all errors and all successes without doing a list + a collect + a map on the right/left projection each time". In fact it's more an helper, not a full validation subset. &gt; I have issues with both ScalaZ and Typelevel and would love to have a third option to build Paperdoll I'm afraid you could be disappointed. I'm not targeting the same public as Scalaz and cats. Hamsters goal is to begin with simple helpers to manipulate a few concepts that are not covered by std lib, then I think people would switch to cats/shapeless/... when they're more familiar with this concepts. So Hamsters will never be powerful enough for someone who needs Scalaz. &gt; at a minimum, Unapply, Leibniz and MonadPlus I think it's a bit beyond Hamsters scope, BUT, I've made a repo for this kind of stuff : [hamsters-extensions](https://github.com/scala-hamsters/hamsters-extensions) The first pull request I have received was out of scope (monad transformers relying on Twitter futures API) so I've asked the author to put it here. An extension can have a dependency on Hamsters, so you can use its core and add as many things as you want. For this extensions I have not policy at all, so you can add everything you want! I hope it helps... and I would very happy to host a paperdoll extension! Anyway, thanks for your interest :)
Templates: I'll go through the templates and I'll mark a few as outdated by the end of the week. Scaffolding: Case classes are all the same no matter what kind of DB layer we use, Forms are always the same ... Look at this: activator g form:User id:Long name:option:String email:option:String That would create the userForm and also the case class. The same goes for controllers: activator g controller:UsersController:scala Ok here we just create the controller and nothing else, the user can do what ever he/she wants to do with that, we don't make any assumptions. activator g controller:UsersController method:index method:update This one would just create the controller and probably something like: def index(): Action { Todo } Again we don't force the user into something ... for Java it's the same. public Result index() { return TODO; } I don't see a CRUD generator for Anorm working, since we interact with plain SQL statements, we really can remove Anorm from our list. I have to admit that I now understand your position and it's quite difficult to make scaffolding for Play but as described above there are options for the things that all technologies got in common. (forms, controllers) &gt; Play tries to make the right decisions where it can, and it gets out of the way where it can't. Implementing scaffolding would be both risky and essentially irreversible. It's better done outside of core. Totally the more I think about it, the more I'm convinced that I only blame the creaters of Slick and no one else. I'll create Anorm DAOs with ease, Ebean and JPA are easy as well but Slick is a fucking nightmare. 
You can use `Action.async`, create and store a `Promise` by id, return its `Future`. Then when the response comes back, fulfill the `Promise`. Pseudocode: // In the controller Action.async { val promise = Promise[MyResultType]() val requestId = submitRequestToServer() putRequestIdForLater(requestId, promise) promise.future } // In the queue consumer def consume(response) = { val promise = getRequestPromise(response.requestId) promise.success(response.value) } 
This sounds like a job for websockets for client-server communication, not something you'd want to do in a request-respond way.
You only need a minimal knowledge of java, but it's easier with LibGdx https://libgdx.badlogicgames.com/
I'm not sure whether this is what /u/paultypes meant by disjoint, but one practical annoyance is that the case classes each have their own type. So if you try to do e.g. `myOption.fold (Child1())(Child2 (_))` it can't infer the right type and you get an error unless you specify it explicitly. The scalaxb example is: scalaxb generates classes based on an XML DTD. So if you were working with SVG it would generate classes for Rect, Circle, Line and so on. But if you then want to pass a "circle or line" around in your code, the classes were autogenerated so there's no way to "retrofit" a CircleOrLine trait and have Circle and Line extend it.
You can do all of those in a macro. They do not need to be in the language, since they only bloat the core language. Also, all of these are related to literals, they are not that important in writing software, it's very rare that you really need to have a literal saying 13466881346, or editing list. Besides, having a trailing comma is NOT important at all. You can just put it on the beginning of the line, if that's so painful to you. oh, and for example in js, trailing commas are forbidden, it's just that most implementations are more tolerant.
Hmm, without making it Applicative you can't offer anything generic, so all this Validation really is is the helper methods (which are just `separate(l)._1` and `_2`) and a load of aliases. If I were going down that path I'd rather just define `lefts` and `rights` functions statically somewhere - I don't think proliferating names by encouraging people to use different names for Left and Right is a good thing at all. I'm also not convinced that's a good way of handling validation of lists - you lose the ordering. What do the use cases look like? I can understand extension projects for external dependencies, but all the things I listed are pure Scala and general-purpose. The right thing is for paperdoll to depend on a project that implements those. And while it's your project, to my eyes they would all fit (certainly it would seem very odd to say the project includes Monad and Monoid but not MonadPlus, for example). So please do try to come up with a clear policy if you can. 
yup: https://github.com/MasseGuillaume/ScalaKata2/issues/35
Thanks for the feedback. At the beggining I was just using Right and Left in my examples but some people seemed to find it confusing : in right/left you have no idea of what side is meant to be good or bad if you don't know the convention. The use is the the example of the README.md file. The project does not include Monad and Monoid either :) As I'm only using std lib containers (Option, Either, Future), I don't need to define monad, monoid types and so on. The more we're talking about it, the more I think hasmters is not what you're looking for. It's really targeting people who don't know what an applicative or a free monad is. Maybe my next project will be closer to your expectations :) But I think Cats is really what you need... 
I get 'access denied' for all of the images... Broken in Firefox, works in Chrome, though.
Yeah, I was reaching a similar conclusion. I'd still advise you to come up with a clear policy though. To my mind everything in Cats is a natural result of ordinary good engineering practice. E.g. List is not an efficient type to use in a lot of real-world code, so your Validation code should really support Vector. To avoid repeating yourself there you'd need a concept of Foldable. Likewise with the monad transformers, if you have a concept of Monad then you can write them generically rather than having to repeat the code for every possible combination.
You can use an object instead of a package to achieve more-or-less the same thing. 
Agreed, thanks for the advices!
When only working and worrying about the application logic then it is pretty unimpressive.. It's just an RPC plug gable mechanism. However if you're task in your organization is to make sure everything AROUND that application code is solid then Finagle is pretty hard to beat. Things like distributed tracing, routing based on logical path ("/s/user" could go to staging or production but the app doesn't know), ability to kill a portion of the request and retry if it's hitting the SLA boundaries, etc. The finagle documentation isn't the greatest at selling itself but the benefits to the infrastructure portion of your organization is amazing. 
Have an upvote.
TIL about Http4s. Looks very unopinionated.
So if I declare my method like: def logIntoMyWebsite(driver: RemoteWebDriver, username: String, password: String) { ... } Then I could pass a `ChromeDriver` or an `HtmlUnitDriver` to that method? It seems like some of the methods I'm calling seem to not work when passing an `HtmlUnitDriver` when using my original method declaration 
What is scage exactly?
I [did](https://github.com/gelisam/ludum-dare-33#readme), but I haven't tried libGDX/mini2dx. The project seemed a bit immature at the time, as I had to email the author about a few undocumented bits. I've since modified the [wiki](https://github.com/dunnololda/scage/wiki/Scage-methods-overview) to share that information.
[a game engine written in Scala](https://github.com/dunnololda/scage)
final schedule is up
Of course there is: Reducing the layers of indirection 😉
&gt; 5) Where is the best place to ask questions like these? The mailing lists? http://scala-lang.org/community/#mailing-lists
&gt; Do you use the play forms for the validation? I assume you're referring to the Mapping interfaces and the request parsers. Yes, they're quite helpful, so that we don't have to go nuts with Jackson (or similar). We also use extra Constraints for total form validation required in special cases (i.e. a validation dependent on field `a` and field `b`). The Mappings work well against our domain Case Classes. &gt; And do you have any tips/recommendation to use Swagger with Play? Swagger is a sad project. NPM and Node land are cool, but pretty much every implementation out there you see where Swagger is used to professionally document an API has notable tweakings to the code to make things appear correctly, work with your given auth frameworks/ACL, etc. We had to do just that. Add to that, the `swagger-ui` and `swagger-editor` projects are completely separate. Sure, http://editor.swagger.io looks cool, but that's not what you'll get when you host your own docs. Add also that various complex parsing and object/form layouts are not supported by Swagger (spec or UI), meaning that certain things simply cannot be specified, or done via the interactive docs, because of defects in the Swagger Spec which are listed as "Wont-Fix" (based on circular logic that it's not in the spec, so why add it?). Another note on Swagger, you cannot break your spec into multiple files with include statements, and you can't make template objects (i.e. like generics) so you'll wind up with a 10K line JSON spec eventually. I use `jq` to check it locally, and then fire up `swagger-editor` locally to confirm it looks good and validates. A real pain is that swagger-editor is crazy slow while running on my maxed out MPB, with startup usually taking 6min.
Can you share if you find your answers? 
&gt; Do write it if you get the chance I just moved halfway across the world, so it won't be anytime soon, but If I do find some spare time I will try it out This is somewhat related http://blog.scalar-conf.com/post/143419902425/scalar-2016-whiteboard-voting-results &gt; I've met very few people who were using Scala for any other reason than the JVM support / migration path. Its probably due to where you work/bubble syndrome (which isn't unlikely, it happens). If you honestly want a language that is Haskell on the JVM, then there is frege
It's a shame about ScalaIDE usage. Even if IntelliJ is really great (my own experience has been decidedly mixed), we really need meaningful competition in the IDE space to drive progress.
Sounds like you're almost entirely IO-bound, am I right? Latency and throughput are clear enough, are you willing to sacrifice scalability to hit your targets? Also, database or no database?
The simple answer is Promise: create one, return the associated Future in your response, complete the Promise when you get the signalled from the processing server. It takes a bit more to connect the bits and pieces obviously, as a Promise created inside a controller won't be available in the same context as you handle the other server's response. Off the top of my head, you could create an Actor for each request that comes in. Have the actor create the Promise and do the call to the processing server, passing the Actor's unique name so that it can be looked up when the task is completed. The processing server will have to pass the UUID back along with the result. Bear in mind that there may be several layers of HTTP-servers (apache/nginx/reverse proxies etc.) in the architecture that may terminate a HTTP connection after a preconfigured delay. This will close the response but it won't clean up Actor instances automatically. You will want to schedule some form of timeout in order to terminate the Actor and fail the Promise if the processing takes longer than expected or you'll create a memory leak. --- If your scenario is very asynchronous by nature it may not make sense to keep a HTTP connection open. Rather, you can signal to the caller that the process has been started by responding directly with a 202: ACCEPTED. In this scenario you pass the responsibility of actually getting at the result to the caller.
The code is from the course's presentation. The course's code is I feel is clearer because I think using child classes in the parent class isn't a good coding pattern. EDIT: ~~Is putting child classes in the parent something done often in functional programming?~~ a later lecture says this is a style decision and should be decided based on whether you find yourself adding more class or more methods into each class
Here is the official Scala schedule: https://github.com/scala/scala/milestones 2.12.0-M5 Due by May 27, 2016 2.12.0-RC1 Due by June 30, 2016 
I used scalatra for a project and liked it quite a bit. I was a little unhappy with the use of Any here and there, but otherwise it was a good experience.
I think you've got it? If we write 2 for S (S (Z)) then S (2) + 2 is (just by the definition in the code) new S (2 + 2 ), and it recurses down. Another way to think about it is that Peano arithmetic represents numbers as the length of lists - the data structure is very similar to a linked list, with Z = nil and S = cons (the only difference is cons contains an actual list element). The code for + is very similar to the code for appending to a linked list.
Show the actual code that isn't compiling (ideally as a standalone buildable file on Scastie or similar). I suspect you have a RemoteValidator [A] which you're trying to pass a Widget to when it needs an A.
&gt; There are some auto-generators out there: All outdated and unmaintained but I'll have a look at alvin alexanders tool. &gt; and there's more examples in Play in Practice, the book I'm writing about doing useful things with Play: Got it, waiting for chapter 6 thanks !
You can only mix in traits at the class level. This is what you're currently doing with `class MyClass extends FlatSpec with ShouldMatchers with HtmlUnit`.
Hmm, I'm not sure how to properly explain this so please bear with me. The application is not particularly IO bound. I would say it is more memory/computation bound. You can think of it as an application that receives some events from an external source and has to do some processing. The processing itself might consist of aggregation of data from other sources and applying some filters/transforms/etc to it and then making o decision based on the result. Now depending on the events and the "state of the world" the application will have to decide what to do and how to do it (it basically generates a series of commands for some other component that executes them). What we would like to do is to maximize the number of events handled in parallel. And minimize the time elapsed from receiving an event to the moment when we send the commands. I was looking for something along the lines of "use value classes to avoid unnecessary allocations" and "avoid transformations on lists (where possible) because they are strict and each step creates a new object". We don't have a database per-se, but do have a kind of event-store as in the event sourcing examples. Excuse me for being unable to give you more specific details.
No, that's plenty of detail - or at least enough to let me know that I'm not going to be a ton of help to you. My experience with Scala almost entirely involves IO-bound applications, so most of my optimization knowledge is based around that. &gt;I was looking for something along the lines of "use value classes to avoid unnecessary allocations" and "avoid transformations on lists (where possible) because they are strict and each step creates a new object". Value classes are probably a good idea in your case, though I'm not so sure about avoiding collection operations - Scala implements [persistent data structures](https://en.wikipedia.org/wiki/Persistent_data_structure) which take a lot of the allocation cost out of immutable collections. If you want to, you can even make any Scala collection non-strict (but call-by-name, not call-by-need) by calling "view" on it and then return to a strict representation with "force". In the end, though, most of what I have to offer here is stuff you probably already know. "Profile, profile, profile", use parallelism when appropriate (check out the parallel collections library and ScalaZ.Task), remember [Scala's super-annoying Stream hygiene rules](http://blog.dmitryleskov.com/programming/scala/stream-hygiene-i-avoiding-memory-leaks/), and profile. ;) As I said, not my domain. But if you end up discovering some good rules of thumb around this stuff, PM me if you still remember. I'm curious about how to achieve the other kind of performance in Scala, even if it's unrelated to my day-to-day.
Im having a really hard time learning akka. Can someone suggest their favorite book for doing so for beginner? Ive been between [Learning Akka](http://www.amazon.com/Learning-Akka-Jason-Goodwin/dp/1784393002/ref=sr_1_1?ie=UTF8&amp;qid=1461767812&amp;sr=8-1&amp;keywords=akka) , [Akka in Action](http://www.amazon.com/Akka-Action-Raymond-Roestenburg/dp/1617291013/ref=sr_1_3?ie=UTF8&amp;qid=1461767812&amp;sr=8-3&amp;keywords=akka) and [this one](http://www.amazon.com/Reactive-Messaging-Patterns-Actor-Model/dp/0133846830/ref=sr_1_2?ie=UTF8&amp;qid=1461767812&amp;sr=8-2&amp;keywords=akka) Any non book suggestions? Is the principles of reactive programming course up to date with syntax?
Funny thing is, saying Java is the next cobol is saying it's not going to go anywhere for a long long time.
&gt; Do you think they are the future of the JVM? I'm not sure exactly what this is asking, are you asking if one of these languages will displace Java as the reference language? As the de facto language of choice? If these languages will stay on the JVM as a platform? If these languages will drive JVM adoption? If you want quality answers you should rephrase what you're asking for.
With that solution you're losing type safety, and you're building a stack trace each time you fail with an exception, which may also hurt performance.
In my opinion the JVM has a future, projects like OpenJDK and Android ensure that and Java ecosystem is really rich. JVM has many programming language for different scenarios, same are discussed here https://www.reddit.com/r/java/comments/4goq6b/devoxx_uk_java_is_dead_long_live_ceylon_kotlin/
I proposed this as an alternative : &gt;Future.sequence(Seq(first,second)).map(_.flatten().sum()) * Seq(first,second) is a Seq[Future[Option[Int]] * Future.sequence(…) is a Future[Seq[Option[Int]] * ….map(_.flatten()) is a Future[Seq[Int] * (….sum()) is a Future[Int] What do you think ?
For a good introduction you can read Effective Akka, which is short and cheap. Once you get the concepts, the docs will be what you read most. I've bought Akka in Action too as a reference, but I haven't read it yet (i'll probably read it when it's completed).
Did the version matching TFA's code : http://ideone.com/kFuRbH Future.sequence(futures).map { case somes if somes.forall(_.isDefined) =&gt; Some(somes.flatten.sum) case _ =&gt; None } Works but less idiomatic :/
It's not possible in general. Write `flatMap` in terms of `map` and `flatten`, then think about `flatten`: You have a `T[U[T[U[A]]]]` that you wish to turn into a `T[U[A]]`. If you had a `T[T[U[U[A]]]]` you could invoke `.flatten.map(_.flatten)` and be done. So how do you get a `T[T[U[U[A]]]]` from a `T[U[T[U[A]]]]`? Let's set `B =:= U[A]`; we need to turn the `U[T[B]]` into a `T[U[B]]`. But you can't do that just with the monadic interface. Let's think about it specifically with `Future` and `Option` to add some intuition. The article is about `Future[Option[_]]`. The ungeneralisable bit is turning a `Option[Future[B]]` into a `Future[Option[B]]`. That's easy in this case: `.fold(Future(None))(_.map(Some(_)))`. Now, what about the other way round? `Option[Future[_]]`? Can we turn a `Future[Option[B]]` into a `Option[Future[B]]`? That is, can we tell, before a future has necessarily completed, whether it will complete with a Some or a None? Of course not. (Apologies for any silly mistakes: I've been writing a lot of Haskell over the last few days.)
For me personally Scala is the present of the JVM - I've been doing it full-time for 3 years now. Java has a huge existing ecosystem and will probably always be the first choice for low-level mechanical-sympathy type stuff. But it's been very slow to add functionality. I think for everyday application code it deserves to be displaced by Scala and/or Ceylon. But that will take decades if it happens at all. Scala certainly has a future in the medium term - it has a pretty mature ecosystem. Java and Kotlin can't compete with it on power. Ceylon maybe can, and is more elegant/coherent at the moment. I'm worried about the loss of momentum from Dotty - I think breaking changes to make a more consistent language are necessary for the long term, but I worry that Dotty will simply fail in the market. I think that will be what determines who owns the long-term future of application code on the JVM. Kotlin I view as overhyped and underdelivered. It's no more elegant than Scala, and less powerful. It's not a whole lot more powerful than Java 8, and much less elegant. It's worse than Ceylon in every way. It has some good marketing but that's all. Ceylon is the best language going on the JVM, IMO (not counting Idris as it has very poor integration with the wider ecosystem). Whether it's better by Scala by enough to be worth leaving the larger ecosystem is another question though, particularly if Dotty can deliver a more elegant Scala that's compatible with existing libraries. 
Sure, agreed, which is why Futures have a `recover` (or similar) method which takes a partial function from a `Try[A] =&gt; Try[B]`, so you can handle the exception by matching on its type.
&gt; I'm worried about the loss of momentum from Dotty What loss of momentum? There are a shit-ton of things being worked on independent of Dotty. Not sure on Ceylon being better. It's ridiculous that they have things like HLists built in, but made them utterly useless compared to library solutions in Scala. Anyway, I don't think Scala has to be concerned about Ceylon anymore. Marketing &gt; Technology, and Kotlin shit-talked their way to the top.
&gt;Isn't this only kind of, partially true? AFAIK there are no optimizations for filter/map and so on and every single step in a pipeline will actually generate a new collection. So, yes and no. Yes it will generate a "new" collection, but the only actual allocation required is for any elements that are changed when the new collection is produced, instead of a naive approach where you'd have to copy over everything to a new location in memory to create the new collection. For more details, see the following: * http://www.codecommit.com/blog/scala/implementing-persistent-vectors-in-scala * http://www.codecommit.com/blog/scala/more-persistent-vectors-performance-analysis * http://docs.scala-lang.org/overviews/collections/performance-characteristics.html
You could do it with foldLeft too. Though honestly the most idiomatic way is to just use ScalaZ.
Runtime pattern matching is unsafe and inefficient though. E.g. you can no longer see from the signature which functions return Options and which don't. Same reason I'd rather return Either than return Any and then pattern match the type.
The [doobie](https://github.com/tpolecat/doobie) database library has a lot of users and it's based on algebras of the JDBC types and `Free` interpreters.
The first thing that comes to mind is Doobie, which uses Free Monad to abstract over jdbc, if I understood it correctly. You can use it to compose many queries with each other. For example: getUser fetches a user from your db, getRoles(userId) fetches a user's roles. Compose the 2 together, you get a new object which fetches both the user and his roles. https://github.com/tpolecat/doobie I think that's how it works, if I'm wrong I apologize.
That's very neat, thank you!
&gt; I don't think either of the features I mentioned would break binary compatibility. I don't think the former does, the latter maybe. &gt; It was the major complaint among people who didn't use Scala. I was never quite convinced of their sincerity though. Has the slowing down of development actually lead to more adoption? In company scenarios, definitely. It was mainly large companies that were complaining about stuff like ABI binary compatibility, tooling and such. Their primary issue wasn't that Scala didn't have enough features, their issue was that compile times where insane, tooling wasn't that good and Scala kept on breaking binary compatibility every 3 months.
The singly-linked collection in Scala is `List` so you could conceivably use `List[Foo]` and be done. If you wanted an intrusive version like your Java code, I think the closest analogue would be something like this: class Foo(parent: Option[Foo] = None) extends Traversable[Foo] { override def foreach[U](f: Foo =&gt; U) { f(this); parent foreach (_ foreach f); } } Then your `m` function would be def m(foo: Foo): Unit { foo foreach { f =&gt; // } } Or you could just have `m` do what you want (since you must already of a `Foo` in order to call `m`), then instead of `m(foo)` you would have: def m(foo: Foo): Unit { // } Foo foo = ??? foo foreach m
Idris is not on the JVM. Maybe you mean Frege?
No jooq at all ?
I'd say it's fine in application-not-library code, as long as you know exactly what all the things using the global context are. But as soon as your application gets big enough that you want to split it into modules then treat those modules as library code.
There are plenty of cases where you really do still want to use get(). It might be better to rename to something like unsafeGet() though to be more explicit that's it's a partial function. A form of flow typing might allow us to only allow get() when it's safe, but I don't believe that's likely to happen in Scala anytime soon. 
&gt; If you've already checked it's 'Some' earlier on, you don't need to check again. No, I disagree in principle. I recommend watching this video - https://www.youtube.com/watch?v=gVXt1RG_yN0. The compiler can't prove that `x` has a value here: val x: Option[Int] = Some(42) if(x.nonEmpty) { x.get } else { 1111 } Using partial functions is wrong: http://www.cis.upenn.edu/~cis194/spring13/lectures/03-rec-poly.html.
I'd make the argument that partial functions are ok as components of a total function. For example, if you're going to use `PartialFunction.orElse` with the right-most function being total. I think you're referring more so to what might be thought of as a "partial method" in Scala, like `Option.get`, where such composition doesn't exist. But I agree with your skepticism that there's a great number of use cases for `Option.get`. I'd be interested in examples.
&gt; No, I disagree in principle. And I agree with you in principle. In practice, however, I occasionally find myself in situations where the 'correct' approach is substantially more complex, and the 'unsafe' approach, being far simpler, is less likely to harbour a subtle bug. The goal of type safety is, among other things, to ensure correctness and reduce cognitive load. So I have a tradeoff between two things 1 - Statically guarantee that I won't receive an "NPE" at runtime, but increase the complexity of business logic that needs to be verified by hand and/or tests, and may fail in subtle ways that might be hard to detect. 2 - Simplify business logic such that this is easier to verify [business logic] correctness and understand the code, but lose the strict guarantees from the compiler that I won't receive a NPE - however it's still fairly simple to manually verify, and if I do make a mistake that can cause an NPE, it's almost certain to fail hard early. Option 1 increases the chance of a submarine bug that may fail in subtle ways and go unnoticed, possibly resulting in data corruption or incorrect business logic that might cost myself or my customers money. Option 2 decreases the chance of a submarine bug, but opens the possibility of a NPE that will fail immediately and very loudly panic in a way that is hard to miss, and almost certain to be found quickly, most likely before it goes into production, and is unlikely to cause major issues even if it does. In a perfect world I'd have a type system that doesn't make me compromise, but since I don't, If have a choice between correctness of something where a failure is annoying, and correctness of something where a failure could cost a lot of money, I'm going to pick the former. (A hard crash is far, far better than incorrect business logic that nobody notices, and since we're doing a lot of network operations over flakey connections, the entire application is inherently resilient to such failures as part of its design) I'm a die hard FP purist, but one thing that I really don't agree with is the religious focus on type safety above all else, completely missing the point of the actual business problem it's trying to solve. I've seen people spend months trying to write code that satisfies a perfect academic ideal of "Correctness", completely missing the point that the edge cases they were trying to catch were unlikely to ever happen in production, and they could have solved the problem with a few dozen lines of unsafe code. &gt; Using partial functions is wrong: http://www.cis.upenn.edu/~cis194/spring13/lectures/03-rec-poly.html There's plenty of excellent uses for partial functions - especially in Scala where they have first class support and can in many contexts be used in a fully typesafe way that still guarantees totality. Taking it even further, using an SMT solver we can use partial functions while still guaranteeing totality and giving us some rather nice tricks we can do that we couldn't do if we religiously require pure functions. Which brings be back to... without a full SMT solver, even with basic flow sensitive typing, get() would be a non issues since we could guarantee that, even though it's a partial function, it's safe to use in certain contexts. This is used to great effect in i.e. Ceylon.
I have a situation where Option.get works and is safe. I have a series of traits like: trait BaseAction extends Action { val user: Option[User] = ??? } trait AuthorizedAction extends BaseAction The plumbing guarantees that anything inheriting from AuthorizedAction will have a valid user, so calling user.get is perfectly valid. 
&gt; "Many of the functions in Haskell's prelude like head, tail, init, and many many others fail unnecessarily." http://stackoverflow.com/a/23184020/409976
It's like transporting a steam engine in a tesla...
Screw that. Scala programmers understand what .get means, they understand the implications. A lot of the time code may be better without .get but a lot of the time it reads more naturally with it. if (aOption.isDefined) { val a = aOption.get do a bunch of stuff else { do a different bunch of stuff } now, that could have been written as: aOption match { case Some(a) =&gt; do a bunch of stuff case None =&gt; do a different bunch of stuff } but it's a question of taste, and I may not be in the mode to deal with a few thousand new warnings in perfectly reasonable code just because some people would like to deprecate .get to satisfy their idea of purity. Mind your own business.
https://github.com/mdedetrich/scala-json-ast/blob/master/jvm/src/main/scala/scala/json/ast/JValue.scala#L116-L120 Here is a situation where its useful, and its due to performance
Maybe you should parameterize BaseAction by an `F[_]` type that's Option for some subclasses and Id for AuthorisedAction.
In principle I agree with having an escape hatch. Though note that even without `.get` you could always `.asInstanceOf [Some [A]]` if you really needed to. In practice I really can't think of a single case where there isn't a better alternative to .get, in 5+ years of Scala. Certainly it shouldn't be such a short and obvious method. 
I learnt Scala by doing stuff until it works. I know experienced Scala programmers already know to avoid `.get`, but I want the language to keep growing.
&gt; I guess it's the same Scala plugin for both IDEs right so it shouldn't really matter which IntelliJ version I use? This you can easily find out. The latest Scala plug-in version in IDEA 2016.1.1 is 3.0.3. If you are using the free community edition, I guess updating is a no-brainer.
That's a useful reference, thanks!
It's difficult to quantify because I continuously update, so I don't know at which version you stopped. In general the plug-in keeps improving in terms of speed and correctness, sbt project model stability etc. At least it has been long time since an update gave me a serious regression (that could happen years ago). Otherwise, also no revolutionary advancement, some type inference improves, new wrong red highlights appear elsewhere… I have given up the hope that one day you will have a 100% correctly highlighted file, but at least we're close now. IntelliJ has improved quite a bit since 14. Start-up time is much lower now, for example. I think improved placements of debugger breakpoints on multi-expression lines is something that might not be available in 14. __Edit__: You should be able to follow what has been done since the plug-in version you currently use by skimming through the blog: http://blog.jetbrains.com/scala/
That's a really good suggestion, and one that I would totally do, if there weren't four different major projects all using some variation of the core framework. Maybe some day! 
I think you can make this safe: trait BaseAction extends Action { val user: Option[User] } trait AuthorizedAction extends BaseAction { override val user: Some[User] }
&amp;nbsp;&amp;nbsp; I really don't like the names mathematicians have chosen for these abstractions. Instead of normal names like ComputationBuilder, Mappable, AppliedMappable, Combinable, IdentCombinable, and InverIdentCombinable, you get isoteric terms like "Monad", "Functor", "Applicative", "Semigroup", "Monoid", and "Group". I don't know what "Free" is, but I'm willing to bet that there is a much more intuitive name for it (like InterpretedComputationBuilder).
&gt; I have given up the hope that one day you will have a 100% correctly highlighted file Interesting, Scala IDE user here. While with type inference heavy code semantic highlighting will get laggy (i.e. play catch up with SBT) wrong red highlights are generally speaking a rarity (I mostly get them with macros and am able to resolve via a set incantations and fervent prayer to the lord of bits). Do you get spurious syntax errors for run-of-the-mill scala code, or is it more scalaz, shapeless, etc. that causes these scnearios?
Yes, I was thinking someone should make a PR to use sbt-android instead.
Disagree. If we follow that line, we can remove `IndexedSeq.apply` (or force the use of a valid path-dependent `Index`), remove the integer division operator to avoid ArithmeticExceptions, ...
this is cool... will have to check out if png quant works :)
Except that this is meant to be a public facing api, so we had to use `Option`. In the context of this library, pulling in something like scalaz wasn't acceptable. In any case, the point is that it is useful in some circumstances, and it definitely shouldn't be removed unless the compiler (not a library) can remove boxing in 100% of cases 
&gt; I'm not really keen on the casting approach as an escape hatch. It feels like much more of a code smell than simply having a partial function. To my mind it *should* be an equally strong smell, since it's equally unsafe. &gt; Plus, you can use WartRemover to hard fail on any calls to .get() unless you've explicitly annotated a block of code as unsafe. (Which means it turns up very quickly in code review, and will get the banhammer of rejection unless there's a very good explanation why we have an unsafe block). Yeah, and I do. But that's a bit ad-hoc. Maybe just a generic way of marking functions as unsafe would do most of what I want. &gt; b) Create a second version of the model that doesn't have optional fields for use in this area. We can now pass this around safely, but it means we have to create another model for every variation needed to satisfy totality for one function or another. That's probably the approach I'd take. In my experience you rarely need more than two or three different representations of the same thing, and it's easy to declare another case class. Also there's the option of parameterizing by a `F[_]` type.
High quality article as always! :) Regarding wrapping id-types in case classes: `case class UserId(id: Int)` Isn't it a good idea to make it `extends AnyVal`? I think that will save you the runtime overhead if that ever became a performance concern. Another technique I've been thinking about lately, is to tag the type instead of making a case class: `case class User(name: String, age: Int)` `def getUser(id: Int @@ User): User` and then to use it: `val someUserId: Int @@ User = 42.taggedWith[User]` `val user: User = getUser(someUserId) // works` `val user: User = getUser(someMachineId) // does not work` `val user: User = getUser(42) // doesn't work either` `val user: User = getUser(42.taggedWith[User]) // now it works again (obviously)` I'm not sure if it's correct to use tagging of types this way, but it seems like a perfect use case. You don't need to create a case class instance, or even create a new class just to get the type safety. The tagging of types only works as a compile-time safety. In reality, it's always just the integer 42. However, you can do this though: `def add(a: Int, b: Int) = a + b` `add(20, someUserId)` Since `Int @@ User` is only a specialization (or "subtype") of `Int`
that's really nice, thanks!
You don't have to wait a few years. Despite the version number, Scala.js is already fully functional and production ready in my experience.
Oh I Know! I'm already using it and wrote some blog posts about it a few months back. Also I'm trying to write an idiomatic facade of rxjs to write some real awesome stuff in the future. I meant more about in the terms of a larger community, more available libraries and frameworks in the future. (Might write one myself)
I agree; I just don't understand why scalajs chooses to output what it does, rather than this
Wrote this to bulk load data into Cassandra for back processing 1 TB+ of data since spark-cassandra-connector was not fast enough.
I like his choice to leave this out :-) These are useful optimisations, but there are sufficient caveats and a need to delve into specifics of which is better, why, how they combine with type erasure, auto-boxing, which library to choose for tagging, etc. His article is clear and to the point (perhaps partly due to not getting bogged down in such details), and an interested person can later investigate the optimisation opportunities (this could also be a follow-on article). But I generally agree with your comment about what's possible, and that it's useful.
Ok, that's quite fair. In general I am fairly ignorant about high performance computing, so I hadn't considered that use case.
This will not work as type `value.T` is an abstract type member. Although this is probably not what you need, the closest use case I know of is something along these lines: scala&gt; import scala.reflect.runtime.universe._ import scala.reflect.runtime.universe._ scala&gt; trait Trait { type T = Int } defined trait Trait scala&gt; typeTag[Trait#T] res0: reflect.runtime.universe.TypeTag[Int] = TypeTag[Int] Edit: Fixed comment, see Milyardo's answer
`.type` is a type for singleton values, based on value equality (structural equality), which exists at runtime (pattern matching uses `.equals` and `.isInstanceOf`). I think the compiler doesn’t have any special logic to know that "foo" and "foo" have this property. Edit: For pattern matching expressions, the compiler only checks that the Java types are compatible, not their values. So I guess that value/structural equality is only checked at runtime. Thus two equal values aren’t known to be equal at compile time, and two non-equal values aren’t known to be non-equal.
Thanks! Are all type members abstract types? And in which cases a type is considered abstract? Thank you!
If your dealing with http requests check out Akka HTTP which is now part of Akka as of 2.4. If you need to process data in a way that prevents race conditions thats not something that akka is going to do for you out of the box, its something your going to have to come up with yourself. As for ETL, it also depends on why do you think that AKka is the best tool vs. other competitors in that field, why not use Spark? 
We're using spark streaming to process incoming data for this project. Currently this is the L part of our ETL. It's a great tool for the job its doing but from what I can see a single Spark job isn't going to give the granularity we're going to need for the rest of the application. Maybe I'm wrong but an Akka cluster is going to give us the ability to track and scale our ETL. We're also using Spray for our API layer and its working out pretty well. I'm accustomed to the actor system of design and I would like to learn more about it. If there were better options out there I would love to hear about them. I'm still prototyping the application out so now would be a great time to consider alternatives to Akka. What I like about the idea of an Akka cluster... Reactive Streams Clustering Monitoring JVM based for Java Lib use Cheers, Conor
Or even just this: def memoize[I,O](f: I =&gt; O) = new mutable.HashMap[I, O]() { override def apply(x: I) = getOrElseUpdate(x, f(x)) } This can be used as a function, or as a map with `contains` etc: lazy val myFunc: I =&gt; O = memoize { ... } myFunc(100) or lazy val myFunc: HashMap[I,O] = memoize { ... } myFunc(100) myFunc.contains(50) // true
Re: NonEmptyLists, it is possible to use :: in the standard library if `List` is a better choice for you than `(String, Seq[String])`: &gt; def lookup(name: String): ::[String] = ::("1234", Nil) &gt; val numbers = lookup("name") &gt; numbers.reduce(_ + _) 1234 It is a `List`, so it has the API you’re familiar with, without the need to match it as a tuple.
First, terminology: each set of arguments is called a "parameter group". The `T` in each example is a type parameter, which will be replaced with a concrete type at the call site for the method. There are two main reasons to use multiple parameter groups: 1. Implicit parameters Implicit parameters are put in a parameter group of their own, prepended with the keyword `implicit`. If none of the parameters in this group are specified, then the values are taken from the implicit scope. This is usually the case for `Ordering` and `ExecutionContext`. See http://stackoverflow.com/questions/5598085/where-does-scala-look-for-implicits 2. Better type inference When an anonymous function is passed as a parameter, all type parameters for that function must be fully known at the point of definition. But type parameters are resolved at the end of each parameter group, not within a parameter group; so if the type of an anonymous function can be determined by another parameter, putting that other parameter in a different group may allow you to avoid explicitly annotating types in certain cases: Here's an example using a single parameter group: scala&gt; def combineAs[A](a1: A, a2: A, combine: (A, A) =&gt; A): A = combine(a1, a2) combineAs: [A](a1: A, a2: A, combine: (A, A) =&gt; A)A scala&gt; combineAs(1, 2, _ + _) &lt;console&gt;:17: error: missing parameter type for expanded function ((x$1, x$2) =&gt; x$1.$plus(x$2)) combineAs(1, 2, _ + _) ^ &lt;console&gt;:17: error: missing parameter type for expanded function ((x$1: &lt;error&gt;, x$2) =&gt; x$1.$plus(x$2)) combineAs(1, 2, _ + _) scala&gt; combineAs(1, 2, (a: Int, b: Int) =&gt; a + b) res0: Int = 3 But here is an example using multiple parameter groups: scala&gt; def combineAs_[A](a1: A, a2: A)(combine: (A, A) =&gt; A): A = combine(a1, a2) combineAs_: [A](a1: A, a2: A)(combine: (A, A) =&gt; A)A scala&gt; combineAs_(1, 2)(_ + _) res1: Int = 3
You forgot about how scala uses it for type inference, which is actually a critical piece if you start getting deep in to writing generic functions. 
As I mentioned, Duralumin already wrote about Scala-specific reasons (implicits, type inference).
Hey argv_minus_one! Thanks for the feedback! Always appreciate anyone who takes the time to type out their thoughts. I welcome the opportunity for us to learn from each other. &gt; What kind of a name is CharPML_gQdBkrozvt? This prevents shadowing issues when implicits accidentally use the same names &gt; Why have Message1, Message2, etc types instead of using tuples? MessageN case classes do not store the message only the key. They are sugar on top of the Messages class. &gt; UTF8Messages is a misnomer. Java ResourceBundles are loaded from class files (UTF-8), XML (any encoding), or properties files (ISO 8859-1), and the character encoding frankly isn't relevant anyway. Maybe call it JavaMessages or something. I don't have a link for you but my understanding of most resource bundles for message formats are encoded using ISO-8859-1 since they are Java properties files. The name and structure of UTF8Messages is copied from how Play framework handles this problem. &gt; The documentation for I18NStringTag does not link to the definition of I18NString. It also does not explain what a “type tag” is. I can add that, thanks! Also the real definition is located in net.s_mach.package since it is a type alias. &gt; I18NString appears to be impossible to fulfill, as String is final. The documentation does not explain this. The documentation also doesn't explain why it exists at all. The first line in the readme of the overview section explains I18NString. String is final, but I18NString is a distinct type alias. &gt; There is no documentation for the package s_mach.i18n.messages. In particular, there is no explanation for why it is a separate package from s_mach.i18n. It is a separate package since it brings into scope commonly occurring names (such as "Messages"). You will note that all types/objects under s_mach.i18n. _ are prefixed with "I18N" to prevent name collisions. One need only import s_mach.i18n.messages when building message declarations. Most code usage will only require s_mach.i18n. _ &gt; There is no documentation for the package s_mach.i18n. The documentation of this package should describe how to use the library, link to entry points, etc. Your project's README is not a substitute for package documentation. We will have to agree to disagree there. I have a number of libraries and this would require me to keep up-to-date two copies of the main documentation, one in asciidoc for readme and one in javadoc for the package. &gt; Traits with single implementations (e.g. StdI18N) are an anti-pattern. This is not EJB. Refactor them into concrete classes. The purpose of StdI18N is to provide a mechanism that allows more easily overriding the default I18N[A] type-class handlers for built-in types by way of setting the StdI18N formatter in I18NConfig. Once one decides to supply a new I18N[A] type-class for any of built-in types one can no longer include s_mach.i18n. _ without using package import exclusions. &gt; There is no explanation as to why s_mach.i18n.Implicits exists. This exists for anyone who wishes to replace all of the I18N[A] type-classes for the built-in types. Implicits does not inherit from I18N.Implicits. &gt; tl;dr: API design needs work. Appreciate the feedback, but I can assure you the API is in its final form. I'm already using it in projects and if you don't find it helpful feel free to create your own or put in a feature request on github. Thanks! 
Is that really the principle of least astonishment? &gt; getDeclaredFields() &gt; All the fields, regardless of their accessibility but only for the current class, not any base classes that the current class might be inheriting from. .length isn't declared on Array(). In scala, length comes from an implicit conversion from Array
I'm a programmer, and even *I* feel the temptation to yell “nerd!!!” at Scalaz developers.
Adding support for more types of shapes would be straightforward in itself. However, one of the main factors that drives the rendering time is the number of ray/primitive intersections that has to be computed, and adding more primitives to a scene causes the time to linearly increase. The most common type of shape is a mesh of triangles, which can add thousands of primitives to a scene. Acceleration structures such as KD Trees and BVH are the usual way to reduce the number of intersection calculations. There are also techniques to speed up the image convergence, but all of this comes at the cost of clarity as they significantly complicate the code. I would hope that the State monad for the RNG doesn't introduce that much of an overhead in the grand scheme of things.
The original example `withdrawWithoutMonadTransformers` is straight forward to grasp and arguably easier to understand than the fancy scalaz version.
Your characterization of `widthdrawWithoutMonadTransformers` is misleading because it uses some scalaz features even without using monad transformers.
Are we talking about the same snippet? Because the only non-standard Scala I can see is `Future(none[Amount])` instead of `Future[Option[Amount]](None)`.
How does this compare against https://github.com/makkarpov/scalingua or http://rapture.io/mod/i18n?
In your example scala does **not** know `someTrait.T` is `Int` because you have declared it as the wider type `Trait`. scala&gt; val someTrait: Trait = new Trait { type T = Int; val value = 3 } someTrait: Trait = $anon$1@352f25d8 scala&gt; Predef.implicitly[someTrait.T =:= Int] &lt;console&gt;:20: error: Cannot prove that someTrait.T =:= Int. Predef.implicitly[someTrait.T =:= Int] ^ If you leave off the ascription the inferred type includes the refinement `type T = Int` which is probably what you were expecting: scala&gt; val someTrait = new Trait { type T = Int; val value = 3 } someTrait: Trait{type T = Int} = $anon$1@32a83743 scala&gt; Predef.implicitly[someTrait.T =:= Int] res8: =:=[someTrait.T,Int] = &lt;function1&gt; scala&gt; val x: someTrait.T = 5 x: someTrait.T = 5 Much much more on this stuff [here](http://typelevel.org/blog/2015/07/13/type-members-parameters.html).
&gt; traits vs case classes A trait is like a java interface, it provides nothing but a way to inherit certain characteristics, and some default implementations. A case class on the other hand creates a class and its companion object, it also implements the apply, toString, equals, and hashcode methods that you normally will have to implement yourself in normal classes. A case class can also inherit from Traits making them again, closer to the idea of a class. To expand on your question a bit, a trait will be used to abstract certain actions such as the much loved DAO pattern, which provides an interface with the standard operations to be performed on an object. 
congrats. I found the documentation for pants to be easier to understand than competing build systems (i.e. bazel) especially including 'best practice' section like the 1:1:1 principle. I think ultimately the choice in tool comes down to out of the box support for which codegen you want off the bat: thrift vs protobuf/grpc
Thank you for your answer, but I still not clearly understand it, especially in the case of implicit argument. Please see the following code: trait Trait { type T } implicit val v0 = new Trait { type T = String } type Aux[T0] = Trait {type T = T0} Do the following two pieces of code work the same? def func(implicit ev: Trait): Aux[ev.T] = ev // `ev` have the type of `Trait`, right? val ret = func // apply the function implicitly[ret.T =:= String] // compiler knows that `ret.T` is a `String` and val ev = implicitly[Trait] val ret: Aux[ev.T] = ev implicitly[ret.T =:= String] // not works 
`v0` and `v1` don't have the same type. the type of `v0` is `Trait`, the type of `v1` is `Trait { type T = Int}`, which is a subtype of `Trait`.
Ints. For example 115896 into Vector(1,1,5,8,9,6)
* Yes, a type that can be viewed as another type is subtype of that type. Since `Trait` is `trait Trait { type T }` with `T` unbounded, it is supertype of `Trait { type T = Int }` with `T` bounded. * Another example would be: `Trait { type U }` is subtype of `Trait` since it's a `Trait` with another type member `U` introduced. You can checked the subtyping by: `implicitly[Trait { type U } &lt;:&lt; Trait]` 
Your approach is sound. A string is a `Seq[Char]` so if you take a `String` and map a function from `Char =&gt; Int` over it, you'll get a `Seq[Int]`. `char =&gt; char.asDigit`, like you're using, will do the trick.
Oh right, I get what you are asking now, since there are 2 implicits available why is it legal for it to choose one of them. Thanks for the reply. 
When resolving multiple implicits there is an attempt to choose the most specific one via the static overloading rules. That is, there's some precedence among available implicits. From the spec: &gt; If there are several eligible arguments which match the implicit parameter’s type, a most specific one will be chosen using the rules of static overloading resolution (§6.26.3). If the parameter has a default argument and no implicit argument can be found the default argument is used. The value which defines `type T = Int` is more specific than the one which does not (it's a subtype), so it is chosen.
See currently last comment from Martin Odersky: &gt; If people have suggestions how to express ADTs without too much fuss and good integration with classes that would also be interesting to discuss!
That's kind of what I am doing but it's gross and requires so much extra boilerplate. I was hoping there's be a cleaner solution. Thanks though 
The short answer is “as strict as you want it to be”. :) If you don’t mind posting a simple working example of your var solution, it’ll make it easier to come up with a val solution that will work for you too. But I’m thinking that the trick to replacing var with val is usually to replace iteration with tail recursion.
They don't both match for evidence of `Trait`. There is a implicit value for `Trait` and there is a implicit value for a subtype of a `Trait`. There is no ambiguity.
I'd say mutable state is fine if you're modelling mutable state. I would try to go for an append-only structure though i.e. store the list of timestamps. That way there is only a small amount of mutability. You could do a Haskell-style State Monad approach if you wanted - http4s *might* support sequencing those at the framework level, so your code would only supply a command value and mutability would only exist in the framework's interpretation of that value. But that's overkill IMO.
`v1` is not matching for Trait, it is matching for a subtype of `Trait`. When resolving the evidence for `implicitly` more than one search is happening. For example, if we define an implicit for another subtype of [Trait](http://scastie.org/16911), we end up with an ambiguous implicit because there are two values for the same search. 
Thanks for your elaborate answers. I will look into the Haskell Style approach that you mentioned, i have not heard of it so far. It's probably an overkill for this task so i might go with the append-only structure you suggested. But it's always nice to find new concepts :)
Can I ask what the use case you're thinking about? Also, this answer would be different if it was an established Java application moving towards Scala vs a greenfield Java application vs a greenfield Scala application... Etc
I got a Java codebase which I don't want to dump, but for now I'd rather finish the project in Scala.
Generally speaking, it's straightforward to call from Scala to Java. It's significantly less straightforward to do the reverse. So if your Play! app is a Scala Play! app, and you just have some (maybe a lot!) of logic in Java, you're probably in good shape. If you already have a Java Play! app, then I think you have a bit more work to do to get the outermost code—your controllers etc.—into Scala, and then it should be relatively straightforward. As a stretch goal, you may wish to consider moving on from Play! and doing something like using [http4s](http://http4s.org) with its [Twirl](https://github.com/http4s/http4s/tree/v0.12.4/twirl) template support if you need it. One nice thing about this would be that you can then easily wrap Java APIs, even multithreaded stateful ones, in monads with `Task` or `Free`, and make use of them in a sane way. Recommended if you can afford the time.
It sounds like a log would suit better for this situation? There are probably a few helpful tools on the [awesome-scala list](https://github.com/lauris/awesome-scala). Yours isn't a fantastic starting point for total newbies, so decide how much time you want to spend on this now. If your functions work and pass all tests, you can always come back later and refactor. Here's a brief overview, skipping a lot of material: One of the core principles of *pure* functional programming is "referential transparency". Basically, if you have any function A -&gt; B, then any A you call it with would always return the same B. This works great for reasoning about a problem. Two examples of where it's impossible would be your TimeStamp problem, and a database update. If I call a function which reads a database: def readID(id: Int): Foo = // returns Foo with id then I can't be sure of referential transparency. What if someone calls this: def updateFoo(foo: Foo): Try[Int] = // updates using foo.id to replace all other fields of foo in DB And if I have another function deleteFoo(id:Int) then updateFoo loses referential transparency as well! updateFoo(foo) // Success(_) deleteFoo(foo) // Success(_) updateFoo(foo) // Failure(error) Likewise, TimeStamp. That function will *never* be transparent. def getTime() { System.currentTimeMillis } // don't call me twice! So we solve all these problems by tucking them in a corner by themselves, and encapsulating them so that the problems caused don't go any further than their tiny little corner. If a bug is found, it *must* be in that single snippet of code. Maybe my Database API is updated so that the Int it returns can now be a 3 or 4, and I'm still returning a normal success - but the private member which handles that is still in that little snippet - I make the rest of my codebase referentially transparent, so when something goes wrong, I know which pattern match to extend, or to make a new case object from the relevant sealed trait, or whatever. So, not seeing your codebase, I doubt anyone can give you an exact answer - but I can tell you a great starting point first, with two things: First, if you're not already, use anything but the pre-java 8 time library. If you're just using System.currentTime that's fine. If you need to handle dates and such, use JodaTime or a scala wrapper for it. Second, find everything associated with finishing a job, and put it in one "place" if you can. Either the same package, or even better, a single class. having to use the "new" keyword to show that "this stuff isn't very functional" is a good tip to your future self, or others. But if you're doing a lot of different kinds of work with these TimeStamps, don't bother for now - that is, if you'd have to implement all of the case class magic yourself (hash, toString, etc). But keep in mind that the "new" keyword can start to look like inline documentation along the way. :) One last thing occurs to me, however: If you're storing these TimeStamps in a collection, *do not* make that a mutable collection *and* a var. You can make an immutable collection as a var, or a mutable collection as a val. Using both is downright wrong. If you don't know this already, please ask and I'll explain more.
What needs to mutate here? Assign a time to a start Val. At the end subtract current - start and assign to a total time val. There, immutable 
For me, it'd look something like [this](http://scastie.org/16918). A few points: * I created a couple of obviously trivial subprocesses to run. * I wrapped them in [`Task`](http://timperrett.com/2014/07/20/scalaz-task-the-missing-documentation/), which is essentially a sane version of `Future`. `delay` means "when the `Task` runs, run it on the current thread, but not now." * I use [scalaz-stream](https://gist.github.com/djspiewak/d93a9c4983f63721c41c) to turn each `Task` into a stream (AKA `Process`) of one element with `Process.eval`. * I `++` my streams to say "do this, then do that." * scalaz-stream has a `time` module, which provides a stream consisting of calls to `System.nanoTime`, called `duration`. * I `zip` my stream of external processes with `duration`, which gives me a stream of pairs of external process results and the times of their completion, with 0 being the time before anything has run. * This isn't what you asked for: you want the time _before_ the 2nd process runs, but _after_ the first process has run. So I `Process.emit` a "*MARKER*" so when I `zip` the `duration` we get a timestamp at the marker, i.e. before the following external process. * I `map` over the stream to get just the timestamps (`_._2`). The first one will be the time after the first process has run, and the second one will be the time at the marker, so I `.drop(1).take(1)` to get the second one. Upon reflection while writing this, of course that's wrong: you want the difference between the second and first. So it should be something like `.take(2)`, then, when you `.runLog` the stream, you can `.reverse` the `Vector` and `reduce` it to the difference. OK, this is a lot, because I assume you aren't particularly familiar with `Task` and scalaz-stream. tl;dr: scalaz-stream acts a lot like the Scala standard library `Stream`, especially in that it's lazy, so it can be "infinitely long." It differs from `Stream` in that it can also contain effects, almost always modeled with `Task`. So it's perfectly reasonable to talk about "a stream of things to do," "a stream of timestamps," etc. and to go merrily about `zip`ping, `filter`ing, `map`ping, and all the other stuff you can do with sequences. It takes a bit of wrapping your head around, but it's _unbelievably_ useful.
That's quite a stretch, but it's good to see there's still some competition in the Scala web framework space... :)
I recommend a really big bottle of scotch.
Just had a double already, so I'm glad I'm on the recommended path ;-) 
I do have Scala code with Java libraries many times. I found that having a Scala wrapper (or some utility method) for dealing with exceptions/nulls and sometimes collections to be really nice actually 
My deepest sympathy! I would continue to code in Scala and see if anyone notices :-) 
Something like https://beachape.com/blog/2015/07/25/slim-play-app/ maybe.
Accessing Java code from Scala is fine, accessing Scala code from Java can be a real pain.
Heck, while you're at it pick up other JVM languages like Kotlin or Ceylon. 
Just wondering why the switch?
Here's one contrived REPL example with scalaz. scala&gt; Some(2) &gt;&gt;= (x =&gt; Some(x)) &lt;console&gt;:17: error: value &gt;&gt;= is not a member of Some[Int] Some(2) &gt;&gt;= (x =&gt; Some(x)) ^ scala&gt; some(2) &gt;&gt;= (x =&gt; some(x)) res0: Option[Int] = Some(2) ```some``` returns an ```Option[A]``` whereas ```Some.apply``` returns ```Some[A]```. There exists a ```Monad[Option]```, but there does not exist a ```Monad[Some]```, so it can't figure out how to use bind. The proposal would make ```Some.apply``` return ```Option[A]``` automatically like the smart constructor from scalaz does.
Why always return the transformer. Like, whats the reason? 
Maybe *always* was too strong of a word. :) It's really just my preference. *Usually* you'll want map/flatMap over the 'parameter' inside *both* contexts (in this case the either and the future) when mapping over it. When you don't, it's easy enough to call .run on the transformer to get 'back' the Future[\/[Error,A]]. But if you return just the raw type without a transformer, calling map on the above type gets you the either itself, which you may have to then in turn map over, etc. 
Write in Scala, `javap` on the class files.
Thanks for the detailed answer! I already knew about the boilerplate but no string interpolation? Oh vey. Do you know of well written open-source Java libs? I could have a look and learn from the code of the masters. 
Greener pastures really. 
And if you're unfortunate enough to write Java 6-, Map&lt;String, List&lt;String&gt;&gt; someMap = new HashMap&lt;String, List&lt;String&gt;&gt;(); In Python, this would be somemap = {}
Leave that job ! Or scotch as already mentioned !
I've been trying to port the freer monad approach to Scala as https://github.com/m50d/paperdoll (I'm aware there are other similar efforts).
**KISS** Keep it simple stupid* *_Applies to all areas of life_
This looks very promising! Thanks also for your thoughts on project governance.
I'd seriously only accept a "Java" job if: 1. I had an architect role. 2. One aspect of being an architect consisted of beginning the migration to Scala. This would include leading internal training/brown bags/reading groups, having an explicit budget cut out for external training/conferences/books, etc. In other words, not "we're switching tomorrow! Boil the ocean!" But a thoughtful, measured, API-by-API or service-by-service transition, making sure everyone on the team comes along. _Starting_ with Java, today, is fine. _Staying_ with Java, today, is not.
Not only typeclasses, try folding over an option 
Just to point out you can use [Lombok](https://projectlombok.org/features/index.html) to get around the case class/val issue. Though you can just use the final keyword in plain Java to enforce immutability.
&gt; but I'm honestly trying to think of some good things you can expect from making this transition and I'm having a tough time of it Java's Enums are nice. I do miss those a *bit*, not even close to enough to want to write Java again.
In addition, I use akka-http in [this project](https://github.com/blbradley/kafka-cryptocoin). Not the best example, and the code is still changing rapidly.
It's a three-line recursive function. It's pretty simple. I am surprised that I'd get downvoted for just *suggesting* it as an alternative to a technique that converts an Int to a String and then Strings back into Ints. 
[Streams](http://doc.akka.io/docs/akka/2.4.4/scala/stream/index.html) then [HTTP](http://doc.akka.io/docs/akka/2.4.4/scala/http/index.html)
Side note: It is not true that [async uses the continuations plugin](https://github.com/scala/async#comparison-with-cps-plugin), though. Instead it's using macros, a less powerful but also easier to understand approach.
So I don't quite understand what's going on in the internals of the runtime, but a scala Array isn't just an alias to a java array. This is the source code for scala's Array class final class Array[T](_length: Int) extends java.io.Serializable with java.lang.Cloneable { /** The length of the array */ def length: Int = throw new Error() /** The element at given index. * * Indices start at `0`; `xs.apply(0)` is the first element of array `xs`. * Note the indexing syntax `xs(i)` is a shorthand for `xs.apply(i)`. * * @param i the index * @return the element at the given index * @throws ArrayIndexOutOfBoundsException if `i &lt; 0` or `length &lt;= i` */ def apply(i: Int): T = throw new Error() /** Update the element at given index. * * Indices start at `0`; `xs.update(i, x)` replaces the i^th^ element in the array. * Note the syntax `xs(i) = x` is a shorthand for `xs.update(i, x)`. * * @param i the index * @param x the value to be written at index `i` * @throws ArrayIndexOutOfBoundsException if `i &lt; 0` or `length &lt;= i` */ def update(i: Int, x: T) { throw new Error() } /** Clone the Array. * * @return A clone of the Array. */ override def clone(): Array[T] = throw new Error() } So clearly there's some magic going on since it's a final class and all the methods just throw Exceptions.
You're not getting me at all. This has nothing to do with Scala, as Scala reflection **works**. No need to discuss Scala further. This has to do with vanilla Java reflection not working on the length implicit. That is a **Java** implicit, not Scala implicit. Repro Java code: class Foo { public static void main(final String[] args) throws NoSuchFieldException { args.getClass().getDeclaredField("length"); // croaks } } 
I found [Type-Driven Development with Idris](https://www.manning.com/books/type-driven-development-with-idris)'s chapter 8 on Equality to be enlightening. It's related to my comment since the chapter opens with: &gt; define this function: `exactLength : (len : Nat) -&gt; (xs: Vect m a) -&gt; Maybe (Vect len a)`
I'd say there is a fair chance that you're using the wrong encoding of this data in the first place - given that you seem to place some semantic value in the particular words within a String, i would say you should certainly encode that semantic structure as a case class with named fields (and a practical `copy` method for these cases) That said, to answer your question, you could try pattern matching to unpack your values and repack them into a list as you wanted to : val result = (altFirst, altThird, line.toList) match { case (Some(_1), Some(_3), _ :: _2 :: _ :: tail) ⇒ _1 :: _2 :: _3 :: tail case (None, Some(_3), _1 :: _2 :: _ :: tail) ⇒ _1 :: _2 :: _3 :: tail case (Some(_1), None, _ :: _2 :: _3 :: tail) ⇒ _1 :: _2 :: _3 :: tail case (_, _, list) ⇒ list } 
I think you made a mistake with your example. It isn’t clear what’s going on, so I’ll approach it in more general terms. In your case you’re making an `Array` from `String.split`, but it isn’t clear if this is part of the task or not. You then talk about Lists, but `List` is a bad structure for updating middle elements (see [performance](http://docs.scala-lang.org/overviews/collections/performance-characteristics.html)). So I suggest you don’t use Lists for this. I’ll be agnostic about this and stick with Scala’s immutable `Seq`, which is a trait covers everything like List, WrappedArray, Vector, Buffer, Stream, etc. The next part of your question isn’t clear how we are given these ‘options’, or how we know it’s the 1st, 3rd, 9th or 400th element that needs replacing. In your sample output you’ve modified the 2nd element rather than the first, so it’s not clear what kind of indexing system you are after. I’m going to carry on and assume we will be given a series of replacements with 0-based indexing. Now if you’re hardcoding the updates, then what you did is fine: seq.updated(0, replacement) If you were *really* using `Options` (and it’s not clear where/how/if these are really part of the scenario: are we getting passed a set of these or what?), you can replace the imperative `if (option.isDefined) { list = list.updated(0, option.get) }` with the functional: seq = option.fold(seq)(seq.updated(0, _)) or: seq = option.map(seq.updated(0, _)).getOrElse(seq) However this is very risky: you haven’t explained how long the ‘list’ so we have to assume the worst: `.updated` will throw an Exception if the index is out of bounds. On the other hand `.patch` won’t throw an Exception, it’ll just append the element. It’s not clear what you wanted. So I’m going to assume that we will be supplied with a sequence of data, plus a list of single-element replacements to be made, and that we should ignore any that are out of bounds. Here is a tail-recursive (loop) function that will apply those changes: def patch[T](seq: Seq[T], replacements: Seq[(Int,T)]): Seq[T] = replacements match { case Seq() =&gt; seq case (i, r) +: remaining if i &gt;= 0 &amp;&amp; i &lt; seq.size =&gt; patch(seq.updated(i, r), remaining) case _ =&gt; patch(seq, replacements.tail) } You can use it to patch your sequence: &gt; patch(Seq("abc", "def", "ghi"), Seq(0 -&gt; "xyz", 99 -&gt; "***")) Seq[String] = List(xyz, def, ghi) Edit: I probably should have called it something other than `patch`, since there is already a standard library method with that name.
You could make a List[Option[String]] for the values you want to replace. There's probably a better way to do this, but as a first pass it might look like this: val line = "abc def ghi jkl".split( " " ).toList val optList = List(Some("xyz"), None, None, None) optList.zip(line).map(x =&gt; x._1.getOrElse(x._2)) 
so first thanks for this. Probably like you, i'm convinced that encoding constraints ("business logic") is best done via the type system, whenever possible. And for this scala is a god-send. In any event, i did a quick first pass but it went a little over my head so i've bookmarked it for when i have a little more time. One question: perhaps i'm generalizing too much from your example, but your example (inventories of hats) seems to be a prototypical use case for _path-dependent types_. Am i abstracting too much from your example (coming up with simple examples to illustrate complex topics relating to the scala type system is never easy)? Or is there a distinction between your use case and the aim of path-dependent types (that i obviously missed)?
A class extending App has a main method. http://www.scala-lang.org/api/2.11.8/#scala.App
Maybe point out that that's the difference then - that you can use arithmetic rather than converting to/from strings. Currently your comment sounds like it's advocating using recursion instead of `map`, which I'd imagine is why it's getting downvotes.
so now i kinda understand CPS, but i still don't understand why anyone would use it. it seems like a readability nightmare much worse than even implicits
akka http is the newer version of spray! It was added to the akka project and renamed!
Nice. I remember I had trouble pattern matching based on the mixed in traits. I guess I could of used WeakTypeTag for that? Something along the lines of this: trait B class A class C extends A with B List[A](...) match { case a: A with WeakTypeTag[B] =&gt; .... } 
Keep in mind that type erasure is not something to "[overcome](http://stackoverflow.com/a/21843984/5431135)." It's actually a _good_ thing.
I imagine the point is that, if you can solve your control-flow problem with Continuation-Passing _Style_, you can solve your problem better by having actual _continuations_. If you want to see how nice that is, I highly recommend working through [this tutorial](http://okmij.org/ftp/continuations/index.html#tutorial).
CPS is kind of an "imperative" solution to async code, where as map/flatMap on monadic structures like Task/Future are a "functional" solution on async code. CPS is basically what governs languages like Go
Recursion is fine, but not an advantage, particularly compared to map. And the community values conciseness - rightly IMO - so you need to give a compelling justification for a longer version of a method. 
This description makes ScalaNLP NER much clearer for me. As a exhaustive guide code from samples can be easily reused as a complex solution. Thanks!
They basically introduced type erasure in order to keep the compatibility with old code (reusing old interfaces etc.). They could have decided to say "look guys, we know it's a pain in the a**, but if you just invest one week to learn how to work with this new generics stuff it will be best for everyone in the long term". This is kind of what .NET did. Instead, they went with the "let's keep as many existing clients happy as possible" solution. Nothing wrong with that, but type erasure is not a good thing. It's a glue to make the old clients happy without forcing them to learn generics. 
No it's not, the only that is debatable is if erasure should have been introduced while still claiming the JVM supports reflection. You can't have both and given the choice I'd choose generics every time.
Yet people keep coming up with ways to do so, e.g. the post, Guava, etc. C# does a better job IMHO, so does Swift, but it has other type issues.
That's probably the best explanation out there, yes, although the link in my OP is also extremely good.
All of which reflect that we haven't done a good job of explaining the value of parametricity, free theorems, Curry-Howard...
I agree. I added a sentence describing that List[Any] indicates an instant design flaw, but it's here just to illustrate the point. 
I learned from Prof. Brent Yorgey's lecture: http://www.cis.upenn.edu/~cis194/spring13/lectures/05-type-classes.html Although the entire lecture is enlightening, I recommend the section, `Two views on parametricity`.
&gt; For what it is worth, my own advice is that libraries and framework developers should always include the slf4j-nop if they use slf4j-api. Definitely don't do this. The error message that SLF4J provides tells a developer that there's some code on the classpath that has some logging functionality but, since top-level applications may opt for one underlying framework over another for various reasons, the library does not impose a choice of it's own. By including the `slf4j-nop` implementation on the path there would be no indication that the functionality is available -- not ideal in it's own right -- but that library is in effect also making that decision for every other library that is being pulled in which uses SLF4J. I believe that the author's analysis is completely off the mark; the end application transitively pulled in SLF4J which fell back to safe default of doing nothing but informs the developer that there's a a potential choice to be made. As a bonus it makes this notification at the point of relevance when the app is run rather than just buried in documentation. It at that point the developer makes the decision that they don't care about logging then they can pull in the `slf4j-nop` dependency to quell the warning. If they decide they do care, then they can pull in the one of the dependencies to enable the logging framework of their choice.
Here are a few. I'm not sure if these are all junior: Understanding immutability, the pros and cons of using persistent, immutable data structures Having no problem using collection transformation functions like fold, map, filter, flatMap, collect, etc. Understanding PartialFunctions/matching Understanding Option, Try, Future, how to map and flatMap over them, when to use them Understanding how to write Algebraic Datatypes using sealed traits and case classes Understanding when to use object methods/values vs classes. Also preferring static, testable functions and composition when possible vs inheritance. Understanding the basics of context bounds i.e. typeclasses in scala
At my previous job developers who were hired for Scala positions were required to know Akka or at least pass [a scala course](https://www.coursera.org/course/progfun) at coursera. At my current job developers required to show ability to learn Scala and Akka. 
&gt; So if some object is a List[Int], runtime will see it as a List[Object]. If it’s declared as List[T &lt;: Vehicle] and is actually a List[Car] at runtime, it will be seen as List[Vehicle] Is this really true? I was under the impression that erasure removes every trace of generics, i.e. `List[T &lt;: Vehicle]` becomes the raw type `List`, whereas `T` references in the erased scope become Object (only reference types are allowed in JVM generics so it lines up.) I also believe, like some people are saying, that erasure **is** a good thing for the JVM as it theoretically imposes no limits (well, except erasure) on how advanced the generic type system of a hosted language can get: If JVM generics were reified, things like higher kinded types would either be unavailable to Scala, or Scala would have to go with a half baked model with sporadic reification.
I would say that type erasure makes the implementation of higher-kinded types easier. Most of the languages with reified generics (C++, Rust, NET languages) are lagging behind on this point. For the JVM, the main drive was probably backwards compatibility, but it's one of the cases where backwards compatibility led to a correct design decision. Edit: that being, apart from this point, I found your post well-written. Most of the time, I write generic code and consequently forbid the use of ClassTag and friends; but in performance critical sections I sometimes revert to the dirty tricks. Still, we should, on average, be moving *away* from these tricks. There are a lot of patterns that play the same role, only safer (type classes at the forefront).
Completely agree. But people "keep coming up with ways to do so" because the safer design patterns are not established (type classes, free monads, ...). They start to be documented now, but mostly in tutorials where they are presented in isolation. How are you going to use them in a medium-sized Scala app? What are the new trade-offs involved (abstraction complexity, runtime, library dependencies, binary compatibility)? Until this knowledge is discovered and spread, tutorials about "Scala as a better Java" have their use.
We use Scala at my company but we don't actually care if our candidates know it already. We use our interview process to see if the candidate is capable enough to learn as they go. We look for people that are just good software devs in general and can demonstrate the following things: they're good at abstract reasoning and problem solving, they have a history of actually delivering projects (internal or external), and that they are easy to get along with and would be a good cultural fit.
&gt;&gt; So if some object is a List[Int], runtime will see it as a List[Object]. If it’s declared as List[T &lt;: Vehicle] and is actually a List[Car] at runtime, it will be seen as List[Vehicle] &gt; Is this really true? [...] List[T &lt;: Vehicle] becomes the raw type List. I think the original text is incorrect. The transformation described only occurs for generic methods.
Regarding bounds, yes, this is what I found in the [docs](https://docs.oracle.com/javase/tutorial/java/generics/genTypes.html). I never really examined the bytecode though. Regarding whether or not it's a good thing, it is highly debatable. Perhaps I should have worded my post (especially title) in a manner which doesn't indicate that it's necessarily a bad thing. I simply wanted to show how to get past it if you need to.
I see your point. Thanks for the observation, I agree and will fix that part.
Glad to help, thanks for the interesting article :) To nitpick, I just came across something &gt; What is type erasure? Well, simply put, it’s a procedure performed by the Java Virtual Machine I'd rephrase this part to state that the Java compiler performs erasure as the JVM specification does not support it.
&gt; Speaking for myself only, the bare minimum is to be able to write Scala - not necessarily idiomatic, not necessarily purely functional, just a solid grasp of the basic syntax. The rest I can teach. As an inverse anecdote, my first job out of school was using Scala. I hadn't actually used Scala before I was hired there, and was hired based on my experience with Haskell and familiarity with pure FP. 
It is not just a rename. In my job we was considering to upgrade our code base from Spray to Akka HTTP, but the amount of changes make it unfeasible at this moment. We are considering to stay with Spray as much as possible for the current code. For new features, we will evaluate to use small new projects (sort of microservices). Spray is really great. Our logic uses state machines everywhere, and Spray fits pretty well on them. But, to be honest, I'm not sure if it was a good decision, given how fast it was deprecated. 
If you could search for symbolic operators.... that would be amazing... example: https://duckduckgo.com/?q=Scala+⊛
Ah right. I need to be more careful (or precise) when writing things like that. Thanks.
So I'm seeing some odd inconsistencies when using infix operators: val elem = "elem" val myList = List("one", "two") elem :: myList //Does DOES work elem.::(myList) //this works too myList :: elem //This does **NOT**work. myList.::(elem) //*must use this syntax instead* So for some reason when the `myList` is first, you can't use the infix operator `::` to add to the list. You have to use the normal function call syntax. myList.::(elem) Why????? Even more confusing as to why this happens: myList :+ elem //works elem +: myList //also works! So what I think is happening: elem :: myList here `::` is a method that belongs to `myList`, which is a `List`. But `elem` has no such method. It seems like when using this infix operator, the `::` is getting called on the object on the right. In this case, `myList`. But if that's true, then: myList :+ elem //this totally works Should not work! `elem` has no such method. So sometimes the infix operator belongs to the right side, and sometimes the left? WTF? EDIT: I think I flipped something around. Gonna go check my IDE EDIT 2: Yea I messed it up first time. Now it's fixed.
I didn't take the time to fully understand your question ( I hope someone do :D). I think these links below could help to give some direction to your research. http://docs.scala-lang.org/tutorials/tour/implicit-parameters http://docs.scala-lang.org/tutorials/tour/implicit-conversions http://blog.scalac.io/2015/05/21/dynamic-member-lookup-in-scala.html
Instead of a `List[List[String]]`, parse the file into more meaningful types and use a map to look them up. Something like case class Service(name: String) case class User(name: String) case class Password(text: String) case class Credentials(user: User, password: Password) val serviceCredentials: Map[Service, List[Credentials]] = ???
Terrific write up, thanks!
I would expect someone to be able to do a lot of the 'easy' problems in '99 scala problems' on a white board with a bit of help and plenty of time. 
Infix applications can be confusing. The [spec](http://scala-lang.org/files/archive/spec/2.11/06-expressions.html#infix-operations) contains some pretty ad-hoc rules, of which one of them is: &gt; The associativity of an operator is determined by the operator's last character. Operators ending in a colon `:' are right-associative. All other operators are left-associative.
Part of the issue is that since an actor is doing the polling this means its not on the thread that the test suit runs, so the test suit will finish running before all of the polling takes place. 
If you can get through the medium difficultly problems on HackerRank.com you're in a good place.
What city is your company in?
Thanks! Yes, that's the same talk from a different date/venue. The F# code I mentioned is shown starting at [8:28](https://youtu.be/FiflFiZ6pPI?t=8m28s) and the Scala code appears at [11:31](https://youtu.be/FiflFiZ6pPI?t=11m31s). It looks like in that earlier version of the talk there was a typo in his slides. He also didn't talk as much about the implicit versus explicit quoting there as he did when I saw the talk, though he did mention that type inference is involved, which I don't remember being mentioned.
Seconded -- if you're writing a framework and you have any kind of end users who will add their own libraries, then you should not be including an SLF4J implementation. That should only happen at the very end of the chain. 
There is a limit on the constraints you can express at the type level (Scala's type system stops at path dependent types), and there is a limit on what you can enforce without a huge amount of boilerplate. For example, try the following simple problem: express that the length of the sequence `x ++ y` is the sum of the lengths of `x` and `y` at the type level, when the lengths of `x` and `y` are not known at compile-time. Anyway, all these impure methods `.apply`, `.head` ... can be forbidden using an automated style guide checker.
&gt; I don't understand what you mean by "quoted". It seems like the F# code is implemented with what would be the equivalent of macros. Quoting and macros are related, but are not quite the same thing. Macros are a way of programmatically constructing part of your program's syntax tree, while quoting is a way of having part of your program's syntax tree that would normally be code be treated as data data. They're often used together, as (quasi)quoting code fragments is a convenient way to tell the macro system what to insert, but my question only involves quoting, not macros. &gt; Your scala code isn't just pure scala (in terms of only using the standard library). I assume you're using Slick. It isn't really my code. See the linked slides, or the talk linked to from other comments. &gt; Slick uses macros and shapeless to do its type level programming. Also implicit conversions. I'm asking more about the resulting behavior rather than how the implementation is partitioned between various libraries. Your mention of implicit conversions makes me suspect that it treats the rhs of: val youth : Rep[ List[{ val name : String; val age : Int}]] = as an unquoted expression, and then only quotes it when the type doesn't work. I'm wondering if there are cases where that can lead to ambiguity, where you want the quoting but didn't get it because the unquoted type was also compatible. I'm also still wondering how the splicing part of this works, especially the ambiguity that might arise if `DB` and `Rep[DB]` have fields with the same names (and possibly even types).
Thanks. I'll read through those.
&gt; support implicit conversion from the normal value types we care about (eg: Int, Boolean, etc.) The operations are performed `Rep` against `Rep` so there's no implicit conversion happening. The only implicit involved is providing *evidence* that 2 `Rep`s are equivalent (and can therefore be added, compared, etc.). &gt; How does the db.people in the original snippet work I don't use Slick, but my limited understanding of how the library works is that `people` would represent a db table and have a type similar to `Query[Entity, Mapping, CollectionType]`; i.e. a `Query` represents a Scala Entity (typically a case class) a Mapping to/from table columns and their underlying primitive type (Int, String, Boolean, etc.), and the result type of a given query operation. `Query` then, being a monad, supplies various query-like collection methods (flatMap, map, filter, groupBy, etc.) that build up the AST. Here's the [definition of `Query`](https://github.com/slick/slick/blob/master/slick/src/main/scala/slick/lifted/Query.scala). I as well would like to understand the library in more detail. How do `Rep`s relate to `Column`s? Is `Rep` the base type of tables and columns, or is `Node` the underlying base type? How does `Shape` relate to Entity and Mapping? Slick is an impressive piece of engineering but I find it difficult to grok the internals.
&gt; The operations are performed `Rep` against `Rep` so there's no implicit conversion happening. I thought that in your example: age + 1 &lt; 30 `age` had type `Rep[Int]`, but `1` and `30` just have type `Int`. The `+` and `&lt;` in your simplified implementation took a `Rep[Int]` as their second argument, so I assumed that something must be coercing `1` to a `Rep[Int]`. &gt; The only implicit involved is providing *evidence* that 2 `Rep`s are equivalent (and can therefore be added, compared, etc.). I think this relates to part of the code that goes beyond my comprehension of Scala. &gt; I don't use Slick, but my limited understanding of how the library works is that `people` would represent a db table and have a type similar to `Query[Entity, Mapping, CollectionType]` Where/how is the `people` field defined? *Is* there actually a definition for `people`, or can you just access arbitrary field names on a `Rep`?
You could create a fake resource that will respond to a poll by counting down a countdown latch, which your assertion will await for.
The biggest stop for me was the absence of a decent functionality of DDG without javascript. It was there a couple of years ago, but has been broken later. I moved on to searx engine. ( https://github.com/asciimoo/searx ) If DDG would be able to provide non-js functionality back - that'd be great, people love alternatives.:)
oh i did not know that! Could you explain what you do to distinguish what to unquote vs what not to unquote? even if tou're explicitly quoting the stuff this seems like a decision you'll need to make
Link seems to be down :(
Seems to be fine on my end, are you able to access other medium.com posts?
Are you using iOS app ? There seems to be an issue with the app for medium links . I never successfully opened a medium url in the app
&gt; We hire smart engineers that know their data structures and algorithms. The problem with that for me is that there is more to software development than data structures and algorithms, and some people (like myself) are really bad at data structures and algorithms (wtf is quicksort again) but really good at other things (here is the distributed architecture for how I would do this application. Here are UML's. This is a 5 step plan. And here are the books/tutorials I plan to do in order to know what I need to implement this thing). For me, some things that seem absolutely trivial (what is the name of that function. I don't have an IDE) are hard for me and some things that other people struggle with I find fun/easy. There's more to implementing a software project than data structures and algorithms.
This goes back to what I said to rodrigosetti The problem with that for me is that there is more to software development than data structures and algorithms, and some people (like myself) are really bad at data structures and algorithms (wtf is quicksort again) but really good at other things (here is the distributed architecture for how I would do this application. Here are UML's. This is a 5 step plan. And here are the books/tutorials I plan to do in order to know what I need to implement this thing). For me, some things that seem absolutely trivial (what is the name of that function. I don't have an IDE) are hard for me and some things that other people struggle with I find fun/easy. There's more to implementing a software project than data structures and algorithms. 
The important thing is how the interviewer helps you. I think i've seen enough of your comments to know that with a bit of prodding and friendly nudging we could get you to say, reverse a linked list or implement a map function on said list. Believe me, I also clam up and start going down the wrong track often when asked to do something on the spot. A lot of it is if the interview makes it feel like he/she is helping you vs. judging your every thought. The "easy" 99 scala problems aren't really 'algorithmic' trickery, they're just sort of writing a few lines of code. They should take between five and ten minutes. Under pressure of an interview, I wouldn't expect anyone to do them in under 30 minutes (though I have seen people answer them in a couple minutes) *with* my help. 
Very interesting. So simple! Why do every library out there keep inventing NonEmptyList as a new class/type? cats, scalaz, scalactic (scalatest), + lots of libraries all make their own implementation of non empty lists. I mean, I really appreciate their efforts, but if this can be done _this_ simply, then it really should. Having so many implementations of non empty list on top of the standard library's List-type is confusing. I'd almost rather not have the non-emptyness guarantee. I also like this solution for another reason. It's still just a List, but with an additional compile time type information that it's non-empty. So any method that expect a List as its input, can take a ::() as its input (obviously) - unlike custom classes/types that you might have to call .toList on first to convert it back into a scala List
And thanks for the thoughtful response. You're right that path-dependent types would have been completely suitable for this example. That said, the example was definitely oversimplified. The code that originally led me to document this had parameters further down (eg the parallel for the Size type had it's own parameters) and in those contexts path dependence can become too specific. Here's a simple example of a case where you might need more control than path dependence gives you - https://gist.github.com/beezee/8eb90cb44b9a3b1e7928bcbd5f5d2b02
Why don't we generally use final with case classes as default? Usually I see just case classes...
It's actually very simple: the unquotation is done by an [implicit conversion](https://github.com/getquill/quill/blob/master/quill-core/src/main/scala/io/getquill/package.scala#L29) from `Quoted[T]` to `T`. For instance: val q1 = quote(query[Person]) val q2 = quote(q1.filter(_.name == "test")) is equivalent to: val q1 = quote(query[Person]) val q2 = quote(unquote(q1).filter(_.name == "test")) This means that any code within a quotation will be quoted and runtime values can't be used directly. The current release requires [parametrized quotations](http://getquill.io/#parametrized-quotations) to enable binding of runtime values when `db.run` is called. We're currently working on allowing [lifting of runtime values](https://github.com/getquill/quill#bindings) in any part of a quotation as well.
I suspect for the very trivial reason that it's an extra word to type. 
Create the actor and have two distinct streams, one with the actor as a sink (the "first half") and the other as a source. In general for any pipeline-like scenario you shouldn't need to do that though - the only reason to use an actor as a source or sink is to integrate with some more complex flow that you can't model by streams. What are you actually trying to do?
Trying to understand a large codebase by reading unit tests is like trying to understand an animal by looking at its cellular processes. You may be able to eventually put together a coherent picture, but it's definitely the long road to understanding.
Your requirement is the decimal expansion of the number in Base 10. It is lucky that `toString` provides this (except that each integer instead has a `Char` representation). You can make use of this similarity as you've done. It just happens that your requirement, and the String output use the same base (well, not just, it is by far the most used base for human consumption of numbers). A more general formulation would follow something similar to what /u/cathalmc suggests below, since it can work for any base, not just Base 10.
Your solution works in my case (I think, at least that's how I was trying to do at first), but the code gets a bit ugly. I want to read a csv-like file format where I can have some special "header lines" in the middle. I'll try to give you a toy example (sorry if it is a bit convoluted): Imagine that I have the following case classes: sealed trait Profile case class OldProfile(name: String, email: String, password: String) case class NewProfile(displayName: String, loginName: String: String, passwordHash: Long) And I have a "csv-like" file format that, in each line, either has a profile or the type of the following profiles: old-profile Anna, anna@gmail.com, password123 new-profile Bill123, Biil Gates, 86984712536847 old-profile Alice, alice@gmail.com, SuperSafePassword Bob, bob@gmail.com, UnsafePassword Using an actor, I can change the profile loading strategy with a simple `context.become` when I get a `"old-profile"` or a `"new-profile"` message. Otherwise, I think I would need to store a `var` with the current profile loading strategy.
&amp;nbsp; I hadn't thought of reading the git log. If you start at the beginning, the git log gives you an idea of what order the code was written in - what code came before what. &amp;nbsp; Assuming that everything was written gradually and without breaking whatever came before it, the later stuff should be dependent on the earlier stuff.
FP with types is sufficiently different that I think this book will end up being very helpful. Might also look at Dean Wampler's *Programming Scala (2nd Ed.)*? It's a good modern survey of the language that might give you some footholds.
I would not worry about it. There will always be parts that you don't understand. Make sure if you encounter something unknown structure (if you are not familiar with scala / libs) to learn it, otherwise just try to implement what the business wants. 
Right, which is why I wrote about characterization tests. I just meant the obvious: "don't break the unit tests." On the other hand, if you write characterization tests that subsume the unit tests, and your refactoring changes the implementation such that the unit test breaks, that's when you remove the unit test, since it's no longer relevant.
You say that as if there's an better alternative to this long road.
I think not all programmers would agree to try clean the mess, especially if there is an alternative opportunity and you can afford changing position/project. I'm in my 20s and I would definitely try change the project to something more fresh and modern. The golden rule for me is that I work on project if it teaches me something new or I really like it.
I'm not sure this is a good recommendation but to the extent that any of what I learned and use in Scala on those topics is in a book, that book is *ML for the Working Programmer*.
No it wouldn't, and your implication that those words are synonymous shows you have an incomplete understanding of those concepts. 
So Eq from Haskell... I like it!
Thanks. All good ideas. I'll join both of those groups. I reached out the local Scala MeetUp group, but haven't seen much happening. http://www.meetup.com/boston-scala/ 
Are you a developer yourself?
Yes.
Where have you posted to job? Do you work with any local head-hunters?
is it anything interesting?
My advice - hire a good generalist software developer and let him/her pick it up on their own. For a good software developer learning new language takes ~2 weeks, and he/she would be grateful to you for giving him/her a chance to prove themselves. I think that people tend to be very nearsighted when it comes to hiring when they insist on candidates having THIS VERY MINUTE EXACT skill. And this, IMO, just shrinks pool of candidates, but doesn't improve overall quality of your workforce. 
Nothing public, and I'm never quite sure whether what I do qualifies as proof - maybe I'm missing something - but as far as I can see it does. Evidence values represent facts, methods represent theorems, you pass everything to where it's needed almost like CPS. If you've got an example of something you want to prove about your code, and the proof of it, then I could try to take a look and apply the technique I'm talking about. 
I have no problem with DDL and migrations. But I'm used to have it fully automated with Doctrine and feels weird writting it by hand.
I don't use Play but in a similar context I've used Liquibase with Hibernate - Liquibase can generate a diff between your Hibernate classes and your current database. (Many people don't like Hibernate from Scala, but I've found it to be the best of a bad set of choices).
It's important to note Play isn't doing the persistence, and doesn't actually need persistence to run at all. Play does HTTP, and everything on top of that is plugins. There's a Play project template that uses Flyways to run migrations for you -- as far as being handwritten DDL, you can use whatever works for you. https://github.com/playframework/play-isolated-slick
I've used Java EBeans plugin and it manages the evolutions. It makes for weird code when mapping forms in scala but otherwise works fine.
Awesome - thanks!
Here is the link to the job posting: https://www.emkinstitute.org/about/careers/softwareengineer We are a new museum that uses Android Nexus 7 tablets, running a custom build to talk to our JVM platform servers. The visitor can scroll through information and in some exhibits vote on a bill interactively with other visitors. We also have a simulated US Senate experience. Students become a historical Senator or a current one, depending on the bill, and they go through the process of passing amendments, debating, voting, using the tablet to help in the process. We have the only replica of the Senate chamber, so it is very immersive. The developer on this project, and others, would have a great opportunity to shape the experience, fix bugs and game logic potholes, and be a part of a mission-based organization.
I agree with the sentiment of dimacq above. I have heard that anyone with decent javascript experience would be useful here. I may go down that route soon...find someone with curiosity, energy and initiative and give them lots of room to grow.
FTR case classes with `var`s are possible (if a bad idea) and will have setters.
I think this is really cool. Have you been able to approximate the performance of this solution? Curious to know if it's fast enough or dirt slow..
2 years to pick up a language is insanely long. A developer should in 2 weeks be able to pick up a language from scratch and develop a non trivial project. Within a month they should easily be contributing code.
I don't really understand what Dotty is or why I should care about it. Is it just a new Scala compiler, and if so, why the new name? Why do some people seem so worried about what it means for the future of Scala?
The meetup used to be a lot more active. For the last year or two the meetings seem to come in spurts with a several month hiatus.
Your post is really well-written, good job on that! But the fact that the point is illustrated by a contrived example means that it's unclear how useful `ClassTag` and others really are. I have been slowly been convinced over time that there is *less* of a need for reflection / runtime type information than I might have thought about a few years ago, coming from Java (see also [Why is ADT pattern matching allowed?](http://typelevel.org/blog/2014/11/10/why_is_adt_pattern_matching_allowed.html) linked below as well). It'd be nice to see how many *non-contrived* use cases there might be of knowing at runtime that you have a `List[Foo[Bar]]`, if any. 
I have some formal interface specification in a different language (think for example of a Swagger API specification written in YAML). I now want to generate the glue code needed to provide or access such an interface. My idea is to annotate an abstract class or a trait with an annotation, taking a string with that specification as a parameter. I will then provide a type provider as a macro, using macro paradise and white box macros. This macro will then inject the necessary method definitions (and when needed the glue code) into the class or interface. The developer can then implement the trait or inherit the class and overwrite the methods needed. This will be especially easy with the existing IDE support to create the code for overwriting or implementing methods. At least for IntelliJ I will also have to provide a small IDE plugin that tells the IDE about the the type of the code the macro injected. Is this a reasonable approach? Anything I forgot? Is there a better or easier way?
Dotty is a research project for the next version of Scala. Some of the ideas may be folded back into the existing Scala codebase, it maybe be that Dotty just becomes Scala 3.0. How we will get to the next version of Scala isn't quite decided yet. Some people argue that the work of Dotty is overshadowing maintenance of the existing Scala compiler, which is more or less nonsense to me. Work on Dotty is work to improve Scala.
Thanks! From one of the examples: &gt; A quotation can be a simple value: &gt; &gt; val pi = quote(3.14159) &gt; &gt; And be used within another quotation: &gt; &gt; case class Circle(radius: Float) &gt; &gt; val areas = quote { &gt; query[Circle].map(c =&gt; pi * c.radius * c.radius) &gt; } How does `quote` know to get `pi` from the unquoted environment? And where is `c` coming from? Do you have an explicit notation for splicing in values? Out of curiosity, why did you choose to go with explicit quotation? I know Wadler also expressed a preference for this (and I lean in that direction as well), but did you try implicit quotation and then abandon it for some reason? 
As others mentioned, the meetings happen more erratically now, but every time I've gone in the past few years, the meetings have been very well-attended, sometimes to the point of needing a waiting list, and have been full of people working with Scala and those who'd like to. I've written Scala in the Boston area for a few years now, and now it seems most of the recruiter contact I get is via Linkedin, though that may have more to do with Linkedin's tags and search features than anything else.
Is there a way for a macro to generate files alongside the output class file, for use with `Class#getResource` at run time?
&gt; Work on Dotty is work to improve Scala. Usually, work to create the next version of something and work to maintain the existing version are two different types of work. Focusing on one to the exclusion of the other is possible.
Do consider just generating code with a program. It's inelegant but probably faster than hooking up a macro like that. 
&gt; How does quote know to get pi from the unquoted environment? `pi` is of type `Quoted[Float]`. There's an implicit conversion from `Quoted[T]` to `T`. For instance: val areas = quote { query[Circle].map(c =&gt; pi * c.radius * c.radius) } After implicit resolution, it becomes: val areas = quote { query[Circle].map(c =&gt; unquote(pi) * c.radius * c.radius) } &gt; And where is c coming from? `c` is the param of the `map` function. &gt; Do you have an explicit notation for splicing in values? Currently, the quotation must contain only quoted terms. Runtime values must be used through [parametrized quotations](http://getquill.io/#parametrized-quotations). The next release will support [lifting](https://github.com/getquill/quill#bindings) of runtime trees within quotations. &gt; Out of curiosity, why did you choose to go with explicit quotation? I know Wadler also expressed a preference for this (and I lean in that direction as well), but did you try implicit quotation and then abandon it for some reason? I haven't tried the implicit approach for two reasons: - I prefer to make more explicit what's being quoted - It wouldn't be possible to compose [compile-time static quotations](http://getquill.io/#compile-time-quotations) using explicit types. Basically, static quotations in Quill are both compile-time and runtime values, that's why Quill is able to generate the query at compile time. I tried a third approach in the beginning making the DSL methods macros (`query`, `flatMap`, `map`, etc) and not requiring explicit quotation. It'd allow declaring the quotation this way: val areas = query[Circle].map(c =&gt; pi * c.radius * c.radius) but I hit two main problems: - compilation-wise the performance is much worse because each method call is a macro call and requires lifting and unlifting of the AST - It makes it very hard to reason about what's being quoted
What's the salary range?
&gt; &gt; How does quote know to get pi from the unquoted environment? &gt; &gt; `pi` is of type `Quoted[Float]`. There's an implicit conversion from `Quoted[T]` to `T`. For instance: &gt; &gt; val areas = quote { &gt; query[Circle].map(c =&gt; pi * c.radius * c.radius) &gt; } &gt; &gt; After implicit resolution, it becomes: &gt; &gt; val areas = quote { &gt; query[Circle].map(c =&gt; unquote(pi) * c.radius * c.radius) &gt; } I still don't understand how it knows that `pi` should refer to the local variable. In Scheme if I had: (let ((pi (quote 3.14159))) (quote (* 5 pi))) The the result is `(* 5 pi)`. The `pi` in the second quote form is just the symbol -- it doesn't reference something in the enclosing language. So how is Quill deciding that `pi` refers to a Scala name? Does it just choose to bind any unbound symbol in the AST to the corresponding symbol in the enclosing environment? &gt; `c` is the param of the `map` function. Gah. Yeah, that shows how rusty my Scala is. I didn't even notice the `=&gt;` in there. Thanks so much for all of your answers to my questions!
Sorry. What is the best cloud host to keep a web app in Scala as type safe as possible with minimal configurations outside of Scala and Java? I would like to write cool web apps in Scala while keeping the system configuration files and other untyped files to a minimum. 