I'd like to answer that, but I'm not sure if I understand and if you could give me some code sample or pseudocode, that would be helpful. Splitting and joining streams is what Rx on the whole does, but maybe I'm misunderstanding you. I can tell you what Monifu is being used for in production. We are gathering signals coming from industrial machines, from multiple sources and then analyzing them in real-time. These signals are used to model state-machines that reflect the behavior of those machines on a per-machine level, creating streams of higher-level state updates that then get signaled to other micro-services, like another component that monitors and controls those industrial machines as an aggregate, like it's a big virtual appliance. In the process we're doing plenty of splitting and merging. It's not automatic though. And for example Monifu doesn't handle the actual communication between the nodes (Monifu is not even being used in all components). For the actual communication we are still using Akka actors or WebSocket connections, though Monifu does handle the back-pressure side according to the reactive streams protocol and also the buffering. I just published yesterday [a sample](https://github.com/monifu/monifu-sample) that shows 4 server-side streams being merged in one graph on the client-side, with the server-side implementation being based on the Akka actors support in Play framework, exposing Monifu Observables on that WebSocket, then consuming them client-side. But then, after you take care of the protocol for that communication between nodes (which might very well be Akka-based), you don't care from where that data is comming from and then you can merge it and split it and send it somewhere else. I'm not sure if that answers your question, but btw, there's a Gitter channel available and you can also ask questions as GitHub issues. I mean, if you have a specific use-case in mind, I can probably help out.
TLDR **Monifu** sample is consistently beating Akka Streams by at least a factor of 7 and RxJava/RxScala by a factor of 2 - for the lazy ones: USE IT instead of Akka Streams/RxScala, it is better
Of the things you mention, several are also supported by Kotlin: * [Infix Methods](http://kotlinlang.org/docs/reference/functions.html) * [Operator Overloading](http://kotlinlang.org/docs/reference/operator-overloading.html) However, while not a popular thing to say on this subreddit I suspect, I do prefer Kotlin over Scala. It's simpler, I think more thoughtfully and pragmatically designed, and has excellent IDE support (at least if you use Intellij). It also has some super-useful features that Scala lacks, like implicit casts, and zero-overhead null-safety.
Operator overloading is (fortunately) pretty limited compared to Scala.
Your first question can be answered by the following snippet: import monifu.reactive.Observable import monifu.concurrent.Implicits.globalScheduler val x = Observable.fromIterable(1 to 5) val y = x.map(_ + 1) val z = x.map(_ - 1) val a = Observable.zip(y,z).map(r =&gt; (r._1 + r._2)/2) a.dump("zipped").publish().connect() x.dump("original").publish().connect() with the outcome: 0: original--&gt;1 0: zipped--&gt;1 1: original--&gt;2 2: original--&gt;3 3: original--&gt;4 1: zipped--&gt;2 4: original--&gt;5 5: original completed 2: zipped--&gt;3 3: zipped--&gt;4 4: zipped--&gt;5 5: zipped completed So the answer is yes, they will emit the same elements and the order they're emited in is the same, but you can't expect for them to be emitted at the same time as they're basically different data sources. 
Hi Noel, Yes, zip behaves exactly as you'd want it to behave. There is also no diamond there. Monifu will never, ever blow out the stack. This isn't Scalaz :-P ; for `zip` in particular, if you'll take a look at the implementation, we take the value of the first source that emits, then we apply back-pressure until the second one emits. There is no glitch to speak of. Schedulers are enhanced execution contexts (the Scheduler inherits from ExecutionContext). They can be anything you want, as long as they give you the possibility of scheduling tasks for asynchronous execution. Monifu always starts to execute tasks asynchronously and will not freeze the current thread (except in cases where the operation is really fast, like Observable.unit). The implementation of "map" is not doing asynchronous execution, as "map" is inherently synchronous. This doesn't mean that all events passing through "map" are handled on the same thread, this being the responsibility of the upstream source that is pushing events through "map". On the other hand, there are operations that are inherently asynchronous, like concat/concatMap and some operations are inherently concurrent, like "zip" or merge/mergeMap. It's there that the Scheduler is being used. You will also not see schedulers being taken as parameters by the Observable operators because Observables are pure until you "subscribe". That's the sane way to do it and it's one thing I don't like about `Future` sometimes. It also makes `Observable` compatible with any Monad or Applicative Functor implementation you want. And before you ask, `flatMap` also behaves as you'd want it to behave. You've taken Ronald's comment too literally. The whole purpose, the raison d'etre of `Observables` is to help you handle concurrency with higher level abstractions. Basically if you like Future, then Observable is like a Future on illegal steroids. I also disagree with Dr. Ronald, I actually believe that the Rx approach coupled with my improvements lends itself to better parallelism, but then I'm more the get down and dirty type of guy. I'd love to be proven wrong though. On your Kleisli vs Monad comparison, let me give you a counter argument. As a younger self I learned to trust my nose and thus I avoided making many bad choices like what other people made, for example things like XSTL, ASP.NET, Wicket, EJB, Hibernate or other technologies built for demos. You could sort of feel when something sucked, if only people trusted their nose more. I lack the education into what Kleisli is or how it's applied to programming, I guess that it is about composition for monads. I assume that since most FP solutions that came after monads are about composing monads, since this is the Achille's heal of FP. That's a fine comparison, but my perspective is different. I believe in simple (non-complecting) and powerful solutions that are built for the real world. For example, I'm much more inclined to believe in the usefulness of Clojure's *Transducers*, than I am to believe in something that is about flow graphs that need an actor materializer. And if there's groundbreaking work happening in Akka Streams, then it needs to be distilled into something simpler first.
how would scalaz actors be applied to the functional reactive model? can you give an example?
&gt; Perhaps the performance optimization is not to implement a local database? And it's not a local database, it's actually a replicated database, with that replication leading to some of their performance issues. Yes, but at this point we are just being pedantic &gt; Yes. We are one of those companies with our in house spark alternative because of these issues that I specifically call out. If there weren't these performance issues, then you wouldn't have companies implementing their own alternatives, and blog posts from twitter talking about their alternatives. I am not questioning that. What I have an issue with is you scapegoating this issue as some sought of style guide problem. Its evident that you have an issue with their style (as do I, which I have stated numerous times), but call a spade a spade, and say that you have an issue with their style. Instead you are trying to do this wishy washy thing were you are correlating their style with their performance, which isn't helpful and doesn't get anyone anywhere. I mean you can use that argument if you want, but in reality it will probably have the opposite effect of what you want (improved performance). Spark having performance issues is not something thats the end of the world (and it may be due to a number of things, such as their design having some weakness's in certain scenarios) 
My startup is in Bay area. Please send a message to me if you are interested in this position.
We are a startup so there is no enough resources to train a programmer.
Currently Akka Streams does no more parallelism than Monifu. And in that sample Monifu is not single-threaded. See update at the bottom of the article (you might need to force refresh, Ctrl-R on Windows/Linux, or Cmd-R on OS X). 
I have read the response, it doesn't invalidate what I said. Akka Streams was designed to be fully backed with akka actors in mind, and they haven't implemented fusion (yet), hence why there is the performance gap &gt; Currently Akka Streams does no more parallelism than Monifu. No, but akka-streams makes it a hell of a lot easier to make your non parallel code parallelizable due to how akka actors work (in combination with `.conf`/`ActorRef`) since its parallel from the start. Its not a question of whats possible vs what nots possible. I mean, this is the whole point of Akka in the first place. Its not that Akka allows you to make code that wasn't parallelizable suddenly parallelizable. What Akka allows you to do, is that if you make your code use Actor's (either directly, or indirectly), its incredibly easy to alter to the code to work between single processors on your CPU, to clusters on a network, usually by just configuring/providing a `.conf` file and/or adjusting how `ActorRef`'s are created. Also note that I was mainly responding to this comment &gt; 2 - for the lazy ones: USE IT instead of Akka Streams/RxScala, it is better Which was deceitful in its premise
&gt; Akka is not about parallelization, but about dealing with concurrency. These are very distinct notions, concurrency being the opposite of parallelism I wouldn't argue that parallelism is the opposite of concurrency, but it seems like I/we have intentionally conflated terminology &gt; Again, linked notions. And nothing prevents you from doing the same thing with Monifu. Actually, nothing prevents you from piggybacking on top of Akka actors while doing so with Monifu, as I've shown in this sample. I made this point before, its not a black and white, i.e. possible vs not possible. You can code a website in brainfuck if you want, that doesn't mean its a good idea. The central point about akka, which I mentioned before, is that its very easy to scale your concurrent code horizontally without having to **actually modify your code**(or in some situations, **changing how ActorRef's are set up**, which doesn't usually deal with your business logic) even if **you have coded your business logic to just use a single core**. I am not sure if this holds water with your library on Monifu, although happy to be proven wrong &gt; PS: On that promise you're saying it was deceitful, that wasn't me saying it, but somebody else being enthusiastic. The general tone of the that comment was definitely leaning on the "don't use this library, it is bad" more than anything else. I don't have an issue with someone making claims about that, but at least be objective about why. It was deceitful because the person used a benchmark, without putting things into context (i.e. if he read the replies on the article)
OK, I'll grant you that concurrency is slightly overloaded. A definition I like is that in programming concurrency is the composition of independently executing processes. Composition, as in having multiple processes [contending](https://en.wikipedia.org/wiki/Resource_contention) on the same resources. Whereas parallelism is the simultaneous execution of multiple processes. The issue is that when processes are contending on the same resource, they can't run in parallel. A metaphor I like (heard it from somewhere else) is that 100,000 people can watch the same football game at the same time (parallelism), but those 100,000 people can't all use the same bathroom at the same time (concurrency). Hence in software engineering we jump from portions of logic that are parallelizable, to portions in which the processes become concurrent and contention happens. Of note here is [Amdahl's Law](https://en.wikipedia.org/wiki/Amdahl%27s_law), my favorite law in the universe :-P I do have one question ... &gt; **you have coded your business logic to just use a single core** What in the world gave you that idea? This is not true, I already explained it, I already replied to your whole comment, I gave you a pretty good code sample of client/server communications. Please look at that, instead of referring brain-fuck. I'll be here to help you understand, but I can't argue against a marketing brochure.
What drove the change? 
I got the same errors but it still installed fine and appears to run fine.
It doesn't really work on windows https://github.com/lihaoyi/Ammonite/issues/119, though there is hope we could get it working. Give it a shot on ubuntu or OSX and see how it goes!
Yes, but the difference is, in maths you can create your own universe that is a subset where the operator only means a certain thing. In programming, you can't really do that. I mean you could, but then the only thing your program would be able to do is something like add numbers (and only add numbers). Maths has the liberty of being able to define whatever universe they want, and thats because its so abstract. General programming doesn't really have that liberty
Your help is welcome =) I don't have a windows device and windows expertise. If you could help make Ammonite work on windows by default that would be amazing. Windows, more than anything, needs a reasonable shell. 
@mdedetrich, for one thing, Akka also has issues that you need to solve by yourself in its communications over the network. For one, my sample is implementing back-pressure, whereas Akka actors don't do that. My sample is using a buffer of events that starts dropping events on overflow. Akka actors don't do that until the latest 2.4 (not stable), where they finally added a new mailbox type that does it and this was for me a surprise, as it's something really obvious to do. Akka actors are pretty cool, but fairly low level. &gt; That sample you showed me was explicitly coded for server/client, akka code is automatically implied to be server/client You're wrong about this. It is true that Akka's selling point is that it doesn't matter whether the actors you're communicating with are in the same process or spread over the network. Monifu claims the same thing - my sample is in fact showing that it doesn't matter where the producers or the consumers are on the network, you still have the same API, same as Akka. That I had to build the logic for actually communicating over web-sockets, well, not even Akka works without importing akka-remoting in your project. Plus I managed to do that and introduce logic for reestablishing the connection in a couple of lines of code and that's quite the accomplishment. You seem to be under the impression that Akka is designed for parallelism on the network. Akka is not Spark, but then I can't argue against a marketing brochure, as marketing brochures are not falsifiable. &gt; *If someone showed me a sample of Monifu code, that they coded just to work on a single core (or assuming that it only works on a single core), and then I asked them to scale out that code to 10 nodes on Amazone ECS, would you be able to do it without rewriting the business logic* Yes and no. What I've been trying to tell you is that you've got the exact same limits as with Akka. The exact ones. Monifu parallelizes what it can, but it cannot parallelize logic that cannot be parallelized by its nature and I'm not going to be disingenuous to claim otherwise in order to sell snake oil. Akka Streams can't do that either. Take a look again at the sample in the article. See that `merge`? That's not an operation that you can parallelize. See that subsequent `scan`? That's also not an operation that you can parallelize. See that `throttleLast`? That's also not an operation that you can parallelize. We are talking about fundamental stuff, about the limits of computer science, ok? But again, that Monifu sample does not run on a single core. It will in fact jump cores for one, since it's using a thread-pool and it can use 4 cores in parallel, one for generating random numbers, two cores for processing that split and another one for the merging. So 4 cores. Same as freaking Akka. On Dr. Ronald's comment, I haven't argued much against what he said, because, having implemented a fully functional implementation, I know what he's talking about. But just as notes (1) you're misinterpreting his words, as he's talking about the design approaches, not what came out of it and (2) Monifu has different design goals than Rx.
1) we really like the DSL to create routes from Spray/Akka HTTP - flexible &amp; elegant 2) fully asynchronous, fitting in nicely e.g. with Slick 3) library, not framework: lightweight, no need for containers
As a follow-up, I've started using zinc, and it's great. Thanks, @blarg_industries!
I actually agree that Akka actors should be untyped and that's because they need to model state machines in an asynchronous and concurrent environment (context.become). You can't model state machines like that in current type systems, plus actors can expose different APIs depending on whom they talk to. So without modeling this, the set of all messages that an actor can receive is often as interesting as Any. At this point I think we can agree to disagree. Moving on to other things, I saw you are attempting a Joda DateTime port to Scala and Scala.js. Just wanted to say that would be very useful.
https://github.com/finagle/finch Finch is also cool. I've never used it, but it does some cool Reader monad stuff to give you the context.
Slightly related - which of these support websockets out of the box? I know Play does but, what if I don't want a full blown framework? I love finch but finch does not support websockets out of the box.
The "correct" way according to the HTTP-spec is to send the [Location header](https://en.wikipedia.org/wiki/HTTP_location): respondWithHeader(HttpHeaders.Location(Uri("https://www.google.com"))) { complete(StatusCodes.Accepted) } edit: use StatusCodes.Created if you're redirecting to a resource you created as an effect of the original request.
Someone posted this a little while ago: https://github.com/gvolpe/light-play-rest-api
First of all, it really depends on project. Do you need a full featured MVC framework or a simple library is enough? Do you need web socket support? Is this project a fun project or very serious production application? Since there are lots of unknowns about project, I'll give you my personal thoughts. * **Scalatra** and **Finatra** - I *don't* like sinatra inspired frameworks. Scala is *different*, the way of doing things in scala is *different* so what is the point of ruby-like frameworks? However, the framework behind Finatra, Finagle, is very interesting. You should read the paper [Your Server as a Function](http://monkey.org/~marius/funsrv.pdf). Services and filters are simple yet powerful building blocks. * **Akka-HTTP** - is new Spray. It fixes some parts of spray but it is still experimental and its documentation is incomplete. I don't recommend it. * **Play** - is full featured MVC framework with great documentation and community support. It is great for big and complex projects and I recommend it if you need to develop more than REST API. For simple REST APIs, it is overkill. * **Spray** - I like spray! I started Scala development with spray in 2 years age and it was fun experience. It was simple enough and work well with akka. I must warn you that there are lots of magic happening behind the scenes and it may get very confusing for new comers especially when you had an error. After 2 years, I work with spray on my current project and I really appreciate its design. I admit in behind there is implicit hell but in front directive composition and custom directives are great tools for DRYing your code in a type safe manner. So there are my personal thoughts and I hope it helps!
I did some good stuff with scalatra. The code is clean, concise and performs pretty well.. Even with some more advanced things, such as a custom handler for HTTP Authorization, it allowed me to solve the problems cleanly.
 redirect("https://www.google.com", StatusCodes.SeeOther) SeeOther is probably the status code you want... see [this document](http://www.w3.org/Protocols/rfc2616/rfc2616-sec10.html) for details. You certainly want something in the 300s, 201, or 202.
Depend on the project, but if I can I choose **Scalatra**, I love the syntax (it's come from ruby sinatra framework, but who care, it's more verbose than spray, and you can found the route in the right place) , have swagger, akka, atmosphere (websocket) support in module. Easy to learn and work, and you know what happened in the background. I hate **Play** routes file but it's have big community so a lot company use this (and buy support) **Akka-HTTP** and **Spray** tilde concatenation is the ugliest thing (worst than play routes file) but it's fast and work Scalatra doesn't have own persistence framework but who care (I hate slick) I using activate framework for relational database. Here is my [sample project](https://github.com/b0c1/scalatra-activate-swagger-demo) 
jmh or it doesn't count? The results are highly variable due to jvm warmup time, as well as contention on any of the cores (or if the execution ends up placing the threads on the same core). Even beyond that, the async code has its start inside the await block, eliminating that overhead. It'd be like putting the start after the creation of the future in the other examples. Scala async may very well provide benefits but this benchmark is a long way from showing those benefits.
This was a pretty informative thread. It seems the crux of /u/mdedetrich's argument is that akka streams can currently handle concurrent and parallel computations. And, by virtue of it being an abstraction on akka actors, it will eventually handle distributed computations transparently? And your response is that Monifu currently handles concurrent and parallel computations as well. But I'm not sure I'm 100% clear on your response about if/how it performs distributed computations? Regardless, this is a very nice project.
&gt; I actually agree that Akka actors should be untyped and that's because they need to model state machines in an asynchronous and concurrent environment (context.become). You can't model state machines like that in current type systems, plus actors can expose different APIs depending on whom they talk to. So without modeling this, the set of all messages that an actor can receive is often as interesting as Any. Oh yes definitely, my point was that people who were arguing that Akka actors were terrible because they were untyped were missing the point of why Akka actors are untyped. This is why `scalaz.Actor` never got anywhere, if you are doing concurrency strictly locally (and you don't plan to scaling it horizontally over the network), than Actors isn't your best abstraction, and you are best off using something like `Future` or `Task` &gt; At this point I think we can agree to disagree. Moving on to other things, I saw you are attempting a Joda DateTime port to Scala and Scala.js. Just wanted to say that would be very useful. Sure thing! And thanks for the support on `Soda-Time`, its a lot of work, but when its finally usable it would be a huge boost to the ecosystem
It's also important to understand what exactly are you measuring up. In some cases I'd expect `Future.successful` to be an appropriate way of creating Futures. This way, the Futures have already completed, and you are measuring the map/flatMap rewrites, context switches etc. All this after the warm up you already wrote, and a fair "System.currentTimeMillis" placement.
If I remember correctly, Finatra reinvets the wheel for things contained in the Scala SCK.
Awesome, thanks for the reply. Spray and finatra are the main two im considering right now. Could you give me a bit more of a comparison since you've done things in both? Thanks
In terms of technology, they are where the JVM was in 2000-2005.
Initializing a reference to null to signal that it's still uninitialized is just a design choice. One shouldn't access uninitialized data. The idea is that since we have null anyway why don't use it also for uninitialized references? If we want to deal with uninitialized data explicitly, we can use an Option and decide that uninitialized Options are equal to None (i.e. they're initialized to None). This way, the use of null is not necessary anymore and it's just an implementation detail (for instance, Scala might use a special internal object `Undefined` hidden from the programmer).
[removed]
What I personally would really want to happen is the absence of `any2stringadd` (which allows concatenating String to Any).
Http4s is clearly the best of all possible frameworks. Why? Because I said so. More seriously, you're asking for personal opinions, and my personal opinion is I like http4s a lot. However that doesn't mean it's the right choice for you. I like http4s because I understand all the patterns it's built on. It's just a bunch of algebraic data types and a few type classes. Easy! But then I've been doing Scala for six years now, so I know this stuff backwards. What's good for me might not be the best choice for you. The documentation isn't that great, for instance (though people in the Gitter channel are very helpful.) Other than that, my *opinions* are: * Play documentation is good. The model is very simple, and it follows what I consider good practice for the most part. I recommend it as a second best choice after http4s. Some people complain about "bloat" but I don't really understand what this means. As if Play's templating engine is going to somehow sneak into your REST endpoints and ...? * Spray. Not much of a fan. Has what I consider bad practice, like using exceptions. * Finatra / Scalatra. Not idiomatic Scala (annotations, stringly typed). Really not a fan. * Finch. Probably pretty good, though I haven't looked at it much.
I'm a bit confused as to why the author is using the monadic comprehension (which executes sequentially) instead of applicative zipping (which executes concurrently) when comparing to the async-await library. The post appears to highlight the problem of using monads to compose futures that don't have data dependencies. The simple solution is to use applicatives (e.g zip).
What I have been personally using - Scalatra This is still a very good all rounder REST HTTP API. It is **very** easy to get started with, supports a lot of JSON protocols, supports WAR interface, is still being maintained and supports stuff like Swagger/Scalate. - Play - Play stands above the rest when it comes to its insane tooling, we are actually thinking of moving from Scalatra to play, but its for one main reason, an that play has the best tooling/build system for frontend dev (sbt wrappers for require.js, less, coffeescript, sass) plus stuff like auto reloading out of the box. Play also handles applications lifecycles well (when it comes to stuff like database connections). Also if you are not a fan of how they do DI, you can also do manual dependency injection - Spray - Spray is quite a low level REST framework, that is heavily focused on performance. If you are doing frontend dev, I wouldn't recommend Spray as you would need to build your own frontend toolchain, however if you want a high performance HTTP/S backend, its a good contender. The thing about Spray is its fully based on Akka's actors, which makes apps built in Spray quite easy to distribute and cluster - http4s - Has a very good high level functional approach to REST/Routing. The biggest issue with http4s is maturity, they haven't (yet) reached stability, and although a lot of trivial functionality works fine, a lot of complex operations are still being changed around - Finatra is a layer ontop of Finagle, which is what twitter used internally for their HTTP/TCP/RPC backends. Its been heavily tested in production (twitter has been using this stuff in production for years). There is also https://github.com/finagle/finch, which puts a more functional layer ontop of Finatra Since you are new and getting started, I would recommend Scalatra. Its very easy to pick, and its how I first learned Scala. People would argue its not completely idiomatic Scala (even though a lot of people don't really define that properly), but its better to get started building something rather than just bashing your head against a brick wall Also as a side note, Akka-Http is actually Spray, Typesafe is absorbing Spray and re-releasing it as akka-http.
i thought you could just use double-$? as in [this stackoverflow](http://stackoverflow.com/questions/16875530/escape-a-dollar-sign-in-string-interpolation). has that changed? (i don't need "$" very often, heh)
I remember trying that at some point and getting a compile error, thanks for the tip though, will try it again
I think you can use `${'$'}` for that.
Friggin' finally.
Good try Jetbrains but you won't have my money muahahha
I would pick Play, because all the others suck. And it's definitely not overkill for REST apis. Actually that's its sweet spot. And stay far away from both Scalatra and Spray.
Your reddit username is perfect considering scala.predef is where the implicits that make this happen are located.
[**@ManningBooks**](https://twitter.com/ManningBooks/) &gt; [2015-09-10 16:18 UTC](https://twitter.com/ManningBooks/status/642009196020502528) &gt; New MEAP! Save 50% on Type-Driven Development with Idris w/ code mltdidristw at &gt; https://www.manning.com/books/type-driven-development-with-idris \#IdrisLang &gt;[[Attached pic]](http://pbs.twimg.com/media/COjf9g9W8AAK_jk.jpg) [[Imgur rehost]](http://i.imgur.com/tUuNZRx.jpg) ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
Hi Gabriel, thanks for replying. I was confused by when the futures where started and should have read your github code. The name sequence is often used in Haskell for sequencing of effects. I briefly looked at the Future.sequence implementation and it is building the composite future using the monadic flatMap, but since the futures have already been started in your example, the effects are not sequenced. If the future constructor calls are provided in a lazy stream, then I'm guessing Future.sequence should then sequence the effects. Cheers, Tim 
What's wrong with spray for APIs services, exactly?
I already did something similar for a customer: a DSL (actually a Turing complete language, but de facto just a DSL) to process graphs. But we didn't compile to Haskell, but to the JVM. Unfortunately the project is closed source and not publicly available. A few hints: * If you are free in your design choice, create an "internal DSL", i.e. a library that can be used as a DSL in Haskell, Scala or Clojure. Don't create a whole language on its own. No need to re-invent a whole ecosystem, from the type system and the libraries up to the compiler and the IDE. * If you have to create a complete language, then use [xText](http://www.eclipse.org/Xtext/) for your first prototype. If you provide it a grammar and some helper classes, it will generate an Eclipse based IDE with syntax highlighting, code completion and a simple type system. With some additional work it will compile your code to the JVM and will even support refactoring. The compiler won't stop on the first error, but will try to gather errors and compile as much code as possible. This is great for syntax highlighting and code completion. * First compile to source code and later to byte code or binary code. And the most important hint: Keep it simple! 
I'm talking about scalaz-streams.
Yeah, give at least 1 reason per framework to justify why those options suck.
Absolutely agree after using all 4, I like Finch but prefer how Http4s is based on scalaz.Task, Request =&gt; Task[HttpResponse] and the simplicity of EntityEncoder type classes for marshaling results. It is by far the simplest in my opinion... but there's little documentation if you aren't comfortable browsing the code/scaladoc and familiar with the patterns used. Http4s, Argonaut, and Doobie make a great stack for service based apps. 
Thanks for the suggestion, but I've come to the conclusion that I should implement this in Haskell. My language requires knowledge of Haskell so I think that the Haskell community will be more interested in the project. Frege is just not popular enough.
Wow. Yeah, auto-conversion to `String` really seems to make the compiler's job more difficult than it already is, with no real corresponding benefit to the programmer.
Ah OK, I got this wrong. But I think you can still apply some parts of the advice: xText is a great tool for prototyping textual programming languages and you should consider to use it. You can combine [xText](http://www.eclipse.org/Xtext/) with [Eclipse Graphical Editing Framework (GEF)](https://eclipse.org/gef/) and the [Graphicla Modelling Framework (GMF)](http://www.eclipse.org/modeling/gmp/). GEF/GMF uses the same meta-model (called [Ecore](http://www.vogella.com/tutorials/EclipseEMF/article.html#intro_emfmodel)) as xText and can [interchange data with xText on the fly](https://eclipse.org/Xtext/documentation/308_emf_integration.html). With GEF you can build a graphical editor for your programming language; think of an UML editor, but you can freely chose the visualization. This should match your "graph language" very nicely. When combining the two tools, you can quickly build an IDE for a graphical programming language. With the help of xText, you could still maintain a textual representation of this language. The programming language for this will very likely be (very ugly) Java, together with the [Xtend2 language](http://www.eclipse.org/xtend/). Programming this way is really ugly, when compared with Scala (don't even think on Haskell....). But you can get to a working prototype very quickly and you will get lot's of features for free or very cheap (probably even a [debugger](http://www.rcp-vision.com/4089/the-jvmmodelinferrer-the-debugger-and-xbase-in-xtext-2-3/?lang=en) for your language, as long as you target the JVM via the [Xbase meta-language](https://www.eclipse.org/Xtext/documentation/305_xbase.html#xbase-expressions)). At some point you will reach to some limitations with this approach or become fed up with the ugly, partially generated Java code that drives your generated IDE. At this point, take the ideas you gathered to this point an bring them to Scala and Haskell. But until this point, the xText/GEF machinery will help you to concentrate on the language you want to build and not worry about editor support, code generation and graphical visualization. EDITS: 1. Added Ecore and GMF 2. Fixed links
I'm currently working on a project using Finch (with [Circe](https://github.com/travisbrown/circe) to serialize my case classes to JSON without any boilerplate code-- in fact, besides the import statements, I don't have to do _anything_ to transform my results to JSON) and am extremely impressed. There are still a few things in flux with Finch, but I'd recommend giving it a look.
Stupid bot...
No problem and you didn't waste my time. Just a small suggestion: Invest one hour of your time. Download the [pre-configured Eclipse](http://www.eclipse.org/Xtext/download.html) and follow the [xText tutorial](http://www.eclipse.org/Xtext/documentation/index.html). When you come to the [part with the interpreter](http://www.eclipse.org/Xtext/documentation/208_tortoise.html#tortoise-interpreter), divert from the tutorial. Instead of running an interpreter in Java, start GHCi. Then for each code line you want interpret, generate an equivalent Haskell line and run it through GHCi. Parse the result and take it as the result of your interpreter. After that one hour, close Eclipse and continue with your original Haskell project. I'm sure you will go back to Eclipse and xText very soon. Haskell is a great language. But for prototyping new programming languages, it can't beat the productivity of Eclipse. And if I am not right, you only have invested one hour. And you probably had some fun with the xText tutorial. After all, during the tutorial you will implement about seven DSLs, completely with a compiler or interpreter, and full IDE integration. You will learn how to design working grammars, how to bring in the concept of scoping, and how to handle imports.
Great work, I was just looking for something like this. What are the advantages of this compared to jesse eichars scala-io, which I think has been incubating for quite some time now?
Awesome! I like the API design :)
Last commit on scala-io was 3 years ago: https://github.com/scala-incubator/scala-io
I am the author and yes, I do not claim to understand "file system security" :) If you are worried about concurrency, I would recommend using NIO directly. But, for the common everyday case (i.e. how to write to and read from a file), Java I/O is just awkward to use. Look at the number of people who upvoted these questions: http://stackoverflow.com/questions/4604237/how-to-write-to-a-file-in-scala http://stackoverflow.com/questions/2885173/how-to-create-a-file-and-write-to-a-file-in-java This library is not intended for usage in a complex app which has to work resiliently over a dynamicly changing filesystem underneath. In those cases, I would recommend to use the NIO stuff directly. This library is meant for basic everyday usage where I have to write some stuff to a file or read a file or copy/move a file around.
Thats right. Im just curious if there was a feature scala-io lacked that inspired this lib
Mostly related to file attributes (e.g. setting permission, owner, touch(), globbing etc.)
Looks a lot like http://lihaoyi.github.io/Ammonite/#Ammonite-Ops =) Good to see more people dis-satisfied with the holes in the Scala ecosystem, trying to patch it up!
&gt;To be fair, java.nio.file doesn't exactly discourage racy behavior either. In a well-designed file system API, all operations would be on a file descriptor, never on a raw path. Paths can end up pointing to different files over time, but file descriptors always point to the same file. That sounds amazing! I look forward to your non-racy, reactive, well-designed filesystem API appearing on maven central =D 
A great many security holes have come into being because someone, somewhere decided that it wouldn't matter for the little things that their code would be used for. Then that code was used in a situation where it *did* matter… That attitude is not acceptable in 2015. *Every* app needs to use the file system securely, or delegate to a library that does. No excuses. If you make excuses about this, somebody's going to get hurt.
“Then do it yourself” is not a valid response to criticism.
To steer the conversation towards a more positive side, please file any bugs you find. I would be happy to fix (or atleast make the application programmer be aware of through documentation) of any such race conditions etc. This library is at best a thin wrapper/DSL over Java file I/O APIs so people don't have to google simple things like "How do I write to a file in Scala" more than once.
You can, use "$$" for that. It works.
I search a book for experienced OO programmer and willing to learn scala. I need a good introduction.
 You can buy it(or any other related) from [here](https://www.typesafe.com/resources/e-books). Notice edit: I've never read these books completely. If you aren't a beginner at programming you can get really far with reading tutorials online, reading [the first edition of Programming in Scala](https://www.artima.com/pins1ed/)(good old times...), joining to [this course](https://www.coursera.org/course/progfun) at coursera and creating remakes of widespread libraries or anything from your mind.
Hi @pathikrit, just keep up the good work! Some guys are not very happy with their life and prefer the criticism rather than help you. Just take what you consider relevant and discard other opinions. After all is an open source project and everyone is invited to collaborate to improve the design. I'm very confident you'll improve this library and learn from the community. Cheers, Gabriel. 
This is a really nice API. I especially like how it uses common Unix idioms for operator names. It would be great, if `bytes` and `content` would be more lazy and would return some kind of stream (probably with some convenient implicit conversion to `String` and `Array[Byte]`), so that the API doesn't crash the application (out of memory...) when accessing a huge file.
[functional programming in scala](https://www.manning.com/books/functional-programming-in-scala) and [coursera](https://www.coursera.org/course/progfun) You can use [ScalaKata](http://ScalaKata.com) if you want to code directly in your browser.
This. I'm also starting to learn Scala and i'm going over Martin Odersky's videos in the Coursera course "Functional Programming Principles in Scala". So far its been very useful and i feel i'm learning at a good pace. I'm following everything he does in the videos on my own in a scala worksheet.
Read these: - [Programming Scala (2nd ed.)](http://shop.oreilly.com/product/0636920033073.do) to learn the language - [Functional Programming in Scala](https://www.manning.com/books/functional-programming-in-scala) to learn to write programs Get on the #scala IRC channel and ask questions.
Slick 3.0 is shaping up nicely.
https://groups.google.com/forum/#!msg/scala-language/Mz_VoJdJf1w/5f1fg5Z9EgwJ &gt; The really big stumbling block is that Option is entrenched as a means of communicating "maybe there is a result" but also a means of communicating "it is not null", and these are not the same thing, neither interchangeable nor unifiable in a space of one bit. &gt; &gt; Assuming Option is a value class and new types are not introduced, then either: &gt; a) the bit means "it is not null", and you can't have signatures like `def find(f: A =&gt; Boolean): Option[A]` &gt; b) the bit means "it is not there", and the collections cannot contain null &gt; c) the meaning of the bit shifts unpredictably with the winds &gt; It is probably unrealistic to save Option. I would target a new type - and make sure the meaning of its one bit is easily identified. 
Year-old repost? The cake is a lie. I would avoid it at this point. Just use constructor arguments to describe your dependencies, then add Macwire to clean up instantiation. No need for any wizardry here.
Definitely used in production systems. The library is undergoing some big changes right now, including a name change (to FS2), so all the current documentation will be out of date shortly.
Thanks! What about F# projects on the .NET? Are they out there in healthcare software?
I thought they would use [MUMPS](https://en.wikipedia.org/wiki/MUMPS), since that's what it's for. 
http://www.scala-lang.org/files/archive/spec/2.11/
it's good to know just to know to avoid it
The DI I'm talking about is just instantiating objects and passing them to other objects. Macwire is just a compile-time macro to simplify this. Don't really know where you're getting off calling this evil.
I just released support for iterators that does not consume memory , implicit codecs amongs other things: https://github.com/pathikrit/better-files#streams-and-codecs
Another Tour of Scala: http://naildrivin5.com/scalatour/
Yes, [Driver Group](http://drivergrp.com/).
Most of the time, you don't need 'new class (mydep)' in scala. Traits with abstract defs instantiated as objects. If you're worried about encapsulation, use self types. The pattern above is trait MyTrait { def b: MyDep def me = b.doSomething } object MyImpl { lazy val b = SpecializedMyDep } No new required. Reconstructing prototypes is a sign that you aren't managing state. Methods in that prototype are sharing some state that may change while running the program, and you are hiding that mutable var as an object instantiation instead of threading it through your calls. This is not necessary, and even if it was you can do it by new upping a trait providing the dep as above in a factory method, provided as a singleton object to the trait like above. Don't code scala like it's Java. The cake is not a lie. It's the simplest solution to the problem that cannot possibly have colliding dependencies and is compile time verifiable.
Driver Group looks intriguing. What do they do exactly? I would guess that they do large scale meta-analysis of combined chemo trials and outcomes. Sort of like "big data" map-reduce of separate clinical trials from different institutions. Intriguing that they start with lung cancer specifically. That is exactly what IBM's Watson project is doing in collaboration with Memorial Sloan Kettering in NYC. Wonder if that's just a coincidence. Also, website home page has real clean design, and a bit ominous.
I like [Scala for the Impatient](http://www.informit.com/store/scala-for-the-impatient-9780321774095) because you get up to speed very quickly. And I like [Programming in Scala](http://www.artima.com/shop/programming_in_scala_2ed) because of the explanation of the philosophy of the language and the good writing style.
The underlying file system usually doesn't make the necessary guarantees. And in my opinion, the filesystem can't do this without sacrificing performance and without completely new, transaction oriented APIs. To make some guarantees that avoid race conditions, the file system must make some guarantees about the order of certain operations. The same principle is behind database transactions: The database brings all operations in a certain order according to their respective transactions. In principle there are several ways to implement this: 1. Use locks. In this case this means: When an application accesses a file (or a enumerates the contents of a directory), it locks all that file and the directories and symlinks it used to find that file. When the application is done with the file, it releases all these locks. Up to then, no other application can access any of these ressources. 2. Merge the result of parallel operations. In this case: The OS works similar to GIT. When there is a merge-conflict, it holds all operations and asks the user what to do. 3. Detect conflicts and retry the according transactions. In this case: Each application sees its own version of the file system. The OS automatically merges the differences between these views. If the is a merge conflict, the OS terminates the respective application, throws away the according view and restarts the application. With an extended API, it's not necessary to restart the whole application. The OS would just tell the application to retry the last n operations that lead to the conflict. Current operation systems use parts of these strategies. Windows works a lot with locks. The result is that you cannot delete or rename a file that is opened by another application. Linux tries to merge metadata: One application can delete a file while another application can still read and write to the file content - the OS will produce an "invisible file" and throw away the file content when no application accesses that file any more. But when you try to merge more operations, you will soon run into merge conflicts. So without an OS making stronger guarantees, it is not possible to make an API without race conditions. And I think it is unlikely that we get these guarantees soon: They would need support from all programs running on the respective OS (restart a bunch of file operations) or the results would be impractical (manual resolution of merge conflicts on a server or no parallel running programs because of locks all over the file system).
Right back atcha.
[Tracelink](http://www.tracelink.com/) has a product that tracks drugs and other medical supplies from the point of initial manufacture to the point of final sale that's written in Scala and uses AWS. Congress (and other countries' equivalent) have recently mandated such tracking.
Scala runs on the JVM. It provides interoperability with the Java world. You don't need any specific Scala server. Any Java web server is enough. As Play! runs over Netty (Java based).
I am a bit confused. I read that akka-http is an abstraction, higher level stuff? Also, I heard that spray won't be upgraded because of developers team working on akka-http? 
Thanks for your answer, do you have any information about websockets implementation in play/lift?
The problem is I have no knowledge regarding java world. I understand for example how python/php works using nginx or apache and how I can scale it. Increase max threads in apache or increase number of work processes in nginx.
They do "Lung Cancer, Cancer Genomics, Personalized Medicine, Clinical Trials, Precision Medicine, Panomic Analysis" but I understand maybe half those words. 
http://twitter.github.io/finatra/ Worth mentioning, while you're doing your explorations. Just got 2.0 released. However, might be worth checking out whether it supports everything you need out of the box. Also worth mentioning is that since it JUST got released, there might not be that much information with the exception of docs.
Akka-http is the next reincarnation of spray. They got it working and they plan to make it fast in the next release. In the meantime you can use spray. It will still work but new developments will be added to akka-http.
Thanks for your suggestion, I will dig into it and try to find the best solution. I am still quite unsure about all Finagle thing.
Ok sorry, I missed the last part of your explanation. So in this case you will find a big world with a lot of alternatives... I suggest you to start with Play! Framework because is good for beginners and it has a great documentation. And it has a great Web Sockets support. Cheers, Gabriel.
 Spray is a framework for creating REST APIs on top of Akka actors. Akka-http is basically Spray 2. In the future the Play Framework will be built on top of Akka-http (there is already support for this but it is experimental). Since you only want to create REST APIs, then you will probably want Spray or Akka-http. Which one depends on how far along Akka-http is. I believe they are API compatible so upgrading shouldn't be too difficult. Play, Akka-http, and Spray are typically deployed as standalone applications. You create a Java applications and it has its own embedded web server. Lift uses the more traditional Java deployment model. In this model, there is a separate Java server (such as Tomcat, or Jetty), commonly referred to as a 'Servlet Container', that loads your application ( which is deployed as a 'war' file). 
From what I've heard, the typical timeline for these major new features tends to be a few major releases down the line. They've already mapped out the major features of the next few major releases: http://www.scala-lang.org/news/roadmap-next EDIT: If you're specifically referring to TASTY, they've got a paper and proof of concept implementation out already, but seems like there's still a long way to go to getting it into the main line Scala compiler.
I agree, but isn't that exactly what fixing binary compatibility entails?
You didn't link Martin's talk, so I don't know what he was talking about. But I assumed it was to deal with binary compatibility between major Scala versions. Code compiled for 2.9 wouldn't run under 2.10, and code compiled under 2.10 wouldn't run under 2.11. That's why your sbt dependencies likely include the `%%` operator; it uses convention to stick the Scala version into the artifact ID. Library dependencies are a different beast, and not solvable in a general way. It's always possible that a library will have breaking changes between releases. Even if the library obeys semantic versioning, it's entirely possible that the author messes up and changes some behavior that people were depending on (arguably, all bug fixes are breaking changes). This is why projects typically have both lower and upper bounds on library dependencies, that's what /u/Martissimus was talking about.
This is all correct, although none of it is new information for me. https://www.youtube.com/watch?v=TXNs51UII60 There's the talk. I took away from it that eventually the binary compatibility issue is going to be solved at some point. I'm kinda wondering when...
I listened to most of the talk, and it seems like he's only talking about binary compatibility - that is, not what /u/Martissimus was talking about.
Consider a less opinionated approach like undertow: http://undertow.io
Scala seems to attract the drama. It always has; I don't know why.
Its a best tutorial help me a lot. 
For anyone looking for a better Scala tutorial, look into the Scala Koans. 
This is book really good for introduction intro scala?
Futures are not suitable for asynchronous I/O because by design a Future signals a signal value to its consumers and then that's it. Asynchronous I/O is more about streaming. The other problem is that asynchronous I/O for file operations requires at least Java 7, you can really say goodbye at that point to Android and it would be really stupid without requiring Netty or another library that takes care of the nuts and bolts. But then we've gotten astray from the purposes of a standard library, haven't we? I personally think that I/O operations should not be handled by Scala's standard library.
Best tutorials for beginners..
It feels wrong that if a person new to Scala asks, "So, how do I write this text to a file?" we respond "Download this third-party library and include it on your classpath." Having said that, I definitely see where lihaoyi is coming from. This has been tried before and failed. The middle ground seems to be "drop down to Java", which still feels wrong, but not as dirty as requiring third-party support to *write a file*.
These are really good tutorials. Thanks a lot man..
I can only second this! Use the Cake Pattern if you prefer a complicated solution to a simple problem. Go for MacWire otherwise.
&gt; Dependency injection is evil *Runtime* dependency injection **is** evil; Macwire is compile time.
[removed]
I think the data-centric approach (where your library consists of basic data and functions on it) makes more sense than the OOP approach (with inheritance) in this case. The one potential issue I see with your current data-centric implementation is that there might be invariants for `TextLayout` you want to protect, such as non-emptiness of the array and its contents, and equal width of the strings inside the array. To protect those, you could limit access to the concrete type itself, and only allow a number of pre-defined basic functions on or for it (such as `width`, `height`, `widen`, `space`, etc.), and then let users of your library write their functions like `spiral` in terms of those pre-defined functions. If you then wanted to use OOP on top of that, you could define an interface for a `TextLayout` library - it must have a `TextLayout` type, and it must have the different pre-defined basic functions. Users could then use the common interface for your library, and implementors could then write difference implementations, for instance a slower but easy to write and maintain first version, and later on a version with better performance if needed. That latter approach is something I have used a couple of times - it is also very nice if you want to make a faster version of some existing part of your program, and you want to be able to compare both the performance and the behaviour (to help test the new version by comparing output for the old and the new version and checking they are the same). Of course, it is probably a bit overkill in this case :- ).
&gt; Important Note: Only runs under Java 8. Why is it necessary? // Debian-stable, for example, does not have the 8-th version by default. Same for Ubuntu-14.04 LTS.
Because http4s is built with Java 8 as you can read at http://http4s.org/. It was a decision of the committers. You can see it if you take a look at the issues history (for instance this two: https://github.com/http4s/http4s/issues/158 and https://github.com/http4s/http4s/issues/313). If you try to run "sbt test" using Java 7 you will get an error like this one: java.lang.UnsupportedClassVersionError: org/http4s/server/package$HttpService$ : Unsupported major.minor version 52.0 Cheers, Gabriel.
Thanks for ticket references and the explanation.
Wow, this is quite a lot of work someone put into this, thank you!
2-4 hours a week, especially fri/sat/sun
I've never heard of this project. It looks interesting. Its goals look similar to [Parrot](http://parrot.org).
The right choice is what the development already know. 
Invariants are a property that you want to always be true for a given type or part. For instance, you might have a class for representing convex polygons, and there you may want to have an invariant that the data in the class must always constitute a valid convex polygon. In imperative programming, it can also be a property that must hold for a for-loop: At each iteration of the for loop, the loop invariant must hold. That is used as a way to help ensure and verify correctness - see for instance [the loop invariant used to help verify the correctness of the sorting algorithm implementation at this page](http://www.sorting-algorithms.com/insertion-sort). Invariants can be protected in different ways. One straight-forward way in Scala is partly to ensure that your type is immutable, and then simply check when constructing it that the invariant holds (and for instance throw an exception if it does not). This way, if the invariant at any point goes bad, it goes bad when trying to construct it - not later on in the program, where it may be non-obvious that it is the type that does not have the expected property, not some other part of your program (which can make debugging harder). Another way is to make it impossible to break the invariants in the first place, by limiting how the type can be created and interacted with and ensuring that whatever is done with the type, the invariant always hold. This way is not always possible to do, and it tends to be more involved, but it does have two nice benefits: First off, instead of some sort of error mechanism usage being necessary in case the invariant does not hold, the property simply always holds; and second off, you may be able to avoid runtime checks when the object is created. As for how I would implement it, I would make some somewhat straight-forward modifications to your solution - change the internal representation from an array of strings to a class containing a vector of strings (`Vector` because it is immutable, and it is therefore not possible to break the invariant by simply changing it directly like it would be with Array), with the class checking the invariant upon construction. Note that I have also split the "library" part into its own object: object TextLayouts { class TextLayout(val value: Vector[String]) { require (value.isEmpty || value.forall(s =&gt; s.length == value(0).length)) } def textLayout(s: String): TextLayout = new TextLayout(Vector(s)) // fill by width and height def textLayout(s: String, w: Int, h: Int) = new TextLayout(Vector.fill(h)(s * w)) def width(t: TextLayout): Int = if(t.value.isEmpty) 0 else t.value(0).length def height(t: TextLayout): Int = t.value.length def above(t1: TextLayout, t2: TextLayout): TextLayout = { val t3 = widen(t1, width(t2)) val t4 = widen(t2, width(t1)) val res = t3.value ++ t4.value new TextLayout(res) } def beside(t1: TextLayout, t2: TextLayout): TextLayout = { val t3 = heighten(t1, height(t2)) val t4 = heighten(t2, height(t1)) new TextLayout(for ((s1, s2) &lt;- t3.value.zip(t4.value)) yield s1 + s2) } def widen(t: TextLayout, n: Int): TextLayout = { val n1 = width(t) if (n &lt;= n1) t else { val halfDiff = (n - n1) / 2 val h = height(t) val left = textLayout(" ", halfDiff, h) val right = textLayout( " ", n - halfDiff - width(t), h ) beside(beside(left, t), right) } } def heighten(t: TextLayout, n: Int): TextLayout = { val h = height(t) if (n &lt;= h) t else { val w = width(t) val halfDiff = (n - h) / 2 val top = textLayout(" ", w, halfDiff) val bottom = textLayout(" ", w, n - halfDiff - h) above( above(top, t), bottom ) } } def stringify(t: TextLayout): String = { t.value.mkString("\n") } } object SpiralObj1 { import TextLayouts._ val corner = textLayout("+") val space = textLayout(" ") def spiral(nEdges: Int, direction: Int): TextLayout = { if(nEdges == 0) corner else { val sp = spiral(nEdges - 1, (direction + 3) % 4) val verticalBar = textLayout("|", 1, height(sp)) val horizontalBar = textLayout("-", width(sp), 1) if(direction == 0) above( beside(corner, horizontalBar), beside(sp, space) ) else if(direction == 1) beside( above(sp, space), above(corner, verticalBar) ) else if(direction == 2) above( beside(space, sp), beside(horizontalBar, corner) ) else beside( above(verticalBar, corner), above(space, sp) ) } } def spiral(nEdge: Int): TextLayout = { spiral(nEdge, nEdge % 4) } } object Main { import TextLayouts._ def main(args: Array[String]) { import SpiralObj1._ (0 to 10).foreach( x =&gt; { println() println(stringify(spiral(x))) } ) } }
Check out my little experiment comparing how it looks to work with some libraries/frameworks to build http services with Scala: https://github.com/mfirry/web-frameworks-templates (it's still a work in progress)
Hi, are these positions remote-work friendly?
I will surely do! Thanks
Can you describe the companies? Are they startups or Fortune 50 companies? Do they have 1 current employee? 10? 100? 1000? 10000? 100000? What does the company do? Services? Products? Are they B2B? B2C? Does the company make things? Hardware? Software? Some sort of other products? Is the Scala developer going to be developing the company's product, or just working in the backoffice, building internal company software? Can you please describe the company culture?
One thing to consider for a web app is that Scala.js seems to be more mature and supported that any of the Haskell compile-to-JS options.
I find that whenever a Haskeller criticizes scala, they criticize it because it's awkward to program in scala as if it were Haskell. That's like criticizing a round hole because your square peg won't fit into it. 
In EU some (not the big one) hires. At least I've found one in Poland yesterday. 
Evolution Gaming is in the EU, doing Akka + Akka Persistence + Play. Feel free to message me if you have questions.
I have, I was hoping for something that didn't pull the whole web in as dependencies :)
 I'm talking about those "best libraries" mostly. 
Perhaps you should name some concrete examples because I meant the best libraries in terms of readability in that sentence and it doesn't make sense that those would be the ones that are horrible, by definition. At least not without some very, very subjective definitions of the term readable.
Check out http://www.typesafe.com/customers/our-customers-are-hiring for some more (including other regions). 
When I talk about readable I mean code that is cleanly structured, whitespace to separate the pieces, reasonably short lines (in terms of tokens, not so much in terms of characters, long identifiers are not bad after all). You need to be able to understand what code does without keeping a myriad things that don't fit on the current screen in mind and ideally for those most are part of the base language and thus the same everywhere or heavily covered by conventions most people use (e.g. the short variable names used in Haskell or maths or Hungarian notation to indicate types in some other languages). I would suggest you look at actual released code instead of random github repositories returned by a Google search. Depending on the kind of repos you find you might be looking at code written for an abandoned beginner's test project on one end of the spectrum or the cleanest library. As for readable DSLs, that is actually one of the main things I dislike in Scala, the way DSLs are created by making half the syntax optional, making it very hard for someone unfamiliar with that particular DSL to figure out what is actually going on. Haskell, on the other hand, makes this relatively easy since it uses custom operators which can be plugged into Hoogle to find the corresponding documentation, using the same rules of precedence and function application everywhere in the language. If you think Haskell can't handle state you clearly do not know the language and if you think using state is a good thing you clearly haven't realized that you can't hide state. OOP is essentially a giant excuse for creating lots and lots of global state, you might not be able to inspect it from every part of your code but every part that interacts with an object holding your state potentially behaves differently depending on the value of that state. The proper management of state, using it where necessary, but only where necessary, is one of the greatest challenges of the upcoming decades of programming and Haskell is one of the few languages right now making any progress in that direction. As for OOP, there is very little in it that I would call goodness. It conflates too many concepts into one language construct which are all better kept separate. Inheritance (between concrete classes, not interfaces) is ill-suited for both polymorphism (where people frequently break the Liskov Substitution Principle) and code reuse. Encapsulation is frequently required around several objects working together which need to know each others internals, not just a single one. Putting code and data into the same language construct offers no clear advantages and has many drawbacks, in terms of construction cost, the ability to reason about methods (you never know which of the fields each has access to a method's behaviour depends on and which of them it changes, most likely it has access to a lot more than it needs), the difficulty faced by most ORMs when putting data generated based on database fields and code written by the user together,... OOP has been around for at least two decades now, during that time there has been little or no progress in terms of code reuse, reliability, ease of debugging,... I would say we can safely write it off as a failed experiment. What little there is in terms of theory most implementations and OOP coders do not follow or even know (e.g. co- and contravariance in container- or subtyping relationships, the LSP mentioned above,...).
http://stackoverflow.com/questions/17058942/sum-of-even-numbered-items-in-seq One way of thinking about the problem is to think of your positive integers as a mathematical set. You only want to sum the odd ones, so one way of doing it is to filter out everything from the set that is not appropriate. In Scala, most collections have both a filter function and a sum function, so you shouldn't do your own summation: data.filter{ }.sum 
Speaking of Maven, if Maven plugins could alter the POM, that'd be great.
&gt; When I talk about readable I mean code that is cleanly structured, whitespace to separate the pieces, reasonably short lines (in terms of tokens, not so much in terms of characters, long identifiers are not bad after all). This could be achived by most languages. Do not think Haskell is special here. Everybody can write bad code in anything. I don't need to try hard to find horrible haskell code. &gt; e.g. the short variable names used in Haskell or maths or Hungarian notation to indicate types in some other languages 1. Those short variable names, symbolic function names(nub for example) wingdings operatos are hardly understandable. Those are the signs of a missing IDE. 2. Hungarian notation considered harmful in every sane language(as a Hungarian, it's funny). &gt; I would suggest you look at actual released code instead of random github repositories returned by a Google search. Depending on the kind of repos you find you might be looking at code written for an abandoned beginner's test project on one end of the spectrum or the cleanest library. Even your most loved frameworks(yesod, happstack, shakespeare fullfilled with {-# LANGUAGE ... #-} hacks, ugly operators, endless lines) are flawed. The problem isn't the beginners but the language itself with its prude community and view. &gt; As for readable DSLs, that is actually one of the main things I dislike in Scala, the way DSLs are created by making half the syntax optional, making it very hard for someone unfamiliar with that particular DSL to figure out what is actually going on. If you don't like it probably you don't want a general purpose language - then I'm not interested in your opinions in this theme. &gt; If you think Haskell can't handle state you clearly do not know the language and if you think using state is a good thing you clearly haven't realized that you can't hide state. You're wearing a blinder if you think this way. This purist evangelionism is one of the main reason haskell is unusable in production. And I don't need to hide state(except in actors). The problem was never the state but the lack of typesafety and safe communication with the outside. &gt; The proper management of state, using it where necessary, but only where necessary, is one of the greatest challenges of the upcoming decades of programming and Haskell is one of the few languages right now making any progress in that direction. If haskell could handle state well then it wouldn't be that hard to create good client and web apis. &gt; OOP has been around for at least two decades now, during that time there has been little or no progress in terms of code reuse, reliability, ease of debugging,... This is true for haskell: no progress in code reuse, it still allows unhandled errors and there are no mature debuggers, IDEs, webframeworks, client frameworks for it. 
Disclaimer: I'm the author of the MongoDB Scala driver, but I've long been a fan of ReactiveMongo and think Stephanes work on it has been brilliant. Plus points for the new MongoDB Scala Driver: * Fewer dependencies. It only requires the Java MongoDB drivers, so deployment is greatly simplified. * Official MongoDB Driver. New features of MongoDB will be supported, including all enterprise features. * Standalone Observerables. A simple but composable default trait for async streams that include "back pressure" support. Doesn't make assumptions about your stack and is easy to [integrate](http://mongodb.github.io/mongo-scala-driver/1.0/integrations/) with any preferred mechanisms. Minus points: * No Case Class support (scheduled for 1.1) * No GridFS support (scheduled for 1.1) * No Play integration * Perhaps not as idiomatic as ReactiveMongo. The new driver follows the specifications for all the official drivers, which at times may not be considered idiomatic. 
You clearly do not know the current state of Haskell (or the state it was in even a couple of years ago) very well so I see no point in continuing this discussion.
Author is here. I would like to get feedback on my code, and contributions for sure :)
Hi niels, part of your confusion might be the type parameter A in the reverse method, which in fact is introducing a new type A, that happens to have the same name as the List's type A.
Great post! We could use more content that demystifies type-level programming in Scala. 
Err, did you ask any questions besides “Anyone up for some tutoring?”
I didn't really understand the use case for this
Whoops thought you were someone else I had PM'd. My apologies. Quetsions I have for you: REST APIs you've worked with? Github samples? Spark experience? When are you available, I need 2-4 hours a week at least. Want to do this for a year What industries are you experienced in? I am interested in healthcare and adtech. IntelliJIdea experience? Please answer all questions, can be terse in a response, one or two lines, just to get around about of your background and if it fits my requirements.
&gt; Scala can make the Android API much easier and reliable to use and reuse, thanks to the functional programming and traits especially. &gt; Do you have a github repo for the project?
How's your programming experience? I burned through scala for the impatient in a few days to get a good kickstart... I really hate technical books much longer than this... there are a few highly rated fat books though.
Scala for the impatient
1. **Programming Scala, Second Edition** by Dean Wampler and Alex Payne 2. **Functional Programming in Scala** by Paul Chiusano and Rùnar Bjarnason 3. **Scala Puzzlers** by Andrew Phillips and Nermin Šerifovic
+1 Not only does this show you how to write scala it shows you how to do functional programming and it nicely explains *Why*. 
Not saying it's a bad book, but I personally loathe it. I've felt it was aimed at people who "just want to get shit done" - which is a perfectly fine goal to have, just not the one I had. I need to feel I understand what I'm doing and I didn't feel my understanding deepening while reading _Scala for the impatient_. I didn't have patience for this book.
Why not case classes unless this is an exercise in learning macros?
Pretty cool. Take a look at this too: https://github.com/adamw/scala-macro-debug It would be nice to wire this up with various backend loggers (e.g. sl4j , logback etc).
Happy to hear it! I was very discouraged with Scala macros until I discovered quasiquotes. :)
Puzzle: write foldLeft in terms of foldRight and vice versa.
Interesting post, thanks for sharing!
Not sure if this is intended in the question but generic solution is possible with shapeless: implicit class TuplePrepend[T](t: T) { import shapeless.ops.tuple._ def &lt;+[E](e: E)(implicit prepend: Prepend[T, Tuple1[E]]): prepend.Out = prepend(t, Tuple1(e)) } source: https://github.com/milessabin/shapeless/blob/master/core/src/main/scala/shapeless/syntax/std/tuples.scala#L59
You can generalize it to all tuples using HLists: https://github.com/milessabin/shapeless/wiki/Feature-overview:-shapeless-2.0.0#hlist-style-operations-on-standard-scala-tuples scala&gt; (23, "foo") :+ true res6: (Int, String, Boolean) = (23,foo,true)
By "add" tuples together, do you mean add their elements like the following? scala&gt; (1, "one") :+: (2, "two") res1: (Int, String) = (3,onetwo) Or do you mean concatenation? Either can be done with HLists, but that seems overkill. In summing elements approach, what happens if `+` isn't defined for one of the types in the tuple?
Are any of these positions remote?
Sorry, no remote positions at the moment. Where are you located?
A [dns implementation](https://www.ietf.org/rfc/rfc1035.txt) using [scodec](http://scodec.org/) and [scalaz-stream](https://github.com/scodec/scodec-stream). Plus a schedule that resolve or not a name depending on the time of the day/day of the week :-)
Your example pretty much covers what i was thinking - add each pair of elements with `+`. I can think of a few more features and the more we can verify at compile time the better - ensure tuples are of the same size, ensure each pair can be added legally and be able to "upcast" when adding something like an Int and a Double. 
Was this list from years ago or something? Just a simple search shows that prediction.io has over 7k stars, play has nearly 7k edit: its just some kind of karma farming bot posting nonsense.
Kamon is Open Source and can integrate with a lot of backends, The new Typesafe beta, reports to Takipi, who is paid..
Let's say I have a function called EmailWelcomeLetter. It takes one argument, the email address to send the email to. I also have a timing library that will invoke any function with no arguments after 5 minutes. I want to use the timing function against the email welcome letter function.. So using a partially applied function I could make a function with one argument take none. The whole theory is about mixing functions together and generating new functions so that I can increase code reuse and readability. Rather than get data from a, convert it to b and pass it to c, I could make a copy of c that's understands a's data directly. Sorry am writing this on a phone.
Yes. 4 years as a Java developer (and little personal experience with Javascript - mainly nodeJS)
A porting of [typesafe config](https://github.com/typesafehub/config) to Scala An [etcd](https://coreos.com/etcd) client for Scala 
Correct Add is a type class. In reality you'd never have to write the Add type class, it's a very common type class known as Monoid. There's an implementation of it in [scalaz](http://eed3si9n.com/learning-scalaz/Monoid.html).
My first job out of school was scala
But I think takipi can talk to statsd, right? I was thinking about quality of the monitoring though, but your'e right - the fact that it costs money means it needs to be a higher quality product to get eyeballs.
We've hired multiple entry level programmers as a scala shop
Then I stand corrected. I am currently in a locality where being a Scala dev is great as it is just picking up. But almost nobody is over 3yrs experience.
This is a very good post, thanks!
Oh. It is inferred. Why haven't I tried that... :) Thanks!
Hi, I built a client / server framework based on [scalatra](http://scalatra.org/), [scala-js](http://www.scala-js.org/). It is light and ready to use. You just need to fork the project on github. [https://github.com/mathieuleclaire/scalaWUI](https://github.com/mathieuleclaire/scalaWUI) It also use as an example a wrapping of the [D3.js](http://d3js.org/) library (a graph is shown as example), that could help you for drawing your things.
Yes, you should make a difference between the backend and the front end. Play! is built on Akka. For instance you are able to communicate the Akka Cluster app with the ActorSystem running behind Play.
Annotating function return type is a sign of language flaw? What the hell, even Haskell programmers do that. It's just good practice all around for many reasons. Avoiding type inference ambiguity is just a small part of it.
Not really. I had an internship in school that had me doing PHP and a little bit HTML/CSS. That went into a full time job, but only for about six months and then I got laid off. The place I work at now hired me in January and by mid February I was learning Scala (when I started I was working on legacy code bug fixes in PHP and writing some internal Python utils).
Agree in some parts, disagree in others. Arguably the reason for annotating types in methods isn't due to getting around Scala's type inference, its more to do with * Its just generally really good documentation * Documenting return types of public methods. Calling `zip` on an `Option` is very different to calling an `zip` on a list, and if you don't see what the return type of a public method is, you can get into some nasty surprises. Another good example is returning a `Future[List]` rather than just a `List`, both have `map` methods which do very different things * It helps compile times for people using your library, since the Scala doesn't need to do type inferencing * Is needed in cases for overriding super methods, or using stuff like implicits (where you should/need to specify the type for obvious reasons) Overall, automatic type inference hasn't personally been a pain. At our company we have a very strict rule that anything which is public has to have its return type annotated, however people are free to use type inference locally in method scopes if they want (ods are, if you annotate the return type of your public method and your local type inference is doing something weird, then it wouldn't compile) I think Scala has a nice middleground, however improvements could be made. I have yet to see a valid reason for an inferred type intentionally being `Any`, so in cases where a type is inferred as `Any`, that could throw a compile error. I am glad that I am not working with languages like Haskell (or dynamic languages like Ruby/Python), where reading through non trivial code that doesn't have documentation involves ridiculous amount of magic or guess work
"great documentation" is a bit exaggerated, but it is ok.
If you are doing a pure REST backend, there are many options (Scalatra, http4s, spray, finagle, akka-http are the common ones now) If you need to do some non trivial client side work, you are better off with Play (or maybe Lift if you like their way of doing things). Play has an enormous amount of client side tooling (i.e. working with javascript/coffeescript/Less/CSS + things like require.js) working seamlessly through SBT plugins If you want to go on the wild side, you can also try Scala.js
I've tried a few frameworks for Scala from the point of view of the developer experience. You can check them out here https://github.com/mfirry/web-frameworks-templates/
http://xitrum-framework.github.io/ is an awesome framework and often overlooked. I just completed the backend API for a large web property using Xitrum and Squeryl and it was a pure joy to use. Note: documentation is not that great, but the source code is super easy to read.
Yeah, I do it for readability first and foremost.
You're probably aware, but wartremover has checkers that ban inference of Any, Nothing, Product and Serializable.
Cheers thanks, I actually have had issues with it in actual code, but it appears in more complex scenarios that involve existential types
Function return types shall be annotated is very close to the top of our coding standards. I mean, that's part of the whole type-safety thing. The compiler will catch if there's a path that returns something other than what you planned.
My company uses Scala and I had no experience at all with it when I started. I'm still learning everyday 
Dat forced intro doe... Am I the only one who felt uncomfortable?
Terrific Q&amp;A, thanks!
&gt; When would you ever want an expression to widen into a set of supertypes automatically? That question doesn't convince me. I see no reason why defining a type as a set of traits for example isn't a sensible scenario. You are basically proposing something based entirely on your subjective preference. 
Why does wart remover consider the following to be a wart? &gt; Avoid usage of Monads
In the meantime, check out recently published [Scala by the Bay talks](https://www.youtube.com/results?search_query=%22SBTB+2015%22&amp;page=1)
An IRC server and client in Scala with Akka Streams A Torrent tracker using Scala with Akka HTTP
If the Scala code is being more-or-less recompiled at load time, why is the (AOT) compiler generating JVM class files at all?
I have had a similar experience to a lot of the commenters on this subreddit (from looking at older posts), and that is I set out to use Slick 3, found it was way too complicated, while also missing even basic functionality. I then switched to ScalikeJDBC, and in a fraction of the time I was up and running with hardly a hickup.
Agree. I wrote a thin wrapper around jdbc using shapeless and never looked back. 
Slick is good and does what it says on the tin. Would a sample project help? https://github.com/wsargent/play-slick-3.0/
Are you using Postgres? In my experience the queries generated by slick on complex joins/groups etc completely stump the MYSQL query optimizer.
this isn't my exact expertise but it sounds awesome. I bet you could do a NIO proof of concept in a day or two and throw a bunch of fake downloads at it and see how it scales. NIO can work well for longstanding connections.
Yes, it is postgres. Agree that the generated queries are at least unusual. Or I would never write then that way. Notice however, that plain SQL queries are also available without losing type safety.
Can't help with the http upload aspect at the scale you need (have a Play http upload routine in place but it is non-streaming and capped to 10MB). However, I have a new project where I will need to handle uploads upwards of 1GB so am very curious as to the solutions that may be presented here, particularly around resuming failed uploads. Once you *do* get the file uploaded to the server, from there [sshj](https://github.com/hierynomus/sshj) may be an option -- have been using that to sftp uploaded photos to remote servers, nice project.
try the slick 3.1 release, apparently the extraneous sub queries are gone now. Obviously use latest MySQL 5.6 release as &lt;= 5.5 face plants on any sub query you throw at it. p.s. awesome talk at SBTB, thanks for the quasiquoted macros a la Lens breakdown, good stuff.
there is scaffolding for slick: https://github.com/slick/play-slick-codegen you just have to customize it :)
I'm retrograde and use Hibernate. It's not bad. It's ok.
I used Anorm for a project that had a legacy database which has a schema that doesn't lend itself well to ORMs and it works fine. Plus, I was able to copy existing queries almost verbatim from a Windows application that had been using that database (rather than needing to recreate them), making Anorm a more natural choice for me than it might be for someone starting from scratch.
Can you help me? I'm learning ScalaFX for the first time, but i can't find an example that uses both ScalaFX and actors. http://pastebin.com/YNDFD5fr I found this GUI online and i tryed to add two actors. I want these actors to change the two words (hello and world) and so some other little things. I saw that if I pass, for example, the stage to an actor, I can't access the stage content (stage.scene, etc...), so i tried passing the stage or the scene to the actors and it worked. But if I try to pass the 2 text to the actors, i keep getting problems. Can you help me with this simple example please?
Nothing in there about backwards compatibility; is that not being considered, or is this sort of document not the place to address that? It's not like Scala has a sterling reputation with library version robustness as it is.
I'm interested. just started to learn scala fundamentals.
But i can't see the two text from the list and it doesn't work if i put the text outside the list.
I am in. 
Singleton string types would also be very welcome in Scala.js, to accurately type JavaScript APIs taking "enum" strings as parameters, and returning different kinds of objects depending on those values. Typical example: `HTMLCanvasElement.getContext()`.
Wow I did not know that!
I'm also learning Scala. 
I hope someone can create a Scala group on Slack so everyone who interests in can join.
I have created a [subreddit](https://www.reddit.com/r/scalastudygroup/) for us to start with this studygroup. I have also added a [introductory post](https://www.reddit.com/r/scalastudygroup/comments/3nnt4h/printlnhello_world/) to kick off things. Please add your comments and suggestions. 
Of course, and these take time. But at a 2.x stage, these things need to be finessed at least a little. 
100% agree, but I'm starting to wonder if the Scala community actually uses anything anyone else wrote, or if everything is assumed to come from whole cloth. Library version brittleness is a huge problem for us library *users*. And it's equally unrealistic to assume that every maintainer is going to be maintaining a version for the last `n` Scala versions. Now that said, perhaps Scala isn't meant to be "write once, use many", but that's an equal shame if so.
But even TASTY won't give you a binary format that will survive a transaction such as moving part of the collections API out into extension-ops or type classes. It is meant for things such as adding methods to existing traits or targeting different platforms (JVM, JS).
I wish this was true. Things like not being able to use vals, scala lists and case classes really take away the fun. 
yup backwards compatibility is why Java is such a mess. Breaking changes suck but if done for a good reason and you can document the upgrade path. please do it
Just another thing. I want to modify the interface from another actor. http://pastebin.com/9ynGfRwB I created a simple interface and passed the scene to 2 actors and i have these problems: - I can't see the text inside the rectangle. Why? - Is there a way to change the interface from an actor? Every time i try it, I get the "Not on FX application thread;" error. - If I try to pass the rectangle instead of the scene and I do "rectangle.fill= White;" inside the actor, I get "Rectangle.fill : A bound value cannot be set.". How can i fix this problem?
As soon as you throw actors into the mix, you're dealing with multi-threading. The UI of a JavaFX application can only be updated from the application thread. [Platform.runLater](https://docs.oracle.com/javase/8/javafx/api/javafx/application/Platform.html#runLater-java.lang.Runnable-) was provided for that purpose.
In addition to what JavadocMD says - you have to use runLater, as in: runLater(new Runnable { override def run = { // do some updating of UI widgets } } Now, if you put that into an actor, you might run into a problem where your actors are throwing too many of these jobs onto the JavaFX thread, and thus your system will freeze, become unresponsive, and even eventually run out of memory - because 8 threads could potentially put tasks onto the 1 JavaFX thread faster than it can clear them. There are a number of different strategies you could use to solve that, but which one is right would depend on what you're doing. 
Play's WS library is pretty nice
I don't think you need the framework, I think it's just a library. 
I like spray/akka-http, but that's probably because I'm usually writing a spray server as well. i'm not sure that I'd use spray just for the client.
id like to throw out [ning async](https://github.com/AsyncHttpClient/async-http-client) as its fairly easy to use and gives you callback options if you end up needing it
you can try jersey client works nicely.
[Dispatch](http://dispatch.databinder.net/Dispatch.html) is pretty OK although a little bit too DSL-y IMO. It inspired Newman.
I'm not sure. Nothing obvious jumps out at me.
Sim. De modo geral não vejo muita necessidade de tutoriais em pt. Se alguém chegou até esta linguagem, deve ao menos saber inglês. Mas , bom conteúdo. ;)
Honestly, I'm kinda just using [Unirest](http://unirest.io/java.html) It's pure java, but it's simple builder syntax, and backing by apache httpclient means it's legit enough to use for production work. For a simple rest client :)
For funsies. That's why I'd do it.
It'd be super neat if you could use the new Akka streams stuff to translate the request. There could be some very fascinating logic there. And if you could stream all the way through, you'd be able to do deal easily with lots of connections. Wouldn't buffer all the crap in ram. Neat!
Thank you for such a kind statement! :) Yes concurrency is safe - by default prop testing (and random data) is parallel by default on JVM, where as for Scala.JS it's single-threaded.
Greetings from São Paulo :) --- Oi de São Paulo :)
Nunca uma necessidade mas é bom ter. Adoro coisas (livros, recursos, etc) nos outros idiomas.
Como é o comunidade de tec em São Paulo? Scala existe?
thanks, love it!
That example doesn't typecheck; x and y have type Any and are being passed to a method expecting Strings. Please provide a minimal *working* example that demonstrates the problem, preferably with no external dependencies.
Glad it worked for you! 
http://isomorphic.net/
Mmm. Is slack free? We're using a paid version at work. It's pretty great.
maybe a HList ... check out shapeless.
Probably not a helpful comment but might as well start with the basics... How come the arity of your data changes? Like why is it a tuple of N each time?
Free with 10k messages history. The point is who will pay this if we just want a slack scala group?
My problem requires a variable tuple size to map various fields from the tuple's members into three separate distinct classes; each of these requires a distinct tuple containing relevant objects which enables the construction of the three target objects using different fields from the respective variable tuple sized input. My goal with the trait was to pipeline the tuple generation processes into the resolution classes which extend the generic tuple trait that allows for business logic map to those three target class. Does this make any sense? I'd be super happy for feedback, I'm relatively new to Scala/Spark
http://freeenglishnow.com/tutorial/ Btw: I'm not a native english speaker myself.
Hi, Regardless the complexity of build both projects with unmanaged dependencies, it seems that the library LWJGL is on Sonatype Nexus. Did you try it? Or are you using a different version that is not in the repository? https://github.com/LWJGL/lwjgl3 "LWJGL 3 can be used with Maven/Gradle/Ivy, with the following dependencies: org.lwjgl:lwjgl:${version} org.lwjgl:lwjgl-platform:${version}:natives-windows org.lwjgl:lwjgl-platform:${version}:natives-linux org.lwjgl:lwjgl-platform:${version}:natives-osx where ${version} is a version (e.g. 3.0.0a) released on Maven Central. Nightly builds are also available from the Sonatype Nexus repository, with a snapshot build version (e.g. 3.0.0b-SNAPSHOT)." Cheers, Gabriel.
Ah, thank you, that's new to me! :) Still figuring out how to get the natives the main jar itself wasn't a problem, it was: `libraryDependencies += "org.lwjgl" % "lwjgl" % "3.0.0a"` **edit:** If I add it like this: `libraryDependencies += "org.lwjgl" % "lwjgl-platform" % "3.0.0a" classifier "natives-windows" classifier "natives-linux" classifier "natives-osx"` I'm not sure where to set the `java.library.path`
Scala `object`s are modules: like packages, but more general because they are also values. So just think of them as namespaces where you can hang things like type aliases, methods, constants, etc., that cannot appear as top-level package members. You are correct that these objects should not hold mutable state or perform side-effecting work on initialization, but then again neither should anything else.
Also note that `object`s are not necessarily global: they can be scoped within traits and classes or other objects: class Foo { object Bar {} } 
For my test I had to use the servlet support to run in Tomcat. I was running my test in AWS on four load balanced m1.small instances each with a 1 gig max heap. The scenario involved deserializing a small JSON object with a single key and long value (done with Jackson and json4s) then issuing an update in a connection pooled Aurora db running on an r3.xlarge and returning a 204 no content response. I could only maintain a steady state of roughly 450 requests per second across all machines, so less than 120 each. Pushing above that lead to a cascading increase in latency resulting in every request timing out after 5 seconds. There was no CPU or memory pressure on any machine. We tried tuning both GC and thread pool sizes but continued to see the cascading failures. On a whim I replaced http4s with a basic hand written implementation overriding the doPost method of the HttpServlet class, leaving all other things as they were. After that I could maintain a steady state of 1000 requests per second with no failures or timeouts, and 2000 after upgrading the database instance. When I ran everything in my local MacBook pro, including a MySQL db, I could get http4s to 2k requests per second before my CPU was maxed. But that had an average latency of 20ms while my version reached the same with an average latency under 10ms. As for blaze, there is some indication in [these preliminary results](https://www.techempower.com/benchmarks/previews/round11/#section=data-r11&amp;hw=peak&amp;test=plaintext) that it also does not perform so well and that is [pretty simple](https://github.com/TechEmpower/FrameworkBenchmarks/blob/master/frameworks/Scala/http4s/src/main/scala/WebServer.scala) too. This was all like 2 days ago so I haven't yet figured out the root cause. And I didn't do proper profiling so there's a chance I accidentally changed something besides http4s in my servlet implementation. But my experience coupled with those preliminary results does point to http4s not being a peak performer.
Singletons aren't the anti-pattern, global mutable state is the anti-pattern. Singletons can be quite useful for many ways already pointed out itt
&gt;the presence of global state brings all sorts of problems The presence of global **mutable** state brings problems. Global constants are fine. Scala objects end up being a simple way to namespace functions and constants. Most push back against it is a remnant of the industry's overly OOP obsessed past. &gt;the presence of global state brings all sorts of problems You should enumerate some of these problems. I'm fairly sure other Scala best practices mitigate them.
semicolon are not needed, so why type them? It's just a ritual same with return, it's just a ritual.. additionaly if you write in "functional"-style, they look awkward (you wouldnt write f(x) = return 5 would you?) if you write more "java-like" scala (which is okay, scala is can do both) then they make more sense
`return` is not a stylistic matter: it changes the meaning of your program. It should [never be used](http://tpolecat.github.io/2014/05/09/return.html). Semicolons are usually inferred for you and are therefore usually omitted. This makes code cleaner (the fact that they are inferable means that they are redundant when used explicitly in these cases). 
Okay, I _think_ I got this working using path-dependent types. I just had to change `SearchService`'s `def service: Service` to `val service: Service`. Then I changed the search method from `def search(query: String): Seq[P]` to `def search(query: String): Seq[service.P]`. Thanks for the direction!
Minor comment addressing the proposed markup language. Note that having a syntax with non-matched parenthesis may break text navigation for some editors (jumping to matching parenthesis may not work, as well as jump to the beginning of a surrounding block). The `git diff` command could get broken, too (it tries to find the surrounding function/block definition for most languages). But please don't assume this to be criticism, really. I just thought about it and considered as worth writing. Happy coding anyway.)
I once wrote a library that can be wired with any logging you already have or want: https://github.com/vn971/macro-format I haven't touched it for some months though because I want to make up my mind about the best approach for it. (See Future Plans, and the proposed expansion `m"hello, ${a+b}" =&gt; "hello, a+b = ***"`.)
That's really interesting about the return. I'm looking through the other "bloggish scribbles" on your github. Looks like there is a lot of good information there. Thanks!
Thanks. I would actually love if you could send me that example, mostly for my own learning. I think it might be beneficial for me to see a concrete example of the different approaches. I'd like to get in the the right mindset to help me avoid this sort of thing as I go forward in my Scala career. So, no rush on getting that information, but I would like to see it just for learning purposes.
Singletons are useful in distributed computing where you know you want one instance per JVM. Need another instance? Spin up another JVM.
After a lot of fighting with sbt, here's what I realized- try to use the DSL as little as possible. Just with this in mind forced me to try to understand the types of everything. I know this is a very general information, but that's the best I can do at this time because I don't know your specific problem: you define keys for tasks using: lazy val key1 = keyType[ type of value that's returned ]( "name for key" ) //then you write the actual code for what you want. def key1Work: Initialize[ KeyType[ Type of Value ] ] = Def.(task or input or setting based on keytype){ code that returns the actual type of value } //And you finally point the taskKey to a certain piece of code in a certain context key1 in (subProject1, Compile) := key1Work() for example, I want to create a new task. A key for task is `TaskKey` (which has a proxy method `taskKey` too) and the actual code corresponds to a `Task` lazy val taskKey1 = taskKey[ Int ]( "this returns the number of files in the tmp folder when its called" ) //OR lazy val taskKey2 = TaskKey[ Int ]( "taskKey2", "this returns .... " ) def tmpValueReturner( fuzzTheNumberABit: Boolean ) : Initialize[ Task[ Int ] ] = Def.task{ val numFiles = new java.io.File( "/tmp" ).listFiles.size if( fuzzTheNumberABit ) numFiles + 1 else numFiles } //Now assign taskKey1 a value taskKey1 in (subproject1, Compile) := tmpValueReturnr(true).value taskKey2 in (subproject2, Test ) := tmpValueReturner( false ).value //Within the code definition of tasks, one returns the value of actual type, e.g. Int, String and not Task[Int], Task[String], so how do you depend on another task? You do a `another task.value`. e.g. the `numFiles` variable could have been assigned the value of another task that computes the unfuzzed tmp file count by saying. You could do that in two ways, either doing a `.value` on a variable of type `TaskKey`, or doing a `.value` on a method that returns `Initialize[Task]`. Sorry I know I just blaberred without any specific context but I hope this helps you. 
For problem # 0, I'm going to assume you're now successful at pulling in LWJGL as a library dependency in sbt. For problem # 3, you _should_ be able to (I've never tried it, but others here may have) publish your `core` engine as a package to your local Maven repo (i.e. inside your home directory, see http://www.scala-sbt.org/0.13/docs/Publishing.html#Define+the+repository and http://www.scala-sbt.org/0.13/docs/Publishing.html#Publishing+Locally), and then list it as a library dependency of your `application` project (you'll also need to add your local Maven repo as a resolver, see http://www.scala-sbt.org/0.13/docs/Library-Management.html#Resolvers). This way `core` is treated as a normal package dependency of `application` and you can still develop both locally.
Here it is. It's not really reduced to just two lines, I forgot about the pattern matching :) but even better - it was decomposed into two smaller functions. Odersky would be proud. Notice how it resulted in a better program flow even in this minimalistic example. Before: def instanziateJsonDocument: JsObject = { def maybeMongoId = (document \ MongoEntity.MongoIndex).asOpt[JsValue] if (maybeMongoId.isDefined) { val mayBeObjectId = (mayBeid.get \ "$oid").asOpt[String] if (mayBeObjectId.isDefined) { return document ++ Json.obj(primaryIndex -&gt; mayBeObjectId.get) } } document } After: def instantiateJsonDocument: JsObject = { maybeMongoId() match { case Some(id) =&gt; document ++ Json.obj(primaryIndex -&gt; id) case None =&gt; document } } private def maybeMongoId(): Option[String] = { (document \ MongoEntity.MongoIndex).asOpt[JsObject] .flatMap{ mongoIndex =&gt; (mongoIndex \ "$oid").asOpt[String] } }
Definitely, the upgrade process was seamless, nice to see that Play Slick got an instant update. It's also worth mentioning that [slick-pg](https://github.com/tminglei/slick-pg/releases) got a corresponding update pretty much immediately, too. Unfortunately new compiler back-end completely broke one of my queries - not a big deal, I replaced it with raw SQL, but it's just worth noting that there might be a period ahead when all the quirks are fleshed out.
failing futures are not type checked :) and when using scalaz either, it's a monad and you can transform the future with eitherT
You can put things in the left side of an Either other than exceptions.
Did you have programming experience before the Scala?
Yeah I graduated college in CS and knew Java, Python, JavaScript etc 
Did you have working experience with Java, Python, and JavaScript ? Thanks
The Failure value for future means the the computation unexpectedly failed. While the computation returns a Either because it expects there to be a possible error case of type X, which may or may not be an Exception.
In fact these days I'd argue you should be, honestly I don't see much use for Either anymore. We have Try as the specialized case for the left hand exception. We also have scalaz disjunction with the same monadic fail fast mechanics for cases where we want to just put in error messages. We also have scalaz validation for cases where we want to accumulate errors. This leaves true union type cases where something can legitimately be one thing or another. However in this case I'd advocate using a sealed trait ADT pattern to represent this.
That depends on the person and the other candidates, but I wouldn't rule them out automatically. You definitely don't need to learn the more advanced stuff to become productive with Scala.
&gt; it looks like it offends DRY by forcing you to check for a failed future and the error case of either. Those have two separate causes. It's similar to why you would have different catch blocks for different exception types in Java. Hopefully you don't have causes where it'd be smarter to do different things based on the type of an exception, but don't simply because of 'DRY'.
To be realistic, a Scala job is fundamentally a programming job which requires some knowledge of (1) object-oriented programming, (2) functional programming, (3) type system-driven programming, and of course (4) version control (git). After that, depending on what specific areas you're working in you need _some_ knowledge of (5) concurrency/parallelism (`Future`), (6) actor systems (Akka), (7) configuration management (sbt), (8) web programming (Akka HTTP nee Spray, or Play), and (9) data science (some math + statistics + R or Python i.e. Pandas, NumPy, SciPy). If you can demonstrate solid knowledge of (1) to (4), your chances are better than most others. When you're trying to get specific jobs, you'll need to demonstrate some knowledge of any of (5) to (9). Something else that boosts your chances despite not having programming work experience is a portfolio of projects you've worked on. GitHub is a perfect place to put such a portfolio.
I think there is a nice compromise for you in terms of semi-colons: Let the IDE display them for you. It's great because I never type them, but I still get the feedback from the compiler/IDE where it inferred them. There should be a button in your ScalaIDE toolbar to enable this.
Thanks for posting all this great information. I will take this like a road map to get a Scala job.
Yup, I posted an issue on Github, I hope it's going to be helpful...
Very cool stuff! Have you any real-world (probably OSS) projects using all this nifty things?
Sri is new baby in the town , but scalajs-react web apps already in production :) 
Is it compiling everything to scala.js or native code for each platform ?
Just seeing what's out there tbh, i like play :)
Didn't expect to see that pop up here, thanks predef! I'm the author of Tabulate, so feel free to send questions and suggestions my way.
If you want to use either for error handling, You should really be using Future[X \\/ Y] where X is your error type and Y is the type you want to receive. If you're using exceptions, then I recommend scalaz's Task which is basically a Future[Throwable \\/ Y] but it's a bit of a jump because scalaz's futures are a bit different than the standard ones. We actually use this to achieve DRY because we can chain operations of this type together monadically and only deal with errors once at the end of the world. 
What if my whole program is monads?
First, do you really need to build it? It's already build for a variety of versions. The Spark site has explicit instructions on building it, which I believe make you go through maven, and setting MAVEN_OPTS to what it recommends makes it build ok. Though having such lame defaults in maven or sbt is really disappointing. 
I am able to do that. The part I'm confused with is how to use succ and pred to carry out the math operations. 
This is a maths question. See the “Arithmetic” section of https://en.m.wikipedia.org/wiki/Peano_numbers and use pattern matching to detect zeros.
def sum(a:Int,b:Int):Int = if(b&lt;1) a else sum(succ(a),pred(b)) Does this make sense? It works in my head, but want a second opinion since it's pretty late and my mind isn't fully functioning.
Have you tried it?
Cool stuff! Seems to be simple enough to use for hot recompilation of client side stuff in my web projects :)
Any blog post where I'm quoted gets the thumbs up from me. ;-) More seriously, I have a similar aversion to actors but I've been reasonably happy with the few forays I've made in Akka Streams. I think the programming model is perhaps a bit too complicated, but it is reasonably clear what is going on. More generally it's a really interesting time for streaming systems in Scala. Scalaz-streams is getting a big new redevelopment (now called FS2), and Monifu is another new entrant. I think it's great to have this choice available.
&gt; This suggests that implicit dependencies propagate upwards failing at the first in a nested sequence This statement is mostly nonesense, can you reword it? &gt; This is unfortunate and misleading behavior, and means you can end up in a nightmare of guesswork if you are not watchful of implicit dependencies. It's not misleading at all, it did not find a valid `Functor[Future]`, however the compiler in it's default settings could say more about implicits it considered, but did not use because all conditions weren't satisfied. In the meantime you can use `-Xlog-implicits` to have the compiler tell you about all the implicits it considered. EDIT: Also Intellij got a feature a eariler this year to show a graph of implicits considered on any expression with just a keybinding, which is more convenient to use. http://blog.jetbrains.com/scala/2015/03/05/scala-1-4-eap-brings-advanced-implicits-analyzer-and-faster-play-compiler/ 
Could you share some "prooflink-s" ?
Define a seperate method for `giveMeMyDocument()` to use which is implemented by the leaf class. $ scala Welcome to Scala version 2.11.6 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_51). Type in expressions to have them evaluated. Type :help for more information. scala&gt; trait Documentor { protected def document: String; def giveDocument: String = document } defined trait Documentor scala&gt; trait DecoDocumentor extends Documentor { override def giveDocument: String = super.giveDocument + "Decorated" } defined trait DecoDocumentor scala&gt; trait DecoDocumentor2 extends Documentor { override def giveDocument: String = "Prefix" + super.giveDocument } defined trait DecoDocumentor2 scala&gt; object HelloDoc extends Documentor with DecoDocumentor DecoDocumentor DecoDocumentor2 scala&gt; object HelloDoc extends Documentor with DecoDocumentor { override def document = "Hello" } defined object HelloDoc scala&gt; HelloDoc.giveDocument res0: String = HelloDecorated scala&gt; object GoodByeDoc extends Documentor with DecoDocumentor with DecoDocumentor2 { override def document = "GoodBye" } defined object GoodByeDoc scala&gt; GoodByeDoc.giveDocument res1: String = PrefixGoodByeDecorated scala&gt;
environment variables can be set in your shell when launching SBT, no? I mean, I only see it making sense when starting the SBT.
What's the problem?
 def sum(a: Int, b: Int) = b match { case n if n == 0 =&gt; a case n if n &lt; 0 =&gt; sum(pred(a), succ(b)) case n if n &gt; 0 =&gt; sum(succ(a), pred(b)) } that's it for sum, it should get you an idea how to do the others. 
I'll have to scrap the whole thing!
Oh, so you mean the leaf class is there just as a placeholder with an abstract method which I define and let the decorators decorate?
Use scalatra. Sry I'm not like play. (maybe that's my fault) because: - the routing is not part of the application (yes, I think this is one of the worst thing about play, the route is must be a part of the application and not a separated thing) - using guice instead of cake pattern (scala have compile time di, why using runtime tools? I try to avoid every annotation based things in my application) I made play vs scalatra (in jetty 9) performance comparison (in scalatra I using akka) and no performance difference between the two solution. 
You dont have to use guice with Play, you can use any kind of DI you like. 
I couldn't care less for scalas image of maturity and robustness if that would buy me actual robustness. Daniels proposal seems wonderful. If Daniels proposal gets through, and a sizeable part of the scala FP community gets behind it, this would be more than wonderful for Scala. The Great FP War would be instantly over. Large swaths of scalaz and cats would become obsolete, and the parts that won't would integrate more easily with stdlib collections. For me, as a scala hobbyist, this would be amazing. I would no longer have to choose between projects and worry about comparability. I would never have to deal with libraries that are useful but nonetheless insist on giving me Seqs anymore. I could use map on collections without that nagging feeling that I have actually no idea what I'm doing anymore. If it would suit my needs and/or curiosity, I could even write code that integrates with the stdlib. This might be the best proposal in scala I've ever seen. If that costs me the image of robustness and maturity, I'll deal.
Thanks, the correction, but it's not change the first (worst) point. 
&gt; A focus on just the core collection types: maps, sets, linked lists, and some form of array-like sequences (maybe Array itself). I think that's too short-sighted. Personally, I find `Vector` one of the most useful types, and I'm not sure this is included here since `Array` is mutable. Also `Range` obviously is a very frequently used type. Also, knowing that there is a `Queue`, `Stack` or `SortedSet` in the standard library _is_ a great feature, even if you use them less frequently.
From my point of view, things could be quite easy: We would have some base classes (`Set`, `Map`, `Stream`) and some traits (`parallel`, `mutable`, `persistent`) we can combine with these classes. Then we would have some type classes (`traversable`, `foldable`, `indexed`, `mkString`) that can be used outside the collection library (e.g. to fold over Strings). Of course such a collection library might work but it will never be fast. For optimizations I would use macros, that can compile the collections down to several backends (Java collections, Java arrays, LAPACK/LINPACK/BLAS, GPU specific backends, etc.) Macros can make very powerful optimizations, but of course they are quite slow during compile time. So we should just optimize the compiler for the commonly used collection optimization macros. If someone wants an different collections optimizer, this is easily possible but will result in much slower compile time. I am not sure about the implications of such a scheme, and I don't have straw man or even a workable example. But I my gut feeling says that it *could* work. 
Cross-posted to [/r/programming](https://www.reddit.com/r/programming/comments/3okxhw/ant_colony_optimization_in_scala/). This is very ML-style Scala, with clear modules but functional implementations. I don't shy away from local mutation, but effects are not exposed outside of individual functions. Feed-back is appreciated!
Unless I'm overlooking something, he said people never do X twice: * I have never, ever called map on BitSet passing a function of type Int =&gt; String * Look at it this way: do you ever create a value of type Seq? [...] we never ever do it. If you, by "several" mean "both" you may be a very strong exception. I didn't know anyone ever mapped a BitSet to a String. I'd be interested to hear how it's useful though. Could you share your use case (here, or preferably as a comment on the gist. This may be useful information)? If you mean, you have used Seq.apply, I can sort of understand. I have too. I probably shouldn't have though, and wouldn't miss it being gone. I just tried to understand what it even does, and I can't find out. It's defined in https://github.com/scala/scala/blob/v2.11.7/src/library/scala/collection/generic/GenericCompanion.scala#L1 for your viewing pleasure. The word awful appears twice: * Have you ever tried to implement a new collection that sits in the collections hierarchy? I have. It's awful. &lt;- this is true. * There are some useful abstraction lines that we can draw, but something as blunt as Seq simply isn't going to cut it, and it encourages absolutely awful behavior. &lt;- a little hyperbolic The word terrible doesn't appear in the document at all.
Thanks! My thoughts... - Generic interfaces: I disagree that being able to call `apply` or `:+` on a `Seq` is bad. If that's primarily what you want, ok, then use the `IndexedSeq` type, but in many occasions where there is no performance bottleneck, allowing a `List` for example to enter here is totally fine and no need to change the API signatures. - `CanBuildFrom` - I don't understand why nobody loves this. I frequently use `map` to go from `Map` to `Seq`, `List` or `Vector` or vice versa. Neither do I find it too "complex" nor wrongly designed. - custom collections - I agree that you have to scratch your head a bit until you get them right - goals - I largely agree here. Daniel's sample code is simple and nice.
Serious question (to anyone who can answer), regarding his List map implementation: def map[B](f: A =&gt; B): List[B] = this match { case head :: tail =&gt; f(head) :: (tail map f) case Nil =&gt; Nil } Won't this blow the stack with a long list? Or am I taking this gist too literally?
To be fair, the Java collections are a bit more low-level and simple compared to Scala's very ambitious collections API.
If I'm not mistaken, it's also to maintain compatibility with java. 
`Seq.apply` comes from the `Seq` companion object via its inheritance hierarchy, where `apply` is ultimately defined in `GenericCompanion` and uses the abstract method `newBuilder` to kick off construction and `result` to complete it. The path is `Seq -&gt; SeqFactory -&gt; TraversableFactory -&gt; GenericSeqCompanion -&gt; GenericCompanion`. The `newBuilder` method is implemented in the `Seq` companion object directly. package scala package collection object Seq extends SeqFactory[Seq] { /** $genericCanBuildFromInfo */ implicit def canBuildFrom[A]: CanBuildFrom[Coll, A, Seq[A]] = ReusableCBF.asInstanceOf[GenericCanBuildFrom[A]] def newBuilder[A]: Builder[A, Seq[A]] = immutable.Seq.newBuilder[A] } That delegates to `scala.collection.immutable.Seq.newBuilder` - so you at least "know" (i.e. can derive) that the default `Seq` type is immutable. The definition in `immutable.Seq` is pacakge scala package collection package immutable object Seq extends SeqFactory[Seq] { /** genericCanBuildFromInfo */ implicit def canBuildFrom[A]: CanBuildFrom[Coll, A, Seq[A]] = ReusableCBF.asInstanceOf[GenericCanBuildFrom[A]] def newBuilder[A]: Builder[A, Seq[A]] = new mutable.ListBuffer } And that returns a `mutable.ListBuffer` which returns an `immutable.List` on `result`. Therefore the default `Seq` type is an immutable `List`. Seq(1, 2, 3) res0: Seq[Int] = List(1, 2, 3)
Exactly, and this is why the current implementation looks less "elegant" but actually avoids such pitfalls: https://github.com/scala/scala/blob/v2.11.7/src/library/scala/collection/immutable/List.scala#L272
Nice. From glancing over it, you might have some trouble with accumulating `mapValues` calls in each iteration (*). I think you end up there with a linear slow-down. (*) https://stackoverflow.com/questions/14882642/scala-why-mapvalues-produces-a-view-and-is-there-any-stable-alternatives
Unrelated to OP, but this `Seq(1, 2, 3)` thing reminded me that one thing I wish would be done is make those constructors very fast. If I'm not mistaken since the `apply` method takes _aleady_ a sequence (`A*`), basically when you write `Seq(1, 2, 3)` or `Vector(1, 2, 3)` or `List(1, 2, 3)` you make Scala produce an entirely useless throw-away sequence just to be passed on to the `Builder`. Instead, if the companion objects' `apply` method would be a macro, it could flatten those var-arg literals all away straight into the collection's builder. Or not?
That's pretty awful. Thanks for the heads-up!
And this is relevant to Scala programming... how? 
A bunch of devs, likely Scala devs, just entered the market
I wouldn't use free monads in Scala as the JVM doesn't have tail call optimization. A free monad chains the calls to map and flatMap in a non-tail recursive function. The heap implementation of free monads is too slow to be usable.
What are the best plotting libraries for scala? The plot at the bottom of this reminds me of `seaborn` for python.
I do not get it, why couldn't they have more teams and keep all the people but making them work in parallel. Let's say have 30 small teams instead of 20. They were trying so hard to find the best people and now they are firing them because their strategy of how they work changed. 
4100 employees for a relatively simple and not profitable service like Twitter is simply too much. Compare this to WhatsApp's 55 employees ...
In most cases Scala's return keyword works just like C style return. In most cases the compiler just emits an ireturn/lreturn/dreturn/freturn/areturn instruction and the VM (more-or-less, usually, ish) just does whatever your platform's return instruction is. But once you have nested function values Scala does something different. It's explainable semantically, but it's complicated enough that you're better off avoiding return in Scala without very specifically needing it. As for a tight @tailrec loop - that's exactly when you don't need return 
So the 'refresh' from TASTY in a binary-incompatible dependency resolution is a separate step that kind of "rewrites" the jars before they go on the classpath or into an assembly jar?
I've actually never used Atto, and never compared the two. I compared against scala-parser-combinators, and I think I know why it performs better (in the talk!). I'd be interested in a comparison with Atto if anyone had an Atto JSON parser to throw into the ring
Isn't that a bit premature? As far as I know, the macro API will change fundamentally with Scala 2.12.
would it be possible to use the presentation compiler instead? I believe scala ide is doing it, so they get support monocle macro annotations for free.
According to the [roadmap](http://docs.scala-lang.org/overviews/macros/roadmap.html): &gt; At the moment, we don’t plan to introduce new reflection- or macro-related features in Scala 2.12, so the functionality of Scala 2.12 and Paradise 2.12 is going to be the same as Scala 2.11 and Paradise 2.11 modulo bugfixes and stability improvements. Plus, if I'm not mistaken, what IntelliJ does is provide an API for _its own_ PSI (which is not Scala ASTs). Here is the example from Monocle: https://github.com/JetBrains/intellij-scala/blob/idea15.x/src/org/jetbrains/plugins/scala/lang/psi/impl/toplevel/typedef/MonocleInjector.scala
Your question would be much clearer if you abstracted away from the details of your particular problem. The details of your image parsing code are not really relevant, for example. I might be able to write a solution later today, assuming I understand the question correctly.
Solution is here: https://gist.github.com/noelwelsh/2b27272573c0e5294bb4 There is a cleaner solution using a monad transformer, but what I have in the gist is a direct solution to the problem you described (and the setup is what I mean about abstracting away the details---reading images is irrelevant, it's using the value in the state monad to control termination of the loop that is the essential part of it.) Possibly worth a blog post.
Hey /u/three-cups, I think your initial question was answered by /u/paradigmatic but after reading your code I wanted to also point you to these resources: - Cool lib for configs in Scala https://github.com/typesafehub/config - Instead of `null` always consider using an `Option` instead: http://www.scala-lang.org/api/current/index.html#scala.Option
Really nice read. I recently found myself wishing there was a monadic interface to akka streams, but until now took the concept of a Flow for granted and had no idea that I would give this up with some alternatives. Also thanks for the concise handle on Kleisli.
Thanks a lot for your response! Yeah, I see what you mean, and that's exactly what I was asking for. There was no need for me to write irrelevant details about images. Your example is very clear. Thanks a lot! EDIT: Rephrasing, because it seemed I was being rude on a sentence. Sorry! 
Do you need state here? You just reading file into array of bytes, group this bytes into records and then process _array of records_. Sounds stream processing to me :)
Would work fine if you'd synchronize the entire optionalProp method. Now there would be only 1 way to read and write to the properties object and its trough a synchronized block. Anyways I prefer akka for this kind of stuff. It makes it a lot less abstract.
Typessafe config is really nice, and can also be used in Java land if needed
Cool, thanks for clarifying.
Its a technique to do multi threading. Basically you send messages rather than calling methods. Using synchronize is fine to, I just think it becomes a little easier to reason about the code paths. It of course remains a difficult subject and with akka there are also many pitfalls (you drop type safety somewhat for example). [Docs](http://doc.akka.io/docs/akka/2.4.0/scala.html)
Are you sure? 3145728 is 3.14 x 10^6 , 3145728KB is 3.14 x 10^9 bytes. Isn't 10^9 bytes a gigabyte? 
Yup, missed a thing. I am derp. 
https://news.ycombinator.com/item?id=10068058
Also Ruby, Python, or Perl. This is a waste of effort.
Actually, dependency injection is commonly thought of as being the process of passing or "injecting" a dependency to a component at construction time, as opposed to having the component create or find the dependency itself: &gt; An injection is the passing of a dependency to a dependent object (a client) that would use it. The service is made part of the client's state.[1] Passing the service to the client, rather than allowing a client to build or find the service, is the fundamental requirement of the pattern. (https://en.wikipedia.org/wiki/Dependency_injection) Guice and Dagger are dependency injection *frameworks/toolkits* which automate the process of explicitly passing the dependency, through the use of reflection or other meta-programming.
Not sure why you assumed I hadn't read the ~article~ slides. If there's specific mention of Ruby, other than in the ridiculous "DANGER BELOW" splats, I didn't see it. Anyway, just to tack onto "my waste of effort" statement, let me add, horrible. &gt; This leaves Perl on the table. So we have a Java based solution that claims to be better than Perl. I'm not sure who that's supposed to impress, but I guess there was an audience for Ant too, so anything is possible.
Does [Specs2](https://etorreborre.github.io/specs2/) not meet your needs?
Any hints as to how Dotty would behave in this case?
Thanks a lot for your reply! To be honest, I didn't think of Streams, as I was more focused on how the state would change every time I read a record. I'll give this one a try too.
Dunno. I just vaguely remember that being a design goal.
Creating a new test configuration ration in sbt is as easy as just creating a new config and adding the default test settings to it lazy val DBTest = config("dbtest") inConfig(DBTest)(Defaults.testSettings) libraryConfig += "org.mytestFramwork" % "mytestFramwork" % version % "dbtest" libraryConfig += "org.memorydb" % "mymemorydb" % version % "dbtest" You can now have a src/dbtest/ directory with sources for tests that connect to a DB that you can run from sbt with `dbtest/test`
no, that is not a problem
I 100% agree with your sentiment. In the past, I've used class extension to pass parameters via the constructor to do this. That worked fine, except I wanted to get rid of the class extension. Is there a way to get this without class extension? BTW, The reason that I'm trying to not use class extension is because of the constraints of the single-inheritance model enforced by the JVM.
If a method is generic in the trait, it must be generic in the implementation of the trait. This isn't a reflection thing at all actually. The first Getter definition says that every getter must have a method get that returns some T that is a subtype of Object. It can't specialize that T it has to work "for all" T, which doesn't really make sense in this example.
Oh. I was going by [this](http://stackoverflow.com/questions/26567370/how-to-get-rid-of-class-type-required-but-t-found) and similar examples which use ClassTag. Original error message (in my real use case) was class type required but Entity found and googling that had lead me in the direction of type erasure. Thanks!
I wish Scala was pushed as an official language for Android (with the required runtime libraries in the Android builds etc). I think it would be great for Scala and much nicer for people to get into Android development too.
That ship has sailed: upcoming Scala 2.12 requires Java 8, and who knows when/if Google will support a non-ancient Java. I'd say that the immediate future WRT to Android development is Scala.js via React Native.
The absolute worst way to write an android app using scala: scala.js and react native. Also, just because 2.12 is out doesn't mean 2.11 is obsolete. There are no compelling features in 2.12 to force a migration at this point (personally, for the longest time, I used scala 2.8 even though 2.10 was out and 2.11 was impending). The ship has most certainly not sailed. 
There's nothing preventing anyone from implementing a DEX compiler for Scala similarly to how Scala.js outputs it's own IR. There's just been little motivation to do so when you can reuse Google's classfile to DEX compiler. 2.12 features like the classpath optimizer would actually make a compiler plugin nicer to use instead of relying on Proguard like many apps do now.
Scala 2.11 for Android is a dead end. Some day the official support for this version will be stopped. And even today Scala is not the best choice for Android development. Scala and Android will never become good friends. This is sad but as simple as that.
Can you substantiate that claim? Because I'm not aware of that.
That didn't give me anything to support your claim. Bear in mind "googling" is user-aware; we may just get different results on our ends. It would be nice if you'd post some hard links.
I'm not seeing anything, and I would be surprised if there was anything substantial given that both languages generate Java bytecode without much indirection (no Groovy/Clojure/...-like stuff). Scala is probably a bit faster because it has a better, optimizing code generator.
then you can keep using scala knowing it's faster than kotlin.
Guess, my main man, you can do that.
Mimshot - try again, I was able to load it on my phone (Iphone 6)
Yes, Scala is definitely a lot more fun than Java, especially more fun than Java 6. But Scala comes with a big additional library and since Scala 2.12 will require at least Java 8 it is a dead end for Android development (as already said). The best choice for Android in my opinion is Kotlin.
Dropping official support doesn't mean much. This is the same situation as java and android. Dead end it may be, version-wise, but you are not the least bit limited. As a comparison, the last java 6 update was in early 2013, more than 2 years ago. This has not impacted android in the least and will continue to be the standard for years to come. Even if typesafe support for Scala were to be completely dropped now, that would not affect its utility on android for years. 
Scala is a considerably better language than kotlin. You should use kotlin on android if all you want is a java++ (I support kotlin in my build tools) 
What /u/ItsNotMineISwear wrote is correct. You could get around this using, say, a type member like trait Getter { type T def get: T } final case class User { type T = String def get = "foo" } but *don't do this*. There is almost certainly a clearer way to reformulate your problem that won't involve type member gymnastics. 
Now I can use Scala for analyzing all the data that Im scraping with my Node server. 
C doesn't have classes, so there's no generics or anything like that there either
Didn't they already have CasBah for that?
Have you tried something like: new HBox { children = (1 to n).map(_ =&gt; makeMyWidget()) } 
Yep. Understanding the generics and why / how to use them now. It was just the proverbial, "huh?" for me for a few moments lol.
Last time I looked at Casbah it was synchronous (meaning blocking) and a bit intricate to use. Not to disregard the effort, I always felt there should be a better match for the Scala ecosystem, seeing how most infrastrucures are based on non-blocking IO (through the use of Akka or Netty). As such, and from the limited time I spent looking at the presentation, this approach looks quite promising! 
Also ReactiveMongo
 def foo[A](in: A): A creates a type variable with no constraints. Read as "for all A in TheSetOfScalaTypes". You can call foo with a value of *any and all* types. def bar[A &lt;: Bar](in: A): A creates a type variable with a constraint that it is a subtype of Bar. Read as "for all A in TheSetOfSubTypesOfBar". You can call bar with a value of *any and all* types that are a subtype of Bar. It seems clear to me that def foo1(in: Int): Int is not a substitutable for foo (so, not a subtype). foo can be called with a String; foo1 cannot. This is the case in exactly the same way that def bar1(in: SomeSubTypeOfBar): SomeSubTypeOfBar is not substitutable for bar.
Yeah, that's logical. To quote myslef: "If I understood correctly, it's the fact that the implementation above is not really implementing get() since it has a different (more specific) signature." Here foo1 has a more specific signature; it only works for Ints. I mean, thanks for confirming it, but that's pretty clear now to me. But then, how is it that you cannot have def foo[T &lt;: SuperClass]: T and implement it with def foo[SubClass]: SubClass but you can have trait Foo[T &lt;: SuperClass] and extend it as class Bar extends Foo[SubClass]
You are right, they will make sure that your system is not blocked by a request (as long as you spawn a new actor for each mongo query) but it will still idle and consume CPU.
People still use MongoDB?
So, you've got nothing. 
The short answer is that extending a trait is the equivalent of calling a method. You can think of one being function application at the type level (extending) and one at the value level (calling a method). 
You can set or bind preferred and maximum widths for HBox/VBox. If your text has very absolute positioning within the rectangles/boxes, I would recommend using a Group though.
Yes.
Sorry, I haven't used swagger yet.
Yes, but is it [consistent](http://r6.ca/blog/20110416T204742Z.html)? That's the main reason to run darcs these days.
Is that really different from just having the worker though? You can always send a message to an actor, its mailbox should "be reactive" no matter if the actor itself is blocked or not. So wrapping one or N workers in a boss-actor would really only serve to reify the act of message passing. Due to the blocking operation you would only be able to fully serve ~N connections simultaneously, if the DB access is the limiting factor. The server would accept an unlimited number of incoming requests but anything over ~N would give slowdowns due to the N working actors standing around doing nothing while waiting for the database to return.
If I read [their theory page correctly](https://pijul.org/Theory), yes, it is consistent.
Seq isn't a concrete type
I'd only ever use Scala either if scalaz isn't permitted to be in the project for some reason.
If you're willing to use a trampoline rather than TCO you can use scalaz disjunction loopRight for fail fast recursive semantics
In Scala the return statement is not semantically equivalent to implicit return
Does intellij offer a feature like that?
There isn't really one recommendation. There are lots of library options. There are some plans to clean this up. See [here](https://github.com/scala/slip/issues/19) for more details.
Or not an error.
It's extraordinarily difficult to do it well. SJSIR does not support java libraries. This is a requirement on Android.
I think [better-files](https://github.com/pathikrit/better-files) is probably the best library right now.
Thanks. Most Scala job posting are looking for +5 years experience developers.
It's painfully complex to do simple stuff that should be one-liners. So you should use java.nio.file._ instead (Path, Files, etc).
There isn't a consensus yet, but [Ammonite-Ops] (http://lihaoyi.github.io/Ammonite/#Ammonite-Ops) &amp; [better-files](https://github.com/pathikrit/better-files) are both great for simple, quick &amp; dirty I/O. For everything else, particularly production code, java.nio is good. I believe ammonite &amp; better-files both target "simple" use-cases but they probably silently swallow some exceptions to do that.
I tried appending Arbs to it but it didn't work. I got an error saying &gt;vector + x found: arb.arb required: string Where x is my Arb "object" that I've created. Is it possible that I am creating my vector/initializing my vector incorrectly? I found a way to get past this error by putting the arb object into the vector when I initialize the vector but it doesn't work when I try to use loops and then append using the + operation. 
Honestly, someone should make a SLIP ticket for a proper, scala written, IO library. Something like the design of better-files, but also has stuff like * Having stuff like `Future[File]` when doing async file IO * Written completely in Scala, and not just a low level wrapper (will help tremendously in the future when non JVM backends are used) We should not be having competing libraries for something as fundamental as file IO
Looks like someone has started [a discussion about it](https://github.com/scala/slip/issues/19) as pointed out by eeperson. But in reading over that, I don't see any consensus forming yet.
Cheers, I didn't know there was an SLIP for that, commented on it!
[scalaz-stream](https://github.com/scalaz/scalaz-stream/blob/master/src/test/scala/scalaz/stream/examples/StartHere.scala) is pretty good
[removed]
Well obviously for the operations that only make sense to do so. The main point I was making is that Scala (unlike Java) pretty much has a standard for async operations, its `Future`. Well, to be fair, Java also has `Future`, but the API for Java `Future` was so bad that it couldn't really be used for file IO (and `java.nio` came out before Java Future iirc). When you use other more modern languages that deal with async IO (such as node.js), they use the same interface for async IO as they do for other async operations (i.e. async HTTP requests, async DB requests) tl;dr If you are doing async operations, you should be dealing with a `Future[T]`, if you are doing async operations, you will be dealing with just `T` I dont think its entirely possible to make sure all possible file IO operations have an async version, operating system support for async file IO support is not consistent (i.e. the story for linux in this area is pretty bad), so there may be a reason why `AsynchronousFileChannel` only exists for certain file operations, but I don't know enough in this area to give a completely correct answer.
Personally, I like having a seed project -- a git repository that is empty save for all the new project scaffolding like SBT, unit testing, etc. When starting a new project, I just clone that. Most of it will get replaced eventually for project-specific things, but it helps get the first couple of classes running. From that point on, my main problem to solve is directory structure -- src/com/name/othername/packagename/class.scala is super unwieldy without an IDE and so far I've found no good enough solution.
You mean `:load x`, right? That's the REPL command to load a file `x`. Also works great if you set up a predefined script that you want to try out--you can load that, try it out, then clear out your session with `:reset` and iterate if necessary.
I normally use [giter8](https://github.com/n8han/giter8) for this
Good point.
The problem with Seq is that you have no idea whether it is finite, mutable, iterates with reasonable performance characteristics, etc (does the code you have keep these things in mind?) Something better to accept or to pass around is exactly what you need. Often this will be something you can fold. A foldable typeclass can be used for that. As far as returning goes, just return what you have. A List or a Stream or a Vector, or what have you. This exposes some internal structure, which generally isn't much of a problem.
Mmm. OK, thanks. I would expect a Seq to be capable of efficient iteration, but that's about it. Not that keen on the idea of exposing more implementation detail than necessary.
Both, Scala and Android have a steep learning curve. In addition to that you will have a more complicated and furstrating build setup with unofficial Gradle or sbt plugins rather than the official products (e.g. ProGuard or MultiDex configurations). You should definitely learn to code Android applications in Java before experimenting with Scala on Android. In my personal experience Java is a rather easy and straightforward language to learn. Android and Scala are obviously hard to compare, since one is an SDK and the latter a programming language, but the timely effort necessary to feel comfortable in any of them succeeds learning Java drastically.
To complicate things even more I am from Hawai'i in California for a few months for health reasons and thus did not bring my desktop so any learning I am doing is all on my tablet...lol. Like I said in the op I have done some programming (basic) in java so I understand some of it so I am not starting at nothing. To me it seems like once you understand the basics of java then you can learn scala... It's like I can code in JavaScript (and did for years...just slowly) but about two years ago I learned about jQuery and it made all my website and greasemonkey work I do so much easier and faster because for me it just...made more since...not really sure how to explain it. I know that jQuery is just a library to JavaScript so maybe Scala is not really what I am looking for but when I was looking at some example code in scala it just looked so much like jQuery... That I just assumed...lol. So please if you know what I am trying to say about jQuery and feel you know that Scala is not what I really am looking for but has an idea of other things that might be up my alley feel free to say.
That's some funny looking Scala code at the bottom! Google "case classes". And avoid 'vars' unless you have a good reason to, i.e performance.
&gt; When starting a new project, I just clone that. Most of it will get replaced eventually for project-specific things, but it helps get the first couple of classes running. &gt; The problem is I feel like I can't program Scala without an IDE at all. Especially without the type information the IDE gives me.
Scala is a language in its own right that happens to be interoperable with Java. It's not like jQuery, which is a JavaScript library and not a language to itself. Basically jQuery is to JavaScript at Guava is to Java - a library written in the language that makes certain tasks much easier. Scala is a different beast. Scala cannot compile with Java compilers. It requires the Scala compiler. But it does run on the JVM so it can interoperate with other JVM code that may have been written in another language like Java, Clojure, or many others. Since Scala compiles to JVM bytecode, you can use Scala to do Android development, though it doesn't have official support. There are a few frameworks that aim to make Android development with Scala easier like [Scaloid](https://github.com/pocorall/scaloid) and [Macroid](http://macroid.github.io/).
Try solving some problems of [scala 99](http://aperiodic.net/phil/scala/s-99/). On your tablet you can use [ScalaKata](http://scalakata.com) to write Scala code in your browser.
Yeah in a post above I was talking about jQuery being a library because I just knew someone would say something... Lol. You gave me alot to Google.... Have to me is a fruit that grows on a weed tree taking over the island... Lol....also scaliod is how i first learned about Scala. Bummer about the compilers wonder if a can to one of the app developers to add support. 
&gt; a lot of jQuery in the fact that it makes js "readable" and simplified js for me...is that kinda like Scala too? Yes and no. It reduces boilerplate code, so in a sense it's definitely shorter. But shorter != simpler. I'd say the information density in Scala is much higher than Java.
Trampolines spend memory to avoid stack overflows when you can't do tail call elimination. It seems like you could implement this as a straight recursive tail call so I wouldn't use state or a trampoline at all. 
Whats your JDK version and patch level? JavaFX still has lots of bugs
Thank you for your reply! To give some more details of the problem, I have to read a register from a file, extract a part of it an process it, and then read the next one, and so on, until there are no more registers in the file. The idea of using State was because every time I read a register I need to drop it as well in order to read the next one. I'm thinking about what you mention (no need for State or Trampoline), and the only thing that comes to my mind now (it's 10:30 pm in Japan now :) ), is, when reading a register, to return something that let me know where to read the next time I need to read, along with the next register, something like tuple (info for next reading, result of this reading), but this comes to what State does. Let me give a it a deeper thought this weekend, after a good rest :) Thanks again!
Where to read is state for sure but it could be implemented as a parameter to a recursive function. If the state monad could express that recursion in constant memory and stack space it would be appropriate but I suspect you'll hit Scala/jvm limits in that regard and might have to express it explicitly instead of abstracting it via the monad.
There's a lot of boilerplate involved in using type-classes in this way in Scala, and it really tends to obscure the intent of the code in my opinion. Nonetheless, here's how you might do it: https://gist.github.com/hakuch/11c1488c8b63a45276e4 Libraries like [cats](https://github.com/non/cats) are using additional libraries and compiler plugins to reduce this complexity, but ultimately the snippet is fairly close to the result that's produced. You might also be interested in looking at [spire](https://github.com/non/spire), which has set the standard for this kind of stuff in Scala in the past. I agree that it's obscure and complex, and I'm very open to seeing other's take on a good solution. 
A `Numeric` is a type-class, so if your matrix element type is `A` (such as `Float` or `Int`), you need an implicit instance of `num: Numeric[A]` to perform element-wise addition. You can use `import num._` to get syntactic sugar so you can write `elem1 + elem2`, instead of `num.plus(elem1, elem2)`. For example: trait Builder[CC, A] { def append(elem: A): Unit def result: CC } trait Matrix[A] { type Repr &lt;: Matrix[A] def shape: Vector[Int] def rank: Int = shape.size def size: Long = (1L /: shape)(_ * _) def newBuilder: Builder[Repr, A] def iterator: Iterator[A] def elementWiseAdd(that: Matrix[A])(implicit num: Numeric[A]): Repr = { require(this.shape == that.shape) val b = newBuilder (this.iterator zip that.iterator).foreach { case (x, y) =&gt; import num._ b.append(x + y) } b.result } } I'm using a `Builder` here in order to obtain a new immutable matrix after addition instead of replacing values in a mutable matrix. Of course you could update `var`s instead, but often it's easier to reason with immutable objects. Here is an example of a two-dimensional matrix: import scala.reflect.ClassTag object Matrix2D { def tabulate[A: ClassTag](rows: Int, columns: Int)(elem: (Int, Int) =&gt; A): Matrix2D[A] = { val data: Array[A] = (0 until rows).flatMap { r =&gt; (0 until columns).map { c =&gt; elem(r, c) } } (collection.breakOut) new Matrix2D(rows, columns, data) } } class Matrix2D[A: ClassTag] private (val rows: Int, val columns: Int, data: Array[A]) extends Matrix[A] { type Repr = Matrix2D[A] def shape = Vector(rows, columns) def iterator: Iterator[A] = data.iterator def newBuilder = new Builder[Matrix2D[A], A] { private val peer = Array.newBuilder[A] def append(elem: A): Unit = peer += elem def result: Matrix2D[A] = new Matrix2D[A](rows, columns, peer.result) } override def toString = iterator.grouped(columns).map(_.mkString(" | ")).mkString("\n") } val a = Matrix2D.tabulate[Int](4, 3) { case (row, column) =&gt; if (row == column) 1 else 0 } val b = Matrix2D.tabulate[Int](4, 3) { case (row, column) =&gt; if (row % 2 == 1 ) 2 else 0 } val c = a elementWiseAdd b (The `ClassTag` is only needed because we're using arrays here as backing store)
Type classes are the way to go. I recommend approaching implicits through the patterns they enable (namely, type classes) rather than just picking up the implicit machinery without context. Implicits are like assembly---powerful but you want to build higher-level constructs on top of them. You can understand the higher-level constructs without understanding all the underlying machinery. There is a lot of boilerplate involved in encoding type classes with implicits. There are a few SBT plugins that will remove this boilerplate: - [Simulacrum](https://github.com/mpilquist/simulacrum/) allows you define type classes directly with an `@typeclass` annotation - [Machinist](https://github.com/typelevel/machinist) provides specialised (unboxed) and fast operator dispatch 
Congratulations, that's a huge step!
The gist above is a great example of the general outline. Spire is a good place to look for a more complete implementation (and likely provides everything you want already). 
You haven't included the stack trace in your code, and you haven't listed the Java version, Scala version or OS that you're running on, or how you're running it. Command line? From IDE? With what JVM options? This is information you should always provide whenever you're asking for help. Try starting with a basic known good application like import javafx.application.Application; import javafx.scene.Group; import javafx.scene.Scene; import javafx.scene.text.Text; import javafx.stage.Stage; public class HelloWorld extends Application { @Override public void start(Stage stage) { Scene scene = new Scene(new Group(new Text(25, 25, "Hello World!"))); stage.setTitle("Welcome to JavaFX!"); stage.setScene(scene); stage.sizeToScene(); stage.show(); } public static void main(String[] args) { Application.launch(args); } } 
We don't want to terrify the poor fellow.
Awesome. Just cloned the Dotty repo as per [Wiki install guide](https://github.com/lampepfl/dotty/wiki/Getting-Started) and compiled. 34 seconds `;clean;compile` on warmed up JVM; that's pretty good for 45kloc, particularly when compiler optimization/speed up work has yet to be done. Dotty imports into Eclipse without issue. Thrilled to take the new compiler for a test spin ;-) Thanks!
Thanks to https://twitter.com/connerdelights/status/657623877313523712.
Yes. The languages are very similar, the only major thing that dotty is not going to support is early initializers. We have trait constructors instead.
Also see https://www.reddit.com/r/scala/comments/3pwzan/dotty_has_finally_bootstrapped/
Thank you very much! This is actually great, but I have to dive in more. Especially since I "can" not use case-classes as I want my Vectors to be mutable (yes, I know... bad, bad boy, but in my 3D-engine I have to keep the GC at bay)
It is extraordinarily easy to build scala on android. Use the right tools. 
I maintain some algorithm implementations and interview question type problems in easy to understand Scala here: https://github.com/pathikrit/scalgos/tree/master/src/main/scala/com/github/pathikrit/scalgos
Do you have some documentation on how these trait constructors work?
http://docs.scala-lang.org/sips/pending/trait-parameters.html
You should have a look at scala-offheap. Sorry I'm on mobile so I can't link, but it might be worth using in your case
Can you tell me your steps please? I was using Activator ui. How to get this working and into IntelliJ?
Assuming you are on windows Make sure you have activator downloaded and stored someplace that is in your path open up a command prompt and go to the directory you want to store your project in Type: 'activator new' this will bring up a list of templates choose "minimal scala" it will then ask for the a name, this will be what it will call the directory it will create change directory to the newly created project you then can do a few different things depending on how you want to proceed... you can open IntelliJ and import this project as a sbt project (make sure you have scala installed in IntelliJ) you could edit you build.sbt in a text editor to add your dependency and then type 'activator console' to get a scala console and start interactively coding Let me know if that helps. I'm pretty new to scala myself, i come from a .net / python background and learning the tools in the java world was initially confusing but stick with it... the promise of what languages like scala are well worth the effort 
I don't know about windows, but on Linux Scala is super fun and easy to use. If I just want to test an idea real quick, I'd just make a simple text file on my desktop and run it in the command line like so: `scala script.scala` If I want to something a bit more serious, with some jar dependencies, I use sbt. Create a new folder, handwrite the barebone build.sbt file which is like 5 lines, put the source file in another sub folder, and then just `sbt run` All of this can be done from a simple text editor and the file explorer. 
I'm not sure how anyone else is supposed to relate to "15 minutes of random tinkering and it works" It either works or it didn't and your instructions are vague enough to mean anything. Perhaps you should do a recording illustrating what you're having problems with.
Clearly the range of answers speaks to the complexity... activator is nice because it has many examples/templates and will make adopting Play framework very easy... 
Whether it's gradle or SBT I've never really had it just work nicely &amp; integrate well into an IDE. You think as programmers we would make the best tools for ourselves first, and not put up with buggy integrations.
IntelliJ plugin has been sucking for me too, on OS X, I just use Eclipse.
You'll need to give better context to get an answer. We can't diagnose from something that small. Perhaps you should ask your TA or professor? As a shot in the dark, are your packages setup properly? You said it's every file at the top. 
You need to give us at least the text of the errors. Or if you can, attempt to create a simplified version of the part giving you trouble but that isn't your actual assignment's code.
and the [paper is here](http://arxiv.org/pdf/1510.05216v1)
The Scala compiler is mostly a train wreck, and probably not a good learning example. If you're on the JVM, look into ANTLR which is a parser framework and has many examples geared toward JVM targeted languages. 
I'm finding activator a bit tedious to use due to its dependency issues with various libs and scala versions. And this is considering I'm on the latest libraryset of everything.
The things you mention require no knowledge of macros or the compiler implementation. I suggest that you learn about the language itself (especially its type system) and forget about macros. They are a tool of last resort.
I wrote a play application using the documentation and vim and somehow it actually worked. Didn't take too long, the bare bones for a Play project is very simple.
I see DependencyInjection as an alternative to Factory objects not Singletons. They still expose global data though it's just easier to safely test.
Yes, I meant "defining" when I wrote "extending". Thanks for the reply, that gives me a start for an answer. It's kinda awkward that you have to choose between genericity and functionality though, because I assume this solution will force me to lose type-safety at some point if I want to use things specific to the postgres driver. 
Ok.
One can use [Acolyte](https://github.com/cchantep/acolyte) to mock JDBC, se you can test what SQL commands were passed. This might help
&gt; scalaz, typeclassic, Scala.js etc. require knowledge of macros,or hooking into the scala compiler and understanding of the phases of the compiler scalaz and typeclasses don't require knowledge of macros or hooking into the compiler at all. They just require understanding of implicit parameters. I suppose that is "hooking into the compiler" in a way since you can end up programming using implicit search, but regardless, macros and deep compiler knowledge are not going to help you there. &gt; Runar's talk on the interpreter pattern touches on this too - build an AST/DSL, and a compiler/interpreter to give it meaning. Learning about scalac is pretty unrelated to Runar's talk (which is a great one). You just need to use a few implicits and then the rest of the Free monad stuff is just sealed hierarchies and other type-system stuff.
It's not just about having your dependencies packaged up. It's about where you get the instances to satisfy those dependencies. Packaging them up in a case class just moves the parameters to the constructor of the class from one place to another. object WithDeps { case class Adeps(b: B, c: C) class A(deps: Adeps) case class Bdeps(c: C, d: D) class B(deps: Bdeps) case class Cdeps(d: D) class C(deps: Cdeps) class D val d = new D val c = new C(Cdeps(d)) new A(Adeps(new B(Bdeps(c, d)), c)) } Isn't much difference than: object WithDirectParams { class A(b: B, c: C) class B(c: C, d: D) class C(d: D) class D val d = new D val c = new C(d) new A(new B(c, d), c) } In both cases the problem is creating and passing around the instances of A, B, C, and D. A dependency injection framework makes that part easier.
I'm definitely keeping an eye on the desktop module -- very interested in creating mac apps with scalajs.
&gt; I don't understand why nobody loves this. I think it has an accessibility problem. It (seems to) complicate the collections framework, and for what gain? I feel awkward. I spent some time in the past few months really drinking the kool aid on Can Build From and then to hear people not like it, I'm confused, hahaha.
Looks like an HBox containing a bunch of other HBoxes. Im not at my pc at the moment so let me know if u need more help.
The cluster examples weren't very good at communicating what exactly akka cluster is imo. Heres a simple explanation: Akka cluster is a membership service on top of Akka. That means nodes in a cluster can subscribe to events about when a node joins or leaves a cluster (and a few other events). A "node" is an ActorSystem, not an actor. Thats all it does. ([This diagram] (http://doc.akka.io/docs/akka/snapshot/common/cluster.html#State_Diagram_for_the_Member_States__akka_cluster_allow-weakly-up-members=off_) nicely shows the different events available and when they are fired) For your use case, you can subscribe to the "Up" message from the cluster that notifies you when a node joins. This will give you a [Member](http://doc.akka.io/api/akka/2.3.1/index.html#akka.cluster.Member) that points to the actor system (but not any specific actor). Now if you already know the path of the actor, you can use that to get an ActorRef via actorSelection. If not, you can simply send the [Identify](http://doc.akka.io/api/akka/2.2.1/index.html#akka.actor.Identify) message (any actor that receives that automatically replies with a message containing an ActorRef to itself) to the whole system (with *) and see which actors respond to build up a list.
[removed]
[removed]
[removed]
I think you missed the boat on typeclasses. Typeclasses are good for when you want to split data from implementation. Why would you want to do that? Well, it makes it easy to * Conditionally "implement" things. For example, for Ordering, there's the instance implicit def Tuple2[T1, T2](implicit ord1: Ordering[T1], ord2: Ordering[T2]): Ordering[(T1, T2)] = ... If Ordering were a trait you couldn't have both ordered and unordered tuples be the same concrete class. Since it's a typeclass, you can. * Have methods that are polymorphic on the *return* type. For example, in the play framework, `JsValue` has an `as` method that takes an implicit `Read[T]` and returns a `T`. Also, in Java, the `ResultSet` from retrieving from a database has a mililon methods like `getArray` and `getBoolean`. With typeclasses, you can have a million instances for a Result typeclass, and a *single* polymorphic get method. * Offer default values without having to have a concrete peice of data around. For example, consider the [Monoid](https://en.wikipedia.org/wiki/Monoid): trait Monoid[F] { /** The identity element for `append`. */ def zero: F def append(f1: F, f2: =&gt; F): F } If you use typeclasses instead of having F extend your monoid trait, then you can define useful helper functions like def foldm(xs: List[F])(implicit m: Monoid[F]) = xs.fold(m.zero)(m.append.tupled _) Additionally, the language that typeclasses were originally implemented in, Haskell, doesn't allow you to define multiple instances of a typeclass per type; you need to use a newtype wrapper to do that. [This is actually a good thing](https://www.youtube.com/watch?v=hIZxTQP1ifo). 
Dotty a compiler for a Scala-like language. The language is very similar to Scala, but simpler. Both Scalac (the current Scala compiler) and Dotty are written in Scala.
Why do you think it's a mostly invented problem?
I think the classic example is ordered sets? `insert` has a type signature like this insert :: Ord a =&gt; a -&gt; Set a -&gt; Set a The argument is that if you call insert in two different places in which there are different instances of `Ord` for `a`, your Set becomes incoherent. The ordering of the Set no longer makes sense. It's a made-up problem because it's easily avoided in Scala: class OrderedSet[A](...)(implicit ord: Ord[A]) { def insert(a: A): OrderSet[A] = ??? }
The primary issue is that typeclass instances in Haskell are used once and then dropped on the floor. Additionally, you often need the instances to agree between different scopes: you might use a set in a different module than you defined it, or map over a Compose[List,Either[A,A], A] in two different modules. You need to keep the instances around, which isn't terrible for a Set but is rather more terrible for Compose. The difference between multiple typeclass instances and multiple functions with the same signature is that the typeclass instance you get in Scala depends on imports and implicit resolution, whereas the function that gets called depends on the name you use to call it.
giter8 then generate project files, open in ide and yay takes like 3 seconds
Yes, I understand the difference. I was just posing the question: why is one situation fundamentally worse than the other? I can import bad or different implementations of a typeclass the same way I can pass bad or different implementations of a function. And they'll all have the same type signature so the compiler isn't protecting me either way. So why do people call one situation bad and "incoherent" and not the other? Simply because one is slightly more implicit? I don't have the answer; I'm genuinely curious.
So you just copy the jar to the folder? How do you import it into the program?
I think this can be approached from various angles, and that's the core distinction from Haskell! In Scala, you can decide whether - the ordering should form a path-dependent type (and fail compilation if the paths of two sets aren't the same) - the orderings are checked at runtime, and - different orderings - cause an exception - mean that merge takes the ordering of the left side (because the first parameter is privileged in OO) - the same ordering makes the method choose a fast-past algorithm In Haskell, you don't get any assurance, and all your code using typeclasses is potentially broken.
With a command line argument.
The implicit part is great.
You want Activator. Activator is sbt + templates. You don't have to use the HTML interface. Activator will work from the command line. Look for seeds: https://www.typesafe.com/activator/templates#filter:seed Here's a Scala template with specs2 and scalacheck: https://www.typesafe.com/activator/template/minimal-scala-specs2-scalacheck Type the following at the command line: activator new myproj minimal-scala-specs2-scalacheck Now you've got a project set up. Then, bring up IntelliJ IDEA, and open the project by clicking "Open Project" and going to the directory. Note that you want to leave "Auto-Import" checkbox unchecked, as it will really slow things down if you edit a build.sbt file in IntelliJ IDEA. Instead, click on the "refresh project" link in the top right when you're done editing the build.sbt file and IntelliJ will reconfigure itself.
Okay, that's great, so how does self typing or the cake pattern improve on the above? Also, I'd argue that dependency injection frameworks don't make that easier. They make it easier to introduce runtime bugs
Error handling is similar to this concept http://fsharpforfunandprofit.com/posts/recipe-part2/. Can I safely assume that Kleisli arrows and Railroad Oriented Programming are similar?
Yep, I even linked to ROP in the post. ROP leans heavily on these concepts without naming them. EDIT: Forgot to mention, Kleisli as an abstraction is more generic because it can operate on any monad - ROP restricts itself to Either (two track function). In later parts I e.g. add Try monad to a pipeline.
Yes, this approach is a conservative approximation, one of several design possibilities. Due to the well-known ML Functor issue we know exactly which advantages and disadvantages we have in various designs. Under-approximation is better than over-approximation and being wrong, like Haskell.
MongoDB is HUGE!
I know you (the author) intend to introduce kind projector to reduce type lambda boilerplate. Would you also consider using simulacrum to reduce type class / operators boilerplate? I feel this would allow readers to focus on the meat of your argument and ignore the "noise".
Oh, right. Arrow's out, then - you could still do your Monad type class, but it might be weird doing just one...
My qsort looks similar def quicksort(list : List[Int]) : List[Int] = { list match { case Nil =&gt; Nil case _ =&gt; quicksort(list.filter { _ &lt; list(0) }) ::: list(0) :: quicksort(list.filter { _ &gt; list(0) }) } }
&gt; However, it lacks of pattern matching, [...] As if that would be a problem ... I find that pattern matching is overused a lot. It doesn't automatically make everything better. On the contrary it can make things worse. The other solution he posted without it is more concise and performs better too.
pivot selection could be better. I think your sorting goes O(N) for List(7,6,5,4,3,2,1)
My issue with exceptions is being able to compose and transform them. But I agree they still have their uses: I started to make them really only for exceptional cases, while input errors, failed pre-conditions, operation errors, etc are handled with disjunctions (preferably Scalaz's over Either).
You could probably use `list.partition(predicate)` to avoid iterating through it twice, and capture the head directly from the pattern matching.
I think the pattern matching solution looks much better. It clearly shows all the three different cases, and can easily be matched to the corresponding recursive formula (which isn't very complex for quicksort, but can be for other kinds of algorithms).
Just started Scala.. TIL, tyvm
(I may have been a bit spoiled by Java 8, where Service would be a functional interface and you can could just cast any matching lambda straight to it)
Why? If I print the actor patch I see that string. So I must use the path after a Member Up?
SAM support is available in 2.11.7(backported from 2.12) with the `-Xexpriemental` flag, with Intellij support in Intellij 15. http://blog.jetbrains.com/scala/2015/07/16/try-experimental-sam-in-scala-plugin-1-7/
Correct me if I'm wrong but in merge sort there are no pivot. You just split the list in two chunks of equal size. The bad approach is to use `list.take(list.size/2)` and `list.take(list.size/2)` because you'll need 4 passes (2 for the size, 1 for drop and 1 for take). But if you don't care about sort stability you can use the following approach: http://rosettacode.org/wiki/Sorting_algorithms/Merge_sort#Haskell 
&gt;Exceptions are sometimes much less invasive, because you don't need to propagate them explicitly through the cascade of your API. Here I disagree because, setting referential transparency, FP "religion" etc. aside, I really hate when I have a line something.call() and I cannot reason about what the code is gonna do next. And true, Scala type system is not perfect, or sometimes, concise and can add a lot of cognitive load - with that I agree, but overall I believe it's a win to have richer 'types'. 
Address of member in member up. That path may be what you see locally, but is not a valid remote actor path.
&gt; Choosing the most appropriate algorithm is at least as important as implementing it correctly. Isn'it ? Well yes, I'm speculating here, but implementing a known algorithm into a new language (even though you shouldn't use that algorithm) may deepen your understanding of that language. So if you know quicksort well, why not use quicksort?
&gt; overall I believe it's a win to have richer 'types'. No disagreement there... I'm also curious to see what effect systems (see my other post) can do in the future, if they will ever become practical to use.
https://github.com/illandan/scala.compiler.guides
Here is the implementation: http://pleiad.cl/research/software/effscript
So when I get it right, this brings [PureScript](http://www.purescript.org) like effects ([Eff monad](http://www.purescript.org/learn/eff/)) to Scala. From what I understand in this paper, we can statically check, which parts of the code access the database, use logging, reads secret tokens or sends mail. So we as a hypothetical example , we make sure during compile time, that no part of the code has access to secret tokens and also can send mail. All we have to pay is some runtime penalty. What I don't get is why we have to pay a runtime penalty when the checking is done during compile time. Perhaps I should read the paper again.
&gt; What I don't get is why we have to pay a runtime penalty when the checking is done during compile time. Perhaps I should read the paper again. I think you don't have runtime checks if the code is fully annotated. That's their addition that they call _gradual effects_ (`@unknown`). Here is from the paper: &gt; For instance: &gt; &gt; spawn { e : @unknown } &gt; &gt; This program is accepted statically, as with `@unchecked`. &gt; The difference is that, during compilation, an _effect cast_ &gt; is inserted just before every effectful operation in `e`. At &gt; runtime, if the flow of execution reaches such a check, a &gt; runtime effect error is thrown if the surrounding context does &gt; not grant sufficient privileges for the effectful operation to be &gt; performed.
I aggree, explicit lifting is more readable solution.
oe even smaller: try scalatra or skinny.
If you want to start doing more functional stuff, look at htt4s. It's super lightweight, comes with its own client like spray does, and using it is essentially just composing functions. It's really nice and easy to use. Last I heard they're working on improving documentation and dropping the scalaz dependency. If you don't want that, use spray for now. Spray is more mature than akka-http. Once aka-http is stable, you should be able to switch with very minor changes. 
If you look for an idiomatic solution, I would recommend [Finch](https://github.com/finagle/finch) (actively maintained, based on Finagle, very good performance) and [http4s](http://http4s.org/) (minimal server, uses scalaz-streams). Other than that, Spray is probably the best choice.
&gt; implementing a known algorithm into a new language (even though you shouldn't use that algorithm) may deepen your understanding of that language This is plain wrong, it will show you how to use the new language with an idiom that doesn't fit well. It could possibly make a bad showcase of the language itself, by not using it in the way it was designed for. Or it could simply avoid to highlight the language strengths, making the reader wonder if the language is worth investigating.
Cons of Scalatra, poor docs.
Certainly try http4s. It's a very cool lightweight framework that takes a more principled approach than spray and is based on streams rather than actors. Also, while spray is mature, it seems like it's no longer being maintained, but akka-http is not yet at a point where I'd use it.
I'd use Play it gives you lots. Akka is a lower level framework for using the actor model. Working with the higher level abstraction is much easier / cleaner. You can use Akka inside of play if you ever need.
&gt; Literal-based singleton types What is the practical use of those? The only case I can imagine is that you could now use string literals as unique symbols. That's more of a convenience than a compelling argument for me. Anything else?
It's imaginable that stuff like Array[String, 8], or things like units of measurement become (more) straightforward.
[refined](https://github.com/fthomas/refined) already makes heavy use of literal singleton types for type refinements, e.g. ``Int @@ Greater[shapeless.Witness.`5`.T]`` by using [shapeless](https://github.com/milessabin/shapeless) for providing syntax for literal singleton types. The syntax will be a lot nicer if we can use literals directly in type position: ``Int @@ Greater[5]``.
If it's always 3 actions it doesn't matter if it's on one machine or not right? You have a singular unit (3 steps). It's not like one step produces a million parallelizable tasks. Is it cheaper to just do the work, without futures, than it is to dispatch to another actor? The thing with futures in an actor is that actor is still processing a message, it's out of commission until it's done. At that point you haven't gained anything with a future unless you are doing async io and the actual thread pool thread is reused under the hood, but semantically you haven't gotten any advantage. The thing with akka and all of this isn't so much best practices, it's what do you _need_ and then you build around that For example, my app uses akka but only in proc. I use it to abstract out a worker pool that is bound to a box. The actors wrap a flaky connection to an outbound integration service. If the connection fails and a message isn't processed I use akka to replay that message to it by recreating a new actor and delegating to it. For actual message persistence though I'm using rmq. This works great for me, but I technically also use a bunch of anti patterns (like the ask pattern) because I want bounded time responses Akka is what you make of it. Keep things simple and conposable and you can rearrange your workflows when you need to 
"Dotty tries to do away with Scala features that are deemed to be inessential". To what extent has Scala's JVM orientation caused design decisions that are deemed to be unfortunate? If any, is it possible to get rid of those in Dotty?
Scala as a language spec is a complex beast, is has to deal with Java interoperability issues, while having to support features which were thrown into the language during the languages "research" phase (its only fairly recently, ~3 years, that Scala has shifted its focus on providing stability). The end result was that Scala was supporting a huge number of things. Dont make this sway you trying Scala though, because a lot of the features which are being re-evaluated/removed are 1. Have to be included via specific imports (this triggers the "should I be doing this" part in your head) 2. Are being removed/modularised already (xml literals/unit inferred returns/implicit views) One of the best filters, as to not overload yourself, is to just have a look at common Scala code. 
Seems like best to start out with 1 actor doing 1 piece of work from start to finish. As long as you have enough work this will be faster. 3 small parts of work will be 3x the communication. Code as 3 distinct code blocks. keep it separate. but start with 1 actor per work. if you need to change later you can, but seems silly. A persister? so send a message from 1 actor to another just to have it write to the database? lot of overhead.
check out EitherT in scalaz. you can use it to combine two failed types into one, so that both a failed future and a successful left will both fail the flatMap.
&gt; if you need to change later you can, but seems silly. A persister? so send a message from 1 actor to another just to have it write to the database? lot of overhead. The good part about this is removing the bottleneck that the database may be compared to the data being produced. But using an asynchronous DB layer is probably faster and easier to manage. 
Yeah +1, you need `EitherT` to get the fast-fail effect up to the top, and need to lift the errors into some common type, either by introducing a common [sealed] supertype or introducing another disjunction. So the final type you want is `EitherT[Future, SomeCommonErrorType, A]`.
I have seen it, a lot of his points are non issues in the majority of code. I do agree that there were serious issues with Scala years back (which is when twitter made the fork), but a lot of them are being addressed. For example, addressing your point regarding collections, I have been using collections for the past 3 years, and for our typical day to day 90% use, not one of his outlined concerns actual caused a problem. There is only one really major sore point that I see with the library, and that is how it treats views (or more accurately, the fact that mutable/immutable share a lot of stuff, which they shouldn't). He briefly touches on that The final point is, although I respect his opinion hugely, I don't think what he is asking for/alluding to actually exists as a language (or is even possible). At the end of the day, compromises do need to be made. If anything, he seems to be asking for something like Haskell, which already exists (and has issues of its own). I maintain the opinion (which other people have as well) that I think he just got burned out from working on scalac for too long. scalac is definitely a mess, but that codebase has been hacked on for like a decade without any clear direction, something that is being fixed with dotty
Thanks for the info, I really appreciate your opinion. Also, I didn't realize Scala is 10 years old already.
Yup, according to https://en.wikipedia.org/wiki/Scala_(programming_language) its technically 11 years old. Scala started as an "academic" language, and it is only recently that it started getting picked up by a lot of industry (places like Twitter and projects like Spark have skyrocketed Scala's popularity). The compiler however, is still the same compiler that was being used from when the first version of Scala came out. You will notice that other languages that have compilers that have been around this long have the same issue. If you think that scalac is bad, you should see GCC/C++.
Another option than merging your ADTs under a common supertype is to simply return `Left(i18n(code))` to the user; i.e. just return a `String` or `Json` message to the client since your validation logic already handles and knows about the failure cases. Of course, if you're using the ADTs internally for logging and such then the string-ly approach isn't nearly as nice.
H1B applicable?
But why would you have a type `Array[String, 8]`, and why would that be so generally applicable that it needs to be baked into the type system?
There is a little bug here. You will lose elements that are equal to head of the list because of *list.filter { _ &lt; list(0) }* and *list.filter { _ &gt; list(0) }*. Try this: quicksort(List(3,1,2,2)) 
We're not looking for people to work remotely. We can probably accommodate it as a transitional thing for a while. Unfortunately, this is a policy that is not up for discussion. 
This is a truly great article. The `Depth` typeclass is really easy to understand. So when you write the instances for `HList` and `Coproduct`, the actual semantics of `Depth` are so small that they don't distract from the structure of the recursion over the structures. I think with this tutorial, anyone can start reading Shapeless source code and begin to understand the various inductive typeclass definitions in there.
Thanks, and likewise.
You know it's a troll when they pre-emptively defend their arguments with 'anyone who disagrees with this is just arrogant and full of themselves and can't take any criticism'.
From the same author: &gt; In 2015, we live in a country where sexually dysfunctional teenagers are pressured into sexual reassignment surgeries and it is permissible for them to force their cross-dressing behavior onto people in the work place. Just fuck off already you piece of shit
It sounds like all you're doing is: for { resp &lt;- callWebService(int) manipulated = doSomeManipulation(resp) persisted &lt;- intRepository.insert(manipulated) } yield persisted Why do you want these steps handled by actors? I think this is the key point. You should be able to answer, what problem do you have that moving to actors will solve? Is there some shared mutable state that each of these steps need an actor to encapsulate? It sounds to me like you are trying to apply the actor system to a problem that is really just sequencing few asynchronous calls. Actors are not a good solution when all you want is some concurrency.
I think this autistic author's schizophrenic article just gave me cancer. /s Dude, you have some issues. If you're having trouble with someone at your workplace, you should seek some help or advice. But this article makes it look like *you* are the one who is hard to deal with.
Kotlin is great, but it lacks open development culture. Remember the multiple alternative implementations of Scala collections? I do not think it is ever possible with Kotlin - it is firmly in hands of one company, as far as I can tell. Having said that, I am following Kotlin news. I work for a company that has zero chance of switching to Scala (mostly due to the development culture). I used Scala for years and it is a bit of pain to write Java code at this point. I think Kotlin may be the middle ground.
This article summarises very well the problem with a sadly sizeable portion of devs out there: too lazy to learn new stuff, much easier to complain.
I can't see myself stepping backwards in terms of the typesystem, so it's kind of a non starter. No existential types, no path dependent types, no implicits...
The enums thing is a joke. 
I don't really understand what this is, but it has sufficiency ~~peaked~~ piqued my curiosity.
This is a cool project. Denys gave a good talk about it at Scala Days in SF. https://www.parleys.com/author/denys-shabalin-1 
Play has an ok frontend stack if you dont want to change any parts of it and you dont mind the fact that running all the node tasks inside of the triereme vm takes ages in larger projects. Recently at my job we have broken away from using sbt for frontend tooling completely as it was becoming a bit of a hassle.
I'm hoping this is satire.
Aw man.. I didn't get quoted..
"piqued" is the word you're looking for, unless you're truly reaching the heights of arousal :-) Definitely interesting; quite elegant. Not really sure how widely useful it is - the only use-case I've found for super-large heaps has been for caching, where serialization/Kryo is normally fine.
 I've experience with both sublime and atom and all I know about atom is - a 'good' text editor that feels like ~~Sublime Text~~ notepad.exe - a good selection of ~~plugins~~ bloatware - not ~~as fast as~~ comparable in speed with Sublime Goodies over sublime: nice and easy ui, parallel linter. I'd wait with atom for a few years... Edit: curious about the downvoters view.
Yeah, I got the impression that I wasn't the target audience. :) When I saw it come by on my RSS feed, this is what my experience was like: * Oh boy! Atom for Scala on the underscore blog, that's basically me right now! I'll probably get some validation on what good resources for getting ensime up (which is something I've yet to do). * Oh... a video. Hmm, I can't listen to anything right now but I'll try watching it anyway in case it looks like there's something cool in it. * It seems like there's a lot of talking in this video, as not much is happening visually right now. Whatever, I'll go back to reading the post since it likely covers what's in the video anyway. * Wait.. where's the rest of this post? I guess that was it, blerg! I'm sure you can pull some useful tidbits from that if you're looking for feedback :) All the best, thanks for sharing it. 
Its more from a marketing, traction POV. The market that Kotlin is going for is very niche, and it can be argued with Java going as fast as it is now, there is less of a reason to switch to something like Kotlin. 5 (or more) years ago, Scala was just seen as a better Java, which is the same position that Kotlin is going for now. Recently Scala has been getting a strong flavour of its own, which is very distinct from Java Its not just Ceylon that is competing with Kotlin, it was also languages like Fantom and XTend. Historically they haven't done too well because there wasn't enough of a reason to switch I do see all of Jetbrains internal devs moving to Kotlin to use it like some internal tool, but I am not seeing it being pushed much further
&gt; But out of interest, what else would you have hoped to have seen? * Syntax highlighting on higher-order stuff like Scalaz, Shapeless, Cats - if Ensime informs highlighting it would be great to show off the hard cases where Intellij et al fall down. * Scala-aware refactoring * SBT integration. Running clean, compile, etc showing output. * Running tests and viewing test results &amp; summary. I don't know what subset of the above is working yet but it'd be great to see demos of what is available.
This is cool. I don't really know what Ensime is or what state Atom is in. I keep hearing about Ensime but I thought it was emacs only or something. I just slug away at Scala in Intellij all day so I'd love to see demos of other Scala dev envs starting from scratch. This video was perfect for me. I hope there are more.
Already have done that (shrinkwrap), the issue is when packages in our build system needs to be bumped. I am right now spending an hour trying to fix npm not building packages because of certain node versions, and our build system has to perfectly replicate the state of node/npm on our dev machines. Builds are also ridiculously slow, we have to clear out the git repo because we have had impedance mismatch when some libraries get bumped There is a huge difference with bower webjars. Webjars are just a maven package (jar) with resources, which means they can be resolved with the exact same mechanism as sbt, which internally uses Ivy. When using grunt, we have to manage node/npm/bower plus sbt, with SBT we only need to manage SBT. Although SBT obviously uses stuff like LESS sources (to compile LESS sources), its **only** for compiling sources. The build system is still entirely with maven.
As an example, I am currently getting this error on the build server when needing to upgrade grunt-sass 04-Nov-2015 03:50:26 make: Entering directory `/home/centos/bamboo-agent-home/xml-data/build-dir/MON-MON-JOB1/node_modules/grunt-sass/node_modules/node-sass/build' 04-Nov-2015 03:50:26 CXX(target) Release/obj.target/binding/binding.o 04-Nov-2015 03:50:27 In file included from ../binding.cpp:1:0: 04-Nov-2015 03:50:27 ../node_modules/nan/nan.h: In function ‘v8::Handle&lt;v8::Value&gt; NanError(const char*)’: 04-Nov-2015 03:50:27 ../node_modules/nan/nan.h:319:38: error: ‘New’ is not a member of ‘v8::String’ 04-Nov-2015 03:50:27 # define _NAN_ERROR(fun, errmsg) fun(v8::String::New(errmsg)) Even though the version of node/npm are the same locally, as they are on the dev machine, and both have been shrinkwrapped so they match
@japgolly and @mushinnoshin - thanks for the feedback.
&gt; Android? Java itself? These are hardly niche ;-) Maybe I didn't clarify myself enough. The amount of Android developers looking to use a language that isn't Java for android development is niche, mainly because the lack of first class support. Its the same reason why many language -&gt; android (or language -&gt; ios) frameworks don't tend to working to well &gt; Relatively speaking Java is, and likely always will be, evolving at the pace of a 3-toed sloth. I think java may have grown an extra toe recently ;). More seriously, Java has been moving much faster lately, at least definitely compared to when it was being owned by Sun in its dying days before Oracle took over. &gt; Kotlin's entire propaganda is, a better Java with seamless interop and low cognitive overhead, something Scala has never been able to claim. Effectively they are going directly after Java. Given that they develop IntelliJ they already have a large captive audience so to speak, I wouldn't discount Kotlin going mainstream. I guess my major personal point is, that with all of the IDE support that Java has (which basically automatically create a lot of the syntax sugar which languages like Kotlin/Ceylon provide), I don't see many people jumping ship Languages like Scala have more to offer than just lot of syntactic helpers (existential types, macros, etc etc) &gt; As for Scala, much needs to be done to right the ship. Tooling is relatively horrendous compared to anything in Java land; build times are equally horrible if you're a Java dev (though incremental builds are fantastic); Standard lib is massive, which bloats non-JVM compile targets (see Scala.js). Dotty and collections overhaul are supposed to deliver on these fronts but we're not seeing anything for a few years, unfortunate. Agreed completely here. Point is that Java has none of these problems, and Java tooling is better than current Kotlin/Ceylon tooling
Personally: * Static typing * Features * I don't love Lisp syntax * Scala feels designed; Groovy just sort of happened. And of course, &gt; I can honestly say if someone had shown me the Programming in Scala book by by Martin Odersky, Lex Spoon &amp; Bill Venners back in 2003 I'd probably have never created Groovy. - The creator of Groovy 
Scala keeps static typing while providing a more developed type system than Java. It has good support for functional programming with case classes, pattern matching, and immutable collections. But it still supports imperative and object-oriented programming fairly well. You can use Scala as a better Java, even though its syntax is rather different. Or you can embrace the things that make Scala unique, and have a very different experience. It's not a binary choice; you can slowly introduce Scala features as you get comfortable with them. It has good Java interop, though it also has plenty of Scala-native libraries. (One caution, though: Scala libraries tend to make strong use of "advanced" Scala features, so they might seem like magic at first.)
I understand that this quote is one of the most used quote in Scala vs Groovy but he left Groovy team before groovy reached 1.0. Just adding my 2 cents. Thanks for your comments.
I wouldn't describe transition to advanced Scala as slow. As soon as you see `Future[Option[a]]` you pretty much forced to use Scalaz, a simple filter for Finagle is much better with implicit classes etc. Though I don't think regular tasks require deep understanding of internals.
I find play to be pretty fantastic at first but it really gives you too many tools all at once akka/http is from the same company typesafe and aims to be a bit lighter on giving you just what you need. For instance you look to be just building a rest api so the psuedo rails style asset pipeline and abstraction wouldnt be used anyway. 
Groovy is really a big hack. Clojure is lisp, so it's fine if you like lisp. While you're at it, you may want to look at Kotlin, especially if you find Scala overwhelming. My personal preference is with Scala, but Kotlin has the "better Java" aspects that Scala has without the complexity. It may appeal to Java developers who just want to get rid of Java's biggest limitations without having to learn a new paradigm. Scala is a different language, but Kotlin is what Java should be.
&gt; Under what circumstances compiler will infer Nothing with no type provided? Disclaimer: I researched to answer this question and so it is a little hand-wavy and some things may be wrong, though they do make sense to me. I'd appreciate any corrections. `Nothing` is a subtype of everything and is, in a sense, the most specific type there is outside of an explicit type. The counterpart is `Any` which is the most general type and is a supertype of everything. Scala infers type parameters using a constraint system. Specifically the "least upper bound" (LUB) constraint for covariant positions (e.g. return types) and "greatest lower bound" (GLB) constaint for contravariant positions (e.g. parameters). Invariant positions must satisfy both LUB and GLB. The LUB constaint sort of leads to the "most specific" type while the GLB constraint sort of leads to the "most general" type. The bounds are computed using the types which contribute to the inference, i.e. parameter types, return types, implicits, and explicit specification. Parameterized types are invariant unless annotated otherwise. Scala also chooses the most specific type possible, which will prefer LUB over GLB in the event they both apply. scala&gt; class A[T](name: String){} defined class A scala&gt; val a = new A("nothing") a: A[Nothing] = A@44e81672 In that example and contrary to yours, the parameter type has nothing to do with the generic type and so the parameter does not contribute to inference. Since nothing else contributes to inference, the LUB or "most specific" type is `Nothing`. Similarly the GLB or "most general" type is `Any`. However the type parameter is invariant so both constraints apply and since `Nothing &lt;: Any` it is more specific and is chosen. You can make Scala infer `Any` by guaranteeing that the type parameter is only used in contravariant positions and forcing GLB resolution. scala&gt; class A[-T](name: String){} defined class A scala&gt; val a = new A("nothing") a: A[Any] = A@180bc464 &gt; What's wrong with this approach It solves a different problem than the case in the post. They don't want the type to be a constructor parameter and contribute to inference. They want safe operations given a specific type, and to default to a known type in the event a specific type is not given.
How much you're paid is a reflection of your ability to negotiate a salary as much as anything else. The company will offer what they think you'll take. So, do you feel underpaid? If so, then you are. *You* have to decide that you won't work for salary &lt;X&gt; any more and then make a change happen. Either ask for more or move to a company that offers more. That said, I know a Scala dev with 3 years of experience (with 20 years in the industry overall) makes $140k or more in the area I'm in. YMMV, but I'd expect $64k to be an entry-level gig.
You need to negotiate your salary. It's only what you ask for and accept that matters. There's unfortunately a lot of misinformation, and employees typically don't understand their position until they find out (as you have) that there are other ways for the salary conversation to play out. For a good overview, I would read Reg “raganwald” Braithwaite: https://leanpub.com/dowhatyoulove/read
What city are you in? I think you are grossly underpaid. Most full-time Scala devs I know (2-5 years of experience) at my company and others get paid between 100k - 160k + stock options in San Fransisco. There are few recent college graduates who start at 80k-90k and there are some senior guys who make 180k and above.
It's mostly a "better Java", while Scala is a very different language. So it's good for Java developers who want a few improvements without having to dive to a new paradigm like in Scala. Additionally I think it's good for Android because of the small runtime and being close to Java, whereas if you use Scala to write Android application you're forced to have a fairly "Java-ish" Scala because of the way the Android API is which is frustrating, and because of the size of the runtime you're force to use proguard even in dev. Also on Android you don't have Java 8, you won't have Java 9 either, so using a different language is even more appealing. So as far as I'm concerned, I keep using Scala for my web projects, but I might consider Kotlin for Android projects.
[removed]
Yeah, I didn't know that this would create such a huge storm. Its kind of getting annoying
He left the Scala world a couple of years after that quote and he became a committer for Kotlin. He stopped doing that not long after, not sure what he's up to today. 
You aren't being underpaid you are being grossly underpaid. I don't really think anyone is worth 64k. You should either be an apprentice who takes a bunch of time and makes less, or you should be making a lot more. 
If you know Scala, your in a league of your own right now. A lot of companies would love to have a guy like you and I don't see why you couldn't squeeze out $100K a year at the minimum if not more. 
I think it's fair to say Scala and Groovy are not remotely on par. Groovy is a dynamic scripting language that fiddles around with making Java's syntax more friendly. It may be useful for writing a Gradle script, but hardly to build large systems. In Scala, although it's a statically typed language, you can basically write as concise as Groovy, but you have a thought-through language with a strong foundation, and much more powerful. To compare these too doesn't even remotely make sense. If you want to compare it with anything, perhaps Xtend or Jython.
Those are awful ways of doing it though. The beauty of scala is you don't have to care *why* something works. Referential transparency ensures I get what I care about and nothing magical is going on underneath me. I used monad transformers for a long time before I even knew what a monad was. 
I have ~4 years experience in web-dev, 2.5 of which are with Scala, and I'm currently at $80k. What I've found though, is that it also depends on the financials of the company. One company I interviewed with had a salary range from 40-70k and I was too expensive for them. Another one I interviewed at had a salary range *starting* at 80k. I ended up at a happy medium company.
Two years is enough time to learn the ins and out of any programming language. Most people (like me) won't, but it's not unrealistic at all for someone who is motivated and passionate.
I like clojure and scala. Clojure is great if your initial development time needs to be fast and correctness is not absolutely paramount. Clojure is also great for small projects that need to be correct. Scala is great for programs where correctness is paramount. It's also good if you have the time for a somewhat longer initial development cycle. Future maintenance will be much easier and less error prone because of static typing. Groovy is ok, but not as good as scala or clojure at anything. I personally hate dynamic object oriented languages. Functions shouldn't go missing because a dynamic parameter didn't actually have the method it needs to have, but that's a common occurrence in dynamic object oriented languages. 
Your solution (1) is reasonable, as is keeping them disjoint and using a type like `Either[FooError, MyError]`. You have a lot of options (but extending someone else's `sealed trait`, as you note, is not one of them).
&gt; as is keeping them disjoint and using a type like Either[FooError, MyError] I don't understand this approach, @tpolecat. Since `Either`'s `Right` is reserved, by tradition, as success, then how would it be appropriate to have a `Right[MyError]`? 
I think this is probably what you are looking for https://www.playframework.com/
It's totally fine to use stdilb `Either` or scalaz `\/` or cats `Xor` for things other than success/failure. They are all generic 2-element coproducts. If you *do* use them for success/failure then right-biasing makes it convenient to use the right side for success, although `Either` is unbiased so in that case it makes no difference.
&gt; As soon as you see Future[Option[a]] you pretty much forced to use Scalaz What?
First of all, use the latest docs http://doc.akka.io/docs/akka-stream-and-http-experimental/1.0/scala/http/ Second, akka-http is essentially brand new. Start with strait akka and maybe spray. Akka streams are a very complex topic
[drama intensifies]
Man, I respect your skills. Looks like you are real professional, but unfortunately in this world you costs exactly how much you get now. In order to change this - go to the interview and sell yourself for much money and get the offer =) Good luck
It may not be impossible, just very unlikely. It is like someone saying they are a master dancer in two years -- it stretches the imagination. I'm reminded of the phrase (and I'm paraphrasing) "Mastery is easy for people who have no idea what they are doing."
We're happy to consider individuals at all levels for this role. The highlighted salary is at the top end and would naturally be for an individual with commercial experience within the Trading/Hedge Fund space. IT may be prudent to mention, I have multiple Java/Scala Roles and would be able to consider either Graduates or seasoned professionals with a Computer Science background and willingness to learn Go. 
&gt; As soon as you see Future[Option[a]] you pretty much forced to use Scalaz Maybe if you're a Haskell refugee and don't know any better?
Could you recall some examples of these 'promised' features?
Shouldn't be that much different than java. It's all the same byte code
Yes, but not all byte-code is equal otherwise we wouldn't ever require JVM-tuning - there would one configuration which would be optimal for all applications. The Scala compiler presumably generates byte-code that may differ to Java-derived byte-code. I would expect idiomatic Scala byte-code to have different characteristics to Java byte-code. Using immutable objects and pure functions will give rise to a lot more short-lived objects. Recursion can lead to deeper call stacks. Etc.
Exactly: there's already a very thorough discussion happening on github and adriaanm is moderating it and removing all the non constructive comments. Why did Odersky feel the need to tweet?!? 
&gt; akka In your application, you could have some false sharing introduced by GC card marking algorithm. You could try `-XX:+UseCondCardMark` JVM option, in many cases it improves parallel performance. More details: https://blogs.oracle.com/dave/entry/false_sharing_induced_by_card
So is this one of those roles where you work until 4am every night? 
He probably couldn't find his llama.
Should Martin Odersky avoid intentionally mischaracterizing his opponents' views in a populist strawman attack? @odersky thinks he shouldn't. 
Most recursive calls originating in library code ought to be written with tail call optimization in mind so that the stack isn't blown to bits.
Minor comment: IMO, all axis should be named in the "Performance" section.
&gt; I don't see how it wouldn't. Your SLIP is vague, adds nothing of value, and doesn't solve a technical problem. There is nothing vague about it. The proposal is to add a concrete JSON AST to a scala supported module (not the stdlib, as that is being modularised) &gt; How are current JSON libraries deficient? Red herring, this is not about a JSON library &gt; Why does JSON need to be core? What language features make this necessary? The fact that we have 6 different JSON AST's lying around, most of which are almost exactly the same and only differ very slightly. The equivalent is having to deal with 6 versions of `String` &gt; Why JSON as an AST? Why not a parser combinator? Because there are various valid (and quite different) approaches to parsing JSON, just like there are very valid and different approaches to parsing a sequence of characters or bytes to form a `String` &gt; Why JSON at all, is the objective really just language support for object serialization? What about other serialization formats? Why not create a Scala Object Notation? Its only, like, the most common format for exchanging data between servers and clients.....
Until the JVM supports TCO, you're reliant on the Scala compiler detecting the opportunity at compile-time and implementing it. Ideally, you should be avoiding using recursion directly.
 - "Compile as fast as Java" - Reified Generics (`reified T` is cute, but isn't it) - "Public beta is planned for the end of 2011" - Pattern matching - Modules &gt; Number of research papers we are planning to publish on Kotlin is ➡ Zero They kept that promise, and now they have a blatantly unsound type system.
So you are looking for a Scala developer that wants to learn Go for a job in Go? I think that needs some explanation. :-)
You got the answer in that thread. The context bound only works for a type class that takes a single type parameter. def f[A: H](x: A) = ??? Is just syntactic sugar for def f[A](x: A)(implicit y: H[A]) = ??? If `H` is expecting more than one type parameter, this won't work.
If you use `@tailrec` you are fine. The scala compiler uses that annotation to verify it is actually tail recursive, and it also transforms it to a while loop
you forgot the best one.. upickle!
Just my 2 cents: I don't think Scala is a popular language. It's powerful, it has the potential, but I don't think the popularity is growing in the near future
Thanks a lot for this link. Will check it out. BTW I am from Ukraine and seems like Java is dominating here :(
Java dominates lots of places. But you can use Java libraries in Scala. So you may just have to inquire about it with the recruiter / hiring manager. There definitely are things that exist out there that may have a Java core but has some specialized services written in Scala that interop with the core. Also, things like Apache Spark are written in Scala with Python, Scala and Java APIs. 
Check this out: http://www.indeed.com/jobtrends/scala.html
There are also a couple of libraries that: * use macros to get additional speed-ups by doing some work at compile time * can be compiled with ScalaJS, allowing you to "write once" for projects that use ScalaJS.
Java is still awesome, especially with Java 8 and 9. There is a bit of an interest in clojure growing too. I've learned seven languages in my career, the landscape is still changing, I'm guessing it always will.
&gt; I've got ~2 years experience with Python and decided to learn something more difficult and powerful. I wanted to ask about Scala popularity and if I will be able to find a good job as a Scala junior or something like that. What do you think about this? It's popular in London at the moment, lots of jobs and not enough developers. And better paid.
I don't think its easy to find a job as a junior for Scala, its better to get some experience on the JVM stack using Java and then filter into Scala. Most companies expect a Scala developer to already be an expert in a JVM infrastructure stack. There are lots of tech companies in London looking for good Scala Devs, there is a shortage.
I guess I should give some context: We have a new process, SLIP, the Scala library improvement process. It's been starting up nicely and there are lots of proposals in the pipeline. The goal is to fix problems and fill functionality holes in the standard library. There's a committee for encouraging and sheperding proposals. It includes Sebastien Douraene, Heather Miller, Eric Osheim, Josh Suereth, Seth Tisue, Dick Wall, and myself. Recently I have observed an increasing amount of interference from people whose stated goal is that the standard library should not improve but stay the same or shrink. What they do is in effect give dismissive and negative comments on each particular SLIP, not based on technical grounds, but because they object to the very notion of even working on these proposals. Immediately before I posted my tweet there was a group around Miles Sabin tweeting that they should all weigh in in the discussion about SLIP-28. Weigh in means: Obstructing the work, not engaging in technical debate. So, I wanted to call the attention of people to what goes on here, and linked to the discussion. That's all. 
That's interesting, i did internship at a bank that is using Scala, and the senior staff is rotated from London. May I know what are those jobs about?
While this is an impressive project, the last time I looked at it the "hello world" equivalent was like 250k. That's kind of a dealbreaker. Have the file sizes of the generated js come down at all?
&gt; I don't think its easy to find a job as a junior for Scala &gt; Most companies expect a Scala developer to already be an expert in a JVM infrastructure stack. I'd like to underscore that in my experience, this has been true, and I agree. It's unfortunate.
I think the best approach there would be to start by making a ScalaJS facade over your existing code and then do new development in ScalaJS. You wouldn't have to put a facade over the whole code base at once. You could do it as you go. Another option is to first type your program using typescript, get it to typecheck, and then automatically convert the typescript to scalajs since there is a tool for that. I'm not familiar at all with typescript or the conversion tool so I don't know how useful that would be. 
There's a nice thread in the Mechanical Sympathy group that should give you some ideas, from people probably more qualified than me(&amp; probably most people here tbh)... https://groups.google.com/d/msg/mechanical-sympathy/gSkbc3grzNY/NVFcQba5W9AJ
First, **remember that jQuery itself is 80 KB** before minification and **33 KB** after minification, and no one complains about including it even for a hello world in JS! More recent UI frameworks for JS weigh several hundreds of KB. Now, the hello world, as such, is around: * 102 KB before minification (aka `fastOpt`, including most Scala.js optimizations), which is what you work with in dev mode with a fast compile cycle, and, * 17 KB after minification (aka `fullOpt`, including some more opts from Scala.js + the Closure Compiler), which takes several seconds to build, so only for production builds. However, this is not a useful measure, as you wouldn't write a Hello World in Scala.js. It is best used for medium to large apps. And for those, you don't see the difference anymore between hand-written JS and Scala.js-emitted code. The smallish-but-not-trivial application that we use as a control measure of the emitted code size is 620 KB in dev mode and 145 KB in prod mode. **Still under the 250 KB** you were talking about. There are thousands of Scala.js developers, among which at least several companies using on production code, and *no one* complains about the code size.
Hello world is lower by quite a lot, and you need a pretty big pile of code to break 250kb gzipped. He talks about this in the talk, watch and find out! =)
&gt; did internship at a bank that is using Scal I've not worked in banks but I know alot of them are pushing Scala at the moment, with big data techs such as Apache Spark making a big impact. Most of my expereince has been working within media organisations (TV, News, Web etc) and within Government Digital Services. All big on Scala at the moment.
I'll consider it when there's a Maven plugin, or enough documentation to write one myself. Last time I looked at the Scala.js compiler, it was a horrendous mess of code, almost completely undocumented, and heavily coupled to SBT. Also, stop fucking generating those pseudo-`.class` files that don't actually work. Call them `.sjsir2` or something if you must, but for the love of Odersky, don't call them `.class` unless they are actual, usable, correctly-compiled JVM bytecode!
Check out scalaz's [NonEmptyList](https://github.com/scalaz/scalaz/blob/series/7.1.x/core/src/main/scala/scalaz/NonEmptyList.scala).
`type NonEmpty[A] = (A, List[A])` Or yeah `NonEmptyList` or `OneAnd` or `Cofree` from scalaz. There are a lot of ways to represent this depending on the operations and generality you need.
Maven support would make Scala.js easier to use at my organization too. We've only used Scala.js for a couple of small greenfield projects so far; being able to integrate into an existing zillion-module Maven build would make it a lot easier to sneak Scala.js in bit-by-bit.
I agree with Martin that the standard library can and should be improved in other ways than simply shrinking. I also think it's a bit disingenuous when people say, "Miles does want to improve the standard library! He wants to improve it by shrinking it!" That's like saying I want I want to improve the weeds in my yard by shrinking their presence with the goal of their eventual total annihilation. My understanding is that Miles Sabin wishes there were no standard library in Scala at all. With that agenda in mind, it's hard for me to see that he wants to improve it; I'm pretty sure instead that he'd rather kill it. That being said, I think it would be great to separate as much of the language as possible from the standard library and to modularize the standard library into individual libraries with a dependency graph. That would make it easy to depend on scala-core but not on scala-json.
I don't know where you read that in the docs. &gt;The Scala.js compiler plugin produces .sjsir files in addition to the .class files generated by scalac. Roughly one .sjsir file is produced for each .class file. (Sometimes, fewer .sjsir files are necessary when the compiler can optimize anonymous function classes as JavaScript functions.) [Source](http://www.scala-js.org/doc/internals/compile-opt-pipeline.html) 
`get` returns an `Option[Seq[String]]`, so looks like when Some(Seq(...)) exists it's safe to call `head` in the map call. If it were simply an `Option[String]`, yes, you could just `getOrElse`, but Play's handling potentially repeated params so you get the maybeSeq.
It might be useful in some cases, especially if the code is not "local" and you would like more enforcements by using the type system. One of the implementations is cats https://github.com/non/cats `cats.data.NonEmptyList` -- non-empty list `cats.data.NonEmptyVector` -- non-empty Vector `cats.data.NonEmptyStream` -- non-empty Stream And of course there is scalaz, if you want to jump on this ship fully.
I love the SLIP initiative, and **I like the idea of a standard JSON AST**. **I just don't think everything should be a SLIP**. The idea is relatively trivial; not everything needs to be democratized. Especially in a community that's becoming famous for it's hostility (even if it's only from the usual suspects). It's a good idea. Just do it. Is the value of the broad community "feedback" in this SLIP worth the hornet's nest shaking? Worth the political fallout when ordersky understandably gets a little aggravated and tweets about it? Would there be half this vitriol if they just shipped it? The majority of this "feedback" is derailments (e.g. people repeatedly talking about json parsers when this is just an AST), quests for perfection (e.g. "this should be streams based! and monadic! and.."), and overstatements (e.g. "this will destroy open source"). It's not all bad tho, there is useful commentary in there (again from the usual suspects like lihaoyi, non, mdedetrich, jroper, ktoso, mandubian, etc). There's also some interesting discussion about how to handle JSON numbers. The experts and prominent JSON library creators should have been contacted directly for advice. That's it. It's just some damn sealed traits and case classes. Just ship it. Less democracy more benevolent dictatorship. And the Scala leadership needs to be less accommodating to the people who constantly fill the community with negativity. Their irascible genius routine hit diminishing returns **years** ago.
FWIW, I never claimed it was still that bad. I said it *was* that bad the last time I looked, and asked if it had improved since then. A fair question, I think. Not sure why it got downvoted.
To put some more thoughts out there, I think an example of a language that is hurt by not having a useful standard library is the scheme family of languages. Having spent some time doing Scheme-related programming in multiple dialects of Scheme, I observed that: 1) It was basically impossible to write any non-trivial snippet of Scheme code that was portable across different implementations of the standard. 2) There were often multiple competing libraries that did the same thing with no clear winner in sight. While Scheme may make for a good research language, in practice the Scheme standard is all but useless for building any useful piece of software. In the best case all you can hope to do is build your software program under a specific Scheme runtime, such as Racket or Chez. The same issue even crops at the level of features that are often integrated into the language itself. For instance, in Racket there is no standard object-oriented system. Last I checked, there were multiple competing OO systems implemented in the language as libraries. At least one implementation copied the Java/C++ style of OO. Yet another implementation was inspired by CLOS. As a developer of a Racket library, which OO system do I use? Whichever one I pick, I now force my users to depend on that OO system. What if I use two libraries that use different OO systems? There is a maintenance burden placed on the language owners whenever making something standard, but the benefit of making something standard is that people can easily build on that standard and interoperate with one another. 
&gt; I think what disappoints me the most about this whole situation is that there is no acknowledgement that those who take Miles' position are actually arguing in good faith for an approach that they believe is the best for Scala. Well, as Odersky wrote very early on in the Github thread: &gt; We have had this discussion before, and decided we will go with a batteries included model. Recycling this debate on individual SLIPs is obstructionist IMO. The discussion about whether to add to the standard library or not had already been had, and as Odersky explained, it was not the topic of that thread. If a lot of people make a lot of comments unrelated to the technical discussion, that is obstructionist. And if they continue to do so after the topic of the specific discussion has been made clear, that is not well-intentioned. It is perfectly fine to have that different discussion - but it should have been made elsewhere, not in that thread given what the topic and purpose was. &gt; The antipathy toward the 'scalaz faction' demonstrated by Typesafe is unique in my experience with programming language communities. I don't know if there is antipathy toward the 'scalaz faction', but there definitely has been a fair amount of friction between different Scala communities. And antipathy has definitely gone in the other direction: If you look at [this thread](https://www.reddit.com/r/scala/comments/2ze443/a_good_example_of_a_scala_style_guide_by_people/), for instance, the antipathy seems to flow towards those who do not use a pure FP approach.
The topic of the debate was clarified, namely that it was a technical debate regarding the specific SLIP proposal, not about whether a library in general should be added or not. And those that continued to argue that point obstructed the technical debate regarding the specific SLIP proposal and did not respect the wishes of those having the debate. There are other places that they could have had that debate, and where that debate has been had previously.
Well, the debate was not about whether to add a library or not, but about the specific SLIP proposal. But you also commented before Odersky clarified the topic of the Github thread.
I didn't intend to suggest it was related to the lack of TCO in the JVM. Most recursive algorithms can be expressed in a non-recursive fashion using higher-order functions such as fold, map and filter. Obviously those functions may themselves be implemented recursively, but at least by using them you avail yourself of whatever optimisations the implementers may have made, including using loops if that's more optimal. Furthermore, by using them you're expressing your algorithm at a higher-level. [This reddit thread](https://www.reddit.com/r/haskell/comments/1nb80j/proper_use_of_recursion_in_haskell/) elaborates on this - it's specific to Haskell but the answers are relevant to any FP.
The picture of the confused dog is very appropriate, it's pretty confusing picking a json library in Scala. It would be great to add some benchmark/performance number for the the different libraries.
&gt; I deal with JSON types when I work with the "json" type column in postgres (it returns something of type JValue when I retrieve it from the database). No it doesn't, some middleware you're using is returning a `JsValue`. Any useful database library maps the result from the database to something well typed. a JsValue isn't your domain, and the fact that you pass around untyped values instead of useful ones doesn't reflect on how most people work with JSON at all.
A bunch of startups here in Asia are moving over to Scala due to the big data movements. It's getting pretty hip with microservice archi and analytics.
Anyone who says that the solution to your Javascript problems is to replace your code with Scala.js is probably not doing any mission critical Javascript. Sure, for toy projects where a one hundred line Scala project translates into 250kb of Javascript, Scala.js is great. In the real world, the size of the Javascript translates directly into users. Every extra 10kb your web page needs to load is more users lost. The people behind Scala.js have obviously never been in the mission critical Javascript field. 
[Here.](http://www.scala-js.org/doc/sbt/run.html)
"troll"? You're suggesting that they're not being genuine? 
A bit of basic formatting works wonders. import java.io.File import scala.annotation.tailrec object CountFilesMain extends App { println(countFiles(new File("/Users/Sharky"), 0, Vector[File]())) def countFiles(file:File) : Int = { @tailrec def countFilesAcc(acc:Int, files:List[File]) : Int = { files match { case Nil =&gt; acc case f::xs =&gt; { if(f.isDirectory()) countFilesAcc(acc,f.listFiles().toList ::: xs) else countFilesAcc(acc+1, xs) } } } if(!file.exists()) 0 else countFilesAcc(0,List(file)) } } //end class
That's not what this proposal is. This is a proposal for a standard JSON *AST*.
Oh, so you want to have Scala.js without any IDE support? Because that's how you get no IDE support.
Did you try SBT? It's a quite brilliant tool.
Very promising! Does anyone have any info about release date?
This is why there are two flaws to this whole concept. First a lot of the criticism just gets squared as being opposition to it and therefore gets dismissed. Secondly I fundamentally don't understand why throwing the idea away isn't still on the cards. If it comes to light that's it's a bad idea as a result of the public debate, then why just do it anyway? For example if the idea is to make Scala easier for first time users, then why introduce the complexity of an AST in the standard library that you _then_ need to find a library that supports it? That's the Java XML library hassles all over again, people aren't learning from history.
While I haven't read the book myself, I've heard good things about http://www.atomicscala.com/. It's a book, not an online tutorial, but the first 100 pages also come as a free sample. I would probably advise against going out of your way to learn Java before learning Scala, just because if you have to learn about static typing, may as well do it in your target language. 
If you didn't notice the 'antipathy' in that thread then I'm astounded, the pragmatists seem to want to hold back progress continuously.
The criticism of adding to the library gets dismissed *in that thread* because *it isn't the topic of that thread*. I understand that emotions can run high when people are (deeply) invested in multiple ways, including in regards to contributions, work, projects, communities, etc., but partly there are existing processes to these issues that have been created (such as SIP and more recently SLIP) to help tackle various challenges, including the general challenge of evolving a language well (which I believe we can all agree is extremely difficult), and partly there are many others with different viewpoints and stakes that are (deeply) invested in multiple ways as well, which is important to take into consideration. Questioning those processes might of course make sense - but ongoing work of the existing processes should still not be disrupted, and the decisions of those that are responsible should ultimately be respected.
Well... maybe I am wrong, and with all due respect, but I think it may do you good to widen your horizons and experience. I have personally experienced how some that have been careful and conservative (and highly capable) has brought far more progress than those that were highly capable as well, but careless and not spending time on understanding what progress really means. I would believe that we both agree that Scala has already done a lot to help advance FP in the mainstream considerably, and Scala is one of the more popular functional programming languages out there despite languages such as Haskell having been around for a longer time, which I think is a worthy achievement and something that constitutes real progress. And I think that it is also important to consider that FP is not a silver bullet (I personally find it informative to investigate and try to understand in which ways FP is not a silver bullet, both in general and in comparison to the existing alternatives), and that it is important to consider what that means for what "progress" here means.
IIRC Atomic Scala, by the authors' own admission, concentrates on object oriented programming somewhat to the neglect of the functional end of things. There's a CS1/CS2 textbook, published by CRC Press, that's quite comprehensive but (IME) positively maddening: confusing, verbose, haphazardly organized, and with a ridiculously scanty index. In general I would say that learners in your situation are not a priority of the Scala community, at least not yet.
Why not mention Scalaz's Task, the preferred way of doing async computations in Scala? 
Thing is `await` IS helpful when you need to implement complex continuation logic but contrived examples in your article don't show it's power. Code using for-comprehensions would work fine and look nicer because there's no boiler-plate. You don't like (implicit, so yeah, that's the whole one line you have to add to your imports) `ExecutionContext` but quite content with explicit `TaskFactory` that does exactly the same thing. These little things show that you don't know what you're talking about.
Wow, that's a condescending assumption right there! This is exactly the kind of thing that makes the Scala community frustrating to deal with. Having built embedded systems in C, frontend applications in various languages and servers in .Net languages, Java, Scala and Haskell. I can tell you that I've found the fully FP approach a refreshing break, which has resulted in minimal bugs and resulted in huge functionality benefits.
I did read your comment. If you meant criticisms, as in not just criticisms of adding to the standard library, then I think your reply is not clear. My impression of the thread on Github is also that specific technical criticism of the general topic of a JSON AST and of the proposal is not dismissed, but argued actively and constructively.
Well... I tried to argue, explain and come with points, but you seem to have your barricades up, so to say. I think it may make more sense to continue the discussion at a later date. And for the record, I was not talking about your horizons and experience in regards to technical competence, insight or experience, though that may have been unclear despite the context of what I wrote later on in that reply.
since when is scalaz the de-facto standard?
Good work nesting calls
It depends on the community you talk to. Scalaz and people leaning more on the functional side will probably use Task. Task is useful when running impure functions, it lets you wait to execute until you want to, which means side effects aren't triggered until you want them to be. This allows you to view your io stuff as referentially transparent even. Because it is until you run it. Futures can have some gotchas because they run immediately. This means they're only "safe" when they contain pure functions (things that are referentially transparent aka have no side effects) I've never run in to issues with them, but I know of people who have. 
Also note that sites like Facebook load about 1.7MB of JavaScript (gzipped!) and they seem to be doing fine with billion+ users :)
You're missing the point. 1. This doesn't mean they don't lose users because of the size of their page. 2. You're not Facebook. Anyone in the SEO business knows how every byte counts in web pages and that there is a direct correlation between page size and users dropping out. 
Use EitherT? 
Not very constructive if you don't know about Scalaz (and even then, I'm not totally sure what EitherT does ;))
I deed. Back to the point of my article, I am not comparing the features of the languages since both, C# and Scala, offer the same functionalities in a way or another. However, how they are presented to the users it what really matters. We don't think async because it difficult by nature, so C# await/async let you do multitasking (very optimized by the way) in a sync way which is easier for developers. The compiler does the horrible job of rewriting everything for us. 
I don't feel the author has a good enough understanding of Scala or asynchronicity to draw this conclusion. They mention that *onSuccess* and *onFailure* are old fashioned but fail to realise that they are only used when side-effects are interesting (which is why they return Unit.) When chaining futures the most common practice is to use map/flatMap (or for-comprehensions). This is comparible with Task#ContinueWith. val uri = ... val fileDownload = downloadFileFromTheWeb(uri) fileDownload.onFailure { case NonFatal(t) =&gt; logger.warning(s"Download of resource $uri failed: ${t.getMessage}") } val futureFilePath = for { file &lt;- fileDownload filePath &lt;- saveFileToDisk(file) } yield filePath Map and flatMap both return a new Future so the argument that Task is better since they return Tasks is invalid. Comparing map with async/await like the article does isn't accurate either.
I think future is fine too if you know what you are doing. I've been doing professional scala for a while now and it's my experience that Task is generally preferred by the teams I've been on. 
I have worked with it for some time now, it is quite good. It offers basically the same functionalities, yet it has some problems. I was just trying to do some comparison on the build in API. On the other hand, that someone has created the async library for Scala confirm that the current API is not easy to use, or at least it is not as intuitive as the C# async API.
Really, the async and await keywords are THE thing that makes async programming in C# so nice when compared to Scala. And even then, Scala's for comprehensions get you close... but they're not quite as seamless as await expressions. Your article does eventually make this point, but you use a lot of words to get there. I'm glad that you're excited about the TPL, but you should be aware that TPL tasks are not "the core of multithreading" in .NET. They are but one tool. They are an excellent tool, but they are not the only way to do concurrency on the CLR, nor are they appropriate in every circumstance. Actor systems, which you only mention in passing, are a solution to a different set of concurrency problems. You would use tasks and actor systems to solve different kinds of problems. As an aside, if you find that you're calling Task.Factory.StartNew all over the place, it's a sign that you might be using the TPL wrong. In particular, that creates a thread-based task, which means your code will consume a threadpool thread while executing the task's body... and if that body contains slow, blocking calls, you'll consume the thread for the entire duration. If available, it's better to use actual async methods, like Stream.WriteAsync. These needn't necessarily use a thread during their execution; they can take advantage of kernel facilities and hardware parallelism (like DMA) to do their work. 
Focusing on cleaning up the method signatures and data structures, I came up with: case class Token(value: String) case class AddedUser(id: Long) case class AddedAdmin(id: Long) case class AddedToSecurityGroup(id: Long, name: String) def login(user: String, password: String): Future[Either[Unit, Token]] = Future.successful( Right(Token("token")) ) // assume `adding a user` requires an authorization token def addUser(name: String, token: Token): Future[Either[Unit, AddedUser]] = Future.successful(Right( AddedUser(55) ) ) // assume `adding a user` requires an authorization token def addAdmin(userId: Long, token: Token): Future[Either[Unit, AddedAdmin]] = Future.successful(Right( AddedAdmin(userId) ) ) // assume `adding a user` requires an authorization token def addToSecurityGroup(userId: Long, name: String, token: Token): Future[Either[Unit, AddedToSecurityGroup]] = Future.successful(Right( AddedToSecurityGroup(userId, name) ) ) def futLeft[A, B](left: A): Future[Either[A, B]] = Future.successful( Left( left ) ) def f(userName: String, securityGroup: String, token: Token): Future[Either[Unit, AddedToSecurityGroup]] = for { addedUser &lt;- addUser(userName, token) addedAdmin &lt;- addedUser.fold(futLeft(_), u =&gt; addAdmin(u.id, token) ) addedSecGrp &lt;- addedAdmin.fold(futLeft(_), admin =&gt; addToSecurityGroup(admin.id, securityGroup, token) ) } yield addedSecGrp And then testing: scala&gt; f("kevin", "someSecurityGroup", Token("secret token")) res10: scala.concurrent.Future[Either[Unit,Improved.AddedToSecurityGroup]] = Future(&lt;not completed&gt;) scala&gt; res10.value res11: Option[scala.util.Try[Either[Unit,Improved.AddedToSecurityGroup]]] = Some(Success(Right(AddedToSecurityGroup(55,someSecurityGroup)))) Perhaps it's not necessary to wrap each successful step, i.e. `AddedSecurityGroup( AddedAdmin( AddedUser ( ... ) ) )`? Please give me your feedback on this attempted improvement.
Good points. Thanks. Im awere that TPL is not the only mechanism in .net to multithreading programs, we also have threads, the thread pool, etc, in a lower api we got locks, mutexs and barriers for synchronization. There are tons of then all over the place, specially that the framework has evolved a lot since where I started using it back in 2004. 
Sure, I don't disagree with this (nor do many other people). However the language that you used implied, that generally speaking, most people prefer `Task` as a general solution to async programming in Scala. This is far from the case
&gt; mission critical Javascript That's hilarious.
Oh sure ... Like for Eclipse + IntelliJ + Ensime + whatever else. + also sbt incremental compilation. + every other tool that inspects the classpath. Or, we can just keep the .class files and *have it all just work*. You have **no idea** what you're talking about, if you start with that kind of "just do that" argument. Also, these .class files are needed *as real .class files* for *macros*. And they are true .class files for that purpose. So they *are* needed, *as class files*. We say you can't use them because they are also *polluted* with artifacts of the Scala.js compiler plugin, and you don't want that in your JVM deployment. Oh and btw, all the information you need to build a Maven plugin yourself is here: https://github.com/scala-js/scala-js/blob/master/cli/src/main/scala/org/scalajs/cli/Scalajsld.scala : a one-file command-line-interface to the Scala.js Tools API with the essentials of what the sbt plugin does. You can probably mostly copy-paste these snippets into a Maven plugin, if you know how to write a Maven plugin. We do not have Maven expertise in the core Scala.js team, so we can't do it ourselves.
sun.misc.Unsafe will be removed but certainly replaced with a suitable alternative (https://www.youtube.com/watch?v=4HG0YQVy8UM). Offheap developer seems to be ready to integrate the replacement as soon as it is availabe. See the project faq: https://github.com/densh/scala-offheap/blob/master/docs/06_faq.md
It would be really nice to be able to integrate scalajs into a play app with code sharing but without resorting to [this level of SBT insanity](https://github.com/ochrons/scalajs-spa-tutorial) with its custom build configuration spanning 3 files in 2 directories and 5 separate SBT plugins. I tried using that as a template, but I couldn't touch anything without it breaking. Do we really have to be SBT experts to do this sort of thing? Could anybody help me figure out to do this a little more simply? 
Those are some pretty brutal requirements...
It's not putting lipstick on a pig to compile Scala to JS. It's smart. There are a billion reasons why using Scala or a different language that provides like strong type-safety, pattern-matching, etc. is going to provide you with numeric short- and long-term benefits over using a language with JavaScript's properties. The only downsides to using Scala.JS instead of raw JS is a larger filesize (not very much) and compilation time if you're used to direct-editing JS. Even the speed matches. &gt; Probably it`s time to people here grow up and support each other. You realise the irony of you calling me childish because you don't like my opinion and then moaning that people should grow up, right? You did it to someone else below too. Maybe next time you should put a list of replies you *want* to hear like *"oooh that's amazing, so relatable to Scala and such a good idea to keep adding shitty hacks onto JS! Great job"* and then I'll just copy-and-paste it to you so I don't get a rude reply for trying to be actually helpful.
&gt; Oh, have some good thing in Ruby that Scala doesnt? Lets just compile Ruby to Scala.... this is bad, this is the real lipstick on a pig. Scala misses the platform as the ability to be used in the browser too. Not features. This is a js-related module - why did you asked this on /r/scala and /r/haskell and not on /r/javascript ?
After trying SBT a couple times, here's my tip: just use Maven instead.
Cool, so Non Java programmers can finally try learning Scala, lets hope they have finally fixed Scala by getting rid of SBT.
Your second link suggest that there in fact is no replacement. The fact that the author is considering JNI as the most performant replacement suggests how badly there is no replacement. A single JNI call is likely 1000 times as expensive as a sun.misc.Unsafe write to memory.
Thanks for the input. I agree with you entirely and try to leverage existing fold map etc whenever possible. Sometimes I find it's easier to write your own tailrec than using fold etc. 
Not a tutorial, but I wrote a smallish Akka app in Scala that hopefully isn't too difficult to understand: https://github.com/NebuPookins/Send-More-Money
I'm interested, but don't know yet how much time I can invest. My Github name is [nightscape](https://github.com/nightscape/). Tensorflow is written mostly in C++ and Python and has some Protobuf specs. Would you want to interact via JNI or use Protobuf?
This looks rather like http://fsharpforfunandprofit.com/posts/recipe-part2/ I can't find the scala talk that relates to this, but remember watching one.
Really nice example think you chose a great problem to tackle. Although the `Thread.sleep` did make me wince a tad ;]
I'm game. Is there a github repo set up?
I bought the early access version of sbt in action, and it hasn't been as illuminating as I'd hoped. 
It's very smart using Scala.js on JavaScript projects, that's why greater JavaScript projects are made with Scala.js instead pure JavaScript. Everyday people in a JavaScript project when faces a problem says "let's use Scala.JS, because trying to solve this problem in JavaScript is doing lipstick in a pig" Yeah, you're right, sorry for being childish and giving my opinion without wasting 2 minutes to think about it.
Because is inspired in Scala and Haskell pattern matching.
tl;dr OP's a freshman at MIT o_O
Basically, I've written a full-fledged programming language using scala's type system. For example I can compute 1 + 1: eval[Plus#ap[_1]#ap[_1]] =&gt; (λx.(λy.(x (x y)))) == _2 I can also write that as eval[_1 + _1] using the aliases included. I can also define a function to generate odd numbers: type F = (k -&gt;: ((_2 * k) + _1)) eval[F] =&gt; (λk.(λx.(λy.((k x) ((k x) (((λx.(λy.(x y))) x) y)))))) And we can run it: eval[F#ap[_3]] =&gt; (λx.(λy.(x (x (x (x (x (x (x y))))))))) == _7 eval[F#ap[_2]] =&gt; (λx.(λy.(x (x (x (x (x y))))))) == _5 It's also a nice proof that scala types are a turing complete system, because the lambda calculus is turing complete.
Well the first link is a video that I have not taken the time to watch. But the second link says the following: "Possible options are JNI and direct byte buffers whichever is more performant at the time we need to replace Unsafe. End-user's code should not be affected by the change." So I believe you are misguided in claiming that I am spreading FUD. Perhaps you'd like to redirect your efforts to providing textual information as to what the replacement for unsafe memory access via sun.misc.Unsafe will be, exactly?
Would be interested. After all tensor flow(open sourced version) is single node based. Writing a scalaAPI expose it to scala/spark world of multinodes and multicores.
If you are using Protobuff, you may want to look at https://github.com/SandroGrzicic/ScalaBuff
Why would anyone take this? The creator of Scala teaches a free MOOC on Coursera. I took it and it was excellent.
The idea behind this is that it will evolve into a complete learning path for people interested in using Scala for data science. It will pretty much be: 1. Intro to Scala 2. Using Scala with Spark 3. Data Science with Scala 4. Machine learning and Scala 5. Advanced data science topics with Scala
Hi! If you are just starting out I'd recommend this little series by [Alvin Alexander](http://alvinalexander.com/scala/simple-scala-akka-actor-examples-hello-world-actors). And I also found the book "Programming Scala, 2nd edition" helpful which has a chapter on Akka.
Yes you can use a view bound for that: http://docs.scala-lang.org/tutorials/FAQ/context-and-view-bounds.html The following REPL session demonstrates it: scala&gt; case class Foo(f: String){ def toto = f } defined class Foo scala&gt; implicit def toFoo(s: String) = Foo(s) toFoo: (s: String)Foo scala&gt; def bar[F &lt;% Foo](f: F) = f.toto bar: [F](f: F)(implicit evidence$1: F =&gt; Foo)String scala&gt; bar("toto") res1: String = toto
As /u/skaalf said, you can use a view bound. Generally, this kind of code is a bad idea. It can be very difficult to work out what is going on. Using implicit classes will achieve the same result while requiring the programmer to be explicit (in an unobtrusive way) that a conversion is taking place.
SBT is STUPID BULLSHIT TECHNOLOGY, but its also favorite among ABSOLUTE MORONS
i was censored as usual which means i prove SCALA IS BULLSHIT. i.e. my previous comment is gone missing
Don't do that. It leads to suffering. Take @noel's advice. But if you insist then you can use a view bound as suggested (deprecated, I think) or just ask for an implicit `T =&gt; Foo`; these are equivalent. def bar[T](param: T)(implicit ev: T =&gt; Foo) = ... 
&gt; Everyday people in a JavaScript project when faces a problem says "let's use Scala.JS, because trying to solve this problem in JavaScript is doing lipstick in a pig" I did this just the other day, actually. I replaced one part of a big raw JS app with code written with Scala.js, because writing raw JS and dealing with typo-bugs and poor tool support just cost too much time.
And we want bugs like 'for(unsigned i = n; i &gt;= 0; i--) { ... }' back again from 20 years old C++ code? Wonderful, heh.
Count me in. My github is: https://github.com/pathikrit
de http://linuxfr.org/news/tex-et-traitement-de-donnees-par-flot-e01-lire-du-tex
Skip straight to Klang's comment for the skinny.
After reading [this one](https://storify.com/realtalktech/shocker-mozilla-and-firefox-are-dying) about how we should all vote for Donald Trump (!!!) and "Christian values are under attack in tech", i reallllllly hope you're trolling
Hilarious.
I agree the whole Brendan Eich thing is ridiculous. There is no reason his personal values should interfere with his work. He wasn't fired though, he resigned after people started making a fuss about him not supporting gay marriage! And the board/him is powerless to defend themselves when people form angry mobs and demand blood. Completely retarded. If you think being a christian is lonely, try being gay or transsexual instead. Yes, the media always, always demonizes one side and glorifies the other, thats just what they do - they churn out shit to get views. But regardless, no one is taking your rights away or discriminating against you for being christian. No one is destroying christian values. Just like christianity is under attack by *radical* LGBT people, LGBT is under attack by *radical* Christians. Both sides of the extremes are crazy. Live and let live. 
Is this the work of a Markov chain generator?
Doesn't matter if you're a majority or a minority, someone, somewhere is always going to attack you and your values. I'm sure christian values are attacked (i see it often on Quora) sometimes. Other people not behaving in accordance with christian values is definitely not an attack, but OP has not said anything unreasonable to that effect here. Again, if you believe in christianity, and want to post stuff about it like this, by all means go ahead. Of course not everyone will agree, but as long as you're not hurting anyone, nothing wrong with expressing your views.
This is not a sub for religious discussion so I will refrain commenting on it again. But functional programming as a way to obscure thing and ensure job security? One advantages of functional programming is that the program becomes easier to understand because of the lack of mutation! This article is a joke, and a poorly written one. CEOs who see their developers as a liability rather than an asset....this is just too silly for me.
Yeah, agreed :P I thought this article is completely insane, obviously written by someone who has never programmed, and needlessly untrusting &amp; hostile towards developers.
I can just see someone clueless stumbling across this joke and thinking it's a serious article, basically the same people who will take an article from the Onion seriously. Perhaps tag with sarcasm or satire or some-such before someone thinks it's serious.
The type class pattern shines when you want to make an existing type conform to an interface, but can't change the type directly. Perhaps the interface change would break other code, perhaps it's a class from another library. Otherwise, it's an aesthetic choice to choose a type class over a more traditional inheritance based solution when both will fit. Newer scala coders may have a bit more trouble understanding how the type class solution works, so there is def an argument for sticking to traits and inheritance when you can. 
Or sometimes when you simply don't want to change the underlying implementation. It's a common stylistic choice to put as little logic in data classes as possible. Typeclasses can serve to factor out "behaviors".
Matlab and D? This is a pretty awful article.
I'm interested. https://github.com/shashir
Yeah, I more or less disqualify people who say this stuff from any serious discourse. I can't take people seriously whose opinions come from reading some stuff on the internet without any research on their own.
In addition to monads and monad transformers like EitherT, another super-duper useful abstraction is Traversable: Some(Future("a")).sequence // gives you back Future(Some("a")) Some("a").traverse(Future.apply _) // gives you back Future(Some("a"))
Suprisingly moderate trolling [over on HN](https://news.ycombinator.com/item?id=10559776), where a Scala topic, gasp, is still top 3 after 5 hours. Feel free to debunk any memes that @ItsNotMineISwear refers to in his [spot-on post](https://www.reddit.com/r/scala/comments/3so2o1/5_years_of_scala_and_counting_debunking_some/cwz63m0).
I would not categorize long compile times as Scala FUD. I work daily in very large scala codebase. Long compile times are very interruptive, and are without a doubt the #1 complaint amongst the engineers I work with. And this is after our team has bent over backwards to make compile targets smaller and to make builds incremental. Is this a dealbreaker? No, I don't think so. But it's absolutely something to consider before you decide to make widespread use of Scala, and I think it's the #1 thing the Scala team could improve to make the language better.
I attended the [Scala Exchange](https://skillsmatter.com/conferences/6862-scala-exchange-2015) in London last year and will be again this year. Looking forward to it :D
The codebase itself is on the order of millions of lines of code, split roughly 50-50 between java and scala. Obviously the compile targets are not that large, but there are many that are several hundreds of thousands of lines. 
Obviously this is kind of hard to nail down, as it varies quite a bit depending on the target, and an incremental build depends on how incremental the changes are. I'm understanding when a clean compile takes a long time, even tens of minutes. But incremental builds should generally be on the order of seconds to complete for most changes. I get nowhere near 12 seconds for an incremental build. I'd say they usually take around a minute, sometimes more. 
No, thanks. This repeats all the mistakes of Maven.
Maven is a mistake. The only thing it got right was dependency management. 
The evidence on the side of FP is a lot of great experts who agree with proven track records (e.g [John Carmack](https://www.youtube.com/watch?v=1PhArSujR_A) who has probably coded for 10,000+ hours in his life), or maybe even the fact that Odersky, creator of Scala!, built the Java (the one true way according to you) compiler. Oh and millions of other programmers and the collective evolution of software. Your "proof" on the other hand as far as i can tell is this statement: &gt; Functional programming is the sociological construct of deviance theory &gt; &gt; It's a defense mechanism, but truth is, you really gotta be top 5% of programmers to understand concurrency and parallelism in True Languages. plus a random paper you found that would only mean anything if we already assume your statement is true. Or your brilliantly informed opinions such as &gt;Maybe they felt too intimidated by implementing concurrency in C++, so they thought they could mask all of it if they remembered a bunch of symbols instead (also backed up by nothing). Hint: All of that is *intuition* (which is why i linked to the video), nothing even close to evidence. Seems like you think math and FP is hard, and your defense mechanism is to rage against it. Anyways, I'm done. I hope your delusions continue to bring you comfort! 
~~carmack probably hasn't written a line of code since the 90's.~~ (edit: not my point) he gives a language a small nod, and you think that equates to efficacy under market conditions? In reality where the clock is ticking? Even if fp were this unicorn, how do you expect for people to drop everything to learn something that goes against the grain of computation. Hint: All of that is intuition (which is why i linked to the video), nothing even close to evidence. Seems like you think concurrency and imperative programming is hard, and your defense mechanism is to rage against it. Anyways, I'm done. I hope your delusions continue to bring you comfort!
A build definition written in a non-programming language is also immutable. You don't need to do what SBT did just to accomplish that.
I like the Either example to show how much `sequence` and `traverse` are useful. For those unfamiliar with Scalaz: `\/` is analogous to Scala's standard `Either`, with `-\/` being the Left and `\/-` the Right. import scalaz._ import Scalaz._ val fail: List[Int \/ Int] = List(1.right, 2.right, 3.right, 4.left, 5.right) val ok: List[Int \/ Int] = List(1.right, 2.right, 3.right, 4.right, 5.right) fail.sequenceU // short-circuits and returns the first left case // =&gt; scalaz.\/[Int,List[Int]] = -\/(4) ok.sequenceU // unwraps all the Eithers and returns a list with all the successes // =&gt; scalaz.\/[Int,List[Int]] = \/-(List(1, 2, 3, 4, 5)) fail.traverseU { e =&gt; e.map(_ + 1) } // short-circuits // =&gt; scalaz.\/[Int,List[Int]] = -\/(4) ok.traverseU { e =&gt; e.map(_ + 1) } // increments all the values and returns a new list // =&gt; scalaz.\/[Int,List[Int]] = \/-(List(2, 3, 4, 5, 6)) (if you pay attention, `sequence` is just a special case for `traverse` with the identity function). Also a small correction (apologies for the pedantry): the Scalaz type-class is named `Traverse`, probably to avoid conflicting with the stdlib `Traversable` collection class. 
&gt;Maven is a mistake. What does that even mean?
Perhaps that's true, but it can be equally true for any other supposedly less complex language. For example, I found multiple times that when you run into trouble with a third-party Java library of substantial size, you also have to gain a lot of knowledge to penetrate that code and understand what is going on.
&gt; millions of lines of code wat?
Scala, functional programming and the like is not worth waging a war over. There are far worthier topics out there to engage in vigorously. And for a technical field like this, I believe the approaches that some people use only poisons the well for everyone. And that includes people like realtalktech and Tony Morris. Please hold a higher standard. As for functional programming, it is indeed awesome, but it is not a silver bullet or the be-all and end-all of the future of programming (and I do not believe it is always the best approach even when correctness is a strict requirement - for instance, if creating hard real-time software that may not fail any deadlines, an imperative approach (for instance by using the Atom DSL in Haskell or using a model checker like PRISM together with a formally verified C compiler and proving the program's correctness) may be a better approach in practice than seeking to build it in a functional programming language). See also this topic: [Quora: What kind of programs should never ever be written in Haskell and why?](https://www.quora.com/What-kind-of-programs-should-never-ever-be-written-in-Haskell-and-why). I am beginning to think that the focus should not be on functional programming in and of itself, but on other sets of values and ideas, where functional programming (pure, impure, mixed with other paradigms) "merely" ought to be the default in many or most domains, because it happens to be the best tool for the job for achieving our goals (for instance, correct, efficient, adaptable software written in a timely fashion that can be achieved reliably in practice and that does what we want it to do). That would agree with the push for functional programming, but make it much more clear that (pure) functional programming in itself is not a goal, despite it being a worthy approach to follow, seek, delve into, and contribute to.
I'm warming up to SBT but I'd like the user-facing interfaces to be stricter. Dependency declaration always seemed a bit weird to me, with % and %% and then tacking on configurations and methods and such. A more explicit `libraryDependencies += Dependency(group = "com.foo", artifact = "bar", rev = "1.23", configuration = Test)`, with or without named parameters, would to me be more legible. That being said, SBT as an engine — like the JVM — does a good job doing its thing! I really wouldn't want it to die in a fire.
&gt; A more explicit [...] would to me be more legible. Just do it? libraryDependencies += ModuleID(organization = "...", name = "...", revision = "...", ...)
&gt; If reality is the measure, how do you explain the growth of FP? Scala, Closure, Java adopting FP constructs, new languages like Rust applying FP to lower-level programming, Erlang being used in huge distributed, critical systems. What growth? That's begging the question a bit. Compared to node and golang? Where does it fit relatively? Who says that growth is an indicator of its' viability in a business or production setting? &gt; Of all the subreddit's you could have come with this jab you do it on the Scala one, a language that deliberately includes OO and imperative constructs to allow you to mix them in if you want? Is that a good thing? I love the flexibility of scala. In practice this has to be tempered if the team wants a readable codebase. &gt; You readily dismiss and ignore 50 years of academia and huge examples of success of FP, but thinks your own poorly formed arguments are "proof". You really need to evaluate your own standards, and at least inform yourself properly. What is your definition of success? I haven't seen any functional programming houses on the NASDAQ. The exception would be financial/trading. &gt; The defence mechanism is to create better ways to deal with concurrency. That's exactly what many functional languages provide. It seems like you have this idea that one has to stay "pure" to computing roots to do anything. You don't. You can do it when it is necessary or when it's profitable, but turn to something more abstract when convenient. Programming is not just about the computer: it's about translating human thoughts, and abstract languages do it in more manageable, correct and intuitive ways. The defense mechanism is to work around concurrency being difficult to grasp in imperative languages, but the tools are getting better. That's exactly what many imperative languages provide. It seems like some have this idea that one has to stay "pure" to functional roots to do anything. You don't. You can do it when it is necessary or when it's profitable, but turn decoupled components in a different (for example, functional language) when convenient. Programming is not just about the computer: it's about translating human thoughts, and abstract languages do it in more manageable, transparent and humanly intuitive ways.
&gt; Adding static methods means modifying original class (even if it's a companion object).... Not really, I can choose to forego making my extension a companion object and just make it an unrelated object in my client code, or I could wrap the original class with a new implicit class and put my new behaviour in the wrapper. So, if I just want to extend a single type with new behaviour, I have other ways to do it than typeclasses.
Watching this guy try to use reason to form a coherent thought is amusing in the same way the fat star wars kid trying to twirl around is. I hope he keeps it up! https://www.youtube.com/watch?v=HPPj6viIBmU (video for reference)
i read through the readme of this repository several times and I don't understand what the purpose of this framework is. Could someone give an example of a common use case for it? Thanks!
Play framework uses Logback, Guice and a custom class loader, so you're certainly dealing with all that Java stuff. Here's an example from one the few authentication libraries for Play. First, you have to wire up DI like this https://github.com/sne11ius/play-silhouette-slick-seed/blob/master/app/utils/di/SilhouetteModule.scala#L30 and then you still have to write code like this https://github.com/mohiva/play-silhouette-seed/blob/master/app/controllers/CredentialsAuthController.scala#L54
What is "Cracking the Code" ?
&gt; What growth? That's begging the question a bit. &gt; Compared to node and golang? Where does it fit relatively? Scala, Erlang, Haskell, ML and Scheme are all ahead of Go in the Tiobe language index, for instance. &gt; Who says that growth is an indicator of its' viability in a business or production setting? Go look at the companies that user [Erlang](https://en.wikipedia.org/wiki/Erlang_%28programming_language%29) and explain to me how that does not represent viability in production settings. &gt; Is that a good thing? &gt; I love the flexibility of scala. In practice this has to be tempered if the team wants a readable codebase. So you claim FP-advocates want everyone to move in at once and that it is bad. Then you claim moving in piecemeal is bad. So what you want is not change at all. Not because you've shown any strong arguments against FP as a paradigm (you haven't, and don't even seem to have even brushed up the literature on the subject), but because you see it as an attack on existing programming models or something? I honestly cannot comprehend the connections you make. &gt; What is your definition of success? I haven't seen any functional programming houses on the NASDAQ. The exception would be financial/trading. "There isn't any FP in use except for those billions of dollars in trades flowing around and those huge telecom companies". Nice selection bias there. &gt; The defense mechanism is to work around concurrency being difficult to grasp in imperative languages, but the tools are getting better. That's exactly what many imperative languages provide. That is not at all an argument for why the FP solutions are worse. Saying that imperative tools for concurrency are getting better does not imply they *are better right now*, that there is no place for other solutions, or says anything about the merits of either comparatively. &gt; It seems like some have this idea that one has to stay "pure" to functional roots to do anything. You don't. You can do it when it is necessary or when it's profitable, but turn decoupled components in a different (for example, functional language) when convenient. Gasping at straws? Scala is a not a purist functional language. Industry tendency of adoption of FP is not and has never been about purism. I never made any argument about purism. You're replying to ghosts. 
Those are Scala-files so it seems you support me by evidence but the tone of your comment suggests you disagree. You don't **have** to write code like that, really. You *can*, if you want or if you're stressed or if you just don't care, just like you can with any other language I have experience with. You don't have to use Guice with Play either, in fact it supports compile time dependency injection using native Scala features. You can also use something else than Play: I'm certainly not dealing with all that Java stuff. Not to bash Play or anything, I just don't have a use-case.
I mean, a single linked and double linked list list source code is part of Scala itself. Dive in! I.e. here is double linked list: https://github.com/scala/scala/blob/5cb3d4ec14488ce2fc5a1cc8ebdd12845859c57d/src/library/scala/collection/mutable/DoubleLinkedList.scala Not sure what seeing how linked lists are made will help though, to understand Scala you need to understand the history of the language and the tradeoffs it makes. It will take a lot more than 20 minutes to get that. 
Cracking the code is written in Java and C++ since those are considered to be the language of business. Scala is used as well in industry, but if you look at the numbers its nowhere close to the two I just mentioned. 
The reason for using macros was to make the syntax easier to understand. It used to be worse, believe me.
Check this out. It's a quick and simple Actor model tutorial using Akka. http://rerun.me/2014/09/11/introducing-actors-akka-notes-part-1/
Odersky did a class on coursera that was super good
Yes I have no idea, its a queue or something, I guess I would just use RabbitBQ
Oh, really? I thought Nix was the new cool thing? Or Stackage? Or Stack? I guess I'll just wait a bit until these things are less volatile than JavaScript's ecosystem.
I prefer to spend my time tracking down bugs due to race conditions. I don't actually like to make algorithms or programs, just fix existing ones. /s
&gt; Functional programming has it's good things about it. You do this every so often in your writings, maybe this can at least help you writing in a decent English: http://theoatmeal.com/comics/apostrophe Sadly there is no much you can do to overcome the total lack of content and justification for your writings. Imagine some haskell developer going into /r/java spamming rants about OOP; or some Java dev ranting into /r/javascript or /r/cobol. For some reason that doesn't happen, where does this put you? Or maybe, taking your approach, we should ask "why OOP?"; in the end we sent stuff on the moon writing in archaic structural languages. In the end when there is something new coming along people divide into two groups: some of them may be suspicious and keep the old ways, maybe because they do not have enough time/motivation to learn and that's OK; others act enthusiastic as they have something new to learn and a new way to improve on their craftsmanship and that's OK as well. Across this spectrum, only people complaining, ranting and regurgitating their frustration on top of the others like you do are not.
At least they're not spreading cancer like certain other people, right?
From his storify bio "Tech for Alpha Males. No code of conduct. Vote Trump." Beautiful. :eyeroll: I'll never understand the lengths trolls go through to get a reaction.
&gt; Discrimination? You think I get good feedback from being a Christian? Call yourself a Christian, get ready to be automatically written off as bigot in social media, college campuses and many work places. Where's the love your neighbour as yourself in your blog posts? Where's the love your enemies and do good to those who persecute you? Where's the turn the other cheek and go the extra mile? Where's the "neither do I condemn you"? Where's the judge not lest you be judged? Most Christians I know are really considerate people who talk kindly about others, but I think you're giving Christians a bad name if you spew so much hate on the internet and then act all hurt when people call you out on it. You use such unpleasant language and then expect people to ignore all the vitriol and respond to your points, but honestly, it's hard to find them amongst the ugly language. This isn't the way to get the point of view of Christians heard, nor the way to debate your concerns about functional programming.
I don't have this directly, but use Play + Slick in prod and can probably guide you. Coding up a very minimal gist. See at: http://pastie.org/10561422 Your main choice is where you want the "db.run" part to live. It can live in the controller, which is good because it lets you compose a bunch of queries together - and do stuff like complex transactions. But then DB coder is living with controllers. In this example I put the actual DB.run inside the database code... If this doesn't work for you, post to github what you have and I can fix it for you. Little tricky to grok slick + play, but they are nice together... 
&gt; Tech for Alpha Males. No code of conduct. Vote Trump. That guy is a winner.
less.js? Why not scss? I don't think that less.js will win the battle ]:)
&gt; redditor for 1 day ... &gt; -81 comment karma Here is the new [agleiv2](https://www.reddit.com/user/agleiv2)
second this, its probably the biggest/well known Scala conference in the UK, not sure if there are any others actually?
Regarding Odersky's note on out-of-the-box experience: &gt; let's say I need to do some JSON stuff in Python. I would take the pre-installed python package, or if it's not there install it. Then I would expect I could start the REPL and read in my first JSON doc. If somebody told me, no, you first have to make an SBT project and edit your dependencies, and btw that means you have to have at least a rudimentary understanding of SBT before you can get started, you have lost me right here and there. I think this is a valid point, but then this has nothing to do with the question what should go in the standard library, etc. (as the text says, the question is wrong). It rather implies that we have something entirely different to sbt/maven to organize modules. So it implies the language adopts a new module system? __Edit:__ Personally I think sbt is good enough, it's a proven system that works. If one considers the effort to write a minimal `build.sbt` too big, perhaps the smartest solution is just to add a light-weight user-facing thing that feeds sbt.
I rather think this is an argument to give the REPL dependency loading/downloading functionality rather than that a JSON module should be included from the stdlib. 
Stupid question, but any idea when his course is being re-released? I want to be able to submit the homework and have it graded and currently cant do so as submissions are closed. 
I don't really care how its named, organized or rephrased, and if it is called SBT, Maven or PIP. As I think Odersky and the entire community understands, batteries included is not just a cry of the lazy programmer who can't google stuff and copy snippets from stack overflow on "how to read a file" We already have a super computer in our pockets, and yet we still buy a watch that will save us from the need to reach out to the pocket and read a text message. Convenient matters to people. It's not laziness. Having a decent JSON parser built in, a decent file system handler, a decent REST client, should be available for a developer out of the box. I don't really care if you call it the core library, the standard library, the "Endorsed by Odersky (tm)" library or the scala-a-to-z library. In Java, batteries were not included, for most things, and we have apache commons (whether you like it or not) to fill in the void (as well as Guava), but it took years and only happened because Java became such a popular language and the mass need for those "batteries" created the basis that made amazing projects like Apache Commons possible. It took years but eventually Java 8 added some long needed batteries (JSON parsing), and no one died, and it's about time Scala did so too. I think it is a blessing that this is discussed and taken seriously. I think it will help more people appreciate Scala. p.s. I still think that Scala needs trailing comma, support underscores _ in numeric literals, support binary literals, just to keep the promise that a valid Java literal expressions is a Scala valid literal expression. And add Enums for the promise that anything you can do in Java you can do in Scala. It will just help adoption more from Java developers, and I don't see any harm in that. 
I wonder why we can't have a single word alias for the maven / ivy FQN to simplify namespaces. Just like npm or gems. e.g. xyz add apachecommons will lookup in xyz.org for a mapping between appachecommons to a maven org / artifact FQN... will make life easier for common and popular dependencies 
Nope the one on the site now is from 2014. Future sessions doesnt say anything unfortunately :/
&gt; There is some deep stuff going on here. Not really. Number theory is interesting and all, but when you are talking about the reals, there is this thing called the commutative property that they have. I somehow doubt the teacher was trying to teach abstract math to a second grader.
A few people have made similar comments in other forums. The post is really not about the teacher's actions or the properties of reals, but about the separation between expression and evaluation which is implicit in stating that 3x5 is not the same as 5x3. If I get time I'll update the post to make this clearer.
tl;dr: 3x5 could be different from 5x3 if you mean something other than integer multiplication. (which they obviously didn't)
My understanding is that, mathematical equality is a relationship between expressions in which they represent the same object. So in this case, both expressions "evaluate to" hence represent the same object (i.e. number 15). It seems like authors understanding of "mathematical equality" involves number of operations in each expression and specifics of the evaluation. 
But isn't mathematical equality is an assertion regarding the values yield by the expressions ? https://en.wikipedia.org/wiki/Equality_(mathematics) edit: added link
I hear COBOL is pretty good. Why would you want to use anything newer and force people to learn new things? &lt;/sarcasm&gt;
&gt; I still think that Scala needs trailing comma, support underscores _ in numeric literals, support binary literals, just to keep the promise that a valid Java literal expressions is a Scala valid literal expression That hasn't been true for a long time already, and it seems people are moving further away from that.
Yes, that's what I call the "standard interpretation" in the post. This conflates the expression with the value it evaluates to, which is normally harmless. However, the test was asking the student to separate these concepts and I wanted to explore the implications of this separation in the blog post. To summarise the points I was trying to make * expressions and their values are distinct, though we often conflate them * we can explore this separation via programming languages; and * this separation allows us to do interesting things Unfortunately most people have misinterpreted the point of the post (see other comments here) so I obviously didn't do a very good job of clearly laying out my intention. 
Thanks, tomorrow I'll increase the number of threads and I'll update the results.
http://www.scala-sbt.org/0.13/docs/Scripts.html The only thing missing is some kind of repl support from the SBT side. You could also use Ammonite's repl to frontend SBT instead.
Yes. PM me.
&gt; Having a decent JSON parser built in, a decent file system handler, a decent REST client, should be available for a developer out of the box. I don't really care if you call it the core library, the standard library, the "Endorsed by Odersky (tm)" library or the scala-a-to-z library. Totally agree - and as someone who maintains a library in Scala that needs a REST client and Json library, it's a real pain because: * When you import a lib, your user may have a conflict between your dependency version and his dependency version * You can't expose a Json object to your user, because it would be weird if it's not the library he prefers 
&gt; You can't expose a Json object to your user, because it would be weird if it's not the library he prefers Here's where the `jawn` project might be useful. Let your user supply their own json facade, and then you can return a json object from their preferred library. Facades are provided for the major json projects.
Agreed, but `jawn` pretty much proves his point. `jawn` itself has to target 6 JSON AST's, as does any other type of generic JSON parser (such as rapture json) or any other library that has to deal with JSON (i.e. slick-pg)
Yes absolutely. I'm not the hiring manager, but I know for sure we have open positions on my team. Pm me. 
I've used them for non-error handling. I had rows of data that had a couple fields that came in as obfuscated string identifiers and needed to be translated back into integer identifiers (FKs in the original database table they came from). Rather than having a separate case class for each stage of processing I used one case class that had a bunch of `Either[String, Int]` fields. At the beginning they all had `String`s and at the end they all had `Int`s. Worked great.
At that point, you could use `Option[Option[Double]]` rather than `Either`.
When is it a good idea to use such unusually-named identifiers?
Author here. This post is meant as a first introduction to what property-based testing with ScalaCheck looks like, don't expect a deep dive ;) Although further posts might cover advanced topics, so stay tuned.
The intention is a lot clearer to me in this representation.
The results have been updated. When I increase the number of threads to 3 the results are similar to use only 1. When increasing the number of threads to 10 and 20 the results are really bad for all the alternatives with the async-await approach as the best result but close to the result of the for-comprehension approach. As I heard before "Context switch is evil". https://github.com/gvolpe/computation-expressions-demo/tree/microbenchmark-harness Soon I'll update the blog post with this results.
He goes by agleiv_17 these days. I don't know what happened with 3-16. 
&gt;But that also feels tangled and aberrant. It is 
FORTRAN master race!!
I'll probably just keep using SBT and not having to deal with this mess.
One might as well say that you've got the mess of ant, ivy, maven, sbt, gradle, etc. so I'll just keep using cabal and not have to deal with that mess. Most people just use cabal, and for the most part it works smoothly.
Problem is: people think that functional programming is entirely linked to Monads. Good part of it really can be expressed as monads, but you don't have to know how to write a monad to use one. Also, *foreach*, *map*, *flatmap* and passing functions as first-class values, are indeed the next big thing in the commoner programmer toolbelt. Also, the main shill against functional programmers does come from people not wanting to improve. C# has some concepts borrowed from functional languages IIRC. 
Are you open to remote work?
And it will! Javascript is one of the most used languages nowadays and I find it really close to Scala, in some concepts, but Scala is a way richer and deep language, with tons of advanced things, making it IMO the best language for academia and business. I learned monads a lot later after I started working with Scala. Monads are not *really* that hard to understand, people just explain them in the wrong way, putting category theory in field and other not so friendly things. But yeah, ML based languages *shove down* the functional down your throat, while Scala (and Javascript) are a lot more flexible, letting you write pure procedural programs instead of using all the power it has to offer. 
So, at some point when I first heard about ScalaCheck I really wanted to drink the kool-aid... And I've used it for a bit, it's interesting. Really good at making sure you have your negative/MaxInt cases covered. But at some point someone told me that on Scalawags (haven't checked) the sentiment was... This is just a poor man's version of using an aggressively typed data model. That your types should encode the contracts that you want to enforce. And random testing is good if your extremities are untyped/use primitives... But there's essentially no point in testing things that are typed properly, because by definition there would be no out of range values. It's interesting. I'm on the fence but leaning on agree. That said, I still think random testing is good anyway precisely because people don't model/type hard enough, and this will show you where your weaknesses are.
Yes we are open to remote work. Drop us your resume.
This may not be the best place to ask this but does anyone know (or point me to some resource) regarding what is the plan for Dotty in the next few years? Is it: a) Just a research/academic language with no other future? b) An incubator language whose features would slowly land in Scala? If yes, approximate timeline? I see the timeline ends on Jan 2016: http://www.scala-lang.org/news/2.12-roadmap c) No slow crossover into Scala 2.x; instead it would simply be called Scala 3? Anyway, super excited about Dotty!
The [github repo](https://github.com/lampepfl/dotty) seems to indicate option 2 - its a playground for new features that may be ported into Scala. presumably they are relying on the community to play with dotty and get feedback on how new features work. It is a full compiler afaik so perhaps if its a major success it would just replace scalac altogether? Theres also the talk at scaladays ([slides](http://www.slideshare.net/Odersky/scala-days-san-francisco-45917092) @slide 40) which mentions they are planning to use TASTY to merge scalac and dotc. Dotty definitely seems awesome. Besides all the nice language features, im really excited about TASTY.
I've chased down that John Hughes video, I think: https://www.youtube.com/watch?v=zi0rHwfiX1Q Thanks for that - enjoyed it (for anyone tempted to watch: it's not Scala-based, but the principles and examples were good, I thought). The take away point or claim was: property based testing finds more more bugs with less effort (presumably compared to debugging production failures, or compared to wiring manual tests).
no sorry, it has to be in NYC
See `scala-records` https://github.com/scala-records/scala-records for an existing implementation of a similar concept. It works on Scala/JVM and Scala.js (unsurprising given that one of the authors is also a core developer of Scala.js).
I believe the plan is roughly a combination of the three. It's research/academic, the "easy" things can bleed into 2.x if they are found to work, the more fundamental differences might in some form become Scala 3 in an undefined future.
Easy way, create a promise, create a play enumerator, resolve the promise within the enumerator (e.g. on Input.EOF), don't run an iteratee to consume the enumerator. Additionally, it can create additional gc overhead if you're holding references to large objects across a significant number of map/flatmaps on the future. Either way though, neither of these is a leak, and there's alternatives to both.
This page from some time ago describes the roadmap for the next several years: [http://www.scala-lang.org/news/roadmap-next](http://www.scala-lang.org/news/roadmap-next).
I found this [tutorial] (http://maciejpirog.github.io/fishy/) very ~~fishy~~ funny and give pretty much a overview about monads, if you don't get the idea at all. The [Maybe Monad] (http://scabl.blogspot.com.br/2013/02/monads-in-scala-1.html) is a good place to start learning about monads, and so is the Scala List and the [Try Monad](http://mauricio.github.io/2014/02/17/scala-either-try-and-the-m-word.html). The list is pretty straight forward, to the point that you don't even know what a monad is, and in the Coursera Scala Progfun Course you are assigned to implement it IIRC.
Having worked in Scala almost 2 years, but never used Slick, I recommend this book. It got me up and running quickly. I've found that the book's Slick code examples are straightforward and explained well.
&gt; &gt; &gt; A third type of company wants smart people that can learn. They realize a language is just a syntax, and a good programmer can use any language. For these kind of companies, Scala can often impress them. The difference between Scala and Java is a bit more than syntax. You statically guarantee more things in Scala than in Java. It's just 100% untrue to say that programming languages just provide syntactic sugar.
Those companies you listed definitely do use Scala in their stacks somewhere, but the reality is most Scala developers don't only work with Scala, they work with Java almost just as much, as such you'll far more often see postings for Senior Java Developers who are familiar with Scala.
&gt; They realize a language is just a syntax, and a good programmer can use any language. Ironically, it is not uncommon for people who are learning Scala or Haskell, to claim they've been forced to renounce statements like that they've made in the past.
I like playing with Data and speed and scalability tend to be easier expressed with Scala
Hum the only thing I make people renounce is that Ruby is better because it compiles faster.
&gt; A language is just a syntax to convert thoughts to machine code. They are different, but all serve the same purpose. Goes against my point tho
I was also approached by Google due to my github profile (and usage of Scala)
Do you really want to work in such a company though?
Do you know if there are any tutorials or examples for using that?
It's as Joel Spolsky says, that it's as much about them hiring a good programmer, as it is about a programmer choosing his work environment. And yeah... Seems there's a lot of these weird checklist type of "interviews" going on.
Depends on what you want to do. If you just want a quick way to render a model, use a library like libGDX or jMonkeyEngine. Those can already do that but since they are designed for Java they aren't exactly idiomatic Scala code. If you want to work a little closer to the metal, you can use lwjgl or JOGL. This gives you more of a free hand when designing your code and allows you to write nice wrappers but also means more work for you.
[We're hiring](http://sortable.com/software-engineer/) Clojurians and Scalists. But we'll happily interview people who are talented in another language, willing to learn Clojure or Scala, and don't have a holy war approach to programming languages.
We could have been coworkers! And argued about functional programming in person!
Well, all programming languages that are Turing complete are equivalent in their computing power, so in a sense they're all syntactic sugar for assembly.
Andrew, Those are not "commandments" or "mortal sins", they are platitudes. In times of peace, when pastures are green, skies are blue, the harvest is plentiful, and so on. Christianity would have never came to me a world religion if we sat around like monks proudly preaching morals. SJW's are cancerous. But religious bigots are just as toxic. You can have liberal values and not be PC Principal. In the same way, you can be a Christian and not be WBC. My point is still the same. Christians don't get much sympathy. Just for being contradictory to me, you get karma. Out of nothing more than demographics of the scene we're in. Now, if this reddit's demographics were Arkansas, Nebraska. Good farm state. Then you'd find all of a sudden the opposite. I'm the virtuous one with all the backup.
I know! Would have been a hell of a lot of fun
When I was looking for work ~2 years ago, a lot of companies were listing Scala in their requirements when their codebase was primarily or even entirely Java in reality.
Two possible reasons: - There are very few Scala developers so if you only hire Scala developers, you will never find anyone. - Their main code base is in Java. They only have a few lines of Scala here and there from an old project and they are now moving back to Java. Posting an ad to attract both Scala and Java developers won't hurt. 
At runtime yes. At compile time no. Not all languages can encode the same static guarantees. And that makes all the difference. Also some languages aren't Turing complete or make Turing completeness optional. And it's pretty useful.
Some measurements on my computer: * Vector operations run in the order of 1M operations per seconds * Mutable sets run in the order of 100k operations per second * Immutable run in the order of 10k operations per second * Higher-order functions (moands, etc) run with about 100 operations per second with scalaz and 10k operations per second with Cats. *Summary:* Abstraction is really costly, costing you several orders of magnitude on performance, from mutable vector (1M) to mutable set (100k) to immutable set (10k) to higher order functions (100). And Cats (10k) is currently faster than scalaz (100) on Scala.js for higher order functions. (all numbers in operations per second) 
Regarding `Vector` you are right. I thought about the underlying array but didn't consider that you cannot change it. Regarding the comparison: I only look at orders of magnitudes. And with a rounding error of factor 10 I think you can compare the numbers. It's just to give an estimation about what ball park you can expect. And I tested it on Chrome, FireFox and IE 11 and got the basically same numbers (with regards to the order of magnitude). So with this in mind I think they are comparable.
Knowledge of the JVM is the only reason I can think of. Otherwise, they're a Java shop that wants to use Scala.
OP is a poor attempt at creating a novelty account.
Yes, I agree with that use case, my earlier comments were too hasty.
I've had false flags with scodec in both 14 and 15.
Stop spreading FUD.
One of the major syntax highlighting scalaz bugs that I've seen in both 14 and 15 is `sequenceU`. That being said, I haven't noticed any new highlighting bugs between 14 and 15, and 15 is way faster. Scalaz hasn't been any different, at least in my experience, between 14 and 15.
You should learn both. I would never hire anybody who only knew one language.
Scala plugin team grows (no Kotlin influence in this part, only positive by suggestions for new ideas and features). Regressions are normal part of evolution for so difficult thing like Scala IDE. We are working with regressions very attentively.
Choose different libraries? There are a lot of pure scala implementations of popular java libraries. Slick is a little bit of a different beast since so many databases use jdbc as a connector, which means they can take a well maintained connector and put a proper scala interface on top of it.
So if you take away the Java that is under Scala, then Scala becomes a weaker version of haskell or F#. Not that haskell or F# is bad per say, but what is so great about scala is that it is good, and it interacts with the JVM libraries when needed.
Its both the great blessing of Scala, that interop is incredibly useful and powerful and also a curse that impacts the language in so many awful ways (type erasure). Its a great transition language and its clearly influenced Java very heavily since it became popular.
F# is to C# as Scala is to Java. It has the same ability to leverage all of the CLI libraries as Scala has to leverage all of the JVM libraries. 
I disagree with singling out type erasure as one of the worst side effects of compiling to byte code - in scala, much more so than in java, you should (almost) never have to rely on runtime type introspection. The type system, and the ability to use patterns such as type classes, allow you to have (almost) all type validation done at compile time, where it should be. More often than not, requiring more type information than is available at runtime is a sign of poor coding rather than a flaw inherent to the language
Well, and for pattern matching, right?
Tell me something I don't know? The point of my post was that if you take Scala and throw away access to Java libs.. it would be pretty silly to use Scala over F# or Haskell. The Java libs is what makes it useful to a lot of people (not all, some people go pure Scala)
I don't think that's true, but I'd be happy to be proven wrong. When pattern matching on sum types for example, the compiler can do a lot of cool things - check for non-exhaustivity, say - but I believe it'll still compile to a series of instanceOf checks. For a concrete example, pattern matching on an Option[A], I believe 'case Some(a)' will be turned into an instance of check, a cast and a call to Some.unapply.
Any spaghetti in particular?
lambda-specific breakpoints *are* awesome. However, they crash jdwp on android :-( edit: to be clear, setting a breakpoint in a lambda, or on a line containing a lambda causes debugged process to crash.
If they know Java, good. If they know Ruby, good. If they know Java AND Ruby, and can talk to you about closures / lambdas in Ruby and type safety in Java... great. Ideally, you want someone who is already comfortable with more than one programming language, and can point out the strengths, weaknesses and appropriateness of each programming language without being dogmatic / zealous / closeminded about it.
Yes, you are the only one. The JVM is a great platform and Scala is only improved by having access to vast existing codebases and a high performance VM with world class portability. 
What does this even mean -- if you take away the runtime layer of a language it becomes less useful? This statement applies to any language in existence.
Pattern-matching is a match on the value (or structure thereof) an expression takes, *value* usually being something that only exists at a runtime. You could pattern match on a literal expression, i.e. one whose value was known at compile-time, but there wouldn't be much point.
They should know what zygohistomorphic prepromorphisms are and how to use them. But I suppose a real question would be "what did you learn this week / month ?" It'll give you pointers on whether the person enjoys programming and therefore will be likely to learn new stuff / methods / programming paradigms, or if the person just sees it as a source of revenue. Curiosity usually comes with drive and willingness to learn. 
It's a valid complaint, but there are a lot of interesting languages that nobody uses for want of libraries. 
That was my point: Scala needs to use it internally, I don't really see how it could do runtime matching on values without runtime type introspection, so I'm quite glad that java, and thus scala, doesn't have total erasure.
You don't need runtime type information for all types in order to pattern match. You only need it for sum types. It just so happens Scala uses instanceOf for sealed traits in addition to matching on unsealed traits. But it's would be completely possible for only sealed traits to be tagged without there being runtime type information for all values. 
Even without Java interop Scala offers feature that Haskell and F# don't have.
F#, as a language design (completely ignoring ecosystem, or what platform it is on, like JVM or .net) is quite different to Scala. F# is a lot closer to your ML's, to the point where (at least the last time I used it), you had to define the correct order of files if you wanted your project to compile. Due to this, it even had issues in using code from the actual .net libraries. F# also doesn't have things like Higher Kinded Types (last I checked), or Scala's really strong Macro system These reasons (plus more) are the ones why I like Scala more than F#
I honestly think that lately, there has been a push on not having to rely on the JVM/Java so much, http://www.scala-js.org/ probably has a lot to do with this (due to `Scala.js` design, it only works with `.scala` source code, it doesn't work with `.java` code, or JVM bytecode for that matter) In SLIP land, there has been a lot of move to get basic Scala libraries done in idiomatic Scala, rather than just "relying on Java" so much. The latest target is IO, but it can apply to other areas as well. Around 5 years ago, there was a project to make a LLVM backend for Scala, however that is pretty much dead now. With the new focus on Dotty, as well as the TASTY backend, its going to be much easier to make alternate backends for Scala while still maintaining binary compatibility/dynamic libraries As a virtual machine, the JVM is the best of class out there, but there are still cases where you cringe that Scala is so dependant on it. Go, which is a language that targets a similar market to Scala, is being used in places where Scala should be used, but its not, and thats just because of the JVM. As an example, writing a supervisor agent for watching something like docker containers that are running. All of that kind of stuff is being written in Go, because it compiles to a single statically linked binary. You can't really do that in Scala, and having to manage a JVM (as a dependency) for an agent is basically a no go, the agent by design needs to have no dependencies as it has to support stuff like no downtime upgrades, even across virtual instances.
What issues do you have with Slick? So far its been the only database library that has provided the proper abstractions (`Query`/`DBIO`/`Future`) that allows you to express anything that you would like to do with databases in an elegant way with type safety and code reuse. I haven't found any other database library that has managed to do that. Sure it isn't perfect, but once you use something like Slick, its hard to go back to anything else. Also Slick isn't inherently tied to JDBC. They are in fact in the process of refactoring it out, so Slick can do stuff like properly support async (which means using something like https://github.com/mauricio/postgresql-async instead of JDBC) 
Not what he is saying at all. His point is Scala didn't start from scratch which is why it was able to become so popular.
Not sure of the relevance of Ruby - Java has lambdas. Most of the FP'ers I know wouldn't touch Ruby. 
Too much code required to solve simple problems compared to other ORMs like .NET Entity Framework and ActiveRecord. Even basic queries like "find all posts with authors and comments" require manual processing of results.
Hi guys, would just like to get some opinion on whether my idea of `checked exceptions on steriods` is possible to implement in Scala. Are you mostly just happy with using `Either`s and ADTs? Because I find that for any large scale CRUD app, error handling is a crucial architectural problem yet I cannot find a satisfactory solution to achieve what I'm looking for.
What do you mean by "manually processing results"?
Hey, thanks a lot for your detailed reply. I'll definitely check out the links you got there and see if it solves my problem.
It seems quite silly indeed. Have you filled a bug report?
Generally it isn't a match against the type - each of the pattern alternatives has to be of the same type (or have a common sub-type in the case of Scala and F# where discriminated unions are implemented as sub-types). But even in the cases where there is a match against a type, the type of the thing being matched isn't known at compile-time - it's matching the dynamic type.
None of the mentioned languages started from scratch. All of them either share a runtime with other languages or provide a FFI (i.e. to C) that allow you to leverage a large body of existing code.
&gt; No support for eager/lazy loading. This doesn't make any sense. Slick is not an ORM.
Curly braces define a block of code, which is nothing else than an expression. You can put chunks of code into braces to group expressions together (value of such a code block is equal to value of the last expression inside braces). { x =&gt; ... } is evaluated to a one argument function during compilation. Another important thing to note is that Scala allows you to skip the parens on the last parameter list in a function call, if that parameter list consists only of a single function. So doing: Action { x =&gt; ... } is the same as doing Action.apply((x) =&gt; { ... })
I'm comparing Slick to Entity Framework and it's way easier to use. I can use it just as Slick with manual joins and manual conversion to proper objects but also it can create object graphs automatically.
Is it possible to be a bit more clear here, its not making much sense. eager/lazy loading doesn't mean anything. If you mean streaming, Slick does support that. Otherwise you need to clarify. Also what do you mean by object graphs?
It does the same thing, when desugared this both expressions look like val echo = Action.apply({ request =&gt; OK.apply("Got request [" + request + "]") })
This might be a dumb question, I know in scala you can treat object as function and function as objects, if you wanted to treat object as function you can use object_instance.apply(function_args) provided that object_instance have a apply method, but I am looking at the source code right now it seems like there is no apply method for Action, https://github.com/playframework/playframework/blob/cde65d987b6cf3c307dfab8269b87a65c5e84575/framework/src/play/src/main/java/play/mvc/Action.java I am confused. What does Action do to the code?
If it's pure scala code it will work (including macros). some limited set of java functions are also available in Scala.js Most of the reflective stuff won't work AFAIK. but you can read more about it here [http://www.scala-js.org/doc/semantics.html] JS doesn't have funky floats. it only has double (64bit IEEE 754 floats). In practice, JS also have 32 bit ints. So it lack long type, but doubles can be used up to 53bit int.
Action in your example code refers to an object named Action, not to a class/trait/type named Action. [Link to scaladoc](https://www.playframework.com/documentation/2.0/api/scala/index.html#play.api.mvc.Action$) 
Very nice, love the comparison table!
Is there a way to call the compiler programmatically? Or is there a place I could look to find it? 
You have to call `scalac` with the appropriate compiler plugin. For this, it's like scalac/JVM. Then you also need to call the linker. For a complete example that does it all, see https://github.com/lihaoyi/scala-js-fiddle/blob/master/server/src/main/scala/fiddle/Compiler.scala
Because only Java programmers can use Scala, since SBT hides everything, Java programmers due to their Jar files experience, only they can understand nuts and bolts of Scala 
Make sure to use the most up-to-date versions you can. Some of the things from older versions, and this is a great example, won't work with newer versions. Don't make yourself learn more than you have to. Unfortunately, Play has few step-by-step tutorials that I've been able to find that work with 2.4. They do have many complete examples on the typesafe website to look through, but again be careful of when they were created. A good exercise might be to work on them and try to figure out how to upgrade them. There are migration guides on the Play site that will help.
Looks nice. I really like that it's proposing Scala.js as a first-class alternative to vanilla JS.
It's a bit hard to reply, your architecture is unclear. Are you building an HTTP API ? And what are you using behind to actually "process the orders" : database(s), other API(s), etc. ? Also "develop a robust callback chain mechanism? (i.e. to implement workflows)" is the more abstract and meaningless sentence I've read in a while :] Anyway, whatever you're building it sounds pretty basic, nothing that you can't do with just Futures. I would avoid Akka, it is rather low-level and probably not the best for a Scala newbie.
Floats might not be "funky" but it's important to note that longs are represented as signed 64bit floats. So, if you returned from your Java/Scala server a particularly large Long javascript will happily, and silently, only take the first 53 bits of your Long. scala&gt; Long.MaxValue res2: Long = 9223372036854775807 &gt; Number.MAX_SAFE_INTEGER &gt; 9007199254740991
Thanks! That's exactly what I was looking for! I have a project generating scala code that I wanted to compile and serve as JS. 
The comparison with TypeScript is interesting to me because I just started playing with it after some frustrations with scalajs. So far I like both languages quite a bit, but I find Typescript's library/ecosystem to be a lot easier to work with, and the build system is a lot less painful to deal with. Scalajs is overall a much better language, but I can't ever seem to do what I want to do with it. I'm curious, how is the TypeScript type system weaker than scalajs? I haven't found it to be weaker...there is an Any class, but it isn't really used much in practice and Scalajs has the same thing that is likewise not used very much. 
[removed]
No implicit parameters in TypeScript is definitely a big reason why it's weaker.
110k? Like, an intern level salary? EDIT: for NY, I mean. 110k for a non senior scala engineer is probably pretty good in flyover country.
A personal list: * Cannot mandate that a field be immutable. This means *no immutable objects ever*. Hard to write functional without this guarantee * No `sealed` hierarchies -&gt; no ADT and their pattern matches * No safe extension methods (you need to mutate the prototypes) * No implicit parameters -&gt; no typeclass design pattern * Edit: No declaration-site variance annotations (of course, since it's virtually useless when all your objects are mutable) * No abstract type members (they are not often used, but when they are, I wonder how many casts I'd have to do without them) * Covariant method parameters * I'm probably forgetting a few right now 
We use Scala.js for some real projects at my work. It's light years ahead of plain JS from a developer productivity standpoint. Typescript comes closer, but Scala.js wins because it doesn't explicitly inherit JS's flaws like TS does. (TS being a superset of JS and all.) The biggest downside of Scala.js is the need to use SBT, but that's (almost) a one-time cost. Even with that I'd take Scala.js over the alternatives any day of the week.
Well, that's something. I hope I can derive from this how to make ScalaJS work with gradle as that is what I personally use for my Scala projects. I definitely won't be going back to sbt. Not until there is an actually stable (1.x) version of it. Having started with Scala in a time when sbt was at 0.7 I'm just too damned tired of having to rewrite my project build files all the time.
Great analysis and interesting read!
 Using it in prod. Share code between server and client. Awesome.
Just letting you know that dispatch isn't abandoned, it has a new name called dispatch reboot https://github.com/dispatch/reboot
https://www.playframework.com/documentation/2.4.x/ScalaActions is the right link. You can click the dropdown arrow on the right-hand side to change which version of the docs you're looking at. 
Sure, but with other disadvantages which have been described before. Entity for example, may do it in a single query, but how does it deal with asyc and/or fine grained atomicity? Slick shouldn't directly deal with this issue, its by design a fairly low level library (in that it doesn't abstract that far from the actual relational design). All this is asking for is scope for a new project that uses Slick as an underlying driver
I can cut you a deal. I will write your scala for only 1 trillion. You can keep the other 14.
TypeScript's build system doesn't do much, so naturally it will be less painful to deal with. But on a real project you'll have to tie that with a dependency management system, like Npm or Bower and with a build system like Grunt or Gulp. Note that I'm biased towards Scala.js because I'm a Scala developer, but I find best about Scala.js is the tooling and that includes the build system.
&gt; The biggest downside of Scala.js is the need to use SBT In my opinion that's one of the big upsides. In order to do what you can do with SBT you'd have to use a compiler sometimes with it's own configuration file (e.g. tsconfig.json), plus a dependency management system (e.g. Npm, Bower or both), plus a module system that needs integration in the build process (AMD/Require.js, Common.js, ES6 or Google Closure), plus a build management system that never works (e.g. Grunt or Gulp or Brunch.io). And on the whole, it's a clusterfuck. Whereas SBT is a tool that handles all of that, works well out of the box with minimal configuration and is very extensible. As an example, whenever I've worked on Javascript projects before, I never had tests because setting up the infrastructure to do that in Javascript is so freaking painful, whereas in Scala.js all my projects now have tests because setting up testing is painless. If anything, for me SBT is one of Scala.js's biggest selling points. For some reason it has a bad reputation, but I personally don't understand why. And sure, it does have some problems, but I've worked with many build systems before and I'm genuinely interested in what better build tools exist out there, because I've never encountered them. 
Most of the sbt hate comes from the old versions that had a whole bunch of weird symbols used everywhere (also things like empty lines mattering etc.)
Oh, wow, thanks, that's a big miss. I'll update my post
&gt; just "how quickly you can pick it up and use it" Yes that was exactly my target : giving a direction for people who just have a few one-off HTTP requests to do and just need a quick-to-integrate, quick-to-work solution. Personally even if have a big project with a bunch of external HTTP APIs to connect I still use Play-WS, but I understand how spray-client can be to someone's taste. Re-usability : I'm not sure what you mean, but if you're talking about reusing some request-building or response-reading logic between HTTP requests, yes I do that all the time with Play-WS, just by factorising the code with private functions, nothing special, but it works and is easy to read. With spray-client I understand that it is built-in with the pipeline composition stuff. Testability : can't comment on that, I never write tests for stuff that depends on an external resource (like an HTTP API).
&gt; Testability : can't comment on that, I never write tests for stuff that depends on an external resource (like an HTTP API). So this is something that raises red flags for me. You don't test how your code responds to HTTP requests it makes? Why not? What if that HTTP request was part of a library abstracting a particular RESTful service like Amazon's Dynamo or Google's Datastore? Surely you'd want to be sure that it is building the request properly and handling responses sanely. You can't achieve this without testing. This is where spray-client really shines for me in my projects. It's just a pipeline of functions that can easily be ripped out and replaced for testing and re-use. As a self proclaimed testing Nazi, I appreciate libraries that make it easy for me to compose and mock behaviour like spray-client does. I do agree that the akka system requirement of spray-client is a bummer for a lot of projects, but that is not a problem for me personally.
I can acknowledge that, but in no universe is it sensible to define custom operators like `/?`, `&lt;&lt;?` `&lt;:&lt;` just for your little third party library, regardless of language. I also don't quite see the value in .withHeaders(HttpHeaders.`Cache-Control`(CacheDirectives.`no-cache`)) over something like .withHeaders("Cache-Control" -&gt; "no-cache") but I could at least think of plausible explanations for that.
Yes there's a bit of a culture of DSLs in the Scala ecosystem, it's like when people write an API they can't resist to try to make it look as clean as possible, but it ends up being more harmful than helpful IMO. I remember having the same problems when I started Scala, I could understand the language but not many libraries and docs. But yeah Upio is right too, sometimes these libraries are still very good underneath, don't let it put you off entirely.
Maybe they believe their equity offer is more enticing? A startup entering a $15 trillion dollar industry and you get 0.06% (subject to dilution). Some people might think the lower salary is worth the risk.
Does it integrate with libraries written in Java?
Overall a good article that helped my understanding of variance. I do think the Toaster bit was confusing though. I was thinking the friend had handed me a universal adapter or something. To my knowledge there are no universal toasters, only adapters. This made it confusing to me on first pass. Had to read it twice. I think casual descriptions would have been fine on their own: &gt; cool, whatever, as long as you provide me with a function that will accept my cars, I’m fine And, &gt; What printCarInfo said is that it wants a function returning an AnyRef. Is String an AnyRef? Yes, it is Just my 2c. Thanks for writing this article :)
No, Java libraries cannot be used, unless they are rewritten in Scala.js.
As for `implicit class OptionOption[T]`: &gt;So why not do it this way? Because Scala used to not support implicit classes or value classes, so any attempt of doing it with implicit conversions to `OptionOption` would both be more verbose and induce unnecessary allocations. It was done with strings and arrays do to necessity, but custom classes could use this simpler and more efficient way.
Oh, and look at the new doc, all methods have a non-symbolic alternative. For instance: http://dispatch.databinder.net/HTTP+methods+and+parameters.html
Amazing article. Very well written. Thank you very much.
Play-WS also depends on Akka, even though it is not visible in the API.
It is good to use symbolic names which are well known, such as the mathematical symbols like +, -, *, / (given that you follow the well known semantics of them). But it is problematic to invent your own cryptic symbols like : /, /?, &lt;&lt;, &lt;&lt;&lt; since they are harder to remember and pronounce than English words.
My comment was more meant as a joke, but thanks for the nice reply. On more serious terms: Do you know if there are plans to let Scala.js create more compact code, e.g. by reducing the size of the base library or by generating code that has less dependencies? Currently it looks, that there is only a optimizer working as a kind of "after burner".
I guess Ammonite can help you a little bit: http://lihaoyi.github.io/Ammonite/#Ammonite 
There's a few different libraries, see [scopt](https://github.com/scopt/scopt) for n example.
The challenges are similar to those Java codebases will have: the compiler and the build tool have to understand modules, with the latter also preferably emitting modules. Before Scalac and Sbt start supporting modules, we may end up in in a temporary period, when only non-module libraries work without issues. But since a similar period will happen with regards to Maven and Gradle, it will take time for the new, module-based ecosystem to emerge, and in the meantime, everyone will keep doing things the old way, waiting for new tools. Problems may start happening when projects start dropping support for Java 8 and only module-based library releases become available. If Scala tools won't manage to support until then, Scala programmers will become cut off of a part of Java ecosystem. ScalaJS should be mostly unaffected. The only issue I can imagine is when modules allow for two identically-fully-qualified-named classes to exist – in this case ScalaJS would have to start mangling class names differently, including module names.
I don't agree with scalaj-http characterization. Of course it is synchronous, but wrapping any request in a Future is just a few lines. And simple usage patterns for this lib are... simple.
Do you use ScalaJS for any non-trivial applications ? I love the idea, just wonder how it plays out in reality .
We do: www.openmole.org.
Nest team and Firebase team. 
Thanks!
&gt; My comment was more meant as a joke, but thanks for the nice reply. Oh. That suddenly explains the last sentence of your comment, which made no sense whatsoever to me before :-p &gt; Do you know if there are plans to let Scala.js create more compact code [...]? I would know, since I'm the author and leader of Scala.js. There is not really such a thing as "the base library". With reachability analysis (aka dce), only the parts that are used end up in your .js. The problem is more that Scala's standard library has *a lot* of coupling, which means that touching the collections library tends to transitively depend on many other parts. So what we really want is a less coupled collections library. There are no immediate plans to tackle this as part of the Scala.js development alone. But I keep larger projects such as https://github.com/scala/slip/issues/27 under my radar, obviously, and I will make sure that, should any of that happen, the resulting library will exhibit less coupling so that Scala.js gets leaner as a side effect. In the meantime, we perform small uncoupling tasks of our own when we spot something, such as the recent PR https://github.com/scala-js/scala-js/pull/2020
C is far simpler than Java, and Brainfuck is far simpler than C. I still prefer to use Java and I would imagine a lot of programmers would agree in terms of making something fast. Sure, and Scala decided it valued interop with Java highly, hence the fast adoption. Java being easy and popular only makes it easier to adopt Scala. 
I am very interested. I've been doing scala data processing development in various forms for the past year and a half including machine learning and graph processing. I was immediately interested in TensorFlow and would be thrilled to collaborate on a Scala API.
If I am reading over someone else code, and I need a quick overview of what is happening, and I see custom operators like `/`? `&lt;&lt;?` `&lt;:&lt;`, I usually have no idea what the hell is going on. Its much easier to understand code that says .withHeaders(HttpHeaders.`Cache-Control`(CacheDirectives.`no-cache`)) since its obvious it is adding headers to a request. You can create your own symbol for "withHeaders" but then that is extra redundant documentation, and its an extra symbol that people have to learn because they have no idea what it means originally
The reason for SBT HATE is simple and needs to be Fixed, sooner the better. SBT is a Road Block in way of Scala newbies, specially those of us who never did Maven nor Java. Many of us gave up after reading Scala books for months, after knowing the Language, thats like being back stabbed. So simply put, when we are trying out an hello world example in spray or akka http, we are forced to face an formidable enemy called SBT for unknown reasons, spending days banging head against it; come on man take advice of that indian Scala Genius, lets not force so much Ceremony just for a "Hello world on web" program.
You've correctly identified all the upsides of a build tool with plugins or other support for the work you're doing. I'm completely on board with that. I'd just like to be able to use a build tool other than SBT. I don't like using SBT if I don't have to. Having Maven or Gradle as options would be very useful at my organization. (We have a few Gradle builds, and many very large Maven ones.) Both of those tools could do all that's needed - invoke scalac with the scalajs compiler plugin, set up class paths, etc etc - it's just that no one's wired it up yet.
I think this is essentially right, but the point is that the mere act of _constructing_ a `Future` commits you to resolving it (because a `Future` executes at construction), which isn't true of a `Task`. So I don't think "neither of those is a leak," is quite true, and "there's alternatives to both" kind of misses the point: `Future` introduces the possibility of a leak unnecessarily; `Task` avoids it completely. OTOH, I guess you're actually on point, since `Task` is a superior alternative to `Future`. :-)
Will the TROLL Milyardo Answer that? NO.
I agree with you, and like being able to choose whatever abstracrion I want for asynchronicity (I like scalaz Task better than Future), but it also means that the underlying oibrary is not making use of java nio. This can make a significant performance difference if you're, for example, writing a scrapper.
https://en.wikipedia.org/wiki/Dependency_injection
It's simple - IntelliJ is a very good IDE with particularly good Scala support. You can use the open source community edition with the Scala plugin for free. Lots of people use it and find it very useful, hence the votes.
Scala support in IntelliJ is the reason I jumped ship to IntelliJ a few years ago. 
I've run into this same issue. Luckily, this limit was removed in Scala 2.11, so assuming you're using any release of Scala from the past year or so, you should be fine. (I think the most recent stable version of Scala is 2.11.7.) Here's [a Jira](https://issues.scala-lang.org/browse/SI-7296) about the change.
Scala itself could stay unchanged. The build tools (mainly sbt) must support importing modules and should support creating them. But Scala could use this to split its own base library in (mostly) independent modules. This could lead to Scala.js to generate smaller JavaScript code. But I would't expect this to happen soon, because it's a lot of work. 
At this point in time, I don't have the slightest idea if and how it will affect Scala.js. When the time comes where scalac and sbt developers start thinking about this, I will make sure to be part of the discussions so that we can find something that works well for Scala.js too.
OK, I will mark the next joke clearly with :o) As a rule of thumb: If it doesn't parse, makes no sense or offends you, I probably tried to make a joke... Regarding the base library: There is currently a defacto base, because every reasonable complex script will usually use collections, functions, and some kind of DOM access. What you could do is provide different profiles with very limited dependencies. A programmer could then use only code from a small profile, leading to fewer dependencies. Ideally one could signal this intend using an annotation (e.g. `@profile(pure-js)`) and the compiler (or a plugin) would then enforce this. One suggestion for such profiles 1. pure-js: Works only with pure JavaScript constructs. No dependencies at all. Useful for very small scripts. 2. arrray-based-collections: Works with a very limited subset of the collection library, backed by JavaScript arrays for sequences and classes for maps. Probably provides implicit conversions to the "real" collection library. Useful for wrapper code for JavaScript libraries and for script interfacing with such libraries. 3. scala-base: Dependencies to the Scala base library, without reflection or type tags. Useful for medium sized scripts. 4. full: No limits For the first two profiles it might be useful to generate different code for function objects (no dependency on "Function") and lambdas where possible. And btw: Thanks a lot for Scala.js! I really like this tool!
Understood. But think about this: When one module doesn't depend on the other, the code in the module can't use the code of the other module. Fewer dependencies means less code. And less code means that Scala.js can throw away more code. Or in other words: When Scala introduces modules, it very likely has to restructure its code. Currently nearly everything uses collections and collections bring in a lot of code. With modules you very likely will end with a scenario where nearly everything depends on a subset of the collection library. And this subset is written in a way that needs only very few code. It's not a must to do it this way and I have no indication that someone is currently working on this. But it would make sense to do it this way. With Java 8 you already can generate smaller versions of the JVM (so called ["compact profiles"](http://www.oracle.com/technetwork/java/embedded/resources/tech/compact-profiles-overview-2157132.html)). There is even a tool included in the JDK to create a small JRE according to a given profile: [JRECreate](https://docs.oracle.com/javase/8/embedded/develop-apps-platforms/jrecreate.htm). Modules in Java 9 are intended to support even smaller profiles (see [JEP 220](http://openjdk.java.net/jeps/220)). I would expect Scala to follow this approach more sooner than later. EDIT: Added info about JRECreate tool
https://github.com/lihaoyi/utest
Its really good and i use it for some of my scalajs tests but I miss tagging.
Why not Finagle/Finatra?