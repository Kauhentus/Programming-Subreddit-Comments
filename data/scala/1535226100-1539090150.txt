But i hate go xD
I'm already create a small [library](https://github.com/fsanaulla/scalacheck-generators) that may help with it. 
Dunno, there's been quite a lot recently. I lurk in some of the Scala gitter rooms, and it looks like there's quite a lot of not particularly useful discussions going on there as well.
scalacheck shapeless solves verbosity. as to values being "too wild" - my take is that one of the major value propositions that property testing brings is that you will cover an order of magnitude greater variety of inputs than with fixed input tests. the notion of reigning that range of inputs in (beyond potential performance concerns) seems to run counter to that.
&gt; The sheer complexity of FP decomposed to business rules and usecases is massive. Unless you entered it from a CS background, don't FP programmers just remember what they were like before they went pure FP? I remember, it wasn't long ago I was doing OOP in C#. There is a learning curve, but it isn't much different from the first time you learn OOP concepts, things take time and practice to sink in. In my humble opinion, Scala is no longer a niche language. A lot has to do with Spark as a big data platform, many companies are ridding that bandwagon.
I've explained here how this is different from scalacheck-related library: [https://www.reddit.com/r/scala/comments/9a3xwu/instantiate\_case\_class\_with\_arbitrary\_values\_to/e4tw5hq/](https://www.reddit.com/r/scala/comments/9a3xwu/instantiate_case_class_with_arbitrary_values_to/e4tw5hq/)
We just need to be careful not to throw the baby out with the bathwater. Much of the drama is rooted in technical issues and many of the concerns are legitimate and relevant to the 99.9% of us who are mostly quiet and hidden.
I don't feel it's that big of a problem. Most of the concerns that people have seem to be valid. For example, a library development is halted to wait for Scala 3. They are not trolls like "lol Scala suckssss". Their complaints are insightful to me. &amp;#x200B; What I would like is a sum up about what the complaints are and what the responses are.
Sure. If it stays technical, fine. There’s plenty to discuss about the “Infinity War” talk, for example. But on too many posts like that lately, there are long comment chains that devolve into innuendo, veiled accusations, and general sniping between different camps. A comment will be 90% technical and 10% little digs at the author of the post or the Scala Center or whatever. That then spawns other threads asking about the fighting, where things continue, and the narrative becomes that there are huge rifts in the Scala community, when in reality it’s a rift between a tiny number of prominent devs, and the rest of the ecosystem is doing just fine. (Admittedly, this post is part of that. But hopefully it will be the last one.)
I just downvote anything that isn’t about scala or using scala.
What are your favorite (and probably unknown to many people) tricks of customising IntelliJ to make it better? &amp;#x200B; &amp;#x200B;
The scalafmt plugin with this `.scalafmt.conf` file https://gist.github.com/joshlemer/c50a4b1031a8f48458290e243e0e0159 
Also, it's not really a trick of customising, but a pretty new feature is, you can turn on displaying all implicit conversions/converters/parameters by pressing CTRL + OPTION + `+` (not sure what it is on windows/linux). To turn it off, CTRL + OPTION + `-`
What is the menu name for this shortcut? This is helpful. I gotta try it!
&gt; Much of the drama is rooted in technical issues What are the technical issues?
Things like: * Pure FP versus Unpure FP * Cats versus Scalaz * Scala 2 versus Scala 3 * Scala as Kotlin versus Scalas as Haskell There has unquestionably been a lot of tangible benefits from these arguments for even non-FP programmers. So we just need to be a little cautious that we focus the differences and negativity in a positive direction i.e. creating libraries.
I agree.
If everything have to be based on sources then it gets harder to be biased. But yes, even then (as seen on wikipedia), bias can be present. Maybe having one page with content both parties agree and then two pages each for one party to present their perspective? I think some information is still better than none which leads to people repeatedly asking similar questions, getting almost no useful/factual responses. For example statement "ScalaZ devs were toxic" is quite useless to me, because "toxic" currently some people are using as a synonym to "male" (don't know if in this community, but I have no way of knowing). Unless there are quotes of what people actually said, those statements carry no weight to me. I don't think censorship is going to resolve this - it is supposed to end "drama" in community, improve community, noob-friendly community. Yet I think only result would be "Scala community silences those they disagree with" plastered all over various social media which IMO would not inspire people to try Scala or join reddit Scala community. It would only inspire blog posts about censorship around Scala, discouraging people from using Scala and driving existing people to other communities or even languages.
I don’t think it needs to be censored, or clarified, just denied oxygen until it dies out, knowing the embers are still there and any slight stirring of it will result in another flare up. These are relationship conflicts (from my perspective) and are about as interesting to most people as any relationship conflict. If I go to a party and two different friends who happened to have a bad breakup happen to both show up, the last thing I want anyone doing is asking them “so what’s the real story behind your breakup, I keep hearing different sides”. Both parties will feel compelled to “tell the real story” and everyone else will just feel awkward and want to leave to find another party.
I don't know what all this is about, so can't say if your comparison is accurate, and that is my point. I have no interest in starting using some library (in your comparison dating someone) and later discovering I was banned from every library forum/channel just because I have different opinion on some topic which might not be even related to programming (in your comparison breakup because of vastly different values). At this point I am considering rather continuing in learning Haskell/Eta and put Scala and Scala FP on hold (was considering buying that new Scala FP book), because reactions from this community feels fishy - trying to hide what happened, charged responses to calm polite questions, discouraging discussion, proposals for censorship...
&gt; Yet I think only result would be "Scala community silences those they disagree with" This has been the case for a long time. &gt; would not inspire people to try Scala or join reddit Scala community. Half disagree. This sort of silencing of dissent works for other communities, as you get ideologically aligned people joining despite discriminating against other groups, but you lose out on true inclusivity, which is often a stated goal, but directly in conflict with this. For some people though, a hard political stance makes them _want to_ join. For the record, I'm not advocating for one or the other. I'm neutral on this. &gt; It would only inspire blog posts about censorship around Scala, discouraging people from using Scala and driving existing people to other communities or even languages. Those have popped up too before, and silencing dissenters (Paul Phillips is probably the hands down best example of this happening) has also happened. To take a neutral view, you must take into account those who believe driving certain groups of people away improves a community, with those who believe in ideological inclusivity (not the "we have a bunch of different colors so we're inclusive" kind). I'm unsure whether these two camps can be reconciled.
Oh no, I didn't think of it that way. I merely wanted to contrast the differences between 2 approaches.
It could also be restricted to 1 day/week or one Auto mod thread.
And a lot of it is not, i.e. the scalaz vs cats debacle isn't rooted in anything technical at all.
I'm not a fan of solving problems by forcing them underground. Sunlight is the best disinfectant. We need to solve problems by recognizing they exist and getting to their root. 
&gt; I’m currently working with Java 8+, those saying that Java added FP features don’t know what they are talking about I also worked with Java-8 quite heavily for about 3 years, and helped quite a number of people learn Java 8. Occasionally, I'd hear one of them get excited say "We don't need Scala because we're already writing FP in Java!" I'd usually try to correct them and explain that Lambdas and Streams are only a tiny fraction of what FP has to offer. 
I don't believe trying to keep these things secret helps anyone, so I'll tell my perspective. It will be incomplete and one-sided, and the order in which I encountered things is not necessarily the order they happened or came to prominence in, but hopefully it'll give you some idea. * The dim and distant past * I first hear about Scala as an interesting new language from Martin Odersky, the creator of Generics Java (and, therefore, the author of the Java 1.5 compiler). Apparently, Generics Java had reached the limits of what it was possible to to do in a language that stuck to being a superset of Java. * Lift reaches some prominence as the first vaguely mainstream native-to-Scala web framework. It follows a different design from most contemporary frameworks (and enforces this quite strictly) and makes heavy use of symbolic operators. Its founder, David Pollak, is outspoken and unsympathetic to those who disagree or have difficulty learning ("Yes Virginia, Scala is Hard" is a much later talk but gives an idea of his general ethos); many dislike this attitude, but Lift is, for now, the only game in town. * ScalaZ is created at some point by Tony Morris (I don't encounter it until later). It offers many useful general-purpose operations (apparently largely taken from Haskell), to the point where some see it as a "second standard library" (a la guava); it also gains some notoriety for heavy use of symbolic names, refusal to include documentation (except for type signatures), and a communication style that ranges from nonconstructive (e.g. Morris' explanation of the removed `Pointed` typeclass on the scalaz website consists of several lines about how it was a bad idea but no explanation of what it was) to downright abusive (I believe the Morris' "Kevin's tanties" post to the Scala mailing list, and consequent banning from said mailing list, happened in this era). Since the library is very general and foundational, other libraries begin to depend on it, and even those who dislike the library and/or its community often end up with it on their classpath. * Scala already seems to be becoming a magnet for criticism. Much of this focuses on overuse of symbols (in Lift, ScalaZ, and also Dispatch, which is the only native-to-Scala http client library), an arrogant "this is the right way to do it" attitude, and a community that's unwelcoming to newcomers. Steve Yegge dismisses the language; Rod Johnson (Spring creator) gives a meandering but negative take. Various rants go viral; "Scala – 1 Star – Would Not Program Again" is from slightly later but gives a good idea of the reception Scala is often getting. There's criticism from inside the community as well: Chris Marshall posts a pointed Stack Overflow question about the major, compatibility-breaking rewrite of the collections library in Scala 2.8, titled "Is the Scala 2.8 collections library a case of “the longest suicide note in history”?". * The incident * Scala continues to grow. Alternatives to Lift and Dispatch emerge; ScalaZ remains the only mainstream option for a lot of important functionality. While ScalaZ 7 makes small steps towards alphabetical rather than symbolic names, its community remains unpleasant and many people are unhappy. See [this archived post](https://www.reddit.com/r/scala/comments/4x4wa9/is_it_a_shame_to_use_scalaz/) for various people's takes including mine. * Typelevel is formed (I don't know exactly by who, but Miles Sabin and Lars Hupel are the most prominent) as an umbrella organisation for foundational libraries, initially including Shapeless and Spire. (Morris has subsequently claimed that this is a fabrication, but refuses to substantiate his claims and goes on irrelevant tangents when asked to elaborate. This is not unusual for Morris). Typelevel adopts a code of conduct at a time when this is a controversial subject; this particular code of conduct also attracts criticism for some very unclear wording. * At some point Sabin sends a message to Morris asking him to step down from ScalaZ and dissociate himself from the project for the sake of the community, with the final phrase along the lines of "if you refuse I will pursue other plans that are already in place". In the light of subsequent intents, some interpret this as a threat to have Morris removed as maintainer of ScalaZ; Sabin claims he was only talking about setting up Cats. * Hupel announces that ScalaZ has a code of conduct, is part of Typelevel, and that Morris has been banned for violating the code of conduct. Morris is visibly banned from the IRC channel. The code of conduct is rather unclear. Hupel (and subsequently Sabin) gives several contradictory explanations as to what has just happened: first that Morris had obviously violated the code in a linked IRC log (there was no such obvious violation; the code as written only seemed to be about discrimination rather than general unpleasantness), then that he'd violated the code elsewhere (no details given), or that he'd refused to agree to the code and so been pre-emptively banned, or that his ban was nothing to do with the code of conduct. * Many ScalaZ channel members express confusion and concern about this unclear code, and press Hupel for details. Hupel disconnects for a month or so, claiming this is necessary for his mental wellbeing. Morris sets up an alternative IRC channel and a fork of the project (scalazeta); the fork README makes vigorous statements about "restoring the original goals" of the ScalaZ project, while providing no details of what those goals are (Morris goes on irrelevant tangents when asked to elaborate), but is widely understood to be a reaction to previous events. * A few months later Morris is back in ScalaZ, ScalaZ is not part of Typelevel, and *no-one is saying anything about what happened*. Cats exists as a Typelevel project with a code of conduct offering much the same kind of functionality as ScalaZ; it's widely seen as a less-complete knockoff, though sometimes with better documentation. * Aftermath and other controversies * Several prominent libraries migrate to Cats; some use libraries or code generation to build against both ScalaZ and Cats. For a while ScalaZ development appears stalled; on the other hand ScalaZ is reasonably complete and still offers some things that Cats is missing. Typelevel discussion tends to happen on Gitter under a (still unclearly worded) code of conduct; Scala proper switches to do the same at some point. * Odersky announces Dotty, a... new language? Playground for prototyping some features for future Scala? Messaging is unclear and many fear that this will distract Odersky from work on Scala proper. Typesafe renames itself to Lightbend and puts out a roadmap for Scala that seems very focused on Java interop, with effectively a 4-year or more moratorium on new features (Scala 2.12 will be 100% source compatible with (non-experimental) Scala 2.11, containing only Java 8 compatibility changes and internal improvements). Many functional-first programmers are unhappy. Typelevel creates a fork of the compiler offering new features that much of the functional/pure community considers important (singleton types, better type lambdas, better partial unification, better desugaring of `for`/`yield`). * Paul Phillips quits work on the Scala compiler, attacks the collections library in particular, creates his own alternative collections library. * The typelevel compiler fork mysteriously disappears/is rebooted as a place for incubating PRs onto official Scala. Sabin's implementations of several substantial functional-focused features (in particular, partial unification) are accepted into mainline Scala, contrary to the previously announced roadmap which has also mysteriously vanished. * Odersky puts out an RFP for a compatibility-breaking rewrite of Scala collections. While there's a lot of initial interest, it becomes clear that the backwards-compatibility constraints in the RFP prevent resolving most of the issues that functional/purist programmers had (including many of Phillips' criticisms). In the end the lightbend "strawman" proposal is the only complete one that meets their compatibility requirements, and is expected to form part of 2.13. It's widely seen as an incremental improvement over current Scala collections, but there are concerns that it represents too little progress compared to the scale of the issues, and that a source compatibility break is too big a cost for the relatively small benefits that will actually be delivered. * Lightbend announces that Dotty will become Scala 3. While most like the design of Dotty there is a lot of concern about compatibility with existing Scala, and about Scala 2 getting adequate maintenance and investment in between now and whenever Scala 3 is released. I think that's most of the things that people hint at and don't talk about; there are plenty of other controversies around e.g. macros but I think they tend to take place more in the open?
Have a look at the bans on Gitter, the various tickets in the bugtracker that look like a reenactment of Fahrenheit 451, or the policing of random people's YouTube comments: One thing that's certain is that cracking down hard on dissent and unapproved opinions hasn't helped in shutting people up.
Btw, that new book is free. Treat yourself ;-)
Oh, I know the e-book version is, but I like physical books and also would like to pay for it, so I am waiting for the physical version. I felt a bit bad downloading it for free and reading few pages. I know how time-consuming writing is (theoretical part of a thesis took me so much time - endless polishing). Your nick seems familiar, aren't you the author? :D
Even in the early days of cats, scalaz was more monolithic -- which is not a bad thing in itself.
But nobody's is creating drama because one is more or less monolithic than the other.
There were some details that were left out here concerning how interactions played out between Typelevel and Scalaz that were incredibly concerning, and inform the strength of the conflict. There are [emails](https://twitter.com/larsr_h/status/921244624555008001) that show that [Lars' ultimatum](https://gist.github.com/ekmett/81a507f50d857345691c) was continued with Lars messaging Tony's place of work twice, urging them to terminate his employment over Tony's response to Lars' theft of Scalaz (the emails are readily available through different avenues). Lars had effectively removed all maintainers from Scalaz with the exception of his friends, and a few choice folks like Paul Chiusano and Runar Bjarnason, and effectively "taken" Scalaz, folding it into Typelevel without communicating it to the core maintainership (those whom he banned). It was only later, that he was [convinced by a few of those that were left](https://groups.google.com/forum/#!msg/scalaz/9X_putSGoCY/FIyeN0KVun0J) to continue with a fork and call it something else, stepping down from Scalaz. Since that time, there have been verbal fights between Scalaz and Typelevel sympathizers over this conflict, culminating over the last few years, culminating in events such as [supporting](https://i.imgur.com/WQyB84E.png) people calling for [Do Not Hire](https://i.imgur.com/ou1sNsH.png) lists. Typelevel leader Stew recently stepped down because he didn't want to give up [the privilege](https://i.imgur.com/vvfNmRH.png) of actively conflating Scalaz members with racists/neo-nazis. [Vitriol like that](https://i.imgur.com/rOtFjnE.png) extended even to Scala contributors like Scalaz's Kenji, and there was an active [strain of denialism](https://i.imgur.com/v5Iqn3O.png) among Typelevel and Scala folks as this was going on that lent to escalating the conflict over time. **Thankfully, we seem to have come to a relatively good place recently, and this information not meant to support any side of the argument, but to completely inform the reader of the strength of the conflict. I'm glad we could work things out eventually, and our mutual corners seem to have de-escalated with a few choice members of TL leaving. More power to them if they wish to cry "Nazi!!" into the night, but those of us who want to continue in a mature manner seem to have been successful in that regard.**
This is the only scala kernel for jupyter I actually managed to get going. Forever grateful to the author! 
&gt; Unless there are quotes of what people actually said, those statements carry no weight to me. Are you surprised a bunch of technical people don't want to go thru the Twitter, Gitter and Scala forums archives to find enough negativity to satisfy the latest "Why are some people mad?" thread? You got a lot of thoughtful responses from people in your thread. There's a lot of thoughtful video critiques of Scala. There's blog posts about warts. There's work towards solutions. There's a lot of technical info out there. People don't feel like relitigating the interpersonal conflicts that emerged from that. Can you blame them? Recently, Python's most prominent library author had a riff so big that he created a new python sub reddit and attacked the original community. Guido had debates supposedly so intense that he stepped away from the language he created. Go gets attacked weekly about it's error handling and generics. All this stuff happens in communities all the time. If I walked into any of those communities asking for these political details, I'd get the same response you did - for good and for bad. So I read some blogs and PRs, watched some videos, and made my decision. Use Scala. Use Haskell. Use Python. Use Go. Use them simultaneously. Don't use any of em. It'll be fine. Good luck with whatever your true intentions are. If you have any *technical* questions or critiques of Scala - feel free to ask!
Just wanted to say: this is a really great write up! It across with how I seen it happening. There are some things missing but I believe we should record everything, not be silent, because silence is simply not satisfactory for the intellectually curious.
It took me so much time to write it you honestly couldn't pay me enough to make it financially rewarding, so just take it for free unless you really want to say thanks with cash :-D I wrote this book because I wanted to read it, not to make money.
Just wanted to say, I've started reading your book and it's been great. So, thanks for that. 
&gt; this information not meant to support any side of the argument, but to completely inform the reader of the strength of the conflict. I find that thoroughly implausible. You've linked to bad behaviour exclusively on one side, your descriptions of your screenshots are clearly slanted ("actively conflating" as opposed to what? Passively conflating?). I saw Morris using far more aggressive language than what you're calling "vitriol" when Odersky does it, multiple times a week; if you spent any time at all involved with ScalaZ then I refuse to believe you didn't. I'm not going to defend Typelevel here, and you're entitled to present your side, but let's not pretend you're giving a neutral summary.
Provide me with screenshots and I'll add them to the post! I'd be happy to. I simply don't have any. You've mentioned "Kevin's Tanties", so I assumed to some extent that you had shown examples of Tony's behavior in the past, and that was sufficient to some degree, but if you'd like to add more, by all means, send it my way.
I don't care. Short of his explicitly consenting beforehand that email was super not ok and I do not want to be associated with a project in which that kind of communication happens, regardless of the ultimate outcome.
I'm not interested in dredging up all the bad behaviour that's happened in the past and comparing archives of screenshots. I thought we were trying not to have the whole argument again. I mentioned a few longer pieces of writing I was aware of (and thanks for finding Hupel's ultimatum, I do think that's a useful piece of context), but I don't think screenshots of tweets or IRC are useful. Even if you're only posting screenshots you have and not posting ones you don't have, the editorialised descriptions you've given in your links are a long way away from neutral. That's not a question of what facts you do and don't have, that's a very strong slant coming straight from you.
&gt;I don't think screenshots of tweets or IRC are useful. I think they inform exactly why certain events took place, and why things escalated to where they did. Without it, many are still left wondering why things got so bad. This at least helps people see where things were, like museum exhibits. &gt;editorialised descriptions you've given in your links are a long way away from neutral If you have specific suggestions, I'll amend the post. Otherwise, I don't think I went as far as, say, &gt;Morris has subsequently claimed that this is a fabrication, but refuses to substantiate his claims and goes on irrelevant tangents when asked to elaborate. This is not unusual for Morris But they called things what they were - Martin was taking out some personal stuff on Kenji, Tony was abusive, Stew was abusive. Heather was abusive. It is what it is. If you would like me to word it a specific way, I'm amenable. But like I said in my subsequent posts to your responses, I honestly can't find a way to spin this as anything other than "Tony vs. Scala + TL". The other Scalaz maintainers really don't participate much in this fight, other than Sam, who was very angry when Stew was accusing him of FUD. 
Don't be offended for people in the past. If they had a mode of interaction which didn't lend itself to feelings being hurt, then leave it at that. 
We're talking about a message from the project leader to the project's primary mailing list (indeed I believe Morris went out of his way to reply to what had previously been a private response on the main mailing list). That absolutely represents the project. I do take it as what it was, but I simply don't believe it was intended innocently, whether it struck home or not.
&gt; Do your friends hold you to things that happened 10 years ago? For some things, yes. &gt; Maybe he was dealing with health issues, did you ever factor that? Maybe the people he was attacking (the vast majority of whom none of us here will ever know, because Morris drove them away from the community before we got to know them) were dealing with their own issues, did you ever factor that? People tried to help Morris learn to present his views more constructively, and encouraged him to step away from a newcomer-facing position if he wasn't able to improve his behaviour. He refused to do either. At some point a person is doing enough damage that it's incumbent on a decent community to stop them. &gt; If you want to present the facts as you find them, and not mix it with emotion, please add references to all claims of toxicity. It is appreciated by everybody who reads your version of events. This kind of response is exactly why no-one wants to talk about these issues. I don't have the time or frankly the emotional fortitude to revisit the things Morris said to me, and even if I were to post my IRC logs I have no way of proving their authenticity. I've given my perspective; I know what I saw. You're welcome to believe me or not.
&gt; Please keep the personal attacks to yourself. If you see this as a personal attack, I apologise. I merely meant to point out that you guys (and gals) tend to employ a rather confrontational communication style, from time to time. Or at least that is my impression from following discussions here, on GitHub and Discourse. Then I'm not sure if you should hold other people to a higher standard.
I would definitely put Magit up against IntelliJ's VCS any day. 
I don't understand - you want to take an expensive course twice and then do some tutorials? 
$11,000??? How about buy the red book (Functional Programming in Scala) and one of the Programming Scala books on the right?
This absolutely works. Thank you!
my .02 is do FP for mortals or advanced scala with cats first. both take a more practical approach and at least for my learning style got me going faster than the red book. red book is a bit more abstract and a bit more steeped in theory, and could make a better 2nd book if you haven't gone through those others yet.
If you have access to ModelA and ModelB , you can store a link to modelBRepo. If this is an `object` you can pass it using `.type` otherwise you can implement a parent class for both Repos. 
The compiler will not find the implicit in the trait because of the lookup rules. The compiler will look for implicits that are defined in scope, then look for imported implicits, then look in companion objects (and its supertypes), then follow the same pattern for any arguments of the method, then for any type parameters of the method. At no point does it look in the definition of the trait. See [this SO post](https://stackoverflow.com/questions/5598085/where-does-scala-look-for-implicits) for a more thorough answer. You also wouldn't want the implicit in the definition of the trait in this case because it will create once instance for everything which inherits from the trait rather than one instance total in the companion object.
I second this - reading the [Scala with Cats](https://underscore.io/books/scala-with-cats/) while practicing and reading other resources (like the [Neophyte guide to Scala](https://danielwestheide.com/scala/neophytes.html)) is probably more productive if you want quick returns.
Tbh I like the red book and am not looking for quick returns - I was just wondering if anyone had any general advice on absorbing the information more quickly. It's a difficult book, which I get, but I am very impatient. For example, MIT's lectures complement the SICP textbook quite well. That is kind of what I'm looking for. The FP in scala has a chapter based wiki, but it offers( from what i've seen) tangential information that is only so relevant to the chapter. 
How well did you absorb the information? I always feel guilty about looking at the solution(even after struggling for 50 min +)
By now, pretty well I'd say. Sometimes I'd have to look over something a few times to really get into it, but working through examples as thoroughly as possible was enough for me to at least feel comfortable moving on to the next section when it was time. If something was used again (i.e State or Stream) I'd look back at its implementation if I didn't feel like I totally understood it, and if I was really lost I'd read that part of the chapter again. For me, that was enough to grasp the principles of each chapter and be comfortable with implementing related code.
https://projects.spring.io/spring-data-jpa/ Why reinvent the wheel?
I think an easy way would be to just have a def repository in your trait. Then model a and model b implement the repository then you would not have to do special logic per model in the base class
You could also start taking the coursera course: [Functional Programming Principles in Scala](https://www.coursera.org/learn/progfun1). This maybe a good way to put the skills you're learning into practice.
&gt; its impact on application size and performance It's pretty much guaranteed to be more performant than spending three months writing your own dumb framework from scratch.
You can do something like this: trait ModelRepo[M &lt;: GenericModel] { def checkUnique(model: M): Boolean def insert(model: M): Option[M] } And then have your generic helper defs take an implicit repo that matches the model: def insert[M &lt;: GenericModel](model: M)(implicit modelRepo: ModelRepo[M]): Option[M] = modelRepo.insert(model) def checkUnique[M &lt;: GenericModel](model: M)(implicit modelRepo: ModelRepo[M]): Boolean = modelRepo.checkUnique(model) Your `ModelRepo` instances should be instantiated as a part of your application bootstrap if you need them to be dynamic, or could be members of an `object ModelRepo` companion object if they can be static. If the only thing that differs between the ModelRepo instances is stuff like name and such you can keep most of the implementation in the trait and add an extra `def name` member to fill in the blanks.
You don't need to read this book to find a Scala job.
Personally I find there's no substitute for doing; particularly if we're talking about an expensive course I would see how far you can get on your own and where you get stuck. But you presumably know how you learn best. 
I would write some non trivial Scala. I’m not sure the book puts together the sort of real production style code you might really be writing because it’s so focused on teaching you things.
[https://leanpub.com/fpmortals](https://leanpub.com/fpmortals) explicitly lists the Red Book as follow up material, so it's definitely recommended to do it in this order.
within the next few months.
I never went out of my way to implement the examples tbh. I always skimmed through the readings and examples in excitement to do the exercises. I"ll try that too. 
This might be a dumb question and may betray a lack of understanding, but what is the idiomatic way of specifying operations should (or could) be run in parallel when writing in a tagless final style? For example, if I have List[F[String]] and I want to convert it to F[List[String]], how can I specify this to happen in parallel? I've tried to use the .sequence on the Traversable on the using the Applicative on F, but it happens sequentially when my effect type is a Monix Task or Cats Effect IO. I've read Task.gather can do this, but I don't want to "pollute" my core program with knowledge of the effect type and would rather keep that as far to the edge as possible. 
Thanks a lot! That explains it =D I was sure it couldn't be as bad as I thought.
I don't understand how implementing a functional programming library yourself, as opposed to just using one can be considered "steeped in theory". If the Red Book is just too theoretical for you, I don't know if you have much hope is ever doing much practical with the libraries. That isn't to say there isn't a role for both kinds of books, or that a books focused on usage of scalaz and cats isn't useful. I'm just confounded on how anything in the Red Book could be considered theory in any way.
I hated that course. Sorry!
Well I guess I should give up hope of doing anything practical with the libraries then. Shit my boss is gonna want his money back
Hi. I have created a small course for learning basic functional programming ideas in scala - [https://github.com/dehun/learn-fp](https://github.com/dehun/learn-fp) It's learn-by-doing course - you have to implement functors, applicatives and monads from scratch and pass all unit tests. This would be probably an additional resource that will help you to look at the problem from different angle.
That would certainly be easier than admitting you've made a poor description of something.
You can use the `Parallel` class from cats like so: import cats.Parallel import cats.implicits._ def apply[F[_]](repo: DataRepo[F])(implicit P: Parallel[F, F]): Service[F] = new Service[F] { def process(list: List[F[String]]): F[List[String]] = { Parallel.parSequence[List, F, F, String](list) } }
May be I should have worded my original post more carefully. I meant a "mainstream" Scala OSS project. 
Twitter has very good projects which are usually well documented, for example, see [Finatra](https://github.com/twitter/finatra/blob/develop/CONTRIBUTING.md).
[Http4s](https://github.com/http4s/http4s/issues?q=is%3Aopen+is%3Aissue+label%3A%22good+first+issue%22) has few labelled issues that might be good starting point. [Frameless](https://github.com/typelevel/frameless/issues/164) has a lot of straightforward issues and it's a solid way to polish/learn Spark and Shapeless stuff. In my opinion even just asking on gitter might give you a good direction. It is probably harder to start contributing to more mature projects because they usually either don't have a lot of work planned or it's too advanced. Nonetheless, good first issues happen from time to time so if you really like specific project I recommend to track what's going on and something will come up eventually. :) Also, have in mind that giving feedback, writing blog posts, documentation, doing workshops, helping out other users on gitter etc. are all great ways to contribute.
I've tried to provide something like this for the Scala organization (which includes the compiler, standard library, language spec, websites, modules, and so on) in my “You Are a Scala Contributor” talk. Video and slides here: [https://na.scaladays.org/schedule/you-are-a-scala-contributor](https://na.scaladays.org/schedule/you-are-a-scala-contributor)
Because Java. [Learning Scala](https://reactdom.com/scala) shows you how much java has fallen behind and how those concerns can be addressed.
Akka question. A have a bunch of workers which pulls job from master by sending JobRequest message. How should I initialize workers, so they start pulling job. How to ensure they keep pulling jobs after failure?
We should make one!
&gt; How should I initialize workers, so they start pulling job You can try overriding `preStart` to send the first `JobRequest`. Or you can send a special `Start` message. &gt; How to ensure they keep pulling jobs after failure? If your failure handling is to let the actor die and be restarted by its supervisor, overriding `preStart` may be sufficient. If the actor stays alive then presumably at some point it knows that the job has failed, e.g. a `JobFailed` message, and you can send a new `JobRequest` during the handling of that message.
But it feels bad. We can’t just give up and let a few people move mountains. There has to be a way.... 
If you're going to direct people there would you be ok with locking the thread after a couple of weeks? I hope what I wrote is useful and am happy to let current discussion play out, but I'd rather not be getting more replies weeks and months into the future. 
Yep!
Yeah I usually don't implement the example right away, I keep reading and see how relevant they end up being. Some of them are necessary implementation details of whatever you're learning, some of them are basically asking "what if...". Depends.
I'm afraid if one is even considering the red book, it's already too late for the course: it only goes far enough to mention the higher-order function and present collections. If my memory serves me well, that's covered before the end of Chapter 3. That's not to say the course is not useful; but it's not exactly the same league.
Trying to make Ammonite docs site faster and prettier :D, see https://github.com/lihaoyi/Ammonite/pull/854
I've done this sort of thing before using something my coworkers and I called "double dispatch": trait DAO { def checkUnique(ma: ModelA): Boolean def checkUnique(mb: ModelB): Boolean def insert(ma: ModelA): Option[ModelA] def insert(mb: ModelB): Option[ModelB] } trait GenericModel[M &lt;: GenericModel[M]] { def checkUnique(dao: DAO): Boolean def insert(dao: DAO): Option[M] } class ModelA extends GenericModel[ModelA] { override def checkUnique(dao: DAO): Boolean = dao.checkUnique(this) override def insert(dao: DAO): Option[ModelA] = dao.insert(this) } class ModelB extends GenericModel[ModelB] { override def checkUnique(dao: DAO): Boolean = dao.checkUnique(this) override def insert(dao: DAO): Option[ModelB] = dao.insert(this) } Note that I haven't compiled this, I just sketched it out. The downside is that it's hard to factor out the implementations of `checkUnique` and `insert` in `ModelA` and `ModelB`. The repetition is minimized, though. This avoids pattern matching on `GenericModels`, but that feels like 6-and-half-dozen.
True. But sometimes just hearing a different voice of the same ideas could help comprehend and retain the material.
Looks cool! I'll take a look. 
At Http4s specifically, [we had a solid week with a snowball of new contributors](https://github.com/http4s/http4s/issues/1890) due to some labelled issues like this. That said, you don't _have_ to contribute upstream to OSS you don't use, that's just silly. But once you use a library and stumble upon an issue you want to fix, or an enhancement you want to contribute (If the library is open to contributors, some aren't and that's fine too), all you have to do is trace how exactly it is that your use of the library functions by reading source.
I looked at this book and it looks well written but I'm the type of person who needs exercises otherwise I don't get past a few chapters...
trying to get Scala 2.13.0-M5 out the door. we're very nearly there. details at [https://contributors.scala-lang.org/t/2-13-0-m5-release-train/2125/18](https://contributors.scala-lang.org/t/2-13-0-m5-release-train/2125/18)
i started by implementing every excise under one project, companion with [lihaoyi's utest](https://github.com/lihaoyi/utest), which gives me instant feedback. Scala has quite a few unit test frameworks that one can choose from, the point is instant feedback of unit test makes the excises pleasant and rewarding, WARNING, after a few days it can even get addicted to FP ;-)
What was the design choice behind not allowing temporary variables in the constructor of classes? &amp;#x200B; I understand a few ways around it, but for me it still seems like it would be a lot easier to have temporary variables in the constructor then have to create workarounds.
I'm just guessing here, but how would one decide, if something is to be temporary or belongs to the class? Either it would need special rules (like a new keyword) or existing rules would have to be changed. I think both is more troublesome than the alternatives like factory methods in companion object (which is a good way to do it anyways) or local scopes as in `val someting = {val temporary1 = ???; val temporary2 = ???; temporary1 + temporary2 }` &amp;#x200B; &amp;#x200B;
But why was it chosen to not have a keyword in the first place? Like: `temp val x = ...` Local scopes just make it slightly less readable and factory methods seem to just be adding verbosity (obviously there are real use-cases for factory methods but I don't think this should be one)
I can't speak for the contributers at that time, but at least for me, a new keyword (which is not a minor thing) is not even close worth the benefits. Why would factory methods add verbosity? If your class is so complex, that you need a lot of stuff to initialise it, then using a factory method and just providing the needed dependencies to the class constructor is the way to go anyways. Well, maybe it's me, because I rarely had this problem, but right now I cannot really think of a case where I would like to have a way to define such temporary variables. Maybe you like to give an example to make it more clear?
I hope you find the book you're looking for, you're not the target audience.
Sure - I'm writing this off-the-top of my head so the syntax could be slightly wrong: ``` class Foo(size: Int) { var listBuffer = new ListBuffer[String]() for (i = 0 to size) listBuffer += "Test" val list = listBuffer.toList() } ``` I want `listBuffer` to be the temporary variable in this case
Thanks! So, in this specific case, I tend to say that this is not a good design anyways. Imagine, someone wants to create a \`Foo\` not from an \`Int\` but different number type. Or someone has a listbuffer or even a list already. The class \`Foo\` contains a list that decribes the data that is important to \`Foo\` and the size is just some property that is completely dependent on \`Foo\`s data. As there is no state in \`Foo\` either, my design for \`Foo\` would look like that: ​ case class Foo(list: List\[String\]) { val size = list.size } object Foo { def bySize(size: Int) = ??? } &amp;#x200B; If \`Foo\` contains state, It would not be a case class, of course. &amp;#x200B; All in all, it is more verbose, yes, but on the other hand, it forces a design that makes a lot of things clear, such as that \`Foo\` really contains a list of strings - how has it been created? we don't care about that - it could change any time. Do you agree?
&gt; You can reuse typeclasses like Applicative with stdlib Future, and have the typeclass instance carry the ExecutionContext Yeah, except these instances are unsound, because of side-effects on every method of Future.
I apologies that was not my intention. I think the question was how to start contributing to the bigger projects like SBT or ScalaZ.
What side effects? If you consider forking a thread to be a side effect then `Task`/`IO`/... are also unsound (`apply2` may fork more than the `flatMap` construct it's supposed to be equivalent to). If not, `map` and `flatMap` on stdlib `Future` are perfectly legitimate. 
I'd challenge that 'never will be'. Even an effect system has been under consideration for some time now, never mind other FP improvements in dotty and 2.12.
&gt; 1. code gen. 2. class gen. 3. runtime bytecode manipulation. Oh, you mean a custom slow, bug-ridden, informally specified emulation of half of Scala macros? &gt; There's a ton of other options available asides from macro's that could be seen as macro-like. Sure. In fact macros are inherently the wrong thing to do for the language, as it should strive to make more of its entities first-class until one doesn't have to stoop down to direct AST manipulation to express something non-trivial. But at least they're powerful, and way safer and more visible than bytecode generation.
&gt; When we introduce a type parameter into an ADT, we call it a Generalised Algebraic Data Type (GADT). &gt; scalaz.IList, a safe alternative to the stdlib List, is a GADT LMFAO
[https://github.com/scalacenter/sprees](https://github.com/scalacenter/sprees)
I was also learning Scala for the first time when I started. Honestly reading the text and following the examples helped me a lot with the syntax. There are some things they're just going to gloss over though, so I don't think looking at the answers in cases like you described is cheating at all. 
You only made this information available after I told you about the book. This is how conversations work: I'm not a mind reader! Also, you're welcome to your money back, just click the refund button.
for scalaz, just read fpmortals ;-)
&gt; They do nothing but build an AST. Sure, but if two statements that should be equivalent according to the monad/applicative laws build inequivalent ASTs then that's a violation of the laws. &gt; Future does side effects on map, flatMap, etc. Even the trivial equality a.map(b) == a.map(b) doesn't hold, since different effects are executed by the same statements. `a.map(b)` is always equivalent to `a.map(b)`, what would it even mean for it not to be? It is true that if you consider forking a thread to be a side effect then some important equivalences don't hold (e.g. `a.map(identity)` is no longer equivalent to `a`) - but as I've said, if you're that strict about it then `Task`/`IO`/... are also unlawful. It's also true that if `b` isn't referentially transparent then `Future#map(b)` is not referentially transparent either, but that's perfectly normal and true for plenty of perfectly legitimate monads e.g. `Option`.
Scala and its community are wonderful. Super excited about Scala 3. &amp;#x200B; See it happens in other programming language communities too: [https://www.reddit.com/r/haskell/comments/9awvvw/what\_happened\_to\_bryan\_osullivan\_don\_stewart/](https://www.reddit.com/r/haskell/comments/9awvvw/what_happened_to_bryan_osullivan_don_stewart/) &amp;#x200B;
I tuink the first resource is your company code. You cannot bring your rules to the established team, better start off with their recommended reads.
Pontica Solutions| Scala Developer |Sofia, Bulgaria | ONSITE | Full Time| Relocation Our client is a leading all-in-one email service provider that not only enables customers to send transactional and marketing email to their contacts, but also better understand them, email after email. The intuitive tools deliver results for both marketing and technology-focused emailers as they give senders the right amount of analytics to get the most value from each campaign and to reach each inbox. They are now looking for a skilled Java/Scala Developer to join their growing team. **YOUR ROLE:** * Participate in the core development and work with cutting-edge technology. * Maintain good test coverage of existing and developing features. * Develop high-volume, low-latency applications for mission-critical systems and delivering high-availability and performance. * Collaborate with other developers to design and optimize code. * Investigate bugs and determine appropriate fixes. * Collaborate and provide technical assistance to others. * Carrying out the code review and validating the compliance with the standards and best practices of the company. * Implementing the principles of continuous integration and maintaining them. **REQUIRED SKILLS:** * 2+ years of experience in Java/Scala programming and common Java/ JEE frameworks. * A significant advantage will be: – experience with scalable Databases (PostgreSQL, Cassandra); – experience with queuing technologies (Kafka); – working with SCRUM methodology; – developing, debugging, testing and deploying cloud solutions. * Excellent knowledge of English (French will be considered an advantage). * Ready to move to new technology architectures. * Leadership potential would be a plus since the position could evolve towards management. **WHAT WE OFFER:** * An attractive remuneration. * Exclusive discounts &amp; offers. * Additional health insurance and other social benefits. * Constant trainings and extensive performance improvement programs. * Great opportunities for career development. * Excellent business environment and a friendly atmosphere. * Open-minded management team promoting innovation, personal and professional development. * Work with an amazing and diverse team from around the globe. * Employee referral bonuses. * Fixed-working hours (10:00-19:00). * Permanent employment; full-time. * Employer: Pontica Solutions Ltd. CONTACTS: [work@ponticasolutions.com](mailto:work@ponticasolutions.com) or [k.atanasova@ponticasolutions.com](mailto:k.atanasova@ponticasolutions.com) 
&gt; Sure, but if two expressions that should be equivalent according to the monad/applicative laws evaluate to inequivalent ASTs then that's a violation of the laws. (And if your AST representation doesn't include any semantics about when forking happens then it might as well just be Eval). They evaluate to equivalent ASTs. They interpret to inequivalent effects, but that's **fine**. At the time *when you compose them*, before they're run, you can rely on their composition making sense and adhering to all the laws. When you run them they've already been composed, hence these properties do not apply. &gt; a.map(b) is always equivalent to a.map(b), what would it even mean for it not to be? Second `.map` will come with different side-effects, it may have exhausted the threadpool for example, which makes the two inequivalent. &gt; if you're that strict about it then Task/IO/... are also unlawful. The entire point of having these types is that they're not. *At the moment of composition* all the equivalences hold. &gt; It's also true that if b isn't referentially transparent then Future#map(b) is not referentially transparent either, Future.map is never referentially transparent irregardless of `b` due to submitting tasks. All I'm trying to say is that it does make sense (it's obviously useful) to compose descriptions of effects – and that these compositions are sound. Running effects such as Future do not compose however, their methods match the signatures, but not a single equivalence holds. It's not as useful to compose them as it seems, because you can't rely on any of the inherent properties or laws of Monad/Applicative, it becomes nothing more than a lawless interface. In one codebase I looked at, I've seen pseudo-tagless-final code, where on surface it was parameterized by `M: Monad` – but implementation completely relied on the fact that (lawless) Monad instance for Future in `scalaz` was implementing `.pure` with `Future.apply` – i.e. it spawned new tasks. I think you should agree that this (and the scalaz Monad instance for Future) is beyond awful.
https://www.reddit.com/r/scala/comments/8ktqkf/signup_form_to_become_a_mentored_contributor_to/
Thanks to everyone who responded to this thread. Sorry if I gave the impression that I was trolling. I was not looking for open source projects to contribute to. I already have a long list of projects to which I want to contribute to. The problem is that despite good intentions I can't contribute to those projects. So here is a proposal. Is it possible that every major Scala open source project say (SBT, Cats, Http4s etc) do a yearly 1 hour new-hire orientation event. This can be advertised via twitter and reddit and recorded and published on youtube for future viewing. I always feel that using CATs vs contributing to CATs is two very different things. this 1 hour event should be dedicated to providing the minimum information needed by someone to start contributing to CATs. (mind you that CATs is just an example here). I think Seth did a talk already on the Scala compiler (thanks for posting that here). I guess we need something similar for other big libraries like SBT, Cats, ScalaZ etc etc. 
Follow the established conventions of the existing code. Absent that, I tend to keep related classes, traits, and objects in the same file until they get past a certain SLOC size that feels like they should be a separate file for the sake of readability. The exceptions: * case objects or case classes that refer to a sealed trait _must_ be in the same file as the trait. * helper objects (objects with the same name as a class) ~_must_ be in the same file as the class. The sole exception is when it gets to be HUGE – like more than 1,000 lines – in which case it's probably appropriate to refactor it into smaller units. Think of it like this, as well: You're not going to be wrong if you structure it like Java. Java in Scala syntax still "better" than Java. The annoyance will be only with those who want "everything" in one file.
I'm completely new to Scala, so take this with a huge grain of salt, but RealWorld is usually well regarded: [https://github.com/gothinkster/scala-play-realworld-example-app](https://github.com/gothinkster/scala-play-realworld-example-app) &amp;#x200B; &amp;#x200B; &amp;#x200B;
Maybe this is a bit unsatisfying as an answer but I think that getting involved in these larger projects is just to basically: 1) Trawl the issue tracker -- is there anything here that you can understand? Try to find bugs labeled "good first issue". 2) Look at what PR's are being submitted. Can you understand what changes are being made and why? Any way to make this change more general purpose / robust / featureful / performant? 3) Ask questions on Gitter. I think most maintainers would be happy to see people taking interest in helping out. 4) Do you have any ideas that you'd like to see implemented in the project but don't know how to do it? Create a ticket for it, and ask for help / pointers about where to start. 5) Maybe start with scaladocs. Anywhere where a public or even private/protected api is not clear to you, see if you can figure out what it's doing, and open a PR with a nice scaladoc for that method/class/etc. 
Guess I'll have to get used to this feeling of having my ass get kicked lol
You're right - chapter 3 alone provides more education than that course lol 
No Tenery operator. The closest is: if (cond) true else false As the other poster said, it doesn’t call .split but it doesn’t think myVal is astring
Sunlight is actually not a very good disinfectant. Regardless, this has hardly been sunlight. It's a lot of back references to drama most of us haven't been party to. It's a hot mess. 
Btw, what you call helper objects are usually referred to as companion objects. If the companion object becomes too large, the convention I've seen is to define a separate trait for which the companion object extends. 
Thanks! I got it working eventually, but I had to carry around a second type. Monix doesn't include a Parallel[Task, Task], but instead a Parallel[Task, Task.Par], so that required adding a G[_] that gets carried around everywhere. Not ideal, but it works.
you can have [https://scalaz.github.io/scalaz-zio/usage/ref.html](https://scalaz.github.io/scalaz-zio/usage/ref.html) as somethingToReuse. and do lazy init in tokenize. In here [https://scalaz.github.io/scalaz-zio/usage/ref.html#compare-and-swap](https://scalaz.github.io/scalaz-zio/usage/ref.html#compare-and-swap) you can see how it is first get created and then used from another functions. &amp;#x200B; &amp;#x200B;
Short answer is \`flatMap\` once and pass the dependency as a parameter at construction site (eg. before invoking \`main\`). The concept of sharing state in FP is a common problem that has a very simple solution. I wrote a blog post about it: [https://typelevel.org/blog/2018/06/07/shared-state-in-fp.html](https://typelevel.org/blog/2018/06/07/shared-state-in-fp.html)
btw, you don't need to type \`IO.syncException(...)\` you can just use \`Task(...)\`
Right, this can work. The advantage is that it doesn’t impact the code outside the interpreter. 
Thanks for the tip (and for your excellent book, while we’re here!). I’ll try it that way. 
Hey sorry for having to remove this but this is in fact a scala forum, so kotlin specific articles are off topic. Thanks.
You still need to pass the dependency as a parameter (whether the Ref or the abstraction that encapsulates it)
&gt; If two ASTs behave differently upon evaluation then in what meaningful sense can they be said to be equivalent? They will behave the *exact* same way *given the exact same input*, even though in case IO it's impossible to give *exact* same input (counting the state of the world), it still gives you a useful intuition. &gt; Equally e.g. Option#map creates a new object instance which may exhaust memory, so you might consider a.map(identity) inequivalent to a and Option not to form a valid monad. Option.map doesn't have a `malloc` call inside it, the JVM chooses to allocate memory to run it, while Option.map itself is RT. &gt; But there's an excluded middle here: either we consider forking a thread equivalent to not, in which case Future is fine, or we consider them inequivalent By contrast, Future always directly accesses and modifies global mutable state. There is no interpretation of Future that is RT. &gt; in which case Task/IO/... are also illegitimate. Task/IO etc. are entirely abstracted from forking threads, allocating memory or anything else. I may well choose to just serialise the instructions instead of executing them, yet the composition will still be valid. &gt; This is the view I'm arguing against. But why? You don't need mental experiments to see the difference, even simplest refactors in Future cause very different runtime characteristics, non-RT of Future is not something theoretical, it's shooting people in the foot daily. &gt; Well, I think scalaz's decision to make Monad#pure take =&gt; A rather than an A is partly at fault there Partly, but they also deliberately implemented it with Future.apply instead of Future.successful as in cats, which is just bizarre. &gt; much the same thing could just as easily happen with Eval, which we all agree is a perfectly reasonable monad. I don't think you can construct a program in `Eval` using just the Monad instance that would behave observably different from the same program in `Id`.
Aren't you already "leaking" an implementation detail by declaring `tokenize` to be effectful? 
I'm spanish and I was looking for decent Scala-related job in Spain for 2 years (about 4 years ago). Everyone was like "uh, if you know Scala, you can do Java, don't you?". And salary mostly was mediocre of course. In the end, I got network engineering job on Costa Blanca (don't ask) and suddenly I'm very happy with it. Though I still love Scala and use it in my small projects. I'm really happy that Scala is finding its way into Spain.
&gt; They will behave the exact same way given the exact same input But we're not concerned about input, we're concerned about concurrency (since that's the only functionality that `Future` offers). And if we care about concurrency, we surely don't consider two (or n) operations running in parallel to be equivalent to them running serially, and yet `(someSlowTask, someOtherSlowTask).mapN(_, _, =&gt; )` will probably run the slow tasks in parallel while `someSlowTask flatMap {_ =&gt; someOtherSlowTask} map {_ =&gt;}`, which should be equivalent, will run them serially. &gt; Option.map doesn't have a malloc call inside it, the JVM chooses to allocate memory to run it, while Option.map itself is RT. `Option.map` has an (indirect) invocation of `new`, which programmers generally understand to allocate memory. There's no qualitative distinction you can draw between `new` and `Thread#start` in terms of being side effects or not (both can fail due to resource exhaustion, both are common and cheap enough that you often want to reason as though the resource were unlimited). &gt; By contrast, Future always directly accesses and modifies global mutable state. There is no interpretation of Future that is RT. In exactly the same sense that main memory can be considered global mutable state, in which case you can't consider `Option#map` to be RT either. &gt; Task/IO etc. are entirely abstracted from forking threads, allocating memory or anything else. I may well choose to just serialise the instructions instead of executing them, yet the composition will still be valid. In which case they're just overcomplicated versions of `Eval` and useless for reasoning about concurrent behaviour (which is their whole raison d'etre). &gt; But why? You don't need mental experiments to see the difference, even simplest refactors in Future cause very different runtime characteristics, non-RT of Future is not something theoretical, it's shooting people in the foot daily. Not my experience at all; most people seem to find the behaviour of `Task`/`IO` more confusing than that of `Future`, and it's very easy to silently lose (or never achieve in the first place) parallelism in `Task`/`IO`. &gt; Partly, but they also deliberately implemented it with Future.apply instead of Future.successful as in cats, which is just bizarre. Agreed. Two bad implementation decisions in this monad implementation, not an issue with `Future`. &gt; I don't think you can construct a program in Eval using just the Monad instance that would behave observably different from the same program in Id. If the monad instance uses `Eval.later` to implement `pure` instead of `Eval.now` you could, and that would make just as much sense as using `Future.apply` does.
&gt; Lars had effectively removed all maintainers from Scalaz with the exception of his friends, and a few choice folks like Paul Chiusano and Runar Bjarnason, and effectively "taken" Scalaz, folding it into Typelevel without communicating it to the core maintainership (those whom he banned). It was only later, that he was convinced by a few of those that were left to continue with a fork and call it something else, stepping down from Scalaz. Very briefly, and without touching on the whys and wherefores of any of this… I hear people saying things like the above quite a lot, and it's not really historically accurate. The set of people who had **Write** permissions on the scalaz/scalaz github repo was actually quite large at the time all of this went down, including a large number of people who could in no way be characterized a part of any special Lars-centric group (e.g. Jason Zaugg still had admin rights at that point). A vast number of those people left (or hid their membership) when everything exploded. Lars was *the* de facto maintainer of Scalaz from the time when Jason left (just before Scalaz 7 was released, IIRC) until the split. He was by any meaningful definition *the* project owner. Tony was absolutely still around and occasionally got involved in things (mostly on IRC, or jumping in to close pull requests that he disagreed with), but it wasn't common and he wasn't really doing any of the work, nor was anyone else. There also was no notion of "core maintainership". Not really. There were people more central to scalaz than others, but that set of people had been the same loose clique for most of the decade (e.g. Paul and Runar are two examples). If that's what you mean when you say "core maintainership" then your statement is absolutely correct, and this was the heart of Paul's complaint about the whole process on the mailing list, but the "core maintainership" was not generally involved in maintaining or developing scalaz on anything close to an ongoing basis. So again, no vitriol, just correcting a few historical facts. Lars was, for all intents and purposes, the owner of the scalaz/scalaz project at the point when all of this happened, and had been for several years. He was the owner by virtue of being the one who did all of the work, made all of the meaningful final decisions, and was universally recognized by the broader community as such without any complaints. The eviction of Tony marked the first time anyone objected to Lars in this role, and also the point at which "Lars the Interloper" became an oft-repeated narrative.
&gt; Lars was, for all intents and purposes, the owner of the scalaz/scalaz project at the point when all of this happened For not a single day was this true. I understand why you might think it is true, and I find that funny. 
Why? Once you understand Scala well enough, both technically and politically, and if you're an independently thinking person, you'll leave it alone like the rest of us.
Let me help. I did a talk in Chicago in 2014 where I discussed why Scalaz succeeded, part of which is abandoning the ridiculous idea of "community." Lars got pissed, talked to his psychopathic buddies, and plotted the take-over. Lars, and importantly his psycho buddies, didn't know that I knew what was up, and that I took to fucking with them as a consequence. People took "screengrabs" of that fucking-with and called it abuse. Much of it was. I giggled at it and made it turn into actual abuse, so that the scapegoating was accurately directed. Lars, and his psycho buddies, subsequently fucked off and most things are back to normal. A few of them hung around to be total dick heads, wondering if my response is the same. The answer is yes, so then they fucked off too. Occasionally one of them drops by to tacitly/inadvertently ask me if their twisted ideas are yet allowed to influence the scalaz project. Normal, except of course, we have all since learned that Scala itself is a waste of time. We will never see anything useful out of Scala again, except for the comedy components.
Very well raised points. I just wanted to add another point regarding performance - sometimes code written in Scala can even outperform the same code in Java, due to lazy evaluations. I've been trying to introduce Scala to my friends/colleagues, but most of them feel that its too big a jump from Java, so I've kinda resorted to introducing Kotlin first, to give them a taste of some of the more basic Scala features, before introducing to them the more advanced features in Scala.
&gt; I don't understand this. Considering the github usage statistics from the time Lars started committing (roughly june 2011) to his last commit (Dec. 2014) there was plenty of activity (mostly coming from Jason, as you said, who stepped down), but there was also a fair amount of activity coming from many others. I'm not sure if I buy that argument. But then, I wasn't there, so I can't know what really went on. It's best to look at the pull requests and issues themselves. Particularly towards the end of his tenure (going off memory here, but at least the last 2 years of it), Lars was the one who tacitly had the final say on effectively everything. He made decisions as to what did or didn't make it. He arbitrated disputes. He merged the vast majority of PRs. He planned and cut releases. If you don't like "de facto owner" then perhaps "undisputed maintainer and arbiter" would be a better term for it. The best analogue in the modern project set would be Kai on cats, who was not in the original set of creators but is now looked upon as the de facto lead. Though Kai writes a lot more code himself than Lars did, so the analogue isn't perfect. Lars mostly sifted through and mediated other contributions. &gt; Runar, Paul, Travis, Tony, Stephen, and Kenji, yes. That's who I mean. I don't think "core maintainership" would have really been an appropriate term for that group (also some other people might be validly added, such as Brian and Rob), but naming aside, I think your original statements are accurate. This set was very definitely not well informed on the events prior to their unfolding, and was extremely not pleased. &gt; I remember joining around 2014 as well, and I don't remember ever seeing Lars interacting with the community in #scalaz. I definitely can't speak for the IRC room as I avoided it almost entirely, mostly due to Tony. Without checking any of the archives, I have little doubt that you're correct though (regarding Lars' limited interaction there). Lars' interaction in the Typelevel gitter rooms is also nominal, though he doesn't really have anything like a definitive leadership role. &gt; The thing happened 10/2014 - so he could only have been a "leader" (loud maintainer) for upwards of a year to two years maximum. That paints a picture of someone who's maintainership went to his head The way I saw it at the time was more that decision-making and ongoing maintainership had been tacitly ceded to him, and he was running with that. When everything went down, it felt very much like it was in many was a public referendum over Tony's "original claim" vs Lars' "present undisputed stewardship". It would have been much more interesting to see that play out without the backdrop of either personality, since it would have said a lot about the nature of OSS, but I suppose we'll have to wait for some other project to decide that particular precedent.
In JDG's video [FP to the Max](https://www.youtube.com/watch?v=sxudIMiOo68) he defines a `Random` trait, a companion object and then there is another `nextInt` inside the app, that nextInt on an implicit instance of Random. The relevant lines in this gist: [https://gist.github.com/jdegoes/1b43f43e2d1e845201de853815ab3cb9#file-fpmax-scala-L65-L71](https://gist.github.com/jdegoes/1b43f43e2d1e845201de853815ab3cb9#file-fpmax-scala-L65-L71) My question is: why having this external \`nextInt\` is desirable? It seems like unnecessary boilerplate. The code that needs this capability might as well changed from: `def gameLoop[F[_]: Program: Random: Console](name: String): F[Unit] =` to `def gameLoop[F[_]](name: String)(implicit p: Program[F[_]], r: Random[F[_]], c: Console[F[_]]): F[Unit]` and invoke `nextInt` directly on the `r` instance. What am I missing? &amp;#x200B; &amp;#x200B;
I went through the history and he did indeed have many merges. Most without a word. Very strange behavior, but he did clearly have an impact on administrative things. On Scalaz now, we at least say high, discuss, and thank contributors, so I'm glad that's at least changed since Lars' time. it's all very strange. Either way, I know Tony to be a good guy, so I don't have too many doubts about his side of things. At least it's all in one place now for other people to make their own decisions. I, for one, still cannot get over the fact that people, let alone leaders, were unironically supporting the act of trying to get someone fired, or blacklisting other developers. Regardless of how abrasive you find him, I couldn't ever see Tony doing that to someone else. That and lazy semantics. Can't get enough of those. Hopefully we're done with the fights tho :) 
I did not imply that there was some "conspiracy." You Scala programmers keep thinking this is about Lars, like I have it in for Lars. You all think I do, which is weird as fuck. Try again.
Aha, that's what it means? I always thought you were leaving Scala in favor of Haskell; and it always puzzled me why you were still so active in r/scala. But now I get it
&gt; I just wanted to add another point regarding performance - sometimes code written in Scala can even outperform the same code in Java, due to lazy evaluations. And sometimes it's the other way around: Compare Java streams ("lazy") with Scala collections (strict). The opportunities where Scala can be lazy are dwarfed by the amount of code that uses collections indiscriminately and is therefore magnitudes slower than Java streams. Using Java has reduced the amount of while loops I had to write to almost zero, compared to Scala where this was a common occurrence.
While loops in Scala common occurrence? I want to say you are doing it wrong.
There are those who have read the collections implementations, and those who haven't.
I would go with "no" for the main question of the article; it is not a good sales pitch. It's long (I needed two attempts to reach the end); it goes in circles about how bad Java is (still, it's out there in the wild, and feels fine, so are those problems \_that\_ important? Maybe they are, I don't know, but maybe not), and then there goes a standard description of what FP is. &amp;#x200B; But that's not the point. For a *move* to Scala, one needs to understand the **current** process, and the **current** problems. If it's a pitch for a company, what is the pain? Why would one even bother switching to anything? The "managers" (they're always there, those pesky managers) have raised a point: *“If we start using Scala, we need to validate it with the company hierarchy first. To find Scala developers is more difficult than Java ones”* — and this point is reiterated, *"it’s already hard to find Scala developers: therefore it‘s a risky bait,"*— but still not addressed. &amp;#x200B; Finally, the conclusion: *"I think going to Scala is the best step Java developers can do"*— our imaginary managers are of course convinced by now. Of course, let's do what's good for developers, what else company is supposed to do? &amp;#x200B; So, alas, you're preaching to the choir and *ignore the very people you were about to sell to.* 
It depends on your performance needs. Idiomatic Scala collection usage performance can be a train wreck in certain use cases, causing you to have to resort to arrays and while loops.
Every country in the world lacks scala devs man. Quite hard to hire :(
&gt; I, for one, still cannot get over the fact that people, let alone leaders, were unironically supporting the act of trying to get someone fired, or blacklisting other developers. Regardless of how abrasive you find him, I couldn't ever see Tony doing that to someone else. It's not really just abrasion. Tony has a lot more history than you think, both on and offline. It is what it is, though. I'm glad to hear the Scalaz community today is welcoming and inclusive and works with contributors. This marks a stark difference from how Scalaz was for *years*, dating back long before Lars learned Scala. I truly am glad. The world needs more of that. Some day, I really do hope that the turnover in the old guard eventually phases out nearly everyone who had any direct involvement or direct bone to pick with either side. We're already seeing it start to happen. Accounts of events are increasingly second- and third-hand. I hope that this "new generation" of contributors and maintainers and leaders can stop fighting the battles of their fore-bearers, as it were, and rise above tribalism just long enough to allow the fires from four years ago to finally go out. I'm just worried that these second- and third-hand accounts are always going to be factually colored by the opinions of the original storyteller, as we perpetuate the battles and the points of view handed down to us by those who came before. Whatever you think of Lars, or Tony, or Scalaz, or Typelevel, or *Scala*, these wars are bad for everyone everywhere. I sincerely hope other PL communities are taking notes on what happened so they can head it off at the pass if it starts to arise in their own spheres of influence.
I've only been doing Scala for a little over two years but have never written a loop at work. Diddling around at home, sure. Some people I work with do, though.
I would check out [https://github.com/pauljamescleary/scala-pet-store](https://github.com/pauljamescleary/scala-pet-store) &amp;#x200B; I am the author, so this is a little self-serving.
Some facts to add to the mix. [https://groups.google.com/forum/#!topic/scalaz/EBP\_7sfB2ks](https://groups.google.com/forum/#!topic/scalaz/EBP_7sfB2ks) [https://groups.google.com/forum/#!topic/scalaz/OjUf4hfjyyw](https://groups.google.com/forum/#!topic/scalaz/OjUf4hfjyyw) [https://groups.google.com/forum/#!topic/scalaz/EqoQaL\_yH4U](https://groups.google.com/forum/#!topic/scalaz/EqoQaL_yH4U) [https://groups.google.com/forum/#!topic/scalaz/ki3MjAxD3Bs](https://groups.google.com/forum/#!topic/scalaz/ki3MjAxD3Bs) [https://groups.google.com/forum/#!topic/scalaz/9X\_putSGoCY](https://groups.google.com/forum/#!topic/scalaz/9X_putSGoCY)
From what I hear pay in Spain is laughably low for software engineers. 
That is true. But that's not only in Scala, it's any IT role. You will earn more in a London or Swiss company and, if you get the chance to work on remote, BINGO! Salaries in Spain are growing though (still a long road ahead). Especially Barcelona with the tech-hub and all the start-ups. 
4 years ago lol. I can imagine the "you can do java" thing. I suppose the whole sector is changing quickly. It is picking up quickly in Madrid, companies like Packlink, DatioDB, tecsisa... there are also quite big Scala meetups there. In Barcelona, there are also quite a few that are starting to implement it or to migrate from Java8-scala. By the way, congrats on the Costa Blanca job, good lifestyle for sure! &amp;#x200B; 
What makes you say sunlight is not a good disinfectant?
&gt;I would say that is relative. &gt; &gt; &gt; &gt;Don't you care about the sun bro? Lol. 
If you naiively use higher order function calls everywhere in scala you really get shit on by the jit failing to inline stuff nearly as well as with while loops. Shit, try a really simple bench: pattern match vs `.fold` on either option or `Either` and you see a significant difference in ops/s. I'd say you're either naiive, or you don't ever try to optimize performance in scala.
Thanks, and I agree with you. The article strays from its original purpose. A lot of points are technical and developer-oriented (Annotations, FP) but it's difficult to explain some points without being techy (those would by dry points?). The thing is that we can't summon Scala developers where there is none, so the answer I give is basically "let Java developers explore Scala, using the tools they know. It's not that different, and they will write more concise and robust code at the end". I've explained some of those concepts to some developers, they clearly understood, almost "illuminated". But yes, the managers look beyond that.
That's step one. Then comes step two: half of your Java developers start writing Haskell in your Scala codebase, and half of them are trying to keep things to "better Java." The "not that different" part flies out of the window, and you have the team split and alienated. Next steps, please? Again, I love Scala, and in a week it'll be 4 years since I have switched. It made a perfect sense *for me:* it's fun. For the project as a whole... For the most recent one, it did make sense, but then the management was heavily invested from the start. For the earlier one, not so much. For a short project last year, they've ditched Scala *exactly because it was missold.* So when you sell something, make sure you can deliver what you've sold.
Markup looks hosed...
If I had to get a Java team to move away from Java, I would also be introducing Kotlin instead of Scala -- even though I prefer Scala as a language. I've found it hard to get Java developers to get into Scala, whilst they've generally found Kotlin easier -- as they get to keep Spring, Jackson, and other libraries that they are familiar with.
&gt;half of your Java developers start writing Haskell in your Scala codebase, and half of them are trying to keep things to "better Java." If you have some processes such as: code review, pair pro, someone looking like a lead developer, this should not happen. The codebase will stay consistent (and probably "raise" level across time, that happened to me). I could do the "same" in Java. For instance —while I'm selling Scala— I've already replaced tons of code with abstractions and Streams (I'll probably add vavr at a point), created modules, split up tons of classes, add generics where I can. It's still Java, but coded way differently than previously, and I don't need to sell anything to my manager here: "still Java". I need to sell it to my coworkers. I'm just keeping them on board through PR and reviews. &amp;#x200B;
I would like to build a REST service (just CRUD functionality) in a functional way. I finished part 2 of the red book and tinkled around with defining my own algebra in other projects, I kinda followed their approach for library design. But now I don't know how functional I'm gonna be if I don't use IO and stuff because this is contained in chapter 4. Should I just keep trying to build the system or continue with the book? Also I would like to use Doobie and Akka HTTP, are these enough or is there some good library for JSON marshalling? 
I would always recommend building useful programs first and foremost, since that's always the end goal. The functional techniques are a means to an end - indeed I'd say it's well worth experiencing the issues with non-functional approaches yourself, that gives you a lot more appreciation for what the functional techniques buy you and when they're appropriate. There's inherently a bit of a conflict between a CRUD style and a functional approach - when you're doing something so fundamentally non-functional there's a limit to how much you'll be able to gain the benefits of functional. But you can use IO to control when database access actually happens and you can derive some value from that. doobie is built around having an `IO`-like construct that can suspend effects for future execution (there's a minimal one included but it's really intended for use with `IO` or similar), whereas akka-http is built on the standard library `Future` which doesn't suspend. So while you can use them together, you'll have a slightly awkward boundary between them; it might be better to use either a more `Future`-oriented database library (slick is popular) or a more `IO`-oriented HTTP library (http4s; rho offers a more akka-http-like API on top of it). For JSON marshalling most of the pure-functional-style world seems to be on circe these days (I use spray-json, augmented by spray-json-shapeless, but that's officially deprecated now).
It's worth noting that Scala is generally easy to refactor automatically/safely since you tend to make stricter use of the type system than in Java. So there's less need to get the code layout right first time and ensure every class starts in the right place; rather it's fine to start by putting everything in one place and then split up classes/packages/projects as they grow too unwieldy. You definitely want to avoid any kind of "every business area needs these 4 layers" structure; rather let the structure of the code in each area reflect the requirements in that area. Or put another way, when you see a pattern in your code that's usually a sign that there's a higher-level common structure that you could factor out.
You mean static annotations? Because normal java annotations are done the same way as on JVM.
[https://github.com/lihaoyi/cask](https://github.com/lihaoyi/cask) is based on custom annotations
Those are implemented using Scala macros. 
You should expand your question to at least include what examples you have seen, and why they don't solve the problem you're looking to solve.
uuugh. blockchain.
/r/yesyesyesyesno
fuck blockchain 
Ahh, if this posted a year later I would apply straight away. Good luck 
&gt; Do you, by any chance, have a good tutorial for IO Stuff? No; I'm afraid I kind of picked this stuff up as I went along. If you've got a book whose style is working for you then I'd say stick with that. Are you comfortable with monads generally? I don't think `IO` is the best place to start (personally even after 8 years of Scala I don't bother with it most of the time); it forms a monad but doesn't have much other structure, so I find it easier to first get comfortable using monadic and related constructs (`flatMap`, `traverse` etc.) with types that you can also use as plain values (e.g. `Writer`, `Either`) to start with. There's not a lot to do with `IO` because of that lack of structure - all you can really do is form one and then run it (just remember to never discard one without running unless that was what you wanted - I highly recommend building with `-Ywarn-value-discard` if you're using `IO`).
Check out Jon's library: [https://github.com/propensive/adversaria](https://github.com/propensive/adversaria)
Apply now
Apply for a job now that I'm not available for? 
Is it onsite?
Original seems to be this: [https://lepo.group/posts/2017-06-05-error-handling-pitfalls-in-scala.html](https://lepo.group/posts/2017-06-05-error-handling-pitfalls-in-scala.html)
Scala Spree is a good starting point. You can find the open source from the earlier event. Most of those project will have the github link that tags those issues with **good first issue** or **help wanted**.
Yes. My team's office is in central London (Soho).
How big is your team, how big is the London office? How do you find the culture? Snap doesn't have the greatest reputation for being a good place to work, is the London office different? 
Having an issue figuring out what a good way to sanitize a string with a set of characters that need replacing. For example, below, if I chain a bunch of `replace(a,b)` together, it will do the trick, but it's not very elegant. Any advice on away to clean this up in a logical way? ``` def sanitiseName(name: String): String = { val replacedName = name.replace("\\", "-").replace("/", "-"). replace("*", "-").replace("[", "-"). replace("]", "-").replace(":", "-").replace("?", "-") } ```
In my team we have 15 people. We're part of an org spanning a few more offices in the US and we work closely with them. There's another engineering team here working on computer vision. We own our products and we have autonomy in the technical choices we make. Writing our software in Scala was our choice, for example. Here in London a lot of us came from companies where decisions depended on the headquarters, which was a pain point. So for us this ownership aspect has been important and a significant part of what makes the office a good place to work, in addition to the team being composed of good people.
As someone coming from a Python background, I am thoroughly confused as to how packages work in Scala (and I guess the JVM ecosystem in general). I'm learning Scala in order to learn [Figaro](https://www.cra.com/work/case-studies/figaro), a probabilistic programming language, and to get my hands dirty with functional programming. And online resources explaining package management are scarce or really counter-intuitive for me. Could someone please give a quick rundown on the process of installing and importing packages in Scala? Do I always need to use the sbt? And if so, how on earth does that work anyway? &amp;#x200B; Thanks!!
Do you sponsor visa?
Yes -- that shouldn't be a problem.
most of the stuff in that book will never be asked in an interview trust me , focus on what the others have said, computer science fundamentals and work on some projects. Understanding fp is a bonus but won't be what your tested on in interviews.
Nice. Just one suggestion ... can't `Unsigned` be declared as an `AnyVal`? It seems to me that it can and it might avoid boxing sometimes. 
Hey you should just download IntelliJ with the sbt plugin, and create a new sbt project. Then, in the build.sbt you'll have to add libraryDependencies ++= Seq( // your libraries here ) Each library is uniquely identified by its organization, artifact id, and version. This will usually be given in the readme, but can be found also at search.maven.org. For instance go here https://search.maven.org/artifact/com.cra.figaro/figaro_2.12/5.0.0.0/jar and scroll down on the right until you find the sbt code snippet: "com.cra.figaro" % "figaro_2.12" % "5.0.0.0" So then you can add this to you dependencies. Then refresh sbt through intellij, or type `sbt compile` and it will pull down the dependency
Interesting question. `Unsigned` can't be extended with `AnyVal` due to the additional typeclass constraints on the type parameter - final class Unsigned[A: Bounded : Integral] private(val value: A) If extending with `AnyVal`, I get the following error message - `value class needs to have exactly one val parameter`. The typeclass constraints allow `toString` to be defined as needed.
Thanks for that, I think I should take more time to look into Spire.
Ah, ah see, OK. Btw, with type classes and restricted parameteric polymorphism, often times it's a better idea to place those constraints on the operations themselves, not on the data structure definition. 
I've created a small library that's nothing but a small annotation macro, producing compilation error if the date parameter set in the annotation is older than the current date: https://github.com/norcane/reminder
Thanks! I figured out that you can do that by creating a project with sbt. It's tedious that you'd have to create a project to play around with new packages. It feels like it discourages experimentation. Is there some way around this?
Woah this looks a lot nicer! 
Thanks, it all makes sense. In my specific case I prefer to not have it visible in the business logic but I understand the different options. 
Thanks, it all makes sense. In my specific case I prefer to not have it visible in the business logic but I understand the different options. 
Ahh, that makes sense. Thanks a lot!
I'm trying to add support for value class in Spark, see [https://github.com/apache/spark/pull/22309](https://github.com/apache/spark/pull/22309). This allows me to have specialized [ScalaCheck](https://github.com/rickynils/scalacheck) generator for 1 of the integer columns (says \`user\_id\`) while at run time, they are still all integers.
I agree. `Unsigned` can be defined as - final case class Unsigned[A] private (value: A) extends AnyVal The only issue is that the `toString`implementation has to work for all types - scala&gt; Unsigned[Byte](6).show res1: String = 6 scala&gt; Unsigned[Byte](6) res2: unsigned.Unsigned[Byte] = Unsigned(-122) This is probably okay since it would be hard to mix the two unintentionally (and not notice). 
This is a great idea. SBT is not really good for noobs. Better to use it the simplest way you can. 
Good to know I'm heading right direction thanks
http://www.lihaoyi.com/post/ScalaScriptingGettingto10.html Try ammonite if you want, and Li's blog is really good. http://www.lihaoyi.com/hands-on-scala-js/ And check the right pane on this sub if you did not yet )
Just pick one build tool and one IDE/editor and stick with that until you at least know how to actually write Scala programs. You are not going to be creating major projects from scratch for quite a while. All you need is something that will manage your dependencies, and which you can click/type "build/run/whatever" and get a running program. I'd recommend Intellij and use the maven or SBT plugin, but to be honest, until you need to download and use packages, vim/emacs/notepad and scalac are fine.
I am ready to try anything thanks for giving me advice! It's because of people like you that I am learning Scala. 
I'm going to stick with one for a while and focus. I'm just turning over stones and looking for waypoints. Switched to colemak... switched to Linux.... Might as well start doing things the right way and getting good habits. I was thinking vim or emacs was also a good learn but the more I read... The more I hear people who don't think these editors work well for Scala which I'm trying to focus on. Ensime tries to provide this in emacs but I just hear complaints online about it. Now I feel conflicted. 
I wasn't suggesting using emacs was a good idea. I was saying that whatever choice you make isn't important. Just use whatever text editor you are already comfortable with. Learn about Scala first, then you can start thinking about build systems and IDEs.
Now that we're at it, why not also make the `FunctionN` classes extractors as well? This was, we can have an equivalent to Haskell's [view patterns](https://ghc.haskell.org/trac/ghc/wiki/ViewPatterns#Basicviewpatterns). Though we already have extractor objects, which diminishes the usefulness of view patterns, it's sometimes very verbose to declare an extractor, especially if it's defined in some nested scope and depends on what's in scope so it cannot be taken out. So it would be nice if we could write: val content = (_:Node).content ... case ... content(0 | 1 | 2) ... =&gt; ... ... instead of: object content { def unapply(n: Node): Some[Content] = Some(n.content) }
I’m an ordinary day job Scala developer, and I think IntelliJ is fine. Just pick something and play with it.
Combining this proposal with anothing PR(https://github.com/scala/scala/pull/6703), we can create the extractor as: ``` scala val content = PartialFunction.fromFunction((_:Node).content) ... case ... content(0 | 1 | 2) ... =&gt; ... ... ```
&gt; In my reading I found many Scala devs hate Intellij By now a majority of Scala developers use IntelliJ IDEA, because it's the best IDE. It has some quirks, but you get over it and move on. You can use a plain editor, like Emacs or VSCode or Vim of course. It's better for learning actually. But if you're thinking about installing IDE-like capabilities in these tools, like Ensime, you're not going to be better off than just going with IntelliJ IDEA.
Having Random be implicit can be really really useful for things that need a seeded random value, random level generation etc.
use intelij idea. It works best for scala. It'll also help you with good practices. 
Sure, in your example you compose the \`List\` functor with the \`Option\` functor nested in each other. Two Applicatives can also be composed by nesting them in each other. So for example: \`\`\`scala def getUser(info: UserInfo): Future\[Option\[User\]\] def getAccount(info: UserInfo): Future\[Option\[Account\]\] case class UserAccount(user: User, account: Account) Applicative\[Future\].compose\[Option\].map2(getUser(info), getAccount(info))(UserAccount) \`\`\` This will yield a \`Future\[Option\[UserAccount\]\]\` Another example where this comes in real handy is when using \`traverse\`: \`\`\`scala def getAllUsers(userInfos: List\[UserInfo\]): Future\[Option\[List\[User\]\]\] = userInfos.traverse(userInfo =&gt; Nested(getUser(userInfo))).value \`\`\` \`Nested\` is a very simple wrapper class for exactly this kind of composition. You can check out the documentation here: [https://typelevel.org/cats/datatypes/nested.html](https://typelevel.org/cats/datatypes/nested.html) 
&gt; But we're not concerned about input, we're concerned about concurrency (since that's the only functionality that Future offers). Input here means abstractly all input, i.e. state of the world and output includes concurrency effects. &gt; And if we care about concurrency, we surely don't consider two (or n) operations running in parallel to be equivalent to them running serially, and yet (someSlowTask, someOtherSlowTask).mapN(_, _, =&gt; ) will (probably) run the slow tasks in parallel while someSlowTask flatMap {_ =&gt; someOtherSlowTask} map {_ =&gt;}, which should be equivalent, will run them serially. They will both run serially in cats-effect.IO and scalaz-ioeffect/zio.IO, you have to use the `@@ Parallel` tag and summon different instances to run in parallel. I don't know about monix. &gt; Option.map has an (indirect) invocation of new, which programmers generally understand to allocate memory. There's no qualitative distinction you can draw between new and Thread#start in terms of being side effects or not (both can fail due to resource exhaustion, both are common and cheap enough that you often want to reason as though the resource were unlimited). In practice we might say we want to refactor our code and are happy for this to change memory usage but not change threading behaviour, so we're going to track thread starting as an effect (that is to say, regard code that starts a thread as inequivalent to code that does not) but not track memory usage as an effect, but this can only ever be a pragmatic choice rather than something principled. It's not about changing the threading behaviour, side-effects in Future can change the output of the function itself on refactors, here's a good example: https://www.reddit.com/r/scala/comments/3zofjl/why_is_future_totally_unusable/cyns21h/ &gt; In which case they're just overcomplicated versions of Eval and useless for reasoning about concurrent behaviour (which is their whole raison d'etre). That they are, cats-effect.IO is literally an extended version of Eval. Their raison d'être is a combination of providing a runtime with green threads (Fibers) and a RT IO type. I doubt monads can help reasoning about concurrent behaviour, they can only model sequential processes. &gt; Not my experience at all; most people seem to find the behaviour of Task/IO more confusing than that of Future, and it's very easy to silently lose (or never achieve in the first place) parallelism in Task/IO. Surely Future is more approachable to beginners. But it is often a footgun for people that got used to reliable refactoring or who trust their Monad instance. &gt; Agreed. Two bad implementation decisions in this monad implementation, not an issue with Future. IMHO, there's only one bad decision – a Monad instance for Future. Gladly, scalaz 8 doesn't repeat that mistake (yet?). &gt; If the monad instance uses Eval.later to implement pure instead of Eval.now you could, and that would make just as much sense as using Future.apply does. The reason I think you couldn't is because a subsequent `.flatMap` will evaluate the `.later` anyway, i.e. there is no laziness inside Eval and without using functions outside of `Monad` instance, I don't think you could construct a program that would surface the laziness in `.later`.
Have you checked http4s? IMO its simplicity is its biggest selling point. It's fast and easy and gets the job done :)
Scalatra? It’s a lightweight Scala framework.
Just brilliant answer, thanks!
My teammates and I use IntelliJ to develop the Scala compiler itself, and really like it! (I lead the Scala team at Lightbend). It's not perfect, and has red squigglies sometimes on more advanced code patterns, like macros and fancy typelevel tricks, but I would recommend avoiding those anyway (at least for the first few years ;-)).
Cask: https://github.com/lihaoyi/cask
I'm really confused by what "strawman" means in this context. Usually a strawman would be an unusually weak or contrived definition but these look accurate to me, unless I'm missing something.
The simplest reason is ... because you can :-) By adding the restrictions on the data structure, the data structure itself becomes less generic. Deferring those restrictions on the operations themselves, you can end up with a more reusable data structure. For example: sealed trait List[F[_], +A] case class Cons[F[_], +A](head: A, tail: F[List[F, A]]) extends List[F, A] case class Nil[F[_]] extends List[F, Nothing] This is a generic data structure and `F[_]` can be anything. You can't do much with it in this state, but that's fine: - For example if `F[_]` would be a `cats.Bimonad`, you would be able to describe simple lists with it and you would be able to fold such a list, because you can iterate over it via `extract` at each step, so with a plain loop - You could require `cats.effect.Async` and thus be able to deal with side effectful, or even asynchronous `F[_]` values, but here's the gotcha: if you require `Sync` or `Async` from Cats-Effect, you can no longer have `Comonad`, but that's fine, because you can traverse this data-structure via `flatMap`, the `Sync` type class requiring by law for `flatMap` to be stack safe - If you end up describing an operation that concurrently processes and merges two lists in parallel, you'll end up needing `Concurrent`, also from Cats-Effect; but such for such an operation to be described, it's a pity if you have to restrict your whole implementation to `F[_] : Concurrent`, when for most other operations `Sync`, or even plain `Monad` or `Applicative` would do That's just a simple example. But if you take a look at the data structure itself, it's just a very generic shape. It certainly is a more generic version of Scala's `List`. And it doesn't matter what `F[_]` is, until you use it.
Probably header related, maybe \`Accept\`. Run \`curl\` with \`-v\` and then try Akka with some of those.
You gotta check out Li Haoyi platform! :D Simple, fast, straightforward Scala code.. Great engineer and a very nice guy.
Could also be user agent, since it's a 500 maybe the server is messing up parsing the string. Could also be http version even, if you have an old version of curl maybe the server only supports 1.0. Regardless, it's a 500 so if you have some support from the bank you should notify them so they can fix what's broken on their end.
I'm just a kid so someday I will be there with you in the squiggles. Just a little bit of time. I'm spending most of my time right now getting used to my new Unix. I love command line now. 
I don't know about Flask, but Djnago certainly does all those things you listed
Soo this doesn't really work with Windows yet. Is there maybe a way where you can get Scala to see certain external libraries by default? Like using an environment variable? 
Akka HTTP is pretty good. 
Add import akka.http.scaladsl.model._ and val futureResponse = Http().singleRequest(Get(uri).addHeader(headers.Accept(MediaTypes.`application/xml`))) Although unless you need an actor system for any other reason, I'd recommend either using sttp or scalaj-http if you are just going to be creating requests and handling them. They are a bit easier to reason about unless you need to have Akka around for other reasons
I use IntelliJ and SBT. Most projects I come across use SBT. It is kind of the default for Scala. I have seen a couple use gradle, can’t say I have ever seen a scala project use Maven YMMV. Definitely recommend ammonite for tinkering.
https://github.com/pauljamescleary/scala-pet-store Not a road (but working on that) but can show a sample setup
I am working on improving performance of Maps and Sets in the new collections by experimenting with builders that mutate the underlying tree structures of the hashMap/Set, while building them https://github.com/scala/scala/pull/7118 https://github.com/scala/scala/pull/7138
These pics are meant for being integrated in Cats-Effect’s documentation. The author is very talented, follow him on Twitter.
Would you be okay with SF based remote?
Yes, it was `Accept`. It turns out that curl adds it by default and Akka Http does not.
And so under-used, if that is even a word...
I’m also going to suggest Http4s. It’s a very light, but awesome library for building web services. It does so by emphasizing FP and usage of libraries in the FP/Typelevel ecosystem, but the design is modular so you can pick and choose. The community is friendly too and you’ll find plenty of help.
Maybe. I would agree with giving each piece of state its own owner and send operations to the state rather than trying to move the state around - that's the good part of the actor pattern - but IMO using akka is too big a sacrifice in type safety compared to doing the same thing manually. `AsynchronousFileChannel` sounds reasonable if your file is only ever appended and "eventual consistency" is ok. I wouldn't want to use it for a file that you expect to read and modify concurrently, because per its documentation: &gt; When multiple read and write operations are outstanding then the ordering of the I/O operations, and the order that the completion handlers are invoked, is not specified; they are not, in particular, guaranteed to execute in the order that the operations were initiated. The ByteBuffers used when reading or writing are not safe for use by multiple concurrent I/O operations
I'll map one actor per file and do not let anyone else modify it outside the actor. Thanks for the review!!!
I use and recommend Maven - it's simpler, better documented, and has better IDE integration than any of the alternatives IME. I haven't seen any bugginess with large projects nor anyone claiming that (the main criticism of Maven is that it isn't very flexible, which is true but I find to be more of an advantage than a disadvantage - the build system is not a good place for complex logic IMO. Since your whole problem is overwhelming choice, a build system where there's only one way to do it might help you out). But as others have said, the main thing is to pick one and work with it. Stop worrying so much about how things build, and start making useful programs. You'll be able to make a more informed choice of IDE and build system once you've got a bit more experience working in Scala and know which things are important to you.
Low effort troll post. Do you have an actual problem with any you'd like to address?
No, I'm literally just frustrated 
There's also a script runner for sbt. You and have the set project definition as a comment in the top of your script file and run the script with an executable called `scalas`.
Underestimated? :)
Is there something on earth that Li Haoyi didn't made a simple and elegant implementation of ? ^^ This guy is awesome.
Check out https://github.com/softwaremill/sttp it's agnostic as to what async backend you use and in it supports alternatives to Akka such as Scala Future, Monix, Scalaz, etc
Underrated?
One of the worst DSL I ever saw. Also no support of CORS make it difficult to use for html rendering in server (server side rendering).
First commit is 20 july 2018. It's very yound !
STTP is a great recommendation. A small point on terminology, what you are calling a stack overflow is actually a stack trace. 
Thanks, I'll check it out !
Gigahorse is an option, which supports various backends: https://github.com/eed3si9n/gigahorse
Disagree, DSL is completely fine. And CORS, yes - not available out-of-box, but there are addons available to use or if you're into microservices you could do it using API proxies/gateways/controllers.
How do I create a spontaneous Set[A] from two items and an A* ? Code follows which does NOT compile , but you should be able to see what I'm trying to do. I need to take a general iteratable and spontaneously convert it into a Set[A] inline. final class Boxing[A]( max :Int , ropes: Set[A] ) { /** Auxiliary constructor **/ def this(max: Int , firstItem : A , secondItem:A , otherItems : A* ) = this( max , {otherItems ++ firstItem} ++ secondItem ); // Will not compile. What needs changed? } 
Http4s is pretty cool!
Snap has an office in SF as well. If you send me your CV I can look into related teams there.
you should be able to do this: this(max , (otherItems.toSet + firstItem + secondItem)) 
Most of what you posted isn't actually a problem... 2- Then I run the project. It crashed : [info] Running shopifyClient.Main SLF4J: Failed to load class "org.slf4j.impl.StaticLoggerBinder". SLF4J: Defaulting to no-operation (NOP) logger implementation SLF4J: See http://www.slf4j.org/codes.html#StaticLoggerBinder for further details. SLF4J: Failed to load class "org.slf4j.impl.StaticMDCBinder". SLF4J: Defaulting to no-operation MDCAdapter implementation. SLF4J: See http://www.slf4j.org/codes.html#no_static_mdc_binder for further details. This isn't actually an error. It's just telling you that there's no logging implementation, so it's falling back to the defaults. - Stakoverflow tell me to add a dependecy (which I don't need either in my app) to a SL4J implementation. I add the dependency : `"com.typesafe.akka" %% "akka-slf4j" % "2.5.0"` This isn't actually a slf4j implementation, it's just an akka interface to slf4j. A slf4j implementation is like logback It is just like 10 lines of code, not a big deal, but I'd prefer to avoid that How is that 10 lines of code? It should be 1 line. 8- The program is still not exiting properly despite a call to `actor.terminate()`. Why ? I don't know. Still no solution found. actor.terminate()? Or system.terminate(). This could be any non daemon thread that still exists. take a thread dump and see which threads those are
Thanks, everyone ☺️
now that Scala 2.13.0-M5 is out the door 🎉, I'm working on: * publishing Scala modules for M5. [sbt-scala-module](https://github.com/scala/sbt-scala-module) needs some love * working with library authors to help get their libraries published for M5 * maintenance of the Scala community build, as usual; for example we're now on [newer Play](https://github.com/scala/community-builds/pull/779) and [assorted newer Typelevel library versions](https://github.com/scala/community-builds/pull/775) * giving my "Compiler Plugins 101" talk [at SF Scala on September 11](https://www.meetup.com/SF-Scala/events/254191025/) * planning travel to Lausanne for an in-person Scala Improvement Process meeting after the Reactive Summit * setting up some more structure around Scala Code of Conduct enforcement online (working with folks at the Scala Center on this) 
I haven't heard of anything using Scala in that office apart from maybe Spark or Kafka, but that doesn't mean there isn't a team open to it.
Apparently my company has an incredibly difficult time finding Scala devs here in New York City! I think it's a combination of most startups using Ruby/Rails, or NodeJS, and other enterprise level jobs are still in Java. Most of the mobile positions are Swift/Kotlin as expected. So it's a combination of finding people and also availability of Scala roles.
So, a quick followup to my [previous question](https://www.reddit.com/r/scala/comments/9aofbi/got_a_quick_question_ask_here_august_27_2018/e4x1zwk/) I am able to run things in parallel via tagless final using Cats's Parallel typeclass. However, when using Cats Effect or Monix, I can't use Parallel[F, F]; instead, each use a newtype (IO.Par/Task.Par) for the applicative, so I have to carry around an additional type argument. My function ends up looking like: def doStuff[F[_], G[_]](implicit P: Parallel[F, G]): F[List[String]] = Parallel.parSequence(List(firstThing, secondThing)) I end up having to thread this additional type argument throughout my entire program. I tried defining a ParSequence typeclass like this: trait ParSequence[F[_]] { def parSequence[T[_] : Traverse, ?](s: T[F[?]]): F[T[?]] } object ParSequence { def apply[F[_]](implicit P: ParSequence[F]) = P implicit val ParSequenceTask: ParSequence[Task] = new ParSequence[Task] { override def parSequence[T[_] : Traverse, ?](s: T[Task[?]]): Task[T[?]] = Parallel.parSequence[T, Task, Task.Par, ?](s) } } which works, but it seems like a lot of duplication, especially if I need more stuff from the Parallel typeclass. Any suggestion as to an elegant way to solve this, or am I best off just biting the bullet and threading that extra class through?
 import requests // or could be requests.requests ? No import is needed; once it's added to your `build.sbt` you can immediately do `requests.get`
I’ve adding memcache to a Play app. The @NamedCache features seem really powerful but I’ve come to accept Play is not designed to mix running both EhCache and Memcache at the same time. Not only that, but EhCache has a global instance per JVM that means I can’t use it without turning off Parallel running in the test suite. So I’ve resorted to not using EhCache at all during the test runs. I tried not loading the Play Modules and doing it all programmatically but there’s a lot of initialisation I can’t figure out and EhCache is apparently written in Java. It’s all a bit less than ideal.
 Basically you always need Sbt and to create a hello world project.
This may not be errors, but it is still annoying and I lost time implementing it. &gt; This could be any non daemon thread that still exists. take a thread dump and see which threads those are How do we do a thread dump ?
I'm glad that I am not the only one who dislikes akka http routing dsl
Hi, I've had the same problem. ws-client in Play and ws-client-standalone are *incompatible* with earlier versions of Play because of the versions of Akka they depend on. I pulled something out of the app , ported it to ws-client, realised it couldn't run alongside a different version of Akka, then had to go back and rewrite it out. I went back to a former implementation based on a Java library called "ning" (which I had to shade because tht's what ws also uses), so that also didn't conflict with Play. Anyway, this works: https://gist.github.com/philliptaylorpro/2e5f0e83c8b87879a5e7a29810d5e1b2 
What you're doing is what I'd suggest. I'm surprised cats doesn't include such a thing already - for most cases where a `Parallel` is possible I'd expect there to be a single "canonical" `G` for a given `F`.
Have a look at Vert.X. It's a simple powerful toolkit that doesn't get in your way.
I created some Docker images for `almond`: * https://hub.docker.com/r/popatry/almond-images/ You can run Jupyter with almond kernel from Docker: docker run -P popatry/almond-images:almond-2.12.6-0.1.5
&gt; as a user, you can't do anything about it other than playing with different versions Sure you can: You simply vendor the fixes until you can get your fixes upstreamed. There's no need for any annoying release process or similar. (Also, remember that you it's only even relevant for *immediate* dependencies.) This *used* to be quite tedious with Cabal, but it's trivial nowadays -- you literally just clone the upstream repo and point your cabal.project file at the directory you've cloned to. I believe Stack has also supported this type of vendoring for a long time -- perhaps even since its first release. I don't see why a similar approach wouldn't work for Scala if compile-from-source became a thing.
akka's main use case is large systems where having to do a bit of one-time setup is trivial and having things like logging and contexts set up is more important, it's not really designed for small one-off utilities. Not saying this isn't a problem, just trying to give you a sense of where that's coming from and why it's designed like that. &gt; How do we do a thread dump ? Find the process id (via `jps`) and then use `jstack`.
&gt; Find the process id (via jps) and then use jstack. Didn't knew about those commands. Thanks !
&gt; As a consumer of various libraries I'd vastly prefer just compiling all my dependencies from source and fixing problems arising from my immediate dependencies. That has to do with with the consequences of breaking bincompat being so dire (+unfixable as a consumer) and it's so hard to get right that even the scalac people got it wrong at least once. I would like to challenge that. First, with source dependencies you would also have to fix problems arising in transitive dependencies as well, if you do that. In fact, you would probably have to fix issues more frequently, given the volatility of sources in Scala. Second, bincompat is not unfixable as a consumer, or at least it is as fixable as source-compat. In a situation where you would consider acceptable to fork and fix the source of a transitive dependency, you could just as well publish the binaries of the fix (if only locally, which is not worse than having to recompile from source locally), and then use a simple `dependencyOverrides` in your downstream project. It's even less of a hassle than with sources, because you only need to rebuild the fixed library, instead of all the libraries between it and your application. (unlike what you say in your footnote [1], you do not have to fork all of them) Third, *yes* maintaining binary compatibility it is hard, but as I explain in the talk, maintaining source compatibility is *impossible* for Scala. Between hard and impossible, I know which one I prefer. I am actually afraid of an ecosystem that would be built on source dependencies in Scala. I am convinced it would be a much worse evil. Even if that is counter-intuitive.
Hey people, turns out be broke compatibility by mistake. Fix is on its way, so probably expect a 1.3.1 soon
Eh, as much as I'd potentially be interested, I want something low key where I can do the work and not get caught up in all the hype.. Not to toot my own horn or anything, but I'm actually a talented and experienced developer with a few noteworthy accolades that always draw a lot of attention from recruitment teams, and tend to draw out the most immature culture and I know I'm better suited towards an experienced and dedicated scala team that's a bit off the grid
I find this so interesting. Have other languages come across a need for this? Like is there any prior work on this? Seems to be a lazily constructed collection that optimizes for append/prepend.
So what's the trick?
Thanks for the fix -- I updated the snippet.
Someone let the cat out of the bag!
 I took that course last year. There are no videos recordings that I know of. The book (TPL) explained the subjects in the same way as Prof. Odersky did. However, the books goes into more subject and details, and had exercices which were very relevant for the exams and assignments. TPL's author explains the subjects very well.
It uses more case classes than `List`'s `::`/`Nil`. This way it can represent concatenation – case `Append` – and conversion from other sequences – case `Wrap` – in constant time. The catch is that while it's fast to do bulk operations such as `map` and `fold`, it can be asymptotically slower to decompose progressively like you may do with a list, as was pointed out in the comments. I wonder if a linearized version could be cached internally using a `ListBuffer` to avoid that.
All that said, the best thing you can do to preserve the ability to migrate your codebase in the future for your company is to not depend on scala libraries. I realize this may be controversial, and personally I find it a bit distasteful, but when it comes down to it, if you depend on, for example, msgpack-scala_0.6.0_2.11 and would like to migrate to scala 2.12 you are stuck, but if you instead depended on msgpack-java_0.6.0 and want to upgrade to scala 2.12, 2.13, whatever, go for it, it just works. I'm starting to wonder if the cost of some of these wrapper libraries is worth it. Of course if I had source-deps for msgpack-scala_0.6.0 it would likely compile with scala 2.11 and 2.12 just fine, with absolutely no issues, but the author does not want to support msgpack-scala any longer which is a reasonable decision for them to make, which leaves me with the decision, do I move to the java dep, use an internal source-dep (which leaves my company now maintaining it internally), make an upstream pr which will never be accepted. I chose java in this case, but wouldn't have had to make the choice with external source deps (say a link to a github commit hash). Anyone have options they consider better in this scenario? 
Note, these are different data structures. Chain is optimized for concat so it has O(1) concat and O(log N) head/last/tail. The Haskell implementation you linked to makes the opposite trade: O(log N) concat but O(1) head/last. There are many immutable data structures which make different trades. We should have more implementations in scala to reach different points in the space.
Oh, thanks, mislooked it
&gt; At what price does this perfection you speak of come? I'm used to writing code, then testing code because I find it's not all perfect, even those scala stdlib binary deps. I guess if you can really promise perfect, never a bug from switching versions, maybe it's worth any price, but you must admit that's not really what is being offered, because source or binary deps, there will still be bugs from upgrading versions (and also that those bugs can be caught by testing in many cases). The price of perfection is, as a library maintainer: * use MiMa, always; enable it the moment you've published version 0.0.1 of your library * don't filter out MiMa warnings, unless you know what you're doing, or unless you're willing to make a breaking release * in order to know what you're doing, learn how Scala signatures map to binary signatures The last step is the hard one, of course. It requires actual learning, training. But if you get there, you *can* offer perfection. Scala.js has been perfectly backward binary compatible for 26 versions spanning 3.5+ years. &gt; Is there a difference in time to delivery for source deps vs binary deps? Not sure. I think it mostly depends on what a developer is used to do on a regular basis. I'm used to publishing stuff on Maven repos, so it takes negligible time for me. I have never really set up a serious source dependency, so that would take me a while. It would probably be different for different people. &gt; In difficulty of fixing a bug? It depends on the bug. Some bugs are more easily solved at the source level, some are easier to deal with at the binary level. For example, when implicit resolution is involved and some subtle changes in the library, your code using the implicits might be broken. Solving such things in the library can be tricky at the source level, because more changes to the implicit scope are likely to break more stuff. At the binary level, you could simply reintroduce the problematic method as a non-implicit def to fix the bug. &gt; In what happens when the maintainer isn't available for a few months? That doesn't change much. You publish your fork on your own. And I mean that by either publishing sources or publishing binaries. &gt; Is there any difference in the difficulty of taking a dependency that may be published with a build tool different from what I currently use, and have never used, and building then publishing it (anyone out there struggle with publishing form time to time?) then depending on your own artifact? This question is very much in favor of binary dependencies, actually. That's because each project will be built by its own build tool, using its own build configuration, in isolation. So the only difficulty is learning what commands to issue to the build tool to make it build and publish (if you're lucky, you find those in `.travis.yml`). With source dependencies, you suddenly have several builds using several build tools that need to interact. I wish I never have to deal with such a situation. &gt; Do you even have your own private artifact repository, or are you just a hobbyist doing something on the side? If so, do you want to publish a fork of someone else's project that the whole world can access? Say I depend on an old version of scalacheck that is no longer updated, but it compiles and all tests pass just fine with scala 2.12. Do the cost of me just changing the scala version vs publishing and depending on my own version play into your preferences or is it not even on the radar? IMO, if you're a hobbyist doing something on the side, unless you are used to publishing stuff on Bintray/Sonatype, I would recommend to publish locally. This is probably what you would do for your own little libraries anyway. That's assuming an ecosystem of binary dependencies. With source dependencies, this step should be easier on the hobbyist. If you want to make it available to the rest of the world, you basically become a library maintainer. Whether that means publishing sources or binaries doesn't change much, I think. &gt; Whether it comes to source vs binary deps or making classes final by default sjrd, you express similar disregard for the expense of upstreaming a change vs implementing it locally (as here for example https://contributors.scala-lang.org/t/make-concrete-classes-final-by-default/2058/51?), calling anyone who would do this short sighted and the decision accidental. I called the *arguments* short-sighted, not the people. And I called accidental some facts about non-intentional design of the library (if it is intentional to leave a class non-final, then of course you can extend it, but then also the author would mark it `open` if final was the default). It's hard enough for me to convey my thoughts in writing without offending anyone. Please don't make my written words even worse than they are to begin with ;-) That said, if that is how some people interpreted my words, I apologize. To me those are significantly different things. I have short-sighted ideas, opinions and arguments all the time, like most people I believe. I try not to make short-sighted *decisions*, though, which requires that my short-sighted opinions be detected and pointed out by other people. &gt; Is it really so hard to believe that I may think through the costs of upstreaming a change to a library, bake it off against the feature I am being paid to deliver this month, and decide the most responsible thing to do is to over-ride a class in a library, make a pr to upstream, add a todo ticket to remove my override on next upgrade if the maintainers accept it in 3 months, then finish my ticket and move on to the next thing I am being paid to do. What if the maintainers are away for months? Should I just hold off on the change for a few months and tell my employer that using an over-ride and shipping the feature now would be accidental? Obviously I don't know your day to day workflow and how things are done at your employer, but is it conceivable that things are done differently at my place of employment and there may be multiple reasonable workflows? My employer is EPFL and pays me, among other stuff, to maintain Scala.js, which is an open source project. My arguments will always be biased in favor of library maintainers (and I'm quite happy that I am reminded of the realities elsewhere, even though the post I'm writing is probably going to look pretty defensive; because it is, I guess). As a library maintainer, leaving holes open that people can exploit in one version is dangerous. Because people will exploit them, and then I won't be able to plug them or evolve my library. Because if I do, no matter what reasonable developers like you say about forgiving my breaking "internal" APIs in future versions, there *will* be *unreasonable* developers who will attack me. We've seen enough burnt out open source developers that I think I need to protect myself against that. Given those constraints, I'm afraid that yes, I expect companies using my libraries to fork and publish fixes for themselves if they're not happy with my release cadence (2 months for Scala.js). That includes making a class non-final if that is what they want. All that being said, I still do believe that doing so is not harder with a binary ecosystem than with a source ecosystem. &gt; If it really comes down to education It probably doesn't. It is very possible that there are facts about your setup/company/workflow/etc. that I don't understand or am not even aware of, and that would make my opinion flawed. Given the information I have and understand now, however, I remain convinced that an ecosystem of source dependencies will be a much bigger burden on everyone than binary dependencies. I guess we'll see whether Fury proves me right or wrong.
Woohoo!
I feel like a brainlet when I open this book. It is too hard for me :(
I accidentally posted to the GitHub repository instead of the release notes: https://github.com/typelevel/cats-effect/releases/tag/v1.0.0 If any admins can edit the link, I’d appreciate it.
You can solve tasks from coursera course on scala - they involve some functional programming and laziness(Streams mostly). Also consider solving small tasks from hackerrank(or any similar platform) using functional programming style. Also if you would like some practice on functional programming basics please consider [https://github.com/dehun/learn-fp](https://github.com/dehun/learn-fp) &amp;#x200B; &amp;#x200B;
A bit of feedback -- the README doesn't really illustrate \*what\* Cats-Effect is used for. Some examples would go a long way!
I think you're going to have a harder time getting a remote position as a junior dev for sure.
Is it more risky to take juniors as remote? What disadvantages are there?(simply curious)
I think it's more like, junior devs will probably need to be mentored/worked with closely/have their work more nicely boxed up and given to them, and might be harder to do that from long distance. Plus, as a Senior developer you've likely acquired some somewhat specialized skills that make employers willing to broaden their horizons, while there isn't as much to distinguish one entry-level developer from an other.
Makes sense. Anything I can do to compensate then? Ill try to apply around and if all else fails I'll just have to suck it up
&gt; like open source contributions Despite the good intentions, I've never heard of anything like this tipping the scale in favor of a candidate. You would probably have to be knee deep in a project or several as the lead contributor for this factor to be material, not someone questioning whether or not to do it.
There is a link to the documentation in the first sentence: https://typelevel.org/cats-effect/datatypes/io.html Is this link what were you looking for? Do you think it needs more exposure?
Even if I am still not in full agreement, I really appreciate the detailed responses. When I asked "at what cost" I was referring to the cost to the user, you responded with the price to the library author, but in the end that is probably my largest sticking point. You describe a wonderful world I have no faith will ever come to pass. I have probably over 100 dependencies (never counted actually) and the chances that all of their authors will take the steps you advocate seem slim. I guess we'll see whether time proves me right or wrong ;)
I would say that for your very first development job, open source contributions can look very good and make you stand out maybe in a University co-op program among other students, but in the upper junior - intermediate - lower senior levels I don't think most recruiters or employers seem to care at all about open source contributions. Recruiters especially ask really silly questions like "How many years of professional SQL experience do you have?" and it seems really silly to me to quantify this in terms of years.
I like circle-ci myself. It's been some time since I played around with it but it still does its job and I much prefer it over wercker and, well, Jenkins.
Gitlab
I've worked remote as a Scala dev but I can operate pretty much autonomously. I think it would of been very difficult and frustrating for both sides if I attempted in early in my career.
Tbh I'd be willing to work 7 days a week if it would somehow help. Do you have any ideas of how I can compensate? Maybe even work for free for a while? I just really like my life here but I also like scala and FP lol 
What if I master everything in the FP in Scala book? :D 
d'oh res0.unsafeRunSync :-)
Junior devs need guidance, I suspect that would be challenging to do that remotely.
I'd be curious to hear more about what you think the underlying cause of the failures you're seeing is. (My own experience, anecdotal of course, is that I maintain or contribute to a bunch of projects that use Travis and haven't been dissatisfied, either in general or in recent days.)
It's definitely possible, my first job as a developer was with a London company and I worked remotely from Canada. I was a major core contributer to the Akka project at the time though, so the only reason companies were approaching me was because of that. So my advice is that if you do go that direction be prepared to put in at least a few hours a day at making contributions to a well known and used project and work your way up to being an important part of that project.
[Are you talking about this book?](https://www.manning.com/books/functional-programming-in-scala)
Yes
See if this library is helpful: https://github.com/ChristopherDavenport/cats-par
This is perfect. Thank you!
Does anyone know of a more detailed description of "match types"? The best I can find is an [example of a problem](https://github.com/lampepfl/dotty/pull/4964#issuecomment-417221115). Odersky mentions: &gt; Revert from rewrite methods to the preceding scheme for inlining.
Quick googling gave me this : https://blog.jetbrains.com/scala/2015/10/14/intellij-api-to-build-scala-macros-support/
Yeah, I saw that, but is from 2015, so it’s the old macro api, furthermore the links they put as examples give 404 on GitHub so it’s not a reliable source I’m not expecting people to google stuff for me, if I’m asking is because I did it already and couldn’t find what I’m looking for 
I really like /r/lihaoyi 's work in general but I was a bit surprised by this library. I get that it's convenient and easy to learn, but it's ignoring pretty much all strengths of Scala: async, type safety... It's probably good if you're writing a small script, but any bigger app I wouldn't recommend it.
I found this in the PR: https://github.com/dotty-staging/dotty/blob/a7ea1053f699baeba8eb9d279f811f93dc463735/tests/pos/matchtype.scala
The links inside the blogpost are indeed outdated, but you can check out our wiki page on GH: https://github.com/JetBrains/intellij-scala/wiki/Library-Injector Under "Available extension points" you can find links to the API and example usages you'll need to implement support for your library. Regarding the distribution model there are currently two options: publishing a standalone IntelliJ plugin which depends on Scala plugin(described in 2015 blogpost), or publishing support as a jar alongside with your original library(the GH wiki link) You can also get additional help on our gitter channel https://gitter.im/JetBrains/intellij-scala or even ping me there directly
Thanks for the hints, I’ll check it out over the weekend!
I've \_definitely\_ heard of OSS work tipping the scale. But it has to be significant, like being a core contributor. Especially if I were hiring someone remote, this would be useful data because it would literally show they could contribute as a remote developer.
I think point 3 here is especially important. In my experience you will progress much quicker when co locating with senior devs me
Does anyone know how easy it would be to add random access to this data structure? Like Vector's apply(n) which calls getElem(n) and updated which allows you to mutate a value at position n. Looking at the code it wasn't clear to me. Would be nice to have take and drop too,
Intellij has this and also scala.meta annotations expansion: https://blog.jetbrains.com/scala/2016/11/11/intellij-idea-2016-3-rc-scala-js-scala-meta-and-more/ e.g. [freestyle](https://frees.io) macros are recognised by Intellij correctly.
The new release breaks: "org.typelevel" % "cats-effect\_2.12" % "0.10.1" code.
This release is not compatible with 0.10. You have to upgrade your code. Biggest changes are probably related to `ContextShift`and `Timer`
My favourite ones are - Web Crawler - Using Akka Streams to poll a service(weather for example) and trigger a warning if weather is too high for some time(&lt;30c for 10 hours) 
Real-time trading engine. Could exercise streaming data, analytics, and you could make a simple web portal to view status in real-time with Play. I am doing this “for real” at this time. 
You can easily implement them e.g. using its `iterator`, but it'd incur a runtime of O(n) in the worst case
I have question regarding Scala Promise . I want to assign prmise.future to some other future task which matches with promise.future. But getting error . Same thing is working if used with promise.completeswith(future) &amp;#x200B; See code below:- `var p = Promise[Option[User]]()` `// not working` `p.future= userRef.get().map(snapshot =&gt; snapshot.getValue(classOf[User])) // gives future[Option[User]]` `p.future.foreach(x=&gt; print(x.get.email))` `//working` `var a =userRef.get().map(snapshot =&gt; snapshot.getValue(classOf[User]))// gives future[Option[User]]` `p completeWith(a)` `p.future.foreach(x=&gt; print(x.get.email))` 
I see, thanks
Not sure what the problem is though, with the second example. Is it not a good solution for some reason?
&gt; I have no idea how the scala-native guys do/will deal with this kind of thing, but it can completely sink a running system. Hence my hatred of just 'relying' on bincompat. I want errors up-front goddamit! You should be happy with Scala Native then (and Scala.js). In both, binary incompatibilities are caught at \*link\* time. Technically different from \*compile\* time, but definitely fits the \*upfront\* requirement.
We're now relying on so few Scala libs, that I'd actually forgotten that Scala.JS does yield linkage errors at link time. Glad to hear that it also applies to Scala Native! Unfortunately, this doesn't apply to the Scala.JVM, which is kind of the main platform which runs the *really* important bits of our applications (i.e. scheduled tasks, etc.), so that doesn't help me much :/. Btw, I really appreciate your responses even though we may lean towards different conclusions. I think this is actually a *really* interesting problem.
As far as I know, removing null from reference types is being considered for 3.1, to be replaced with `String | Null` for nullable types. It's too much of a breaking change for 3.0 of I recall correctly.
What are the correct imports for Unit Testing keywords for , fail("a message") x should be &gt; 100 I have tried import org.scalatest.Matchers._ import org.scalatest.Assertions._ import org.scalatest.FunSuite import org.scalatest.MustMatchers._ And I also extended my testing class with class MyTestingClass extends FunSuite with BeforeAndAfterEach { Absolutely none of the above strategies work. "should" is perpetually highlighted in red as unresolved. The fail("a message") resolves but underlines a squiggle in my IDE. The reported error here is Method apply is not a member of type Nothing. Method isDefinedAt is not a member of type Nothing. Googling these error messages verbatim goes nowhere. The bulk of unit testing websites just tell lies about which imports match unit testing keywords. Your thoughts? 
sounds fun, is there a public source of data / streams you're using?
Many brokers offer APIs for streaming data for any market they trade. Data subscriptions may have a $0 to $2 to $100 cost per month; mostly on the lower side. Fidelity, ETRADE, Interactive Brokers would be large brokers to investigate to see the differences. Crypto exchanges like Binance or Coinbase are another interesting market. Both of these are free to make an account and you could buy $5 of BItcoin to experiment with for trading. People don’t realize this but you can literally trade like $1 of Bitcoin — much cheaper to test a trading engine on compared to a few hundred dollars for a stock or FOREX position. The other, less reliable option would be searching for something like “free FOREX streaming data.” There are plenty of providers but many are unreliable and the data streams may die at times. I don’t have any of these to recommend. I intend to use my traditional and crypto brokerage accounts (some/all of those mentioned above) in the long run. Starting with Coinbase or Binance would allow you to test the full cycle (data, analysis, decision making, trading) at minimal cost. 
Since I liked programming in Scala, for my Google interview, I asked them to give me a Scala / functional style question. The Scala functional style question that I got was as follows: &amp;#x200B; You have two strings consisting of alphabetic characters as well as a special character representing the backspace symbol. Let's call this character is '/'. When you get to the keyboard, you type this sequence of characters, including the backspace/delete character. The solution you are to implement must check if the two sequences of characters produce the same output. For example, "abc", "aa/bc". "abb/c", "abcc/", "/abc", and "//abc" all produce the same output, "abc". Because this is a Scala / functional programming question, you must implement your solution in idiomatic Scala style. &amp;#x200B; I wrote the following code (it might not be exactly what I wrote, I'm just going off memory): &amp;#x200B; **def** processString(string: String): String = { **val** result = string.foldLeft(*List*\[Char\]()){ **case**(accumulator: List\[Char\], char: Char) =&gt; accumulator **match** { **case** head *::* tail =&gt; **if**(char != **'/'**) { char :: head :: tail } **else** { tail } **case** emptyList =&gt; **if**(char != **'/'**) { char :: emptyList } **else** { emptyList } } } result.mkString } **def** solution(string1: String, string2: String): Boolean = { *processString*(string1) == *processString*(string2) } &amp;#x200B; So far so good? He then asked for the time complexity and I responded linear time (because you have to process each character once) and linear space (because you have to copy each element into a list). Then he asked me to do it in linear time, but with constant space. I couldn't think of a way to do it that was purely functional. He said to try using a function in the Scala collections library like "zip" or "map" (I explicitly remember him saying the word "zip"). Here's the thing. I think that it's physically impossible to do it in constant space without having any mutable state or side effects. Like I think that he fucked up the question. What do you think?
I haven't written the code but I think I have a solution. Hint: process the strings right-to-left.
&gt; Crypto exchanges No, fuck that bullshit
I mean I know that if I was doing it in C++ the String would be a null terminated character array and I could basically create two pointers, one to the end of each string and I would be decrementing my way to the front. If the character is not a backspace, I would check that the characters are matching. If it is a backspace, I could decrement the pointer until I skip over a number of characters equal to the number of consecutive backspaces I encounter (stopping when I get to the first character of the String). That being said, this is very much NOT idiomatic Scala.
We had a jr. candidate who had contributed a bug fix to a major project and to me, that showed the candidate could write production-level code, could read code other people wrote, and could take some initiative to solve problems beyond the basics. I think it's a pretty strong signal for a jr dev.
Possibly all true. The mechanics are the same and you don’t have to risk hundreds of dollars and spend several dollars in commissions for each trade. Ignore this guy. 
The frustration is more related to being stuck for long stretches. 
no, the mechanics are not same because buttcoin is all price manipulation by the exchanges. There are no regulations so the price can be whatever the exchanges want it to be. Whatever thing you coded up to predict the price manipulation will fail miserably when you try to apply it to real money. You can also trade against real money exchanges using historic data and that won't cost you hundreds of thousands either.
The latest version of the description is: https://github.com/lampepfl/dotty/blob/9897d228b64607365c541ac2393f7c0361768206/docs/docs/reference/match-types.md 
I am not able to understand why promise .future assignment is not possible?
I just use JUnit, `org.scalatest.junit.AssertionsForJUnit`, and `org.scalatest.mockito.MockitoSugar`.
I use ScalaTest but mostly just use `assert(result == expected)` because I don't like the pseudo-english matcher syntax. I chose ScalaTest for our new project because the team already knew it (I was using specs2 before). If I was starting a new project today I would probably check out a testing library such as `testz` instead of using a traditional framework.
Better ask on stackoverflow
Thanks for the tip, appreciate you spending the time for that 
Really solid advice! Do you think I should do this after the second part because it actually covers functional design? 
Akka doesn’t really use any of that which is part of what makes it cool. I think you will want to be comfortable with Scala in general but otherwise I would go ahead and dive right in.
Thank you a lot. I have kind-projector but not partial-unification. It looks much smoother now with just EitherT.pure(()). 
uTest works quite well, in scala.js is attractive as it compiles faster than scalatest 
[https://doc.akka.io/docs/akka/2.5/dispatchers.html](https://doc.akka.io/docs/akka/2.5/dispatchers.html) &amp;#x200B; It uses executors under the hood.
Finally found somebody who doesn't approve of the fad. Who the fuck even thought it is a good idea? 
The flexible syntax is just to accommodate different testing styles. Some folks like to write proper English, and others don't. &amp;#x200B; Just pick the style that you like and use it? If you need your test framework to enforce the way you write tests, ScalaTest definitely isn't for you.
It's only one of the styles, but it's the most prominent in the docs. I prefer assert with === nowadays, with the DiagrammedAssertions trait for the nicer failure messages.
Note that that particular one doesn't always infer (note the explicit signature I had to put). Btw you should come on gitter, for example typelevel/cats, you'll get a much quick answer there.
Go for it, you already know enough to get started. Learn by doing (and occasionally reading up)!
I'd say that the only thing you really need to understand is how thread pools and executors work if you're doing blocking I/O (e.g. databases), and to be careful about closing over actor state when creating futures or threads. But because receive is running serially for a given actor, and actor state shouldn't escape the actor, there is only one reader and one writer for an actor's state. This removes the need for most concurrency primitives, like locks and semaphores. If you want to read or write to an actor's state from another thread, you just send a message asking to read or write, and that message will be processed in the order it arrives.
I prefer utest because utest supports sharing nested logic. Scalatest, for some reason, strangely doesn't support this. It also doesn't support more than 3 levels of tests. For example: describe("aaa") { describe("bbb") { doSomething(); // This is executed only once for these 2 tests. it("ccc") { // This doesn't work } it("ddd") { // This 3-level nesting doesn't work. } } } PS. I use FunSpec because I like fun.
I found [https://danielwestheide.com/blog/2013/02/27/the-neophytes-guide-to-scala-part-14-the-actor-approach-to-concurrency.html](https://danielwestheide.com/blog/2013/02/27/the-neophytes-guide-to-scala-part-14-the-actor-approach-to-concurrency.html) handy when I was first grasping actors. &amp;#x200B; Are you familiar with the immutable/functional approach to concurrency? Actors are super cool and can be quite handy, but I think the immutable/functional style of concurrency is probably more useful most of the time and might be worth learning first.
Yesterday I watched video about Typescript's null-safety and flow analysis. It is freakin amazing! Checks every branch for types etc. I'd love Scala had that.
Uhm, I do this all the time in scalatest....(I'm pretty sure I'm right, I don't have an example handy) The third level nesting is totally allowed, IIRC. I don't think there's even a limit to the level of nesting.
You're right. I'm not sure why I remembered I encountered the error from nested \`describe\` before.
I'd love to understand the logic behind that. It's breaking too much, so it's not shipped in a major version, but in a minor one?
Truly non-nullable types are tricky because Scala does not prevent you from reading a field before it's been initialized, and uninitialized fields are set to null (or 0 for primitives). https://github.com/lampepfl/dotty/pull/4543 is an attempt at making initialization in Scala safe. If this succeeds, there's a good chance we'll get non-nullable types too.
Ahhh, yeah for this simple matter I suppose gitter would work way faster. Thank you
Hmm yeah that does seem weird, maybe I'm misremembering..
I didn't know about DiagrammedAssertions, and now I'm itching to try it for my project. i've been sticking to small tests cause error messages when you get more than a little complex become nightmarish. DiagrammedAssertions looks like it might make that a little nicer to deal with
You mean, doing symbolic manipulations like SymPy so you could get: sqrt(8) res: 2*sqrt(2) If so, you could look at Galileo. But I'm not sure how well designed it is. 
If you could derive client and server from one single definition, could you also derive swagger ? Or a javascript client ? Also, strange operators like `:|:` or `:=` make the code barely readable.
Hi, there is already a sub-module deriving a JS client called js-client. regarding Swagger, that is possible but I didn't get around yet to do it. And regarding the syntax, there are two dsl available. One which is inspired by Haskell - which is also the case for the whole project - and one which is more function call like (see this example).
 [Hi , ](https://medium.com/@atp.iitk/hi-7210ff1b2306?source=responses---------0---------------------) [this code as well as your github is compiling but intellij is giving error on mouse hover :-](https://medium.com/@atp.iitk/hi-7210ff1b2306?source=responses---------0---------------------) [http://tinypic.com/r/95pq4w/9](https://medium.com/@atp.iitk/hi-7210ff1b2306?source=responses---------0---------------------) [Could you tell what is the issue](https://medium.com/@atp.iitk/hi-7210ff1b2306?source=responses---------0---------------------)
[teztz!](https://github.com/scalaz/testz)
I agree. I think even small change like renaming operators would help: val MyApi = // GET {body: User} /fetch/user?{name: String} (root / "fetch" / "user" / Query[String]('name) / Get[MT.`application/json`, User]) ++ // POST {body: User} /create/user (root / "create" / "user" / ReqBody[Json, User] / Post[MT.`application/json`, User]) I think for many people this would already be more readable. If you allow reordering get/post and req/res to be more like query: get[MT.`application/json`, User](root / "fetch" / "user" ? query[String]('name)) But I am quite used to Akka-HTTP routing so take it with a grain of salt.
Looks more readable to me.
`Promise.future` is not a field you can assign; it's a method returning a `Future`. That `Future` will complete and hold the first success or failure value given to the `Promise` from which it was created.
Just out of curiosity, why did you need ScalaJS? Because I'm also planning to make some components for revealjs in Hepek (which is just a static file generator). :D
I actually made a SIP (or SLIP) request for this and iirc Martin said this wasn't really possible to do generally, it would be nice if we could integrate this work into the official scalac
Actors are mostly useful for error handling hierarchies and distributed programming. In case if those two are not the main concerns - other models will suit way better because of more strict typing. You can use various IO/Task/Future monads and you can also use akka streams - they will be more managable. &amp;#x200B; As for error handling hierarchies - see [https://doc.akka.io/docs/akka/2.5/general/actor-systems.html#hierarchical-structure](https://doc.akka.io/docs/akka/2.5/general/actor-systems.html#hierarchical-structure) As for distributed computing - see this article - [https://www.the-paper-trail.org/post/2014-08-09-distributed-systems-theory-for-the-distributed-systems-engineer/](https://www.the-paper-trail.org/post/2014-08-09-distributed-systems-theory-for-the-distributed-systems-engineer/) &amp;#x200B; Also if you have some spare time/interest you can learn erlang and OTP framework. &amp;#x200B; &amp;#x200B; &amp;#x200B;
There is a comparable api/dsl available, as I pointed out in my reply to /u/gbersac. Just take a look at the README or the example given in this post. If you would like to see something like get(...) instead of api(Get ...) Feel free to open a PR to add functions ;) (honestly, PR are highly welcome)
Because I wanted to scrap some boilerplate and I know Scala :). I mean now I can spare me some HTML code I needed to write which was just plain repetition and I get headers without writing a line of JS for every slide.
I was going to propose a SIP myself after getting implementation right, but I saw when implementing implicits for `=` bindings that it's not that simple. It's hacky enough I decided to make a milestone release instead of a proper one :) There was some discussion for `point` to be used instead of tuples for `=` bindings [here](https://github.com/lampepfl/dotty/issues/2573), and that, if done, could make the change nice and possible.
Why not just ask questions in the sub itself? I’d rather see questions by people and discussion in the sub, and all the blog spam posts corral to a single sticky!
Does there javascript equivalence of bindi ng.scala? I recently am learning Vue.js. I hate it because it adds so many extra language feature and rules and corner case , the language is too exotics to me.
Yeah i just meant from a syntax/usage point of view. All of that will be hidden if you stay within the actor system. 
Some questions are so small and one-off that it's not really worth a whole thread. Asking these questions as their own thread are not forbidden at all, but this thread is here for people to ask "quick questions" which they don't want to form into a well-written post or whatever.
&gt; Does there javascript equivalence of Bindi ng.scala? Can you repeat/clarify your question?
There are also typed actors, although with a bit higher of a learning curve. Also, I'd add that actors are good at implementing mutexs around shared resources. That said, I agree that the higher level tools you mentioned are probably a better choice, where possible. 
Try scalatest’s FunSuite style. No funny dsl to learn. Just test(“name”) { assertResult(4)(2) }
I'm a little confused by the suggestion that side-effects work better with lazy evaluation. I was under the impression that the two were essentially mutually exclusive, because in a stateful environment a lazily evaluated expression could evaluate differently at different times.
Typed actors would be great. However they are simple not there - still experimental and not suitable for use in production. [https://doc.akka.io/docs/akka/2.5/typed/actors.html#introduction](https://doc.akka.io/docs/akka/2.5/typed/actors.html#introduction) [https://doc.akka.io/docs/akka/2.5/common/may-change.html](https://doc.akka.io/docs/akka/2.5/common/may-change.html) &amp;#x200B;
I'm not sure if the example misses some context, or if people got side-tracked with their projects again. The question whether you can assign a "better" type to something that is clearly `T|Null` by showing that a value is written to before it is read is certainly an interesting question (largely around ergonomics), but completely orthogonal to implementing explicit nullability.
Got it. That'll be a tough project. Might help to check out the free screencast from Destroy All Software about building a compiler from scratch https://www.destroyallsoftware.com/screencasts. It doesn't use a functional approach, but still may help. 
Also been working on [using structural sharing] when concatenating HashMaps, which allows us to combine HashMaps without visiting each tuple in the maps. 
I believe he's asking if there exists anything in js which is like Binding.scala. Afaik there is not
Very cool, I've wanted to do something like this myself but never put in the time :)
Yeah, the way I'd look at it is that you get some more architectural reliability at the cost of exposing yourself to migration risk. Pick your poison. But considering I don't think most people should be creating a whole bunch of custom actors or knitting their business logic into their actor implementations, it should be possible to protect against that migration risk.
Those phrases are a bit fancy. A simple way to think of tagless final encoding is just that you abstract out the effect type of your API trait. e.g. if you have an API trait like ``` trait MyApi { def doSomething(id: Int) : Future[String] } ``` Abstract the `Future` out ``` trait MyApi[F[_]] { def doSomething(id: Int) : F[String] } ``` This will liberate your whole program from being coupled with `Future`. Now `F` can be anything, it could be `Future`, it could be a `Future[Either[String, ?]]` it could be `IO`, when you write the whole program though, you don't need to care about it. 
I like to think about tagless as DI + effect (sync/async, pure/impure) abstraction. Works well to explain the concept to OO colleagues.
Yup, DI as well. 
Yes, fucking awesome! Will have a look for sure, although I believe that Tagless final is so basic that not many helpers would be needed...
Hey sorry, this article is very close, but I think slightly too off-topic for this subreddit. Maybe if this post were a self-post with some kind of body of text to start a discussion, it would be more appropriate, but as it is it seems not very relevant.
Very nice explanation of the abstraction!
Do you have a plan in place to move away from scalameta paradise? Or some way of getting new updates?
After going through it, it seems to solve a certain kind of issues one encounters when being on a more advanced level than I am. The stack safety for example is kinda cool. Thanks /u/kailuowang for the awesome contributions to the Scala community
Highlights: * New dark theme * Windows gaming improvements * Enhancements for generative art * Embedded mode for devices like the Raspberry Pi * Improvements to the Kojo-Arduino bridge * Scala upgrade to 2.12.6 More info in the [release notes](https://kojoenv.wordpress.com/2018/09/02/new-kojo-release-2-7-03/).
Great post, thanks for sharing! One thing I disagree with is this sentence: &gt; Consider a scenario where you want to serialize a tagged value to JSON using play-json. play-json has a contravariant typeclass for this: Writes[-A]. Since A @@ B &lt;: A then Writes[A] &lt;: Writes[A @@ B]. This means you do not have to write a single line of code to implement JSON serialization. For instance, Writes[Int] &lt;: Writes[Int @@ UserId], which implies that the default implementation will be picked up. That’s a much bigger problem with the case-class approach, where you simply need to re-implement everything and, as explained in the next section, it turns out that you cannot really do this as generically! I'm not sure about `play-json` but with `circe` this is only two lines for value classes: ```scala implicit def valueClassEncoder[A: UnwrappedEncoder]: Encoder[A] = implicitly implicit def valueClassDecoder[A: UnwrappedDecoder]: Decoder[A] = implicitly ```
I made similar comparison [myself](https://kubuszok.com/2017/tagged-or-anyval/) some time ago so I would add that this is quite important when you are choosing your poison: * value classes are standardized, so virtually every library that generates instances supports it. However, you cannot rely on promise that compiler will always remove overhead (also, good luck mocking returning AnyVal values - compiler and frameworks cannot agree whether it should be boxed or unboxed type) * tagged types have no one standard - Shapeless has one, Macwire has one, I think some other library also had one... - no one support them out of the box, but since this is just a compiler trick you can easily lift and \`T\` to \`T @@ U\`, but also \`M\[T\]\` to \`M\[T @@ U\]\`, etc so whatever you pick there will be some pains to deal with.
You can create an Object for the base trait and implement an unnaply method that extracts the field/fields you're after You would still have to implement the match statement but at least the bulk of it would be centralized in the object . The other alternative I can see is trying to use shapeless and deconstruct the obj into a tagged HList and extract the field you're after.. I'm not 100% sure of the details or if it would work but from what I can gather those are your two only options..
It's using ScalaMeta for the macros, which IntelliJ supports natively. I haven't tried this library, but maincoon and freestyle (on which it's based) both work fine in IntelliJ. You can even click an icon in the gutter to automatically expand a macro and see the generated code. 
&gt; bunch of traits like HasA, HasB, HasC (...) But this doesn't feel like a great solution. sealed trait Thing { def a_? : Option[A] = None def b_? : Option[B] = None } sealed trait HasA extends Thing { val a : A; override def a_? = Some(a) } sealed trait HasB extends Thing { val b : B; override def b_? = Some(b) } case class One(a : A, b : B) extends HasA with HasB case class Two(a : A) extends HasA case class Three(b : B) extends HasB 
I've found all the fancier test libraries to be more trouble than they're worth; I stick to plain JUnit and find that makes it much easier to see what any given test is actually doing.
Why the question mark? 
Note that there's already a mostly complete but under-tested xml interpolator implementation for Scala 2: https://github.com/densh/scala-xml-quote
&gt; I'm very grateful to eed3si9n for starting the conversation and showing us how to make this kind of program. What exactly is the conversation started here? How to interactively work with the console on the JVM, or write a functional game loop? Eugene's post seems to be clearly about the former while for some reason you're focused on the later.
Hello, For a challenge of the "Essentails Scala" book I have this solution : h[ttps://scalafiddle.io/sf/e0S0cxD/0](https://scalafiddle.io/sf/e0S0cxD/0) &amp;#x200B; Can I refractor this so it's better Scala. I did not learn things like for/yield yet
The PR you linked to doesn't remove xml literals. And even if the dip is accepted it's likely that support for xml literals will be kept in 3.0 but marked as deprecated.
My understanding was that removing xml literal was a done deal
I don't think you can disentangle those aspects? If you're going to access the console in a game-style program then how you interleave that with the rest of your program is a concern you can't ignore. 
&lt;Goodbye, XML?&gt;
Be explicit. Give concrete examples of the benefits. What problems does Scala solve? Why does it solve them better than the alternatives? What are the cons of Scala? If you just say "another team used this and I liked it" you won't get far.
Change peoples mind is really hard, but as a person who really wanna use Scala in my current job, I'm doing weekly workshops focusing initially into APIs like Scala collections and functional programming concepts.
Thanks, I had to solve this very issue myself some days ago.
How new are you to the startup? You might want to try to understand their decisions behind going with those languages before trying to introduce anything new.
Changing a language is a very difficult decision. Even if we had a language that is far superior than anything, familiarity/expertise would still be the triumph criterion(?). One good plan of introducing Scala is to use it on a small low-risk system. With this way, you can show how great Scala is. You'll also need to earn your team's trust by being a great engineer (e.g. finishing project, willing to refactor, and other usual things) because you'll become the only Scala expert for others to learn from. \---- Now let's do some talking points: * C++: we should never use C++ for anything unless we have an explicit reason to do so. Writing anything in C++ would litter codebase with memory corruption and security vulnerabilities. One reason for using C++ might be: you need the speed that other languages can't give you. Think of Google Chrome. It needs to be the best of the industry and ten milliseconds faster is critical. Using Golang/Java would be unacceptable. In the present time, using Rust might be a better choice. * Python: no type safety. This becomes a huge maintenance pain as the system grows bigger and older (e.g. upgrading pip package, refactoring). Using dynamic language (e.g. Ruby and Python) is very punitive if you initially use a wrong design. * Go: Go is like speaking English with 7-year-old vocabulary. It will be verbose trying to capture complexity of your requirements. Go aims at specific goals (e.g. compile much faster than Java, difficult to make mistake, easy to learn). It is created to solve Google problems (e.g. large codebase that takes hours to compile in Java , many engineers writing code with inconsistent quality, onboarding thousands of engineers every year). Fun fact: Rob Pike, Go creator, said that newbie engineers were not capable to understand brilliant languages; They won't have problems with learning Golang though. ([http://nomad.uk.net/articles/why-gos-design-is-a-disservice-to-intelligent-programmers.html](http://nomad.uk.net/articles/why-gos-design-is-a-disservice-to-intelligent-programmers.html)). For a smaller company, I'd avoid Golang. For me, Scala seems to strike a good balance. Type safety, less verbose than other typed language (e.g java, go), Decent performance (e.g. faster than python, slower than Java). Two disadvantages of Scala are, of course, slow compilation and steep learning curve... Please also keep in mind that these talking points don't matter much when comparing against familiarity/expertise within a team.
Well, one thing I'd push on is the difference between imperative/declarative and functional/mutating. &amp;#x200B; You can write functional code in almost any language (although it may be harder/more boilerplate than you'd prefer). But if your goal is to have code in a functional style, then write functional code in the languages you have and make a case for why that approach has advantages. If/when people come to appreciate that, then point out how much easier/less boilerplate you could have if you did the same in Scala. Similarly, you can write declarative code in the languages you have and if you get traction then show how it can be done in Scala.
*Why* do you think they should change? You haven't mentioned that. Honestly, my advice, don't be "that guy" who shows up to a company who thinks they know better than everybody and tries to change something that's so fundamental without understanding what decisions let them to where they are now. They probably have a ton of tooling, monitoring, etc that work for their current languages, and introducing new ones may take a too if effort to do properly (emphasis on "properly"). If they're a startup, chances are that there now interested in trying to get shit done than they are in introducing a ton of new complexity into their systems.
&gt; C++: All the same ability to write cryptic unmaintainable bullshit but with garbage collection. People saying that haven't worked with C++ much. That or they secretly love C++, or at least the puzzle that is C++. After all, nobody knows the entirety of the C++ language, not even the people currently maintaining and evolving its spec. So I can see how that's a life journey. In other words, this claim is hyperbole. &gt; Go: As good or better concurrency tools but with generics. Generics and implicit parameters (aka type classes) are a game changer due to the potential for writing reusable and correct (i.e. reasonable) code. This may or may not benefit projects. For example projects heavy in I/O, like database queries, the kind of projects that were built in say PHP, or projects that simply move data from one port to another (e.g. proxies), such projects don't need vast abstraction or static typing capabilities that Scala can afford. But switch to more complex projects, like all of these projects in the blockchain bubble, or say trading platforms where production bugs can cost the company a lot of money, so projects of complicated business logic and the value of languages like Scala is more visible. Versus Go also get the JVM. Tooling for the JVM is miles ahead imo. But this too has some disadvantage. For one the JVM has a slow startup and for Go there's value in just shipping a light binary with no dependencies. But we now have GraalVM which apparently can compile JVM bytecode to native and reports from the people trying it are promising. And we also have [Scala Native](https://www.scala-native.org) and I wouldn't use it in production. It's more immature for sure, but looks promising at least. Speaking of which, if you're looking for light, native binaries in a language that affords some low level programming, while not being so brain dead, another good alternative is OCaml. It's mind blowing why people don't use it more. &gt; Python: Basically the same syntax but with 100x the power and speed. Err, I agree with the power and speed, but Python is THE imperative language, the antithesis of FP. And if you have software developers that actually like Python (or Go for that matter) in your company, getting them to like Scala is an uphill battle and it's actually far easier to switch companies. And yes, I think Java or JavaScript developers are easier to convince due to their pragmatism and dislike of the language, Python being harder to combat because Python comes with culture behind it (I could rant all day about it, but I'll shut up for now 🙂).
That was really well explained! Would that all tech notes were so clear
For introduction of anything into the team the main question will be - what are the business benefits? If you want to introduce it only because it benefits you then team will not listen. * Is it shorter time to market? How exactly it will be shorter if you only one in the team who can use than language? * Is it less errors due to superior type system? Is business in the domain where having less errors will be beneficial? I personally saw several successful businesses testing right on the production. * Is it cheaper developers? Or less developers needed? We know that scala developers will not be cheaper, on contrary they usually more expensive. Also think about * expanding team - searching for scala developers is harder than for c++/go/python * performance - c++ will be faster and has potential to be as fast as possible. Also no gc pauses - predictable latency. Maybe that's the business requirement? * python is faster to write in some cases. It is also awesome for end 2 end tests automation. Like QA engineer writing scala code - forget about this... They all use python. Why you joined that startup in the first place if you want to work with functional programming? You are missing out a lot of things now. The only realistic way in that startup will be to start a new project using scala. But who will review your code? How will you learn if you are there alone? Best scenario - people who only started to learn language will review your code. How do you plan to progress in such environment? How exactly you utilizing team/work in the office in your favor in such case? You can work alone remotely with same benefits. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Forcing people to do something unknown against their their habits is the best way to ensure they won't like it. Most of the time I hear that someone tries to add Scala to a typical Java project, people only end up annoyed that this thing doesn't integrate with their established Spring + Hibernate workflow. Greenfield project is a great idea, because you can just pick up frameworks and libraries that work well together and don't leave that clusterfuck sensation.
Wow didn't know that. This is cool.
Shameless plug: we are hiring. PM me if interested.
Is there any viable replacement at this point?
For sure, there's a bell curve distribution going on. But anecdotally speaking many of today's developers that do FP appreciate it because they have worked with conventional Java, JavaScript etc in the past. 
If you just joined and you're not in a leadership position then frankly I see it as super unlikely you will get much traction. If you have the leeway to run a project on your own and make that call then that's likely the only way. You also need to be extremely fluent in Scala to be able to do education. Do be prepared for Scala and/or yourself to be viewed pretty negatively if the project goes poorly. You also need to evaluate if it's a good for for the team - what happens to your project if you change jobs? If no one can take care of it then you've cost the company quite a lot money.
Fwiw, the static type system in Python 3 is more sophisticated then Go, and is a huge boost to maintainability and correctness
The following talk is an awesome inspiration for those attempting to adopt FP principles at work. Give it a try :) [YOW! 2017 Ken Scambler - Adopting FP: A Human-First Approach](https://www.youtube.com/watch?v=vpcKnqyNdSQ)
Briefly, on the whole, yes, but we can summarize why as "because type-checking is faster than type inference." This is a little hand-wavy because the compiler will still almost certainly need to do some type inference in the body of the function, and it may even take _longer_ to infer whatever you do in the body and check it against the return type than it would to just infer the return type. But broadly speaking, it helps to declare the return type, both because it helps the compiler and because it makes your intention explicit—the compiler will _tell you_ if you don't actually return a value of the right type.
\&gt; some type inference in the body of the function Inferring type in the body would take only one pass, assuming that all methods' return types are known. But I understand your point. Maybe I overestimate how long it takes to traverse a tree (compared to type inference). \&gt; Briefly, on the whole, yes, but we can summarize why as "because type-checking is faster than type inference." Ok, so it seems it might speed up the compilation. I probably should try to explicitly define return types for all methods and see how much faster it is. Thank you for your input!
We'll considering that doing this makes it possible to compile more things in parallel it should be a win. (There was an issue on the dotty/scalac GitHub where a person experimented with simply running every pass *up to* type-inference over all the code and then stopping the compiler, pre-filling all the types and then running the compiler with all "public" types explicitly specified... this yielded a significant speed-up with a large number of cores.)
Berlin again :-/ There are good cities in Germany, not just Berlin. At least it's remote.
There are lots of other great cities in Germany :) There are Scala roles on the platform in Munich and Hamburg too!
There are lots of other great cities in Germany :) There are Scala roles on the platform in Munich and Hamburg too!
&gt; Munich Usually doesn't make sense economically. &gt; Hamburg This is nicer. I'd prefer Rostock though, but there's no jobs there, I know.
Get out! Berlin is great. 
I'm not living there anyway :)
I haven’t visited Rostock yet, will definitely put it on the list for my long weekend getaways. Cheers!
I love visiting Germany but haven’t been to Rostock yet. Will definitely put it on the list. Cheers for the recommendation!
The good old scala-reflect based macro. See the issue here https://github.com/typelevel/cats-tagless/issues/6
Hamburg? I need to have a look! 
update to the latest version 
Ok, that was the expected number 4. I hope you are upfront with users asking why null-safety is coming later than expected ... because people chose _again_ that working on intellectually satisfying and academically interesting stuff was more important than to fix the issues people have. Regarding unsoundness – initialization issues are by far be the least useful class of issues. I hope you haven't looked into Java library interop yet if you are concerned about unsoundness, because there will be tons of it to deal with. I already expect though that people at the EPFL will try to treat Java types as `T|Null` when they finally come around to it –which is not going to work for the reasons obvious to anyone who has spent more than a few minutes thinking about it. Then there will be more wasting of time trying to engineer increasingly elaborate workarounds for the fundamental issues, before devs will _maybe_ backtrack on it, wasting even more time.
Big fan of your work, but can we not with the undefined use of "this" in post titles. &gt; Scala got better with THIS ONE TRICK It's clickbait and it's opaque.
You're right. That would be a better question. Could you elaborate more on different kinds of type annotations? What are other type annoations?
How high are you in the company? Realistically, unless there's a clear business case, you probably won't be able to "sell" them on Scala. It will be an uphill battle because you got to show them explicitly how much it will benefit their business with Scala. Then you need to answer on how to train people in Scala, how to find new developers, etc. In the companies I've been with, it has to start from the top, almost CTO level for Scala to be sold to the engineering team. Then you gotta deal with developers who aren't convinced of the benefits of functional programming. I've been at a companies where a few imperative programmers used Scala and was decent at staying in the functional paradigm, but they didn't think it was a big deal. They still preferred their imperative languages. 
&gt; Could you elaborate more on different kinds of type annotations? What are other type annoations? I am not an expert. I am just talking out of school. Like on values, on methods, on protected, on private, on classes, on objects, on implicits, etc. Inline annotations on values...
In theory it will, but not in most cases not in anyway you will find observable.
Simon, I think you'd be happier if you redirected the energy you spend writing comments like this towards doing something else. I like contributing to Scala because my work can reach many people and hopefully improve their life in some way. I'm passionate about it. But in the end, it's just a programming language. If I thought like you that it was beyond hope, I wouldn't keep arguing about it with others. There's many other programming languages, and so much more to life than this. I respect and appreciate all the work you did on Scala in the past, I'm sorry if you had some bad experiences, but I think you need to move on.
Does it count as constant memory if you use a String as your accumulator? def processString(string: String): String = { string.foldLeft("") { case (accum: String, char: Char) =&gt; accum match { case a if a.nonEmpty =&gt; if (char != '/') accum + char else { if (accum.length &gt; 1) accum.substring(0, accum.length - 1) else accum } case _ =&gt; accum + char } } }
Rest assured that my happiness is not something you need to worry about. :-) I apologize if my statements were too close to reality.
The best you can do is build the case over a long period of time. You can educate people on where Scala could make an impact as you see how people approach concrete problems with the tools they're using. Translate functional idioms into the code that's already in use, and educate people on the upsides of that style. Then show how it would look in Scala, with the benefit of a more natively functional language. Also acknowledge the places where their chosen tools are working well, and know enough about other non-Scala alternatives to speak to them as well. If you're lucky, you may be empowered to pilot use of Scala on a project. If you get that opportunity, make sure to bring people into the fold and let them do the work with your coaching to ease the learning curve. 
For the uninitiated, what is Cats?
Cats is a library which provides abstractions for functional programming in the Scala programming language. The name is a playful shortening of the word category. Scala supports both object-oriented and functional programming, and this is reflected in the hybrid approach of the standard library. Cats strives to provide functional programming abstractions that are core, binary compatible, modular, approachable and efficient. A broader goal of Cats is to provide a foundation for an ecosystem of pure, typeful libraries to support functional programming in Scala applications.
hi friends, anyone know how to use libgdx with scala in the current year of 2018? i'm finding all these great resources from 4+ years ago, such as this one gitter8 template that didn't work. the libgdx doc for "other jvm languages" includes scala but also just points to the same template that hasn't been updated in 4 years.
Ctrl + Shift + P to see where implicits come from too !
Alternative explanation if you understand OOP terminology but not yet FP terminology: If you know *design patterns* then Cats are the interfaces of FP design patterns, their implementations for build-in data structures as well as some additional PF data structures that standard library is missing. Because of how FP work (composability, et all) you can build a lot on top of these common interfaces. Kittens are ways of generate implementations for any ADT, Cats Effects are about providing better abstractions about sync and async computations than Futures (to simplify), FS2 are about building whole IO pipelines as lazy streams (build on top on Cats Effects), and so on. So basically an extension to standard library allowing you to build a purely functional ecosystem around it.
I agree, `this` should be type annotated for clarity and self-documentation
EU again :/
&gt; For the uninitiated, what is Cats? I'm curious, have you found the currently posted answers clear enough? How unitiated are you? I'm super hypersensitive to not-clear explanations so if you need another take, lemme know!
I was going to suggest this. Anything wrong with this approach?
Maybe there's a bit of XY going on here. Why are you extracting fields from all the possible objects as an `Option`?
Don't take the unprincipled option-based approach to working with data. You have an answer using optics, as /u/volpegabriel stated.
Why is it unprincipled?
The view/inline implicits option is such a brilliant UX. I really think it's a game changer for how people treat implicits. &amp;#x200B; I guess it wasn't possible before IntelliJ had the feature to inline parameter names? (another feature, in the Java editor, that I'm a fan of)
The short answer is no. [Cats is using semver](https://github.com/typelevel/cats#binary-compatibility-and-versioning) which maintains backward binary compatibility between minor versions. So downstream libraries won't run into problems if they remain on older 1.x Cats. When Cats goes 2.0, it will likely break such backward binary compatibility at least on Scala 2.11, in which case downstream libraries will be recommended to update to help the whole ecosystem migrate. 
I think the combination of the above two was quite helpful. If there is sufficient audience to make it worth your while, however, describing a common use case scenario might add an additional layer of understanding (and maybe the OP could consider combining the responses into a brief section on the github page)
This honestly looks fine to me. My only complaint is the name `Sum` for the result of evaluating entire expressions which may include more than addition. I might call it `Eval` or something along those lines.
I finished the 2017 Advent of Code puzzles, and it only took 10 months. &amp;#x200B; Nearly all of the solutions use immutable data. Some use scalaz, Cats and fs2 in various ways &amp;#x200B; [https://github.com/justinhj/scalaadvent2017](https://github.com/justinhj/scalaadvent2017) &amp;#x200B; &amp;#x200B;
For the `sbt-release` plugin, does anyone know how to see what the release version would be from the sbt shell? I've set the releaseVersion task to a custom function, and I want to test that it works
Scala is not an fp language
It's a non-blocking effect. Info in the API reference: https://github.com/typelevel/cats-effect/blob/c62c6c76b3066c500fca2f9e0897605bc12eb2a0/core/shared/src/main/scala/cats/effect/IO.scala#L1234-L1272
Congratulations Sébastien. 
Typescript + mobx
With `IO.sleep` there's no thread-blocking.
Hah, hah, hah, the rascal, I suspect he's been hiding this for quite some time :) Congrats, hopefully his new office won't be too far from Scala.js (figuratively speaking that is).
I don't really get how a `Store` can supports such function :(
You are godsent for people struggling on the front end. 
[Here you go](https://github.com/scalaz/scalaz/blob/series/7.3.x/core/src/main/scala/scalaz/ComonadStore.scala) 
Could you explain more how a Store represents (S, A) =&gt; S
Think about what the function `(a,s) -&gt; s` means. In fact, we can start by trying to understand what `s -&gt; (a,s)` means in the context `State`. `s` represents a sort of context. If you give me an `s`, i'll run overand retrieve for you the pair `(a,s)` which is a value of type `a`, indexed by that state value. You can think of storing values in the dual sense, where if you say "give me a way of extracting an `a` from a store, where some value `a` is produced from some context, then if you give me the store, then I can get a thing i want out of the store, and all i need to know is where the store is. In order to contort this idea into something we can work with, we don't have an exact `(s,a) -&gt; s` representation, as with `State`, instead, opting to represent it as data - if you give me a way indexing some value and the index, i can store the thing. You end up with some interesting principles, and the following representations - newtype State s a = State { runState :: s -&gt; (a,s) } deriving Functor data Store s a = { _peek :: s -&gt; a, _pos :: s } deriving Functor instance Monad (State s) where return a = State (\s -&gt; (a,s)) (State st) &gt;&gt;= k = State (\s -&gt; let (a, t) = st s in runState (k a) t) -- and instance Comonad (Store s) where extract (Store f s) = f s duplicate (Store f s) = Store (Store f) s these actually being the 'opposite' of one another, in some sense. If one were to go for the `(s,a) -&gt; s` representation, you would run into some immediate problems (not _technical_ problems, but language-level limitations) when you notice the following: -- because a is now in negative position, -- Store this is now a contravariant functor instance Contravariant (Store s) where contramap f (Store k) = Store $ \(s,b) -&gt; k (s, f b) instance Comonad (Store s) where extract (Store k) = -- Oh no! extend (Store k) f = -- Oh no! 
One good way to influence a team to switch to functional programming is to encourage your team to take an online class together. Our team is currently taking the Functional Programming with Scala course on Coursera. It also helps your company by offering continuous learning opportunities, because that shows that you are willing to invest in your team and your employees. It's a win-win, you get to expose your team to new ways of thinking and your company gets better trained developers. If you can't get your company to recognize the value then your likely not going to get your team to ever switch to Scala. In which case your time would be better spent looking for a different job that already uses Scala then trying to swim upstream against your company culture.
Have you tried ScalaTest’s RefSpec style? It could not be easier (though it’s JVM only): class FooSpec extends RefSpec { object `add` { def `adds` { assert(add(2, 2) === 4) } def `does not subtract` { assert(add(2, 2) !== 0) } } }
It might be worth noting that the play-redis module supports both ehcache and redid at the same time. 
The amount of work you keep doing to keep up to date with upstream React, *and* improve it with type safety to boot is amazing! Thank you for that!
When asked what stack I use, my answer is "the [japgolly](https://www.reddit.com/user/japgolly) stack."
is there a giter8 template, or some other project template? I would like to what is the best way to do JS using Scala. 
The explanation above takes the reasonable steps you describe in the first two points already into account: &gt; - If the is an annotation of nullable or non nullable, that decides the type. &gt; - If there are no annotations, leave it to the scala/kotlin user to declare what is reasonable in this situation, via a type annotation. What I describe above is solely focused on: &gt; - If no type annotation fall back to one or the other (probably T | Null) ... and explains why this isn't going to work. &gt; Do you take issue with how kotlin handles this? The various stages of grief I described are pretty much what Kotlin went through before settling on "platform types". The basic problem is that you have two buckets: known-to-be-nullable and known-not-to-be-nullable, and regardless of which bucket you choose to put Java types into, you lose. This is what the situation looks like in a perfect world with no interop: Known Nullability / \ Not Nullable Nullable 
groovy/ClasspathMagicCommands.ipynb
I'm not sure what's the FUD here. That projects need to have a full-time engineer to be acknowledged on the website is ScalaCenter policy. I asked because I wasn't sure whether being an executive director would interfere with being a full-time engineer on Scala.js.
&gt; other project template https://github.com/Daxten/bay-scalajs.g8 I haven't updated it for some time, will see if I can get back to it (have a bunch of changes localy which I should merge)
Hey, was seriously considering using this. We were considering generating a default config file with comments from code. During my testing it worked pretty well. Unfortunately in the end decided we would rather write the default config by hand. 
Heap Analytics | Software Engineers | SF, Worldwide | ONSITE &amp; REMOTE | Full Time We're eager to meet all types of engineers, regardless of where you live or what tools you use day-to-day. Your creativity and intelligence are much more important to us than your experience with our stack. Our app-layer stack is TypeScript, React , Node.js, Redis, and PostgreSQL. Under the hood, Heap is powered by CoffeeScript, Scala, ZooKeeper, Kafka, and CitusDB. If interested, contact me at marconi at heapanalytics dot com
Hi, Great article. We also use Kafka Streams and Scala 2 things: 1. How do you handle with user interactions that requires validation feedbacks with cqrs? Optimistic update won’t cut it because you need to give a server feedback to the user such as adding a user that already exist 2. You put posts as a map with user Id a the key. That seems highly inefficient because every time some post will change you won’t be able to update the delta but the entire byte array (the way the map is being serialized and saved to rocksdb) How did you solve it?
I haven't used Evil Plots but looking at the API it appears you can show a rendered plot in a new window (which should work when debugging) or you can write the plot to a file and load the file in IntelliJ. Is there another workflow you need?
Does it compile with Scala native?
Why not post this in the who's hiring thread?
Can use add a tag to those tests then run just the tag?
Some might say [this](https://github.com/lampepfl/dotty/pull/5114/files#diff-c9e9d747cc67122c0a70671bedd3f683R80) is another instance of "those who don't learn from history are doomed to repeat it"; on more serious terms though: Kotlin literally changed their language syntax to avoid having this construct, because they thought the problems associated with it were that bad.
tag the test names with something unique, e.g xxx, then testOnly -- -z xxx
Looks pretty cool! Love the fact that Martin is working hand in hand with Cats maintainers to remove the warts from the type class syntax.
What were the arguments against having the type parameters after the method name? I'd prefer the type parameters before, but its not a hill I'm willing to die on. 
We can, but is there a better way? The combination of test name and suite should already be unique. We have \~1,000 test cases, so tagging everything is tedious. Not to mention, it would be verbose.
Off topic: What's the deal with the `` enclosed variables in scala? Is there a way to not use them for example [here](https://github.com/lampepfl/dotty/pull/5114/commits/63d8b3a522c7c7b49fe4a4bf3ebc415041fcd1f8#diff-f1b9493e9c2a3001285a11a0ad206e93R25)? It just looks like a hack to me.
Please, at least try it. Adding Tag("some tag") to a test isn't any harder than adding test.examples.HelloTests.test1 to a shell script. Using the tag makes your shell command simpler, and a good tag name also helps describe why those tests are tagged a certain way, which the the command line argument way doesn't do.
You might be able to get what you want by using the Runner with -t. http://www.scalatest.org/user_guide/using_the_runner#selectingSuitesAndTests
Please repost this thread in the "Who's Hiring thread"
You use them in two ways afaik. Firstly you can name a variable anything inside them, even if it would normally be invalid, including names of keywords. Secondly, you can use them in a pattern match to compare your match input against the value held in an arbitrary reference, where without the backtick syntax it would be an assignment
&gt; What's the deal with the `` enclosed variables in scala? For example: `class` can't be a valid identifier, but after enclosing, it can: val `class` = 0 &gt; Is there a way to not use them for example here? It's just a fancy convention. The constructor parameter of extension class plays the same role as `this` keyword in normal class. So, for better clarity, you might want to choose a name that conveys that role. My personal convention is `thiz`. TIL I could have used `thiś`.
The command only runs one test suites. It can't run two different test names in two test suites.
Dunno about parent's reasons, but `def (x: T) + [T : Numeric](y: T): T` does look a bit weird. 
Minor nitpick, but I'd prefer not to be required to type `(c: Circle)` for every method. As it is, the current implicit value class syntax is simpler and cleaner.
Consistent nesting. Being able to read source code from the left to the right is an extremely useful property to have, which you don't realize until it's gone. C/C++ are probably the worst examples of this. I thought this was pretty clear when implicit classes where introduced. It's a bit surprising that this lesson has either been forgotten or disregarded now.
That's high praise coming from you @sjrd, thank you! (And yes, the React team really keep me busy.)
with uTest you could do testOnly -- {pkgone.OneSuite.myTestOne ,pkg2.TwoSource.myTestTwo}
Ha! Very cool. I didn't expect to watch all the way though but did
Yup, I've been using utest for my small projects. But, for older/bigger projects, sadly, they are on scalatest. utest seems be more sensible in terms of design, though it lacks a few features (e.g. no junit reports).
LEO Innovation Lab | Data Engineer/Software Engineer | Copenhagen, Denmark | Onsite | Full Time LEO Innovation Lab’s mission is to innovate to improve the lives of people living with a skin condition. As part of the Lab, Imagine develops image recognition-based artificial intelligence to give both patients and doctors a better understanding of the development of skin diseases, improve diagnosis, and make it easier to find the right personalized combination of treatment and lifestyle. Your main responsibility will be to ensure high-performant, consistent and increasingly automated data pipeline flows including images – sourced from thousands of users through our mobile apps, labelled by medical experts, and used for training AI models. Our stack: Scala.js, Scala, AWS, Lambda, MySQL, Akka Job ad:https://leoinnovationlab.com/careers/data-engineer-sw-developer/ If interested, please contact me: anders.nickelsen at leoilab dot com.
Cute! What use cases motivated you to write it? 
The amount of effort put into this is amazing. Even better since this is very nice to work with.
All informations about stack safe free monad you can find in this paper: [http://days2012.scala-lang.org/sites/days2012/files/bjarnason\_trampolines.pdf](http://days2012.scala-lang.org/sites/days2012/files/bjarnason_trampolines.pdf)
*sigh* My opinion pieces never get thumbs ups.
I struggled with the formatting of your code examples, but to construct a stack-overflowing example look at the cases where the stack will get deeper. case FlatMap(x, f) =&gt; run(f(run(x))) This will first call `run(x)`, so you want to form a case where `x` is another `FlatMap`. I don't understand that definition of `forever`, but if you create a deeply nested pile of `FlatMap`s via e.g. val p = Suspend(() =&gt; println("abc")) (1 to 10000).foldLeft(p){(a, b) =&gt; a.flatMap(x =&gt; Return(x))} (note that I had to override `IO#toString` to make the interpreter not stack overflow when trying to print this) then calling `run` on the result of that (which will look like `FlatMap(FlatMap(FlatMap(...`) does stack overflow as expected, and the fixed version of `run` does work correctly. The idea of the resequencing of the nested `flatMap`s is that `FlatMap(FlatMap(..., g), f)` becomes `FlatMap(..., g andThenK f)` (where the point is that `g andThenK f` is a function value that does the thing that `g` and `f` together did). So any long chain of `FlatMap(FlatMap(FlatMap(...)))` is gradually reduced to a single `FlatMap` which can then be executed without a stack (or rather, the stack has been pushed into a large function object that we've constructed on the right of the `FlatMap` - but function objects are stored on the heap and don't overflow).
Scala with Spring + Hibernate actually works beautifully; it's very difficult to get help from either community when doing it though.
I would echo what other commenters here have said, that if the author wants to get a better reception of their articles, they should completely cut out the swearing and the antagonistic adjectives ("terrible", "stupid"). It comes off really abrasive and immediately makes anyone reading it check out.
&gt; it's the only way to achieve equational reasoning... but claiming that isolating effects with IO is "stupid" Update: Also note that while I use the IO Monad as an example of using Monads to contain side effects, this article is not about criticizing the IO Monad specifically, but rather the general practice of using Monads for side effects. Monads are not the only way to be able to reason better about your code. If you know in your head which lines of code have side effects and which don't, you can reason without the explicit presence of a Monad to explicitly execute your side effect when a call to say "flatmap" is made. Monads are not some sort of silver bullet. &gt; you don't need to take a single course to understand the abstractions. Update: Now at this point you might say that you can learn all of scalaz (and I'm just using scalaz as a classic example - this article isn't about specifically criticizing scalaz), but you're still shooting your team in the foot. Scala already has a big learning curve. Learning curves aren't a good thing. All things equal, a smaller learning curve is better than a bigger learning curve. And by adding all the category theory stuff on top of the core language, you are increasing the already relatively steep learning curve. A lot. Imagine a single codebase with 4 million lines of code and 400 programmers working on it. Yes, such a codebase actually exists. Simply put, adding all this extra complexity and adding to the already steep learning curve simply is not worth it. Not reconsidering, but your feedback was taken into consideration. Thank you. 
IO is just a classic example of using Monads to contain side effects. IO is not the only Monad that has ever been used to wrap up a side effect in Scala and this is more a criticism of the practice as a whole rather than the IO Monad in particular. In specific, I am talking about people who write code that looks like this: for { \_ &lt;- statement.executeUpdate("INSERT INTO timeTable VALUES (now())"); } yield () instead of code that looks like this: statement.executeUpdate("INSERT INTO timeTable VALUES (now())"); &amp;#x200B; Simply put, I do not buy into the notion that the presence of a Monad is the ONLY way for you to be able to reason logically about the code. The scalaz IO Monad and the IO Monad in Haskell have some nice properties, but this is not a piece about the IO Monad. It is about the practice of wrapping side effects in Monads to make your Scala code look more Haskell-esque. Like if you look at the example above, that is the kind of code I am talking about. If you have the awareness of which lines of code contain side effects, the good really isn't worth it. That is what this piece is saying.
Thank you, I will take a look
Your input has been taken into consideration.
Your input has been taken into consideration. Thank you.
&gt;I don't think people write code that looks like this: I worked at Amazon and I saw code that looks like that mixed with code that just straight up calls a method like "def perform(): Unit", often times in the same file. Sometimes they write code that goes `_ &lt;- createTestDependency("foo")` to show that "createTestDependency" is introducing a side effect on execution of its "flatmap" function and other times they call something like "def createTestDependency(str: String): Unit". In practice they are nested so it looks more like: &amp;#x200B; def test1(): Unit = { \_ &lt;- createTestDependency1("foo") bar &lt;- createTestDependency2("bar") \_ createTestDependency3(bar) } &amp;#x200B; and then in some other part of the code they do something like: &amp;#x200B; def test1(): Unit = { createTestDependency1("foo") bar = createTestDependency2("bar") createTestDependency3(bar) } &amp;#x200B; For the love of god, just pick one. If you are doing to be calling methods like "def perform(): Unit" or even "def createTestDependencyByCallingStatefulAPI()" you don't need to mix and match monadic with non-monadic stuff. In practice what ends up happening is they go the not purely functional route and then try to wrap arbitrary side-effecting-functions in Monads that execute said side effect on call to "flatmap" while not wrapping other side-effecting functions. &amp;#x200B; I likely will check out pure FP in Scala, maybe for fun, but production codebases in huge for-profit corporations aren't about fun. They have to be good and practical. And I don't think that wrapping up some side effects with Monads while leaving others unwrapped is good. And making everything pure FP often times just isn't practical. Like I know of a monolithic Scala codebase with 3-4 million lines of code that took 6+ months just to perform a single major version number upgrade, and part of the reason was dependency hell, and one of the dependencies in that dependency hell was, as you may have guessed, scalaz (again, this isn't specifically about programming in scalaz - if they started with catz and then industry migrated to something else that would also cause problems).
&gt; If you know in your head which lines of code have side effects and which don't Then you may well be wrong. Indeed I'd say most production incidents I've seen in my career happened because someone thought something was an innocuous function and it wasn't (e.g. removing a do-nothing proxy that turned out to be where the transaction interceptor was applied. E.g. replacing a function with its happy-path result value when it turned out that function actually always threw an exception and the surrounding code only worked correctly if the exception was thrown). Humans aren't good at tracking this stuff by hand. Get the computer to do it for you - repetitive tasks are what it's good at. &gt; Scala already has a big learning curve. Learning curves aren't a good thing. All things equal, a smaller learning curve is better than a bigger learning curve. And by adding all the category theory stuff on top of the core language, you are increasing the already relatively steep learning curve. A lot. You could make that argument for any library. But no-one would say that you write better code or reduce the learning curve by avoiding all libraries. At least I hope not. There are some confusing things in Scalaz, certainly. But IME its power-to-weight ratio is very good; I got more out of learning Scalaz, for less time investment, than I got out of learning e.g. Spring, Jersey, Drools... because many of the Scalaz tools are very reusable, whereas a lot of JVM frameworks are only useful in specific situations.
&gt; If you know in your head which lines of code have side effects and which don't, you can reason without the explicit presence of a Monad to explicitly execute your side effect when a call to say "flatmap" is made. Indeed. I like pure FP not because it's a lot of smart stuff, but because it lets me get away with being too stupid to learn every single function in whole project and watch each commit for changes that turn functions from pure to side effecting. I'd rather spend time learning some basics that will last me a long time and doesn't change from project to project, and, in some cases, from language to language.
&gt; But no-one would say that you write better code or reduce the learning curve by avoiding all libraries. At least I hope not. Actually, this is EXACTLY what Morgan Stanley has been doing on its 4 million line of code monolithic Scala codebase. It ran into such dependency hell upgrading across major version numbers that it basically scrapped its dependencies. No scalaz. No catz. No shapeless. &gt; There are some confusing things in Scalaz, certainly. But IME its power-to-weight ratio is very good; I got more out of learning Scalaz, for less time investment, than I got out of learning e.g. Spring Spring doesn't even feel like real programming to me. It just feels like copy-pasting stuff out of other Spring apps to add functionality. Oh, I need Quartz scheduler. Copy and paste stuff out of a Quartz Scheduler Spring demo app. I need Kafka integration. Copy and paste stuff out of a Spring Kafka demo app. I need to add a form which will be submitted via a POST. Find some sample code online that does that and copy-paste it in. If that doesn't work, git reset --hard and copy and paste another example and see if that works.
Because you wrote an article full of derogative statements oriented towards the community which has nothing to do with your problem. It's fine to be frustrated by mixed codebases with no standards on FP stuff, but this issue needs to be raised with your coworkers and higher-ups, regardless of whether you prefer all-FP or all-imperative style. Neither pure FP nor FP community is not to blame here. We develop tools we _like_ working with (in Scala!) and share them so others could benefit from them as well, and I don't think there's any problem with that. Why we like wrapping stuff in IO is a different question you could find answers to, if you wanted.
It can run multiple test suites. You repeat -s. After each -s use -t to name the specific tests. class OneSpec extends FunSuite { test("1.0")() test("1.1")() test("1.2")() } class TwoSpec extends FunSuite { test("2.0")() test("2.1")() test("2.2")() } run with "C:\Program Files\Java\jdk-9.0.1\bin\java.exe" -classpath ... org.scalatest.tools.Runner -o -s OneSpec -t 1.0 -z 1.2 -s TwoSpec -t 2.0 Run starting. Expected test count is: 3 OneSpec: - 1.0 - 1.2 TwoSpec: - 2.0 Run completed in 248 milliseconds. Total number of tests run: 3 Suites: completed 2, aborted 0 Tests: succeeded 3, failed 0, canceled 0, ignored 0, pending 0 All tests passed. 
It sounds like your beef is with doing weird things mixing code styles, and doing a poor job of managing dependencies; not with using monads. &amp;#x200B; Again, using something like \`IO\` isn't about "showing that it returns 'Unit'." It will show that, but that's essentially the least important thing you get from wrapping impure operations. &amp;#x200B; Doing this kind of thing has \_very practical\_ benefits that are useful for for-profit, production systems. 
You're right. It's not about PureFP. It's about the fact that we end up mixing a style of code that wraps side effects in monad with a style of code that calls side effecting functions directly. Like fine, if you are going to use the newest scalaz IO SafeApp, fine wrap each and every single side effecting function in your entire app in a Monad. But in production, what ends up happening is that they don't wrap the entire app in a scalaz SafeApp. They end up with a mix of methods like "def perform(): Unit" and lines of code that look like "_ &lt;- perform()". It's not good.
Isn’t it verbose and tedious to repeatedly type `testOnly {some,set,of,tests}`?
What's the biggest benefit you get from IO other than knowing that no IO means no side effects (assuming your entire application is wrapped in something like a [scalaz IO safeapp](https://github.com/scalaz/ioeffect))?
I wrote about this extensively: [https://www.reddit.com/r/scala/comments/8ygjcq/can\_someone\_explain\_to\_me\_the\_benefits\_of\_io/e2jfp9b](https://www.reddit.com/r/scala/comments/8ygjcq/can_someone_explain_to_me_the_benefits_of_io/e2jfp9b) [https://www.reddit.com/r/scala/comments/8ygjcq/can\_someone\_explain\_to\_me\_the\_benefits\_of\_io/e2jfrg8](https://www.reddit.com/r/scala/comments/8ygjcq/can_someone_explain_to_me_the_benefits_of_io/e2jfrg8) &amp;#x200B; I would humbly suggest that before writing scathing criticism of something, one should make the effort to understand at least the basics of it
I'm pretty sure that with a little bit of a good will everything is doable. But guys like that just tried to do Java in Scala the Java way, and any reason to move back to Java was a good reason. From what I remember they literally complained that they could do thinks the way they used to do anymore (even if the new way would be easier/better after a while). So, you know ¯\_(ツ)_/¯
What's the best way to handle CPU-bound parallelism when writing using IO (or abstracting over an effect using tagless final)? If, for example, I have a `inputs: List[AnInput]` that I want to transform into `outputs: List[AnOutput]` via `veryExpensiveCalculation: AnInput =&gt; AnOutput`. I know I could do something like this, presumably: for { inputsDelayed = inputs.map(Sync[F].delay(bigCalculation(_))) outputs &lt;- inputsDelayed.parSequence } yield outputs but it feels really weird to have to wrap up my pure calculation in an effect--not to mention that the type signature will be misleading, as my code just does a bunch of number crunching without any side effect.
Are you sure you want this out for future prospective employers to see? I don't think this helps you even at an imperative shop 
Well, the case for Scala is often made on the basis of seamless Java interop. If they were told it would work just like Java and then discovered it didn't, it's fair enough if they complain. Most people don't like change unless they can see the benefits - now rather than later - and frankly I think they're right.
Crunchbase | Platform Engineer | SF | ONSITE | Full Time &amp;#x200B; Crunchbase is hiring platform engineers. Come help me build scala services with akka-http, postgres, redis, elastic, kafka, kubernetes, and AWS. Scale is currently about 5k requests/minute for a fairly busy service. &amp;#x200B; Team: Platform engineers at crunchbase build our microservice-based reactive, eventually consistent core data storage and retrieval machinery alongside the systems that enable us to choose an optimal balance between performance and flexibility at each step in the data lifecycle. &amp;#x200B; Company: Crunchbase helps millions of entrepreneurs make the world a better of place. &amp;#x200B; themba (at) crunchbase dot com 
I like that this is moving forward but the syntax is kind of awkward. I'd just borrow C#'s syntax and call it a day. Instead of: def (x: Int).combine(y: Int): Int = x + y Something C# like: def combine(this x: Int)(y: Int): Int = x + y See: [https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/extension-methods#example](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/classes-and-structs/extension-methods#example)
I like the spirit of this but not the syntax. The `def (target: Type).method` syntax is not insurmountable, of course, but it is rather...unique. I think I'd prefer something like "just make `implicit class Ops(target) extends AnyVal` slightly easier". To that end, maybe `extension class Ops(target: Type) { def method }` is good enough? Then you can have type parameters and context bounds in the usual places. While I think the `extension class` strawman is one of the best available options, I think taking a page from C#'s book would be nice too, e.g. `object Ops { def method(this target: Type) }` or `def method(extension target: Type)` or `extension def method(target: Type)` would be better. No doubt I'm missing something that makes the more familiar syntax less desirable. Fundamentally all that's happening writing a free function with `n` parameters but allowing it to be called with the same syntax as it were a method of the first parameter with `n-1` parameters. That is, `def method(target: Type, arg: Arg) &lt;=&gt; class Type { def method(arg: Arg) }`. So I like `extension class` for evoking the notion of "adding methods to a type" and not needing to specify the target type of every method, but despite `class` I'd expect it's possible to encode this as just static method calls.
It's different. Tagging means modifying Scala code, which will definitely go to version control. &amp;#x200B; For the bash command, I'll definitely generate it based on some data. One scenario that I plan to implement is to run specific browser tests based on the files that are changed based on code coverage of the tests. Distributing tests to different machines based on their time.
WHOA! I was having a tunnel vision on using SBT; \`sbt testOnly\` actually rejects \`-s\` and \`-i\`. I didn't realize using Runner would be more flexible. I thought their capabilities would be equivalent. I'll try this today and report back. Thank you!
In that case, what work is `class` doing here? Why not just extension Ops(target: Type) { def method = 1 }
The ability to inherit existing implementations was once touted as the benefit of implicit classes over extension methods.
It feels like sometimes the best design is to do nothing. I have issues seeing the solution to the big problems the proposals are trying to solve. If they aren't substantially better than the code people already wrote (e. g. with the help of annotations), why even bother? At least with annotations, people can fix/fork/write their own. A language is rarely made better by adding more features. &gt; I'd expect it's possible to encode this as just static method calls Is the encoding really important? I'm not sure it's a good idea to focus the design around a concern that will be completely irrelevant in the mid-term.
Glad you like it! Have a great Scala day.
As far as I can tell there isn't a default "print the current and next versions". But I did find a way to make the release plugin show the info, just with a side effect of actually setting the versions that would be used for `release`. One of the default release steps is `inquireVersions` which will prompt for which versions to use. It also displays what the default release version and next version will be. You can execute this step manually by adding `commands += sbtrelease.ExtraReleaseCommands.inquireVersionsCommand` to your build.sbt. Then in the shell you can run `release-inquire-versions`.
Good point. That totally works for me.
Thank you again!
&gt; It feels like sometimes the best design is to do nothing...A language is rarely made better by adding more features. I can agree with that. I was only trying to comment on "if we're changing the language what might nicer extension methods look like" and not "do we really need to change the language just for nicer extension methods". &gt; In fact, it feels quite similar to the enum feature, which saves a few keywords at the cost of probably being the worst enum implementation one can think of. I must have missed this. Where could I read about it? &gt; If both semantics and syntax of "extension methods" aren't substantially better than the code people already wrote (e. g. with the help of annotations), why even bother? I'm personally not a fan of using annotations so given the choice I'd prefer to have a nicer syntax to achieve my goals with explicit code. Though it's not like I write a ton of extension methods so the current implicit AnyVal syntax is just a minor annoyance. &gt; Is the encoding really important? I'm not sure it's a good idea to focus the design around a concern that will be completely irrelevant in the mid-term. I'm not arguing to focus the design around the encoding, but I do think it's valuable to consider encodings. Static methods are generally very friendly to the JIT, for instance.
&gt; I must have missed this. Where could I read about it? Try searching for enums in this forum, I don't have a link at hand... &gt; I'm personally not a fan of using annotations so given the choice I'd prefer to have a nicer syntax to achieve my goals with explicit code. I agree on that, I think that a feature were people can't even agree on whether it is better or worse than what people hacked up with annotations is not good enough to be baked into a language. &gt; Though it's not like I write a ton of extension methods so the current implicit AnyVal syntax is just a minor annoyance. There will always be minor annoyances in a language, things that could be made nicer with just some tiny addition ... but there is a language that went out and tried to fix all minor annoyances with new language features. The language is called C++! :-) In this specific case that minor annoyance is born out of technical debt that was never cleaned up. &gt; I'm not arguing to focus the design around the encoding, but I do think it's valuable to consider encodings. Static methods are generally very friendly to the JIT, for instance. OpenJDK is working on implementing value types in the VM; so they will have zero wrapping overhead, with methods being de-facto static methods. But Scala decided to go NIH instead. :-/
Hey! I'm a total scala and IDEA newbie and I want to know how to import Play framework source to an existing project (rather than creating another project).
I wanted to generate Swagger JSON from the web application code automatically, but we need to define additional meta data which can't be retrieved from static type information (e.g. description of methods, parameters, etc...) in typical web frameworks in Scala. But they are in Scaldoc in fact. So I thought if we could get them from Scaladoc, we can't avoid duplication of these information. This is my motivation to create this library. Here is my experimental web framework which uses this library to generate Swagger JSON: [https://github.com/takezoe/resty](https://github.com/takezoe/resty)
Need to find more time to do so, but I'm still working on the Scattersphere project. Would love some input as to which direction to take it with the distributed server. Current release will be a stand alone server, but I plan on adding support for etcd/zookeeper support. My plan is to still keep it simple, so if it means making my own mechanism for keeping contact (ie. master/slave election), I would prefer that. Introducing new libraries generally means a large number of dependencies that I don't want/need. Either way, (the project is here)[https://www.github.com/KenSuenobu/scattersphere/] - would love some feedback!
Remote from anywhere in the world or just from the US?
Forking threads is widely seen as a side effect. If you don't want to treat it as one in your codebase then you can just do the forking and executing directly (or even use `IO` and just call `unsafeRun` or whatever it's called before you return), but in that case I don't really understand the question: what is it that you want "using IO (or abstracting over an effect using tagless final)" to do, if you don't want to treat your code as effectful?
Unless you use something similaro to \`testOnly\` all tests are run, regardless of what was (re)compiled. Actually, it would be pretty challenging to figure out which changes in code affected which parts of tests - that difficulty in figuring out what was affected by changes is the reason we have regression tests in the first place. (BTW, unit tests are usually very fast. Like one or two orders of magnitude faster than compilation). When it comes to caching you probably set up everything correctly. About recompilation... you probably underestimate the number of dependencies between definitions in files - change in one file might result in changes of things available in explicit and implicit scope of many other files. And in order to run even one test all of compile and test dependencies have to be compiled, as well as all files in currently tested module. You cannot say: hey, I just want to run tests from this suite, so skip compiling all the other files. Whether it's Scala (JVM), Scala.js or Native Scala is not important. As long as you use compiled language it works the same way in virtually all build systems on all platforms.
I ended up writing all these equations on paper, and it really helped. BTW, if we don't re-sequence flatMaps, \`run\` method just hangs! \`FlatMap(FlatMap(x, g), f)\` becomes \`(x flatMap g) flatMap f)\` which leads us to the initial expression \`FlatMap(FlatMap(x, g), f)\`. I didn't realize it would happen, but now when I'm looking at it, it looks quite obvious. Anyway, thanks again for explanation, you helped a lot.
There's no library with that name/version, at least not in maven central. Where did you get the `"com.typesafe.play" %% "play" % "2.6.19"` line from? I can't find any documentation on the play website about how you add their dependencies the normal way (it's all "seed projects" which I don't know anything about), but I suspect the library name needs to be something slightly different.
&gt; BTW, if we don't re-sequence flatMaps, run method just hangs! FlatMap(FlatMap(x, g), f) becomes (x flatMap g) flatMap f) which leads us to the initial expression FlatMap(FlatMap(x, g), f). I didn't realize it would happen, but now when I'm looking at it, it looks quite obvious. Yes indeed, I should've mentioned that. Unfortunately this is a pitfall of `@tailrec` - it turns recursion into loops, but that means an infinite recursion (which would stack overflow) becomes an infinite loop (which just hangs forever).
Hmm, I was not aware they are making such guarantees. What you might not cache is the modification date of each file. From what I see in the implementation (https://github.com/sbt/sbt/blob/10d471ad347f7abc3c9f98cd14d93ffb8926c2e9/main/src/main/scala/sbt/Defaults.scala#L871) it relies on timestamps (modification time) that might not be preserved during copy-&gt;cache-&gt;restore procedure.
What did you struggle with in the 1st assignment?
I tried this [https://www.scala-exercises.org/](https://www.scala-exercises.org/)
&gt;There will always be minor annoyances in a language, things that could be made nicer with just some tiny addition ... but there is a language that went out and tried to fix all minor annoyances with new language features. The language is called C++! :-) I agree with not adding something to the language which can be added with annotations easily, but the comparison with C++ isn't really fair! C++ is implementing too much in STL instead of language features (see std::visit and template magic that is used way too often). It's just that some features in C++ aren't really orthogonal because of backwards compability?
Nice! I will give this a try. &amp;#x200B;
I'm in the same situation as you. I started the course 3 days ago and I was thinking it would be a basic one, but I had problems even with sbt installation. If you can find some help I would appreciate if you share it with me. We wont despair!! 💪
I'm afraid it's not the case, cause I copied the lines from sbt files and just double-checked. What build tools are you using?
You need to be specific. Post precise questions and people will be willing to help. 
I use maven (most of the community disagrees with me) and when I do server-side HTML UIs (which is rarely these days) I use wicket (with wicket-scala). Can you put the full sbt files you're using up somewhere (e.g. github)? I don't know what to say other than that "com.typesafe.play#play;2.6.19" error message strongly suggests you've got a `% "play"` that should be a `%% "play"`, because it should be resolving to "play_2.12" rather than "play" (I can well believe you'd hit other problems, but not the same error).
Hum, the first 3 weeks or so are supposedly very basic. As someone said, can you be a bit more specific about what got you stumped?
Thank you for taking your time to help me. [https://github.com/pavelioS/SBT](https://github.com/pavelioS/SBT)
Literally the first google search result for "recursion practice": [https://www.geeksforgeeks.org/recursion-practice-problems-solutions/](https://www.geeksforgeeks.org/recursion-practice-problems-solutions/) &amp;#x200B; For Scala specifically: [http://www.scalakoans.org/](http://www.scalakoans.org/)
The course is as introductory as it gets. If you don't mind, would you recite the course here, explaining the material as much as you can in your own understanding, from there we can identify where you get lost and reenforce the objectives and lessons of the course, and hopefully prepare you the rest of the course.
So, is it "everything" or is it recursion? My guess is that the course starts with recursion, because recursion is a rather fundamental part of FP. To quote a tweet from John De Goes: &gt; Immutable data leads to recursion. &gt; Recursion leads to higher-order functions. &gt; HOFs lead to parametric polymorphism. &gt; Parametric polymorphism leads to type classes. &gt; Type classes lead to higher-kinded types. &gt; Higher-kinded types lead to category theory. With imperative programming, if you want to do something like finding the sum of a list of integers, you would, generally speaking, write a simple loop and use a *mutable* variable to store the current *state* of the calculation at each iteration. The value of the mutable variable at the end of the loop would be the answer. // Scala val numbers = List(2, 10, 55, 11) var sum = 0 for (n &lt;- numbers) { sum += n } println(s"The sum us $sum") In FP, we very much want to *avoid* using mutable state, including mutable variables whenever possible. There are always exceptions, often performance related, but for pedagogical purposes, when we talk FP, we are first and foremost concerned with *immutability*. So, how do we perform the same calculation without mutable state? Try and write a loop that does it, but only allow yourself to use `val` instead of `var`. // Scala val numbers = List(2, 10, 55, 11) val sum = 0 // notice this is val, so it's now immutable for (n &lt;- numbers) { sum += n // error! we can't change the value of sum! } This is why immutability leads to recursion. We need another way to handle state during iterative calculations. Functions, as it turns out, provide us a very convenient way to manage immutable state by allowing us to pass along the current state as an input to the next iteration of our "loop" which is now modeled as a series of recursive function calls. def sum(list: List[Int], state: Int = 0): Int = list match { case x :: tail =&gt; sum(tail, state + x) case Nil =&gt; state } And this is where you may be getting stuck. If you aren't used to dealing with recursion, something as *simple* as "find the sum of the integers in this list" suddenly looks like a foreign language to you. But, just like there are patterns in the different types of loop structures that we commonly create in imperative programming, there are also equivalent patterns in recursive structures. Take the `sum` function above. Here, the `state` parameter takes the place of the `sum` mutable variable in the loop example. The compiler can actually take this recursive function and unroll into an actual loop - it's entirely equivalent. The difference is that in its recursive form, we aren't mutating any variables. Each iteration of the "loop" is a separate function call with its own beginning state (the two input parameters) which are derived from the previous iteration. And just like a loop needs to know when to end to avoid an infinite loop, we must have a way of terminating our recursion. In this case, when the `list` argument is `Nil` (an empty list), we know there are no more numbers left to process so we can simply return the current `state` of the calculation. Of course, in this case, our `state` begins at 0 with a default value, but the more idiomatic form is to use an internal function for the recursive function so that the external function's parameter list does not include the state: def sum(list: List[Int]): Int = { def go(list: List[Int], state: Int) = list match { case x :: tail =&gt; go(tail, state + x) case Nil =&gt; state } go(list, 0) // Starting state is 0 } When I was learning recursive functions, this was my biggest issue. Understanding how to translate imperative looping patterns into recursive function calls. So, a good way to get started would be to write the function imperatively with a loop and then look at two things: 1. What state are you keeping track of? (ie: what variable(s) are you mutating?) 2. What determines when the loop ends? The answer to those two questions will inform you about what your recursion needs to look like. Your state needs to be turned into one or more function arguments for the recursive function and your termination condition needs to be included to avoid infinite recursion (looping). This isn't a hard and fast rule, however. There are multiple ways to skin a cat. The above functions I showed you were *tail-recursive* which means the line that is recursive does nothing more than return the value of the recursive function, ie: `case x :: tail =&gt; go(tail, state + x)` does nothing more than return the value of `go` with the given arguments. Here's another version of `sum` which is not tail-recursive, and which would probably be less obvious to you if you are trying to simply translate a loop: def sum(xs: List[Int]): Int = xs match { case x :: tail =&gt; x + sum(tail) case Nil =&gt; 0 } The reason it's not tail-recursive, is because the line that does the recursion includes the return value in an expression rather than simply returning it: `case x :: tail =&gt; x + sum(tail)` In this version, we aren't keeping a state variable for the current sum as a function argument. Instead, our "state" is inlined with each successive call to `sum`, meaning the compiler cannot turn this into a simple loop, but instead has to expand the stack until we reach the end of the list. That is to say, given: val myList = List(1, 2, 3) sum(myList) // returns 6 The call stack would look like: sum(List(1, 2, 3)) 1 + sum(List(2, 3)) 1 + 2 + sum(List(3)) 1 + 2 + 3 + sum(List()) 1 + 2 + 3 + 0 It's these non-tail recursive functions that have always been toughest for me to come up with. But, generally speaking, tail recursive functions are often more desired due to their ability to be unrolled into loops (and thus not lead to stack overflow errors for very large inputs) and for many situations, you can use the method I described above to translating an imperative loop into a tail-recursive function. I hope that gives you some insight into *why* recursion matters (immutability) and an idea of how to start to translate what you know now into the recursive paradigm.
That's surprisingly significant. I've gotta try doing this in my codebase and see how much faster it will be. I'll report back.
It's a bit roundabout, but I learnt functional style via *ML for the Working Programmer*, which is available for free on the author's site. Standard ML is maybe not the most practical language (though I know people who'd disagree), but it forces you to adopt a functional style by simply not giving you any other option (the book doesn't even mention e.g. mutable variables until quite late on).
I found that [Functional Programming in Scala published by Manning](https://www.manning.com/books/functional-programming-in-scala) is a better resource for learning functional programming (regardless if it is Scala or not), than the Coursera course.
A bad news to TypeScript fans.
Thanks, I think that should help!
This a a good answer I feel. Just a wanted to say that it is weird for me realizing that you are saying that the tail recursive was easier to click and learn than the non tail recursive. It seems the later is more obvious and simple but now that I thinl about it was probably because I learned the data structure first and only then operations over it. On my university when I learned haskell and these concepts it was a build up from first simple recursive functions that could blow the stack and then multiple hours of turning it into tail recursive and multiple ways of doing it and why it mattered. 
\+1 for SICP - a lovely book.
Looks like you have it correct in `build.sbt` but `plugins.sbt` has `%%` when it should be `%` according to the website.
You need to actually learn recursion. SICP does an excellent job at this in chapter 1. There are also accompanying video lectures(first 3-4 or so?) that will explain it in a way you will understand. 
Thanks, remote work is a possibility. In office locations would either be San Jose, CA or Richmond, CA or Austin, TX.
I tried both ways at this point :(
You could try posting something on r/https://gitter.im/scala/job-board
Just noticed that you have `% play %` in `plugins.sbt` but the webpage says it should be `% sbt-plugin %`. So it's not the same thing in both files. Though I don't see this in Maven Central either so I'm not sure if that alone will fix it.
Aah, that might be it. I'll try tarring my files before caching them and see if that helps. Thanks!
\`implicit class extends AnyVal\` is not just too verbose, but also is not self descriptive in any way. I think it's a fine construct, and it's really powerful in conjunction with other features, but I think the language can go a long ways towards improving ergonomics for everyday application developers. This would make the language far more appealing to the mainstream. I personally think that a new syntax should go a bit further in that direction to merit its usefulness by letting people define extension methods as one-liners by doing something like \`implicit def circumference(this c: Circle)\`. (The surrounding object would be synthesized.) Or put the parameter list before circumference -- I think either way would be fine. I'm a huge fan for the enum feature, whatever form it eventually takes. Define data type hierarchies as ridiculously verbose compared to OCaml or Haskell, and for seemingly no particular reason. Probably 90% of my classes have no methods. With a really simple extension method syntax, maybe that would be even higher. You would know better than me what pitfalls there are of adding this sort of sugar. But assuming they can be addressed, I think it would be a massive improvement.
No, but what I wanted is to use information which already is in Scaladoc (e.g. @param or @return) at runtime.
&gt; Just a wanted to say that it is weird for me realizing that you are saying that the tail recursive was easier to click and learn than the non tail recursive. Yeah, I may actually be in the minority here. I think you're right. I was trying to translate loops and so that naturally lead to tail-recursion, but if you tackle it from the data structure point of view the non-tail recursive function may be more obvious. There were certainly situations in the red book where the tail recursive function was hard for me to glean. I recall foldLeft vs foldRight, for example, giving me some difficulty.
`plugins.sbt` needs to be in the `project/` directory rather than the root of the project; also the thing you're adding should be called `sbt-plugin` rather than `play` (as it is on the page you linked to). (I only figured this out by looking at https://github.com/playframework/play-scala-starter-example and seeing what was different)
https://imgur.com/a/NLfYzcq This is not OK 
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/e6uxzHc.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
So in the USA! Hard to reason about, but there are a few people outside of the USA who uses the internet yet 😈
Yeah. People talk about "referentially transparent" as though a function was either referentially transparent or not, but actually it comes down to whether something is "equivalent" to something else or not, and it's up to you to define what that means for your codebase. More concretely I tend to ask myself "if my refactoring changed this to that, would I care?" So personally when writing e.g. a web service I'm quite cavalier about e.g. writing log messages or even reading from the filesystem without tracking that via `IO`, because I really don't care whether I log a message once or twice, or read a file into memory once or twice. But if I was writing e.g. a file manager then I probably would want to use `IO` to keep track of what order I was doing filesystem operations in, because then it's quite important whether you do a file operation once or twice, and whether you read a file before or after you move it. Ultimately it's up to you what category this task falls into; personally I wouldn't worry overmuch about how many threads I spawn, but if you're doing an expensive computation then you probably do want to track/manage when that computation occurs, and not accidentally turn a single execution of that computation into a repeat or vice versa when doing what looks like a simple equivalent refactor.
This seems to be working! SBT update completed without errors, but the play framework didn't appear under External Libraries and I can't import anything play-related in my files.
Is Scattersphere intended to run in a cluster? If not, why does it depend on Spark?
That makes sense--I guess it's viewing IO (or effect-wrapped functions) not just as something that "does an effect", but more abstractly a function whose execution path you want to reason about.
IMO the main value of monadic style is that it lets you write code that you can reason about both operationally - the "actual execution" - and denotationally - as functions and values. This is kind of hard to see with `IO` because an `IO` value doesn't really denote anything - it's a "sin bin" for random effects that we can only reason about operationally. With e.g. `Either[String, A]` or `State[MyStore, A]`, you can reason about it operationally as "(a handle that you execute to get) an `A`, that might raise an error `String`" or "(a handle that you execute to get) an `A`, that might read or write to a `MyStore` state", and that's a useful perspective when you're reading code in `for`/`yield` style - it's a procedure where some lines (those with `&lt;-`s) might trigger effects, and you can reason about the execution of that procedure. But you can also reason about them denotationally as a value that's a `Left[String]` or a `Right[A]`, or a value that's a function `MyStore =&gt; (MyStore, A)`. When you think about it from that perspective the functions are much more complicated, but you can never get confused about what the effects are doing because there are no longer any effects, just plain functions and values. This is only sort of the case for `IO`, because `IO`s are only values in a pretty degenerate sense - the only thing you can really do with an `IO` value is to run it. (E.g. you can't even meaningfully say whether two `IO`s are equal). So personally I didn't get a lot of value out of `IO` until I was already quite familiar with monads in general, and even now I'm fairly skeptical about using it.
Not quite sure how you're running this. You need to create a new module with Scala support in order for IDEA to work. If you have a project open already, you can import a new module from existing sources, and select SBT for the module type.
&gt; This would make the language far more appealing to the mainstream. I don't think that helping people write more implicit conversions is the thing that prevented mainstream users from adopting Scala. &gt; I'm a huge fan for the enum feature, whatever form it eventually takes. I think everyone except Martin agreed 5 years ago that Scala needed to have better support for enums – I'm just not sure why the proposal today is literally worse in every aspect than some of the proposed designs back then. To be honest, I have a hard time seeing how saving _one word_ per enum at declaration-site is worth the hassle (at use-site you save nothing at all).
Try softwaremill, they have deep scala skills and are experienced at effective remote working. 
Seth from the Scala team at Lightbend, here. I'm working on: * helping Adriaan and Jason get Scala 2.12.7 out the door. We merged two more PRs today and are QA'ing a new release candidate. Details at https://contributors.scala-lang.org/t/2-12-7-release/2301/7 , even gorier details at https://github.com/scala/scala-dev/issues/558 * getting the Scala community build going on JDK 11 (https://github.com/scala/community-builds/issues/742) * constantly tinkering with Scala community build as always, things constantly break and need updating. gory details: https://github.com/scala/community-builds/commits/2.12.x * publishing Scala modules for Scala 2.13.0-M5. scala-xml is out, scala-parser-combinators is out, genjavadoc is out. details at https://github.com/scala/make-release-notes/blob/2.13.x/projects-2.13.md * working with library authors to help get their libraries published for M5 * setting up some more structure around Scala Code of Conduct enforcement online (working with folks at the Scala Center on this). stay tuned at https://contributors.scala-lang.org * fixing a bug in Fortify SCA for Scala (https://developer.lightbend.com/docs/fortify/current/) involving Scala 2.11 trait forwarders My "Compiler Plugins 101" talk from SF Scala is now online, longer 90 minute version (early-2018 version was 30 minutes): https://twitter.com/SethTisue/status/1042864355279163392 And also a 16 minute interview with me about Scala 2.13, Scala 3, compiler plugins, Lightbend, etc.: https://twitter.com/SethTisue/status/1042864944767590400
Decent article, horribly bloated website... 
I’m the author of this article. Thanks for your feedback, I’ll see what I can do about getting this fixed. 
IMHO every programmer should definitely give Scala a shot. I have been mostly a Java programmer for the past 8 years but I have also worked on Node.js and PL/SQL a lot. I tried Scala in a project few months ago and fell in love instantly. The harmony between OOP and FP is a big win. Also smart constructs like implicits and extensibility are major features. I would advise you to carry on your path of learning. Since you have good SQL experience, I assume you might be having a good understanding of databases. Couple that with good understanding of Scala, you could try out as a Data Engineer. Many projects that use traditional ETL and BI workflows are moving to a more scalable, distributed data processing architecture. Scala is turning out to be a very popular tool in this domain. Since you are also dabbling with other languages, I would also suggest you to pick up Python which should be relatively easy to get comfortable with. &amp;#x200B; All the Best!! Just keep learning and keep applying for the right jobs. You will make it!
There's always [r/ScalaConferenceVideos](https://www.reddit.com/r/ScalaConferenceVideos/)
Press Ctrl+Alt+R in Firefox.
I have already subscribed to that. What I want is, to get the interesting and knowledge talks out of the clutter on YouTube.
Hey it’s a great book, but don’t really think it’s suitable as a first book on FP.
Create a new play framework project in some empty directory and then copy across all the bits manually, eg the config, build.sbt, routes file etc.
it's on mobile
has there been any progress on opaque types. every day i want them more and more, and if they could be added they'd be a huge boon
I just started enabling -Xlint and -Xfatal-warnings, among a boatload of other wart catching flags in my projects. It's really helped keep my code clean. The most common thing that blocks compilation for me now is -Ywarn-unused, but I love it since it points out where code/imports i'm not using are so I can remove them.
You can check out scala exchange videos, for example (skills matter are generally sharing all videos from their hosted conferences and meetups the next day): https://skillsmatter.com/conferences/8784-scala-exchange-2017
We just relased a new version with 2.12.6 support: https://scalacenter.github.io/scalafix/docs/users/installation.html You should also check RemoveUnused: https://scalacenter.github.io/scalafix/docs/rules/RemoveUnused.html
yeah, I saw. I was curious, will this version be forward compatible or will it become incompatible once 2.12.7 is released?
I always use these [Scala flags](https://tpolecat.github.io/2017/04/25/scalac-flags.html) that /u/tpolecat recommends.
great! glad to hear. i'll begin using it in my projects then 
Can you open an issue? https://github.com/scalacenter/scalafix/issues/new
What prevents you from compiling scalafix on your machine?
there's a number of things. java 11 apparently has ```.lines``` for strings now, which shadows the scala implementation, and which scalafix uses a lot of. also, some stuff wrt java.home, though that may have more to do with my build environment than scalafix. I've posted the information in the bug report.
If you're referring to my screenshot, it was taken on android chrome in vertical view which made it completely unreadable. I cannot stress enough how important it is to resist the temptation to add annoying clutter and bars that limit the field of view (the header bar takes up 1/6th of my screenspace, that's unacceptable). If you fix it I will gladly read your article :)
This summarizes my initial struggle with this course, I was expecting to just learn Scala but Odersky tries to get you in the FP mindset/paradigm by using lots of recursion and some examples that can be a bit too abstract for an introductory class (they are not hard but they can present a struggle if you are not used to recursive models). &amp;#x200B; I am not complaining about this approach, is an awesome approach but can be daunting if you are in a hurry to learn the language itself. &amp;#x200B;
you're requiring a status \*object\* and not the class itself. fir it to work you would have to call the method as `count(list, Error("whooaa"))` &amp;#x200B;
Do you want to check for specific errors or want the more general separation whether it in an error? If the first: `count(list, Error("myError"))` If the second: ``` def isError(s: Status) = s match { case Ok =&gt; false case _: Error =&gt; true } list.count(isError) ``` or ``` sealed trait Status { def isError: Boolean } case object Ok extends Status { override def isError = false } case class Error(mesg: String) extends Status { override def isError = true } list.count(_.isError) ```
Haha I saw this and thought that maybe we were getting Union Types in 2.X 
A slightly more Scala-esque version (or more precisely, less Java-esque) would be: import scala.reflect.ClassTag def count[S &lt;: Status : ClassTag](list: List[Status]): Int = list.collect{case _:S=&gt;}.size &gt; count[Error](list) res0: Int = 1 &gt; count[Ok.type](list) res10: Int = 2 If you don't like the `.type`, you can always have: type Ok = Ok.type &gt; count[Ok](list) 
I never understood what people like so much about `-Xfatal-warnings`. I guess it just really doesn't play well with my coding habits, which are mostly: code like a pig to make it work, and then clean up before committing. When prototyping or developing code, I just really want to get the code to type-check and pass the tests ASAP, so I can _then_ focus on making it clean, robust and beautiful (doing these prematurely is a huge waste of time). At this point all other concerns are superfluous and just slowing me down. It is very common that I comment different versions of the same pieces of code just so I can quickly experiment (both statically and dynamically) with varying combinations of them. So it's very often the case that I have unused warnings (and others) floating around during that phase. Finally, I won't feel comfortable committing code that contains warnings, so I will end up cleaning the code and remove the warnings eventually. And even failing that, isn't the CI the tool supposed to make sure that we actually do? As opposed to micro-managing it on every single compiler run. 
If you remove the S and just say List[Status] it should work fine
I agree with you. This is why I think adding all these compiler flags by default is a bad idea: it nags you about things that an automatic tool could help you fix later when you really want to submit a pull request. These kind of checks should only take place after I'm satisfied with the semantics of my code, because nobody ain't time to yakshave!
I'm gonna finish the red book today. Any suggestions on what I should do next to learn more about FP? I thought about building something but also going through cats docs and how they allow to do FP sounds good. Any suggestions? Thanks
&gt;or want the more general count of errors? I don't care about the error messages, just want to count all the errors.
I really like this solution although I don't understand the function declaration. What is this `[S &lt;: Status : ClassTag]` ? And should the list parameter not be of type `List[S]` instead of `List[Status]` ?
`count` type parameter can be the one used to set the filter: ```scala def count[S &lt;: Status : ClassTag](list: List[Status]): Int = list.count { case _: S =&gt; true; case _ =&gt; false} count[Error](list) count[Ok.type](list) ```
&gt;trait EventSource { this: Actor =&gt; &gt; &gt;import EventSource.\_ &gt; &gt; // We're going to use a Vector but many structures would be &gt; &gt;// adequate &gt; &gt;var listeners = Vector.empty\[ActorRef\] &gt; &gt;// Sends the event to all of our listeners &gt; &gt;def sendEvent\[T\](event: T): Unit = listeners foreach { \_ ! event } &gt; &gt;... &amp;#x200B; &amp;#x200B; What is happening in this part???? &amp;#x200B; &gt; this: Actor =&gt; &amp;#x200B;
Does it prevent the trait to be mixed with anything that isn't an Actor?
Twitter | Senior Software Engineer | SFO, CA | onsite | full time | (N/A My team is hiring developers that are talking Python and Scala. Amazing team, amazing boss and great company. Warning: you will NOT write scala all day but it will be probably 50% python and 50% Scala. https://careers.twitter.com/en/work-for-twitter/201808/senior-software-engineer-infrastructure-management-services.html DM me if you have any question.
This is like an ultimate dream of mine (if ever finished). I hate working with Play. Generating swagger from it is pain. And usually you end up with incomplete specification anyway, since you need to manually enumerate even the implicit outcomes, such as malformed payload etc. I still do not understand how is it possible that the individual handlers are not typed in Play. Also, do you have any vision regarding Dotty? The combination of union types + singleton literal types might come handy. For example if the following `{ if(???) Ok(...) else BadRequest(...) } }` had a type `Ok[...] | BadRequest[...]` you would be able to generate pretty much complete swagger doc. &amp;#x200B; Yet, there is one thing, which I am missing both in my example and your project. How do you plan to provide descriptions of the individual cases for the swagger? Annotations? &amp;#x200B;
Hey there! I started this a week or so back, but haven't had the time to start filling it out. See [here](https://github.com/awesome-scala/not-yet-awesome-scala). I'd really love for a lot of people to get involved!
Yes, exactly. See https://docs.scala-lang.org/tour/self-types.html
`: ClassTag` asks the compiler for an implicit `ClassTag[S]`. That's necessary for `case _: S` to work. ClassTag is the Scala version of Java's `Class&lt;S&gt;`
Thanks, I knew you wanted to start this so I didn't create a repo. :D
The Scala Lang website has a Really Great getting started guide which will guide you through all of Scala’s most important features. It is better if you previous experience with Java 
You can always do something like: ``` scala&gt; list.partition(_ == Ok) res0: (List[Product with Serializable with Status], List[Product with Serializable with Status]) = (List(Ok, Ok),List(Error(whooaa))) scala&gt; list.partition(_ == Ok)._1.size res1: Int = 2 scala&gt; list.partition(_ == Ok)._2.size res2: Int = 1 ```
You can get rid of that crazy looking type: `List[Product with Serializable with Status]` with this ``` sealed trait Status extends Product with Serializable ```
Running on CI makes perfect sense too, I was focusing on local development instead :)
I believe this is [the tracking issue](https://github.com/scala/scala-dev/issues/504) for opaque types. Seems the implementation has been scheduled for 2.13.1 as of August 7.
Learn about cats, cats-effect, fs2. Use them to build stuff. Join us in the respective gitter channels for questions or discussion :)
this is how i got started years ago, and i recommend it too
[removed]
Thanks! I had a university course in Haskell and Prolog, and I felt I understood the basics well enough. Plus C++ templates are pretty close to functional programming as well. I appreciate the guides, I'll be sure to read through them. What are implicits, if you don't mind going into more detail?
One of the most interesting things about Scala is that it's very gramatically consistent in the sense that there aren't many restrictions on where language constructs can be used. Everything is lexically scoped, which permits some interesting approaches (e.g. method-scoped classes). In fact, you can think of Scala classes as closures carrying both state and behaviors.
It will eventually be written to run in a cluster. It doesn't necessarily depend on Spark; Spark is simply there such that it can be utilized by Scattersphere to run a DAG of tasks within the Spark server cluster. Same with Mesos, eventually. There's no reason to use Spark with it - it's simply there if you want to use it to distribute compute resources.
Aren’t these videos old? They were already published when the event took place in June. I guess they have been republished on the YouTube channel. Earlier they were made available on some other site 
also you can use notebooks like zeppelin or jupyter (via Apache toree) and embed resulted image to your notebook
The little voice in the back of my head that kept repeatedly screaming “WHAT BLACK MAGIC IS THIS?!” as I read through this article would like to thank you for it.
Thanks! I guess for learning cats the book "Scala with cats" is a good start? I thought about programming a server accepting TCP connections and handling a self-defined protocol and learn cats,fs2,.. as necessary. But I assume that first working through this book will give me a more complete overview. What do you say?
Great, I can finally watch them without having to peek at the html source to get the embeded youtube link. I wonder why they upload the videos again instead of making the previous videos public. On the other site that was used previously the videos were also hosted on youtube...
Implicits are function parameters that the compiler will look for in scope based on the type of the parameter. They are super powerful*, but also slow down compilation and are difficult to understand and give confusing error messages for beginners. An easy example that shows the power is a (de)serializer. Other languages either use reflection or do not support user-defined types. Scala can do it at compile time: ``` case class A(field: Int) implicit val aToJson: A =&gt; JsValue = ??? /* The library would define this */ def jsonToFile[T](path: String, t : T)(implicit serialize: T =&gt; JsValue) =&gt; ??? // User calls without implicits jsonToFile("a.json", A(1)) ``` * A lot of things other languages need language support for could always be done in Scala using implicits, e.g. extension methods, async/await, typeclasses.
So, if you've done the red book (with the exercises), you should be able to skim `scala with cats` fairly quickly, just to get used to the actual names and syntax in cats. The one think to watch for is that the book doesn't talk about `IO` and uses `Future` instead, which you definitely don't want to do when writing actual pure FP code
Thanks again, will do that. Can your recommend any learning resources for cats-effect or fs2?
The cats-effect doc are good, I'd start from there. We'll help on gitter as well if you have extra questions. For fs2, my talk [here](https://www.youtube.com/watch?v=YSN__0VEsaw) and Michael's tutorial [here](https://www.youtube.com/watch?v=B1wb4fIdtn4). Obviously we have docs as well, but not nearly as good as the cats-effect ones atm (contributions welcome!), so definitely come to gitter if you get stuck.
Scala differs from Java in the compiler. After compilation is finished both the Java and the Scala compilers output functionally compatible JVM bytecode. There are other Scala compilers that output native code and JavaScript, but you will probably be concerned with the JVM target. Scala differs from C++ in that it is garbage-collected like Java, and of course in a variety of semantic and syntactic differences. An interesting similarity to C++ is Scala's implementation of typeclasses–a polymorphism technique similar to C++'s concepts. For syntax gotchas, check out http://scalapuzzlers.com/ For experienced devs new to Scala, either Odersky's _Programming Scala_ or Cay Horstmann's _Scala for the Impatient._ You can access them online on Safari, likely through your public library. For practice, try http://www.scalakoans.org/
Thanks!
&gt; But Scala decided to go NIH instead. :-/ Isn't that the whole point of Scala? Otherwise Prof. Odersky wouldn't have bothered and we'd just be using Java...
See also the ScalaDays NY 2018 presentation about this: https://www.youtube.com/watch?v=lQNXwb66eQ8 It's too bad that the compiler itself needs to be re-compiled with macro libraries when your code uses macros. Otherwise it wouldn't be too much work to use this in Gradle as a replacement for the ScalaCompile task (or the equivalent in sbt, mill, bazel, maven, ant, etc).
makes you wonder why continue scala-native at all
Finally, some time to respond to Reddit messages :). Thanks for the kind words. Appreciate it. Regarding Swagger, I still try to figure out some nice way to add comments without cluttering the whole API description too much. So far I haven't found any. But I also hadn't the time lately to look closer into this problem. Regarding Dotty, I am eager to upgrade the lib when singleton types are a thing. Makes the whole API creation way smoother. But again, I hadn't the time to fiddle with Dotty so for.
fun, being independent of oracle, maybe using it as a phd project, having choice etc. btw: turning your question around you could ask the same question about graals native image tool since there are quite a few native compilers for the JVM already.
Symbolics library similar to Symja in Java, but based on mathematical typeclasses as in Spire. 
Wtf is this post history of yours? 
Not an experienced Scala developer either, just wanted to chime in since my pet project is an IRC daemon with Akka too. I'd be interested in some pointers as well.
Could be a bot 
Scala native provides better support for low level memory management - i.e. you can use stack allocation. I'm not sure if this is enough of a selling point, but it does highlight the different goals of the project. AOT compilers for Java have been around a long time. Graal is just the first official and free one. 
&gt; Scala native provides better support for low level memory management - i.e. you can use stack allocation. I used to follow up to release 0.3, and it didn't really have that. &gt; AOT compilers for Java have been around a long time. Graal is just the first official and free one. But that's the gist, being opensource (not just free), and being as general purpose as it is, unlike the others.
Just terminate the next call. The condition must be accessible. There is a lot of ways to do it. I would use closures. You can use functional parameter. 
All right! I'll contact you after releasing it on github.
Theoretically scala-native has much more room for optimization compared to graal. Also interopt with C is much easier with scala-native due to the usage of LLVM struct types (with Java C interopt is a massive PITA)
Not so easy. Incremental compilation (Zinc, which is used internally by Sbt, Gradle, Maven, Bloop, you name it) adds a couple of phases for API and dependency extraction (in addition to discovering your test classes, main methods, etc), and those phases call back into Sbt.
Can you recommend some well-written articles on understanding Tagless Final? Thanks.
I think this is a good one that motivates why you might want to use tagless final [https://softwaremill.com/free-tagless-compared-how-not-to-commit-to-monad-too-early/](https://softwaremill.com/free-tagless-compared-how-not-to-commit-to-monad-too-early/) &amp;#x200B; This is a good comparison to the free monad [https://medium.com/@agaro1121/free-monad-vs-tagless-final-623f92313eac](https://medium.com/@agaro1121/free-monad-vs-tagless-final-623f92313eac) &amp;#x200B; Here are a couple that are more "how to get to tagless final" from a starting point &amp;#x200B; [https://www.beyondthelines.net/programming/introduction-to-tagless-final/](https://www.beyondthelines.net/programming/introduction-to-tagless-final/) [https://blog.scalac.io/exploring-tagless-final.html](https://blog.scalac.io/exploring-tagless-final.html) &amp;#x200B; And here are some neat things you can do with tagless final &amp;#x200B; [https://typelevel.org/blog/2018/05/09/tagless-final-streaming.html](https://typelevel.org/blog/2018/05/09/tagless-final-streaming.html) [https://typelevel.org/blog/2017/12/27/optimizing-final-tagless.html](https://typelevel.org/blog/2017/12/27/optimizing-final-tagless.html) [https://typelevel.org/blog/2018/06/27/optimizing-tagless-final-2.html](https://typelevel.org/blog/2018/06/27/optimizing-tagless-final-2.html)
&gt; https://typelevel.org/blog/2018/05/09/tagless-final-streaming.html &gt; &gt; https://typelevel.org/blog/2017/12/27/optimizing-final-tagless.html &gt; &gt; https://typelevel.org/blog/2018/06/27/optimizing-tagless-final-2.html Excellent. Thank you very much.
As I suggested yesterday, I would express this as a `while` loop: def foldRight[Accum](accum: Accum)(f: (A, =&gt; Accum) =&gt; Accum): Accum = if (isEmpty) accum else { var _accum = f(head, accum) var _tail = tail while (!_tail.isEmpty) { _accum = f(_tail.head, _accum) _tail = _tail.tail } _accum }
I made this: [https://github.com/JohnReedLOL/pos](https://github.com/JohnReedLOL/pos) The way this is intended to be used is, assuming you don't have a debugger set up, you just click on your code and press **Command + Alt + Down** on Mac or **Ctr + Alt + Down** on Non-Mac to scroll through the print statements in the order in which they are executed.
Really great write up, definitely shows how the abstractions provided by cats/scalaz can really make code clearer and simpler. 
Is there a roadmap for Apache Spark to upgrade to Scala 3?
The book is called "\_functional\_ programming in Scala". This would be ok in an OO codebase, but the mutation-based while-loop is not an acceptable solution for FP.
Sure it is. There's no violation of referential transparency, no side effects visible outside of the function.
I know. I’m just following up on what I told OP in an earlier chat. Do you have a tail recursive solution btw? I can’t see how it’s possible in this case.
Do we allow memes or low effort posts on this subreddit? I'm not against it per say, I just don't know if it's a thing.
Neither...I use coflatMap because it's cats
Yes!
You may regret that, not anytime soon though, it's going to take a while for sbt to resolve all the memes that need posting.
That + should be a •. 
**iHeartRadio | Senior Software Engineer | New York, NY USA | ONSITE | Full Time** &amp;#x200B; I'm looking for a detail-oriented software engineer to join our backend services team. Our team develops the core APIs that power the client applications used by millions of users daily. We primarily use Scala (with a few legacy Java components) and deploy/run our code in Kubernetes. We also create and maintain some data pipelines to import/export data to other internal consumers. As part of our team, your responsibilities would include designing/building new features, maintaining high code quality via tests/code reviews/metrics, and keeping a focus on continuous improvement on all parts of the development process. Our team takes prides in having high quality code and developing in a principled fashion. &amp;#x200B; For more info (and to apply) please see our job description ([http://jobs.iheart.com/job/senior-software-engineer-scala-1077327/?gh\_jid=1077327](http://jobs.iheart.com/job/senior-software-engineer-scala-1077327/?gh_jid=1077327)) or message me!
**iHeartRadio | Senior Software Engineer | New York, NY USA | ONSITE | Full Time** &amp;#x200B; I'm looking for a detail-oriented software engineer to join our backend services team. Our team develops the core APIs that power the client applications used by millions of users daily. We primarily use Scala (with a few legacy Java components) and deploy/run our code in Kubernetes. We also create and maintain some data pipelines to import/export data to other internal consumers. As part of our team, your responsibilities would include designing/building new features, maintaining high code quality via tests/code reviews/metrics, and keeping a focus on continuous improvement on all parts of the development process. Our team takes prides in having high quality code and developing in a principled fashion. &amp;#x200B; For more info (and to apply) please see our job description ([http://jobs.iheart.com/job/senior-software-engineer-scala-1077327/?gh\_jid=1077327](http://jobs.iheart.com/job/senior-software-engineer-scala-1077327/?gh_jid=1077327)) or message me!
so long as you promise to remember that monads aren't really boxes ;)
Wait I thought they were burritos... /s
&gt; I don't think that helping people write more implicit conversions is the thing that prevented mainstream users from adopting Scala. I'm not talking about implicit conversions; I'm talking about extension methods. Even though it's more of a library feature, it's pretty common in my experience to use them at the application level too. The current approach is hella cryptic. &gt; I think everyone except Martin agreed 5 years ago that Scala needed to have better support for enums – I'm just not sure why the proposal today is literally worse in every aspect than some of the proposed designs back then. I actually don't care that much about actual enums. I'm a big fan of the use of that feature to make ADT definitions much more fluent.
&gt; Is it possible to refactor the foldRight to be tail recursive and still allow early termination when the predicate is evaluated to true in the exists function? I don't believe this is possible, certainly not in the general case. Even though `exists` is short-circuiting the recursion of `foldRight` by taking advantage of the non-strict evaluation of its second argument, `foldRight` normally accumulates its result from the end of the sequence to the beginning. If the result of `exists` is `false`, then the (non-tail) recursion has to go to the end of the sequence to determine that. For a sequence which has a natural traversal from beginning to end, but not from end to beginning, `foldRight` must store information somehow to support an end to beginning traversal. In this particular implementation, `foldRight` is using stack frames (via recursion) to store that information. If you were dealing with a reasonably short list, you could implement `foldRight` by reversing the list (using tail recursion), and then `foldLeft` (tail recursively) on the resulting list. In that case the information would be stored in the heap, in the form of the `Cons` elements that you use to build the reversed list. If you had a doubly-linked list, then you could tail recursively traverse it from end to beginning as easily as from beginning to end. So whether tail recursion is possible really depends upon the type of data structure you're traversing and whether that order of traversal is natural for the data structure. In this particular case you are dealing with a Stream, and Scala Streams (if not the ones in this example) actually can be of infinite length. So reversing such a Stream in order make a tail recursive `foldRight` is not an option. On the other hand, if you implement `exists` without using `foldRight`, it is possible to do it tail recursively, because `exists` doesn't care about the order in which elements are evaluated. If the data structure supported it (e.g. an array), you could even use multiple threads to implement `exists` in parallel. That is not the case for `foldRight` and `foldLeft`, which are inherently sequential operations. 
what would that look like? 
 def foo(name: String, size: Int): Foo = { val _name = name val _size = size new Foo { override val name: String = _name override val size: Int = _size } } Is there a better way to let the foo method and the Foo trait have params / members with matching names? Needing these temp variables in this scenario is really annoying. Am I missing something? Is this considered an anti pattern?
Early termination arises out of \`true\` being a fixed-point of \`||\`. In its general form, \`foldRight\` doesn't know properties like that of its \`f\` argument and therefore cannot exploit them. You can write \`exists\` in a tail-recursive form and exploit your knowledge of the properties of \`||\` to affect early termination. It looks like \`\`\` @tailrec def exists(p: A =&gt; Boolean): Boolean = this match { case Nil =&gt; false case Cons(h, t) =&gt; if (p(h)) true else t.exists(p) } \`\`\`
* How does Scala differ from Java/C++? How is it similar? Scala offers Java-like OO capabilities, but has different sensibilities. Coding in Scala you'll rapidly be exposed to new ideas arising from Functional Programming techniques as they are applied in Scala. As an example, Java has generics but Scala takes them much further. * What syntax gotchas should I be looking out for? There are a whole ton of syntax gotchas in Scala---it's pretty complex syntactically. Some that come to mind include implicit conversions, the awful `++` implicit syntax, automatic method conversion failures, and case-sensitivity in pattern matches. It's hard to answer this question conclusively. * Since Scala compiles to bytecode and is compatible with Java, is it safe to assume that garbage collection occurs? Yep, absolutely. * Is there a good primer resource for experienced devs who are new to Scala? There are a whole load of resources on the side bar. If you're familiar with Java and trying to dig into Scala, however, then you may want to challenge yourself to learn the functional side of Scala. For this, Runar and Pauls _Functional Programming in Scala_ is by far the best. It can be quite challenging, though. * What would you recommend for practice to learn Scala?
This isn't a place where you need generic/type parameters. ``` def count(list: List[Status], target: Status): Int = list.count(elem =&gt; elem == status) ```
m50d got it already, but I'll try to describe it another way. The key issue with tail-recursive handling of `FlatMap` is that `FlatMap(x, f)` is composed of two `IO` stacks, the `x` and the result of `f`. We could simplify `FlatMap` slightly to the following form `case class FlatMap[A, B](x: IO[A], f: IO[B]) extends IO[B]` where I've just made the second argument into a direct value instead of a function. Now we see the underlying structure that was hidden by that function: `FlatMap` induces a binary tree! Any binary tree requires some form of care if we want to traverse it in a stack-safe manner. In particular, we can maintain a manual stack and manage it ourselves (similar to the trampoline method) or we can continuously rotate the tree so that it unfolds into a list as we traverse it. The complex `run` method does the latter. It "reassociates the flatmaps" to the right which you can see as a tree rotation pushing the nested structure on the left on to the right so that we can make incremental progress in a single step (and don't need to maintain a stack). So this then gets to why `forever` isn't poorly behaving. Despite being infinite, it's _always right associated_ and therefore has a "tree" structure that's just a totally right-biased linked list. This won't trigger a need to maintain a large stack and thus works perfectly. The trick that's required to make `forever` go is the way that laziness interacts with the function parameter of `FlatMap`.
We need more of these ‘learn through meme’ posts.
&gt; It's too bad that the compiler itself needs to be re-compiled with macro libraries when your code uses macros. There are ways you can fix this in the native graal image by packaging all the jars that define macros (and its dependencies) together with the compiler jars. Graal (or Scala Native) could do so. The problem is when your build *does define* macros. In that case, every time you make a change in the macros module you would need to link the native image again. And yeah, Zinc would need to be part of the graal image too.
Thanks!
I am trying my best [here](https://twitter.com/impurepics) 
Has the author considered using Writer? If so, why not. I suspect it wouldn't work because WriterT would order the effects incorrectly and there's so equivalent of an IO transformer. Then there's also the issue of parameterizing over the inner effect in a transformer stack. None the less it seems like an omission to not mention Writer.
Gradle feature request: https://github.com/gradle/gradle/issues/6905
This looks like a constructor for an anonymous class. You could instead give it a name and a regular constructor possibly with an \`apply\` companion method. Simplest way to do all of that is \`case class Foo(name: String, size: Int) extends Foo\`. Then you would call \`Foo(...)\` instead of \`foo(..)\` for creating the instance.
Oh, and here's a good talk I just watched that was published the same day I made my previous comment :D. It walks through converting an imperative program to a monad transformer program to a tagless final program to one based on bifunctor IO. https://www.youtube.com/watch?v=y_QHSDOVJM8
Not sure in all honesty, one the engineers in our team mentioned something similar. I'll reach out to the author and try and send him this way :)
I'm not sure what definition you are thinking of that uses `Writer`? Since we have `type Writer[L, V] = WriterT[Id, L, V]` and `WriterT[F, L, V]` is essentially `F[(L, V)]`, defining `IO[Writer[L, V]]` is like defining `IO[(L, V)]`, which is our `WriterT` again. Am I missing something?
Thanks for your explanation! The way I see it, logs are a result of other `IO` actions (e.g. logging a message saying some part of a process completed successfully). This way, I can't see how those logs could ever escape the `IO` context (they have to be in `IO`), and the order of effects aren't wrong that way. It's a limitation that logs get lost if we encounter errors (as mentioned in the blog post), and you have to decide, based on your circumstances, if that's acceptable.
Logging is inherently stateful, however it's debatable if it's inherently a side-effect. That said, it might be interesting to consider writer that is an alias for `WriterF[F[_], L, V] = (F[L], F[V])`, where you independently build a two programs, one logging what the other does.
That does sound interesting, and like it could probably work. I guess the trickiest part is nicely dealing with log accumulation for separate parallel processes.
Nice. And the second case can be refactored to, `p(h) || t.exists(p)`
The Scala standard library is full of mutating code like this.
Thanks! Yes, you can definitely create a `MonadLog` instance using a `Ref`, but that also means logs from parallel processes will get mixed up. If you know of a nice way to avoid that, then I'd be curious to hear about it!
Airframe doesn't play well with functional programming though. If you want runtime construction of tagless final algebras – try [distage](https://izumi.7mind.io/v0.5.50-SNAPSHOT/doc/distage/)
&gt; Hmm, fair enough (though I think that's a change since the last time I saw them). But anything that can't run in parallel is no substitute for Future, and anything that can run in parallel still can't give you principled control over parallel behaviour (because sometimes it's impossible to run a monadic construct in parallel, but possible to run the equivalent applicative construct in parallel). The best that it's possible to offer is a monadic construction that will parallelise on a best-effort basis, and that's what stdlib Future already does. What's the problem with principled control? Just use `parTraverse` to run in parallel, or the Parallel Applicative instances. &gt; Then why talk as though these things are replacement for Future? Future isn't and was never meant to be a replacement for Eval. They overlap. Green threads model they implement is a replacement for Futures. &gt; Side effecting calls are side-effecting. r.nextInt will return different values depending when you call it. That's got nothing to do with Future though, the exact same thing would happen with e.g. Option. Option doesn't capture the computation – only the result, it's consistent in this case. &gt; Well, you haven't been specific about what your problem with Future was. But if we do the exact same example as your link in Eval rather than Future, we get the exact same behaviour It will only behave like that if you break Eval's contract – `later` is for pure lazy computations, it's implementation is not RT for non-RT closures. Try your example with `Eval.always`, or with IO – https://gist.github.com/kaishh/9e6461b311c4dcd3fd09de88abdefa81 [This is](https://pbs.twimg.com/media/DiAbp_8W4AEVCbk.jpg:large) the fundamental problem with Future. Each Future value creates it's own *identity* with state, two similarly constructed futures are not the same future. It's not RT by the very definition of RT, regardless of whether you consider threading a side-effect or not. &gt; No, a monad instance for Future is a great idea. The one in cats works great. All you have to do is make pure call the right function (Future.successful). Using a strict constructor for .pure avoids only a little bit of nastiness, it, and Try, still blatantly violate monad laws (`Monad[Try].pure(???) != Try(0).map(_ =&gt; ???)`) – their instances are a very leaky abstraction.
The client have built a cardless payment system, that already had well over 1.5million users, with around 150,000 payments every week. They are using Scala to it's most functional: cats.effect.IO, Monix Task and Scala Future. Now into their series C with $55 million, they have new products in the pipeline and some big contracts with online retailers to manage. Able to hire both junior and senior engineers, with a very healthy relocation package on offer that includes: Temporary housing, a relocation budget, a "rent support scheme", Japanese lessons, and an office of people very willing to hlep as they have been through the same journey as you! if you would like to learn more, please follow the link or drop me an email on Tom@functionalworks.com. 
I have seen they hired some great engineers this year, good luck to them!
Wrong link, whoops :( Changing the link to the correct one now. 
The client have built a cardless payment system, that already had well over 1.5million users, with around 150,000 payments every week. They are using Scala to it's most functional: cats.effect.IO, Monix Task and Scala Future. Now into their series C with $55 million, they have new products in the pipeline and some big contracts with online retailers to manage. Able to hire both junior and senior engineers, with a very healthy relocation package on offer that includes: Temporary housing, a relocation budget, a "rent support scheme", Japanese lessons, and an office of people very willing to hlep as they have been through the same journey as you! if you would like to learn more, please follow the link or drop me an email on Tom@functionalworks.com. 
The original post 1 hour ago was the wrong link, and linked to a Clojure position, which I removed as off-topic. This is an actual Scala position, so I'll leave it here.
I'm afraid this isn't the right place to ask that question - this subreddit is about the Scala programming language, not the Scala tuning software. That said, judging from [the documentation](http://www.huygens-fokker.org/scala/scl_format.html), you can create .scl tuning files with any program that supports plain text files. So Notepad would be a suitable choice, while Word would not.
i have update stack overflow question.
FYI Airframe supports higher-kinded types since 0.64 [https://wvlet.org/airframe/docs/release-notes.html#064](https://wvlet.org/airframe/docs/release-notes.html#064), so we can use bindings for tagless final patterns. 
I think you may be confused what whiles with the `.scl` extension are. Scala programming source files are typically use the extension `.scala`, with `.sc` sometimes used for scripted source files.
Fixes to sbt. Yes. Please, more of this. Can't believe how scala repl or sbt command interface has been one of the most broken and weird compared to any other sane interface on the command line. One of the only ones I've used that's actively frustrating. This pleases me very much. Great effort everyone involved. Thanks. 
How would I go about writing a code which takes a date as input from the user and outputs the following date? 
@Japgolly found a regression unfortunately. https://twitter.com/japgolly/status/1045449111330119682?s=09
Oh, so I cannot migrate my Scala.js project yet. Oh well.
Living in Tokyo, what a dream for a weaboo like me :B
As [**u/DanielShuy**](https://www.reddit.com/user/DanielShuy/) explained you can "ask" the method to return a `Try` instead of an `Either` But in case you want an `Either` and you feel like `Either[String, ?]` is a lot of boilerplate you can always create a type alias `type Result[A] = Either[String, A]` and call `toJson[Result, String](content)`
if you want to find out more, please don't hesitate to get in touch with me! 
&gt; At which point you're giving up on the monadic niceties (e.g. for/yield syntax). Which is a legitimate tradeoff for some use cases, but not the only option. Sometimes clear syntax and best-effort performance is better than the converse. If you use Futures with for/yield – they will run sequentially, so I'm not sure what exactly you're saying. &gt; What on earth are you talking about? The example code you showed will have exactly the same behaviour with Option as it does with Future. Because Option does not capture the computation, it captures just a value. It doesn't have anything to do at all with how the value was computed. `Option(readFile("abc.txt")) == { val x = readFile("abc.txt") ; Option(x) }`, while `Future(readFile("abc.txt")) != { val x = readFile("abc.txt") ; Future(x) }`. &gt; Indeed - exactly like Future.apply If Future is only meant to be used with pure lazy computations, why are you talking about it as if it's a viable alternative to IO? &gt; Replace Future with Option and you'll get exactly the same behaviour. Again, not a problem with Future. Yes, exactly, when you run an effect outside of Option, then wrap the result in Option, your computation does not become RT. But the difference is that Option does not create any state – all side effects happen outside of Option and it has nothing to do with them, so the Option itself is consistent no matter what values you feed it. While Future wraps the entire computation and creates mutable state associated with it, it's not pure no matter what values you feed it. &gt; Monad[Eval].pure(???) != Eval.later(0).map(_ =&gt; ???). Future does not violate the monad laws (rather ??? violates the value laws). Ok, fine, both cats and scalaz-8 Monad encodings do not allow meaningful interaction with ???
What is a "newtype"? I see this mentioned a lot, but I don't really get what is is or what the motivation for something like that would be.
Your implicit converts a vertex to an option of model and neither of those findAllModels deal with Option[Model], they deal with List[Model]. Be aware I cannot read your code as it goes off the screen: https://imgur.com/a/tlTVEwM 
You can try this: ``` case class Vertex() case class Model() implicit def vertex2Model(v: Vertex): Option[Model] = ??? def findAllModels: List[Model] = { val all: List[Vertex] = ??? // all.map(v =&gt; vertex2Model(v)).flatten // all.flatMap(v =&gt; vertex2Model(v)) all.flatMap(v =&gt; v: Option[Model]) } ``` The reason why (a) doesn't work is because you need a implicit conversion like this: ``` implicit def vertexList2ModelList(v: List[Vertex]): List[Model] = ??? ```
&gt; If you use Futures with for/yield – they will run sequentially, without any parallelism Not necessarily - depending on when/how they are instantiated you can end up with quite a lot of parallelism. Of course this is uncontrolled best-effort parallelism that may be destroyed by refactoring, but sometimes taht
A newtype is an alias or wrapper that gives one type a new name. Giving it a new name makes it a distinct entity in the type system and allows you to create interfaces which are easy to understand and hard to misuse as well as add new behaviors. It's most common to see with primitives. Ideally, a newtype has exactly the same representation as what it wraps so that there is no run time overhead, only compile time safety. That is, if you wrap an `Int` then the compiler will treat it as if it were not the type `Int` but at run time you will have just those 32 bits without being wrapped in an object or allocated on the heap. For example, a database library might have a method like `connect(connectionTimeout: Int, idleTimeout: Int): Connection`. The could be called with something like `let conn = connect(3, 5000)`. What's not apparent when you read that without looking at the definition is what the 3 or the 5000 represent. Even if you know they're timeouts, which one is which? Are they milliseconds or seconds? One could just as easily write `connect(3000, 5)`, which would have totally different behavior, especially if you got the millis and seconds mixed up. I've had to fix a production issue due to precisely this kind of swap so it's not purely a hypothetical problem. To address these concerns one could add newtype wrappers such as `class ConnectionTimeout(millis: Int) extends AnyVal` and `class IdleTimeout(seconds: Int) extends AnyVal`. Then the method becomes `connect(connectionTimeout: ConnectionTimeout, idleTimeout: IdleTimeout)`. Now you have to create a `ConnectionTimeout`, which asserts "this `Int` is definitely my connection timeout", and it is completely impossible to switch the parameters. You can go a little further and add methods like class ConnectionTimeout private (millis: Int) extends AnyVal object ConnectionTimeout { def millis(m: Int): ConnectionTimeout = new ConnectionTimeout(m) def seconds(s: Int): ConnectionTimeout = new ConnectionTimeout(s * 1000) } class IdleTimeout private (seconds: Int) extends AnyVal object IdleTimeout { def millis(m: Int): IdleTimeout = new IdleTimeout(m / 1000) def seconds(s: Int): IdleTimeout = new IdleTimeout(s) } And now you can only create these by _also_ asserting that the `Int` you are using represents particular units, which the methods ensure are correct. This turns the final call into something like connect(ConnectionTimeout.millis(1000), IdleTimeout.seconds(5)) which has all relevant information present. There is no guessing about what the numbers mean and no possibility to accidentally mess then up, but they're still just an `Int` to the JVM.
Anyone have any thoughts about this subject? https://blog.philliptaylor.net/the-closed-source-scala-code-problem/
You do these?! They're great, thanks for your hard work!
&gt; Not necessarily - depending on when/how they are instantiated you can end up with quite a lot of parallelism. (Of course this is uncontrolled best-effort parallelism that may be destroyed by refactoring, but sometimes that's a worthwhile tradeoff) Ok, but that would be exactly **LACK** of [principled control](https://pbs.twimg.com/media/DiAbtVYXcAEGSP_.jpg:large), not gain of it &gt; How so? If we don't care about forking threads then Future(readFile("abc.txt")) and { val x = readFile("abc.txt") ; Future(x) } are equivalent (or at least, it is often a useful perspective to treat them as equivalent - even e.g. Some(1) and Some(1) are not absolutely equal (System.identityHashCode will distinguish them), all our monad laws etc. are defined in terms of what we consider equivalent). Replace `readFile` with `readLine` or `while(true)`. It doesn't matter if you care about forking threads or not, `val` version will block forever, `Future` version will keep going and return a result. It's absolutely not useful to think of them as the same, there's just no point! &gt; I'm not! All I'm claiming is that Future is a) a perfectly legitimate monad, law-abiding in the same sense as most Scala monads b) sometimes useful. If it's only useful as a monad when used with pure computations, and not when used for most of the stuff it's used for normally, then, well, it's still not really that useful &amp; it's instance is misleading people into believing that it can be reasoned about as any other monad, or used to manage asynchronous effects instead of IO. &gt; Future is pure provided you don't use particular unsafe APIs (which is the same situation as e.g. IO). Any given `IO` value is always pure, there are no 'unsafe APIs' to create an impure IO, it always captures and replays the closure as is, with no identity attached. &gt; The implementation of Future may contain mutable state just as internal implementations of e.g. parser combinators often do, but lawful code will never observe any mutation. Any given code can observe it trivially, by just using normal `val`s. If you mean that Future behaves well with pure values, that's not as useful and it means that it's in an entirely different domain from IO. 
I have no idea why the formatting of the code is wrong it appears fine to me. This is a bug in reddit. But I've reproduced what I see here. Thanks for letting me know. https://imgur.com/a/slLeqtK
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/3ch4oao.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) ^^| ^^[deletthis](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=delet%20this&amp;message=delet%20this%20e6t38c2) 
You're only shifting by multiples of 8 and with 1k random values your max is highly likely to be large and positive. With large positive numbers and multiples of 8 shifts &lt;= 24 bits are likely to still return something positive, and then shifts start repeating at 32 bits. So you're really only seeing 4 unique values, all of which are likely to be positive. Infinite loop.
&gt; bits are likely to still return something positive, and then shifts start repeating at 32 bits. So you're really only seeing 4 unique values, all of which are likely to be positive. Infinite loop. Wait... Bitshift is done modulo 32? **Why**!? 
It's what most things do for 32 bit numbers. While C and C++ technically have (or at least had) it as undefined behavior most compilers would do modulo 32 shifting. The [Java language spec](https://docs.oracle.com/javase/specs/jls/se11/html/jls-15.html#jls-15.19) simply defines this to be the shift behavior. &gt; If the promoted type of the left-hand operand is int, then only the five lowest-order bits of the right-hand operand are used as the shift distance. It is as if the right-hand operand were subjected to a bitwise logical AND operator &amp; (§15.22.1) with the mask value 0x1f (0b11111). The shift distance actually used is therefore always in the range 0 to 31, inclusive. 
Looks great! I am going to be trying this library out in the near future.
For an example of capabilities, you can look at the source of the docs (https://github.com/shadaj/slinky/tree/master/docs), which itself is a Slinky app (that's SSRed to a static site). For simpler example apps, the templates are a good starting point: https://github.com/shadaj/create-react-scala-app.g8 and https://github.com/shadaj/create-react-native-scala-app.g8
I thought &gt;&gt;&gt; was looping but &gt;&gt; was not. No ? 
OMG YESSSS!
No, never heard of it before. Interesting. What were your results?
Curious to hear your results if you try j9
This is an update announcement, the library is not new. And examples are part of the really good documentation of slinky: [https://slinky.shadaj.me/](https://slinky.shadaj.me/)
You can run scala on the JVM just by including scala-library jar, see https://alvinalexander.com/scala/how-to-run-scala-sbt-packaged-jar-file-with-java-command So I don't see what would prevent you from using the Java functions 
Here’s a blog that might help: http://msdynamicscrmmeanderings.blogspot.com/2018/05/dynamics-crm-azure-functionapps-and-java.html. It covers using scala even though java is in the title.
/u/lauchpad45 by the way you never included a link to any article.
Is there a decent job board for remote scala jobs?
We have quite some Scala AWS Lambdas at AutoScout24. As long you have a jvm, you can spit out a jar out of your build process. For the cloud runtime it does not really matter what's in your jar. You should optimize for start time of the jar though and remove unused dependencies, e.g. by shade plugin to keep the size down.
Thanks Josh! :D
On AWS they freeze the machines which launch the jars, so if you have a steady stream on data flowing through the machines are recycled which is much cheaper. We are using this for data processing, so this is not really critical. Jar size is about 40-50mb I would say. If you want guaranteed quick response times I'd prefer Node.js, since this is much better on cold starts than jvm.
&gt; Ok, but that would be exactly LACK of principled control, not gain of it Well yeah, you can gain consistency by choosing to always take the bad case. Sometimes that's the right tradeoff, but not always. Fundamentally there are only three options here: disallow monadic composition entirely, run applicative compositions sequentially even when they could be parallelised, or allow parallel behaviour to differ even for equivalent constructions. Earlier versions of `IO` took the last option, and IME it's often the better choice. &gt; Replace readFile with readLine or while(true). It doesn't matter if you care about forking threads or not, val version will block forever, Future version will keep going and return a result. We only define equivalence up to termination - see all the fuss about general recursion, "fast and loose reasoning is morally correct" etc.. Plenty of monads behave weirdly if passed nonterminating functions (e.g. `Option#map(while(true){})` sometimes terminates and sometimes doesn't). &gt; If it's only useful as a monad when used with pure computations, and not when used for most of the stuff it's used for normally, then, well, it's still not really that useful &amp; it's instance is misleading people into believing that it can be reasoned about as any other monad, or used to manage asynchronous effects instead of IO. `Future` *can* be reasoned about as any other monad. It doesn't suspend arbitrary effects and has never claimed to; it's only IO advocates who are misleading people by claiming there's some commonality there. &gt; Any given IO value is always pure, there are no 'unsafe APIs' to create an impure IO, it always captures and replays the closure as is, with no identity attached. What's the (observable) distinction you're trying to draw here? If you pass an impure function into an IO and call `unsafePerformIO()` on it, you'll get an impure result. &gt; Any given code can observe it trivially, by just using normal vals. What are you talking about? I'm sure it's possible to observe mutation of a future by accessing its internal fields just as you can with parsers etc., but both those things are cases of "don't do that then".
*then* never happens
It has to if you enforce it with CI.
I'm still doing a lot of work on the new `HashMap`s and `HashSet`s. In particular, we're trying to get as much structural sharing as possible in all the transformations on HashMaps and HashSets. I've also been writing a lot of property tests for the collections (especially Map and Set).
[removed]
Put a few `println` statements in `loopsForever`, one just before the `while` loop to print out values of `maxValue` and `it`, and another just inside to print out whatever you would like to see about your boolean test in the while loop. This will take only a few minutes, and you won't have to think too hard about it.
Link seems to be dead or else I might have thoughts on whatever that is.
if you have java 11, there's an inbuilt graal compiler.
 I'm not sure if it has a name, but it reminds me a lot of Clojure's style of interop with mutable objects + void/Unit methods: (doto (Thing.) (.update) (.update)) https://clojuredocs.org/clojure.core/doto
The technique to constantly display the log at the same position in the terminal is really useful. I've always wondered how certain console applications achieved this. Can't wait for this feature to be released.
Do you need to process/transform the data? If yes, what kind of processing/transformation do you need?
It's one of the avian combinators, this one is the particular is a variant of the Kestrel that return unit instead of being polymorphic.
I think older versions of scalaz called it 'tap' 
No, tap is when you have a functor and you examine its contents for a side effect but then return that value. fa.tap(println): F[A]
The data formats will need to be normalized and some basic transformations and aggregations will need to be done such as calculating averages etc The data volume will not be high
To be honest I haven't used the other ones. I've used it to build a ML library and haven't had any issues with it.
If you're already using (or planning to use) Kafka, I would suggest Kafka Streams, as it is very easy to set up on top of Kafka, and also integrates easily with many other external data sources with Kafka Connect. If not, if you want something quick and dirty, and if it is unlikely you will ever need to scale horizontally, you could simply build a simple REST API backend and write the transformation/aggregation functions yourself (I will not provide a comparison of Scala web frameworks here as there are already plenty of them you can find online).
Please do the same for compilation errors. I always have to scroll through all of them , fix first few, recompile and repeat. Everything but the first ~5 errors is completely irrelevant most of the time. Please please please ;)
I might be biased because I have to use it a lot (at Skymind), but ND4J is very cool and getting better. For example lately we've added support for reading [serialized numpy arrays](https://github.com/deeplearning4j/deeplearning4j/blob/c44ce4c209c1dc4c5ac263e7d967aad073b1ce19/nd4j/nd4j-serde/nd4j-base64/src/main/java/org/nd4j/serde/base64/Nd4jBase64.java#L96) and loading and running [tensorflow graphs](https://github.com/deeplearning4j/deeplearning4j/blob/451dd76b50355358dc176f2b704e98c43423c5b8/nd4j/nd4j-backends/nd4j-tests-tensorflow/src/test/cpujava/org/nd4j/tensorflow/conversion/GraphRunnerTest.java#L53) and [auto-diff](https://github.com/deeplearning4j/deeplearning4j/blob/9b858cccdff031d52401c8203313847139e44ad9/nd4j/nd4j-backends/nd4j-tests/src/test/java/org/nd4j/autodiff/samediff/SameDiffTests.java#L136) (Which [can look really cool](https://github.com/wmeddie/schain/blob/master/src/main/scala/schain/examples/ExampleNet.scala#L18) with some help from Scala) . It also supports a ton of platforms including Power and ARM (our CI infrastructure is insane). You can see it in action inside [DL4J](https://github.com/deeplearning4j/deeplearning4j/tree/master/deeplearning4j), [FastML4J](https://github.com/rzykov/fastml4j) . I'll admit the Scala wrapper could be better though, the community has been doing a pretty good job keeping it up to date, but with a little love it could be amazing.
Apart from all the flashy stuff, at it's core it's not a just matrix library but a general tensor library that is trying to be as powerful as numpy. We think you should be able to do real scientific computing in a managed and type safe language like Scala while getting near C++ performance.
Sorry, I moved my site to docker / lets-encrypt and have been suffering some "orchestration headaches". I realise now I should have made some independent Dockerfiles rather than this single, massive, fragile docker-compose file.
Nope, but seems like exactly what I need. I even thought about writing such a thing myself but seems I should have googled more intensively.
I guess \`tap\` is overloaded. See here: [https://github.com/typelevel/mouse/blob/master/shared/src/main/scala/mouse/any.scala](https://github.com/typelevel/mouse/blob/master/shared/src/main/scala/mouse/any.scala)
Well, you can always use Id as a Functor to have it available on every value.
It's worth saying that Java is very much the exception rather than the rule in terms of having indefinite binary backwards compatibility. Even with e.g. C, you have people stuck on glibc `libc.so.5` (which it's increasingly hard to maintain a linux system with it installed on) because their binary-only libraries depend on it. It's even worse with e.g. a binary-only Python library. So while the problem is real, I'd just be clear that it's not really a Scala-specific problem.
In terms of specifically "functional" things, I think laziness is the wrong choice and kills usability of Haskell (because it means performance is noncompositional). In principle I'd be interested in moving to Idris, but there are a bunch of practical things that Scala does better than Idris (and often even than Haskell): dependency/project management, availability of non-memory-unsafe libraries, IDE support, top-notch compile-to-JS support, companies that will pay me to write it. And fundamentally I'm not entirely convinced that the disadvantages of having methods on objects outweigh the discoverability advantage. And while I'm willing to believe that there might be a better solution to record-like problems than OO subtyping, I don't think Haskell has found it. Of course in principle there's no reason there couldn't be a language with OO-style records and Haskell-style purity, but I'm not aware of one at even an Idris-like level of maturity/usability.
Funny how some people put away every single language that doesn't enforce purity at the language level as a BetterJava™.
Why link to a an 8 month old post?
Based on your requirements so far, I'd go for PostgreSQL and https://www.graphile.org/postgraphile/ to set up a simple GraphQL API on top of that. - PostgreSQL since the data volume is not high. Postgres supports writing stored procedures in Node with the PL/v8 extension: https://pgxn.org/dist/plv8/doc/plv8.html . You can write procedures to make HTTP calls, grab the source data, and store it. - Postgraphile and a GraphQL API since you want a thin client to access a single API and for visualization, it's useful for a frontend to grab different subsets of data for different graphs etc.
http4s seems promising, but beware that might require you to look at some Cats and fs2, sometimes
I have had some success with Scalatra.
Http4s
akka http
I've spent the last several months built with Scalatra a few REST web services that involve JWT. It's been alright. If I were to go back and do it again, I'd probably use http4s based on what I've heard about it and what people I've hired since I started on them know about it. I don't regret using Scalatra, though.
I'm going to make a shameless plug here. At my company we've been working on a REST framework of our own for the last couple of months. You can find it in our [commons library](https://github.com/AVSystem/scala-commons/blob/master/docs/REST.md). I'm actually really excited about it. It lets you build REST web services simply by writing Scala traits. In this aspect it's analogous to "classic" frameworks like Java's JAX-RS. However, it leverages compile-time reflection, typeclasses and other Scala powers for much better type safety and platform independence. It can also automatically generate [OpenAPI documents](https://github.com/OAI/OpenAPI-Specification/blob/master/versions/3.0.1.md) for your REST API. It's a very fresh thing and so far it has never been really announced to the public (even though it has always been available on github). For this reason frequent breaking changes in upcoming versions are very much possible. Nevertheless, I encourage you to take a look!
Definitely taking a look, thanks for sharing
Another solution is \`set maxErrors := 1\` or 2 or 5 or whatever. No plugins needed. :)
How do people structure their error ADT's in a Scala app. Do you wrap exceptions? Do you not use exceptions, and instead try and provide contextual information about an error (eg userId) etc? Do you have an ADT heirachy? I.e. product types containing several suberrors?
Is that related to the \`pos: org.scalactic.source.Position\` that you can see in tests? 
You may also want to look into Akka HTTP ([https://doc.akka.io/docs/akka-http/current/](https://doc.akka.io/docs/akka-http/current/))
What do you need the result type to be? If it's fine to have it as an `Iterator[Char]` you could do `Iterator(char) ++ buf`. If you need it as a `Source`, you could do new Source { override protected val iter = Iterator(char) ++ buf } 
I agree that having access to the source of your libraries (and a license to use that library/source should you fork it) is a good goal. I haven't personally needed a no-source library but if I had to choose one for my project I think I'd try to ensure that project is at least as actively maintained as my project itself is, and preferably backed by some large company that is unlikely to disappear in the next couple years. I don't really see this as a Scala problem though. It's a more general "how much control/influence do I have over my dependencies" problem, which affects every language and project to some degree. Java might be the only one that hasn't really had that issue at all in the last 20 years.
You may find some useful exercises [here](https://www.scala-exercises.org/).
I'm surprised no one has mentioned it yet, but if you wanted purity in Scala, can't you just use Scalaz or Cats?
Thanks. Could you share a job spec URL?
for functional programming you can try [https://github.com/dehun/learn-fp](https://github.com/dehun/learn-fp) master branch - TDD style course, answers branch - all the answers filled in
I doubt it - even the upgrade to Scala 2.12 is scheduled for the next release (2.4) and it took a while for that to happen. Since Scala 3 itself [is not scheduled to launch until early 2020](https://www.scala-lang.org/blog/2018/04/19/scala-3.html), I think it'll be even longer before Spark supports it.
The discoverability in OOP is achieved by a combination of two things: That the argument comes before the function syntactically, and that functions (methods) are overloaded on their first argument (the object). Putting the argument before the function is achieved by the commonly available `x |&gt; f` syntax. However, overloading is impossible or heavy in most functional languages, probably because it complicates the type system. However, it's important to note that the discoverability has nothing to do with inheritance, subtyping or dynamic dispatch.
It looks like you are constricting your type to IO, where the code expects constriction to \`F\[\_\]\`. I guess your User API is using just \`IO\`?
The last web service I built I used Finch and was very pleased with it. 
Not really. You can use an `IO` type but there's no way to enforce that you always use it, and a lot of libraries contain functions that perform unmanaged I/O.
I don't generally pass exceptions around; if I need a library function that throws exceptions I'll catch and convert them immediately. Occasionally if I'm calling several library functions in a row I'll use `catching`/`Either` to compose those together. Most of the time the only thing I actually do with a given error is display it to the user, so I tend to keep it as `String` or, at most, a java `Enum` of possible error cases. I'll add more structure as and when I have a use case that actually warrants it (e.g. if I've got a GUI form that has specific handling for specific kinds of form validation failures, then I'll make sure my validation failures include enough structure to drive that specific handling). But IMO there's no point coming up with some complex ADT hierarchy if you're only going to `toString()` it.
I like http4s because I like pure fp. I would recommend play framework if your not drinking the kool aid. I also like akka http, however it's easy for people to make a mess of actors, so be careful of that. Akka streams is really good though. 
The easiest thing is probably to do the prepend at the `Iterable` level if that works for your use case? Something like `Seq(char) ++: buf.toIterable`.
It's correct in this case. That was the original impetus for Scala. It's no coincidence that copy methods, field accessors, hashcode, equality, and setters (for vars) in case classes are the exact set of fields used to define what's referred to as POJOs in Java. Hell, XML literals are still a part of the language. You really can't avoid the comparison in this case because it is _verifiably true_.
I believe Odersky stated that his goal in creating Scala was to explore the synergies between OO and FP. That is not "BetterJava". He also stated that he felt it was more expedient to utilize the JVM, than to try and create his own (look at the generally inferior VMs in Ruby, Python and PHP for the reason why). This then created the need for Java interoperability. The reason for field accessors, hashcode and equality (and null references) is Java interop. While important to the success of Scala, this was not, as you claim, the "original impetus for Scala". I'm not sure why you are bringing up XML literals. Odersky admitted they were a mistake, and you know full well that they are slated for removal in Scala 3 (of course, there is a faction that doesn't want them removed, which is why they are still a part of the language).
"Now, during the Pizza and GJ experience I sometimes felt frustrated, because Java is an existing language with very hard constraints. As a result, I couldn't do a lot of things the way I would have wanted to do them—the way I was convinced would be the right way to do them. **So after that time, when essentially the focus of my work was to make Java better, I decided that it was time to take a step back. I wanted to start with a clean sheet, and see whether I could design something that's better than Java**. But at the same time I knew that I couldn't start from scratch. I had to connect to an existing infrastructure, because otherwise it's just impractical to bootstrap yourself out of nothing without any libraries, tools, and things like that. So I decided that even though I wanted to design a language that was different from Java, it would always connect to the Java infrastructure—to the JVM and its libraries. That was the idea. It was a great opportunity for me that at that time I became a professor at EPFL, which provides an excellent environment for independent research. I could form a small group of researchers that could work without having to chase all the time after external grants. " - Martin Odersky on [the origins of scala](https://www.artima.com/scalazine/articles/origins_of_scala.html) &gt;I believe Odersky stated that his goal in creating Scala was to explore the synergies between OO and FP. Yes, that's what it's now shifted to as Scala transitions to Dotty &gt;I'm not sure why you are bringing up XML literals. Odersky admitted they were a mistake, and you know full well that they are slated for removal in Scala 3 (of course, there is a faction that doesn't want them removed, which is why they are still a part of the language). Your tone is a little aggressive here. The point supports the claim, so I'm sure you understand why I would bring that up. I don't care if it's been removed in Scala 3 - that is an entirely different language, comparable to saying "oh I don't know why you bring up laziness in Haskell - Agda is strict!". The point is that they are in the language for a reason - because Scala was, at one time and still now to a degree, intended to be a BetterJava™️. Lightbend even teaches this in their training material - it's a non-controversial statement to make. 
To me, "Better than Java" is pretty different than "BetterJava". It implies a hard break from Java rather than an attempt to improve within its paradigm.
So what exactly is your definition of "Better Java" if not "A language inspired by Java to be better than Java, targeting the JVM"? Clojure is most certainly not in this group because it was intended to be a Lisp on the JVM (and same with Frege), while Scala explicitly built upon and attempted to improve upon basic Java features (boxing everything, streamlining POJOs, adding xml support,) as a result of the author attempting _to better java_. XML literals are evidence of this, yes. Because the Java ecosystem relies very heavily on XML. &gt;You can make this argument for any language feature not found in Java: pattern matching, implicits, higher-kinder types, etc... You could, but it would be a stretch. You could also argue that Scala is a Better Go™️ or a Worse Haskell™️, but considering it was trying to improve on neither of those, you wouldn't get anywhere. If you're going to split hairs over "better" and "better than", then we can peacefully agree to disagree, and I can continue shouting Haskell's merits from the rooftops.
I like this website for Scala exercise: [https://www.scala-exercises.org/](https://www.scala-exercises.org/) &amp;#x200B;
What are you trying to write ? Various FP concepts can be useful for various styles, various style can be useful for various projects. What projects are you working on ? If you want to write "functional" code simply avoid all in-pure function and never use mutable data structures.. done, that's FP. But various concepts can be expanded on and becomes useful depending on the problems you are tackling. Programming languages are tools, they have little inherent sense in them until you can think about using them to solve problem. You can't learn a hammer, you can only learn how to use a hammer in order to hammer nails.
https://www.manning.com/books/functional-programming-in-scala bible
You have to re-read the first sentence of the original post :)
Bad habit of skimming through posts
Sounds like you found the best books already. Advanced Scala using Cats is really an introduction to the basic Cats stuff, and doesn't go into how to build a real world app. It is however very nicely written and has exercises, I think it's worthwhile. Sam's book FP for Mortals describes building a real world app and is good guide to Scalaz. I believe one of the final chapters wraps things up using the finally tagless method. Less often cited but still really good from a business apps kind of point of view is Functional and Reactive Domain modelling. It covers FP concepts from a practical point of view including the usual suspects of GADT, Functors Monads and Applicatives. It covers Free Monads briefly but not finally tagless. Well worth a read. After that I'd go straight to the gitter channels and the individual documentation sites. 
Shameless Plug: I am author of [https://app.pluralsight.com/library/courses/scala-big-picture/table-of-contents](https://app.pluralsight.com/library/courses/scala-big-picture/table-of-contents) and have got good feedbacks so far! Nonetheless, I have focussed more on the functional style of Scala than on the object-oriented pieces. Please reach me out if you have any specific questions on Scala. Thanks
Hey, will be glad to help out with any questions on the pet store. &amp;#x200B; I covered it in my 15 minute talk last year - [https://www.youtube.com/watch?v=CEv9KrjTF8g](https://www.youtube.com/watch?v=CEv9KrjTF8g) &amp;#x200B; Things have changed since, but that is a decent overview of it. Also, would be interested if you did watch it if it helped at all.
As far as "functional way", I am still learning a lot myself. The community has been great in answering questions to that end. &amp;#x200B; The way I think about FP these days is to think about "principles". &amp;#x200B; In OOP, you have fundamental principles that you do not question, but greatly influence how you build systems. OOP has principles like encapsulation, marrying state and behavior, and everything is an object. This has a profound impact on how you write software. What is the first thing you ask yourself in OO when you have new behavior? A: Who (which class) this belongs on. All of a sudden when everything is a class, and you follow good separation of responsibilities, then how do all the classes "know" about each other? A: Dependency Injection / IoC, gave rise to Spring, Guice, and the rest. Solving problems using interfaces, base classes, and concrete classes gave rise to things like GoF design patterns. I can go on. &amp;#x200B; In FP, you have different fundamental principles. Again, you do not question, and once accepted greatly influence the way you build software. Principles include a) a function always returns a value (no throws) b) a function does not know of anything else in the world other than it's arguments, c) a function can make no assertions on its arguments and d) immutable everywhere (you can use vars inside if need be, there are good reasons to). &amp;#x200B; This also greatly influences the way you write software. New behavior? Write a function. Dependency Injection? Function arguments. Don't throw or use null. No setters, use copy. &amp;#x200B; Since you cannot throw, how do you short circuit processing? Use Monads. Since you cannot use null, use Option. Once these are pervasive in your code, you have to deal with them, so you naturally use for comprehensions (short circuiting), map, flatMap without even thinking about it. &amp;#x200B; Also, you avoid things that violate your principles. For example List().head throws an exception, so you do not use it. String.toInt also does, so you avoid it. You avoid all throws and use a suitable Monad (Either if you can do something with the error, or IO if you cannot). &amp;#x200B; Anyway, long winded. But accepting those foundation principles I mentioned and do not violate them, and then everything seems to fall into place pretty naturally.
I've been spending a lot of time recently on a partial re-write of [Avro4s](https://github.com/sksamuel/avro4s), a library that creates Avro marshallers and schema generators for Scala types at compile time. You can think of it as a bit like Circe but for Avro rather than Json. I've been addressing some of the long standing issues (mostly around corner cases that break the macros). I'm close to having 2.0.0 ready now.
I'm working on extending the `org.apache.spark.sql.Column` class to include add some methods that are currently defined in the `org.apache.spark.sql.functions` object. Spark forces you to write `lower(col("blah").substr(0, 2))` and I'd rather write `col("blah").substr(0, 2).lower()`. I'm doing this work in [spark-daria](https://github.com/MrPowers/spark-daria) in [this object](https://github.com/MrPowers/spark-daria/blob/master/src/main/scala/com/github/mrpowers/spark/daria/sql/FunctionsAsColumnExt.scala).
Hi. This is great! I'll definitely have a look into it! 
I've been on nearly the same page about half a year ago. FP Mortals gave me the overview on how to architect an application (hint: it's Tagless final). It was a great book and together with Advanced Scala with cats the primer on fp in scala. A list of good talks I heard at Scala days: https://youtu.be/MfpXcaG-Wog - (Advanced) Introduction to interpreters. https://youtu.be/yEYPf44rS2U - (Basic) Introduction to Monoids / Traverse https://youtu.be/w7FuQiSi48w - (General) Leverage the type system https://youtu.be/GWDyIV7Oxyc - (Basic) Monads etc. made simple https://youtu.be/y7QfAWIun2k - (General) Introduction to Monix Last words: Focus on one ecosystem (I chose cats) and bring a service to production. Had some wow moments when doing this. Testing async stuff is for example very easy with Tagless final, since you can plugin Id Monad instead of Task or whatever. Then your tests become sync and voila le wow!
You're going to have to scope it down to what you need to know for the job. Scala, the programming language, is notoriously complicated. &amp;#x200B; Is it possible they want you to be working at a higher level where you can get by knowing, say, the Spark API?
Thank you for your answer! Yes, would be full time (roughly 40 weekly hours).
Yes, I believe so. It has something to do with Spark. The project in itself is automating some big data tasks (not much info)
consider attending this course: &amp;#x200B; [https://www.eventbrite.com/e/functional-scala-by-john-a-de-goes-sf-silicon-valley-edition-tickets-49652715609](https://www.eventbrite.com/e/functional-scala-by-john-a-de-goes-sf-silicon-valley-edition-tickets-49652715609) &amp;#x200B; Then start coding and practicing. Joining and contributing to an open source project might be a good way to practice and learn too.
Well prof. Mark C. Lewis at Trinity University used Scala to teach CS1 and CS2 courses, and published several books about that...
If you just want to get some stuff done in Spark, have you considered Python? Python is a much easier language to learn for a non programmer. In addition, if you're using the Dataframes API, there will be little to no performance impact (unless you start using UDFs and UDAFs written in Python). 
When you see a fancy functional technique used, it's usually because it would be hard to write the desired code in terms of ordinary (i.e. RT) functions and values without using the technique. So I've found the best way to learn the techniques is in terms of the problems they solve: start writing code, and when you find yourself writing code that wouldn't be refactor-safe (e.g. "I need to do this sequence of database queries and it's important that query A happens before query B, but I still want them to be separate reusable functions") then look for a technique that will let you solve that particular problem in plain old refactor-safe code. I'd also say that the most important thing is working code that solves real problems. Don't be afraid to put an impure bodge in place if it lets you keep working; usually you'll find that this causes problems, but by experiencing those problems you'll better understand the benefits of doing it the pure way, and having a specific example of what can go wrong can make it easier to understand what the general property that you needed was. &gt; For instance, sometimes I see tagless final solutions where every function just returns a F (I can understand what a higher kindest type is) that ends up being materialised in an IO type like Monix Task, but I've also read somewhere that we should constrain (say from an IO to a Writer or Reader) for easier testability. Did this paragraph even made any sense? It did (though I wouldn't use "constrain" in that sense because it tends to have a specific meaning in these conversations). I found http://www.parsonsmatt.org/2018/03/22/three_layer_haskell_cake.html to be a very good perspective. The functional techniques are powerful but ultimately they exist to make it easier to use plain old functions and values; whenever you can write code directly in terms of plain functions and values it's better to do that.
&gt; but Scala is never the recommended first programming language for someone to learn programming As a teacher, I would totally use it as a first language. The basic syntax is quite simple and similar to what you learn in math class. Sure you have denote the parameter types, but that is reasonable because in programming we have more stuff besides numbers. def f(x: Double) = 2*x + 4 Once you understand the colon notation, you have already learned some UML. You can create a class in one line with equality as you would expect it. And you can ease into OOP by starting with `object` than abstracting that into `class`, when you find commonalities between objects. That's the bottom up approach a course should use. You can also use various classes before you know what they are, like `List(1,2,3)`. So yeah, I think Scala is top notch as a first language.
akka-http doesn't require you to use actors directly (and I'd recommend against doing so); just use the routing DSL.
This is very good advice. Thanks!
I might be the only one suggesting Finatra here. It might be not as idiomatic as akka-http or Finch, but allows to get job done quickly. It has lot of batteries included
Would you share a link please?
Very curious situation. How do you go from never programmed anything -&gt; getting asked to code full time in scala? Would your job be a full time programmer, or would you manage a spark project? I can imagine that to manage a big data project properly you might want to learn something about the technologies used, but I doubt you would have to actually learn programming. If your job is actually to program full time id say, considering no programming experience, a year or two to be a proficient programmer (in any language you pick). Learning the language is not the hard part, a programmer can learn a new language in a few weeks or months. What will be the major roadblock for you is all the general programming skills and just applying programming in general to solve problems, and thats whats important. 
Please keep in mind that functional code still needs comments and docs, and that the comments-to-code ratio will be even more extreme, given how concise functional code tends to be. Articles, talks, and books are made usually by lots of explanations and a little bit of code. Actual FP-style Scala projects are heavy on code and people usually skimp on comments, especially when it's a side or a pet project.
I've seen people do 4-year CS degrees and fail to learn how to program; I've seen people pick up enough to work with and the habit of learning more in a couple of weeks (not to say that you'd memorize the whole language/framework/... in that time, but you'd be able to write programs that worked and look up new things as you needed them). I've seen a study that gave people a simple programming test at the start and end of a programming course and got the same results each time, and argued that students either understood the concepts immediately or not at all. I appreciate that this isn't a terribly useful answer for basing a decision on, but I fear it may be the reality.
Still useful :) It reinforces the idea that the red book is must :)
I loved this talk too https://www.youtube.com/watch?v=y_QHSDOVJM8
AKKA-HTTP or http4s would be my pick. &amp;#x200B; There is a new one around that has similarities to Python's Flask if you want to look at but I have no experience with it: &amp;#x200B; [http://www.lihaoyi.com/cask/](http://www.lihaoyi.com/cask/) &amp;#x200B; &amp;#x200B;
I like this website, it has cool exercises: [https://www.scala-exercises.org](https://www.scala-exercises.org) 
In the sense in which you're talking about Scala being a good first programming language, I agree, and think that Haskell would be an even better choice. &amp;#x200B; In the sense in which I was I was talking about it (a situation where someone wants to enter the industry quickly and get things done), something like Python or Ruby makes more sense.
I’m working on my next course which might publish by next month Meanwhile, what topics are you interested in learning? I’m planning to start a YouTube channel to teach Scala, I can take your inputs for the initial videos, what do you think? Thanks
I’m working on my next course which might publish by next month Meanwhile, what topics are you interested in learning? I’m planning to start a YouTube channel to teach Scala, I can take your inputs for the initial videos, what do you think? Thanks
akka-http is really low level and I wouldn't suggest it. Play is a full featured framework, and I use it myself. Scalatra is more barebones than play last I used it, but not as much as akka-http. I don't know much about http4s
It's hard to go wrong with http4s, I personally don't care much for play.
Http4s is pretty damn good, however there is a barrier of entry wrt effects. On the other hand, other approaches are not exempt, http4s just refuses to sweep it under the rug 
Cask can also be a good option for someone without knowledge of Scala: http://www.lihaoyi.com/cask/. I've never used it myself, but I know it was inspired by Python's Flask. So, maybe this would be a easy option, although not the most functional one.
It really is a masterpiece imo. I would rank it higher than SICP already. I've never enjoyed a textbook as much as this one. 
akka-http is my go-to. its mature, has a clean api and nice support for things like streaming and websockets. scalatra is easy to use, but feels pretty clunky compared to akka-http.
This is the same question I had when looking through the documentations. It seems like Play is a full stack framework. Would it make sense to use it just for creating RESTful APIs?
I second this. Our group just switched from Java / Spring to Scala Play. The ramp up is a little painful, but I love it now.
How long was the ramp up? Also, are you using it with other frameworks/technologies? Sorry if it's a dumb question, I'm still fairly new to programing... 
I would say that you don't need templating (ie. Play framework) because you already have a front-end written, what you want is HTTP endpoints. It depends what you want to do with it, do you think you will need scalability ? Will you need some clustering ? Is it going to run inside kubernetes ? Is it going to run inside many datacenters and need data replication ? You can't go wrong with Akka Http, but it can be a little painful to pickup. I think you could also use Lagom which is based on Akka and it comes with all the Akka stuff, abstracted onto a framework. However, it is a very opinionated framework.
I am not very familiar with Play but after a quick google search, it seems that it used in conjunction with Akka for scalability.
I have built an extensive (200+ function) rest interface using Akka HTTP. There is a bit of a learning curve (functional reactive thinking) for basic HTTP and a steeper learning curve for Akka streams but both are invaluable. It scales like a breeze and has really good test infrastructure. 
I think you can should go for Akka-http as it has the needed flexibility for your project and as other comments mentioned Play is rather a full framework. I recently built a back-end service with akka-http for the first time, whole project with integrating with some other frameworks like Kafka and spark took roughly 1 month.
 val l = List(1,1,1,2,2,3,1,4,4,4,1,1,9) l.foldRight[List[(Int, Int)]](Nil) { case (elem, (headElem, count)::rest) if elem == headElem =&gt; (elem, count + 1)::rest case (elem, ls) =&gt; (elem, 1) :: ls }
Play is a good start if you're not used to Scala. It has a "Java feel" to it, which makes the transition easy. If you're interested in exploring the functional side of Scala, I'd also recommend Http4s.
Mine 😂 no just kidding I have some personal GitHub projects mainly for code reuse, they're not very well documented I think the play framework has a lot of documentation but is lacking real world examples. I've built up a lot of experience in the past couple of years so it's not a big deal but I remember at first I had trouble seeing things up properly. For instance the slick examples only cover the bare minimum and don't really scale well. I have personally created a Table -&gt; DAO -&gt; Service -&gt; Controller structure but it would be nice if something like this can be documented more extensively
fs2 is the place where I think better documentation would have the best power-to-weight. It's an extremely powerful/general/useful library (and there's a bit of similarity between what it does and what spark does), but the interface is a huge pile of methods that makes it very hard to know where to even start.
&gt; akka-http is really low level How so? You did find the routing DSL, right?
yeah, the performance is really good, especially for streaming data, which is key to my use case
I wrote a few more specific things on http://m50d.github.io/2017/01/23/becoming-more-functional.html which might give a bit of an idea of order, though it's a bit dated and sounds like you may already be past the things I talk about there. There's also the [lambdaconf ladder of functional programming](http://lambdaconf.us/downloads/documents/lambdaconf_slfp.pdf); while it attracted a lot of criticism at the time and of course the most important thing is what problems you actually have, I found it useful to have some sense of which techniques are the basic ones it makes sense to learn early and which are more advanced things that you might be better off leaving for later.
Oh, That's really cool. I think, topics like type-classes, implicits, async, futures are difficult. And then, on next level, things like monads, functors, category theory, are even more complex. I know, explaining these things are bit too much and self-study is the key here. And, I'm waiting for your next course!!
yes, and compared to play or scalatra i found it p low level
Seconded. Fs2 would be a great choice because of how ubiquitous it is on the FP side of scala
&gt; This tool helped me the most &gt; &gt;Getting confused about compilation errors? Scala-clippy can make some of them less vague. does it come with a poorly animated 3d paperclip that suggests sbt tasks for me to run?
You have mentioned Cassandra and there is actually a project related to that and (already mentioned) fs2! https://github.com/Spinoco/fs2-cassandra/issues
I mean from the point of view of someone doing a HTML UI it's low-level, sure, in that you'd have to do your own templating / form handling / ... - that's why it makes sense that Play is built on top of it. But the question is asking about a backend for react to talk to; for that kind of use case I can't see how akka-http is "low-level". Any concrete examples of differences?
Most of the pain is the same pain you need to go through for any Scala framework, so I advise picking the one that resonates best with you. I now use it for every project -- mostly Angular front end, Play for HTTP endpoints. We don't use templates.
Are you trying to make some kind of "original sin" argument?
A lot of the documentation is in gists and in Fabio's and Michael's head hehehe
\\o/
The guide is pretty good, though. I think that adding tut examples to all the methods would be extremely helpful, though, and some doc comments around Chunks, Pulls, and the concurrency primitives would also help.
This is great list, and also, would take some time to build. But these are definitely some topics on my radar to build videos on. Please be a little patient while I get the YouTube channel started as I told you my second course is in the making, and I will finish it up before starting the YouTube channel. Meanwhile, is there an email I could reach you once I have my Pluralsight course out or when the YouTube channel is up? Do you mind sending a DM to me. Thanks a ton again for showing the interest to learn, it fires me with in to finish up my courses faster! :) \#happyfriday and #keeplearning.
This is an awesome topic. I totally hear what you are saying. Every conference video is at least an hour long, and since there are so many of them, and as a learner you are looking for nuggets which might be * Better ways to use the language * A new library which makes the work easier * A better way to design the programs and projects * A better way to test * A better explanation to the concepts I thought about this in past and started with something like [https://medium.com/@harittweets/conference-video-review-field-guide-to-ddd-cqrs-using-the-scala-type-system-and-akka-ce6d1bb2bbe0](https://medium.com/@harittweets/conference-video-review-field-guide-to-ddd-cqrs-using-the-scala-type-system-and-akka-ce6d1bb2bbe0), however, I never got time to make more of these. But honestly, I loved the experience. I am willing to do more as I see, I totally love working with Scala.
Hi all, I'm sorry if anyone opened the website and couldn't read it's content due to overlapping menus. This is fixed now.
Ahh yes I do need to use Scala for the backend, as told by my boss. As for scalability, we're thinking it will be for thousands users at first and hopefully 1M+ in the future. It does require authentication and a mysql DB, and I need to maintain the project for at least a couple of years. 
This is amazing material! Thanks once again!
What are the constraints? Is it REST based? Do you need database backing? How good of an engineer are you? What other things have you done? Why did you choose scala? Are you an OO or FP programmer? The fact that you said "but not sure exactly what they are" is a huge red flag for me.. mainly because if you don't know what the frameworks are after finding them, then it means you haven't really explored their documentation or even tried to build something quick and dirty with any of them. We need a LOT more information to truly answer this question.
Awesome! I was waiting for this. I hope that a new version of fs2-kafka will be following soon. 
I agree with @pedrorijo91. It is you who are going to do this alone and you don't have colleagues which can help you out with Scala? Scala and the relevant libraries is a powerful and excellent tool when you have invested a *lot* of time in learning and using it, but the ramp up is very heavy. IMHO your boss would probably save a lot of money if he told you to do the backend in nodejs instead, as you already know (or already are forced to learn) JavaScript (or similar) due to the React-frontend. But if you are allowed to spend a lot of time learning Scala, it can be very valuable for your own personal knowledge/experience/career.
&gt;I'd recommend using rho as a layer on top of it rather than using http4s directly. I think that would be a mistake. Rho has almost no documentation and a very complicated implementation. If you get something wrong it gives terrible compile errors. On top of that it does not offer much on top of the standard DSL. 
thanks... if only half kidding, some small personal project might be a cool place for me to start. Obviously no charge. I could do it in exchange for feedback and a reference. PM me if interested (I have some background that makes me a good fit for this kinda work)
Woa! That tip for Akka Persistence is really valuable. Thanks I guess.
 import scala.util.Try val delete_before_write = true //can be true/false //Below, x should end up either as valid string or as an empty string val x = { if (delete_before_write) { val reported_time = Try( //intesive operations which can break //finally returns a timestamp "some_timestamp_as_string" ).getOrElse("") if (reported_time.nonEmpty) s"DELETE FROM tableName WHERE reported_time = $reported_time" else "" } else "" } println(s"x = $x") Better way to code and make it elegant? I feel this can be improved and scala-fy it. scala-fiddle: [https://scalafiddle.io/sf/xFvNMTM/2](https://scalafiddle.io/sf/xFvNMTM/2)
In both cases, you will have to install OpenJDK instead of Oracle Java.
The most up to date LTS version will still be free, as it always has been. So this won't affect Scala.
Thank you!
Cheers to the best library I've ever had the pleasure of using. You guys are great!
This isn't entirely correct. Old versions of Java no longer be free (i.e. future updates of Java 8 SE will not be free, however you will have Java 10 at the time). In 2019 the oracle JDK won't be free, but they have ported basically all functionality of Oracle JDK to OpenJDK (such as mission control). Furthermore, Oracle JDK is actually built intop of OpenJDK (ever since Java 8) &amp;#x200B; There is a lot of FUD going around in this area
Can I ask: why? &amp;#x200B; It looks awesome but whats the motivation for creating this? :D
Thanks for sharing!
Hi! Thanks for sharing! I'm one of the main developers behind Stryker4s. If you are interested in mutation testing, have a look at the [rest of the website](https://stryker-mutator.io) (it's pretty cool). We are also [working on a sbt plugin](https://github.com/stryker-mutator/stryker4s/issues/2) to greatly increase performance and easy of use. If anyone has any questions, don't hesitate to ask :)
I'm just starting out with cats and have been looking at libraries that use it: http4s, doobie, etc. However, I still haven't quite wrapped my mind around the basic concept of structuring the overall application that relies on effectful monads such as \`cats.effect.IO\`. I get that, in theory, the program should be composed of smaller independent pieces that "snap" together. However, I'm not very clear on what to do with heavy-weight and/or commonly-used objects - are they supposed to be strung along from the periphery through the entire stack of function calls? &amp;#x200B; Consider the following: package com.example import cats.effect.{ExitCode, IO, IOApp, Resource} import doobie.hikari.HikariTransactor import org.http4s.client.Client object ExampleApp extends IOApp { def run(args: List[String]): IO[ExitCode] = { val httpClientResource: Resource[IO, Client[IO]] = ??? val txIO: IO[HikariTransactor[IO]] = ??? for { tx &lt;- txIO code &lt;- httpClientResource.use(client =&gt; actuallyRun(client, tx)) } yield code } def actuallyRun(client: Client[IO], tx: HikariTransactor[IO]): IO[ExitCode] = ??? } Above, there's a top-level for-comprehension that "exposes" instances of high-level dependencies used throughout the code. Is this the standard approach? Are there alternatives? What happens when an app uses more than just two dependencies?
Great work! [Here](http://simerplaha.github.io/html-to-scalatags-converter/) is another one though :)
You don't actually need the recursion, you can just do it with ranges: def stars(n: Int): String = ((1 to n).reverse ++ (2 to n)).map("*" * _).mkString("\n") Let's say you'll pick 4: The first range will be 1 to 4, you reverse that. The 2nd range will be 2 to 4, you'll take that as is and add it to the first range (using ++). Then you'll get a list: List(4, 3, 2, 1, 2, 3, 4) Then you map each element and multiply "*" by the element, giving you the stars for each line. Finally, you'll joint them all together using mkString. A recursive solution would probably be possible, alltough more complicated. At least I can't think of an easy solution right now.
Yeah, I'm not sure. Functions are degenerate relations, and relations are essentially tuples (we can define a relation as the set of tuples that comprise it). So I'm not sure what the author is getting at. I've also never seen "complexity" measured in this way. I'm certainly fairly familiar with FP, but I'm not plugged into the research space. Maybe that concept is more common there. 
Heh, that's how I feel, too. 
The easy recursive solution is not tail recursive, maybe that’s what you’re missing.
Oh interesting, thanks for the correction! I don't remember the page i read on the Oracle site mentioning the two builds.
Hehe... Just trying to come up with some names that are more "exciting" for the lack of a better word :) 
I showed one of your videos to an internal Scala meetup at our company and it caused many chuckles. :)
Cool! I don't mind the chuckles :) Thx for sharing! 
I'd suggest to focus on problem solving rather on learning a specific framework. My guess is that if you're relatively new to Scala you are still not sure whether Akka can help solving your problem or not. If you take this path you will find different ways of solving your problem (hopefully) so then you can compare which solution will be the best for your use case.
I work exclusively in Azure and was excited to learn that I can easily run Scala in Azure Functions with a little bit of build &amp; deploy tweaking. Hope someone else will find this useful! 
Just wondering, how would I go about doing that because the fit method I've tried applying the fit method at different points in my code but it would always crash?
One way is to ask on Lightbend forum: [https://discuss.lightbend.com/c/akka](https://discuss.lightbend.com/c/akka)
Perhaps, you'll find this talk useful https://engineers.sg/video/scala-akka-real-world-example-of-high-traffic-application-design-singapore-scala-programmers--2843 Not exactly what you asked for, but may be interesting as well.
Web use Azure at work and WE hate it. Most peole I speak to also hate Azure. What's your opinion about it ?
I will give that a try and post any results here. Thanks for the suggestion.
This looks like a good talk, thanks. I will check it out today.
Novice Question: Can someone suggest a good learning resource from basics to advanced other than Alvin Alexander or scala docs? Went through a couple of courses on Udemy but weren't satisfactory. I am from a Java background. Anyone here done that transition from java to scala?
Two books: Functional Programming in Scala and Functional Programing for Mortals. And you're good to go. 
The cold start on Azure functions for the JVM is about 1-2.5 seconds, and that’s what I’m seeing with my function. Requests after that are handled in about 200ms or less. There’s a cold start period for every language, and this has improved significantly with the 2.0 runtime release. I’ll have to benchmark and compare this with JavaScript, but I can imagine node.js takes at least 500-1000ms to start up as well. Java is still in preview so I’m sure we will see the JVM cold start time lowered. 
Azure has changed a lot throughout the years... I have used both AWS and Azure and I prefer Azure because I find it easier to navigate and manage. ARM templates, az cli and other tools I prefer on azure. There have been a lot of changes in the PaaS offerings in azure (functions, web apps). The function framework in my post was literally released about 2 weeks ago. V1.0 was very hard to work with if using anything other than .Net. Besides their management tools I think GCP, AWS, and Azure all suck the same amount. Everyone will always be slightly frustrated and think another cloud provider is better, but trust me it doesn’t make that big of a difference if your services are configured correctly or your using the tooling properly. A management team may just like Azure/AWS arch better :) Why do you guys hate it? 
Any good resource in reagrds with basics which will help me to get going in Apache Spark.. 
One thing to consider might be \[Ahead-of-Time Compilation\]([https://www.graalvm.org/docs/reference-manual/aot-compilation/](https://www.graalvm.org/docs/reference-manual/aot-compilation/)) with GraalVM.
[removed]
I would suggest programming Scala 2nd edition from Dean Wampler, there is a good chapter on FP there but before FP I would start with the basics and IMO this is the best book to learn Scala.
This seems to be a rather reasonable approach, although `JavaNull` is probably not the best name, considering that types with unknown nullability can not only arise from Java.
I wrote [https://gist.github.com/nafg/112bf83e5676ed316f17cea505ea5d93](https://gist.github.com/nafg/112bf83e5676ed316f17cea505ea5d93), FWIW &amp;#x200B;
Can anyone compare the alternatives?
yes please!
Here you go, not complicated, done in my hideous beginner code. &amp;#x200B; &gt;def hour(beg:Int,start:Int,i:String):String ={ &gt; &gt; if(beg!=(-start-1)) &gt; &gt; { &gt; &gt;var sm = 1 + Math.abs(beg); &gt; &gt;var j = i+ ("\*"\* sm) +"\\n"; &gt; &gt;return hour(beg-1,start,j); &gt; &gt; } &gt; &gt; else &gt; &gt; {return i;} &gt; &gt;} &gt; &gt;val a = hour(5,5,""); &gt; &gt;println(a); &amp;#x200B;
Scala mllib 2.2.0 k means. Number of runs &amp;#x200B; As per the [documentation](https://spark.apache.org/docs/2.2.0/mllib-clustering.html#k-means), the \`runs\` parameter does nothing. I have looked at the actual scala code for k means and it appears that the \`train\` method only does one start. There is no way to change this. &amp;#x200B; \*\*QUESTION:\*\* Am I correct that if I want 5 starts I need to write my own code that calls \`train\` 5 times (or until some criteria has been met)? &amp;#x200B; &amp;#x200B; \[1
The Odersky book is the closest thing we have to a K&amp;R. I found it to be really the only book I needed.
Looks pretty great! If you want to focus on memory efficiency instead, I wonder if there's anything better than [debox](https://github.com/non/debox)? 
If I’m considering Scala as my first programming language to learn.. After long survey I’m impressed with possibilities to compile both to native code through LLVM and JS. Is it a good idea? Or maybe the language is too hard for the total beginners? If so, what my choise should be, considering my later Scala plans?
This is amazing! Except... I don't like the JavaNull. I think all types that don't come from Scala should just be A | Null. Much simpler
It’d be interesting to see this incorporated into Option. For example, Some would not allow JavaNull.
Yes please! Typescript, Kotlin, Swift and C# have all shown in their own way that null need not forever be the bane of programmers and language support for optional values is a very welcome QoL improvement.
How about defining a short postfix operator that says “this is definitely not null, but check and throw an exception if it is”? Something like: ```scala implicit class JavaNotNullOperator[T &lt;: AnyRef](v: T|Null) extends AnyVal { inline def :? : T|Nothing = { if (v eq null) throw new NullPointerException else v.asInstanceOf[T] } } ```
Iirc correctly this is how Kotlin, C# and Swift implement language support for it. The Scala equivalent would be making `T?` an alias for `Option[T]`, and automatically casting between `T?` and `T` depending on the code, like the example `if(t != null)` from the link.
Found this article and it looks trivial to use nominative typing in TS - https://michalzalecki.com/nominal-typing-in-typescript/.
Syntax-wise Dotty has added `&amp;` and `|` with identical meaning (AFAIK) as in TS, so if this is what you mean then yes, they are getting more similar. While union and intersection types are/will be used on every step in Scala, I think the languages have many differences. Scala supports structural typing (which TS uses and doesn't directly support nominal typing, but is possible to easily emulate), but I think structural typing in Scala is not encouraged to be used (relies on runtime reflection). Scala has the whole array of uses of implicits, TS has nothing like that. TS has some quite easy to use type-generation/manipulation which is also possible in Scala, but is way harder (at least I think - e.g. create a type which has identically named fields as a type B but all fields are now of type A).
Migration. Maybe one could migrate tiny codebases like scalac in one go, but that's unlikely to work for real-world codebases. It will be necessary to have a language import that treats existing Scala code as if it where of unknown nullability to enable a gradual migration.
Very useful, thanks OP. ;)
Thanks, this repo is a constant work in progress. They are my personal notes that I try to keep up to date while I'm studying.
Another description about this topic is available in the subsection named **Exponentials** of [this useful blog post](https://bartoszmilewski.com/2015/03/13/function-types/) by Bartosz Milewski.
Hum yes, that makes sense.
 interface Id { value: string } class UserId extends Id { private _nominal: void value: string } class PlayerId extends Id { private _nominal: void value: string } It gets *really* annoying defining new types across a code base with the `private _nominal: void` requirement.