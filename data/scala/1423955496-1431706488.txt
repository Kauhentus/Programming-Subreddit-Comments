&gt; which makes it a synchronous call whose result is returned some time in the future. Isn't that contradictory? Most often a synchronous request is something that you explicitly wait for to complete (because you're forced to). I would say it is a number of asynchronous actions fired in a serial fashion (as opposed to parallel). This would unlike a synchronous call allow other things to run at the same time — even in between.
&gt; Isn't that contradictory? Most often a synchronous request is something that you explicitly wait for to complete (because you're forced to). His code forces every request in the sequence to wait for the previous request. The overall result is asynchronous, but dealing with every element is synchronous.
&gt; If I understand correctly, each Akka actor is mapped to a thread in the thread pool. Depends on the dispatcher used, but there is no requirement that each actor is mapped to a thread in the thread pool. &gt; Isn't it up to the programmer to decide how many actors to spawn in the first place, and thus, controlling the thread count? The number of threads is controlled by the dispatcher and its properties, not the number of actors.
I believe it doesn't: every processed item in the sequence will upon completion start the processing of the next one. This may seem like a small distinction but it's not. In fact, it's exactly the distinction to blocking for data to return (with synchronous operations like Await.result) At the heart of things all asynchronous operations work like a chain of events. With a web service there is the request going in, the processing being done like calling other services (which may again call other services in a linear fashion) and the response being the end-result of the last asynchronous operation that gathers it all up. In this particular case, the "response" is the sequence of processed items that will eventually be available. I don't know if this is a good idea or not, but it's not any less asynchronous than your standard asynchronous web service.
&gt; That's exactly what List and Stream already are, facades, the only other option is to use a View, which neither copies, nor memoizes, but is not immutable in any way. What would writing your own possibly do that these three don't do already? The OP is apparently working on a numerical application involving operations on a large number of high-dimensionality vectors. Nowadays, this kind of computation is mostly memory bound. That is to say, the CPUs crunch numbers faster than they can access memory. To alleviate this bottleneck, CPU have a caching mechanism: when they load a value from memory, they also load in the cache all adjacent data, in the hope that the data is structured in memory in the same way as they are accessed in the computation. Now `List` and `Stream` are implemented as cells containing a single value and pointing through a reference to the next element. Thus elements are spread across the heap. On the other hand, arrays stores elements in an contiguous order. When you access to the first element, the next entries will be pre-loaded in the CPU caches for computation hence a huge speed-up. A good primer is found here: http://igoro.com/archive/gallery-of-processor-cache-effects/ I could use an view on an array but they are not specialized. That will imply boxing... If you need numerical performances, most of time you will need to replace the most inner loop with an handcrafted solution implying dedicated data-structures. Of course generic solutions are better for the 90% rest of the code.
Start cooking now. Learn how to search the cookbook: Google, Stackoverflow. Keep your tools simple and your dataflow explicit. Don't waste time with "cool" designs that require 3 blog posts and / or a peer reviewed paper to save 10 keystrokes. Most of your problems someone else had them first. If that's not the case, see previous point. 
Anywhere the .NET platform runs, the JVM also runs. There's nothing about the .NET platform being the platform of choice that prevents them from using the JVM.
&gt; I don't know if this is a good idea or not, but it's not any less asynchronous than your standard asynchronous web service. It is not a good idea when you're talking about dealing with high performance processing. When you want high throughput and low latency, his paradigm is not much better than running this computation synchronously in one thread, and is in effect the same as awaiting every result in the sequence before performing the next. You may be able to do other things in the code, since you're dealing with a future, but you'll not be using the I/O system and the OS to its full extent, since you have one thread executing the future, and waiting on it, so that it can then execute the next request. This may perform similarly to a "standard" asynchronous web service, but it won't be anywhere near a tuned backend service that needs high throughput and low latency. To get that kind of performance, you would need more enough requests to saturate any type of external connection pools, as well as enough sequences running in parallel so that the results of multiple sequences are being handled while other sequences are waiting on external results. At that point, you are not handling your data fast enough, and will fall behind. If you add another processing node, it will not be used to its full extent.
The more languages you learn, the easier it gets, as instead of learning new features raw, you instead start relating them back to other languages that share said feature. Then it becomes a syntax issue, which you will learn best by writing code. When I learn a new language, I match up "normal" features to other languages, figure out the gotchas specific to the implementation, and then try to learn the syntax by writing simple little prototype programs. If the language has a new or novel feature, then I will usually spend a bit more time on that, with an eye critically on how will this feature help me write less code, be more efficient, solve an open problem I face in other languages. If it doesn't do one of those things I put the feature on a back burner until it does, and don't really worry about it much. TL;DR - I learn language features by reading, if i've learned the feature elsewhere I use analogy to reduce my uptake time, and i learn syntax in the editor/IDE.
1. I skim quickly through a few tutorials and the official doc/reference (to know where the information is, and to be able to find what I will need). 2. I spend some time to learn what is the usual tool-chain and I learn how to properly set a new basic project. 3. I try to implement some complex algorithms that I already know well (computer science college exercises are perfect for that). 4. I try to rewrite my code such a to match the idiomatic style of the language. 5. I start reading more carefully about the language to be sure that I understand exactly the meaning of everything I have written and all the implications. When in doubt, I "use" stack overflow. 6. I start a serious project, trying to use the standard library as much as possible. 
&gt; Otherwise what exactly does "platform of choice" mean? It means, "we have most of our code in c#, and we're familiar with c# deployments". It doesn't mean "our hardware can only run .NET runtimes". That's why it is a platform choice and not a platform requirement. All current hardware and infrastructure can run the JVM platform the same as the .NET platform. There is no cost from a hardware/infrastructure standpoint. Beyond that, if you're working for a decent company, if you can show that there is a significant benefit to using JVM/Scala, then you can use it.
I usually take one or two foundational books on the language or framework and read it all the way through to gain some basic understanding of syntax and best practices as well as how the language was designed. I kind of skim the basic stuff that I've already learned (I never skip) like what is an int. I focus on interesting things like what is the Ruby kernel. How are lambda dispatched? Does this language handle tail recursion well? Then, pick a couple of small projects or I take an old project and port it to the new language/framework. I start looking at cookbooks like stack overflow or tutorials to see what's available and what pieces fit together. While I'm doing this, I'm reading the documentation for all of the API I'm using. Tutorials tend to hand wave what a function is actually doing by passing null null this null false into the parameters so I read the docs go learn what's actually going on. At this point, I'm pretty confident in what I'm learning because I've learned most of the foundational stuff and applied it to simple projects. Now I go off on my own making something super duper fun! I'm pretty by the books when I learn because I emphasize good code instead of "it works". I really hate bad code when I'm reading and writing. It's just not something I want anyone to be proud of. You can't really be authoritative in a subject until you've done it for a while. I feel pretty authoritative in Android and this is after 4 years of working on it. I dabble in a lot of things but j can't say I know it like the back of my hand. However, I aim to be knowledgeable in most of everything. I've messed with Web Dev, Android Dev, system programming, bash scripting, Python, and a bunch of esoteric stuff like J, K, APL, and I'm getting into Haskell and Rust. I don't know most of these but I'm familiar enough to program in them and probably read most of the small stuff. However, I'm a lot more knowledgeable than most people my age so if that makes me authoritative then I guess that's how I do it. Lots of reading, lots of documentation, lots of practice.
I quite like the Or and Every types from [Scalactic](http://www.scalactic.org/).
But inferred `Nothing` usually won't compile anyway, because it is not possible to create any values of that type. That's the point. Inferred `Any` (or `AnyRef`) is another story, though. Anyway, what about using type annotations and a suitable compiler plugin? Then you'd write something like def f[A @meaningful](x: A) = … and the compiler plugin would check that, in every application of `f`, `A` is not `Any`, `AnyRef`, or `Nothing`. Or, for the `Not` type constraint example: def printColor(color: Color @not[Yellow.type] @not[Blue.type]) = println(t) This would have zero run-time cost (since the annotation class is not loaded at run time), not pollute function signatures (no `implicit` evidence parameter), and the syntax is cleaner and more to-the-point. The downside, of course, is the need for a compiler plugin…
&gt; reading more than reading You probably meant reading more than coding.
This is good advice. Actually learning what can be done instead of just diving in makes things a lot easier.
&gt; I don't share your allergy to implicit evidence parameters :-) I noticed! I guess your opinion is no less valid than mine, but evidence parameters really irk me. They're run-time values that don't *do* anything. They are an artifact of compile-time checking that's being uselessly leaked into the run-time environment due to a limitation of the compiler. Type class values do something: they provide a concrete implementation of the type class' methods, much like how classes can provide concrete implementations of traits. `TypeTag`s do something: they store a run-time representation of an unerased Scala type. But evidence values do nothing at run time. The JVM could optimize them away entirely, and the program would still function correctly. &gt;but I will say that I prefer context bounds Too bad Scaladoc translates that back into an evidence parameter… &gt;a compiler plugin is a black box that I can only reason about by checking it out and understanding how it interacts with the compiler. It's almost certainly not expressed as logic, per se, at all. Define “expressed as logic”. It would presumably examine every type conversion, and apply the requested type checks if the target type is annotated with the constraints. You could implement a macro that does exactly that, albeit only inside a block, e.g. a macro named `checkTypeConstraints` that is used like so: checkTypeConstraints { // code that needs to be checked for type-constraint annotations goes here } &gt;Whereas these type constraints, in their entirety, are 51 lines of straightforward Scala They're not that straightforward to me. Lots of subtlety is involved, like how `IsTypeClassExists`' two `implicit def`s interact to correctly yield `Exists` or `NotExists`. I can't speak for compiler plugins because I've never written one, but with macros, it's not so subtle. You look for type conversions, imperatively check each type constraint, and raise an error if any aren't met. I won't call it *simple,* because the macro API unfortunately isn't, but it at least doesn't leave anything unsaid. &gt;I'll take using the language over extending the language 100% of the time. But type annotations *aren't* a language extension. The language already has them. The proposed compiler plugin would define a compile-time behavior for them, but since the behavior is an extra correctness check, the annotated code would still compile and work without the plugin. In general, I'd like to see better support for annotation metaprogramming in (mainstream) Scala, like the Macro Paradise plugin's macro annotation support and Java's Project Lombok. I think there's a lot of potential there, including adding custom type constraints like I proposed.
The total number of pooled threads is increased. Waiting tasks (actors/futures) in the pool can be run on those new threads. [edit]See this for more information: http://doc.akka.io/docs/akka/snapshot/scala/dispatchers.html
&gt; `pip install dexy` It's a trap!
Intense reading, even if I'm a bit lost. E.g. third of a book like Scala garden steps. Then code a non-trivial real world problem that I've already implemented in a different language, rinse and repeat. The first implementation is usually just like the other, later iterations help me understand the language. "Learning new languages is pretty easy, learning new paradigms is very hard" someone smarter than me, whose name I've forgotten.
I think the other comments here, and even the question itself, are understating the issue. The issue is not learning a "language", but rather a paradigm shift and a whole new philosophy. I have gone through several over the past few decades. None of them were easy. All of them required time, of both types: hours of effort, but also months to let it settle and become part of me. The first language paradigm shift for me was from spaghetti (BASIC) to structured (Pascal). This was the easiest of the paradigm shifts for me, because it solved problems in a way that was easy to grasp, and was taught to me in college so I didn't have to pick it up on my own. The second language paradigm shift for me was from structured to OOP. This was extremely painful, in part because I was out of school and on my own. The only way I got the aha! was by finding a book that explained the philosophy. http://www.amazon.com/Object-Oriented-Design-Heuristics-paperback-Arthur/dp/0321774965 The third language paradigm shift for me was from OOP to Scala. Notice I didn't call it "functional" or even "object-functional". Scala is a philosophy unto its own that incorporates other things as well: conciseness, operator-looking functions so that "language" features can be added as a library DSL-style instead of to the compiler itself, inferred typing, etc. This paradigm shift was also pretty painful for me, in part because I was learning Spark at the same time. But also, I'm not aware of any book or even blog post that concisely captures the Scala philosophy all in one place. Worse, there are elements of intentional obfuscation, obscurity, and arrogance within the Scala community. Plus, there are rabbit holes. Cake intentionally breaks the Liskov Substitution Principle from OOP and should be banished in my opinion. sbt is great in theory but fails in practice. In my experience, there is no way I can understand a language book without having first programmed in that language. TL;DR Do first, then read, then philosophize.
&gt;Still, legibility matters, and I'd have thought you'd have appreciated having good ol' Boolean algebra—And, Or, Not—in types. I did appreciate that, yes. &gt;Through the Curry-Howard lens, these say: &gt; &gt;1. "Not A" is the same as "A implies Nothing". &gt;2. "T or U" is the same as "not (not T and not U)". &gt;3. "Not not A" is the same as "not (not A)". &gt;4. "For all T, U there exists X such that X implies T or U". Ah, *now* that makes sense. Thanks. This is the problem I have with Scalaz in particular: everything is expressed not in terms that programmers of an imperative background (like myself) would understand, but with Greek letters, mathematical dingbats, people's names (I only know that Haskell Curry made some sort of great contribution to functional programming, and I have *no idea* who the hell “Howard” is), and metaphors that mean nothing to me (e.g. “Arrow” and “Lens”). I assume that's because people like me are not Scalaz's intended audience. That's fine, but when I then go asking for union types or whatever, you can't just point at Scalaz and expect me to use it. &gt;Maybe you can help me understand this, because I can't see any subtlety here at all. One of the implicits will be resolved if TypeClass exists; the other if it doesn't, by virtue of a (evidence!) existing or not. The subtlety is in which implicit is chosen. `typeClassNotExistsEv` is always a valid choice, but for whatever reason, the compiler chooses `typeClassExistsEv` instead, if possible. A subtle implication of this is that there is a way (other than `asInstanceOf`) to generate evidence that `T &lt;: U` is false, even if it is actually true. &gt;What does "extra correctness check" mean if "the code would still compile and work without the plugin?" It means that, if the code is compiled with the plugin, the plugin will detect certain correctness errors and refuse to compile. Without the plugin, such incorrect code will successfully compile despite its incorrectness, because the correctness check isn't there. &gt;Not because I don't trust you; just because the potential for error is orders of magnitude higher than with the four simple type aliases, or the 51 lines of Scala I imagine it would help to have a simpler, cleaner API for processing type annotations. We don't currently have that, but that doesn't mean it's impossible. &gt;After years of Spring programming, I emphatically don't want this, because annotations never stay semantics-preserving, never stay side-effect free, and so always require looking inside their black box somehow. Do you have some specific examples? I understand your concern, but I'm having a hard time envisioning how this could happen to a simple type constraint like `@not`.
BTW, I use the following approach for "libraryDependencies": libraryDependencies += "org.scalaz" %% "scalaz-core" % "7.1.1", libraryDependencies += "org.scalaz.stream" %% "scalaz-stream" % "0.6a" Seems like a good alternative to `Seq`, in my opinion.
&gt; Ah, _now_ that makes sense. Thanks. You're welcome! &gt; This is the problem I have with Scalaz in particular: everything is expressed not in terms that programmers of an imperative background (like myself) would understand, but with Greek letters, mathematical dingbats... The situation used to be bad enough that there's a [Mac OS X keyboard layout](https://github.com/dchenbecker/scala-osx-keyboard) for Greek/Unicode input. Truth be told, I never used scalaz 6. Partially for this reason; partially for the lack of docs reason in a pre-[Learning Scalaz](http://eed3si9n.com/learning-scalaz/) world. In scalaz 7, the Greek and Unicode has spelled-out equivalents and is relegated to the [`syntax`](https://github.com/scalaz/scalaz/blob/v7.1.1/core/src/main/scala/scalaz/syntax/SemigroupSyntax.scala#L7) package, to be imported (or not) at will. &gt; ...people's names (I only know that Haskell Curry made some sort of great contribution to functional programming, and I have no idea who the hell “Howard” is)... [William Howard](http://wadler.blogspot.com/2014/08/howard-on-curry-howard.html). That interview is nice if you're already one of the cognoscenti, I suppose, but personally I'd skip it and read Wadler's [Propositions as Types](http://homepages.inf.ed.ac.uk/wadler/papers/propositions-as-types/propositions-as-types.pdf) instead. To me, the key sentence in it is: &gt; Those of us that design and use programming languages may often feel they are arbitrary, but Propositions as Types assures us some aspects of programming are absolute. Words to live by! &gt; ...and metaphors that mean nothing to me (e.g. “Arrow” and “Lens”). Fair enough, but at one point the metaphors "abstract factory" and "visitor" meant nothing to you, either. [`Arrow`](http://eed3si9n.com/learning-scalaz-day15) generalizes the idea of "function," something that transforms one thing to another. [`Lens`](http://eed3si9n.com/learning-scalaz/Lens.html) "focuses," if you will, on a (potentially nested) element of an immutable compound data structure and supports manipulating it "directly." &gt; I assume that's because people like me are not Scalaz's intended audience. That's fine, but when I then go asking for union types or whatever, you can't just point at Scalaz and expect me to use it. Why not? Here's some non-scalaz code I wrote a few months ago: var maybeCookie = Option.empty[String] ... val baseURL = "..." // including "?baz=bletch&amp;..." &lt;loop&gt; val newParam = maybeCookie.map("foo=" + _) val url = (List(baseURL) ++ newParam).mkString("&amp;") &lt;get JSON from url&gt; &lt;set maybeCookie from optional JSON field&gt; &lt;end loop&gt; It's nothing but library code. In particular, the machinery around `++` of an `Option` to a `List` involves all the power of the [`CanBuildFrom`](http://blog.bruchez.name/2012/08/getting-to-know-canbuildfrom-without-phd.html) trait and implicit resolution. Why is scalaz any worse, especially since we know its `UnionTypes` are based on Miles Sabin's blog post? Let's [look at them](https://github.com/scalaz/scalaz/blob/v7.1.1/core/src/main/scala/scalaz/Union.scala#L10) again. We see `!` and `!!` for "not" and "double negation," using more programmer-familiar syntax than the logician's "¬". `Disj` is a clever beast: a recursive trait that leaves `D` abstract and has a type constructor `t[S]` that builds a new `Disj` from the old `D` (whatever it is) and (`with`) `![S]`. A type constructor `t[T]` provides the base case where `D` is `![T]`, and now we know how `t[Int]#t[String]` becomes `(Int =&gt; Nothing) with (String =&gt; Nothing)`, and the point of the recursive `Disj` is that we could add more: `t[Int]#t[String]#t[Boolean]`. `or` remains `!` of the conjunction of the negations, and `Contains`/`∈` remains `&lt;:&lt;` of the final disjunction. Now, I still agree that: import scalaz._, Scalaz._ type StringOrInt = UnionTypes.t[String]#t[Int] def size[A](a: A)(implicit ev: A ∈ StringOrInt): Int = a match { case i: Int =&gt; i case s: String =&gt; s.length } isn't awesome syntactically, but it manifestly _does_ work, and requires no more study and deserves no less trust than `List(...) ++ Option(...)` does. &gt; The subtlety is in which implicit is chosen. typeClassNotExistsEv is always a valid choice... Not when there is a higher-precedence implicit. &gt; ...but for whatever reason, the compiler chooses typeClassExistsEv instead, if possible. Well, "if possible" makes all the difference, doesn't it? :-) What's going on here is that, as we've seen, implicit arguments put additional constraints on type parameters of methods. So the `TypeClass` of `typeClassExistsEv` is "more specific" than the `TypeClass` of `typeClassNotExistsEv`, with a vengeance: in the body of `typeClassExistsEv` you could even do something with `a` if you wanted to, or you could add another implicit `TypeTag` argument and print `a`'s actual type, etc. &gt; A subtle implication of this is that there is a way (other than asInstanceOf) to generate evidence that T &lt;: U is false, even if it is actually true. I'm a constructivist. Show me. &gt; It means that, if the code is compiled with the plugin, the plugin will detect certain correctness errors and refuse to compile. Without the plugin, such incorrect code will successfully compile despite its incorrectness, because the correctness check isn't there. That's what I thought. So your plugin is _not_ semantics-preserving: leave it out of my sbt project/plugins.sbt, and incorrect code will compile! No, thank you. &gt; I imagine it would help to have a simpler, cleaner API for processing type annotations. We don't currently have that, but that doesn't mean it's impossible. I'm still talking about the compiler plugin, although I don't especially trust annotations not to change the meaning of my code either. &gt; Do you have some specific examples? Not offhand. I have, thank God, not been a Java developer in almost 5 years. &gt; I understand your concern, but I'm having a hard time envisioning how this could happen to a simple type constraint like @not. OK. How would you implement "this type is not equal to X" as an annotation? But remember the main point: to make incorrect code not compile. From where I sit, you've already forfeited by having your annotations rely on a compiler plugin and, if the plugin is missing, turn into compile-time no-ops. Thankfully, you can't forget to include the type system. :-) 
&gt; The next Future won't be started until the previous one is completed. But that is order of completion, not wait-s in any way. That is why everyone has said functionally equivalent. The waits will have the same output and approximately the same performance as combining future. The only difference is that they will occupy the thread. It's also the same behavior as if the calls themselves were blocking and you just ran them inside of a Future/blocking rather than wrap each individually in a future. Although it's not blocking, it "sucks in performance". It's a terrible implementation to work around a much larger issue. &gt; Now, you want to build a service that uses these requests. You, for example, start blocking on each request and wait for results. Obviously, everything is blocking and sucks in performance. It only sucks in performance if you have enough simultaneous requests that exhaust your thread pool and cause additional requests to wait. I feel like half the responses in this thread are from people who only use node.js/libuv/libev or some another single threaded event loop type application. 
Waiting on futures by blocking kind of defeats the point of having futures in the first place. Under high load you could exhaust the pool and still end up blocking on further requests. You can get the same result *without* blocking by doing a basic traverse operation, handling any number of requests in a constant sized thread pool. 
Agree. The practical difference between these two implementations is that one would work fine in a constant-sized thread pool (and the constant is &lt;50 :), but the other solution will create lots of threads, will spend them `wait`-ing and absolutely will not scale.
You might want to remove the return and put an = before the {.
Here's my algorithm for picking up a new language: 1. Read a few articles from all over the web to get a general idea of a language, its philosophy and reasons why I should learn it 2. Work through a couple of good tutorials while writing short programs in the language 3. If I like the language, work through a good book (like Real World Haskell or Programming in Scala) 4. If I want to go deeper, start writing non-trivial programs and find a way to work with the language professionally
To expand on that, you should not use the "return" keyword in Scala. Basically, nearly everything is a typed expression (even blocks). Which means that you have to write something like : def function[T](f : Array[Object] =&gt; T) = { // the = means that you function has a return value, and specifically it returns the result of this block ... val listOfArrays : Array[Object] = ... // Array is not covariant, meaning that an Array[Foobar] is not an Array[Object], so listOfArrays have to be typed as Array[Object] for f to Work listOfArrays.map(f) // because this is the last expression of the block, your function returns this }
Scala is another language :) def myMethod[T](fn: Array[Any] =&gt; T) = listOfArrays.map(fn)
&gt; You can get the same result without blocking by doing a basic traverse operation, handling any number of requests in a constant sized thread pool. Nope. If your thread pool is constant, you can exhaust it, if any of your operations block. If you have no blocking operations, can you either exhaust the jvm memory, or the cpu processing. That's the thing with his implementation. It will still exhaust the threat pool if you have a large number of small sequences, or break large sequences into small sequences. Traverse, like his implementation (which is traverse, but slower), works, only if you allow a fixed number of those operations. At that point, you're occupying at least one thread, and can exhaust your thread pool. If you're spawning enough futures to exhaust the thread pool when spawning them individually or with sequence, you'll exhaust them with any other manner. You either need to split work load, or queue them. 
Well, one drastic way is using JuiceSSH and connecting to any linux server. I'm doing that with a VPS at cloudatcost - a pay once VPS provider, very low performance but enough for my needs: playing with languages. That way I can read scala books while playing in the scala repl. All from my android phone!
Nice post! I have been using Redis for a while and it is a really powerful and easy to use tool!
So what's the actual error message you receive?
&gt; Longtime java dev now caught up with object-functional programming and scala devotee "object-functional programming" i kind of shivered 
No. Provided the function that works on the sequence creates an idiomatic future (non-blocking as mentioned earlier), one thread **will** be able to handle the sequence *as well as* requests incoming from a dispatcher. This is what I've been trying to tell you for the last couple of days. This is because the homebrew traverse presented here only keeps one future at a time running. This future will, when finished, create a new one. Other futures can still be created by the request dispatcher, and will be handled by the same single thread running the sequence processing in between.
&gt; His implementation makes no guarantees he won't blow the stack His implementation is actually *guaranteed* to blow the stock for a large enough queue size, since it's not tail recursive. OP was asking if there was a 'standard' function that executes futures in this way, and provided a poor mans example of what he's trying to do. Several people have responded and pointed out that yes, this is what a normal applicative traverse operation does, and this the example he gave is in fact a flawed but working implementation of a very fundamental part of the Haskell standard library. The point is not that OPs implementation won't have problems. The point is that, in answer to OPs question, the standard applicative `traverse` operation does exactly what he's asking, and is a very common library function. It's not part of Scala out of the box, but there are several good implementations available (Scalaz having probably the most popular). `Future.traverse` is close, but does not actually implement an applicative traverse correctly. A properly implemented traverse will not blow the stack, nor will it exhaust the thread pool unless you're blocking (In which case you'll only block one thread at a time, no worse than if you weren't using the traverse). As such - if you have an API that produces a future, and you wish to map a sequence of values to this function and then combine the results back into a single future - in answer to OPs question, `traverse` would be a good idiomatic way of doing this. 
``` scala&gt; call(911) ```
actually you can compile and translate to dalvik on your laptop and then send the compiled jar to the [mobile application classloader](http://developer.android.com/reference/dalvik/system/DexClassLoader.html)
So, what is the joke?? and why do you want to call 911??
&gt; From the op's post. If he is having problems with Future.traverse he will have problems with other traverse functions as well. Future.traverse is failing because he is using blocking futures that are blocking the dispatcher. He has a root issue that is alleviated because he's blocking one thread a time per each usage of that function. OP did not mention blocking calls. Futures are normally used for non-blocking operations. A traverse over non-blocking futures is itself non-blocking. If the futures *are* blocking, they are still only going to block one thread, which is no worse that your proposed solution of wrapping the whole thing up in one single blocking call. (A blocking operation will *always* block a thread, there is no magical incantation that will avoid this). Regardless, the question OP asked was: &gt; I wonder, maybe I'm inventing a wheel and actually such function already exists somewhere in Scala's standart library? Also I would like to know, did you encountered described problem and how did you solve it? Maybe, if this is a well known issue with Futures, I should create a pull request in Future.scala so this function (or more generalized version of it) would be included in standard library? Specifically &gt; **maybe I'm inventing a wheel and actually such function already exists somewhere in Scala's standart library** After providing an example of a traverse function that *did* solve his problem, he was asking if it was a standard operation. The answer is "Yes" - It's a standard applicative traverse. And it's the proper way to solve the specific problem he was having - namely, executing a function (A -&gt; Future[B]) across a Seq[A] and getting back a Future[Seq[B]] while only executing one task at a time. I use this operation **extensively** in my own codebase and it works exactly as expected without exhausting the default Scala ExecutionContext with 4 active threads. I even use a lot of small atomic blocking calls (wrapped in blocking{}) without issue. If it did not work, then my phone would be ringing right now with customers complaining that our production server is slow. 
&gt; OP did not mention blocking calls. Futures are normally used for non-blocking operations. A traverse over non-blocking futures is itself non-blocking. Show me an instance where a bunch of non-blocking futures takes over a thread pool. ... Oh right, they don't. &gt; I even use a lot of small atomic blocking calls (wrapped in blocking{}) Atomic blocking? WTF? You just made my brain hurt. With that, I'm just going to let you go back to creating horrible code. [edit] &gt; If it did not work, then my phone would be ringing right now with customers complaining that our production server is slow. They don't call, they just look for other providers since your service is slow. 
&gt; free all the best using a substandard free version
If it tells you anything I have a license for the paid version, but seldom (almost never) bother using it because the differences are so small.
The IDEs are not perfect, but there much better than for some languages.
That's fucking awesome.
Nice
&gt; You continue to disregard the issue that if Future.sequence or traverse is filling his execution context, that means he is blocking his execution context, and any other implementation merely delays the occurrence of the blocking. It doesn't need to mean that. **Scenario A** * You have a seq of 10,000 elements. * You use Future.traverse(items)(someNonBlockingFn) which creates a queue of 10,000 futures in the ExecutionContext. **Scenario B** * You have a seq of 10,000 elements. * You use OPTraverse(items)(someNonBlockingFn) which creates a queue of one future. Creating an additional future afterwards will in either scenario add it to the end of the EC-queue. The difference is the size of the queue. So the difference between A and B is that in A, the EC will have to "touch" 10,000 futures before handling the separatedly created future, whereas in scenario B the queue will be at most 1 future long. edit: here's a gist: https://gist.github.com/megri/3bc5952f812918332a8b
&gt; someNonBlockingFn This. You can't fill an execution context with non-blocking futures. You can overload the jvm, but you will still be able to run other threads with non-blocking futures. Overloading an execution context, especially with akka, means the system "hangs" until a blocking future finishes. If the blocking future finishing requires some task that is waiting in the execution context queue for an available thread, your system will hang forever. This behavior can occur with Future.traverse or the OPTraverse. All it requires is the the EC be filled with futures that are waiting on a task that cannot be sent to the EC. If you have a 64 thread max EC, it simply requires 64 calls to OPTraverse ahead of the call which will allow the waiting future in the EC to finish.
The thing most people don't get who watch this video is that–despite these flaws–it's still better than the alternatives.
&gt; Both Scala and Java allow subclasses to be placed in collections of a parent type Yes, because Scala collections are implemented with covariant generics. However, by default (e.g. MyCustomCollection[T]) containers in Scala are not covariant. &gt; Covariant collections mean that Array[Admin] is a subclass of Array[+User]. You cannot do that in Java. You *can* do it in Java because arrays are covariant.
I'm afraid there's no point in discussing this if you won't read what I write, let alone look at the examples I prepare.
Here how I used a remote python console to develop on Android using android SL4a. I the Android SL4a script manager I run the script **shell.py** that is a reverse shell, that connects to a server in my workstation, the server is created by the command in a Linux Terminal, there is also a netcat compiled for windows. nc -l 9090 Then I can type commands in the terminal and it is executed on Android. I don't know if is possible to create something similar in Scala or Java. **shell.py** Credit: http://www.shysecurity.com/posts/remote%20interactive%20python import sys, socket, logging import contextlib @contextlib.contextmanager def std_redirector(stdin, stdout, stderr): orig_fds = sys.stdin, sys.stdout, sys.stderr sys.stdin, sys.stdout, sys.stderr = stdin, stdout, stderr yield sys.stdin, sys.stdout, sys.stderr = orig_fds class socketWrapper(): def __init__(self, s): self.s = s def read(self, len): return self.s.recv(len) def write(self, str): return self.s.send(str) def readline(self): data = '' while True: iota = self.read(1) if not iota: break else: data += iota if iota in '\n': break return data def ishell(local=None, banner='interactive shell'): import code local = dict(globals(),**local) if local else globals() code.interact(banner,local=local) def linkup(local,link,banner): import traceback link = socketWrapper(link) banner += '\nStack Trace\n' banner += '----------------------------------------\n' banner += ''.join(traceback.format_stack()[:-2]) banner += '----------------------------------------\n' with std_redirector(link,link,link): ishell(local,banner) def listen(local=None, host='127.0.0.1', port=2000): server = socket.socket(socket.AF_INET, socket.SOCK_STREAM) server.setsockopt(socket.SOL_SOCKET, socket.SO_REUSEADDR, 1) server.bind((host,port)) server.listen(1) client,addr = server.accept() linkup(local,client,'connected to %s:%d'%(host,port)) client.shutdown(socket.SHUT_RDWR) server.shutdown(socket.SHUT_RDWR) def connect(local=None, host='127.0.0.1', port=2000): link = socket.socket(socket.AF_INET, socket.SOCK_STREAM) link.connect((host,port)) linkup(local,link,'connected to %s:%d'%(host,port)) link.shutdown(socket.SHUT_RDWR) if __name__ == '__main__': #listen() # nc localhost 2000 # This is my computer address 192.168.0.8 connect('192.168.0.8', 9090) # nc -l 9090
It's like when python programmers talk about how slow Java is. 
Arrays are covariant in Java, generics are not. Integer[] x = new Integer[1]; Object[] y = x; 
Entirely correct, and the source of much grief. Since arrays are both covariant and mutable, you could assign, say, a String in your Object[] x and the compiler won't stop you - you'll have to wait until runtime to detect the type error. If you think about it, it also means that Java keeps type information at runtime - in the very specific case of arrays, types are not erased!
This is all great discussion. i think youre both right. Milyardo presents the most elegant way of doing things, but paradigmatic echoes some concerns ive had. Nobody ever seems to address concerns related to underlying hardware. my computations are indeed memory bound. i need the lightest weight data structure possible, i dont need generic (all doubles), and i need interop with numerical library. as of now im using breeze, and will be sending jobs to a spark cluster. it looks like i can construct a breeze.DenseVector right from a case class before sending to cluster 
Unless the problem is in second case, then yeah, it's not a pure function not dependant on input.
I think we're in agreement. What happens is totally reasonable, but it violates the second law of functors (sorry for talking in Haskell terms) map f . map g = map (f . g) So it seems like the given example is a problem with Set, but this problem would never come up if it weren't for a function like **g** which can return different results for the same input. If **g** were a pure function this wouldn't be possible and map would perform as it should. Set removes duplicates - as it should - and the results of the example are predictable. It's not a problem of 'side effects' exactly, it's a problem of function purity. A function that can do this scala&gt; g 0 res0: Int = 305000 scala&gt; g 0 res1: Int = 307000 is bound to violate equational reasoning. I thought a lot of the presenter's points were very reasonable things to complain about, but this one was bogus. No implementation of map in Scala can prevent users from passing it a badly behaving function and getting bad results.
apps1.map is evaluated before the concatenation action (:::) which means that you're trying to concatenate a List[java.lang.Long] to a List[Long]. There is no applicable implicit from List[java.lang.Long] to List[Long]. edit: and even with an available implicit conversion, the operation will fail as it is valid to ::: two lists of non-related types (so no implicit will be tried). This gives a List[Any] (which is pretty worthless. Type inference doesn't help in this case..)
To clarify, any operator that ends with a colon(:) in Scala is right associated, meaning that the expression is evaluated from right to left, instead of the other way around.
This has nothing to with side effects or map. The difference comes from using strict versus lazy collections. The above is correct for as long as the evaluation of Set is strict. Using a stream(assuming it had the constraints of a set) wouldn't have this problem because it is lazy, so the question is, should immutable collections be strict? Welcome to Scala version 2.11.1 (Java HotSpot(TM) 64-Bit Server VM, Java 1.7.0_76). Type in expressions to have them evaluated. Type :help for more information. scala&gt; val f: Int =&gt; Int = _ % 3 f: Int =&gt; Int = &lt;function1&gt; scala&gt; val g: Int =&gt; Int = _ =&gt; System.nanoTime % 1000000 toInt g: Int =&gt; Int = &lt;function1&gt; scala&gt; (Set(3, 6, 9).toStream map f map g) print 340948, 541565, 596674, empty scala&gt; (Set(3, 6, 9).toStream map (f andThen g)) print 257446, 313706, 350857, empty
Typeclasses basically give you external polymorphism. Start from that goal and it starts to make sense. So most examples show some kind of generic function and then you want to use it with "any" type, whilst maintaining type safety.
Typeclasses really aren't all that complicated, but they do require a good understanding of multiple Scala concepts and take some getting used to. Assuming you're from a Java background, think about the difference between `Comparator` and `Comparable`: `Comparable` is essentially a typeclass. Scala just makes it more convenient with context bounds (which are mostly syntactic sugar for implicit parameters). Word of warning though: once you get comfortable with the concept of typeclasses, you'll start reading up on standard ones, discover functors, monoids, foldable... and before you know it, you're programming in Scalaz (or its less drama-queeny younger brother, cats). And *that* will sour your relationship with any language that doesn't support typeclasses forever.
You know how object-oriented languages' functions have an extra invisible argument, usually called `this`? And you know how objects are able to magically look up other functions and variables from whatever they inherit from? All Scala is doing is breaking the inheritance relationship (which even OO practitioners discourage these days) and making the "extra argument" visible, but still not necessary to pass in explicitly (but you can if you want to)! Where it actually gets weird is when the implicit argument isn't even used to provide any implementation to the function: its type is only there to add constraints to the type argument(s) of the function. You'll start to see (if you haven't already) Scala function signatures with `implicit ev ...`, which is short for "evidence," that are only there to serve as "evidence" that the type parameter of the function satisfies some set of constraints. If you wonder what use any of this could possibly be, I suggest having a look at [Shapeless](https://github.com/milessabin/shapeless), but this is most definitely a dive into the deep end of the pool.
Nothing written there on what is this kata and when i click the website, there is a blank screen and some icons, nothing happens on clicking or anything, Really sick people have entered Scala with sickness as SBT and REPL
It's true that a lazy version of Set would prevent **map f map g** and **map (f andThen g)** from returning sets of different sizes, but the root of the problem is that **g** can return different results each time you call it with the same input. Laziness is a performance optimization, it shouldn't affect program correctness (even if the program never completes without it). Even with a lazy version of Set, the law map f map g = map (f . g) would still be violated. With a **g** like this one even g 0 = g 0 would be violated.
Type classes may be better understood from a didactic point of view in Haskell. 
With as much as I like the Scala language and the REPL, this kinda looks painful to use.
I believe that depends on the color theme you're using, I had to edit the style to turn that on for myself. EDIT: Here's an example of my theme with an implicit member underlined, and using ctrl+shift+P to show implicit parameters in a method call: http://imgur.com/f2xnh9v
I am probably going to be arbitrarily downvoted for this again but frankly this doesn't appear to have any meaningful way to display diagrams or mathematical formula. I see people all too often fall into the trap of putting too much text on their slides then just reading it. Yes the feature of running code from your slide is cool but this is lacking many features that presentation tools have had since the 90s. When giving a presentation your slides are a visual aid to your talk, draw diagrams, show pictures, don't use bullet points your audience will thank you. 
thanks, but this only concerns filesystems. I need to determine physical drives, not partitions.
You can vote here to include the documentation of scala: https://trello.com/b/6BmTulfx/devdocs-documentation
Ascii diagrams are just a lot of work though and for more complex figures its not going to be as clear. For informal presentations I frequently just import pictures I have hand drawn on my tablet.
You could always just ascii-ify your pictures I guess: http://picascii.com/
we're totally innovators
Article link is useless may as well just link to github
Inspiration: https://www.airpair.com/clojure/posts/using-apache-spark-clojure http://mikanassociates.com/news-and-events/mikan-blog/item/33-in-spark-we-trust/33-in-spark-we-trust https://books.google.com/books?id=JPKGBAAAQBAJ&amp;printsec=frontcover#v=onepage&amp;q&amp;f=false Spark tutorials https://www.youtube.com/results?search_query=apache+spark+tutorial Spark Graphx tutorials https://www.youtube.com/results?search_query=spark++graphx+tutorial 
Databricks also has some reference applications: http://databricks.gitbooks.io/databricks-spark-reference-applications/
Hi Scala subreddit, I still write Scala like Java and would be happy for feedback on how to learn and use Scala's functional components.
You're going to want to use `java.nio.file` for this. (Needs Java 7 or later.)
Please expand your answer, I am eager to understand how you do it !
Preach it! I'm looking at a combination of [jove-scala](https://github.com/jove-sh/jove-scala) and [live-reveal](https://github.com/damianavila/live_reveal) myself.
Why's that? The infoscience page provides a pdf download of the technical report, which isn't hosted at github.
I'm sorry I left this avenue of misunderstanding available. A function with different results each time is simply a concise way to demonstrate the problem. It isn't a requirement. Here is an example with no side effects. When this program is run it prints Set(abc) Set(abc, abc, abc, abc, abc) The first line is xs map f map g, then second is xs map (f andThen g). object Test { def wrap[A: Eq](xs: A*) = Set[Wrap[A]](xs map (x =&gt; new Wrap(x)): _*) val f: Wrap[String] =&gt; Wrap[Any] = _.weaken val g: Wrap[Any] =&gt; Wrap[String] = _.strengthen[String] def main(args: Array[String]): Unit = { val xs = wrap(Stream continually new String("abc") take 5: _*) println(xs map f map g) println(xs map (f andThen g)) } } final class Wrap[A: Eq](val x: A) { def weaken(): Wrap[Any] = new Wrap(x) def strengthen[B: Eq](): Wrap[B] = new Wrap[B](x.asInstanceOf[B]) def map[B: Eq](f: A =&gt; B): Wrap[B] = new Wrap(f(x)) override def equals(that: Any) = that match { case w: Wrap[A] =&gt; implicitly[Eq[A]].same(x, w.x) case _ =&gt; false } override def hashCode = implicitly[Eq[A]].hash(x) override def toString = "" + x } trait Eq[A] { def same(x: A, y: A): Boolean def hash(x: A): Int } trait LowPriorityEq { implicit def universal[A] : Eq[A] = new Eq[A] { def same(x: A, y: A) = x == y def hash(x: A) = x.## } } object Eq extends LowPriorityEq { implicit def reference[A &lt;: AnyRef] : Eq[A] = new Eq[A] { def same(x: A, y: A) = x eq y def hash(x: A) = System identityHashCode x } } 
&gt; defaulting to one form of evaluation and enabling the other via imports is a better solution. Ugh, that sounds awful. I don't know what you mean anyway: scala is eagerly evaluated, full stop. By-name parameters are syntactic sugar for Function0. def foo(x: =&gt; Unit) foo(println("bob")) is nothing but sugar for def foo(x: () =&gt; Unit) foo(() =&gt; println("bob")) The thunk is eagerly created, and it's called if and when it's called, just like in any other eager language.
&gt; the root of the problem is that g can return different results each time you call it with the same input. I hope I've adequately demonstrated this is not the root of the problem. The root of the problem is that intermediate expressions carry hidden semantics which influence expression results, even in many cases where there is no obvious avenue for this influence to be exerted. The type inferred for the intermediate expression can alter the result even if the type is never seen externally.
Can't the function private def getBrokenLinks(repo: GHRepository) = { try analyzeReadme(repo.getReadme().getHtmlUrl()) catch { case _: Throwable =&gt; (0,Seq()) } } be written simply as: private def getBrokenLinks(repo: GHRepository) = Try(analyzeReadme(repo.getReadme().getHtmlUrl())). getOrElse((0, Seq())
Thanks, good to know, updated. Reference: http://www.scala-lang.org/files/archive/nightly/docs/library/index.html#scala.util.Try
Set's behavior is not being subverted at all. Set's behavior is what makes any of this possible. Reference equality is beside the point. It's just a handily available equals method. Pick any equals method you want. I don't know what to say other than study the example harder. You know about type classes right? That's a type class. It's not doing anything exotic or surprising.
Don't know why you posted this in /r/scala. But have a look at http://opengameart.org/, /r/gameassets and /r/gamedev And here I hoped you will show as how you used actor models in your game. Goodluck,
a) I said types, not runtime tags. b) Which part of "not too painful" didn't you understand? (Also looking at you, typed.clojure.)
Also try https://www.parleys.com/course/stairway-scala-applied-training-1 .IMO is the best course for biggeners.
http://infoscience.epfl.ch/record/204804/files/CodeHealthForScalaMeta.pdf
This continued to bother me, so I kept looking, and found [this](http://www.scala-sbt.org/0.13/tutorial/Hello.html): &gt; In this case, sbt works purely by convention. sbt will find the following automatically: &gt; &gt; • Sources in the base directory &gt; &gt; • Sources in src/main/scala or src/main/java &gt; &gt; • Tests in src/test/scala or src/test/java &gt; &gt; • Data files in src/main/resources or src/test/resources &gt; &gt; • jars in lib So I guess in the current docs, "read the Getting Started pages" should be taken seriously!
My talk, obviously! Essential Scala: Six Core Principles for Learning Scala. First slot after the keynote on the first day. It really depends what interests you. Some people want to learn how to crank the type system to 11. Some people want to know about distributed systems. Big data is another popular theme. Just depends where your interests are.
Oh might have to catch that! Yeah- I've got a couple I want to see, just wanted to know if there are any awesome talks I might miss out on!
I'm totally biased, but let me recommend Rúnar Bjarnason and Tim Perrett's "Reasonable RPC with Remotely" anyway. That's our (Verizon OnCue) type-safe, purely-functional Scala RPC implementation that we think is really nice for Scala-to-Scala service communication.
In the list that shows # repos Q2/12 to Q4/14, Scala grows from 4K to 11K (factor 2.8), compared to Java 50K to 223K (factor 4.4), Go 2K to 22K (factor 11) and Rust 148 to 4K (factor 29). The latter two are very young languages which compete in the area of system's programming and basically want to replace C. I don't think the overlap with Scala is that great in the sense that a growth of one implies a scarcity of resources for the other. Java growth is vital for Scala, as Java strength means continued investment in the JVM. Scala might not be huge, but it's still the second strongest option on the JVM. Looking at Reddit, only Clojure is slightly more popular, with Kotlin and Ceylon being basically inexistent and Groovy's future beyond a scripting language for Gradle highly uncertain. Looking at GitHut Scala is significantly ahead. Whether Rust will make inroads within the next years, for me [is still unclear](https://github.com/trending?l=rust&amp;since=monthly). Whether Go will drink Scala's milkshake, again [I'm not sure of](http://boldradius.com/blog-post/U62N9C0AAC8AVoav/the-difference-between-scala-and-go).
There is a difference between being subscribed and actually producing code in it for commercial use. 
And would that ratio be different across languages? 
rust is not even stable.
Common, your post got 18 points (75% upvoted): http://www.reddit.com/r/scala/comments/26pdb3/what_is_keeping_you_or_your_company_from_starting/ What are you complaining about ? 
Some would argue that scala is not yet ready for production due to its lack of production ready libraries and problems with backward compatibility. Java is production ready since a couple of eons back and it's growing fast. 
The post started being downvoted, then the upvotes prevailed. But look at some of the discussions unraveled in that post. The kind of discussion is just... unwelcoming, even aggressive.
&gt; Some would argue that scala is not yet ready for production due to its lack of production ready libraries and problems with backward compatibility. They may, but it's absurd at this point. It's not even worth enumerating the organizations I know of that have had Scala in production for _years_ at this point. So maybe it's worth remembering that not all fear is rational.
Posters here just aren't particularly well engaged. Look at /r/haskell: in terms of *users here now* at the time I write this, it's 0.45% vs. 0.27%. Posts tend to have more comments, even a comment for something as niche as PhD student openings. And there's perhaps a bit of a persecution complex around here that the Haskell community lacks, leading to a feeling of negativity. Due to fewer trolls over there, I'd guess.
You were in a thread with at least one Cedric Beust sock puppet. Unfortunately, I think you were tarred by "guilt by association," i.e. people weren't sure you weren't _another_ Cedric Beust sock puppet. Try not to take those reactions personally.
It's Spray 2.0, they took the project over and integrated it into akka + added java interfaces
If you go by growth (new people, packages), communities around nodejs and ruby on rails had/have a incredibly strong showing, but this doesn't mean they are the best technology stack to build your business upon. It only shows that these are very popular and probably accessible. Scala isn't simple nor easy for new people, also it isn't as hyped as other technologies. Naturally many people will rather stick to dynamic languages like JS, Python, Ruby, PHP. And that's fine, as long as they don't have to scale into the millions. As for your comparison with Rust: I have extremely high hopes for Rust, but right now it's barely 1.0 and doesn't have anything on the big ecosystem of libraries and frameworks Scala (and the JVM) already has. I'd argue Go is also better suited for completely new development, because of this.
That lynch mob mentality is exactly the problem with the Scala community. It's tragic that you're not even realizing that. 
While you had a bad experience, you are still counted as a subscriber and still commented on a story posted on /r/scala. 
Can you give an example of something that isn't production ready that say, Rust, Go, or something else has? 
wasn't comparing with rust or go. 
A bit of experimenting in the Scala repl: import java.nio.file.FileSystems import scala.collection.JavaConversions._ val fs = FileSystems.getDefault val stores = fs.getFileStores.toList val devices = stores.filter(_.name.startsWith("/dev")) Not sure if that actually helps, but I guess it should be enough to start experimenting ...
Read [Functional Programming in Scala from Paul Chiusano and Rúnar Bjarnason](http://manning.com/bjarnason/) and do [the exercices](https://github.com/fpinscala/fpinscala).
IntelliJ works pretty well for me.
I agree its a good path to walk down, if you have time.
I'm using eclipse and I'm quite happy with it. It what way do you think it's not mature enough?
I've used ScalaIDE, IntelliJ and more recently Derek Wyatt's VIM plugin for scala. https://github.com/derekwyatt/vim-scala As far as full fledged IDE capabilities I think ScalaIDE is still the best, but I really find Eclipse awkward to use. If I'm going to use an IDE I would use IntelliJ.
Thanks for pointing out Scala plugin for Vim. I use IntelliJ with IdeaVim, but damn it's so slow when editing Scala code.
Give it more memory? I give my IJ 3 gigs and it works very snappy
I'll add another vote for Eclipse.
Of course. He's ahead, because wont have to unlearn stuff.
Not sure. What version of Scala are you using?
Hmm, how about nothing really works? I mean, you can type code in, and you can run it. but that's about it. The compiler gets confused. Code completion gets confused. Not a single offered refactoring works reliably. It's just enough to get by, but I can't imagine calling it "mature".
I have never had any problem with those features. But then again I haven't used scalaz or similar libraries. Others have mentioned problems with those.
You're not alone in asking that question, and I think that's why giter8 was created. Have a look, it might be what you're looking for.
Thanks for the response. I looked at giter8 as a solution but thought the /r/scala community might be able to answer the core question of "why isn't this better?"
The fast track to get an answer is to put this into a [Minimal, Complete, and Verifiable example](https://stackoverflow.com/help/mcve) on Stackoverflow. For example, specify `YuckClass`.
Last time I tried IntelliJ it ignored screen DPI, so it was rendering everything in ~5pt font or smaller. I ended up sticking with Emacs.
I hardly see how it's possible that you haven't had any problems. I literally have phantom compiling errors every day. I don't use any third-party scala libraries - I refuse to deal with anyone else's undisciplined use of scala's features. Not one of the offered refactorings works reliably. Sometimes, they work. Sometimes, they create code that doesn't compile and I have to figure out how to fix it, and sometimes they screw up the code so bad I really struggle to put the put back the way it was.
Unfortunately, a nontrivial example of this is a bit beyond a one-page jist. I am more looking for comments about what to make of the error message than ways to change my code...
How much scala code in your project?
Good points in general. I think you are right that the method should not be called "map" (maybe "quotienting" instead?), though I think renaming it to something clearer and more precise would be an example of better documentation ;- ).
As the message says, arrays are invariant in their element type. That means for trait Foo trait Bar extends Foo def test(x: Array[Foo]) = () you cannot use an array whose element type is a sub-type of `Foo`: test(Array[Bar]()) // fails Arrays being mutable data structures, you can access and update elements, therefore the element type must be invariant. See [here](https://stackoverflow.com/questions/6684493/why-are-arrays-invariant-but-lists-covariant).
Oh. I'm playing with projects with 30,000 lines of code.
Right because Lists *aren't* invariant they are covariant. So if we have class Derived extends Base, then List[Derived] is a subclass of List[Base]. Rephrased in a way that makes sense to me, you can imagine the compiler writing this somewhere: class List[Derived] extends List[Base]. This is because List was defined as covariant ie: class List[+A] ... This is not true with Array (so Array[Derived] is not a subclass of Array[Base]) for reasons mentioned above. Hopefully that helps clear it up, don't worry type variance is pretty difficult to understand at first
&gt; since it has a preferred directory layout and template files that it requires. Actually, it doesn't. Creating a minimal SBT layout is as simple as mkdir foo Personally, I think tools that generate templates for you, which you then need to edit, are terrible. They're a band-aid for systems that require too much boilerplate.
i know, i'm struggling with it! i'm coming from a background in R/Python..
Everyone struggles with it. It's a challenging book especially compared to most other programming books you can breeze through. 
[Activator](https://typesafe.com/get-started) is the answer.
I had the same question and found this at stackoverflow.com: http://stackoverflow.com/a/12781664
I think scala + play will get you 90% of the way there. IT has web stuff, JSON stuff, rest stuff, templating stuff, database access stuff (anorm). Maybe try out slick instead of anorm, each has pros and cons... 
I have a github repo that is just an empty sbt project for this purpose. I just clone it and run the init script when I need a new one. https://github.com/spjt/sbt-skeleton
Here's my setup: vim-scala for syntax highlighting- not perfect, but gets the job done. ctrlp.vim for navigation https://github.com/dscleaver/sbt-quickfix for navigation through compilation errors https://github.com/ceedubs/sbt-ctags for tags If you have programming experience of less than 2 years or scala experience of less than 2 months, I'd suggest using IntelliJ first. Eclipse, last I checked was super buggy. 
Aside from Play framework you will, most likely, need to use some ORM library. The best one to start (in my opinion) is Slick, but be aware of their politics to lock up the code for some database connectors behind a paywall at any time ( https://github.com/slick/slick/issues/1052 )
Vim. I've blogged a while ago about [my setup](http://bleibinha.us/blog/2013/08/my-vim-setup-for-scala).
In my opinion Scala/Play works best if you try to write most code server side, which means to use server side views. The best webstack I've used so far with scala is: Server: Play!, Slick Client: RequireJS, Less, PJAX Just makes no sense for me to write this failproof great backend and then use something like angularJS clientside and dip deep into all that non typesafe stuff 
Reminded me of http://googletesting.blogspot.com.au/2013/05/testing-on-toilet-dont-overuse-mocks.html, and http://googletesting.blogspot.com.au/2013/06/testing-on-toilet-fake-your-way-to.html
Not a financial trading company, but Tendril in Boulder is doing some interesting stuff.
I have been told that Morgan Stanley has projects using Scala + Akka. Sorry I can't be more specific, but it could be worth looking into.
&gt; it becomes more and more confusing what the purpose of the test actually is That's true regardless mocking presence.
You most likely need some database access library. Not necessary a ORM library.
I use Eclipse. It's clunky, but IntelliJ's metaphors and UI have never matched well with how i think. And until recently, IntelliJ looked like ass on Linux, my platform. A bunch of my colleagues use IntelliJ; in general, we report the same number of problems, just different ones. IntelliJ uses its own Scala parser, which sometimes gives spurious red squiggles. This became a problem on my team, since we had to avoid certain valid, non-crazy idioms just because IntelliJ couldn't handle them. Eclipse uses scalac, so it doesn't have this same problem (though it can report spurious errors too). IntelliJ's workflow just feels weird to me every time I try it; Eclipse, for all its faults, makes more sense. Other people report the opposite, YMMV. More basic features work in IntelliJ, from what I've heard. Some of the rough edges of the Eclipse Scala plugin make me wonder if the plugin devs actually use their own tool. They claim to on the mailing list, but if so, their use patterns must be *way* different than mine. 
Are you *really* sure they wont aks fees for open source DB connectors one day in the future? I really like Slick and I'm using it in my project, but the story with MsSQL and the "we are trying to find our business model" thing does not appeal to me at all.
Yeah I'm p confident they won't ask fees for MySql/pg drivers. That would be laughable suicide for the library.
 I heard that they create statistical softwares mostly.
Thanks for the link, ScalaJS is actually something I've been looking into as well. I've been involved with 3+ largeish SPAs in the last couple of years (mostly Angular) and I've definitely felt the pain. If I'm not mistaken, ScalaJS really picked up some steam recently. 
If you are anything like me (keep in mind I am about 2-3 months into learning Scala), I would recommend it. I personally believe it helped me learn more pure Scala and less Play! Scala. Play! comes with a great number of conveniences and they tend to be well documented, but sometimes forcing yourself to find an alternative will help you better understand the community/ecosystem at a different level. I think your comparison to Rails and Sinatra may be appropriate, with the caveat that this is entirely based on anecdotal knowledge of the two frameworks, I have never used either Rails or Sinatra. 
still scarred from the first! 
I did NOT like this class! I really enjoyed the FP in Scala one, but this one was disjointed.
There is really limited articles about spark monitoring. Thanks for sharing!
Thank you, I'll probably go on this route then. I'm in no hurry anyways, so it's not something I want to do in a matter of weeks.
giter8 is probably what you're looking for.
No misconception, I understand, I just disagree. ;)
That's how I've been building my last couple of SPAs as well, they're actually in separate repos so the team can be more split up and flexible. That said, Javascript is still nasty even compared to other dynamic languages.
This is quite.cool! It certainly is an interesting way to look at the problem. I don't know anything about f bounded polymorphism. Would you.Say that #4 is an instantiation of it? What's a good way for a beginner to learn and practice this concept? I feel with these things, understanding how the syntax explains these ideas is a real kicker. A talk might be too fast. What about adding more repl friendly blocks? I always love when I can follow along to new info with a compiler :)
&gt; The original FP course, by contrast, didn't have any of these problems. I had such a problem in the original course. Which session did you do? Maybe they fixed them recently. If they did maybe there is hope that they fixed them in Reactive for this session. 
The only issue I have with giving each layer its own error types is that, in a web service/app, it amounts to a ton of boilerplate code if every service method needs to handle every possible repository error and convert into equivalent service errors. Especially when many of them are common errors... not found, already exists, unique/foreign key, etc, will all be mapped to identical service errors and then to their equivalent Http respones (404 Not Found or 409 Conflict) responses. The ugly solution is to resort to implicit conversions to handle all the standard cases.
It's a list. And sometimes you want different performance characteristics.
Pressing space always takes to next slide 😃
F-Bounded polymorphism is just a specific version of parametric polymorphism. Parametric: `trait WObject[Self]` F-Bounded: `trait WObject[Self &lt;: WObject[Self]]` http://en.wikipedia.org/wiki/Bounded_quantification#F-bounded_quantification S#4 is not F-bounded, because it doesn't have the recursive type requirement, therefore - it is headache free(-er) :) I'm not sure it is a concept that needs a lot of grasping, but I already know it, so... Also - all the code there should pretty much run on REPL.
Agreed, and the example code shows just such duplication. Union types are a solution to this, and discussed at the end of the article. I've since come across a simpler way to encode union types in Scala: http://japgolly.blogspot.co.uk/2015/02/zero-overhead-recursive-adt-coproducts.html
Your functions are curried: they have multiple argument lists. When a function is curried, it's actually a function that returns a function. Your `uncheckedUpdate`, for instance, is a function that takes an `S`, a `U` and two `Boolean`s and returns a function that takes a `Writer[S]` and a `Writer[U]` and returns `Unit`. Declaring different implicits doesn't actually change `uncheckedUpdate`'s parameter types but its return type, and this is why the compiler is (rightly) complaining.
I suspect the reliance on sealed traits and pattern matching in base classes means this system will not scale beyond simple examples. Is this concern unfounded?
Probably because old guys from Unix era, on their death bed are creating Scala tools. its hopeless since we are not even allowed to say the truth in Scala communities, let alone fixing these problems.
You can fix the abstract types in a couple of ways. First with a self-type: trait T { this: Self =&gt; type Self &lt;: T } Or with type bounds: trait T { type Self &gt;: this.type &lt;: T } In either case, you're declaring that `this` must be an instance of `this.Self`. Not sure how well these actually work (I'm on a phone right now), but they *should.* Probably. :)
i dont want to miss any of the talks which shows how to do Scala RAD development using Open Source IDE
Ah, thanks, I am not yet hip to keyboard based slide navigation.
Interesting, I wonder what would happen with a hybrid F-bounded abstract type approach; i.e. would it help to solve the problems that each alone present trait Foo[T &lt;: Foo[T]]{self:T=&gt; type Self &gt;: self.type &lt;: Foo[T] } or just make things worse ;-)
You can simplify the definition of your type classes if you abstract over applying values to your entities. This will remove the need for you pattern match for the entities type and have a single definition for implementing for your type class instances. For example in `WObjectOps` you have this method: def withHp(hp: Int): Self In order for a instance of `WObjectOps` to know how to construct an instance of `Self` when applying a `Int` as a HP value it will need a function to do that. implicit class WObjectOpInstance[A &lt;: WObject](obj: A)(implicit apHp: (Int, A) =&gt; A) extends WObjectOps[A] { override def withHp(hp: Int @@ HP): A = apHp(hp,obj) } Now our general WObjectInstance can apply a HP value without know how to do so or pattern matching on what A is. When implementing a WObject we only need define an implicit function for applying an Int to HP like so: object Rock { implicit def apHp(newHp: Int @@ HP, rock: Rock): Rock = rock.copy(hp = newHp) } case class Rock(position: Vect2, hp: Int, id: UUID=uuid) extends WObject I have a scastie [here](http://scastie.org/8309) with a full implementation along with a few other notes. 
Have you looked at any of the Lens libraries like Monocle? I would be very wary of F-bounded polymorphism and deep inheritance hierarchies in general. I've rather use algebraic data types and type classes.
I have to disagree. The issue is, as OP's error message says, with [default arguments](http://stackoverflow.com/questions/4652095/why-does-the-scala-compiler-disallow-overloaded-methods-with-default-arguments). &gt; Your functions are curried: they have multiple argument lists. When a function is curried, it's actually a function that returns a function. As far as I am aware *that* is not the cause for erasure issues here... methods get all compiled down to actual full parameter lists in byte code no problem and scalac won't complain either. This is why [this](http://stackoverflow.com/questions/3307427/scala-double-definition-2-methods-have-the-same-type-erasure/3308161#3308161) works and why OP's solution would work too if he didn't use default arguments. P.S. Partial application is implemented by just wrapping in an appropriate anonymous function: def foo(a: Int)(b: Int) = a + b will be compiled to something like int foo_lowlevel(int, int) { ... } and a call f = foo(2)_ that returns a function will be realized as f = (x =&gt; foo_lowlevel(2, x)) (At least in my test code this is happening as I described!) 
Yes, we have looked into them. They tend to be more suited to entity systems, one of the explorations is here: https://github.com/bartosz-witkowski/entity-system-lenses However inheritance based approach makes more sense to me personally.
If you have a poorly typed object you still need to pattern match: http://scastie.org/8310 That's the main point: Scout.moveTo -&gt; Scout, Movable.moveTo -&gt; Movable from users perspective.
Will this also work with maven? 
The problem has nothing to do with curried functions but with default arguments as explained [here](http://www.reddit.com/r/scala/comments/2xlcnj/compiler_error_says_im_overloading_a_method_with/cp1o4v0).
I put it in my ~/.sbt/0.13/global.sbt. Now I have it available in all my projects :3
I meant make the operator shorter. 
Here's the diff: https://www.diffchecker.com/3hw85nuk If there's a better website for diffing, let me know. I couldn't figure out how to get github to do the diff (renamed the file).
What are those additional features of lenses that are mentioned? 
How will that become less feasible? And pattern matching at call site means I have to repeat tons of code. 
 libraryDependencies += "com.lihaoyi" % "ammonite-repl_2.11" % "0.2.4" % "test" initialCommands in console := "ammonite.repl.Repl.main(null)" It's honestly that simple, but be careful with the scalaVersion setting. I inlined it (used % "ammonite-repl_2.11" instead of instead of %% "ammonite-repl") and it's been working fine so far. Might yell at me if I use it in 2.10 projects, we'll see. :)
I find it super convenient to have each module do something along the lines of object Foo { trait FooConfig { username: String; password: String } def doFoo[A &lt;: FooConfig](s:String): Kleisli[Option, A, Data] = ??? } You can then compose a 'master configuration' type that you thread through multiple monadic APIs. http://blog.originate.com/blog/2013/10/21/reader-monad-for-dependency-injection/ https://thenewcircle.com/s/post/1108/dependency_injection_in_scala
At my work, we had a few projects built with the cake pattern. Compile times were long and the code was hard to read. We switched to doing our DI and wiring with constructor params, and haven't looked back.
I haven't dove deeply into scala specific DI, but the base Java ones seem to work well. Using Play2.3, I have been happy enough with Guice DI for a relatively small project. It seems the play team has defaulted to Guice going forward (https://www.playframework.com/documentation/2.4.x/ScalaDependencyInjection). In another system, we're doing DI with Spring and since it uses the same base annotations, it feels the same. Thankfully, not driving any of the config via XML. I know that these aren't the coolest approaches, but easy enough to grok. 
love it
The advantages of the cake pattern to me always seemed fairly tenuous, especially compared to the complexity it brings. But then what people do is throw it away and use some DI framework instead. Is there really a need for it? I just new things up and pass through dependencies in constructors, it works and everyone understands it. 
Man, I just wanted to know what kind of development environment is mostly used. That's all. Have a nice day.
Or you can just use manual dependency injection: http://di-in-scala.github.io Very simple syntax ("just Scala") and clear, easy to understand, at least for me.
 I think you need to create some cool projects from scratch. Reinvent scalaz(it helps to understand typeclasses with traits, implicits through categorytheory), create yet another DI framework, contribute to opensource stc. No, haskell won't help you, it is too poor.
Where I get really confused with the Reader stuff is... * what do my methods look like when I don't have option, I have `scalaz.\/` containing either FooError or Foo, wrapped in a `Future`. * is there no way to elegantly describe what a module's dependencies are without passing around a global config object that holds every dependency? I've only reached the point where I can grok the EitherT transformer to compose multiple `Future[\/[FooError, Foo]]` together.
Two good books will lift you up 1. Functional Programming in scala 2. Category Theory by Steve Awodey
Very simple, first learn how to add JAR files in eclipse scala Projects and start tinkering with their usage. # Basically, if we can get past SBT this way, there will be no looking back and we all will be free to use Scala as we would like to, but right now our world is infested by PSYCHOS.
[**@dh44t**](https://twitter.com/dh44t): &gt;[2015-01-19 02:01:47 UTC](https://twitter.com/dh44t/status/556994900089376768) &gt;SBT = Stinky Bullshit Tool [#Scala](https://twitter.com/search?q=%23Scala) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2xsk0p%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
WHATs THE USE OF ALL THAT IF WE CANT GET PAST SBT ? AND WHY LEARN A LANGUAGE IF ITS USELESS, OTHER THAN BEING A LANGUAGE FOR NO REASONS ?
Such content Many argument So quality Wow
Sure, that should be possible to implement as well (if not already implemented), but then you have to repeat the class name and give the specific person you want to update anyway. Different use-case :)
I use sbt for all my scala stuff, granted I only use scala for personal projects. Personally though... I love it and I don't really understand the hate. It's so flexible and modular with tons of plugins. Granted, I've never used Maven and used gradle for 5 minutes. I have used Ant for an android project, thought it was a nightmare... 
Please, *yes*.
At least Maven's configuration file syntax is simple (though the grammar certainly is not).
I'm co-teaching the Scalaz course with Noel the week of the ScalaDays conference. I happened to learn the most about FP from http://learnyouahaskell.com, which let me understand what scalaz is trying to do, and how it does it. 
Haskell will toss you into functional programming and lazy evaluation at the same time, which seems to confuse some people. OCaml or SML will get you functional programming without the lazy-by-default of Haskell. They all have *basically* the same type system (there are a couple differences), and they all have proper type inference. (Although Haskellers tend to discourage the use of type inference more the others.) All 3 are based on ML, and have similar syntax and type systems but there are some differences. SML is designed around type inference, so you *never* need to explicitly specify a type. (but you can) Haskell is very much designed around lazy evaluation. OCaml seems a lot more pragmatic, although it's also written by researchers. Personally, I learned Scala last.
Good intro stuff. And goes perfectly with the submission just below it: http://www.warski.org/blog/2015/02/quicklens-modify-deeply-nested-case-class-fields/
&gt;what do my methods look like when I don't have option, I have scalaz.\/ containing either FooError or Foo, wrapped in a Future. You answered your own question! EitherT! So to make it a little easier for coworkers to grok and to avoid type lambdas, I will have type FutureReader[A] = Kleisli[Future, FooConfig, A] So, now we can do type SatanMonad[A,B] = EitherT[FutureReader, A, B] //A is error &gt;is there no way to elegantly describe what a module's dependencies are without passing around a global config object that holds every dependency? Well, that's why I did the bounding on my type parameter. So each module can have it's own config, and then when you want to combine them you can make a GlobalConfig that extends all the relevant configs, this allows you to mix and match your SatanMonad between different modules. Does that make sense? I may not be too clear here... Also, I should mention I learned all this stuff from the IRC channel (freenode network) #scalaz. There's a REPL in the chat room so you can get real time help on types, and a lot of smart folks that are more knowledgable than myself. 
I recommend using simple constructor based DI assisted by [macwire](https://github.com/adamw/macwire).
FWIW, I ditched the cake pattern on some projects in favor of doing DI with constructor params. At the same time, I was also migrating a medium-sized Scala app off of Spring (we'd ported the app from Java and inherited the Spring mess). We evaluated Guice, Macwire, and probably some others before deciding to just do it ourselves. We had a basic Wiring trait: trait Wiring { def foo: Foo def bar: Bar //etc } and a concrete implementation: final class ConcreteWiring extends Wiring { override lazy val foo: Foo = new Foo(config.baz, ...) override val bar: Bar = new Bar(...) private val config = Config.load() //from classpath, whatever //lots of vals, defs, and lazy vals } Writing in pure Scala let the compiler find wiring errors, and made everything explicit - for us a big bonus. We didn't get any fancy magic wiring-by-matching-up-types stuff that Guice and Macwire can do, but we didn't want that. Plus, Scala constructs did 99% of what we'd let the DI framework manage. I.e. why deal with @Singleton (or whatever) when you could have a lazy val?
I'll be there giving a talk about my new [type-safe off-heap memory project](http://event.scaladays.org/scaladays-sanfran-2015#!#schedulePopupExtras-6560). Hope to see you there.
I'm attending, and I've signed up hoping to TA the [Creative Scala](http://underscore.io/events/2015-03-15-creative-scala.html) course on the 15th. :-)
This is great, thanks! It's nice to have practical, non trivial examples of macros.
Go can Compile to Machine Level, and when Go will compile to Google Native Client, JVM will GO, i mean JVM will become OBSOLETE# # ;-)# # i Recommend Google to port Go for Android AOT also. That should kill the entire Java ecosystem for Andriod.# #We are Anonymous, we do not forget, we do not forgive, expect us.# Moral of the story, you dont vote down Thinktanks on Reddit, since we can exterminate you all by ideas alone, and ideas cannot be killed just by voting down. 😛 you mother vote downers.
Both really, depending on which is more convenient. Sometimes it's annoying to lift or otherwise coerce your types to be right... I still think it's a good way to go, but that's the downside, sometimes you lift, sometimes you need to wrap etc. Right now I have a few helper methods that basically add a 'toSatanMonad' from a few different types via implicits.
Have you seen activator? it literally has a menu to create dozens of types of applications, simple stuff.
Julian Dragos has a presentation.
Flying from Montreal. I'm working as a volunteer.
looks awesome to bad can't be there for either :( 
Oops I told you the wrong order, sorry! I changed the types in my original message. If you have a (f:FooConfig) =&gt; Future[\/[FooError,A]] Your transformer will be EitherT[Kleisli[Future 
Going to be there. Talking about core Scala patterns in the first slot after the keynote on the first day. Say hi if you see me around! Running a bunch of events around Scala days: - Creative Scala before hand (with /u/paul_snively as TA!). We would really benefit from a few more TAs, so if you're interested please sign up. - Helping /u/arosien with the advanced Scala workshop on Thursday. Event descriptions here: http://underscore.io/events/
I wish. Hoping for lots of videos to watch at least. 
If you want a good laugh, read his comment history
Will be there as well, presenting our progress with the new metaprogramming platform for Scala: http://scalameta.org/.
You'll see me there :)
Hi, the old recursive macro is here: https://github.com/pathikrit/sauron/tree/3bde2a2f27094390465cb05ff7692066a3d98d55
Activator is clouds based. i am form Eclipse /IDE era, for that. And i am against donating my precious code to the illuminatis. and i guess you all will live in the tyrannical era of 1984 forever , so you use sbt command line with Vi and Emacs.
I will be there and attending the advanced Scala training. Looking forward to meeting other Scala devs.
I'll give a talk about [Reactive Slick](http://event.scaladays.org/scaladays-sanfran-2015#!#schedulePopupExtras-6554)
Newbie question: What would the for-comprehension look like? Here's my attempt: for ( instance &lt;- instanceIds status &lt;- Try(EC2.terminate(instance)) failure &lt;- ??? exception &lt;- failure.exception ) yield exception Edit: Duh, the OP variant is a for comprehension.
I'll be attending, giving my infamous [Skeptic's Look at scalaz' Gateway Drugs](http://event.scaladays.org/scaladays-sanfran-2015#!#schedulePopupExtras-6532) talk. I'll also be teaching the !sold out! Advanced Scala training course. 
&gt; Ec2.instances(instancesIds).map(Try(EC2.terminate(_))) Does some newer version of Scala let you do that? AFACT, with 2.11 you'd have to revert to =&gt; syntax, like Ec2.instances(instancesIds).map(x =&gt;Try(EC2.terminate(x))) It would be nice if Scala could figure out that's what you meant based on the types though.
I don't like using map for effectful code. You aren't transforming the data, you want to trigger an effect for each id. It's good that the foreach stands out and doesn't look like a simple side-effect free data transformation, IMO. I wouldn't go out of my way to call people on it, BTW - just defending the foreach which I think is a better convention for these cases. 
Nice. I was looking to refresh my Scala knowledge, so it comes really handy right now. Edit : have to note that it's a little annoying that the answers are white space sensitive, they need space after comma 
Could you make a bifoldable for try and then use Separate on monadPlus? Then you'd get a tuple of the failures and successes! 
This guy 😒
Are you like one of Martin Odersky's disgruntled ex-girlfriends?
Better? It's on their getting started page https://typesafe.com/get-started with a download link and a video.
He was around months ago with a different account, I have yet to figure out his motivation.
Please do not post extremely low content posts like this again.
Thanks everyone!
Didn't work in Google Chrome for me. I saw a pretty background and a "How it works for me?" button which did nothing when I tried clicking. Oh, wait, when I tried again it worked this time? Hmm...
Man, this is the most teenagey thing I've read in any of the Scala/Rust subreddits I visit.
I can't delete your account ;( But my contribution is to make you do it ;)
I guess your english isn't so good eh
An old-but-similar project is described in this [PDF](http://www.csc.depauw.edu/~bhoward/papers/mcurcsm07.pdf). Edit: minor change to wording.
Hm, no big news once you've skimmed over an Akka introduction tutorial ...
i also notice in chrome it maxes my cpu while open :(
&gt; It's honestly that simple, but be careful with the scalaVersion setting. I inlined it (used % "ammonite-repl_2.11" instead of instead of %% "ammonite-repl") and it's been working fine so far. Why?
I follow 120-line margins :)
For new learner, you can do it by your self. IDE will do things automate, but it not good for you understand what behind the GUI things. I preferred learn a new tools or language via do things by hand. not the automatic tools. If you already know how to do it by hand, it is better moved to the automate tools . Tools be invented to save our time, to enjoy our development progress.
Don't know about this scaladoc vulnerability but regarding to statically served files, the following code has XSS vulnerability and it doesn't need to be dynamically served to be vulnerable. &lt;script&gt;document.write(location.hash)&lt;/script&gt; Exploit using url `http://domain/file.html#&lt;script&gt;alert(1)&lt;/script&gt;`. 
tks for all the gr8 feedback folks! i only discovered Try and Either after i wrote the post
++Gradle --Incoherent weird comments/rants
Indeed you can! I'll update the slides to mention these things. The problem with abstract types is that all methods need specific types: scala&gt; def self3MF[A &lt;: Movable with Fighter](a: A): A = a.self.self.self &lt;console&gt;:10: error: type mismatch; found : a.Self#Self#Self required: A def self3MF[A &lt;: Movable with Fighter](a: A): A = a.self.self.self ^ scala&gt; def self3MF[A &lt;: Movable with Fighter { type Self = A }](a: A): A = a.self.self.self self3MF: [A &lt;: Movable with Fighter{type Self = A}](a: A)A And when pattern matching from a poorly typed collection you can't get that specialization: scala&gt; object B extends Movable with Fighter { | type Self = B.type | def self = B | } defined object B scala&gt; self3MF(B) res6: B.type = B$@7d49576a scala&gt; self3MF(B: Movable with Fighter) &lt;console&gt;:13: error: inferred type arguments [Movable with Fighter] do not conform to method self3MF's type parameter bounds [A &lt;: Movable with Fighter{type Self = A}] self3MF(B: Movable with Fighter) ^ &lt;console&gt;:13: error: type mismatch; found : Movable with Fighter required: A self3MF(B: Movable with Fighter) ^
? This is the link, it's the actual article: http://alvinalexander.com/scala/simple-scala-akka-actor-examples-hello-world-actors
Well, this is all nice and true for people who know scala. but the OP has a good point for new people coming from Haskell, Ruby, Node or python. For people coming from Java (at least me) SBT is even more tolerable than maven (no flame wars please) But for someone who is usual to &lt;npm/bower/brew/gem/pip&gt; new &lt;foo&gt;; cd foo; &lt;npm/bower/brew/gem/pip&gt; start / run then these are the small things that people say - well if everyone is doing X and scala doesn't, I wonder what else they didn't get in the zeitgeist of times... moving on to (go / rust / him / swift / julia / clojure) as my "2nd go to langue to learn in my spare time" The more silly syntactic sugars we the scala community add, the more it will appeal to the general audience who is used to instant gratification and X instal Y and you got yourself a full 3 tier REST server with a kitchen sink. The lack of standard built in JSON, File, Zip, and other easy to use runtime libraries is also discouraging. In Python, Ruby and I think also Go, a lot of the basic stuff (parsing JSON, Http/REST client, file handling, compression, time handling) is all done nicely in the core libraries. In scala it is "how to X in scala", and if you don't find something that you like it's "how to X in java" the java.io.File API is terrible for people coming from other languages into Scala. and Scala's file handling library is lacking to say the least... Thinks should be as simple as URL("foo").post(...) as a trait, and having different implementations. library authors should not define the API for basic things, they should define the implementation. /rant 
p.s. I urge you to add this and suggest a pull request... I don't see any reason why it's a bad thing to have sbt create myApp that has defaults for everything (default you can modify with command line params) I'm voting for it...
Elsewhere in the thread I replied that encouraging people to use activator instead of just sbt may be a good idea, and the more I think about it, the more true I think it is, both for the "create the project structure from a template" feature and for the "give me easy access to reasonably high quality bits of the ecosystem" feature. In other words, it really is the `gem` or `pip` of the ecosystem.
Sorry, i am coming from go and trying to evaluate scala right now so this was one of the first articles I came across. I am still trying to figure out the scala best practices.
nice! just not very typesafe to use runtime/reflection and a "::" string to denote double-colon for list concatenation.
&gt; Since this library was made so that Clojure can consume Scala cljs's only domain(weak) is websites, so don't be scared, it isn't going to happen. &gt; A typed facade over useful things from Clojure (if there are any?) You can't really create something with acceptable dsl in clj - just functions... and functions. I wonder what OP wanted here. 
Yes. A `scala.concurrent.Future[A]` is able to implicitly convert from / to a `com.qifun.statelessFuture.Future.Stateful[A]`. See: http://qforce.qifun.com/stateless-future/0.3.1-SNAPSHOT/api/com/qifun/statelessFuture/Awaitable$.html#fromConcurrentFuture[AwaitResult](scala.concurrent.Future[AwaitResult])(ExecutionContext):FromConcurrentFuture[AwaitResult]
There are various things you can do to make your code more scala idiomatic. 1) You can take advantage of the fact that If are expressions not statments. So instead of this: var retValue: Int = 0 if (n == 1 || n == 2) { retValue = n } else { retValue = nthFibonacci(n - 1) + nthFibonacci(n - 2) } You could have this: val retValue = if (n == 1 || n == 2) n else nthFibonacci(n - 1) + nthFibonacci(n - 2) 2) You can use pattern matching. def nthFibonacci(n : Int) : Int = n match { case 1 | 2 =&gt; n case _ =&gt; nthFibonacci(n-1) + nthFibonacci(n-2) } 3) You could make use of the method [getOrElseUpdate](http://www.scala-lang.org/api/2.11.0/index.html#scala.collection.mutable.Map) in the mutable map: def cache = scala.collection.mutable.Map[Int, Int]() def nthFibonacci(n: Int): Int = { if (n &lt; 1) throw new RuntimeException def originalNthFibonacci(n: Int): Int = n match { case 1 | 2 =&gt; n case _ =&gt; nthFibonacci(n - 1) + nthFibonacci(n - 2) } cache.getOrElseUpdate(n, originalNthFibonacci(n)) } As far as optimizing the code you should look into memoizing the fibonacci function.
Question 1: In the preferred Scala style it almost always possible to avoid using explicit return statements. All expressions return a value so the first function could be written thus: http://pastebin.com/QZwHRUAz Question 2: Your caching mechanism is not correct. Instead of a def you should use a val for your cache. You can confirm this for yourself by doing a println(cache.size) after attempting to add a value to it. The def is defining a method so every time you call cache it is actually returning a brand new empty map. By using a val you will be updating and looking up values from the same Map instance. That is what you want. As far as style, again, the code could be restructured to avoid using return statements. I have not fully checked your logic but it would be better to keep your function simpler by using a second helper function. You are throwing the exception correctly but IllegalArgumentException is the standard exception for invalid arguments that are passed into a method. It is a sub class of RuntimeException. Question 3. Using recursion puts a lot of frames on the stack. You can increase the stack size with JVM configuration. Also, I would recommend looking at tail recursion and specifically tail recursion optimization in Scala using the following annotation. @tailrec Question 4: It is normal for your Scala code to look like Java initially. Over time you will learn to make good use of the Scala idioms and the code you right will be more concise and expressive. The idiomatic Scala style is typically to write small functions or methods and a distinct preference for nested expressions over the use of temporary variables. The main thing that will help is reading Scala code that experienced developers have produced. I would recommend the "Functional Programming in Scala" course by Martin Odersky et al. on Coursera. It's a good course and they teach some of the Scala style guidelines as well. 
In addition to the other answers, there is also the recent book [Functional Programming in Scala](http://www.manning.com/bjarnason/).
Alternatively, you could make a self-recursive infinite list: [(copied from here)](http://www.scala-lang.org/api/current/#scala.collection.immutable.Stream) scala&gt; val fibs: Stream[Int] = 1 #:: 2 #:: fibs.zip(fibs.tail).map(n =&gt; n._1 + n._2) fibs: Stream[Int] = Stream(1, ?) You can then use it like a function: scala&gt; fibs(0) res0: Int = 1 scala&gt; fibs(1) res1: Int = 2 scala&gt; fibs(2) res2: Int = 3 scala&gt; fibs(3) res3: Int = 5 scala&gt; fibs(10) res4: Int = 144 scala&gt; fibs(20) res5: Int = 17711 scala&gt; fibs(40) res6: Int = 267914296 This example probably isn't very helpful, but interesting nonetheless.
 These stickers are very funny, it's hard to choose!
.distinct :)
But doesn't distinct remove all duplicate elements and not just the duplicates that are next to one-another?
I think you meant repetitive elements? C++'s unique operation does this: http://www.cplusplus.com/reference/algorithm/unique/
I keep track of last element I added to list (I call it `current` in the code). To begin with, `current` is `None`. If `current` is equal to the first element in the list, i.e. (`current == Some(list.head)`) I do not add it else I do. I recurse on rest of the list till I get to an empty list.
or using fold: val fruits = List("apple", "apple", "orange", "apple") fruits.foldRight(List(fruits.last))((fruit, result) =&gt; if (fruit == result.head) result else fruit :: result)
This would fail for empty list :) def removeRepeats[A](l: List[A]) = l.foldLeft(List.empty[A]) {case (result, elem) =&gt; if (result.lastOption == Some(elem)) result else result :+ elem} 
Hi, sorry I am late replying I had a busy day. Why is the code all one-lined? Can it not be split into a block to make it more readable? I'm not by any means a professional at Scala and am still learning but what does [A] mean? How could I split the cases and inside if statement up to make it more readable and understandable? Thanks in advance, I really do appreciate your time and help.
It's less "fun", but faster def f(n: Int) = ((((1 + math.sqrt(5)) / 2: BigDecimal).pow(n) / math.sqrt(5)) + 0.5).toBigInt() 
If you don't know what `[A]` means, you need to learn Scala basics. A good place to start would be these links: http://stackoverflow.com/tags/scala/info http://learnxinyminutes.com/docs/scala/ http://scala-exercises.47deg.com/ Anyway, here's a non 1-liner for clarity: def removeRepeats[A](l: List[A]) = l.foldLeft(List.empty[A]) { case (result, elem) =&gt; if (result.lastOption == Some(elem)) result else result :+ elem } 
Thank you very much. From one of the links I got the following, would you say it's a simple "explanation" of the [A] part? "A should have an implicit conversion to B available, so that one can call B methods on an object of type A"
Can you explain more? I think you mean `lazy def` ? :)
I see where you are going. So maybe a syntax like this: lazy val fib(n: Int) = if (n &lt;= 1) n else fib(n-1) + fib(n-2) ?
As demonstrated by the code in the link, there's no need for a language level keyword since Maps and Dicts are also functions in Scala. Creating a cache is just as easy as composing a Map instance with your function. Most most of the time you want a cache that more complicated, where the exact implementation and details are determined at call site. I don't think a language construct can capture these more subtle requirements(unless you consider a type level computation done by implicits, similarly to CanBuildFrom).
&gt; Ammonite Yes that's probably what you are looking for.
The [Scala Console in Intellij](https://confluence.jetbrains.com/display/IntelliJIDEA/Working+with+Scala+Console) is quite nice - autocompletion, import package-help, etc.
I wrote this in Java the other week and using int it will not work as there is an overflow of the 32 bit integer. The solution was to use a Long as it's 64 bit and can obviously handle larger outputs.
Author here. A have found long unmainained package for ctags/etags extraction for Scala language at http://programmer-monk.net/darcs/repos/sctags/ I have made it work with the recent version of Scala compiler and extended it to support proper scoping, type/method signatures, etc. I have also provided some example Vim/Tagbar configuration in the README. I hope you will find it useful. 
&gt; Very cool! I use a custom .ctags file, but it doesn't do any fancy parsing. Yes, I was using the usual .ctags definitions but wanted something more. Sctags uses the Scala parser so could make sense of lot more elements.
Hey people! The results are in. Here are the winners: http://imgur.com/UsiFFbN I selected the best this morning and took them to print Here is the result: http://imgur.com/KSzNk4W http://imgur.com/YSbRDai http://imgur.com/4qtXfkt After Scala Days we will start shipping these to whoever put their address. I didn't expect people from all over the world! I've closed the survey. If you still want a few of these, email me at jaime at codacy.com and we'll try to send a few for you. Keep shipping great Scala code!
There's also https://github.com/megaannum/vimside which is the vim implementation for ensime (which is great for emacs).
Converters are doers, ie. methods you call to do the conversion. Conversions are done things, ie. actions that are taken on your behalf by the compiler. 
Ctags is common format for indexing programming language definitions (class names, method names, etc). Etags is the same but for Emacs. There are a lot of tools/editors that understand and use ctags for searching and jumping to definitions, auto-completion, hierarchy browsers etc. This package extracts ctags/etags from scala source files 
1. new String(Files.readAllBytes(Paths.get("myfile.txt")), StandardCharsets.UTF_8) 1. Files.write(Paths.get("myfile.txt", "hello".getBytes()) See http://docs.oracle.com/javase/7/docs/api/java/nio/file/Files.html#write(java.nio.file.Path,%20byte[],%20java.nio.file.OpenOption...) and http://docs.oracle.com/javase/tutorial/essential/io/file.html
This throws a compile error on getBytes saying it expects a string: java.nio.file.Files.write(java.nio.file.Paths.get("myfile.txt", "hello".getBytes())) If I remove .getBytes then Files.write throws an error: &gt; overloaded method value write with alternatives: (x$1: java.nio.file.Path,x$2: Iterable[_ &lt;: CharSequence],x$3: java.nio.file.OpenOption*)java.nio.file.Path &lt;and&gt; (x$1: java.nio.file.Path,x$2: Iterable[_ &lt;: CharSequence],x$3: java.nio.charset.Charset,x$4: java.nio.file.OpenOption*)java.nio.file.Path &lt;and&gt; (x$1: java.nio.file.Path,x$2: Array[Byte],x$3: java.nio.file.OpenOption*)java.nio.file.Path cannot be applied to (java.nio.file.Path) Maybe it's not java.nio? Compiler didn't recognize it without namespacing. 
The general answer to this question is that Scala standard library doesn't give you much in the way of IO support. You can read text and that's about it. So you can lean on APIs provided by the JDK or use a library like [rapture.io](http://rapture.io/).
Hmm. In general I'm finding Scala a lot easier than Clojure, but in Clojure the answers to this one are (slurp filename) and (spit filename contents). 
This worked: class Filehelper (val folder:String) { //create file if doesn't exist, overwrite if does exist def spit(filename:String, contents:String):Unit = { val fullpath:String = folder + "/" + filename val strandwriter = new PrintWriter(fullpath, "UTF-8") strandwriter.write(contents) strandwriter.close() } //if file doesn't exist, return empty string def slurp(filename:String):String = { val fullpath:String = folder + "/" + filename if (new java.io.File(fullpath).exists) { val source = scala.io.Source.fromFile(fullpath) val s = source.mkString source.close() s } else "" } }
Conversions are perversions
Exercise: How do you differentiate between a file doesn't exist and an empty file?
Apache Commons IO FileUtils class will do all of these things. http://commons.apache.org/proper/commons-io/javadocs/api-release/org/apache/commons/io/FileUtils.html
You could write those 2 functions yourself, no?
How is the character encoding specified, or does it simply assume UTF-8?
Would be interesting to know why exactly they want to phase out... Anybody?
There's an optional param: (slurp "/path/to/file" :encoding "ISO-8859-1")
Very cool stickers! I love the Future one and the Failure is not an Option one!
[Here is a document](https://docs.google.com/document/d/1h3KUMxsSSjyze05VecJGQ5H2yh7fNADtIf3chD3_wr0/edit) describing the current layout for serialized typed syntax trees.
Perhaps a stupid question, but if there is a hash collision, does that mean that Scala would accidentally believe that a binary class file is compatible when it's not? Is that just a question of enough hash bits to make this less likely than a meteor hitting earth? I also wonder about the argumentation that build-from-source is not an option simply because we are relying too much on Maven. If that was the only reason, couldn't build-from-source be slowly introduced? I have the feeling, the compiler speed (typer) and the initially shown possible problem of source incompatibility are actual problems that favor this new approach. 
I wasn't saying libraries are bad. You seemed to be discounting Scala for not having those 2 convenience functions, so I was pointing out you could make them for yourself.
Another question... "You can add methods anywhere". So let's say I have a library that provides a `trait Foo` and I add an abstract method `bar` to it. What happens now with clients using that library? I suppose that if the client does not have any class implementing `Foo`, it's ok. But if does have a class that doesn't happen to already have `bar` it will be incompatible. Correct? So if I extend my API, I would still have to announce a new "major" version, indicating that it potentially breaks client code. Or am I misunderstanding something? To make it more complicated, let's say another library `Baz` depends on `Foo`. How does the typed-trees approach then solve the mentioned type of compatibility issues (adding a method) in such a scenario?
Believe me I'm not discounting Scala, I'm really liking it a lot.
&gt; Don’t resort to map to transform values &gt; // Before &gt; map.map(f(_._2)) &gt; // After &gt; map.mapValues(f) &gt; Again, the special method looks cleaner and the new map is created without copying any elements. This is dangerous advice. mapValues secretly creates a view under the hood. I didn't know this and recently had a performance bug due to it. I was accessing a map created by mapValues in a tight loop. The function for mapValues was a groupBy of a very large collection. This massive groupBy was then called on each access to the view since that's how views work -.- I now have a mapValuesEager method mixed into maps which uses map which is strict. Since this guide seems very focused on performance, this mapValues advice should be removed. 
Good find, yes `mapValues` should be deprecated. Hopefully that refactoring didn't make it into the suggestions of the IntelliJ IDEA plug-in.
The real reason as usual, which is never stated. The older tech leader has left, the new guy doesn't want to deal with something he is unfamiliar with. 
The combination of junior AND remote seems like a deal-breaker to me, or more obviously factors that are massively hindering your hit rate. Consider changing one or more of these.
We're hiring Scala developers at the moment, but we are not offering permanent remote working (weekly days in the office required), as our domain quite complex for new comers. Jobs are out there, just keep looking, but as mentioned before be flexible to relocate, as a remote confident Scala dev is one thing, but a remote junior Scala dev may just be a step to far for most employers.
Thank you, Taonas. Actually, I considering relocation, but I think decisions like this should be done at least after several weeks of remote work (especially if it is relocation to another country).
I really think you should've looked into [rapture.io](http://rapture.io) You need to depend on libraries *rapture-io* and *rapture.fs* If you use sbt, your *build.sbt* file looks like scalaVersion := "2.11.6" name := "rapture-copy" libraryDependencies ++= Seq( "com.propensive" %% "rapture-io" % "0.10.0", "com.propensive" %% "rapture-fs" % "0.10.0" ) Then you import all the magic and copying becomes as simple as it can get import rapture._ import core._ import io._ import fs._ val src = File / "put" / "your" / "path" / "to" / "source" / "file.here" val dst = File / "put" / "your" / "path" / "to" / "dest" / "file.here" // et voila! src &gt; dst 
Brighton, which is on the south coast of the UK
There is a bit of a catch-22 here. You don't want to work on site for a company before you've worked remotely for them first, and an employer will not want you to work remotely until they've seen you working on site first. To be frank, since you describe yourself as junior, I think you're on the losing end of that discussion: you should seriously consider relocating to wherever a company will offer you a job in order to build some experience. On top of that, Scala jobs are pretty hard to find overall, but good luck to you. 
Apache commons-io FileUtils is what you're after. The VM isn't meant to cover even the most common operations, but is structured to facilitate the broadest rage of generic micro-ops. The commons family of libraries usually fill in these gaps pretty well. You should learn them. That said, if you're a newb, you should probably learn stream handling anyway; just the idea of reading a file to a string without knowing the size and structure of the file can be a dangerous weakness in your code if you rely on it too much. I know your files are small now, but they won't always be.
They'd rather use node.js or Python than Scala? Where is the sense in that?
You're possible right on both both problems. But... 1) That's why I'm not claim a middle position, but of course I have solid understanding at least of threads and things related to concurrent programming and about a LOT of other things incorporated in development process. 2) Actually, I write, but it is really different things to write code by yourself for yourself with tasks managed by yourself and with result reviewed by yourself and to work for real-world tasks.
Node.js would be the move to a frontend oriented architecture, something Bloomberg, for example, did recently. As for Python, maybe for server admin, probably has nothing to do with Scala. Java 8 and (ironically enough) Play's Java support are the Scala "killers" here. 
If you don't need JS then yes I'm pretty sure you can do everything with Play and server side templating: https://github.com/playframework/twirl/blob/master/README.md. But if you need anything especially dynamic or interactive you'll likely need JS. You can use ScalaJS for that though and even share code with your play app. 
You can easily use all the goodness of grunt&amp;co with [play-yeoman](https://github.com/tuplejump/play-yeoman) and develop in your favorite frontend tool and ignore server side templating entirely. or not. or mix it. 
Angular is a fine front end, but "easy to learn" is hardly ever used to describe it.
&gt; I'm also curious if it's possible to have Play deliver fully functional HTML to the browser without the need for sophisticated JavaScript. Play templates are made do to this, and are very easy to use : https://www.playframework.com/documentation/2.3.x/ScalaTemplates You can write nice apps with Play templates and add some Js code in this templates, for example with jQuery. On the other had, you can also write simple REST services on your play backend and use a full JS frontend technology like angularJS or Backbone... it only depends of the tools you prefer.
nice post, i'd love to see a similar post on akka-http, since it seems to tbe the way forward instead of using spray, but the documentation is a little sparse.
Looks great, but it's a full framework, isn't it? I mean, it looks like it isn't compatible with Play Framework.
I think you are right about dotc not using abstract classes for traits. This is why it depends on Java 8. I think Martin mentioned it in this talk about binary compatibility: https://youtu.be/TXNs51UII60
videos plz :) Clojure/conj had their talks up hourly... Will we not see scaladays videos for some time because they must first be typechecked?
[Scala.js](http://www.scala-js.org/)
Does this not mean that you could write a compiler that could compile to .NET IL, or even machine code? Having an intermediate language means that you can essentially translate the typed tree to be used in any language, right? From what I understand, the hurdle that stopped the .NET runtime was the difference between java's erased types vs c#'s reified types. Since the typed tree happens before erasure, it should be possible, right? 
pretty sure that's a joke
I hope so, but after reading the rest of the document, I have serious doubts.
Author of the guide here. First, I have to admit that **I am by no means a Scala expert**, despite having used it for a few years and have written some of the largest and most complicated projects in the Scala ecosystem. Second, a lot of the objections you have are exactly the ones we find counterintuitive or easy-to-be-misused (e.g. putting a flatMap in for-comprehension to me is a form of nesting). I guess therein lies the difference :) This guide draws from our experience, and might not apply to your specific needs (especially if you have a very small team of hardcore functional programming lovers). We have found that it is critical for us to employ the simplest concepts. Ethos such as "minimize the loc" isn't the best goal because a single LOC can contain a lot of information in Scala. With regard to "type of engineering team ... cultivate ignorance .. refuse progress", I **respectfully and vehemently disagree**. Here's a subset of our work that has been open sourced: Our team wrote most of the Spark code (from low-level network transports to distributed scheduling to user-facing APIs). We have also built 2 distributed query engines, a distributed streaming data processing engine, a distributed machine learning engine, and a graph computation engine. Each is among the most, if not the most, actively developed/used technologies in its respective category. Among our engineering staff are hardcore engineers (and PhDs) in programming languages, networking, databases, OS, and we interact regularly with the Scala team from EPFL/Typesafe (although we might disagree on specific issues). We have been working extensively with a large community (incidentally one of the largest open source communities), and arrived at this guide the hard way: finding a lot of obstacles and challenges coming from misusing advanced features. Our engineering team is absolutely pushing the boundary of technology. To us, a language is just a tool. We do not feel we need to innovate and "progress" as much there. (OK I lied -- we also built a query optimizer -- possibly the world's first production quality one -- using pattern matching and quasiquotes) 
That was actually a joke. I guess it was not as clear.
Oh BTW - I do want to expand the thought process behind this guide. That will probably generate even more controversy. Look forward to the day when I have more time to do that.
Nice writeup btw!
&gt;As we've seen, the typing rules for polymorphic variants are a lot more complicated than they are for regular variants. This means that heavy use of polymorphic variants can leave you scratching your head trying to figure out why a given piece of code did or didn't compile. It can also lead to absurdly long and hard to decode error messages. Indeed, concision at the value level is often balanced out by more verbosity at the type level. Not sure how this applies to union types in particular. &gt;Polymorphic variants are type-safe, but the typing discipline that they impose is, by dint of its flexibility, less likely to catch bugs in your program. So is being forced to use the nearest common supertype for all the values a function might return, which in the above example is `AnyRef`. So, for that matter, is using exceptions everywhere. Every exception will end up being caught somewhere, sure, but perhaps not where you wanted to catch it. That's why we're having this discussion in the first place. Note that Java's checked exceptions are kinda-sorta equivalent to the union type in the above example. They have their own problems, though… &gt;This isn't a huge effect, but polymorphic variants are somewhat heavier than regular variants, and OCaml can't generate code for matching on polymorphic variants that is quite as efficient as what it generated for regular variants. Shouldn't be much of an issue for union types on the JVM. It'd compile to the same thing as a pattern match on types now.
&gt; def f(…): String|IOException|ParseException That's what def f(...): Try[String] is for
Why do people want scala to run on the CLR at present? Mono sees severe performance loss and the jvm sees high performance on all supported platforms. What's the benefit? Thats an honest question. Not an attack. 
&gt; Unfortunately, current solutions for that are ugly as hell. It's a planned feature, but who knows when it'll actually land. The union type you're referring to isn't disjoint, and is inappropriate for error handling. The disjoint unions that are already available in Scala(either in the standard library or elsewhere) are already perfectly fine for whatever your use case is. 
[There's a lot wrong with using return](http://tpolecat.github.io/2014/05/09/return.html)
That's a neat library. I may check it out. But wouldn't using implicits still be type safe if you have the implicit declarations in the DTO and persistence entity companion objects which would only imported in the controllers and persistence modules? 
Yes, implicits would work too - you would just be forced to declare the types explicitly in some places. One thing I like about macros is if you add (or remove) a field from one layer - you don't have to manually go remove it from your other models. Sure, in either case, the compiler would force you to handle the new field but its less code-editing with macros.
To me it's mostly a novelty thing.. I only really write server-side code so it'd just be cool to see. But also to be able to have a language that can do wpf applications that's not C#, but have all the .Net libs would be nice for people that have to deal with UI. 
@rxin Thanks for posting the guide, and for being so even-handed in the discussion here. I think it goes in the right direction, and I agree with most of the rules, but not all of them. For instance, I use apply and call-by-name a lot, I curry where it buys me better type inference, and I avoid redundant braces. But I am sure we agree that disagreement on technical issues is natural and healthy. I am sorry about the tone in some of the comments. If there's one thing I cannot stand it is arrogance and the title of this thread certainly reeks of that. 
I found that this guide starts off well, but quickly turns condescending and patronizing. &gt; Use 2-space indentation in general. I'll admit I'm a little opinionated on the tab-vs-space debate(towards the tab side), but I'm not bothered by a space only policy(consistency is better than nothing still). However I believe this decision was made for the wrong reasons, and I'll use this next quotes to support why I think is. &gt; Do NOT use vertical alignment. This is the probably the strangest convention in this document, I have never seen anyone recommend this before, in any language. I can only infer the reason from this: &gt; make the aligned code harder to change in the future. This is isn't really true, and any decently featured text editor can do vertical alignment. It doesn't matter if you're using vim, emacs, intellij, visual studio, sublime, or whatever is the hipster text editor of the month. Though if one assumes you're aren't really comfortable using whatever your editor of choice is, the extra few seconds of time spent aligning manually is only the result of the decision to use spaces instead of tab characters. &gt;They draw attention to the wrong parts of the code Honestly, all have I to say is that this justification is complete bullshit. &gt; If a class is long and has many methods, group them logically into different sections, and use comment headers to organize them. You should consider using a header editors can fold on here. &gt; Do NOT use infix notation for methods that aren't symbolic methods (i.e. operator overloading). This is bad advice, you're directly contradicting the [official style guide](http://docs.scala-lang.org/style/method-invocation.html#arity1), if anything turn on the compiler's warning for postfix notation and require that `scala.language.postfix` be imported if having both methods of invocation are problematic. &gt; apply Method &gt; These methods tend to make the code less readable, especially for people less familiar with Scala. A strawman argument. &gt; It is also harder for IDEs (or grep) to trace. This is false. Any IDE that supports scala knows how to dereference `apply`. &gt; In the worst case, it can also affect correctness of the code in surprising ways, as demonstrated in Parentheses. This only demonstrates that no-arg `apply` methods are degenerate, which no one will disagree to, since you can't apply nothing to a value. &gt; It is however ok to define them in companion objects as factory methods. This exception is arbitrary. &gt; Call by Name &gt; The main problem with call-by-name is that the caller cannot differentiate between call-by-name and call-by-value, and thus cannot know for sure whether the expression will be executed or not (or maybe worse, multiple times). That's not a problem with call-by-name, that's the exact intent of it. &gt; Symbolic Methods &gt; Under no other circumstances should they be used. This is rather heavy-handed, symbolic methods aren't harder to understand just because you say they are. For example you claim that: &gt;// self-evident what is going on &gt;channel.send(msg) &gt;stream1.join(stream2) But this isn't true, you have to know about the types you're working with for anything to be self evident. Is the above `stream1` performing a monadic join? Is `channel` sending a message, or are you sending a message to `channe`l. Sometimes a `join` is called `bind` instead, when naming methods should which one should you choose? What if there's also a `bind` method? Is `join` something specific to streams then? The only thing the words `join` and `send` add is a English language word to read aloud. &gt; Implicits This section isn't very well written, it conflates several different kinds of implicits, ie, implicit versions, implicit parameters, type level computation, etc. &gt; Implicits have very complicated resolution rules and make the code base extremely difficult to understand. The rules aren't very complicated at all, and are described with two paragraphs and 5 bullet points in [Section 7.2](http://www.scala-lang.org/docu/files/ScalaReference.pdf) in the SLS. &gt; Do NOT use Try in APIs, i.e. do NOT return Try in any methods.Prefer explicitly throwing exceptions for abnormal execution and Java style try/catch for exception handling. This is the exact opposite of what you should be recommending. Throwing unchecked exceptions(Scala has no checked exceptions you can even try to rely on those) should be vehemently discouraged(in Java, or Scala) and you should be returning failure cases as values via some sort of disjoint union. You don't have to use scala.util.Try, but you should use something else besides throwing exceptions. &gt;Monadic Chaining Plenty of others have already done a good job on commenting on why this section is completely dishonest. &gt; Scala Collection Library &gt; An especially bad offender of this is Seq#size() being O(n) in some cases. Seq#size is always O(n) if the implementation is a scala.immutable.List, near constant if it's a Vector. You should always choose the right collection for the task, and this is true even in Java collections. &gt; Java Features Missing from Scala &gt;Static fields &gt;Static inner classes This is untrue. cat &lt;&lt;'EOF' &gt; test.scala object Test { val ACONSTANT = "abc" class INNER_CLASS } EOF $scalac test.scala $javap Test.class Compiled from "test.scala" public final class Test { public static java.lang.String ACONSTANT(); } $javap -v Test.class ... InnerClasses: public static #21= #20 of #2; //INNER_CLASS=class Test$INNER_CLASS of class Test ... &gt; Do NOT use implicits, for a class or function. This includes ClassTag, TypeTag. This is dishonest, implicits that don't require some sort of type level computation can be used from Java. They're just another parameter on the function. &gt; Unfortunately, there is no way to define a JVM static field in Scala. Create a Java file to define that. This is false, any methods on a top level object will be static. If you need to use an object as a value from Java I often add a method that looks like this: object A { def instance = this } //Can be referenced from Java with this: A aValue = A.instance(); EDIT: I would like to clarify that despite all my criticisms, I find more fault with the reasoning behind many of the style choices, than the style choices themselves. Only a few of the conventions in the link would leave to more difficult to read code.
Ok perhaps I should work on my tone, but how can you say this reeks of arrogance but when his style guide mandates that the best way of writing code is his very peculiar style, that's just good intentions? He's allowed to have a *very* opinionated guide on 'good' scala style, while i'm not? 
Enjoy the short-sighted hypocrisy that makes Scala.
The Resilient Distributed Dataset abstraction is fantastic. The work that the AMP Lab at Berkeley did to get this abstraction into code is also fantastic (remember they were the ones who made Spark). The stewardship of Spark under Databricks...is quite depressing.
Why are you so insistent that the main use of implicits is to get a ClassTag? You've repeated that multiple times. 
Your response to him calling out your ban on implicits only said &gt; A good Java API should not ask the caller to manually construct a ClassTag or TypeTag.
Haha thanks. It is fun to do this once in a while. People in general are actually very encouraging and nice.
Oh I think you might have misunderstood his point then. His point had nothing to do with ClassTags and everything to do with implicit parameters in general. Implicit parameters in general are usable from Java. 
The language change is the ability for functions parameter to be implicit; right now this is a property of method parameters. The result to me looks like a very complicated way to implement the Reader monad. I hope I am missing something.
One other thing w.r.t. implicit resolution. I was told that scalac does not implement the full implicit resolution defined in the language spec, because of the complexity. I can't find much about this online. I will ask the scala team about it.
Ok I'm going to bed. Have fun here.
I think the problem was simply that there were too little resources and interest to maintain the .NET back-end. A preliminary version did exist at some point, so the reified types were most likely not the blocker. I guess with the new two-stage compiler model writing new back-ends becomes easier, but I doubt that overall it makes it straight forward to write a .NET back-end. The original two problems, resources and interest, don't go away. I vaguely remember having heard the word "LLVM" again recently. That might be a more interesting option to recover.
&gt; I have to admit that you are much more intelligent than I am, as I find a lot of the stuff you deemed simple pretty complicated (e.g. implicit resolution). I don't believe this to be true, self depreciation doesn't solve problems or aid in understanding. &gt; Vertical alignment does mean you might have to change the whole block even though the original scope is a single line -- this will make it harder to do code reviews. Multiple books suggested this, and it matches our experience. It only makes diffs more verbose and difficult read, if your only method viewing a diff is inline. This is a non-issue if viewing diffs side-by-side. &gt; I'm well aware that this differs from the Scala style guide. I don't think there is anything wrong with that. That particular convention was lacking justification, if there any you would like to add to why you would choose to against it? &gt; I am not sure what you mean by "exact intent". Are you saying "call-by-time" is exactly intended to confuse the caller? It does exactly what it's supposed to do, calls expression by thier name, instead of by their value, or by reference. If you have the expression `x +=1`. Then assign that expression the name `xPlusOne`. Anywhere you use the the name `xPlusOne` replaces `xPlusOne` with the expression `x += 1`, instead of the value of `x += 1`. So the this example: val x = 7 def xPlusOne = x += 1 def doBeforeAndAfter(f: =&gt; Int)(beforeAndAfter: =&gt; Int): Int = { beforeAndAfter f beforeAndAfter } doBeforeAndAfter(x +=2)(xPlusOne) With call by name you just substitute the expression and the call to `doBeforeAndAfter` becomes: val x = 7 { x += 1 x += 2 x += 1 } I'm not sure if giving yet another example of call-by-name parameter helps, but having expressions as values, not just functions is a pretty important feature. &gt; If you truly think "&gt;&gt;=" is as clear as "join", and your brain is wired this way, then good for you! No the point isn't that they're both clear, they're both meaningless without context. And that the ambiguity of English language can lead you to make assumptions about what a method does. Once you've read the documentation of a dsl/library/method, then the difference is much smaller/near moot. The English method can easily be read aloud, the symbolic method is much less likely to contain difficult to spot typos. The English language methods can get confusing when too many synonyms are used. The US keyboard doesn't have many symbols on it. For example, it'd be nice to use Σ instead of sum, series, aggregate, or integral , but most keyboards don't have a Σ key. &gt;I'm all for a more explicit return type that contains the possible exception and the result for the normal case. The problem with Try itself is: &gt;A large API surface, i.e. many different ways of doing the same thing, and thus increasing the cognitive burden on code understanding. &gt;The error case in Try actually doesn't help you much with type information, since it is just a Throwable. So it seems instead of exceptions, you should have an Either type you do like and recommend it in the style guide. &gt; There are a lot of collections that are not List nor Vector. Exactly, and you should use the correct one. The point is that `Seq` is abstract. Just like how `java.util.List#size` can be `O(n)` if you use `java.util.LinkedList`. &gt; A good Java API should not ask the caller to manually construct a ClassTag or TypeTag. I don't disagree, ClassTag and TypeTag are example of type which require a type level computation to provide. But if you had: def run[T](task: Runnable[T])(implicit execututor: Executor): T = ... from Java calling this method is just: Runnable&lt;String&gt; myRunnable = ... Exectutor myExecutor = ThreadPoolExecutor.create(...) String result = Myclass.run(myRunnable,myExecutor) Implicit parameter lists don't get lifted to `scala.FunctionX` like curried ones do.
Frankly, I too am confused by the choice to extend the scope of a feature (implicits) which has proven to be one of the most confusing and dangerous (meaning that you need to use it with caution to avoid a mess) of the language. If implicit function types will be implemented to handle effects, I hope the final result will be easy to understand and to use correctly, otherwise it would do more damage than good.
Although I agree that the tone of the answers and title are inadequate, I find that the arrogance is more on the spark side, both in the posts here and in the style guide. I speculate that it is because of that spark-arrogance that the title and posts here are more emotional than they should be.
You are allowed. But are you managing a team of developers and contributors? It isn't arrogance to expect contributors to a large project, or members of your team, to follow a style guide. Get off your high horse. 
naiv way for the map part: val myMap = Map("Susan" -&gt; 23) val susanOption = myMap.get("Susan") val theNumber = susanOption.getOrElse(0) "nicer" way val myMap = Map("Susan" -&gt; 23) myMap.get("Susan") map { theNumber =&gt; // do sth with the number } Interesting Part: "Susan" -&gt; 23 is equivalent to ("Susan", 23). Maps are Lists of Tuple2
I don't fully understand the slides &amp; I'm not an expert on monads or effect systems. Personally, I would love it if something like this could work: def f(i: Int) : Int throws Ex = ??? def g(i: Int) : NetworkIO[Int] = ??? val xs : List[Int] val ys : (NetworkIO &amp; CanThrow[Ex])[List[Int]] = xs.map(f).map(g) Do you think something like this could work with dotty with it's effect system?
How about this? (1) This is much faster than the reader monad, (2) you can use all of Scala under an implicit, are not restricted to monadic expressions. Don't people find monadic style constraining, no matter whether you use for expressions or flatMaps? For me this is a bit like going back to 3-address code where every intermediate result has to be bound. 
`:+` doesn't modify `lol`; it returns a new list, which /u/blarg_industries evaluates and prints in the repl, but which you throw away.
/u/rxin: Can I ask, why do you use Scala? Many of these rules imply that you prefer to use Scala in a way that's more like Java (guarding ifs, throwing exceptions instead of Try, monads/flatMap, return statements, no recursion, no implicits, no currying). Why not just use Java?
I just realized that I screwed up this title badly by writing "type inference" instead of "implicit conversion". I might have to repost it. 
Map[A,B] can be thought of as Seq[ Tuple2[ A, B ] ], so e.g. myMap.map( _._2 ) for all the "second elements" 
To whoever deleted it, deletion is denial of stupidity. Leaving it their is acceptance, and also others will know what's wrong so everyone is better off. 
Come on, these are systems people, not PL people...They were probably just looking for a better Java, the functional programming sips in much more slowly. Systems people are pretty pragmatic about PL (just look at...Go). 
Keep exploring! but don't forget to write a 3rd edition to your book when you are done :) there are some people here (me included) who write scala professionally and really want to move to the next level. This means we need not just great documentation (kudos on the improvements) We need *online* based *advanced* training (I'm in Atlanta and all of your courses are NY / London / SF...). I'm representing the people who are already sold on Scala and want to learn it more deeply, but we don't have a book to buy or an online course to take (I took both of your courses in Coursera, they are great, but WE WANT MORE!). I want to really understand better both the theory and the fine implementation details of the language, I want to be part of the SIP, I want to be able to do pull requests on the language and ecosystem, I want to be involved but there are so many smart people involved I'm too scared to even make an opinion. The only way for me to be there is either time to explore on my own (which I don't have) or learning from those who did. (p.s. typesafe subscription is too expensive for me so this is not a good option). Please do something for people who already love scala, know it pretty well and use it in their day job, but want to move to the next level, you'll get tons of contributions both to the existing stack and to the entire ecosystem. Thanks for creating the most fun language I ever worked with, I'm so lucky I use it in my day job :)
ITT: guy who wrote the most popular Scala project in github gets support by the person who invented Scala, and still gets called "get off your high horse" and "willful ignorance". Yes, this is Reddit.
Some good questions. The pattern matching does in fact check the type at runtime, which is also why you cannot match generic type parameters. Since generic type parameters are erased at compile-time, the pattern matching does not have access to the type and therefore cannot match the type parameter at runtime. Pattern matching against types in Scala is generally more ok because it is typically safer than in Java. The main kind of pattern matching that people use in Scala is where you have a number of case objects/classes that extend a sealed trait and you want to pattern match a value of the traits type on the different cases that extend this trait. For example if you are writing an abstract syntax tree for representing expressions in a simple calculator application: sealed trait Expression case class Inte(value: Int) extends Expression case class Variable(name: String) extends Expression case class Plus(expr1: Expression, expr2: Expression) extends Expression Since the trait is sealed, the number of cases is strictly limited at compile-time, and the compiler knows the specific cases. Since the compiler knows these cases, it can check at compile-time that you have matched all cases, and can give a warning if a pattern match has not been covered. This means that if you for instance add another case object or class that extends your sealed trait, the compiler will give you a warning in those places where the new case has not been handled. This cannot be done in Java, since Java does not support sealing classes and interfaces. Without sealing, the interfaces may be extended later on, and the compiler can thus not guarantee that all cases have been matched in the pattern matching. That said, pattern matching can be (ab)used in the same way as in Java, where you for instance match an object of type `Any` against it being an integer, string, boolean, BufferedReader, etc., and this kind of pattern matching is generally considered bad. **TL; DR:** Pattern matching can be used in a safe and non-fragile in Scala, which is why it is considered ok compared to using `instanceof` and type casts in Java.
http://stackoverflow.com/questions/754166/how-is-pattern-matching-in-scala-implemented-at-the-bytecode-level
I don't think anyone belittled Spark the project or their code base. There are plenty of Scala projects on github of varying code styles and quality. I know when I put my projects on github, I'm very eager to hear feedback from the community and to continually learn about the language and programming techniques. I am proud to consider myself a perpetual student of programming. However, the Spark team seemed (in this instance) to do the opposite. The style guide does come off condescending with it's insistence that 'maintainable' code must follow their definition of 'simplicity'. They do make numerous errors and misunderstandings of the Scala language. They did not seek out the community to help them or solicit feedback, they did the opposite. So while I don't agree with the general demeanor of the OP, I understand the sentiment completely. 
What didn't you like about Monad Transformers? I too found them confusing at first, but I *think* it was more the lack of good examples than the fact that they're a 'complicated' concept. Sometimes once you learn something it's hard to remember how challenging it was, so it's possible I'm just forgetting the extent of my frustrations with learning them though :) 
The run-time effect of `case` matching against types is equivalent to a series of Java `instanceof`s. The Scala compiler does add some extra safety checks for pattern matches, as /u/notenoughstuff explains, but those have no run-time effect; they exist only at compile time.
By doing that they are going to miss out on a lot of great Scala libraries. Most of the cutting edge innovative (and risky) libraries are in Scala. Some are available from Java, but all the risk takers are in Scala. If I were to list them all out you would be amazed, like... just pick one, Apache Spark.
It's really not that easy, they may be able to optimize pattern matching over case classes with sealed hierarchies better but beyond that, there isn't much that you can do with open hierarchies.
Definitely, that's the best way here by far. I was just pointing out a different way to write a function that takes a tuple, and allows naming the parts of the tuple. Sometimes there isn't a direct way to do that, like there is with .values: seqOfTuples.sortBy { case (foo, bar) =&gt; bar } etc. 
Wow, that sure looks sleek. Seems like a perfect fit for event-driven and cqrs type applications. I like how Commands can be explicitly represented. Getting rid of the sender, imo, is a good thing - it sure looks "magical" to the receiver --- especially if the message comes from router etc. Sorry, I've not tried to build it yet, it looks like it's been added after last release, so I wouldn't be surprised if it doesn't even build. Maybe post an issue on github? https://github.com/akka/akka/issues?q=is%3Aopen+is%3Aissue+label%3At%3Atyped
This Odorski is least bothered about usability of Scala or Eclipse, so please do not ever again post anything by this callous Genius.
I just cloned the repo and was able to use it in the REPL. Start sbt from the root and run `akka-typed-experimental/console` You could also probably run `publishLocal` from the root and try it out in a test project. I didn't try that though
You don't need class scoped private fields. Never. I have never ever needed anything except `private[this]` (which I write `private` because it is by far the _most common_ case) and `protected` (so that you can access stuff from implementation mixin traits). It's a clear case of making things more complex than needed.
 git clone https://github.com/jsuereth/streamerz.git cd streamerz sbt "examples/runMain examples.AsciiWebcam" # win!
Thank you! Now I can write something like: val program = get[Stack] &gt;&gt;= {st =&gt; if (st == List(1, 2, 3)) put(List(8, 3, 1)) else put(List(9, 2, 1))} But I'm curious why this works. When is the `implicit def` being used by some other functions(which I've no idea about)? Could you please give me a brief explanation, or point me to the right places to look into? Also, I still cannot use the for-yield syntax. When I try to write something like: s &lt;- get[Stack] The compiler will always complain "value foreach is not a member of State[Stack, Stack]". I'm not sure what that means. 
Your State type must have a flatMap / map method in order to use for-yield. Although scalaz implicit may give you those for free? You're missing foreach, which makes me think you aren't using for-yield but instead a regular for loop. Can you give the broader context? Your implicit is being used here: https://github.com/scalaz/scalaz/blob/v7.1.0-M3/core/src/main/scala/scalaz/syntax/BindSyntax.scala#L5 Monad extends Bind, so you have an implicit Bind in scope. So this allows the implicit conversion that gives you the ```&gt;&gt;=``` operator.
I wonder. I made [this way](https://github.com/makoConstruct/RequestResponseActor) of avoiding race conditions when mutating actor state from an ask closure(IE, during the foreach/map methods of the Future asking returns, although the syntax for asking in my way is `query(requestResponseActor, message)` ), does akka-typed do that? It looks like they probably at least had the opportunity to clear out whatever was holding them back before.
I took a screencast of my talk and uploaded it here https://vimeo.com/122611959 The typesafe people will eventually have a full video including me waving my hands, and the Q&amp;A (which I forgot to record) but for now this should satiate the curious
Great question. We still use a lot of Scala features that do not exist in Java. To name a few: - (not a feature per-se) Concise syntax that can be typed in an interactive REPL - Scala REPL itself - Pattern matching - Closures - the collection library is quite nice to use in general - functional transformations (note that we never said no flatMap -- it was only asking to be cautious and don't chain a bunch of flatMaps together) - quasiquotes In particular, the Spark SQL query optimizer is built using many features (most important of which are pattern matching and quasiquotes). We recently wrote a paper about it that will appear in this year's SIGMOD conference. We will post the paper online soon. 
That part was for defining symbolic methods, not using them. If you are using a library that has only symbolic methods defined, then there is really no choice (e.g. Scala's own process builder). 
Thank you very much! I'm excited to put my hands on scala.js and it will be great to see your talk.
Thanks. I've looked into them before. I can't say I fully understand them yet, but I never thought to use them for this. I'll have to give them a look. As for implicit parameter. I use them a lot as a replacement for dependency injection, and appreciate that they don't take control away from my application and put it into the hands of a library like inversion of control. 
I would be happy to help out, give my opinion, and/or talk about the pros and cons of different scala features with any and all of the Spark team. I'm sure I would learn a ton about distributed systems and databases in the meantime. One of the great things about Scala is that it does support different styles and it's fairly seemless to interop between them. If they wanted, they could refactor one small module/jar or write one new module in more canonical Scala style as an experiment. 
Scalaz (6) was notorious for having symbolic methods, but in Scalaz 7 they went with the rule that there must exist a non symoblic method name and symbolic methods are just syntactic sugar. I agree with this. It's too hard to communicate about "Hey rxin what does colon colon colon bang mean?" and it's a pain to Google. If in some cases it makes sense (cons operation...maybe?) then I suppose an additional symbolic is acceptable, but it's one of those things someone should have to justify with a well written comment at the very least. 
Is there really that much boilerplate in slick though? I haven't found there to be very much that I would reach for an *additional* library. Can you explain what you mean by direct-embedding? 
really? almost all this line is boilerplate def website = column[String]("website") why I need define my column name "obligatory" when slick could read the name of my method and assign it to my column (with macros it must be possible) even better, it's more natural write case class Blah(name:String) to need define your columns as methods.. why I need define a method * where generally speaking, this include all the columns, it's all about convention over configuration and I think than it's pretty clear checking what those macros generate and comparing what you need type and the resulting code https://github.com/ebiznext/slick-macros/wiki/2.-Quick-User-guide notice: this is not a slick criticism, I like slick although I don't consider it clean and I feel than it has so much innecesary boilerplate, principally when you considers and care "convention over configuration"...
is slick the one that wont let me run on oracle or mssql unless i inject payment? 
If somebody made slick models defined the way squeryl models are, I'd use slick for everything. Models to not be included in * would have an @transient annotation, and whenever the field name doesn't match the column name you just use an @column("colname") annotation. Your classes end up looking like: case class User(id: Int, @Column("user_name") userName: String, password: String, ... Etc;)
How is this the top story on the sub? There's no content in it.
Your talk was so entertaining. Definitely a highlight of Scala Days!
Direct Embedding: http://slick.typesafe.com/doc/1.0.0/direct-embedding.html
It's not out yet though, so we'll have to wait and see what kind of support they give it and how it will perform. I'd be happy if it's good, but im not too optimistic about it yet. 
hey! Do you have an example for this?
The only problem with that, and why I haven't made up my mind yet and just done that, is because mp3 and mp4 have fields in common that are not in flac/ogg. That would cause me to duplicate code between mp3 and mp4 or make an unpleasing and somewhat harder to maintain extension from mp4 to mp3 which doesn't feel right since mp3 isn't an mp4. but this is a notoriously messy situation which many programs sidestep by only supporting a limited number of common fields. 
Imo having irrelevant fields is worse than some duplicated logic. But I think you can do this without either.
Not only that, but using a string to indicate Senior and Junior is probably not the best idea. This is something a sealed case class could have done pretty well.
Glad I could help! Hope it works out for you. Post here or ping me if you have more questions.
@runT1ME - happy to discuss. Shoot me an email at rxin at databricks.com. 
While far from popular, [Scala.js](http://www.scala-js.org/) is at least worth knowing about. It is to Scala what GWT is to Java; it compiles Scala code to JavaScript, so you can write everything in Scala. It provides means for using JavaScript libraries. For examples or to play around, see http://www.scala-js-fiddle.com/ 
I guess the issue is that somehow people must be paid
 Thanks for the interesting module [@japgolly](https://www.reddit.com/user/japgolly)!
Using scala.js does not make you to give up native js. You can write bindings or use [existing ones](https://github.com/greencatsoft/scalajs-angular).
Its really great, I did a full project in ScalaJS, the main point is that my thinking is already in the Scala language. So when I want to code a function, I can go ahead and write it while ignoring that we are in the browser. I wrote a ScalaJS program which works on AtomShell https://github.com/atom/atom-shell and in the browser, so it was desktop app and browser app and the same time. Also it has bindings to other Javascript libraries and you can easily create your own method stubs for javascript libraries or import from a typescript definition. You can do mutable state if you feel your immutable things are too slow in browser but in general I did everything immutable and never noticed it go slow. I have not used Widok yet, but it looks like a nice solution for UI in web page https://widok.github.io/ I can only say after 15 years of programming commercially, this is where I want to be in Scala/ScalaJS as I can think in Scala, I have faith in the functions and I get to deploy on client or server. I also want to say, all the real innovation occurs in the new new "things", languages or functional programming, Scala being one of them, Scala has a huge number of libraries to choose from for almost everything you can think of, I've been building a list but it takes weeks to compile, I'll eventually put it up. 
I do both a lot of front-end and back-end coding, so have been watching and using Scala.JS a bunch. Having type-safe JavaScript is very useful, and I like the Scala type system a lot more than TypeScript or Flow. However, there is one thing that I've noticed no one really talk about, and I've already had to deal with it when doing a larger project in Three.js: If you are using Scala.js, then you are targeting the DOM. This means you have to be aware of [all of the shit the DOM brings](http://programmers.stackexchange.com/questions/147451/whats-so-bad-about-the-dom). This is obviously not the fault of Scala.js, but it's something you should at least consider: the main reason why people hate front-end dev is the DOM and cross-browser inconsistencies. If you're targeting the browser, then now it's part of your life. 
What about targeting canvas? I've heard about Pinterest (or maybe Flipboard) using ReactJS to target canvas? That should be possible in ScalaJS too, right?
I used to write a lot of Eclipse plugins (written in Java) for model-based engineering projects. During last year, I was lucky enough to do some projects in Scala, and literally fell in love with it (I can't stop talking about it). Anyway, when I learnt about ScalaJS, I figured it was time for me to get my hands dirty and write some web front-end code. A couple weaks ago, I started coding some stuff for fun. I have a lot to learn, and I often hurt my head against whatever nonsense brought from web technologies (the dom is a huge steaming pile of crap). I also started reading some javascript to translate some behavior from it to ScalaJS. There are things you can't write façades for (or I haven't figured how to) : some libraries use dynamic extension systems, which seems to be a relatively elegant thing to do in javascript, but won't work in ScalaJS if you wan't static typing (however, you can still do everything dynamically if you want to). But I'm pretty happy with how it how works, how the ecosystem seem to evolve rapidly and how rapidly I manage to get some small things done. So my point on view on ScalaJS is this : it made me want to do some front-end code on my own, which is something I would probably never have done. PS : apparently there is a [Scala-JS-actors](https://github.com/sjrd/scala-js-actors) project which interops with Akka actors running on the JVM. The code is not up to date with the last versions of ScalaJS, but it got me pretty excited, and it has some neat working examples ! 
If you don't like it, use an open source database. Or don't use slick. 
&gt; some libraries use dynamic extension systems, which seems to be a relatively elegant thing to do in javascript, but won't work in ScalaJS if you wan't static typing (however, you can still do everything dynamically if you want to) You can write a facade for that using implicit extension-methods; inside the extension method, you do a case to `js.Dynamic` and call the thing you want and cast back. Not quite as elegant as the "default" way of doing facades, but no less safe in the grand scheme of things ^_^ If the pattern comes up a lot the cast-call-cast can be lifted into a function to re-use if necessary. (of course, this doesn't change the fact that since the extension is *dynamic*, calling the extension-facade too early before the extension gets monkey patched will `undefined is not a function`)
Take a look at https://github.com/lihaoyi/workbench-example-app/tree/autowire
Thanks for the heads up, I'll give it a try ! 
It seems like what you want is a [multiple project structure](http://www.scala-sbt.org/0.13.5/docs/Getting-Started/Multi-Project.html). Edit: changed link to the latest version. Thanks /u/predef for the warning. 
This is a very interesting example of an internal DSL in Scala. Thanks for sharing this.
I took came from Ruby and believe wholeheartedly in BDD, however I went to Ruby from Java, so I have a bit of an unfair advantage. For me discovering scala was like having a language that ran on the JVM and gave me all the libraries I could ever want, but had even more power than Ruby. :) Anyways, Scalatest is my favorite, you can use a format very similar to how [rspec behaves](http://scalatest.org/user_guide/selecting_a_style). See the FunSpec trait. SBT is a bit more complicated... I haven't fully grasped that one yet. It's not too difficult to do simple things, and the newer versions of SBT are far easier to grok than the older ones, so use the latest version. CLI Apps would work the same way they do for java apps. You'd need a JVM installed, and you can build a jar a certain way, probably with the [command line application tutorial](http://www.scala-sbt.org/0.13/docs/Command-Line-Applications.html). Then you'd publish it to maven central (for open source stuff), or put the jar file up to be downloaded somewhere. Unfortunately, it's not quite as easy to put stuff up on maven central as it is to publish gems (IIRC). [This guide for SBT](http://www.scala-sbt.org/0.13/docs/Using-Sonatype.html) and [info from Sonatype](http://blog.sonatype.com/2011/10/publishing-your-artifacts-to-the-central-repository/) are probably good places to start.
hey there - fellow .rb-ist here 1) check out [giter8](https://github.com/n8han/giter8). I've used it to set up a scalaxb project, and it worked flawlessly. There's templates for many framework ecosystems, and they look pretty easy to fudge into something like thor's generator capabilities. 2) [scalatest](http://scalatest.org/) is pretty close to rspec, and runs in a guard-like file monitoring mode with "sbt ~test". This was the thing that got me into the ruby-style workflow the quickest - IDE, terminal #1 with 'sbt ~test' and terminal #2 with 'sbt console'. I still haven't found a repl environment as nice as pry (especially with runtime integration), but I haven't been looking for very long. 3) haven't tried it, but [conscript](https://github.com/n8han/conscript#readme) seems to be pretty close.
np :) Interestingly, I created all the data structures and logic first, and then created a separate DSL module for nice usage (as opposed to adding bits of dsl all over the place to each data structure). Nearly all the DSL is separate and in one place. It was very interesting to separate function and usage like that.
This blog post might help: http://underscore.io/blog/posts/2014/09/03/enumerations.html
Just a heads up, as someone who used to be passionate about Scala: the problems with the SBT plugin don't end. Sometimes they get better, sometimes they get worse. I gave up when build.sbt and build.scala support remained broken for weeks.
Can you paste the whole build file?
What did you give up to go to?
The point of object-oriented programming is to pair data with operations on that data. The method should be put into a trait and then mixed in to the classes which need it.
Does "StridentStandard" have source files? I don't believe it should if you define it as an _aggregate_. An aggregate is strictly to be able to execute commands on a number of sub-projects together, e.g. `compile`. If it does have sources, you should probably make it use `core` as base directory instead of root, and use `dependsOn` instead of `aggregate`.
Nope--the point of OOP is to _hide_ the actual data and just expose messages that you can send to it. The trait-and-mixin technique does exactly that, because client code simply works in terms of the methods exposed in the traits.
I think that is the point of encapsulation, which indeed is part of OOP. Lest we split any hairs, I won't discuss the point further. Either way I think we agree that trait inheritance is what OP wants.
https://youtrack.jetbrains.com/issue/SCL-8278
I solved the issue by restructuring my Build.scala file considerably, based one used by Spray... simplified massively.
&gt; Is there anywhere a full project including imports (e.g. for the JSON string interpolation?) There are some examples [here](https://github.com/scalaz/scalaz-stream/tree/release/0.7a/src/test/scala/scalaz/stream/examples). I haven't looked for JSON stuff, though. &gt; Do I get it correctly, that the only way to support multiple sinks is using toppics? And then when one sink is too slow, either the queue will fill up all memory or the topic will drop notifications? No. There's a handy method, [`observe`](https://github.com/scalaz/scalaz-stream/blob/release/0.7a/src/main/scala/scalaz/stream/Process.scala#L990), on `Process`. `observe` sends the values in the stream to a sink, but also keeps sending them downstream. So you can use `observe` as many times as you like to let as many sinks as you like observe a stream. Regarding slow sinks, please read the [backpressure](https://gist.github.com/djspiewak/d93a9c4983f63721c41c#backpressure) section again. Because scalaz-stream has pull-based semantics, your slow sink will just pull from the stream slowly. But by using `observe`, nothing downstream is affected by this: `observe` is echoing the values on down the stream, and downstream "pullers" can pull at whatever rate they're able. Hope this helps! **Update:** I looked at the whole gist again, and as far as I can tell, Daniel is just using a Sink that stores JSON as an example, so just pick any of the myriad Scala JSON libraries that support string interpolation. [Rapture JSON](https://github.com/propensive/rapture-json) is a very nice framework that I've used to good effect.
Thanks for your informative response! Regarding the following part: &gt; [...] scalaz-stream has pull-based semantics, your slow sink will just pull from the stream slowly. But by using observe, nothing downstream is affected by this: observe is echoing the values on down the stream, and downstream "pullers" can pull at whatever rate they're able. So in other words: Using `observe` no messages are lost, as long as their is enough memory to buffer them. But their is no upper limit about the amount of memory needed for the buffering. `observe` will not add to back-pressure. Did I get this correctly? 
You're welcome! &gt; So in other words: Using observe no messages are lost, as long as their is enough memory to buffer them. But their is no upper limit about the amount of memory needed for the buffering. observe will not add to back-pressure. &gt; Did I get this correctly? Not quite, I think, but it depends a bit on your topology. Because scalaz-stream is pull-based, there's no buffering going on unless you ask for it. The upshot is that your slowest sink will limit the throughput of the whole system, which is basically what backpressure means. This is assuming that your sources are all constructing streams directly, however. [This](https://gist.github.com/pchiusano/8087426) gist from Paul Chiusano talks about some possibly unavoidable other cases, though, where you don't control some async, callback-y API that nevertheless needs to be the source for a stream. This is really where something like `Queue` comes in handy.
For me it's working try to reimport project by sbt 
Is this play? Run on a Play app stopped working.. there is a bug in the bug tracker for it but no fix and no hint of in progress. Sad days.
I don't know anything about Slick, but I did pop open the [source to AbstractTable](https://github.com/slick/slick/blob/master/slick/src/main/scala/slick/lifted/AbstractTable.scala): abstract class AbstractTable[T](val tableTag: Tag, val schemaName: Option[String], val tableName: String) extends Rep[T] { type TableElementType } It looks like AbstractTable has no idea how TableElementType and T relate. On the other hand, Table (which lives in [RelationalProfile.scala](https://github.com/slick/slick/blob/63b5e75aca93efa8a5415aa49f7395959d405d4f/slick/src/main/scala/slick/profile/RelationalProfile.scala#L180)) does seem to know: abstract class Table[T](_tableTag: Tag, _schemaName: Option[String], _tableName: String) extends AbstractTable[T](_tableTag, _schemaName, _tableName) { table =&gt; final type TableElementType = T } I don't know why this is defined here and not in AbstractTable, but I'm sure there are good reasons.
I had a very similar problem - it failed to update the scala plugin each time it tried until I manually installed it from a file. Now seeing a weird error ' Cannot start process, the working directory /Applications/IntelliJ IDEA 14.app/Contents/bin does not exist' every time I try and run a test.
I got it working after removing and reinstalling scala plugin and deleting the old .idea directory and re-importing the project.
Thanks for all the feedback guys, but yes it's a play app, so this guy is the winner! :) guess we will have to wait for an update
Right. I modified my original post after I figured this out. I also figured out a way to continue using the lower level abstraction, and get the results that I wanted. 
Ah, sorry. I must have loaded your post, and then replied to it much later, so I hadn't seen your edit. 
Sure thing! I think there are two confusing things here (not just for you): 1. Pull semantics. People are used to message-oriented middleware that's push-based (JMS, AMQP), and it's hard to dislodge those intuitions. 2. Types enforcing topology to a considerable extent. For example, when you say "multiple sinks are pulling the same source," I don't even know how to compile that: import scalaz.stream._ import scalaz.concurrent.Task val p: Process[Task, Int] = Process(1, 2, 3, 4, 5, 6, 7, 8, 9, 10) val sink1: Sink[Task, Int] = sink.lift(x =&gt; Task(println(s"Sink 1: $x"))) val sink2: Sink[Task, Int] = sink.lift(x =&gt; Task(println(s"Sink 2: $x"))) val p2 = p to sink1 to sink2 The last line doesn't compile: &lt;console&gt;:14: error: type mismatch; found : scalaz.stream.Sink[scalaz.concurrent.Task,Int] (which expands to) scalaz.stream.Process[scalaz.concurrent.Task,Int =&gt; scalaz.concurrent.Task[Unit]] required: scalaz.stream.Sink[?,Unit] (which expands to) scalaz.stream.Process[?,Unit =&gt; ?] val p2 = p to sink1 to sink2 ^ Instead, we have to write something like: val p2 = p observe sink1 to sink2 That compiles. Then: scala&gt; p2.run.run Sink 1: 1 Sink 2: 1 Sink 1: 2 Sink 2: 2 Sink 1: 3 Sink 2: 3 Sink 1: 4 Sink 2: 4 Sink 1: 5 Sink 2: 5 Sink 1: 6 Sink 2: 6 Sink 1: 7 Sink 2: 7 Sink 1: 8 Sink 2: 8 Sink 1: 9 Sink 2: 9 Sink 1: 10 Sink 2: 10 **Update:** `to` means "send to a `Sink` and that's it," so the `to` above means `p2` is only useful for its side-effects. If you want to keep the stream after `sink2`, just change `to` to another `observe`. You might also want to experiment with adding some `Thread.sleep()`s to either or both of the `Sink`s' `Task`s to slow them down, although I hope the use of a static, constant `Process` helps make clear there's no pushing or queueing going on.
If you build with SBT you can have a lot of stuff that will support it.. since most Scala people come from Java, I see a lot of the Java CI servers in use (Bamboo is the cool kid ATM, but Jenkins and Hudson used to see some love)... If Semaphore adds support, seems fine? CI shouldn't be super heavy-weight.
Codeship works well, using specs2 and actually able to run chromedriver+selenium integration tests that work well both on local and Codeship's servers. Only step I take is git push to github, the rest is automated. Current flow local -&gt; github -&gt; codeship -&gt; heroku I should mention this is using Play framework 2.3.6, Scala, Slick and SBT.
There are a few things going on here. Your `def`s are largely equivalent: the first has no argument list, and the second has an *empty* argument list (which can be omitted on invocation). They have the same η-expansion: scala&gt; def x = 5; x _ x: Int res6: () =&gt; Int = &lt;function0&gt; scala&gt; def y() = 5; y _ y: ()Int res7: () =&gt; Int = &lt;function0&gt; In the second example, as @pagoda_5b notes, you are first passing a **function** with an empty arg list, and second passing the argument **by name**. Your third example is not valid scala, although the following is: val x: (=&gt; String) =&gt; String = _ =&gt; "hi" In any case, there are some subtle issues here. I have a couple blog posts which may be helpful in understanding (a) η-expansion and [methods vs functions](http://tpolecat.github.io/2014/06/09/methods-functions.html) and (b) [by-name parameters](http://tpolecat.github.io/2014/06/26/call-by-name.html).
CircleCI detects sbt automatically and it works pretty well. Also supports parallel tests. 
Yo 
On the ensime project https://github.com/ensime/ensime-server we have just switched from https://travis-ci.org/ to http://www.shippable.com/. travis is fine for most projects. They used to have weird cpu limits but with their changes to a docker based system these have been relaxed. By building a docker image with a pre-initialised ivy cache and emacs dependencies we were able to hugely speed up our builds.
Yo(2) (Coming from .net, know nothing atm, really interested in Scala&lt;&gt;Java interop, Play framework, Akka, Jenkins...)
Downside is you are literally paying double to do heroku (once to azon and again to heroku) what you could script yourself in a few days. Fine for tiny projects I suppose.
I doubt it would be accepted as a CS paper, doing maths with a different base is still maths, it is however a good idea.
Semaphore does that as well. It's the other side of the same coin. :)
I really like the added control. Jenkins is very, very flexible. Of course, there are hosted Jenkins solutions too, but I'm a student and I'm not really looking to throw a lot of money at this. It's just for fun and experience. Using a hosted and complete solution just isn't as much fun :)
I'm in the same boat. I have a small play project I would like to put together.
I know it is not totally new. Smalltalk and Lisp have invented almost everything. And I am doing this not to get a science paper, so I can use old ideas. ;-) To bring this kind of programming into a visual structure is new. There have been many attempts before of visual programming systems. The best are indeed RAD systems. I have worked with Delphi a lot, which I really loved. It combines graphical components with small bits of programming. I am trying to bring the same component oriented programming to basic functional and logical programming. Which does seem to work. What I find exciting, is that this same structure seems to work on low-level and high-level functions. So it may be possible to create large applications completely from functional and logical blocks. Thanks for you information, I'll have a look at it. 
Are you planning to implement this with Scala? Will it be open source?
It will be open source.. and free. Somehow I have an income and time to do some stuff. And I don't believe in ideas that you have to pay for. Scala is partially similar, so a part or initial code might be in scala. Now scala.js is available, this is not a bad idea. Since Scala is combining object oriented stuff and functional programming, I think that some of the ideas I am working on might be available in Scala in the future. Because of its simple structure, this system might become a first step for people to learn about functional programming. Scala could be the next step. 
Hacker news threads: [Scalability! But at what COST?](https://news.ycombinator.com/item?id=8901983), [Bigger data; same laptop](https://news.ycombinator.com/item?id=9001618).
1TB still isn't "huge" by Spark etc standards. If it fits on a single computer, it isn't huge. THAT'S the usecase.
Sounds right to me. 
Yup, I have the exact same thing happening. As a bonus, when I create a new SBT project, it seems to freeze when downloading Scala 2.11.6 javadoc files from Maven. Although, truth to be told, I only tried that from work so maybe it's a 'network' issue of sorts, although I can download the exact same .jar file manually without any issues.
We can gloss over the fact that you can likely get better performance out of this software if it's configured by a practiced hand (data locality, rack awareness, structure of the data, access patterns, etc). That being said, there is clearly tons of overhead in it -- you're pointing us to a comparison between memory access and disk/network IO. 100x should be expected, not be a surprising. Looking here for some basic rationale: http://architects.dzone.com/articles/every-programmer-should-know So why use it? Well first off, it's durable and failure tolerant. When you're talking about volumes of data you can't possibly put in a backup this begins to be important. Imagine if a Google lost all of their data.... shut off the lights on your way out. Second, it's scales. Think about that for a moment -- in your example the minute you run out of storage on your host, you are done. They can add machines on the fly and expect to produce a predictable level of performance regardless of how large the data set gets (within limits of the master processes of course). Certainly most companies dont have these problems. But if you do, there is little or no other alternative solution that doesn't entail software and systems engineering black magic. This comparison is ok, but not to show that big-data stuff is bad -- but rather to inform people about the difference between optimizing for low-latency/performance and optimizing for predictable, scalable throughput. They are not the same thing. 
We use spark regularly to process 100s of TBs of data. There's no going back to single machine at that point. Even for much smaller datasets like 1TB, sure you can write a whole program to be efficient, but thats only a tradeoff between dev time to write a program = money vs. the money for a cluster. With spark, a few devs set it up and now our data science team can use it without worrying about what happens under the hood most of the time. They don't know about all the tricks you can use to make a program more time/memory efficient, that is not their job. With spark, they don't have to worry about that. They have a full time job reading papers, building models, picking features, etc. .Designing and coding a very efficient program is a whole another full time job.
&gt;128 cluster Are hardware specifics mentioned anywhere? 128 cores could mean a few nodes on a cray, or a pair of quad socket Xeon boxes connected via infiniband, or a 128 rasberry pi's connected via 100 mbit ethernet.
Be wary that it only works as a sbt plugin and only on posix systems. 
I had the same problem - resolved by blowing away my config/profile folder and starting fresh.
What about making our own chatroom with some simple functions for planning ?
Well you could continue to use Apache Commons from Scala.
Yes, but it's too "Java-ish" and some of it's APIs are redundant
as a musician I love seing scala being used for music! could you explain what exactly is happening here? i get that you're turning a list into a stream that repeats from the list head once the end is reached. still, I'd be thankful for some comments! def loopListToStream[A](list: List[A]) = Stream.iterate((list.head, list.tail)){ case(head, tail) =&gt; if(tail.isEmpty) (list.head, list.tail) else (tail.head, tail.tail) }.map(_._1) def scale(startDegree: Int, startPitch: Int, note: String) = { val scaleStream = Stream.iterate((startDegree, startPitch, note)) { case (degree, pitch, note) =&gt; val noteStreamIndex = noteStream.indexWhere(_ == note) val step = stepsForMinorScale(degree) val nextPitch = { if(step == 1 &amp;&amp; note == "G#") pitch +1 else if (step == 2 &amp;&amp; (note == "G#" || note == "G")) pitch +1 else pitch } (degree+1, nextPitch, noteStream(noteStreamIndex + step)) } scaleStream.map{case (d, h, n) =&gt; n + h} }
If it would not require you to learn sbt then learn how to define your own task than it will appeal more to people who are used to "pip/gem/npm install foo" (in my humble opinion) 
I also think there is a point of view problem here. You try to do Java / python in Scala. I struggled with it for some time too until I understood that you need to change your mindset to work with Scala. There is no better language to do Python than Python. Same with Java. If you want to do Scala, then you need to change your habits too (if you want to profit from it). Usually I try to use Typesafe's libs or Typelevel or any other library that is well supported. Libraries in scala tend to die faster than flies. Activator is quite good to bootstrap a project (even though it is far from perfect and feels a bit amateurish for my taste). scalaz-stream looks awesome and if you have data flow where you need to persist in files I would definitely use it. Embrace Scala and it will reward you with better code and awesome functional skills!
Just started a private subreddit, if you want to join but havent been invited just shoot me a PM ;)
If you think sbt is like gem or npm, then you are mistken about the purpose of sbt. If anything sbt is more like grunt.
Absolutely agree, it's just that sbt takes two roles (build tool and dependency manager, I'm only interested in the latter) I would probably want something new, like for example "spm"
Please publish that list when you complete it! Sounds very interesting...
Well, Scala is a dual citizenship entity, right now it feels to me that the OO ones are second class citizens. All of the frameworks suggested so far (as much as I love them) are more on the functional side than the OO side. (to be mild) e.g. people with Python / Ruby background would be a little overwhelmed when seeing ?|? or |-&gt; etc at the first time. or having to do foldLeft or understand monads just to write to a file. I don't disagree that learning scalaz-stream / shapeless won't enhance your FUNCTIONAL skills. but the OP's point of "getting scala to the masses" - there needs to be a balance towards the OO a little. I don't see any harm in a little simpler API for getting the basic stuff done. and the evidence is that the top comment in this thread from a developer coming from Python / Ruby sums it up nicely. 
Ugh. I love scala, but ffs - everybody and their brother writes a 'DSL' package for their little stupid library, and nothing is even remotely intuitive, but we're supposed to learn a new dsl every time we want to pick up a library. A domain specific language is still supposed to be a LANGUAGE! It's supposed to relay information about a specific domain in a terse yet *comprehensive* way. Why can't you make the API intuitive rather than requiring a cheat sheet to remember what all the different symbols do?! **edit** not you, op. Sorry. Rant over. 
Here you can view it but its still growing and changing. The purpose of the list is so that I can go to the list to work out what libraries I want to use when I have a problem to solve. https://docs.google.com/spreadsheets/d/13DfKuEfICRfJEjgIvXa-o_39cjpdWr8FTR2Cx_v155o/edit?usp=sharing
[Image](http://imgs.xkcd.com/comics/standards.png) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini-USB. Or is it micro-USB? Shit. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 1396 times, representing 2.4072% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cpwhtni)
&gt; In OCaml or F# we could use the 'forward-pipe' operator (|&gt;). We can define a forward-pipe operator in Scala (and people have); but the implementation isn't something you want running in production. Why not ? I'm curious ... this operator can be implemented in an extension value-class and therefore should not produce any overhead. 
You can get the zip/unzip and a lot of other common operations from sbt.io. API: http://www.scala-sbt.org/0.13.0/api/index.html#sbt.IO$ How to include: http://stackoverflow.com/questions/18282402/how-can-i-use-sbt-io 
Mhhh, I think your idea is right, but `override` is the wrong anchor for describing it. Scala has virtual dispatch by default, with `final` as an opt-out. C++ has no virtual dispatch by default, with `virtual` as an opt-in. It might look like it, but `override` in Scala is not equivalent to `virtual` in C++.
For DB and most I/O, I've found that I end up picking the library that's either in Play Framework or used in or provided by Typesafe products. (Reactive-Mongo, Play-Json, HikariCP, et al.) So I've decided to always start there and only grab something else where needed. The Play Framework stuff has a very consistent style, which makes it easier to pick up new bits as you need them.
Great piece - bookmarked, thanks much.
The implementations I've seen involve implicitly wrapping each piped value inside a wrapper object which defines a pipe method. That seems untenable in production. There are probably better ways to do it that I can't think of. I'll probably wipe out that section. EDIT: I was wrong, what you were saying just clicked in my head. I'll update my post. Thanks!!!
How realistic is a simulation of the U.S. Senate if it allows people to actually get things done?
Pattern matching (using the `match` and `case` keywords) is one of the built-in constructs in Scala. Lower-case names inside case patterns are taken as wildcard bindings: They match any value inside the pattern, and can be referred to in the expression of the case part. So, since `nameMaybe` is of type `Option[String]` and [`case class Some[A](x: A)`](http://www.scala-lang.org/api/2.11.5/index.html#scala.Some) has a single member `x: A`, `name` is going to be bound to the value of the `Some` case class's member `x` in the case part that has the pattern `Some(name)`.
"case Some(name) =&gt;" is an example of pattern matching. The pattern match is what allows "name" to be declared that way. You can do all your programming without using "val" at all. You could do "3 match {case x =&gt; ... }" instead of "val x = 3". The heavy lifting in "case Some(name) =&gt;" is done by the method Some.unapply. Unapply methods can be created by the compiler by declaring the class a case class, so most of the time you don't need to worry about it. Most classes use the compiler generated unapply rather than writing their own. The scope of "name" is everything from the =&gt; to the next case statement.
Greate i will invite you, but im gonna be gone(goint to a cabin) until saturday so the others will need to bring you up to speed.
Nice write up. I don't really follow why you use both a type parameter and a type member. Just using a type member should be sufficient. You can place modules on the top level using objects instead of vals, i.e.: object IntOrdered extends Ordered[Int] { override def compare(t1: T, t2: T) = t1 - t2 } (and analogous using classes instead of defs). But of course this introduces a new type (which can be both good and bad). And you don't really go into the powerful combination of first class modules and implicit parameters. IMHO, the the real beauty of Scala how this relatively small set of atomic language features can be combined in really powerful ways, and Dotty reduces the set even further. 
Ya unapply is the magic I think OP wants
Thanks! Thinking about it, you're probably right that type members should be able to do the job instead of type parameters. I wanted to have my cake (no reference to the Cake Pattern) and eat it too: I wanted external users of the traits to just see an `A` type parameter but the traits internally to alias and build their own types with more topical names (`E`, `T`, etc). About toplevel modules, my issue is exactly that I want to upcast the modules and functors to their signature types at time of declaration. Hide all implementation details. And, I've repeatedly seen how Scala manages to elegantly express concept after concept from the functional and modular programming worlds in terms of OO, sprinkle some syntax on top, and get a _very_ useable language. It's very impressive. I feel it's best covered exclusively in another post. I might do such a post in the future :-) EDIT: see my other reply.
well it can provide a model of how things should be done, lol
No, in fact you and /u/Baccata64 are right to point out that it's feasible in production Scala. I've updated the article to reflect that. Thanks.
Jesus, variable variables are actually a thing.
Thanks to everyone! I will look up extractors, I appreciate the help!
On site in Canada? May want to post that in the description, will rule out 95% of the forum right away.
Hey, will you consider hiring fresh grads? Or you like to have people who can be productive asap. You didn't mention expected experience in job description.
concrete example, please.
Assuming that I meet almost all your requirements (I do just do not want to link my linkedin here). I also have experience with working in startups. Here is the catch: I live in Japan (with my wife which has her own career there). Would you hire me to work remotely (even though the puppy is a huge perk)? And if yes, at what conditions?
Pretty much anything discrete. If you actually want it to be a non-trivial case of bin packing, you'll need both objects that are different from each other and bins that are different.
I'm interested
We are definitely open to new grad applications! Especially if you have any interesting internships or open source experience. 
Dang I would apply (again) but I just got a new job :( Good luck finding candidates; you seem like an awesome company!
Damn! If you're who I think you are we were just about to message you. Congrats on your new job! Let us know if anything changes. 
Whiteboard coding doesn't really tell us if you can do the job or not, so we let you use your own laptop and usual setup and do some tasks alongside us. We try not to freak you out by staring at you the entire time. In fact, we're probably going to be doing a bit of our own work or answering emails while you figure stuff out. Traditionally, we let people use their favourite language. Out of everyone who's gotten hired, only a few people actually used scala for the interview. We're also experimenting with new processes, but we're committed to making a test that simulates a real work session. 
Thanks! 
Yes, you have to write things like: def UnbalancedSet[A](O: Ordered { type T = A }): MySet { type E = A } = to make it work, which is not very nice. So, I see the point of having type parameters for modules (and type aliases as members). Another option is to use type aliases: type OrderedT[A] = Ordered { type T = A } type MySetT[A] = MySet { type E = A } which should give you most flexibility.
I don't see where the existing API are not simple or small. Scala is not Python or Ruby and therefore things are done differently. Scala spent some time (and is still doing so) trying to match programming patterns from other languages into Scala. But at the end, you write Scala. And Scala is a functional programming in its core and therefore it will be hard to get rid of it. If you want something like apache commons, then I would argue you should use it. Nothing prevents you from working with these libraries and if you are more familiar with it, go for it. The other libs mentioned here are Scala libraries, so it is implemented the Scala style. And who says Scala says typesafe and functional style etc etc ... I would define the situation this way. In Scala you can go step by step in the language and don't have to swallow everything at once. So for people who come from Java or Python, they still have the possibility to work the way they use to and slowly understand the power of functional programming and how enjoyable this is. I highly recommend to learn as much as you can about it, it will not only blow your mind but also redefine the way you see these libraries from cryptic to exulting. Your feeling of second class citizen comes, I think, from the fact that the Scala community tends to be pedantic on the subject of functional vs object oriented programming. This is a pity. But please don't get bumped by these people. Play with these libraries, realize how much you can do without libraries and just have fun writing awesome code. 
hmm.. Well I 100% disagree with that, but you are entitled to your opinion and your own definition of the word "trivial", regardless of how off it is. 
Hey, I wrote that question! :)
For me it's fixed (not in the bug report, but with latest IDE / plugin it works again)
It's not my own definition. I didn't write the dictionary. http://dictionary.reference.com/browse/trivial
Sure thing!
&gt; Anorm Isn't it a database abstraction layer, not an RDBMS? I was thinking more along the lines of MySQL, MSSQL, Postgresql, Mongo, Oracle Database, etc?
Why is a `Try` not sufficient in this case? http://www.scala-lang.org/files/archive/nightly/docs/library/index.html#scala.util.Try
Postgresql is well regarded. Probably you should use whatever you are most familiar with.
For a small to medium size project, definitely H2, largely because I'm familiar with it. It's rock solid and simple to use. Pros: full, correct SQL implementation, handy UI, the convenience of an embedded DB and the ease of managing the database as a file. Cons: being embedded, adds to the memory footprint of your app. For large DBs or more complex requirements (for example, need to access the database from different processes, replication), I'd go with PostgreSQL.
It does indeed seem like it! I may end up going with Postgresql then :) - thanks
Seems pretty awesome. Good perf, doesn't eat data like mysql. Json support is nice. Only thing I hate is getting it fault tolerant..... Pgpool and all that jazz is pretty crude and a PITA
Do you have any thoughts on MariaDB?
Its just mysql with a nicer license and a few tweaks. Still think postgresql is more reliable and performant. Maybe someday it will rock??
Maria with galeria could be cool... Wish postgres could get something similar.
Exactly. The problem is people think of libraries like scalaz as some disjoint collection of things that exist in isolation, and are just packaged together for the lulz, as opposed to looking at how `\/`, `Validation`, `SemiGroup`, `Kleisli`, etc. all work together in really nice ways. A holdover from the "Kingdom of Nouns" OO mentality vs. "compose _all_ the things!" FP mentality, I suspect.
I toyed around with https://github.com/cretz/pratphall back in the day that transpiles TypeScript
PostgreSQL has all the NoSQL features and more. There's even async notification support. Postgres-XC gives you multi-master clustering. JSON and XML as data types and lots of functions to support them. Having been a big supporter of Cassandra, I say that PostgreSQL is better unless you need HUGE (petabytes) of data.
Well if you are modeling a computation, sure Try might suit your use case. I'm just pointing out that for instance, \\/ can represent a computation that has two possible return values, and it's biased to one. It may not be an error for instance. Or you may want to not have an error, have a default or whatnot that it doesn't make sense to extend from an error or throwable. 
&gt; It may not be an error for instance. I can understand that, but its not really validation is it? &amp;nbsp; &amp;nbsp; &gt; have a default Wouldn't this be better expressed through Options? val r = mightSucceed() | default &amp;nbsp; &amp;nbsp; &gt; \\/ can represent a computation that has two possible return values I'm starting to see how this makes a lot of sense. You can bind only either the lefts or the rights in an applicative. Edit: Realized the behavior of \\/ is val a = 'x'.left val b = 'y'.left val c = 1.right val d = 2.right List(a, b, c, d).suml res3: scalaz.\/[String,Int] = -\/(xy) 
The pgjdbc-ng driver does async just fine.
Article fails to mention the really nice macros for compile time reads/writes/format generation: https://www.playframework.com/documentation/2.3.x/ScalaJsonInception
My team in Boston, nToggle, is looking for Scala developers. The team includes several experienced Scala developers and is working on a variety of performance, big data, and visualization problems in the ad tech space. Send me a PM and we can talk further!
pretty cool! just a warning, to make sure your connections are properly cleaned up. The last thing you want to happen is run into the dreaded "too many open files" error.
Thanks for the warning but the cool things with dispatch is that it automatically closes them ;) so no worries to have!
I am not a big fan of mixing in validation logic with the serializers/deserializers If you just need to JSON (de)serialize case classes, here's a macro for your macro: https://github.com/kifi/json-annotation and keep the [validation logic separate](http://www.scalactic.org/user_guide/OrAndEvery) If you are writing a strongly typed idiomatic RESTful API, here's a macro for your macro's macro: https://github.com/pathikrit/metarest 
check your email, and thanks.
Odersky is well known for being a method *actor* and keeps the team around him *functional*. As a producer, it was his decision to allow the movie to be *streamed* so *lazy* viewers can watch it from the comfort of their home if the movie *matches* their viewing preferences. 
Hey, you may want to check out my Activator Template on akka-http: https://typesafe.com/activator/template/akka-http-microservice It comes with comprehensive tutorial which explains the most important things.
watched it all the way, thumbs up
Yes. It does.
Hi! I just emailed you and would love to link with you ASAP. Our team (saas product at the intersection of big data and computer vision) has room at our offices in NYC, Philly or Seattle. . .it sounds like a bigger team than it actually is (we number 17 devs in total). . .let me know if you are interested. Thanks!
/u/trollabot aldo_reset
***Analyzing aldo_reset*** * comments per month: 100 *^I ^have ^an ^opinion ^on ^everything* * posts per month: 1.4 *^lurker* * favorite sub [programming](http://NP.reddit.com/r/programming) * favorite words: pretty, really, years * age 0 years 10 months * profanity score 0.5% *^Gosh ^darnet ^gee ^wiz* * trust score 74% * Fun facts about aldo_reset * *"I am very familiar with Microsoft's history."* * *"I've played video games ever since I was a kid, so of course, I decided that the best job I could ever get would be to be paid to review video games."* * *"I am a Demon/Dark Souls fan and I am so excited that Bloodborne seems to be just as good as I was hoping it would be."* * *"I've never heard anything interesting or constructive coming from people who say that something sucks."* * *"I'm a software engineer so technically, I am a professional."* * *"I am in full support of a language designer that is taking all the time they need before hitting 1.0."* * *"I've never understood why people still visit this city called "Point Blank" since so many people routinely get shot there."* * *"I've found Kotlin easier to use to translate type class based code because of extension methods, which Ceylon doesn't have."* * *"I've read your post three times and I'm still not sure what point you are trying to make."* * *"I've read ignores most of the errors."* * *"I've accumulated twice as much karma as you, which makes me your boss."* 
yep, and I've sent you a reply. Hope you got it. thanks
I'm not making fun, I'm just genuinely puzzled because he sounds like a native English speaker otherwise.
Sorry, my native language is Swedish. I try to not make it too obvious, but I end up failing sometimes..
Your English is really good! I would guessed you were British.
Evidently not good enough.
You should hear my Swedish.
string interpolation myS!
Output: Bonjour, mon nom est John. Salut, John! Hello,this string is untranslated. [^source](http://ideone.com/Vk8QpC) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20http%3A//www.reddit.com/r/scala/comments/31iey4/scala_string_interpolation_why_the_s/cq2kb00%20Include%20your%20reason%20for%20reporting%20here.) 
How do you run the code in 2 collumns with Idea? Do you need a plugin?
It's a part of the Scala plugin. Just create a Scala Worksheet file.
Very cool, never thought of string interpolation and how they could be used for SQL. Do you know of any libraries that might use this?
Slick [ships with an interpolator](http://slick.typesafe.com/doc/2.1.0/sql.html#string-interpolation) like the one I described. Seems like Play's Anorm [does too](https://www.playframework.com/documentation/2.3.x/ScalaAnorm#SQL-queries-using-String-Interpolation).
How do you know Scala is the right language, besides the fact that it would make your work more pleasant? Aren't you putting your own preference before your client's requirements? I think you need to factor in the desires of your client in the choice of technology and try to resist the "Everything is a nail" temptation. If you're professional, you will pick different tools depending on the task at hand. Sometimes, it will be Scala, other times, it will be a different language. 
&gt; Anyway, I would argue that Scala is mature (twelve years old, This can go both ways: that client will probably argue that even though Scala is twelve years old, it's still niche, and they are obviously concerned about that since they are thinking about the difficulty of finding developers to maintain the project. 
If maintainability is a concern, then Play has a Java API and JDK 1.8 will let you use lambdas. You'll be able to write in a functional style, and can rewrite sections in Scala once you get the client comfortable with it. Trying to push a client past their comfort zone doesn't happen all at once. Get them used to using a Scala based framework first, and then show them some possible advances on the next project.
&gt; If subreddit subscription is any indication It's not. Different languages have different communities. Haskellers have chosen reddit as a primary medium for communication. Scala hasn't.
You can charge more to work in the other languages.
I can't say I can relate to this experience, I've never had sbt spend any inordinate amount of time resolving dependencies. The closest thing I thing I can think of to that this is referencing is when you use two instances of sbt at the same time(ie, in the command line, and in Intellij) and they constantly lock each other out of the ivy repository. But that's hardly a legitimate reason to slack off, you just kill one or the other.
My favourite: implicit class StringMatcher( p: StringContext ){ def ci = new{ def unapply( s: String ) = { p.parts.mkString.equalsIgnoreCase( s ) } } def r = new{ def unapply( s: String ) = { p.parts.mkString.r.findFirstIn( s ).isDefined } } } "Reddit" match{ case ci"reddit" =&gt; println( "yay" ) case "reddit" =&gt; println( "fail" ) case "Reddit" =&gt; println( "sad" ) case _ =&gt; println( "what??" ) } "Reddit" match{ case r"R.*t" =&gt; println( "yay" ) case _ =&gt; println( "fail" ) } +/u/CompileBot scala 
I usually end up with both a console and IDEA and only doing things on the command line. Then I stop IDEA from resolving dependencies, since I noticed weird things would happen (very weird errors that would miraculously go away after cleaning) when IDEA and sbt on the command line were racing for Ivy cache. Anyone else noticed this?
The hardest problem I've run into with scala is getting values in traits to be not null when I need them. I've discovered that basically traits need to always use def instead of val, and then you can override the def with a val later if you want.
Try it from anywhere outside the US. SBT does not parallelise network requests *at all*, and it seems to need to do a lot of them. So in Australia, where it's about a 250ms round trip to maven servers based in the US, it can take over an hour to initialise a new Play Framework project. 
What would happen if you ran a local Nexus or something? Should get it down to 1-2ms per, right?
Do you happen to have IntelliJ pulling in source and javadoc for dependencies?
&gt; and fact that it will be much harder to find a developer who can maintain the software later. Just an aside, but this is a bit of a myth. It's probably harder to find Scala devs compared to Java ones, but only by a little bit, and definietly by less than you think. In my experience, it's hard to find even competent run-of-the-mill Java people. What's different is tactics. Our recruiters balk at Scala; hiring Scala people may mean swapping time on the phone with obnoxious recruiters in favor of showing up at a local Scala users' group meeting or two and announcing that you're hiring.
Is this a ripped off xkcd with two words changed? 
Since a Nexus installation will not eagerly download the whole maven central, the first resolution will take no shorter, and all artifacts are downloaded to ~/.ivy/cache anyway so the local Nexus is not really helping, at least for the first person in the team setting up the project. 
Sure, but the local Nexus/Artifactory would still speed it up after the first resolve, and the local ivy cache only affects that system.
For individual imports, I think you can specify to include sources and/or javadoc http://www.scala-sbt.org/0.13/docs/Library-Management.html#Download+Sources With a classifier, you might be able to "cast a bigger net" and automatically only get sources. http://www.scala-sbt.org/release/docs/Library-Management.html#Classifiers
&gt;. Jane Street still has to sell the idea of functional programming (let alone ocaml) to a substantial portion of their hires I don't think Jane Street is hurting for programmers at all. Do you have any evidence that they're not rejecting the vast majority of their many many applicants? 
That's correct/expected. It's a full screen editor, write scala expressions and get their result underneath. Press the play button (or Ctrl/Cmd+Enter) to execute. The libraries listed in build.sbt are included, you can import them if you want.
This looks like a very round-about way of doing new X with Trait1 with Trait2.
This is great Gui, I love that you merged the class def + worksheet area, also the autocomplete works beautifully. p.s. where do you host it? and how do you launch it? Using the docker container? where? or just via a vanilla linux box + the sbt plugin + "sbt kstart" in ~/bash_profile? Most Java hosting places expect a WAR file, no? Kudos again, this is really well crafted. 
on aws via docker `sudo docker run -p d 80:7331 --name scalakata masseguillaume/scalakata-bundle:v0.13.0`
Yennick, three things to consider adding about Reads: 1. Use "or" to set default values when they are missing in Json input. 2. Use Reads.pure to set values that aren't in the input - consider rewrite of "Reads with custom value not coming from json" section. 3. Use 1 and 2 together, as in this "notes" field that defaults to an empty string: `... and ((__ \ "notes").read[String] or Reads.pure("")) and ...`
Gotta do what u gotta do when u hate da cake
Deserializers always implicitly have some kind of validation, since there's always some bad inputs that will be rejected. What kinds of validation do you not like there, and more importantly, why? I agree that a validation that requires external inputs (e.g. database lookup) shouldn't be there, but otherwise, I like being able to make assumptions about validity as close to the front door as possible - it reduces the places where an invalid assumption of validity can be made.
Mixing validating with parsing makes it hard to reuse the validator logic. There might be other entry points to your business layer besides user facing APIs e.g. admin tools or offline jobs or remote actors which does not necessarily all talk JSON. Also cross-field validation cannot be done during parsing e.g. if you have something like this: case class Filter(includeIds: Set[Int], excludeIds: Set[Int]) and you want to make sure that: (includeIds intersect excludeIds).isEmpty You cannot do that during parsing of the Filter model. And, lastly, tomorrow if you decide that play json is kinda slow and you want to use some other library like spray-json or argonaut, you have to rewrite all your validation code since it was mixed in deeply with json parsing.
One day we will have some form of quantification for languages, features and how these equate to productivity. We can be fairly certain a higher level language of some description is more productive and less buggy than assembler code, but we don't actually really have a study showing that to be the case. Prove is a strong word, proof on something as hard to measure as productivity is quite likely impossible.
[uTest](https://github.com/lihaoyi/utest) seems to satisfy your `Non fluent, yet idiomatic testing frameworks for scala` question. Not quite the same syntax but close. Don't have anything for your extra question ^_^
Sorry but I do not understand what you are referring to, may you clarify? Thanks
Check out http://activate-framework.org/ it is much better ORM and also supports PostgreSQL asynchronous 
Can't you just decompile your scala back to java? ;-) "senatorpjt why does every commit have 200+ anonymous classes?"
&gt;hiring Scala people may mean swapping time on the phone with obnoxious recruiters in favor of showing up at a local Scala users' group meeting or two and announcing that you're hiring. I'd say at any given Scala meetup I've been to, there are a handful of professional developers looking to transition to a scala gig, and a couple scala consultants looking for their next gig. Shouldn't be hard to find scala programmers if you're willing to do the type of recruiting you've mentioned. 
Exhaustive search?
It finished in .5 seconds here. scala 2.11.6. 
First run took 800ms on a 2014 Macbook pro. Scala 2.11.4; JDK 8. Subsequent ones are ~500ms.
Interesting. Can you comment the solve function to make it more readable? Thanks
That's really odd. On 2.10.4 it just hangs.
I especially like how you piped that welcome message into the eventSource. Pretty cool app!
Someone feel like explaining the main line to me? 1 to n diff (board.indices flatMap cells) collectFirst Function.unlift(guess) So we're taking the difference between the sequences 1 to 9 and the result of the flat map. Then what does the collectFirst Function.unlift(guess) do? Simply apply guess to a single item in that list?
By the way the source is here: https://github.com/hermanbanken/play-sample-chat
1 to n: Try all possible numbers from 1 to 9 cells(i) - Numbers occupied at (r, i) and (i, c) and the ith cell in the square containing (r, c). board.indices flatMap cells: Find all the numbers that are already taken (1 to N) diff (board.indices flatMap cells) - valid guesses guess(x): Try solving by setting (r, c) = x and see if that works. collectFirst Function.unlift(guess) - Find the first guess that works. 
And I used to be the product owner for Play at Typesafe, while James Roper is the tech lead. Things at Typesafe were even more confusing when James Iry was also there. :) But now that James and I are no longer there, James is the only James left.
Great video, very didactic. I'm currently doing some Play and Scala training for my team, this video will be very helpful :)
I decided to change its return type to: Either[(LispError, M), (MValue, M)]
We can generically solve the problem of input models being different from output models (in this case the latter has ids but the former does not) by using macros. Here is a library I wrote: https://github.com/pathikrit/metarest
AWESOME! thanks 
Shippable - www.shippable.com - supports Scala. I see the ensime folks have already mentioned that they use it for CI, thanks! 
They had the SBT hook turned up too high. It's fixed in the new EAP. http://blog.jetbrains.com/scala/2015/04/09/scala-1-5-eap-coding-assistance-for-interpolated-strings-new-inspections-and-better-sbt-support/
[Rewritten in Python](http://pastebin.com/2dBdwqxP) if anyone is interested. 
&gt; If we make Scala easier to learn / adopt (mostly get rid of all the &lt;:&lt; |+| &gt;&gt;&gt; &amp;&gt; in the demos and add much more tutorials and syntactic sugars and stop trying to explain monads to newbies who just want to launch a website) - then more people will choose it. This is a double-edged sword, though. If we eliminate the useful features and syntax of powerful libraries like Databinder Dispatch, scalaz, scalaz stream, etc. and don't explain monads, much of the value proposition of Scala goes away. Yes, there's still _some_ advantage to "Scala as better Java," but it becomes hard to explain just what it is when people say "Java 8 has lambdas, and Java 9 will have a REPL" and all you're competing on is basically less verbosity. Besides, as a _technical_ matter, to really compete with Ruby, Python, and JavaScript on the full range of concise code/short start-to-run cycle/the right thing is the easy thing/scalability, I'd argue you _have to_ use the frameworks that are architected along pure FP principles. A good example is [Project ρ](https://github.com/http4s/rho), which makes it super-easy to develop REST APIs with [Swagger](http://swagger.wordnik.com) documentation. To be fair, I definitely think scalaz in particular could be documented better. But I think that calls for documenting it better, not for promoting Scala by appeals to similarity to Java or other non-FP languages.
Really... Why can't they just upload to YouTube?
Here is a related [StackOverflow question](https://stackoverflow.com/questions/28082581/what-is-the-differences-between-apache-spark-and-apache-flink).
At that point you're probably better off defining your own return type, even if it's just a wrapper for that.
I think the StackOverflow answer is misleading and does not address the difference between the two quite well. Both are well suited for in-memory operations, DataSet and RDDs are roughly the same concept, and both supports batch and streaming processing. After skimming the Flink docs and sources I found some differences among others: - Spark core is written in Scala and supports java using wrapper classes, whereas Flink core is written in Java and supports Scala though wrappers. - Spark Streaming is a soft realtime streaming framework and has to be minibatch, but Flink Streaming is real-time and optionally can perform windowed operations. - Flink is a relatively young project when compared to Spark, having graduated Apache incubating only a few months ago.
How does Parleys make money with free videos?
I have a hobby play application on DO, using rails migrations. My deploy is this: deploy.sh #!/bin/bash ../../play-2.2.1/play clean dist scp -P 2222 ./startapp.sh play@&lt;SSH_HOST&gt;:~ ssh &lt;SSH_HOST&gt; -l play -p 2222 "rm -rf migrations/db/migrate/" ssh &lt;SSH_HOST&gt; -l play -p 2222 "mkdir ~/ migrations" ssh &lt;SSH_HOST&gt; -l play -p 2222 "mkdir ~/migrations/db" ssh &lt;SSH_HOST&gt; -l play -p 2222 "mkdir ~/migrations/db/migrate" scp -r -P 2222 migrations/db/migrate/* play@&lt;SSH_HOST&gt;:~/migrations/db/migrate/ ssh &lt;SSH_HOST&gt; -l play -p 2222 "rm APP_NAME-1.0-SNAPSHOT.zip;" echo "Uploading file" scp -P 2222 ./target/universal/APP_NAME-1.0-SNAPSHOT.zip play@&lt;SSH_HOST&gt;:~ ssh &lt;SSH_HOST&gt; -l play -p 2222 "migrations/rake" echo "Starting app" ssh &lt;SSH_HOST&gt; -l play -p 2222 "./unzipapp.sh; ./startapp.sh; exit;" unzipapp.sh unzip -o appname-1.0-SNAPSHOT.zip; startapp.sh ps aux | grep -ie appname | awk '{print $2}' | xargs kill -9 PIDFile="./appname-1.0-SNAPSHOT/RUNNING_PID" rm $PIDFile nohup ./APP_NAME-1.0-SNAPSHOT/bin/appname -J-Xms128M -J-Xmx512m -J-server -DapplyEvolutions.memory=true &amp; So the main steps: 1. play clean dist 2. upload the file 3. unzip 4. kill the previous, start new 
ansible and docker
So you are basically copying the file over SSH and then start process with application, right?
Why can't you use Capistrano? You could look at [Chef](https://docs.chef.io/) or [Puppet](http://docs.puppetlabs.com/).
Just use Capistrano if you're familiar with it
You can do those, with Ansible. Ansible is not solely for infrastructure.
Look into [deis](http://deis.io/), it's like running your own Heroku, you can use Heroku's [Play buildpack](https://github.com/heroku/heroku-buildpack-play) to get things running easily or roll your own docker setup.
They make money with the logins. 
I'm still choosing between Dokku, Deis and Flynn.
I can, I just wonder if there are better solutions. Chef or Puupet are overhead, I prefer Ansible in that place.
Ditto. Not a clear winner yet but I feel like Deis has had a lot of quick progress. 
After some messages about loading, resolving and updating somethings, I see: [info] --- (Running the application, auto-reloading is enabled) --- [info] [info] play - Listening for HTTP on /0:0:0:0:0:0:0:0:9000 [info] [info] (Server started, use Ctrl+D to stop and go back to the console...) [info] [info] Compiling 1 Scala source to /e2/engine/target/scala-2.11/sbt-0.13/classes... [info] play - database [default] connected at jdbc:postgresql://localhost/e2 [info] play - Application started (Dev) 
So when you make changes, does it print something?
Will do.
Have you tried: activator ~run ? That used to be how you'd make sbt watch for changes. I don't use activator though.
I usually do the following. 1. Build an uberjar with https://github.com/sbt/sbt-onejar 2. Put java on the host machine with fabric, ansible or puppet. No major difference between these. Capistrano would probably also work. 3. Deploy a java service wrapper with fabric/ansible/puppet: http://wrapper.tanukisoftware.com/doc/english/download.jsp 4. Push the uberjar. If I need to deploy to a lot of machines, I push the uberjar to s3 and then have the deploy system pull from s3 in parallel. 5. Push an application.conf and java service wrapper conf. When I want to deploy new services, the only step where much customization is needed is (5). 
+1 on this approach. We used to ship uberjars, but now ship the N dependency jars and do an s3cmd sync to fetch them. We found that saved a significant chunk of time that was previously spent in jarring, pushing and pulling.
I could be totally wrong, but my first guess is that you are using an old/exotic OS, where the JVM can't support/doesn't know to support the file watcher API, which SBT/Play/Activator relies on to get a notice of changes in the file system. But the devs on the Play mailing list might have a better idea.
Looks like you're missing the tilde. Try: activator ~run 
I had the same issue here with a small play app, on a dual core i7 macbook pro and OSX Yosemite. It could be the new osx version has problems with file change detection, but my gut feeling was that the reload process was stuck on some memory shortage issue... just a gut feeling though, I might be totally off track.
You can check [Genson](http://owlike.github.io/genson/Documentation/ScalaGuide/). I think the main advantage of Genson over the existing Json libs in scala is that it just works and is easy to use. But it is also fast, has rich features and comes with integrations with other libraries like jodatime and even json4s if you want to use its DOM model! All that without any fancy unecessary code like implicits, custom readers/writers for basic cases, ilisible API due to operator overload... import com.owlike.genson.defaultGenson_ val json = toJson(Person(Some("foo"), 99)) val person = fromJson[Person]("""{"name": "foo", "age": 99}""") case class Person(name: Option[String], age: Int) Note: Even if I am Gensons author, I try to remain objective here and as you seem to reject the complexity of existing libs I think Genson might fit your needs.
Ubuntu 14 something. I'll try to post something to the mailinglist soon. Thanks. 
The docs are correct. However, the docs are specifically referring to the **activator ui** command.
Further: https://www.playframework.com/documentation/2.3.x/PlayConsole &gt; To run the current application in development mode, use the run command &gt; In this mode, the server will be launched with the auto-reload feature enabled, meaning that for each request Play will check your project and recompile required sources. If needed the application will restart automatically. When I hit refresh, the application hangs. 
I guess the tilde isn't needed anymore. I've always been used to having it when I'm developing. It might be a new feature in recent versions of sbt/activator.
If your ops class extends AnyVal, then you won't have any cost associated with using the operators. It will compile to static methods
Oh, looks like I read the documentation incorrectly. It says a value class "may not have specialized type parameters", which I read as "may not have type parameters". Thanks for clarifying! I'll update the post.
I made a Play Framework web app that uses this SExpr Evaluator - https://github.com/kevinmeredith/play_lisp. I took a stateless approach, by requiring previous, historical SExpressions to be re-run.
Offer a discount for going with Scala.
If you're worried about your ongoing employment, I can recommend using the cake pattern to construct code impenetrable to other developers. Beyond that *don't use the cake pattern*. The cake pattern is one of those ideas from the early days of Scala that looks like it's really neat but experience has shown in almost all cases it is just more hassle than its worth.
Whilst this perfectly acceptable for projects that don't need the large infrastructure, I would suggest you make use of your version string, and use a symlink if necessary with your nginx or whatever config so if this deployment fails, you can change the symlink back to the previous version quickly, or automatically.
Less hassle than Spring, more hassle than normal constructor based, imo. 
Are you using vagrant/VirtualBox? I'm not familiar with Scala/Play/Activator but I remember that shared folders and inotify don't work together. See https://www.virtualbox.org/ticket/10660
So us the cake pattern useful only for singletons? 
No, you can allocate more than one instance of a cake. E.g. more than one Scala compiler running in the same classloader. It happens in the IDE or when you use advanced reflection capabilities.
I have never used uPickle and just had an overview of the doc so maybe I am missing some stuff. From what I see, uPickle is quite limited in what it can do and does for json ser/de. So feature wise Genson has a wider scope and supports more use cases. But I guess your interest is more specific to reflection vs no reflection. Reflection-free is acheived with macros that praise benefits of "compile time safety" where reflection is at runtime. In the "java world" most libs use reflection and never got (when correctly implemented) into the problems reflection-free code advertises to solve. IMO it is more a "marketing strategy", but that is fine we all have one :) Also all the libs that deal with macros use implicits as a way to customize things, I find implicits resolution strategy hard/mysterious and less user friendly than directly configuring an instance of the lib you want to use with your custom code and then use it. They also require you to define implicits for any custom case class or whatever you define. Just a few words on Gensons philosophy: it is not abouting making things look cool but make things work, provide solid documentaiton and make things easy for the people who use it. I think you should try Genson and make you an opinion by yourself :)
The cake pattern isn't great. If you want to look at a compile time DI framework, look at Subcut or MacWire. Otherwise, Guice is your best bet. Some people use Dagger, but it's designed specifically for fitting DI inside of Android, so I don't know how broadly applicable it is. There's also a Parfait pattern that Dick Wall demoed a while back.
Did you turn off mtime or anything fancy on your mount? Could be related to that (but I do not know the file watcher API that well so not 100% )
Thanks, this is one of the reason I posted it so I can get some tips on how to improve. As it is a hobby projects I haven't spent much time with it but symlinking/deploying while the other is running is definitely something I want to do. 
Are you using implicits as well? This sounds like an intuitive route that I didn't really consider before.
 I'd say the best way to find them is to get involved in the community. Go to the local meetup, give a presentation, contribute to open source, attend a conference and soon you'll have people applying to you. 
I would also be open to learning more about your startup
A great quote: "Another interesting move this month concerns Scala. The functional programming language jumps to position 25 after having been between position 30 and 50 for many years. Scala seems to be ready to enter the top 20 for the first time in history."
I liked this quote: "Another interesting move this month concerns Scala. The functional programming language jumps to position 25 after having been between position 30 and 50 for many years. Scala seems to be ready to enter the top 20 for the first time in history."
Agree. TIOBE generates buzz by (randomly) changing language rankings. Nothing to see here.
I am a junior and I'd like some information. 
Are you using Scala experience as a cheap filter? If not, why not just find good programmers first (with Java/C# and/or FP experience); if they are worth their metal they'll be able to pick up Scala easily, especially if you are able to provide decent guidance. 
The people who lead your A round should have some good ideas. Developers who join very early phase startups (I think you're talking about employee 1) know they're getting a lot of equity rather than pure salary. That said, you're still probably looking at 100k as an absolute floor in SF, NYC, or Boston.
I'd be interested in hearing more if you're open to remote engineers.
and Haskell drops out of the top 50, hmmm. Even stranger, Groovy is still hanging around in the 40s despite their sponsor having ditched them (guess Gradle is keeping that ship afloat). I'd take this with a grain of salt, probably only the top 8 are truly popular in terms of mainstream usage. Scala and every other FP-ish language have a long way to go... Saying that, good to see some positive press for the day job language ;-)
Give Stackoverflow careers a try. I stumble over their ads like 10 times a day (on SO of course).
Never heard of tiobe until now, but seems a arbitrary and link-baity. 
Groovy has been picked up by the Apache Software Foundation so hardly down and out. 
happy dance for something meaningless sounds like something managers do (and in this case it's about a report...oh the irony)
ASF funds are far from sufficient to support Groovy team full-time, let alone a single dev. That likely means they will need to get day jobs and contribute in their spare time. I spent a couple of years in Groovy/Grails land (the latter painfully so), leaving in 2011 for Scala. Groovy is basically toast for the long haul, the language brings nothing interesting to the table feature-wise, but does offer poor performance and lack of type safety (i.e. no static compilation beyond a bolted on option). Look at Ruby, Groovy is in the same boat, a sinking one...
Why do you say Ruby is sinking?
Completely agree, Tiobe is meaningless. I mean think about it: they claim they measure the occurrence of the words "&lt;language&gt; programming" on the whole web. Not in new posts but overall. Do you really think that languages jump wildly from one month to the next in that rating? No, the results would be essentially flat and very boring. So, what really seems to happen is that Tiobe tweaks their formula (where they search and what other search terms they consider for a language) every month. That means any movements up or down are much more likely to be Tiobe's doing than they reflect an underlying trend. Crazy really, but people are just so much in love with trendlines that they completely ignore that these are fata morganas.
:/ Well, at least it did help me finally convince some of my peers to finally start to learn Scala so it's not completely meaningless ;) (Scala is an official approved language at my company, but we have some stubborn Java fanatics that won't even try it) p.s. do you have any more accurate metrics on Scala adoption / popularity trends? (e.g. number of downloads / page views to scala-lang.org)
There are a number of places: Go to the local Scala Meetup Group, and introduce yourself, or better yet give a talk about the technical problems you're solving. Look on job sites: http://www.scalajobs.org/jobs/ and Indeed, Put your company on the Typesafe board: https://typesafe.com/subscription/typesafe-together/our-customers-are-hiring Also, don't be afraid to recruit for strong Java developers -- for them, the chance to learn Scala is a huge asset for your company.
&gt; Well, consider that Ruby's prime began in the mid 2000s when Rails burst on the scene, and effectively ended when Twitter dumped Rails for Scala. I was asking what data you derived your assertion from. The graph on the Quora question is something to look at already, but I have a suspicion it doesn't tell the whole story, since you also have to look at what those repositories actually contain, activity, etc. &gt; Scala's rise may have nothing to do with real world changes, but then again it's a pretty compelling choice given the ecocsystem that has grown up around it, not to mention the language itself, which is arguably rivaled only by Haskell in terms of power, concision and expressivity. I'm not even talking about Scala's merits, just about how this particular index is not really meaningful. I would much rather look at statistics from Github, StackOverflow, or when looking at proprietary software, surveys like Eclipse's or Stackoverflows than some obscure measure of Internet buzz that is known to change wildly for no discernible reason.
How would you see today the choice to make the Scala compiler itself be based on the cake pattern? And will Dotty be similarly constructed or use a different approach of composition?
If Tiobe's index is junk, what's good? I'd be especially interested in something that measured what new projects are being written in - that factored out maintenance.
Sure, they are just adjoints to forgetful monads.
I'd like to hear people's strategies for this, too. Spent some time trying to write some performant code (hobby project). I feel like my strategy was probably the same as yours, find top hotspots in visualvm, check for suspicious heap object counts, then get to work removing lambdas, call-by-names, and the other nice Scala features. Usually finding the worst code by looking through the generated byte code. I'd like it if there was a tool that correlated the top hot-spots with heap object counts and could pin-point probable offending source code sections. 
Scala Value classes, anyone? http://docs.scala-lang.org/overviews/core/value-classes.html
 I use activator(the new scala intellij plugin supports it) and it works fast because it comes with a lot of dependencies included. What are the specifications of your pc? 
It should be auto-updated since the IDE checks automatically, but I will look into that better tonight
I would give the client an estimation/cost for you using Scala, and another one for Java. Let him make that decision. If you need some additional arguments to convince him to go Scala, tell him about the companies using/invested in Scala, that every fool can "know" Java, but learning Scala shows you want more than your Textbook language can deliver. If he asks about maintenance, tell him that yes, Java devs are cheaper, but considering the likelihood to get a good Java programmer is less, the time it will take this dev to improve your work could be more. Finally, as a personal opinion, I would only feel comfortable using Scala for a project when I am willing to support it, should problems arise. Because finding local Scala devs willing to do maintenance work on a small project that is not their baby is very hard in my country. 
I've used scala for many years and I love scala for many reasons. But I hate that every fart you do is going to be boxed. Even if it doesn't matter much most of the time, I just don't like the idea. I'm learning Rust now... There you have a mix of ML/Haskell and C made safe. Their credo is "zero cost abstractions". No GC, even reference counting is optional thanks to smart typesystem. Most stuff lives on the stack! It compiles to small portable binaries! Nice. But it isn't always as beautiful as scala, that's for sure... 
Still it's crazy when you are used to maven and then ... bang ... a totally different behavior happens.
Why don't you update to sbt 0.13.8? I think the caching stuff has been vastly improved during the 0.13.x cycle. Certainly I don't have this problem (IntelliJ IDEA 14.1.1 CE, latest Scala plugin, sbt 0.13.8, Scala 2.11.6, located in Europe). And I do have auto-import and download-sources-and-javadocs enabled.
The biggest concern I see in companies (mine included) is that it's hard to hire for scala devs. I really hate this mentality because it assumes people are too stupid or unwilling to learn scala, but it's there nonetheless. At the same time, I've been on hirig teams for many years now and the caliber of a lot of applicants is just straight up abysmal, so I can understand why management would shy away from a lowest common denominator language like Java when thinking 10 years in the future. I've found that companies that do embrace scala, like LinkedIn and twitter tend to have strong technical evangelists and leaders. When those people leave (like LinkedIn) the scala fervor dies out. Sad faces all around 
&gt; In fact, it could be argued that nullable is even better than Option for many practical scenarios, since all types in JVM are nullable. I would argue exactly the opposite. Because any reference can be null technically on the JVM, introducing `?.` is a fallacy. It gives you the idea of safety where there is none, unless of course your code _only_ uses `?.` which clearly doesn't make sense. In contrast, idiomatic Scala is to not use null at all. Then `val x:Option[_] = null` and `val x:Option[_] = Some(null)` are cases that should not exist. _Don't do it_. The only advantage of `?.` is Java inter-op, and I'm not sure that Kotlin is solving this problem here, either. I'm not following the project closely, but I remember they were going forward and backward about it. Are they still sticking to the idea of KAnnotator by which you must tell the compiler exactly which arguments support null and which not? If I wished for any change in Scala, it would be that the compiler treats any type you define in Scala as `@NotNull`, so that if you really need this bullocks for Java APIs, you have to be explicit about it. Perhaps a `@CanBeNull` would be a name that could convince Martin ;)
The `?` could be a nice shortcut for `for-yield` syntax for Scala's Options: Basically instead of: for { a &lt;- aOpt b &lt;- a.bOpt c &lt;- b } yield c do this: `aOpt?.bOpt?.c`
Or simply: def ?[T](x: T) = Option(x) val x = ?(System getProperty "xxx") But I think the OP was hoping to avoid creating an instance of `Option`. For example: val y = if (x == null) null else (x + 2) ...so that `y` can be passed back to Java code. Maybe a macro can do this? import scala.reflect.macros.Context import scala.language.experimental.macros object IfNull { def ?[T](x: T, y: T) = macro IfNull.impl[T] def impl[T](c: Context)(x: c.Expr[T], y: c.Expr[T]): c.Expr[T] = c.universe.reify(if (x.splice == null) x.splice else y.splice) } object Demo extends App { import IfNull.? val x = System getProperty "user.name" println( ?(x, "OKAY " + x) ) // OKAY blah val y = System getProperty "returns.null" println( ?(y, "OKAY " + y) ) // null } 
&gt; In fact, it could be argued that nullable is even better than Option for many practical scenarios, since all types in JVM are nullable. JVM allows you to have val x:Option[_] = null and also val x:Option[_] = Some(null) breaking the theoretical benefits of Option. You say it might be better for practical purposes, but use a theoretical case as an argument: there is no sane, intentional case where one would set an `Option` reference to `null` or use `Some(null)`. &gt; I for one would love to have nullness checks in Scala. Not as a plugin, or macro, or annotation checker, but a first-class checker baked into the language. Scala has more than enough language features already, creating one more whose benefits can be realized in a more flexible way with a type, that is even already included in the standard library, seems quite foolish.
If I get time I'll write it up. Basically you can implement something like the `Id` monad in Scalaz / unboxed tagged types to avoid runtime overhead.
Thanks! :)
I'm not sure this is the best venue to have people explain why they hate Scala. :) The gripes I see normally come down: * people not understanding how to use the language * limitations of the JVM and decisions in Scala's design that aid Java interop that make advanced FP techniques more difficult * complaining about compile time 
You should construct those values with Option() rather than Some(): scala&gt; Option("foo") res0: Option[String] = Some(foo) scala&gt; Option(null) res1: Option[Null] = None
I know I *should*, but I also know that I *won't*; not everytime. Especially, if I am a newbie Scala developer, or inheriting code from another developer, or the example is not so simple as I had given for illustration. Why not let the compiler help me remember?
&gt; val x = java.util.ArrayList&lt;String&gt;() Yeah, Kotlin seems to be lax in checking nullability of elements in an Array List. It does check nullability of Array elements correctly. For example: val x = Array[String]() x[0] = null // compile-time error I will have to see why Kotlin is lenient with ArrayList, but I am new to Kotlin. My hunch is that this is either a bug or some trade-off for convenience (which I don't think is a good choice).
What's wrong with aOpt.flatMap(_.bOpt) this?
The difference of course being that the compiler won't stop you from writing `val x: String = null`.
Out of curiosity, since I'm not a Kotlin expert. What does `System.getProperty("xyz")` give you in Kotlin, a `String?` or a `String` .... ?
It was `String?`, then it became `String` and they are planning to make it `String?` again (if I understand correctly). See this [recent blog entry](http://blog.jetbrains.com/kotlin/2015/04/upcoming-change-more-null-safety-for-java/).
You should never wrap a method call in Some(...): If you're calling a properly implemented Scala method it will already return an Option over a null. If you're interfacing against a Java- or Scala-method that for some reason may return null, you use Option(...) to ensure you keep . Some(...) should be used in pattern-matching or for wrapping a known value. You're of course right in that nothing is hindering users from doing "the wrong thing", but that's true for many things in programming :)
In many cases it's not "so many" people as it is a very vocal core group of critics who generate a disproportionate percentage of the negative comments. In terms of actual data a recent StackOverflow survey found that Scala was the 6th most loved technology (based on data from those actually using Scala): http://stackoverflow.com/research/developer-survey-2015#tech-super
&gt; There is indeed a reason for this. If your opinion of a programming language is decided by what strangers on the internet think of you, that reason isn't valid.
I love programming with Scala and think that either Scala or a language that will evolve from / take a lot from Scala will be eventually the language(s) of the future. But you asked why people hate it? First, I think most people who actually try it, like it. But for those who don't, here are my categorization of the types of "haters" I found from peers and online: 1. Java people who are afraid of change, usually veteran people from Java backgrounds (the ones I know personally are even considered Java gurus), they probably also would have hated Haskell, F# and Lisp if they have ever heard of them. They also probably never tried Ruby or Python and likely to think Groovy is for little kids. They are so caught up in their Java world that they don't need anything else. And to be frank, I'm not sure they NEED anything else for that matter, most of them are good developers. I stop trying convincing the type 1's in my company to even take a look at scala, they are predetermined to hate it. maybe because they call it "better java". I also like to call this group "the trolls" and "devil advocats" who will argue with you on anything that is not praising Java no matter what it is. They also won't use Java 8 lambdas unless they are forced to. But they will use 5 annotations on every line of code (and will use a lot of reflection and dynamic code generation, and IDE shortcuts and prove to you that they don't need to code much, the IDE does it for them) 2. people who come from dynamically typed backgrounds, Python, Ruby, NodeJS, Clojure. They see scala as "ok". (Scala IMHO has more in common with Ruby than with Java) But they usually don't like it for one reason - compile times. 3. Some people from functional programming backgrounds, Haskell mostly, who see Scala as a "lesser haskell" and wonder why on earth would anyone touch something so impure. 4. People who like more opinionated languages and frameworks, like Go, or Python, (or even Ruby) where there is usually one good way to do something, usually all the batteries are included for simple things like file handling, REST clients, JSON parsing etc. Scala is really not opinionated, by definition, it's a language that lets you do a lot of things in different ways which on one side leads to expressiveness, but also a lot of style wars and many, many language feature flags. Even in Scala community, there is still a war going on between the FP and OO sides each pulling to its own direction. 5. People who actually tried it, looked at it, didn't understand it and freaked out from CanBuildFrom and &lt;:&lt; and |+| etc, and started the biggest claim against scala, that it's "too complex" 6. A much larger group IMHO, are people who DIDN'T try it and just read blog posts written by people from type #5 and claim it's too complex without even knowing how it looks like. 7. The rarest group of them all, (I found only a few of them) - people who actually learned Scala, know it better than some Scala developers, but still chose not to use it (there are many common excuses - too many language features, not liking implicit conversions, not liking over use of operators, all of these are not really convincing reasons IMHO to hate the language, but it's their opinion) Bottom line, I don't think hating something like a programming language is making any sense, I hate traffic, I hate wars, I hate injustice in the world, for programming languages it's not about love or hate, it's whether I find it useful or not. I love the fact I'm saving time with Scala, I love *programming* with Scala, but for Scala the language I don't really have any feelings. If tomorrow I find a better language, there will be no sentiments. Having that said, here is the final reasoning about why to start learning Scala: 1. Scala vs Java 8 - You can start using Scala right now if you are a Java shop and you clients still need JDK 1.6 and use advanced featrues that even Java 8 doesn't have, also Scala has everything Java 8 has + 10 times more. Also it's more object oriented than Java... in Scala, everything is an object, in Java - not so much... 2. Scala vs Ruby - it can do anything Ruby does (including duck typing, pimp my library, even method_missing) and it will run better in production. 3. Scala vs Haskell - it can do mostly what Haskell does (with some libraries such as Scalaz / Shapeless etc...), but with wider toolset, Java interop, and 4. Scala vs R - Scala is slowly taking over the big data analytics word with Spark, also Scala license is much more permissive than R (R is GPL, which is viral, you can't use it on client sites so easily as you can with Scala, which simply runs on the ubiquitous JVM) 5. Scala is more productive than Java, there are countless showcases that tell that... Having that said, everything is subjective, YMMV. 
I think having built-in syntax for something so uncommon like `null` is wrong. Also: do we also get special syntax for `Either`, `Validation` etc. then? Regardless of that I think most of it will probably arrive in future versions. - Union types could make nullability explicit (and I don't believe that they would make e. g. `String` mean "nullable String" if they could just require `String|Null` instead. - With Java 10, it might make sense to convert Option to a value type. As soon as Option is a value type, it is non-nullable. I'm not really seeing why it would be `Option`s job to rule about the nullability of its contained value. If you don't want to have `Some(null)`, don't use a type which allows itself to be `null`.
You can define ? as a shorthand for flatMap and the result wouldn't be much different. Although kinda pain to read. And you shouldn't do it. Extract some expressions into vals and make life easier for people who will inherit your code. request.?(_.header.?(_.get("AUTH").?(_.username))).?(db.findUser) No need to invent new language construction and disrupt what I perceive as perfectly balanced, flexible and extensible language with little need for sugar like you propose. EDIT: BTW, this syntax from Swift is my main grudge about it. I still can't wrap my head around it, it's so unlogical and smelly I refuse to do it.
http://techblog.net-a-porter.com/2013/12/ask-tell-and-per-request-actors/
This is a concept covered in Effective Akka. This is where I'd use a trait much like a service concept in traditional enterprise development. You'd define a service that is also an Actor and takes its dependencies - target actor (sender), DAO or whatever - in its constructor, and also define a companion object. Now you'd create an instance of the fly, giving it sender and any other actor refs or services, and job done. I'll try and find a link for you as I'm on my mobile and might be less coherent 😊
I lol'd at this
https://news.ycombinator.com/item?id=9389429
Ooops 20140705
Did anyone encounter this league of legends aspect? Which online forums / blogs did he try that made him arrive at this conclusion. The scala user groups and this sub are what I consider the most active Scala community gatherings, isn't it so? I found a very friendly and helpful people. Yes there are a few outliers but they are quickly pushed out by the majority. What is he talking about?
 Ok, i talked about "inquisitors".
He's talking about Scalaz and the effect that some members of its community have had on the Scala community. 
&gt; Oh, if Union types land in Scala, String | Null would definitely be preferable over String? &gt; Yes. That was not a question :) In Kotlin, a type followed by a question mark indicates a nullable variant of the type. My bad, I should have clarified. &gt; I'm not sure this is possible. What would happen when you assigned it to Option[_]? I wasn't thinking clearly and I am not very familiar with value types so I take that back.
There's a plugin which warns on boxing / unboxing operations written by Iulian Dragos (the author of specialization): https://github.com/dragos/noboxing-plugin It looks a bit out of date now, but if there's interest, it shouldn't be too difficult to get it running on 2.10 or 2.11.
Totally with ya, wish everyone saw it that way 
Had this exact issue. The solution was to turn remove the *fork in run* stuff from my sbt build.sbt: // fork in run := true I also removed the sbt-fork-run-plugin from the list of sbt plugins I was using: // addSbtPlugin("com.typesafe.play" % "sbt-fork-run-plugin" % "2.3.8") Doing this made play much more usable for me. Not sure why the fork in run stuff is so completely broken but it really really is.
FWIW, I tell people you need to allow two months, minimum, before expecting newcomers to Scala to write anything you should consider putting into production, and that's assuming in-house or external training, Coursera courses, team working through "Functional Programming in Scala" daily, etc. A really foresightful startup may pay for this instead of the on-site Michelin chef, showers, and fitness center, but how likely is that?
This worked for me, thanks so much! How'd you discover this? What's going on with that plugin? 
Sure you could say that I'm a contributor *now*, but I hope that doesn't completely invalidate my experiences I had when I first got started with Scala. I'd also like to point out I don't have any academic training, prior experience with functional programming, nor do I know Haskell. I'm not denying some past behavior was unacceptable, but I think it's fair to throw in an alternate anecdote, no?
Does Bruce Eckel even have real experience with Scala beyond Hello World?
can we have some examples of tony morris behavior? So much trash talking about him here but without seeing some examples you're giving people an impression without the ability to pass judgement. I've spoke to the guy on a few occasions and I never had a problem. 
Oh, right! Sorry, I didn't parse that sentence correctly! We agree. :-) &gt; I wasn't thinking clearly and I am not very familiar with value types so I take that back. I didn't want to imply that anything you suggested wasn't reasonable, sorry if it came across like that! It certainly causes subtle issues which will complicate things though...
He was [recently banned](https://groups.google.com/forum/#!msg/scalaz/EBP_7sfB2ks/cV8aynO2TMkJ) from #scalaz, though that is not the first time -- I believe there's an ongoing ban in effect for all Scala Google Groups. Edit: I should point out that he has made significant contributions not only to Scalaz (which I believe he started) but also to Scala itself, so despite the social arena fallouts I think that he, like Paul Phillips, wants to see a vastly improved Scala.
I have to confess to being torn about this. On one hand, I want to help people get into Scala, and I devote some time and energy to that. On the other hand, if the claim is "imperative and/or OO is just as good a way to develop software as pure FP," that's false, and I don't know what's helped by coddling people who believe it. That doesn't mean there's no learning curve involved in putting it into practice, or that Scala is the best language in which to do pure FP, or that there's nothing about doing pure FP in Scala that's fundamentally baffling in its execution. It just means it's reasonable to do, and the benefits are obvious. I don't mean they're necessarily obvious before you do it—if that were true, presumably everyone would be doing it. I mean _having done it_, they're obvious. It's kind of like exercise: you go into it hoping for good things, and come out of it having, if anything, probably underestimated the good things. So the challenge for us in the Scala/scalaz/Cats/whatever community is to try to bridge this gap, from perfectly understandable and healthy skepticism (hey, I was a smug Lisp weenie in a previous life, and CLOS was God's own object system) to the very _concrete_ benefits of pure FP, even in a language like Scala that doesn't enforce it.
Well said, however, you also nail the head on what divides the Scala community: Scala is multi-paradigm, whereas a language better suited to pure FP, like SML or Haskell, is not, and therefore escapes community division by virtue of the fact that the language *requires* a certain approach; its users naturally fall in line as a result. Perhaps when Dotty comes on the scene we'll see a more opinionated Scala, and the community will follow suit. One can dream ;-)
And that, frankly, is a ridiculous stance to have on a multi-paradigm language.
Just so you know - the person you are responding to "aldo_reset" is Cedric Buest.
Falsification of the claim that I quoted.
It follows from the Curry-Howard Isomorphism, the challenge being to strike the appropriate balance between the expressive power of the type system, allowing you to be very precise in what requirements (propositions, types) you can express and type (proposition, requirement) inference, which you probably want to be able to take advantage of in the less critical portions of your program. That's the formal answer. Less formally, anyone my age doing pure FP has not been doing it their whole career unless that career has been in academia, and probably in Europe (America never has been a hotbed of FP). So we do it for the reason anyone would do it: it works better. The example I keep referring to—because it involves open source anyone can examine for themselves—is our (Verizon OnCue's) [remotely](https://github.com/oncue/remotely) and Rob Norris' [Doobie](https://github.com/tpolecat/doobie) JDBC system, which Rob integrated in [one line](https://twitter.com/tpolecat/status/553437166328508416), and that integration introduces no—_can_ introduce no—failure modes. That's the value of pure FP relative to imperative/OO programming.
[**@tpolecat**](https://twitter.com/tpolecat/) &gt; [2015-01-09 06:24 UTC](https://twitter.com/tpolecat/status/553437166328508416) &gt; *click* go the types. doobie + remotely sittin' a tree https://github.com/tpolecat/doobie-remotely/blob/master/src/main/scala/demo/World.scala#L18-L32 ---- ^This ^message ^was ^created ^by ^a ^bot [^[Contact ^creator]](http://www.np.reddit.com/message/compose/?to=jasie3k&amp;amp;subject=TweetsInCommentsBot)[^[Source ^code]](https://github.com/janpetryk/reddit-bot) 
I mean you keep saying FP is better, but if that's true, then it must have been demonstrated empirically more than once. I'm just asking for pointers to that evidence, rather than anecdotes like "it worked well on this project".
Faithfully encoding invariants in the types is orthogonal to functional/imperative/object-oriented proramming. It's more that the typical type system found in many object oriented programming languages attempts where the entire universe is a single lattice of types and subtypes, is fundamentally broken.
If I remember correctly, this is not exact, as Tony's not been actually banned. After some harsh comments and some more or less heated debate on the correct way to behave with other people online, Tony eventually ends officially avoiding those groups where his own view of mature technical conversation is not shared. I don't share his opinions on the correct way to teach or criticise people, but everybody is allowed to have a personal opinion. In any case I also think that he's a great contributor to the programming community in general, regardless of his social attitude.
&gt;In that, Rx perfectly captures my current perception of state of the art in computer programming today: a careful mix of FP and OO that tries to use each of these approaches where it shines. Can you give a specific problem you think Rx solves that a purely functional approach fails at? I'm curious. 
No, because that's not how I phrased it. Rx encourages chains of calls and transformations, so in that, it is extremely FP inspired/compatible. However, the implementation of each operator maintains state that gets mutated at each invocation, so in that, it is intrinsically not referentially transparent. Rx is really awesome and I think that more than lambdas or Java 8, it is going to play a big part in making programmers more familiar with FP concepts, starting with the fact that it's gaining a lot of momentum on Android (even though Android doesn't support Java 8). 
Honestly, take any technology, language, or even political party/view and you will find a vocal minority of irrational fanboys on one side, haters on the other, and the silent 90% of us who understand a tool is only as good/bad as the one using it. I would recommend taking the emotion out of what people say, trying to understand the technical issues they bring up and simply acknowledging they exist if you are convinced and they *still* exist (often they are resolved in a newer version but the haters tone wont change). All languages have some bad parts. IMO (for the little bit of perspective it may be worth), here are some of the bad parts * An internally messy collections library - not sure how much is still true, but the number of collections and scaldocs sure confuses me sometimes. The internal messes mean things can be really unintuitive in pathological cases or have non intuitive performance issues * potential to be abused by too many arcane symbols/operators in DSLs (this depends on the DSL.. also, to all the haters - just dont f**king use the specific DSL if it annoys you rather than pinning it on Scala and ranting about it). Again, the flip side is being able to define DSLs in the first place that can be a pleasure to use. * not quite as sophisticated in functional features as something like Haskell. * Implicits can be abused. Overall, scala has a lot of advanced features (eg implicits, macros) and internal complexity. The features can be great when used in the right hands, but they have the potential to be abused. With great potential comes a little bit of abuse and a lot of haterz.
did i miss something or why is there mentioned a new version of React Native?
Remotely is impressive, removing the RPC latency tax makes microservices in Scala a lot more appealing. Doobie, not so much. String-ly typed query DSLs are the dinosaurs of the present. It's amusing to see attempts at monadic [conditional chaining](https://gist.github.com/kryptt/b2f7ef6719a252dd316c) based on Strings, mixed in with a pure FP model no less ;-) Type safe query DSLs featuring monadic query composition, automatic prepared statement generation (no keeping track of `?,?,?,?,?`), record marshelling (no having to manually specify the query result type as in Doobious), session/transaction management, etc. are the future, Strings be gone. I have yet to see, BTW, any knockout evidence that pure FP in Scala is the one true way. If one `grep`s through the most popular Scala projects there are a surprising number of vars, while loops, mutable maps, etc. Simply favoring immutable constructs over their mutable counterparts and making use of native FP based language features (like flatMap,map,fold,etc.) goes a long way; those are pretty much the only idiomatic elements common to Scala code bases in the wild. Cleaning up the language itself is of course the only thing everyone agrees on, its creator included...
&gt; at some point we have to generate SQL Sure, but that's the job the query compiler (i.e. the DSL). With Doobie (from a brief run through the docs) you have to *manually* [specify the result type](https://github.com/tpolecat/doobie/blob/master/example/src/main/scala/example/FirstExample.scala#L96), and manually type out/keep track of [prepared statement `?` placeholders](https://github.com/tpolecat/doobie/blob/master/example/src/main/scala/example/FirstExample.scala#L99). Basically there are *zero* composition opportunities available with String-ly typed DSLs, as evidenced by the `QueryFragment` attempt link in my first reply. That's the irony, pure FP, but with non-composable Strings ;-) Anyway, it's a side project, can't compare it to projects where developer(s) do nothing but work full-time on that one thing. As a low-level JDBC-like library, it looks decent enough, I'm just very partial to monadic query DSLs these days (Slick and Esqueleto in Haskell land leading the pack AFAICT).
Play was doing pretty nicely in the past in this benchmark (compared to Rails and Django, not compared to raw servlets or C / C++ web frameworks of course) However in this one, Play seems to have failed on all tests. Can anyone from TypeSafe / the community who knows Play well please contact them and see if this can be fixed / redone? this doesn't shed a good light on the Scala toolchain... and Play is one of my favorite frameoworks... Here are the log results: https://github.com/TechEmpower/TFB-Round-10/blob/master/peak/linux/results-2015-03-24-peak-final/latest/logs/play2-scala-anorm-linux/err.txt I'm looking for the test sources themselves... **EDIT**: here are the sources, can you spot any configuration issue? (In previous rounds it worked well, I wonder what's the issue) https://github.com/TechEmpower/FrameworkBenchmarks/tree/master/frameworks/Scala/play2-scala
Edit, play 2.4 master branch's NettyServer.scala has changed compared to the play version in Benchmark; updated the link Looks like it's an [issue with Netty](https://github.com/playframework/playframework/blob/2.2.x/framework/src/play/src/main/scala/play/core/server/NettyServer.scala#L295), not sure why it's happening though, might be ~~no https port set~~ the TE guys need to set `-Dhttp.address` on startup, binds to `0.0.0.0` by default.
You make it sound as if I haven't explained elsewhere, when I have, at the appropriate length—a paragraph or two. The process is a lot like Hamiltonian mechanics: there are only a few equations to know, but the implications are vast. Pure total FP is the same: you can define it in a paragraph, but the implications are vast. What I'm learning is that some people will explore the implications while other won't, and that's the part I have little control over. As for "obvious," you quoted: &gt; It just means it's reasonable to do, and the benefits are obvious. But somehow left out: &gt; I don't mean they're necessarily obvious before you do it—if that were true, presumably everyone would be doing it. I mean having done it, they're obvious. That's called "blatant intellectual dishonesty" and "arguing in bad faith," which I don't tolerate. So we're done here.
This needs all the upvotes. If anybody ever nullifies an option, or makes the contents of an option null, they should probably be burned alive. That has to be a deliberate decision to attempt to screw something up. Unless this is typical with Java interop? EDIT: Oh wait, no. If doing java interop with something that might return null, you just use Option(potentiallyNullValue)
type binding and scope binding, despite both having the word binding in their name are unrelated concepts. Why is it that you ask about all of these things at once? What do you know about them, and what part of them are you failing to understand?
I still don't know what its for.
From what I've seen it's basically a platform to distribute your (micro)services + goodies like load balancing, monitoring, on-demand provisioning. They also ship a set of tools to ease deployment (called bundles in ConductR terminology) and auto-discovery (think Zookeeper). http://www.typesafe.com/products/conductr#features
This seems to be missing one chapter: Scala-JS and how isomorphism is possible with Scala.
Is the article worth reading if they can't even find Scala's right logo?
I love Scala. My only real gripe with it is that it is not "Unixy" in the sense it relies on the JVM. On the other hand, the JVM gets you so much functionality that it's a fair trade. I would be interested in a native Scala with better interoperability with Unix primitives. With that, I could write more low level code with Scala when necessary.
I think I tried to make a "hello, world" style thing in Scala.js, and I seem to recall it generating an ungodly amount of JS. I seemed like it converted everything in Predef to JS. Probably not a big issue if you're building a very JS-heavy app, but not necessarily great if you just want to share some server-side validation code with the client.
That can be misleading though. It may be large for a hello world, but does that size continue to scale up for a a large app at a constant or greater rate or is it just a flat, one time cost? I don't know the answer to that, but that answer is what's important. 
Yeah, that was what I meant by "if you're building a very JS-heavy app". I was thinking of the difference between a large SPA - where it's probably worth a few hundred KB of JS considering all the whiz-bang stuff you do - and a simple app that just wanted to recycle a little server code on the client. But i also didn't realize that production builds further trimmed the fat.
Thank you.
In this case, cringe-worthy abuse of terminology indicating that client and server are programmed in the same language. Otherwise, [this](http://en.wikipedia.org/wiki/Isomorphism).
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Isomorphism**](https://en.wikipedia.org/wiki/Isomorphism): [](#sfw) --- &gt;In [mathematics](https://en.wikipedia.org/wiki/Mathematics), an __isomorphism__ (from the [Ancient Greek](https://en.wikipedia.org/wiki/Ancient_Greek): [ἴσος](https://en.wikipedia.org//en.wiktionary.org/wiki/%E1%BC%B4%CF%83%CE%BF%CF%82) *isos* "equal", and [μορφή](https://en.wikipedia.org//en.wiktionary.org/wiki/%CE%BC%CE%BF%CF%81%CF%86%CE%AE) *morphe* "shape") is a [homomorphism](https://en.wikipedia.org/wiki/Homomorphism) (or more generally a [morphism](https://en.wikipedia.org/wiki/Morphism)) that admits an inverse. Two [mathematical objects](https://en.wikipedia.org/wiki/Mathematical_object) are __isomorphic__ if an isomorphism exists between them. An *[automorphism](https://en.wikipedia.org/wiki/Automorphism)* is an isomorphism whose source and target coincide. The interest of isomorphisms lies in the fact that two isomorphic objects cannot be distinguished by using only the properties used to define morphisms; thus isomorphic objects may be considered the same as long as one considers only these properties and their consequences. &gt;==== &gt;[**Image from article**](https://i.imgur.com/1HUW3cK.png) [^(i)](https://commons.wikimedia.org/wiki/File:One5Root.svg) --- ^Interesting: [^Isomorphism ^theorem](https://en.wikipedia.org/wiki/Isomorphism_theorem) ^| [^Graph ^isomorphism](https://en.wikipedia.org/wiki/Graph_isomorphism) ^| [^Isomorphism ^class](https://en.wikipedia.org/wiki/Isomorphism_class) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqlv87e) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqlv87e)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
&gt;doughnoids in the category of pretzelmorphisms
Blog author here, great point, and that is a valid concern I didn't address. There is a large group of webapps that aren't computationally heavy, or at least, the computation can be pushed to the database layer. I didn't touch on where the computation is more in the backend server itself, when that is the case, Scala would provide a big benefit here.
Thank you for raising this point, we just fixed the logo!
Great blog series. Any ETA on the Essential Interpreters book? It's a very interesting topic of functional design, but right now the main learning resource (outside of this blog) that I can find on using it in the large is the [reasonably priced monads](https://www.parleys.com/tutorial/composable-application-architecture-reasonably-priced-monads) talk.
If the API you're dealing with is Map[String, Any], then you're forced to live in a dynamically typed world. I dont have experience working with Any, but I'd assume you can use isInstanceOf and asInstanceOf to narrow the type. But that is inherently brittle in the same way any dynamically typed system is brittle. Just treat it like the dirty outside world like you'd treat any sort of IO and interop. Coerce it into a nice typed total system and fail fast if your assumptions aren't met. Also, if the doubles always come in as singleton Buffers, you can always cast it to Buffer[Double] and pull the head out
You know, among the set of things I tried was to wrap this with a case class with a field of type Seq[Double]. But I didn't try to coerce it with asInstanceOf[Seq[Double]]. That works. Thanks! 
&gt; Some people from functional programming backgrounds, Haskell mostly, who see Scala as a "lesser haskell" and wonder why on earth would anyone touch something so impure. &gt; Scala vs Haskell - it can do mostly what Haskell does (with some libraries such as Scalaz / Shapeless etc...), but with wider toolset, Java interop, and Most of the dislike I've seen from Haskell-niks isn't that "why on earth do you want to do impure stuff", it's that Scala honestly doesn't handle the pure stuff as well as Haskell does. For example, Scala can only optimize simple tail-recursion instead of general tail-call-optimization. Consequently, [a lot of naive implementations of common functional idioms end up smashing the stack. There's been a bunch of work on fixing that with e.g. trampolines](http://blog.higher-order.com/assets/trampolines.pdf). A lack of purity and laziness also means that various optimizations that are present in Haskell (and can even be written in Haskell *libraries*) are simply impossible to implement in Scala. While you can write lazy scala code, people mostly don't write lazy enough Scala to take advantage of all of the benefits. For example, in Haskell, quickselect k = take k . quicksort is asymptotically optimal - you'll only end up fully sorting the part of the list you actually use. Additionally, not long ago, the syntax for partially applying higher order types was simply horrendous. Instead of saying something simple like instance Functor (State s) where ... You'd say something like implicit def stateFunctor : Functor[({type state[A]=State[S,A]})#state] = ... Additionally, type inference is far better in Haskell than Scala. [Then there's the whole thing about typeclasses vs implicits](http://www.reddit.com/r/haskell/comments/2w4ctt/boston_haskell_edward_kmett_type_classes_vs_the/). Basically, Scala really is a better Java and a worse Haskell. Sometimes that's the right tradeoff for a Haskell-nik (in particular, if you have a Java library you need to use), but it often isn't.
Free monads do compose in the sense that is usually talked about when people say that monads don't compose (namely, in the sense of bring closed under coproducts (the categorical concept, not the type)).
Quite right—I didn't intend my comment as criticism, but should have made that clear.
[This talk](https://www.parleys.com/tutorial/composable-application-architecture-reasonably-priced-monads) is a good motivation. [(slides)](https://dl.dropboxusercontent.com/u/4588997/ReasonablyPriced.pdf)
It looks like the article is truncated or something. I only see two paragraphs, and they don't cover Manifests or erasure at all.
The previous post introduces and motivates the free monad: http://underscore.io/blog/posts/2015/04/14/free-monads-are-simple.html
I use Play Framework since my APIs don't really need extreme performance, but there's [spray](http://spray.io/), which is made for creating REST interfaces on top of Akka and has [extreme performance](http://spray.io/blog/2013-05-24-benchmarking-spray/). spray sounds like what you're looking for. If you're also planning to do "normal" web development, definitely have a look at Play Framework.
Thanks! 
Thanks for working this all out! I appreciate this effort. Here's what I'm seeing. The nested document looks like: Buffer(Map("thing_id" -&gt; 1, "other_number" -&gt; 1111), Map("thing_id -&gt; 100, "other_number" -&gt; 33333), ...) When I apply .asInstanceOf[Seq[Map[String, Int]] the compiler is happy. I have access to the apply() method, it seems, since I can take that and do, say, nested(0).get("thing_id") and get back 1. But I can't map over nested, like nested.map(r =&gt; r.get("thing_id") It give me: Exception in thread "main" java.lang.ClassCastException: scala.collection.mutable.HashMap cannot be cast to scala.collection.immutable.Map Which I find really befuddling. 
The `Map` thats in scope by default in scala is an scala.collection.**immutable**.Map. What you have is a scala.collection.**mutable**.HashMap, which is a subclass of scala.collection.**mutable**.Map. Both immutable.Map and mutable.Map are subclasses of scala.collection.Map. So you can import `scala.collection._` or `scala.collection.mutable._`, or qualify your use of Map, ie: import scala.collection.mutable //Important: no wildcard import val m1 = Map("abc" -&gt; 123) //This is an immutable map. val m2 = mutable.Map("abc" -&gt; 123) //This one is mutable. It's generally good considered good etiquette to qualify uses of mutable collections like above, because mutable collections are undesired for many individuals. But if doing a wildcard import on `scala.collection.mutable._` makes more sense in your scope, don't hesitate to do so.
I should also add that using `asInstanceOf` should be avoided. The reasons for this should be apparent to you because of the class cast exceptions you're getting because of it. `asInstanceOf` has no safe application, it's a get out of jail free card for the type system. You can for example: val seven = 7L.asInstanceOf[String] and this will compile even though a Long could obviously never simultaneously be a String. Patter matching can perform type tests on values in a much more readable way that using `asInstanceOf` and `isInstanceOf`. though a statically verifiable approach would be preferred over both casting and pattern matching, at the moment you must work with what elastic search gives you, given that it returns poorly typed values.
Fantastic! Thanks a ton. Now I'm curious why I'm being given this mutable.HashMap instead of the standard immutable.Map. I suppose it must have something to do with the way Spark is building up the retrieved ElasticSearch documents. Thanks for your help. You've made my day. 
Yeah, I'm not thrilled by all this type casting. Your point is well-taken. Now that I know the types I need to be working with, I'll attempt to do this with pattern matching instead of asInstanceOf
It's most likely because of the conversion from `java.util.Map` which is mutable, as evidenced by your first error when you got class cast exception from `scala.collection.convert.Wrappers$JListWrapper`; the mutable scala wrapper around java collections.
Had EXACTLY the same problem. We ended converting Map[String, Any] to Map[String, Property], (with some nice implicit conversions). Property is a custom class we wrote that has all the conversions in it (it keeps the string representation of the value, the value, the type of the value and a converter to turn it back) I'm going to ask at work if they'll let me post it as a gist, but it's pretty straight forward. Lot's of code in the Property class but in the end I have a method like foo.as[Double] (that uses a class tag) and does a conversion to the value desired (if the actualy value of Any and the runtime class of the type parameter passed to "as" is the same, it's just doing a cast) p.s. as others have said the class cast exception that you get as others have said is becuase you are casting a collection of doubles (with one value) to a double, no can do. Just take the first value of that Buffer and cast it
Hey, you mentioned DDD so take a look on Functional and Reactive Domain Modeling book that it's been written by Debash Gosh. http://www.manning.com/ghosh2/
That's great news. The first time around, some of the early assignments especially were pretty bad. I may give it another try, in light of the changes you mentioned.
It's pretty interesting. The only concern I (and others) have is that there's only one week to do each assignment, because the schedule is tied to that of the EPFL students who're taking the course concurrently. One week to watch all the videos, absorb all the concepts, and then do the assignment is rather on the low side if you're working full-time.
From experience you need more than one Scala/FP evangelist on the team and I'd now hire on the fact you have an interest/used FP over you are a Java developer using Scala as Java++. If people see it as Java++ they have a constant battle, comparing it to Java, seeing FP or Scalaz as to complex etc rather than looking at it as a new separate language with a new set of design patterns that can be used. Granted the barrier of entry to FP is higher due to the lack of good books compared to other languages out there, for some and myself included switch off when pointed to a paper on category theory without real world application examples in code. For one person it's plain hard work as an evangelist even in a small new team of 4-5 people recruited specifically on using Scala as a core project language. A new inexperienced team everyone is unsure of what they are doing and have there own biases. Everyone is in brain overload absorbing in new information wanting to use all the new tools in the toolbox. It's chaos, multiple advocates help resolve this as you have support in numbers. A team of one expert/experienced Scala dev, you may be right but if the other 4-5 people unsure and struggling to get it there's big issues. Rightly so management ask questions if the majority of the team say it's hard, even if hired in specifically to work on Scala when they have no/little direct experience; Some lessons learnt here. Of course it all depends on the strength of a team. I had a bad experience starting out building a Scala team when the 2nd evangelist left and the business brought in new internal members elsewhere with a we need to fill seats over we will keep the bar high and hold out for the right person. Originally Scala and choices made where chosen to throw out the existing constraints and 'this is how we do it' mantra while bringing people in to fill seats brought the baggage we originally threw out back. On the other side after moving on and joining a much stronger dev team in the same org the experience was much more successful. Again moving on to another company who set a very high bar and recruited on high FP interest over you are a Java dev the experience has been exceptional and on boarding new members is easy to bring up to speed as the culture is to be an evangelist. I remember one of Rod Johnson's Scaladays key note and I think it holds true, good developers will be hugely productive with Scala while mediocre will struggle. I think it's true for a lot of company's, a small number of people hold things together and the rest are there to fill a seats. If your company fills seats Scala is harder than other languages due to it's size.
They doubled the time available.
I like Finch (https://github.com/finagle/finch) for this, it's a thin layer on Twitter's Finagle. I prefer it over full stack frameworks like Play for REST API's. The other one is Spray as already mentioned which is great but my preference at the moment is Finch.
So many classes, so little time. 
Not sure I follow: you're a group of people and you want to be hired as a team but allowed to work remotely? Even in mainstream languages, this would be a pretty difficult gig to find. Why don't you all just try to find a job as individuals? 
Great comment. I 100% agree with just about everything you've written, and it matches my experience helping a number of companies transition to Scala. If you're going to use Scala you need to change development practices. If you're just writing Java-without-semicolons you won't see any benefit, or even regress due to a mish-mash of programming styles. Following this I've never understood why many companies emphasise Java experience over a demonstrated interest in programming in their hiring. I wrote some thoughts about hiring here: http://underscore.io/blog/posts/2014/05/02/hiring-scala-developers.html
Many of the people who apparently dislike Scala are actually [Cedric Beust sock-puppets](http://www.reddit.com/r/scala/comments/25kwb1/cedric_beust_continues_to_troll_rscala_and_hacker/).
Well, a few upvotes and no replies must mean some other people are trying to figure this out as well. I'm currently tracing through the migration guides to update some of it, and I'll see how far that gets me. I'll post gists as I get things working.
they started using haskell this year?
Ah ok, all this talk of improvement that's why I assumed. Thanks for clarifying!
I edited my original post to state my intentions more clearly. Thanks for helping me see I hadn't said what I'd meant to say.
Nice, looks like a good example.
What an artful ambush :) 
:)
The problem is extremely well suited to a non-recursive approach, which is likely to be both a lot faster and at least as readable, IMHO. I know this is "old-school", but sometimes that's what's called for. Untested. def reverse(node:Node) = { var reversed = Node(node.value, None) var cursor = node while ( cursor.next isDefined ) { cursor = cursor.next.get reversed = Node(cursor.value, Some(reversed)) } reversed } 
I suppose it depends on the job. If it's your usual app development then I would favour asking questions that demonstrate a firm understanding of the standard library and scala language features. For more advanced concepts like tail recursion (IMO), I would ask what tail recursion is rather than have them program something on the spot in a contrived interview setting.
&gt; The main issue I came across was the EventHandler logging system from Akka 1.3.1 is no longer present in Akka 2.3.9 In 2.3 you mix in the `ActorLogging trait into your actor to log messages instead. The ActorLogging trait provides a single method `log` which provides you access to logging methods. class MyActor extends Actor with ActorLogging { def receive = { case "pigdog" =&gt; log.info("We've got yet another pigdog on our hands") } } You will have to choose a [logging backend](http://doc.akka.io/docs/akka/2.3.9/scala/logging.html)(usually SLF4J or JULI) in your application.conf. &gt; Also remote is no longer in use as part of the akka.actor package. Do you have a more specific question about remote actors? [Deployment](http://doc.akka.io/docs/akka/2.3.9/scala/remoting.html#Programmatic_Remote_Deployment) of remote actor services is typically done with the actor's `Props` object on construction instead of with it's prestart method like in the example. Also, the `ChatManagementActor` uses a Map[String,Actor] to track the lifecycle of actors participating in the Chat session. Instead this actor could use the [watch](http://doc.akka.io/docs/akka/2.3.9/java/lambda-actors.html#Lifecycle_Monitoring_aka_DeathWatch) method manage the lifecycle of session actors. 
"I doubt the interviewer are interested in your knowledge of the standard library" That's a really unsafe assumption. If you don't know the standard library, you don't truly know the language. This applies to any language. I'd question the legitimacy of any interviewer who thought differently. Granted, I do understand the question specified a non-standard data structure, but if we're talking about 'real job interviews', mentioning standard library functions, like 'reversed' are worth mentioning, even if they don't apply. Additionally, more than a handful of times, interviewers have accepted 'I could use library X to solve this...'. If they wanted you to rebuild the wheel, I'd assume they'd explicitly say so.
For-comprehensions are definitely one of the language's best features. Understanding how to use them properly also helped me finally grok some of the things going on in Haskell, since a for-comprehension is essentially equivalent to the do-notation..
Yeah, they announced it right about the time I posted this question. :)
Glad that you find the post interesting!
I'd assume so.
You are right, it seems to be an official Typesafe project (although not commercially supported for the moment). But in this case it would really be nice if they could orient on the standard layout for cross building projects (mixing Scala.js and Scala.JVM): &lt;project root&gt; +- jvm | +- src/main/scala +- js | +- src/main/scala +- shared +- src/main/scala as documented in the [documentation](http://www.scala-js.org/doc/sbt/cross-building.html) for the Scala.JS sbt plug-in. Would making it easier to understand the build process. 
I recently gave Slick 3.0.0-RC3 a try and despite it's impressiveness I ended up going with ScalikeJDBC for two reasons. First, ScalikeJDBC is more about getting things done and though not as "elegant" it's learning curve is not nearly as steep as Slick's. Second, my application needed "for update" record locking support (don't ask) which is currently missing from Slick (see [issue #974](https://github.com/slick/slick/pull/974)).
a little OT but: what's bad regarding 'for update' locks?
You usually need them, when you have concurrency issues in the database and transactions are not anymore isolated in the way you expected. Usually these are ugly issues that are hard to reproduce and cannot be easily debugged.
Ooh, thanks :)
hi, msg me if you want.
although xml is pretty bad, i found write scala for layout is also pretty painful. working with scala + xml works, but scala standard library code will make your app start time much longer. so no scala now.
Why do you need to work with xml ? Have you tried [macroid](https://github.com/macroid/macroid) or [scaloid](https://github.com/pocorall/scaloid) ?
That is a very good question. I'd like to hear the answer.
okay thanks - I was just going off this information from scala-lang.org. It doesn't sound like comprehensive support is available in 2.11.x from the description provided here. http://scala-lang.org/news/2.11.1 "The Scala 2.11.x series targets Java 6, with (evolving) experimental support for Java 8. In 2.11.1, Java 8 support is mostly limited to reading Java 8 bytecode and parsing Java 8 source. Stay tuned for more complete (experimental) Java 8 support. The next major release, 2.12, will most likely target Java 8 by default." 
I'll join you for coffee... If you're paying for the flights! ;-) I'm a new scala on android dev. In short: Android Studio, gradle build, macroid for a thin scala API over Android, no XML layouts. Msg me for more info.
Flying you in to Berlin would slightly exceed my coffee budget, but I'd still like to talk to you. Especially since you chose a stack that I completely avoided in my projects. Would you be available for an interview next week?
I couldn't get scala working with java 8 so if someone has a tutorial with exact versions that would be good. 
this is the right answer!
I prefer Scala over Java, but it was too much of a headache for me to get a good Scala workflow going for Android dev. The benefits of Scala just weren't worth the headache for me. [Functional Java](http://www.functionaljava.org/) is an interesting compromise I've been investigating recently..
I'm not currently doing any Android development, but there are a couple things I'd point out. When I was looking into it, the tooling wasn't very mature. With considerable effort I did get a "hello world" running, but didn't pursue it further. But, even then, one of the hardest things was sifting through Google results trying to figure out what information was outdated and what wasn't. Also, on the android projects I've worked on, getting it done was worth far more than getting it done right.
something like half a second on a Nexus 5.... this is unacceptable~
Same here except for on the server side of the spectrum (Bukkit plugins).
Attempted to build a toy blogging engine. Bought into the "seamless interoperability with Java" propaganda and tried using a couple of Java libraries directly. It was painful. Ceased learning Scala after a few weeks. If I could go back in time I would wrap those Java libraries in Scala façades. Fast forward a few years and I got a Scala development job. I'm learning as I go. It's not as painful as I remember.
I would love to see more Scala in the TechEmpower benchmarks. https://www.techempower.com/benchmarks/#section=data-r10&amp;hw=peak&amp;test=fortune&amp;l=6bk is really lacking in scala frameworks. Where is unfiltered? Where is spray? Play is failing. Lift only has very select test (and is really slow compared to the rest). Finagle only does JSON serialization. For frameworks we have * Unfiltered * Spray * Play * Lift * Finagle * Scalatra For ORMs there are * Slick * Doobie * Anorm * (raw) For JSON serialization there is a ton, at least * Argonaut * Spray JSON * Jerkson * Json4s That means we could have 6 frameworks * 4 ORMs * 4 Json backends = 96 scala entries rather than the handful we have now. And then there is also the option of using different actual database backends (H2, Postgress, MySQL, some NoSQL solutions even). That might give interesting and possibly insightful results
In addition to what others have mentioned (Odersky's book, a lot of time with the REPL), I highly recommend [Scala for the Impatient](http://www.horstmann.com/scala/index.html) and [Functional Programming in Scala](http://www.manning.com/bjarnason/). The latter has some great exercises that are well-worth working through. Also, either contributing to an open source project, or simply working through one in depth-- reading through the code, paying attention to the project structure, its build setup and dependencies, etc.
The [Typesafe Activator](https://www.typesafe.com/get-started) also has some useful project templates and tutorials that might help you get started (especially with Play/Scala).
I just dove right into it. Scala was a curiosity at work, where we had our own Java grammer parser that parsed XML literals inside Java. Scala's xml literals looked to be much better implemented, much less costly on build times (for as slow as the scala compiler was, ANTLR was even slower). So I worked Scala into our build system(which was rather unorthodox at the time) and started writing right away. Eventually I bothered to look at scala-lang.org and learned something.
Hello, I have written and released a real world app in Scala to test-drive it on Android : https://play.google.com/store/apps/details?id=com.alexd.carfinder The app works well, but is not really popular due to the saturation of Carfinder apps ;) I am using this great SBT plugin : https://github.com/pfn/android-sdk-plugin The toolchain lacks a bit maturity (you sometimes have to fully recompile to avoid cache issue) and compilation can be slower than java due to proguard phase. However it is fully usable and getting better each released, and incremental compilation improve compilation time most of times. Scala can make the Android API much easier and reliable to use and reuse, thanks to the functional programming and traits especially. As mentioned in an other comment Functional Java + [Bolts](https://github.com/BoltsFramework/Bolts-Android) can be a good alternative for projects where using Scala is not possible, but you want some functional goodness.
This is it. I've been running Scala 2.11 code on a Java 8 JVM for a long time. 
You can make: * compile-time checking of units of measure: https://github.com/KarolS/units * type-safe heterogenous lists and first-class polymorphic functions: https://github.com/milessabin/shapeless and so on.
Got it in one.
So you would say Haskell is a smaller language than Scala? I'm interested in learning it, but haven't looked much at it yet.
Thanks! What would you say about Haskell's learning curve, coming from Scala? Is the syntax the biggest step?
Yeah, cake was a big failure where I worked too. Its just too wordy for what you get out of it. I prefer old school dependency injection, passing objects into other objects. Stackable traits on the other hand are glorious. I miss them in all other languages now. 
I guess I shouldn't be surprised, but at least Scala supports null. You might end up with Java-flavored Scala, but at least you can make it work. The case I was thinking of was that Scala classes can only have one primary constructor, which all auxiliary constructors must ultimately call. Java has no such requirement, so things get a little weird when you try to extend a Scala class from a Java class and you need to call different base class constructors in different situations. 
That was poorly said on my part. What I meant was that while both are Turing complete at runtime, Scala is also Turing complete at compile-time.
I don't know if you have read Functional Programming in Scala but it focuses a lot on the functional aspects of Scala rather than the language itself. This sounds like a better alternative than learning Haskell or Erlang (nothing against these languages though). What I took away from your story is to focus more on the micro concepts of Scala rather than getting confused with a bunch of ideas at once.
I picked up a bit of Scala on my own, then I took the Coursera course [Functional Programming Principles in Scala](https://www.coursera.org/course/progfun). The course nearly killed me; I found it quite hard. But my way of thinking about code was changed by it. I have rewritten some of my old Java code in Scala. When I look at this code now it seems to be much clearer then the Java equivalent. I have also learnt a bit about Play. I plan now on learning [Slick](http://slick.typesafe.com/news/2015/04/29/slick-3.0.0-released.html).
 OK, I understood it before.
functional web framework like ocsigen (ocaml) handle state using continuation (see https://en.wikipedia.org/wiki/Continuation).
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Continuation**](https://en.wikipedia.org/wiki/Continuation): [](#sfw) --- &gt;In [computer science](https://en.wikipedia.org/wiki/Computer_science) and [computer programming](https://en.wikipedia.org/wiki/Computer_programming), a __continuation__ is an [abstract representation](https://en.wikipedia.org/wiki/Abstraction_(computer_science\)) of the [control state](https://en.wikipedia.org/wiki/Control_flow) of a [computer program](https://en.wikipedia.org/wiki/Computer_program). A continuation [reifies](https://en.wikipedia.org/wiki/Reification_(computer_science\)) the program control state, i.e. the continuation is a data structure that represents the computational process at a given point in the process's execution; the created data structure can be accessed by the programming language, instead of being hidden in the [runtime environment](https://en.wikipedia.org/wiki/Run-time_system). Continuations are useful for encoding other control mechanisms in programming languages such as [exceptions](https://en.wikipedia.org/wiki/Exception_handling), [generators](https://en.wikipedia.org/wiki/Generator_(computer_science\)), [coroutines](https://en.wikipedia.org/wiki/Coroutine), and so on. &gt; --- ^Interesting: [^Continuation ^high ^school](https://en.wikipedia.org/wiki/Continuation_high_school) ^| [^Analytic ^continuation](https://en.wikipedia.org/wiki/Analytic_continuation) ^| [^Upward ^continuation](https://en.wikipedia.org/wiki/Upward_continuation) ^| [^Continuing ^patent ^application](https://en.wikipedia.org/wiki/Continuing_patent_application) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cqvvwbe) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cqvvwbe)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
I suggest checking out references to Data-Oriented Design, which focuses on layout and transformations of data rather than domain modeling. Find stuff by Noel Llopis, Mike Acton and the Insomniac tech blog, possibly http://www.dataorienteddesign.com/dodmain/ to get started. Warning, it can be challenging because of its hardcore focus on raw performance.
I posted this on StackOverflow hoping for an answer, especially after the edit. I've only got an unsure answer at the moment. Hopefully someone here can explain in more detail. Thanks!
Likewise took the Coursera Functional Programming Principles in Scala which also changed my approach to writing code for the better. Also found the course challenging especially as it was really my first exposure to OOP - classes and the like but it was well worth the pain. How is learning Slick going? What resources are you using to learn it?
Isn't Haskell and F#'s type inferencing system more powerful?
 Who mentioned type inference? And why is that a big gotcha?
I misread. And its not. 
Any is a supertype of T &gt;: MouseEvent &lt;: Event. So a function Any =&gt; Unit can be used in place of a function T =&gt; Unit thanks to functions' contravariance. But a function of MouseDragEvent =&gt; Unit cannot be used in place of T =&gt; Unit because MouseDragEvent MouseEvent so that doesn't work due to contravariance. 
Right, but then doesn't it need to resolve the actual type of `T` at some point, because of the need to instantiate the `EventHandler`? Does it simply pick the greatest lower bound when it does so, since it cannot infer such information from the lambda?
Yes I'm fairly sure it would choose Event as T.
Can you clarify the exact type relationship between Event, Mouse, and MouseDragEvent? Trying out this small example in the REPL doesn't compile like yours: Welcome to Scala version 2.11.6 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_45). Type in expressions to have them evaluated. Type :help for more information. scala&gt; trait Foo defined trait Foo scala&gt; trait Bar extends Foo defined trait Bar scala&gt; trait Baz extends Bar defined trait Baz scala&gt; def barlike[T &gt;: Bar &lt;: Foo](lambda: T =&gt; Unit) = {} barlike: [T &gt;: Bar &lt;: Foo](lambda: T =&gt; Unit)Unit scala&gt; barlike[Nothing] _ &lt;console&gt;:11: error: type arguments [Nothing] do not conform to method barlike's type parameter bounds [T &gt;: Bar &lt;: Foo] barlike[Nothing] _ ^ scala&gt; barlike[Any] &lt;console&gt;:11: error: type arguments [Any] do not conform to method barlike's type parameter bounds [T &gt;: Bar &lt;: Foo] barlike[Any] ^ scala&gt; barlike[Foo] _ res3: (Foo =&gt; Unit) =&gt; Unit = &lt;function1&gt;
This is actually from ScalaFX, which I'm working on a pull request so that I can do lambda assignment. The full relationship is MouseDragEvent &lt;: MouseEvent &lt;: InputEvent &lt;: Event 
Also I don't think it *matters* what type T gets resolved to because Any =&gt; Unit will be a valid type to be passed in regardless. But contravariance will most likely cause it to be resolved to the upper bound. A covariant example would be def f[T &gt;: MouseEvent &lt;: Event](xs: List[T]) = ??? If you pass in Nil (which is a List[Nothing]) it compiles due to covariance. And I'm guessing the type would be as pessimistic as possible and resolve to MouseEvent, but once again it doesn't really matter it works no matter what. 
I agree it doesn't really matter since it works, I was just mostly confused as to why it works and how it works. It's the sort of feeling that "Wait, this shouldn't work, but it does". And then you get caught up in trying to figure it out.
Don't pass _system as a constructor parameter, create it - you can't have parameters as ScalaTest doesn't know how to fill them in. Someone had a similar problem on StackOverflow last year - [see this question](https://stackoverflow.com/questions/25390986/scala-simple-funsuite-unit-test-with-akka-actors-fails).
This no-argument constructor allowed ScalaTest to construct MediaFileUpdaterTest: &gt; def this() = this(ActorSystem("MediaFileUpdaterTest")) If you post the error message for the "mock classes" problem, we may be able to help here as well: &gt; the FolderUpdaterDeligateTest also required me to move the mock classes into the companion object in order to work. MediaFolderUpdaterTest didn't. 
I'd be curious what you think of [SDBC](https://github.com/wdacom/sdbc), which has a [SelectForUpdate](https://github.com/wdacom/sdbc#update-rows-in-a-result-set).
You could remove the Disjunctions from your AST and compile your algebra to ```\/[_]``` instead of ```Id[_]``` maybe? Your DSL could then focus on the happy path and you can push errors elsewhere. You would still nicely fail fast too. Then when you want to compose it with other Free algebras, you can still use the other ones' ```Id[_]``` interpreter ```~&gt;``` but just compose it with another ```~&gt;``` that ```point```s the result to ```\/``` Also that ```\/``` with an ```Option``` on the Right doesn't seem right to me. Why not guarantee a Right value has a user and then treat the ```None``` case as another error?
Why would you compare a wrapped value to its underlying storage? Why would you compare a `UserClass` to an `Int`?
Rereading the article, I ordered the (rhetorical) argument poorly. I put in the final section, "when you refactored your code." The idea was that, you shouldn't be comparing a UserClass to an Int, but you previously used an Int instead of a value type. The assertions didn't guard against regression the way you might have assumed, because of the non-fatal warning. 
This talk should be quite useful to you: http://lanyrd.com/2015/scaladays/sdhwzt/
The title of the blog post is extremely misleading. The pitfalls of universal equality applies to all types, not just value classes. Welcome to Scala version 2.11.6 (Java HotSpot(TM) 64-Bit Server VM, Java 1.8.0_45). Type in expressions to have them evaluated. Type :help for more information. scala&gt; case class UserId(n: Int) defined class UserId scala&gt; val john = UserId(7) john: UserId = UserId(7) scala&gt; john == 7 &lt;console&gt;:11: warning: comparing values of types UserId and Int using `==' will always yield false john == 7 ^ res0: Boolean = false scala&gt; class Transaction(val id: Int) defined class Transaction scala&gt; val transaction = new Transaction(5) transaction: Transaction = Transaction@644c78d4 scala&gt; transaction == 5 &lt;console&gt;:10: warning: Transaction and Int are unrelated: they will most likely never compare equal transaction == 5 ^ res1: Boolean = false scala&gt;
Thanks for the reply! I am not having much luck with understanding your suggestions into code. Removing the disjunctions from the DSL makes sense and certainly reduces the complexity. But I'm not sure how I would go about compiling my algebra to `\/[_]` with what I have. Or... would I leave my Users.scala with the existing lift function and then lift it again to a `\/[_]` before I interpret it? Also, if I have a natural transformer for `Log` defined as `object ConsoleLogger extends (Log ~&gt; Id)` then how would I compose it to have the signature `Log ~&gt; \/`? It seems that for every step forward in wanting to learn pure FP in Scala... I get pushed back a few steps more. :)
Also scalaz tagged types to avoid value classes: http://eed3si9n.com/learning-scalaz/Tagged+type.html
I agree with this comment (except for treating `None` as an error when you can't find a user -- you can often handle this case in other ways. E.g. by creating a user.) Free monad talks and posts (my own included) go into great detail about the construction and so on of the free monad, but tend to gloss over practical issue. In my albeit limited experience I'm coming to the conclusion that the free monad itself is trivial and the real work goes into 1) deciding what you model within the free monad and what you defer to the interpreters and 2) actually writing the interpreters. If your error handling is very standardised I would follow /u/ItsNotMineISwear 's advice and not model error handling within the free monad. Of course you get an issue with the granularity of modelling -- if you can't talk about error handling within your free monad language then it becomes difficult to do non-standard error handling. As always, you need to choose the right abstraction boundaries.
This is pretty slick! Thank you! I have managed to get my program to run outside of using `Trampoline`: type Result[+A] = \/[String, A] val hallaInterpreter: Users.App ~&gt; Result = SlickUser ||: (IdToResult compose ConsoleLogger) val hallaInterpreterCoyo: Users.CoyoApp ~&gt; Result = liftCoyoLeft(hallaInterpreter) val q: Result[User] = Users.addUser("a1bc", "john", Seq("ABC")).foldMap(hallaInterpreterCoyo) I know that I need to have a `??? ~&gt; Trampoline[Result[A]]` to compose with `hallaInterpreterCoyo` to get this to work: val q: Result[User] = Users.addUser("a1bc", "john", Seq("ABC")).foldMap(Trampolined compose hallaInterpreterCoyo).run I have tried wrapping my `Result` within `Id` as `type IdResult[A] = Id[Result[A]]` or even a `type TrampolineResult = Trampoline[Result[A]]`. None of which make the compiler happy.
Does it block the caller of dosomething() until foo() completes though? 
Yes, that is correct.
Excellent! Thank you very much for taking the time to answer my questions and providing guidance with this subject. This has been a fun day of hacking!
Yes
Thanks. That's really helpful. 
Thanks. I really need to read more about Future.flatmap and other future comprehensions. 
The compiler doesn't handle the Future type specially (AFAIK). So if a function returns a future, it can't return until it has a future to return.
flatmap is just a map...and a flatten. So val list = List(1,2,3) list.map(i =&gt; List(i+1)) // returns List(List(2), List(3), List(4)) list.map(i =&gt; List(i+1)).flatten //returns List(2,3,4) list.flatMap(i =&gt; List(i+1)) //returns List(2,3,4) Same for Future, Option, Stream, Either, \/, State, etc. 
I understand what Seq.flatmap does, but Future.flatmap seems to be more complicated. 
A simple way to perform typesafe equals without say going the scalaz route is to use something like this: implicit class StricterEqualsA[A](val a: A) extends AnyVal { def =:=(aa: A): Boolean = a == aa def =/=(aa: A): Boolean = !(a == aa) } UserId(1) =:= 1 //doesnt compile
By 'switched' I mean 'started using it for my next Scala project'. Should be in production later this month, though it's pretty trivial, db-wise. Would have been interesting to rewrite the Slick thing in Doobie though, to make things a bit more interesting.
What's wrong with the documentation for the sillhouette project? They even provide a [working example project](https://github.com/merle-/silhouette-rest-seed) to learn from. 
Used it for a new project, first a small side-project, then a much larger system. Read the first 2/3 of the Odersky book.
Do you have a scala framework? May influence the best choice.
SecureSocial's documentation is a version behind its current implementation, but the examples show a 100% working version that will suit most projects.
Did you explore Anorm at all? 
The fact that the current type must be expressed in such an obscure way is troubling. Can this be fixed (made simple) in the language? As I get deeper into Scala I am reminded more and more of C++ templates and the obscure idioms there that arose to do simple things that the language couldn't deal with simply.
There was a [thread](http://www.reddit.com/r/scala/comments/2ulxvq/expressing_a_f_bounded_type_as_abstract_type/coa8j52) about this a while ago here in /r/scala , can enforce the constraint by using the self type as an upper bound.
As the article says, just use a type class and forget about all this OO machinery. That said, this machinery serves a purpose, and it is better that is provided in composable pieces (self types and F-bound polymorphism) than in a monolithic lump that could not be adapted to different purposes. That said, algebraic data types and type classes will cover 99% of your Scala programming needs. Honestly, I've been programming Scala for six years and I can count on zero fingers that numbers of times I've needed F-bound polymorphism or self types and it was a good idea in retrospect.
Does this work? https://github.com/yesnault/PlayStartApp
Yes, the constraint I was referring to is where in Martin's example you can assign sibling types.
flatMap is actually pretty simple, as is easy to see if we function-ize the signature: flatMap(fa: Future[a])(func: A =&gt; Future[B]): Future[B] It returns a new future that encapsulates running the first future to completion, calling a function to generate another future, and returning the result of the second future.
This is equivalent to the F-bounded case in its constraining power but is syntactically cleaner, and it's much easier to use in the `List` context discussed later in the article because the quantification is already taken care of. So in cases where the weak constraint is acceptable this does seem like a nicer encoding. I will update the article to include it when I have some free cycles.
&gt; As I get deeper into Scala I am reminded more and more of C++ The more you will use Scala, the more it will be apparent that Scala is to Java what C++ is to C. Powerful but with an incredible amount of baggage that seems less and less justified the deeper you get into it. The number of arcane and useless details you need to keep in mind as months go by and your language of the language increases is staggering. 
Java 8 introduced lambdas and streams. That's like kindergarten of functional languages. Been awhile since I used Scala, but off the top of my head, Java does not have (and probably will never have) these killer features: type inference, traits, pattern matching, proper higher order functions, powerful type system. 
In addition to that, Java is designed after OOP, while Scala is designed after Functional programming, taking OOP in account. Different focueses, different needs.. Even if Java implements somehow any of those features, Scala and Java futures diverge by design..
&gt; Powerful but with an incredible amount of baggage that seems less and less justified the deeper you get into it. Do you have any concrete examples of this?
Martin, if your solution had been in the article, I probably wouldn't have written the comment - it reads much better than the other options. 
I seem to recall you saying this wasn't used in the collections library because it generates cryptic compiler errors. Is that right? Could you perhaps offer an example?
I'm using Play framework for Scala, and i also now that Play framework has its own way to handle authentication. I haven't look it up yet, no reason behind tho.
Mmm.. did the examples covers all of SecureSocial's features? I don't think that is good to have the documentation outdated.
Yes, this is my preferred solution as well. However it's unfortunate that we can't restrain the self type to be a subtype of the type member to get more safety as in the type parameter case. Does the unification of type parameters and members in Dotty make this possible?
I'm not a fan of Java, but Java 8 actually has pretty good type inference for lambdas (however I hate that there is no equivalent to Scala's 'val'/'var', C#'s 'var' or C++'s 'auto', it would have been so easy to add). It also has a simple form of traits in the shape of interfaces with default methods. The other features I fully agree are non-existent. :)
&gt; Also, anyone else notice once every couple months someone with literally no post history asks some question about Scala dying? It just seems a bit suspicious. .netist and javaist FUD.
 Yes, you can but that is different.
 I'm new to Scala. Is there somebody who can show me Scala's advantages over Java?
Scala typeclasses are implemented with implicit values. Traits are not needed for that. A Java 7 interface can be used as a Scala typeclass, even.
Not quite. While Java interfaces are now allowed to have non-abstract methods, they are still unable to: * have instance initialization code * have non-static fields * have non-final fields * have methods that are `protected` or package-private * override a class method (including the methods of `Object`) Therefore, Scala traits are still more powerful.
Or an awesome tool if used well
I am afraid no. Self types can't refer to type members. So that's one area where type parameters still let you do something you can;t do with a type member. Would be nice if it was otherwise, but we run into cycles if we would allow it.
The short answer is "expressiveness". Scala has language features (for comprehensions, case classes, pattern matching) that Java lacks and that can't really be easily emulated. If you've truly never seen Scala code, you could look at the tutorials on the main page for examples; they cover the interesting features: http://docs.scala-lang.org/tutorials/
 I saw Scala code and I've been practicing with it for a few months... But I want to go deeper.
Some documentation in the README.md would be great. Just a basic Get Started.
The behaviour I saw here was a bit different, on scala 2.11.6. The last line triggered NoSuchElementException: next on empty iterator What seems to happen behind the scenes is weird, the call to s1.hasNext passes through the function passed to span, head calls next, and next throws an exception before hasNext can answer in the negative. I too would recommend takeWhile instead of span, or even take a look at scalaz-streams which should be much more sane for these things.
It's both. Like C++.
To learn Scala and Play, I created a very rudimentary CRUD app and had random people on the Scala IRC channel as well as colleagues code review it. I didn't use any books as reference, just Stack Overflow and [Scala School](https://twitter.github.io/scala_school/) Check out the crud app here: https://github.com/marinatedpork/scala_crud
Awesome, I've been using AnormCypher (even did some contributions to it). I'll definitely check this out!
 Then what would you offer? Smalltalk?
This can be done like so: val pets = List[Parapet[_]](bob, thor) val renamed = pets map (x =&gt; esquire(x)) [Full source](https://gist.github.com/paulp/970d6ca190da7949754c). 
 I think(I dare) Paul Philips has too much complaints. You can look at the [fork of Scala's compiler](https://github.com/paulp/policy) maintained by him. Looking at the [changes](https://github.com/paulp/policy) one could realize that he is mostly doing refactoring(which is useful) and one thing I don't like - *eliminated scala-reflect jar (I intend to eliminate the entire useless scala-reflect layer)*. I don't know what he want to do with Scala (I browsed the [issue](https://github.com/paulp/policy/issues) section and I couldn't find anything informal) but I know that most people's complaints against Scala are just empty words.
you ruined my argument
It's nothing at all like C++ in terms of baggage or hanging yourself. It's a very easy language to keep in your head. The rules are pretty self-contained and sensible. The only thing wonky I can think of are the implicit resolution rules, and even those aren't that bad. Hard to keep in your head, but nothing hard to resolve in your head once you know them. I've been reading through shapeless's source code frequently and it is very easy to follow, despite that library being heavily built upon implicits, type members, and the like.
Curious thing - day ago I've seen here more detailed comment - probably it was updated later :) I myself will prefer `takeWhile`, but there is a small problem with it. If I write: Iterator.continually(StdIn.readLine).takeWhile(_.head != '%') Then the last line is read and checked to stop iteration - and then is discarded and lost. I could not retrieve the value from the last line then (at least I could not invent how to do this with takeWhile). Probably I should create another question for this specific point...
I'm hoping you'll let us know once you're done...! RemindMe! 1 month "Scala on android" 
Yes! This is exactly what I was looking for! I kept my notes when I studied Slick, and I hit some 4000 words before I had to stop due to time constraints. Seems like I got mostly where you got too, but joins still are a little strange to me. I'll probably buy it, especially the Slick 3 update sounds great.
How different is Slick 3.0 compared to 2.x? Also I see there's a section on modeling Sum Types. I use them a lot to model the business domain, but it always becomes annoying to put them in the database. To be fair, we just use jooq so I have to handle everything myself (so I end up rolling my own tagged union or something). It'll be interesting to see how nice it is to model them with Slick.
That sounds much much better. 
I'll make sure to share it here to collect some feedback. Looking forward to have a beta ready in 3 to 4 weeks! Still looking for interviewees, though. Interested? :p
:-) My interview as a guy who never coded for android and was hoping to use scala for an android project- I heard about Scaloid and Macroid- neither seemed standard, the first impression of both was that they are somehow 'deficient' (I don't know how). I wish there were a framework that claims confidently that you can do everything in Scala idiomatically that you would in Java so that I don't worry about wasting time. There's nothing more to it. My search was half day and this is everything I have on the story :-)
Well, lack of any participation in the community coupled with a for profit book based on free material is somewhat eyebrow raising. Zeiger himself spent years developing the project in his spare time as FOSS. Not saying the book won't be useful to new users, it surely will, but there isn't a whole lot of original content in there that you won't find in the docs or on someone's blog.
Java 8 is a nice step in the right direction, (I think it was influenced by Scala but don't have a source) In any case, Java 8's lambdas, streams and default methods for me is just the tip of the iceberg of what I like about Scala. Wrote a little post about it: http://eranmedan.com/will-java-8-kill-scala tl;dr: yes there is a future for Scala, at least as far as I'm concerned, Java 8 only adds a fraction of the stuff I love about Scala. 
Thanks a lot! Starting to study/read through the implementation right now, very helpful!
The problem with `AnyVal` is that it includes `Boolean`, which isn't really a number. You want the `Numeric` type class: import scala.math.Numeric class Fraction[A: Numeric](val denom: A, val numer: A) // This desugars to: // class Fraction[A](val denom: A, val numer: A)(implicit ev: Numeric[A]) // To materialize `ev` in the sugared form, say `implicitly[Numeric[A]]`. 
I'm a fan of scalaz-stream's [TCP support](https://github.com/scalaz/scalaz-stream/pull/250). Basically, scalaz-stream is a very nice API for all kinds of continuous streams of stuff, and sockets make great sources and sinks for streams.
LOL command line gurus from UNIX ERA OF 1969 Bloody these guys are lying half in their graves but still they cant stop harassing us. SUCK SICK SICK PATHETIC OLDIES, DIE YOU PSYCHOS DIE.
I guess you have to write some boilerplate if you want raw sockets to work under Scala/Java. This may not be such a bad situation though. The most common thing is to use libraries, like for HTTP, or IRC, or whatever. If you really do need raw sockets, you probably also have some specific non-typical requirements. Anyway, you can start with: val socket = new java.net.Socket("duckduckgo.com", 80) socket.getInputStream socket.getOutputStream
Thanks! I'm guessing that: [A: Numeric] is just short form for: [A &lt;% Numeric[A]] But I have one last question! I've been trying to make the "+" method for two Operands to return the sum of its values through implicit conversion, for example: val c = new Operand(2) c + c //expect this to print 4 And the implicit conversion being: implicit def operandToValue[T: Numeric](op: Operand[T]): T = op.value I still have a problem because I'm guessing the Compiler assumes that the "+" in "c + c" to be an operator for strings by looking at the first "c". Thus implicitly converting the second "c" to a number doesn't fix the problem. It needs to implicitly convert both. Thus doing this works: c.value + c //outputs 4 But obviously, I feel like this makes things confusing stylistically. Any possible work around for this? Thanks a lot, I'm still a newbie to scala and functional programming in general. 
I didn't see carefully then, but FunSuite fits my needs fine. Thanks
That's a bit ott. If someones taken the time to sit down and write a book that's their choice, everyone needs to earn a living so if it's not free that's ok. It doesn't sound like anyone is taking credit for Slick, if anything a book will help people into Slick increasing it's user base if it's content is good. They've might not of had a visible presence with Slick. Not having a presence doesn't mean you are not a user or don't know it, it just means your priorities have left you concentrating in other areas. Sometimes while there are lots of blogs or docs, a concise book will stop information overload giving a structured learning plan and hopefully authoritative content which can be hit and miss with blogs.
Essential Slick in 1 word: Don't.
`[A: Numeric]` and `[A &lt;% Numeric[A]]` are completely different things. The former desugars to `(implicit ev: Numeric[A])` and the latter desugars to `(implicit ev: A =&gt; Numeric[A])`. (In formal parlance they're respectively called "context bounds" and "view bounds". View bounds are discouraged now; if you need one, the raw implicit form is recommended over the sugared form.) As for making the plus operator work with Operands, you might be better off just implementing the + method on the Operand type.
http://www.degoesconsulting.com/lambdaconf-2015/#schedule-h1
I'm using SecureSocial, it works but its difficult to get started with. For example, you want to store your authentication in the database, how do you do that? Well you need to get it from here - https://github.com/spass/spass/blob/master/modules/users/app/io/spass/users/service/slick/SlickAuthenticatorStore.scala Well that seed could be a good starting point anyway, in general I have found it difficult to use but works.
You can define neum like this def neum(a:Int): Stream[Int] = Stream.iterate(a)(a =&gt; (a*a/100)%10000) Then you can define a stream which at every position contains all values that occured before: def cumulate[T](stream: Stream[T]): Stream[Set[T]] = stream.scanLeft(Set.empty[T])(_ + _) and then find the first index where one of the previous values occurs: def repeatsAt[T](stream: Stream[T]): Int = stream.zip(cumulate(stream)).indexWhere{ case (a,prev) =&gt; prev.contains(a) } This can then be used to solve the problem: &gt; repeatsAt(neum(0001)) res5: Int = 2 &gt; repeatsAt(neum(4100)) res6: Int = 4 &gt; repeatsAt(neum(5761)) res7: Int = 88
What I hear, and see at user groups, is a lot of people strongly prefer Intelli-J. I cannot for the life of me really get used to it. Are a lot of folks here using Scala IDE?
I'd use Eclipse less if the fonts didn't look like poop on linux. That being said, IntelliJ feels more polished in basically every way to me, but it really comes down to preference. I use both. I guess the fact JetBrains made the Scala plugin available in the community version also helps.
I don't like actively use the spelling check inspections but I don't turn it off either because occasionally the squiggly has pointed out a poorly spelled word.
I always use the eclipse version. Love it! Great job guys!
In preferences you can change the fonts to any you'd like. I use Ubuntu Mono. 
I have a lot of issues with Eclipse Scala IDE using Play Framework. Imports not found, false compilation errors when everything compiles fine in SBT.
I've seldom seen Lombok and "useful" in the same sentence. It has a rather nasty side-effect of making Java code un-parsable by the Scala compiler if you ever mix Scala and Java code.
&gt; and then find the first index where one of the previous values occurs: But it seems then hte `indexWhere` will work with `O(N)` complexity instead of `O(1)` as in case with Map - isn't it? So overall complexity will degrade to `O(N^2) instead of `O(N)`...
(1 to 100) foreach (n =&gt; println(if(n % 15 == 0) "fizzbuzz" else if(n % 3 == 0) "fizz" else if(n % 5 == 0) "buzz" else n)) &gt; Meh may as well map a println on the same line ;) Yeah, edited to do just that.
Meh may as well map a println on the same line ;)
Since we're talking FizzBuzz, here's a solution I wrote earlier: https://github.com/kdrakon/FizzBuzz
`implicit object IntIsFizzyBuzzy extends FizzyBuzzy[Int]`
I pretty much only use them along with implicit conversions to add methods to classes. I have yet to run into another use case for them.
* I use them where appropriate (not too hard to write the `extends AnyVal`) * I never actually did performance measurements...
I've used them for implicit classes and that's okay I guess. What I really like using them for is basically ```newtype```. Instead of interchangable Strings representing a bunch of things, I now have a bunch of strongly-typed things that are Strings but can't be accidentally used in place of each other. It's very nice.
&gt; I haven't seen them widely adopted. I doubt this is true, if instead what you're arguing is that they aren't used as much as they could be, it's probably because people haven't thought to use them, don't know about them, or want to give a class for interop with Java.
https://www.coursera.org/course/progfun The official Coursera course is "over." But you can still register, watch the lectures and view the assignments. Not sure what happens if you try to submit them for a grade. I don't know if the automatic test tool will provide you with a grade or not.