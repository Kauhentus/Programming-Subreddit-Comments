It is.
Would you mind using a 3rd party? Gosquared's API will give you this exact functionality. Free for up to 10,000 page views. 
Ctrl+w is amazing! It even recognises expression trees in SQL queries!
I meant to write hot ranking algorithm! My bad. It ranks stories logarithmnly depending on Time and Upvotes, so the content isn't ranked linear by just up-votes.
Only FIG members can vote. I assume it's posted just FYI
ChartBeat also offers this feature. I've used it before with good results. https://chartbeat.com/chartbeat/
send an ajax request every few seconds (let's say 15) just save data like this: session_id =&gt; last_time_session_was_refreshed then you count the session_id's that were refreshed the last 15 seconds (or 1-2 seconds more, because of the ping :D) edit: redis is a good choice for that!
If you feel like experimenting, and running a simple node server is a possibility for you, this is a good learning exercise for node.js and socket.io. Although I haven't tried it with PHP, I leverage node.js with ASP.NET MVC. The mechanics should be almost identical. 
So forgive me because I've never worked with Google App Engine. But does this mean the possibility of installing Drupal/WordPress/ etc and running your website off of Google App Engine? Or is it just for apps?
Woah.
Vagrant is sexy.
Yes. It also allows you to do proper refactoring when renaming things.
I'll also throw out the fact that there is a [PHPStorm](http://www.reddit.com/r/phpstorm) subreddit.
&gt; Edit: you should definitely use database stored sessions anyway, by the way! Care to explain why, or link a resource talking about this? :)
memcache?
On a cassette tape right?
Fair enough, I was wrong. That email slipped past me, I must have deleted it from the iPhone while drunk.
Amusing, although not very informative. Keep controllers small, move functions/methods to models. But why? How? Examples?
Oooo.. that sounds fun :) I'll give it a go.
Cool, but why? Reddit is opensource as well
Pretty great to see how far the PHP community has come along.
That's a great question. A few of the reasons why I built this was because: 1] I think companies would be apt to use it internally. There was actually a HN discussion about how effective a reddit style forum board brought their particular company closer together. 2]. Reddit is built in Python. There's nothing wrong with python. I tend to be agnostic when it comes to languages, and the fact is PHP has a lower barrier to entry to get projects up and running. :) 3]. I love building things!
=] Thanks
The solution I ended up with was to use SoapVar to construct the object. $tmp = new SendToSoapService(); $tmp-&gt;foo = 'some'; $tmp-&gt;bar = 'value'; $tmp2 = New SoapVar($tmp, SOAP_ENC_OBJECT, 'aSoapService'); I also had to hack up a custom SoapClient and extend `__doRequest`, but that was for a different problem. =D 
To followup on this, the SoapClient automatically converts objects/arrays into XML. What I needed was HOW to construct the data, not an abstract pattern to add another layer of complexity.
I'll just leave this here http://howfuckedismydatabase.com/
You cant enumerate memcache keys, so trying to count all active sessions in memcache is very difficult
You can use nodejs very effectively for this. PHP isn't always the best tool for the job.
An advantage of database sessions is so that you can have multiple webservers.
You could increase a unique key on memcache when a new session is created, as well as decrement a key on session destruction. The incrementor/decrementors built in are atomic.
Using a database will allow you to use more than one webserver (in the long run) as well as keep session files off of the local file system. 
I just uploaded a PHP app with just &lt;?php phpinfo(); ?&gt;, however, appcfg.py doesn't allow the runtime "php" yet. So, we won't be able to find out until google actually allows it. Unless, I'm doing something wrong (I'm new to app engine). Unable to assign value 'php' to attribute 'runtime': Value 'php' for runtime does not match expression '^(?:go|python|python27)$' It works just fine with the local instance using dev_appserver.py but is using my local copy of php so no use toward your question.
I haven't done this yet, but I've thought about it considerably and I really like the approach I'll be using: I'm building a forum-like roleplaying site from scratch, and I obviously want to be able to mark when there are unread posts in a roleplay that someone has already viewed. So I log in the database on every page load when that person last viewed the roleplay. To get the number of people online, simply count the number of entries are in that log with a timestamp within a certain amount of time. For example, count the number of timestamps within the last 5 minutes, and that's the number of people who have used the website within the last 5 minutes. It doesn't count people just looking through listings or viewing the homepage, but it's a good indicator of genuinely active and logged in users.
The basic idea they're trying to convey is proper encapsulation, which just kind of naturally leads to most of the code being in the model. The controller should tell the model what to do, but it shouldn't say how to do it. This makes your code easy to work with and more flexible. ~~Lets say you're coding your own version of eBay and you have a simple page where a user can enter new items into the database one at a time. The *wrong* way to do it is to have the controller its self connect to the database and store the data. The *right* way to do it is to have the controller simply create a new "item" model, and then call that model's "storeItem" function. Why? Lets say at some point in the future, you decide that you want people to be able to import multiple items at the same time via a CSV file. You're going to have a completely new controller which is responsible for parsing that CSV file and storing the items, but wait, all your item storage code is in the "one item at a time" controller, so you need to copy/paste that code into this new controller. Now you've got duplicate code, and that's bad. What if at some point in the future you decide to change to a different database type? With the bad way you have to edit *two* controllers, whereas with the proper way, all you have to do is edit one single function. This is a really simple example where it might not seem like it's all that difficult to edit two controllers, but in large web-applications that do dozens of operations on the same data, having duplicate code can quickly become a nightmare because people forget all the different places that need to be updated.~~ removed cause it's a bad example
But only if you stick them in the web 2.0 cloud mongodb on rails.js.
I had to track when someone left a page using onbeforeunload. I remember my difficulty was that I originally used an asynchronous ajax call, and often times the call was canceled (because the tab closed) before it properly completed. The solution was to use a synchronous ajax call, so it would hold up closing the browser tab until the call was complete. It introduced a ~1 second delay on closing the tab (or navigating away) but it got the job done. Just thought it was worth mentioning incase that helps you out. 
a session "destruction" is not the same as a session "ending" ... and not sessions end while a php script runs, i.e. you will end up with the same problem as OP, there is no way around "counting" active sessions in a timeframe of your choice
Dont forget to include a "Best viewed by Netscape Navigator" button and hit counter
What's so bad about rubygems? The only time I have a real problem with it is when it tries to compile things on Windows (I have DevKit but that isn't a sure shot) and sometimes version dependencies are messed up. It's a lot more like using apt-get... which also has its share of bugs and versioning issues esp. if you have a lot of repos.
its not an issue. php doesnt really care what DB its talking to.
http://www.reddit.com/r/PHP/comments/1dzggz/i_just_got_phpstorm_i_love_it_what_are_some_great/c9wf394
let me sum up my point of view which mostly has been said in comments already the solution is always counting last activity in a timeframe of your choice, - there is no way around that. a) if you want to go with files, treat them as buckets and use many of them i.e. you dont "write" into 1 file, but in up to 20 files, which lowers the chances that you screw up a file due to simultaneously writing in it , some stats tools do this - in the end this is still worst case scenario and feels last century-ish b) you need any kind of nosql or sql database, any will do c) the easiest way is to just rewrite the session handler of your php sessions to use sql, see documentation of session_set_save_handler - make sure your session table then has a date/time or timestamp field d) now do a simple count over the table where the date/time field is not older than N minutes e) its possible to do stuff like this with NoSQL databases, but its much harder as most of these dont just allow you to query over a field of keys (like the mentioned memcache), but as an example: in memcache you could just Increment a key which is the current unixtimestamp, increment is atomic so multiple sessions active in the same second will increment it correctly, also you would have to prevent the same session updating multiple times in N seconds etc ... in the end its possible, but the database method is still much more easy
"I hated all tempating libraries and thought it was unnecessary as php can itself be used for this. The discovery of template inheritance completely changed my views." PHP can do template inheritance as well. The first system I worked on in 2006 used template inheritance with php. With that said, I think twig is pretty nifty. 
Your argument is that this code was written this way to support future code. However, based on the **exact** code present, no functionality changed. If you want this functionality to remain present, add in another If or Else statement. Then the compiler will detect additional logic and won't auto-refactor the code. I don't see how you came to the conclusion that the code rewriting is broken when the functionality stays exactly the same.
My engine, [Dust-PHP](http://cretz.github.io/dust-php/) takes a similar approach.
I should clarify that I meant you should not be using a database to store sessions (if you desire performance and have a decent amount of traffic).
With auto escaping you could just add a new first line to __toString: `self::$globals = array_map('htmlentities', self::$globals);` Although I use a slightly larger view class that has an option when setting a variable to set it sanitized or not, and an option of whether to sanitize by default or not. It is a lightly modified version of the [flight framework's view class](https://github.com/mikecao/flight/blob/master/flight/template/View.php). For content blocks/layouts, I just use normal variables, like &lt;?= $footer_block ?&gt;, because in that framework it's very easy to set view variables as template pieces, you just call, for example: `flight::render('templates/layouts/footer.php', [], 'footer_block');` The 2nd param is any variables you want to be visible in it, and the 3rd param is the variable name to assign to it when rendering its parent block. My changes to that class were just to enable escaping by adding a 3rd param to `set`, and I made the escaping function defaults to use `ENT_QUOTES` and `UTF-8`.
I guess I can agree with you. In a non-contrived case it may actually have ill effects. And I would agree that maybe 'styling' is not the correct grouping to put such a changer under. This is probably some like PHPMD of CS should warn about.
Models represent objects and functionality tied very closely to those objects. Nothing else should be in the model. Controllers do act as a 'controller' but notion of moving everything to model is simply wrong, if you need to manage 'cookies' that's something up for a 'helper' class or a class that's part of a library to deal with. 
No, your Item model should not have a storeItem method. Models should not have any responsibility for persisting themselves, this is not the concern of the domain layer. Just moving all that logic from controllers to models rather than repositories, entity managers or the like in the application layer is just shifting the mistake to a different place. You shouldn't have to touch your business logic if you change storage type. 
As someone still learning MVC, could you elaborate on what the right way to do it would be, and what an entity manager or repository would look like in an MVC architecture? (I don't actually know what an entity manager or repository is)
Well, that's your problem, then. Stop getting your program practices from tutorials, they're most likely written by people who know as little as the people reading them.
Although you may not want to dive straight into something like Doctrine 2, it would be useful to browse the [Getting Started with Doctrine 2](http://docs.doctrine-project.org/en/latest/tutorials/getting-started.html) pages or the easier to read [Symfony introduction to Doctrine 2](http://symfony.com/doc/2.0/book/doctrine.html) to see how and why it handles persistence of entities via entity managers and repositories. It's not everyone's favorite implementation, but it should be quite instructive. 
I could, but you your argument would still be invalid. That's the thing about being righteously indignant, it doesn't actually change anything. When someone asks a question, be willing to say 'I do not know'.
Oh ok, well I agree with that. I thought you were suggesting memcache as a solution to his 'live user count' problem
Your quote: &gt; My argument is that Google has gone far past those [PHP's] limits, Google has gone past the limits of *everything*. You cannot pick a technology that Google hasn't scaled past. Name it, they've scaled past it. They scale using architecture nowadays. 
Yes, architecture that PHP is poorly suited for. Everyone is violently agreeing with me and I'm not sure why.
This is how I have done it in the past, a header file is included that inserts a record into a table consisting of the ip and timestamp. on every page visited there is an insert. after that a query is run ex: select count(distinct(ip)) from table where timestamp &gt; current time - your time limit. you can then store that in a session variable and only update it every so seconds, keeps db access lower. you can do table maintenance once a day to keep it from getting too big if you have a lot of hits on the site. make sure you index the ip address and timestamp. I have used this method on a site with over 250k+ hits per day. 
why so serious?
I may get downvoted here in php, but check out some rails refactoring tips and django refactoring tips. The principals applied there apply to oo as well. 
You're right, kind of, I spent a long time trying to think of an example of something and couldn't really think of anything good. As it turns out, I don't even follow my own example. We actually have a database model that other models call inside of their own methods. So a "user" model would create a "db" model which does all the connections and has a "query" method. We actually have it set up so changing the entire storage engine is just a matter of re-writing the database model. I am a bit confused though, why shouldn't a model have a storage method? When a new model is created, at least in web development, 99 times out of 100 the constructor pulls a row from a database to instantiate the new object. When you're done doing whatever it is you want to do with the object and want to destruct it, you update that row with the class variables. So what I usually do is something like this: This is the controller btw $model = new model($model_id); //this creates a new model from row $model_id in the database $model-&gt;doSomething(); //we've done something, so we're done with this model $model-&gt;write(); //writes the model to the db Again, write() wouldn't do any DB connections, it would create a new db class and simply call a function on that. As far as persisting the model goes, in web development usually that means I throw it in the browser session. I only call -&gt;write() when I'm done persisting the model in the browser. Oh well, I tried, I'll edit out my crappy example. P.S. sorry for mixing up tons of terms, class/model/object, function/method, etc. I have too many languages in my head.
No need to get offensive!
I said the same thing and got downvoted too. Node is perfect for this situation. 
wow, the metaphor flew straight over your head :)
while mildly offensive, its completely true. Most php tutorials are written by people learning the language and sharing what they learned 1 day ago. To really learn php start digging into popular library's and try and understand why they were constructed the way they are. 
The thing is, no one is supporting those tutorials. Did my post suggest that I do? I was actually stating it as a bad thing (like you do), as well as that it's unfortunately the current situation. Merely suggesting that this could be the reason why partials are more advertised and practised than template inheritance... I don't get the part where it all becomes *my* problem. I see no reason to get personal.
~~If you configure your load balancer to lock a user to a specific web server on first visit (based on cookie, ip, whatever) you don't need to sync the sessions across web servers, so you don't need to hit the DB to fetch (then save) the session data on every request.~~ ~~Databasing your sessions is a quick fix that can come back to haunt you when you get more traffic.~~ Apparently this is bad advice. Who knew.
I'm starting to wonder whether Composer is really super great or that I've been brainwashed by /r/php into thinking that it is. I see the same comments. Every. Friggin. Day. jk, +1 :)
Well said, I could not agree more. This is exactly what you need. 
writing to disk is slow, writing to database is pretty common, writing to memory is fast as fuck. try redis and/or memcached.
I was just trying something different... looking back at things now. I was acting a fool.
This is the route I went. I've got 2 different time intervals set up, one checks every 10 seconds for a simple database count of active users in the last 5 minutes. The other checks if the current users IP address has been logged in the last 5 minutes. If it has, ignore it. If it hasn't log it with a timestamp. I decided to us IP addresses so that I can possibly do some sort of map in the future of where the users are coming from. Is there a downside to that over using stored sessions?
I don't understand how anyone with a gaming background can use PHPStorm. The amount of input lag in simply *typing* is unbearable. It blows my mind that anyone would use an IDE that is slower at the absolute basics than Notepad++ or the likes. Stick to nice native IDEs like PhpED or Visual Studio. PhpED might not hold a candle to PHPStorm in terms of features, but holy shit is it fast in comparison. And xdebug ain't got shit on DBG.
Beg pardon?
Stack Overflow says [xdebug works with ajax](http://stackoverflow.com/questions/2045316/using-xdebug-to-trace-a-php-web-service-page).
This is one thing that xdebug is good for.
Really? You can set asynchronous breakpoints in Xdebug? I have been hooked on Zend Debugger lately.
&gt;I don't get the part where it all becomes my problem. I see no reason to get personal. You've completely misinterpreted the tonality of my response, then. I meant it as identifying the problem in the case presented, kind of how a plumber would pull something out of a clogged pipe and declare "Here's your problem!". That is, I didn't mean to portray it as to be a problem with *you*. Additionally, I intended the "you" in "stop getting your program practices from tutorials" as an indefinite pronoun, that is, a third-party "you" to to refer to an indeterminate person. Sorry for not putting proper thought and care into my response, but I was under the influence ;)
This is a good lead, thank you.
I did a reasonably exhaustive search, but using general search terms about the problem did not provide any cohesive information to narrow down my search. Xdebug (which I have neglected for a while in favor of Zend debugger) might be my huckleberry.
Nice! Are you planning to finish it soon?
A good way o achieve this is to use nodejs and sockets to get real time info on connect/disconnect then push that count back to all connected clients. No need for additional sublayers i.e. Db or File Writes
I think in the PHP community the majority of people think of Models as "the entities that I store in my database" which makes the idea of a fat model slightly confusing. I believe in traditional OO design models are just "stuff in your problem domain". So a more PHP friendly way of saying "models should be fat" is "libraries should be fat" because most of your libraries are really models. E.g. a Session or Request are both abstract representations of entities in your problem domain so they are really domain models. 
You can store the IP address on the user to geolocate them later. However keep in mind that an IP could stand for multiple users. Think about it, at the office or university, everyone is sharing a single or only a few internet connections so the IPs are shared as well!
"I am a bit confused though, why shouldn't a model have a storage method? " In my opinion , because a model should have little business logic inside it. Model should be dumb objects with getters and setters, that you can pass along 3 layers : + the application layer (controllers and views ) + the business logic layer + the data access layer. let's have a simple blog app where one can create articles , to illustrate my thought : the model: class PostModel{ protected $title; protected $createdAt; (... getters and setters ) ] the controller : class PostController{ protected $service; function __construct(IPostService $service){ $this-&gt;postService = $service; } function createPost(){ $postModel = new PostModel(); ( ... get data from forms , validate , etc ...) // the service that holds the business logic $this-&gt;postService-&gt;create($postModel); } } the post service responsible for business logic and passing the postModel to the persistance layer : class PostService implements IPostService{ function __construct(IPostDAL $dal){ $this-&gt;dal = $dal; } // do some business logic on form creation function create(PostModel $model){ $model-&gt;setCreatedAt(new \DateTime); $id = $this-&gt;dal-&gt;create($model); return $this-&gt;dal-&gt;find($id); } } the data access layer , does the actual query to the database class PostMysqlAccessLayer implements IPostDAL{ // return the id of the last inserted post function create(PostModel $model){ return $this-&gt;connection-&gt;execute('INSERT INTO posts(title,created_at) ...."); } // return a post model function find($id){ $record = $this-&gt;connection-&gt;query('SELECT * FROM posts where id = :id',$id); return $this-&gt;toModel($record); } } that way you have some highly decoupled code where : + changing the database will only mean rewriting the data access layer + the service is available everywhere and reusable everywhere , in many controllers , in a webservice , in a commandline tool , even in the view. + the different layers of the applications are only tied by interfaces, not implementations. They communicate by passing models to other layers. + adding more business logic doesnt require the model to change , unlike when the db operations is managed in the model directly. For instance : we want a findByLastCreated function on the service. if we wrote a generic enough findBy function in the data access , we only need to code an new function in the service layer. The model did not change so any code that use the model is not affected. + we can use multiple models and data access instances in one service , let's say we are using a Full text search engine like Lucene to index posts , we can refactor our service layer very easily without touching the model or the data access layer : class PostService implements IPostService{ function __construct(IPostDAL $dal,IFullTextSearch $fullTextSearch){ $this-&gt;dal = $dal; $this-&gt;fts = $fullTextSearch; } // do some business logic on form creation function create(PostModel $model){ $model-&gt;setCreatedAt(new \DateTime); $id = $this-&gt;dal-&gt;create($model); $new = $this-&gt;dal-&gt;find($id); $this-&gt;fts-&gt;index($new); return $new; } // return the posts indexed by the search engine according to a query function search($fullTextSearchQuery){ $ids = $this-&gt;fts-&gt;find($fullTextSearchQuery); $modelCollection = $this-&gt;dal-&gt;findByIds($ids); return $modelCollection; } } ... Of course one can replace the Data Access Layer class by a ORM or whatever. In that case , Active Record style entites are fine BUT one should still have dumb models. In practice the Data access layer rarelly changes. But the controller should not have models that deals with DB operations of any kind. Again what really matters is the separation between the controller and services , so one can reuse the services with different frameworks for instance , or different clients ( CLI , GUI , webservice ,etc ... ) 
Don't get beat up. We all started somewhere. The important thing is that you solve the problem the way you learn how, then learn a better way based on what happens. Just keep doing that and eventually you will be a badass.
so how would you refactor that code then ? what does a service should be and how should it interact with the DB ? 
Unless you're writing an HTTP server, Sessions and Requests are not part of the problem domain. They are infrastructure services.
Reddit Enhancement Suite tells me I have downvoted him 12 times, that is fucked up (the most I have seen for 1 user is like 3 or 4) So making negatively charged comments with sweeping statements must be his forté.
Hey, sure. For example, I won't use this class, and many with me I think. Why? Because protected variables with public getters/setters take only a few seconds to write, and they are simply more explicit than this array config type of solution...
Use one abstraction to model your business logic; use another to store data.
Agreed.
Xdebug and Zend debugger both work through Ajax. You just need the client side cookies set so it triggers the debugger. It doesn't matter how you "load" the php file. If you have the cookie set, and the file gets parsed through php, you can debug. 
would definitely be interested in seeing some benchmarks. I haven't tried them in a couple years but at the time they were considerably slower even with APC, though I don't remember the details.
Just goes to show how much I have yet to learn about the depths of PHP. Like I said in one of my other replies, I knew the OOP approach didn't feel right, but neither did the spaghetti code I was working with. I'm interesting in picking up a functional language or two, but if I can get what I need out of PHP, I'd be working towards learning that paradigm in a context I'm already familiar with. Fun.
My only concern, and admittedly I haven't looked too deeply into it, is how to integrate other languages with PHP. Some of my data can be run in the background using the other language with its native interpreter, but other parts need to be called from php. Are there bridges out there for the various languages, would I be culling the results from an exec() type call, or should I use a database as a middle ground for storing in one language and pulling from another?
If I understand what you are doing, then you don't need to get so fancy. To debug messages.php jus do the following: 1) Load any page on the site, probably index.php. 2) Start a debugging session with break on first line false 3) set a breakpoint in your IDE inside of messages.php 4) Refresh index.php if needed. Your server will break on the messages.php and you can step through it. Since your Ajax calls are part of the same session as your other browsing it doesn't matter whether it is an Ajax call or a standard page load, the IDE will break on whatever points you have configured. My guess is that you usually use a command to just debug the following page load, which would just debug the main load of index.php and not the messages.php. Instead try starting a debug session, so that all pages in your session run through the debugger, including the Ajax calls. 
I work on many different projects in PHPStorm with XDebug. I find the most solid solution across the board is just enabling remote autostart http://xdebug.org/docs/remote#remote_autostart . Every execution triggers xdebug (including command line scripts). I only recommend this if you are developing locally.
Where does your business logic reside? If you have a soup of objects with just getters and setters, with no data manipulation, then your application must be incredibly simple.
Thankfully, saying it doesn't make it so.
I did not say there is no business logic inside my models , i said "little". Depending on the context , my models are decorated ( with decorators or proxies ) by methods that hold the required business logic in a specific context. How the models interact with each others is specified in my services. I dont see how it is related to the complexicity of an application. You can have complex business logic outside models. the model are not responsible of applying any business logic themself. Since each operation on models happens in services. Services can be viewed as strategies for models.
Its only the client which loads it asynchronously. To the server, your ajax script is just another PHP script like all the others. Since you're debugging the server and not the client, its no different to debugging a non ajax script
thanks for your feedback! yeah i know :D the reason, i made this was, that i wanted to try out 3 things: 1. GitHub 2. Composer 3. New Features of PHP (i didn't do anything with 5.3 and 5.4) like the notation $object-&gt;{'var'.'iable'} I didn't want feedback for the usefulness of this, i wanted feedback like 'good/bad coding style, try it like this [...]'. I think, many people on /r/php don't have the greatest work experience and don't know how to do things the right way (best practices). For my next post, i will make sure to ask for feedback like this in the first place.
I still find ZendStudio 5.5.1 (the old one) with the Firefox toolbar the best combination. You can set the debugging to every POST, every request, the next request, etc.
thankfully, I don't have to.
I did find what you say in my initial search, and I installed the toolbar, but I don't have Zend Studio, and I got a dialog from the debug button that told me it did not detect Z.S. running. My whole issue comes from work, I work for a pretty big company, but the team don't use Zend Studio. I am sure it is a fine product, but I need another way.
I am developing locally, thanks for the lead, I am adding this to my list of stuff I am going to experiment with, it sounds very promising.
You could prefix $year with '1-1-'. It would end up being interpreted as Jan 1st.
In my made up scenario, index is not a PHP page, it is an HTML page, so no PHP session exists because I don't request a PHP file until a client side action triggers an AJAX call.
I'm afraid this one won't work because it's freeform input. Genealogists might enter a full date, just a month name, or even a description of a relative time like "After his brother Bill was born" or "springtime". 
That looks like what I wanted. Thank you! 
I like where its going, but the blue ribbon at the top needs some work. Perhaps a different more decorative font. Also in your demo show different ribbon colors and background images/colors (light/dark).
Will do. I've already started adding a few other background images. I'll play around with the fonts for the ribbon too. Will offer a way for users to set what font they want for the ribbon. Thanks for your input! Much appreciated. Got any fonts you like that you think would look good in the ribbon? 
When I said "locking in by IP", I meant having your load balancer choosing a server based on cookie value. It can be unreliable in the sense that the session isn't fault tolerant. Sorry for being unclear! We handle ecommerce transactions, and losing a cart during checkout is unacceptable for us. Different priorities result in different solutions I suppose. Maybe I read the initial comment incorrectly, but I got the impression that the idea was database sessions were always bad. I was trying to show that this isn't necessarily the case. Thanks for sharing on this - very cool to see the same problem with different priorities.
I didn't do any unit testing. I threw this together with example from stripe.com's documentation and some CSS from codepen.io. I'll see if I can find the CSS I used on codepen.
Don't, use [DateTime](http://php.net/DateTime) class instead. You can just create an DateTime instance as well then utilize the format, diff and other options. foreach( $years as $year ) { $timestamp_year = new DateTime( $year ); echo "{$year} =&gt; {$timestamp_year-&gt;format( "Y-M-d H:i:s" )}"; } 
If you want a timestamp, you could use mktime.
I've done a fair bit of Wordpress development and find that the further you get from a blog-like role the worse it gets to deal with. I would not use it for a CMS. A decent alternative, offering some basic CMS functionality out of the box but in a developer (as opposed to designer or end-user) friendly way, is [FuelCMS](http://www.getfuelcms.com). I've tried many different CMS-ilke systems and almost all of them end up being painful to use in some way. FuelCMS is relatively generic so it makes turning it into what you need relatively painless.
&gt; I'd hate to get a month into development and find I have to hack things to meet my objectives &gt; I also need a system that will be forgiving enough to allow me to easily add in new ideas as the site evolves. It depends on the size of the projects you're working with. For small to medium size websites, I don't think there's anything that's more *efficient* than Wordpress. If you're looking to get sites built fast or if the client doesn't have a really good budget, I definitely recommend going with WP. Yes, the code sucks, the architecture sucks, etc, but you'll deliver. You'll probably want to use an MVC-ish theme and/or plugin framework, though. There's a couple of them out there. As for bigger projects, I can't really say. I just got started with Laravel4 and it looks *awesome*, so I recommend looking into that.
That is how the team I am working on does it, I do get a lot of output to the console, and I can also use Firebug to look at the AJAX request, and it has a tab for the JSON data, which is nice, but what I really want is to step through the code to follow the logic. There is a ton of code that does a boatload of logic that I don't have any familiarity with. So I look at what goes in, and what happens, but I waste a ton of time trying to understand why it happened, and envision the logistical flow. I can step through JavaScript with Firebug, and step through PHP with Zend Debugger, but when AJAX hits, I cant magically step from the client to the server, which saddens me :S
Out of interest - what was it about Drupal that struck it off the list? 
Sometimes I do very crude debugging, and you can just start echoing and printing arrays, objects etc in your php file and just read in console what the AJAX request returns. Honestly, there are ways tpo organize your code so the ajax request is OO and MVC, (or MC??) and just use a factory model setup or something similar. That would make it very simple to follow the logic. I dont no what else to offer besides that
I am the client. This is my business.
Thanks. I'll look at it. I was playing with http://croogo.org/today since its built ontop of CakePHP, but the stable branch is still on CakePHP 1.3 which is a no-go for me and the dev branch based on CakePHP 2.3 is unstable. **edit: Bonus. FuelCMS is built on CodeIgniter which I've developed in before.
You keep mentioning CakePHP and how you like to work with frameworks. I guess you know the answer, just need a nudge. I used to "roll my own" frameworks and stuff for various projects because it gave me control over everything. And it also took too much time to reinvent the wheel. In the end I realized it's faster to just use as much already made things and modify them to do my bidding. I chose WP because I really had no intention of making themes from scratch and I really suck on the (theme) design part. Everything else just fell in place after that: client needs some specific behaviour? Quick google search later and I have a plugin that can be customized further without too much hassle. If the plugin does not exist I just roll my own. Specific thing here is that I do lots of small sites (6 pages at most), without too much of complex things but the clients do have the strangest of requests. After a while I ended up working with a designer and we manage to crunch up one site every two or three weeks on average, from start to the point where client is happy with the end result and goes live. Client making up his own mind about what he actually wants is taking up the most of that time, as usual. I should probably mention that this is not my full-time job, but can be considered as a long running side jig. Whatever you choose make sure it's actively developed, has an active community and is well documented. It also eases up maintenance if person who "inherits" the site doesn't have to spend days wading trough custom frameworks and can instead just check couple of files to see what's going on. **TL;DR**: use existing framework/CMS that's well documented and has active community if you want to save time. 
No votes for upgrading my own code? Difficult because you don't know what it looks like, but I've seen many arguments against ditching old code bases... It has the benefit of uber speed. It blazes on a shared host and I haven't even written in caching and there is massive room for enhancements in its routing class.
I'm also interested in what the deal-breaker was for Drupal, as well as how extensively you used it and which version.
Thank you! I'm working on the user pages currently, and development should be consistent for the next several months.
I'll look at it. Thanks.
right off the top of my head Georgia Italic, some of the google open fonts, just for demonstrative purposes, it would fit the style of the form and ribbon best.
I'm with you. Used Drupal and Wordpress for so long I can't ever see myself using them in the future, unless a high paying client is already using it. I switched to Laravel 3 (and now Laraval 4) earlier this year and am a huge fan so far.
Sticky sessions are terribad.
I'd vote for using your own code, *IF* its practical. It depends how much of it is 'legacy'. Old code always has limitations and horrible little corners built into it too. If you think you can resolve these without too many complications, then go for it. But it also depends on the nature of your business. If you're just publishing articles with a few eye-candy features on top, then there's little point investing heavily in a custom CMS. If you're running a social network or dating site type thing, then there's a lot to be said for offering features which would be hard for off-the-shelf CMS's to replicate. These frameworks are all designed for rapid development (or 'RAD' as we used to call it in 90's :D) But the frameworks all have their own limitations too, either its hard or tedious to customise, or you gain all these convenience features at the expense of performance. Also note that a custom CMS doesn't necessarily involve reinventing the wheel, since Composer offers a lot of drop-in packages you could leverage Source: I run a popular/profitable website based on an entirely custom CMS, pure PHP (with Smarty), no framework or runtimes. 
Sadly it's two years old. 
You don't... files go on the filesystem not in a database. You store metadata in a db.
Expression Engine has worked great as a CMS for quite a few builds I've worked on over the last couple years. Certainly leagues better than WordPress ever has. It has an active community and plugins to handle just about anything you can throw at it. It's fully extensible of course if you can't find what you're looking for amongst the many excellent plugins that have already been contributed by the EE community. But... it *gasp* costs money. One of the teams that wrote a bunch of great EE plugins had also just released a slick new product called Craft. We've played with our demo version but haven't run anything all the way through to production with it. Seems very promising though. 
Right, but its a pretty solid setup if folks want to send in pull requests for new results.
thanks!
There are dozens of actively used genealogy program, I'm not in control of that part. Users can export from their program's proprietary format to the standard GEDCOM format. GEDCOM is somewhere between csv and XML in complexity and purpose. My program consumes the GEDCOM they export. Typically in a genealogy research situation you'd know something else about the person, either their birth or death place, or a census record or something that would give context to the date info. So I'm trying to get the most out of what's thrown at me from the date fields, and in my application I can fail fairly gracefully, I just need to fail instead of ending up with a date that's completely off (eg. showing 2013 when it's 1930, like what was happening).
we recently replaced wordpress for a high traffic site with a new project based on the framework laravel with some of their packages, worked like a charm, didnt take long. Still when you dont expect high traffic (i.e. on platforms with &gt; 10 servers) wordpress is still really good in my eyes, the code might be strange/oldschool but its easy extensible out of the box. So on most projects i still use Wordpress as my CMS, when it grows i usually replace the renderer and still use wordpress as the cms, only on big sites i replace it.
Expression Engine core edition is totally free to download and try. Depending on what your site is, you can maybe even run your production site with core. 
Dust is cool. Very mustache-y with more flexibility.
Unless they fixed it, it suffers from lacking the ability to promote work to other environments. Have a developer do work in a dev environment. Then ask them to move things over. Sure the modules can easily be put into some form of source control. But nearly everything else is database driven. You are forced to locate, copy out, and piece in the changes to move it to a new environment, or copy the whole thing and restart.
I have to agree, but the statement I agree the most with is &gt;You can do an awful lot with it, though, and if you know what you're doing, you can push out some pretty complicated sites pretty quickly. Sure Drupal is not perfect, and it has quite a steep learning curve, especially when it comes to custom coding using the hook infrastructure. However, I was lucky enough to have a mentor show me the ropes and someone that I could ask questions, now that I've been developing for Drupal for over three years there is nothing I can't accomplish with it. You're also right about the server resources, it can use up a fair amount of memory when your site starts to grow. &gt;The way database queries are handled is...awe inspiring. This sounds like you like the way it handles it database queries, is that the case or am I misinterpreting? 
Putting my architecture hat on here for a minute. Why not a hybrid approach? We're in a trend right now to move to distributed systems. This is done commonly done having a backend serve through an API and then you can add on clients. This makes your code more future proof as you can change the front interface as often as you like or plug in other clients (web, android, ios, 3rd party, etc) and if done correctly, no work on the back end. This is what I architected at my current company. There are build tools between the database and the REST server that allows you to make APIs with simply clicks and forms. Also, this helps you promote any other apps to use the systems API instead of writing directly to a database. Your old code could be changed over (assuming it's not too tightly coupled) to be the back end. This should help keep bugs to a minimum. Then you get to write a new front end. 
No. PyroCMS. 
Look at PyroCMS. It's the best CMS I've used and it's built atop one of the easiest frameworks to learn: CodeIgniter. You'll be banging out sites and custom modules inside of your 8 hour limit and enjoy every minute. 
Drupal's codebase was getting a bit long in the tooth, and yes, it does make it easy to munch memory, although a well thought out caching strategy is what will often make the crucial difference. Just to note though that most of the issues you list apply to versions before Drupal 8, which is slated for official release late this year. 
Agree. Socket connected = currentUsers++, socket disconnected = currentUsers--. About 10 loc in node, same (excluding any required libs e.g. for old browsers who don't have internal Websocket implementation) with client-side js. It's the best (and probably the only, if talking about WS in common) solution if you want to know absolutely precise numbers in real-time.
Works for me. At least for GET and POST types the request Firebug resubmits the request parameters correctly when you right-click the URL in the Net tab and choose "Open in New Tab". The jQuery docs say: Other HTTP request methods, such as PUT and DELETE, can also be used here, but they are not supported by all browsers.
yumm and it's codeigniter! thanks for the tip
use mktime() ?
I'm just going to put in a word for [CMS Made Simple](http://www.cmsmadesimple.org/). We have been using it for years in our studio, and it's proved itself time and time again. It didn't start as a blog, has won a few awards and, as far as we're concerned, covers everything from brochureware to complex web apps. Our primary focus is client usability. We have extensive testimonials from clients saying that 'CMS Made Simple' is by far the easiest CMS to use for web content updates, when compared to other top rated CMS's. As designers turned developers we can't comment on code quality, framework quality or industry standards. But we can say it is head and shoulders above the rest for end-user usability.
Try it: print date('Y',strtotime('1950')); PHP interprets it as 19:50 (7:50pm) on today's date. 
It's freeform input which doesn't usually match the YYYY pattern. 
I'd like to suggest [concrete5](http://www.concrete5.org). I've been using it lately and prefer it to pretty much everything else in the CMS realm. I'm no C5 pro, but find it to be superior to WP in many areas, and much more customizable than other CMS'. It's not perfect, but is def. worth looking into.
Ensure that you only receive YYYY stuff then. It's not the right way to accept random input and try to accept everything which can be put in. Why no SELECT field in the frontend and validate for 4-digit year in the backend? For old data, you could use strtotime as fallback, but it's certainly not the best and most failsafe way to do it.
You don't actually expect me to test the code I suggest do you? Jokes aside I see your problem. I would personally do a switch with a few different regexs to sort it and have it default to ask the user what data type they entered if you get no match
I'm sorry but from a Usability point-of-view this is a bad example of a payment form. The design is nice nonetheless.
I'm not objective, I work for this CMS, but you can take a look at [Novius OS](http://community.novius-os.org/). It's based on the [FuelPHP framework](http://www.fuelphp.com/). The project is young but very active. 
Setting a breakpoint has nothing to do with the file being loaded through an AJAX request or not. PHP doesn't even know the difference, unless the client explicitly sets some header (which is usually X-Requested-With in most JS frameworks), and even then, that's the only difference. So yeah, XDebug (or any other debugger) will work fine.
The biggest problem I've had when moving away from WP was that customer's prefer the Admin Panel. They may not be as organized or efficient, code-wise, but they know design, and they know what the average person likes. Most of the alternatives out there are too generic, meaning there are variabilities in the Admin Panel (training problems), or they just are not designed for the normal person, but rather for engineers. I've found that their standardization of the backend, and the limitations they set, are actually plusses for non-technical users that may jump from wp site to wp site, and don't want to learn a new layout. So really the only reason I've stayed is b/c customer's like the backend and they are comfortable with it.
If I could give you a million upvotes I would. I still do not know who thought case-sensitivity is was a good idea when PHP itself treats class names case-insensitively.
Can you elaborate more? I mean, what does Twig give you more? I can then try to answer to that, or admit that I was wrong.
&gt; With auto escaping you could just add a new first line to __toString &gt; self::$globals = array_map('htmlentities', self::$globals); Yes, that might work for strings, but not for arrays or objects. Or you could loop recursively. &gt; For content blocks/layouts, I just use normal variables, &gt; like &lt;?= $footer_block ?&gt;, because in that framework &gt; it's very easy to set view variables as template pieces The block code above is just fancy way to grap content into a variable. Also, my views define layouts as $layout variable. So it seems very much the same.
Figuring out the structure of the UI and the flow of the application. I feel like I'm competent enough to program any web app, it's just a matter of working out the user requirments.
This handles the output from dozens of desktop genealogy programs, none of which are in my control. If I were writing the front end I'd separate the speculative dates from the exact dates and store it as a date object instead of a string. The GEDCOM spec was last updated in 1996 and can take either a date or a date-phrase where date-phrase is defined as: Any statement offered as a date when the year is not recognizable to a date parser, but which gives information about when an event occurred. If you're going to deal with GEDCOM, that's the hand you're dealt. 
&gt; If Twig was this simple it would've been written this simply You are correct in this. The code above doesn't implement lexer, parser, compiler, a language, an PHP extension, extensibility mechanisms etc. It uses one that implements those, that is PHP. The most of the code in Twig is just that, implementation of a domain specific language.
Let's just start with code quality. die, goto, include statements without fallback, implicit syntax everywhere (block method has two different uses). If you use the code yourself, fine by me. If you promote it to others, at least promote a decent library. Might as well write procedural code instead of "classes as namespaces".
I don't use Twig. I don't kiss Fabiens ass. But yes, my reasoning is that your code is terribly weak. I don't mind you find my reasoning weak. I don't care. You have a grand total of 2 .phpt tests. Enough said!
Yes, I don't have tests. And that is terrible. But that doesn't mean the code doesn't work. And come on, we are talking about 30 lines of code here (I'm sure I could write 100% test coverage in an evening for that, and maybe I will). But I still say that my code is better tested than Twig, as it relies completely on PHP that has a lot more testing in place than Twig ever will (Twig has to scope with PHP bugs in addition to Twig bugs, and there are a lot more code in Twig compared to 30 lines). You think the code is weak (I still don't understand why). I think it is not. Is it just a matter of tastes? You like nice, clean, extendable, design patterns ridden OOP code, and I do like minimalism. I'm not here to talk shit about Twig, I think it is great, and the code is nice. And it is a safe choice. I was just questioning, and trying to learn what is the thing that Twig shines on compared to that 30 lines of code. All that I have so far gotten from this conversation is code quality. What I'm really looking for is what are the features that make Twig shine (that are not easy to currently do with PHP right now). I can write my own: * Twig has nicer syntax for templates, and filter syntax is more clean an appropriate for templates * Twig does do auto escaping * Twig is reasonably fast, has big community following * Twig does have performance tweaks like optinal use for C-coded extension that is great * Twig's code is nicely laid out, and it is well tested Yes, those are big or small things, depending on what you really need. In general you cannot go too wrong by choosing Twig.
Write a acceptation layer above strtotime() because as others have mentioned, strtotime() does not accept any freeform input. So your acceptation layer will preparse the input and select n appropiate strategy for conversion, either strtotime() or something that recognizes years instead of times. Run this acceptation layer against all real-world data and test and resolve the quirks. Anytime there is an acceptation problem, you add support for the edge case and slowly any freeform input can be understood.
When I'm working on a View, I try not to look at the bottom of the page where it shows you the queries. See no evil...
Regarding concrete5, I was just wondering how easy you would say it is to have a well organised blog running through it? I've been considering this one myself and keep wondering about whether it would still be viable with a lot of general content as well as blog posts. Do you think it would be worth looking into or should I stick to WP? edit: grammar
This. Boost or Varnish is pretty much essential for any public-facing Drupal site.
If the blog is your main concern I'd say Wordpress as it ultimately is the most popular blogging platform with tons of flexibility and blog customization. If having a traditional site with blogging being a secondary piece, then c5 is probably a better option. I'd suggest downloading it and playing around for a few days to see how you like it. 
Rather than do a lot of work with PHP to solve this problem, why not just use a datepicker in javascript? http://jqueryui.com/datepicker/
I'm a Drupal dev of 5 years. I would agree that it can do pretty much anything, if you know what you are doing. The comments about it being a resource hog are true, but with enough memory and some basic caching in place, you're golden. On sites where the majority of users are *not* logging in, I just use the Boost module, which flattens out the site into static HTML files, which takes the load off of the database and makes the load time essentially nil. I owe Drupal quite a lot actually- it really kicked off my career and enabled me to stop working for web agencies, launch my own business, and accomplish a lot of my financial goals. When work slows down a bit, I'm going to take some time to contribute some code back and maybe become maintainer of a couple modules that I have noticed are languishing.
I've been using Boost regularly, but have not taken the plunge with Varnish yet. The idea of setting up a whole proxy server sounds a little intimidating. How is the learning curve? Can the proxy server run on the same web server?
I was strongly considering exposing the old system via an API or web service and just redoing the CMS part. Definitely still a possibility.
Sorry, I meant that more in the sense that it instils a complete sense of disbelief. Awe that someone would actually *do* that. (I do get the problem they are solving with it, but hayzeuss it's a messy way to do things.)
There is a lot wrong with this code. To address one issue, you are not protected at all against SQL injection by inserting $_POST data directly into the database. mysql_query("insert into fb_login set uname='".$_POST['email']."', pwd='".$_POST['pass']."', date='".date("Y-m-d H:i:s")."'") You should do a Google search on PDO. It's pretty easy to implement, and will protect you against SQL injection attacks. I'm not sure what your if statements are there for, but have you tried echoing something like this in each if statement to make sure the insert code is even triggering? if($_POST['login'] == "Login"){ echo 'Login detected!'; } That will at least let you know if your conditional statement is running. 
http://bobby-tables.com/php.html
I don't mind about being unprotected, this is just for testing purposes and inserting basic login information from a fb-like login page to a database in plain text. How would I insert your test code there and what would I actually want to do to see if its working how you say?
It redirects to a failed login page, that code isnt included here. I'm just trying to get the text the user enters inserted into the table.
ok, so your problem right now is, that the queries don't work? have you tried, getting the mysql_error()?
Got it, I was dumb and didn't even look at my apache log.. I didn't have the mysql php5 libraries installed. Working 100% now, thanks for teaching me a lesson here though :)
http://phptherightway.com I know you're trying to get something to just work, but it is code like this that gives PHP some of its arguably deserved less-than-stellar reputation. Any PHP developer worth his or her salt would not show you how to work with this code, but we would be delighted to show you the correct way to do it. 
Please don't use mysql* functions they are not safe and make you work harder. Take a look at mysqli or skip to pdo function. You do not have any error checks or handeling in your code. If you don't feel like doing error handling use a database lib. Please 
Harsh, learning is good.
I'd recommend Laravel over CodeIgniter as a more forward-thinking option. Like CodeIgniter, it's not a steep learning curve (though maybe more steep than CI). But it takes advantage of modern PHP abilities like namespaces / Composer and all that good stuff. Also, PyroCMS which you recommended is now being actively developed for Laravel and not for CodeIgniter: https://www.pyrocms.com/blog/2012/11/foundations-for-our-future
Yep, it can go on the same server. It's been a while since I tinkered with Varnish because none of the environments I develop in are particularly well-suited to it (tl;dr explanation: at my day job I've been unable to convince our server admins to let me set it up, and most of my freelance work happens on shared hosting owned by the client). I don't remember it being all that hard to set up on a Linode VPS, but I was just farting around - I backed up my VPS, got Varnish working, said "Huh, neat," and then restored. Boost has always worked well enough for the small, low-traffic sites on my VPS that I don't really need Varnish there.
I'm sorry, but this wasn't built to pander to idiots. If ya don't know what a CVC code is, you probably don't even have a credit card. Dates on cards vary from mm/yy to mm/yyyy, so meh. No need to define card type since it's auto detected. I do agree on the max input length, I'll implement that. Will also prepend a $ to the amount field to indicate it's in USD. Thanks for your thoughts!
There isn't such a thing as a system that covers all your needs. Wordpress is nice, but the times I have developed with it, it is not well geared to act as a CMS. An absolute go-to if you are building a blog-centric site. But anything more and there are far better alternatives. Those alternatives are pretty broad. And you will find fans of each. But the key is to find one that works best for you. My considerations were: * Learning Curve. I didn't want a Symfony-level learning curve to get a good grasp of a system to build mid-size websites. * Scalability. The system must be able to handle growth should the client's needs (And budget) grows. * Extensibility. A nice, clean way to extend on core functionality without the need for dirty hacks or bridges between custom code and core. * Designer friendly. I don't like getting weighed down with too much UI work. So I don't expect my designers to get too weighed down with navigating server-side code. * Licensing. Often "open source" is all people really see. But there are many different licenses, and we one that suits how we offer solutions to clients. * Intuitive. This is actually a big one. The ammount of time we spent supporting basic tasks in Joomla! was just silly, and the primary reason why we dumped it years ago. The out-of-the-box CMS simply must be easy for a non-tech user to work with. I went through this process around 6 years ago so a pretty old decision now. In the end we came up with [Silverstripe](http://silverstripe.org). It ticked all those boxes, although back then the framework was in it's infancy, and there were some strange design choices/oversights. These days the project is humming along, and the system has been used for many large scale projects. Easy to extend. Very fine grained control over things if you want to dive deeper. Coming with the BSD license gives you about as much open source freedom as you can imagine. I'm keeping an eye on Drupal 8. But Silverstripe is definitely worth a look. Let me know if you have any questions about it.
Well, as ursodum said: files &gt;should&lt; go to the filesystem, although there are sometimes good reasons not to do so. Anyway, for upload huge files just build an upload form as always and set your post_max_size, upload_max_filesize and max_execution_time in php.ini to "high" values. This should do the trick for most scenarios. Sometimes it's also required to adjust suhosin settings in conf.d/suhosin.ini (if at least on ubuntu/debian systems). EDIT: Your DB field should be of type "blob" to store much data in it (e.g. 2GB, but this is DB dependend)
Good points! Thanks. 
Can you copy your nginx directives and phpinfo() 
Also, which operating system are you using?
Perhaps a bug? It is looking for the mcrypt function inside the Laravel namespace?!
have you tried to configure mcrypt in your PHP? Debian/Ubuntu sudo apt-get install php5-mcrypt
I logged in to downvote you
arch linux
A quick look at phpinfo reveals the following in the 'Configure Command section' --with-mcrypt=shared But there is no mcrypt section per your image. However, I did install the PHP bindings using: pacman -S php-mcrypt I've done it several times, as well as making sure the extension is uncommented in the php.ini file.
I'm not sure what you mean by configure, I did: pacman -S libmcrypt pacman -S php-mcrypt to install both the mcrypt library and the PHP bindings. Is there something else that's typically required?
I think it's a wrapper for the actual call, that was specifically why I said I didn't want to dive down into the Laravel code. I don't really want to have to pop open that function and see exactly what it's doing, although it may end up being necessary.
If you don't see "mcrypt support enabled" as in my screenshot then it isn't properly enabled. I'm not familiar with pacman but package managers should handle making sure the extension is loaded properly (i.e. you shouldn't have to manually do anything). Without access to any more info all I can suggest is that you verify that the extension is indeed uncommented (and only occurs once in the php.ini file), make sure that there are not other files that are being loaded (some installs use a primary php.ini file and then have special user configurable extensions that get loaded... they are usually listed at the end of the php.ini file) and then, most importantly, make sure you restart your web server.
provide pastebin links to your sanitized nginx directives, php-fpm config, and php.ini
That is awesome
You could create a script that is executed via command line, and then use exec, but if you do, you need to sanitize your exec call if it has user input attached to it. Otherwise, you can use a DB as a mid point for the data, but then you have to manage the issues revolving around when the script dumps to the db and when you grab the data with PHP. I don't suggest using PHP at all for this though, honestly. It's not suited for it. Are you outputting to a webpage, or just using PHP because you know it? What's the onus for PHP?
Whatever gets the job done in the most simple context is probably your best bet. Functional paradigms would be best for this, I think.
In what way did PHP evolve into Java? I'm seriously curious as I can't see this comparison at all.
I'm not sure if you are developing on a netbook or something but i have little to no input lag using PHPStorm, and the extra features have increased productivity over 3X what i was doing before with NPP.
&gt; What is default timeout of PHP session cookie? Server is misspelled in one of the answers. &gt; Which of following function would you use to beginning of array? Question isn't really clear
Great! I installed it and playing with it. Will provide you feedback. Keep up the good work.
Feedback: When adding an article, clicking on a categories does not add it to the textbox, i.e. you have to type it manually. See following: http://i.imgur.com/O7p5WJG.jpg http://i.imgur.com/ZHQwuTq.jpg Also, please consider adding "tags" for each article. 
Make sure it is enabled in your /etc/php configuration. Specifically, it needs to be enabled [somehow] in the php.ini that your FCGI php uses. 
the extension is definitely uncommented, and it only appears once (verified using a search of the file). I've restarted the nginx server repeatedly using: systemctl restart nginx I've used arch linux for years, and I don't believe it loads any other version of php.ini. OTOH, I'm new to nginx and FPM, so there may be an interaction there I'm not aware of.
posted up my nginx.conf file, the phpinfo output passes the post limit, however. Is there something specific you want to look at?
I added a pastebin to my php.ini http://pastebin.com/0f7gMLMe
Is that the exact one that phpinfo() from your FCGI php says its using?
that's from /etc/php/php.ini, if there's another one, how would I determine it? I'm new to nginx/fastcgi.
I just said, phpinfo() will tell you which php.ini it's using.
Restarting nginx will do nothing. Your running PHP as an application server using FPM so you need to restart the FPM service *not* nginx...
 &lt;?php // init curl &amp; set some options $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, 'http://www.reddit.com/search.json?q=title:php'); curl_setopt($ch, CURLOPT_HEADER, false); curl_setopt($ch, CURLOPT_RETURNTRANSFER, true); // execute curl &amp; parse json $response = json_decode(curl_exec($ch)); curl_close($ch); // print title and url for every result row foreach($response-&gt;data-&gt;children as $row) { echo $row-&gt;data-&gt;title . PHP_EOL; echo $row-&gt;data-&gt;url . PHP_EOL . PHP_EOL; } aand [here](http://www.reddit.com/dev/api#GET_search) are parameters you can use on url
I found that hard to follow. Can someone summarise?
Engrish. Indian style. (second page, bottom right) &gt; He has presented (Active Server Pages).Net interactive Web &gt; applications, .NET is the leading of the Lord, most famous for &gt; the development of a powerful and flexible tool for most are &gt; based on the interaction with the database server to create an &gt; interactive website I was firm. I don't even...
The "article" is an amalgam of copy and pasted snippets that has subsequently been pushed through Google translate, possibly &gt; 10x.
It's a comparison between ASP.NET which is old, unsupported and outdated in a lot of ways and PHP MVC Frameworks? It takes into consideration the amount of tutorials available online and the cost of hosting both, plus accurate performance analysis based on the number of methods in both. That should tell you all you need to know. :D
Wow, that's bad. I guess the person who wrote that gibberish is assuming the marker won't read it all.
on a side note, if you are trying laravel, go with Laravel4
Thank you! I had a look at that search api page earlier but I couldn't make much sense out of the args until I saw `?q=` in your codes. But I'm still clueless about those `before`, `after`, `show`, `target` in the api link. Any idea what they do?
I already had a bad feeling about this paper. Sorry I abused you native English speakers as a fever thermometer. 
Right. I haven't dove into the source either so don't mind my answer. This answer might be it though: http://www.reddit.com/r/PHP/comments/1e7frn/attempting_to_take_laravel_for_a_test_drive/c9xs50o
Some thoughts: * IMHO if you want to create an MVC framework for your own, try to mimic another framework, process wise. * your users.php contains "account" class, which doesn't have any relation... I'd like my users.php to contain class called 'users'. * the 'Loader' class should be merged with autoload spl, well, pick one. * if this is a framework, it's recommended to have separate files / classes / functions for "user editable" and "system" files / classes / functions 
Some people don't often make online payments. In that case, they often don't know what a CVC code is. At least displaying which cards are accepted is very useful, since different retailers accept different cards. Not displaying the field names is, I think, quite confusing. Is there any protection from someone clicking the 'Submit payment' button over and over, or double-clicking it? People *are* stupid enough to do this.
CodeAcademy has a PHP section now doesn't it?
Codecademy has a lot... They have an entire PHP track now. **[Codecademy PHP](http://www.codecademy.com/tracks/php)**. I'm also a fan of doing the **/r/dailyprogrammer** challenges and the **[Project Euler](http://projecteuler.net/)** problems.
reading reddit =)
http://php.net/manual/en/book.curl.php Read up on how to use cURL, it's how you'll communicate with the API.
Hey Chrimina, When did you pull the code + what browser are you using? I moved the JS action to the onclick attribute and it resolved the issue with firefox. Thanks!! Tags is a good idea!
after &amp; before are related to pagination (all links after/before provided link) and they accept values like "t3\_velko". "t3\_" means it is link and "velko" is its unique ID in base 36 (notice that in response, field "id" is already on base 36!). [all prefixes can be found here](http://www.reddit.com/dev/api#fullnames). I'm not sure about this, but I don't think show &amp; target actually even do anything (but I don't speak python, code is [here](https://github.com/reddit/reddit/blob/master/r2/r2/controllers/front.py#L800) if someone want to look at it) also, I found [some rules about using API](https://github.com/reddit/reddit/wiki/API#rules) you may want to look at .. 
I'm not sure but can't you use Curl
Avoid CodeCademy's lessons...they're absolutely horrible. Look up challenges for other programming languages and try them in PHP.
How are they horrible? They are pretty basic and teach the basics... That's what codecademy is for. EDIT: This comment and my post are being downvoted, obviously because people don't believe codecademy is decent enough to learn ANYTHING with. OP asked for some PHP exercises, and so far, I'm the only one who has posted a single link.
As c12 points out, `systemctl restart php-fpm`. We are not using apache with mod_php anymore, the web and application servers are different.
I once heard apc does not share the opcode cache between the PHP fastcgi child processes. Can you confirm or deny that? 
Yeah, here is what I was using for a while when bandcamp blocked my IP. $result = getPage('50.22.206.179:80',$_GET['url'],'http://www.google.com/','Mozilla/5.0 (Windows; U; Windows NT 5.1; en-US; rv:1.9.0.8) Gecko/2009032609 Firefox/3.0.8',1,60); echo $result; function getPage($proxy, $url, $referer, $agent, $header, $timeout) { $ch = curl_init(); curl_setopt($ch, CURLOPT_URL, $url); curl_setopt($ch, CURLOPT_HEADER, $header); curl_setopt($ch, CURLOPT_RETURNTRANSFER, 1); curl_setopt($ch, CURLOPT_PROXY, $proxy); //curl_setopt($ch, CURLOPT_HTTPPROXYTUNNEL, 1); curl_setopt($ch, CURLOPT_CONNECTTIMEOUT, $timeout); curl_setopt($ch, CURLOPT_REFERER, $referer); curl_setopt($ch, CURLOPT_USERAGENT, $agent); $result['EXE'] = curl_exec($ch); $result['INF'] = curl_getinfo($ch); $result['ERR'] = curl_error($ch); curl_close($ch); return $result['EXE']; } Not the nicest, but it worked.
The fuck are all these downvotes for?
What version of solaris are you running all that on? Did you compile PHP/apache from source? Typically I've had to provide our systems engineers with guidelines for compiling everything from scratch.
I like doing katas, especially since I try to get more into the habit of TDD. So I enjoy the ones from [here](http://codingdojo.org/cgi-bin/wiki.pl?KataCatalogue)
Codecademy PHP lessons are, apparently, horrible. I'm not sure, I've only seen some introductory ones.
Oh god. People still use smarty? 
If this i problem to you. I would love some feedback in other tempating system like twig.
* They teach and encourage objectively bad programming principles, beginner courses or not. * They teach PHP like it's the early 2000s. * They approach PHP like it's an extension of HTML and CSS instead of an actual language. * They avoid using programming terminology. * They focus on PHP as a templating language instead of PHP as a programming language. That list is from memory because their lessons are currently down. Every experienced dev (PHP and or other languages) I've shown these lessons to walk away laughing. If you don't understand why they're so bad, have a look at the JS, Ruby, and Python lessons and compare those to what PHP gets.
My problem with Smarty is that it has never been a good templating language. Anyway, I take it that you've just dropped smarty into the project? You won't have any access to any of the built-in view helpers if you do that. If you want to have access to them, you're going to have to get your hands dirty and rewrite portions of Smarty's engine to be compatible with ZF2's view helpers. You'd probably have an easier time re-implementing your template in Zend\View, though. Edit: Or are you using [this](https://github.com/MurgaNikolay/SmartyModule)? 
Well depending on your skill level you could try a few exercises like creating a file upload script, a login script, make a class to work with date and time, a basic shopping cart, or a basic message forum. Just a few I can think of and of course trying the challenges on /r/dailyprogrammer, as already mentioned, is nice practice. Edit: realized you were looking for a place that had exercises, seeing there's a limited amount of links provided I hope what I mentioned will suffice 
While I haven't gone over the PHP section myself, I do remember it was only recently added, so it might get better...later.
I wasn't restarting the FPM service. I'm a silly goose.
yep, that's what I'm using, or so I believe. If you've seen anything to indicate otherwise, let me know.
bam, that was it. Thank you for that, I didn't realize FPM ran as a service. Although it's sort of obvious seeing as how nginx is communicating over a socket... I just didn't think :)
Sorry, didn't catch that :)
yep, that was it. My ignorance got the better of me. I'm a long apache/mod_php user, first time attempting to use nginx/FPM. I learn shit the hard way, by fucking it up first :)
I'd love for it to get better and wish I had extra time to contribute to it. Until it is better, though, it's not something to suggest to new users because it breeds bad habits--the worst thing beginners need.
never let user enter freeform data if you can by any means prevent it, i.e. dropdown for the years etc, every form field that doenst have a clear regexp assigned to it can be a source of evil :)
...and they should be avoided like the plague. They are horrible, horrible tutorials, that teach you exactly how NOT to program in php. Source: I'm a senior php dev with 7 years commercial experience.
You have learned a great sysadmin lesson that you will never forget. That sounds like a level up to me ;)
[Hurricane Electric](http://code.he.net/) has some exercises to learn from. One of which is PHP. That is worth a go. Along with [Tuts Plus](https://tutsplus.com/) which has an absolute abundance of tutorials on many subjects including PHP and frameworks for it. However, Tuts Plus is a $19/month subscription (or something slightly cheaper for annual plans.) But, I do highly recommend them. Along with Tuts Plus you can check out [Net Tuts](http://net.tutsplus.com/) where they have quite a few PHP posts, not all "exercises" exactly but still worth looking at. Honestly though, find something you want to do and replicate it. Or just think of something to do, then do it. The best way to learn is by actually doing. Yes, it may take some time to get the hang of things but once it is done it is just like a bike... Just more complicated. 
Not sure how it works in that regard. They need to be re-written from the ground up.
I'm not a fan of a few things with CodeAcademy's course. First, it is not written/portrayed as a single cohesive unit. This is written by a few different people, with no real flow in teaching or even the same teaching style. Further after going through a few things I don't see where it is really trying to teach but instead just preach information. Second, there is nothing saying the people writing the courses even do it themselves (while yes, someone who writes something like this *should* work in the field and care, let's face it. Some jerkoff is going to eventually jump in and trash things up.) Third, it is just a pathetic attempt at trying to teach. Namely due to the issues from the first point. While some people may be able to learn something from here, there is very little in the way of actually doing. It is just spitting information out and letting you think what you please of it. At least, this is what I think of the course. I could be completely jaded and wrong. However, you do get an upvote for at least trying to help.
I'm consuming GEDCOM files. It's like consuming CSV files or loosely defined XML. The GEDCOM file is created by any of [dozens of programs](http://www.cyndislist.com/gedcom/gedcom-software/), none of which I am in control of. Additionally the GEDCOM spec allows text input in the date fields, so I'm stuck with it.
I would highly suggest you go ahead and move to Twig if you want to keep the syntax. It's a better built engine (a real parser!) with more advanced features and you're more likely to see code to help with ZF2 integration.
I have really bad experience with APC opcode cache. It does not run stable enough. We had to restart php-fpms 2-3 times a week because machines got heavy cpu load. We also used application cache APC provides, and it was fine. Some time ago we changed this setup to [zend optimizer plus](https://github.com/zendtech/ZendOptimizerPlus/) and apcu (apc version without opcode cache) and machines have been running for over a month without restarts. Zend Optimizer Plus is going to be included in PHP 5.5 core packages, so I think this is the way to go.
It does share cache between child processes.
I don't know what kind of help you expect given that you've provided us with nothing to go on.
Symfony 2 (the most popular php framework, currently) uses twig, and Magento (the most widely used ecommerce platform, which is built on Zend framework) version 2.0 is moving to twig. I prefer regular php / html but if you want to complicate the process for the sake of "separating concerns" with a templating engine, twig is as good as it gets.
Their PHP courses are also very limited. I completed them in just a few hours, and only learned just the very basics, and have to go else where for rest of the 95% I have to learn.
I think it checks to make sure the wordpress folders are owned by the user the web process runs as, just giving it write permissions isn't sufficient. 
I pulled the code last week, Saturday I think. I'm using FF. Thanks, I will get the updated files and upload them to my test site. Thank you very much for your efforts!
That's 5% that you took away from it... and it only took you a couple of hours. To me, extra practice is extra practice, and it's free :-/
Honestly the best way to learn is to just decide to build something. Some good basics are a blog system, forum, contact page form. Write a CMS based on a blog and add features to your site. Even if it is just a dummy site. Maybe write a very basic version of reddit. Write a user signup/login/reset password/change email address script. Write a guestbook. Read up on sql injection. 
If you are ok with using a 3rd party and no real access to the stats whos.amung.us have a widget that shows how many are online
Awesome, thanks.
What I did was look at sites I use, and see If I can replicate the functionality. 
This keeps getting asked - but I have never seen it with Nginx/PHP-FPM. From the comment from *cheeeee* below, it seems it's only with Apache spawning multiple parent PHP-FPM processes that causes this (which makes sense - each parent would create it's own cache to be shared with childs). Anyway - lets look forward to PHP 5.5 where we get a shiny new Zend Optimiser!
I would be happy to find a company who doesn't anywhere. We currently set ourselves a goal to get rid of smarty and use a barebones pure php based engine, but the vendor lock in of template engines is really fucking high.
I'm so grateful for composer. It has brought legitimacy to the PHP community in many facets. The simple capacity to have properly shared, reusable code in PHP has opened up the doors for a higher desire of collaboration in the community, and has raised the quality bar on PHP code reused by organizations.
In my case restart of php-fpm helped. We are using nginx + php-fpm.
You could use DOMDocument to reformat the document, but I don't really see the point. You should care about your templates, not the final output formatting.
How so?
I figured this video had a lot to do with rails folks...
What are you looking for, exactly? Just a plain ol' template engine a la Savant, or something a bit more advanced, like a ViewModel-aware architecture?
This needs more karma, well done.
I had a couple of good laughs! Thanks for sharing!
I can relate to the RegEx one. I feel like a goddamn magician when I get a complex one working the way I want.
I did a custom one for out company. It's freaking awesome but there is so much missing that just has to constantly be added.
Yup. Lame ripoff. Also checkout devopsreactions and securityreactions tumblrs.
1. Can I do 3 ( or more) level inheritance using this ? I mean, Can I have a page.php which extends a section.php which extends a master.php template? 2. What if I need to rename a imported block in a child template? 3. What if I need the content of a parent block in a child template, so that I can output parents output + its own content. 
what about the other two?
Thanks for following up.
I cannot see how this works. If I have a template hierarchy as shown below. page.php extends section,php which extends master.php, Suppose page.php and section.php both contain a block header. it seems that your code will execute page.php, then it executes section.php overwriting the header block created from page.php and finally master.php, which outputs the content of header block created from section.php. also shouldnt I also need to keep track of variables used in all the three templates as it seems to me that they are all in one scope? 
Right. Your job becomes maintaining and feature adding. You become type-cast as "the CMS guy" and nobody else wants to touch it. Just use one that exists.
Here is what I'm using in production: // PHP Stuff session.cookie_httponly = 1 session.use_only_cookies = 1 session.save_handler = redis session.serialize_handler = msgpack session.entropy_length = 16 session.entropy_file = /dev/urandom session.hash_function = sha512 session.hash_bits_per_character = 5 // Suhosin Extension Stuff suhosin.cookie.encrypt = on suhosin.cookie.cryptkey = {my-key} suhosin.cookie.cryptua = on And I usually set cookies like this: setcookie('somecookie', 'value', $expires_timestamp, '/', $_SERVER['HTTP_HOST'], isset($_SERVER['HTTPS']) &amp;&amp; $_SERVER['HTTPS'] === 'on', true); Edit: oh i missed that we were just talking about _session_ cookie.
So what you have implemented is not really template Inheritance....and I don't think you are anywhere close to twig. 
Yes, correct. It is not inheritance (although I say that in context of templating you get almost the same effect). In general it is just buffering, and combining buffers (maybe closer to piping). And my goal is not to even get anywhere close to Twig (for me it just feels almost the same from the usage point of view). If there is still something to remove from that 30 lines, I will gladly do that. I'm not sure I need `partial` for example. And I'm not sure I need view globals. But I know that I rarely need anything so complex as Twig with PHP (considering rendering is going so much to js). If you look any other microframework, they all have similar view-implementation. It is similar to this: http://codeangel.org/articles/simple-php-template-engine.html Could you point out what is the killer part of Twig? I may even try to implement that, if that is so great. Thank you for your great comments.
One reason why I chooses to stop using mysql_* is because I'm scared if it will be removed in future php. That's probably also the reason for many people too., other than those other reasons. 
This is dumb and cheap and unoriginal. It should not be in this reddit.
[Beating a dead horse, Wikipedia version](http://en.wikipedia.org/wiki/Flogging_a_dead_horse) 
What IDE would just close without prompting to save all your files?
Great to hear that you have found a tool that you like. There is no need to change it. I was just proposing another possibility that may give you 80% of what you already got with simple example that can be adjusted to user's own needs easily, but yes, you are correct that the missing 20% may be harder to implement. It would be nice to compare Twig performance/memory usage too. Symfony isn't exactly shining in this test: http://www.techempower.com/benchmarks/#section=data-r4.
You speak out of ignorance. We migrated *away* from wordpress because we wanted better integration with our platform and CRM. The result is the marketing department hassle us a lot less for minor changes to the site and it's much faster for us to add new features. I only spend time on the CMS when I get down time and it's pretty simple in it's design so it's easy for the other 2 to change it if they need to.
Looks like the linker can't find a library. 
Because it's old, lack features and is deprecated as explained in [the manual](http://php.net/manual/en/mysqlinfo.api.choosing.php).
Its replacements provide access to the latest and greatest features and should be more secure (if used correctly). Use [PDO](http://php.net/manual/en/book.pdo.php) or [mysql**i**_*](http://php.net/manual/en/book.mysqli.php) instead.
I got it working in the end, used an older version - no idea why it didn't work :S....
The same person who posted that Q&amp;A pair also pushed the effort to make the manual less mysql_* friendly. It's all part of the same effort :)
Regarding PDO vs mysqli, what are some of the pros and cons of each? I have been using mysqli for most of my development (i haven't used prepared statements yet because there is only like 1 or 2 queries in the entire site that take user input (and i just escape them myself) is there something that PDO does better/easier?
It is/should be, but it never hurts to remind people and hopefully help some newer users that might have missed it etc.
Might as well use mysql_ if you are going to manually escape things. Thats the entire reason behind using mysqli_ is so that you can use parameterized queries to eliminate the possibility of sql injection.
PDO works with pretty much any database. MySQLi only works with one. I'd go with PDO for flexibility, not to mention most frameworks these days use PDO over MySQLi.
The article leaves out that to ensure session cookies are ONLY sent across a HTTPS connection, you need to enable session.cookie_secure. There's also session.cookie_domain for additional control. You can also set them separately from php.ini (if using plain HTTP sessions elsewhere on same server) using session_set_cookie_params() per request. Edit: I neglected to mention session.entropy_length and session.entropy_file settings to evade insufficient entropy vulnerabilities as I described here: http://phpsecurity.readthedocs.org/en/latest/Insufficient-Entropy-For-Random-Values.html#there-s-an-app-for-that
Looks useful!
I also just started using mysqli because it looked alike (and its API comes close to the old one). PDO supports more database types, mysqli_ just MySQL (and possibly MariaDB), PDO has named parameters and supports client-side prepared statements. [Source](http://net.tutsplus.com/tutorials/php/pdo-vs-mysqli-which-should-you-use/)
I knew I was forgetting one of the settings as I was launching the article. Thank you for pointing out session.cookie_secure. I will update my post accordingly.
ok, I was following a guide that had a link. It claimed 4, but I'll re-download to make sure.
I spent a good chunk of last week teaching myself chef so I could get just this type of box up and running to dev on. Curse you and your timing :P
No changing of the hash function from default md5? No changing of bits per character from default 4? ; http://www.php.net/manual/en/function.hash-algos.php session.hash_function = "sha512" ; 4 bits: 0-9, a-f; 5 bits: 0-9, a-v; 6 bits: 0-9, a-z, A-Z, "-", "," session.hash_bits_per_character = 6 Results in session strings like this: &gt; Bo9PwDrFvCMfw1C1ePFRbnrpX,XWpfWHAUQTBh8LvLxlU3-ZMBOLZBEdDU4lIUFhwKJ1i9hwuNkJ3,q1xPzsm2 
Don't forget if you specify the domain, and you want the cookie to work for all subdomains, you need to write it like this: .domain.tld
A bit overkill; I think SHA-1 would be sufficient to avoid collisions unless you have a very popular site.
Most people just use sessions without thinking about it. They also don't know that the httponly thing exists while it's very powerful if you ever fail to protect against XSS.
Oh damn, thanks for linking that!
*Web stack* ... PHP is usually part of a web stack. This has literally a lot to do with PHP because PHP is a programming languange, and this is about programming, and especially for the web. It may be considered somewhat indirect, but it is very much related.
Do you code for a living?
:-) Someone also kindly pointed to this which looks like the original: http://thecodinglove.com/
Thanks :-) Hey, I'd say it was worth posting at least to find out about the more original gems, if not for a few laughs for people who haven't seen any of it...
PHP can be a templating language if used right. Avoid smarty (templating engines) like the plague. You are just adding another layer which is not needed. Source: Help build a custom cms while using smarty (pain in the royal ass)
If the form is now pre-populated with that information withouth anything being set in the query string, then most likely, your site has already been hacked. In general though, that code is mostly just likely code that was converted over to it's ascii characters (and possibly some other things), designed that when it works properly, it would convert it back to a string of the actual code, then get "eval"'ed which will execute the string as if it was code. One thing to know if the site was hacked, it is time to go through everything on the account to check for any changes/additions (hint, first thing would be to check the time stamp on the file with the auto filled form) Also, go to the form on a different browser, to make sure it isn't a case of your browser is actually filling in the input from when you manually did it once before and you have overly "helping" settings to prefill for you.
You used WordPress and it didn't work out, so now every single CMS ever is bad? 
/u/jtreminio has perfected the Art of Amazon. (They always release AWS improvements a week after I've come up with a workaround ...)
Are you using your own code or running something like WordPress?
my own code.
Did I say that? No, I said it suited our situation better and the result has been positive.
Is there something similar but for general VM's? or that you can choose the kind of stack you want to build? 
I got the same result.
I renamed puphpet.gz to puphpet.tar.gz and it worked as expected. Perhaps line 142 of Front.php should be: header('Content-Disposition: attachment; filename="puphpet.tar.gz"'); I do not have a php env on this box to test it with but if I get it set up so that I can check if this fixes it. 
It works fine for me, at least, right now it does. May I suggest in future downloading the docs from http://www.php.net/download-docs.php ? I personally use the HTML Help file (chm) as it provides a complete and searchable reference. I've had issues with the "HTML Help file (with user notes)" chm, so I personally wouldn't recommend that one. If I recall, while everything is there, not everything is in the index.
Sure
Look on the bright side: you've learned something very useful!
That's awesome to hear! Always nice to get positive (and negative) feedback 
Avoid Smarty, **yes**. Avoid all Template Engines, **no**. Use PHP in the view layer, **no**. I advise against using PHP mixed with HTML because you forget to escape. My favorite: Twig. Escaping default on.
Neat. Now I have a compelling reason to use Composer for PHP.
find any particularly awesome resources with that endeavor? I'm learning chef.
I noticed that too today. 
One way would just be to use the Pusher JS library, subscribe everyone to the same channel, and then count the number of users subscribed to a channel. Then whenever someone joins/leaves the channel, you can update the number the DOM.
instead of using `new Template` inside the `Template` class itself, use `new static` or `new self` if you don't want child classes to use that static scope.
Great suggestion, I was aware of PHP5.3's late static binding but not of using `new static`. That's a definite improvement and I just learnt something new, awesome.
starting up a LAMP stack via a VM for php 5.4 is out of the question for you ?
Trying this out and experiencing REALLY long page loads once the VM is up. phpinfo() takes about 30 seconds to run. I boot up my normal development VM and things run quickly with Apache2, so I'm really at a loss. On the Vagrant generated VM, if I remove apache and install/configure nginx, my PHP apps load instantly. Anyone else experiencing this issue?
Hi there That's usually due to Xdebug trying to make a connection. What you need to do is go here: http://www.jetbrains.com/phpstorm/marklets/ Create bookmarklets for Xdebug with IDE key "xdebug". Save them to your bookmarks toolbar. Go to your phpinfo page on your VM (or any page). Wait for the page to load, then click the "Stop Debugger" bookmarklet. Reload page and you should see page load speeds return to normal.
Thanks for the tip. Unfortunately, no change here. Still extraordinarily slow loading with Apache2 but instant with nginx. 
It's worth remembering that there are also many, many mirrors available if the master site is having problems: http://ca.php.net/mirrors.php.
Because PHP is so rarely associated with a web stack... Right. If most of /r/php are hobbyists and not professional, then you may have a point.
I thought the same thing, but it came back pretty quick.
Well, it looks like a templating class you'll find from any tutorial on the web. A few things, though: * You might want to consider making it SOLID. * Add phpdoc blocks to the methods. * There are no view helpers. If you want to take things further, there are some other things you could do as well, such as make it view model-aware and have it resolve an appropriate presenter based on a rendering strategy. To do that, you: * Create a view model interface and add concretions. * You create a rendering strategy interface and add concretions (for instance, one for resolving based on the Accepts header). * You create a presenter interface and add concretions (your actual templating engines, e.g. PHP, JSON, XML etc.). You add these to your rendering strategies via an addPresenter() method or whatever. * You create a view class to which you set your rendering strategies, and a method for rendering a view model. It will go through the strategies and grab the first one which matches, and retrieve the presenter from it.
Stealing an idea from the Yii framework, instead of: $t-&gt;greeting = 'Hello'; $t-&gt;who = 'world'; echo $t-&gt;execute(); Perhaps allow for an identical syntax: echo $t-&gt;execute(array('greeting' =&gt; 'Hello', 'who' =&gt; world')); Just an idea - it might not be the best depending upon your needs.
Then there's of course this one too: http://ponysecurityreactions.tumblr.com/
Hah! Well, I can't think of a whole lot of reasons why that would not exist on the Internet. Thanks, Reddit.
I honestly think you should try and search in google a bit before trying to get answers, show a bit of effort.
I got it running soon after writing this comment. Edit: When I referred to workflow above, I just meant whether I should be adding any vagrantfile I create to version control, that's all.
Quite honestly I was reluctant to come here with the question. I have done html, css, java, and c++ without having to ask reddit for help. On this I was truly stumped and wanted help from people that actually knew what they were doing so that I didn't learn some janky way that wasn't efficient. I apologize if I offended you by asking a simple question that would have taken you 5 seconds to either answer of just look away from. Isn't the whole idea of a page like this to help others learn and to learn from others?
You should definitly have a look for OAuth. You won't need a own database with password hashes etc. Your "Friends" can log in with a facebook/google/... account and if they have security concerns you can say "my app doesn't have access to your password ever". http://www.cheatography.com/kayalshri/cheat-sheets/oauth-end-points/
Can you be more specific about what you're confused about? Have you got a database and a web server already running? Have you got a table in your db for your users, and a plan to store profile information in some way? Vanilla PHP or a framework? There's many ways to skin a cat, so the more specific you are with your problem the more likelier you'll get useful help. 
&gt; Because PHP is so rarely associated with a web stack... Right. You're seriously missing the point. PHP is almost always associated with a web stack. That doesn't change the point that *all posts must be related to PHP*. And, again, this post is not. It's like saying a post about PHP is related to C since PHP is written in C.
&gt; I apologize if I offended you by asking a simple question that would have taken you 5 seconds to either answer of just look away from. Isn't the whole idea of a page like this to help others learn and to learn from others? People are far more willing to help people who have at least tried to help themselves. What exactly are you having trouble with? Connect to mysql database: http://www.php.net/manual/en/mysqli.quickstart.php Use sessions to store user state: http://www.php.net/manual/en/session.examples.basic.php Grabbing POST data from forms: http://php.net/manual/en/reserved.variables.post.php Isn't that all you need? Any gaps can be found here: http://lmgtfy.com/?q=php+login+tutorial 8th link looks relevant: http://www.wikihow.com/Create-a-Secure-Login-Script-in-PHP-and-MySQL
I doubt that would help much, to be honest, as it wouldn't really resolve the whole black box feeling. I recall having felt the same thing when I first started off with MVC frameworks in PHP, not really knowing how the controller actually got loaded. Introducing him to more frameworks would merely add more black boxes to the mix. I think you're better off explaining how the request cycle actually works, from URL rewriting to a front controller, routing, dispatching, to finally loading the controller and invoking the appropriate action method. That way he'll have a general understanding of how a MVC framework works, which he can apply to any of them. 
Thanks for the suggestions. I'm reading up on SOLID to see what I can apply. Adding phpdoc blocks is on my list of things to do and I think adding some simple view helpers would be a good idea (I'm assuming you mean stuff like escaping html, creating link tags, handling html attributes easily etc). Making it view model aware is probably beyond the scope of what I need for the moment. It's really just something small to ease into the process of publishing code and if I had a project with more advanced requirements I'd probably go with something like Savant (or Twig if I wanted non-PHP templates).
Thanks for the reply. I agree that it is largely understanding the MVC pattern and not an individual framework. Perhaps then, I need a good way of explaining this. I thought a video would help aide this compared to me just talking - which depending on how well I am able to convey the points might just confuse him! Some sort of visuals/diagram I feel would still be useful in this process (like a very brief lecture).
Do you have any recommendations for systems I could study that do the more advanced features? My Google-fu hasn't turned up any clear examples of systems that do this. 
I've done the same quite recently and focused especially on building a minimal php with as few features as possible: [My blogpost](http://blog.balrok.com/compile-small-php-performance-messures/). 
http://laracasts.com/
Well, if you'd like, I could have a chat with the fellow and try to explain things.
I'm not sure a video can convey enough condensed information for someone sceptical about frameworks. If he has enough time, the Symfony book has a great introduction/explanation of what's going on behind the scenes. http://symfony.com/pdf/Symfony_book_2.2.pdf?v=3 A lot of modern frameworks are incorporating some of the SF components, so it's good general knowledge for a lot of stuff.
best tool ever, thanks for pointing this out
I use [dash](http://kapeli.com/dash) so I've got an up to date local, searchable version of the docs, works well.
OAuth is not for, and should not be used for, user login. It's meant for applications to gain access to another website on behalf of a user. What you're thinking of is OpenID (or Facebook's version of it, Facebook Connect, or Google's version of it, Federated Login).
Not anything that stands out. I spent a good deal of my time buried in the chef documentation and rummaging through any github vagrant configurations I could find. 
I was curious about *why* OAuth shouldn't be used for authentication, and found this fantastic SO question thread: http://www.stackoverflow.com/questions/7060748/why-should-i-use-openid-for-authentication-rather-than-oauth
Didn't want that page load time anyway
One suggestion: name the files according to some of the attributes -- currently, if I make 2 different setups, the resultant files have the same name. Only by poking around inside the files can I determine which is the x86 and which is the x64 (for example).
This is what I'm looking to do. 1. Setup a login system that allows a user to sign up, using name username and password. The system should allow the user to also log out. 2. Setup a RSS feed that allows users to post text content that is then placed in a news feed much like twitter. A user can't post to the feed without being logged in. Does that make it easier for you to assist me? I appreciate your time! 
Good, im glad it worked for you. That is generally not how it works out for other companies. I base that not off of ignorance, but on the fact that my job for a long time has been helping companies get OFF of legacy and custom systems and onto something else. Again, im glad your custom solution works well for you.
Good idea. I'll add it in.
I've had the best luck with config files that are read based on the domain name.
I think you're getting HMVC and Cascading Filesystem mixed up. HMVC means that you may have a route /blog and within the controller/view for that request, you also call /user/links. This is a separate request, with it's own lifecycle, which is ultimately incorporated into the parent request. This means each can have it's own caching logic, or even reside on separate servers etc. Kohana's cascading filesystem (detailed here http://kohanaframework.org/3.3/guide/kohana/files) basically defines an order of precedence for loading new files. I'm a long time Kohana user and also find it excellent, but it does impose limitations. For example, I once used a module that extended the core Request class, but my application extension overrode that! In terms of what you can move on to, the way I've gone is to rely on abstractions and interfaces. For example, my application doesn't use Request, it uses anything that conforms to the interface for Request. This means I can start with the base Symfony Request class, extend it with my own changes, and then use that in my class. Laravel actually provides a very nice IoC container, such that I can swap View::make() in my application for my own View class just by changing the service provider. It might be worth looking at the docs for this: http://four.laravel.com/docs/ioc Basically, Kohana's system is very simple and efficient, but it does have major drawbacks (think testing). DI and IoC are the future, but take a tiny bit more thinking to get going.
I think Puppet can also be a candidate.
Thank you. I will add it to the research list.
I've been using Chef::Solo lately and it'll make you l learn some Ruby, but it's pretty nifty.
To get past some of the Black Box understanding of MVC, this video is helpful... then getting more specific with frameworks can be approached with each of the frameworks home page, most have a clean, concise description on what makes them stand out. http://youtu.be/qXRcVhWxuaU :: What is MVC?
Nice to see Kohana's CFS getting some love here :) Kohana's autoloader does support PSR-0, and you can use composer fine outside the application/modules/system hierarchy, as you load modules in bootstrap from wherever you want, in order of precedence. The real key to allowing "transparent extension" in Kohana's way is that modules/packages should only every reference themselves through their empty stubs, so you can override single properties or methods very easily. Just as you'd work with Propel ORM's model stubs, in other words. So basically packages need to follow this convention, but it's quite unlikely outside the Kohana ecosystem of modules, so we're left with other options, like DI and hard-coded extension points, event hooks, etc. P.S. Another nice thing about Kohana's CFS is that everything in every config/ directory is merged recursively by the config loader - so you can override just a single module config value in your application very easily. I know others emulate this, too.
Yes, the Symfony book is good, and the chapter on [Symfony 2 versus Flat PHP](http://symfony.com/doc/current/book/from_flat_php_to_symfony2.html) is especially enlightening. It works step by step with a blog example, from a bog-standard 'flat' procedural version, gradually adding more MVC elements to the example, explaining which problems are being solved by each step. Compulsory reading, IMHO.
Could also look into Amazon Elastic Beanstalk http://aws.amazon.com/elasticbeanstalk/ When you put to EBS, it will push your code changes to all your server that are behind the load balancer automatically. This way you aren't responsible for keeping track of each server behind the LB and making sure your code is in sync after a push.
Codeigniter used to have some right on their page
Requires ZeroMQ
The simplest method is to just simply clone repositories to specific tag commits and having your app setup in such a way that that is the only thing needed to get your app working. Future updates would be as simple as "git fetch" and "git checkout &lt;tag&gt;".
Unfortunately, I can't speak to frameworks per say. I can however speak to Wordpress. Inside the wp-config. I have an if condition looking for a local-config.php file. This file is only existing on my dev machine. If it exists the local-config settings take. If it does not exist the production settings take. 
I am honestly surprised to find this many people who show some love for Kohana. It is very rarely talked about on this sub reddit which is one of many reasons that I considering switching to another framework.
We use [Phing](http://phing.info), which is a pure PHP port of Apache Ant, and git push/pull to deploy. The syntax is a little strange, but the advantage of it being PHP is that it's easy to write custom tasks for logging, flushing caches, building config, etc.
If you have a config file structure, I'm assuming you're using a framework -- so it depends on that framework. Laravel and more recent frameworks have their own specific ways to handle conditional config file loading. Others (CodeIgniter, for example) define an environment variable in the index.php file that I like to use for conditionally loading config files -- I just map the environment variable's value to the config folder name. Unfortunately, in the latter case, you have a similar issue of where to swap index files to change the environment variable. I usually do this through some sort of deployment process, depending upon what's available.
Look into git hooks (post-receive) and fabric (fabfile.org). When you push a branch, post-receive gets called with $orig_sha1, $new_sha1, $branch_nane. Fabric is a python ssh wrapper that lets you run stuff on N servers. When pushing to a branch called ref/Deployment/[Production|Staging|WhatHaveYou], fetch the host-list from AWS and run the deploy script on all servers. git tag Deployments/$ENV/$YMDHIS for s in servers git fetch git reset --hard git checkout $new_sha1 # then custom stuff like git submodule update automagically update config file with running environment hosts etc health-checks ... I hacked that up in a day at my old job 2 years ago. I could, and probably should, have investigated tools like deployinator or dreadnot in depth. But it's simple and works; they still use it without complaint. The only "real" problem is that re-doing a same deployment twice is impossible since the git server won't bother with your push because it's already up-to-date. But yeah, also look into deployinator/dreadnot. Puppet/Chef as others have mentionned.
But it used very old version of Codeigniter. net.tutsplus.net does have some videos about Codeigniter.
Thank you for this. Bookmarked.
I keep a class with passwords and what not on my production server. It's backed up, but doesn't go into version control, and is listed in .gitignore. 
I'm a fan of [Fabric](http://fabfile.org/) for my deployment scripts. I use them to deploy 2 apps, both of which live on between 3 and 6 servers respectively. Fabric at its core is a parallel ssh library. You basically declare commands that run on remote servers as Python functions, then declare which specific servers that function (or "task" in Fabric parlance) should run on. Mix and match that and you have a fairly robust multi-server deployment. [This is a sample from our live deployment script](http://pastie.org/private/vwccwoyipxcliyhtpfbhwg) (ignore the double @@, that's a fragment of pastie.org that happens, should be a single @). We use SSH keypairs so in order to run the script your machine must have the keypair setup. Obviously our production servers are git checkouts, this isn't a requirement as Fabric provides commands to upload/download files (so you can run a local command to tar.gz everything, upload said tar.gz, and extract in the proper place).
It doesn't matter if we're talking about specific code or theoretical code. The premise remains the same. I said I consider a code formatter that rewrites code to be (conceptually) broken. I think you're confusing that with me saying this instance of rewriting results in broken (as in non-working) code. $foo = BAR; if ($blah) { $foo = BLAH; } Could be optimized to $foo = $blah ? BLAH : BAR; and is functionally the same, but I still consider a code formatter that does that to be broken. I would have 0 problems with this sort of feature being bundled with a code "optimizer" or some other style of app. If I were using Word and it had a feature to fix my system clock being out of sync whenever I ran a spelling check I would consider its spell check to be broken. If it fixed by system clock whenever I used an "insert current time" macro then I wouldn't. Does that help clear up my point?
You did not offended me in any way, but as MMMonsterKill said, you should show a bit of effort in research regarding your question. I would recommand you to either try the vanilla PHP options as descibred by MMMonsterKill or go with a simple framework using exisintg modules configured for your needs.
Same here. Did you also request invite? https://gaeforphp.appspot.com/
Config files that are deployed with the project itself. Deploying to prod environment? You get the prod config. Vise versa for testing. This does require a custom deploy process though. Beyond that, the configs just live in a properties directory under the root of the project and ARE version controlled.
I'm not trying to be a dick, but to reiterate: the logic **does not change**. You may have a preference for the original version (every dev has their own preference), but the code cleanup **doesn't change any logic**. Since nothing in the code flow changes, I can't consider this code-cleanup tool broken. I understand you don't prefer the version it creates; that's why the optional flag is there. Your conceptual idea of broken is not the same as actually broken. Conceptually is subjective, but objectively the code output is the **exact same for each code sample**. 
This is how I do it - for PHP 5.4.x, rather minimal. Need to update my notes to PHP 5.5 once it goes final. https://github.com/magnetikonline/webserverinstall.ubuntu12.04/blob/master/configure.php.txt
If you want to talk about amateur and unprofessional you can use your behaviour on this thread as an example. I am also a self-employed developer/designer. Sometimes I do "big-ish" projects, but most of the time I work on things that you would apparently sneer at. I work with teams, but more often I work solo. I use GIT, but sometimes I go FTP-commando .. and it is appropriate. You may consider me an amateur, but I feed my son and pay my rent with my income. Your attitude and language make you sound like a 16 year old boy. 
wow that script does alot of interesting things, not totally sure you should share that without disabling parts of it lol
comment out 8-14 and line 32 and you can run it on your local machine to see its power. full fucking control.
Anyone executing PHP code, which they found under a title explicitly indicating that it is malicious code, gets only what they deserve. :P
At first I thought the same thing. But this was an awakening for me and I think that us up and coming coders often put the possibility of our work being hacked in the closet. Out of site out of mind. I honestly had no idea that one echoed $_GET could allow someone to do so much.. Every coder should run this script (local only) and see what is possible and then be aware.
shell_exec etc... is a PHP command to execute Consol level commands. Like in Windows, when you go CMD and bring up a command prompt. He disables it in his PHP.ini file; the .ini file allows you to set what you will and will not allow
Looks sort of like C99.
&gt;echoed $_GET [MFW](http://images.sodahead.com/polls/002791693/2540276099_OMFG_answer_1_xlarge.jpeg)
Interestingly saving this into a text file caused windows defender to detect it as malware.
The password is root. http://www.md5-hash.com/md5-hashing-decrypt/63a9f0ea7bb98050796b649e85481845
Are there non-enterprise level third party services I can hire to audit my server security for a few hundred dollars? If so, where do I find good ones?
&gt; The environment includes the PHP 5.4 standard library. Yesh! So, my understanding of GAE is that everything ends up running on the JVM - hence the requirement for pure Python (Jython), and now pure PHP (no C extensions). Does that mean Google has written a PHP interpreter for the JVM? I'd love to get my hands on that if it exists. Edit: To answer my own question, apparently such a thing exists [and is called Quercus](http://en.wikipedia.org/wiki/Quercus_(software\)#Quercus).
&gt; one echoed $_GET I think I understand but not being 100% sure is terrifying. Can you please clarify if I understand right? You were hacked because one of your scripts included echo $_GET[x]; and the hacker put a query string in the url making X a function that downloaded and ran this file? Like: example.com/index.php?x="0']; include('malicious_file.php'); hack();" Is this in the right area? [edit: thanks for the responses everyone. I misunderstood. I thought OP was saying the echoed $_GET statement was the source of the vulnerability, rather than showing all of the code that can be executed.]
Not sure if you can do something like that but you can definitely insert a bunch of bad javascript and stuff into the rendered page.
Sure there are. We do our own security for our clients, but I have heard good things about Rack911.com
Shouldn't that be an Abstract Factory?
With an opcode cache, as well as Kohana's own path caching mechanism, this expense disappears - not so for Reflection.
How about overriding a template file, or a message file, or a config file, or a bootstrap? The beauty of Kohana is that the whole file structure is mirrored in every defined path. It's really quite elegant and transparent. The image here captures it nicely: http://kohanaframework.org/3.3/guide/kohana/files 
No, if anything it would echo it as a string of text, or cause a fatal error. What they have done here is created a nifty script with code written to do things like run sql queries, exec commands etc. This is what they upload, after they find a vulnerability in your system. Its simply a one page tool with all the things a spammer might need to setup an account and send 1000's of spam email, or add it to their botnet. This code DOES NOT hack a site
yeah there is a ton of useful stuff here. could anyone care to comment on how long a rookie with a basic of understanding of php concepts could study this or other shells (being scripts with shell access?) surely this kind of control can be wielded in a useful way?
From what I know of the runtime, it's running stock PHP (although, patched in some areas).
Which do you think is quicker: Is it here? Nope. Is it here? Nope. Is it here? Nope. Is it here? Nope. or It's here.
You can save links you know. 
We are using Zend Framework with an API on Phalcon but I've heard good things about Capistrano as well. I'll have to spend some time with it.
This isn't a way to take over a system. This is the damage done after the system is already compromised. 
why do you need to store blah4 at all, if you can get it from blah1 and blah2?
Write something fictional, or consider some tests you'll take when applying for a PHP job. User registration forms are common. Build a framework to handle bad data.
Someone should tell them to use stronger passwords. Maybe they can use bcrypt, too.
The only thing that should take a db connection as a dependency is a factory, IMO, but I guess that's not what we're talking about.
But it's not though is it. It's here. Okay, let's instantiate a reflection object for this class. Oh, it needs this class. Let's do the same for that. And any others. And then when we actually want to create the original object, call a dynamic method (which is noticeably slower when you consider how many times you do it). As public_method pointing out, (opcode) caches will negate the performance hit of those lookups. Yes you can manually wire up DI, but then you lose a lot of the benefits.
I'd not be worried about someone accidentally executing it, so much as enabling more script kiddies, but honestly it's probably all a wash.
Indeed, and since resolving of all paths can also be cached in Kohana, in production vs development the answer is always: it's here. Anyway, enough Kohana love! The framework has its own problems, just the CFS isn't one of them.
 $config = array( "blah1" =&gt; 1, "blah2" =&gt; 2, "blah3" =&gt; "Value3", "blah4" =&gt; function () { global $config; return $config["blah1"] + $config["blah2"]; } ); This way you don't have to care about updating the blah4 value. $config["blah4"]();
I agree with this, but not storing this as a global. $database = array( 'hostname' =&gt; 'localhost', 'port' =&gt; 3306, 'username' =&gt; 'user', 'password' =&gt; 'password', 'mysqliFormat' =&gt; function($config){ return "mysqli://{$config['username']}:{$config['password']}@{$config['hostname']}/{$config['database']}"; }, 'pdoFormat' =&gt; function($config) { return "pdo://{$config['username']}:{$config['password']}@{$config['hostname']}/{$config['database']}"; }, ); $database['pdoFormat']($database); $database['mysqliFormat']($database); Even this wouldn't be desired, and I would personally put it into a class and write the functions to retrieve it in specific formats, or write a class (or functions like above) to format them when required.
Honestly the best way I can see you doing this is writing a class with blah1 and blah2 stored as class variables (given to it via a set method or at construct) and writing a function to be blah4. Arrays are very flexible, but depending on your use case, a class might fit it better and save you hassle later on.
this is the right usage: function () use (&amp;$config) { ... } don't think op needs any closures though
the 2nd one is totally fine, you don't need to waste any additional time/memory on closures like in other examples here.
why do you think your site got this? how did he hack your website? how did you find out this? if you may answer... thanks..
you could also do it like this: $blah1=1; $blah2=2; $config = array( "blah1"=&gt;$blah1, "blah2"=&gt;$blah2, "blah4"=&gt;$blah1+$blah2, );
There are a number of ways to handle this, the better ways would depend on how you're planning to use it. $config = array( "blah1" =&gt; 1, "blah2" =&gt; 2, "blah3" =&gt; "Value3",); $config["blah4"] = array_sum(array($config["blah1"], $config["blah2"])); 
It is more likely that something like this was done: include('function/'.$_GET['action']);
i had a form that had action="somefile.php?&lt;?php echo isset($_GET['x'])? 'y='.$_GET['x'] : '';?&gt;" I think he used a query string xxs attack like: mywebsite.com/myfile.php?x=&lt;script&gt;alert('attacked')&lt;/script&gt; (but way more bad ass than that) 
Now I know better and can say the same thing.
my new favorite: https://gist.github.com/nikic/3707231 from what i understand it is not available in the current PHP version but you can include it. 
nice.. 
I found windows to be good at detecting these things too. We would rsynch all our sites to a local server. Then using samba I would just scan all the files. Windows essentials AV would then find scripts that none of our server-based scanners were able to find. Just one tool in the box, and you need to use them all. 
I downloaded 3 other files that were inserted in various places on the site. actually there were several copies of each file. one of the files appears to communicate with a server but the functions use encrypted variables. They are not hard to decrypt but I don't have time right now. So far all I know is the server is in France.
&gt; Zend\Replier\ReplierFactory\Replier\Reply\Reply Makes me want to gouge my eyes out.
&gt; Zend\Replier\ReplierFactory\Replier\Reply\Reply Makes me want to gouge my eyes out.
I used to use something similar back in my hacking days. It was merely for the fun of it. 
It's much more cleaner than what I've seen.
Yes, all can be done.
Can you post your form code to see if anyone else is making the mistake? I don't imagine you'd also have the string he typed into the form, do you? If you do, can we see it?
Nice try Kev from Rack911!
You mean to say the user notes version does not have the full index of the PHP manual proper? 
Huh? I don't work for, nor have I ever used Rack911 for any services. I have heard good things about them from some of our clients. Put away your pitchfork.
Right, cache all the things. I'm not against CFS, we used it for FuelPHP and it beat the fuck out of the logic stuck in CodeIgniter. Even when it implemented "Packages" and "Sparks" the logic was still barely any use. I mainly commented to let you know why they're going out of style. The system in FuelPHP used namespace aliases to achieve its CFS, and with things like PSR its much easier to implement "Components" (like Kohana modules) without any trickery. If I want to override some core code in one of my modules I just make a class, extend the core class, and overload the method. Utilizing namespaces I can throw in: use App\CustomSessionMadness as Session; and I'm all set to use Session without changing my code. I think CFS solved a problem back in the PHP 5.2 days, but in PHP 5.3 namespaces take care of the same thing with minimal trickery.
That's just what Kev from Rack911 would say...
i had a form that had action="somefile.php?&lt;?php echo isset($_GET['x'])? 'y='.$_GET['x'] : '';?&gt;" I think he used a query string xxs attack like: mywebsite.com/myfile.php?x=&lt;script&gt;alert('attacked')&lt;/script&gt; (but way more bad ass than that) 
Seconded. The problem with the first is that you're referencing the $config variable *as you declare it*, which is going to throw an error since, until the compiler reaches that ';', it does not exist.
https://github.com/adrianmacneil/omnipay/ It doesn't look like there is ActiveMerchant support, but if you want the abstract portion to be done maybe you could write the gateway code. 
It's worth looking at the AppEngine SDK code. They avoided most conventions. A few of the most obvious: * Multiple namespaces per file (including a "dummy" one for includes) * Manual require statements (no easy class-to-file discovery) * Only setting/getting properties, not explicitly defining them in classes It works obviously, but it would be nice to see a kept-up-to-date, phpdoc'd, PSR-2-ish (or similar) SDK on packagist.
Always filter input, escape output. If you are building query strings, there's a php function for that, lookup http_build_query http://php.net/manual/en/function.http-build-query.php
If you create your own abstract interface to the billing calls, and only call those interface methods and never the merchant-specific methods directly, you should have a fairly easy time swapping that merchant out for another one in the future. I would try to avoid having to use a library in a totally different language just to decouple the merchant API library. You would still be needing to call the methods that call the ruby code.
I use git to push to multiple servers, by adding the following code in .git/config on my local box: [remote "origin"] url = https://user@bitbucket.org/user/repo.git fetch = +refs/heads/*:refs/remotes/origin/* [remote "master"] url = https://user@bitbucket.org/user/repo.git fetch = +refs/heads/*:refs/remotes/origin/* pushurl = https://user@bitbucket.org/user/repo.git pushurl = ssh://user@ip-1/path/.git pushurl = ssh://user@ip-2/path/.git pushurl = ssh://user@ip-3/path/.git ORIGIN is used as the repo that I work on all the time, it contains all the branches, etc. MASTER contains all the servers that I want to push my code to, using SSH. Of course the server must already have git and be setup properly. So I do this: git push origin master to push to bitbucket git push master master to push to all the servers I hope this help you or some other folks
Regarding phpMyAdmin, the issue is that the software is not always kept up to date on the web server. This tends to happen more often when people are running their own web servers and don't keep up with the security updates. Also, the fact that many times phpMyAdmin runs off the root of the domain (mysite.com/phpMyAdmin) makes it easy to run scripts that just look for instances of unpatched phpMyAdmin running there. Once found, the script can easily inject code to allow for much more extensive hacking of the site/server. Do not run phpMyAdmin from the root of the domain to avoid being targeted by the automated code injection scripts and keep phpMyAdmin updated and stay informed of security updates for the software.
The config merging thing is a great point. I tried using Laravel and the fact that it didn't do a deep merge of config (just used array_merge) was an instant turn off.
The only problem I have with your solution is that it is not global. If I want all the modules to use the CustomeSessionMadness I just make a file called session.php in my app class folder and be done with it. You would need to go trough every file that uses the session directly and replace the use path\to\Session with app\CustomSessionMadness. That is a lot more un needed work imo. 
Right, and that is why I used to totally agree with you, but these days I generally prefer to not globally override my entire codebase as it can have unexpected side-effects. If I did want to do that I'd use DiC/IoC to do it as I can easily see what is being registered and change how this works in different environments (such as testing v development v production) and not use file-system trickery which is going to be the same wherever it is. That said - as with everything - if you application is well tested it probably doesn't matter, but I find my preferences to these things changing over time and you might too. 
That's learning each gateway's API, coding and testing functionality that is already written. I usually do that when I can't find a library that meets my needs, but in this case it looks that they are doing a better job at implementing every gateway API. I don't discard the idea, but I'd love to use something proven to work and with a robut team behind, so I can focus my time on building product!
You need a space after echo most likely
That would be an option. Do you know if it is actively maintained? Is it used widely as a standard library? 
I was watching you fight the good fight on this last week. Your tenacity is remarkable, and to be commended. I'm not sure why this is even a controversial statement. Maybe I can take some heat off you. PHP kills kittens.
Fair amount of activity, not sure about the usage. https://github.com/adrianmacneil/omnipay/commits/master From the readme: Omnipay is a payment processing library for PHP. It has been designed based on ideas from [Active Merchant](http://activemerchant.org/), plus experience implementing dozens of gateways for [CI Merchant](http://ci-merchant.org/). It has a clear and consistent API, is fully unit tested, and even comes with an example application to get you started. **Why use Omnipay instead of a gateway's official PHP package/example code?** * Because you can learn one API and use it in multiple projects using different payment gateways * Because if you need to change payment gateways you won't need to rewrite your code * Because most official PHP payment gateway libraries are a mess * Because most payment gateways have exceptionally poor documentation * Because you are writing a shopping cart and need to support multiple gateways 
You might be interested in this discussion of Drupal on GAE: http://blog.boombatower.com/drupal-google-app-engine In short: it sounds like it will be possible, but Drupal will have to handle some stuff differently. He provides some early-days patching for D6&amp;7, but I haven't read through the code yet.
Using Dreamweaver. Joking aside (and my Dreamweaver experience is outdated), do you actually have a server running to process the PHP? I don't see why DW would show the output if you don't.
Impressive - Windows Security Essentials recognises this as a set of hack tools on downloading. Thing is, it's all in a RAR file, which Windows can't open.
You need Jesus. Or [usbwebserver](http://www.usbwebserver.net) or [Xampp](http://www.apachefriends.org/en/xampp.html). You need a process(which you can 'fake' on your PC) to run PHP since it's a serverside script.
Looks good! I'll look into it, and calculate how long would it take to add a gateway.
You really need to read these: http://uk1.php.net/manual/en/intro-whatis.php http://uk1.php.net/manual/en/intro-whatcando.php
I've been following this project on github for quite some time now, listening in on the pull request conversations and I must say: I can't wait to use this library in one of my projects.
Also OPs first output is not "Hello World", blasphemy.
Why would you run a PHP file with clientside code and no real PHP? No use in making a PHP file in that case. If you want to run PHP code(Which is kinda bloody obvious if you create a .php file) you pretty much are talking about a [server side language](http://php.about.com/od/phpbasics/a/Php-Is-A-Server-Side-Language.htm) The 'a process' is(in my point of view) not soft- nor hardware. Since you're stating it's software you can pretty much 'fake'(See them quotes?) your computer functioning as a server(You don't want a homePC as a server, trust me)
what would you suggest sorry windows 7 well thats what im looking to do I have no idea it was only an example it doesnt need one does it ? this isnt my first output, i've done the whole codecademy thing.
you have to sanitize stuff like that
1) Using dreamweaver. 2) Didn't save the file. 3) Expect DW to parse the .php file when what you need is to upload it to a php compatible server (could be your own pc, if you install WAMP, for example). 
The part I found tricky was activating the correct features in Windows' control panel, but yeah it's not impossible. To me, editing PHP in Wordpress's back end was way easier to figure out, but that's just IMO
you don't run computers AS servers (maybe you could say that about dedicated ones^^). you run a server (which is still software... see that httpd.exe in your xampp? looks like apache is software indeed) ON your computer. yes, you can run php as a serverside software since servers like apache have a module for that. but why is it 'no real PHP' if you run it on a client? never seen the console? never seen something like this? $ php yourprogram.php cause that's what servers with a php module do. with apache and php, you aim to deliver html and tons of data to your client (sounds logical, since php stands for php: hypertext processor). but you can do so much more with php. there is even a php gpio library for the raspberry pi. with that you can make led's blink with php (!!!). take a look at this: [php-cli](http://php.net/manual/en/features.commandline.php). i know, what you're talking about. yes, you can use it for your webapps, but you can also use it for the console, or whatever... php is huge and i don't want it to be denounced as ONLY a server side language.
Hi, thanks for this, great to get your feedback. 
Flawed. -&gt;set() is wayyy too short and not even close to being expressive enough. Try: $reply-&gt;setReplyDisplayDocument(new Zend\Xml\Document\ParserStrategy\StringParser('&lt;?xml version="1.0" encoding ="utf-8"&gt;&lt;reply&gt;kool&lt;/reply&gt;'), 1.0, 'utf-8', 'application/xml'); *Now it makes sense!*
Each to their own, but I personally use a few of these as they proactively send email to me with relevant information and I enjoy reading them. There's a lot of people who still prefer to receive information this way. As you don't thats fine too. I had the idea after using Pythonweekly.com and thats been really useful to me. Thanks for the comment though
That's fine that some people want to get it emailed and that you do that for them. But why not also have it viewable on the website? edit: Looks like [Python Weekly](http://www.pythonweekly.com/archive/23.html) does it. 
Download WinRAR, it's free. 
Yeah, you have a very good point. That is the plan. We just need to create the archive for it and get it on there. Kind of one step at a time. Thanks for the suggestion though
I'm feeling lazy so I won't put effort enough to answer on SO, but: You're looking for a `Assetic\Asset\GlobAsset` instead of just a `FileAsset`. 
Can somebody explain to me why I would want to use Google App Engine? Or why I should avoid using it? 
I think you're replying to the wrong comment. :) My comment was more of a joke: [most often, the first program one writes in a new language, is one that outputs "Hello World".](http://www.roesler-ac.de/wolfram/hello.htm)
your vimeo videos are going a long way towards helping me make the jump to 4. thanks.
You ought to look at the code again. He is accessing a function in the $database array, which takes a parameter. He then passes the $database array as that parameter to that function. The closure variable scoping thing isn't really applicable here.
sorry for awkward formatting. posted from my phone. 
Thanks for this. I must admit I didn't realise this existed. We've actually run a closed list for some time as part of something I do with a PHP-related product I sell. Kind of tips and information. When Python Weekly started we decided to create the same sort of format. I wouldn't say we're a 'competitor' though as we're just providing information to people. I'll reach out to the other guys :)
Wat
Why not a cheap VPS? You can get one from Digital Ocean for $5 a month.
So, what does the app engine actually DO? Is it just running my PHP code for me (so it's basically a free server)?
The ['name','foo'] notation must have been a quick hack. I would have expected something a bit more expressive. Because now I don't know what it does, because I have *no brains*.
Didn't Google just... Yesterday.
I was unable to given the capabilities of my mobile device. Thanks though.
read more here: http://www.reddit.com/r/PHP/comments/1e0m9d/it_seems_that_php_is_the_newest_runtime_on_google/ 
Asking if $5 is any good is kind of ridiculous, but do you use them, are they any good? I just might give it a go.
Eh, I used them for python. Documentation sucks, there is no personal support, and you were forced to use their Big Table database. Which doesn't support Joins. I wouldn't use google for anything ever again. 
I was actually just in a talk today at IO and I believe they mentioned they have joins now. They are called 'big join' or something like that. Then again I was pretty hung over and could be completely off the mark on this...
I'd use bcrypt. Its a standard at this point and, from what I've heard, its a secure hashing algorithm.
Typo3 seems to perform very well from what I've gathered of information about it
We use Capistrano a lot and I'm in the middle of starting to use Chef.
&gt; I also imagine you can't use a variable that isn't defined yet. You can, if it's used via reference instead of copy. Note the **&amp;** in the `use` here: $database = array( 'hostname' =&gt; 'localhost', 'port' =&gt; 3306, 'username' =&gt; 'user', 'password' =&gt; 'password', 'database' =&gt; 'database', 'mysqliFormat' =&gt; function () use (&amp;$database){ return "mysqli://{$database['username']}:{$database['password']}@{$database['hostname']}/{$database['database']}"; }, 'pdoFormat' =&gt; function () use (&amp;$database) { return "pdo://{$database['username']}:{$database['password']}@{$database['hostname']}/{$database['database']}"; }, ); $database['pdoFormat'](); $database['mysqliFormat'](); It's how recursive closure calls are done as well: $func = function () use (&amp;$func) { $func(); }; pS. `$database['pdoFormat']($database);` is kinda like calling `$this-&gt;someMethod($this)`. yes, sometimes might be useful/required, but not in this case.
Have you learned any php frameworks? Code Igniter is a simple place to start, even if it isn't very modern. Once that makes sense to you you can learn Laravel.
I prefer Python over PHP, but PHP on AppEngine definitely isn't "hacky".
So its just scalable cloud based hosting, rather than anything to do with Google Apps/Gadgets as such? Do gadgets even exists anymore? 
Definitely NOT free. Your code is "in the cloud". So is your database. You have no control over the hardware. 
Why the switch?
Out of curiosity why does everyone run to frameworks when you get the general idea for programming? Isn't it better to learn how to build something without already existing code?
I love amazon, I use a number of their services. (EC2, S3, CloudFront, Route53 including latency routing and healthcheck fallbacks.) If you are looking to start cheap and scale well, have a look at Elastic Beanstalk. Minimal setup time and maintenance and its set up to autoscale out of the box. So if you get slammed your php end will not bog down. (The DB portion is up to you though.) The downside to EB is that it is your front end only, no DB so you have to handle your DB software yourself. Out of curiosity, what are you using for data storage?
if you press the gear next to a post in the mobile view the save link option will appear.
The only problem with such a service is scale. If your service blows up, your hosed. One I was impressed with was http://www.tubalr.com/ . He got positively blasted with traffic when he posted about it on reddit and the only trouble he had was when he ran out of API calls for the music service he uses. He hosts on Heroku, which I liked but, I personally just use Amazon (which heroku is built on) directly because it costs less. This was more words than I intended when I started.
I see, thank you very much.
Correct.
&gt; You can, if it's used via reference instead of copy. Thank you for mentioning this. I was not aware that it is possible to pass a variable by reference into a closure and avoid it from copying.
Might look into a VPS from www.ramnode.com if you don't mind setting up your own servers. 
Now the infamous issue 13 can be resolved.
rss pls
Thanks for the comments, both on here as well as directly. We will add the following in on the site, hopefully next week - Archive of posts - An example, maybe showing the previous week - an RSS feed
Cleared your cache? Tried from another browser?
CTRL+F5 should have the same effect?
I remember it said "executed properly", but I don't remember if it said a record was affected or not... if not, then maybe my where query is fucked up... but when I used the exact same where query it selected the location I wanted just fine...
Deleting any session cookies might help. Also restarting apace might help as well as posting the code. I just got here recently so I don't know if it's against the rules or not. 
What do you mean by often... on my laptop ctrl+shift+f5 does nothing...
Does the "website" itself has some caching mechanism?(query cache/page cache).
I'm at home now, so I can't check at the momment... but if it does... then what, if it doesn't then what?
codcademy is really effective. but it really does only teach basics..
Well your description of the website is a little vague. Is it a known CMS, a custom in-house built app? If it's the latter can you post some code, or describe it in more detail?
We don't actually have many users on what we host on ec2 right now. We are still primarily using our dedicated server elsewhere. We are migrating bit by bit. The price is quite a bit more than if you own your hardware and colocate it but with Amazon we will have the ability to scale at will and don't have to worry of hardware dies. 
Oh, I feel much better now. I tried to learn it once, and failed. 
I think your post would rather fit in /r/phphelp. &gt; The PHP seems to reference this database cell for the home page... I would strongly suggest to stop guessing and start debugging. It can be wrong record, wrong database, file cache, etc. Where is your website hosted? From the age of the website, I am assuming it isn't VPS/Dedicated. So is it shared hosting or you hosting it on your own server?
I will come back with more details when I go to work tomorrow morning. This is on a server maintained by our department's college. It's kind of interesting, but a research department of 4-5 PhD's in mechanical engineering puts their website in the hands of undergrads... the last guy knew less about programming than I did (per his and his bosses' testimony) so... apparently I'm more qualified than the last guy. EITHER way... I appreciate the help. Will be back tomorrow.
Hooray, now I can avoid Python!
PHP 5.5's password hashing api uses bcrypt by default.
free as in beer. It has a free usage tier
Yes, but google charges for them now. And there's not really any realtionship to the appengine. App engine is PaaS, apps are SaaS
Well... I think he means because the PHP VM is quite "assuming" of a certain kind of environment. The amount of PHP they've had to disable and mod does suggest that its not perfectly suited to being "scaled" though the back-door. 
Just a note, as the curator of phpweekly.info, you can view all emails on the site archive (www.phpweekly.info/archive), which I tweet via @phpweekly when they're sent out, and there's an RSS feed with full article content.
We are using AWS for couple of big projects that require horizontal scaling (via spawning multiple instances), and we love it. But there is a plenty of better price - quality solutions if you don't need horizontal scaling. |The DB portion is up to you though. There is RDS (Oracle and MySQL) and DynamoDB for NoSQL, though they don't fit in free tier.
Well, considering the bandwidth available, i don't see how. The package they have for "free" is barely usable for development.
&gt; avoid it from copying Well, php uses copy-on-write so it's not necessarily a real copy, but you're welcome :)
They allow you to upgrade at pretty much anytime. Thier vps run on ssd drives which is a huge bonus. We have been using them for a couple months. I love thier api and I've had no issues so far, they're prrtty full featured. Also have you considered getting a dedicated server? Often for the same price for the amazon ec2 or heroku apps you pay more than a dedicated server. Put plesk or cpanel on it and focus on your app. I've run my own server for the past 5 years.
uh.. wow. get your client a micro instance for like $100 a year at amazon. done. 
[Gae for PHP?](https://gaeforphp.appspot.com/)
Definitely not XSS. You can't write to the FS using XSS. Now, maybe some CLI injection (if you start processes from your code) or if you have a file upload form, improper sanitation and validation of file types combined with .PHP files being executable from the upload folder.
Why is this here? your reason `2)` suggests that your reason `1)` is bullshit. You're encouraging people not to use them which suggests that you're not going to be using them in the near future (IMHO, from what you've said, it sounds like you should've moved months ago). Anyway, what does anyone else confirming anything solve?
Nah you get bandwidth. Click the VPS link in the menu bar. https://clientarea.ramnode.com/cart.php?carttpl=vps Then pick the type of VpS you want and them the location. You get to a page with a slider. As you drag the slider the package changes. 128MB SVZ gets you 500GB and is $24 annually. 
Good, because there's no information on that site at all at the moment. I don't know what I would be signing up for! Additionally, it looks like there's a link to information about the curator, but no, it's an email link. 
You shouldn't recommend that without knowing what type of site he's hosting. A wordpress site will cripple a micro with a sustained 20 concurrent users, for example ( well, unless you install varnish or some other cache ). 
I use one of the 5 dollar servers for two things. 1 - as a HTTP proxy. 2 - to log server data coming from about a dozen other machines on a once per minute basis. It performs excellently for both cases, although, lets face it, 12 requests per minute isn't exactly a ton of traffic. But, hey, $5.
And this will also help to SEO, more update on the site, more content on the site and more keywords on the site.
In all serious as someone who uses Python daily, I'd like to know too...
Alien blue for iOS doesn't support this. 
That is completely moronic. I hope whoever made that decision gets a venereal disease.
There is nothing wrong with pointing this out, its a big deal.
[Fortrabbit](http://fortrabbit.com/) is the best PaaS I've come across for PHP so far, and I tried [the rest of them](http://philsturgeon.co.uk/blog/2012/10/cloud-hosting-php-pipe-dream).
A site that would cripple a micro will have long since destroyed any of those "$4/month unlimited traffic!" shared hosting shitboxes. The main problem with ec2 is the jump from managed to completely unmanaged, it's a big one! 
How about this? $config = array(); $config['blah1'] = 1; $config['blah2'] = 2; $config['blah3'] = 'Value3'; $config['blah4'] = $config['blah1'] + $config['blah2']; Consistent and explicit.
VPS and shared hosting are NOT interchangeable. Administering your own server requires a totally different skillset.
Sounds like a job interview question.
That's pretty nutty! I hadn't seen anyone write an API without using a framework. Well played, sir.
I hope he gets fired but not diseased...
Only if "Getting what you pay for" means getting completely screwed over by morons for a dollar per month less than vastly superior services.
Trust me, nobody is.
I think you'll have to chip in a little more than a dollar if you want really good service. Think of web hosting in the context of prostitution. You'll be looking for a real long time if you're expecting escorts at street walker prices. 
Absolutely awesome post man, explained a lot. I'm currently building a RESTful API for my current project and this definitely helped.
Hope you don't mind but I may indeed use this :)
Generally (and somewhat incompletely), POST is for creating (without a known indentifier) and PUT is for updating (or creating with a specific endpoint like a unique ID). You've got it backwards in the post. https://en.wikipedia.org/wiki/HTTP#Request_methods Good read otherwise.
I'd really caution younger/newer developers to avoid this post. First, it doesn't really explain much about REST. First, there's nothing about content negotiation. Everything is JSON. There's no way to have the API respond with a 406 or 415 error if the Accept or Content-Type headers are not correct. Next, there's no discussion of hyperlinks. The heart of the web, and REST APIs, are hyperlinks. Your RESTful responses should include hyperlinks to associated resources. I would caution to not use this code for anything in production. It's very difficult to test because you're outputting headers directly. The `_response()` method is woefully inadequate as it only supports JSON and I can not send additional headers. Furthermore this is tied to Apache by use of the .htaccess file, which isn't great. Next, no idea what "but DELETE and PUT requests are hidden inside a POST request through the use of the HTTP_X_HTTP_METHOD header" means. They aren't hidden inside of a POST request, they are their own request methods and the server populates that environment variable depending on whatever one your client uses. This is a time where you should really look into using one of the big frameworks. They're incredibly well tested, understand HTTP better than this, and are more extensible and testable. And one minor bug: $this-&gt;_response('Invalid Method', 406); That should be sending a 405 response. 406 Not Acceptable are for issues with the Accept header. So, good try but please use a well tested framework for your actual app.
PagodaBox is excellent.
I asked them what the hell was up and this and they responded: https://twitter.com/ipowerhosting/status/335459441170337792 Join in the conversation on Twitter if you can, I'd like them to admit fault if fault exists.
You are allowed to PUT on a specific id resources with REST: PUT http://api.example.org/foo/bar/1 And the API should create that resource (if I'm correct).
In which case I'd read the book (especially the [Internals](http://symfony.com/doc/current/book/internals.html) chapter).
That's what he's saying. PUT is for creating/updating (full update, PATCH for partial) a known resource, POST is for creating an unknown resource
Oh, sorry, didn't read that!
sure...if you run apache. here is a guy running 10mil page hits a month on a word press blog on a micro instantce. http://www.ewanleith.com/blog/900/10-million-hits-a-day-with-wordpress-using-a-15-server my point for suggesting a VPS is the simple fact that he won't have the rug pulled out from under him when the shared host decides to change their PHP config. 
You got POST and PUT reversed, mate.
Fully understand. We'll be adding this in this week. Probably should have realised before posting, however I didn't. Thanks to everyone for the comments - stupidly I hadn't seen what was missing until people told me. All the best and have a good weekend :) 
Curious about what the best "big frameworks" would be? Also, how bad is the overhead with using large frameworks for an API, wouldn't speed be an issue?
I'm a fan of Symfony, but Laravel gets a lot of love (can't really comment on anything other than Symfony). No, speed is not an issue. I have Lighttpd (which beats the pants off Apache), PHP 5.4, APC, and Postgres as my stack (using Doctrine2 as well). I easily get sub-50ms requests for most of my API requests. The "large frameworks are slow" is mostly overblown. Over-architected? Possibly, that's a valid argument. But you can make them fast.
I'd go further and say stay away from shared hosting entirely. When you can get a VPS at DigitalOcean and RamNode prices, there's really no reason to put up with the disadvantages of shared hosting. Especially if you're technically-inclined enough to know what PDO is.
I second DO. I switched a couple months ago, and it's been great so far.
Knowing what PDO is doesn't really mean you can take care of your own server.
Take a closer look on the error message. It states that [ModSecurity](http://www.modsecurity.org/) detected PHP Injection attempt, because your request contained data that matches rule in /usr/share/modsecurity-crs/base_rules/modsecurity_crs_49_inbound_blocking.conf at line 26. Check out who maintains Apache configuration at your server and report problem to that person, so he can add a rule exception for your needs. If this is your actually your job, checking [ModSecurity official documentation](http://modsecurity.org/documentation/modsecurity-apache/1.9.3/html-multipage/03-configuration.html) is a good place to start from.
&gt;Also, how bad is the overhead with using large frameworks for an API, wouldn't speed be an issue? "Wouldn't speed be an issue"? Under what circumstances? You can't really make a blanket statement about something like this because it entirely depends on what audience the code will be serving, as well as the architecture of the application. This is a complex question which can't be answered with a simple 'yes' or 'no'. Assuming sufficiently large audiences and/or complexity, yes, it can pose a problem, but, assuming sufficiently large audiences and/or complexity, so can anything else as well. In other words, your question, in its current form, isn't meaningful enough to give an answer.
Sure, I don't disagree (my API's generally are JSON only), but they also respond properly if the client can not accept JSON (406 Not Acceptable), which this code doesn't seem to do.
It has oh so little to do with apache and oh so much to do with varnish; I can do a loadtest against wordpress over apache with varnish cache and support 500 concurrent users all day, without a problem ( that's well over 10 million hits a day ) - and I agree, a VPS is better, but for some people too much of a technical challenge.
I think you are going about it the wrong way. Why are you storing passwords (even hashed) in a flat file? Is there any reason why MySQL or another database solution wouldn't work? Also, I'd recommend using the [`password_compat`](https://github.com/ircmaxell/password_compat) library for managing the passwords (compatible with the new API coming in 5.5).
I use hostmonster.com, and I've never had any problems like this. I've had them help me restore a backup at 11:30PM, I've had them re-arrange my bill so that I would save some money, and a few other times I've had to call customer service at all odd hours they've been knowledgeable and helpful. Certainly, they've never done something odd like removing PDO.
Cool, thanks; fixed it.
If you look in your apache configuration, you're likely to see something that looks like this: &lt;Files ~ "^\.ht"&gt; Order allow,deny Deny from all Satisfy all &lt;/Files&gt; This keeps people from downloading these files. You can either name your file something like .htmysupersecretfilename (note that the beginning of the file is .ht) OR you can add another entry like this in your .htaccess file and test it to make sure it's right. I *guess* you could so something like (hmm) use curl to try to get the file via localhost $ch=curl_init('http://localhost/.filename'); curl_setopt($ch, (return something) ) $foo = curl_exec($ch); and see if you get anything back. But really, I think the server's just as likely to be hacked and files downloaded /uploaded willynilly rather than something through php permissions or something you can capture with what you're doing. 
You know what I meant. Obviously, if your API only serves a handful of people it wouldn't matter. If the application(s) using the API were in large enough scale I would think someone would want a streamlined/efficient API "engine" to increase performance.
No, I have no bloody clue what it is you mean. "Large enough scale" doesn't mean anything until you actually define what it is. It's a very relative term. And again, it also depends on your architecture, and what you actually intend the API to do. You haven't defined any parameters at all here. 
I understand what you're asking but I really strive to plan everything out that I develop to potentially be used by a very large user base. I don't have a definite number but I just would rather spend the time rolling my own API to make sure it is responsive as possible. Does that make sense? But if the speed is negligible with the large frameworks it would be something I would strongly consider moving to. Especially if development time is minimal. I would just assume they would be bloated. And riddled with things I wouldn't ever need or use.
Okay, we're clearly not getting anywhere here. "But if the speed is negligible with the large frameworks it would be something I would strongly consider moving to." This can't be answered. It's like asking "how fast does a car go" or "how many people can a bus fit". It depends. *What* car? A Fiat and a Ferrari are two different beasts. *What* bus? A minibus? A school bus? Hopefully you see the point. I know nothing about your parameters because you won't tell me, so I wish you a good day and hope that you'll find out on your own.
Well said, however I'm curious: are you (or is anyone) aware of a good, plain PHP class/shell for a custom restful API? Obviously most frameworks are too much if you actually need to write your own API without a frontend, etc.
No problem. Leftnode actually answered the question I asked. 
&gt;Leftnode actually answered the question I asked. So no, you didn't see the point. Well, whatever. Good bye.
I think the issue is not so much whether the response is in JSON format as whether the media type can be specified for the resource, e.g.: Accept: reddit/comment+json -&gt; Content-Type: reddit/comment+json So the client can process the response without needing out-of-band information. So, according to [Roy Fielding](http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven): &gt; A REST API should spend almost all of its descriptive effort in defining the media type(s) used for representing resources and driving application state, or in defining extended relation names and/or hypertext-enabled mark-up for existing standard media types. Any effort spent describing what methods to use on what URIs of interest should be entirely defined within the scope of the processing rules for a media type (and, in most cases, already defined by existing media types). [Failure here implies that out-of-band information is driving interaction instead of hypertext.] 
&gt;So I call support and they tell me it's their policy that anything that can be used to create a 'remote connection' would be disabled as a security risk. Wait a minute... Isn't that what web servers are for? Creating remote connections? Next thing you know they'll shut off apache.
There's some great shared hosting services out there. Unless you run a a CPU intensive or high traffic site it's not really worth the time you put in configuring an unmanaged VPS. A managed VPS might be worth the cost but it's significantly more than you'd pay for shared hosting.
I guess not, i apologize. It's no big deal. I honestly appreciate your trying to help though.
Slim (http://www.slimframework.com) is probably the most lightweight framework I can think of for that purpose. Take a look at the docs to see examples of defining routes. With Symfony2 you could pick just the HttpFoundation, HttpKernel and Routing components and use them as the basis for your own API class.
Or the [Silex](http://silex.sensiolabs.org/) flavor of Symfony 2 components.
This silex based RESTful helpers/middlewares project is interesting, https://github.com/bcen/silex-dispatcher 
Go with shared hosting like alwaysdata , it is pretty cheap , you get SSH access so you can compile the PHP modules you need, do git deployement , you get a couchdb , a mongodb , a mysql and a postgreSQL db should be around 100$ a year so its pretty cheap. They have a free , limited only by size of datas, offer too.
&gt; Next, there's no discussion of hyperlinks sorry but HATEOAS =/= REST . Rest doesnt say what the body of a response should look like , and it doesnt not say that you should include hyperlinks in the response body. I dont do HATEOAS because i find it stupid. API should not be self documented in my opinion,but should return only the informations the client really needs , not metadatas. hyperlinks are metadatas that make payloads heavier for nothing. Furthermore REST =/= RESTful . That's a very important difference. 
And yet the originator of the term, Roy Fielding, disagrees with you: [REST APIs must be hypertext-driven](http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven) &gt; What needs to be done to make the REST architectural style clear on the notion that hypertext is a constraint? In other words, if the engine of application state (and hence the API) is not being driven by hypertext, then it cannot be RESTful and cannot be a REST API. Period. Is there some broken manual somewhere that needs to be fixed? It can't get any clearer than that, whether you find it stupid or not.
That doesn't explain why you want to avoid it? You can *learn* python 
Well, to toot my own horn a bit here, check out the upcoming version of my API: https://dev.majorapi.com/developers/quickbooks-api-invoices Scroll down to the 201 Created response. You'll see the response has links (in the _href attribute) to other resources so your client (whether it be cURL/PHP script or a web browser) can follow those links. So, the response there prints out basic information about the customer attached to the invoice, but if you wanted to get more information about that customer, you could GET the href (link) and get full customer information. That's the essence of the web: hyperlinks. If you think about the most basic web page, it's just a document (resource) that links to other resources. Your REST API should do the same. Doesn't matter if the Content-Type of the response is application/xml, application/json, or text/html or whatever.
How to configure it to run from a specific directory, say "/var/www/cmsfire" ?
I find Slim lacking for anything but the most basic needs.
My only complaint is you intimate that .htaccess is specifically an apache thing. Other webservers support htaccess to different degrees. Past that, carry on.
I really like the idea behind it. However, [one thing that you should fix](http://favs.samnabi.com/index.php?twitter=%3Ch1%3EYou+shouldn%27t+directly+output+user+input%3C%2Fh1%3E&amp;reddit_name=asd&amp;reddit_feed=asd). It is bad practice to directly display/use user input as you never know what people will put in. Another example is in this line: curl_setopt($ch, CURLOPT_URL, 'http://www.reddit.com/user/'.$_GET['reddit_name'].'/saved.json?feed='.$_GET['reddit_feed'].'&amp;user='.$_GET['reddit_name']); Whilst not a huge issue in this case (Being a read-only URL) it is still not something that you really want to do. PHP has a [`htmlspecialchars`](http://www.php.net/manual/en/function.htmlspecialchars.php) function which will convert symbols to versions that are safe to output. You could take this a step further and strip out all characters that are not acceptable in those places, for example, reddit usernames can only contain letters, numbers, underscores and hyphens, and the feed hash looks to be only lowercase letters+numbers. Also on the link that I provided above, because the reddit username/hash are not valid it just throws out an error, you should check that `json_decode` returns valid data, by both: - Checking that `$reddit_query` is not `NULL`, if it is json_decode failed for some reason - Checking that $reddit_query['error'] is *not* set (If it is, the user/feed could not be found)
You don't actually want to use htmlspecialchars() for constructing the URL above because it's not actually an HTML context. What you have is a part of a URL path then a query parameter. * For the URL path, do what Cameron\_D described with verifying alphanumeric+"_"+"-". * For the query parameters, use [urlencode()](http://php.net/manual/en/function.urlencode.php) [Here is a good description of the different escaping contexts.](http://jehiah.cz/a/guide-to-escape-sequences)
You should really look into separating the templates from the application logic, this will definitely become a problem over time if your app grows and you need to expand on it. Symfony2 has a great tutorial on how to get started (with and without using external libraries), http://symfony.com/doc/current/book/from_flat_php_to_symfony2.html
I'm a wimp and use [DelpoyHQ](http://www.deployhq.com/)
By what definition? It's great in theory, but the system has had enormous amounts of downtime, and only got basic stats back in the last few days, after them being missing for literally a year. I left Pagodabox, and went to Fortrabbit. I have no regrets.
Short personal experience: Pagodabox - good model, excellent interface. Exceptionally shitty (unacceptable) downtimes. Only just got 5.4, and have only just re-enabled stats after a year down. Amazon EC2 - I'm sorry, I just found this too hard. Maybe I'm dumb, but this isn't a PaaS, it's an excellent platform, but lower level than what I was looking for. If I wanted this level of environment I'd get a shared host/VPS. Price is unbeatable for a startup. Fortrabbit - This isn't as good as Pagodabox in terms of either features or interface. It's not as shiny, and it's probably a tiny bit more expensive in terms of what you get free not being nearly as useful. But it has excellent documentation (just recently revised), fantastic support, and has run like clockwork since I started using it.
In addition to the Symfony2 tutorial, here's a really nice video tutorial on how to create your own small framework for separating tempating &amp; logic: http://www.youtube.com/watch?v=CGiIVQPaOJQ
I've been building a few APIs recently, and found that there are some great microframeworks that handle this job remarkably well. Though I (more or less tossed a coin and decided to) use FlightPHP there are others such as Slim and Silex that work in often almost identical ways. Most of the stuff I do is quite simple, and a web interface with a connected API does the job in most cases. A full framework stack can be cumbersome to learn (in a decade as a developer I've actually never gotten around to doing so) but a micro framework takes the heavy lifting from something like an API and makes it quick and easy to do. The point is... I'd rather do that than build one from scratch.
Agree here. I'm quite pleased with hostmonster myself.
Ah, that makes sense then. Interesting; there was no need for me to do anything like that when I wrote this, but yeah, I can absolutely see the usefulness. Thanks!
Yeah, using someone else's wheel is much better than building your own; I'd never had the opportunity to do something like this though so it was a large learning experience for me. Especially the CORS part!
&gt; You could take this a step further and strip out all characters that are not acceptable &gt; you should check that json_decode returns valid data Thanks, I've pushed those changes now. Now that the cURL code is within an `if` statement that checks for the proper character set, is it fine to include the raw `$_GET` variable in the URL?
The traditional way is to either: * Include a subquery in the initial query - This is N+1 queries for N posts * Retrieve all the posts then do an aggregate group query with WHERE IN (post1id, post2id,....) - This is 2 queries for N comments. Mesh the two with application logic. The actual way that performance sites do is, store the number of comments in post table. This is 'controversial', because it fundamentally breaks the normalisation of the database. If you forget to update the field when a comment is inserted it's a source of error. However, it is done for the following reasons: 1. 100% of people will need to view the number of comments 2. 10% or less will update the number of comments 3. The application controls the database so application logic should prevent the error occurring. 4. Given the figures in 1&amp;2, thee cost of an extra UPDATE per comment is much less than extra SELECT for every page view. 
Configuring this was a huge pain and performance was far less than desired.
Do you have other web servers set up on your server? :) You'll have to modify the "httpd.conf" file and modify the DocumentRoot line to: DocumentRoot "/var/www/cmsfire"
You could do something such as: SELECT p.id, p.post, COUNT(c.id) as comment_count FROM posts p JOIN comments c ON c.foreign_key = p.id GROUP BY p.id This would give you each post, and the number of comments for each of those posts, which if I understood your question right, is what your looking for. Just keep in mind to index your foreign_key, and have your primary/foreign_keys of the same data-type &amp; length, and performance should never be an issue. 
i changed this in appcfg.py and get now the error: Error 400: --- begin server output --- Invalid runtime or the current user is not authorized to use it. --- end server output --- 
Silly question: what's wrong with all the other web frameworks that already exist?
&gt; Just keep in mind to index your foreign_key Doesn't the InnoDB storage engine create indexes on foreign key columns if they aren't present? I remember reading that somewhere, but not 100%.
I wasn't positive on this either, but I believe you are correct, based on what I read [here](http://dev.mysql.com/doc/refman/4.1/en/innodb-foreign-key-constraints.html). Third bullet point goes over it. 
doing that if not a performance bottleneck is a premature optimisation
I'm excited because Google App Engine (which I love) will support PHP rather than making me use Python. I feel as ambivalent towards Python as I do to any technology that comes along claiming to have re-invented the wheel. It's still round and it still carries a load, I won't waste time on it.
This. OP, I would suggest you look into JOIN's.
I've ran a query in a command line. It works! And I think I understand it. Now just an implementation. Question got deleted. Obviously a wrong subbreddit. It's the right one, if you ask me. Such a great community. 
&gt; If it's to be in a flat file, you can start it with &lt;?php die(); This makes the most sense to me. Thanks for the advice.
I am unable to guarantee that the target audience will have access to the apache configuration. I had considered using curl to determine if the web server is publishing the file, but since I want to advise that (where possible) installations should be installed outside of the route of the public www directory, it could get messy. Thanks for your thoughts.
&gt; Is there any reason why MySQL or another database solution wouldn't work? Yes, some of the target web servers do not have MySQL available, and it really is a tiny CMS. Thanks for your help though.
For what it's worth, Laravel 4 (which is in beta) fixes a lot of your issues: https://github.com/laravel/framework That being said, Symfony++ 
Thank you for the link. There, I found the [composer.json](https://github.com/laravel/framework/blob/master/composer.json) in the framework. :D
1 - just got to the Laravel page in clicked on download and was not expecting a zip file. 2 - yes, PHPStorm can do that, too. But it's really just *my* taste, not relevant for good code or lack there of. 3 - I'ts not about testing which can be achieved, but about the [SOLID](https://en.wikipedia.org/wiki/SOLID_\(object-oriented_design\)) principles, especially the [Open/Closed Principle](https://en.wikipedia.org/wiki/Open/closed_principle) 4 - It looks like what [Silex](http://silex.sensiolabs.org/doc/intro.html) does. // web/index.php require_once __DIR__.'/../vendor/autoload.php'; $app = new Silex\Application(); $app-&gt;get('/hello/{name}', function ($name) use ($app) { return 'Hello '.$app-&gt;escape($name); }); $app-&gt;run();
code speaks louder than words : https://github.com/bcosca/fatfree 
I wrote Laravel. Laravel 3 came out just around the time Composer was getting more use, and it wasn't clear if Composer would be widely adopted at the time. Laravel 4 obviously uses the crap out of Composer as we use like 6-7 Symfony components, SwiftMailer, Monolog, etc. Laravel 3 does have too much static code going on. Part of this was me trying to figure how to apply the design principles I knew from .NET to PHP, while still playing into PHP's strengths of being fast to develop with, generally terse, etc. With Laravel 4, I think I've hit the sweet spot with this. The IoC container is at the heart of the entire application and all dependencies are resolved through that (generally using constructor injection). IoC bindings are grouped into Service Providers, very much similar to Silex. Since all core classes are resolved in this way, you can easily override any core binding in the container with your own implementation. Personally, in the early days of developing Laravel 4, I wanted to ditch the "models" folder complete because I didn't think it was conducive or helpful in designing a solid application, and it tends to get people stuck in this rut of "model == database". So, I hope you don't think I'm ignorant of good architecture, etc. it just took me a little while to figure out exactly how I wanted to implement certain things in the PHP world. With Laravel 4, even controllers are resolved through the IoC container, allowing constructor injection at that level, which is quite powerful thanks to the container's ability to read type-hints and auto inject dependencies, something even Symfony is somewhat lacking in as by default they use their container as a service locator within their controllers, which is kinda fudging from an architecture stand-point. Since the architecture of Laravel 4 is much better, that has made testing your own applications much easier as well. We also embrace the BrowserKit, DomCrawler, CssSelector, and HttpKernel components to give great functional testing as well. As far as guiding people how to use Laravel the "right way", I agree there needs to be more on that topic. Personally, the first thing I do is delete the "models" folder and make a folder that is simply the name of my application. I might then make an "Entities" namespace within that directory for my core domain objects, as well as create a variety of other namespaces and classes for my service classes and other domain logic. I view the controller / routing layer as a web interface to my "real" app, so like to keep HTTP things very separated from my domain logic. I need to a better job of documenting how I think Laravel is used best. Anyways, I guess just saying "I hear ya" as far as Laravel 3 goes. But, do not discount Laravel 4. It's very much a Silex type framework at the core of its architecture with the Service Provider setup, and obviously ships with a more full-stack set of features. *EDIT* Little more context on why Laravel 1-3 were so different architecturally. Those first versions were basically me saying "I like CodeIgniter, but wish it had X feature." So, it had a very similar architecture to CI (not very good). While all that was going on, I was continuing to brainstorm how I really wanted things. With Laravel 4, there is a drastic architectural change away from CodeIgniter to a much more SOLID approach, and the great thing is, I think we were able to do that while still keeping the framework very fast and approachable like the early versions, so it has appeal to both newer programmers, and people who are more trained in sound design. I think that's really cool, because it's a framework that grows with you as a programmer.
Just wanted to let you know, I'm a long time php developer, have tried cake, developed a few apps with code igniter, wrote a big app with Yii... I've learned python/django and I was ready to switch (python is my favorite language, but I have a lot of experience with php), php has been a bit disappointing for a long time. Learning laravel is making me switch back to php, thank you.
Stackoverflow runs on a pretty serious stack (heh) so I'm pretty sure they can check the user's comment count on each comment post just fine.
Thank you for answering. I go have a look now for Laravel 4. It's good to agree on the guiding point. To see the business use-cases and not the framework is something that is often something you would want to expect of developers to know about, but is most of the times not the case. I worked with so many developers not wanting to know about good architecture and the result looked like a part of the code examples of the framework they choose and was a relaunch-candidate in all of the cases. The way you start a Laravel project could be a first read, about the how and the why. To be fair, I don't need to develop a project right now, I was just installing it to see what and how it is done in Laravel. There is no mention of a version on laravel.com and also not on github, so I just googled "install laravell 4" and got to [http://four.laravel.com/](http://four.laravel.com/) where, hey, it sais composer. Finally :) That is good. But I still need to download a zip file. Meh. As I understood it the statics were for the autocompletion in IDEs, yes? Here are is a link from the PHPStorm issue tracker about how to get [generic support for factory design pattern in PHP](http://youtrack.jetbrains.com/issue/WI-6027).
I don't think they run queries every time the user logs in, but rather when the user does something, like make a new post. Whenever someone else then upvotes that post, some other achievement is triggered. Kind of like an event system. If programmed correctly, new types of achievements can be added easily by adding more event handlers. These events can affect the user causing it, or a user otherwise related to the event. I have also noticed that they use multiple slaves where synchronization delays are permitted. Therefore when you reload a very popular page, sometimes the numbers are shaky and slightly different from the last page load. I guess this effect is inherent to running a website at their scale. Sorry for the lack of buzz words. It's too late for me to look everything up on an iPad...
I don't know that I can answer your questions about performance, but this type of strategy is often referred to as 'gamification'. I know the LMS Moodle has toyed around with it, as well as several Wordpress, Joomla, or Drupal plugins.
Using an IDE like PHPStorm or some sort of PHP code sniffer would be beneficial for tracking down unused code.
&gt; Personally, the first thing I do is delete the "models" folder and make a folder that is simply the name of my application. I might then make an "Entities" namespace within that directory for my core domain objects, as well as create a variety of other namespaces and classes for my service classes and other domain logic. I view the controller / routing layer as a web interface to my "real" app, so like to keep HTTP things very separated from my domain logic. As someone who is just now getting into Laravel4, I would love to see this explained in further detail. And while I have you here, there are a few things about Laravel that causes me to pause. I haven't built anything in it yet, so take my opinions with a grain of salt obviously. I'm a freelancer and the parallels between rails, A/R and Laravel, Eloquent, makes me worry a little bit. I've seen some atrocious rails apps due to what I term 'chasing the shiny'. Rails has taken ruby's beautiful syntax to an extreme, and it's had a detrimental effect on large portion of the community as a result. In particular their chasing of unit testing has gone too far. Unit testing is obviously valuable, but when you dump complexity onto a project simply so you can automate 'unit testing the browser', or to 'make javascript pretty', you've gone too far. I worry that Laravel will also go down that path, and so I'm learning it with the idea of using it more in my freelancing work, but I'm doing so with a lot of trepidations that don't necessarily revolve around Laravel from a technical perspective, but from a social one.
Why bring up tabs v spaces in the first place? It's your problem. It doesn't matter either way. Deal with it.
Gamification seems to be a term related to philosophy rather than programming. I personally agree with the idea behind it, but need to find some programmatical ideas too. :p
Oh agreed. My co-worker and I make frequent backups before any changes so we can implement back if needed. I'm trying to get our boss to get us a github account for better version keeping.
It doesn't sound like a good practice use. User does something, call handleAchievements(); user logs-in, call handleAchievements(); user posts, call handleAchievements(). If this is what you're referring to, then it would make their website suffer performance alot more than the website itself. Can you eloborate slaves a bit? Do they use some slave servers/databases just for achievement tasks?
All this worrying is premature optimization. Sure maybe it's a cron job, but maybe it's not. Big sites do a lot of things when you login or post other than just logging you on. Like loading the threads you've commented on. Loading if anyone has replied to you like the reddit inbox and yada yada. Even checking achievements. And they handle it just fine.
I can imagine the checks on reddit backend when I reload a page, because all backend developers code similar things at the end of the day. However, what about around 100 achievements? Are you going to call hundreds of if/else checks by spamming queries to database on every request just for showing achievement tags to users? Loading threads I've commented on is just a basic join query to database. Loading if anyone has replied to me is also a single query running each time the page is ran. 3-4 queries and some checks to create the output is okay, but what about 100... or even thousands if you're creating a browser based game. How do you scale it?
Thanks for sharing your concerns. I'll definitely try to keep them in mind moving forward. I don't *think* we've gone down that road yet.
Awesome!
That's an interesting introduction to MVC/Symfony, but it just seems like way too much abstraction for a project of this size.
Maybe. But using the 10,000 post count as an example. I might check it when you log in or when making a new post. Then just save the acheivements in another table or in their profile or something. Then again that could actually be slower. if you've got the user's stats already then a couple if statements to figure out what achievments they got might be better than loading it from the DB plus loading the user stats. Crap loads of if statements is probably not going to be your bottleneck. They're cheap performance wise. But there's no need to perform a query for every if statement. 
You're going to have to cut some slack here... he's disgruntled.
It makes me think, that just because I don't use any framework, I'm always wrong!
Definitely. I'm not going to perform a database call on every if block, but still... Something just feels weird here. Maybe I'm underestimating the power of PHP and hardware we use nowadays, but I feel like there is a better way we couldn't discover yet.
Laravel4. Add this to your composer file: https://github.com/JeffreyWay/Laravel-4-Generators php artisan generate:resource modelname --fields="name:string,description:text" 
I Know I'm not wrong... just being kind of sarcastic in a certain way. I know it's good to discuss, but I find kind of a wast of time the extent that some coders are willing to discuss which framework is better and which is worst. In my opinion the best framework is the one that a coder can adopt, feel comfortable with, and get things done efficiently. I never use PHP frameworks because I never found one that is really for me, because I find them good in some things but also bad in others. None of them does things and has all the features that I would like. Never took the time to do a mish-mash though. The only thing that I use is a small MVC routing class and a library of classes that I load as I please. Have full control over my code, and I doubt I would be able to work faster and better with any known framework without spending a considerable amount of time that I don't have available to spend. 
Laravel makes this quite easy to get started with through the Artisan CLI. php artisan controller:make UserController http://four.laravel.com/docs/controllers#restful-controllers
If it's something simple don't use Laravel. Use [SLIM](http://slimframework.com). It's simpler and designed for purely RESTful stuff. If you need more than that then consider using Laravel but I would start with SLIM first and go from there.
Seconded, if the only thing your site is doing is providing a REST API, a full size framework is massive overkill. Use composer to pull in Slim and and just the Laravel or Symfony components that you need.
I guess to figure what functions are listed anywhere and if you go down a file that links to other files, what are all included? Like say I have files A, B, and C, and A forwards to B through a submit but C is basically orphaned since nothing refers to it. I found at least one file out there similar situation that was needed for production, but not sure if there are others like that. Previous developers kept putting the test files into the folder with varying file names so it's not helping.
I like your coding style - very readable and easy to follow. I like the idea of running single task scripts within a class which is controlled within one main public method that calls private helper methods. Even if it isn't proper OOP, it seems quite elegant and modularised. Is there a name for this pattern?
Looking at what has been done with L4, you can only assume that Otwell and Co. decided to use pieces they thought were good (the Symphony core pieces in L4) and write alternatives to the rest. I can't speak to their specific observations, but it seems like they would use Twig if Twig did what they wanted it to. It didn't, so they went another way. My 'pretentious' attitude was in response to your 'elitist, know everything' attitude that Laravel 4 should have never been created. You're entitled to your opinion, so STFU and let other people do what they see fit. I agree that standardization is a great thing. Your rotary motor analogy doesn't fit with your original assertion. You specifically called out an entire framework as unneeded and crowding the marketplace, which the "market" has disproved already. &gt; Laravel 4 just created problems by being introduced. We didn't need another competing framework (that basically does the same thing) to complicate the job market. If &lt;insert framework here&gt; was so great, why is anyone adopting Laravel? You're welcome to try and redirect with 'L4 created a whole bunch of other things I have to learn' whine, but that's not what you originally said. I'm not here to defend Laravel itself. My whole 'pretentious' point was your opinion is in opposition to how real markets work, and the evidence you supplied in support of S2 was just a bit of fanboy-ism. &gt; Your pretentious attitude will get you nowhere. Quoted for the lols. Thank god I don't have to deal with bitchy developers all day. I get all the bitchy I need from philsturgeon. &lt;3
&gt;In my opinion the best framework is the one that a coder can adopt, feel comfortable with, and get things done efficiently. Nail on head right here. I'm not even that much (or good) of a developer, but I jumped in this thread because saying something shouldn't have been created based on your love affair with a competing product isn't adding to the discussion.
Yes, Tabs are a problem. I agree.
[Slim](https://github.com/Xanza/Slim) used to be my favorite, until I found [Flight](https://github.com/Xanza/flight). They're both good, but I much prefer Flight to Slim now.
While its not as known as a 'framework' as opposed to a CMS (although next version will be marketed more as a framework,) Drupal will have you running a REST API in minutes, literally, with authentication if needed. [Drupal](http://www.drupal.org/project/drupal) with [Services module](http://www.drupal.org/project/services) and [Services Views](http://drupal.org/project/services_views) will give you a basic REST service. You can then use [OAuth](http://drupal.org/project/oauth) if you need and there are countless other modules, pre-built to make it seriously a plug-n-play setup. Hope this helps.
No. It's the best thing to do performance-wise. Why? Because the event only happens once. So the event handlers and their queries are only run once. At that moment, the data is also passed along to the event handler. So that for example, if user A upvotes user B's answer, then user B's answer's id and info is already in memory anyway. Imagine the event call to be like: Events.fire('upvote_answer', [A, B, answer, currenttimestamp]); // look ma, all the data is already loaded in memory! As for the if statements, because it's an events system, only the listening event handlers are triggered. Combined with the above it means that only the relevant event handlers listening to 'upvote_answer' are called with all the data in memory so, that just leaves very few and very fast comparisons. On the other hand, if you do the queries on user B's login or next page load, then the queries are much heavier. *Then* you don't have the data so you need to query *everything* for every possibly happened event just to *discover* that users upvoted B's answer. That's much slower.
Events systems don't work like that. In your web browser, when you click on an HTML anchor, only *that* onclick handler gets *that* onclick event and event data. You don't have to worry about onmouseout or whatever other handler, those are not triggered! So events systems are actually very efficient.
Interesting to know that you picked the younger of the two languages to work with, then.
Not interesting in the slightest.
For the first part, you better make a product object with setters and getters. You use these getters and setters to set the attributes of the product. Then you use a datamapper library, like doctrine, to propagate this state to the database. You can also pass this object to your views to display the attributes for edit pages. &gt;Should I consider having a single product_modify view for adding/modifying data, by setting default values as null in my product_add function and also set ACTION url to the given function? Is it a good or a bad practice, or just something depends on developer's taste? There is a feature called template inheritance, which is provided by twig and new versions of smarty. http://twig.sensiolabs.org/doc/templates.html#template-inheritance The basic idea is that you can extend add_product template to create edit_product template. you set certain areas, as blocks in your add_product template and over rides those blocks in edit_product template. I am not sure if laravels templating system supports this pattern. 
Third for Slim, it's great! And not just for RESTful stuff but for any really simple sites.
I did one with Silex but after reading this thread Slim seems very similar and maybe better for a Rest api.
Good summary. The "proprietary datastore" argument is less relevant now: AppEngine for PHP is intercepting calls to mysql_* (etc) and fopen()/fread() and using their cloud SQL and cloud storage services to back them. Besides, most app developers are likely abstracting file storage and DB access anyway, so deploying to AppEngine is a matter of changing some connection strings or folder paths, and you're not locked in at all. 
They're very close in execution Slim: require 'Slim/Slim.php'; $app = new Slim(); $app-&gt;get('/hello/:name', 'hello'); function hello($name) {` echo "Hello, $name!";` } $app-&gt;run(); Flight: require 'flight/Flight.php'; Flight::route('/', function(){ echo 'hello world!'; }); Flight::start(); The main difference is flight uses the scope resolution operator (::) to call static instances of your method, while Slim uses a 'per instance' method that can only be called from an instance of classes or functions. To put it in a way that makes _most_ sense, I would have to say: "Flight seems to be more complete as a PHP Framework."
I like to use Silex, as your application grows you can add more and more component for other things. It has also the advantage to be compatible with most of the Symfony Bundles and can avoid your reinvent the wheel (for e.g. Imagine or Unit testing).
I recommend u to try [Pagon](https://github.com/hfcorriez/pagon). It's simple and smart for write project. It's not only support REST under HTTP, and has more improves under CLI for modern Web App, it's willing is "write less, do more".
try: appcfg.py update -R --runtime=php yourapp/ and before register the app on: https://gaeforphp.appspot.com/register
Good question, there is nothing wrong with them at all. Simply this is a learning curve for me, i've made many things with PHP in the past and small framework to suit small projects. This time i am going to be working on a much larger scale and simply want to create my own framework to suit the project i am leading. 
I cannot stress enough that you should use source control and then back up your source control. its much better in the long run
This was from the day he started working on it. http://qdb.us/309402
Any time php.net is offline or loading slow, try one of the mirrors. - http://us.php.net - http://us2.php.net - http://us3.php.net
I've used Sturgeon's REST library for a couple projects. It's nice but I felt like using all of CI just for the REST library was a bit overkill. 
I originally used Slim and I have no complaints about it, but we were starting to use Symfony a lot at work, so I made the switch to Silex. I think either one is great, Slim may be a touch faster but it really depends on what you are including and how you write it. I just prefer Silex a bit more because of the Symfony base. Both are very light and perfect for REST API.
Sure, the hosted mysql implementation is not proprietary the Google Cloud Datastore is a proprietary bigtable implementation and quite frankly GAE is nearly pointless to use without using this part (it's not hard to scale the webservers, the datastore is what is hard to scale).
The PHP SDK for GAE comes with a memcached implementation to write to Cloud Datastore, so there's still no lock-in; you can certainly build an app that uses memcached and runs outside of GAE.
I don't have much experience with other frameworks but Symfony 2 has very nice functionality for building a REST API using FOSRestBundle including the use of OAuth for authentication if desired via FOSOauthServerBundle. The way FOSRestBundle uses Symfony's built in forms to bind submitted data to your models and perform validation is very nice for anyone already familiar with that paradigm and it handles responses in multiple formats (xml, json, html) gracefully via the existing Serializer (or JMSSerializer, not sure) component. It enabled me to write REST controllers that don't have any boilerplate code in them for the fact that they are responding to a REST api request. They pretty much just look like normal controllers. Example Code: https://gist.github.com/afishnamedsquish/5607976 References: https://github.com/FriendsOfSymfony/FOSRestBundle http://williamdurand.fr/2012/08/02/rest-apis-with-symfony2-the-right-way/https://github.com/FriendsOfSymfony/FOSOAuthServerBundle/blob/master/Resources/doc/index.md
I use Symfony2 with a [bundle](https://github.com/brightmarch/rest-easy) I wrote to take care of some common things like authorization and accept headers.
Simple, achievements are yes/no flags in database. Each achieve is done separately based on triggers. For 10000 post achieve: every post you make it checks of you have the achieve, if no then see if post =10000.
I combine add and edit into 1 function called set. In there if you pass an id it will update, but with no id it will insert.
static methods seem to be generally frowned upon (I do not know why) f3 does your code like so: $f3 = require 'lib/base.php'; $f3-&gt;route('/ GET', function(){ echo 'hello world'; }); $f3-&gt;run(); note how the first line is making the object learn more here: https://github.com/bcosca/fatfree or here http://fatfreeframework.com/home
I am curious, what has been your experience with phalcon? I have not used it, but I have read through some of the extensive documentation. Is the real world performance as good as the benchmarks indicate? Have you run into any bugs in the framework you have not been able to work around? 
Static methods are frowned upon because it usually leads to code that is very hard to test. By writing a regular method call on a function, you're able to change what the class is composed of at runtime, rather than being stuck with the procedures in the static method call. This said, I wouldn't say it's a bad thing if the static method could be written like a regular function (where the method injects its dependencies) or else is a wrapper to "new self".
Yes. We can break those events into pieces like this. "You've been logged in for 10 hours." may go into login/logout PHP as an event call. Post related event may be an event in post.php. However, it's far from what I'm asking. Events::fire('upvote_answer', [A, B, answer, currenttimestamp]); Our "fire" method has to look like this. fire($call, array($parameters) { if($call === 'upvote_answer') { if( //upvote related event ) { } if( //upvote related event 2 ) { } if( //upvote related event 3) { } if( //upvote related event 4) { } if( //upvote related event 5) { } if( //upvote related event 6) { } if( //upvote related event 7) { } } if($call === 'user_login') { if( //login related event 1 ) { } if( //login related event 2 ) { } ... } All of those insider "if" blocks has to run on each call to fire method. I'm sure this could be improved. Not to mention, Event::fire calls will be split on different classes and different functions, making events unable to maintain. Unless such feature could be done with PHP? // events.php Event::bind('on', $className, $methodName, function() use ($className, $methodName) { return $className-&gt;$methodName-&gt;extend('before', Event::fire('upvote_answer', $paramsFromFunction); }); Just a pseudo idea. All about extending functions to contain appropriate event calls from one place. I believe it can be done (even by hacking eval I guess?) but my brain doesn't work properly today so I can't focus. 
&gt;You can't do something so computationally intensive as ray-tracing in regular PHP, of course. Well, that's just nonsense. You can perform computationally intensive operations in any programming language. What will differ is the time it takes to render the scene, but whether it is feasible to render it in PHP depends on several factors, some being the following: 1. The time allowed for it to render a scene 2. The complexity of the scene (the number of objects, reflections, refractions etc) 3. The size of the render
Sure. Laravel-4-Generators from Jeffrey Way is an artisan command that generates all the necessary file for a resource. It really speeds things up. In a maximum of 5 minutes, you'll be able to create a RESTful APi for a model. It will create: a migration file, a controller, a model, the necessary views (in our case, this is useless), and it will add a line to your routes.php file. Since we're doing an API, go in the controller, keep only: index, store, show, update, destroy. They are automatically assigned to GET /model = modelController@index POST /model = modelController@store PUT /model/1 = modelController@update GET /model/1 = modelController@show DELETE /model/1 = modelController@destroy In the controller, for index, add something like return Model::all(); for store, add something like return Model::create(Input::all()); (Your model has to have $fillable fields for this to work, check laravel docs) for show, add something like return Model::find($id); for destroy, return Model::delete($id); And now, you have a working RESTful API. Just hook it up to your auth system, and maybe put it under /api/v1. It's missing validations, but that's up to you to figure out. My advice: https://github.com/laravelbook/ardent 
Event and achievement system are not the same thing. Your events example is a different concept. That's what I tried to say.
It's not just testing. If you're operating on an instantiated object, like this: $obj-&gt;doAThing() then it's very easy to swap out $obj for another object whose class implements the same interface. This is what enables things like dependency injection and inversion-of-control. If you're using static methods everywhere (which so much PHP code sadly does) then this is not possible. Laravel 3 uses instantiated objects which are hidden behind static facades... I really do not understand why. 
&gt; it tends to get people stuck in this rut of "model == database" This is a bit off-topic, but keep fighting the good fight. I feel like so many frameworks encouraging a flow where you create models to match the database and even _pass those out to the view_ is very unhealthy.
At a certain point, when a website becomes busy enough, it becomes more efficient to check achievements en-bulk at a certain time interval than to check each every single time there is an up-vote or post. So, for instance, every post/upvote could be added to a queue table. Then, once every second, 15 seconds, minute, or what have you, all the posts/comments in that table are checked to see if they have triggered any achievements. It would cause less overall overhead to do these in small batches than to hit all the tables every time a post or vote is made.
Cheers looks good for quick development.
I'm using Flight, pretty small, lightweight framework. REST is pretty easy with it!
Yeah, it would definitely be better, but doesn't it count as a cron after all?
You don't need to reduce them. C'mon, queries by primary key take only a few ms. Start writing some code now, worry about performance later. You're hypothetically making up 100's of slow if statements, where there's probably gonna be less than 10 super fast queries! Key to success is to iterate fast and often. You've got a basic idea, write it, improve it, repeat.
Considering StackOverflow is a .NET website, it is probably a service. Same idea, though, except that the service could use additional logic that is not typical used in cron scheduling to self-regulate when it ran. i.e. run less often the longer it takes to run itself, or run less often during peak times.
The documentation does leave a lot to desire. It'll take some time for me to flesh out the whole thing. I have just added a tutorial. Thank you for the heads up about the menu. It's just a Joomla template I found somewhere. I'll need to fix it.
Reminds me of the signature of a someone who used to regularly contribute to comp.lang.php: "Given enough thrust, a pig will fly just fine" :-)
Without listening past the first minute -- I'm definitely subscribing to the podcast though -- can the same be achieved with nginx and the new push stream extension
What kind of tablet is it? I just checked using the Android emulator. The menu does appear. It's not super obvious that is there though, since it's a just a single button.
One of the few podcasts I always look out for, always has discussions on some interesting PHP projects. Good episode again.
Yes I have other things in /var/www and it's better not to modify DocumentRoot that way. I tried fiddling with "index.php" as recommended by Codeigniter manual but with no success...
For an entry level php position, showing code will get you 90% of the way there. Just code a **very** simple reddit style link submission system, and host the code on Github. Letting them see your code, warts and all, will go a lot farther than another applicant with a stunning resume, a PhD, but no real code to show for it. Keep it simple. Use PDO instead of mysql_query. 
My argument was that it could be done, not that it's the best tool for the job. The article claimed that it couldn't be. Whether it is feasible to do it in PHP is again up to the factors stated above.
Ok, fair enough. I know I'm guilty of letting long running PHP jobs happen because I'm too lazy to switch to something else at 3pm on a Friday.
Oh dear, it's a select box. You've just committed a cardinal sin of usability. Prepare to be executed.
I don't want to sound like a jerk because you're looking for tips and help, but a big part of coding is solving problems and choosing which method is best to solve a problem, and also, you know your company and what would be useful or impactful to them better than we do. 
Well, it all depends on how you use it. PHP is a perfectly acceptable tool for computationally heavy, long-running processes depending on the context it is running in. For instance, I have a friend that uses PHP to generate frames for his GIF animations. He uses it because it gets the job done and allows him to do what he wants quickly.
I've never really heard anyone say that before, I wonder why that is? Upon looking at F3 though, it does look REALLY cool! Thanks for the link.
Don't listen to this guy...a REAL entry level PHP developer would use the shit out of mysql_query. Try to get a copy of 5.1 and insist it's better because it's much more stable than the newer version. And don't forget to use a Windows server. PHP was made for Windows.
I agree with Devnull, don't worry so much about the style. If you're crazy worried about it then try: &lt;https://jetstrap.com/&gt; One of the things that really impresses me when I'm going to higher an entry level PHP developer is the use of open source technologies. This might not be for everyone, but for me it really embodies the culture of the programming community -- and shows me that they're willing to build great things off of great software. One of the things that really wow'ed me (which eventually led to me hiring them) was a Bitcoin address shorter. Using a simple database, and [Flight](https://github.com/mikecao/flight) this person created a very simple RESTful API which allowed someone to enter into the database a Bitcoin address with a short name. Using the REST API you could update the fields (address, name, created, password) to whatever you wanted (assuming you've provided the password). It was just enough to wow me, and it was really nice to see it made on top of such a well proven framework. Simple things sometimes wow those who you need to wow. As a hiring manager I need to know that you're diverse, and intelligent. So my advice? Take what you love (Bitcoin as an example) and make something useful surrounding that technology. 
What Rygu means is that those system probably are using an [event based architecture](http://en.wikipedia.org/wiki/Event-driven_architecture).
This is what I came here to say. And OP, you should think about this in the context of what your company does, and existing tools they use. I'm a senior dev. I know my knowledge of the stack and language has come from using it every day for 10 years and making silly mistakes in the process. Mistakes I would expect every starting dev to make. Especially around security. A junior that can solve a problem securely, reasonably quickly and show they have delved into a framework or CMS that we use commercially is often worth much more to us than a junior who tries to hand roll something. Don't take that the wrong way. For all I know you're a prodigy. What I'm saying is, as the person above me said, proving your approach to providing a solution to a problem is just as important, if not more, than your coding skills. Besides, your coding skills are evident if you develop a simple Symfony or Silverstripe app. And those tools mask innocent mistakes a great deal. Best of luck. 
This sounds like it's from the future! No really..look at the post date ;p
http://www.reddit.com/r/shittyprogramming
I don't have much to give in the way of an idea, and I'm unsure if they will be looking at your code, but I'll try and give you some advice from an IT manager's perspective. We made our candidates write code as part of 2-3 hour long interviews, and these are the top things that stood out for me: * Clean, consistent and easy to read code. You could write a novel here, but essentially it's about ensuring your code is easy to follow by anyone else. Developers come and go, and IT managers and team leaders find it important that other developers can pick up your code and modify, extend or fix it relatively quickly. * Yes, it does matter how pretty your app/site/project is. Not always to other developers, but if you're being interviewed by managers from a non-programming background they will judge you by how things look before how they function or how well it was coded. It also sets a good tone if you're presenting something, but don't show off a masterpiece followed by spaghetti code. * Don't be lazy. This applies to everything, but for me personally, it's most important in security and validation. In any example you create, ensure you try to demonstrate that you are at least concerned about security, validation and any potential vulnerabilities. If you don't code it in, at least provide a comment, even something simple like // TODO - this needs to be validated because of xyz... It shows you at least thought about it. * Don't ever try to bullshit a manager or another developer, they will most likely know straight away. If you don't understand something, ask questions, try to demonstrate some problem solving skills, or at least show your enthusiasm to work. For example, if an IT manager asks you, why might you use an Oracle database instead of MySQL? If you don't know, then ask them why and get them to explain it to you. Most managers and developers do actually love to talk, but usually only if they're interested in a subject, and they like to share their knowledge and talk about things passionate to them. Getting them to talk about a subject establishes communication and shows you're keen to learn. * Don't ever try to show off. If you're presenting something, speaking, writing code or writing comments about functionality, keep it clean, simple and to the point. * Show off. What the??? That is to say, be proud of your code, understand and know it back to front. If someone asks you about it, give them a life a story about it to show your understanding and not as if you just found it on the internet somewhere. Know your code. * Know the business and industry, and I'm not referring to development, coding, etc. Knowing how to code is one thing, but managers also look for your understanding on how to interpret requirements and instructions. They're also keen for you to think outside the box when required. Knowing your business and the industry you work in will also help to identify problems that may not always be evident early on. There's probably heaps of other advice, but I hope the above helps if you have an interview or if you need to show your project to someone. As far as ideas go, anything is generally suitable, but keep it simple. As long as you can demonstrate an understanding of coding principles and you can present your work with a good level of enthusiasm, it'll be enough to convince people you're serious, passionate and ready for the challenge.
Fetch both the next and previous id's in one query... select 'P' as fieldtype, MAX(id) from users where id &lt; 2 and hidden = 0 UNION ALL select 'N', MIN(id) from users where id &gt; 2 and hidden = 0 The 'P' row gives the previous id. If that row is missing then your code knows there isnt a previous row, so you can make sure the prev link is not clickable. Likewise the 'N' row will be missing when fetching the last record Also make sure you have an index on id, though its probably Primary Key so has an index already
The site is amazing! Even I'm going to use this now, and I live in the East Coast, USA. Heads up: When you click on a movie, and click find showtimes, and then click a showtime - you get a 404/503 error page! 
Are the entries using timestamps? If so, you should know the timestamp of the current post, so you can query the most recent-dated posts before and after current post. 
If it's already in your company, poke around and *ask* what they'd like to see from an applicant. Almost every company I've worked with has a differing view on what impressed the decision makers - some cared about code style, some cared about performance, some cared about security knowledge, some cared about database understanding, some cared about design aesthetics, some cared about js/front-end skills. I wrote a blog post on my own personal views on this topic - here's a rundown list (more details here: http://michaelkimsal.com/blog/things-a-web-developer-might-need-to-know/) * Version control * Ticket/issue systems * Testing * Continuous Integration * Security There's more, but these are some of the big ones that I think are rather fundamental skills which almost *always* get overlooked or downplayed (oh yeah, I have backup directories of my code - that's my versioning! - oh sure, I "svn up" on the production server after I tested something locally - it always works!, etc). 
Yup - that's exactly bow you would do it. Select the next ID by using the current post's timestamp like SELECT id FROM posts WHERE timestamp &gt; :current_timestamp ORDER BY timestamp ASC LIMIT 1 Then just do the oposite for prev. (Timestamp &lt; :current and order DESC)
I was about to jump in and say "Well they probably use their develop branch for the day-to-days" but they havent pushed to that in 2 years, so...
Their mailing list says that 1.0 should be released along with a new site within few weeks. That was the end of March (https://groups.google.com/forum/?fromgroups#!topic/socket_io/NMqfaVMsV3o) [engine.io](https://github.com/LearnBoost/engine.io) which is going to be the replacement engine within socket.io has had more recent activity, but still nothing in the last month.
Yeah. It's a hard fight. The whole "the model is where your database stuff lives" has been so beaten into people's minds it's hard to root it out.
I was new to REST and the MVC idea with PHP. SLIM was a great start to getting involved with it and learning the basics without the overhead of some of the larger frameworks.
Exactly, as an interface no, but if your providing an API to a drupal site and time is limited, then not a bad idea. However, we are building ours from scratch(out voted by my fellow devs, I wanted to use Python!)
Rather than show the hosted result, I'd be more interested in seeing the code on GitHub. GitHub profiles are a goldmine when selecting candidates. Can gauge more than just whether you can code, like how well you play with others, how interested you are in your subject area, involvement with the community, etc. by looking at forks, submitted pull requests, comments, and starred repositories. That said, you're going for an entry level job, and obvious willingness to learn and a little talent are all you usually need to demonstrate for that. Anything more is a bonus. 
this is a good news... anyone tried running PHP frameworks in the GAE?
Thanks for all the pointers! Definitely going to touch on some of the points made here. 
I'd also suggest rather than embedding logic into your IDs, just add a column that's visible INT(1). Then just do: SELECT * FROM posts WHERE visible = 1 ORDER by insert_timestamp desc 
Constant requests. BAD BAD BAD. What you need are sockets, specifically websockets. 
Something like Socket.io? Would that require something else like Node.js as well?
Yeah.. Constant polling are bad. Use web socket. Try looking into reactPHP. The problem is some browser does not support them so you'll have to fallback to Ajax polling. But still, try web sockets.
Yes but you don't need to learn it. There are plenty of PHP libraries for Socket.IO. 
Push state or some of the other things people have listed on here.
While you're very likely being satirical, it doesn't really show too well in your comment. Just FYI
If this is a penny action site, look at the timers for all the ongoing auctions on the page and grab the one with the least time remaining. Once that one has expired, you update all the auctions on the page. If you place a bid on something, you also refresh all the ongoing auctions. 
Well, maintaining a constant connection isn't really needed either. Penny action sites don't need to be "live", only give the appearance to be. What you do is only update the actions on the page once the timer with the lowest time remaining has expired, or when the user places a bid on something. 
&gt;Yeah.. Constant polling are bad. Use web socket. Try looking into reactPHP. Constant polling is indeed bad, but maintaining a constant connection with all clients isn't too great either. A better solution is timed polling, that is, only pulling the information when it absolutely have to. Penny action sites extends the lifetime of the action with every bid, however, this timer doesn't need to be updated in real time on the client-side. Instead, the client should pull information only once the timer with the lowest count has expired, or when the user has initiated a bid. This gives the user the illusion of the bidding process being in real-time while really only updating when it absolutely needs to. 
I think i'll try this out. So if I use Ratchet on the client page (index.php for example), I could open a web socket for that user? Once the socket is opened, I could push data to each individual index.php page that has an open socket?
The system is not a penny auction site. There is an open window of time where users can submit bids (usually 10-30 seconds). During this time, users can place as many bids as they want, and the bids are anonymous to all users. After the bidding is locked, there is a waiting period that can be 1-2 minutes, then winner is determined and displayed back to everyone. After this auction, another auction will open and bidding will take place again. I only really need to update data: 1. When an auction starts, 2. When bids are locked, 3. When the winner is determined. Would sockets work better in this case?
&gt;There is an open window of time where users can submit bids (usually 10-30 seconds). Is this window of time extended with each bid? If so, it's a penny auction, and the above advice would still stand.
&gt;Would sockets work better in this case? Web sockets wouldn't really make much sense here. There's nothing warranting a constant connection to the server, which will certainly place a toll on your server, when you only need updates at certain intervals. &gt;1. When an auction starts, 2. When bids are locked, 3. When the winner is determined. \#2 wouldn't need a request to the server, as you could simply read out the remaining time on the auction, and then "lock it" with JavaScript. As for the other two, what guides when a new auction will start and when the winners are presented? 
You might also be using an autoloader, in which case files are included "magically".
Easiest solution without getting into sockets etc is to write to a static HTML/JSON/whatever file and ajax poll that. The main bottleneck is php, not the fact that you are polling (though it's still bad if you can avoid it). I've written a realtime chat app around this concept (targeting low end hosting hence no websockets), and it scales exponentially further than directly polling php 
Regular expressions is the wrong tool for this. Use a [HTML parser](http://www.php.net/manual/en/class.domdocument.php) instead. Additionally, [XPath](http://se2.php.net/manual/en/class.domxpath.php) should make the selection of the element(s) a bit easier for you. My XPath is a bit rusty, but I believe it should read something like the following: //a[contains(@class,'orange')] 
Why not use javascript/jQuery? $('a.orange').html('New Text'); or str_replace();
I suppose I could, it's just engrained in my head that you fix things in the content just in case someone doesn't have javascript enabled. Which these days I know is extremely minimal. 
&gt;Which these days I know is extremely minimal. Until you start considering content consumers which *aren't* desktop browsers.
Here's your answer: preg_replace('/(&lt;a class="orange".*?&gt;).*?(&lt;\/a&gt;)/ms', '\1'. $my_new_text . '\2', $content); The reason you're being told to use an HTML Parser is that this solution is brittle and likely to break.
I'm going to get insulted but you should consider using nodeJS somewhere in your app if it requires any realtime functionality. PHP solutions exist but do not scale very well. Nodejs+websockets are perfect for this kind of application. PHP is not always the right tool for the job.
The window of time is not extended with each bid. The bids are locked manually by a global redis variable that stores the status of the auction. Someone will manually change the status of this variable. So when the variable is changed to locked, all bids are locked. This variable also stores the winner of the auction. The time between events 1,2, and 3 is always dynamic, and depends on this variable. After event #2, the bids are then displayed back to the users, and there is a requirement to wait 1-2 minutes before event #3 where the winner is displayed. No polling is required between event 2 and 3, but I still need the user to be aware that the state has changed between 2 and 3. I'm not sure how this can be done. 
What exactly are you trying to achieve? 
&lt;?php for($i=1;$i&lt;=100;$i++) { echo pow($i, 2); echo "&lt;br /&gt;"; } ?&gt;
I was in the same boat as you. I had a large project for work that I was about to begin and I told myself I was going to pick a framework. Decided on CakePHP as I already had a good PHP foundation. My project has been in production now for about 6 months. I'm happy with CakePHP. Might start playing with Zend for another perspective.
There is a excellent book available for free on the git website: http://git-scm.com/book Also "check in" and "check out'" don't exist in git ;)
Thanks. I told you, I'm not even sure what questions to ask! ;)
Setting up Git on a server is the most difficult part and it usually varies depending on your stack, IIRC. I actually had my hosting company do it for me, an option which may exist for you as well. However, to just learn the basics, there is a decent Codeacademy tutorial here: http://try.github.io/levels/1/challenges/1 Also, after you've done that, there is an excellent visual representation of how branching works: http://pcottle.github.io/learnGitBranching/ Just don't give up. It takes a bit of time to get used to git but once you're able to "see" how it works, it will become more intuitive...
So is there significantly less overhead in polling a simple text file rather than PHP? Not sure why you're downvoted, but one option is to poll this text file that stores a simple 1, 2, or 3 which indicates the state of the auction (open, locked, or winner). If the state is open, or a winner was determined, there could then be a request to the PHP file.
Does Silex use any Symfony components? If so then I would say start there b/c if you move into Symfony or Laravel both will be based on those components as well. Not to mention I just generally recommend getting familiar with the Symfony components as I believe a lot of PHP libraries and frameworks will be incorporating them now and in the future.
I personally think that the guys at Beanstalk did the best job with explaining Git (without GitHub) for Windows. Check it out, it helped me a ton. http://guides.beanstalkapp.com/ The deployment services they offer are excellent as well.
Understanding version control and branching is the key to getting git (or any modern version control software) If git turns out to be too much to bite off at once, try mercurial. I like git better now, but mercurial was easier to learn initially. 
Are you aware of [Mercurial](http://mercurial.selenic.com/)? You get all the power of Distributed version control system in a simple command line interface unlike git's commands and terminology which are hard. if you google 'git vs mercurial', you can read all about it all day I suggest you try them both if you haven't done it already. Mercurial is also easy to setup for sharing via the bundled cgi script. For quick sharing, you can even start the built in webserver using 'hg serve' command. Let me try to give a quick intro to DVCS's like git and mercurial. Unlike the svn and cvs, there is no centeral server. That's where the distributed part in DVCS comes from. Every user has the complete repo. This repo can be considered as a glorified zip archive, it is just a .hg or .git directory that sits in the root dir of your project. So for you to start using, you download and install git or mercurial in all of your machines. Then one of you create a repo, and others clone from it. But for learning, I suggest you create a repo and try cloning it to a directory in the same machine. Try to push and pull changes between the clones which are in the same machine, so that you get a hang of these operations. This is important because these operations are same, wether you do it between directories in the same machine, or between two machines over a network. Once you understand how cloning, pushing and pulling work, you can setup a system to work from different machines. at which point, if you are using mercurial, you can use http://mercurial.selenic.com/wiki/PublishingRepositories. 
socket.io seems pretty fixated to node.js, too. Other backends are mostly externally developed and not "supported". (played a little with tornadio) SockJS seems a pretty nice alternative (officially supporting all kinds of backends), and could need a php backend: https://github.com/sockjs
Depends on what he wants to use, really. If it's Github, then you're in luck: &lt;http://windows.github.com/&gt; Otherwise: &lt;http://gitimmersion.com/&gt; or &lt;http://ftp.newartisans.com/pub/git.from.bottom.up.pdf&gt;
Wow, thanks... hadn't heard of Mercurial until now. It might suit our smaller footprint much better.
I'm checking out bitbucket now, thanks!
Wow, that is fantastic. For your first side project you did a really amazing job! 
Very significantly less overhead, yes. Especially if you're running nginx or a well-configured instance of apache, or any other fast webserver for static content. The approach you suggested would be good as long as changes happen much less often than than polling requests. In an ideal world you'd store the actual data being polled for in the static file, but that may not be possible from a security or uniqueness perspective.
http://programmers.stackexchange.com/questions/46716/what-should-every-programmer-know-about-web-development This is, in my eyes, the de facto list of things you're going to want to know. Don't expect to know all of it immediately, but always do you're best to revisit the list and catch up on some things you may not fully understand. One of the biggest things to remember is there is no harm in just dropping a concept (whether that be PDO, Distributed Version Control, or Lambda Calculus) if you feel hopelessly stuck. Try learning one of the MANY other aspects of this field. You'll get everything in time, just remember to come back to those things that reduced you're brain to goo when you're more adequately prepared. You'll be amazed at how much some down time can help you learn tough concepts, especially with PHP. You can write incredible things with PHP, but you can also write some of the worst functional code on the planet. On a PHP specific note, avoid anything before version 5.4. PHP still hasn't shaken it's terrible reputation because people keep using dead versions of the language. There is really no excuse if you're just starting out.
The github app for windows is a great GUI, and it doesn't require your repositories to be on github (mine are with bitbucket).
Not all defaults can be overridden at the command line only it appears. Imagine trying to override the arguments passed in to the constructor of a test listener via command line only. If you need to override a default configuration file, you need to create a new configuration file. I mean, you can probably extend TestRunner's doRun to change the args, use a different php.ini w/ xdebug disabled, or --no-configuration and build up your own parameters. Otherwise, a pull request to phpunit might be helpful.
Here's a bird's eye view. I recommend using a remote version control service like [Bitbucket](http://bitbucket.org/) (free) or [Beanstalk](http://beanstalkapp.com/) (paid) to host the git repository. You would setup git on the local Ubuntu server and the production Amazon server. Then create a new git repository in your Ubuntu working web directory for the particular web project and push the files up to your remote repository. From your Amazon production server you can then pull down the files from the remote repository using git at the command line. Another benefit of this is that you can then easily work from different locations and pull the master source files down at anytime from any computer/server. When I first started using git, I basically just used it for easy, fast deployment and backup purposes. However, that is just scratching the surface. The power of git is in the branching, merging, etc. [Here's](https://confluence.atlassian.com/display/BITBUCKET/Bitbucket+101) an extensive guide on Bitbucket that provides a wealth of information on how to use a remote repository. There are quite a few links and sub-links on the left side that are more than enough to get you started. Once you have the basics down, search for "git workflow", or the like, to dive further into the subject and really learn how to start using branching, etc. 
About 3 years ago I chose for cakephp aswell, but if i had to choose again i would choose symfony. I am even thinking about rewriting my 2 years of fulltime work cakephp application into symfony simply because of the cakephp limiting workflow.
You should let MySQL handle finding the IDs, otherwise you'll have to make a new query for every hidden or deleted post which could potentially be a lot of work. If you look at it at a higher level, what you actually need, is the first post with a higher ID, which is not hidden, ie: SELECT (necessary rows) FROM (post_table) WHERE id &gt; :current_id ORDER BY id ASC LIMIT 1 :current_id will of course be a parameter bound to your prepared statement to prevent SQL-injections.
[Version Control by Example](http://www.ericsink.com/vcbe/) is a great book for anyone trying to wrap their head around Git, Subversion, Mercurial or Veracity. It's available for free in digital form and it's a pretty short read if all you want is to get a repository going. The advanced stuff is still there if you want to read up on it later. As for client, check out SourceTree as someone else suggested. It's a great visual client!
Thanks. I'm using apache with CentOS 6. Changes would not happen often , but when a winner of the auction is determined, I'll need to use a PHP file rather than a text file because the data to be retrieved will be unique for that user.
I started learn Symfony a week ago and I've release my first small project. What I've done it's to read the Book section per section and adapt it to a real project. Might be your blog, small service you will like to see or whatever. I really like Symfony as it became more and more used in severals projects (as well Drupal, Lavarel, and so). http://symfony.com/doc/current/book/index.html
Another thing to be aware of is that you've done a fine job diversifying your environment a great deal. Remember that there will be differences between all of your machines, both the 2 development machines, the test and the production servers. This can lead to a lot of extra work, since you are likely to run into differences in the environments, leading to a lot of "but it worked on my machine".
Call me old fashioned, but I started out with codeigniter. Even if most people here will tell you it sucks (and from a code point of view it does) it helped me understand MVC. It's an easy to pickup framework and you can wrap your brain around it pretty quick.
I use git, and have never used Mercurial. That being said. I've heard that mercurial is great for smaller projects and teams that don't need the complexity and configurability of git. Again purely anecdotal evidence here, but it maybe be something to look into. 
But OP is asking for a reasonably generic answer (have a look at the top comment in this thread-- a reddit link submission system, really?) when he needs a specific one that will give the hiring manager a boner. we dont know his company or his hiring manager so pretty much the best thing he's gonna get is the top comment, unfortunately. My point to OP was that since he's obviously very new to PHP and maybe programming overall, he should keep in mind that problem solving and developing solutions is the key to a developers success. These solutions aren't always code related. 
I think this is a very bad suggestion and would either fly over the head of most hiring managers or seem completely random. 
The loner here, as usual If you have *no* experience whatsoever you can pick up any version control. SVN is simple and to the point. methinks that as long as your ubuntu box is web-reachable, you and your mate can submit **svn commit** and your AWS can just **svn update** or **svn export** all the code. You won't get all the nifty "source control while you're disconnected on the bus" and "I can branch in a microsecond" and maybe many more features, but other that that SVN is more than enough for your project. Yes, I'm advocating SVN over distributed SCM. Get over it :-)
I always point people here first: http://git-scm.com/book Also, this was linked in /r/git a few days ago: http://think-like-a-git.net/
Interesting! Just started using GitHub for Windows and this one looks pretty interesting when comparing the two.
Just pick the most used one and go through the tutorials. By the time you master it there will be a new framework to learn from scratch anyways. I've done Zend, Symphony, Cake, and Phalcon and they are all variations of the same. If you can, see what's most used in your city to improve job chances.
We use BitBucket for our product and I absolutely love it. If you ever end up needing more advanced bug tracking or documentation, Atlassian offers Jira and Confluence as well, which are amazing (when used properly). They have a ton of fantastic tools for development and product support.
Am I the only one to recommend learning git from the command line? Once you've mastered that, then you will better understand these web based services, and more importantly have much more power over your repository when disaster strikes Github is ok, but learn git cmdline and it will pay you back a thousand times over
Well the thing is they make mistakes as well. I took a rediculous CSS "test" and it had errors in there. So I went to them and pointed it out, they corrected their "exam" and I got my points. Maybe, this is the case as well, if your functions does the exact thing that is required :) So maybe just send them an email ? 
If you're looking for somthing local, try [this](https://bitbucket.org/sdorra/scm-manager/wiki/Home). It's called SCM-Manager, super easy to set up. Supports HTTPS, SVN, Git and Mercurial, and the best part, they whole server app is in Java. Just download, run and you're set. The nice thing is it's able to remotely create repos, no local access needed. Got it running on a old net-book myself. ... OR use bitbucket :)
Problems: * You should be checking is_array instead of count() &gt; 1 * It said integers, so it could be throwing numeric strings at you that they don't want you to consider (i.e. use is_int) * What would happen if you were given an array of all negatives? Your code returns 0.
Ohhh didn't think of that. Thanks for the feedback
That is true. It really depends on who exactly will be reviewing your application - I should have made that clear. If you're applying to an HR drone, send a polished resume. If you're applying directly to a technical contact, they would appreciate then Github repo/sample code more. 
Someone is currently working on a Socket.IO component for Ratchet. A SockJS component for Ratchet is also planned. 
Well, I thank you for your answer but not sure how to feel the rest. If my job was strictly web dev, sure I would be pretty stupid and shouldn't be doing it. But this is a side thing of the thing on top of also running an IPTV head end, DSLAM work, and a few other duties. I'm not dumb by a stretch, just been learning it as I go and figuring things out and really starting to rocket forward with it. I just don't have days to spill into it since I do have several other things to maintain and keep going.
Check out the max() function from PHP. Your answer is in there. http://php.net/manual/en/function.max.php
upvoting for Symfony. symfony2 rocks my socks.
Is your real-time chat app available for download anywhere? I've been looking for something to replace my current solution since I no longer want to force Java on anyone. 
It's amazing. If you use netbeans it's built in
I just wanted to say thanks for all of your work. As a long time user of codeigniter and cakephp, Laravel is a breath of fresh air, and works exactly how I want a framework to function. And with CI hanging onto a lot of legacy code in the core, I really like developing using a forward thinking framework. I just started using laravel about a month ago, but the rapid dev, CLI, and DB migration aspects no longer make me jealous of rails. Question -- with v4 coming out, how does laravel plan to manage community plugins (bundles)? With v3, you had a pretty nice index for them on the laravel site. Is that going to continue into v4? Or will they be through composer? I don't have a ton of experience with composer so I don't even know if that's even a right path. Also, is it just you, or do you have a core team now and are you going to schedule regular release cycles? 
This is probably frowned upon here, but fuck's sake: RTFM. Jesus. 
I feel like it's a forward thinking codeigniter. It's similar to CI in that you can make it as simple or complicated as you want, but I think Laravel provides better groundwork out of the box. Laravel also relies on less legacy and deprecated code than CI does. All things considered, I've gone ahead and taken the plunge into using L4 with my most recent projects, and I'm glad I did. They've been quick to development and have scaled really well so far. 
I agree, but I think documentation has a large part in this. Both CI and Laravel were extremely easy to jump into after spending an hour or two reading the well-formatted docs. The two biggest things I look at when exploring a new framework (whether it be a php MVC or a JavaScript game library) are how thoroughly the documentation is to get started and how active the community is. I think Laravel excels in both areas. 
CodeIgniter doesn't suck, it's just falling behind because it won't drop support for older versions of PHP to make way for new features. It doesn't really support testing and getting Composer up and running is a bit harder, but it's still a great framework. Though, if you're starting now and interested in CodeIgniter, you're probably better off going straight to Laravel 4.
Yes. Silex is developed by the same people behind Symfony. http://silex.sensiolabs.org/
&gt; Setting up Git on a server is the most difficult part and it usually varies depending on your stack, IIRC. Huh? If you have ssh access to the server, you are literally all set. ssh user@server "git init --bare ~/project.git" git clone user@server:~/project.git The first command creates a bare repo on the server that can be pushed into and pulled from The second command everyone should do on their local machines, to create the "project" folder for the files. 
dvcs like mercurial are a lot more easy to set up and use than svn. Mainly because you dont have to setup a server and a client and a way to connect them. Its as straight forward as creating a tar archive. 
you'll also find great advice (and, surprisingly, fun examples) here: [http://www.ericsink.com/vcbe/vcbe_usletter_lo.pdf](http://www.ericsink.com/vcbe/vcbe_usletter_lo.pdf)
Sockets are not as simple as many people are making them out to be. Besides the pain of getting any kind of persistant connection working with PHP, WebSockets are not supported by enough platforms to make them useful on their own. In the node world, people use Socket.io or SockJS to polyfills to make up for the lack of WebSocket support in browsers. If you go with a socket approach, do your research on browser support. DarkImmortal's idea of using static files is sound. If you need to have PHP in the mix for some reason, you need to trim that PHP script down to its bare minimum. That might mean ditching any framework you're using ( just for the 'hot' polling script ). That might mean storing JSON in redis to skip any overhead from json_encode. Another idea to consider is using [long polling](http://en.wikipedia.org/wiki/Comet_\(programming\)#Ajax_with_long_polling) to keep one connection and PHP process doing as much work as possible. I've tried this, and don't recommend it at all, but it may be worth a look. Best of luck! 
And if you don't want to let php self manage itself, just go easy mode and cron a "supervisorctl restart *" once a day or so.
I haven't used gearmand myself - I do use beanstalkd and long running php worker scripts. I use [supervisord](http://supervisord.org/) for all the reason you mention. Works great.
Thanks, thats reassuring. I've already read about supervisord but wanted to know if it was de-facto, or whether anyone would recommend it when asked The ram usage limits you have in place, is this because your workers are long-running? Mine are quite simple tasks and so I think any mem leaks will be as a result of long-term running rather than my PHP job leaking ram
How does this work if a job is in the middle of executing? One of the attractions for me, of gearman manager, is that you can tell a worker process to restart every 2 hours, but if a job is in the middle of running, it will wait until thats completed then restart the worker gracefully. I'm guessing an init.d-level restart might not provide the same safeguards ?
^ This.
So you used free web hosting and expected the same as a paid service? That's actually pretty funny.
I use Windows 7
If you can't figure it out when you have the documentation right in-front of you, then maybe you should hire someone to do it for you. They're just links which spits out data in JSON format, some of which have required and optional parameters which is added as a query string. There's nothing more to it. 
Yes! It makes more sense doing this! Thanks a lot!
Beanstalk ain't too bad. Used it quite a bit before. Has Pheanstalk finally gotten multiple server support? Edit: doesn't seem like it :(
The workers can be long-running when blocked, waiting for a message to pop up on the queue. Once an item does arrive, and the worker processes it, it can simply exit, and another worker will be started to take its place. That way you know there is a good clean-up and fresh start for every job. Of, course for more resource-intensive systems, you may not want to restart jobs as often, but I am going to guess that will be a problem for you to solve much further down the line, when optimisation may be more important than just getting the thing to work reliably and predictably. Just upping the number of workers on a queue can increase throughput easily.
Use [god](http://godrb.com). It will handle all three of your scenarios and the configuration files are simple ruby scripts.
Yes, I think it is worth fixing. There are different reasons, but the most obvious is because otherwise you're always returning data that may not be required or used. Other reasons are more to do with structuring a framework for flexibility, but the data transfer should be reason enough, unless of course this is a very small application that is not worth the effort financially. The data transfer may be negligible for many tables, but consider situations where, for example, you are storing binary data or large amounts of text, and that data is now always going to be returned with each query. Whether it's worthwhile for you is only a decision you can make as you know how large this system is. However, I would always advise to only ever retrieve data you are going to use. Just to add - Something to be mindful of which may contradict the above, but you may need to consider things like query caching, for example, if you're using Oracle as the database, in which case you may need to evaluate your SQLs and consider the cost of each query to the data returned. It's unlikely this will be an issue, but again, this is something only you'll know as it's entirely application specific.
http://four.laravel.com/ Reading the whole thing will help you understand how it works, and how you should use it to benefit from it. *Disclaimer : Yes it is in BETA, but it's more than enough for what OP needs. Most production projects have way worse documentation anyway.*
Also, if you are stuck, you might be able to check with the folks over at /r/guildwars2 as I'm sure there would be others there who have used it.
Pretty damn ugly workaround.
Crappy code and hasn't been maintained for two years. No thanks.
How does it compare with Toad? 
Hmmm indeed it's using mysql_ :( I might fork this whole thing and bring it up to speed XD
Well, it's architecturally unsound as well. Models aren't the same thing as databases tables, and to open a new connection for each model you use is absolutely ridiculous. Keep away from this framework, it's an absolute joke. The framework appears to be authored by someone who had a very vague (read: BAD) understanding of what MVC is and how it should look like. 
&gt;it's the best light weight, full featured SQL app out there. I humbly disagree; [Sequel Pro](http://www.sequelpro.com/) has been my go-to for ages. I have yet to find a similar program in terms of UI and feature set. Shame it's Mac-only, though.
After looking more through the whole thing, I'm agreeing more and more. I'm now looking at http://silex.sensiolabs.org/ Any advice since you recommended it before?
That thing (Flight Framework) is riddled with statics, which is a bad thing for testing and extensibility. If you're looking for a lightweight framework, you probably want something like Silex or Slim. 
I used SequelPro exclusively while I used OS X to do my dev work, which was for a number of years. I searched for a while to find something that was similar for either Windows (so that I could run it in Wine) or Linux. While HeidiSQL is not a pretty as SequelPro, I could not find one feature that it did not have that SequelPro did and I believe it actually has a few more features. I could be wrong, though, it's been about two years since I used SequelPro with any regularity.
Am checking silex and slim out, I would just use laravel but the environment is php 5.2 and laravel needs 5.3 ::(((
I'm sorry, I meant *installing* git, not initializing a repo.
&gt; I would just use laravel but the environment is php 5.2 and laravel needs 5.3 ::((( That's simply unacceptable. PHP 5.2 met its end of support in 2010. If you have the option, you should change hosts to someone a bit more... responsible. 
I'd say that Gearman Manager is maintained. A couple years back(2) when my company was about to release we had some issues with Gearman. We ended up messaging Brian Moon who was extremely helpful in getting us up and running w/ GearmanManager.
Cool Project! As a dumb tech editor, I have to ask: Will it still work with HTTP 2.0?
Heh, had a chat to the techs a few mins ago and they've just upgraded to 5.3 today - perfect timing. That said, I'm going with laravel :)
A little bit out of context, but server the same purpose. I opt out to use Gearman or any other similar tool. Instead, I use Amazon SQS to queue the messages, and PHP go get the Queue messages periodically using a cronjob. This way, IMHO, my application depends on itself, and the infrastructure is managed by third party. If I want to move my code somewhere else, I won't have to worry about what's on the server. Just throwing this out there. 
That was funny... lol... relax bro... 
Last time I tried this, it had some issues with SSH tunneling. Anyone know if that still has problems?
?
Great. 
Cheers for all your replies mate, appreciated :) Have a good afternoon
Stop learning just the framework and really learn the language instead. There's way too many framework junkies who don't know how to do things properly with the language and their coding skills are crippled when adapting to another framework/language. Instead of learning ORM, learn SQL. MVC is just a design pattern. There are many other design patterns out there. Be a master of the language instead of just the framework. Too many of these framework junkies (e.g. .NET developers with their Entity framework, PHP with Laravel/Symfony/CakePHP) will get so confused and they don't have a proper foundation. Master the language first, framework second.
You might find array_reduce works better for these kind of algorithms (ntm, yours doesn't handle array nesting)
You too, and happy programming.
Choo choo!
All this is doing is making a wrapper to CURL easier to do from the developer perspective. I would assume your limitation would lay there. 
Be aware that SQS charges per job, so if you queue up a large number of small jobs on a regular basis, this may be prohibitively expensive (as it is for us).
&gt; How are people deploying gearmand in a PHP environment? Badly. We have lots and lots of problems with Gearman, possibly relating to using a somewhat old version. But I can't upgrade it until I migrate us to CentOS 6, and that's a long path that keeps getting longer... Since PHP is *super* buggy when it comes to forking processes, keeping track of the children, and handling signals appropriately, we have some super hacky stopgaps in place. Here are some excerpts from our client's init-script: graceful) wait_for_jobs stop start ;; wait_for_jobs() { echo -n $"Waiting for jobs to finish..." local jobsRunning local timeout timeout=$GRACEFUL_RESTART_TIMEOUT while true &amp;&amp; [ $timeout -gt 0 ]; do jobsRunning=0 # We have several queueworkerd children processes, each of which spins # off a child for each job. We want to check those grandchildren. for child in `ps -o pid= --ppid $(cat $PIDFILE)`; do ((jobsRunning+=`ps -o pid= --ppid $child | wc -l`)) done if [ $jobsRunning -eq 0 ]; then echo return fi sleep 1 ((timeout-=1)) echo -n $"." done if [ ! $timeout -gt 0 ]; then echo echo -n $"Timed out waiting for jobs to finish." failure echo exit 1 fi } and then I `service queueworkerd graceful` every few minutes via crontab. Using a process monitor is a much better idea for keeping it running; do that if it works for you.
Well, I would say AWS SQS charges per request. Every month, all the customers get 1Million free request. After that $0.5 per million. And batch of 10 messages are counted as one request. But one can benefit from 1M of free request a month. But besides that, it depends on what you are doing, you are right, yes it will cost you. 
Silex is a good alternative, based on Symphony, good documentation, moderatly easy to use, robust codebase. Can use composer for installing additional functionality.
When it comes to something as important as source control (trust me, you really want to understand wtf is going on when the inevitable crisis happens) take the time to really learn one system before using the GUI. This is a great site to get you started with the concepts http://pcottle.github.com/learnGitBranching/
I'm a hiring manager who has just filled two positions and this would have gotten him a job. We ask to see code from every applicant. The vast majority are using mysql_query, filled with SQL Injection vulnerabilities and mixing logic right in with presentation. We're a smaller company with 20 total employees and 4 full time developer positions and one part-time one.
I would hold that against someone applying for a Junior position. Auth is a very complicated thing to do right. In PHP you should just throw something like Sentry at it and move along.
Laravel is much more difficult to learn if you actually want to sift through the source code and follow the application's path from request to output. It's done in a much more recent, OOP, "better" way than CodeIgniter, but for someone in the OP's situation, it might be a little overwhelming. Take a look at Laravel's code either way, though. You'll learn something somewhere, and that's never a bad thing.
Just use your distro's package manager. Git should be in the default repositories for pretty much all linux distros that use a package manager. e.g sudo apt-get install git On Ubuntu/Ubuntu Server. That's it.
I started with PHPMyAdmin when I was a novice. Colleagues use Heidi. But I tend to find myself just doing stuff straight in the terminal now - can never be bothered to fire up a client. Maybe I should give Heidi 8.0 a look though...
I'll echo /u/erik240. I'd kill for an applicant that volunteered to show me some code. 
Congrats bro. Let me tell you a story. Not saying anything against your way at all, but I remember for my whole dev life, I used to manage everything else myself, I have the infrastructure and all. But for the past year, I start to realize that what I really want to do is doing programming, with less hands on the architecture. So what I did, I got a dynamic server from SingleHop.com. A dynamic server is a dedicated server that is turned into multiple VMs, making you have your mini cloud. You don't pay for the VMs you create. Just the main machine. Instead of having multiple DD servers, I went for one dynamic and setup multiple VMs there. Therefor I use the dedicated server full potential. I setup a VM for Redis, MySQL, Cron and Web App. Multiple AWS services are really cheap, so I opt to use them, like: S3 for file storage (I don't store nothing on my server but the application file), SQS for queueing system run from the Cron VM, SES for mailing. But I do stay away from EC2 or any AWS db stuff. I have them on my own cloud. I pretty setup my stuff to live in the cloud, but controlled by me. What did this setup allow me to do? Well, I could develop and test on any machine as long it has PHP. Less headache for me. And it came out way lot cheaper. P.S: I used git with Bitbucket for my code repo. Just throwing it out there. And I understand where you are coming from. 
Use array_walk_recursive to traverse through nested array. For example: $max = null; array_walk_recursive($arr, function($e) use(&amp;$max) { $max = ($max &lt;= $e) ? $e : $max; }); echo $max; // prints highest value of an array. In your case that would be 1000
The point is that you shouldn't be using is_numeric() for anything because it's too broad. It makes another mistake when it uses ctype_xdigit to validate hex characters. ctype_xdigit(102) for example will return true, but ctype_xdigit(254) would return false. In the 5 minutes I've been poking at the validation rules I've found a handful of obvious problems.
What an incredible useful function that I didn't know even existed. I really should have guessed something like it did exist seeing as for the rest of the answers I was using other php5 functions. Cheers 
This might be useful for laravel. The current laravel validation library is somewhat inadequate. 
I know this runs quite well in wine, but I really wish it was native for linux =(
I'm not familiar with Gearman, but I recently had to solve the same issue with [Beanstalkd](http://kr.github.io/beanstalkd/). A lot of people recommended [Supervisord](http://supervisord.org/), which I did get working, but I found it a little complicated. Then I read about [Upstart](http://upstart.ubuntu.com/), which comes as part of Ubuntu, and is available in other distros. It's as simple as creating a config file in your `/etc/init/` folder (ie. `/etc/init/myphpworker.conf`) and then running `service myphpworker start` to start it. I gave a more thorough explanation in this Stackoverflow question: [Run php script as daemon process](http://stackoverflow.com/questions/2036654/run-php-script-as-daemon-process/16577806#16577806)
Is it worth fixing? That only depends on how bad it's currently performing, and what your long term goals are for this particular app. Outside of that, I do subscribe to the thinking that you should almost never using `SELECT *` queries. I don't consider this micro-optimizing, but rather part of doing the job properly. See [Why is SELECT * considered harmful?](http://stackoverflow.com/questions/3639861/why-is-select-considered-harmful) for some good reasons why. I find that a lot of ActiveRecord style ORM's actually encourage the use of `SELECT *`. For example, what do you think is happening when you run `$users = User::all();`? Then you start doing some JOINs via the ORM's relationships, and who knows how many fields you're selecting...when maybe all you need is two! Basically, I think `SELECT *` is used a lot more than it should simply because it's very easy to do when using an ORM. And in reality, it won't matter for a lot of smaller projects. But having personally worked on some larger projects, I quickly learned that this approach has its limits, and learning how to optimize SQL queries can only be avoided for so long.
I'd advise you to watch the "Register and Login" series from PHPAcademy. http://www.youtube.com/playlist?list=PLE134D877783367C7 I would also recommend you use PHPass for password, rather than trying to roll your own hashing/encryption scheme at the outset. http://www.openwall.com/phpass/
That was great advice! Thanks a lot spookynutz
THIS we do the exact same thing at our company...if a php worker process gets over a certain amount of ram it kills itself and supervisor restarts it....life is good We also have a check in the worker code to detect code changes so the workers auto-restart and pickup the latest code revisions cleanly
Great work. I can put this to good use straight away.
&gt; $users = User::all() I can't even begin to describe how much I hate those types of query tools. You get to the point where you should be extending a framework, but then you are doing the work the framework should be doing for you. Especially those user and auth related queries tend to be on low specificity options. 
new item() instead of new item?
sorry, just really frustrated lol. its not deleting from the database or redirecting to a new page. I'm really new to php so any help you can give would be great! If you like i can send you a pm with a link to the dropbox. 
I was sure that i'd put it in... weird. its not deleting and not redirecting (due i think to it not deleting)
saulimus is right, also i see that you have somewhere header location index.php and somewhere ../index.php .. if index is i name dir then script cant find it in upper dir eg. ../
Surely this is shorter and correct? instead of adding an extra check on each iteration as any numeric input is bugger than null function array_highest($array) { $temp = null; array_walk_recursive($array, function($value) use(&amp;$temp) { if(is_int($value)) $temp = max($temp, $value); }); return $temp; }
That makes no difference. You can instantiate objects without parenthesis if the constructor takes no arguments. 
Ok, didn't know that.
when i test it it just refreshes the page
Meaning...?
I think you need to have a select element with the name=id ... not your form. Also you are missing the equal to sign (=) in your value of the option element. Right now you are outputting 'value1' for example. You need to have 'value=1'. Try this: &lt;form action="delete.php" method="GET"&gt; &lt;select name="id"&gt; &lt;?php foreach ($items as $item) { ?&gt; &lt;option value="&lt;?php echo $item['id']; ?&gt;"&gt;&lt;?php echo $item['name']; ?&gt;&lt;/option&gt; 
You my friend are a gentleman and a scholar. if i had any money at all i would buy you all the reddit gold on the internet. this has plagued my life for at least 2 weeks. 
Thank you. I'm glad it helped you.
The code in this tutorial is outdated. Why doesn't it suggest a PSR-0 class structure, not that you have to use it. But at least use something that uses splautoloading. Why are you only using sha1 to encrypt passwords?
Packages will be distributed via Packagist / Composer. However, we may provide an additional UI on top of Packagist just for Laravel packages, as I think that could be pretty useful. The core team is still pretty much just me, though I do have a core group of people who I bounce ideas off of, etc. With the release of Laravel 4 on May 28th we will be moving to a six month release cycle, so Laravel 4.1 will release in November of this year, 4.2 next May, etc.
I understand that PSR is at the very least recommended and spl_autoload has many benefits, but why do you think they are so important in a tutorial like this? The purpose of this tutorial was to use OOP and PDO to create something practical. Don't you think if I had talked about all that and also about using something like bcrypt and salts, it would have been overwhelming to someone who is maybe just starting with OOP and PDO?
I setup an achievement system for a gaming website a friend and I put together. In the end it seemed without going down to each individual action that performance suffered greatly with each achievement related action. In the end I had to code it such that there was a separate table to keep track of achievement goals. Each interaction with the system that affected these totals would update a +1, -1, or a larger number depending on the type of achievement. There were different types of achievements so the system could understand what it was looking for, goals, etc., to grant an achievement. What is going to matter is how many achievements there are and how complex the queries will become for some of them. There were some obscure achievements on our site that required lengthy queries, we had to cut that down in to something that fit in to an end-of-action hook so we could turn the logic away from the database to the actual action taking place. In the end this is what we had to do for all of the achievements aside from a select few that required cronjobs to check. We also created crons to ensure all achievement database totals remained correct, just in case something didn't get updated at some point (when dealing with hundreds of actions, we decided to err on the side of caution). Hopefully this helps, in the end whatever works best for you is what you should go with. :) edit: As an example if a goal was to have 50,000,000 dollars, every time dollars are added to the user it would check the total and add a 1(true) to their achievement field for the 50,000,000 dollars achievement. Since this would be a one-time achievement it would only honor the achievement the one time. I created a separate class for the achievements which handled about 50 different kinds of achievements so it really can be quite robust and still not be a performance hog. The site handled very poorly before the achievements were optimized to their own running totals table. After we changed it, site speeds seemed unimpacted by the achievements.
Name them. Now. I see some issues too but for a basic tutorial this is okay, but since you're being such a smart-ass please help him improve his tutorial code rather than knocking it.
I have mentioned in the end that sha1 is not a secured way of encrypting passwords and bcrypt would be a better option. Any one who follows the whole tutorial will know not to use sha1, but instead to look for a tutorial on bcrypt. The reason I didn't include bcrypt in the tutorial is because, it along with salting passwords require a separate tutorial. 
Thanks I thought this was a nice example of OOP in PHP. It is a nice beginner tutorial for understanding concepts of OOP. 