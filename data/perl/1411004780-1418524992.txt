Then you will definitely want to change the regexp to something like the one I posted. The only difference is in the first capture braces -- the '?' means that the previous + operator will try match a minimum set of characters instead of matching as many as it can, which is the default behaviour. See the 'Quantifiers' subsection in [perldoc perlre](http://perldoc.perl.org/perlre.html#Regular-Expressions). So an input line of: parameters = foo=1,bar=2,baz=3 under your original regexp would result in a hash entry 'parameters = foo=1,bar=2,baz' =&gt; 3, while with the added '?' the hash entry would be 'parameters' =&gt; 'foo=1,bar=2,baz=3' which is I think what you would want. edit: typo
Well done sir, the rest of the code is just setup and output display. I was needing to do something similar today and I would have been lazy and used a loop, where you used 1 line. This is why I love perl.
&gt; I feel like a god damned magician Yeah. Perl can have that effect :-)
On some platforms ;)
I think you mean thine (=your), not thou (=you). 
Should it not be `HTTP::Tiny-&gt;new-&gt;get()-&gt;{content}` ? Also the 2nd example wont print anything because it's inside double quotes and $ip is being expanded by the shell?
Thank you so much for bringing this up - I updated the article to include `-&gt;{content}` Re the quoting issue - I tested this on Windows cmd.exe and it worked fine. I'll test the one liner on Linux later today and update if necessary.
Or it could be blessed art thou, RegEx. :)
LiquidWeb.com
The Wunderground API is pretty sweet, and the WWW::Wunderground::API module makes it easy. I like it. 
Checking it out, thanks! 
Intercept the calls? You could do that with a proxy server? Get squid in between you and the http request and you can run arbitrary Perl code on the content. 
Just be aware that soap is done differently everywhere. I have found many cases where perl soap libraries were just slightly off and needed to do raw soap. Standards :(
You can use wireshark or tcpdump to capture the tcp stream then use "strings" on the pcap file to pull the text bits out of the session. Assuming of course that the interaction is done using plain old http. After you have the plain old xml it's just a matter of using lwp or maybe Mojo::UserAgent or something as the client. Or even XML::Compile::SOAP which seems to be the most complete implementation.
Does the S now stand for 'stupid'?
Emacs with Flycheck means I get 'perl -c' running in the background constantly, with red underlines on syntax errors. 
The obvious answer to not being able to get modules installed on a system-wide basis is to put them in your application's directory tree instead. That way you not only avoid the block, you also ensure that any non-standard moduses it needs are always distributed with it. Similar to the way I build any CPAN modules on my home Linux box into my home directory when I need them for a project rather than from the repositories. So if (more likely when) I change my distro, I don't have the worry of having to remember every module I've installed.
I've been using [Carton](https://github.com/perl-carton/carton) to great effect in these situations. I find it's much better to control the dependencies yourself on a project-by-project basis than relying on a big global install of every module for every project. It makes figuring out your actual dependencies on new projects very easy, too. I also quite like [plenv](https://github.com/tokuhirom/plenv). That even lets you do super easy local installs of different Perls. If your hosting company is stuck at 5.12 or something, then plenv could be your savior.
&gt; I don't see the same "no module" requirement nearly as often with other languages. This makes no sense. Perl is not making this requirement: the company is.
See also: http://shadow.cat/blog/matt-s-trout/but-i-cant-use-cpan/
There are always options. http://shadow.cat/blog/matt-s-trout/but-i-cant-use-cpan/
I don't use modules if I can help it. It's a hassle to distribute code to friends / co-workers. If there's a way to do it in vanilla perl, I'll go out of my way to figure it out, rather than rely on a third party.
What make you think it's a shortcoming of Perl? It isn't.
 Perl basically assumes you have sudo on the box. That's why it's a perl problem
&gt; Perl basically assumes you have sudo on the box. Not really. You can always install modules into your own user tree and use them from there. You don't *have* to install them into system directories.
I always install modules local to the user simply because I don't want to execute arbitrary code as root.
&gt; Perl basically assumes you have sudo on the box. That's true. With npm or bundler/gems, you don't have this problem. The default CPAN client really wants to manage a global installation of modules. People in the know tend to use perlbrew/cpanm/local::lib to get around this problem, but Perl's defaults are Perl's defaults, and that doesn't help people who aren't in the know.
5.14's cpan sets up local::lib by default (if you choose the "let cpan set things up for me" option when configuring cpan). We've had a few people in #perl wonder why they couldn't use the modules they installed. Either way, people get confused.
I *never* modify my system's perl install myself. I let my linux vendor's toolchain manage that.
Yes, I do this regularly. I never install CPAN modules into system directories.
So many problems when people start doing that without knowing what they're doing :(
This was on Godaddy's old shared hosting. They gave you ftp access to public_html, along with mysql access and other things, and that was it. No ssh access or anything.
If you can install a regular Perl script, you can also install the module code to the exact same place.
 do you have do sudo to do this? 
&gt; 5.14's cpan sets up local::lib by default In five to seven years, when Red Hat and CentOS make 5.14 available, that'll be great.
You have now. Hi!
I can speak only for myself, but I tried to install ANY neural network on WIndows 7 64 bit with the Perl (5.10) coming by default with the windows oracle database client. After installing visual studio to get nmake, rewriting a couple of files, finally installing strawberry because there was no chance to get any of the cpan neural networks running I gave up, because none of them compiled under my Windows. Long story short: it was a mess. Perhaps it was because Windows never was supported well by perl modules or at least in my case cpan gets more and more outdated. Background: I'm not an expert but an experienced perl programmer, but, because of sysadmins work, i have not very much know-how in installing modules especially not in windows.
My point is, don't downvote the "it's a Perl problem" guy into the oblivion. He has a certain point. Even python (which is nearly as bad as perl in the software distribution department) has moved toward sandboxed environments (`virtualenv`), replicable setups (`pip freeze`) and locally-installable single-file packages (`wheel`). Javascript hasn't got where it is in one day, just imagine what Perl performance might be if all the smart minds would work on JIT-compiling and similar stuff.
Perl6 is not that slow anymore. See these slides from Jonathan Worthington. http://www.jnthn.net/papers/2014-yapceu-performance.pdf (comparison graphs start at slide #79)
Sure, but CentOS 5 (which uses Perl 5.8.8) won't even hit EOL until 2017. I assume RHEL 5 is the same. http://wiki.centos.org/FAQ/General#head-fe8a0be91ee3e7dea812e8694491e1dde5b75e6d And you just know that plenty of companies won't even upgrade to CentOS/RHEL 6 until long after that happens, never mind 7.
I know. But is there any Linux distribution which will go to a newer major version of any core software package during the lifetime of a release? I don't think that problem is specific to either Perl or RHEL. If I'm wrong, I'd love to see examples. The answer is to leave the system Perl to the system and install your own version for your apps. Or, don't RH have a new system where they'll give you RPMs of newer software that gets installed into /opt?
If there is one, you're quite right - I wouldn't want to use it. There are rolling-release distros of course, but they're not going anywhere near my production servers! I'm a bit rusty on RH so am not sure about the new system you mention - there are of course other solutions like plenv and perlbrew, but they come with their own headaches.
Cpan is seen as amazing to experienced Perl developers. To newbs and people from other languages, its a problem. Cpan -i Moose doesn't work out of the box on Debian Stable. You have to pipe yes into it because it's so noisey and prompts for a million questions. Its shitty and broken and people resent the fact you already aptitude, a real stable repository. I know of cpan minus but others don't. The name cpan is dirt outside of the core perl community. It burns everyone by not working, printing hundreds of test failures suggesting the software you're installing is poor in-and-of-itself and that's why people don't want it. What's the point of a high level cross distro scripting language which is more frustrating to distribute than a shell script? Where's the jar file solution? Don't shoot the messenger... I'm just honestly telling you what peoples' perceptions are.
See [here](http://www.redhat.com/en/about/press-releases/red-hat-extends-red-hat-enterprise-linux-platform-with-latest-versions-of-popular-programming-languages-and-databases) for more details.
&gt; Cpan is seen as amazing to experienced Perl developers CPAN client is not equal to CPAN repository. CPAN client is long known to have problems. That's why we have cpanminus now. You're right of course. CPAN client is broken out of the box on Debian Stable - I just tested it. Even its upgrade process is broken, and that is really bad. The first and last thing I always install with CPAN is cpanminus, everything afterwards is installed with cpanminus. I think, in general, we just have to cross our fingers and hope that beginners will stumble upon cpaminus as early as possible :) 
Yes. Leave system Perl alone, install modules locally with local::lib.
I use Perl for everything and I'm also on Win 7, but installing other people's code on Windows is indeed an annoying problem. The problem, though, is not Perl, but authors who are not thinking about Windows compatibility when they release. I find similar problems with Ruby, Python, and even Java code, because authors expect *nix utilities to be available and don't deal with things like spaces in paths. I think that the Perl community might be more *nix-y than most.
&gt; I think, in general, we just have to cross our fingers and hope that beginners will stumble upon cpaminus as early as possible :) How's that misplaced optimism working out for you? :-/
Perl has similar tools to python, and people are using them, so why would it be worse than in python?
I have to sudo to update my Operating System using my linux vendors toolchain, yes. But I also never have to use `sudo` to install modules into my `~user/`'s perl. I hope that answers your question :)
It does still prove a problem as soon as you hit XS deps, and having to unpack and ship loads of files by hand is not ideal. But its still doable. ( I have also dealt with Godaddy hosting, even their SSH access doesn't work usefully because they have neither gcc or `make` available, which pretty much renders anything dead as a doornail )
Linux vendors like Debian and Redhat actually breaking Perl installations doesn't help :(. And understanding tests I guess is hard for novices. cpanminus has a `--notest` option, and disabling tests (and test dependencies) would make it easier for novices, but having tests off by default I consider a *bad* default. Perl has a very test oriented culture, and testing by default encourages this, and encourages contribution. Every test that fails is ground for a bug report(1), regardless how trivial the failure. Whether the solution be to patch the tests not to fail, or wether it is requiring a patch to the code itself, tests failing == something needs fixing. Test that fail for no valid reason simply encourage people disabling tests, which leads to them not observing tests failing for *valid* reasons when they arise. (1): ^(Most bugs can be reported via a bug tracker listed in the metadata of the distribution, or assuming the rt queue on rt.cpan.org for that distribution is valid. There are some exceptions to this rule with certain authors and there's presently no obvious way a novice will know about this. Solutions to this problem that don't entail coercing certain authors to be nicer, welcome :])
In support of this comment, I wanted to lay out some specifics for beginners: First, follow the instructions for **installing [plenv](https://github.com/tokuhirom/plenv)**. The best approach is the git approach. Don't forget the "plenv init" line. Also, do **install perl-build** as the instructions suggest. Now that you have plenv, **install a Perl**. Unless you're brave or really need bleeding-edge Perl, install the second most recent even-numbered Perl. You can get a list of Perls with "plenv install --list". At this time with Perl 5.21.* out, my advice would lead you to running "plenv install 5.18.3-RC1". Why? Full module support, dependent upon each module's author/community, tends to lag behind the bleeding edge; my advice leaves you with an environment that should feel stable. Now, **"plenv shell 5.18.3-RC1"** to stop using system Perl for now. Run **"plenv install-cpanm"**. This provides you the "cpanm" command, much better than the old cpan command. **"cpanm Carton"** installs the Carton framework, which allows you to specify dependencies on specific Perl modules and have them installed locally, much like how Maven works. If you want to package up your Perl code into large executables, I recommend also installing at this base level the convenient PAR Packager: "cpanm pp". Now, let's get to work. You've set up a git repo, right? At least a directory for your project? In that directory, **"plenv local 5.18.3-RC1"**. This creates a ".perl-version" file, which you will want to add to your repo. Any time you are in this directory, you will be using your locally-installed Perl. Outside of this current shell and directory, you will be using your system Perl. You can always check what you are using with "plenv version", and I like to use "perl -V" to be sure. Now set up the file for Carton. Suppose the only module you want to use is [Sub::PatMat](https://metacpan.org/pod/Sub::PatMat). **Create a file called "cpanfile"** that has this line: requires 'Sub::PatMat' =&gt; '0.01'; Always specify specific versions when you can. To install the module, just **run "carton"**. This will create a manifest file and a local/lib/perl5 directory. Now Carton has pretty much done everything you need it for. Maintain your Perl module requirements in the cpanfile, and rerun carton whenever you are updating those. During development, run scripts with "perl -I local/lib/perl5 -I lib". The Carton approach is "carton exec perl -I lib ...". Let's talk about packaging. One option is PAR Packager. It's easy: instead of calling "perl" to run your program, call "pp". "pp -I local/lib/perl5 -I lib --output my_standalone_program bin/myprogram"; this creates an executable in the current directory called "my_standalone_program". It will include the current Perl interpreter and all the dependent packages. Caveat: It assumes any shared libraries are similarly installed on target devices. Like every other language's *env approach, plenv/Carton/PAR ignores the rest of the realities of the state of the system. Another consideration of PAR: You may instead want to share modules across multiple scripts/programs. If you are deploying for a Debian target, you're probably better off just building appropriate deb files for installation. Nonetheless, with plenv, cpanm, Carton, and maybe pp, you have a full toolchain for working with any version of Perl with any custom package setup. Hope this helps someone.
Yep on Linux clusters it's easy to set up your own home directory for perl modules. export PERL5LIB=$HOME/perl/lib/perl5:$HOME/perl/share/perl5:$PERL5LIB before you run a code with a perl module. Works every time. [This website has a short guide on how to set up everything](https://surfsara.nl/systems/lisa/software/perl) 
&gt; CPAN client is broken out of the box on Debian Stable To reply to myself: everything works on slightly older Perl and slightly older Slackware machine, even the upgrade, so this might be Debian-specific.
As far as I know, Red Hat screwed up their version of Perl once. In 2007. I don't know the Debian story you're referring to. I'm not sure that repeating these stories seven years later is very helpful.
It hardly works. Here in Croatia, there are no Perl jobs at all, apart from some sysadmin stuff here and there. I'm probably working on my last Perl projects these days. The future here lays in Java/.NET ecosystems only.
I get holding back one stable release, but installing an RC? \* *loosens collar* \* Also, to the esteemed reader, once you get started developing with Carton, for deployment, "**carton bundle**" drops all the snapshotted module tarballs and a fat-packed carton script in **vendor/**, so Carton itself doesn't need to be installed as a dependency on the deployment system. Instead, from your project directory, run **vendor/bin/carton**.
Good tip on the Carton side. Any idea what this RC is about anyway? Normally I use 5.18.2, but this morning is the first I saw of the .3 update, and I didn't think we usually went back to earlier versions to update. (I can update my instructions if it is considered more stable to sit on a pre-RC version.)
Certainly better than P5 in the general sense anyway, exciting times
This is why when I write presentations about "How to do X in Perl", I try to start with "How to do X in Perl using only core modules". Barring that, "... only pure-Perl modules" so it can be Fatpacked.
&gt; exciting times I've been eating popcorn for 14 years already! 
can you elaborate more on the parsing bugs you've encountered? did you point them out on irc or send a quick mail to the rakudobug mail address?
Mojo::Log. Whether using Mojolicious or not, it gives you most of the power of Log4perl without the hassle.
I think it may be because you're declaring the array inside the sub procedure. The scope of that variable is limited to that block.
Note where you're defining @pez: sub action { push(my @pez, $input); So @pez shouldn't exist outside of sub action. Try turning that into my @pez; sub action { push(@pez, $input); and see if that works. 
That would work. I don't remember their shared hosting allowing you to override @INC though. I guess if you could, then yeah there's really no reason to not use modules.
Okay, I see it now. Thank you!
Now it won't let me enter more than one. I type a flavor, press enter, it prints an empty line, and then prints `The contents of @pez are ` 
That's simple.. local$,="\nYou added ";print"You added "and say@_; Then just set `@_` like this `@_=qw/foo bar baz/;` You added foo You added bar You added baz It's a popular perl idiom. Use `undef@_;` to clear out `@_;`
Never mind I forgot to add a semicolon after `my @pez`.
Your code is only accepting one input at a time. my @flavours; for(my $i = 0; $i le 10; $i++) { print "Enter a flavour, Enter after each one\n"; chomp(my $input = &lt;STDIN&gt;); push @flavours, $input; } foreach my $flavour (@flavours) { &amp;action($flavour); } and then in sub action: sub action { my $input = @_; ... }
The Digital Ocean API is pretty neat. I made a digital ocean dynamic DNS update script for my server on my home connection with it, https://github.com/chandwer/DigitalOcean-DDNS
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Comparison of open-source configuration management software**](https://en.wikipedia.org/wiki/Comparison%20of%20open-source%20configuration%20management%20software): [](#sfw) --- &gt; &gt;This is a comparison of notable [free](https://en.wikipedia.org/wiki/Free_software) and [open source](https://en.wikipedia.org/wiki/Open-source_software) [configuration management software](https://en.wikipedia.org/wiki/Software_configuration_management), suitable for tasks typically performed by a [system administrator](https://en.wikipedia.org/wiki/System_administrator). &gt; &gt; --- ^Interesting: [^Configuration ^management](https://en.wikipedia.org/wiki/Configuration_management) ^| [^Project ^management](https://en.wikipedia.org/wiki/Project_management) ^| [^CFEngine](https://en.wikipedia.org/wiki/CFEngine) ^| [^List ^of ^free ^and ^open-source ^software ^packages](https://en.wikipedia.org/wiki/List_of_free_and_open-source_software_packages) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ckr1e1m) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ckr1e1m)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
No need for `scalar`: `==` provides scalar context.
I prefer say "You added $_" foreach @_; 
 use strict; use warnings; use feature 'say'; my @pez; say "The \@pez is empty."; while (&lt;&gt;) { chomp; push @pez, $_; last if @pez == 10; } say "You added $_" for @pez; while (my $air = pop @pez) { say "You took off $air" }
Any ideas on how this compares to the very mature Ansible and Salt ?
Did you read the FAQ? [How can I hide the source for my Perl program?](http://perldoc.perl.org/perlfaq3.html#How-can-I-hide-the-source-for-my-Perl-program%3f)
I been playing with this all morning, and I have to say: "very cool stuff". Very easy to configure and powerful. Two of my favorite features. 
Has a nice website too, awesome!
http://www.rexify.org/
That looks pretty cool. Gonna download and play with it.
http://perlbrew.pl/Reinstall-All-Modules-On-New-Perl.html
Interesting. I still think I have access to a shared hosting account there, I'm going to try to get in and see if it works.
That's a non-standard tool that doesn't come with perl. In this area it's worse than Python that does come with `pip`.
It calls "/bin/sh". If this is provided by bash, yes. If you are in debian or other system where this isn't provided by bash, no. http://perldoc.perl.org/perlop.html#qx/STRING/
It depends. If it's a simple backtick/qr/system of a single command such as $now=`date` then perl just performs a clone/exec without bringing sh into the mix. Equally, $now=`date -u` is handled in the same way. However, if the command being evaluated includes shell metacharacters like $ then perl passes everything via sh -c. For linux systems where /bin/sh mainly (always?) symlinks to /bin/bash, you're now in trouble. Here's an example script with a safe and unsafe backtick: #!/usr/bin/perl $var=`/bin/echo bob`; $var=`/bin/echo \$myvar`; And here's strace proving where sh comes in: strace -f ./tester.pl 2&gt;&amp;1|grep echo ioctl(0, SNDCTL_TMR_TIMEBASE or TCGETS, {B38400 opost isig icanon echo ...}) = 0 [pid 13597] execve("/bin/echo", ["/bin/echo", "bob"], [/* 18 vars */] &lt;unfinished ...&gt; [pid 13598] execve("/bin/sh", ["sh", "-c", "/bin/echo $myvar"], [/* 18 vars */]) = 0 [pid 13598] execve("/bin/echo", ["/bin/echo"], [/* 17 vars */]) = 0 And given we're on centos in this exmaple, sh is really bash: $ ls -l /bin/sh lrwxrwxrwx. 1 root root 4 Sep 23 21:01 /bin/sh -&gt; bash (edit for more examples...) Thinking more broadly in perl you have to look for any place where you're asking perl to evaluate something with shell metacharacters. The following deliberately bad code is vulnerable as perl will ask sh -c to evaluate the $myconfigfile line: open(RES,"grep something \$myconfigfile|") or die; 
On Debian-based systems, `/bin/sh` is usually `dash`.
Had to come up with the right context... the issue is with the shell loading in the subprocess: $ cat poc.pl #!/usr/bin/env perl use strict; use warnings FATAL =&gt; 'all'; $ENV{x} = '() { :;}; echo vulnerable'; system("echo test one"); system("perl -e 'system(\"echo test two\")'"); $ perl poc.pl test one vulnerable test two 
Is this just an alternate perl distribution with some extra CPAN modules installed?
Yes.
when bash is invoked as /bin/sh, it switches to posix compliance mode. Not sure that matters much here, the bug might be a systemic bash'ism even in compliance mode. Worth verifying though 
Oh man SOAP... prepare to have a bad time.
Even if you can't override @INC, as long as you can place files IN @INC you can do it. And if you can't place files in @INC, you can't use `.pm` files at all. Yes, its ugly having `./lib` being a mosh of 3rd party code and your own. But thats **STILL** superior to writing everything yourself from scratch and wrongly.
Shouldn't it just install Template when you do perldoc Template and it's not installed? It's not doing what I mean. Also, there's no explanation of what it adds to Perl unless I somehow glossed over it.
I am not sure about autoinstalling a module, but it could certainly give a better result. (eg. opening the browser to MetaCPAN, or telling you how you can install it) For this version the list of addition can bee seen in the cpanfile linked from the first paragraph. Future versions will probably have a list directly on the web site. Please open an issue here: https://github.com/dwimperl/dwimperl-linux/
Look at https://metacpan.org/pod/Expect for Linux/Unix/OSX
will this allow me to take all the output as an array the way i was able to with a backtick?
If you open a filehandle `$fh`, then you can slurp the input into an array using my @array = &lt;$fh&gt;; However, if you are going to interact with the program, you may not want to do that, since your program will block until the external program ends (technically, until the filehandle returns EOF.) If the external program is waiting for user input, this means you will block forever.
 use strict; use warnings; use autoeverything; do_my_homework;
...I'm 37. :P
Don't worry. I won't hold it against you.
IO::Prompt, Term::ReadKey, Term::ReadLine
The correct answer is "doesn't matter, patch bash ASAP." It's an easy fix assuming your distro has released an update.
Except the updates [aren't all complete](https://access.redhat.com/articles/1200223) yet.... :(
You're apparently not familiar with the concept of shell injection exploits. A shell will always execute commands. That's what it's for. This isn't something that can be fixed without ruining the shell. This is a problem though when user input to a program (like a web app) makes it all of the way to the shell where it is interpreted by the shell. Obviously, input from random web users should not be going to the local command shell. system(), open() and other calls in Perl are available in "one argument version" and "three argument versions". That's a simplification, but this for example bypasses shell and runs the program directly: system '/bin/ls', '-la'; Or more in general: system '/bin/ls', @user_supplied_args; Even then, it's a really good idea to do validation on the user supplied args and make sure that they contain reasonable values. Bypassing shell is precisely what you need to do. For backticks where you capture the output, use IPC::Open2 or IPC::Open3 instead. perldoc them for examples. There are probably some Tiny:: or Simple:: modules that do the same thing now and are easier to use with less crufty documentation.
Perl's system command does some extra checks on the command to see if it needs to use bash. If it has some sort of extra characters or unusual format, it will fire up a shell. Otherwise, I think it just try to run the command directly to save on fork overhead.
Half fixed is better than nothing. Besides, most black-hatters will be trying the first exploit.
I'm glad you think you're a genius, however, people should still be *patching their shit* instead of watching you show us all how smart you think you are. Jesus I hate this industry sometimes.
You should still update... some protection is better than none. It takes a minute or two tops.
Two/three arg open isn't genius. It's strongly recommended for all uses, and the single arg flavors are there for one-liners and back compat. Anyway, I came back to apologize to you because I just saw http://seclists.org/oss-sec/2014/q3/656. I haven't read enough to understand what they're talking about, but I first commented here, I wasn't aware that there was a CVE. They might just be talking about what I'm talking about. You're welcome to yell at me if it makes you feel better, but in general, please try to be patient with people who make time to try to help other people with code. We sometimes make mistakes and misunderstand questions, but we're still volunteering time to try to help save other people from frustration. Thank you.
Since you seem to be a reasonable human being, sorry for yelling at you. I've spent half my day patching servers that I'm not technically responsible for because other people have decided to have 'technical analysis meetings' to 'assess threat' rather than, you know, installing the f---ing patch... meanwhile if someone gets into our system that doesn't belong there, I'm going to be the one they wake up in the middle of the night. So I'm a little testy. Edit: and yes, technically speaking, from a security standpoint you should use the form that doesn't invoke the shell. Very few people obey that, though.
This is very good advice. I come down very hard on devs in my team using backticks or single arg system calls, if they are unnecessary (and they generally are). This exploit is only way that inappropriate use of the shell is dangerous from perl (and other languages). system ("grep $somepattern $somedir &gt; /tmp/results"); Is tremendously convenient. But where does $somepattern and $somedir come from? Are they from the user? Might one of them be "blah ; rm -rf /"? When you invoke the shell you startup a massive piece of software, with huge amounts of functionality. Do you know all of it? Do you know how to properly escape the above so it doesn't get executed by the shell? Do you understand the implications of unicode input data? Do you even know what shell the user might be using? No, you don't. If you see someone escaping tainted data to pass to the shell you should immediately see that as a massive defect and a security hole waiting to happen - because it is. On top of that, do you know your environment? Do you know your users environment? Do you know what happens if they have a different PATH? A different IFS? Can you control that? The reason why people use the shell when they don't need to is for IO redirection - and that's when you use IPC::Open* as /u/scrottie says. Learn them, they aren't optional - if you actually care about your code being secure. None of these have anything to do with the recent bash exploit. Using the shell unnecessarily has always been a source of problems. Obviously though, if you never use the shell from perl, you don't need to worry about the state of bash exploits :-) 
I did say sorry about the old woman but from behind you looked ... 
For the very basics, since you already know at least one other language, try "man perlintro" from the UNIX command line. You also want [Modern Perl](http://onyxneon.com/books/modern_perl/). You can pay $37 for the paper edition and/or download the free PDF. 
I still haven't found a good technical description of the exploit in question. Have a reference for me? Edit: I was off base when I posted then. I thought the question was about the general case of shell injection vulnerabilities. I only read something vague about the environment factoring in after I posted that. Update: https://www.us-cert.gov/ncas/current-activity/2014/09/24/Bourne-Again-Shell-Bash-Remote-Code-Execution-Vulnerability http://www.kb.cert.org/vuls/id/252743
Original poster was referring to this: https://www.us-cert.gov/ncas/current-activity/2014/09/24/Bourne-Again-Shell-Bash-Remote-Code-Execution-Vulnerability http://www.kb.cert.org/vuls/id/252743 I missed that when responding initially. I hadn't seen this bit of news yet. Short answer, yes.
Learn Perl the Hard Way http://www.greenteapress.com/perl/perl.pdf
Duh. They should assess the threat and plan the response to being completely fucking vulnerable before it happens. So that's how I found out that I'm spending the night fixing code. Wheee! chmod ugo-rx `ack -l system`;killall -HUP starman First line of defense. Usually I see something on front page here or my Twitter feed or something. Usually I don't stumble in to a question like "Are Perl backticks or the `system` command vulnerable to the BASH environment variable execution vulnerability?" with no references. &gt; https://www.us-cert.gov/ncas/current-activity/2014/09/24/Bourne-Again-Shell-Bash-Remote-Code-Execution-Vulnerability &gt; &gt; http://www.kb.cert.org/vuls/id/252743 
While this is enough to get something functional, the above document is _full_ of errors. I suppose for a "zomg I need to learn enough to make this thing _right now_!" task, this is fine. If it's the sort of task where you're going to be working with Perl for more than 3 hours, .. ugh.
"Learning Perl" by O'Reilly is the book you want.
The answer is in the question (*Learning Perl* is the best book to learn Perl).
"Learning Perl" or "Beginning Perl" are the best books to start with (but make sure you get recent editions) and "Modern Perl" is a great next step. Online, you can look at http://learn.perl.org/ for pointers to resources. And the [Perl tutorial hub](http://perl-tutorial.org) rates many tutorial sites.
Ironically, the O'Reilly book with the same name as your post is one of the best ways to start. Although if you are comfortable with basic programming concepts, you can probably jump to Programming Perl.
Perl Maven is a great place to start
I bought "Learning Perl" and "Intermediate Perl" from O'Reilly and learned enough to be productive.
That article is spectacularly well written.
&gt;Although CGI was popular back in the day, all the modern Perl web frameworks use FastCGI and are immune to Shellshock. Modern web servers do not enable CGI by default and some like nginx do not even ship with CGI capability. What extra-dimensional fairy tale planet is this guy from? Old skool CGI is *everywhere*. 
At first glance: Yes. Looking at the details though: No. Massive errors. Checking $SHELL will not tell you if you are vulnerable (as that's just the current login shell of your account). /bin/sh is not "a symlink to the default shell binary". Edit: ok, another error that could be easily avoided by RTFmanpage instead of guessing: .bashrc is *not* read when it's started from perl -- the only reason why his example works is most likely that he has started a new terminal (thus starting an "interactive" bash, which reads .bashrc) after editing the file. But his Perl is flawless (apart from "but I could have done that regexp with 1 character less!" ;)
but it shouldn't be. when I got into Linux 6-8 years ago, CGI was already considered to be an antiquated (and often insecure) method of running web applications. for a newbie, it was also significantly harder to set up CGI than mod_{perl,python,php}. I have a hard time feeling sorry for people that haven't upgraded their software stack in a decade.
Forgive my bash ignorance but should there be a \s* between the } and the ;?
yeah, likely; and it might have false-positive problems. If your system actually uses the 'pass a function declaration and definition as environment variables', it could strip out legitimate functions/variables; for example: beltorak @ kryos [~] $ z () { run_program &amp;&amp; { echo 'Completed'; }; unset z; } beltorak @ kryos [~] $ export -f z beltorak @ kryos [~] $ bash -c 'env | sed -n -e "/^z=/,$ p"' z=() { run_program &amp;&amp; { echo 'Completed' }; unset z } Let alone any variables that just happen to contain `}\s*;`, such as (granted I am just making this up) `SPECIAL_CHARS='+-_=()[]{};:#@!``....
load module, set file handler (which is almost always done by default), your code runs now.
vs. put in cgi-bin, your code runs now...
3000 out of how many? Wanna bet most of those 3000 will still be vulnerable months from now because they're forgotten and unmaintained? Almost all of the articles I've read neglect to mention that to make the bug exploitable you also need some horrific and obsolete coding practices in your Internet-facing applications, and this created a pretty panicky readership.
Thanks for the feedback
&gt;Don't downplay the severity of this bug It's going to be really interesting to see how this plays out. The perfect storm of conditions required to make the (currently known) attack vector work, in my opinion makes it unlikely to cause much heartbleed (haha). Two other angles seem like possibilities: exploits via non-cgi routes and hardware devices. For non-cgi routes, if someone could find a way to pass environment variables to a host via another commonly installed program (e.g. telnet) then it could be a much bigger issue. One [claim](http://blog.erratasec.com/2014/09/bash-bug-as-big-as-heartbleed.html) that's being repeated in the media is that the real risk is in hardware devices - but they always say this and it doesn't seem to ever play out. It's a hard claim to prove / disprove. Either way it's going to be interesting :) 
It looks great !! I am totally trying that this afternoon, thanks for suggesting me an other framework. Best case it works, Worst case I learned something new :D
I can't believe I started watching the video, despite the text instructions being clear enough. Tip: If you use Firefox, you can search directly on MetaCpan using an open/quick search for it.
IMHO, Perl was used for CGI because in the beginning it was done by sysadmins. Now that webdesigners and webmasters are two separate roles, sysadmins will continue to use perl and the designers will move on. I don't see any problem. 
That sounds fantastic. Do you have any recommendations for exercises? I will be at the Nike Dev Ops team, so I'll be working with Perl/JBoss/Tomcat/Puppet 
Same shit, different day. All the navel gazing and self loathing on this sub is just unbearable. Let me tell you a little secret: Perl is just one of many programming languages. If you find yourself wishing perl had all of the features of Python, then maybe you should just code in Python. If you like what perl does well (and there is quite a bit that it does well), then continue to use perl. Wishing that the next perl release is going to change all arrays to array references and break decades of legacy code just so that you can use them like you do in other programming languages is a complete waste of time.
I've been looking for work in San Francisco for the last several weeks. I've gotten a definite impression that describing Perl as my strongest language, or speaking of it in positive terms, has been a significant factor in getting turned down at several places. Also, it's beyond depressing that searching on "san francisco" on jobs.perl.org turns up only five job postings, at just two distinct companies, one of which is actually located twenty-five miles away.
Just pick up a book on programming Perl or some guide online and work through them. Infact, to an extent you could just use exercises from a non-perl source as well for extra challenge :P. For the other tools, I'm not familiar with them beyond puppet but I'd bet there are a lot of resources just a search away.
IMO no one should read Programming Perl as a beginning Perl book. I think it is more a "I'm really interested in Perl so I'll read this" kind of deal since we have much better alternatives for introductory stuff.
I just skimmed through and nothing terribly wrong popped out at me. Care to help me see what I missed? Aside from the errors it seems like one of the best practically orientated primers I've seen in a while.
OK, if that stops you as a programmer.... good luck!
Horses for courses, then?
OK, I'll risk lookimg stupid an ask the question... MetaCPAN??? What's that?
&gt; Same shit, different day. All the navel gazing and self loathing on this sub is just unbearable. It's a general Perl thing. Half the stuff written about Perl by the Perl community seems to be how it's not really a dead/dying language and here's how we can save it.
There's no way to fix it anymore from this file. All of the question marks in it are ascii 3F. There's no data left to convert it back to chinese writing. Which program did you use? If it's office, there may be some autosaves lying around. If not, then you could try to undelete a previous copy.
They are mad if they use python, it is so high maintenance. You write something, than comes a new python version, and everything stops working. For a developer, that can be fine, but I don't think a sysadmin would put up with that.
Can we please rename "Perl 6" to "Butterfly" or whatever and get on with calling Perl 5.22, Perl 7... for all our sanity and our livelihoods? Please?
&gt; significant factor in getting turned down at several places. That's rather strange. There are a lot of Perl shops in SF. And if you are getting turned down by some punks because you know something well — you ~~probably~~ don't want to do business with them to begin with, they are doing you a favor and saving you time, effort, and hours of anguish (by removing themselves from the equation).
Perl was used because of the lack of alternatives "in the beginning" and the lack of libraries in C++.
For webdesign, maybe. For system administration, no.
That is how I learned...but, that was 15 years ago, and your choices were pretty much Llama or Camel back then. Unless you wanted to get mislead with the terrible SAMS or Learn X in 30 days books.
When working on documents like these, be sure to use a UTF-8 capable editor like Notepad++ You stripped out your encoding.
For perhaps the most unambiguous example, one company asked me to complete [this](http://www.thumbtack.com/challenges/software-engineer#simple-db) coding challenge, a simple in-memory transactional database, in any high-level language. I used Perl. I got turned down in an e-mail that also included some criticisms of my code that didn't remotely apply. I replied, suggesting that my submission must have gotten mixed up with someone else's (yeah, right), and briefly refuted the criticisms with references to particular lines of code. The final response was something like "We've double-checked the submission and still feel the position isn't the strongest match right now." Argh.
Don't use CSV. There is no way to specify the encoding, short of putting a BOM in the file, which might not be interpreted correctly by non-Excel readers.
In keeping with the Perl theme, Nacre.
A web site to interact with the content of CPAN. Search for modules read documentation etc.
I know that can be the case between 2 and 3 but it is really true in the general case?
You dodged a bullet (speaking from my own very lengthy experience). ^(PS-ish thingy: And don't even start me on "coding challenges" — utter waste of time only demonstrating how inadequate a given employer's hiring practices are. These approaches only breed mediocrity and usually these places are to be avoided like plague, unless, of course, you enjoy this kinda thing.)
Since PHP.
There are so many programming languages, but the reactions on criticism is the same across the languages. Not very long ago i read a delphi board. - Does Delphi have regular expressions (it didn't that time)? And the reactions were, that obviously nobody needs that unreadable shit. - Does Delphi have support for evaluationg code? No, it is completely nonsense for a compiled language to support this. - and so on And you could go on with every language you want. You just have to read some boards. So my conlusion is: What ever a language does not support must be shit. What people observe that is better solved in other languages: Shit. Anything that is not praising the language. Shit. And if you have the feeling there are a couple of people who thing the same: Same shit.
Same reactions in Germany: I really was asked if I know what OO is. (after mentioning Perl as my favourite language) I would have preferred to ask how they do roles and traits in their c# world but I left it.
Fuck me. Even when we've got a CMS in place, the marketing jackasses still can't figure that shit out. The techs have to copy/paste their marketing spiele into the CMS-generated pages... On a different note, as it was high time I got to grips with this Ruby stuff (because it's like Perl 6 or something), I'm grinding through the Hartl "Ruby on Rails Tutorial" right now. It's pretty good, but my eyes keep glazing over. Regardless, I don't see any way that regular jackoffs would ever get their heads around designing layouts and shit in ERB, HAML, or anything else like that. That stuff's all too "techy" and needs to be given to the "web people team-type dudes" to figure out. The more I look at it, the more I can see that Perl is Ruby's *Spiritual Liege*. 
&gt; That stuff's all too "techy" and needs to be given to the "web people team-type dudes" to figure out. Sure, those kind of techy people are better described as web *developers* rather than web *designers*. But that's not to say that web designers (who are more artist than programmer) don't also write simple PHP code to add functionality to their web sites. PHP made that possible because, from the web designers' limited perspective, PHP was just another kind of HTML tag that made magic stuff happen. The difference between server-side PHP and client-side JS is largely immaterial if all you're trying to do is display the current time and date (I'm not saying that's necessarily correct, but rather how they might perceive it). Perl, Python, Ruby, etc., are all "foreign languages" to most web designers, not because they don't understand the syntax (or couldn't learn it) but because they exist in a different paradigm as far as they're concerned. They don't do command lines or know how to configure Apache/mod_perl. But they do know how to write web pages. PHP made it possible for them to start "doing programming" without first having to learn a new modus operandi. They just put the code straight into their web pages and it Just Worked™. So that's the longer answer to the question: &gt; Since when do "web designers" write code? The answer is "Since PHP made it easy for them to do so". 
Yup, you're right. Was just having a little bit of an episode. Our marketing twats talk about the ivory tower of CMSes and whatnot, but then find it's too complicated for them to actually learn how to use. Even though it's all pointy-clicky. The trouble is, we're fucked now. It takes 10 times as long hacking something something decent together in the bastardised GUI thing than it does knocking up a fragment of HTML (not even anything PHP-like either...). All the day-to-day copywriting was supposed to be handled by the marketing muppets directly, instead of going through the "nerds". The nerds could be doing something more productive.
I looked for a FF extension to do this automatically but no dice. I was thinking I should learn how to write an extension for this :P
Yeah, and what fun that was (and still could be)... I still have nightmares back from early 90s. 
I can see a strawman rising here... There I'll recluse myself from commenting further itt. :)
Happy cake day, Dav.
Not really, why would they?
You can use a [generic redirector extension](http://perlhacks.com/2013/01/give-me-metacpan/). Or, add it to your quick search list and go there directly.
Ugh, not this "devops in the cloud" crap again. The tool looks interesting though.
I would love to see some PR campaign similar to the "Nope, Chuck Testa" meme. Describe all these wonderful language features and then ask the question: "Must be language X right? Nope! Perl."
Thanks for the suggestion, I think I'll do that :)
Good to know
I'm a bit of a bum and use `use experimental 'postderef';` regularly.
Yes, programming Perl is really good holiday reading for a Perl enthusiast. 
It sounds like you just need a simple way to tack a little metadata on a frame? One of the simplest things to do would be to crib the header/body style of http and rfc2822 mail -- stop reading headers when you hit the first \n\n, no body decoding necessary if your channel is 8-bit safe. Header: value Blah: foo &lt;binary data until the end of the frame&gt; I'm not entirely certain I've understood your description or architecture from the post above, though.
Maybe I'm in the minority but I don't really like this.
Perl's marking problem can be solved by TimToady retconning the version numbers like what was done with the advertising Juggernaut Java. 
Red Hat is currently on a python binge, so they will do most of the maintenance for you.
Why threads rather than forks?
I don't think so. Right now it is prime time to rob Rust of its time to shine.
I should note, I am actually having no problems adding the seconds together to come up with my aggregate total. It is converting them to the mm:ss format that's giving me problems. I've been trying to figure out time::piece with no luck. I even cobbled together a rough solution just using the division and modulous operators but it's not working quite right and it just seems like an ugly way to do something that must have an easier solution.
Not so long ago they introduced helper functions in Delphi. Instead of typing IntToStr(myInt) you type myInt.ToString(); At first I thought - hmm - it really does not matter in which way you type it, but I noticed that the second solution is the direction you type your code. You do not have to jump to the front, set appropriate brackets, jump back again and continue typing. I never used the first solution again. Imaginge a much longer call and you will end up searching the point to set your @{ When using -&gt;@* you can just continue typing.
I'm a fan of this notation. 
I'll check them out. Thanks!
You mean the language that we showcased in the last YAPC? That language? Yeah, we are totally robbing Rust of its publicity right now.
&gt; @{ $arrayref } Well, that's more neatly written as @$arrayref, but the old style really gets ugly when it comes to dereferencing a ref returned by a sub/method call. @{$self-&gt;books()}; vs $self-&gt;books()-&gt;@*; I'm still not convinced which is less noisy, but the latter is certainly less clumsy. It'll be interested to see what we think after we have gotten more used to it.
Both threads and forks have their advantages. Threads: * lighter * easier commiuncation between several threads * more portable (there are no forks on windows) Forks: * safer, better encapsulation. 
What do you want to happen if quantities of seconds produce hours? You could use division and modulo but it wouldn't handle the case of when your quantities produce hours. $ perl -E 'my $duration = sprintf "%d:%02d", (90 + 103) / 60, (90 + 103) % 60; say $duration' 3:13 **Time::Seconds** has a **pretty()** method: $ perl -MTime::Seconds -E 'say Time::Seconds-&gt;new(90 + 103)-&gt;pretty' 3 minutes, 13 seconds I suppose you could parse it out from that, but it would depend on what you want to happen if it's possible the quantities could produce hours/days/etc. my $duration = sprintf "%d:%02d", Time::Seconds-&gt;new(90 + 103)-&gt;pretty =~ /(?:(\d+) minutes, )?(\d+) seconds/ 
Yeah, and there is no equivalent perldoc perllocal to see what modules were manually installed.
Hmm. While I generally prefer postfix syntax for stuff like this, that's feels like it's just replacing one ugly, hard-to-grok syntax with another ugly, hard-to-grok syntax. Except that the new one is longer. And (depending how you feel about asterisks), more line-noisy.
Thank you for the tips and examples. Apparently there is a whole realm of time related modules I'm unaware of like Time::Seconds. The current numbers I'm totaling shouldn't reach up to hours but what would you suggest when they do? I'm sure somewhere along the way where I might want a total elapsed time.
Yeah Time::Seconds is mentioned somewhere in Time::Piece docs. Well it all depends on how you want it formatted. Do you always want HH:MM::SS or should it only output as much as needed, i.e. if there are no hours just output MM:SS, if there are no minutes output just SS? If the total sum was 59 seconds should the output be 00:00:59? Also you say MM:SS but then say it should display 3:13. MM:SS would be 03:13, do you not want the leading zeroes? 
I love this syntax (fewer curlies!) can't wait for it to move out of experimental status ...
~~Can you predetermine the size of the blob? You could implement a simple protocol with a content-length header, the blob, and maybe a known terminator sequence to be extra safe at the end of the blob. Something like:~~ ~~Content-Length: 16802~~ ~~Terminator: 0001020100~~ ~~&lt;16802 bytes of data&gt;~~ ~~&lt;0x00 0x01 0x02 0x01 0x00&gt;~~ **EDIT**: Ignore all of that, I misunderstood the problem. What you really need is an ID tagging system for the data blobs. Still a protocol issue, but instead requires a bit of client-server negotiation. When the client wants to send a blob, it should first ask the server for an ID number. The server manages these unique IDs and holds them in a database with meta information about the blob's permissions. The client should then send the data frame, with the first *n* bytes being the agreed upon ID, followed by the data. The size of your ID should be known or null-terminated.
I wish they've fixed given/when instead... 
It's a trivial matter to create the k-mers, but to do anything substantial you'll need an index. Look at http://www.genometools.org/tools/gt_tallymer_mkindex.html.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Base 64**](https://en.wikipedia.org/wiki/Base%2064): [](#sfw) --- &gt; &gt;__Base64__ is a group of similar [binary-to-text encoding](https://en.wikipedia.org/wiki/Binary-to-text_encoding) schemes that represent [binary data](https://en.wikipedia.org/wiki/Binary_data) in an [ASCII](https://en.wikipedia.org/wiki/ASCII) string format by translating it into a [radix](https://en.wikipedia.org/wiki/Radix)-64 representation. The term *Base64* originates from a specific [MIME content transfer encoding](https://en.wikipedia.org/wiki/MIME#Content-Transfer-Encoding). &gt;Base64 encoding schemes are commonly used when there is a need to encode binary data that needs to be stored and transferred over media that are designed to deal with textual data. This is to ensure that the data remains intact without modification during transport. Base64 is commonly used in a number of applications including [email](https://en.wikipedia.org/wiki/Email) via [MIME](https://en.wikipedia.org/wiki/MIME), and storing complex data in [XML](https://en.wikipedia.org/wiki/XML). &gt; --- ^Interesting: [^Base64](https://en.wikipedia.org/wiki/Base64) ^| [^AMD ^Phenom](https://en.wikipedia.org/wiki/AMD_Phenom) ^| [^PD ^Ultraman ^Battle ^Collection ^64](https://en.wikipedia.org/wiki/PD_Ultraman_Battle_Collection_64) ^| [^C*Base](https://en.wikipedia.org/wiki/C*Base) ^| [^PowerPC ^e5500](https://en.wikipedia.org/wiki/PowerPC_e5500) ^Parent ^commenter ^can [^toggle ^NSFW](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+ckx3xdt) ^or[](#or) [^delete](http://www.np.reddit.com/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+ckx3xdt)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
The only way to fix taint is to kick its balls and throw it down the well.
Ugh, this is gonna be another smart match fiasco.
But that way I'd still need to encode the data in base64 or whatever, right?
I like that idea. The question is how to make sure that the following data frames (after the one with the agreed size) really belong to the same client? WS is async, so there might be the scenario where two or more clients would send binary data to the BE. Or did you mean to send a specific (negotiated) size for every single slice of the data?
Mostly PDFs and images, but the PDFs can be up to 50MB (maybe more). I like the idea of using another channel. I'd need to open a second websocket for that, right?
Anyone who's going, please ask if he can get a nice fixed version of http://dheeb.files.wordpress.com/2011/07/gbu.pdf available to the public again.
This looks good, but I'm struggling to get Rex to use my Perlbrew perl instead of the system perl. My user sets all this up in .bashrc but it seems to get ignored
That's a good chunk of change. Good for them.
This is amazing, lets keep showing the world that perl is relevant :)
Yo, man, Ruby on Rails is a ghetto.
Yeah, but the marketing people get all steamy just thinking about it. Seriously though, I'm working through this bloody Hartl book. I'm so close, I can bloody taste the leads coming in from my new site; but then the vital revelation is not revealed until the next chapter. I'm trying to resist the urge to bail out, use Perl and just get shit done. I *need* to diversify. 
The source code looks state of the art... for Perl 4. Let's take a look: * Calling subroutines using '&amp;' * Large number of package variables (defined with 'use vars') * Using libraries ('require "somefile.p'") instead of modules ('use SomeFile') * Variables scoped with 'local' rather than 'my' I think I'll pass, thanks.
This is all kinds of nope.
This is unfortunate.
You have to provide information regarding the operating system you're using and what you exactly installed. Also, you can't "figure out" a programming language; you have to study hard and long. I can highly recommend "Learning Perl" (the book). Yes, a book as most online resources to learn Perl are mediocre at best. Moreover, personally I prefer to read a book on programming mostly away from the computer and that's easier to do with a printed book. The reason for this is that I want to avoid copy paste programming (aka Cargo Cult programming). Once I get a chapter, I do the exercises if possible on paper, and then verify it behind a computer.
Be aware that even if *you* haven't managed to work Perl out, there may be programs on your machine that need it. So if you remove it, you may break them.
Appropriate username. 
The excellent "Modern Perl" is available online, for free ... http://onyxneon.com/books/modern_perl/ , but once you get into it you'll want a paper copy. What percentage of your storage space is Perl taking up? How much do you have left? I rarely delete software i install... you might want it someday. If you didn't install it, some other system may be using it ( definitely true on many Linux, MacOS ). In fact, standard programs shouldn't even be updated. Leave the system Perl / Python / Ruby the way it is, and install a more modern version elsewhere,where you can get at it, but leave the old one for the system utilities to use. It's so cheap to install a larger hard drive ... 1 TB, 4TB, even 6 TB, why worry about 1% of 1% of that space?
Why bother to remove it? It's taking about as much room on your system as a five-minute video.
what about perl do you find difficult. I honestly think it's a great language to start with. 
I had been reading about it for a while, it's just not my thing
It doesn't do anything if you don't use it for anything. So why bother removing it? As for how to remove it. Use whatever facility you used to install it.
I'm sorry you feel this way; I don't know very much about Croatia so I am not really qualified to comment but I have an acquaintance who _told_ me ( emphasis, she _told_ me, I don't know... ) that she is Croatian but I'm not sure whether or not to believe her as she has been rather less than forthcoming in the past. In any case, she is very nice &amp; I was thinking about spending some time talking to her &amp; maybe learning more about Croatia. I am a Midwest American who does some Perl, PHP, &amp; sqlite3 development, mostly for small, insignificant projects but I was thinking of trying to find new ones. It makes me sad to think Perl is not prospering in Croatia. I wonder how it is doing in Eastern Europe as a whole.
That ... elegance! /s
[Fey](https://metacpan.org/pod/Fey)?
I'm sad that this module never got any traction. I thought it was pretty good, and much better than the API insanity that is SQL::Abstract.
Everything about how where clauses are specified is pretty nuts. SQL::Abstract makes completely arbitrary associations between Perl data structures and the resulting SQL. One small examples: my %where = ( user =&gt; 'nwiger', status =&gt; { '!=', 'completed' } ); This produces the SQL `WHERE user = ? AND status != ?`. Why a hashref on the right side? Well, it's because the arrayref was already used, of course. Here's another fun one: priority =&gt; [ -and =&gt; { '!=', 2 }, { '!=', 1 } ] To produce `priority != 2 AND priority != 1`. This is all quite complicated and fairly arbitrary. It's not driven by any sort of clear design other than "we have to jam all possible SQL queries into a few data structures". SQL::Composer doesn't seem much better in this regard. 
&gt; This is all quite complicated and fairly arbitrary. Arbitrary yes, but quite cleanly documented and not at all complicated. [The documentation says](https://metacpan.org/pod/SQL::Abstract#WHERE-CLAUSES): "The main logic of this module is that things in arrays are OR'ed, and things in hashes are AND'ed." 
The devil is in all the details, for example what types of things can go in hash keys or the way that and/or conjunctions are handled. I think Fey's approach of using methods or literals that match SQL (`$select-&gt;where( '(' ); $select-&gt;where( $col, '=', 42 ); $select-&gt;where( ')'); `) for much of this stuff is a lot clearer.
I agree with you; this is wholly unnecessary and more confusing.
nice. seems like it would be fitting in /r/sysadmin as well. 
&gt; if your upstream release vendor is not producing security fixes in a timely manor, the fix isnt to deploy a development tool chain to production servers; its to find a different upstream OS vender. Unless you're stuck supporting legacy systems. 
It would be totally awesome if every company that made a bundle on Perl would consider tossing some thank you cash at the organization.
"New Class of Vulnerability in Perl Web Applications" is a bit of a misnomer. This "bug" has existed for as long as CGI.pm has been around, and the behavior is documented to work that way. Just because you, or the authors of your favorite application, wrote something without considering the implications of their design decisions, doesn't make a "new" class of bugs. The author just figured out what many of us already know - don't do that. Lazy programmers mixed with lazy "journalism" leads to a big yawn.
The class of bugs (and I say class, because, as he demonstrated, any function that returns a context-sensitive value could produce a bug like this) is new *to that developer*. Yes, many of us know about this problem, but many developers have not. Is it wrong for him to spread the news? If you've already seen it, then move on and forget about it. But for the rest of us who haven't, [don't ruin the fun](http://xkcd.com/1053/).
[Image](http://imgs.xkcd.com/comics/ten_thousand.png) **Title:** Ten Thousand **Title-text:** Saying 'what kind of an idiot doesn't know about the Yellowstone supervolcano' is so much more boring than telling someone about the Yellowstone supervolcano for the first time. [Comic Explanation](http://www.explainxkcd.com/wiki/index.php?title=1053#Explanation) **Stats:** This comic has been referenced 2220 times, representing 6.1544% of referenced xkcds. --- ^[xkcd.com](http://www.xkcd.com) ^| ^[xkcd sub](http://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](http://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](http://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_cl2bw1i)
Point taken. I just wish people would shy away from such inflamatory tones. To put it another way, I wish some things (the experience to check the lay of the land before you screech about falling skies) didn't have to be relearned over and over. "I already learned it, dammit, why do those who come after me have to learn it too?!" /rant Some things are better learned over and over, because learning can be fun. But some things... &lt;sigh&gt;
That still doesn't make it "new".
Yes it does: &gt; The class of bugs ... is new *to that developer*. Just because it's not "new" to *everybody* doesn't mean it can't be called "new".
&gt;It's misleading to claim that blindly trusting unvetted user input is a "new class of vulnerability". We should all probably know that user input should never be trusted until verified. How do you handle data that has not yet been passed to the "verification" step? You can safely pass data around without having to explicitly "trust" it. Perhaps the dev was aware that the data was not "verified" yet, but knew that the `Bugzilla::User-&gt;create()` function would do that "validation" for him. What he forgot (or didn't know) was that the `CGI::param()` function could interact with variable passing in the way that it does. This problem could still exist even if the user input was fully validated. Granted, it couldn't happen while using the `param()` function, but other functions act the same way.
&gt; You can safely pass data around without having to explicitly "trust" it. I consider it safer to unpack data in one place and verify it all at once, rather than hoping that I haven't missed one of several places where I might want to verify it later.
To be vulnerable to this, you have to be using a crappy old interface *and* be using it wrong. But since it's so easy to use wrong, it's a fair bet that other people will be affected. And now that it's publicized, there will be some fallout from it.
I wonder if it could be backended by an eliza bot that pesters IRC for code examples: bot&gt; How do i 'my @array = dir(/path/to/dir);'? DenizenA&gt; perldoc -f glob DenizenB&gt; @array = qx(ls '/path/to/dir') DenizenC&gt; We're not here to do your homework! DenizenD&gt; my @array = glob("*"); bot then perl -c the responses and live edits the lines into the code.
I think this bug has nothing to do with blindly trusting unvetted user input. It has to do with Perl design failures. 1. =&gt; is not for assigning a hash value. It is just a comma in disguise and cares nothing about what comes after. 2. Perl arrays are flattened whenever possible 3. Perl is context sensitive 
It hosed all network access on Debian Squeeze, and the backup it had made wasn't a backup of the original bash, it was just another copy of the executable that it had just created (both bash and bash.bak were identically sized at 2.5MB, whereas the working bash 4.1.5(1) from my own backups is 811K). 
what you call design failures i call useful features. 1. awesome if you want to convert a hash to an array or vice-versa 2. arrays in list context return a list, so yeah they flatten, good for merging, if you don't want that use an array ref 3. context is awesome, but can be tricky at first. especially when combined with prototypes
lol new? I remember stepping on this so many times in the 90s, when I didn't even have proper understanding of the context.
Well, that's just a JavaScript overlay. Use Firebug for Firefox, or Developer Tools in Chrome/Safari and inspect what is actually being posted. That is a dynamic form, and WWW::Mech will not execute the JavaScript to get this form rendered.
&gt; It hosed all network access on Debian Squeeze Bash 4.1 is a 6.3 mb download, the patches are just a few kb in total. None of the downloads are conducted in parallel, so can you elaborate? &gt; the backup it had made wasn't a backup of the original bash, it was just another copy of the executable that it had just created It makes the backup before copying the new executable. Sounds like you ran the script twice. 
The initial run told me I was missing byacc. Installed it and re-ran script. So the duplication may have been caused by that. Script should have noticed if a backup already existed though. It apparently successfully ran and updated bash (as according to bash --version) and the system appeared stable. It passed all of the 'are you vulnerable' tests. When I looked at /bin/bash and /bin/bash.bak, both were sized at the same 2,5??,??? bytes (no longer have files available) Box was taken down for the night. Restarting in the morning mostly appeared to complete, except for no network interfaces being brought up. Restored what I assumed was the backup but had the same problem. Pulled a copy of a working /bin/bash from a remote vps that ran a matched version of debian squeeze. A simple copy of that file over the non-working bash and the subsequent reboot brought the system up with all network access as expected.
You're not coercing it, the symbol table is stored in that hash. http://perldoc.perl.org/perlmod.html#Symbol-Tables
nice
what in the fffuuu
I am talking about replicable setups. On machine A: $ pip freeze &gt; my_setup.txt On machine B: $ pip install -r my_setup.txt Voila, the two machines have the same environment.
Well, you might want to read a book like https://www.perl.org/books/beginning-perl/ (free legal download) to find out how to read a file. The construction like $file = next if /&gt;/ doesn't really make sense. PERHAPS you mean something like while (defined($line=&lt;$file&gt;)) { last unless $line=~/^&gt;/; } my @r = split(',',$line); return @r; } Or something like that? It's hard to guess what you want to do since your description of the file format was vague. 
Okay well the first problem is in your while loop. while (&lt;$ref&gt;) { next if /&gt;/; chomp $_; So this populates $_ with each line of the file right. (As an aside chomp works on $_ by default so `chomp $_;` is the same as just `chomp;`) In the test `if (index($ref, $seq) != -1) {` you're comparing *$seq* against *$ref* but *$ref* is the **filehandle** and not the current line of the file. *$_* is the current line. So you would want to use: if (index($_, $seq) != -1) { The second issue is in getReads. You're passing a filehandle to it so you need to read lines from this filehandle. Just to go back to your while loop again, here is the output of me running the command **perl -MO=Deparse -e 'while (&lt;$ref&gt;) { chomp }'** in my shell. $ perl -MO=Deparse -e 'while (&lt;$ref&gt;) { chomp }' while (defined($_ = &lt;$ref&gt;)) { chomp $_; } -e syntax OK This shows you what Perl does to the syntax *while (&lt;$ref&gt;) {*. It assigns the output of *&lt;$ref&gt;* and stores it into the *$_* variable. *&lt;$ref&gt;* is shorthand syntax for *readline $ref* which reads the next line of input from the file pointed to by the filehandle *$ref*. If your reads.txt file is just 2 lines, you can read and discard the first line, otherwise you would need to use a while loop to process it like you process ref.txt. Here is an example of the read/discard method if it's a 2 line file. sub getReads { my $file = shift; # read next line from $file without storing it # &lt;$file&gt; can also be written as: readline &lt;$file&gt; # if you prefer to use that syntax &lt;$file&gt;; my $line = &lt;$file&gt;; chomp $line; my @r = split(',', $line); return @r; }
This won't fix your problem but looks like that's already done below. Just thought I'd mention you might want to look into the [autodie](https://metacpan.org/pod/autodie) module to avoid writing all those pesky "or die ..."s
Beer and dim sum.
This was interesting - also I learned what a "quine" is!
I always thought this kind of technique is cheating. The point of a quine is to get the language to do a little backflip to print out its own source code. This is possible in any language, but these kind of filehandle tricks remove the generally-interesting part for a Perl-specific interesting part.
That module doesn't even have a changelog so it is difficult to tell but it looks like these tests might even have been failing before the latest release
Would [this](https://metacpan.org/pod/Net::DNS) work? It looks to be better maintained
I recommend using: https://metacpan.org/pod/Net::DNS::Dig That is just a poorly designed test for a module
Yeah, tests that depend on things outside of the author's control are bad form. 
There was a single talk about Rust. "Showcased" is a bit of a stretch. 
Check out [testers matrix for the module](http://matrix.cpantesters.org/?dist=Net-Nslookup+2.04). It seems to me that this is just a deviation. &gt; imagine the sound of my head hitting my desk There's rarely a need for this. This is just software :) 
Becauce (acient trick from the perl 4 days) open X is short for open X, $X with `$X` the global variable. And `$0` is the file name of the script itself. BTW, "every Perl program" is not quite right, I guess it will fail if the script name contains a space.
The funny thing is that the IP address returned for the 3rd test is the same as the one expected in the 4th test. And the test didn't like it. Hardcoded transitional values are bad. The test would better have compared these results with results from other, reliable programs (such as command line nslookup). But of course, that solution is not cross-platform. And I tend to agree, the test shouldn't rely on exact output, which should be restricted to developer tests, but on an assessment "does it seem to work at all?", thus: does the output *look like* an IP address (matches a particular regexp), not "is it the IP address I want it to be?" 
There is a --notest switch. 
Haha ... I feel your pain. Working with CPAN modules can be frustrating as CPAN has no quality standards at all. But there are some good tools for measuring "quality" - CPAN Testers, cpan reviews and the kwalitee metrics for instance. It's small consolation but once you get comfortable with the CPAN toolchain, it really is a wonderful thing. Patching tests / modules takes just a few minutes and if you submit the patch to the author, everyone can benefit.
oh, **thank you** !!! I really wanted this!
In statistical terms, what you have is both categorical and continuous variables. If you're using an algorithm that only takes discrete inputs, as you said, you have to discretize them. Since you want continuous output, decision trees might be a good bet. You might want to see if you can get your data into Weka first and play with it there. I wish Perl had more machine learning support, but it doesn't yet. I'm working on it. ;-)
This is probably not all that helpful, but when faced with an issue like this, I will typically interface Perl with scikit-learn from python. Perl just doesn't have anything that can compare. https://wiki.python.org/moin/IntegratingPythonWithOtherLanguages#Perl When using Algorithm::NaiveBayes, I have gotten better results when turning continuous inputs into discrete values when I can identify a monotonic relationship between input and output by first binning the input values rather than using human chosen thresholds, and encoding as a &gt;= or &lt;= on/off activation rather than =, ie. with three bins (low,med,high) low: low=1, med=0, high=0 med: low=1, med=1, high=0 high: low=1, med=1, high=1 
Nice, it goes both ways now :)
Hmm...this is good to know. However, at the current rate of Perl 6 dev work, it'll be 2020 before we even see a production-ready build.
A bit curious why you don't care for Ruby? I'm slowly moving towards Ruby as my go to language instead of Perl. Ruby seems to take all the nice stuff from lot of languages I like and presents them in a nice package. Programming Ruby so far has been pretty similar to Perl but with cleaner syntax.
Unix's lack of a user-friendly GUI will always be a problem, along with its strangely-named, obscure commands. I'm no expert, but I can't see it surviving to the 21st century.
For not being around very long, you seem to have found most of the historical high(low?)-points. The rise of other dynamic languages coupled with the premature announcement of Perl6 have both worked to limit Perl5's adoption in the past decade. That said, the momentum in the Perl5 community has been building back up in recent years. I doubt it will ever be what it was, but still resurgent is better than dead. The key I feel is Perl's flexibility. The language is malleable enough that the community can adapt its [object](https://metacpan.org/pod/Moo) [model](https://metacpan.org/pod/Moose) and even its [syntax](https://metacpan.org/pod/Moops) in order to drive the development of the language. In this way Perl may delay becoming a thing of the past. When your fellow developers give you grief about Perl, show them some of the cool stuff, like Moo and Moops, show them the power of [Mojolicious](http://mojolicio.us) (they don't want to have to write javascript on the server-side just to get a non-blocking web framework do they?). Then show them the culture of testing and documentation that CPAN has and maybe they will think again! Anyway, I should get off my soapbox. Happy Perling! (P.S. get yourself a http://blogs.perl.org blog and let us know how your progress goes) 
^This Things like Mojolicious and Dancer are a massive boost to perl. Moose is great and I hope the perl5 team are seriously looking at integrating it into the core. 
Book recommendation: [Modern Perl](http://modernperlbooks.com/mt/index.html).
IMO, the better question to ask is where are you going, and will perl get you there... if it will, all is well, if not, find what will. Book... [Higher Order Perl](http://hop.perl.plover.com)
The biggest advantage of perl is the community and culture. I have some grievances with the language but it's worth it for things like CPAN. 
That doesn't seem like a valid comparison. There are a ton of alternatives to perl but very few for OSes that are really that different. Simply put, it's a *lot* easier to choose an alternative to perl or even rewrite the perl to something else than it is to try to hack up and maintain your own operating system. 
Tell that to the 1970s. Operating systems are a lot less complicated (and necessary) than people think.
Moose as it is now will never be cored, but it is definitely possible for Moose's *successor* to be cored.
&gt; What is the future of Perl? Well, there's very little new development in it. So my best guess at a future would be unadvertised personal use inside companies, for small utilities and one-liners. Talking to people at YAPC seems to back this up. Most people seemed to be there out of personal interest. They had the freedom to write code in whatever they wanted and they had an affinity for Perl for some reason. This is kind of a return to the roots. It was a long time before many companies really acknowledged using Perl. Slashdot/Geeknet did, but for a long time, that was it. It was kind of a revolution when one company after another, such as Amazon, were outed as using Perl, and then companies became less secretive about this and their employees more involved in the community and conferences such as YAPC. The companies that still use Perl have ramped up their involvement, but there are fewer of them. Perl being underground again seems to be the future. I have 15 years of experience with Perl, but I find myself doing more JavaScript and other things when I do get a project. I just got my Java cert a bit ago. I'm vaguely involved with SNOBOL (nothing like COBOL; it's name pokes fun at it). I think there are a lot of parallels to Perl's situation there. It's a brilliant language that's fun to program in but lacks a few modern niceties that people now days insist upon having. It was also created by linguists and mostly used by social scientists, libraries, and language researchers. It's also known for its parsing/text processing prowess. There are a few hackers around and several old retired guys who still dabble in it. Implementations of the language are still maintained and still get new features. They just created a package manager and not long ago, the csnobol implementation got a JIT. But I'd be surprised if anyone still uses it for work. It's fun, nostalgia, habit, hackery, and personal use. Languages don't die, but losing your market scatters your friends and fellow hackers to the wind.
You'll have to show at least some of your code. What does it look like near line 458? Did you forget a semicolon on the previous line? Edit: My bad. I didn't see that it's line 458 in html.pm, which is clearly not your code.
You mean "it will be 2015 before they start the next great rewrite, the long-promised Great List Rewrite-Everything-From-Scratch"?
Perl is not going anywhere in computational biology. Maybe if Perl5 ever loses support. 
If you want to use HTML::Entities, why aren't you just using it?
He's probably using it from within the 'html' module, which is where the error is coming from.
The other great advantage is that it's so great for productivity. Most languages I work in, I end up taking longer to produce what I want than I initially expect (oh the hell of working in Java to make Android apps!), but with Perl I nearly always finish *quicker* than I expected. Sometimes by big margins.
UNIX has already survived quite well, thank you, through the first seventh of the 21st century. 
Well, actually it was helpful, checking the Python list I've found several algorithms that I could explore. Linking to Python is not an option right now. So I've found a module that takes mixed input, AI::NaiveBayes1, now I have to find a way to turn the output, which are categorized probabilities, into a real number without a plain average which just feels wrong. Another module that is supposed to do mixed input, continuous output is Algorithm::LibLinear, but I can't get it to take the feature scale in or react to certain feature changes during prediction.
A stable, surprisingly fast, and bug-free perl6 release happens in the next two years and gets traction. It heavily optimizes on the static typing stuff. Or perl6 never happens. Either way, perl5 will sorta slowly fade from here. Don't get me wrong, perl5 is still a great choice for shoveling around text and DB data and gluing together executables, and this will remain so. But that's a crowded space. I don't see how Python or Ruby hold up well, either. The 90s style dynamically typed interpreter language is hitting the wall of hardware and software trends. It'll stay fine for the sysadmin type stuff it started out targeting, but it has a very limited future for general programming. Threads and JIT with some level of fast static typing and memory layout control (you really need contiguous Array&lt;int|float&gt; types) are going to be non-negotiable. That stuff is necessary to be performant on smaller devices like phones and it's necessary to be economical on server hardware facing the public internet and large numbers of users. Being 150x slower than C++ was OK when we were talking about processing 500MB data sets or serving 5K concurrent sessions. Multi-terabyte data sets and potentially millions of concurrent sessions are not rare use cases now. Perl/Python is just not an option when you're looking at eight hours of processing time vice 20 minutes for a faster language. This sort of thing comes up all the time now in machine learning and other fields. If you have to drop down to C++ or Java in parts to make if work fast enough, you might as well just write the whole thing in C++. C++14 vs perl5 is not at all what C++98 vs perl5 was. The C++14 is barely going to be more typing. Java 8 doesn't really suck either. The money and effort are going to go into expressive but fast languages. The tooling for faster languages is going to get better and better to the point that there will be insufficient advantage to starting off with a Perl or Python prototype for much of anything. I don't like Go, but its success at taking Python programmers illustrates my point. So the future of perl5 is pretty much what it is now: a handy but fading tool for shoveling text data around and gluing C/C++ libraries/executables together. If MoarVM succeeds at allowing *fast* software and perl6 libraries are made to be fast, then there's a popular future platform there. If the perl6 people misunderstand the growing importance of performance and concurrency and instead think they just need to make a more expressive and less crufty version of perl5, well that's not going to achieve any sort of popularity.
&gt; A stable, surprisingly fast, and bug-free perl6 release happens in the next two years and gets traction. That's been two years away since 2000. If, as some people believe, [p6 doesn't know what it wants to be](http://outspeaking.com/words-of-technology/theme-pragmatics-and-purpose-in-programming-language-implementation.html), it's difficult to imagine that it'll find a successful niche in a field crowded with competitors, most of which either have an established foothold or backing from an organization with real resources (Rust, Swift, Clojure, JavaScript, Go).
.... I'm... I'm not sure how to reply to that. Wat.
I just hadn't gotten far enough to use it yet, still trying to include it. use html; is html.pm, the html::entities module, in the same directory as the script.
I'm a little confused about what you mean by that. I'm not aware of an html.pm module, so are you creating your own? If so, then we'd need to see the code in that file, because that's where the error is occurring. Did you just take the HTML::Entities module and rename it or something? Either way, it sounds like we'd need to see the code in html.pm, probably around line 458, like I said. It sounds like you have access to it, so you should open it up and take a look.
Well what is this "html" module, where did it come from, and why did someone give it an all-lowercase name?
It's very tempting to think of Perl as under-appreciated and therefore some kind of secret weapon, yet compared to what? CPAN no longer outclasses everything else so dramatically. Even if you prefer Perl to Python, Python probably has more modern domain-specific learning resources relevant to your own specific needs. There are many innovative languages in terms of speed or parallelization, like Clojure, Rust, Go, Elixir, Julia etc, that don't have their future mapped out at all, but may have a greater potential for an interesting upside than Perl, which seems unlikely to see any grand renaissance. Even if those others just fade away too, they embody new concepts that are likely to be useful as other new, modern languages evolve. In fact one could even argue that Java 8 and C++14 are incorporating a good deal of the progress being made in trendy languages You'll be able to find specifics where Perl is a better choice than other languages, but the number of problems it can solve where it is the best overall tool is probably decreasing compared to languages that are currently making faster progress. Anyway, my point isn't that Perl is flawed, or worse than other languages, so much as to state that it is worth questioning what favors Perl over other languages, given the negative conventional wisdom about the language, regardless of how unfair it is. My recommendation would be to look at the offerings on Coursera/EdX/Udacity for an introduction to programming regardless of whether its Python, Javascript, C, or some Lisp, maybe even R, for a quick and intensive introduction to fundamentals, and after that consider Perl's advantages for your needs.
The perl5 OO will be its own simplified version. Moose will likely re-build itself to use those keywords on the backend.
[thatsthejoke.jpg](https://31.media.tumblr.com/tumblr_mbzxt23X8c1r3zat8.jpg)
Sorry, it's the file from the first link in my op. I should have named it Entities.pm
Sorry, it's the file from the first link in my op. I should have named it Entities.pm 
I love Perl, I've been coding in it for about 10 years now. Everything from small shell scripts to large, multithreaded multicast engines for financial services. This year, I'm moving away from Perl to Go. It's not that Perl has gotten bad it's just you can definitely feel the trend away from Perl. I detest Python and wouldn't touch it for any $$$ but Go is really an awesome language and that's where I'm going. My prediction is that Perl is not going anywhere but its future is a niche programming language. p.s. will miss cpan dearly :(
Yeah, you can't expect `use` to work unless the file is named `HTML/Entities.pm` and you write `use HTML::Entities`. Try that and see if the error remains the same. Also, point out exactly which line is line 458, just in case there are any differences between your local copy of the file and the one you linked. Line 458 of the linked file is only a closing brace.
Ok, I grabbed my own copy of HTML::Entities from the link and used your code to create a test file. The only thing I changed was use html; to use HTML::Entities; and moved the module to the proper location so that Perl could load in the file. I didn't have any problems loading it in, so you might want to start narrowing things down to see where things are going wrong. The other thing that I would do is put use strict; use warnings; at the top of your file (after the !#/usr/bin/perl) and fix any problems that come up when you try to run the script. Those two lines will tell you a lot of problems with your code before it runs the script. Most Perl programmers never start a script without them, so it's good to get used to adding them.
Ok, i'll have to find out how to add warnings, as i already had to add strict. Again, this is microperl, so a lot has been removed.
You say "Hmm. Maybe my assumptions are not as sound as I thought they were. I have some reading to do." then you go away and learn how computers work.
Go is quite verbose though, isn't it?
Thanks for the thorough answer. I'm still ruby newbie so I lack the real actual experience using it. So far only done few simple scripts and Ruby has worked fine on them. Heh, your "run latest or we don't support you" just brings back memories from the past. Had to do a tad more complex reporting script in Perl. In enterprise env which was firewalled from internet. #perl channel wasn't too helpful when you only had the system's default Perl installation without CPAN to work with. But all in all, one thing I love about Perl that it usually just works. 
Well, it is assumed that for modern development, one will use public available modules, as they give much better results and save time. If your environment is crippled, both perl or ruby can't help you. Python does include many modules in the default package (but not everything), which could be of help. They aren't as robust as perl, but not as bad as ruby.
Whew! For a moment I thought we were having a Joe Biden moment ("America has the technology to lead the world in the twentieth century!")
So your problem is the login? don't you keep the session info in cookie and just remind logged in after refresh?
Strict is more important. It'll take you far. It's not listed in your code, though, so, unless it's just the use html; there's something wrong with the code that you're not showing us.
How did you install HTML::Entities? * The best way is probably to use cpanminus * The next best way is to install the version that is prepacked for your operating system (but that option might not be open to you given that you're on an embedded system). * The way we all used to do it in the good old days was to download the tarball and follow the instructions in the README. * Very very worst, not recommended unless you're in the direst of straits is to try to manually copy the files into the correct place on the target system. This really isn't recommended at all. And, reading your comments, I suspect it's what you have done.
Hard typed languages aren't the "final solution". There is still going to be a strong need for dynamic languages. Not a lot of people like coding 25 lines just to add two numbers together.
Have you actually tried C++11/C++14? It has features like type inference, closures and variadic templates. It is not a Java, it can be remarkably consise IME.
It's not as if biologists ever update their software. Some still use tools hand-optimized for the 386, no joke.
That's why I have hope for Perl5 :) 
I downloaded it from the link I posted to the same directory as the script. This is an embedded system and I only have about 700k to play with, so I can't do any of that fancy cpan stuff.
That's not line 458 in the link you provided. Are you sure you didn't modify the module? In the file you linked to, this is line 458 } It really sounds like you've changed the code you're using, so it's hard to help if you aren't giving the right information. I also can't figure out how you're using it with use html; It shouldn't be able to find the package that way. Another thing you could try to do to troubleshoot is the run perl -c Entities.pm Obviously, you'll have to adjust the argument based on wherever you currently have the module file, and whatever you're currently calling it, but it should try to compile the module to make sure there are no syntax errors. If you haven't modified the file, that should pass with syntax OK Then again... maybe this is some odd bug in microperl, but I'm still skeptical at this point.
You suggest GO as a perl substitute? I tried to use an GO app and it just flat out decided it hated me and refused to work. 
yum, belgian beers ... brb
It is and the modules are not nearly as well documented. Still, one must keep up with the times and that's where the trend is.
What are the previous couple lines?
Don't get me wrong though, I do have quite a lot of respect for Go, at least for its speed. I've read that it's the fastest language after C or something.
Talk will probably focus on the following editors: vim, emacs, sublime text, and then maybe padre, eclipse/epic, and komodo. Any other recommendations?
Ages ago, on Windows, I used Textpad (3 and later 4) a lot.
You can't just go around and rename modules. If you download HTML::Entities from cpan, you absolutely NEED to put it in a directory called "HTML/" and call it "Entities.pm". Remember: These names are all case-sensitive. You also need any dependencies this module has. Like this: yourscript.pl HTML/ Entities.pm
You are using the old style of (de)referencing complex data structures. This is one of the reasons that perl was considered hard to read and hard to maintain. But we have had the -&gt; operator for a long time now and it makes your code much simpler to read and maintain. $postCount += scalar @{$decjson-&gt;{'data'}-&gt;{'children'}}; for my $hash (@{$decjson-&gt;{'data'}-&gt;{'children'}}) { $subredditList{$hash-&gt;{'data'}-&gt;{'subreddit'}}++; } There is still one extra set of {} used to dereference the array ref, but perl 5.20 adds a new feature that can solve that one as well (although it is experimental for now) $postCount += scalar $decjson-&gt;{'data'}-&gt;{'children'}-&gt;@*; for my $hash ($decjson-&gt;{'data'}-&gt;{'children'}-&gt;@*) { $subredditList{$hash-&gt;{'data'}-&gt;{'subreddit'}}++; } Read the [perlre](http://perldoc.perl.org/perlref.html) docs for more info on references and how to use them.
A few things would help: * remove quotes in hash key names, they're optional if key name is a single string, * assign structures to intermediate variables, there's much less to type afterwards. Here's your example: my @children = @{${$$decjson{data}}{children}}; for my $hash (@children) { my %data = %{ $hash-&gt;{data} }; next if ($data{ups} - $data{downs}) &lt; $karmafloor; my $domain = $data{domain}; if ($domain =~ m/youtube\.com/i) { my ($id) = $data{url} =~ m/v=([\w\-]+)/i; $YTID{$id} = decode_entities($data{title}); } elsif ($domain =~ m/youtu\.be/i) { my ($id) = $data{url} =~ m/youtu\.be\/([\w\-]+)$/i; $YTID{$id} = decode_entities($data{title}); } elsif ($domain =~ m/soundcloud\.com/i) { $YTID{"SC_$counter"} = $data{url}; $counter++; } } 
Are you serious? I don't follow development of Perl 6 and this is not a sarcastic question. 
The mistake is to think of Perl 6 as continuation of Perl 5. It is quite a different language. Has similar ideals, but it is more different than same. However, Perl 5 keeps progressing and releases happen all the time. The problem here is mainly with semantics and marketing. Perl 5 will never be able to become Perl 6. It will just increment the minor version forever. So we might see Perl 5.100.0 at some point in the future. Which poses a problem that it isn't as "cool and hip", because it is not a "new hot" version. However, some pretty major features and changes have been introduced via these minor version bumps.
I like your answer, I think you may be able to simplify it further: $decjson-&gt;{'data'}-&gt;{'children'}-&gt;@* $decjson-&gt;{data}{children}-&gt;@* 
I downloaded a new copy, put it all in HTML/ now, Entities works, but it complains it can't find Parser. If I have to manually add these into the device firmware, this just got a whole lot harder.
Here's how I would have coded that. With the exception of %YTID. I never declare hashes with %, only as references ( so 'my $YTID = {};' ), but since it's declaration isn't shown, and your usage of hashes, I'm assuming you declared it with %, so I left it without the arrows. The keys to readability are: * declaring a reference to $hash-&gt;data * using the arrow operators rather than using {} to dereference everything Code: foreach my $hash ( @{ $decjson-&gt;{data}-&gt;{children} } ) { my $data = $hash-&gt;{data}; next if( ( $data-&gt;{ups} - $data-&gt;{downs} ) &lt; $karmafloor ); if( $data-&gt;{domain} =~ m/youtube\.com/i ) { my $id = $data-&gt;{url} =~ m/v=([\w\-]+)/i; $YTID{$id} = decode_entities( $data-&gt;{title} ); } elsif( $data-&gt;{domain} =~ m/youtu\.be/i ) { my $id = $data-&gt;{url} =~ m/youtu\.be\/([\w\-]+)$/i; $YTID{$id} = decode_entities( $data-&gt;{title} ); } elsif( $data-&gt;{domain} =~ m/soundcloud\.com/i ) { $YTID{"SC_$counter"} = $data-&gt;{url}; $counter++; } } It's also worth noting that if depth was really an issue, I'd be working with object here to at least ensure validation of the hash contents... especially if it's coming from an external source like JSON. You don't want to be iterating around and find one entry doesn't have 'ups' or 'downs' defined at run time, etc... 
Even without the experimental stuff, you only need the first -&gt;. @{$decjson-&gt;{'data'}{'children'}}
You'll need HTML::Parser, yes. Maybe, because this is a very strict environment, you should consider reinventing the wheel. Normally I would advise against that, because CPAN has a module for everything, but you obviously can't deal with long chains of dependencies.
I just need to replace all the html codes like %20 and whatnot. I've ordered a few books and will do some more learning I guess.
We are not golfing here, but trying to make the code more readable. Yes, you can remove the extra arrows, but for me it doesn't improve the readability of the code so I always leave them in. Either way is correct though, it just comes down to personal preference I guess.
Use a session variable to identify testing env and set a cookie with auto login using same session on reload?
You can cover most entities by yourself and basic string replacements, it's not worth the hassle trying to get XS modules running for your system.
No problem!
"there will be significant rewrite and refactor of the current Rakudo codebase"--has it really been 18 months since the last big rewrite?
Not sure why you would do HTML entity encoding on the URI. You shouldn't have to unescape the passed-in URI or encode it, I believe it should be fine as-is. But I could be wrong about that. As for preventing XSS, I haven't read up on HTML::Scrubber, but I don't really believe there are a lot of ways of preventing XSS when the input is arbitrary HTML. Too much difficulty. What about using xpath to grab the bits of data that you want? Also, why allow the user to specify the first part of the URL at all? Why not just take their input and append it to http://whatever.com/. Finally, let's say that whatever.com has some SQL injection vulnerability in one of their URL paramters. Bad guy, wanting to get some data from them, decides to proxy through your site. Now whatever.com has logs showing you exfiltrated their data using SQL injection exploits. Yay! You should be as restrictive on that URL parameter as possible. And you should be considerate of the website you are hitting, so that bad things like lawsuits and criminal charges don't happen to you. What you should really do is talk to whatever.com owners and see if they have an API for the data you're sourcing from them. Maybe it's already available for free somewhere.
p.s. along the same lines, and perhaps more relevant for xsite scripting ... what would be the safe way to make a link to the url in question .... e.g. how would you change this code? and/or sanitze $uri before printing? print sprintf('&lt;a href="%s"&gt;%s&lt;/a&gt;', $uri, $uri);
Thanks for the response!! I am using use HTML::TreeBuilder::XPath to grab the parts and then eliminate some unwanted subparts, The most important part is the main content area which has html text that would be in a news article ... I apply HTML::Scrubber to that and I just allow div p a and some other standard tags and remove most attributes, scripts, etc. Good legal advice. I'll have to give that some serious thought! 
Probably not advisable to do this on a Web server.
I don't follow. Could you elaborate?
I hear you and see more of the risks by posting here. but there's lots of sites that do something similar. Consider this one: http://validator.w3.org/
Thanks! I've ignored postfix dereferencing in perl 5.20 up until now (I find it ugly and I'm not yet using 5.20 anyway). But this example shows the whole point of postfix deref and why it might make code more readable, i.e. by removing @{} enclosures. 
I don't use postfix dereferencing either and I agree that it looks ugly (but that is probably because it looks alien to me as it is new). I would have been happier if they stuck with the same construct that allows you to execute a function reference: $subref-&gt;() So the following would be equivalent: @{$arrayref} @$arrayref $arrayref-&gt;[] The same would work for hashes then: %{$hashref} %$hashref $hashref-&gt;{} To me that looks cleaner than putting the -&gt;@* on the end, but there was probably a good reason not to do it this way...
Yeah, I like your preferenced syntax too. The @* part looks completely arbitrary. But it still beats [PHP's choice for namespace separator](https://wiki.php.net/rfc/namespaceseparator) :) 
I am reading to this the section "XSS Prevention Rules Summary" is particularly helpful. https://www.owasp.org/index.php/XSS_%28Cross_Site_Scripting%29_Prevention_Cheat_Sheet
The title makes it sound as though this abstraction is a bad thing, perhaps something that has arisen accidentally over time
&gt; Then, it uses the built-in Perl read() function in order to read the incoming data line by line. Hmmm, I've never used read but that statement is wrong. The line in question reads data 8192 characters at a time
The Rakudo devs have been criticized for their tendency to rewrite code instead of pushing towards a 'production-ready' release by incremental improvements - it shouldn't be all that hard to find some rants by chromatic about that. The toolchain went through several rewrites (PGE, NQP, NQP-rx, NQP-ng if I remember correctly), the object model got a complete rewrite (nom), Parrot got replaced with MoarVM and now we get a 'Great List Refactor'. Having said that, I do believe Rakudo actually is approaching a state that I'd consider generally usable - my guesstimate would be 2016 (let's see if the GLR works out and leave some time for further performance improvements and stability, P5 interop and getting some infrastructure in place).
"it had a dozen users"--after fourteen years, perl-6 should be so lucky! "I have about a thousand lines of perl6 so far"--I'm not impressed! perl-6 has a handful of users with a little bit of code, and after fourteen years it still doesn't have a stable spec let alone a single complete implementation. No one is asking for a waterfall. We're just wondering if anyone working on it is capable of completing anything.
"my guesstimate would be 2016"--it's always 18 months away, isn't it? 18 months here, 18 months there, and suddenly it's 14 years later and the spec is still changing things as fundamental as lists. Are people to think that suddenly a switch will flip and the habits that led to 14 years of churn will become habits which produce stable "useful and usable" production ready software? 
This is great! Website works pretty good and it is fast. I hope it will kick some momentum into the marketing vector of Perl.
I think it's worth mentioning that you should avoid building a threaded perl unless you are absolutely positive you are going to need threads. A threaded perl takes a performance hit, it can be as little as a couple of percent or up into double figures. So think twice.
From the article: &gt; The web site is hosted on Linux servers. We have database servers running MySQL and Sphinx Search and application servers which run Apache and a web application written in Perl using Dancer and Template Toolkit. In front of the application servers a layer of Varnish application cache servers helps to handle the load.
Just curious, were you a dev on the project? You seem frustrated with the path it's taken.
No thank g-d! Just a poor punter who donated money to the TPF in more than one of its incessant charity drives... and then for the next decade watched perl-6 fail to deliver anything "useful and usable" as Perl languished.
Awesome! Welcome to the dance floor, BBC!
Or just use [perl-build](https://metacpan.org/pod/distribution/Perl-Build/script/perl-build)
I'd heard that too. Glad to see that it's not the case.
doesn't perl-build assume that you already have perl installed?
Am I the only one who thinks that 1.7 million page views per month for the search.cpan.org is a huge number?
That's about 56666 per day. I easily average about 20 page views per day (conservative estimate). If there are 2833 people like me, that's 1.7 million per month. Keep in mind also that search.cpan.org is well indexed in Google. Sometimes searching for something related can bring up search.cpan.org results, and even non-Perl programmers who are looking for solutions might check it out.
No real advice, but some links ganked from freenode#perl's bot: http://books.perl.org/ http://perl-begin.org/books/ http://www.perl.org/books/library.html http://www.onyxneon.com/books/modern_perl I take that back, here's advice: learn to use the documentation, specifically perldoc. "perldoc perldoc" to start.
I'll look into these thanks. 
\#!/usr/bin/perl
Heh. In all seriousness, I learned mostly from the man page for perlfunc.... with a bit of help from the perlmonks web site. And I check cpan before I try to reinvent the wheel.
Thanks for the help! 
Thanks! This should really help me out I appreciate it. Everything like App::Rad is a module correct? 
The thing that's helped me more than anything learn new languages is already knowing C, and the stdlib. Stuff like the format arguments to printf are applicable everywhere, and even if you never use the language itself, having an idea of how things like addressing work (why do array indices start with 0, not 1, for instance?) on a "lower level" helps enormously, I find. "The C Programming Language" ("K&amp;R") is a slim volume, but will still be helping you out for years to come.
I've been exposed to perl for a few years now but only recently began really perusing getting to an actual level or competence so I may already now enough basics I would get from C. I will still definitely look into it, thanks! 
Check out Modern Perl. I haven't looked at Learning Perl in a while, and it might be good, but when I was learning it seemed pretty basic.
I'm interested to learn perl to parse data and make some invoices for billing. I've been able to do three steps so far with just awk but wrapping it in perl may be more efficent. 
Changes are described here: https://metacpan.org/pod/release/ABIGAIL/perl-5.21.5/pod/perldelta.pod
&gt; Special handling is required on EBCDIC platforms to get qr/[i-j]/ to match only "i" and "j", since there are 7 characters between the code points for "i" and "j". Fucking EBCDIC.
I like foreach \%hash ( @AoH ) { ... }
I finally had a need to code this in Perl. Here's a take: my $KMER_SIZE = 20; sub kmers { my $seq = shift or return; my $len = length $seq; my @kmers; for (my $i = 0; $i + $KMER_SIZE &lt;= $len; $i++) { push @kmers, substr($seq, $i, $KMER_SIZE); } return \@kmers; }
Can you use a 'my'? foreach \my %hash ( @AoH ) { ... } EDIT: Seems to work.
Ok, then get on with it! 
He or she is 17, though, and mentioned "perusing programming," so probably basic is just the thing.
perl has been NSA backdoored since version 1.0. Got it :-P
I thought Perl was written for work at NASA, which is quite different from NSA. Can I get a confirmation?
Larry indeed did work for the NASA JPL in the early days, but Perl was developed while he was working for SDC (later Unisys).
We can't tell you it's super secret stuff.
That's all nonsense. All perl hashes and it's serialized forms habe unlimited key length and 2^32 number of keys, not just DBM::Deep. I never heard of any level restriction neither, only recursive cycle prevention or not.
Hey this is cool, thanks for sharing. If you're interested in sharing data between processes, you might like [Hash::SharedMem](https://metacpan.org/pod/Hash::SharedMem)
My attempt at a BuzzFeed style headline.
If you're interested in doing OOP in Perl, you should definitely know about [Moose](https://www.google.com/webhp?q=perl%20moose#q=perl+moose). (I realize this is not an answer to your question) :)
NDBM_File had some horrible arbitrary and not well documented limits on key/value length. Suspect OP is referring to that.
Are you referring just to hashes in memory? Because I'm referring to persistent hashes stored on disk. SDBM and NDBM and the other "built in" hashes stored on files are limited to 1009 bytes for the key and data. Same with Berkeley DB. Hence my reason for looking for another solution, as I couldn't get SQLite to work. 
I agree and I'd recommend reading through the Moose manuals: https://metacpan.org/pod/distribution/Moose/lib/Moose/Manual.pod
Thank you, will check !
"For example the CentOS 5.10 system provided by Digital Ocean does not come with Perl preinstalled." - from the article.
Post the entire code, we need more context
Well, here's how I'd write it: #!/usr/bin/perl use strict; use warnings; use v5.10; my @order; while(&lt;&gt;) { my @fields = split /, *| *\n/; @order = sort { $fields[$a] cmp $fields[$b] } 0..$#fields unless @order; s/^0+(?=\d+$)// for @fields; say join ',', map $fields[$_], @order; } This is meant to be used as: $ ./script.pl input.csv &gt;output.csv or $ ./script.pl &lt;input.csv &gt;output.csv That is, it acts like a standard Unix program. Doing it this way gives the user a lot more flexibility — maybe they want to process the output with a pipeline rather than writing a file. It also makes the script significantly shorter. I've also taken the liberty of using the default variable (`$_`) in a few places to make the script more concise. Let me know if anything isn't clear.
Drink fine scotch while wearing a tux while coding, or type with your pinkies up in the air and speak in a British accent. Code born of such elegance could not possibly be anything other than more elegant. 
Stefan Seifert, aka nine, did [a fast paced demonstration of the advanced P5/P6 interop already available via Rakudo/NQP/MoarVM and his new Inline::Perl5 module](https://www.youtube.com/watch?v=I_oHwATg8CI). The screen showing nine's slides is hard to read. Here's [a plain text version of his slides](http://niner.name/talks/Inline-Perl5/content). He starts with "How to port a Catalyst based web application from Perl 5 to Perl 6." Less than three minutes later he's demonstrating [ciderwebmail](http://ciderwebmail.org/about/index.html) running under P6 control and says "OK, I ported a Catalyst application to Perl 6." The audience laughs, but by then he has made a compelling point. The rest of the talk covers: * writing Catalyst controllers in P6; * using CPAN modules *including ones that rely on XS*; * writing subclasses of P5 classes in P6; * passing P6 objects to P5 and using them in P5; * passing P5 objects to P6 and using them in P6.
I like it, though I'd pull the header out before the loop - just looks nicer to be like that. Could do with a couple of comments given you're answering a post of someone totally new to Perl :P
May I recommend using https://metacpan.org/pod/Text::CSV_XS Csv files can get troublesome quick when you start dealing with embedded delimiters and such. Something along the lines of the below, which is a simple example, you can check the return values to make sure everything parses and such. while(&lt;&gt;) { $csv-&gt;parse($_); my @fields = $csv-&gt;fields; #do thing with @fields } edit: formatting
Agreed you need to give platform and Perl version to get a good answer. This is a guess: From your ultra short description it could be that you are using a old version of Activeperl ( 5.12 or below requires a business license for access to ppm http://code.activestate.com/ppm/ - check "perl -version" from cmd). Solution: use a newer version of Activeperl. 
Alternative to map there: say join ',', @fields[@order];
Thanks, wackdroid! This was a coding exercise I sent in for a job application, so using a csv module was not allowed. I chose the language I had zero experience in, but it turned out to be way more fun that I had thought. I have a feeling I'll be visiting /r/perl much more now!
Thanks for the suggestions. As I told Wackdroid, this was a coding exercise I had to turn in to a prospective employer, so only core functionality was allowed. It's good to know that Perl has a great community. I'll be stopping by here more often from now on!
This is longer than your example and it only implements the *reorder*, but you can modify it at will. And the ideas are good; especially the use of 'map'. Enjoy. ------- #!/usr/bin/perl ###vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv# header ### ### 2014.10.24 YourNameHere Parses and sorts a csv file ### ### notes: ### This is a bit longer than yours, but it's robust and modifiable ### include a package name to make this a class (of sorts); it's now available globally in __PACKAGE__ ### the END block in the header can group all the 'globals' without actually making them global (using 'our') ### use anonymous functions to leave the global space for imported libraries; don't forget the trailing semicolon ### optional -- use explicit sigil s to search later based on type (I'm a fan); ### END only run after everything else loads ### the timer has been moved there and functionalized ### Data::Dumper is *useful* for debugging complex data structures ### consider using list-import-style instead of single values ### then you can manipulate the data as it comes in ### be aware of array versus scalar context though ### with a more complex input, it is nice to separate bounds-checking ### not crucial here, though I did it anyway ### I like to use $f* for printf formats ### I like to use $r* for regex content ### since you are willing to read in the input entirely to memory? ### bring the open/close in as close as you can and only do it once ### I moved the timer functionality to the END block ### you tried to used the &lt;&gt; operator in what seemed like a scalar context ### if it worked, you are using a method I don't ### I changed it, though it's probably a lateral delta ### stripping the carriage-returns windows-proofs it a bit (may not be important) ### the principle improvement to a sort problem like this? ### use map with an reorder-index derived from the header ### the -1 in split permits trailing blank fields if present ### I functionalized your sort method so that the code documents itself ### input array context expressly discards after first arg ### the main body return MUST BE THERE if you use the GOSUB technique ### GOSUB technique uses goto to put internal procs after the final return ### it's a clean way to keep internal procedures ### I didn't implement the rest, but this should get you going good ### ### call tree: ### INIT ### END ### main ### order ### package csvsorter; use strict; use warnings; use Time::HiRes; use Data::Dumper; INIT { our( $main ); } END { ### setup our( $main ); my $ftime = "Time elapsed: %s milliseconds\n\n"; ### do my $start = time; &amp;$main; my $end = time; my $time = ( $end - $start ); printf( $ftime, $time ); ####### output: stdout } ###vvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvvv# procs ###~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~~ ### purpose: coordinate reading, writing, and processing ### input: command line file name ### output: a.out ### call tree: ### order our $main = sub { ### setup my( $order ); goto GOSUB; RETURN: ### get internal procs my( $input ) = @ARGV; ####### input my $rcomma = '\s*[,]\s*'; my $ffail1 = "Must specify a CSV file as a command line argument!\n"; my $ffail2 = "Error opening %s!\nCheck your file type.\n"; my $ffail3 = "Must have content!\n"; my $fout = "%s\n"; if( not $input ) { die( $ffail1 ); } ### early out open( my $DATA, '&lt;', $input ) or die( sprintf( $ffail2, $input ) ); ### early out my( $header, @in ) = &lt;$DATA&gt;; for( $header, @in ) { chomp; s/\r//; } ####### input: file close( $DATA ); if( not $header ) { die( $ffail3 ); } ### early out my @header = split( $rcomma, $header ); ### do my @reorder = sort { &amp;$order( $a, $b, \@header ) } ( 0 .. $#header ); my $reheader = join( ',', map { $header[$_] } @reorder ); my @lines; for( @in ) { my @value = split( $rcomma, $_, -1 ); my @line = map { $value[$_] } @reorder; my $line = join( ',', @line ); push( @lines, $line ); } my $file = 'a.out'; open( my $OUT, '&gt;', $file ); printf $OUT( $fout, $reheader ); for( @lines ) { printf $OUT( $fout, $_ ); } ####### output: file close( $OUT ); return; ###--------------------------------------------------------------------------- GOSUB: ### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - # purpose: isolate sorting behavior # input: two indices and the dictionary itself # notes: # you can subsort too, I provided a hook 'byother' # output: sort directive $order = sub { ### setup my( $a, $b, $index ) = @_; ####### input my $headera = $index-&gt;[$a]; my $headerb = $index-&gt;[$b]; my $byindex = ( lc( $headera ) cmp lc( $headerb ) ); my $byother = 0; ### do my $directive = ( $byindex or $byother ); return( $directive ); ####### output }; ### - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - - goto RETURN; }; ### ### common functions that you use and port around can go here ### I'd still make them variables ### to avoid clashing namespaces with imported packages ### 1; __END__ 
This looks great. Personally I only dereference at the data level. Basically I prefer -&gt; over @/%{ ... }. So I have -&gt; a lot in the block logic, but the data structure access is a lot prettier: my $children = $decjson-&gt;{data}{children}; for my $child (@$children) { my $data = $child-&gt;{data}; next if ($data-&gt;{ups} - $data-&gt;{downs}) &lt; $karmafloor; my $domain = $data-&gt;{domain}; if ($domain =~ m/youtube\.com/i) { my($id) = $data-&gt;{url} =~ m/v=([\w\-]+)/i; $YTID{$id} = decode_entities($data-&gt;{title}); } elsif ($domain =~ m/youtu\.be/i) { my ($id) = $data-&gt;{url} =~ m/youtu\.be\/([\w\-]+)$/i; $YTID{$id} = decode_entities($data-&gt;{title}); } elsif ($domain =~ m/soundcloud\.com/i) { $YTID{"SC_$counter"} = $data-&gt;{url}; $counter++; } } 
I agree. Also, theres a couple shortcuts you can use to minimize keystrokes that make more sense as well: my $children_ref = $decjson-&gt;{data}{children}; Hash keys don't need to be quoted if they match the rules for identifiers (variable names), and the second -&gt; isn't needed because perl can assume you're going deeper in to the data structure when it sees { foreach my $link_ref ( @$reddit_links_ref ) { The { and } can be omitted because the precedence can be assumed when dereferencing a single identifier. 
You probably have a proxy. From http://docs.activestate.com/activeperl/5.8/faq/ActivePerl-faq2.html#http_proxy The http_proxy Environment Variable Set the http_proxy variable with the hostname or IP address of the proxy server: http_proxy=http://proxy.example.org If the proxy server requires a user name and password, include them in the following form: http_proxy=http://username:password@proxy.example.org If the proxy server uses a port other than 80, include the port number: http_proxy=http://username:password@proxy.example.org:8080 
&gt;This is all well and good, but split can return a limited number of results if you want: *Yup, that's totally what split does. It's not as if Perl does that with other functions that return arrays, that'd be totally dumb.*
btw you are welcome to review this code, either here or at [codereview_stackexchange](http://codereview.stackexchange.com/questions/67480/reverse-polish-notation-compiler)
 my ( $line, $fullcode ); $fullcode = ""; while ( $line = &lt;$CODE&gt; ) { $fullcode .= $line; } For this part, I would change it in one of two ways. Change the scope of $line so it doesn't exist outside the loop: my $fullcode = ""; while ( my $line = &lt;$CODE&gt; ) { $fullcode .= $line; } or drop the temporary variable completely. while ( &lt;$CODE&gt; ) { $fullcode .= $_ } You also might want to move the rest of the code into subroutines. Even though perl doesn't require it, having a main() sub discourages unneeded global variables and aids with testing.
&gt; Yup, that's totally what split does. It's not as if Perl does that with other functions that return arrays, that'd be totally dumb. Hey pedant no Perl function returns an array. Oops!
You can also use list context to avoid the loop: `my $fullcode = join '', &lt;$CODE&gt;` Or use `read_file` from `File::Slurp`.
If you set [$/](http://perldoc.perl.org/perlvar.html#$/) to `undef`, you read the whole file in one, no need for first splitting into lines and then joining again: my $fullcode = do { local $/; &lt;$CODE&gt; };
Thanks for posting! Really enjoyed Jonathan's [talk](https://www.youtube.com/watch?v=AhCx3CTauBY) on Perl 6 concurrency ... very tempting to dive in.
I don't like sprinkling strings everywhere. My preference is to create a package for strings. It reduces the syntactical clutter. If the package becomes large, I move it to an external file and "require" it. Here's a quick example. #!/usr/bin/perl use strict; use warnings; BEGIN { package resstrs; sub new { my $self = {}; sub str1 { return "string1\n";} sub str2 { return "string2";} sub fname { return "output.csv";} sub strError { my ($self,$m)=@_; return "Exit, error. L=$m\n"; } bless($self); return $self; } } my $strO=resstrs-&gt;new; print $0 ." ". $strO-&gt;str1; my %hash=(); $hash{ $strO-&gt;str2 } = "A suggestion"; open my $fh, '&gt;', $strO-&gt;fname or die $strO-&gt;strError(__LINE__); 
&gt; Perl 6 Journey For fuck's sakes, it's just a 15 year old toy project. No wonder Perl 6 is such a disaster. The whole community is a self congratulating echo chamber. Stop patting yourselves on the back, put down the booze and start working towards a usable first version :/
Yeah, because you are paying them, right?
not knowing the lanuge of perl 0,1,2,3,4,5, or 6, but knowing the history of the language and how it was created, I think perl 6 will do well. LW created patch. His version may not be the one in your OS, but knowing he can create popular tools/utilities, let's see what continues to happen with perl 6.
I like the way you generate the assembly language, but other than splitting the implementation into a module and associated driver I have no useful commentry. I recently wrote [a toy virtual machine](https://github.com/skx/simple.vm) which has a perl-based compiler and decompiler, so it's nice to see similar things being done with perl
Many people donated to TPF's various fund drives over the years. Many people donated code, tests, docs, bug fixes, patches, bug reports, et cetera over the years. If it's intended to be a community project, it shouldn't be immune to criticism from the community.
See PREREQ_FATAL in perldoc ExtUtils::MakeMaker, but I vaguely recall a better way to handle that. The danger is that CPAN testers test reports are going to blow up, your module will be (based on their testing) be marked as not passing tests on any platform. Maybe they have hooks into PREREQ_FATAL and other modes of die'ing in ExtUtils::MakeMaker. ET::MM documents the old and traditional way of creating Makefile.PLs. Other systems might have other approaches too. 
Another way is to build the C program by creating an Alien module using [Alien::Base](https://metacpan.org/pod/Alien::Base). For an example, see [Alien::nasm](https://metacpan.org/pod/Alien::nasm). Let me know if you go down that path. We can discuss it on the [mailing list](http://lists.perl.org/list/alien.html). :-)
Oh, and if the C file is entirely your own, you could use Inline::C and let that compile and generate XS for you. I'm doing that right now for embedding R in Perl.
unfortunately
You can lookup what the best and fastest serializers are. For hashes it would be JSON::XS (or better Cpanel::JSON::XS), Data::MessagePack or Sereal. The performance depends if the serializer needs to detect cycles in the values. For dbm ties it would be any, which is not so broken as NDBM, SDBM or LMDB, with its key length limitations. BDB and all others have none.
Your crack. I want me some of that shit!
Do I win the *least elegant prize*? hahaha. EDIT: it has a certain monstrous beauty, at least. :)
Hi, I would suggest you use [Pegex](https://metacpan.org/pod/Pegex) to write the compiler. You can use Pegex to write a grammar and then use the parsing capabilities to invoke callbacks at every token enabling you to create an Abstract Syntax Tree. I have written a compiler called [VIC&amp;trade;](http://selectiveintellect.github.io/vic) that uses Pegex and it works well. Join the #pegex IRC chatroom on Freenode for more information and help. 
Sounds interesting. Thanks.
At the time I was writing this I did not knew how to use modules or create modules.
You have not read the article. Import::Base has Import::Into under the hood. &gt; What makes Import::Base more useful than rolling your own with Import::Into is &gt; the granular control you can get on the consuming side. On a case-by-case &gt; basis, individual imports can be removed if they conflict with something in the &gt; module (a name collision, for example). Then, the offending module can be &gt; used directly.
Checkout Coro https://metacpan.org/pod/Coro I'm not sure how much it's used in production environments though. I haven't used Coro, but I've used some excellent modules by the same author.
I use it in production. No problems with Marc's code in general and he fixes things quick if you find issues. He does things his own way, but very good code. Reminds me of djb and qmail
Doesn't Go do a thread pool? That makes coroutines nonequivalent. If you need concurrent parallelism in perl you have to do IPC. Look at ZMQ or MPI, cordinating processes through a database such as BDB, or even a message queue such as RabbitMQ. Depending on what you're doing, a systemd/xinetd type forking server or maybe even xargs might be good. The answer to the question Can one very easily dole out work to a thread pool with perl? is "No." 
Jonathan Worthington, a fantastic presenter, doing important work, sharing interesting information. Enjoy!
I guess there is a POE thread pool thingy, but personally I would probably use fork + zmq for a simple case.
It reminds me of [this](https://github.com/EnterpriseQualityCoding/FizzBuzzEnterpriseEdition). 
I think it has been clear for about a decade that - Perl 6 is a research project and not in a hurry to deliver something that's suitable for use in production (even if Perl 6 was ready today, most people won't use it in production the next 3 years; hell, I have customers who are still on Perl 5.6 (!)) - Perl 6 is not the next major version of Perl; it's a different language inspired by Perl 5. - Perl 5 is not going change a lot - Perl 5 usage is on the decline I don't get it why people want Perl 6 right now (this Christmas ;-) ). Finally, don't give someone a beer if you can't afford it. Especially don't hand out beers expecting someone to come back to your house.
You might want to take a look at [threads::lite](https://metacpan.org/pod/threads::lite). It's closer to what you're talking about than the model used by [threads](https://metacpan.org/pod/threads) but Perl is not efficiently parallel in the general case
isn't Go mostly written in C? Same for Perl ? so ... why cant the guts of Go be added to the guts of Perl? 
A small part of me is so exited. Perl 6 has been a *long time* in coming, but from the beginning I saw the promise and the possibilities. Even after all of these years, it's still full of concepts and designs that are advanced and novel among general purpose languages. Yet at the same time, it has an elegance and coherency that is breath-taking. I think there's a non-trivial chance that Perl 6 could bring Perl back into the league of major, commonly mentioned languages. Thanks to everyone who has contributed to it, including the many not really false starts over the years, that have brought us to this jumping off point. 
how then does Inline.pm do its work? https://metacpan.org/pod/distribution/Inline/lib/Inline.pod 
OMG. WTF. This really isn't going anywhere, is it? Just a bunch of travel metaphors to explain why this project hasn't shipped anything usable yet. Wow. 
What features would make it exciting?
Briefly, in no particular order: 1. Incremental data typing that will actually make programs run faster (and, potentially, more correctly) 2. Generally much easier to learn/teach 3. Quite a few novel, interesting and powerful concurrency features 4. JVM support will allow it to be added to 'big enterprise' Java apps There's tons of others! 
Came here to suggest just that. [Inline::C](https://metacpan.org/pod/distribution/Inline-C/lib/Inline/C.pod)
&gt; What features would make it exciting? If you haven't seen it, Jonathan's [talk](https://www.youtube.com/watch?v=AhCx3CTauBY) on concurrency in Perl 6 is pretty exciting.
Has been for a few months now...
that's what https://metacpan.org/pod/Devel::CheckBin does.
[Video of talk](https://www.youtube.com/watch?v=AhCx3CTauBY)
You could take a look at the [Perl's solutions of the problems on rossetacode.org](http://rosettacode.org/wiki/Category:Perl) and try to find a problem with a solution of 4-5 lines that you consider "beautiful". For me it seems that the solutions for "Averages/Root mean square" and "Caesar cipher" are okay for a shirt, although I looked only for 5 minutes, so... Oh and don't forget the hat (cowboy hat, I think)! =)
The 3 great virtues of a programmer are ... Laziness.
The historical precedent is in this [comment I posted a while back](http://www.reddit.com/r/shittyprogramming/comments/2k5rj2/you_dont_have_to_be_a_c_dev_to_look_at_the_code/clii6c9).
Little bigger than you asked for but its a classic and could fit on a shirt. http://www.perlmonks.org/index.pl?node_id=45213
my $hirt = @wesom[3];
Scalar value @wesom[3] better written as $wesom[3] at -e line 1.
I think this could fit on a shirt and strike a fun tone: http://www.99-bottles-of-beer.net/language-perl-737.html That said its not "easy on the regular expressions" ;-) 
I just picked it up on Amazon, should be here Saturday.
 Can't locate Perl.pm in @INC
If it's not in Perl 6, it's not Larry Wall.
Post all of the code, not the part that you consider relevant, and then give a more clear definition of "can't get it to work". Also, either 'use autodie;' or check return values of open() and close() calls (and of print() if you feel paranoid). Also, use 3-argument open(), and full file paths, i.e. not open (MYFILE, '&gt;&gt;testfile.txt'); but rather open(my $write_handle, '&gt;&gt;', '/tmp/mytestfile.txt')
 #!/usr/bin/env perl use strict; use warnings; open (my $fh, '&gt;&gt;', 'testfile.txt') or die "Could not open file: $!"; print $fh "\n\nHere is a new line!"; close ($fh); your code does work though, give us more information.
Your code looks fine. You're using bareword filehandles and the two-argument form of "open", both of which are no longer recommended, but that won't stop your code from working. I'd write it like this: #!/usr/bin/perl #iotest.pl use strict; use warnings; open (my $file, '&gt;&gt;', 'testfile.txt') or die "Couldn't open file: $!"; print $file "\n\nHere is a new line!"; close ($file); Any problems you have are elsewhere in your code.
Don't use bareword filehandles. It's so last season.
I'm wondering if you come from a PHP background using the old `import_request_variables` or a similar method? Perl doesn't do that sort of thing because it's really easy to clobber yourself doing it. In modern Perl, you need some kind of framework like Dancer or Mojo to fill in `$firstName` and `$lastName`. There's also the old CGI method, but there's no particular reason to learn that unless you're involved in an environment that still uses it.
Bah. Offering alternatives is for wimps. Real men just call the closest matching alternative straight away :-) See [Symbol::Approx::Sub](https://metacpan.org/pod/Symbol::Approx::Sub).
http://perl.plover.com/classes/HelpHelp/samples/slide010.html
It seems to me that there needs to be an "automatic" eval { } surrounding the whole program, which will capture the error and put it in $@. eval { foo() # $@ = Undefined subroutine &amp;main::foo() called at ... Foo::bar() # $@ = Undefined subroutine &amp;Foo::bar called at ... $foo-&gt;bar() # $@ = Can't locate object method "bar" via package "Foo" at }; exit Devel::DidYouMean::suggest($@); Although I don't know how this could be done with only "use Devel::DidYouMean;" statement.
Okay, apparently there is this thing called $SIG{\_\_DIE\_\_} = sub { my ($error) = @_; }; but I don't know if NOT local'ising it is a bad idea or not.
Thanks for the feedback. I'll make some changes and post the rest of the code when I'm home, but I'm pretty confident there's not an error there. It's mostly CGI output so I could verify in the browser that the form data was being passed. It occurred to me that this might be a permissions issue. The few lines of code I have that worked were in a different directory ('~/desktop'), where the one I'm having issues with is in the htdocs directory that xampp creates (localhost).
Actually, no. I have beginner java and C# experience and am currently in a web scripting course. It's a pretty quick overview of javascript, perl, php, xml, etc., spending a week or 2 on each. I'll be hitting up PHP next. We're using CGI for this project, so I'll be sticking with that. If I do any personal projects with perl in the future, I'll make sure to check out those other frameworks. Thanks for the input!
Thanks, I'll check that out!
...why yes, that would indeed make it literally unreadable. :p
How about a photo of what you ended up with?
that looks like a nice util do you know what this can scale to? The examples seem to reference only a handful of workers. Go has the distinction of being able to drive thousands of channels concurrently. If your process is spending a lot of time on io (eg slow network from target), it makes a lot of sense pushing many more channels than cores. Maybe MCE can handle these types of workloads -- anybody have experience ? 
I dunno, all my advice would be to simplify the program. Seems you want to add needless obfuscations to hide the intent. That code does a number of things it doesn't have to, sub p3{$_[0]&lt;($_[1]||=2)?pop:$_[0]%$_[1]?(++$_[1]&amp;&amp; &amp;p3):p3(shift()/$_[0],(pop)x2)}print p3(600851475143) Sorry im not good at this.
Instead of literal 1 and 2, use $!=!($!-$!); and $@=$!+$! respectively. You can then use !$! as 0. Use these variables as array indices. Remove unnecessary return statements. Use the conditional operator, instead of if/else.
The main body of the post doesn't seem to surprising I think if you know the basics. The question at the end and the misunderstanding in the comments are more interesting though
This whole rabbit hole is a perfect example of why having an interpreter that is too forgiving will enable a poor (or completely lacking) mental model of what is going on. I feel like (at minimum, among other things) we need a flavor/fork of Perl where warnings and strict are non-optional.
Yet another great time to use [B::Deparse](https://metacpan.org/pod/B::Deparse)! $ perl -MO=Deparse -e '$x = int a, b, c; print $x' $x = int 'a', '???', '???'; print $x; -e syntax OK $ perl -MO=Deparse -e '$x = (int a, b, c); print $x' $x = (int 'a', '???', 'c'); print $x; -e syntax OK 
 #!/usr/bin/env perl use strict; use warnings; my @lines = &lt;STDIN&gt;; for my $line (@lines) { my @read = split(/,/, $line); print $read[0], "\n"; print $read[1], "\n"; } If you have your items in a file called "genome.txt" on linux would just be $ perl read_genome.pl &lt; genome.txt AAAAGACCTAGCATCCTTCGCTCTTGCTTTTCAAAATGATTTACTCTCTC GTGGCATTATGGTGCTAACACCAGCCTTGTGATTTCACGATTACTTAGAA GCTTCCGTACATGCGCGAGATGACCACGTTAGGGTGTCATCGCGCCACAG TGGACAGTAGGAGGAACAAGTCAATCAGTCATTATGCGCGCCTTCAGGAC While this doesn't merge them or do anything like assembly yet, it reads the pieces out and gives you references you can begin to do something with. How exactly were you hoping to combine the genomes afterwards? Sorry if I missed the mark entirely, just trying to help. Edit: I realize this isn't very efficient, but it's simple and easy to understand!!
These are highly complicated algorithms that use hash table lookups of k-mers and then deconvolve the pathway. I would start with "Algorithms on Strings, Trees and Sequences" by Gusfield. It is a good introduction into these algorithms. The paper on Abyss is pretty good too. You can access the papers describing their assembler here: http://www.bcgsc.ca/platform/bioinfo/software/abyss The Allpaths paper is also good and it uses a different technique for assembly http://www.broadinstitute.org/software/allpaths-lg/blog/ 
Any translation needs to be done? You can do that with regexp, for advanced translations (that require a specific pattern to be present) you may require look ahead/behind as well in your regexp. Not sure what you want to do, other than what /u/borick said
This isn't my field exactly, but I know a guy who does something similar to this. From what I gather from listening to him, the gist of an assembly algorithm is this: 1. Split each read into *k*-mers. This just means split it into segments of length *k*. I can't remember the values of *k* that are usually used, but it depends on read length. It's a balance between any two *k*-mers being likely to be unique and the overlap between fragments (and error rate, and the size of an integer on your machine, and so on). I don't recall whether it is common for *k*-mers to overlap. 2. Determine the "similarity" between *k*-mers. This can be a hash table lookup as /u/three_martini_lunch says, but requires a "fuzzy" hash unless your sequencing machine has an incredibly low error rate. I hear good things about simply sorting the *k*-mers and pairing them consecutively. 3. If two *k*-mers align, the two reads probably align with the offsets given by the *k*-mer alignment. Sanity check by comparing the remainder of the aligned reads to account for repetitive regions. Your paired-end reads may be useful here. Here is my attempt at ASCII art (asterisks represent any old base): Reads: *********AAAGT******** ***AAGT*************** &amp;c. Sort into 3-mers: *** *** AGT AGT *** *** &amp;c. Use 3-mers as a base for aligning the reads: *********AAAGT******** ***AAGT*************** Obviously 3-mers don't work too well, as the segments are likely to occure often by chance.
To me that says an early step would be to get all the strings in their "proper" order.
**Edit: Please read /u/neverbetterthanks solution, it's better :)** Well you could use the perl [reverse](http://perldoc.perl.org/functions/reverse.html) function to reverse after reading it The syntax to use reverse, to reverse a string is kind of funny. Here's the amended program, also improved the output a bit. #!/usr/bin/env perl use strict; use warnings; my @lines = &lt;STDIN&gt;; for my $line (@lines) { chomp($line); my @read = split(/,/, $line); print $read[0]; print "-"; $_ = $read[1]; print scalar reverse, "\n"; } Output: $ perl test_genome.pl &lt; genome.txt AAAAGACCTAGCATCCTTCGCTCTTGCTTTTCAAAATGATTTACTCTCTC-AAGATTCATTAGCACTTTAGTGTTCCGACCACAATCGTGGTATTACGGTG GCTTCCGTACATGCGCGAGATGACCACGTTAGGGTGTCATCGCGCCACAG-CAGGACTTCCGCGCGTATTACTGACTAACTGAACAAGGAGGATGACAGGT How would you want to merge them, by randomly combining them? Keep in mind this approach is fine for small sets but would be too slow for very large sets. It can be optimized further, if necessary :)
[This might be enough to get you going][1], depending on your existing knowledge of perl syntax. If that is incomprehensible to you, then try [this one][2]. Examining the second one, most of that is probably fairly transparent to you if you've written in any other programming languages (A cool feature/weirdness of perl is that `&lt;&gt;` is the input operator, in this case reading the `__DATA__` segment at the bottom). The important step is `$kmers{$kmer}++`, which increments the key `$kmer` in the hash `%kmers`. Later, this is looped through (`for` is equivalent to `foreach` in perl), and all kmers with more than one entry are printed. In this case, the 12-mer "HELLO R/PERL". Caveats: I am just discarding the second read of the pair; consider using the built-in `reverse` function. Also, hashing is exact; this won't cope if read errors are common enough to occur in every kmer. Hope this helps. FWIW, everyone struggles with perl syntax at first. Then you grow to love it (Stockholm syndrome, some call it). [1]: http://pastebin.com/ftTQFyBc [2]: http://pastebin.com/SCgj5ujF
This is a much better approach, thanks for the pointer. I've updated the [repo](https://github.com/sillymoose/Devel-DidYouMean), should be on CPAN in a few minutes ...
Couple of minor problems/style issues here: * assigning to $_ is generally a code smell * using &lt;STDIN&gt; in list context like that will require that the entire file fit in memory * no need for the scalar keyword if you are using scalar context Example: use v5.12; while (my $line = &lt;STDIN&gt;) { chomp $line; my ($first, $second) = split /,/, $line; $second = reverse $second; say "$first-$second"; }
I'm doing a similar kind of project and this is what I did: 1. Sort/Fetch a list of reads which are common in both the Fwd and Rev read files. 2. Use Flash tool to merge the common reads. It would be great if you mention what kind of Libraries you don't want to use. Perl? or NCBI? anyhow, assuming Perl, 3. Classify the reads using Kraken or if you know the organism's lineage, use reference assisted assembly. or 4. Use either Denovo assembly. 5. Use aligners to check out the coverages. I'll put the scripts here, later. They are on my workstation and I'm don't have access to it currently.
Cool thanks for the improvements :) Edit: Btw, had to look [this](http://en.wikipedia.org/wiki/Code_smell) up! :D 
We sorta do. If you `use v5.12;` (or more recent) to get all the fancy new features, strict is on by default.
Hmm forgot about that. But this whole "opt-in" business is still one step too far. Consider me taking the extremist side of this war.
Did you know that "use v5.12" doesn't enable ~~"use strict" and~~ "use warnings"? Btw, the feature (in case anyone is curious) is documented [here](http://perldoc.perl.org/feature.html) (had to look it up :))
I stand corrected. This should be mentioned on the feature page! Do you think best practices is to just "use warnings" then if you are use v5.12 or would you also explicitly also "use strict" for some reason? Do you happen to have any knowledge of reasoning why "use warnings" isn't included in the feature-set? Thank you!
&gt; this whole "opt-in" business is still one step too far You're gonna love Perl6 !
&gt; You're gonna love Perl6 ! Buddy, I've been talking about steps too far! That's like six steps from now! Camels have big feet.
The modern source to learn Perl is http://modernperlbooks.com/books/modern_perl_2014/ ... available free online, but you'll want to buy a real paper or ebook version.
There is no quick path. But you can pick a fast path or a slower path. The fastest path is to pick a good book -- the old hands such as "Learning Perl" and "Programming Perl" are a bit dated by now, but the style taught there is still the majority of Perl. I have not read Perl-related books for over 10 years, so you should probably go with /u/TomDLux's suggestion. I'd say that it took me about 6 months to feel that I had a proper handle of Perl, and for many years later I was still surprised by the behaviors of the various builtins as I used. Some things you guess based on what they seem to be doing, and guessing wrong leaves you with subtle bugs that can take a long time to understand. It is a sad fact of life that virtually every built-in of Perl has some weird quirk that you just won't know about until it bites you somehow.
&gt; every built-in of Perl has some weird quirk that you just won't know about Could you give an example? Thank you!
well, it took me a while to realize that 'split "something"' actualy still parses the thing between "" as a regular expression rather than as a literal expression. In particular, split "." did not work as I expected and I groaned when I found out. Then later on I realized that split trims the empty items automatically at the end. Then I learnt that it has a 3rd argument that can take values from -1 to some number that indicate how many pieces you want, and the negative value prevents the empty value trimming. Yeah. Perl is like that.
If you are about to use a new function or haven't used it for a while it's good practice to read perldoc -f &lt;function&gt; e.g. perldoc -f split I've been programming Perl for a while (roughly since the early 90's) and still do so now and then.
Highly recommended you seek **up-to-date resources** and always keep an eye out for improvement. There is so much bad Perl and bad Perl advice out there, most of it from an age I would rather forget. Do yourself and the community a favor and learn *The Right Way* of doing things. I will make your Perl easier to write and debug.
Sure. Sometimes you just guess, and I did early on guess how split worked and thought I had it down. I guess here Perl violated the rule that it does what it *looks like it's doing*. I remember I had another battle with open() because you learn the 2-arg open with typeglob filehandles at first and then you deal with Symbol::gensym() and local *FH and all that bizarreness. Then you learn you can just do open(my ($fh), "foo") and then later on you learn the wisdom of always using the 3-arg open. Then later on you learn that if file name looks like 'cat /etc/passwd|' and you use &lt;&gt; then Perl still uses that horrible 2-arg open() ... What can I say, the road to Perl mastery is long and painful. I kind of don't like the language at all because it should be simplified for a person like me. I tend to guess, and I don't even realize I've guessed, and then I go to long bisective tangents trying to figure out where I guessed wrong. Perl is a bad fit for me because it's fundamentally highly complex and intricate in pretty much every respect.
I highly recommend this book given your specific skill set. [Minimal Perl: For Unix and Linux People](http://www.amazon.com/Minimal-Perl-Unix-Linux-People/dp/1932394508)
The other problem with guessing is that perl is the type of language that is more likely to run and do the wrong thing rather than not run at all and just error out. For example how many functions default to operating on $_ rather than default to just, you know, bitching at you for not telling it what it should be operating on. 
perldoc perlintro
We keep a curated list of tutorials here: http://perl-tutorial.org/
Yeah, but everyone knows about that. It's always explained as a special awk compatibility thing.
Recently, I fixed someone's script who had really struggled with the difference between %foo and $foo in his scripts. He'd do somefunc(\%foo) and then do sub somefunc { my $foo = shift; }, but after that used $foo{...} in the function. It was done wrong in every place. It was kind of impressive.
I haven't read it, but there's also this fairly recent book from 2009: [Automating System Administration with Perl](http://www.amazon.com/Automating-System-Administration-Perl-Efficient/dp/059600639X)
Coke.
This is exactly how I began to "move up the chain" many, many years ago! Perl is an awesome language and it flows nicely from my fingers after many years of use. This is why I subscribe to this sub. Nowadays I would honestly recommend Ruby or Python. The other answers here have some great ideas. I started by converting some of my more complex bash scripts to Perl. In fact, I was able to make a particularly complex bash script run more than 20x faster by converting to Perl. This was the main reason I started on the path in the first place! The only tip I would offer is: From the start always: use warnings; use strict; don't forget about Data::Dumper for easy debugging and learn how to use the perl debugger.
Thanks! Many of the higher-paying Linux jobs in my area require Perl. And since I already know Bash and regex I figure it shouldn't be *too* hard...
For a comprehensive introduction I would strongly recommend [Beginning Perl](http://www.wrox.com/WileyCDA/WroxTitle/Beginning-Perl.productCd-1118013840.html) or [Learning Perl](http://shop.oreilly.com/product/0636920018452.do). 
Praise Be! 
I hope Mojolicious gets ported!
Wait and see. At the moment Perl6 still feels quite unperlish to me. Let's see if this feeling changes.
Oh good grief. It's only a decade too late. 
That's the announcements? That too much hype ... 
Hey everyone, if you have any feedback on what you'd like to see in "What's New On CPAN" please post it here! For example, would you like to see a "module of the month" box in the article?
\***crosses fingers**\*
Had to learn it this year from work from a similar situation. Read the book and what ever you do do the exercises. Did I say, do the exercieses. After doing this was able to write useful scripts and made me wonder why i'd spent so long using just sed, awk and bash. 
I honestly thought this wasn't going to be mentioned until FOSDEM and that it was being saved as a surprise announcement. At the Austrian Perl Workshop, the Perl 6 people got together and asked what was blocking a production release and came up with: 1. The Great List Refactor (something they've talked about for years) * Shaped Arrays * Some Unicode work The first item is critical for some massive performance gains. Without it, there's no point in having it production ready. The second item let's you do this: my @array[5]; $array[7] = ...; # boom! That's an exception Shaped arrays allow you to predefine the "shape" of your array and if you violate that, you get an exception. Not having to reallocate your arrays can be a huge performance win and can also prevent bugs by ensuring you don't accidentally add things you didn't mean to. The Unicode work is ensuring that all strings in Perl 6 are in a pre-determined format ([Normalization Form Grapheme](https://raw.githubusercontent.com/perl6/specs/master/S15-unicode.pod)). There are other features in Perl 6 which will be delayed for later releases, but these, as I understand it, are marginal features that most won't use or care about. I find it ironic (and sad) at this point that Perl 6 might have an official release before Perl 5 gets a MOP. The above info is just what I understand the situation to be. If anyone wants to step in and correct or expand up it, please do!
Isn't Perl 5's lack of a MOP just a result of Class::MOP being "good enough"?
Steven Little is still working on getting a MOP into the core. There may be benefits to that, but personally, I tend to prefer the approach of building libraries using existing language functions.
Need to format addresses from all over the world? https://metacpan.org/pod/Geo::Address::Formatter
Absolutely not. Class::MOP shows us the power, but it's slow and cumbersome. And when I converted `Test::Class::Moose` to [test-class-mop](https://github.com/Ovid/test-class-mop), it was amazing how much easier and shorter the code was.
Is theading support complete then? It seems like last time I looked only some backends supported some things.
Perl 5 desperately needs a MOP in the core. While I love Moose and being able to (ab)use the included mop, it's syntax is still cumbersome and there's only so much you can get in the way of performance improvements. Plus, it's one of the major blockers I've heard when I've told people that Perl's better than they thought: "oh, I have to download and install an external package to have decent OO?" Many people rightly expect such a core feature to be, well, core.
[The concurrency support is there](http://blogs.perl.org/users/ovid/2014/08/try-rakudobrew-and-play-with-concurrency.html), but I'm unsure how the threading support it. In any event, threads are strongly discouraged because they're so painful and error prone. It's like writing assembler code when a high-level language would do just fine.
As parrot maintainer I can not confirm this for the parrot backend. We are still struggling with a serious GC bug with very low memory systems (256 MB RAM) or very big perl6 modules. But the jvm and esp. the moarvm backends do look fine for production.
Fair enough. I have to say, I was pretty impressed by the last build I tried. There's been huge improvements in speed and polish. Is there a plan to do any work on the web site or gather together some examples and documentation for the release? Reading specs and finding current code samples can be a bit difficult and the design of the website could use some love. 
For very small values of 'production', I am assuming. (Also, title is inaccurate since it is not 2015 yet.)
He's restarted in different repositories. Long story. But he's still on it, trust me.
I hope they didn't wait an extra 6 months for this joke. But Perl being Perl, who knows
Too late for what?
For reference's sake, I started with Perl about six months ago having previous experience with only VB, VB.net, and VBScript at a hobbyist level (I know, horrible stuff) . I'm now writing scripts that are fairly complex (network monitoring and configuration parsing/verification) and classes using Moose. A couple of tips I would give: * learn the difference between scalars, arrays and hashes (the easy part) and the differences between arrays/array references and hashes/hash references (the harder part). If your debut is going to be anything like mine, you're going to have a lot of bugs related to casting the one into the other and assigning/removing keys, values, etc. * learn how the sort function works early on - Perl stores hash keys in a (seemingly?) random order and sort fixes that for you. 
Not on my network! I wanna see a stable release first.
Wow. I never thought I'd live to see the day...
it could be harder than you think. a noob writing bash scripts tends to have little problem getting started and productive. in perl, be prepared for it to take longer. once you get past a certain pain level, all the clouds suddenly clear and you realize perl is fantastic. you should also familiarize yourself with CPAN. you will be surprised to find that most of what you think you need to write has already been written. so your programs tend to be little more than glue components. 
&gt; Looks like Perl 6 is officially ready for production! The year mentioned on the page you linked is 20*15*, not 2014! How did you manage to miss that? :( Anyone who really knows about Perl 6 knows it's much more likely @Larry means Xmas 2015, a year from now, than any other date. I think the timing of the linked talk, early next year, will be good for a call-to-arms to prepare an "officially production ready" Perl 6 by the end of 2015. Unless I hear differently from Larry Wall, that's what I'm guessing this talk will be about.
You actually think more people would've taken Perl 6 more seriously 10 years ago? Or that it would've generated more buzz? I severely doubt both.
Sure do. I certainly would have.
You missed [Mojo::Pg](https://metacpan.org/pod/Mojo::Pg) which is still marked as experimental, but some people might find very useful. This is a response to the Mojolicious community taking a step away from MongoDB. That of course left a bit of a whole in the Mojo database world, so SRI is working on a Mojo-ified Postgres interface.
Indeed. The whole essence of Perl is being practical in getting shit done. On the other hand, Perl 6 is an academic wankery fest by drunks rather than academics.
&gt; Need to format addresses from all over the world? https://metacpan.org/pod/Geo::Address::Formatter Added to the article, thank you for posting
This link works
1) Why do you need to copy the files to a ramdisk? 2) Why bring mod_perl into the picture at all if it's only used to copy files when Apache starts? Why not just add the `cp ...` to the init.d script?
I just tried out the WebService::HackerNews module (featured in OP's link), and I thought it was really neat as a quick don't-want-to-leave-tmux-but-what's-happening-on-HN distraction (though that may prove to be a bad thing). I did have to install IO::Socket::SSL (not included as dependency) and use utf8::all (though declaring stdout with binmode 'utf8' would have worked as well). Test script (mostly from the example on metacpan): use utf8::all; use strict; use WebService::HackerNews; my $hn = WebService::HackerNews-&gt;new; my @top10 = $hn-&gt;top_story_ids; @top10 = @top10[0 .. 9]; my @items = map {$hn-&gt;item($_)} @top10; my @titles = map {$_-&gt;title} @items; my @users = map {$hn-&gt;user($_-&gt;by)} @items; my @names = map {$_-&gt;by} @items; my @karmas = map {$_-&gt;karma} @users; for (my $i = 0; $i&lt;$#items; $i++){ printf qq{"%s" by %s (karma: %d)\n}, $titles[$i], $names[$i], $karmas[$i]; } 
&gt; Test script (mostly from the example on metacpan): Nice, thanks for sharing
How often do you copy an array and leave both copies around unmodified? How often do you do it leaving *more* than two copies? COW adds a cost to string operations, but it's a cost that pays off because strings end up being copied around a lot. If you want to COW anything else, I would start by collecting evidence that it would actually kick in enough, and have enough benefit, to justify slowing down all modification and destruction of that type.
And everyone knows that silver is a more precious metal than "white". :-P
Woohoo, congrats!
A better way to do this would be to have the checker run only when the files are modified. Not sure how that is accomplished in general Unix land, but sbt and I believe node have something like that.
&gt; It runs any code in BEGIN, UNITCHECK, and CHECK blocks Hey thanks for pointing this out, this is good to know. I've updated the article.
I would say that the update doesn't go far enough. Examine this case: The file Foo.pm package Foo; use strict; use warnings; print "I could have said rm -rf $ENV{HOME}\n"; 1; The script t.pl #!/usr/bin/perl use strict; use warnings; use lib "."; use Foo; And the command `perl -c t.pl`: I could have said rm -rf /home/cowens c.pl syntax OK You can't see the `BEGIN` block, but it is there (hidden as a `use` statement).
Use [PDF::Reuse](https://metacpan.org/pod/PDF::Reuse). &gt; prField - assign a value to an interactive field &gt; prField ( $fieldName, $value ) &gt; $fieldName is an interactive field in the document you are creating. 
To approach to such, I like to use a standardized formatting, stock commenting, function composition, self-commenting code through aliasing, left-column flow control, and one-step-only coding. Your code would document like this: **(IT'S A MOCKUP, i DIDN'T TEST IT!)** ------- ### purpose: handle some html decoding ### input: reference to the json hash ### notes: ### I used tab=2 and paired-level-braces ### Also, I like putting spaces in most groupings; it's easier on my eyes... ### 'topicalizing' turns the for-block into a switch statement ### take care that it is the only process touching the $_ variable though ### hash slicing can too be good for self-documenting ### output: ### a trace of the run, AND a reference to the closure ### call tree: ### warnuser ### decode_entities my %YTID; ### closure our $do_a_thing = sub { ### setup my( $decjson, $karmafloor ) = @_; ####### input my $regex_youtube = '(?i)(?:youtube[.]com)'; my $regex_mini = '(?i)(?:youtu[.]be)'; my $regex_other = '(?i)(?:soundcloud[.]com)'; my $regex_fromyoutube = '(?i)(?:v[=]([\w-]+))'; my $regex_frommini = '(?i)(?:youtu[.]be[/]([\w-]+)$)'; my @slice = qw( ups downs domain url title ); ### do stuff my @choices; my $counter = 0; for my $hash ( @{ $decjson-&gt;{data}-&gt;{children} } ) { my( $dataups, $datadowns, $datadomain, $dataurl, $datatitle ) = @{ $hash-&gt;{data} }{@slice}; my $is_skip = ( $dataups - $datadowns &lt; $karmafloor ); my $is_youtube = ( $datadomain =~ m/$regex_youtube/ ); my $is_mini = ( $datadomain =~ m/$regex_mini/ ); my $is_soundcloud = ( $datadomain =~ m/$regex_other/ ); for( $is_skip, $is_youtube, $is_mini, $is_soundcloud ) ### topicalize { if( m/$is_skip/ ) { last; } if( m/$is_youtube/ ) { push( @choices, 1 ); my( $id ) = ( $dataurl =~ m/$regex_fromyoutube/ ); if( not $id ) { &amp;warnuser( $dataurl, 'not from youtube' ); next; } ####### output: stderr $YTID{$id} = decode_entities( $datatitle ); ####### output: closure last; } if( m/$is_mini/ ) { push( @choices, 2 ); my( $id ) = ( $dataurl =~ m/$regex_frommini/ ); if( not $id ) { &amp;warnuser( $dataurl, 'not from youtube' ); next; } ####### output: stderr $YTID{$id} = decode_entities( $datatitle ); ####### output: closure last; } if( m/$is_soundcloud/ ) { push( @choices, 3 ); $YTID{ "SC_$counter" } = $dataurl; ####### output: closure $counter ++; last; } } } return( \@choices, \%YTID ); ####### output }; ------- EDIT: When the activity gets bigger than this, I reduce the mental-overload by functionalizing discrete bits and composing them. This keeps the namespaces separate, and reduces the amount of "cerebral stacking". **So function F_too_huge_to_comprehend would become**: sub F_do_complex_behavior { ### setup my $setup = &amp;F0_do_some_setup_stuff( @_ ); ####### input ### do my( $setup, %outhash ) = &amp;F1_use_setup_stuff_in_some_specific_way( $setup ); my( $setup, %outhash ) = &amp;F2_use_setup_stuff_in_some_other_way( $setup, %outhash ) my( $setup, %outhash ) = &amp;F3_correlate_outputs_and_add_indexes_or_something( $setup, %outhash ); my $output = $outhash{3}; return( $output ); ####### output } **or composed** sub F_do_complex_behavior { return @{ &amp;F3_correlate_outputs_and_add_indexes_or_something ( &amp;F2_use_setup_stuff_in_some_other_way ( &amp;F1_use_setup_stuff_in_some_specific_way ( &amp;F0_do_some_setup_stuff( @_ ) ####### input ) ) ) }{qw( 3 )}; ####### output } **and then the whole reads like a sentence.** -------
And it is things like this that still make Perl a thing. I'm guessing OP is now going to go and automate boilerplate fill-in for thousands of required forms without having to muck around with the inner workings of PDF files or change some kind of fragile business process. The script might take a day or two to perfect and save a ton of money. At least, that's what I hope will happen here...
the vim check doesn't take advantage of vim's built-in compiler support. just set the compiler to perl and run make.
How about posting the code?
`inotifywait(1)` is one way.
I was going to post `flycheck-mode`. It's pretty rad.
How would I know what the $fieldName is? thanks
&gt; just set the compiler to perl and run make. Great tip! Added an example to the article.
PerlySense does this too, but using Flymake. I've been meaning to change that to use Flycheck for some time (but, no tuits). http://search.cpan.org/dist/Devel-PerlySense/lib/Devel/PerlySense.pm#Displaying_Code Importantly, when you're dealing with things other than just a simple .pl script, PerlySense will set up the @INC properly with all the required include libs, so checking lib/My/Module.pm also works nicely. This can also be set up to highlight Perl::Critic violations. I find both incredibly useful.
 Nice. Perly looks worth the time to learn if you have some big projects to deal with.
This looks like it is for creating PDFs with values in the form fields. The OP is asking for something that can take a third-party PDF and automate filling in the interactive form fields. Maybe there is a way to read in a PDF, get a list of all the interactive form fields, set their values and then export a new PDF with them filled in. 
If you have the full version of Acrobat you could edit the forms to see the form field names. Or, perhaps the PDF::Reuse module can read in a PDF and then list all the form fields by name. EDIT: I did some googling and found CAM::PDF http://search.cpan.org/dist/CAM-PDF/lib/CAM/PDF.pm#API This API function might be just the ticket. $self-&gt;getFormFieldList()
Not sure about job-finding, I'm sure that there are pure-perl posts out there, but mostly I use it as part of being a sysadmin. Take a look at perlmonks.org for question/answer/advice on perl programming though. [The newest nodes list](http://www.perlmonks.org/?node=Newest%20Nodes) is a good place to browse.
Okay I will look there. Thank you! 
"Inexpensive" should not be on the front page. It would be better to attract enterprises, who are willing to foot the bill, by charging more and not listing the price right away. Then elsewhere, just say, oh, individual tickets are $250. Marketing, people!
I have tried that place. They have only had one job posting where I live in the last month. :( but thanks for the tip. 
A lot of people come to YAPC on their own power. The price has gone up substantially in the past couple years in an attempt to market up (and to improve the actual quality of the conference) but let's not do those people a disservice by convincing them that it's a corporate event that they can't afford to go to.
I programmed games in high school years ago in Qbasic. I learned C++ a little with one year of computer science and I made bubble gum websites with html and a hair of JavaScript in the late 90s. I am not completely new to programming. Oh and I made minor applications with Visual Basic also in the 90s. I regret not pursuing a career earlier but I am here now trying to get back into it. I have been teaching myself Perl and watching YouTube to learn how to use github. I just feel lost and not sure how to proceed. 
It's an illusion. Keep the individual price at whatever. Just don't walk around going LOOK HOW CHEAP WE ARE. It's not a good message.
[pdftk](https://www.pdflabs.com/tools/pdftk-the-pdf-toolkit/) is a pretty great utility for all things PDF and forms. "dump_data_fields" would be the appropriate option, or you might even use "generate_fdf" to create something that you can then use with one of the Perl FDF modules. I did most of my FDF/PDF processing in Java or Python, but [this overview](http://redgoose.ca/blog/perl-and-pre-filled-pdfs) might come in handy for picking from the plethora of CPAN modules.
that's the place to look for perl jobs, so just keep looking. if there are no jobs on there, well, there are probably no jobs where you live
You already said the Perl jobs site only had one listing for you. Consider that you might need more than one job to apply to. And just look at the salaries for different programmers. Perl, not exactly a winner. If salary is important to you.
&gt; I'm still working on figuring out what the namespace should be, and what the final name would be. I'm attached to the name 'tel' because I've been using it for 14 years, How about App::tel? You could still type tel at the command line to run the script.
Okay thank you. 
What programming language would you recommend me learning and why? 
Can somebody who has no programming experience get a position like that? 
Probably Python or Ruby. Maybe Java. Maybe Scala, wink wink. Or even stick with some front end stuff for now. Python and Ruby suffer from the same (ideological) problems I have with Perl, but I think the market is much more fruitful. There are more job offerings and more resources and more peers who are using Python. Java I don't like on nerd reasons, but it is very popular. So if a career is what you are after, familiarity with the JVM is not a bad idea. There's also C# and that whole Microsoft family. C# is not bad. You should do what you need to do to be successful. And picking a language environment that is lush and full of opportunity is important, I would think. Otherwise we would all be LISPers.
Oh because I have seen ads in other cities for programming with no knowledge needed, they will train you. Do you think those jobs are scams? 
I am noticing from job ads that it might be best to learn multiple languages. Wow I have a lot to learn! 
Yes, software isn't exactly everyone's cup of tea; there's a lot to learn, if you want to be an effective hire. In my opinion, you are "behind". There's an entire market of people who are more experienced than you. And you can't wait for on the job training. I think that, like many successful programmers, you have to train yourself, off hours, for free. Hopefully it would be fueled by passion for the field but this is what it takes to be competitive. So, for real. Spend less time thinking and planning and spend more time learning and applying and solving problems, contrived or otherwise. No magical answer will be a substitute for putting the time in.
Okay I will do this. Thank you. 
If you are really interested in Perl ... contact me on eng.bashir@gmail.com . I think I may help you in finding one where you may learn and work. PS, I'm neither an employer nor a recruiter :) I'm a software developer.
What smueller1234 said,... it is still happening (dig around my github repos to see) but I have nothing yet ready to share/discuss/test and currently have a lot of non-OSS responsibilities demanding my time. 
Depends how much fun you want to have with it. http://en.wikipedia.org/wiki/Evolutionary_algorithm In this case the chromosomes you are working with would be arrays of length 5 [a,b,c,d,e] and the fitness function would be how far off it is using those constants to evaluate your known answers. Fitness closer to zero is desired so you take all the ones that have fitness lower than some threshold and breed them using whatever technique you like. Crossover would be easy. Mutate them a little, randomly bump values up or down a little bit very infrequently. Repeat until the fitness of one chromosome is low enough to be within some acceptable range and stop. http://www.perlmonks.org/?node_id=298877 for perl specifically. http://en.wikipedia.org/wiki/Artificial_neural_network You could use a neural network with 5 input nodes and 1 output node. Those are fun too. http://search.cpan.org/~ovid/AI-NeuralNet-Simple-0.11/lib/AI/NeuralNet/Simple.pm You could also look into discrete optimization http://en.wikipedia.org/wiki/Discrete_optimization Lots of techniques in that field that are meant for this kind of thing.
Just out of curiosity, what makes you think chromosomes? 
Thats just the terminology I am familiar with. A potential solution is an individual, the individual is made up of one or more chromosomes depending on how complicated the problem space is. Each chromosome is made up of genes, which are atomic units in the question. In this case a gene would be one of the constants and a chromosome would be a list of however many we need. I have a soft spot for genetic algorithms, I used them in my undergrad to win a few AI game playing competitions where the game was very similar to the problem being presented here. So whenever I see ax+bx+cx=k I have fond memories of my old lisp genetic algorithm code. There are a ton of ways to do this problem though, and this certainly isn't the "best", just in my opinion the most fun :)
this is a class of math which aims to do a "best fit" of parameters to a specific equation. what you need to add to your problem is a "cost" function -- which is a fancy way of saying how big your error is when your data points deviate from your function calculated using your estimates for (a,b,c,...). Often it is a square function (i.e. the sum of (yreal-yest)^2 (where yest is the y=f(x) calculated for your best guess) at each data point. But it can be different, depending on the nature of your problem (eg abs(yreal-yest)*weight which lets you add weights to each point. The weight could be a function of x itself, or number of data points or the phase of the moon or whatever ). Most algorithms you will find will however assume only on the sum of the squares as the cost function (sometimes knows as least-squares). I like to use the Simplex or Expectation Maximization libs because they let me write *any* cost function. It can be as funky and non-linear as you like. They also don't tie you down to a linear f(x), so you can try to fit functions such as f(x)=a + b*x + c*x^2 + d/x if you are willing. IMHO the cost function is the most important part of what you are doing, and you need to understand your problem well before you can settle on the right one. the two i mention have their downsides, particularly with "local minima" .. i.e. where the algorithm gets stuck in a ditch (even though there is a deeper better ditch somewhere else). but your function is awfully simple, so you will be fine. the way they work is they try to reach the bottom of a hill by sampling alternative points near where your current estimate is. how they pick these points is the gem of each method, the better ones will reach the bottom efficiently and not get stuck in the wrong spot. There are many many algorithms out there, each good for a specific type of problem. now, actually i think you mean to fit y = f(x1,x2,x3,..) = a*x1 + b*x2 + c*x3 + ... the following two will be more than good enough for this type of prob: * Math::Evol * PDL::Opt::Simplex Another (faster but simpler) one is Math::Amoeba 
I'm in a bit of a hurry, but it seems like you are looking for [the method of least squares](http://en.wikipedia.org/wiki/Least_squares) In your case you should probably fill a matrix A with the x from the input. So if your first input is f(1) = 1 the first row of your matrix is [1,1,1,1,1]. Your output data goes in the Vector b. The best approximation for a..e for your data is now the vector y so that A^T * A * y = A^T * b (Gaussian normal equatiotion). I bet there is a cpan module that solves this for you, but it's also not really hard to implement. For example via [QR-Factorization](http://www.seas.ucla.edu/~vandenbe/103/lectures/qr.pdf). But as /u/StealthyC suggests, evolutionary algorithms are probably more fun.. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Least squares**](https://en.wikipedia.org/wiki/Least%20squares): [](#sfw) --- &gt; &gt;The method of __least squares__ is a standard approach to the approximate solution of [overdetermined systems](https://en.wikipedia.org/wiki/Overdetermined_system), i.e., sets of equations in which there are more equations than unknowns. "Least squares" means that the overall solution minimizes the sum of the squares of the errors made in the results of every single equation. &gt;The most important application is in [data fitting](https://en.wikipedia.org/wiki/Curve_fitting). The best fit in the least-squares sense minimizes the sum of squared [residuals](https://en.wikipedia.org/wiki/Errors_and_residuals_in_statistics), a residual being the difference between an observed value and the fitted value provided by a model. When the problem has substantial uncertainties in the [independent variable](https://en.wikipedia.org/wiki/Independent_variable) (the 'x' variable), then simple regression and least squares methods have problems; in such cases, the methodology required for fitting [errors-in-variables models](https://en.wikipedia.org/wiki/Errors-in-variables_models) may be considered instead of that for least squares. &gt;Least squares problems fall into two categories: linear or [ordinary least squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) and [non-linear least squares](https://en.wikipedia.org/wiki/Non-linear_least_squares), depending on whether or not the residuals are linear in all unknowns. The linear least-squares problem occurs in statistical [regression analysis](https://en.wikipedia.org/wiki/Regression_analysis); it has a closed-form solution. A closed-form solution (or [closed-form expression](https://en.wikipedia.org/wiki/Closed-form_expression)) is any formula that can be evaluated in a finite number of standard operations. The non-linear problem has no closed-form solution and is usually solved by iterative refinement; at each iteration the system is approximated by a linear one, and thus the core calculation is similar in both cases. &gt;When the observations come from an [exponential family](https://en.wikipedia.org/wiki/Exponential_family) and mild conditions are satisfied, least-squares estimates and [maximum-likelihood](https://en.wikipedia.org/wiki/Maximum_likelihood) estimates are identical. The method of least squares can also be derived as a [method of moments](https://en.wikipedia.org/wiki/Method_of_moments_(statistics\)) estimator. &gt;The following discussion is mostly presented in terms of [linear](https://en.wikipedia.org/wiki/Linear) functions but the use of least-squares is valid and practical for more general families of functions. Also, by iteratively applying local quadratic approximation to the likelihood (through the [Fisher information](https://en.wikipedia.org/wiki/Fisher_information)), the least-squares method may be used to fit a [generalized linear model](https://en.wikipedia.org/wiki/Generalized_linear_model). &gt;For the topic of approximating a function by a sum of others using an objective function based on squared distances, see [least squares (function approximation)](https://en.wikipedia.org/wiki/Least_squares_(function_approximation\)). &gt;The least-squares method is usually credited to [Carl Friedrich Gauss](https://en.wikipedia.org/wiki/Carl_Friedrich_Gauss) (1795), but it was first published by [Adrien-Marie Legendre](https://en.wikipedia.org/wiki/Adrien-Marie_Legendre). &gt;==== &gt;[**Image from article**](https://i.imgur.com/sbRIpQf.png) [^(i)](https://commons.wikimedia.org/wiki/File:Linear_regression.svg) --- ^Interesting: [^Ordinary ^least ^squares](https://en.wikipedia.org/wiki/Ordinary_least_squares) ^| [^Linear ^least ^squares ^\(mathematics)](https://en.wikipedia.org/wiki/Linear_least_squares_\(mathematics\)) ^| [^Generalized ^least ^squares](https://en.wikipedia.org/wiki/Generalized_least_squares) ^| [^Iteratively ^reweighted ^least ^squares](https://en.wikipedia.org/wiki/Iteratively_reweighted_least_squares) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cm1bu9s) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cm1bu9s)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
i should add that your data set needs to fit into memory if it is too big, then you need to look for something that can deal with big data without having to suck the set into its program space. For a linear model (that's your equation), and if you can accept a least-squares cost function, you may want to try out Vowpal Wabbit -- its written in C, not quite Perl, but you drive it with some simple commands from a bash script ... which technically you can use Perl as a wrapper. It has the distinction of being blazingly fast, can run "out of memory", and can run in a distributed fashion (if your data set is spread over multiple machines, you can run an instance of the exe on each machine and they magically combine the results into one final answer -- map/reduce for the masses). 
You and I should hang out some time! I'm currently writing a genetic algorithms library in Scala!
Hey I'm converting a bunch of Perl 5 one liners to Perl 6. Made some progress already. Feel free to pitch in and contribute!
I have about 1200 data points and I can get much more. How much would you say is adequate? Thanks.
Thanks. I tried /r/mathematics, but got nothing back. I didn't know about /r/math.
what a great idea! Very interested to see the ultimate outcome. Have you thought about compiling Rakudo ...
Actually f(x)=a + b*x + c*x^2 + d/x is a linear fitting problem (it's linear in [a,b,c,d])
Cool! I'm currently a Bio undergrad taking Genetic Analysis - I'm just starting to look into bioperl and what not
thanks. This is for fun. I hope I can get close though.
The outcome is mostly fine. There was a test failure with autodie and utime, but I think that's due to NTFS oddities. Ditto with a test failure with File::Copy. I got sidetracked by buggy tests in other CPAN modules I was installing as dependencies though. For example, http://blog.nu42.com/2014/11/youve-gotta-quotemeta.html and http://blog.nu42.com/2014/11/tests-should-not-fail-due-to-eol.html I haven't touched Rakudo in a long time, but if I can, I will try that out as well.
not quite ... the parameters dont govern it ... it's the x's that matter (i.e. the shape of f(x) ) the terms x^2 and 1/x makes it nonlinear try plotting either of those ... and you will see why there is a curve involved
It is nonlinear in x. But that's not what is meant by "nonlinear curve fitting" -- your example is linear in the fitting parameters a,b,c,d, and the least squares solution can be found exactly in one step. A nonlinear fitting problem would be a model like f(x) = ax/(b+x) or something where df/d[a,b] is not independent of [a,b]. These may help: https://en.wikipedia.org/wiki/Curve_fitting and https://en.wikipedia.org/wiki/Nonlinear_regression
+1
sorry i'm confused with your example. I agree ax/(b+x) is nonlinear, but let X=b+x ax/(b+x) = a(X-b)/X = a - (b/a)/X ~ A + B/X by your argument, A+B/X is linear. A+B/X is not a linear combination of the vector X. It is however a linear combination of the vector (1/X). You may now be tempted to try to transform your X values by inverting it (i.e. let W=1/X and now you have A+B*W which looks very linear). However, your least-squares errors are no longer representative of what they originally tried to measure. Your cost function now turns into a pile of bollocks. the article https://en.wikipedia.org/wiki/Non-linear_least_squares describes this problem with a x-&gt;log(x) transformation about halfway down. 
There used to be slashcode, but the only site I can find that still uses and updates it is this: https://github.com/SoylentNews/slashcode 
Act? London.pm? blogs.perl.org? (I haven't actually checked these but I think they're open source).
Okay so we have the vectors **x** = [1, 2, 10] and **y** = [3, 2, 0.2] and we want to fit a function f(x) = a + b/x to this data via minimising the sum of squares of residuals (least squares). The parameter vector is therefore **p** = [a, b]. We write the [design matrix](https://en.wikipedia.org/wiki/Linear_regression#Introduction_to_linear_regression) as **X** = 1 | 1/1 -|--- 1 | 1/2 1 | 1/10 i.e. the columns are ones, and 1/x, as those are the coefficients of our parameters in our equation to fit. The problem can now be stated as minimising S(**p**) = ||**y** - **X** **p**||^2 which just the matrix way of writing the sum of squares for a function linear in the parameters **p**. This "cost function" has a minimum where dS/d**p** == **0** -- which if you do some algebra, is where **X**^T **X** **p** = **X**^T **y** this is a straightforward linear algebra problem to solve, and in this case gives the solution **p** = [a, b] = [0.09836, 3.06557] with a sum of squares of residuals of r = 0.2049180 and this is the exact answer, no estimate (note it is better than the application of a nonlinear method). Of course this is stricly a __least squares__ data fit for the function f(x) which is **linear** in the fitting parameters. It does not matter that the function is not linear in x. I suggest you have a look at an undergraduate maths for scientists textbook if you really haven't seen this before.
Thanks Act added. I can't find the source of London.pm and as far as I understand blogs.perl.org runs on the non-open source versions of Movable Type https://github.com/blogs-perl-org/blogs.perl.org
both added thanks.
Thanks for that. If I am not mistaken the code http://slashdot.org/ uses is still based on the Slashcode but it is now closed source, right?
The current list is here: http://perlmaven.com/web-sites-powered-by-perl-with-open-source-code-base Keep the suggestions coming!
Just 30 or so one liners left to convert
That seems acceptable. I don't know what the limitations of a custom runtime are, but it seems like being able to specify what you need with a dockerfile is the better solution, rather than having a limited set of modules supported by the base system.
www.perldancer.org, source is on GitHub :-) 
http://www.krang.net/using-krang.html
excellent, thanks. it looks like this method can be used for any cost function where you can solve dS/dp = 0 ? 
Yeah. I don't think it ever ran exactly the open-source version of Slash, just like reddit doesn't run exactly the open-source version of reddit, but they're related.
This turns out to be a relatively difficult parsing question. Are you doing this "for the challenge" or do you want to get stuff done? If the latter, try https://metacpan.org/pod/Text::Balanced#extract_variable or https://metacpan.org/pod/PPI
\b means a boundary between a word and non-word character, and "$var###" does have such a boundary after the "r". You probably want to anchor your regexp with /\^...$/; otherwise you're matching any string that *contains* a variable name (which $var### does). Also: * Your regexp doesn't match "$x"; you probably want a \* instead of a + after the \w. * There's no reason to parenthesise the (\w) (unless you *want* $2 to contain the last character of the name). * You can put the _ inside your character class instead of using | for alternation. * The first \b is pointless, because there's always a boundary between the non-word character $ and the word character than begins the variable name. * **Edit**: As joelberger points out, this matches only the simplest cases of scalar variable names, and excludes package qualifiers, the ${foo} syntax, variable names starting with a control character, punctuation variables, etc.
Yup, got it this works perfectly thanks for the help! Also yeah I realized the * error as soon as I posted, figured it was irrelevant to the question though. 
We must go deeper
You would probably need to support ${var} as well.
Stuff I run: * http://irclog.perlgeek.de/ project website on http://moritz.faui2k3.org/en/ilbot (lists other running instances), code on https://github.com/moritz/ilbot/ * http://konzertgeek.de/ (German only), code on https://github.com/moritz/soonish-p5 Both are actively maintained, but seldom enhanced (mostly feature complete)
The DuckDuckGo community platform I once made (https://duck.co/ code at https://github.com/duckduckgo/community-platform). I don't work there anymore, but this codebase I use for several other projects, too. Comment concept, Multiuser Blog, Moderation, custom data types, anything in there. If you have questions, I can help (as long as you reference to commit data before January 2014 ;) thats where I left).
The Perl NOC has a bunch of it's sites on github: https://github.com/perlorg/perlweb (check the lib/ subdir)
Perlmonks http://www.perlmonks.org/?node_id=318123
thegamecrafter.com is 100% Perl, and it runs on Wing: https://github.com/plainblack/Wing Wing is just the core (user management, workflow, web services), all TGC specific code is closed.
Thanks, but the links on that node to everydevel seem to be dead. Do you have a link to the actual source code?
AFAIK it is not any more. The site seems to say: "Do you want to try it" "Just buy here".... Unless you can point me to the source code.
I'll add this, though I am mostly interested in sites where people can come and contribute to the source code or learn how it is done. BTW http://www.wingapi.com/ linked from the GitHub pages is not responding.
It's all on github. https://github.com/movabletype/movabletype They just don't put it under the GPL anymore, is my understanding, but it's not like GPL is the be-all end-all of open source. You can see that there are many recent commits.
Short answer, Visual Namespacing supports readability. There's this joke "Real Programmer" rule from way back about "Strong typing is for weak minds, which is fine for trivial cases, but doesn't scale.
Using references doesn't mean you're not still using arrays and hashes. The examples you gave are only the tip of the iceberg. Consider also things like: push @{$foo-&gt;{bar}}, "..."; for( keys @{$foo-&gt;[42]} ) { ... } while( my ($k, $v) = each %{$foo-&gt;{bar}{baz} ) { ... } ...and so on. There's no getting around the fact that you have to deal with those hashes/arrays at the end of the references, and `%` and `@` are essential for that. This is not an either-or situation. 
The answer is history. Perl 4 did not have means to take references, but it had @ and %. Historical compatibility appears to have forced those sigils' preservation. If I have understood it correctly, Perl6 will actually require use of @ when referencing an array but it works like a reference otherwise.
Among the reasons already posted... Inline lists of primitives are immutable and are not at risk of being modified, while explicit references are. (1, 2, 3) # pass by value, can't modify $numbers # named pass by reference, can modify \[1, 2, 3] # caller does not care about modification
I could not live without hashes and arrays; hashrefs and arrayrefs are not the same. List context or scalar context is also very useful. Consider for example named arguments with pre-defined defaults. Or return values where not all values matter all the time. Depending in which context it is called, you can return a list (not a reference) or a scalar (which can be a reference). sub doSomething { my %args = ( # defaults are defined here... amount =&gt; 42, foo =&gt; 'bar', @_, # the passed arguments, if any, in key/value pairs ); my ($result, $error); # do something ... # .... # depending on the context, return a list, or a scalar. return wantarray ? ($result, $error) : $result; } # call with default values amount=42 and foo='bar', we don't care about any error here... my $result1 = doSomething(); # the result is in scalar context. $error is not returned. my ($result2) = doSomething(); # same but now in list context. $error is returned but discarded # with overridden amount, default value for foo, and we care about errors my ($result3, $error) = doSomething( amount =&gt; 1138 ); if ($error) { warn('there was an error : ' . $error); } my %arguments = ( boo =&gt; 'baz', amount =&gt; 12, ); my $result4 = doSomething(%arguments); 
&gt; is there some more elegant way to get [the number of elements in an array]? Short answer: no. But you could abstract it away: sub array_count($) { my $aref = shift; croak "argument is not an array reference" unless ref $aref eq ref []; return scalar @$aref; } If you don't care about elegance, you can avoid the @ sigil in a number of ways: my $count = $#$aref + 1; #adjust 1 if you have modified $[ my $count = (keys $aref)[-1] + 1; #again, adjust for $[ my $count = keys $aref; my $count =()= keys $aref; my $count = values $aref; my $count =()= values $aref; &gt; is there some more elegant way to get [an array slice]? Short answer: no. But it has already been abstracted away for contiguous slices by the [`splice`](http://perldoc.perl.org/functions/splice.html) function: my $sub_aref = [ splice $aref, 0, 2 ]; #same as [ @{$aref}[0, 1] ]; But beware of the third argument (it is the length, not the last index). Again, it is fairly trivial to abstract the use of the @ sigil away completely: sub array_slice { my $aref = shift; croak "argument is not an array reference" unless ref $aref eq ref []; croak "there are no indices" unless @_; return @{$aref}[@_]; } I can't think of any good way to avoid the @ sigil for slices except for the `splice` case above, but that doesn't handle non-contiguous array slices. &gt; Why we need @ and % if we can use $ref instead， what are @ and % good at ? Well, @ provides a way to get a hash slice: my %hash; @hash{qw/ a b c d /} = (1) x 4; They are necessary for backwards compatibility (if i were inventing a language from whole cloth, I would think more carefully about their use). They provide a quick visual cue as to what will be returned: $ one item, @ multiple items, and % a world of hurt (unless assigning to another hash). Non-reference arrays and hashes are also more convenient to work with (they don't need the first -&gt; operator, they are in a different name space, they work in older versions of Perl, etc.). Basically, if Perl were a different language, then, yes, sigils may not make sense, but since Perl is Perl they do. Edit: If you are using a new enough version of Perl (5.20 and later I believe), you can use an experimental feature that might make your life better as a reference-only user: postfix dereferencing. It gives you elegant ways of dereferencing and getting slices from array and hash refs: #!/usr/bin/perl use v5.20; use warnings; use feature qw/postderef/; no warnings qw(experimental::postderef); use Data::Dumper; my $aref = [ qw/ a b c d / ]; my $c = undef() + 5; say $aref-&gt;@[0 .. 2]; #abc my $href = {}; $href-&gt;@{ $aref-&gt;@* } = (1) x 4; say Dumper $href; This is particularly helpful when you have an array of arrays of arrays or other deeply nested data structure: my $aref = [ [ [ qw/ a b c d / ] ] ]; say $aref-&gt;[0][0]-&gt;@[0 .. 2]; #prints "abc\n"; vs say @{$aref-&gt;[0][0]}[0 .. 2];
There seems to be some speed differences between array/hash lookups and array-ref/hash-refs lookups, at least on my machine: use strict; use warnings FATAL =&gt; 'all'; use Benchmark qw|cmpthese|; my $ITERATIONS = 5_000_000; my $scalar = 4; my @array = 0 .. 9; my %hash = (a =&gt; 1, b =&gt; 2, c =&gt; 3, 4 =&gt; 'd', e =&gt; 5); my $array_ref = [0 .. 9]; my $hash_ref = { a =&gt; 1, b =&gt; 2, c =&gt; 3, 4 =&gt; 'd', e =&gt; 5 }; cmpthese $ITERATIONS, { 'scalar-lookup' =&gt; sub { $scalar }, 'array-lookup' =&gt; sub { $array[$scalar] }, 'hash-lookup' =&gt; sub { $hash{$scalar} }, 'array-ref-lookup' =&gt; sub { $array_ref-&gt;[$scalar] }, 'hash-reF-lookup' =&gt; sub { $hash_ref-&gt;{$scalar} }, 'array-last-index' =&gt; sub { $#array }, 'array-ref-last-index' =&gt; sub { $#$array_ref }, }; 
return value depend on context is cool,I have never think about this, thx
&gt; my $sub_aref = [ splice $aref, 0, 2 ]; This will modify $aref my $aref = [0,1,2,3,4,5,6]; my $sub_aref = [ splice $aref, 0, 2 ]; say @$aref ; # 23456
@ and % have their uses, but I agree with you, I much prefer using hashrefs and arrayrefs for consistency. Nothing wrong with what you're doing.
Can you elaborate on this? I didn't know about this.
My own rule is to use a plain array or hash if I'll end up taking a reference to it zero times or one time, and a reference otherwise. Sometimes you can have the best of both worlds by storing a reference to a lexical array or hash in some other structure, eg: my %params = ( hash =&gt; \my %hash, array =&gt; \my @array, ); $hash{foo} = 1; push @array, 'bar'; 
MusicBrainz
http://perldoc.perl.org/5.14.0/perldelta.html#Syntactical-Enhancements
It's not really that cool. It enables action at a distance and makes for less predictable code.
Interesting, because I'd like to find variables in each subroutine (including main) which are no longer used in code. Is there such a module? Or code? 
Perlmonks.org is mostly code.
&gt; Install Nagios yep
Probably worth pointing out you can just install the exact same version of Perl6 on MoarVM for windows using the following .MSI without needing to go to all this effort! http://rakudo.org/downloads/star/rakudo-star-2014.09-moar.msi
Nagios or other proper monitoring solutions are the right way to do this. But in terms of better-but-still-wrong ways.. You don't even really need perl, you just need to change how your shellscript works. Do not paste the values into the appropriate fields. Something like.. SAMBACONNECTION=`lsof -i :445 | grep ESTABLISHED | wc -l SSHCONNECTION=`lsof -i :445 | grep ESTABLISHED | wc -l` but save the printing for the end. At the end, you would print with: echo "${SSHCONNECTION},${SAMBACONNECTION}" with every variable you just set with a comma between it. Save your script somewhere in $PATH, I'll pretend you named it dumpstats.sh and made sure its executable. Then from your personal workstation make sure you have your ~/.ssh/config set up for passwordless auth. Then you'd just do something like for host in "dev1 dev2 db1 db2 www1 backups";do ssh $host dumpstats.sh;done You now have a complete CSV file you can paste right into excel. What you won't have is any useful graphing, any useful notification of anomalous reports, or..much of anything, which is why you want to install some real monitoring software. 
Hi Sinan, It's great to see you take a look at a current Rakudo. :) Perhaps you are thinking of contributing (by testing, documenting, coding, etc.). May I suggest a focus on Unicode support? My guess is that the next stage in NFG support, a key element in P6's radical grapheme-by-default approach to Unicode, will land by February. I think you could help drive P6 and Rakudo forward by focusing on Turkish text I/O and manipulation. &gt; right on track for a release real soon. I'm concerned you may have the wrong impression about what will happen when. Please consider visiting [the freenode IRC channel #perl6](https://kiwiirc.com/client/irc.freenode.net/perl6) sooner rather than later to say hi and ask about this. And/or see [my recent comment about this at PerlMonks](http://perlmonks.org/?node_id=1106772).
["Pardon me, I couldn't help but overhear... "](http://wondermark.com/1k62/) I *love* your assumption that the parent commenter has a specific interest in Turkish text, too. Way to stereotype.
Very cool project. Good luck!
I believe Sinan might be interested in that since: &gt; "How to Say in Turkish" is a pet project of mine. It's on his Stack Overflow profile.
I can't promise anything, but I will try. Thanks for the suggestion. Also, I did understand what "2015 will be the year that Perl 6 officially launches" really means ... Given the time frame involved in Perl 6 development, Christmas 2015 would be real soon ;-) Seriously, though, given the general experience of building things on Windows using the Microsoft toolchain, I was extremely pleased with how easy it was to have a decent perl6 running on this machine.
Even if I did not have that pet project, given that I am a native Turkish speaker, it would be natural for someone to inquire if I might be interested in helping this way. I am not sure if I can help, but if I can, I would love to. @carlosdelrey, please relax.
Okay. Apologisings, as that Zathras guy from the old TV show would say.
I'm relieved to hear you're not expecting Christmas in February. :) The quality of the MS toolchain build process reflects Rakudo dev [Jonathan Worthington](http://edument.se/en/consultingservices/consultant/jonathan-worthington)'s use of the MS toolchain. (His nick on #perl6 is jnthn and I'm sure he'd enjoy hearing how pleased you were at that aspect of Rakudo.) On the Turkish front, the main thing I'm suggesting you do is talk on #perl6 about [the unusual issues surrounding Turkish text](http://www.i18nguy.com/unicode/turkish-i18n.html) and how these might one day be tackled in P6. I'd expect at least Larry Wall (nick TimToady) and lue (author of [the P6 Unicode design document](https://raw.githubusercontent.com/perl6/specs/master/S15-unicode.pod)) to be somewhat familiar with these issues but having someone with a specific interest in Turkish and software has to be a good thing even if the outcome of talking about it is to explicitly punt on official Turkish support till after 2015. Anyhoo, please have some more fun with Rakudo and drop in on #perl6 to enjoy the [-Ofun](http://perl6.org/fun/) culture of the P6 project. Hope to see you in the [logs](http://irclog.perlgeek.de/perl6/2014-11-18). :)
I like brian d foy's blog, [effectiveperlprogramming.com](http://www.effectiveperlprogramming.com/). It's a sort of supplement to the book of the same name, but the book is not required to read the posts. The posting has been a tad erratic as of late, but there's a large archive of posts. &gt; Also what RSS reader would you recommend for Windows 7? I use [Omea Reader](https://www.jetbrains.com/omea/reader/). It's not the greatest solution in the word; it has a lot of personal-information-manager crap that I ignore or disable, and it's effectively discontinued (last release in 2007), and I suppose that's not exactly a glowing review, but it's what I've settled on.
My site PerlTricks.com has an [RSS](http://perltricks.com/feed/rss) and an [atom](http://perltricks.com/feed/atom) feed. We publish one or two articles per week, mostly Perl 5 focused. 
Hi guys, thank you for all your input, the environment I'm working in is one of the worlds largest HPC environments, I would not be able install nagios off the cuff :) I will get down and dirty and learn some Perl, Im a junior so they are easy on me here ...thanks, when I said a couple of servers in my OP , I was referring to all the gateway nfs/cnfs infrastructure :)
Take a look at Mojo::UserAgent. It provides all these capabilities.
Can't locate object method "say" via package "Mojo::UserAgent" say $ua-&gt;get('https://yuppie:password@what.cd/login.php')-&gt;res-&gt;body;
Several of the videos seem to have no audio, eg nine's Inline::Perl5 talk.
Some of the modules out there: * [Scrappy](https://metacpan.org/pod/Scrappy) (based on [Web::Scraper](https://metacpan.org/pod/Web::Scraper)) * [Mojo::UserAgent](http://mojolicio.us/perldoc/Mojolicious/Guides/Cookbook#Web-scraping) * [WWW::Mechanize](https://metacpan.org/pod/WWW::Mechanize) * [WWW::Mechanize::Firefox](https://metacpan.org/pod/WWW::Mechanize::Firefox) * [WWW::Scripter](https://metacpan.org/pod/distribution/WWW-Scripter/lib/WWW/Scripter.pod) * [Web::Magic](https://metacpan.org/pod/release/TOBYINK/Web-Magic-0.009/lib/Web/Magic.pm) * [Gungho](https://metacpan.org/pod/Gungho) * [Web::Query](https://metacpan.org/pod/Web::Query) 
Someone just write the script for me and I'll pay you in bitcoin ;)
Check out our project: [DuckDuckHack](http://duckduckhack.com/) Also, if you're local to Philly, we're having a dev-event: http://duckduckgo.ticketleap.com/quack-and-hack-2014/ 
Yeah. Some problem with the encoding. mdk is looking into it.
So, it's like a mailinator clone, but OS and with auto-email verification? Why didn’t I heard of if before? Thanks! 
The array is undef or the (only) element in the array is undef? There's a difference. /REGEX(match)REGEX/; if($1){push(@list_of_things, $1);} is not good. You always have to check if the regex matched if ($a =~ /.../) and only then you can safely query $1. Otherwise it's random. (random ment as don't rely on it. Not really correct, but as a beginner I think it produces better code if you treat it like that) PS: On the basis of your question I assume you are a beginner. Avoid using $_ PPS: Let every script begin with "use strict;" "use warnings;" 
Thanks, that clears that up. 
It's because "@list_of_things = (undef);" not "@list_of_things = undef" it's a list made of one undefined element, and therefore it returns *true* when you check it. 
It's because even tho I might know a bit about website development and programming, but nothing about marketing :-)
Exciting. Good luck!
I was just pondering this myself yesterday. Try using [www.regex101.com](http://www.regex101.com) for testing regex expressions. 
~~In this case I think it is safe to check $1. If the match succeeds it is the group, else it is undef~~. However, OP may as well just put the match into the if condition like you suggest and I agree with using a named variable in this case. Though there are many uses where using the topic increases readability, consider for my $line (@lines) { ... which could be foreach (@lines) { ...
&gt; In this case I think it is safe to check $1. If the match succeeds it is the group, else it is undef. This is true, but only for the first loop run. for my $letter ('A'..'Z') { $letter =~ /(G)/; print "$1\n"; } 
Please work on your formatting...
You're exactly right, sorry. To clarify for OP, $1 is not reset undef if a match fails 
is perl6 really happening??? --a concerned biologist 
&gt;Does this mean it's so incompatible that they had to change the name of the executable? Yes. 
Some say "incompatible" others say "enhanced"... &gt;;P but yeah the actual binary isn't related at any level of the implementation. There has been a lot of effort recently on getting Perl5 nicely embedded in Rakudo (the main implementation of Perl6): https://github.com/niner/Inline-Perl5 . You can even have a Perl6 class inherit from one you wrote in pure Perl5, I believe it works even with Moose classes. It's best to think of it almost - but not quite - like the level of difference between Ruby and Perl than something like Python 2.x to 3.x the latter is more like Perl 5.8 to &gt;5.10. Rakudo has been implemented completely independently from the ground up and the language itself is really quite different. But some of the ways you can write Perl6 look a lot like how you would write Perl5, and in many cases are identical. Sticking strongly to TIMTOWTDI, there is just new and more consistent functional and OO ways of doing things in Perl6. These work in addition to the procedural style available in vanilla Perl5. For more info check out http://perlgeek.de/en/article/5-to-6
Yup and efforts are already underway to get BioPerl moved over https://github.com/cjfields/bioperl6
FWIW I [tweeted](https://twitter.com/PerlTricks/status/535519962748973056) them
Always has been, yes. Although interoperability with Perl 5 is definitely a thing — you are supposed to be able to # Perl 6 here ... { use v5; # Perl 5 inside this block use DBI; my $dbh = DBI-&gt;connect(...); # More Perl 5 code ... } # Now we're back in Perl 6 or eval $somecode :lang&lt;perl5&gt;; or use Graph:from&lt;perl5&gt;; # Writing Perl 6 code that interacts with a Perl 5 class my $g = Graph.new; $g.add_edge(&lt;a b&gt;); but all of these are somewhere between experimental and nonexistent, depending on the implementation. `Inline::Perl5` is pretty promising, though.
&gt; Always has been, yes. For a long time, the goal was to have Perl 5.10 be the last version running solely on its own VM, to have Perl 5.12 running on Parrot, and there perhaps not to be a 5.14. By the time there was something that could actually be called a `perl6` binary, that plan had been discarded.
Thanks again. I now get where I was going wrong. Too much time with sed and awk with implicit if statements.
been using your service for a long time, and the only reason i use other services also is because they offer more alternate domains. this would be a good feature to add: http://www.yopmail.com/en/add-domain.php 
GMAFB. This guy wants to glue some programs together with some simple text munging. It makes about as much sense to use Perl as a slower Java as it does to stop using your genitals for reproduction, cut them off, and use them to flavor stew.
_What is "thought leader" an euphemism for?_ Must be #scorpion fan ... http://io9.com/scorpion-brings-the-stupidest-most-batshit-insane-hack-1638333877 http://jalopnik.com/the-ferrari-chase-scene-from-scorpion-is-even-dumber-th-1638526493
Be careful though. This is now marked "experimental".
Could we organize a digital sit-in? I also, [contacted](https://twitter.com/PerlTricks/status/535852221322526720) the CEO, founder. Please retweet :)
&gt; Could we organize a digital sit-in? To what end?
&gt; To what end? Revenge. J/K
Anything worthwhile to note? I'm not seeing much.
Just from scanning the deltas, I'm not seeing anything particularly significant from my perspective. * Lots of performance enhancements (nice!) * Unicode and regex updates * Some new deprecations * Some old deprecations now fatal errors * New double-diamond operator * Experimental Aliasing via reference So, lots of little things but could perhaps add up to risk for regressions?
The notable deprecations: * You can't write `push foo, $val` to mean `push @foo, $val` anymore (this has been deprecated since 1995, I believe, but finally pulled). * `m?PATTERN?` can no longer be written as just `?PATTERN?`. This will probably break a little bit of old code, but it's rarely used and it's been warning for a while now. * The useless constructs `defined(@array)` and `defined(%hash)` don't compile anymore. * `@array-&gt;[$idx]` and `%hash-&gt;{$key}` no longer function as bizarre synonyms for `$array[$idx]` and `$hash{$key}`. * If you're relying on a `{` in a regex being interpreted as a literal "{" because it doesn't form the beginning of a valid `{count}` or `{min,max}`, you will be warned. You should always backslash metacharacters if you want them to be literal. * The deprecated regex `/\C/` character class, which looks into the guts of Perl's internal representation of Unicode strings in a way that can't be used reliably, is removed. It's a relic of 5.6's somewhat-misguided Unicode support.
Yes, Mailnesia only has 3 alternate domains, but anyone can add their own just like at Yopmail, its described on the features page. 
Just read up on the double diamond operator. That's a nice add.
It is easy to overlook, but Test-Simple has been updated to the alpha branches. Basically an redesign of Test::Builder and related tools. It is on alpha 75 as of this release (I just released 76 today) This has a lot of potential to break things. Lots of care has been taken to avoid it, but we still get almost daily reports of things not working with it. It would be very good to check that all the test modules you use work under this. If they do not report it to the Test-More project on github, and to the broken modules maintainers.
I remember when you could only tap into this using the COM interface. It was horrific.
AFAICT, no. Nothing new that's all that useful, and some random "deprecations" that will probably break something with very little benefit. I'll keep using Perl, and keep ignoring the "upgrade" treadmill, for awhile longer.
cheers pal
The choice of creating a brand new operator just for disabling piped open is a bit strange though. I wonder why they didn't use a pragma to disable a flag or something. **EDIT:** OK,did a scan on [this long discussion thread on p5p](https://groups.google.com/forum/#!msg/perl.perl5.porters/xumf0wxn6tQ/Dz-F2q_N8MEJ). Basically the vote went for a new operator instead of a pragma. And we'll also be seeing the double diamond version of -n/-p called -N/-P.
Big thanks to shadowcat for recording and uploading the videos and mdk specifically for fixing the audio on the ones that didn't work at first.
A fan of http://perlmaven.com/ here. He writes some excellent tutorials with step by step walk through of the code. Good site to get your head wrapped around things like AnyEvent and more.
Perl Many Cores Engine? https://metacpan.org/pod/MCE 
have you any experience using this ? Go can do thousands of concurrent workers .. the MCE examples reference only a handful .. I suspect that's all its designed for. 
Considering that this is more of a PR summit for hack.hands, is it really worth worrying about? 
Regarding the example with `URI::Encode`: you'll have to install this module with [panda](https://github.com/tadzik/panda/). And the function is misnamed. $ perl6 -M URI::Encode -e 'say uri_encode("/10ways to crush it with Perl6")'
Of course I will be missing it :(
Not what you are looking for but might help if you don't want to do it programmatically http://asciiflow.com/ http://www.jave.de/ http://search.cpan.org/~osfameron/Text-JavE-0.0.3/lib/Text/JavE.pm
lol windows
So far away.
You are not the target audience, don't bother.
asciio
Wow, this was a great read. Thanks for the share.
Thanks for this. Getting all the prereqs installed on a fresh raspbian can take all night, and I was thinking that we needed something like this.
The installed packages would take you at least 3-4 days to get installed. You're welcome ;)
I didn't see anything in the post that wasn't true though.
I'm no big supporter of p6. I hope it comes; I'm not holding my breath; I'd like my major version number back. That said making the accusation of lack of motivation or else incompetence of a volunteer effort is at best unproductive and in my eyes unworthy of either this greater perl community or further discussion. 
The title of thread is inflammatory
&gt; Why can't they implement it the same way Larry Wall implemented Perl 5? Running your language though a VM is annoying and slow. Perl *does* have a VM. It's somewhat mediocre in a lot of ways, but that's okay. So was Parrot (even though we were fixing that) and so is Moar.
we should forget about it because: * perl5 does just about everything you could want * cpan6 will pale next to cpan5. Libraries are what really matter 
I think Perl 6s aim to be the perfect language, to support all paradigms, to gather all features was a bit too much. I would have wrote a list "why Perl 5 sucks" and thought about the steps necessary to empty it. OO for example. Perl 5 lacks OO, but the -&gt;_private syntax is light and cool, so why not keep it? If you really want to make it more strict why not this? no warnings 'private'; $obj-&gt;_foo();
So while waiting for it did you contribute to it? Rather then complain as a bystander make an attempt to get involved anyway you can? 
Seems just like clickbait... you make a list of other languages, write two questions and two "conclusions" which at best might be called "assumptions/theories" and that's it? What value does your blog post contain other than insulting the devs? To show lack of motivation or incompetence at least say something about the dev progress like ongoing discussions, problems, etc... Then if you *show* that there's nothing going on at all and that the last commit / comment has been a couple of months/years ago, you are maybe right to call them out in this way. Without any of that and hopping from question to "conclusion" without anything in between you're adding nothing to any discussion.
Do you know the meaning of "clickbait"? How is a blog post with zero advertisement, zero cookies and zero user tracking serving as clickbait? 
This looks really really nice!
This is cool! Out of interest has anyone attempted to get Padre to run on the Pi? I do quite a bit of outreach might be nice to do some bioinfo with perl on the pi :)
If you are not a 3rd world country school who can't afford real computers, it might be not effective to use a raspberry pi as workstation. Actually I strongly advice to NOT use it as such, its a pure waste of time. This is a VERY VERY VERY VERY ..... VERY SLOW computer..... never forget this. Any procedure that "takes a bit longer" will be HOURS...... Seriously: Raspberry is a gateway to the electronics, not a workstation replacement.
There is right now a downtime, of course the server decided friday at 18 oclock to break down. I will reply, when its back on (no estimate).
From perldoc on system: &gt; If there is more than one argument in LIST, or if LIST is an array with more than one value, &gt; starts the program given by the first element of the list with arguments given by the rest of the &gt; list. If there is only one scalar argument, the argument is checked for shell metacharacters, &gt; and if there are any, the entire argument is passed to the system's command shell for parsing So if you pass it a LIST, it doesn't use the shell, so you can't redirect stderr.
If you want the output of the process, then you don't want `system()`. Also, `dialog` can be told where to send its output, e.g. `--stdout`, so there's no need for redirection. You can use the "pipe" form of [`open()`](http://perldoc.perl.org/functions/open.html) to get the stdout of a sub-process, and there's a form that avoids the shell. Example: #!/usr/bin/env perl use warnings; use strict; my $title = "Enter your name"; my $initial = "Joe Bloggs"; open my $stdout, "-|", "dialog", "--inputbox", $title, "9", "80", $initial, "--stdout" or die "unable to run dialog: $!"; my $response = do { local $/; &lt;$stdout&gt; }; print "You entered: $response\n"; You could also use `IPC::Open2` or `IPC::Open3`, but they're not really necessary here. 
It's been a while since I've used it but I recall [IPC::Run](https://metacpan.org/pod/IPC::Run) being quite handy for things like this too
You should be able to use [IPC::Run](https://metacpan.org/pod/IPC::Run) to give you shell like redirection syntax
You could try using `fork` and then `exec` the external process, instead of using `system`. I don't know if that would properly spawn the external process as a child process, nor if it would then catch the control-c sent to the parent Perl script.
Thanks all for reply. I edited my original message to give more details.
Look at Capture::Tiny
Finally, done ... http://blog.nu42.com/2014/11/fixing-single-hard-coded-path-in-test.html
Seconded. I've been slowly converting my company's use of backticks and system() to IPC::Run. It is great!
Hehe, some days the bugs just pile up! Thanks for going through all that and writing it up.
I keep getting a syntax error for line 7, near the if statement: (Might be runaway multi-line // string starting on line 4) Unmatched right curly brace at icon-copy line 10.
Has to be, it's for an assignment. 
my $dir = "~/"; Need to quote that line (line 4). Always try to decipher the errors and warnings top to bottom.
Okay thanks! It seems to have worked now. 
What version of Perl are you using?
You need to up your vim game, too ;)
The first thing I thought was: why aren't you using bukkit? It had all these things... Didn't know it didn't exist anymore. Seems like this project got out of hand. But it looks good. Nice job!
Actually, that is hardly accurate. Almost everything installs without any problems at all (except for GD for now) with my self-built `perl`. I am frustrated by the fact that people actually hard-code paths in tests, or interpolate variables holding paths to regex patterns, because those are unforced errors ... However, they are few and far inbetween. If I had just decided to install PPMs sing ActivePerl, or stick with the MinGW toolchain used by Strawberry and ActivePerl, I wouldn't have these problems. I just decided to try using only Microsoft provided tools, and those haven't been exercised much lately, mainly because the other solutions I mention work so well, and Visual Studio used to cost beaucoup bucks before MS made the Community Edition available. That's all. Try building, for example, a Ruby environment from scratch, just using MS tools. I have. It wasn't pretty.
i hate home work problems, but there are many ways to do this. I would do it like this: open(FILE,"&lt;file_with_comments.txt"); @LINES = &lt;FILE&gt;; close(FILE); open(FILE,"&gt;filtered_file.txt"); @LINES = grep !/#/, @LINES; foreach $line(@LINES){ print FILE "$line"; } close(FILE); I know this isnt exactly what you're asking for above, but it should help you get started.
You might want to format the code in your post correctly, the "formatting help" link will help. or link to it on an external pasting service etc
just off the top: sed -i -e "s/^\s*#.*//" might work. my usual "remove comments" command is: egrep "^[^#]" which I love for the adjacent use of `^` with different meanings :P
IIRC this will do the same too find . -name \\*.ico -exec cp '{}' ~/icons \;
Might have been better to post this type of thing to Stack Overflow in future, I think they'd have less opposition to using the wrong tool and reinventing some wheels
as someone that ran Bukkit for many months, this still appeals to me. I don't want to spend time maintaining mods or running nightly builds. just run vanilla and throw a tiny bit of code at it.
They've been given an assignment in Perl so I don't think they can use either of those :( They also seem to need to strip trailing whitespace
When deadlines don't make sense, you move them. When you get onto something potentially delightful, you let it season. It turned into a 20 year project because it became interesting. Moving a deadline an order of magnitude sounds about right, in this case. Your comment is an example of impatience (by many parties), which I suppose is why the idea of a 20 year project makes folks uncomfortable.
 #!/usr/bin/env perl use strict; use warnings; while (&lt;&gt;) { next if /^\s*#/; s/\s+$//; print if $_ =~ /.+/; } And ask your teacher why you need to chomp the input if removing the trailing whitespace will do it for you. Then tell him/her to read the FAQs [here](http://learn.perl.org/faq/perlfaq4.html#How-do-I-strip-blank-space-from-the-beginning-end-of-a-string), because that's pretty much Perl 101 right there. EDIT: Out of curiosity, what book are you using for this class?
I suppose the obvious question is "are you sure that the URL is supposed to be DAV enabled?"
&gt; It turned into a 20 year project because it became interesting I must be misremembering the decade I spent working on it then.
Perhaps it happened after you left, or perhaps it's not interesting to you. Other perspectives exist.
Perhaps I was sitting in the room for many/most of those discussions. Perhaps I took hundreds of thousands of words of notes from those discussions. (If you wanted to browse the archive.org history of use.perl.org, you could find most of them.) By all means, however, don't let that stop you from explaining what *really* happened. It's fascinating to watch history being rewritten.
*sigh* Of course yours is the only valid perspective. I've gotten used to that about you.
The link is supposed to be DAV enabled. After some further investigation, though, I found that I needed to update my LWP::Protocol::https, IO::Socket::SSL, and LWP::UserAgent modules to support using http**s** links with the HTTP::DAV module. I'm not getting this error message anymore now, and I'm able to transfer files to this server. Thanks though.
We're already to the part of the conversation where the (created just to respond to this thread) P6 advocate makes it personal? I know skimming hundreds of thousands of words of P6 design meeting logs takes a while, but we documented those meetings in such detail for a reason.
I'd comment right on your blog, but its comment system won't accept anything I submit, so here it is here: - what version of perl are you running? because... - you must have a rather peculiar setup, given: http://matrix.cpantesters.org/?dist=Moose+2.1402 and http://matrix.cpantesters.org/?dist=Sub-Identify+0.08 Also, I feel obliged to point out that you do *not* need to install Dist::Zilla to submit a patch to a distribution that is packaged with it. (It is nice if you did, to confirm that author and release tests still pass, but it is *not* a requirement, and if you are having difficulties, you should not feel required to.) Also, I've fixed the Moose test here -- https://github.com/moose/Moose/commit/8eb0d8aa9c17675388c71238c62fc62a4d233fcc -- and will be releasing tonight. (You were planning on submitting an RT ticket, I trust?)
&gt; no one cares I think that's being unfair to the people who *do* care, but do not have a MSWin32 system to test on, so they are reliant on people like you to submit bug reports and provide early feedback on new development efforts.
PPMs are kind of help the situation, as each module freezes at the last passing version, so even if a non-passing new version is out, it won't be updated. so the rest of the PPMs can be built on top of it, until it become too old to be useful. With Strawberry Perl, you get things from CPAN, so it is enough that someone on the chain released a non-passing new version, and you are screwed.
I don't - not anymore. consider - an author release a module. all green on CPAN testers. now a year along a dependency released a new version - fails on windows. The dep author don't care enough to fix that. the using module doesn't even knows that his module no longer supports windows. So the users need to bug the dep author (that doesn't care) about windows support. oh well.
In that case, I've found it is helpful to contact the author who is using that dependency -- first of all to let them know that there are downstream problems that they probably didn't know about, and also to let them find alternative solutions that *do* work. Also, they can apply additional pressure to the uncooperative author.
I believe the term is "development hell"
The fact that you were ever sold on Perl 6 as being an 18 month project is clear evidence you should never have been "project manager". Thrashed about with Parrot for years pretending you knew something about VM design and implementation should have taught you that, if nothing else. 
Sorry, "administrative assistant".
- p5p care - the most prolific people and the people who run the whole toolchain care - people outside this who run win32 and can fix bugs care, and they file bugs, and where possible, submit patches. ( These people are _critical_ for care to work, because without people who actively work on win32 reporting and fixing bugs, no amount of us caring will help ). If you find a module you use, and it doesn't work on Win32, you have many options: - Make sure the bug is reported. - If you can, file a patch. - If patches are stalled and nobody seems to care, there are ways around that. Ways around the problem: - Nag perl people to take over maintaining the module by somebody who cares. - Find the reason it is a dependency and rule it out. Ultimately, there is no single point of failure in the absence of care. There is a chain, and people in that chain care. To make a start, all you have to do is care enough to be involved in the process of caring. Yes, it sucks to be feeling like nobody cares, but the more people we have running and testing things on Win32, the more you'll feel like we care because we'll have something to respond to, instead of the deafening silence and confusion where nobody tells us its broken, and you **assume** we don't care so you never tell us about the breakage you see. 
If it helps I wrote a simple rcon command line tool. It currently only works one command at a time. But your post makes me want to extend it into a daemon that runs commands :D maybe scriptable with lua directly or launch CLI app... My mc server used to use bukkit but everyone wanted to update to 1.8 solo we went to vanilla. And that rcon tool is used to run the save map commands when running map backups.
Thanks for reminding me about Advent calendars. Lots of good ones this year.
perl 5.20.1 compiled with Visual Studio 2013 Community Edition. The problem occurs because of specific EUMM treatment of test file paths when the build is being done with nmake. I understand all those tests are passing. Also, I blogged about this as I was going through so I could remember, and submit patches for various things, but I wasn't in a hurry. Frankly, there are too many places where either paths are interpolated into regex patterns, or hard coded paths are used for tests. Doing it right on EUMM and Module::Build versus potentially turning CPANTesters red for Windows platforms is a heavy concern as well. I'll try to test the latest commit for Moose. Thanks for taking care of that.
Well, I cared, and I am making some noise about this particular problem. However, the problem is bigger than the errors in modules. With EUMM not using Windows paths on Windows unless the build tool is nmake, and with Module::Build not canonicalizing paths from File::Find, it seems a kind of complacency regarding portability has set in. perldoc perlport has been around for a while. So has File::Spec. This is a problem that should not exist because CPAN contributors ought to know that hard-coding Unix paths is not portable.
I did not know about that. See also http://blog.nu42.com/2014/12/hey-set-up-test-machine-why-dont-ya.html
&gt; you do not need to install Dist::Zilla People keep saying that, but, is there any way to know _a priori_, just by looking at the checked-out files, that author's plugins won't transform the source files?
lol just replace sed with perl -pi -e and it will work :)
There is often a document in the repository that explains what's going on. I (and some other prolific dzil users as well) include a CONTRIBUTING document which gives detailed instructions how to build or test the dist, including ways to test patches without having to use dzil at all (I also include a Makefile.PL in any dist where some sort of build is needed, e.g. there is XS code). IMO you should *assume*, in the absence of other information, that `prove` will be adequate to testing any patches against the dist. I consider it quite rude to leave the bare repository in an unbuildable state, for exactly the same reasons you've already identified -- it's a barrier to providing patches or even simple debugging.
All tests pass. However, the experience is not as pleasant as you make it out to be. http://blog.nu42.com/2014/12/yeah-you-put-me-in-my-place-real-good.html Still, thanks for the patch. I am assuming the snide remark was put in there before you took over maintenance.
Well, guess the mods have spoken...
The class is intro to Linux so we don't work with a specific language but [here is the book](http://www.amazon.com/Practical-Commands-Editors-Programming-Edition/dp/013308504X).
Thanks for the mention. I forget about publicity until Nov 30 :-)
Shit, how'd I miss this link when it got posted? A lot of the talks look awesome, looking forward to watching em.
Shelling out for things that perl can do isn't really a best practice. It's really resource-intensive and, as demonstrated by shellshock, could make you vulnerable to some really nasty exploits. If you do need to execute an external program, you can use system(), fork()/exec(), or (probably best) something like IPC::Run. If you want a shorter open() -&gt; read(), you could just drop the close(), 'cause it'll happen automatically when your program exits. And if you use a scalar for your file handle, it'll happen as soon as the variable goes out of scope: open(my $file, "&lt;", "file_with_comments.txt") || die $!; my @lines = &lt;$file&gt;; If you really want something like a one-liner, you can **use IO::All** and write it like so: my @lines = io-&gt;file("file_with_comments.txt")-&gt;slurp(); 
I ready died from holding my breath once, It was a good thing I was wearing an amulet of life saving.
It's true. What's probably needed is for these tests to fail on smokers, so they show up in the author's inboxes as pseudo bug reports. This won't solve the problem, but right now authors don't know about the bugs because the existing smokers are using a toolchain that obscures it. I'd certainly be fixing bugs as simple as path sep, if I got reports. It doesn't need to be someone working through the queue of possible modules by hand. This is the kind of problem where smokers excel.
Things are better than they were. I first got involved in CPAN Testing because back in the day, CPANPLUS didn't work/didn't do test reporting on Windows. That's why I wrote CPAN::Reporter (and then CPAN::Reporter::Smoker) -- to allow automated fail reports from Windows. Before that, even just reporting failures was manual and there were more than I could manage.
Somewhat tangential to the main point, the problem is usually people hard-coding paths in tests, but using File::Spec in their code. If both places were hard-coded, things might be fine. That's probably not the case for EU::MM generating Makefiles, but that's a special case. One of the design decisions I made with [Path::Tiny](http://p3rl.org/Path::Tiny) was to use unix separators for all platforms. That minimizes some of these errors since generated paths match the hard-coded ones (unless washed through some other library that calls File::Spec on them again). I also wrote [Test::Filename](http://p3rl.org/Test::Filename) for cross-platform file comparisons. It doesn't help when the path is inside a chunk of output test, but it does help when someone is testing a path, specifically. I agree 100% with your more general point that people need to be more sensitive to portability issues – anytime a file path shows up in code or tests, warning alarms ought to be going off.
So, by now, I have submitted a few reports using cpanm-reporter. https://twitter.com/sinan_unur/status/539853809552723968 @ether_reddit might be getting a few extra fails which is due to my absentmindedness while getting used to the tool, apologies. Clearly, it's a little rickety right now. This is an Azure VM running on a trial plan right now. I intend to shut it down once that is over, but I am learning things ;-) 
Probably from the downvotes. I see no moderation action on it.
I would consider this a bug. On Unix, perl will ignore SIGINT during system in the parent process, I would expect the same on Windows.
Messed up.
There's also a [part 2](http://www.josetteorama.com/all-about-mojolicious-interview-of-sebastian-riedel-part-2/).
I read this as all about Mojitos, was a tad disappointed when I clicked. I shall go read the article now.
Expecting them to announce another rewrite any day now.
I also goofed in explaining cpanmin.us. My apologies to Miyagawa.
Thanks for posting, great job!
I'm going to try to make it to this one.
 Not sure if Perl is what you want. If I'm reading this correctly you want a script that will launch another program and enter some commands at a prompt. If that's the case, then you want expect. You can even use autoexpect ( ^http://linuxcommand.org/man_pages/autoexpect1.html ) so that you don't have to learn expect if you're not interested. 
You are correct. I want enter some command at the prompt at the same time enter a node name to launch. I will check out expect. Thank you.
Thanks a bunch.
This is really useful, thanks for creating it.
Do you have an example expect scripts?
I sadly don't know more, it smells like that.... I just wanted to share the link, hopefully someone knows more or something ;)
What I always wondered is why someone named Poe needs the pen name Ovid. One famous author just wasn't enough?
I suspect it's that plus CGI+shellshock. They do mention RCE after all and I don't think wantarray can allow that. Still the tone of this is really sad. 
Context can be a powerful tool but that does mean you need to pay attention to it
Wow! This guy is a real asshole. https://bugzilla.mozilla.org/show_bug.cgi?id=1074812#c34
He seemed to want them to read his mind and realise that they weren't ready to break embargo... on the day they agreed to break embargo
mail to the perl security mailing list is hidden of course. you cannot know. But this issue is not core related and well known for a long time.
&gt; mail to the perl security mailing list is hidden of course. you cannot know. Of course yep, didn't think of that.
I do not believe I said anything about EUMM's tests, and I do not believe I said anything about EUMM ought to be changed. I did identify why previously passing modules were now failing. FYI.
Awesome interview! Although a perl developer might know most of the things it's definitely good perl got some exposure with the help of this interview. Hope we get this kind of press coverage more and more
The behaviour you describe sounds like a bug, but we'd appreciate more info so we can be sure. It still should have been reported promptly, as newly-failing modules is always a problem that should be closely investigated.
The bugs are in module test scripts which either 1) expect to always be invoked as t/test.t; and 2) which interpolate $0 into a regex pattern without using \Q ... \E. One might make the argument that from the beginning, EUMM should have used Windows style paths on Windows when invoking external utilities, but I worry about anyone thinking that I might be suggesting that such a change ought to be made at this point. If this were to negatively impact Strawberry Perl platform, the cost would not be worth the benefit. Therefore, I will not report this to EUMM. However, as I work through cases, I am getting module authors to fix the bugs in their test files.
How is this going to translate to real world speed increases.
Optimizations like this and the "faster method call" effort might even make up for the blizzard of random deprecations that come with newer Perls. More, please!
I've got it saved to read later, but I'm guessing either automation or remote administration. 
Pretty much any time you need to test interfaces, especially with javascript. This is very useful for automation as well, i automated a significant redundant part of my job with selenium scripts.
You could also use a virtual X server and run it on a server that doesn't have graphics (or just because you don't want to see the result directly), and automate taking screenshots of webpages and similar.
That depends greatly on the application. As an example, the templating system that's used at Booking.com showed a 9% speed increase in a test. That may sound like a small change, but unsurprisingly it's mostly spending its time in string manipulation, not composite data structure traversal. 9% on a system this large is also something that translate to very, very tangible savings in server hardware. I expect other use cases such as our stats aggregation systems to benefit significantly more - on the order of tens of percent improvement.
Real world: do this and get a promotion School world: do this and fail the course
The same use cases as [Capybara](https://github.com/jnicklas/capybara).
^^ this. Selenium is the right tool here. With Test::WWW::Selenium.
Yea except you would have to write redstone... ewww end end end end end end my life please.
That makes sense. A *lot* of sense...
Neat, but installation of the MozRepl Perl module is somewhat brittle - had to force it. Sometimes my Firefox froze and I had to kill it. After 3rd try it worked. Was able to test it with the examples in the article, but the last one failed: MozRepl::RemoteObject: ReferenceError: StackExchange is not defined at ./mozrepl.pl line 13. Anybody having the same issues?
Not in my setup I was able to build and install it on 3 different machines, 2 cloud and the last one being my home desktop (Debian) 
One of the cool things that perl has and no other does as well is that older versions of the language have support for a very long time. Decades old perl scripts just keep working. And will keep working. Perl is a very good language for people that don't want to be the full developer type, where new versions of the language keep coming up and they have to learn the new way of doing things because old versions will lose support, and programs have to be updated, etc. Perl will also be with you whenever you go, it works everywhere. It comes by default in any Unix-like and it is easy to install in Windows. 
Thanks! I'm Asking some newbie questions in the other answer too.
1) Yes, in fact Apple themselves distribute Perl via XCode. See: http://learn.perl.org/installing/osx.html 2) Yes, each computer needs a version of perl to run Perl programs. There are some ways around this, but they tend to be tricky and aren't used very much. 3) Yes, graphical interfaces can be made. Off the top of my head, there's [Gtk3](https://metacpan.org/pod/Gtk3), [Tk](https://metacpan.org/pod/distribution/Tk/Tk.pod), and [Wx](https://metacpan.org/pod/Wx). One of the great things about Perl is that you'll often find that these libraries Just Work on any OS you try.
Another alternative for 3 is writing web based guis
First, if you do want to learn how to program, it doesn't really matter with which language you start. Perl is fine. So are many mainstream languages, but I wouldn't recommend, say, APL. Now, second, but more importantly, you'll need to shed the "I just want to add a button" attitude. This is a serious problem when people do not know what they do not know and assume what they do not know must not be significant. When you are dealing with POS terminals, there is no "I just want to add a button". If you do not see the hornets nest that would be opened if anyone could add any bit of software to the POS terminal, you should not be allowed anywhere near a POS terminal so that the company does not end up being financially ruined. Also, people forget that while paper forms for recording hours may seem old-fashioned, and inconvenient, a computer based system with its associated authentication and authorization mechanisms takes real effort to design correctly. So, don't start this with the assumption that you'll learn a language, and just fix all that is wrong. Start learning how much mental effort is required to correctly put together even small systems. If you go ahead and code a time entry system in an afternoon, you will probably end up with a computer record of employees who work 24 hours a day, but are never there. Just fair warning before you get into trouble. 
Started learning Perl about a year ago and can confirm that I've created loads of small scripts to make my (and others) life easier. Things such as reading/writing to databases, parsing text files etc in work to recording my electricity meter readings, logging into my bank at home. In fact a lot of my old bash scripts have been replaced by Perl scripts. Might take a while to get your head round some of the symbols and when to use them but well worth it.
Meh, any sysadmin will trow scripts around as if it's nothing. Works.
Interesting points, thanks. The POS is just a desktop computer running Windows. The POS is actually web browser based. I'm working in Central European countries where sometimes they are way ahead of the curve tech-wise, but often start-ups are not. This retail shop is using 2008 PCs connected to a scanner, cash drawer and credit card terminal. Yes, maybe my single-afternoon-programming is wishful thinking, but still, the paper-based process now takes 2 people and the bookkeeper to go through it every month and mistakes still happen. If I can get something to reduce the human error part, that would be very useful. Even something as simple as scanning an employee's barcode and just logging the time in a .csv file would do wonders - because then I can Sort and Hlookup and all that to get what I need in about 10 minutes. Mental effort putting small systems together is what I do all day! :-) I've done a number of ISO 9001 QMS for manufacturing labs and it is working out the details and what/ifs of everything. And I know that many times I could have used 'something' to glean information or create information to make a process go smoother. 
Yes, getting info from databases is what I need too. This crazy system they have now only allows you to see the sales of a specific date in the browser, no way to create a .csv file of it! I'd love to be able to pull all sales of Store #1 from Nov. 22, 2013 into a file, for example.
IMO the easiest and best solution is to write down your requirements and hire someone to code it. The same for gleaning / creating information; hire someone who can create that tool.
As others have mentioned, Perl is a great language. It's got a _lot_ going for it. The one place I would not recommend it is the sort of place where you need to create a tool and you need it to _just run anywhere_. Perl is interpreted (..sort of..) from source at run time, meaning, that .pl file is both what you execute and the source. That's a downside when you have any external dependencies (i.e., CPAN modules); you have to have those available on the system too. Perl ships with a _lot_ of stuff in "core" (there by default) and you shouldn't need it for basic stuff, for complicated stuff, or complex tasks, you will, eventually. Python, Ruby, PHP, and all the other interpreted languages suffer from this same weakness. For server-side tasks, or places where you have complete control of the environment, you're fine. This is where the interpreted languages really shine. I'd look at a compiled language. Go springs to mind, it's modern and compiles to executable bytecode you can ship to your clients 
There's a huge difference between a sysadmin creating scripts to make their job a bit easier and creating programs for *OTHER* people to use.
Meh, I do them for me to use and just distribute to colleagues.
What did I just read? Once I tried to execute a Go program, still can't do it, it's hard as hell.
As I mentioned in my article, MozRepl and Firefox have some stability problems even outside of the thing communicating with them. If you're having problems like this, I suspect that there's something slow with your setup. For instance, if your Perl program tells Firefox to load a page but Firefox takes a bit to do that (latency, slow link, whatever), you can get out of sync. As Perl moves on to the next thing, such as executing some JavaScript, Firefox might not have loaded those resources yet. Your particular error means Firefox hasn't loaded StackExchange's JS code. There are some event handlers you can install so Perl waits for various things to happen before it does the next thing.
These days customization is probably best done in JavaScript. 
You can actually compile a perl script into an windows application (exe). I do it at work with about 35 perl applications so they can run on a windows machine without installing perl.
Out of curiosity: which exe-maker do you use?
The ] should be \\] . you still need \s or \s+ for all the white space in the /x regexp. the .* and $ at the end just slows it down.\ Edit: #!perl my @txt = ("Line 1. [foo] bar", "Line 2. foo bar", "Line 3. foo [bar]" ); my $regex = qr/^ Line \s+ (\d+)\. \s+ .*? \[ (\w+) \] /x; my $nregex = qr/^\s*Line\s(\d+)\.\s*.*?\[\s*(\w+)\s*\]/; foreach (@txt) { if ($_ =~ $regex) { print "Lnum $1 =&gt; $2\n"; } if ($_ =~ $nregex) { print "N Lnum $1 =&gt; $2\n"; } }
embedded literal white space is not part of the pattern Edited for clarity
&gt; So what exactly does the /x option give us? It made it possible to insert arbitrary whitespace (like line breaks) and comments without them being part of the actual regular expression, improving legibility. 
That may be best for the op with his ambitions but he could first try. 
Don't worry guys, Perl6 will be out by Christmas edit: I never said which Christmas
I actually did start learning Python first and might go back to it one day. Perl was/is installed on all machines on my work which led me to port all my python scripts over to Perl. Gradually as I learned more Perl, I found I was more productive with it, especially with parsing text files. I enjoy using it more than Python at the moment. 
Semantic whitespace. Can't get past that.
I actually started with Python long ago when I started programming. I came to Perl after going through Unix and C and found that it fit in with the rest of Unix really well. But what kept me using Perl and not going back to Python was that the code on CPAN was often more tested and portable than Python packages. I didn't need to go back and keep making sure that my code wasn't broken. The syntax is really a minor thing compared to a community that cares about working code.
Here's a good explanation of the hash/wantarray stuff, from a Bugzilla maintainer: http://blog.gerv.net/2014/10/new-class-of-vulnerability-in-perl-web-applications/ The TLDR version is that if you assign hash values with a function call, you may be screwed: my $hash = { foo =&gt; "safe", bar =&gt; get_bar() }; Try it with something like this: sub get_bar { return 1, foo, "owned"; } Seems like this happens because the return value(s) from get_bar() are just blindly spliced into the list of key/value pairs. (Remember that '=&gt;' behaves almost exactly like ',', and you can use either one when constructing hashes.) Besides sticking "scalar" in front of function calls (as suggested in the blog post), you could also just avoid making function calls while constructing an array. This ought to be safe: my $hash = { foo =&gt; "safe" }; $hash-&gt;{bar} = get_bar(); 
Thanks for the input. It's great to hear that cpan can still offer so much benefit for authors of code. Also what you're saying is that there is little concern when going from versions of perl? Python 2.x to 3.x may be an issue? 
It's log4j. I thought it was Java but just j. http://logging.apache.org/log4j/1.2/
Well, there are definitely issues for Python 2.x/3.x, but that is to be expected with a major version change. Perl5 is better with backwards compatibility, but the issue for me isn't that. The thing that sets the Perl community apart is that modules are always being tested on [CPAN testers](http://cpantesters.org/). That even helped me find a bug in my own code today. This makes me happy because I don't like coming across a cool module that I want to use and finding out that it doesn't work because of a bug deep within its depedencies. CPAN testers makes for robust open-source code you can depend on.
Thanks so much for your input. Sounds like perl is alive and strong.
Second that; I use Activestates PerlApp and PerlMSI for creating and distributing applications in a corporate Windows environment and it mostly just works. I haven’t had the need for it yet, but you should be able to cross-compile for Windows, MAC og Linux. As an added bonus you can test programs during development under the interpreter, and easily script compilation and wrapping. If this is what you want, I would probably recommend stating with Activeperl 5.16 32 bit for as trouble free start as possible. 
Perl/Tk though it fells old, it's easy to pick up, I can recommend the book Mastering Perl/Tk. I still use it for simple dialogues and things like browsing for files etc. Depending on your needs, web based GUIs are a good recommendation even for some standalone desktop applications. For instance my latest offline desktop app is actually a Mojolicious web app served on localhost by an embedded webserver – all Perl, compiled to .exe with PerlApp. The hardest thing was getting the javascript things to work as expected. 
I'm especially interested in the average salary and job count.
I wouldn't recommend anyone to learn perl either. Too many special cases/variables. I expect it'll eventually go the way of Fortran.
Can't Selenium be used to do this, in a browser-independent way?
Perl 6 is a major sanitization. Still many processes - eg sorting an array (Oh, perl is all about lists, you know) - are via old wives tales (the schwartzian transform or some such). Perl 7 will be a great language that will probably be the user language on the first spaceships 
I know I've tried it in the past, and found that it tends to be weird and inconsistent about it. The Selenium2 browser drivers might have improved on it. OTOH, I've found that the OLE bindings in Perl are surprisingly straightforward for a Microsoft API.
It can, but it's also an overhead. Win32::OLE is faster, and in my experience more reliable than IE on Selenium. Also it's kind of a pain to run a system command to startup selenium server and wait for it to be ready everytime you need an automated browser. The [example](https://metacpan.org/pod/WWW::Selenium) in the synopsis doesn't even work for me on IE 11, selenium server 2.44.0. I get an error "could not access app window". 
"We're announcing the announcement of a call for RFCs to figure out what we should be building."
Added. Thanks.
Win32::OLE is my bread and butter for Office automation. It's incredibly powerful (even enabling functionality no longer exposed through the UI.) All that said, I'm still amazed when I see yet more that Win32::OLE can do.
There are also great tools for managing all that in Perl. Take a look at Carton, Pinto, Local::Lib, FatPacker, PAR etc.
&gt; have found that getting the selenium drivers to work is finicky at best I know exactly what you mean. OTOH, I have had a lot of success using Selenium's [IE Web Driver](http://selenium.googlecode.com/git/docs/api/java/org/openqa/selenium/ie/InternetExplorerDriver.html) with C#. It looks like IE11 has a standalone Microsoft-built web driver package too: [download](http://www.microsoft.com/en-us/download/details.aspx?id=44069), [docs](http://msdn.microsoft.com/en-us/library/ie/dn722338\(v=vs.85\).aspx)
I would like to know how to save the output to a file?
Easiest way would be from the shell actually, ( /r/commandline ? ) $ chmod +x your-perl-program.pl $ ./your-perl-program.pl 2&gt;&amp;1 &gt; logfile.txt
First, always use the strict and warnings pragmas at the top of your code. use strict; use warnings; To save output to a file you can redirect the process's STDOUT to a file: perl script.pl &gt; stdout.txt Or, you can write it to a file instead of STDOUT: #!/usr/bin/perl use strict; use warnings; my $dir = "/home/vli/scripts/logs"; opendir my $dh, $dir or die "could not open $dir: $!"; #I am assuming you are trying to only open files #i.e. you were trying to exclude ., .., and any other #directories, -f is a better choice for this my @files = grep { -f } readdir $dh; my $outfile = "somefilename.txt"; open my $out, "&gt;", $outfile or die "could not open $outfile: $!"; for my $file (@files) { open my $fh, "&lt;" , $file or die "Unable to open $file: $!"; while (my $line = &lt;$fh&gt;) { next unless $line =~ /L{6}|L0{5}/; print $out $line; } } Things to note about my version: * always declare variables with my or our, this combined with the strict pragma will save you tons of debugging time * always use lexical file and directory handles rather than bareword file and directory handles * always use the three argument version of open * never quote variables by themselves (e.g. "$dir", it isn't necessary and can lead to bugs) * always include $! in error messages that come from system calls like open, it contains the error that the system call generated * use things like regex quantifiers (e.g. L{6}) rather than typing the same thing repeatedly, it allows you to see at a glance that there a 6 Ls rather than having to count. An additional thing that could be fixed that I didn't bother with is the hardcoding of the path with "/" as directory separators. Some people consider this to be bad because some OSes use different directory separators. The [File::Spec](http://perldoc.perl.org/File/Spec.html) module allows you to be more portable: use File::Spec; my $dir = File::Spec-&gt;catfile("home", "vli", "scripts", "logs"); In general, I don't write code that needs to be portable beyond Unix-like OSes, so I don't care.
this might be of use, a list of recommended modules for dealing with files. http://shadow.cat/blog/matt-s-trout/mstpan-5/ you can use [metacpan](https://metacpan.org/) for looking up the module docs
Be aware that what comes out of readdir are the names *without* any path info.
Good point. I assumed the script worked the way the author intended and didn't pay much attention to the call to `readir`. A better version is #!/usr/bin/perl use strict; use warnings; use File::Spec; my @dir = (File::Spec-&gt;rootdir, split "/", "/home/vli/scripts/logs"); my $dir = File::Spec-&gt;catdir(@dir); opendir my $dh, $dir or die "could not open $dir: $!"; #I am assuming you are trying to only open files #i.e. you were trying to exclude ., .., and any other #directories, -f is a better choice for this my @files = map { -f $_ ? File::Spec-&gt;catfile(@dir, $_) : () } readdir $dh; my $outfile = "somefilename.txt"; open my $out, "&gt;", $outfile or die "could not open $outfile: $!"; for my $file (@files) { open my $fh, "&lt;" , $file or die "Unable to open $file: $!"; while (my $line = &lt;$fh&gt;) { next unless $line =~ /L{6}|L0{5}/; print $out $line; } }
It does "more"? ;)
&gt; the hardcoding of the path with "/" as directory separators. Some people consider this to be bad because some OSes use different directory separators. I thought perl knew enough to treat "/" correctly on non-Unix OSes.
Nope. It works on MS Windows because windows honors / as a directory separator (via system calls, not the command line). On systems where / isn't a directory separator (like old Mac OSes and other oddballs), it doesn't work. Perl can't even DWIM it for you because it can't tell if you mean one file with a bunch of slashes in the name or a bunch of directories and a file. You might find [perldoc perlport](http://perldoc.perl.org/perlport.html#Files-and-Filesystems) helpful. Personally, I just try to stay away from the oddballs as much as possible and write my library code interfaces such they work on file and directory handles rather than messing with the filesystem directly (that way any platform specific code winds up in a script).
Not only that, but blead (Perl's master) is regularly tested against CPAN to see if new Perls break existing CPAN modules. If it has to break, p5p sends patches to the maintainer of the CPAN module. See "bleadperl breaks CPAN"
 It's called "short circuiting" For x &amp;&amp; y If x is 0, the code won't check y. In this case "x" is "start" and "y" is "next". If pm-&gt;start returns 0, it will do the loop, else will do "next" 
Ok so `$pm-&gt;finish` is nonzero in the second iteration and the loop burns the second element in the array... how does Parallel::ForkManager allow for the second element to be addressed in the loop?
This is great. Thanks...
I love to learn shell too. Thanks...
I bookmark the link for future use. Thanks a lot.
Any answer would likely need to know what operating system you are using.
I love Parallel::ForkManager ... It even works well without `fork` ;-) http://blog.nu42.com/2012/04/can-parallelforkmanager-speed-up.html
If you are on a Windows system with MS Office, I would just set up a mail merge via Word.
I'm using Windows 7
Assuming you have Excel available since you have an Excel file, I think the simplest thing for you will be to use [Win32::OLE](https://metacpan.org/pod/Win32::OLE) and automate an instance of Excel itself to do the printing work. Direct printing formatted stuff from your own app in Windows is kinda involved, last I looked. If you've never heard of it before, it's like your app starting another program and sending messages (commands) to it. [Excel's automation interface is documented online](http://msdn.microsoft.com/en-us/library/office/ff194068\(v=office.15\).aspx), and there are probably some examples of [perl &amp; excel ole code still searchable](https://www.google.com/search?q=perl+excel+ole&amp;ie=utf-8&amp;oe=utf-8#q=perl+excel+ole&amp;tbs=qdr:y). (I limited results to the past year so it won't show ancient stuff to you.)
If you want to learn some new stuff: give XSLT and XSL-FO a try. You can use Perl to turn label.txt into an XML file and transform it to XSL-FO using XSLT and use Apache FOP (for example) to create a PDF.
Each time `start` is called, the currently executing process splits into two, just like a fork in the road. They are both identical, and continue executing at the current point in the code independently, except for one aspect — the return value. It is non-zero in one process and zero in the other. In the non-zero process, execution continues to the next iteration of the loop. In the other process, a URL is fetched, stored, and then that process terminates when `finish` is executed. | set $linkarray to first item in @links | fork | \ | \ | \ next getstore() | \ | terminate | set $linkarray to second item in @links | fork | \ | \ | \ next getstore() | \ | terminate | set $linkarray to third item in @links | fork | \ | \ | \ next getstore() | \ | terminate | set $linkarray to fourth item in @links | . . . This has really nothing to do with `Parallel::ForkManager`. You could achieve the same thing by calling `fork()` and `exit()` yourself, but then you'd have to keep track of how many child processes are alive at any given time in order to limit them to 30, and you'd have to deal with reaping all the dead children. 
It may be too late to save perl Language progress has just been too slow.
I wonder if we could do like... a parity checklist with other languages and see where we are weak. And then shore up those weaknesses. Like a missing framework or industry something.
I wouldn't say we're missing frameworks, in fact from a tech point of view we have a lot of technology on CPAN. Besides low level stuff, like microchips, you can do whatever you want in perl. What we're missing is a popular new thing(website, some form of an app, etc) written in perl that will hold up the Camel Flag. There is a lot of misconception about perl and old perl code that is harmful to us and we lacked some marketing and PR in early 2000s that kinda brought the job count down... Anyways I hope it won't die too soon, I'm still young and hope to retire still using perl for my main job
Win32::OLE is exactly what I needed. I got it running just the way I want it...Thank You!
 Yes, it may be moving faster now. But its too late. 20 years to have function parameters.
You really think that's what kept Perl from becoming mainstream?
Marketing.
&gt; Right now is a good time to be a Perl programmer. Perl is losing mindshare. Very few new Perl programmers are arriving on the scene and quite a lot of former Perl programmers have moved away from the language to what they see as more lucrative, enjoyable or saleable languages. This is like a pitch for learning COBOL 20 years ago.
Unfortunately Perl Mongers is dying too :( There's hardly any interesting talks these days, so getting together just for the sake of it is not useful for building a Perl community.
&gt; Actually in the last 5-6 years it had an increased dev and release speed. Sure, but what's the *vision* for Perl? Where's it going? What's driving it? Why are people using it? Let's seed the discussion with some answers for other languages: Node, Chef, Ansible, Rails, Django, Datomic, WordPress, Ember, Angular, React, Om.
Perhaps there are companies that actually need programmers that already have deep experience with Perl for some reason, e.g. contract work that requires cleaning up some existing mess in a short amount of time. I'd argue that aside from cases like that whatever your programming language you use you should be hiring people who know how to program in general, not people who happen to have existing experience in the language you're using. This is how we do hiring at Booking.com, and we hire a lot of people to program Perl. In our experience there's also pretty much no correlation between existing Perl skills and long-term productivity. Most of the work at getting up to speed at pretty much any company is learning their existing systems and why they're structured they way they are, not the programming language they happen to use. In summary, I think these companies have a self-inflicted problem with bad hiring criteria. They're falling into the trap of treating the hiring of programmers as something they can distill down to a checklist for existing skills, instead of focusing on their ability to learn and adapt, which is usually most of what a programmer's job is about.
&gt; This is like a pitch for learning COBOL 20 years ago. Or even now, actually, still COBOL stuff out there!
I think because a lot of people don't see any problem there. What sort of difficulty, specifically, do you see? Getting things _from_ CPAN is stupidly easy. Uploading is a little more complicated, but there exist several different tools that make the task almost painless. Searching is.. metacpan.org is pretty great, but what's left?
I think the vision is to keep code that's 20+ years old running (backwards compatibility). So where it's going (IMO) is mostly syntactic sugar and speed/space improvements. I am OK with that. If I want a cleaner language I pick Python, and if I want it more Perlish I pick Ruby (note: I know very little of Ruby, so I might be wrong there). One of the problems (I think / I am afraid) is that if you ask 5 people what should be fixed in Perl you'll get 5 mostly non-overlapping sets. And if you check those new languages they probably already exists as Ruby, Python, Haskell, etc. etc. Heh, maybe even Perl 6. ;-) 
It might help if you explain the exact issue(s) you're having.
So (again) what problem(s) are you having with modules. Also, I never wrote that the user has to evolve, or implied that this has to happen. I just explained why I think Perl was never mainstream.