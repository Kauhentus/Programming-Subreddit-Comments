And then goes to write a bastard perl4-written-as-C program for an example. pretty cool though
http://onyxneon.com/books/modern_perl/
Sadly that is from 1998 and thus *BADLY* outdated. You should really use the site chromatic mentioned and stick to the newest ones. There's plenty of choice. :)
For me, [Learning Perl](http://shop.oreilly.com/product/0636920018452.do) was a really good starting point, after that you can continue with [intermediate](http://shop.oreilly.com/product/0636920012689.do) and [mastering](http://shop.oreilly.com/product/9780596527242.do) perl, they are an actual trilogy so each book starts right where the other left off. The first two books come with an exercise section at the end of each chapter to practise what you have just read and it comes handy when learning.
At least we can be sure you're not a BASIC programmer: IF i_cant_spell THAN call syntax_error END IF
It's tchrist circa 1991. What did you expect?
Good point. I will make sure I double check the date of publication. 
I assume some programming knowledge. Someone who's never programmed before will have to do some homework first. (I still hope it's useful, but I assume readers already know how to use text editors and launch compilers.)
A 1000-message-long Usenet flameout, of course!
Dewd, dewd, you are seriously harshing the mellow. He's not a _time traveler_.
This presentation is one of my inspirations to get into speaking at conferences.
I posted this for the sake of novelty. It's really cool to be able to look back and see how far perl has come, and the elbow grease that it took to get us where we are today.
I wrote [Modern Perl](http://onyxneon.com/books/modern_perl/index.html) for people like you. If you learn the two or three pieces of philosophy that govern the design of Perl, you'll pick it up pretty quickly.
Yeah, just reading some of the scripts the guys I work with have written it seems really intuitive. I've been looking at [this](http://qntm.org/files/perl/perl.html) a little bit and I'm starting to like this language more and more. I'll be sure to check out your book, but I do want to say that it's very very cool of you to offer something you obviously put a lot of time into for free. If I like it I'll probably buy a copy just to help you out, thanks!
I will fix
NO
A good thing to learn early is that Perl has a number of predefined variables that refer to a variety of information. These are frequently used in programs, and not being familiar with them can leave you wondering how certain code segments actually work. Here's the perldoc [perlvar](http://perldoc.perl.org/perlvar.html) page for more info.
Btw, where do you work? Did they hire you as a Python programmer, if so why did they switch?
Not sure I should disclose where I work right now as they are very large and I'd hate to tie something back to me on accident. As for my position though, I'm not a programmer at all really, I learned Python for my own personal projects but I do 2nd and 3rd level support for thousands of workstations with hundreds of company and third party packages and it's very helpful to be able to quickly script out a fix for a package deployment or for something that is being broken by some package we haven't tracked down yet. The only thing holding me back is that Perl and Powershell are the only two scripting languages approved for our work in the environment, and I know only the tiniest bit about either, I decided to go with Perl though as the syntax and code structure seemed a lot more familiar to me than Powershells. I do plan on using and utilizing both in the future though.
Ah, very helpful indeed. And IMO that makes things a lot clearer when just glancing at a chunk of code.
Thanks for the answer. Congratulations on choosing Perl first (but also on learning both). Perl is available on far many more platforms and you'll find CPAN very helpful, as have I. 
Ah very cool! [Here's the link](http://www.cpan.org/) for anyone who is slightly lazier than me and might read this.
Thanks for that. I haven't seriously used Perl in over 12 years and I'm sure there is a gigantic gap in my knowledge so this will come in handy.
thanks mr chromatic I'm still reading it. :)
I know one of the Python mantras is "explicit is better than implicit". Be aware of some of the implicit features of Perl. For example usage of special variable $_ etc. 
I'm sure it hasn't change that much, just a few cpan modules here and there ;)
&gt; I've been looking at [this](http://qntm.org/files/perl/perl.html) a little bit That's one concise and extremely well written description of Perl. Thanks for sharing 
I actually found it in another thread here tonight! But don't remember where... It's made me feel very good about Perl so far, too bad I couldn't find anything like this for powershell lol.
https://metacpan.org/
I love you reddit, I came here looking EXACTLY for this &lt;3
By any chance, could anyone suggest the exact opposite? I have some middling perl experience and I am looking to expand into python. 
*Yet.*
You could be lucky, but by default you're on the wrong subreddit for that.
forget everything
Check out brian d foy's "Perl traps for Python Programmers" http://blogs.perl.org/users/brian_d_foy/2011/10/perl-traps-for-python-programmers.html (And the comments). The contents are also in the camel book (Programming Perl, O'Reilly).
On the contrary, there was a tremendous influx of enhancements; you can still run and write code in 1998 style, but there's really much, much better ways.
I would use 'use strict' and 'use warnings'. One thing that caught me early on is that uninitialized variables have a value of 0 or "" when they are used. using strict and warnings helps catch things like that. The only thing annoying about that is having to prefix every variable (even global) with 'my'. This kind of thing can be deadly: $elephant = 100; $tiger = $elpehant + 200; print $tiger; # =&gt; 200 But: use strict; use warnings; my $elephant = 100; my $tiger = $elpehant + 200; # ERROR print $tiger; 
'use diagnostics' is also great, because it explains beginner errors.
the use of unless is missed :)
i just started using prove in a Jenkins system, and -l is exactly what i needed. thanks!
Perl::Critic is awesome, highly recommend pairing it with [Perl Best Practices](http://www.amazon.com/Perl-Best-Practices-Damian-Conway/dp/0596001738/ref=sr_1_1?s=books&amp;ie=UTF8&amp;qid=1322806909&amp;sr=1-1). i can never remember which came first, but this book tackles the pros and cons of many of the critiques very well. 
Very enjoyable article, but this comment in the code has me scratching my head: \# perl arrays are always references so this is in-place \# editing! Perl arrays are obviously not "always references." Does the author mean pass by reference, as opposed to pass by value? Also, what are some other reasons to avoid backticks?
_head explodes_
He is right that the edit happens in-place but for the wrong reason. Some would say he is abusing map and for would be more correct: for (@JobResults) { s/^\s*\d+\s// };
&gt; Does the author mean pass by reference, as opposed to pass by value? The article should probably say "When iterating over an array, the iterator variable is an alias to the elements of the array."
I always feel like I let myself down when I bust out the ``. I am glad to see a nice way of capturing output. I can't wait to try it.
What exactly is your problem statement? Can you give some examples and sample input output?
The article author doesn't seem to know about [Capture::Tiny](https://metacpan.org/module/Capture::Tiny), which is by the same person as IO::CaptureOutput (David Golden), was meant to replace it and is undeniably superior.
It sounds like you want an [interval tree](http://en.wikipedia.org/wiki/Interval_tree), possibly? That would take some time to implement in perl, but CPAN comes to the rescue as usual with [Set::IntervalTree](http://search.cpan.org/~benbooth/Set-IntervalTree-0.01/lib/Set/IntervalTree.pm). 
Well, I know what I'm doing on Monday. A very big *thank you*! 
sorry about the formatting issue :P
&gt; But I swear to God, if I get one single perl 5.6 support request I'll dial the whole thing all the way up to perl 5.14. *This* should have been the reddit headline! :)
Dang, you're right. Too early to be posting. Also, for some reason this thing is getting mad upvotes in progreddit.
Calling functions with &amp; can have unintended consequences; better to leave it out.
How do I call them then? When I remove the ampersand I get this: Bareword "print_help" not allowed while "strict subs" in use at ./spotify-dbus.pl line 22. Execution of ./spotify-dbus.pl aborted due to compilation errors. 
`print_help()` will work fine. :)
Indeed it does! =D It is probably to high tech for me to grasp, but could someone try to explain the difference between using the ampersand and not?
Ampersand is a remainder from younger times of Perl. In the past it was necessary, now it is not anymore. However, you can have interesting side effects. Consider: sub moo { &amp;meep; } sub meep { print "@_;"; } moo( "hi" ); Conventional wisdom says this will not print anything, but the "hi" is indeed forwarded to meep, silently. You might not want this to happen.
In Perl 4, the ampersand was necessary for calling user subs. In Perl 5 it's not necessary or recommended, but it's there, mostly for the benefit of Perl 4 code. Perl 5 has been out for 17 years. This still hasn't stopped certain tutorials on the internet from using the &amp;.
You could also declare your subs before they are used: sub print_help; .... print_help; .... sub print_help { .... }
TIMTOWTDI, but this line is a little overly verbose to my eye: if (scalar @ARGV == 0) { &amp;print_help; } The scalar context is implied and 0 is false. Sometimes simplicity increases clarity. Of course, you can go too far. if (@ARGV == 0) { print_help() } if (!@ARGV) { print_help() } unless (@ARGV) { print_help() } print_help() unless (@ARGV); Personally, I'd go with the last one but it is really a judgment call. Also, if you end up doing any more than simple command line tokens, you should really use a module for parsing. Getopt::Long is the classic option but see [this recent post](http://www.reddit.com/tb/mxea9) for some others.
I'll spot you two characters: print_help() unless @ARGV;
`@ARGV or print_help();` :smug:
Input looks like : GA26895_1509_1772 #genename_startbp_endbp AND a file including many lines of intervals: 223189\t172530 I want to be able to search for startbp and endbp in the file with lines of intervals and print genename to an outfile associated with that. 
Others have already mentioned the obvious ones. Here's a few more notes. In general, you can do most things more efficiently without having to call out to external programs. Instead of executing `whoami`, perl gives you the built-in variable `$&lt;` for the current effective UID and `getpwuid()` which if evaluated in scalar context gives you the username corresponding to that uid. Also, there's no need to call out to `grep` just because the data contains NUL bytes. I would have implemented your `set_DBUS_SESSION_BUS_ADDRESS` like this: sub set_DBUS_SESSION_BUS_ADDRESS { my $curruser = getpwuid($&lt;); chomp(my $pid = `pgrep -o -u $curruser spotify`); my $dbussession = do { open my $env, "&lt;", "/proc/$pid/environ"; local $/; $1 if &lt;$env&gt; =~ /DBUS_SESSION_BUS_ADDRESS=([^\000]+)/; }; $ENV{'DBUS_SESSION_BUS_ADDRESS'} = $dbussession if $dbussession; } Notes about this: - The assignment operator returns the lvalue, so you can `chomp()` and assign with one statement. - Lexical filehandles automatically close when they go out of scope, so there was no need for `close($env)`. - This assumes that `use autodie` is used (always a good idea) which means there was no need to check the return value of `open`. - `local $/` sets `$/` to `undef` for the duration of the `do` block, which means that `&lt;$env&gt;` reads the entire contents of the file. It's not strictly necessary here as usually you don't have any newlines in any environment variable, but it's better to be explicit. - The value returned by the `do` block is the last expression evaluated, which will be `$1` if the match succeeded, otherwise it will be the value returned by the `m//` operator (since the `=~` is the last thing evaluated) which is a false-but-defined value. So the environment is only modified if `$dbussession` is a truthy value. This construct therefore won't work if a valid setting for the variable is something like `0`, but I don't think that's an issue here. Further notes: It's not generally necessary to make a copy of a return value like this: # Dereference the metadata hashref by copying it to a local hash my %metadata = %{ $getorset-&gt;Get("org.mpris.MediaPlayer2.Player", "Metadata") }; # Print all metadata print "Now Playing:\n"; for (keys %metadata) { print $_ . ":\t" . $metadata{$_} . "\n" unless ($_ eq 'xesam:artist'); } # Dereference the artist arrayref by copying it to local array my @artistarray = @{ $metadata{'xesam:artist'} }; # Print all artists. foreach my $artist (@artistarray) { print "artist: \t" . $artist . "\n"; } I'd write that as: my $metadata = $getorset-&gt;Get("org.mpris.MediaPlayer2.Player", "Metadata"); say "Now Playing:"; for my $k (keys %$metadata) { if ($k eq 'xesam:artist') { say "artist:\t$_" for ( @{$metadata-&gt;{$k}} ); } else { say "$k:\t$metadata-&gt;{$k}"; } } This also shows that you can use string interpolation instead of concatenation. (And you're already `using 5.010` so you might as well take advantage of `say` which adds a newline.) 
Shorter yes, but violates the end-weight principle in my eyes.
I have this vision of the OP loosing it by the end of the post. "Alright, so Perl 5.8.2 it is, but so help me God if any of you fucks ask for 5.6 support... I swear I'll take this shit to 11! BLOOD WILL RAIN FROM THE SKY AND ALL WILL ADOPT 5.14!"
Yeah, sorry, but i really do not want to see this kind of golfing spread around.
Took me a day to set up a build of "latest perl/apache/mod_perl/cpan" for a company. And five months tweaking it to get it right ;)
This is much friendlier than bc because you don't have to do that awful syntax echo '1+1'|bc -l 
What do you mean?
I have a slightly more sophisticated script that I use to do general calculations from the commandline with perl. I call it **pc**: https://github.com/dbb/math-scripts/blob/master/pc The best part is that you can easily add your own functions to the script. I know that evaluating user input is generally frowned upon, but even with my rudimentary security checks, I've managed to use this script for 2 years without destroying my computer.
Perl has a stupidly bad reputation for being hard to read already. Spreading such golfy hacks just hardens that reputation and damages the language.
shit? really? The friggin book I've been using matches the style of code that OP has.
Instead of this hacky mess, install [Devel::REPL](http://search.cpan.org/perldoc?Devel::REPL::Overview) and you get a full interactive perl shell where you can run evaluate any expression, including defining variables, functions, etc. 
Now it just needs to integrate PDL so it can be used for linear algebra.
Yeah but then you can just do bc for an interactive shell calculator
It's also much safer, since it doesn't eval arbitrary code. 
I don't get why people are stuck with say 5.8 yet they still want to use new modules. At worst it's a matter of installing yet another perl. Anyone who has used commercial products on linux is surely familiar with this model. A complete tool chain for every product.
My very simple Perl shell: use strict; use warnings; my $input; $| = 1; while (print('psh&gt; ') &amp;&amp; defined ($input = &lt;STDIN&gt;)) { chomp $input; last if $input =~ /^[q\.]$/i; print eval $input, "\n"; } Yes, it uses `eval`, but this is for my use only and I can be trusted.
Either strict just caught a typo in that code or elpehant is just a small tiger.
Oh and the need for "my" helps with scope issues.
I am writing the [Perl Maven tutorial](http://szabgab.com/perl_tutorial.html) that might help you.
I like how he summarized his findings in a tl;dr ;)
I bet this problem has been solved in this project. http://www.bioperl.org/wiki/Main_Page
C'mon, for 10 usd/month you can get decent VPS and install on it whatever you want, no need to stick with plain old CGI. I, personally, recommend [EDIS](http://en.edis.at/), you can find more offers at [LowEndBox](http://www.lowendbox.com/).
Agreed. I use Linode, which is a bit more expensive, but a great service.
Use [Plack](http://plackperl.org/) to abstract your webserver so you can easily switch between mod_perl/FCGI/CGI/etc. [perlbrew](http://www.perlbrew.pl/) to compile newer Perl versions and/or [local::lib](http://search.cpan.org/perldoc?local::lib)+[cpanm](http://search.cpan.org/perldoc?cpanm) for installing CPAN modules. Also, consider VPS as x3nu says.
`mod_perl` is huge overkill for almost any web app. FastCGI has the same performance without being welded to the Apache platform/binary/userid. You should probably be using Plack on the Perl side instead of talking to FCGI directly.
I do that for myself for a pile of sites and I am a big fan of running on a VPS. Unfortunately there are a couple downsides for what I am trying to do. Usually the VPS hosting is very weak in that price range. You have a small slice of CPU and RAM, limited storage, bandwidth caps, etc. With the cheap generic hosting you get a lot more for your money (at the cost of full control and flexibility.) The other thing is if you are making sites for other people that aren't too technical then VPS doesn't work as well, at least if you aren't going to be the one taking care of it once it goes live. They'll often need managed service, and so costs are even higher. The generic hosting providers give fancy web interfaces for controlling everything, which tends to help when people who aren't overly technical are managing everything. I do like using a VPS though. I prefer Postgres over MySQL, and it is nice on when using virtual servers that you can make all those choices on your own. For my tasks at hand though I really need cheaply hosted and portable sites with benefits like large amounts of storage and bandwidth that would cost a lot more on the VPS side. Thanks for the links though. I will check them out. If a VPS provider could meet the needs that would make life a lot easier.
mod_perl gives you a lot more control. I agree you can manage similar performance in most cases with FastCGI, but there are a lot of things that are only possible on mod_perl, at least if you want to interact with and tweak the apache guts heavily. The sites I am trying to put together now don't need any of the mod_perl magic though, so I agree FastCGI is likely an alright path. You are the second person to mention Plack. I've definitely got to check that out.
I don't understand why people are still running Perl 5.8 on RHEL/CentOS - there is ActivePerl which doesn't replace system Perl so it is safe to install (and easy, there's RPM package!). 
From [2 years ago](http://www.reddit.com/r/programming/comments/9k3tu/regular_expression_matching_can_be_simple_and/), &gt;* DFAs are only faster in the worst case scenario (relative to regexp structure, independently of data), for normal regexps there's no difference. * DFAs force us to abandon many extremely useful features, and don't provide any in exchange. Trying to emulate these features without regexps would be extremely slow, and painful to programmers. * There are virtually no real programs where regexp engine performance is the bottleneck. Even grepping the entire hard disk for something is really I/O bound. &gt;Given these facts, it's understandable why programming language implementers are not impressed.
Another option is to use Mojolicious with any virtual hosting. You'll be limited to version 1.99, because they've bumped the requirements to Perl 5.10 starting Mojolicious 2.0, but it's quite mature at 1.99 to write serious web apps. Mojolicious is quite popular and has good documentation (though it being developed rapidly, and I think they update docs for the latest version too). Dancer is also popular, and it's similar to Mojolicious in many ways. Though I know nothing about other that it exists, and it's also relatively popular.
Oh Christ, not this FUD *again*. Look, if you want to write and maintain a parallel DFA-based regexp implementation, then post to p5p offering to do so. I'm sure they won't laugh at you too hard. **Edit**: oh look, [here I am saying the same thing two years ago](http://www.reddit.com/r/programming/comments/9k3tu/regular_expression_matching_can_be_simple_and/c0d3ne7).
Agreed. Very good article overall, the only thing I feel missing is a non-Dancer sample Perl code. But this is a Dancer article after all :) To use Bcrypt outside of Dancer, check out: https://metacpan.org/module/Authen::Passphrase https://metacpan.org/module/Authen::Passphrase::BlowfishCrypt I admit, I still use MD5/SHA1+salt :) 
Correct, the cheapest VPS offerings sometime come with no backup (!!!), no user control panel (e.g. cPanel/WHM), and minimal support for the inside of your system. You have to pay extra for those. And often you will need all these since you're giving access to tech-unsavvy website owners. There's a reason why shared hosting is still alive and it's not only cost: they're simpler to manage. 
Yes, use something based on Plack/PSGI, can't be said often enough. I'm still wondering if the popularity of mod_perl has backfired and pushed Perl back 5 years in web development? 
When was the last time a normal web *application* need to tweak Apache guts? I use mod_perl in a control panel application, but only for managing and customizing Apache behavior. And I'm looking to replace this scheme since I really want to support nginx (and possible future other webservers). Apache is still going strong, but not nearly as dominant as it used to.
Even if you don't use Mojo, take a look at [Mojo::DOM](https://metacpan.org/module/Mojo::DOM). It's seriously cool. 
Btw, there's this [Perl Incompatible Regex Engine](https://github.com/dprokoptsev/pire) if you want faster (but more limited) regex. Doesn't seem to be catching on though. 
Rerererepost.
If you mean that the awesomeness of mod_perl limited the motivation to create something better, perhaps that's true.
Kind of. mod_perl is powerful no doubt but because it's popular it's being used even though it's not the right tool for the job. Sometimes people just need a faster/persistent CGI to deploy their webapps. The popularity of mod_perl also takes focus of Perl developers from alternative webservers.
mod_perl did two unrelated things: * allowed Perl control over the entire Apache httpd request/response cycle * provided a persistent environment for Perl-based programs I suspect that the latter was far more popular than the former.
&gt;some clever maths geezers figured out how to reverse MD5 very quickly Details on this? I think reverse might have just been a poor choice of words.
And, in fact, [here's a CPAN module](https://metacpan.org/module/re::engine::RE2) that replaces Perl's regex engine with a DFA-based one within a lexical scope, falling back to Perl's engine for regexes it can't handle. OK, problem solved. Game over. Nothing more to see here, folks.
So how exactly would one go about generating salt / storing it?
Just to make sure, the downvotes aren't over the content, are they?
I just checked, and all the Perl Advent Calendar submissions on the frontpage are unique. Maybe people aren't reading and just skimming? In any case, I'm installing App::cpanoutdated right now :-)
Huh, maybe that's what it was. Thanks for pointing the similarity out. :) Also, man, one day i really do need to make that website that makes personalized rss feeds for cpan updates.
I thought the proper solution was always to fiddle with `%SIG{WARN}` and use [`Log::Dispatch`](https://metacpan.org/module/Log::Dispatch). But what do I know.
Now watch someone do this in a CPAN module and suddenly everyone's script doesn't print warnings.
Redirecting STDERR will also redirect anything like print STDERR "text" while that won't trigger $SIG{\_\_WARN__}. In some case that's what you want, but it is not the same. 
If *local* is used then it won't happen as the change will be localized to the module.
Well shit, I'll go back to my corner now.
I forgot to add local to the first version of this post and only added after an IRC comment. Let's sit together in the corner.
Think about corporate code. Most of the print STDERR statements will come from the in-house code added there on purpose. Most of the warnings will come from perl itself unwanted.
Incredible answer! Thank you! I've been meaning to get back to you after upgrading my code according to your suggestions, but I haven't found the time so I'll just write this so that you know that I appreciate the effort you put into this. Again: THANKS!
&gt;Really, **Encode should not be dealing with folding.** Amen. the whole time while I was reading this post, I was thinking to myself: what the hell has processing Unicode text to do with "folding", which is an act of processing email headers?? Clearly, [Encode](http://search.cpan.org/perldoc?Encode) is overreaching.
I'm really happy that he's putting the work in to remove the reliance on globals. :)
Nice! A simple version check command is very helpful.
He's doing both Advanced and Beginner courses and if you hunt around on his site you'll find time limited discount codes for both - really big discounts. His tutorials so far have been excellent so I signed up for both.
I use a simple script to check modules' version, but this trick is cool. A couple of caveats, some module have high versions (like 20111208) and it exits with a non-zero status (not a problem unless you need to check exit status). Also, if version is not high enough, you need to Ctrl-C as it will "hang".
thank. Please note, the Beginner course has two separate parts (listed on the same page)
Looking forward to more tutorials in this series. I've known about Moose for a while but never really got into it, because Perl's rudimentary object model support has been fine enough for my purposes but it'll be interesting to learn more about Moose and find out what its advantages are.
For someone like me, who is still learning Perl, I find using the Moose methods to be a lot easier to build OO code than the built in Perl methods. 
I also emailed you when I signed up. Senior linux sys admin looking to improve on his Perl. :) I got the beginner's course because I know there are some things I am missing (being self taught), I like your tutorial style and, with the discounts, it was a no brainer - thank you.
Moose is a way to save a _lot_ of typing. For the most part, it also saves you from making a lot of really bad OO design decisions (though in the spirit of Perl, doesn't force the issue). Inheritance is a huge thing with Moose. It's so damned easy. Attributes in Moose can have a type, and you can make your own types, and coercing one type into another (say your user passes you "2001-12-08", you can do some work and end up with a DateTime object in your attribute) automatically is easy. Roles ("mixins", sort of) are insanely useful and take the idea of code reuse to a whole new level. Finally, becuase Moose is built on top of `Class::MOP`, you can do some crazy awesome stuff with the meta model and introspection (naval gazing) to find out things about a class or object at runtime, and even alter a class at runtime -- like say, add a new method, and without futzing with the symbol table (I'm looking at you `SOAP::Lite`..)
Oh, that's you. Sometimes it's a bit hard to connect names with nicknames. Thank you for your comment in both places :)
Done! I'm taking intro courses through OST (O'Reilly) and want to round out my modules know-how. I wonder if there are any testing-specific courses on deck. I'd really like to drill down into automated testing, for Perl and otherwise.
not the worst perl tutorial that I've read. Needs a bit of updating though.
I am going to do a testing course too. Soon.
Oh man, those guys are hilarious.
s/for Perl/for austria.pm/;
The other teams had such Perl persons as mst or Florian Ragwitz among them. I'm not blaming them. Just saying that you can't just say "Oh, austria.pm just had a bad team." when they were even better than some of the best coders Perl has to offer. This is an interesting Post-Mortem from mst: http://www.shadowcat.co.uk/blog/matt-s-trout/plat-forms-redux/
i thought at first perlweekly was just a bunch of your beginner tutorials, since my feeds seemed to be bombarded by them earlier (before i filtered them out). now i see that there is stuff in perlweekly which might interest me, but i already get it all from other sources, like perlbuzz.com and blogs.perl.org, ironman, etc. also, email newletters are passe nowadays- inbox 0 is teh new cool. and your rss feed has the same problem in that the news items have already been seen by users by the time it hits your feed. so your main problem is no unique content. it would make sense if perlweekly was somebody's only source of perl news, but that is very unlikely to be the case. something i would be interested in would be a perl planet that aggregated from multiple sources, but filtered out the duplicates items. i see the same items in blogs.perl, perlbuzz, ironman, perlsphere, etc. and tagging/categorization, so i could avoid beginner and p5p stuff.
I think the question here is: How to reach the people who aren't already using these sources. What other websites would people read who use Perl, but don't read blogs.perl.org daily?
I commend you for looking at your "baby" and deciding that it needed "changing". :) Looking forward to D2.
What Mithaldu said but also, regarding the "newletters are passe": The Ruby Weekly http://rubyweekly.com/ has over 10K subscribers. Of course it is more than a year old but it shows even among the "cool kids" there are many who like newsletters.
Talk team leaders in large companies that do Perl development into forcing their developers to subscribe to your newsletter ;-)
Almost good :) How do I reach the team leaders? Or how do I reach any Perl developer in those large companies?
Kinda sad/ironic to see "powered by python" on your subscription page (eg [here](http://mail.perlweekly.com/mailman/confirm/))
Do you offer guest spots? If you want promotion, the easiest way would seem to be promoting other people's stuff to your subscribers and vice versa. This doesn't mean hawking viagra, it could simply mean including articles of mutual benefit. For example, if I work for BigCo Inc, and I use Perl, my boss will be happy if I have an article published about how I used perl at BigCo, this innovative and intelligent company, to solve a certain problem. This could also lead to extra exposure within BigCo. Equally if I've got MyTechBlog.com, maybe cross-posting to your newsletter would give my blog some exposure. Having something in your newsletter might have a certain cachet, and maybe I would post a link from MyTechBlog back to your newsletter. From my experience this is exactly what most tech conferences are about - companies showing how intelligent they are to get a bit of free publicity. :-)
mailman is a Python application for lists. Nothing sad nor ironic about that.
perlweekly is enough, don't dilute the interest with too much noise
Based upon looking at the page you linked. Tell me what you will and won't do with my email address. "Your email address is safe." does not define "safe". I want to know that the address won't be sold and that I won't be marketed to, or if I will, how much (so that I can decide whether it's within limits I can tolerate). In short, build trust. That said, if you reassure me, I'll probably sign up. And yes, I used to use separate email addresses for such sign-ups, and blah blah blah. But now I'm old and tired and can't be bothered. ;-)
It is ironic. And sad.
Get in the top few results [here](https://www.google.com/search?q=perl&amp;ie=utf-8&amp;oe=utf-8&amp;aq=t&amp;rls=org.mozilla:en-US:official&amp;client=firefox-a).
 die "Usage: rename [-v] [-n] [-f] perlexpr [filenames]\n" unless GetOptions( 'v|verbose' =&gt; \$verbose, 'n|no-act' =&gt; \$no_act, 'f|force' =&gt; \$force, ) and $op = shift; You're looking for that last line. The script get passed in "$op".
Blind language dogmatism is what's sad. I hoped Perl 5 users would be more mature than that. If you have any *constructive* criticism on the topic, I'm sure a link to a Perl 5 mailing list manager would go appreciated.
It would be nice if it was in the top sites of [perl news](http://www.google.co.il/search?client=opera&amp;rls=en&amp;q=perl+news&amp;sourceid=opera&amp;ie=utf-8&amp;oe=utf-8&amp;channel=suggest) but look what's number one hit there. Still use.perl.org
Assuming blind language dogmatism is sad. What's a VALID point is that it's ironic that clicking a link to a Perl list brings you to a page where Python is thrown in your face. From a PR perspective, this is ridiculous. From a practical point of view, it's understandable - who wants to rewrite Mailman in Python when it already exists? Is there anything sad about this? Maybe - but it's not germane to the OP's point. His point is that it affects Perl users (especially new ones) like it or not. I am simply writing in support that the OP has something valid to say about seeing "powered by python"; what's really, really sad is that he's being down voted.
Good idea. Maybe with some modification. I don't include "original content" in the Perl Weekly just links to original content. If a company publishes some interesting article on how they use Perl I'd probably link to it and distribute it to the subscribers. The question how to get the companies to write such articles. 
What's sad is he said it at all. It is immature and doesn't detract from the Perl message at all. Dogmatism is sad.
I agree with your point "the need of trust". I just don't know how much and which text is needed to gain more trust? Would you trust a random web site just because it displays "we won't sell your e-mail". Would other people need a 90 lines long page on privacy policy? Maybe yes. Though I am not sure why would any of those give more assurance. I feel that trust is more a question of people getting recommendation or knowing me from other places and thus trusting me. (BTW looking at http://rubyweekly.com/ or http://javascriptweekly.com/ , that's where I got the idea from.) 
$op contains the first argument to the script, e.g. "s/foo/bar/", which operates on $_, while $was retains the old filename. The rename takes place in the 'elsif' block a few lines below that.
The eval does not rename the file. It modifies the default string (`$_`) according to the perl expression given on the command line. The actual rename occurs a few lines down: elsif ($no_act or rename $was, $_) 
doh! I can't believe i didn't see that. It all becomes clear now... 
I take your point. But, in the past, I've been satisfied with relatively brief statements -- when I have enough contextual knowledge to have some comfort with the source -- stating that a party won't share or sell my email address and will not spam it with marketing (if there's limited, internally driven marketing, stating so upfront usually leaves me comfortable with that). I like a bit more than just the word "safe", but I don't need a lawyerly treatise in such a context. :-) Oh, clarifying that the user can remove themself from the list at any time I also find reassuring communication. Again, along the basic lines of "the user's in control of their subscription". You did ask about getting more peoples' attention. These are things I look for when deciding whether to sign up. Basically, can I trust this to not become a hassle? Oops. Had a look, now, and I see that you changed the text. (Or I was more tired than I realized, at the time of my last comment, and wasn't seeing clearly.) &gt; Just ONE e-mail each Monday. Easy to unsubscribe. No spam. Your e-mail address is safe. I think I'm comfortable with that. Thanks!
I am glad that's good for you. It was there all the time but I admit the page is a bit cluttered. I should make it somehow clearer.
I am sorry, I don't understand this comment.
Can someone get MJD to come to YAPCs again and give talks there too?
mjd is 'hobbit'?
I think that if your work is web development and site management then placing "cheapest" in front of "most reliable and supportive" are like putting the cart before the horse. After 9 years in this specific part of the business, I can say for certain that placing that much emphasis on the cost is a huge distraction, and possibly the margins of your business model are slim enough that you are constantly reminded of the costs. Now I would agree that if you are going to be reproducing the same basic product en masse then it doesn't make sense to pay top-dollar... but that's what reseller accounts are for. If you're a developer of sites that wants hosting control of the client sites you develop, then a reseller plan should be fair route that allows you to worry about a hosting operation's support depth (knowledge, coverage, personality, etc.) then the absolute cost. If you're going commodity/wholesale hosting then I suppose a few dollars here and there is worth haggling over, but if you are going to look for a host that you actually want to depend on at some point, then haggling over a few dollars is going to lead you away from the optimal host, imho.
Perhaps I'm not yet a perfect sage.
He spoke at [PPW](http://pghpw.org/ppw2011/talk/3861) in October...does that count?
I tried doing this a while ago in a program using multiple worker threads, and nothing I tried would change the threads' `$0`. Would 5.14's new method have worked there? Neat use of object stringifying, though.
You are pushing the same hash every loop. Make a new hash inside your loop and push each one onto the array. 
Try this: use Data::Dumper::Dumper; my @record = (); foreach my $ar (@array) { my %records = (); ( $records{date}, $records{port}, $records{owner}, $records{name} ) = split( " ", $ar ); push( @record, \%records ); } foreach my $a (@record) { print Data::Dumper::Dumper $a; } 
Also, you can assign to a hash slice like so: @records{qw/date port owner name/} = split " ", $ar; Also, it's generally not necessary to set arrays or hashes equal to `()` when you declare them. They will be autovivified the first time you assign to them. 
Absolutely correct, but minor nits of phrasing: &gt; ... it's generally not necessary to set arrays or hashes equal to () when you declare them. It's never necessary. They're always empty at the point of declaration. Unlike C, where declaring a variable means it contains whatever's in the appropriate memory location is the value of the variable, Perl variables start out with known contents. &gt; They will be autovivified the first time you assign to them. Autovivification generally refers to the automatic creation of intermediate containers of the appropriate types. The underlying SVs, AVs, and HVs are all created ready to store things at the point of declaration.
Yup. Like: foreach my $ar(@array) { ($date, $port, $owner, $name) = split(" ", $ar); push (@records, {date =&gt; $date, port =&gt; $port, owner=&gt;$owner, name=&gt;$name}); }
Are you using a web framework of some sort or processing incoming form parameters yourself? If the latter, save yourself some time and look at CGI.pm's param() method.
I use Data::Dumper a lot - but I only do: Use Data::Dumper; ... print Dumper(\$thingy);
Exactly! CGI.pm is your friend!! It is going to save you huge amount of time and hassle. Have a look at these (it's really straightforward): http://perldoc.perl.org/CGI.html and http://docstore.mik.ua/orelly/perl/perlnut/ch10_01.htm Example: create your radio button: radio_group(-name=&gt;'name', -values=&gt;['value1','value2'], #or just put your buttons into an array -values =&gt;\@values, -default=&gt;'value2'); Then pick it up with param: $selected = param ('radio_group');
What no one has told you yet, is WHY you're output is the same hash repeating. That lies in the line "push(@records, \%record);" You're not pushing a hash onto the array, you're pushing a reference to the hash. Which, on the next iteration you are modifying that same hash. SO you're array is filled with N number of references to the same hash in memory, which is why it repeats when you output it. Do this instead: my @records; foreach my $ar (@array) { my %hash; # populate the hash push @records, \%hash; } print Dumper(\@records); This way you create a new hash and stick a reference to that new one onto the array on each iteration. 
Hey, I tried what you suggested. This is my code so far: print $query-&gt;radio_group(-name=&gt;'$row[0]', -values=&gt;['$row[2]','$row[3]','$row[4]','$row[5]'], -default=&gt;'$row[2]', -linebreak=&gt;'true', -labels=&gt;\%labels); $qselect = $query-&gt;param('$row[0]');
for some reason it does not want to loop through and it doesnt generate a radio selection. print qq~&lt;form action="login.cgi" method="POST"&gt; ~; while (@row=$sth-&gt;fetchrow_array()) { print qq~ --------------------------&lt;br&gt; Question #$row[0]&lt;br&gt;&lt;br&gt; &lt;img src="/images/$row[6]"&gt;&lt;br&gt; &lt;b&gt;Question&lt;/b&gt;: $row[1] &lt;br&gt;&lt;br&gt; ~; print $query-&gt;radio_group(-name=&gt;'$row[0]', -values=&gt;['$row[2]','$row[3]','$row[4]','$row[5]'], -default=&gt;'$row[2]', -linebreak=&gt;'true', -labels=&gt;\%labels); $qselect = $query-&gt;param('$row[0]'); }
if you want to know which radio button is selected - you need to do $query-&gt;param('radio_group'); - not $row[0] 
Why is your "html" part in a loop? Do you want radio group for every entry in the DB?
Yea but my radio group name is $row[0] which pulls from a MySQL table a question ID#
Yes
so basically, the group name is ie. 65
No matter what I do, server isnt "compiling" my cgi.pm form. It ignores it and doesnt do anything. Do i have to have a certain module enabled? Currently i have the following: use DBI; use Digest::MD5 qw(md5_hex md5_base64); use CGI qw/:standard/;
Get rid of the single quotes; you don't need interpolation, and variables in single quotes don't interpolate anyway.
From reading the other comments here, it seems you are somewhat confused as to how the whole browser / server thing works. You are asking us here: &gt; After I've a `&lt;form action="http://example.com/some.cgi"&gt;`, I am having trouble retrieving the form elements with perl. We are assuming that you have properly created your HTML form already. Somehow. How matters not. We're assuming that you've got your server properly configured to handle CGI scripts, that `some.cgi` exists, and that it is Perl code. If you are using "regular" CGI: In your HTML: &lt;input type="radio" name="someparam" value="oranges"&gt;Oranges! &lt;input type="radio" name="someparam" value="apples"&gt;Apples! In `some.cgi`: use CGI; .... my $variable = param('someparam'); And then you can, somewhere, print $variable; And get "oranges" or "apples" depending on what the user selected. Some tips on configuring Apache for using CGI: [http://httpd.apache.org/docs/2.0/howto/cgi.html](http://httpd.apache.org/docs/2.0/howto/cgi.html)
Generating the form and receiving its response are two separate HTTP requests, and therefore two separate invocations of your script (or two entirely different scripts even.) It sounds like you are very confused about HTTP works, as your script can't know what was selected until you render the form, send it to the browser, terminate, wait for a response, and then start executing the script (or a different script) anew from scratch. The two phases are quite separate, but it seems like you're trying to do them at the same time. 
No, i know thats the issue. we've been battling that for hours. because we have to somehow find a way to keep all of the answers that are generated since it is going trough a loop that $answer will have "n" meanings, 1 for each row in the survey table
Yeah I never created a perl form before and forgot to take out the HTML form parts... so they were conflicting. I fixed that issue by inserting all of the cgi.pm equivalents but no to avail the script still didnt work. When I viewed my page, it would break trying to create a form and turn up blank. so now i revered back to a full HTML form and am using my $choice = param('$row[0]'); to grab the answer they chose... but that still isnt working. It just turns up blank. I even have it a part of the loop and the script calls itself to process so i can test it... the main issue s I have a loop generating a form and then pulling the answer from each question individually and inserting that into a table 
Huh... alright. 
That makes perfect sense. It is just the same hashref I am pushing to the array. I moved my hash declaration inside the loop and now I get a new hashref each time. I tested it and it works. Thanks!
Thanks! I tried it and it works perfectly. I'm not sure why I didn't catch that earlier.
Interesting. So I don't need to give the hash a name at all, I can just push elements of it to the array. Is it still just pushing a reference to the array, or actual values?
Another US-only goodness...
&gt; my $choice = param('$row[0]'); to grab the answer they chose... So you have &lt;input type="checkbox" name="$row[0]" value="oranges"&gt; What a strange thing to name your input fields. Perhaps you are confusing the name of the variable and a value? Examine again the HTML example I provided above.
Look at prior art. There's a project to reimplement all the unix system utilities in Perl. Go find that and copy what they do.
check [App::Rad](http://search.cpan.org/~garu/App-Rad-1.04/)
I changed the name to name="answer" and value="row[2]" It still doesnt want to output the value to me when i call it from the parameter. 
For command line parameters, _definitely_ use any of the `Getopt` modules. [Getopt::Long](http://search.cpan.org/dist/Getopt-Long/) is a clean and default solution bundled with Perl, but there are a hell of a lot of [alternatives](https://metacpan.org/search?q=Getopt). If you're suffering from option overload, just go with Getopt::Long. You may want to look into toolkits like like [App::Cmd](http://search.cpan.org/dist/App-Cmd/) or the [Moose CLI modules](http://search.cpan.org/~doy/Task-Moose-0.03/lib/Task/Moose.pm#Command_Line_Integration), though it's entirely possible that they're overkill.
I created [CBSSports::Getopt](http://search.cpan.org/~jbisbee/CBSSports-Getopt-1.1/lib/CBSSports/Getopt.pm) to address this problem at CBS. It provides cbs-script-starter, which creates the initial script for you (pod docs included) and uses [Getopt::Long](http://search.cpan.org/~jv/Getopt-Long-2.38/lib/Getopt/Long.pm) and [Pod::Usage](http://search.cpan.org/~gsar/perl-5.6.1/lib/Pod/Usage.pm) under the hood.
You're still doing it wrong. You do not appear to understand how HTML form submission works. Your form: &lt;form action="some.cgi"&gt; &lt;input type="text" name="bobs_input_field"&gt; &lt;input type="submit"&gt; &lt;/form&gt; You put that in some random .html file. You load it up in your browser. You get a text box and a button. You type "oranges" into the text box. You click the button. The browser _then_ makes a request. The server receives the following HTTP GET request: GET some.cgi?bobs_input_field=oranges If your server is properly configured to handle CGI requests and pass URI parameters to the CGI, and that CGI is a perl script, and that perl script has `use CGI;` like we've told you, you can type: print param('bobs_input_field'); And you will get `oranges` output to STDOUT. In some cases, that will send `oranges` as the only response to the browser. You may be output something different, like properly-formed HTML. That's a detail left up to you. But regardless, reading the other answers here, it appears you are in way over your head. I would suggest either reading some serious stuff on topics like Web Development, the HTTP request cycle, and CGI in general before trying to make a full-fleged application. And then I would end up using a pre-built framework that has sessions and other useful bits so you don't re-implement it and do it poorly and introduce all sorts of security problems for your clients. 
Like the old Perl Power Tools from 1998? Or is there something more recent?
I got it working using this: &lt;input type="radio" name="$row[0]" value="$row[5]"&gt;$row[5] my $choice = $form{$row[0]}; 
 #!/usr/bin/perl use CGI qw/:standard/; use Data::Dumper; my %quiz = ( 1 =&gt; ['question1', 'answer1', 'answer2', 'answer3', 'answer4' ], 2 =&gt; ['question2', 'answer1', 'answer2', 'answer3', 'answer4' ], 3 =&gt; ['question3', 'answer1', 'answer2', 'answer3', 'answer4' ], ); my $q = CGI-&gt;new; my $answers = ""; print "Content-Type: text/html\n\n"; if ($q-&gt;param('qids') ne "") { my @qids = split(/,/, $q-&gt;param('qids')); foreach my $qid (@qids) { $answers .= "Question: " . $quiz{$qid}[0] . " -&gt; Answer: " . $q-&gt;param('q' . $qid) . "&lt;br&gt;\n"; } }; print&lt;&lt;EOT; &lt;html&gt; &lt;body&gt; &lt;form&gt; $answers &lt;h1&gt;Questions&lt;/h1&gt; EOT print "&lt;input type=hidden name=qids value=\"" . join(",", keys %quiz) . "\"&gt;\n"; foreach my $qid (keys %quiz) { print " &lt;h2&gt;" . $quiz{$qid}[0] . "&lt;/h2&gt;\n"; print " &lt;ol&gt;\n"; foreach my $aid (1..4) { print " &lt;li&gt;&lt;input type=radio name=\"q" . $qid . "\" value=\"" . $quiz{$qid}[$aid] . "\"&gt; " . $quiz{$qid}[$aid] . "&lt;/li&gt;\n"; } print " &lt;/ol&gt;\n"; } print &lt;&lt;EOT; &lt;input type=submit value=Submit&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; EOT 
I fixed it since then. I forgot to include that I had parsed the form to assign me form{} variables. I am now able to receive an answer from each question using row[0] as my name and row[2]-[5] as my values I can print the answer now from each question using my $choice = $form{$row[0]}; print "Your answer: $choice.&lt;br&gt;\n"; 
App::Cmd and MooseX::Getopt are useful.
In addition to the other suggestions here, check out [Pod::Usage](http://perldoc.perl.org/Pod/Usage.html) as a means of integrating documentation and usage strings.
In addition to the other suggestions here, check out [Pod::Usage](http://perldoc.perl.org/Pod/Usage.html) as a means of integrating documentation and usage strings.
You probably already know this, but for super simple non-library based command line parsing I do something like: while ($_ = shift(@ARGV)) { if (/^-i/) { $interactive = 1; } elsif ((/^-n/) || (/^--name/)) { $name = shift(@ARGV); } elsif (/^--debug/) { $debug=1; } else { push (@todo, $_); } } All recognized options get handled. Unrecognized things end up in the array. You can handle short and long options with and without parameters. The big thing this can't handle is bundling multiple arguments, ala "tar -xvpzf filename.tgz" but that's rarely an issue for small run utilities. I've tried a few of the Getopts and found them completely horrible. The thing I like the most about this is it's super easy to read and figure out what each option does, and you can add weird code attached to an option easily.
Hmm, I can understand the value of this for learning purpose, but won't recommend it for real usage. It's akin to parsing CGI request environment manually.
Can I also suggest [Sub::Spec::CmdLine](http://metacpan.org/module/Sub::Spec::CmdLine).
The {}'s construct an anonymous hash and return a reference to it. It's that reference that is being pushed into the array. If you did a $a = pop(@records), $a would be a hashref. You could do $a-&gt;{date} and it would pull the value of $date out. It's worth noting that the members of the hash will be scalars, not references. $a-&gt;{date} won't be a reference to $date, it will be the contents of $date so when you change $date the next time through the loop, it won't mess up your stored data. Anonymous references to data structures are how complex data structures in perl are normally created. You could have constructed the exact same data structure like this also: foreach my $ar(@array) { ($date, $port, $owner, $name) = split(" ", $ar); $i++; $records[$i]{date}=$date; $records[$i]{port}=$port; $records[$i]{owner}=$owner; $records[$i]{name}=$name; } for ($i = 0; $i&lt;@records; $i++) { print "$records[$i]{date}\n"; } The line where $records[$i]{date} is assigned will find $records[$i] to be empty and will auto-create and anonymous hash and assign it's reference to $records[$i] so that {date} can be resolved to a slot in it. It's because of this that you can simply do: $records[$i]{$club}[$member]{name}=$name and have an array of hashes of arrays of hashes created for you. It makes a lot of complex data structures super-easy to do in perl. 
Wow sickness. *off to rewrite all my scripts* 
Almost. I've done that, and it's much harder to do right. This functionality is dead simple and predictable. I've done variations that parse clustered switches and even then I'm not convinced using a library is worth it. For scripts where the distribution is low, however, the added code isn't worth it. I've used this for a long time, probably since before perl 5 was out, and every time I've been tempted to switch I've found the result less legible, and harder to adapt. 
There are lots of ancient Perl code floating around which are not recommended any longer. The Perl Power Tools project is more about hubris and experiment than real utility. If you are not sure whether an old project (older than 5 years) is still good/current Perl coding practice, it's better to ask on PerlMonks or SO.
I do so much hate Getopt::Long, but it's probably the right tool here. It's documentation could use a few more examples.
I don't see the issue with it. It is clear code and the purpose is unambiguous. What's not to like? I use Getopt::Long, but the resulting code isn't that much shorter after checking for errors.
I guess the code is simple and it works, so there's nothing wrong with it. I don't want to nitpick but personally, being used to Getopt::Long, I would like the ability to mix short (one-letter) options, e.g. -ni. Or completion of long options (e.g. --na for --name, as long as it's unambiguous). Or syntax checking. And the list can grow. To each his own, I guess.
I've always been fond of Getopt::Std. It is a lot nicer to work with for most things than Getopt::Long.
I usually do something like this (this is a real example from a random script I wrote): my ($daemon, $watch, $logfile, $verbose, $push_to_tivo); use Getopt::Long qw(:config bundling); GetOptions('v|verbose' =&gt; \$verbose, 'q|quiet' =&gt; sub { undef $verbose }, 'h|help' =&gt; sub { die "\n" }, 'd|daemon' =&gt; sub { $daemon = $watch = 1 }, 'w|watch' =&gt; \$watch, 'l|log=s' =&gt; \$logfile, 'push' =&gt; \$push_to_tivo, ) and $watch &amp;&amp; scalar @ARGV == 1 || !$watch &amp;&amp; scalar @ARGV &gt;= 1 or die "Usage:\n". " $0 [-v | --verbose] [-q | --quiet] [--push] [-h | --help] &lt;movie&gt; [&lt;movie&gt; ...]\n". " $0 [-v | --verbose] [-q | --quiet] [--push] [-h | --help] [-l | --logfile=&lt;file&gt;] [-d | --daemon] -w | --watch &lt;dir&gt;\n"; I like that technique because everything gets tested in one expression (including basic @ARGV lengths) so you don't have to write a usage function and call it in 50 different places. I also recently developed the 'die "\n"' trick for "--help" so that it prints the usage but emits no visible errors to the user. I like the short aliases up front so that they line up nicely (contrary to the examples in the Getopt::Long docs).
Don't forget exit codes. EXIT CODES. and use STDERR for error output, not stdout please. // code code code // error condition and print STDERR, "your error" exit 1; // code code // end of script exit 0; I've seen too many command line programs (not necessarily in perl) for too many applications *cough*OpenView*cough* that don't use exit codes properly and it makes shell scripting very tricky. If you plan on making command line utilities it's also a good idea to add some garbage collection and signal capturing. [Documentation](http://perldoc.perl.org/perlipc.html#Signals) Simplist form is using an END block like so: END { // garbage collector and cleanup routine } That block of code will not execute until the script is closing out. END{} gets evaluated after exit() or die(), I think only a Kill -9 can circumvent it. 
I would really like your suggestions on how else to explain this?
IF, and this is a very big if, i understand you right, you have a Perl script that can read data from the device, but you cannot get it to talk to your database. Meanwhile you have a PHP script that can talk to your database. So if you really want to avoid setting up the Perl script properly, you can change it so it accepts parameters via @ARGV, prints the data, and then use [PHP execution operators](http://php.net/manual/en/language.operators.execution.php) to run the Perl script and capture its output.
"but we cannot get it to connect to the database for some reason" if you paste that code, someone might be able to help. It would seem more sensible to do it all with the Perl script, if possible.
Perl should be throwing some kind of connect error. Check that first.
[Use Getopt::Long even if you don't think you need it](http://perlbuzz.com/mechanix/2008/05/use-getoptlong-even-if-you-don.html) "Too often its absence means that I've in the long run made more work for myself--or others--by not having used it originally."
TIL that I've been reading and writing files in perl using "the old way" for 6 years. Whoops. Thanks for the info.
i dont think this needs a better explanation, just more exposure. upvote and all that ;)
I appreciate the need for these tutorials. But there are so many things you can get wrong in Perl because of all its gotchas, and how much the language has evolved. I found Perl Best Practices really helpful, because it covers almost all of them. I have another suggestion - replace the 'or die' (or more usually: 'or die "Unable to open '$blah' for writing: $!") with [use autodie;](http://search.cpan.org/perldoc?autodie). Fatal IO errors + informative error messages for free.
Thanks. Please see http://szabgab.com/how-to-teach-modern-perl.html why I don't think using autodie *in a beginner tutorial* is a good idea. At a later point I'll cover it of course.
Getopt::Long::Descriptive. It's how you expect Getopt::Long to work when you first encounter it.
I would make sure to use the term "lexical filehandle" somewhere on the page so that if someone hears the term and tries to google it, there's a chance of finding the page. Also, you could add to the list of reasons why it's useful the fact that lexical filehandles are automatically closed when their block goes out of scope, which is an appealing property -- no more having to remember to close files at the end of a function, or leaking them if you just couldn't be bothered. 
Good tip -- however I would end with at least one actual example of the right way to do it rather than simply linking to the open docs, so the reader can easily see the difference and how it is safer.
the link is to the tutorial entry about the open but I think you are right. I'll add an example. (maybe a "before - after" comparison :)
good points!
I am glad it helps.
Second this
Eh. I've been doing it this way for a Very Long Time™, and I'm not sure I'm about to change. The thing is, about Perl, is there's no one true way. Does this method have very good reasons for adoption? Absolutely. Is it the only way? No. Why do I do it the old way? Well, because I have a boat load of existing code that I cut and copy from, and I don't have the time to go change it all. I have production code that's been running this way for almost a decade. And, well, muscle memory. That doesn't mean this isn't a good tutorial, or that your needs might be different than mine and you might gain something from switching.
Agree. This is likely the best reason for me to switch my set in ways. Of course, best practice would probably not include just forgetting to close file handles and letting them go out of scope. :)
I keep a couple of basic cli templates on github which I use for starter projects. https://github.com/kimmel/basic-perl-template-for-cli use Pod::Usage and Getopt::Long to handle flags and help information.
autodie is not always the appropriate thing to use in some situations.
Can you expand on that?
Sometimes robustness is more desired in an application, sometimes we want to ignore errors. When I found out about autodie I started using it everywhere by sticking a 'use autodie' statement at the beginning of files. Turns out my application then often died for every little problem it encountered, it got very annoying so finally I removed autodie. The problem perhaps lies in that old code need exception handling (eval/Try::Tiny) in several places instead of just 'use autodie'. 
I'm curious, what kind of "little problems" did you want to ignore? I thought autodie only threw exceptions for fatal/serious errors, but I mostly use 'use autodie qw(:io)' so I may be missing something.
mkdir on an existing directory, for one. I know, we should've used the Perl equivalent to mkdir -p, but this is existing code. Another would be unlinking a non-existing file (shouldn't be something fatal or even erroneous, depends on context).
I've been using the opts module more and more frequently for short scripts. I've found it to be (opinion) much less painful than Getopt::* and to make much more sense.
Yeah, I it took me several months to retrain my mind to automatically use the newer constructs but I thought it is important in the long run so I forced myself.
&gt; The thing is, about Perl, is there's no one true way. True, but some ways make it easier to do the right thing and other ways make it easier to do the wrong, inefficient, and insecure thing.
In those cases it's still less work to just type eval { unlink $foo };
Maybe I wasn't clear. My code wants to ignore errors. So the shorter version is: unlink $foo; without autodie.
This. You never know what you'll need in the future. You'll end up reinventing the wheel.
That does sound annoying. In new code I think I'd prefer to explicitly wrap those things with 'no autodie' or maybe just 'eval' to make it clear I was ignoring potential errors. I think it depends on context, in my use cases, if a file doesn't exist when I go to unlink it, that's usually really bad! :P
No, see, you want to ignore errors only for some cases of unlink. But you'll still want to handle errors elsewhere. So instead of writing or die on all other cases, and eliding autodie; it's more convenient to leave in autodie and eval the calls where you don't care about errors. This also documents nicely for the future that errors there are irrelevant.
Yes, but as I said: that was legacy code, I just plastered "use autodie" on it, which was probably wrong anyway. But even for newly written code, I'd argue that if you want to provide a single custom error message it can be simpler to just say unlink $foo or die "Can't remove primary key file: $!"; instead of: eval { unlink $foo; 1 }; if ($@) { die "Can't remove ..." } or: { no autodie; unlink $foo or die "..."; } the second and the third is rather silly to me. 
I don't seem to have expressed myself very clearly. Let me demonstrate the two possibilities i was thinking of. You can either do the legacy way: my $filename = 'report.txt'; open(my $fh, '&gt;', $filename) or die "Could not open file '$filename' $!"; print $fh "My first report generated by perl"; close $fh or die "Could not close file '$filename' $!"; unlink $filename; Or, to get the same behavior, with less typing, do: use autodie; my $filename = 'report.txt'; open(my $fh, '&gt;', $filename); print $fh "My first report generated by perl"; close $fh; eval { unlink $filename }; # don't care if this fails Besides being less typing work, and easier readable, the latter option also has the advantage that it's made clear that ignoring unlink's error is intentional.
I got you the first time. autodie can be convenient, it does error checking for you, and I do use it quite often. But the above is not 100% equivalent because autodie only dies with predefined error message, and not a *custom* one (hence my grandparent post). Also as to which style is *more clear*, explicit error checking or explicit ignoring, that is entirely subjective :)
Maps are cool! Coincidentally a couple hours ago I just watched [Map of the brain](http://www.ted.com/talks/allan_jones_a_map_of_the_brain.html) which also features some cool visualisation of brain cells. 
I love the description of autodie: &gt;bIlujDI' yIchegh()Qo'; yIHegh()! &gt;It is better to die() than to return() in failure. &gt;-- Klingon programming proverb.
I can see my::house from here.
Let's see, what you can glance from this visualization: *How many distributions depend on a certain distribution ("reverse dependency")*, e.g. http://mapofcpan.org/#/distro/Moose/rdeps . Wow, Moose is getting really endemic (nice, but also scary). *What namespace (areas) do a certain author mostly work on (web development? testing?)* Some example: http://mapofcpan.org/#/maint/ADAMK (mostly unique projects, but also a lot on File, testing, CPAN). http://mapofcpan.org/#/maint/MIYAGAWA (he's all over the place! :) But it's rather unfortunate that project top namespaces are getting more popular. What else? 
It's all done in the obvious way. It really is just some filled rectangles and a string call. You use a monospace font so that character positions are predictable and placing the rectangles is easy. And you've already got the formula for centering down. No, there's no "auto centering". Pay attention as well to the docs for `stringFT` (which I recommend using), especially the part about being able to call it as a class method and get a bounding box for the text. You can use that call with a position of (0,0) and find out how wide and how tall the text will be in pixels, and use that information for the centering, as well as to figure out how wide each character is (just divide by `length($string)` and round)
I see, yeah it is pretty obvious, that's what I originally came up with actually, but I just wanted to make sure I wasn't trying to crack a walnut with a sledgehammer. Thanks a lot for the help.
I think this pretty much exactly duplicates your sample image: #!/usr/bin/env perl use warnings; use strict; use autodie; use GD; my $i = new GD::Image(760, 420); my $white = $i-&gt;colorAllocate(255, 255, 255); my $green = $i-&gt;colorAllocate(50, 200, 0); my $black = $i-&gt;colorAllocate(0, 0, 0); draw_highlighted($i, 380, 209, gdSmallFont, $black, $green, "ATGGATCCCAT", qr/AT/); open my $fh, "&gt;", "highlited.png"; print $fh $i-&gt;png(); sub draw_highlighted { my ($i, $x, $y, $font, $fg, $bg, $text, $highlightre) = @_; while($text =~ /$highlightre/g) { my ($start, $end) = ($-[0], $+[0]); $i-&gt;filledRectangle($x + $font-&gt;width * $start, $y, $x + $font-&gt;width * $end, $y + $font-&gt;height - 1, $bg); } $i-&gt;string($font, $x, $y, $text, $fg); } Although it should really be `... * $end - 1` as the highlighting in your sample creeps one too far over onto the next cell. 
 % perl -lne '(1x$_) !~ /^1?$|^(11+?)\1+$/ &amp;&amp; print "$_ is prime"' 30000 Segmentation fault % 
5.8.x or earlier?
yes.
You're assuming fixed width fonts. That may work for this application, but is not a general acceptable solution.
Split your string into sections and draw each part on its own, in its own color, after you've calculated the size of the text when printed. This is a general approach that works with variable pitch fonts, and using any technology, thus not only on GD, but on PDF, too, for example. A bit of looking around lead me to find the module [GD::Text](http://search.cpan.org/perldoc?GD::Text), where I found the method [width](http://search.cpan.org/perldoc?GD::Text#$gd_text-%3Ewidth%28%27string%27%29): after you selected the proper font and font size, you pass the partial string that you want to print and get back the size in pixels. A bit of elementary match and you can do anything. For example, you can use this to center text: extract half the width from the x value of the center, and you get the leftmost position where you have to start printing. (To right align, subtract the full width from the rightmost position.) That's just a useless example, as the distro also includes [GD::Text::Align](http://search.cpan.org/perldoc?GD::Text::Align) for that purpose, but I'm pretty sure it'll work the same way. **Update**: For the source: see the sub `_align_builtin` at [Text/Align.pm](http://cpansearch.perl.org/src/MVERB/GDTextUtil-0.86/Text/Align.pm). Looks like I was right. :) This module is a fine example of how you can implement it.
OP's sample used fixed width fonts, and I was simply recreating it verbatim. I agree that it's not sufficient for other cases, but it's not clear that the extra work is necessary if the OP is fine with the built-in bitmap GD fonts. 
5.10 has a non-recursive regex engine which allows it to backtrack without hitting limits of the C stack.
That would be extremely cool; I could see it becoming pretty popular as well.
Consider this a PSA. Advantages: - faster startup - faster processing - strict mode by default - much more advanced strict mode that catches inconsistencies beyond just "var is undef" - detailed errors that show the exact template position - automatic HTML entity escaping (XSS-safe) - [actively maintained](https://github.com/xslate/p5-Text-Xslate/issues) and not just [left to languish](https://rt.cpan.org/Public/Dist/Display.html?Name=Template-Toolkit) by an ~~[author who has moved on to C](http://www.reddit.com/r/perl/comments/dnhc2/textxslate_the_fastest_template_engine_for_perl5/c11lwo4)~~ - syntax is straight-forward and modern perl
5.8? Um. Why? 
By 'moved on to C' do you mean 'is writing the next generation of TT in C'? Because that's fairly unfair to make a misleading claim like that.
I guess i should've linked to this as well: https://metacpan.org/author/ABW?sort=%5B%5B2%2C1%5D%5D
This should be the top comment. If your car wont go in reverse, don't duct tape another car to it.
At the risk of shameless self-promotion, I did a roundup of features and benchmarks of Perl Template engines in October 2010 that goes into some more nitty gritty detail: http://www.illusori.co.uk/projects/Template-Roundup/201010/ If you want to skip to the pretty pictures, the report relevant to most people really after performance is instance-reuse: http://www.illusori.co.uk/projects/Template-Roundup/201010/performance_vs_variant_by_feature_for_instance_reuse.html Text::Xslate is the clear leader in that area, both for performance and is one of only a tiny handful of template engines to be as fully-featured as Template::Toolkit. There's a few places where Text::Xslate isn't so great: if you're running with no caching of template code basically, since the compile cost is relatively expensive. But if you're running that way, performance probably isn't your priority. I've been meaning to do an updated set of benchmarks all this year since I've added plugins for a number of other template engines, I just haven't had time, and Text::Xslate is still the clear leader.
You probably should've linked to this as well: https://github.com/abw
That's right, I haven't "moved on to C" or anything silly like that. I use lots of different languages. Perl and C are just two of them.
You should check [Authen::Simple](http://search.cpan.org/~chansen/Authen-Simple-LDAP-0.2/lib/Authen/Simple/ActiveDirectory.pm).
I must admit i was entirely unaware of that account. Sorry for being rash. All i knew was that you seemed to have stopped doing anything with Perl since there was exactly zero CPAN activity since the last TT2. On that note, i'm a bit curious: Have you just not been pushing a lot, or has TT3 development stopped? ( https://github.com/abw/hemp/graphs/impact )
If by some chance you're using Perlscript on IIS (and requiring user identification), then this will do it: use vars qw( $Request $Response ); my $userid = $Request-&gt;ServerVariables('LOGON_USER')-&gt;{Item}; 
You're looking for the [require](http://perldoc.perl.org/functions/require.html) keyword, used as so: use lib '.'; require "a.pl";
I'm not sure if this is the modern way to handle this, but in b.pl, you don't need the namespace prefix a:: unless the function test is in a [package](http://www.cs.cmu.edu/afs/cs/usr/rgs/mosaic/pl-pkg.html). Perl isn't like some other languages where the file a function is in automatically namespaces it. so, you should be able to run that as a(5) in b.pl. If you want namespace separation, you could define: package a; at the top of a.pl Can someone else confirm this? It's been a while since I've written packages
Something like this might work better: **a.pm** #!/usr/bin/perl use warnings; use strict; package a; sub test { return $_[0]; } 1; **b.pl** #!/usr/bin/perl use warnings; use strict; use a; print a::test(5); 
There is no `a::test` because you haven't created a `package a`. Just because there's a file doesn't mean there's automatically a package. A file that *does* contain a package with a corresponding name is called a "Module". So one thing you could do would be to change b.pl to this: require "a.pl"; print test(5); which doesn't use modules at all ­— the other thing you could do would be to rename a.pl to a.pm, and add a `package a;` line to the top, so that the stuff within it is actually scoped to the `a` package. Finally, your definition of `test` is out of whack. You shouldn't write `sub test() {`, that's a prototype that says that it accepts no arguments. You don't want or need a prototype at all here, so just write `sub test {` instead. You also don't want `return $_;` here, because `$_` isn't your argument. `return $_[0];` would be reasonable, or you could write sub test { my ($thing) = @_; return $thing; } which might be considered slightly overkill in this case, but it's the form you're likely to want for more substantial subs, so why not train yourself to use it all the time?
In my code it isn't test() - its just test. I didn't pay much attention to what I was writing in the example; I was more concerned with the use/require/a::test part. Same deal with the arguments. The "module" method is what I was looking for. Thanks :)
I am curious why you didn't send him an email first asking him for the status? I have done that and he has always answered me. I think for large re-writes (such as from TT2-&gt;TT3) you are going to see more git stuff and then a push to cpan when ready for general consumption.
Confirmed, but if you're diligent about writing packages, you'll save yourself a lot of trouble later.
Put it in a Perl module and ''use'' it. If you want to use the PM as a script itself in some cases, you should look into brian d foy's "[modulino](http://drdobbs.com/184416165)" method.
meh.......I am much more apt to use HTML::Template for 2 reasons: 1. I put zero business logic into my templates, so I don't need another PHP-like templating language 2. It comes by default with CGI::Application
Because i actually wasn't aware that he was doing a rewrite until recently and the state of the bug tracker of TT2 seemed to indicate that trying to contact him would be futile either way. The curiosity in my previous post literally just came about because i saw what he had on his github.
This might not be what you want, since it doesn't involve any perl, but we've been using [Piwik](http://piwik.org/) for analytics on our [Javascript-intensive-but-Catalyst-backed site](http://greenfelt.net/) and we're pretty happy with the solution. If you look at the source you'll notice we went to some trouble to make sure that the piwik stuff loaded after the page gets rendered so that it doesn't slow things down. But other than that, it's been pretty straight-forward, with decent statistics with only a couple minor intrusions in the javascript code.
I feel silly for pointing this out, but it caught me for a minute. Once you "require" the external code, you still have to explicitly call the sub subroutine. "require" is like cutting/pasting the code in. So your example use lib '.'; require "a.pl"; &amp;test();
Using '&amp;' to invoke a function went out of fashion 15 years ago with perl 4. In perl 5 we just say test();
Okay, thanks. I have an old Perl book I read through. Guess I need to get a new one. 
I include all my commonly used subroutines residing in 'a.pl' by just saying do "a.pl"; at the top of the file I want to use them in. 
perl has changed an amazing amount in the past decade ... and just as much in recent years as in the years before. There is a lot of wonderful stuff to catch up on -- and very powerful modern ways of using perl now which are completely different than in earlier times.
Have you read these: [sort](http://perldoc.perl.org/functions/sort.html) , [grep](http://perldoc.perl.org/functions/grep.html) ? Can you show some code which describes the difficulty you're experiencing ?
To sort on the second column numerically: sort -t$'\t' -k2,2 -n To filter for the third column being less than 0.05: perl -F'\t' -ane 'print if $F[2] &lt; 0.05' Both (and no useless use of cat): &lt;input.txt perl -F'\t' -anE 'print if $F[2] &lt; 0.05' | sort -t$'\t' -k2,2 -n &gt;output.txt
It's something I can easily do by writing a perl script, but I'm quite new to the whole perl on the command line thing. Anyway, I thought something like: perl -lane 'print sort $F[1]' file perl -lane 'print $_ if $F[2] &lt; 0.05' file should work, but I'm not getting what I expect. Any pointers?
the filtering actually works and there's no need for $_
The filtering works just fine (you could also omit the -F parameter as the default delimiter (' ') works for tab delimted files. Regarding the sorting, I know about 'sort' but I'd like to do that using perl. Any pointers?
&gt; you could also omit the -F parameter as the default delimiter (' ') works for tab delimted files. It doesn't work fine if your first field has spaces. Tab delimited means tab delimited, not whitespace delimited. You can do the sorting with perl, but honestly it's going to be uglier and longer than using sort: perl -F'\t' -ane 'push @data, [@F] if $F[2] &lt; 0.05 }{ print join "\t", @$_ for sort { $a-&gt;[1] &lt;=&gt; $b-&gt;[1] } @data;' You could also do it with a hash: perl -F'\t' -ane '$lines{$F[1]} = $_ if $F[2] &lt; 0.05 }{ print $lines{$_} for sort keys %lines' But this will break if you have repeated data, which could be fixed with: perl -F'\t' -ane 'push @{$lines{$F[1]}}, $_ if $F[2] &lt; 0.05 }{ print @{$lines{$_}} for sort keys %lines' But this will fail if any of the columns use scientific or general format, since the default comparison is `cmp` (stringwise). You could fix that by using: perl -F'\t' -ane 'push @{$lines{$F[1]}}, $_ if $F[2] &lt; 0.05 }{ print @{$lines{$_}} for sort { $a &lt;=&gt; $b } keys %lines' But really, just use sort. 
actually this is a job for [App::p](https://metacpan.org/module/App::p) , if it had support for CSV implemented..
use either [Text::CSV](https://metacpan.org/module/Text::CSV) or [Text::CSV_XS](https://metacpan.org/module/Text::CSV_XS) to split those columns. you're not getting nothin cause there's no built-in splitting into $F[0] $F[1] and $F[2] ... you need to do the splitting yourself..
Upvote for inflicting the }{ hack on an admitted Perl command-line noob.
Would you explain your comment to another command-line noob?
i know this is /r/perl, but just use awk and sort: awk 'FS="\t"{if ($2&lt;0.05)print $0}' file|sort -k2 or something
Sorting can be done using a [Schwartzian Transform](http://en.wikipedia.org/wiki/Schwartzian_transform): perl -e 'map { print $_-&gt;[0] } sort { $a-&gt;[2] &lt;=&gt; $b-&gt;[2] } map { [$_, split(/\t/)] } &lt;STDIN&gt;' &lt; input.txt The trick here is to read it backwards, with data flowing from right to left. The *last* `map` takes each line of `STDIN` and yields an array reference (`[...]`) for each line. The array contains the original string (`$_`) in the first element and then the input split into fields on the tab character (`split(/\t/)`). map { [$_, split(/\t/)] } &lt;STDIN&gt; The `sort` in the middle sorts the array references by the third element, which is the second tab-delimited field in each line. sort { $a-&gt;[2] &lt;=&gt; $b-&gt;[2] } The leftmost `map` takes the sorted array references and prints the first element, i.e. the original string: map { print $_-&gt;[0] } 
`-a` enables the built-in autosplit into `@F`.
When you run: perl -ne 'foo' The `-n` causes perl to surround your code with a loop so that it's as if you'd written this: LINE: while (&lt;&gt;) { foo } The label is there so that you can refer to it if you want, for example if your `foo` contained an inner loop and you wanted to be able to break from inside that loop and skip ahead to the next iteration of the outer loop, you could write `next LINE`. (If you didn't have an inner loop you could just write `next` without needing a label.) The `&lt;&gt;` includes some magic to loop over all lines of all filenames given on the command line, or standard input if none were given, and so it's really as if you'd written this: unshift (@ARGV, '-') unless @ARGV; while ($ARGV = shift @ARGV) { open(ARGV, $ARGV); LINE: while (defined ($_ = &lt;ARGV&gt;)) { foo } } [ Note that this uses the dangerous two argument `open()`, which is why it's able to fill `@ARGV` with `'-'` if it was empty, as `open(ARGV, '-')` means (re-)open stdin. But this also means if your filenames contain syntax that `open()` recognizes, then you're in for a surprise. ] Anyway, if `foo` is actually `foo }{ bar` then you get this: LINE: while (&lt;&gt;) { foo }{ bar } Or equivalently: LINE: while (&lt;&gt;) { foo } { bar } A block on its own like that is perfectly fine syntax-wise, and it's sometimes used if you want to contain lexical effects to only a certain few lines of the current scope. In this case, it's not doing that, but since perl inserted that closing `}` we had to balance it by giving a `{`. The point of this is that block `foo` is run for each line, and then after the loop is done block `bar` runs. It's an idiom for `perl -ne` scripts that want to do something for each line (such as read/process data) and then at the end do something else, such as generate a report or sort and print the data. 
++ I guess I learned something new :)
Thanks for taking the time to explain it in such detail.
I'm going to be *that guy*. perl -wle 'use DBI; my $d = DBI-&gt;connect(q{dbi:AnyData:}); $d-&gt;func(qw{stuff CSV data.csv}, { field_sep =&gt; qq{\t}, col_names =&gt; q{name,value,pvalue} }, q{ad_catalog}); for ( @{$d-&gt;selectall_arrayref(q{SELECT * FROM stuff WHERE pvalue &lt; 0.05 ORDER BY value})} ) { print join(q{,}, @{$_}); }'
Interesting stuff, though I wonder how much of this is the author's greater familiarity with the Perl tools than their Python equivalents. I've been typing `sudo cpan Module::Name` for years, but I didn't have much of a grasp of what was going on under the hood until I attended [Tom Hukins' talk](http://conferences.yapceurope.org/lpw2011/talk/3903) at LPW this year. I made my first CPAN upload earlier this week (on an abandoned module that I'd taken over, so much of the work was already done for me), and I spent about as long reading docs as I did writing code for it - and even then, I got something minor wrong. Perhaps the Python tools are straightforward when you understand them?
 $remote_file =~ y#*?:[]"&lt;&gt;|(){}&amp;'!\\;#_#; 
So swap "_" for special characters? How will $ftp-&gt;get know what file to get if I change the name? 
That was just an example of a substitution that you need to apply to the remote filename to get local filename. for my $remote_file (@list_of_remote_files) { my $local_file = $remote_file; $local_file =~ y#*?:[]"&lt;&gt;|(){}&amp;'!\\;#_#; $ftp-&gt;get($remote_file, $local_file, $dir); } 
OK, thanks. I'll go back to my code with this approach. Edit: I'm still having issues, is the last argument to get the local storage path?
novaalpha has it right, but for completeness consider [this MSDN entry on file names](http://msdn.microsoft.com/en-us/library/windows/desktop/aa365247%28v=vs.85%29.aspx). In addition to disallowed characters, note the existence of the reserved device names CON, PRN, AUX, NUL, COM1, COM2, COM3, COM4, COM5, COM6, COM7, COM8, COM9, LPT1, LPT2, LPT3, LPT4, LPT5, LPT6, LPT7, LPT8, and LPT9. It's unlikely that you're going to be transferring files with these names, but I ran into odd behavior recently with exactly this issue at fault. A contractor on a Windows machine was trying to check out of our company Subversion repository, and one of our devs had committed a directory named AUX. That took a little while to figure out because the error message Subversion was giving didn't accurately diagnose the problem. I would also ordinarily also suggest using a relevant module from CPAN, but [Win32::Filenames](http://search.cpan.org/~bch/Win32-Filenames-0.01/lib/Win32/Filenames.pm), the only one I can find, doesn't do much more than a substitution against a regular expression the same as you would be.
Note that it's not just those file names, but those names with *any* extension, e.g. "aux.c". 
i am less interested in perl6 than i was a year ago. i'm 41...i think there is a realistic chance i will be on social security by time this thing is settled and useful racket has proven to be a suitable bit of replacement candy....optional types, functional, fast, and while PLaneT is no cpan, there are more SRFIs than there are perl6 modules it seems like one or two people periodically hack on perl6. and in 2011 there seemed to be a flame war with parrot...i'm starting to wonder what the point is
 ($remote_file = $local_file) =~ s/[^\w]/_/g;
&gt; i'm starting to wonder what the point is It's fun to develop compilers, but it's not fun to maintain software people can use. &gt; it seems like one or two people periodically hack on [Perl 6]. It's more like a couple of core hackers per implementation, with maybe a few more contributors in the case of Rakudo.
It's worth noting that this restriction is only at the Win32 layer. The filesystem itself and the NT layer don't care. Cygwin uses the NT layer directly, so this works fine with Cygwin perl on Windows: $ perl -Mautodie -E 'open my $fh, "&gt;", "CON"; say $fh "Hello World"' $ cat CON Hello World However, this file will be invisible/inaccessable to Win32 apps, so for example if you look in the directory with Windows Explorer, you don't see it. But if you stick to mostly Cygwin programs then you can freely store and access these files without issue, although you might want to disallow them so as not to confuse anyone. 
wow you went above and beyond with this response, thanks so much for the help. that's a very elegant solution, i must say. :-)
Since about 2005-2006, I also have more or less given up hope on using a production-ready Perl 6 (and its equivalent ecosystem, CPAN6) in the foreseeable future. However, stranger things have happened. And nevertheless, Perl 6 is beneficial to Perl 5 (Moose, Regexp::Grammars, and so on), so I (we) can't really complain. Go Perl 5! Go Perl 6! 
&gt; I'll probably keep them out, as I did in the first one. Does it provide a lot of value? I definitely prefer the old style. It gives me a glance through what's available in the chapters. If I wanted a quick reference for say, Arrays, I could just flip to the TOC and quickly look up "Arrays" and find the page. With the new TOC I can't do that.
 my $foo = [ qw(a b c d e f g) ]; 
That makes a simple string scalar, not a reference.
Damn, how did I miss something so simple? :) Thanks!
The [Modern Perl Book](http://www.onyxneon.com/books/modern_perl/index.html) has a good reference starting on page 51 section "Array References".
Your questions already been answered, but if you've never read [perldoc perlreftut](http://perldoc.perl.org/perlreftut.html), I recommend it very highly.
You should write a book. :)
You're my hero right now.
Seconding this recommendation to anyone. perlreftut is the simple guide to how to *never* go wrong with references.
How about a second edition? Watch this space.
I've been stuck on 5.6.2 for so long, second editions are almost foreign.
Some POC code would be nice.
Perl *was* vulnerable in 2003, I guess we've learnt our lesson. 
Yeah, there are no lack of answers at [PerlMonks](http://perlmonks.org) too, so I am reluctant to contribute.
There ARE other ways to resolve collisions, you know...
I'm sure there's still people running a version of Perl old enough to still have this vulnerability, even though it's been fixed for approaching a decade. Given the fix made ordering of hash keys inconsistent between interpreter starts, some people may even be doing it intentionally for legacy reasons. (Very *bad* legacy reasons, but...)
From [`perldoc perlsec`](http://perldoc.perl.org/perlec.html): In Perl 5.8.1 the random perturbation was done by default, but as of 5.8.2 it is only used on individual hashes if the internals detect the insertion of pathological data. If one wants for some reason emulate the old behaviour (and expose oneself to DoS attacks) one can set the environment variable PERL_HASH_SEED to zero to disable the protection (or any other integer to force a known perturbation, rather than random). One possible reason for wanting to emulate the old behaviour is that in the new behaviour consecutive runs of Perl will order hash keys differently, which may confuse some applications (like Data::Dumper: the outputs of two different runs are no longer identical). Anyone using Perl 5.8.0 or earlier to get consistent key ordering (something Perl has never guaranteed anyway) is an idiot and likely has larger concerns than algorithmic complexity attacks.
You can see the behavior in Perl 5 if you turn off the protection. #!/usr/bin/perl use strict; use warnings; my %h; for my $n (1 .. 10_000) { $h{"\0" x $n} = undef; } print scalar %h, "\n"; When run normally, this should print out something like 7502/16384 indicating that 7502 out of 16384 buckets were in use. Turning off the protection like this: PERL_HASH_SEED=0 perl example.pl yields 1/16384 which indicates that only one bucket is in use.
As I said, very bad reasons. ;)
You've been a perl developer for 15+ years and none of your friends who are perl developers could answer this.... 
I shared the solution with a few of them. We were all equally embarrassed that we didn't come up with it.
Fine, you could use some form of search tree in the bucket instead of linked list. Now you have decreased the worst case (pathological keys that all map to the same bucket) cost to O(log n) instead of O(n). However, it comes at a cost in complexity. Consider that with a million random keys the most keys in a bucket in the current Perl 5 hash is generally between 9 and 13 (with most buckets have 3 or fewer keys). Having a tree in this case is a waste. 
It's cheaper to detect when a single hash bucket's being abused (check its length as a fraction of the total hash size) than to have every value written have the side effect of also calling `rand()`.
It kicks in when there are more than 15 items in one bucket (or more accurately it HV_MAX_LENGTH_BEFORE_SPLIT items). I believe the code that does it is in S_hsplit (hv.c): /* Pick your policy for "hashing isn't working" here: */ if (longest_chain &lt;= HV_MAX_LENGTH_BEFORE_SPLIT /* split worked? */ || HvREHASH(hv)) { return; } if (hv == PL_strtab) { /* Urg. Someone is doing something nasty to the string table. Can't win. */ return; } The following code demonstrates what happens (you will need [Hash::Esoteric](https://github.com/cowens/Hash-Esoteric)). #!/usr/bin/perl use strict; use warnings; use Hash::Esoteric qw/keys_by_bucket/; my %h; my $k = "aaaaa"; for my $n (1 .. 1_000_000) { $h{$k++} = undef; } my $buckets = keys_by_bucket \%h; print "bucket 0 has " . @{$buckets-&gt;[0]} . " keys\n"; for my $n (1 .. 16) { $h{"\0" x $n} = undef; my $buckets = keys_by_bucket \%h; print "bucket 0 has " . @{$buckets-&gt;[0]} . " keys\n"; } 
Perl doesn't call rand for every call to the hashing function. The randomizing is done at start up and stored in a variable. This variable is used to initialize the hash function if pathological data is detected. The hash function is: #define PERL_HASH_INTERNAL_(hash,str,len,internal) \ STMT_START { \ register const char * const s_PeRlHaSh_tmp = str; \ register const unsigned char *s_PeRlHaSh = (const unsigned char *)s_PeRlHaSh_tmp; \ register I32 i_PeRlHaSh = len; \ register U32 hash_PeRlHaSh = (internal ? PL_rehash_seed : PERL_HASH_SEED); \ while (i_PeRlHaSh--) { \ hash_PeRlHaSh += *s_PeRlHaSh++; \ hash_PeRlHaSh += (hash_PeRlHaSh &lt;&lt; 10); \ hash_PeRlHaSh ^= (hash_PeRlHaSh &gt;&gt; 6); \ } \ hash_PeRlHaSh += (hash_PeRlHaSh &lt;&lt; 3); \ hash_PeRlHaSh ^= (hash_PeRlHaSh &gt;&gt; 11); \ (hash) = (hash_PeRlHaSh + (hash_PeRlHaSh &lt;&lt; 15)); \ } STMT_END If I am reading the code correctly, by default, `PERL_HASH_SEED` is 0, so `hash_PeRlHaSh` starts off as 0. If there is pathological data, then internal is true, so `PL_rehash_seed` gets used instead (it being the random number chosen at start up). This means it is still possible to break Perl if you know what the seed is (but since it is supposed to change on every run, that is unlikely). Yep, `PERL_HASH_SEED` is `PL_hash_seed` which is `Ihash_seed` which is set in intrpvar.h: PERLVARI(Ihash_seed, UV, 0) /* Hash initializer */ And `PL_reshash_seed` is `Irehash_seed` which also gets set in intrpvar.h PERLVARI(Irehash_seed, UV, 0) /* 582 hash initializer */ and again later in perl.c: PL_rehash_seed = get_hash_seed(); The `get_hash_seed` function is interesting: UV Perl_get_hash_seed(pTHX) { dVAR; const char *s = PerlEnv_getenv("PERL_HASH_SEED"); UV myseed = 0; if (s) while (isSPACE(*s)) s++; if (s &amp;&amp; isDIGIT(*s)) myseed = (UV)Atoul(s); else #ifdef USE_HASH_SEED_EXPLICIT if (s) #endif { /* Compute a random seed */ (void)seedDrand01((Rand_seed_t)seed()); myseed = (UV)(Drand01() * (NV)UV_MAX); #if RANDBITS &lt; (UVSIZE * 8) /* Since there are not enough randbits to to reach all * the bits of a UV, the low bits might need extra * help. Sum in another random number that will * fill in the low bits. */ myseed += (UV)(Drand01() * (NV)((((UV)1) &lt;&lt; ((UVSIZE * 8 - RANDBITS))) - 1)); #endif /* RANDBITS &lt; (UVSIZE * 8) */ if (myseed == 0) { /* Superparanoia. */ myseed = (UV)(Drand01() * (NV)UV_MAX); /* One more chance. */ if (myseed == 0) Perl_croak(aTHX_ "Your random numbers are not that random"); } } PL_rehash_seed_set = TRUE; return myseed; } It tolerates whitespace at the start of the `PERL_HASH_SEED` environment variable, but if it doesn't see a number (or it sees something other than whitespace) it tries really hard to generate a random number.
said the perl fanatic 
Does that change the truth value in any way whatsoever?
yes
What is the change?
just is
There seam to be a start of a module [here](http://search.cpan.org/~jon/Reddit-0.11/lib/Reddit.pm)
Actually, I could use some help with this because I don't have a huge amount of free time. [The code is on Github](https://github.com/Ovid/DB--Color) and would love for someone to pick up and run with this.
I just use Vim and 'syntax on' it so I get colorization. Other good options here, such as :make for syntax checking and other stuff. http://www.perlmonks.org/?node_id=540167
&gt;The vulnerability outlined in this advisory is practically identical to the one reported in 2003 and described in the paper Denial of Service via Algorithmic Complexity Attacks which affected the Perl language Fixed it back in 2003. Edit: This was already posted yesterday... blah sorry. http://www.reddit.com/r/perl/comments/nu5r9/most_web_development_languages_vulnerable_to_dos/ Edit 2: Also the title is wrong it is not a DDOS its a DOS. There is nothing distributed about this. Blah fail 2 
ya... i am very fond of vi for colorization since the advent of vim. there are different schemes out there for you to use as well, but the format is.... em... odd. (ie: i am too lazy to learn yet-another-tool-cfg syntax.)
I watched the 28C3 presentation on this problem today. Turns out that the researchers got the idea from `man perlsec` to begin with.
I'm also a heavy user of vim, but that doesn't get you syntax coloring in the debugger.
What is the purpose of this module? It seems to just add a layer on top of something that is already simple. It doesn't even save any keystrokes in its examples: $match = spath $data, "/foo/0"; $match = $data-&gt;{foo}[0]; # returns boo $match = spath $data, "/bar/0/bat"; $match = $data-&gt;{bar}[0]{bat}; # returns { bat =&gt; "bar" } $match = spath $data, "/bar/1"; $match = $data-&gt;{bar}[1]; # returns 1 $match = spath $data, q{/"foo bar"}; $match = $data-&gt;{"foo bar"}; # returns 20 $match = spath $data, q{/"foo\\"bar/"foo/bar"}; $match = $data-&gt;{'bar"foo'}{foo}{bar}; # returns the call to method passing arguments $match = spath $data, q{/obj/method( "arg1", 'arg2', bareword )}; $match = $data-&gt;{obj}-&gt;method("arg1", "arg2", bareword); The quoting on 'bar"foo' is pure insanity, someone is almost certain to get it wrong. In fact, it looks like there is an error in that example: there seems to be a missing `/` between `foo"bar` and `foo`. Of course, it is possible I just don't understand what is going on. The arguments to a method aren't `eval`ed, so you can only pass static data to the method (and the quoting needed to get `eval` to work right would be a problem even if it did work). The only thing I see it has as a possible advantage over the native syntax is that you don't need to know if a given layer is a hash, array, or method call with no arguments, but I don't believe you can effectively work with a data structure like this without understanding what it holds.
The question is, why didn't other languages pick up the ball in 2003? It's somewhat understandable for Java, since hashes don't have the first-class status that they do on Perl. But what's PHP's excuse? (["Taking over the Internet"](http://www.reddit.com/r/programming/comments/nuz2v/supercolliding_a_php_array/c3c85zg) is the answer I got back when I asked this in proggit. This is exactly the sort of head-in-sand thinking that I've come to expect from PHP.)
And they still have 20+ open perl dev positions for people willing to move to Amsterdam: http://www.booking.com/jobs.html?st=details&amp;job_id=1694
Might be fun to write one.
Having filed a PHP bug report in the past, I'd guess the answer was [CLOSED, bogus] This is not a bug, this is the intended behavior of the algorithm in edge cases.
Yeah, I'm actually working on extending the Reddit.pm library. Are you interested in working on it too?
maybe we can see one for non threaded perl?
Interesting. Performance is improving for all of the 5.10+ perls with the exception of the regexp split test, where 5.8 is still much faster.
The majority of the development team are expats from all over and English is the working language of the company. Ideally we're looking for Perl devs, but we've also hired C, Java and PHP programmers who are willing to learn/switch :) Because Amsterdam gets so many tourists, people don't expect foreigners to speak Dutch. My experience is that almost everybody here, especially in any kind of service role, speaks English.
I've long been interested in them, but going through such processes is lengthy and time-consuming, so one single factor has kept me from giving it a try so far: They don't even give so much as a hint of the pay range that can be expected. Or did i miss that somewhere? (And before you point to it, such donations are not even remotely a reliable indicator. I've worked for companies that blew millions on advertisement, but refused to give 5+ year employees in key positions more than 40000$/year.)
Awesome! Exactly what I need for something I'm working on.
I interviewed with booking.com and got an offer, but ultimately turned it down primarily due to language concerns with schooling for my daughter. The offer wasn't high enough to pay for a private English-speaking school, and I wasn't confident about putting her into a Dutch/English public school.
Traditionally Mouse wins only in startup overhead and memory footprint. Moose is quite fast once it gets moving.
Also, `Class::MOP` has.. actually, I just checked and it was moved to [`Class::Load`](https://metacpan.org/module/Class::Load).. the `load_class()` and its friends: use Class::Load ':all'; try_load_class('Class::Name') or plan skip_all =&gt; "Class::Name required to run these tests"; load_class('Class::Name'); is_class_loaded('Class::Name'); my $baseclass = load_optional_class('Class::Name::MightExist') ? 'Class::Name::MightExist' : 'Class::Name::Default'; 
Yuck! use common::sense instead (pun intended). I frankly don't like spending hours on end fixing things that aren't broken, such as: ~~my $foo = {~~ ~~bar =&gt; 1,~~ ~~};~~ ~~or:~~ my $bar; if (condition) { # Do stuff $bar = 1; } if ($bar) { # Do stuff } The beauty of Perl is its brevity and its nature to do the right thing in the first place. If I was on your development team I would strangle you for even proposing this.
Neither of those barf with strictures.pm, so i have no idea what you're talking about. Sounds like you really misunderstood something.
Just tested it. The first one doesn't seem to generate a warning anymore. It used to because the literal 'bar' wasn't quoted. The second one still generates a "Use of uninitialized value" warning if 'condition' isn't true.
I'll admit that some behaviors are probably gone from complaints by people like me who never use warnings because it complains about some trick that we use. As far as the second one goes, I get it in 5.12.3 with this script: #!/usr/bin/perl use strict; use warnings; my $bar; if (0) { $bar = 1; } print "$bar\n"; Output: Use of uninitialized value $bar in concatenation (.) or string at wtest.pl line 12. Since your module does a generic 'use warnings' the results should be equivalent. I did just do the 'if' statement that I provided earlier and didn't get the error, so apparently it doesn't complain in all instances.
That has nothing to do with the conditional: my $bar; print "$bar\n"; `undef` is false; that's been true for ages. Interpolation of `undef` has warned for ages too. (I know a few people who don't like that warning, but I can count them on one hand with fingers left over.)
&gt; Doing it explicitly adds nothing useful. You mean: my $bar = undef; You're right; that's useless. That's not what I'm saying. When *I* interpolate `$bar` and its value is undefined, that's almost always a bug somewhere else. The opposite is exceedingly rare.
I don't get it. Do we really need a double closure to add two variables?
Not in Perl, but that's the Perl 5 equivalent of the theoretical semantics of the Haskell expression.
Actually, it does add something useful. When you're dealing with user input, there's always a chance that something unexpected get's sent in. Especially when you're downloading JSON or the like from a public API where it's not feasible to validate *everything*. If a value that you'd expect to always be populated suddenly becomes undefined, warnings tell you about this. And with strictures it actually aborts instead of continuing with possibly fatally wrong data.
How is `my $foo += function()` a bug? The only way I could think it is is if the my $foo masks an earlier $foo and you definitely meant +=
I really don't know of a situation that I've ever encountered where I couldn't at least do some validation on the data, even if it is just to make sure something is there. When you're expecting a value but you don't know what, this simple line of code will verify there is something there: if (length($value)) { .... } In this scenario something like strictures doesn't give you the opportunity to catch the exception and recover gracefully from it. In my scenario the user can see what broke where and when and maybe even what to do about it. Perhaps I can give the user a clue about what to tell me, or issue an SNMP call. In your scenario, the user gets a 500 error, calls you and says "It's broken" and you spend a bunch of time combing through apache logs trying to figure out what's broken and why.
My bad, but #perl (freenode) inspired me to write this.
You should try playing Tribes sometime, maybe the recently released Tribes : Ascend, or the older TribesNext. Now, what does this have to do with Perl? Simple: Perl is a language that is easily learned, but hard to master. The ground rules are not very many, but in their interplay they allow for massive complexity and emergent behaviors. A good developer knows these so well that he instinctively combines them in his mind and is able to draw conclusions about their interplay intuitively and thus predict things from a set of indicators that do not describe a problem in its entirety.
The number is of course exaggerated for effect. But the EVE API comes fairly close: http://wiki.eve-id.net/APIv2_Page_Index That is a lot of stuff you'd need to write classes for. But honestly, this does not matter. Even with only 20 data points that is a lot of validation to write and overlook or just plain get wrong. The strictures pragma provides a nice safety net.
I tried to comment on your blog post, but i couldn't actually login. Your OpenID thing doesn't recognize yahoo's openid service as an openid service and trying to login via typepad, using twitter or facebook connection fails because your blog asks for the email. This in spite of me having told typepad to share the email it got from facebook. ~~Anyhow: What policy were you using to get that critic complaint? I tried grepping cpan various ways and interrogated my local Perl::Critic copy and neither of them contains anything like the error shown on your blog.~~ Nevermind, didn't notice that this policy is new to the latest release.
As the policy* says: Such constructs are usually the result of botched cut-and-paste, and often are bugs. Some produce warnings. It also lists some additional cases where such a thing could be bad: my ( $foo, $bar ) += ( 1, 2 ); # same as my ( $foo, $bar ) = ( undef, 2 ); local $Carp::CarpLevel += 1; # same as local $Carp::CarpLevel = 1; state $foo += 2; # adds 2 every time it's encountered *: https://metacpan.org/module/Perl::Critic::Policy::Variables::ProhibitAugmentedAssignmentInDeclaration
Exactly :)
If you're doing it right, you should have objects that encapsulate each call.
Nice article idea, but suggesting use of ExtUtils::MakeMaker in this day and age isn't something I'd recommend, even in the context of "bare minimum to get things working". 
What the hell is this? 1995? Try this instead... cpanp install Module::Starter Module::Install module-starter --mi --author "John Doe" --email "jdoe@co.com" --module "Math::Calc" This creates all of the base files`*`, directories, internal pod, and Test::More testing boilerplate for your CPAN module. If you want the tarball to upload right to PAUSE (cpan), just do perl Makefile.PL make dist And, that's it. `*` MANIFEST, Makefile.PL, ./lib/ directory with .pm files and POD which already has `$VERSION`, etc.. No one creates their own boilerplate anymore.
What??? [Module::Install](https://metacpan.org/module/inc::Module::Install) works on all versions of Perl 5, and it can be totally self-contained (it will put all of the external files needed for install in inc/). It's also easier to work with on Active State because it comes ready to rock with `dmake` commands generated, and if it isn't on the system it will even download it for you. M::I is a far superior method of preparing modules for distribution. Check out [MooseX::Types::DateTime::ButMaintained](https://metacpan.org/source/ECARROLL/MooseX-Types-DateTime-ButMaintained-0.14/) if you want to see how it get structured. No one knows what modules are created with Module::Install and what ones aren't. It's to make the module authors job easier and to be sure all necessary files are created and in the standard place (you didn't even touch on tests).
EUMM is even in this day and age a fine solution that works well for most and especially the simple cases. There are other, newer options, but both of them have their own warts.
&gt; ... both of them have their own warts. "I know," he thought. "I'll inject a superclass into the installer's hierarchy to add methods which perform regular expressions against snippets of platform-independent shell scripts interpolated into platform-independent Makefiles to install these Perl modules. I'm sure I won't have *two* problems."
Module::Install is manifestly not better, since it makes people want to stab you in the face when you use it as the installer for your module. Module::Build, as far as i know, is better, but needs a rewrite to resolve some design issues. Thus, if you're not doing anything special and value stability, EUMM is the better choice over M::B.
I'm kinda confused by your logic there: MB has some design issues that mean it could do with a rewrite, therefore it's not stable? As opposed to EUMM whose internals are such a god-awful mess that it's *impossible* to rewrite without breaking things people depend on, even though it desperately needs one... therefore it is stable? If you're going to consider internal architecture as a stability issue, you should consider it for both by the same yardstick. As for MI not being better: the things that (some, me included) people dislike about it are philosophical differences about a feature that the other two don't support. If you want that behaviour, then MI is your only choice, if you don't want that behaviour then the fact it's *possible* to do is irrelevant since you're not using it.
MI's very design itself has also already caused some fairly stupid bugs; forcing developers of other modules to wait for them to fix their issues. It's not just a matter of "taste", it's a matter of it being outright dangerous. As for MB, i guess it wasn't too clear: My point is that EUMM is still actively being developed, while M::B is, though not quite abandoned yet, languishing for almost a year now. And this is unlikely to change until someone decides to go and rewrite it.
And, the fact that it's self-contained and builds the required `M::I` in is cool too and eases install. If the system has a newer version, it'll go with it. It it doesn't have M::I or has an old version, it will look towards `./inc`
&gt; My point is that EUMM is still actively being developed.... ... in the sense that it's on life support, getting essential toolchain features but not fixing its big problems. &gt; And this is unlikely to change until someone decides to go and rewrite it. As I said, "inject a superclass into the installer's hierarchy to add methods which perform regular expressions against snippets of platform-independent shell scripts interpolated into platform-independent Makefiles to install these Perl modules." I should have added "... which themselves run tiny Perl 5 programs to provide that platform-independence", and even so I think I've left off at least one more layer of madness in the stygian horror which is EUMM.
You think it's any different than if you use cpanp and upgrade the underlying build system that `M::I` uses -- or any other build system for that matter? If your build system breaks reverse compat you could be in a world of pain either way.
&gt; You think it's any different than if you use cpanp and upgrade the underlying build system that M::I uses -- or any other build system for that matter? Backward compatibility is hard enough without having to worry also about forward compatibility with every cargo culted snippet copied and redistributed into `./inc`.
I just. What? On one hand, I like this because we're getting posts to /r/perl, but OTOH we're getting these kinds of posts to /r/perl.
It's an IT job in London, one of the most expensive cities in Europe, with a salary that would be a joke even in Berlin, one of the cheapest large cities in Europe. Entry level or not, it would be hard to just survive on this, so it's really rather silly to post such a job offer in the first place.
There's absolutely nothing in the posting that would make it interesting to *anyone* with any coding skill.
Most people have no way of knowing that until you told them.
You don't have to wait until you grow up. [Start here](http://wiki.cpantesters.org/wiki/QuickStart&amp;version=19).
How so?
This is just introduction part. In the upcoming articles we will go in more details.
One method could be to use [reverse dependency counts](http://deps.cpantesters.org/depended-on-by.pl) and time since last release to draw up a list of modules that seem to be orphaned.
Thanks for the suggestion.
[Text::CSV](http://search.cpan.org/~makamaka/Text-CSV-1.21/lib/Text/CSV.pm)
[Text::CSV_XS](http://search.cpan.org/dist/Text-CSV_XS/)
&gt; Also, you should be clear in the documentation that it makes use of AnyEvent under the hood. It says right there! On the side! On the right! You only need to read it. But ok, i'll add it. :) &gt; There are already plenty of parallel downloader modules on CPAN. Actually. No there aren't. There are plenty of libraries which you can build a parallel downloader on top of, but none that actually give you one. &gt; When creating another entry in a crowded space, it's customary to document why you found it necessary to build yet another different one. I operate under the maxim of "release early, release often". I wanted to get this one out so i stop waffling about stuff i can do with it. People yelling at me like you're doing gives me much better focus as to what still needs to be done with it. As such, I just released the next version with answers to your questions. To quote it: This is not a library to build a parallel downloader on top of. It is a downloading client build on top of AnyEvent::HTTP. Its goal is not to be better, faster, or smaller than anything else. Its goal is to provide the user with a single function they can call with a bunch of HTTP requests and which gives them the responses for them with as little fuss as possible and most importantly, without downloading them in sequence. It handles the busywork of grouping requests by hosts and limiting the amount of simultaneous requests per host, separate from capping the amount of overall connections. This allows the user to maximize their own connection without abusing remote hosts. Of course, there are facilities to customize the exact limits employed and to add logging and such; but C&lt;async_download&gt; is the premier piece of API and should be enough for most uses. Thanks for the feedback. :)
&gt; And WTF is with your license? I'd never be able to use anything with that in a corporate setting. It is a perfectly valid legal license and you can ask your lawyers. It allows you to do exactly what it says on the tin: You can do what the fuck you want to. Ordinarily i would use the kind of licensing i grew up with when i got my first computer as an 8 year old kid 20 years ago, which is Public Domain. However american law is not enlightened enough to recognize this as something valid, so you need to deal with some harsh words. 
Considering that there hasn't been a candidate for the position in a long time, i figured it'd be ok to take the shorter one that describes exactly what it does. :)
Nice and clean. 
I like the interface and i appreciate the thought behind keeping things small. However eschewing CPAN dependencies to the point of rolling your own mini-Exporter and straight-up copy-pasting subs from other modules without attribution reeks of both fanaticism and egotism.
Making a personality analysis of the author instead of reviewing the module itself is rather petty. There is nothing wrong with writing your own import sub. The other issue has been fixed by giving credits to List::MoreUtils at the end of the POD.
The first thing I see wrong is your unescaped @ symbol in your email address. @example is being interpreted as an array, not text, because you used double quotes. use me\@example.com or a different wrapper like &gt;system(q/echo 'msg' | mailx -s 'subj' -A acct me@example.com/); 
Since you're in a double-quote context, perl is going to try to interpolate `@example` as if it was an array variable. You'll need to use a single-quote context (hint: use the `q//` operator so that you can continue to have single quotes in the string) or escape the @. Other than that it should work fine. I'd suggest however giving up on this error prone approach [and embracing the perl way.](https://metacpan.org/module/Email::Sender::Manual::QuickStart) 
Okay, I'll listen to your advice and bring back List::MoreUtils. Possibly Exporter too. Had you made that suggestion nicely and without attacking me personally in the first place, we would have arrived here without all the negative karma. 
I would try using open() open MAIL, "| mailx -s 'subj' -A acct me\@example.com"); print MAIL "msg";
Don't use `do 'somefile.pl';` to load libraries.
You're not being very helpful. I asked "Exactly how" and your answer is "just do it".
&gt; There is no existing case law that supports what you just said. Read the copyright statutes. The best you can do in the US is to note that you waive any copyright interest in a work, but as copyright has been automatic from the point of creation since 1976, you're not releasing the copyright. Contrarily, if you can find a mechanism in the statues by which you release copyright, please enlighten us all.
Wow, i must say, i did not expect this. That shows character on your part. :) And yeah, i did overreact and just wrote what came to mind first. Apologies for that. You've clearly shown i was wrong.
I can't reproduce that. It works fine: $ perl -e 'system(q{echo "This is the message body" | mailx -s "this is the subject" user@localhost})' $ echo -e "print :n\ndelete" | mailx Heirloom mailx version 12.5 6/20/10. Type ? for help. "/var/mail/user": 1 message 1 new &gt;N 1 user Wed Jan 11 16:30 18/549 this is the subject Message 1: From user@ubuntu Wed Jan 11 16:30:04 2012 Return-Path: &lt;user@ubuntu&gt; X-Original-To: user@localhost Delivered-To: user@localhost Date: Wed, 11 Jan 2012 16:30:04 -0800 To: user@localhost Subject: this is the subject User-Agent: Heirloom mailx 12.5 6/20/10 Content-Type: text/plain; charset=us-ascii From: user@ubuntu (user) Status: R This is the message body Please give us a complete standalone testcase that exhibits the problem. 
The module I linked to is one of many in the perl email ecosystem; it's just the simple interface. You can use [`Email::MIME`](https://metacpan.org/module/Email::MIME) to create multipart messages with attachments. SSL is a function of the transport chosen; the default is `sendmail` which uses whatever MTA is installed on the system, which would almost certainly speak the various flavors of TLS when delivering to external hosts. 
Abandoning some rights is not the same as abandoning all rights, and abandonment of a right must be manifested by some overt act indicating an intention to abandon that right. Furthermore, it's not clear that abandoning a right recognized automatically under the Copyright Act indemnifies the copyright holder from any responsibilities--implied or otherwise--arising from publishing a work.
I'm not sure what's not clear. I'm not using the file extension. The OP did. Someone asked why. I pointed out a reference for why the extension exists. Note that the very first words of my comment are "used to be..." When I referred to not finding "where I read that", that was a fair number of years ago when I was starting with Perl. My very first script had a filename ending in .plx because of my reading that very bit. That's probably what made me inclined to comment. Now, I'm done wasting time posting about 8 fucking bits of file metadata that don't mean a thing. Cheers! :D
Yes, you don't run into the limitations on shell commands or worry about escaping every possible thing that might appear in that message. I would also do it this way, although I would know I should use 3 argument open instead ala: open (MAIL, "|-", "mailx -s 'subj' -A acct 'me\@example.com'"); print MAIL "msg"; close(MAIL); #program won't exit until this happens.
and use a lexical variable for the filehandle...
Yes, there is a not so obvious one, besides being able to programmatically pipe to/from a command. When open is called with a pipe, it returns the pid of the process.
A license does not help me when i have to change all the use calls to a module. A license does not help the other users when an author refuses to accept a bugfix patch. You're still ignoring the significance of the CPAN namespace.
It's unclear whether you're looking for an "it *is* being done using a shell script" or a "because that would require rewriting the whole thing" type of answer.
yep, perl threads are crap so what are we gonna do about it ? :) that chart is quite embarrassing, I mean really embarrassing.. I mean ridiculously embarrassing.
Fix the meteor benchmark to bring it in line with the other languages. It's the one that's skewing Perl. And in all fairness, i don't find it embarrassing since most of the solutions for perl were written by people who do it as an aside, at best.
&gt; What's bad about that? They use threads. Any program that doesn't use threads isn't a valid solution to chameneos-redux, because it's specifically a benchmark of threads and how well a language can synchronize threads. Take a gander at the rules.
how about threads::lite,POE, AnyEvent ? None of that works as a "replacement" for threads ?
While "Whose hot-rod is fastest" is cool and everything, isn't it kind of irrelevant since in practical terms when your preferred language is too slow or whatever, you just call out to a library function from C or something to do the heavy lifting anyway, right?
They work just fine as replacements for threads, but none of them is allowed in shootout solutions. 
It means that the questions in red are the wrong questions and then gives the correct question to ask.
To a degree yes, but if you're evaluating which language to use for your next project and speed is important, you generally don't want to have to be constantly working in 2 languages - the host language should be fast enough for whatever you need.
that's pretty lame, one of 'em should be included in Perl core modules
Looking through the various programs, it's obvious that perl is just bad at some tasks, particularly the [Binary Tree test](http://shootout.alioth.debian.org/u64q/benchmark.php?test=binarytrees&amp;lang=all) where perl took 11 minutes compared to C's 13 seconds. This makes me thing the perl's solution was just written extremely poorly. Also, I'd like to note that in most cases when perl does badly, so do other interpreted languages, such as PHP or Python. In a battle between a program compiled for the architecture, like C, versus Perl, C will _always_ win.
The biggest problem is that if we don't fix these benchmark scripts to be more representative of what perl can really do there will be a "perl is slow" meme and it will be harder to get rid of the notion that perl is slow. Especially if people can point to a semi-objective chart saying so.
Judging a speed contest without allowing CPAN is like having a presidential debate where you're not allowed to use any words longer than two syllables. Yes, somebody's going to have an easier time of it than others, but what have you really learned? Nobody uses Perl like this in practice.
Also, I believe part of the motivation for Perl 6 was to work on an architecture that would be faster and thread more gracefully. Does anyone know if any of the Perl 6 implementations have even started implementing threads?
Yeah, meteor looks fixable. As for use of threads: I hacked on several of the Perl programs last year or so to improve the scores on the 4-core machines, and in some of them I used threads — in places where use of threads isn't a disadvantage at all, and it was easier than forking. And as I pointed out in my other post, any solution to chameneos that *doesn't* use threads is disqualified.
I can imagine that it was easier, compared to forking threads are easy to work with. However in certain conditions (threads not pre-spawnable) they're a massive drag, and them being implemented on a microsoft spec for the purpose of fork emulation doesn't make them very stable to use.
I know all this. My point is that you can't look at something and say that it's obviously a stupid solution because it uses threads, when the solutions that use threads are either ones that are *required* to use threads, or ones where threads don't confer a disadvantage beyond some memory bloat.
Eh, i was pointing it out more because of this bit: a transliteration of Python 3 #2 If threads are required, sure, ok, use them. However if they can't be bothered to write a proper perl solution i would've preferred they didn't write one at all.
It's not just that. These tests are targeting a level below perl's design's strong point. Perl hands you some powerful high-level constructs like hashes and makes them super-easy to use. If you asked perl to write a low-level implementation of hashes, it would be *terrible*, but if you asked it to actually *do* what you use hashes for, it would be quite competitive. Also, Perl's scalars are big and heavy compared to typed integers in other languages, but they make programming tasks that are hard in those languages super-easy, both to write and maintain. &gt; In a battle between a program compiled for the architecture, like C, versus Perl, C will always win. And hand coded assembly will always beat compiled languages, until you limit programmer experience and time. Factor in reality, and it's often easier to make a fast perl program than it is to make a fast C program. A C program that's super efficient, but uses arrays and when put into production scale, slows to a crawl in certain circumstances might look great on paper, but a perl program that uses hashes ends up slower when it doesn't matter and faster when it does. A C program then hurries up and waits for networking and disk can eat the dust of a perl program that distributes load across a few disks or over a few machines, coordinating activity over password-less SSH connections. Like most languages, Perl has it's strengths and weaknesses. It's not hard to hit perl's weak points, especially when you port code written for a language with completely different strong points to perl. When you design for perl's strengths, you can end up with a near optimal performing solution that is extremely efficient with programmer time. Some of the most amusing moments in my perl experience have been when people try to estimate how long it would take to re-implement relatively complex perl code in Java/C and the estimates come out at a team of 10 people working longer than it took me to write the original implementation. Those days, perl doesn't look quite so bad.
Good one! I was thinking along those lines but I wasn't sure that would work and was too lazy to look it up.
Yes, but put yourself in the position of someone starting a new project, and it'll need more than one dev to complete. Would you want to choose a language that requires people with expertise in another language, or would you rather just choose a single language that will meet the needs of your project? This is I don't think "oh just use C/XS when you need it" is the best answer we can give. Of course the correct solution is to make Perl faster - but as usual, the correct solution is nontrivial :)
&gt;Also, I'd like to note that in most cases when perl does badly, so do other interpreted languages, such as PHP or Python. But PHP, Python and Ruby are twice as fast in these tests, than Perl. And *that* is bad.
&gt; Does anyone know if any of the Perl 6 implementations have even started implementing threads? Not in any usable form.
I'm sure http://search.cpan.org/perldoc?Devel::NYTProf would help you.
Been using that for a while already. :) I'm trying to get more eyes on this, because i have only so many ideas on my own.
I mean, please write some small document if you are interested in help of others
200 is a good small tester and 2098 is the canonical value to get these results: http://shootout.alioth.debian.org/u64/program.php?test=meteor&amp;lang=perl&amp;id=1#log
Yeah, they have a whole section on that in their Help: http://shootout.alioth.debian.org/help.php#contribute
Constants *are* more elegant and nicer perl idiom - also unless instead of if ! Would be nice if solution was good perl practise *and* fast ;)
I won't say no to a pull request. :)
[Threads work](https://github.com/sorear/niecza/blob/master/examples/threads-feed.pl).
Don't care. I use perl for rapid development and deployment. It's rare that I have to consider run speed. I'm typically bandwidth limited, not cpu bound.
That's just *terrible* for all of my IO-bound programs. I'll have to solve math games in some other fashion.
Saying "now" is misleading because it was the slowest when I checked shootout nearly 2 years ago.
maybe just hit up some folks in #perl6 with a link to this and they can drop by and tell us more about threads in p6. thanks
This was always a safe assumption. All my utility apps start out as perl, and if too slow, ported to java, then to c. I've only had to port all the way to c twice (mostly to take advantage of block loading millions of records into oracle).
I've looked into some of these and played with some of these in NYTProf. This is what I came across: 1. The perl solutions on there are *bad* - for example these bench marks claim that perl has a slow regex implementation. We all know better. 2. With NYTProf I was able to cut 30% of the time off of the n-bodies solution using some perl 5.12 constructs like state &amp; changing the way it initializes variables (really, looping the initialization of a scalar several million times is going to be slow) 3. the perl applications were obviously not optimized (at least not by someone that knows perl), for example: &gt; $mag = $dt / ($distance * $distance * $distance); is much slower (when looped over millions of times) than &gt; $mag = $dt / ($distance ** 3 ); So really, the tests are flawed, we could improve them, but do we care that much? Yes, our scalar implementation is slow, RURBAN has had some interesting things to say on how to fix that: http://blogs.perl.org/users/rurban/2011/02/use-types.html
I've used perl5's threading and while people seem to hate it, I've never had a problem, other than destructors getting run in every thread.
This is my package. I'd welcome any input! I got stuck trying to post comments, and then then holidays... etc, but am planning on getting back to it now that my time is starting to free up again. I think I would like to rewrite it using moose now that I have a better handle on it. If there is some interest in this project, I'll throw it up on Github (or similar), when I initially started on this project it didn't seem like there was any interest so I never bothered.
 #!/usr/bin/perl use strict; use warnings; use LWP::Simple; use JSON; $|++; my $bgcmd = "awsetbg"; # change to whatever bg setting program my $bgloc = "/tmp/"; my ($json_txt, $json, $img, $img_json, $rand); my @imgs; print "downloading list...\n"; $json_txt = get("http://www.reddit.com/r/wallpapers/.json") or die "Failed retrieving list: $!\n"; $json = decode_json($json_txt); for my $href (@{ $json-&gt;{'data'}-&gt;{'children'} }) { push @imgs, $href if $href-&gt;{'data'}-&gt;{'url'} =~ /(jpg|png)$/; } $img_json = $imgs[int rand @imgs]; $img = (split("/", $img_json-&gt;{'data'}-&gt;{'url'}))[-1]; $bgloc .= $img; print "downloading " . $img_json-&gt;{'data'}-&gt;{'title'} . "...\n"; getstore($img_json-&gt;{'data'}-&gt;{'url'}, $bgloc); system($bgcmd, $bgloc) == 0 or die "Failed running $bgcmd: $!\n"; Stole this from a friends bash script.
Congratulations!
Perl's strong points have long been adopted by other scripting languages. However those (python, ruby) have better scores. And not just slightly better, Perl's scores are twice as high.
Perl's regex implementation is insanely fast. Like I got Regex::Assemble to make a regex to match every town name in Australia (about 10,000 of them) a while back. Yes it was amazingly fast. 
I'm thinking this could be improved in speed a lot by using bitmasks instead of arrays. Only issue with that is that the playing field is 50 tiles big, so one has to use either a 64bit number for the bitmask or split it up into two bitmasks and right now i don't quite have the time for that.
"*That*, Detective, is the right question. Program terminated."
&gt; meteor ... It's the one that's skewing Perl. No it isn't. meteor-contest isn't included on that summary page, nor is it included in the direct comparisons.
I'm not sure why a professional coder would use perl for something for which it is not suited. 
The n-body comment was from a Fortran programmer, and if you look at k-nucleotide you'll realize it's all about hashes.
You've already looked at the direct comparison between Perl and Ruby 1.9 -- the tasks listed there are the tasks included on the summary pages. Also, [check one-core](http://shootout.alioth.debian.org/u32/benchmark.php?test=all&amp;lang=perl&amp;lang2=yarv#faster-programs-approximately) as-well-as 4-core.
There's a Perl regex-dna program faster than many other programs shown "as a regular benchmark" - [Perl #2](http://shootout.alioth.debian.org/u32/program.php?test=regexdna&amp;lang=perl&amp;id=2)
I played with a small algorithmic improvement to skip the recursion when it's already found a solution, but apparently missed a condition somewhere.
&gt; only those tests that both languages succeeded on [pidigits](http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=perl&amp;lang2=yarv#faster-programs-measurements) Perl Failed 
This benchmark environment is bogus, and was bogus before. Faster and correct alternatives are not shown, the data is wrong. Please re-test by yourself. I retested on my machine, a debian x64_86, perl5.14.2 (non-threaded, even -Os not -O2): $ time perl binarytrees.perl 20 9m12.778s * ruby 1.8.7 needs 15m43.244s, * php 5.3.6 needs 14m54.491s, * python 2.7 needs 5m22.525s, * compiled perl (perlcc -O3) needs 8m58.287s (not optimised at all), * optimised compiled perlcc -O (using B::CC) does not work yet correctly. I'm working on it. perl has not the most optimised memory and stack handling (as is tested here), but ruby and php are mostly slower than perl. Always were. Note that the original binarytrees.perl needed 12min and was wrong, so I improved it: https://github.com/kragen/shootout/pull/1 But it was still faster than php and ruby.
The tasks listed on the direct comparison page, in step 3, are the tasks included on the summary pages, and [the default tasks for this fun page](http://shootout.alioth.debian.org/u32/which-language-is-best.php). How long do you want to search through PHP source code and config files before discovering that truth ;-) Incidentally, someone just contributed [a Perl meteor-contest program that's twice as fast](http://shootout.alioth.debian.org/u64q/program.php?test=meteor&amp;lang=perl&amp;id=2) and makes no difference to the direct comparison or summary pages.
Yeah, i submitted that. Were the one that accepted it? If so, i'd have to ask why you didn't tell me that you were actually involved in the site? I was questioning what you were saying because you had made exactly zero indication that you had any insight and appeared to me like an entirely random passersby. And if you are involved: Why the hell doesn't the summary page state this upfront instead of making people GUESS at where the data is coming from? This has nothing to do with "truth", this has to do with Alioth hiding very basic facts about themselves, either out of malice or out of plain laziness. Utterly terrible communication at multiple levels in its purest form. And yes, i'm fairly upset that i wasted time on this because this site was unable to communicate itself clearly. Edit: Even most of this conversation could've been skipped if you had answered the question i asked in my very first reply to you: **"how do you know meteor isn't included?"** But no, instead of saying: "Because i know the code of this site." you had to play coy. Thanks a lot.
&gt; Why the hell doesn't the summary page state this upfront ... `- all benchmarks -` in the drop-down menu is out-of-date, and you just found that bug. Edit: But then you wouldn't have found that bug. 
&gt; ruby 1.8.7 The website shows Ruby 1.9.2 not Ruby 1.8.7 &gt; python 2.7 The website shows Python 3.2.2 not Python 2.7 &gt; I retested on my machine On your machine the PHP program is about 15.8% faster and that first Perl time is about 17% faster. **The programs are faster for both languages so maybe you have faster hardware**. Do you think checking programs into `github.com/kragen/shootout` will add them to the benchmarks game? [That's not how things work.](http://shootout.alioth.debian.org/help.php#stepbystep)
This sounds like a great idea!
It probably started out much higher because of the defunct [GitPan project](https://github.com/gitpan) (which suprisingly, people are still using). Anything we can do to increase our standing? Found a [wayback link](http://web.archive.org/web/20100103031227/http://github.com/languages) showing Perl was #2 only a year ago.
I've done some work towards building my own. I'd like to help out. what feature set are you looking at? I have some code for reading through subreddits if you'd like it.
Even if Perl were the slowest, it would not be necessarily so bad, on the overall picture. Suppose I want to implement something quickly, a one-time processing of data. With C or Java I might work 3 hours to write the code, then execute it in 2 seconds. With Perl I spend 15 minutes coding and another 30 seconds running the script. Perl wins by a large margin. C and Java shine at core code that is deployed multiple times, where development time is much less important than execution time. But that is not something we get to develop every day. Usually it's small things. 
&gt; NOT ACCEPTED: Caches the recurrent random number sequence instead of creating a random number every time a selection is made. Well, caching a result looks like cheating to me, too. Could you link to the python version? I heard function calls are really slow in python, which means that everything with a dot is a performance killer. 
I wanted to scan disk images for byte sequences, tried a few languages, but perl wasn't as fast as I'd expected. I think this has changed in the last 4 years. The other scripting languages really did something to increase their performance.
The test may be silly but other languages are suffering the same disadvantage and performed better than perl. It personally doesn't matter to me, I don't use perl because I honestly believe it is faster than python or ruby, I use perl because it makes me faster.
FWIW, I'm under the impression that function/method calls in Perl aren't blazingly fast either.
&gt; but if you asked it to actually *do* what you use hashes for, it would be quite competitive. [k-nucleotide is mostly about hashes](http://shootout.alioth.debian.org/u64/performance.php?test=knucleotide), Perl #2 is quite competitive with some and not so competitive with others. 
Did you see this bit? &gt; Asked them to pull down many implementations that used the same algo as I did. &gt; They did, **to some extent.**
Did you see what was actually said back in July 2011? "[Thanks for your help.](https://alioth.debian.org/tracker/index.php?func=detail&amp;aid=313164&amp;group_id=30402&amp;atid=413100) I've moved programs that use an integer lookup-table into a separate task ... If you think I've missed some from fasta please let me know which to look at again."
Lessons not learned: - *the admins* are willing to listen, the benchmarks game has improved over the years because of that willingness to see if there's a better approach. - being a cheat just isn't cool. - knowing and implementing what works for thy language, and having a faster language implementation *both matter* - bending the rules results in your bogus implementation being thrown out (see #2)
Two examples of german court decisions. I will quote first in german, then add a short english explanation. The quotes stem from this page: http://ig.cs.tu-berlin.de/oldstatic/sa/043/#Anhang &gt; LG Stuttgart: Schutz von Public Domain Software, Urteil vom 19. August 1993 &gt; &gt; Bietet der Berechtigte unter der Rubrik Public Domain Software gegen Vergütung an, so gibt er sie damit nicht zur kommerziellen Vervielfältigung frei, weil der Begriff Public Domain zwar im allgemeinen freie private nicht aber kommerzielle Nutzung bedeutet. &gt; &gt; "... so ist es nicht möglich, allein aus der Kennzeichnung ... als PD-Software unbeschränkte -- insbesondere auch kommerzielle -- Nutzungsrechte herzuleiten. Here the judge says that in german public use Public Domain refers only to private use, meaning that a PD release does not allow commercial reuse. &gt; OLG Stuttgart: Kein Schutz von Public Domain Software, Urteil vom 22. Dezember 1993 &gt; &gt; Aufgrund des Vertriebs [...] als PD durfte die Beklagte [...] darauf vertrauen, daß die Klägerinn zumindest auf eine Geltendmachung eines Urheberrechts oder ausschließlichen Nutzungsrechts verzichtete, jedenfalls soweit es um die unveränderte Vervielfältigung und Nutzung der Programme ging. In this example the judge agrees that a release as PD means the user can trust on the releaser not making use of any copyright; however this is restricted only to the use and redistribution of the **unchanged** software.
What's ridiculous about showing working programs written in Ada and Clojure and Erlang and F# and Fortran and Lua and Racket and Smalltalk - *less familiar* programming languages that many programmers won't have seen before.
That's a great idea! I wonder if comparing the optimization possibilities of specific algorithms and expressivity options limited to specific language constructs is an effective way to achieve that goal. (Actually I lie--I think it's counterproductive.)
I agree. It's a horrible benchmark and pointless. I guess my point is that the test was not unfair to perl in particular. 
Almost forgot this, thanks a lot! :D
&gt; (Actually I lie--I think it's counterproductive.) **I see the analytics data** which shows how many visitors look at the program source code written in Ada and Clojure and Erlang and F# and Fortran and Lua and Racket and Smalltalk and ... What you think is empty supposition. 
Simpler now.
&gt; compared to the fastest programs. Does this mean: "compared to the fastest programs of all other languages in the shootout."?
Then it should say that. :) Otherwise, now it's really clear, thanks!
A cheat?!?! The rules **did not mention** back then that the random function could not be improved on, removing the useless repeating occurrences of the generated number. Since then, the rules have been reworded to require full execution on every nucleotide selection. At least 10 entries, Python included, improved (not cheated on) the random function. So I was just bringing Perl up to date to what seemed a perfect valid improvement shared by several entries. 
"being a cheat just isn't cool" is my response to your opinion "... being a snitch just isn't cool." You're the one talking about "bogus implementations". 
&gt; C++ written in Racket Eli Barzilay and Sam Tobin-Hochstadt and Matthew Flatt contributed Racket programs, not C++ written in Racket. &gt; if I were to teach someone to write idiomatic Haskell... After you've tried "to teach someone to write idiomatic Haskell" you might have something interesting to say on that subject - meanwhile [Real World Haskell](http://book.realworldhaskell.org/) &gt; People focus on scoreboards and territorialism. I see the analytics data, I know how many visitors look at the program source code written in Ada and Clojure and Erlang and F# and Fortran and Lua and Racket and Smalltalk and ... You see nothing, you know nothing.
&gt; After you've tried "to teach someone to write idiomatic Haskell" you might have something interesting to say on that subject - meanwhile Real World Haskell... Funny you mention that; I was one of the people encouraging Brian O'Sullivan to write it, and I submitted comments on the manuscript. (Oh, and the first real world program I wrote in Haskell found a bug in the GHC GC. The second found a bug in the type checker.) &gt; You see nothing, you know nothing. You're right; I can't see how looking at access logs proves that autodidacts are (effectively, or at all) exploring comparative programming linguistics based on silly microbenchmarks.
Will there be a diff available from this to the old version? Or at least tags that marks the commit of the versions that were sent to print?
&gt; encouraging Brian O'Sullivan Did you also encourage Brian O'Sullivan to contribute a Haskell program to the benchmarks game? He did. &gt; proves that autodidacts You keep making stuff up. You keep putting up strawmen to knock down. 
You keep trying to misunderstand so it's hardly surprising that you succeed. The website shows working programs written in less familiar programming languages and the website tracking data shows visitors take the opportunity to look at the source code of those programs, period.
&gt; The rules seem reasonable, but their interpretation often leaves me scratching my head. That's a better way of saying what I've been trying to say. Thank you. &gt; The *worst* thing that could be done (and I know this isn't what you're suggesting) is to modify the runtime to address the existing benchmarks. Not necessarily. It's pretty clear from even simple profiling of the meteor benchmark that Perl 5 could run at least 5% faster if it had typed arrays even only for integers. The overhead of manipulating full SVs when all you need is an IV is measurable. A clever programmer could optimize this by hand with `pack`/`unpack` games, but that's a workaround and not a real solution.
Try Chart::Clicker or Chart::Gnuplot.
Right, a diff is about 800 kbyte. At least the diff i made based on guessing which commits you sent to the publishers. I hope you can add the tags soon so i can confirm i was right. I'm also pondering editing the diff down to only content changes.
Is this "w3techs.com" site run by the same people as [w3schools.com](http://w3fools.com/)? I see no description of their methodology or sample size. The site smells spammy. The user posting this link does too.
Very suspect. There is no way to tell what server-side technology is used to implement a site, other than guesswork or some crude heuristics like "if looks like Movable Type, then Perl." It sounds like they're guessing based on URLs and possibly the value of the `Server:` HTTP header. If true, this is simply laughable. 
Some answers to the questions as provided by the author of said article in the comments: - How did they collect this data? Some crawler analysis, and some actual human interaction. - How do the absolute numbers look like? He didn't want to post them, which is explained because they don't sample the entire internet, but only the top 1.000.000 sites. So in summary, they're actually only looking at the top slice of the internet. I'm still hoping they'll publish the absolute numbers anyhow and will also understand what i mean by weighting.
Any thoughts on what the actual percentage might be?
Interesting, since I just rolled out a project on Mojolicious this weekend...
10/10 Would rage again.
I thought with 23 comments there would be some cool technical discussion or a bunch of alternatives....:(
One thing that confuses me: Why is Perl 6 being implemented in all kinds of fancy VMs and dynamic languages and flavor of the week stuff, but not a single project does it simply in C. Why is that?
I'd love to, but it wouldn't be practical: I don't have the papers to work in the US, for one. I'm sure you'll find someone, though; all the best!
&gt; Spent a decade getting where it is, has its own XPCOM problem (Parrot). Rakudo's XPCOM problem is the big wad of C code that *isn't* Parrot.
I'm still waiting for my comments on there to be moderated. I simply have no reason to believe them at all without numbers and examples to back it up, all they provide is some top level percentages, no source data, no methods, not even any worked examples. Mostly I'm annoyed that they're getting a lot of attention for what could be useful information if they could back it up and publish their raw data, or even a sample of the top 100 or 500 sites.
&gt; Can you clarify what you mean by "simply in C"? As Perl 5 was implemented. Or Python. Or Ruby. Etc. * C's not a very expressive language in which to write and maintain large programs I see this as a possible reason, but not as a strict obstacle. My main worry is that they're limiting the possible pool of volunteers in implementation needlessly. * Perl's execution model requires a runtime I actually do not understand this. Can you explain in more detail?
...but it's still higher than those of Python and Ruby combined. [Not that I have any faith in their methodology...]
i love mojolicious, i really do, but i HATE the name and i honestly think it would be much more successful outside of the perl community with a different name. i honestly feel embarrassed when i mention mojolicious to coworkers
You keep making stuff up. The only person talking about "convincing people to read code of languages they don't normally use" is you. http://www.reddit.com/r/perl/comments/og6zt/perl_fasta_shootout_lessons_learned/c3hvgut
&gt; The only person talking about "convincing people to read code of languages they don't normally use" is you. If this is the point in the discussion where you try to convince everyone that the gulf between the phrase "languages they don't normally use" and "less familiar programming languages" is significant *and* that "tak[ing] the opportunity to look at the source code of those programs" is substantially different from "read[ing] code", have a cookie.
[Here you go](http://xkcd.com/519/)
I have programs I want to run both from my webpage and from my desktop. PHP is an annoyance since it only runs from a server, and I don't like the complications of running a server on my desktop. Javascript has the annoyance of not allowing access to my local files, unless I can transmogrify them into JSON. So that leaves me with perl or python, and I pick the former for its concission.
Do you have a link to the job requirements, description, salary, etc? Also, are they willing to pay relocation?
In most senses there never has been any such things as "the Parrot one". In another sense, the Parrot one is Rakudo, which is the other one mentioned in the headline.
So what's your suggestion for the more apt name?
Won't believe until Netcraft confirms it.
I'm with you with Niecza=Chrome and Rakudo=Firefox. Not quite agreeing with Perl 5=IE. Perl 5 and Perl 6 are different standards, they have evolved into two separate languages. You would not expect perl 5.x to implement Perl 6 specification. The Perl 5 "fanboys" do not sneer at Perl 6's progress (in fact they are thankful that the Perl 6 specs help Perl 5 quite a bit in creating Moose, smart matching, etc). However, they take a "yawn? so what" attitude because none of the Perl 6 implementations can be used for real-world projects, even after 10+ years. What can you say about a browser that can only render very short HTML 1.0 markup and requires 2 minutes to do it? On a usefulness scale, current Niecza and Rakudo are probably like Chrome 0.01 and Firefox 0.02. Moral of the story: analogies are not perfect. 
How about AcmeTron 5000? Is that better?
"Habitual Wheel Reinventor"
Opera is using perl for a lot of company critical applications/systems, and [we are hiring](http://www.opera.com/company/jobs/opening/330/)!
bash != perl, think you ment perl script?
I tried using the tool ( http://w3techs.com/sites ) they suggested to check individual sites as they refuse to publish data or methodology.. the results were underwhelming : I got 0 correctly detected and 1 false postive for PHP on the following sites : * lovefilm.com * slando.com * imdb.com * catalystframework.org * socialtext.net * cpan.org * metacpan.org (misreported as PHP) * hiveminder.com * Bestpractical.com their ability to detect server-side technology beyond (advertised and first tier) web servers is not looking credible.
I looked at their result, tested their tool (http://w3techs.com/sites/) on some sites that I am admin of and what their finding represents is the decline of usage of mod_perl, not decline of usage perl per se. This is not surprising - with arrival of FastCGI and Plack as preferred method to run perl on the servers, more and more site are transitioned away form apache and mod_perl to this new connectors. 
Yeah, I was stretching it a bit with the IE thing. I've been getting a bit pissed off seeing a constant stream of negativity coming from the same few perl5 people every time any perl6 news is posted. The language isn't as unpleasant as IE6 but the vocal minority certainly make it feel that way.
It's because it is not possible to detect if web site uses Perl.
Yeah, both camps should get along better, really. 
Well, that's nice to know. Sorry for my earlier tongue-in-check response :)
&gt; I've been getting a bit pissed off seeing a constant stream of negativity coming from the same few perl5 people every time any perl6 news is posted. It would be nice if that Perl 6 news were more anchored in reality.
you mean ported?
No idea, honestly. I just looked up the January 2012 Web Server Survey: http://news.netcraft.com/archives/2012/01/03/january-2012-web-server-survey.html Maybe you can find more on their site.
I proudly display perl foundation emblem ([the onion](http://www.seeklogo.com/images/P/Perl_Foundation-logo-529822AB19-seeklogo.com.gif)) on my personal website, but it links to http://www.perlfoundation.org, so I'm going to change it right now.
Lickablemojo?
I feel it's too generic to link to perl.org. Maybe there should be a dedicated site for "Built with Perl" (e.g. built.perl.org) that explains the foundation of Perl and gives some links to get started. Also need a sweet and modern button/logo for Perl that is not a GIF from 1995.
Button is being worked on. :) Meanwhile a text link would be really nice.
Text Links have the advantage of showing up in Google for TIOBE and other things to index too. Images are harder to parse.
no reason you can't do both
I think if you add a proper alt tag, Google will pick it up fine. :)
I would love to contribute to this. I wrote some documentation and submitted it over a week ago but there's been no word from the project maintainer. :(
Maybe after another couple of rewrites.
That perlmonks thread is from 2003 :(
Yes, Catalyst. It's a much bigger framework than the other two, so more suited to heavy lifting of larger, more complex sites - which is what companies tend to have. And if you understand Catalyst, you can scale down to the other two more easily than up from Dancer or Mojolicious to Catalyst.
Okay thanks :)
+1 for Catalyst. The first full-time Perl job I had was supporting &amp; extending a large Catalyst application. 
There are quite a few using Mojolicious. https://github.com/kraih/mojo/wiki/Projects-and-Companies-Using-Mojolicious
1. First learn Dancer (because it's easy and quick to learn). 2. Then learn Mojolicious (because it's "just right" when Dancer isn't enough). 3. Finally, learn Catalyst (industrial-strength but overkill for most sites).
Learn moose and dbix::class.
Sometimes companies don't divulge that. :-\\
Catalyst is the one that might take a few hours to learn. If you are familiar with Ruby's Sinatra then you can grok Mojo and Dancer(admittedly styled in the vein of Sinatra) in a few minutes. In fact, understanding Sinatra will get you far in a lot of recent frameworks (PHP's Slim, Node.js' Express, Scala's Scalatra, Python's Flask, etc.) Personally, I'd recommend just strengthening up your Perl skills in general if that's the language you are set on. Frameworks are convenient abstractions/extensions of the the underlying language. If you're interested in the web, read and know HTTP specs fluently (Oreilly's Book, HTTP:The Definitive Guide, is excellent.). Also, keep an eye out for newer webstacks that are starting to use websockets as some of the existing frameworks are already looking antiquated. A good example of this is the recent blog post describing the stack used by Fogcreek Software for their Trello project (http://blog.fogcreek.com/the-trello-tech-stack/). The "Modern Web" is here already and some are not even aware of it. This is another great post (http://lucumr.pocoo.org/2011/11/15/modern-web-applications-are-here/) by the author of Flask who is well-regarded in the Python community. 
If you mean learn object-orientation(of which Moose is an implementation) and an object reference mapper(of which dbix is an implementation), then I agree. But perhaps just saying learn the fundamentals behind these implementations is a better answer and would allow the OP to choose not only Moose but if needed also Mouse, Moo, Mo and the future M( :) ) implementations?
Great, we can finally buy the 50 ft tall stuffed camel we've always wanted.
There are plenty. I work for one of the Dancer-using ones, and know of others. As kraih posted below, there are also companies using Mojolicious. Both are fairly new frameworks, but have been round long enough to be adopted commercially in various places. It has to be said though, if your goal is solely to have a skill on your CV that's likely to be most marketable, Catalyst is probably the top choice, as there are far more places using Catalyst than either Dancer or Mojolicious. (Disclaimer: I'm part of the Dancer team)
Not to put catalyst down. Its just overkill the majority of the time as some others have stated. Honestly, the only reason I do web dev in perl is to use Mojolicious. It is rapidly developed and all the devs are meticulous. I have tried finding another framework in any other language that compares and I have not. I would highly advise learning that. If you want to get a job at a company it is usually mod_perl2 that is deployed on an apache server. This is my experience in Finance at least. 9 times out of 10 they ask for mod_perl experience. Catalyst would probably be next, but I think ive seen it once in my field in the past 5 years. 
I dont think I have seen one firm on wall st that doesn't use perl for something. Most of the people I talk to are Goldman Sachs, Deutsche Bank, Jeffries, Rosenblatt, BoFA, Citi. These firms for sure have tons of perl jobs. This is just to name a couple. If you havent worked in finance in 5 years im not sure how relevant your opinion is.
The problem with that stance -- that users should avoid the system perl and install their own -- is that the very users who are stuck using RHEL/CentOS are the same ones that don't have those kind of freedoms due to administrative policy. They have to stick to installing official Red Hat packages, otherwise their pointy headed bosses get nervous that something might break without a support contract in place. (Edit: yes, I'm aware that Red Hat's policy is that supporting Perl only means that the modules build, they won't help you get your code working if something breaks. But for some reason, that never stops the manager-think that anything self-installed corrupts the whole system irrevocably.) Besides, even if you're not an enterprisey management dweeb, it's still quite a burden to officially take on supporting your own perl: you're on the hook for security vulnerabilities, integration testing of new releases, etc. Yes, in a perfect world everyone would support their own perl and always test their code against the latest releases, but that's a pipe dream. Users by and large depend on the distros for that, so telling them to dive in and do it themselves is probably not going to fly. 
I disagree. These days it's easy to build a perl, install the modules you need and package it up. And of course you have a CI environment with copious tests, don't you?
&lt;http://perlbrew.pl&gt;
IIRC this also happened years ago with Ruby on Debian, which got split into a gazillion packages. This is annoying because you cannot rely on certain core/builtin modules being on a system. But I guess we just need to deal with it. Other "modular" software got the same treatment (Apache, X.org, PHP, etc).
Certainly! Make sure to use [cperl-mode](http://www.emacswiki.org/emacs/CPerlMode) over *perl-mode*, also check out [Devel::PerlySense](http://search.cpan.org/~johanl/Devel-PerlySense-0.0191/lib/Devel/PerlySense.pm) if you want more IDE-like features.
It's a hard question to answer when you don't have an immediate task to solve as they are good for different types of project. Given that your aim is to impress an employer; if I were looking to employ you I probably wouldn't care which you knew something well and could demonstrate some nice code you'd written. I'd pick one (see other comments for the pluses and minuses) and then write something useful with it. Most employers are more interested in finding someone with an aptitude for coding than someone who has just crammed a particular API.
It's all good...
Yeah, there's a thousand stories like this. If you've ever tried to develop on Solaris, the "half-baked-vendor" issue is right at the forefront of every decision you make, and this "To Heck With It -- I'll Just Roll My Own" really simplifies things. 
The bigger problem with Ruby on Debian was that `gem update --system` (i.e. `gem`s ability to update itself) was crippled. A big, big pain. I also recall some problems with OpenSSL, but that may have been OSX and Ruby. 
I'd prefer they'd rename the system perl to, say, "systemperl". That would remove the temptation of people to upgrade it to a newer but incompatible version.
It irks me that cperl is not yet the default mode.
What do people think of [Padre](http://padre.perlide.org/) at this point? I've used emacs for years.
No. He's using [Data::Printer](https://metacpan.org/module/Data::Printer), which is a really nice pretty printer (with emphasis on the pretty). (As far as the name of the function `p`, I think that's borrowed from Ruby, where it [prints an inspection string](http://www.ruby-doc.org/core-1.9.2/Kernel.html#method-i-p) of objects.)
I've used it a bit in the 0.6x days. Quite nice, I guess. Didn't feel sluggish. But I went back to Emacs, probably because I'm just a sucker for CLI. Looking forward the Padre 1.0 though. I hear it's going to be great. 
I use Emacs daily. For coding Perl I just use cperl-mode for syntax highlighting, and M-/ for completion. That's it. 
Good point, but it does line up so nicely the way it is...
Actually, there is a movement afoot to get rid of /bin in Linux entirely, and make it a symlink or bind mount to /usr/bin, and similarly for /lib and /sbin. When this is completed, you'll be able to refer to /bin/perl or /usr/bin/perl equally. The original reasoning behind having two was supposed to be that you could boot the system without /usr existing yet, and then mount it at a later time (such as if it was a NFS mount or something.) You haven't actually been able to do that for a number of years -- [various packages have various dependencies on things in /usr](http://freedesktop.org/wiki/Software/systemd/separate-usr-is-broken) (for example, data files under /usr/share) that create subtle bugs if you try to boot with /usr missing. Maybe it will appear to work, but there will be corner cases and subsystems which fail to initialize. Distros have had to just say "that's not supported" because actually teasing out all those dependencies and then somehow moving the affected files out of /usr would just be a huge mess. If you want /usr mounted on NFS you can just do it from the initrd. Thus the advertised reason for having two directories has ceased to be relevant for a long time, so there really is no use for it. Having them unified would mean that everything would be under /usr, making it easier to mount as read-only or share over a network. [This page explains in detail.](http://www.freedesktop.org/wiki/Software/systemd/TheCaseForTheUsrMerge) Edit: So to answer the question, it's really only Linux that has this split filesystem still. Things like Solaris already have /bin as a symlink to /usr/bin, so /bin/perl should work OK there. 
And now [here](http://article.gmane.org/gmane.emacs.devel/147977) as well :)
OK, I've collated all the comments I've had so far: http://www.davehodgkinson.com/blog/2012/01/emacs-as-a-perl-ide-ii/ Thanks for the input!
perlbrew isn't really that good; there are other full environment managed (like modules) that'd work better. perlall appears to be moving towards being a better perlbrew and doing what most users of perlbrew want anyway. The post linked here sucks, btw. I can't believe someone found it worthy.
Yup I do this too. I also have a script to symlink all my setting files from the dotfiles repository. The problem is, some of the settings are private (e.g. private keys in .gnupg, CPAN password in .dzil, etc). Haven't got the time to separate which ones are public and which ones private.
Or use puppet to manage your dotfiles. lol, I'm sure some people are doing that!
Number 2 is addressed directly in the links I posted as a myth -- /bin is a terrible "minimal recovery system", it's upwards of 450 MB. You can create a small recovery partition of 5-10MB and install one of the many recovery-oriented distros there and achieve the same effect. Number 1 is irrelevant -- you'd still be able to do that under the new plan. And number 3 is dubious at best: stuff in /usr/bin depends on stuff in /lib, the two are inherently interlinked. For example if something goes wrong with libc.so in /lib, then just because /usr as a filesystem was not affected by the corruption doesn't mean the system can still soldier on. No, it will be permanently disabled until the files in /lib can be reinstalled or recovered. So it's not actually buying you any insulation, just the illusion of it. 
/sbin - statically linked binaries required to start/recover the system /bin - dynamically linked binaries required to start/recover the system /usr/sbin - system installed statically linked binaries /usr/bin/ - system installed dynamically linked binaries /usr/local/bin - binaries installed by root from non-system sources $HOME/bin - binaries installed by a user Perl belongs in /usr/bin if it was installed by the system, /usr/local/bin if installed by root, or $HOME/bin if installed by a user.
I used the Mojolicious and Catalyst. The main problem of Mojolicious is that development team knows nothing about stability. They deprecate old stable API and change it with experimental that will be changed soon. It is pain. Catalyst requires a lot of dependencies, but it has stable API. Project that has been build on Catalyst two years ago still works without any modifications. I can't say same about Mojolicious — you have to change your projects regularly if you want to use latest Mojolicious version. 
Or use a [constraint solver to generate your Puppet files](http://homepages.inf.ed.ac.uk/s0968244/docs/ModRef-2011-Talk.pdf)...
Much better :-) And it looks like the additional detail has allowed us to identify the problem - you haven't enountered the term "first world problem" before, so you didn't understand the joke. As harbud3 says, a quick visit to /r/firstworldproblems should make everything clear. [I prefer /r/fifthworldproblems, myself :-) ]
A [first world problem](http://knowyourmeme.com/memes/first-world-problems) is a problem that only people living in the [first world](http://en.wikipedia.org/wiki/First_world) (i.e. rich western countries) would consider a problem. They are trivial, but annoying, problems like: my bread rips when I try spread cold butter on it (you have bread, butter, and a method of keeping the butter cold; what the hell do you have to complain about). Likewise, this is a list of trivial, but annoying, problems related to Perl. For example, having to remember that semicolons are only optional on the last statement in a the end of block (rather than all lines). The humor serves a valid purpose in that it is funny, and it reminds us that we should not let trivial problems ruin our days (because we live in a land of plenty: Perl).
You seemed to have entirely missed my point. Yes the big banks all use Perl. Some of them may even use mod_perl2 by now though my experience was that they were *very* conservative with their technology. But yor implication is that if you want to work in Perl your only choice is to work in finance. That is patently not true. I have been a professional Perl developer for a decade. I happen to have been employed in finance for a while, but jnot exclusively. I also know quite a few people who haven't ever worked in finance. My point is that saying these half dozen companies over here use this older technology is hardly relevant unless you are offering the OP a job with one of them?
If you would of read my post I say, " This is my experience in Finance at least." Which to me means that " This is my experience in Finance at least." So I dont know why you are making some wrong assumptions of my statements. 
Just so that anyone reading doesn't get the mistaken impression that you have any clue at all: this doesn't use all that much memory (a couple megs, most of which is Unicode), and has no problem handling 30,000 requests per second in a single thread. And the point, of course, is not to reimplement redis in Perl; it's to be able to write servers that *use redis as a protocol*, as you might guess from "Redis as a protocol".
&gt; For example, having to remember that semicolons are only optional on the last statement in a the end of block (rather than all lines). Easy solution: just put semicolons *everywhere* :-) This also protects you against adding a new line to the end of a block and forgetting to semicolonize the now-penultimate line.
If there are no PAUSE credentials in your config.ini, it will look in ~/.pause
Oh, I thought it was getting confused by the qw{...}, it's confused by the hyphen?
I believe you are setting $b to the output of that regex rather than to the regex itself, and the output is "", so (pretty much?) anything will match in your if statement. You can just put your regex on the righthand side of that if statement instead of $b (why does it have to be a variable?) or else do $b = '(\d){2}\/(\d){2}\/(\d){4}'; then if ($string =~ /$b/){ Hope this helps.
OK, a couple of things you've missed, here: $b = /(\d){2}\/(\d){2}\/(\d){4}/; That's not going to assign the regexp to $b, that's going to evaluate the regexp against $_ , and assigned a boolean value to $b that indicates whether the pattern matched against $_ . You probably wanted to use "qr" (a quote-operator that returns a regexp object): $b = qr{(\d){2}/(\d){2}/(\d){4}}; Note something else I did there: I used "{" and "}" to delimit the regexp instead of "/"... this lets you avoid escaping slashes all over the place (often referred to a "leaning toothpick syndrome"). Also note that the "{" and "}" correctly balance even though they are also used for the quantifiers ("{2}", etc.). OK, next is that your string *won't actually match this regexp*, because (1) it has only 1 digit in the first group, and (2) it has three digits in the middle group. So even after you correctly assign $b, you *won't* see the message, "hello world". That said, I suspect that you just mis-typed the assignment to $string, and for what you are describing the regexp in $b should be fine. Now, lastly, if what you are doing is trying to match and manipulate dates, I would strongly recommend looking into [Date::Parse](https://metacpan.org/release/TimeDate), [Date::Manip](https://metacpan.org/release/Date-Manip) or other similar packages from CPAN. Most of the really hard work with matching, parsing and manipulating dates has already been done. Edit: Some reddit-formatting turned $_ into mark-up. Fixed.
Perlmonks.
Actually it's not going to match against $b, it will match against $_ implicitly and assign the result of that to $b. My suggestion to the OP would be the same, choose a Date package that does what you need and spend your time learning to use that properly.
Later, when he does: if ($string =~ $b) { ... } that part is matching against $b, yes.
The world is not perfect nor are CPAN modules. One of those failing tests may be critical for the system. I'd rather spend few minutes waiting for tests to finish, than hours of debugging some flipping module that can't get it's dependecies right (and this happens). OTOH, CPAN Testers matrix could be more useful in command line CPAN clients. For example I could then configure Cpanminus to not run tests if everything is ok for my platform - that would be cool. 
Should be great! See you there!
I'm going to see if I can get more devs from my company to go. We have 10 perl developers, but only 2 that go to conferences regularly. But this one is right up the road, so maybe I can convince them :)
From a developers point of view the state of Ruby in Debian/stable is terrible: * distributes slow ruby 1.8 * limited number of gems are packaged * and these libraries are seldom updated * rubygems is patched Perl isn't that much better off I guess, but for example it's easier to create debian packages from CPAN libs than from ruby gems. So there is more diversity, more frequent updates, etc. From a distributors/administrators point of view however, CPAN and rubygems introduce huge problems.
Damien "Damian" Conway? 
Nobody with the required skills cared enough to do it. The current threads for example were implemented because Microsoft paid Activestate to do it.
I could only see [this guy](http://imgur.com/fXRDj)
It's really stupidly simple stuff. You can see snippets of it in the Modern Perl book. Here's a simple one to test the accuracy of a one-liner algorithm: use Modern::Perl; use Test::More; my @foo = (1 .. 8); my @bar = reverseswap( @foo ); is $bar[0], 2, 'swapped the first one'; is $bar[1], 1, '... with the second'; is $bar[2], 4, '... and so on'; is $bar[3], 3, '... and so on'; is $bar[4], 6, '... and so on'; is $bar[5], 5, '... and so on'; is $bar[6], 8, '... and so on'; is $bar[7], 7, '... and so on'; done_testing; exit; sub reverseswap { my @array; push @array, reverse splice @_, 0, 2 while @_; return @array; } 
I vote to not run tests by default. "cpanm -n" is already in my muscle memory. For a missing dependency, users can just run another "cpanm -n" for that dependency. Yes this happens but probably not as often as we think. (Maybe 1% of the time? Since users more often than not install popular modules, which are more tested.) For other weird problems, users are f*cked anyway, since they do not know how to fix them.
Sheel be right, mate.
Yeah, this is probably some of the worst advice I've ever heard. cpantesters might inform authors of failures, but they don't always act on those failures. And more times than I can count the module dependencies have been wrong causing problems that only the test suite picked up.
You know what I'm talking "about"!
Another interesting blog aggregator is http://perlsphere.net/ For Perl 6: http://planetsix.perl.org/
and I just bought it...
appreciate it guys. Will be looking more into these, keep em coming if you find more too :)
Awesome! I love this "one-liners explained" concept. Also love that it's being distributed in the standard format of PDF. Thanks prummins! And, good luck.
I love Mojolicious, I do. I would suggest it over the others (have experience with Catalyst not with Dancer). My only complaint is that Mojo has decided to end support for Perl 5.8 which is unfortunately what RHEL5 supports. Basically, I can't update mojo any more for bug fixes, security changes, etc. And that sucks.
Picked up a copy as well; I'll have to show it to some of the other guys tonight at the Atlanta Perl Mongers meeting... http://atlanta.pm.org
Does the Rock/movie/scene have anything to do with Perl which I missed? Also, can someone mention a "crazier" object system other than Perl's blessing? 
You should post this to the emacs group on Google: http://groups.google.com/group/comp.emacs/topics?lnk 
Thanks for taking on this task. I've kept an eye on your progress and have been optimistic and excited about it. I don't use the default perl-mode, and don't know anyone who does. Can we dig up the former objections and see if they're still valid? I think that showing rms why his former reasoning no longer holds would be a great way to make progress here. I did some cursory searching, but didn't come up with anything right away. 
Wait, you got a correspondence from RMS, and he *didn't* yell at you?
Not so far :)
Wow, the cool thing is that RMS responded! Too bad emacs24 is already frozen, Debian Wheezy is even still at 23.3, so we'll be seeing this in stable+2 (more likely stable+3) at the earliest. That's so far away...
Also posted to https://groups.google.com/forum/?fromgroups#!forum/comp.lang.perl.misc To see if there are any Perl veterans there who might remember what the original concerns with perl-mode were...
It's not that each value of list gets a unique key, but the keys of the hash only count unique occurences. I've also heard it referred to as the "seen" hash.
 1 #!/usr/bin/perl 2 3 use warnings; 4 use strict; 5 6 my @l = qw(a b c a d b d f a c b); 7 my %count = (); 8 9 foreach my $key ( @l ) { 10 $count{$key}++; 11 } 12 13 foreach my $key (sort keys %count) { 14 print "$key: $count{$key}\n"; 15 } output: $ ./foo.pl a: 3 b: 3 c: 2 d: 2 f: 1 
It often helps to use Data::Dumper. Try this: use Data::Dumper; my @list = qw/a b c d d a e b a b d e f/; my %hash = map {$_ =&gt; 1} @list; print Dumper(\%hash); You will notice that there is only *one* d =&gt; 1 because a hash is not an array of some (key=&gt;value) pairs; think of it as a lookup table, that knows exactly 1 value for the key "d" -- if you make the same assignment again, nothing will change, if you assign a new value to the existing key, the old one will be overwritten. 
What's wrong with just a bunch of 'elsif' statements? That's how I would do it in Visual Basic. No, just kidding. Don't do that. You are on the right track thinking about how to use the ASCII table. If you have to make a list, remember you can do it like this: @alpha = ("a" .. "z"); That's all I got. 
-make a hash of all letters { 1 =&gt; 'a', 2 =&gt; 'b' ...} -find the key of the parameter -increment the key - look up the value 
I don't use bind so I can't really try it out myself, but a couple things... Did you try the suggestions from perlmonks? By that I mean using "in-addr.arpa" as the argument to new(), and ending $rev with a dot?
Yes, I did try these. I get NOTAUTH when I use "in-addr.arpa" to make a new Net::DNS::Update. If I use our domain name (like I do when successfully creating an "A record"), I get a SERVFAIL. Thanks for responding. 
"z" would wrap to "aa"..to wrap it back to "a": perl -le '$_=(split("",++$_))[-1], print for @ARGV'
That makes sense...I should clarify. Are you already serving reverse DNS? If so, you should have an in-addr.arpa zone configured (like 10.in-addr.arpa. or whatever). That's what you would want to use, and that's how bind would authorize you...against that zone.
Extra fun version: @uniq = do { my %h; @h{@list} = (); keys %h }
The parameter you'd want to use is whatever zone your nameserver is configured with. For example, if the IP above were 10.1.1.26, the reverse is 26.1.1.10.in-addr.arpa, so bind may be configured for any of the zones: * in-addr.arpa. (you tried this though) * 10.in-addr.arpa. * 1.10.in-addr.arpa. * 1.1.10.in-addr.arpa. Somewhere within bind's named.conf (is it your nameserver?) there should be a line defining the zone 'zone "whatever.in-addr.arpa" {' or so. That zone needs to be configured to allow updates just like the $OURDOMAIN zone is, and that's the parameter to new(). named.conf: zone "1.1.10.in-addr.arpa." { type master; ... allow-update { ... }; } If that were the case, it would be Net::DNS::Update-&gt;new("1.1.10.in-addr.arpa"). Though like I said, I'm kind of going at this blind.
Whatever one you actually have a zone (SOA) for. So if you're authoritative for 10.1.\*.\*, you'd want to specify the zone as "1.10.in-addr.arpa". I think if you use `dig` to do the reverse lookup, you can see the appropriate SOA record come back.
Yes, this is the key point. `map` returns a list, and doesn't have anything to do with hashes or de-duplication. It's the fact that you can initialize a hash from a list (and it will treat that list as a series of interleaved key/value pairs) that is doing the real work: my %h = qw/a 1 a 2 a 3 a 4/; say Dumper \%h; # $VAR1 = { # 'a' =&gt; '4' # }; Each successive key/value pair overwrites the previous one, because a hash can only have unique keys. 
Ah, good idea looking for SOA!
Depending on how you want Z to behave: $letter =~ tr/a-zA-Z/b-zaB-ZA/; Oh, and be aware that unicode will probably throw a spanner in the works. Read "man perlop"'s entry on tr// for some gotchas.
This will take a whole word as input and increment the last letter, which is good for my purposes. What it won't do is take a string like 3b and make it 3c (it returns 4). If I recall correctly, this is just a symptom of the way perl guesses if a literal is a string or a number. How do I force it to treat it as a string? EDIT: Did I confuse the term 'literal' for 'scalar'?
Your specification was a "program that takes a letter as a parameter". You didn't say a word, you said a letter. How can you expect anyone to give you an answer if you change the specification after asking? What is it *exactly* that you're looking for? 
Yes, huf answered my initial question. I'm not asking for homework help – I'm just tinkering and want to see the different ways to solve the same problem. Exactly what I want is to take an entire word with a number in the middle, and increment the last character. huf's implementation works for letters only, but behaves differently if you add a number in the middle of the word. 
Too true.
To keep things simple I would just write upload.pl, copy your FTP code into it then call system("upload.pl $filename &amp;"); from your main script. Edit: does &amp; work to async the call?
I like your description of how to use those various pieces. In this case the presentation I need to give is specifically on unit testing so I probably won't get to integration testing. I do need to address Devel::Cover.
Thank you. I will be looking at dig documentation soon... I've always just done simple 'nslookup' on the hostname or IP address, or even better, just 'getent hosts'. I'll see if I can figure this out... 
upvoted for "There's usually a reason why they did what they did."
Does it have to be FTP? You could pipe the ffmpeg output straight into SSH user@remoteserver 'cat &gt; $filename' or whatever, all in the one system call.
One of the most important things I ever figured out when debugging values with trace prints, was to stick clear delimiters around every value so you see the white-space. I use x's for some reason, but Gabor still makes a good point mentioning it, even if he uses angle brackets. /troll. ;)
Exactly! And to save yourself some headache use: [Parallel::ForkManager](http://search.cpan.org/~dlux/Parallel-ForkManager-0.7.5/ForkManager.pm)
Sometimes unprintable characters will mess up your day, or sometimes you need to care what sort of whitespace. I tend to use this when I suspect either of these: use Data::Dumper; $Data::Dumper::Useqq = 1; print Dumper($myvariable); This forces Data Dumper to use double quotes for strings, with the nice side-effect of making (most) whitespace and unprintable characters into some escape sequence. Data Dumper is also fantastic in other ways for inspecting data. Probably one of my most productive debugging tricks.
Devel::Comments is a source filter and will eventually ruin your whole day (or week) with a bug that turns out to have been created *by your debugging comments*.
I tend to prefer keeping functions with side effects out of logical statements, and instead use variables for the return values. But in this case, you could still be clever (perhaps too clever): if (!!do_thing_one() + !!do_thing_two() == 2) {...} For what it's worth, Perl 6 has a non-short-circuiting and operator, which would solve this easily and cleanly.
I tend to prefer Log::Log4perl and actually coding in useful output messages. The level of control you get with it is amazing.
I actually tend to use single quotes around the values but I thought print "'$var'"; would be a bit unreadable for the post. BTW Thanks for posting the link!
Do you have an example in mind of how it can happen?
Or slightly more compact: keys %{{ map { $_ =&gt; 1 } @list }};
Who says that loops aren't Perlish? I prefer my code to be clearer than idiomatic. There are many ways to do things in Perl. Arguing that there is one way correct way to do things is not very Perlish, it's actually more pythonistic. 
Brilliant! Thanks very much.
&gt; The moment that the speed of iterating is that much of an issue you really should be coding in C. As a general rule this is very much not so. Since many pieces of Perl code WILL be used by other pieces of Perl code small performance penalties can quickly compound and drag code down by extremes. If at that point you choose to just reimplement the whole thing in C, you've just paid a massive tax in time spent to reimplement; when compared to the effort of getting out Devel::NYTProf to find and fix low-hanging fruits. &gt; Perl 5 is not a functional programming language. It is not exclusively a functional language, but to avoid functional programming in a situation where it's at it best (that being list processing) is an unnecessary restriction in scope. &gt; Just because it's easy enough for novices to understand doesn't make it any less of a valid method. True enough. In fact, for someone learning Perl, i would actually have recommended looking at your article. However, due to one single oversight it would not be conscientious of me to do so: Your post misses out on drawing the correct conclusion of reaching for a CPAN module instead of reimplementing wheels. And a uniq function for simple string lists is very much a wheel in today's world. Lastly, noone is saying your solution is not valid. However, as you said yourself: [TIMTOA\^HWTDI doesn't mean anything goes](http://engineerofdanger.blogspot.com/2012/02/perl-is-language-that-provides-lot-of.html)
Log::Log4perl is great, but the context of the linked article is that you don't always have the luxury of working on perfect code, which is something programming courses seldom focus on. If you've got a perl app that was written by someone who left the company two years ago and doesn't have Log::Log4perl set up, and you need to fix why it's broken in the next 30 minutes before you go for the night: you don't have the luxury to refactor it do Do It Right(tm), you need to get in there with whatever tools you have to hand and figure out what's going on. Using print statements to bisect and debug a problem isn't elegant, it isn't a long-term solution, and it isn't the best possible solution, but sometimes it's the tool you have that fits the constraints you're working under. Learning to use it well, to avoid some of the common pitfalls, is more useful in that real-world context than the academic approach of saying "well don't get into that situation in the first place".
How is the example with List::MoreUtils *not* clearer?
The super-easy way would be to write the .mp4 file to a network mounted directory (like NFS), if your environment can be set up like that. How about two separate scripts? One that manages ffmpeg, and one that uploads files. Have the first script create those video files in a loop and signal the second script that a file is ready to be uploaded. There's a bunch of ways to do that signaling, probably the easiest would be to create an empty file with a file name that's similar to the target file ("$myDatetime.mp4.transfer"). The transfer script would periodically look for *.transfer files, try to upload the related *.mp4 file, and remove both files when it's done.
going to have to disagree, just using a module is not always the best idea or the most beneficial if you don't know the back end code is doing. You can still use a module incorrectly or not to its maximum benefit see alot of people just go cpan crazy. 
Now you have O(n*m) problems.
I just found PDL a month ago. It has some rough edges, but overall it's pretty slick. I mainly use PDL to make my computer overheat. \#pdl on irc.perl.org has been active lately.
How does PDL compare with SciPy?
I'm looking at using it to make various backend game calculations more efficient. Reading the book now. Seems pretty promising!
Looking through docs, they seem pretty similar. I don't know if anyone's done benchmarks.
That's a pretty big difference. lol
PDL has a more powerful vectorization engine. That makes a lot of difference if you are able to think in N-D space - you can do more powerful things in less keystrokes. PDL is, well, Perl - which is a good thing if you're a Perlie who likes concise, powerful mixes of procedural, functional, and pipeline forms. By contrast, SciPy is, well, Python -- it is more B&amp;D, so it is easier to pick up but harder to get powerful things done. As of four years ago, PDL's vectorization ("threading" in PDL-speak) engine was marginally faster than SciPy's. I haven't tested lately. The new auto-parallelization really makes it scream on a good multicore CPU. To my mind, the "killer app" for PDL is Inline::PP, which gives your scripts direct access to the underlying metalanguage (based on C) in which PDL itself is written -- that makes it very easy to drop down into gcc-compiled code for the hot spots in your vector calculation. That's a Very Good Thing since all of the vectorized languages (PDL, SciPy, Octave, or their commercial counterparts IDL and MatLab) use memory in a way that is pessimal on modern architectures: if you have a bunch of operations you want done to every element of an array, you want to make one pass through the array and do all the operations on each element -- but vectorized languages require you to make one pass through the array per fundamental operation. PDL::Inline::PP is an end-run around that limit for your script -- your ordinary script can include a custom-built primitive operation that does everything in one pass, and you don't have to jump through a lot of module-development hoops to make that happen. Python's libraries are getting good, but still can't compete with CPAN -- so there's a lot more support for ancillary libraries with PDL, since you get all the Perl goodies for free. I don't know if SciPy has yet caught up, but PDL has had disk-tied arrays, freeze/store operations, and (via CPAN) access to tied SQL objects for half a decade. 
Yes it does, I've got a number of scripts that use this.
Any idea why? Do you know what makes it different than say VBA for these uses?
Parsing already-written logs, not logging.
As far as Windows I see the 'popular' Win32::EventLog. However attempting to use it yields Win32::EventLog version 1 required--this is only version 0.076 at C:/strawberry/perl/lib/Exporter/Heavy.pm line 120. BEGIN failed--compilation aborted at 01.pl line 5. CPAN seems only to have version 0.076. Why is the compiler asking for a different version?
ah okay. i was actually running it off my testServer, which is MAMP on Mac OSX, but when i uploaded it to my real-server space (that is apache), now i get a 403 error. Here is a link: http://the-irf.com/perl-search/perlSearch.html
It seems that, between Tk, and wxPerl, and gtk2-perl, and Perl/Qt, there should be something out there to fill your GUI needs.
Either the file is not executable or your web host doesn't allow you to execute it for some other reason. Can you access the error log of the server? There it will probably be spelled out what the problem is. See e.g. http://www.hostgator.com/cgitroubleshoot.shtml for some possible problems &amp; solutions.
[Came here to say this](http://search.cpan.org/~rschupp/PAR-Packer-1.012/lib/pp.pm)! I use it occasionally. There two things that you should know about PP; Even the smallest Perl script will be a 9 meg .exe file. And the first time that you run a Perl.exe file, there will be about a 20 second "hang" time while it unpacks itself and starts up. After that, it starts much faster. 
If i can access the error log of the server, I don't know how to. I just uploaded the files using FileZilla. I set the permissions to 777 and that didn't seem to do anything different. Ill check the link out.
okay. i will contact my host provider and see if he can grant the permissions in the httpd.conf and related files. I did add this following to the .htacess file that gave me the error I mentioned in the post. AllowOverride Options AllowOverride FileInfo Options +ExecCGI AddHandler cgi-script cgi pl although that didn't seems to do anything, but i kept it.
i tried some of the link's suggestions and i am still getting a 403 error
Check with your provider, maybe you'll need to put the files in a special directory (typically named *cgi-bin*), or maybe your product doesn't allow CGI at all.
The size issue is because PAR::Packer packs a complete Perl interpreter into the .exe along with your program. The .exe size won't grow that much more with your program size. It will grow somewhat when you add in a lot of CPAN libraries. and the hang time isn't that noticeable. PAR::Packer is unpacking some libraries into windows. It shouldn't pause again when you run any other PAR::Packer executable. 
yes that is the error that i am getting. well it is my root directory. you can view my index.html file by going to it just fine. Going to the first.perl file there doesn't work however. I set the script's file permissions to 755, but i am still getting the 403 - Forbidden error.
Well your script doesn't specify the path to Perl. That may be a problem if it's not part of the PATH variable in the webserver's environment. Also, what extension does the script have on the server? I've found some that only actually run a script if it's got .cgi, so .pl or nothing wouldn't run.
i don't think so
i didn't update the post. it does have #!/usr/bin/perl now as the path its a .pl file. Should i change it or make a copy that is .cgi and try it out?
What type of a server is it (CentOS / Ubuntu / Windows / Shared Hosting?)
Unless they're running modperl it most likely needs to be in the cgi-bin in order to execute. I notice in your html file that the perl script is in the same folder. Move the .pl script to ./cgi-bin/ and update your html file. That might work. Edit: Do you have root on the machine? Can you view the Apache conf for your vhost? If so, is there anything in there about a cgi-bin? Or is there anything about cgi-bin in the main Apache conf? Look for default or your site/user name in /etc/apache2/sites-available/
indent your code with four spaces #!/usr/bin/perl print "Content-type: text/html\n\n"; print "Hello, World!"; Also, please answer [this](http://www.reddit.com/r/perl/comments/pf7xy/help_my_first_perl_script_hello_world_is_not/c3ow32l) question. But I think [hobbified](http://www.reddit.com/r/perl/comments/pf7xy/help_my_first_perl_script_hello_world_is_not/c3owcjj) is correct, you need to tell your web server that files ending in .pl need to invoke Perl; this will depend on the web server.
i tried doing four spaces, reddit still doesn't format it like code. The server is a debian-squeeze server how would i tell my web server that files ending in .pl need to invoke Perl?
debian-squeeze
Not upset, just reflecting the attitude I'd run into if I ever tried to push Perl for GUI projects :)
Try [this](http://www.cyberciti.biz/tips/lighttpd-howto-setup-cgi-bin-access-for-perl-programs.html) guide for configuring Lighttpd. I'm not too familiar with it; I wish I could give you further direction. There is a #lighttpd channel on irc.freenode.net
Yeah, Um... Why not just short-circuit all this configuration stuff, and go the 'web-2.0' way with a framework doing the heavy lifting. I like Mojolicious, because it's got embedded perl in the templating engine, which I think is intuitive. Here's the quickie install wiki page: https://github.com/kraih/mojo/wiki/Installation http://mojolicio.us/perldoc and http://mojolicio.us/perldoc/Mojolicious/Lite Here's "Hello World" under Mojolicious Lite. #!/usr/bin/env perl use Mojolicious::Lite; get '/' =&gt; sub { my $self = shift; $self-&gt;render(text =&gt; 'Hello World!'); }; app-&gt;start; Here's the cool part... You can start your app with $ ./myapp.pl daemon Server available at http://127.0.0.1:3000. and the EMBEDDED WEBSERVER makes it easy to just point your browser at 127.0.0.1:3000 and voila. 
That was it. Problem solved. You and userlame got me on the right track, and 'dig' showed me exactly what the zone was, in the "AUTHORITY SECTION". Thanks.
oh sweet! I'll look into that. thank you!!!!!!!!!
Worth a try. 
I thought it was apache, but turns out it is lightpd thank you for the help 
Yeah some others recommended that too, but you were the first :-) thank you for your help!
Creating a cgi-bin in your root dir is worth a shot or possibly one level below that. So from your public_html folder either ../cgi-bin or simply ./cgi-bin. Try both. Beyond that you would need to contact your friend and have him look at the Apache confs to see if/where user cgi-bin's are set to be at. Edit: Spelling.
First off, you should be using the 3-argument version of open() and checking that the file opened. open( my $fh, '&gt;', $outfile ) or die "Can't create $outfile: $!"; print {$fh} $output_page; close $fh; Second, you don't have to do that because Mech has a method for it. $mech-&gt;save_output( $outfile ); Also, you shouldn't have to create a cookie jar yourself. Also, you want to set -&gt;agent() BEFORE you do the first -&gt;get(). What do you get back after you do the click() to log in? You're just assuming that all the links are on that page. It looks to me that the login via -&gt;click is not working. So do a -&gt;save_output() after the -&gt;click() and see what you get back. You have to check every step of the way.
This is tricky to diagnose without knowing which page you're trying to get. Maybe you're clicking the link on the wrong page? After you `mech-&gt;click();`, the page changes. Try adding another `$mech-&gt;get($another_url);` request before you follow the link, or hard-code the URL you want instead of blindly clicking link number 18. Also, because *someone* here's going to say it, you're using the old way of opening files. Instead of using an all-caps HANDLE, you can just use a $variable, and it's considered better to separate the permissions and the filename into different arguments: open my $out, '&gt;', $outfile; print $outfile $output_page; close $outfile; I don't think that this is the source of your problem, though. Lots of Perl tutorials only teach the old way, so no slight on you for learning it that way. Hope this helps.
This, though there's no reason to set useragent - it's automated by mechanize along with cookies - and using set_fields() is more economic than an individual fields statement. Also, please use the ($handle/HANDLE, 'permission', $path) format for handling files. It's sexier and easier to read. EDIT: Setting HTTP::Cookies is fine, but arbitrary.
Firstly, Thank you very much for your response. I greatly appreciate your time. I did verify that the click() was working. But between the click and the follow_link, its as if I am logged back out.
Thank you for taking the time to look at this. I tried hard coding the link using "mech-&gt;follow_link(text =&gt; 'LINK');" When that didn't work, i tried the number thing as well in hopes that that would work... Sometimes persistence and blind luck work out. I made some changes to the way I write the file based on petdance's suggestion of "$mech-&gt;save_content($outfile);"
Thank you!
Makes sense. Thanks for the reply.
Can you tell us what site? if the logons js going to have issues as mech doesn't support it but there are work arounds, also there could be security measures in the POST with the login as well, you should look at what it sends during the log on i use https://addons.mozilla.org/en-US/firefox/addon/httpfox/?src=ss
This discussion was had months ago and yes, it's complete bullshit. The Perl they used to "teach" people was taken straight from sites like this: http://www.tizag.com/perlT/ They were testing how well people would pick a language up if people were to start from absolute zero and use the first internet search hit they got, which was that at the time.
What did they search for? Learning Perl from crap code?
They probably just googled for "perl tutorial", which back then had a Perl 4 tutorial as first hit and only crap after that. Only now that i made perl-tutorial.org there are modern materials as the first few results.
RTFM
&gt; [There are way too many issues to lsit them all here.](http://perl-tutorial.org/rejected/) Of all the places for that to happen...
Agreed. Perl isn't rocket science. I think it carries over from the fact a lot of people found it easier to use PHP on their shared server since it didn't require using the CGI bin and chmodding and they happened to find more code that was easier to copy and paste and make working. So naturally to them it mean PHP must be better.
Isn't a "Beginner Maven" an oxymoron?
There are already python and ruby implementations, and I wanted to make one in Perl. Also, the RSS feed doesn't give you some of the data, like the number of comments.
The 10th trap (line 101) is useless. I'm not sure why I used parentheses there-- perhaps it was some sort of developmental check that is no longer needed. I'll remove it.
Yes, that's true. I also thought this module might be useful in Perl-based (mojo, catalyst, not sure if anyone still uses CGI) web apps. Maybe your post ends up on HN, and you want to use the known ID to update the number of comments next to a link to the discussion on your site, or something. Ultimately it was just a proof-of-concept.
I just wish it would install on Windows.
Why in God's name *would* you want to use the RSS feed and XML::Simple? If you can treat it as abstracted away, so much the better!
for the love of pod, post a bloody example !
I have installed the software on my own server and set up an account http://24.189.205.62:1337 username: test password: p4$$w0rd123
I tried, that, I dont think Im setting the cookie correctly. I was using httpfox to see things as they were happening. I installed the software on my machine and I'm testing it out this way so I can hand out accounts to anybody that would want to help me test it out.
This is the current code I am using: #!/usr/bin/perl use strict; use WWW::Mechanize; use HTTP::Cookies; my $outfile1 = "out-test.htm"; my $outfile2 = "out2-test.htm"; my $url = "http://24.189.205.62:1337"; my $username = "test"; my $password = "p4\$\$w0rd123"; my $mech = WWW::Mechanize-&gt;new(autocheck =&gt; 1, cookie_jar =&gt;{}); $mech-&gt;agent('Mozilla/5.0 (compatible; MSIE 8.0; Windows NT 5.1)'); $mech-&gt;get($url); $mech-&gt;form_name('login'); $mech-&gt;field(frmUserName =&gt; $username); $mech-&gt;field(frmUserPass =&gt; $password); $mech-&gt;click(); $mech-&gt;save_content($outfile1); $mech-&gt;follow_link(text =&gt; 'virtual folder'); $mech-&gt;save_content($outfile2); 
You left out the link. When you add text, it becomes a self post.
Fixed. &gt;_&gt;
Modern Perl is my go-to recommendation for learning Perl. rt.cpan.org is full of bugs in CPAN modules you could try to bite into once you get more comfortable (see also github). There are maintainers that'd be happy to help you along writing your first patch. I'd also recommend using Perl in your day job - it's a great tool for system administration. You could pick up a copy of Automating System Administration With Perl if you want a focused resource on that.
If you are a sysadmin, you will probably like the book [Perl Hacks](http://azurl.net/0596526741).
Also hanging out on irc.freenode.net#perl can be helpful.
I highly recommend "Higher Order Perl" by Dominus. It dominates. 
&gt; Any advice on how to handle encountering so many new concepts at once? The book really should mention this, but I learned from writing a bunch of very small test programs to show how each feature worked. This was before the days of `Test::More`, so it'll be easier for you. Write a test testing what you expect to happen, then write code to make it happen. The smaller the scope of the test, the easier you'll learn.
I love the book, really. But isn't it a little too advanced for a beginner ?
You also don't mention what it does, or why I'd be interested other than "it contains Perl!" and it's "something a friend of mine and I created". No, I'm not going to click on the link on the off chance it's going to be anything useful to me. And that's assuming you've done a better job, on the other side of that link, of saying what it is and what it can do for me.
Just now checked this, tried to work on it but looks like you took the test server down. 
IMHO, Bash... a few steps, and you are doing Perl.
Description added.
hehe no problem, i generally don't do any coding at home and now im at work, but ill take a look tonight if you can get it setup :)
I'll def get it set up. I really appreciate your time and help!
Random tips: - In your `die`, include `$!` to show the reason for the failure. Or use autodie. - If you don't need the whole file in memory, it's usually better to process it as you read it. It's certainly less code: `for my $line (&lt;FILE&gt;) { ...` - The two-argument form of `open` and use of bare filehandles is deprecated. Use the three argument form and lexical filehandles. - You don't have to do things like this: `$line=$line . $cfg; unlink($line);`. Just write `unlink($line . $cfg);` if you don't need the value after that. - It's probably slightly more idiomatic to write `if(!unlink(...))`. 
I just did a project in mojolicious, and I really liked the embedded perl in the templating engine. Basically, you pass a reference to a hash or whatever into the templating engine, and you can loop around your data building tables and stuff.
Updated the code to reflect your points. I *think* I understood them all. Let me know if there are additional changes that should be made.
&gt; Is that correct? No, you just put autodie next to strict/warnings. That's the point, you only have to say it once instead of per statement. &gt; What would be a more advantageous usage? Perhaps a script with several check-able functions? It won't make much of a difference here, but if you have a large piece of code interacting with the OS in multiple ways (I/O, commands), you really don't want continue-on-failure being the default. Having every failed OS interaction stop the script means it only keeps going when you've prepared it to handle errors correctly.
Thanks.
Is it set up correctly now? If not, could you please repost the code with the correct usage?
You can replace eval{ open(my $file, "&lt;", "ghosts.csv"); } with just open(my $file, "&lt;", "ghosts.csv"); The eval catches errors, but you want to die on error in this case: there's no point in reading a file that you can't open. It's probably good practice to leave in the `close($file)`, but you don't really need it for a script this short: `$file` will be closed on exit.
even better, use the Try::Tiny module instead of eval {}
-v, please
I want to apologize for reading into your statements then. I still think you were overly general in your initial comments and that your advice to learn mod_perl2 simply isn't relevant for most of the jobs he'll find in the current Perl job market. But that doesn't mean that I should have assigned malice or any other intent to your statements.
Wait, so which one is faster and has better quality?
Just so you know, its up and running now. http://24.189.205.62:1337 username: test password: p4$$w0rd123
As an advocate of functional programming, I have to say that there is really no good reason to write this particular program in a functional style. Using "map" is only substantially different from using "foreach" if you want to collect the results of all the iterations into a list, which is not needed here.
I happen to like mojolicious. It's easy to get started with, but powerful enough to grow to your needs. My experiences with catalyst was worse, I had to to know about way too many different places, concepts and namespaces for tweaking very basic stuff.
You asking for Catalyst version? We use perl 5.12 with whatever version we can grab off cpan :)
Yeah. Moose is the only object system I've seen that works after the fact. "Oh hey, let me add Moose to this library..." Just need to know a little bit about what functions are worth using before/after hooks.
I want to know something about the code quality and coding time between the 2 frameworks. But you answered it below... Thx.
Anybody has heard of Jifty?
&gt; What's the reason to use eval{}or do{} vs a foreach? No, no, they do completely different things. You put it **inside** the foreach in place of the if/else. `perldoc -f eval`
That's exactly what it does.
Dude, don't troll the poor newbie.
Do you know how I can find the version of Perl a machine is running in terminal?
 [mike@orion ~]$ perl --version This is perl 5, version 14, subversion 2 (v5.14.2) built for i386-linux-thread-multi Copyright 1987-2011, Larry Wall Perl may be copied only under the terms of either the Artistic License or the GNU General Public License, which may be found in the Perl 5 source kit. Complete documentation for Perl, including FAQ lists, should be found on this system using "man perl" or "perldoc perl". If you have access to the Internet, point your browser at http://www.perl.org/, the Perl Home Page. 
Thirded. Throw in CGI::Application::PSGI, and you get a big win for testing.
Have'nt had the same experience. We have camps, too, but we've standardized on CGI::Application since it hides just a enough to let you focus on modular development.
&gt;If you don't need the whole file in memory, it's usually better to process it as you read it. It's certainly less code: for my $line (&lt;FILE&gt;) { ... Actually, you're still reading the whole file into memory there, because `for` imposes list context on the &lt;&gt; operator, which makes it return all the lines before processing actually starts. To only read one line at a time, he would have to use a `while` loop (which imposes scalar context): `while (my $line = &lt;$file_handle&gt;) { ... `
Ah okay. I swore I read it in the llama book, but I couldn't find it thiis morning. Thank you!
For catalyst or for cgi::application. Which turn around time and code quality is better?
I would fourthed this, but What about all the catalyst is better than cgi::application above?
Hmmm sounds interesting. Ill check it out.
Nope
It's quite a nifty looking web framework: http://jifty.org Here is an 2006 article from OnLamp: http://www.oreillynet.com/onlamp/blog/2006/08/hey_thats_pretty_jifty_er_nift.html
Mason, the next gen HTML::Mason, is out now too.
Like it mainly because it was what appeared to be a cleaner attempt at "perl on rails". Keep in mind I learned in 4 years ago. Honestly? It appears that mojolicious will be the way forward. It's good in that it gives you a default template and a structure to work with right out of the gate, again, much like ruby on rails. It is very object-oriented and there's a pretty clear "right" way to do things. What's bad is that after all of this time - it still isn't very mature and there aren't many devs working on it. I had to write my own LDAP auth backends, and never got back to it to write it in SSL. Worse, it didn't use any kind of caching, so for every page load, it tried to re-bind you to the LDAP backend. Couldn't decide on a better way to handle it, so there you are. Needs more work. I think mojo is your best bet.
Cheers. Have fixed.
Nifty jifty, yipee.
Boy, with all of these downboats, someone doesn't like C::A! LMAO.
hmm okay. i am relatively new to Perl as well. Ill look into Catalyst now too. Thank you. Also, please keep me updated on the web app-- sounds interesting!
i have heard dancer is good to use for small apps. what do you like about it?
kk thank you
Okay so far, Catalyst, Mojolicious, Mason / HTML::Mason, and possibly jifty or dancer have peaked my attention. Ill look into them. Any others or reasons why I should/shouldn't use these?
Assuming you are on a Unix/Linux system: Most unix commands have help option. Either `--help` or `-h` (sometimes `-?`). That would be my first stop to find out what a command/tool offers. The `perl` command is no exception: $ perl --help Usage: perl [switches] [--] [programfile] [arguments] ... -v print version, subversion (includes VERY IMPORTANT perl info) 
Can you give an example of an address that has the conditions you need to check for? Just trying the code against google.com seems like it already works: ./hoho.p google.com The results are the same: $results = { '208.67.220.220' =&gt; '74.125.65.100, 74.125.65.101, 74.125.65.102, 74.125.65.113, 74.125.65.138, 74.125.65.139', '8.8.4.4' =&gt; '74.125.65.100, 74.125.65.101, 74.125.65.102, 74.125.65.113, 74.125.65.138, 74.125.65.139', '8.8.8.8' =&gt; '74.125.65.100, 74.125.65.101, 74.125.65.102, 74.125.65.113, 74.125.65.138, 74.125.65.139' }; 
In terms of popularity, any of Catalyst, Mojolicious, or Dancer is a fine choice. The others are also good choices, but probably less popular.
Odd - for any hosts, such as google.com, that have several IP addresses, I receive this error for every dns queried. *** WARNING!!! The program has attempted to call the method *** "address" for the following RR object: *** *** www.google.com. 86399 IN CNAME www.l.google.com. *** *** This object does not have a method "address". THIS IS A BUG *** IN THE CALLING SOFTWARE, which has incorrectly assumed that *** the object would be of a particular type. The calling *** software should check the type of each RR object before *** calling any of its methods. *** *** Net::DNS has returned undef to the caller. I'm fairly new to Perl - why would this be happening? why doesn't the resolver object I made have an address method? It seems likely that there's a difference in our machines/installations, which might be the problem here. I'm running perl version 5.14.2, and my Net::DNS module is up to date.
HTML::Mason is like PHP - you can mix Perl and HTML seamlessly to create web pages. I love it, but it has issues with sharing variables between components. I currently use a %GLOBAL hash to hold whatever I want to share. All global variables need to be declared in handler.pl directly, which requires an Apache restart to update.
It is also further complicated by the generally crappy module availability on many hosted environments.
I noticed when I first came here there were a slew of answers that had been "downboated" for no real reason at all? And now my answer which provided two Jifty links also incurred the "downboat" wrath :(
Why better ? Just different. C::A is a much simpler framework, just look at the dependencies of the packages. Catalyst is a more complete, and complex solution. But is assume for example that you are going to use Moose.
HTML::Mason: http://www.masonhq.com/ http://search.cpan.org/~drolsky/HTML-Mason-1.48/lib/HTML/Mason.pm Mason: http://search.cpan.org/~jswartz/Mason-2.15/lib/Mason.pm 
Go look at some of the code: http://perldancer.org/
This makes much more sense that what I've scripted with my limited knowledge. How would I go about having the script take two arguments? The first being the location of the .csv and the second being the directory to operate on.
I don't know anything about BioPerl (when does the fasta file get used?), but: * obligatory exhortation to use **strict** and **warnings** * why put "something horribly wrong has happened\n"; when you could put "something horribly wrong has happened: $!\n"; and get some information about the horrible thing.
As others have said: * _use strict;_ and _use warnings;_ are your friends. They will break your code whenever you do something really bad. That's the point. The general rule of thumb is "always 'use strict;' unless you can convince freenode/#perl not using it is ok." * I know your probably read an example or tutorial or a book that said using the form of _open_ you're using is ok. For various reasons I won't bother with, use the three-arg form: _open my $genes1, "&lt;", $ingenes1 or die $!;_ -- at the very least, now you don't have global file handles littering your code. On to design! I would create a hash. Call it %genes. It should have a few keys, relevant to your data: $genes{$id} = { id =&gt; $id, chromosome =&gt; $chromosome, file1 =&gt; [ $start1, $stop1 ], file2 =&gt; [ $start2, $stop2 ], strand =&gt; $strand }; Iterate through both files and populate this single hash. Once you're done, you can look at each key in `keys %genes`: for my $gene_id ( keys %genes ) { my $first = $genes{$gene_id}-&gt;{file1}; my $second = $genes{$gene_id}-&gt;{file2}; # Do some testing } In the comment, you've two array refs, `$first` and `$second` that point to the start and stop locations of the id. Get to them like `my $first_start = $first-&gt;[0]` and so forth. 
That will suck much more if a critical security issue will be found in Mojolicious.
BioPerl has a GFF parser ([Bio::Tools::GFF](https://metacpan.org/module/Bio::Tools::GFF)), why don't you use that instead of hand-rolling something yourself? GFF is more complicated than just splitting on strings, see the specs ([version 2](http://www.sanger.ac.uk/resources/software/gff/spec.html), [version 3](http://www.sequenceontology.org/gff3.shtml)).
Just remembered that I have a script for that, or at least something similar. There are some methods in my library that I put into the bottom of the pastie for a reference, so you'll have to edit some. http://pastie.org/3408274 But still, you should go to /r/bioinformatics.
Calling CGI::Application an MVC framework is quite a stretch. CGI::Application can be written in an MVC manner, but alone it is basically just a fancy dispatcher.
flankbed - fantastic! Thanks!
&gt; That's a very good question. How long is a piece of string? While passing test counts definitely [don't tell the whole story](http://perlgeek.de/blog-en/perl-6/when-we-reach-100-percent-we-did-something-wrong.html), I don't think it's completely right to dismiss the significance of passing 20k tests either. Each new passing test means we're closer in some sense to the spec, or exhibiting one less bug. &gt; Note that the spec had almost 20,000 tests just over four years ago That's an interesting data point. Note also, however, that we didn't *pass* nearly as many tests four years ago.
This looks very handy. Thanks for the link. Will be testing it at work as soon as tomorrow.
Following your link I tried it out but I've got to say I'm not a fan of this site, it's a bit 'monkey see, monkey do' without any of explanations. Also it doesn't pick up on syntax errors correctly (errors is perhaps an unfair usage, I only tried dropping the final ; which it didn't pick up on - a basic error in the coding of the site and one I've seen elsewhere. Sorry but I can't recommend it.
Not really, this was written at least in part because Ubic is utterly unsuitable for these purposes. Because Ubic is Not Designed For That. It requires buy-in to the Ubic way of doing things, it doesn't generate LSB-compliant init scripts, and it's basically a replacement for init scripts as service management whereas this is a means to write init scripts for your existing perl code. I spent a couple of hours discussing this with the Ubic author; he's building a very nice piece of software for the use cases he has - which at this point doesn't actually involve init scripts at all, since his colleagues have moved to using ubic directly to start/stop services and ignoring the underlying OS' service management. I also helped out with Daemon::Control somewhat, because Daemon::Control is well on the way to being a very nice piece of software for the rather different use cases that I have, which generally involve heterogenous solutions where collaborating with the underlying OS' service management is essential.
Some good tutorials: * http://perl-tutorial.org/ * http://www.perl.com/pub/2008/04/23/a-beginners-introduction-to-perl-510.html 
ah okay. that makes much better and more sense. thank you!
The reason for the error will be listed in the server's error log. That's the first place you should look.
oh okay. its right there. im sorry. Here is what the error log says: [Mon Feb 20 21:48:43 2012] [error] [client 127.0.0.1] malformed header from script. Bad header=Hello, world! : helloWorld.pl So if it is a bad header, what type of header should it be?
I know it's 1000+ pages, but the price is a bit steep. But I hope for the best to the authors. Their _decades_ of dedication deserves it.
haha. there apparently was a great shirt with the raptor, but the sop doesn't work.
http://platosakademeia.com/ will be going online and into beta phase in the next week. The first lessons on it are in Perl.
If you say so!
So I broke down and bought [Programming Perl 4th Edition](http://shop.oreilly.com/product/9780596004927.do?green=019E302B-6811-59F9-A1F7-2311E42C2039&amp;cmp=af-mybuy-9780596004927.IP). $20 was a reasonable price and its very well written. Easy to understand. I already feel like I've learned a lot even though I've only gone throught the first 40 pages or so. Thanks to everyone for suggestions and advice!
oh okay. that makes sense. thank you for explaining. :-)
System administration, automation, log parsing.
I guess this was the original intent of local? sub FOO { local($x, $y, $z) = @_; # name formal parms local($i, $j, $k); # push locals ... } 
I don't use perl, I use python. *trollface
Ha yea I love that line
Exactly what I use it for. Although I create smallish web applications (Mojolicious) with it for internal team stuff too.
Read almost all of Larry's post, saw the perl 2.0 beta link, saw the post date...you win this round, OP...
We use Perl for server administration development nowadays (daemons, scripts that run via cron &amp; command line, control panel software, etc). Many of our web front-ends are in PHP, but that's just temporary. I hate PHP and will replace it with Perl as we see fit. 
The t-shirt was a limited edition and is no longer available.
Well, this is horribly sad. :(
Me too, what lab?
There were no lexicals at the time, just one big global stash. So if you wanted to avoid having a routine trample all over another routine's variables, you either made sure to use distinct names everywhere (like writing old-school BASIC) or you localized, so that you could use whatever names you wanted, knowing that any damage you did would be undone by the time you returned.
Automation scripts, many of which involve file processing.
Most recently, to post-process Raman spectrographic signatures.
Test automation 
Just make the shebang #!/usr/bin/env perl Now you can manage which perl is run by modifying `PATH`. If you put your custom perl first in the `PATH` it will be used, otherwise the system perl will be used. As to perlbrew, it has countless advantages over DIY. It can automatically do everything with one command (download, build, test, install.) It can manage multiple versions installed at once. It can automatically manage your `PATH` so that you can switch between those multiple versions at will, dynamically, without hassle, just by issuing `perlbrew switch`. Edit: as to number 1, there are a number of reasons why you should not even consider attempting that. The system perl is used by many scripts for administrative tasks, and you don't want to be responsible for testing all of them. But more importantly, the package manager "owns" everything in /usr/bin and /bin, you do not. When you modify things that you don't own, you create trouble. For example, the next time the system perl package is updated, it will overwrite all of your changes. And by installing a different version of the perl shared library in /usr/lib, you're probably going to break all the compiled XS modules on the system. Normally the package manager handles this, but when you go behind its back it can't help you. That means that many modules would be broken, and those admin scripts that depend on those modules would therefore also be broken, resulting in a system that might fail to boot or fail to let you log in or fail to activate hardware devices or fail in other numerous strange and infuriating ways. 
Far as I can tell, only five commenters went and read the article. I expected to see Larry and tchrist in that thread, but didn't realize Johan Vromans and Chip Salzenberg went that far back.
Perl, not PERL.
I use perl for quick and dirty sys admin stuff, usually for data munging. Even though our outfit is a "Python, C++, or Bash" outfit only, I still don't give up my perl scripts ;)
You mean, like Text::Table? I like it because it's easy to use, and usually does what I want.
Could use it as a starting point for learning about pack/unpack :)
Or once you get past the initial overhead of writing some nice generic XML templates and a suitable datastructure, I love Excel::Template for this. And hate it, with a passion, of course...
PDF::API2 and PDF::Table
Haha I had kind of a missed opportunity there. Maybe should have reworked the title
For me, I'm just frustrated that people didn't click the link and read, but merely answered the headline. It says to me that those people are more interested in talking than listening.
I wouldnt get too frustrated about that. Human nature etc.
THANKS! This looks good. I got it running and have some good output. Just tweaking now. 
Oh I like that - thanks 
Thanks!
Thanks!
From the error messages im receiving im assuming Perl treats constants as functions right?
Yeah. use constant PI =&gt; 3.14; is almost entirely equivalent to sub PI () { 3.14 } (the parentheses are an empty prototype, which means that no arguments are expected after the name of the function, and the function's return value is allowed to be "constant folded" at compile time. Using prototypes on your functions is *not* usually recommended unless you have a very specific reason.)
Not in a way that does what you want without side effects that you probably *don't* want. If you're paranoid, you can do something like `die "Invalid number of arguments" unless @_ == 3;` but that's not very common either.
yea using a constant confused me. not having to use the sigil in the second line of code confused me a bit as well. The only reason I like using a constant is that it really only functions as a lookup table so I might as well make it a constant.
Its just a different concept after coming from programming C# and Java. It seems much more useful to me though.
No problemo! In your first line of code, COLSTRING was being defined as an arrayref containing a bunch of hashrefs which I didn't think was your desired data structure. Then, in the second line of code you were referencing a hash element contained within COLSTRING, but no hash elements existed directly within COLSTRING (because it was defined as an arrayref). Does that help?
&gt; basically i created an array of references that contained refrences to hashes? Exactly. You've got it. &gt; And second when I was referencing the hash element nothing was there but references so it error-ed out correct? I believe so. &gt; Is there anyway to reference the hash references which where in my array reference haha? Haha, yeah, but it'd be a huge waste of resources... You could reference them (assuming your original COLSTRING definition) as COLSTRING-&gt;[$n]-&gt;{$cc}, but you would have to loop over the entire COLSTRING arrayref for each lookup, so I'd highly recommend against doing it that way. ;-) 
I just registered perlacademy.com to start a tutorial site. Any ideas?
It's the backbone of DBIx::Class, so I use it often. I do question my use of ORMs, but given you want one, SQL::Abstract does it's part well. I also second jawnsy recommendation of SQL::Translator. It makes schema diffs and updates a breeze. 
Yes and no. It makes simple queries easy and Perl-ish, but it really breaks down when you want to do anything complex. You then have to map it out in your head how to convert a query into a hash of data that will be translated properly back to the SQL statement in your head. Don't misunderstand me, for a lot of things, it's great, I just get annoyed when I look at the reference to an array reference syntax they chose for complex subqueries. I also find myself far too often having to pass raw SQL into it to accomplish what I need.
I test embedded firmware with it, mainly settings values etc... just regex stuff.
See I didnt know that. I figured that marking as constant would sorta be making it read only. So since its a constant href it doesnt matter if what its referencing changes as long as there is something there to reference?
awesome thanks!
On a related note: there's Perl6::Form, which is an much better version of said functions.
Perl was never an OOP language to begin with, but that never stopped Python or C++ ;-) Objects are often useful when you want to be able to parcel some state up with its own identity. For example, a severity-based logger can easily be represented as functions, but what about when you want more than one in the same program? Sure, you can go pure(-ish) functional with closures, but then you end up with a roughly similar thing: state hidden up behind an opaque reference. I often use the IO::Select module for network programming. One instance each for readers and writers, handed into a call to IO::Select::select. This case is actually kind of weird: you create explicit objects with 'IO::Select-&gt;new()', but then hand them over to a function defined in the same package. Perl 5 is not particularly married to object orientation, and the attitude I've encountered so far is that there's no need to write code that conforms to a strict interpretation of it. As mfontani says, it depends on the size and scope of your project; the existing coding style for the project; and what, if any, reusable components you want to extract from it.
I know you said without Moose, but use Moose!
I use Perl 5 OOP when I think that it is effective. Case in point: I used Class::Factory to register a bunch of handlers for application defined types in an XML stream. The idea was to make it easy for a new handler for a new type to be added by someone who is (1) technically aware but (2) not necessarily a programmer (ie. a sysadmin, for instance, or even a receptionist). 
&gt;Perl 5 is not particularly married to object orientation, and the attitude I've encountered so far is that there's no need to write code that conforms to a strict interpretation of it. That is correct, and quite relevant. Java forces the programmer into an OO framework, with as a result that when that is too restrictive, they come up with all kinds of "patterns" to work their way out of the corner they painted themselves into. For example, there's no need in Perl, if you call `new` on one class, that the object you get back must really be of that class. You could just as well get an object back of a different class, for example depending on the value of some parameters. "Factory"? In Perl that is very straightforward.
CGI::Application, Template::Toolkit and DBI::Class. Recently converted to Plack/PSGI really easily to run on dotcloud. KISS.
A detail I opted out of, on the theory that the OP would discover this shortly and come to the realization that doing inheritance with 'raw' perl OO is silly.
Read [`perlreftut`](http://perldoc.perl.org/perlreftut.html) then ask about specific questions. Check [`perlref`](http://perldoc.perl.org/perlref.html) for the details. You can read the [2010 version of Modern Perl at perl-begin.org](http://perl-begin.org/tutorials/modern-perl/) while we wait for the new 2012 edition to be made available on onyxneon.com. (BTW, I agree that it was somewhat questionable to remove the electronic version of the 2010 edition from the publisher page because it makes it a lot harder to find in google results.) 
Think of something you do every day, and find a way to stop doing it.
Perhaps 'silly' was a poor word choice? 'Bad', 'Frustrating', or 'Opaque' might be better. The point that, of the choices available for perl 5, futzing with @ISA is usually the worse choice.
This is the best way to do it.
if you want entertainment, write a game :) for example, here's a curses version of tetris: https://github.com/jdeb/tetris-curses
Full agreement.
&gt; I agree that it was somewhat questionable to remove the electronic version of the 2010 edition from the publisher page because it makes it a lot harder to find in google results. I know; I'll put PDFs up tomorrow.
Isn't it illegal to download videos from Hulu?
now you know...
What ffffruit said. This is illegal. As of the DMCA (or was this a piece of the Patriot Act? I keep forgetting), any intentional circumventing of DRM is bad mojo. Since they're using Flash as their sole deployment medium, it seems likely they're trying to prevent you from copying it for permanent personal use.
I doubt that simply using Flash counts as DRM. However, the Hulu video streams are encrypted so that certainly does.
Wow, I didn't know that it was easy to download from Hulu. I thought there was a constant arms-race to prevent noncommercial set-top boxes (eg. XBMC, Boxee, Orb) from using Hulu. This is especially true if they're trying to bypass the licensing restrictions on so-called "TV-connected devices" [[1]](http://www.techdirt.com/articles/20100215/0234358166.shtml) [[2]](http://support.google.com/youtube/bin/answer.py?hl=en&amp;answer=1701426) (ie. get normal Hulu to show up on a normal TV) Awesome, it looks like it should work. I'll take a look tonight.
That site is great!
Before asking for crowd-sourced help, it would be nice to know what the payoff is -- why do we want `Test::Builder2`? What does the replacement bring? Why is all this effort being spent on it? How is it better? Why should I care? 
Use perl to eliminate seeing problems from day to day.
Thanks! I'm enjoying it so far. Is there any chance of a PDF Table of Contents? edit: the online version is updated now. Thanks chromatic!
Thanks! I've been checking every few days!
Mine has a TOC. Do you mean a more detailed one? Also, I like how the TOC and the page #s in the index link to the correct pages. Very nice!
The next major release of Perl includes major revisions of the existing OO docs. You can read them now. * [Perl OO Tutorial](https://metacpan.org/module/CORION/perl-5.15.8/pod/perlootut.pod) * [Perl Object Reference](https://metacpan.org/module/CORION/perl-5.15.8/pod/perlobj.pod)
Thank you very much for your continued contributions.
Yeah, that uses a feature called PDF bookmarks. I had to remove that for the printed version (and I removed the detailed Table of Contents in the printed version), but I'd like to enable it again in the electronic versions. It's on my todo list.
&gt; I like how the TOC and the page #s in the index link to the correct pages. Very nice! Thank LaTeX for that.
Run 'perldoc perlre' or read it on the internet: http://perldoc.perl.org/perlre.html A quick read through it will answer your question.
 If you want to keep everything after Monitoring try: $content =~ s/(.*?)Monitoring/Monitoring/;
Tho really - If you're going to scape an html document for text, you might as well treat like it's an html document. Load $content into an xml parser and get the text elements you want using something like XML::LibXML or at least XML::Simple. Another route would be to figure out what is generating the data you wish to scrape and go straight to the source.
You could use a positive look-ahead, just to be really clean about it $content =~ s/.*?(?=Monitoring)//s;
Thanks HHI - made my head spin a bit, but helped nonetheless!
Please call it something else besides Test::Builder2. Module names with a 2 stuck at the end remind me too much of some hideous legacy code I've had to clean up where appending a number was how they did 'version control'.
Ooh, that looks like a technique I need have in my toolbox. Thank you!
Oooh, that's good to know! Thanks! Duplication is good in an index of a reference book, IMHO. Sometimes you just want to grab a book because you vaguely remember a neat trick with the *blarf* function...
[This link](http://www.perlmonks.org/?node_id=490846) should prove helpful. but more or less use XML::LibXML; my $parser = XML::LibXML-&gt;new(); my $doc = $parser-&gt;parse_file($filename); foreach my $row ( $parser-&gt;findnodes('/path/to/tbody/tr') ) { my @cols = (); foreach my $c ( $row-&gt;findnodes('td') ) { push @cols, $c-&gt;to_literal; } # now @cols is each &lt;td&gt; and this foreach goes through each &lt;tr&gt; in a table. } 
Thanks, it's even better now
Thanks JS, especially for the link =D
(Apologies in advance for the wall of text.) Firstly, here are your lines with some corrections: $content =~ s/.*?(Monitoring)/$1/s; # Note A $content =~ s/Shared.*\z//s; # Note B A: In line one, you have parentheses around the .* that matches all text up to "Monitoring". This captures that text and stores it in $1. As you are not using the $1 in the subsequent clause of the s///, they are doing nothing there. However, if you put them around "Monitoring", then you can use $1 to put Monitoring back into the content string, as you are already doing with a literal "Monitoring". Second: I added ? after the .* before the "(Monitoring)". This makes the * less greedy; it will match as few characters as possible before "Monitoring". In this case I think it actually doesn't affect the behavior of the regex, but if it were more complicated, it could have an effect. At any rate, it's more explicit about what you are grabbing, which I always think it good. B: You again have parentheses in this line that capture text that you do not use. Note also that you've put the endline assertion inside the parentheses. I think you probably should not do this. The endline assertion is just that, an assertion, and does not match any characters, so there's no point in putting it into capturing parentheses. Second, I believe the endline assertion should not be $, which will match the end of the *line* (that is, is valid right before an endline character), as you are using the /s switch, but rather \z, which will match the end of the *string*, which I'm guessing is what you want. Okay, those are my suggestions for just changing what you have. But you asked if there are easier/more elegant ways to do it. I can think of a couple different ways; whether they are easier or more elegent is for you to decide. The first is just to combine the lines as you have them: $content =~ s/\A.*?(Monitoring.*)Shared.*\z/$1/s; What this does (in theory, I haven't tested it) is it matches everything from the start of the *string*, with the \A assertion, up to the word "Monitoring"; the parentheses around "Monitoring" capture it and all the characters up to the word "Shared"; after the close of the parentheses, all text from "Shared" is matched to the end of the *string*, with the \z assertion. Because the entire string is matched in the s///, and only the "Monitoring.*" section is captured, you are replacing the entire string with the section you captured, with the $1. Something else, in case you haven't thought of it, is you might use the /i switch, in case you have to match "monitoring" or some other combination of cases. The second way to do it is: $snip = ( $content =~ m|(Monitoring.*)Shared|s )[ 0 ]; Here, rather than replacing a part of the string, you are just matching the part you want, extracting it and putting it into another variable. First, there's the match clause inside the parentheses. Note that I'm not matching the entire line here, just the first "Monitoring". Note that there are again parentheses around "Monitoring.* "; this captures "Monitoring" and everything after it up to "Shared". Now, when you put a match clause like this, one that does capturing, into parentheses, what that does is it puts it in *list context* and all the captures from the string become the members of the list. It's like an array. Then what you can do is put an array dereference after the parentheses. In this case you have [ 0 ], which means the first list member. The list generated by the matching will have at most a single member, which is the match of "Monitoring.*". The dereference means get that member; and it is stored in $snip. You could also do $content = ( $content =~ m|(Monitoring.*?)Shared|s )[ 0 ]; if you don't want to create another variable. HTH.
Brilliant! Thanks. Checked the Amazon.com page and got this: &gt;8 new from $29.24 **3 used from $76.22** Screw pork bellies and the works of Van Gogh -I should buy a few thousand of these as an investment... 
Huh? That's the worst stackoverflow page I've ever seen linked to on reddit. You sure you got the right one? Also, yes. Perl is certainly in the minority, by a large margin, when it comes to coding things that generate stuff that is displayed in browsers. PHP, .NET, Java all blow everything else out of the water.
According to daxim in #perl-help on the Perl IRC server: `perl -mIO::Socket::SSL -mNet::SSLeay -E'my $client = IO::Socket::SSL-&gt;new("encrypted.google.com:https") or die IO::Socket::SSL::errstr; print Net::SSLeay::PEM_get_string_X509($client-&gt;peer_certificate)'`
Why isn't octal notation first deprecated (say, output a warning on octal constants under -w) and then eventually pulled out from perl? In the rare case you need it (UNIX permissions), you could write a simple function to construct the value from 3 arguments.
&gt; Why isn't octal notation first deprecated... It's been there as long as I remember. You break a lot of stuff by removing it.
&gt; Why are the numbers invalid exactly? The leading zero means Perl interprets them as octal numbers--base eight instead of base ten. That means that 020 becomes 16 and 080 is invalid, because there's no digit 8 in octal. &gt; And why is the obvious solution not just to change the numbers into strings... That's the right thing. You have to quote them explicitly.
Has it been removed from perl6 then?
ahh thank you. That makes it very clear.
I'm not making any comment on Perl's applicability towards web app development (though I think it's not great), and I'll readily admit that there are a decent number of Perl web applications deployed, but those numbers are dwarfed by PHP and .NET.
Let me put it like this: {{Citation needed}}
Not me, daxim. :) You can also find him on stackoverflow and give him some upvotes there if you wish.
Microarray files are really big. Like 32000+ lines with dozens of columns big. I use an SQL (MySQL or SQLite) database to store the files and then run SQL queries with Perl to parse the results into "report" type text files. The "queries" you are running with your Perl script should not take too long with SQL. 
My guess is that your data set is too large for the system's memory. This causes the system to start swapping which is always a bad idea. A better plan might be to recast the array work in terms of direct file IO. using MLDBM from CPAN might be one way to approach that.
SQL is a bit beyond my capabilities for the moment, but I'll keep that in mind for the future. Thanks for looking through it for me!
Honestly, I don't think SQL is necessary at all for this. The overhead of loading the data into memory can't be all that much. Do you have a sample data file that you could put on pastebin? I'd be happy to take a look at it, but running a program over data is usually the fastest way to identify a bottleneck.