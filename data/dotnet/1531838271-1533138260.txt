Razor can be a part of MVC. It is for the most part just the display part of the MVC. In asp net core razor uses MVC. Not sure about normal net.
Just for the record, if I am asking the wrong community could you please share some info where I sohuld ask? Whenever I ask questions of this nature on stackoverflow I get downvoted to oblivion with the excuse "we have discussed c# vs java 1000 times here already", even tough this question now is more relevant than ever I feel, that was not even the question itself.
I've worked on sizeable systems (&gt; 100,000 loc) in both languages. Here's my take on the topic. I'm not going to win any friends with this: the two languages are, honestly, very similar to each other. Couple differences here and there but it's pretty much balanced in the end. Generics are better in .NET, the JVM historically had the upper hand for JIT performance, etc. As far as programming languages go they're pretty much cousins. There's a bit more diversity on the tooling. A couple years ago Java had the upper hand on tooling, much more diverse for all kind scenarios. However with how things are going now with .NET Core it's more nuanced. The lack of cross-platform has been a major showstopper for adoption and now it's gone, making it a decent alternative to java for most scenarios. So again, both platforms are solid, have large user base and a huge number of libraries. Overall, both would work perfectly fine for most kind of system. In the end, perhaps the choice boils down to how easy it is to hire for either platform in your area.
Thanks for the response. Regards to "hiring", I belive here is pretty balanced, my primary issue is that majority of youngsters whom I usually like to work with are more prone to C#/.net rather than Java. Either way, what is your experience with Entity Framework+LINQ combo, is it really superior to Spring-based solutions like HQL/Hibernate/JDBCtemplate? Also Java has this annoying serilaization, JDO ORM object conversion inconviniece instead of just working with a single JSON like JavaScript, is the implementation similar to C#/.net in this regard? Cause that seems like a giant mess for nothing good for me. And about this: " you can use Open JDK instead of the Oracle runtime. " &lt;- I was given this advice before, but there must be a reason every single business I ahve ever encountered used Oracle JDK over Open JDK. Maybe lack of support for the former?
Thanks a ton. This should be useful. Have you ever used EF or EF Core with Postgresql?
Not in a real project... but I used postgres with django (in a real project) and now I love it and gonna use it with aspcore It ain't really a big deal, just change the ef db provider to postgres in that project, look here how I switched from in-memory db into sqlite: https://github.com/0xRumple/dorm-portal/commit/edb219e76f4627fa38fb8ee7e5558750c4880c7b Just make the necessary changes in those files and it will do ;)
You aren't going to get an unbiased answer in either the .Net or Java communities. You probably need to go to neutral ground like /r/programming
It really depends on the developers and talent pool in your area, unless you are going to use remote developers... 
Given experience with .Net, if its not a desktop app, .Core is a reasonable choice. 
Without details of your project, nobody can answer this for you. Use .Net core and look around for hosting. There are so many options from Google to Azure to Amazon or hosting your own server. You can use a Docker container too...
Wow. Why? I have been a .net coder for 20 years but from my understanding PHP is still actively supported and pretty good. Why switch? As for learning. Pluralsight videos and practice, practice and more practice.
EF Core exposes some commands as powershell commands, but not all of them :P
I don't think /r/programming allows text self posts.
Well so much for that idea...
[removed]
&gt; Either way, what is your experience with Entity Framework+LINQ combo, is it really superior to Spring-based solutions like HQL/Hibernate/JDBCtemplate? I hate both :D Seriously though, again they feel mostly the same in the end. They both work well in the beginning and fall apart as the application becomes bigger. It really boils down to how well you use them given your scenarios and constraints. It's much more important to master the ORM and know it inside-out than which one to use specifically (at least for the most popular ones). Don't be shy about ditching it though for reporting or tricky queries. &gt; Also Java has this annoying serialization, JDO ORM object conversion inconvinience Not sure what you are referring to, been using Hibernate and JPA. The experience is similar to .NET ORMs, IMO. &gt; there must be a reason every single business I ahve ever encountered used Oracle JDK over Open JDK Perhaps for historical reasons, I've not been in the Java universe long enough to tell. What I can say is that the code is the same minus a couple exceptions. Support might be the answer, there are long term releases with three years support for the Oracle implementations. As to Spring vs ASP.NET Core, well they're both flagships of their own platform. Unless you have very specific needs that can only be satisfied by one platform. I'm not aware of anything similar to Spring Cloud in .NET, for instance. Otherwise either will do fine. 
Not IME.
The +0.0 != -0.0 issue is actually not present anymore in .NET Core 2.1! class Program { static void Main(string[] args) { double d1 = -0.0; double d2 = 0.0; bool b1 = d1.Equals(d2); bool b2 = new MyDouble(d1).Equals(new MyDouble(d2)); Console.WriteLine($"{b1} {b2}"); } } public struct MyDouble { public double Value { get; } public MyDouble(double value) { Value = value; } } In .NET Core 2.0 this will print: True False In .NET Core 2.1 this will print: True True
[Pluralsignt.com](https://Pluralsignt.com) is probably the best and very affordable resource for extensive .NET training
Before hopping into Java. If you're looking at any client side development specific to Windows, very heavily consider that the JVM performance is only better server side for long operating processes. You'll have a nightmare of Java support versions, asking clients to manually update Java runtimes, and generally hate life. Java code is also very very very easily decompiled, so don't put ANYTHING critical in the client side application you don't want someone essentially having the source code for. If you plan on open source or don't care if people can get to the source and consider packaging your application to bring along OpenJDK instead of asking the user to use Java SE. You'll have no issues this way. This all comes from my experience in enterprise level development with both languages. I have quickly and easily reverse engineered Java in enterprise level production environments, for hight level banking applications, many times. I've seen certs, clear text passwords, encryption algorithms, ect just in their Jar files completely nullifying any security. That IS the developers fault, but it's laughably common. .NET can have the same issues, however to decompile is less easy and the code is much harder to read out the other end. Java often comes out, comments and all, in clear text. So few Java developers in high security applications obfuscate for some reason. If you're looking at .net core, I have no comments on how easy it is to decompile. I assume pretty easy, probably the same as Java. But without the JavaSE support nightmare.
To answer your question about enterprise not seeming to use OpenJDK. That's because the support model has recently shifted. Here's a rundown. Oracle Java (JavaSE, JavaEE) IS OpenJDK. (Oracle owns OpenJDK!) Oracle Java comes with support and a 1-800 number and WebStart. OpenJDK is just the Java runtime. Recently Oracle has said that they will start offering a subscription model for Oracle Java. $2.50 per month per desktop, a much bigger charge for servers. Oracle themselves said if you don't want or need Enterprise Support, switch your company and platform to OpenJDK. So think of Oracle Java vs OpenJDK as Subscription Java Enterprise vs Java Community Edition.
&gt; our product would be a simple webapp to manage (a preferably, but not neccesseraly) NoSQL database, and get some statistics based of that You could build that in anything. I'd worry about other factors, like cost and ability to hire. Check the job boards in your area for job posts and see which tech stack has the most posts. I admit I have an irrational hatred and would never touch an Oracle product. If I ever met Larry I'm not sure I could refrain from punching him. 
Start small. If the web app is as simple as you say, just hack one together and get a product running. It doesn't need to be fast or amazingly feature rich at this point. Keep the design simple, don't add anything you don't need now. Remember you may throw it all away later, so separate your business logic and isolate it in the most language agnostic way possible. I'd probably consider getting some design consultancy, i.e. someone to do some pretty graphics, perhaps with some UX experience. That said, Reddit is hardly the paragon of design Nirvana, and they've been moderately successful. Google too. It's a logo and a text box :) Ultimately, I'm for .NET. Core is open source and looking pretty hot now, Java has a lot of great developers still working in it, and depending on your location, you may find one easier to hire than the other. But seriously, if your design is as simple as you say it is, take a PluralSight course and hack something together now, but be prepared (this is a design hint) to throw most of it away.
&gt; Why? Consultants said so. Literally suggested technology the entire tech team is opposed to. Yay corporate! PHP is great. There are features that I wish we had, so I'm not too upset. But .net seems so verbose. I'm sure I'll get over it. I used to have pluralsight, so at least I like it.
Pluralsight it is. Thanks.
&gt;nies chose Oracle Java because they liked the &gt; &gt;idea &gt; &gt; they could ask for official help. But now, with a cost, it's going to shift. I do not (not even the least) consider frontend to be done in either Java or .Net I was just asking about the backend (whoops, shoulda mention that :D ) I will do the frontend in Angular either way, I have exp. with that technology and it seems fine to me. 
Thats heartwarming to know that I am not going to suffer any major disadvantages if I end up stuck with Java by using Open JDK. Either way, do you have any experience regarding how many new projects in your area ( wherever you may live ) use C#/.net over Java? Just because in my area (here in HUngary, which is a relatively low ecosystem), new projects tend to use .net over Java technologies, and partly I just wanted to know why. And in case this project fails and I have to go back working for someone else, I really do not wanna work on legacy code, its one of my reoccouring nightmares. My original tought was that Java is way too robust, and this whole serialization, Entity object DTO etc. is too much of a struggle compared to how c#/.net handles this ( I have no idea how this is done in .net, I guess somehow better?). However I belive that now Kotlin seems to be a rising star, java based technoligies might "survive", as the problem has never been with JVM, but rather tha language itself.
Here there are more Java devs than c# devs, however more youngsters seem to prefer c# (which is something I like, as I like to work with younger people more). I am just afraid that java is going to decline in the upcoming decade and eventually c# will take its place (or Kotlin that would be my other tip, as it uses JVM and there are already Spring implementations using Kotlin).
[removed]
&gt;hing. &gt; &gt;I'd worry about other factors, like cost and ability to hire. Check the job boards in your area for job posts and see which tech stack has the most posts. &gt; &gt;I admit I have an irrational hatred and would never touch an Oracle product. If I ever met Larry I'm not sure I could refrain from punching him. The reason why I asked this question is not solely the project itself, the part where we have to use Java/.NET could really be done in either of them, but more so my "future career". This project we are doing is really bold, and might not work out at all, as we have little-to-no business experience. And from what I ahve noticed more and more companies tend to start their new projects in c#/.net rather than java. &lt;- And I really really really hate refactoring legacy code and working on features on them.
" ltimately, I'm for .NET. Core is open source and looking pretty hot now, " &lt;- Yes this is what I was talking about. This is not only about the "project", but also that I do not want to invest too much time/energy into a technology that will decline soon, as I really hate working on legacy code. Now that .net core apps seem to run smoothly on linux servers, and is open source I belive it will replace Java. Many aplications run on Java8 (which oracle will charge for), the IDE support is not as good as for C#/.net, c# as a language is more up-to-date less robust and cleaner. And what I have noticed most companies use c# for their newer projects over Java. However this might change with Kotlin.
Your familiarity with the non-windows platforms should make the transition easier. I work with a guy who was a PHP dev. Things that could have been blocking for me were old hat for him. With the .Net stuff, it goes the other way :)
Just check what features you need and make sure there's a library for them. Simples
&gt; however to decompile is less easy and the code is much harder to read out the other end. This is false. C#(or IL rather) is super easy to reverse. Do not depend on client code decompilation hardness as a metric for security, that is dumb.
Go f#. It's as consice as you can go without losing flexibility. It's,.net and the learning curve is probably close to just as high. (ofc. The consultants will never agree) 
For my side project, we are using dot net core and MySql both running on cheap Linux VPSs (Linode, Digital Ocean). We have been in business for almost a year now and have customers relying on our infrastructure. So far, no problems with our set up. The Linux VMs are holding up fine.
I've had an interest in f# for a while now. Are there many devs out there, which is a concern. The dev team tries to avoid anything that is difficult to hire for.
This is good to know.
I work at www.firstagenda.com and we built all new stuff on dotnet core. Have been for over 1 and a half year.
There is no ideal envirenment at all,I think)From my prespective,if you already familiar with classic .NET freamwork core(.net core) will be a good choice for you. It develop very rappidly and provide a lot of new features. P.S.Good luck to you!
Many are recommending pluralsight, but I'm not sure - at least for the language itself. Pluralsight has a lot of stuff for beginners, but you're obviously not a beginner, so I would not suggest learning C# that way - and C# is worth learning properly to understand what's going on. I came from GNU/C++, Python and PHP, but I was a lot younger and less experienced than you are now (PHP 5.3 was brand new back then). Still, I'd recommend: - 'C# in Depth' (http://csharpindepth.com/). This would give you a sense of the history of C# and how several features of it evolved (Generics, Properties, Lambdas, async/await). I really enjoyed that one. - 'LINQ in Action' (https://www.manning.com/books/linq-in-action) if you really really want to do a lot of LINQ stuff or struggle with the concept, otherwise skip that one. - Now, my guess is that you're going to learn ASP.Net MVC or ASP.Net Core. Whenever I needed to learn a stack, I bought an Apress book that starts with 'Pro' (did it with Silverlight, WPF, and MVC). https://www.apress.com/us/book/9781484234341 could be a good start. They really teach you a stack bottom up in all detail, and you can skip parts that are not that interesting to you. In addition, they are good for reference. Instead of the Apress books you could of course take a Pluralsight course. But I always liked that I could go back to the book and read things up quicker than finding the part where the lecturer talks about what I need in Pluralsight, but that is just personal preference. **Good luck, and welcome to the .NET world! It's not half bad here :)**
&gt;Following the [initial announcement](https://go.microsoft.com/fwlink/?linkid=872708) of Visual Studio IntelliCode at Build 2018, we’re excited to report that the [Visual Studio IntelliCode Extension](https://go.microsoft.com/fwlink/?linkid=872707) has been updated to enable coding convention inference for C#, to help you and your team achieve more readable and consistent code. If you’re new to the Intellicode extension, it already provides AI-assisted IntelliSense suggestions, which you can read about in the [initial announcement](https://go.microsoft.com/fwlink/?linkid=872708). If you already have the extension installed, you may have automatically received this update. If not, you can get started now by [downloading the extension](https://go.microsoft.com/fwlink/?linkid=872707).
Old job was .net. new Job is a proprietary Java framework. I do all my personal projects in .net core. Some reasons: - I like c# better. Some things that my company has to abuse reflection in order to achieve are available out of the box for c#, such as extension methods. Also c# has a vast standard library. - c# moves faster than java. Java takes 10 years to impelement features that it should have had 10 years ago - c# has nuget which feels cleaner to use than maven or gradle. If you use vscode or visual studio this package manager is directly integrated into the IDE 
https://twitter.com/terrajobst/status/1019017763036123137 &gt;Should JSON_NET be part of the .NET Standard? I believe the answer is no. But what do you think? https://github.com/dotnet/standard/issues/834
It is slightly harder by obfuscation, not by ability to decompile. I should have specified better. Either way, you are correct.
Aha. So either way OpenJDK with Wildfly or .Net Core, you'll be honestly happy. Just consider resource usages between the two.
We do exist :-) We are just far fewer than C# developers. There is a fairly vibrant and supportive community around F# and [jet.com](https://jet.com) is all in on the F# wagon (I do not work there :-) )
C# and Mongo work fine together. I haven't run into problems and have used them extensively.
This is awesome. Even on solo projects, it's hard to be consistent at times, especially if you take breaks from a project. I'm hoping that this will be added to visual studio code too (feel free to correct me if it already is). 
I agree. Even at my work I believe this would be handy to ensure code is consistent across the board. The amount of variations sets my OCD alight haha
Consider HttpClientFactory in .NET Core 2.1
The other way around. MVC can limit you.
No.
Is there any such extension for visual studio code?
If the host you're connecting to uses DNS for traffic management, then following this author's advice is actually pretty harmful as the shared HttpClient does not refresh its own DNS cache. See http://www.nimaara.com/2016/11/01/beware-of-the-net-httpclient/.
Definitely yes. ASP.NET Core uses JSON and its really weird to not have a core library not included in the standard.
I am doing some researchs about web frameworks like GO, react vs but I am not sure that will it be better to use that frameworks instead of my experience in .net. Yes it won't be a desktop application. Thanks for your comment :)
I was seeking for this answer :) I have a little knowledge about linode host. I tried to create a web site using wordpress in the cheapest Linode VPS. I wasn't sure that MySQL is fine with .NET core. So you say that it is possible to start with cheapest VPS with .NET Core and MySQL. I am so happy to hear this! Do you recommend any framework for .NET. For example I found dotnetify-react framework. Do you think is it better to start with or is default .net core mvc project enough to create something?
Nice to see working examples. Did you have any bottleneck because of the .net core? Which database are you using? (if it is not private information for you) 
HttpClient is really awful.
VSC has an EditorConfig extension, which in theory could use the generated config file, but it looks to me like it's only capable of enforcing a couple of the most basic (and not-language-specific) settings.
Foundation: yes Frameworks: no :) 
Basically I want to create an international calendar, but in a smart way. It will act according to the events. For example if there will be an exam date, it will contain the exam date, results publication date. Maybe people will subscribe to get new updates on the event. So there will be lot of work in the backend. Maybe some notifications, maybe it will be more logical to develop mobile applications also. Because sms or e-mail is not suitable. Maybe push notifications would be more interesting. It will be possible adapt lots of kinds of events. I know it won't be an easy application but I will start from somewhere. (I hope :)) I am working as devops in my company. So I am experienced with automations but our company has lots of applications in production environment, so we can't adapt new technology like docker, .net core because lots of people using 7/24 so we need very very stable environment (especially we are a government IT) So I am a little far away with docker technology. Do you think will it be a better idea to also starting with docker? 
Thanks. I think using a singleton for httpclient is a terrible idea... especially since things like baseaddress and things are immutable after the first request is sent through it... the write-up you linked provides a much better alternative. 
Please elaborate.
mostly, lots of backend code, subscribing to events, suggesting similar events according to user history, creating an advert model, creating an api that other programs can integrate my database. Maybe a framework can limit my potential so like you said, I can find library for my needings. Do you think .net core is suitable for me? 
You totally right. But I am thinking for a long time, I did nothing. At last I thought that I have to start from somewhere even if it not the best. So I wanted some opinions who is experienced in these subjects. Thank for your good wishes. I am open to every suggestion :)
&gt; I think .NET Standard should be part of Newtonsoft.Json. It's stable and used practically everywhere in .NET projects, it's pretty much what .NET Standard wants to be. &gt; If anything they should merge with your project, and then rebrand themselves to NSFT on the stock market. [Best comment.](https://github.com/dotnet/standard/issues/834#issuecomment-405559868)
If you are coding it yourself or with a small team, you don’t even need to worry about how it is hosted yet. Get a basic site working first. Maybe use a simple azure website for your dev environment. Once you are close to going live, research your options for hosting.
I think having it managed by the .Net Foundation would be good as it reduces the dependency on a single individual. I just don't see any reason to make it part of the .Net Standard or Framework and Rename it System.Json
Well, right now .net core is really popular. Recently it has shown to be very fast and is getting to be quite robust for ASP.net development. Around here, Colorado USA, we have a large mixture of both Java and C#. C# tends to live more on Windows servers and desktops and Java is viewed as being cross platform. However a lot of companies were scared by Oracle Vs Google. No one wants to be in court over their app being successful. OpenJDK solves that it a lot of ways with it's license, but with so many burned by many changes Oracle has done up to this point (often to the fault of the developer), people took it as an opportunity to jump ship. Especially since .net core is a very viable replacement and is not as resource hungry. But, you could end up with legacy code after a few years either direction. It's always a risk. C# is very similar to Java in a lot of ways. For web development, depending on if it's WebForms, webapi, MVC, handles serialization a little different. I find it honestly easy to serialize a class and pipe data to JSON for a front end in JavaScript. A lot of serialization actually happens automatically but sometimes you need to specify. I use, depending on the project, either EntityFramework or straight SQL and my own class objects. (All depends on SQL environment requirements). But, I'm also the DBA so I have a different viewpoints on that matter. Java itself isnt dead, it's changing. And so is C#. Regions tend to be heavy with jobs from one to the other soley based on what local schools are teaching and what era the company started in. That's my personal input anyway.
LOL I have to admit, I trust Newtonsoft more.
Its not private. We use azure SQL services. And some older projects Aws hosted ms SQL servers. No bottlenecks so far. 
Switched from php to C# a few years ago and I don't regret it... C# can be verbose, but doesn't has to be. Some stuff can be much easier (filtering lists, parallelism) for example. And it's saver (there are no textfiles to be intepreted) I'm sure you checked out the C# reference (there are a lot of handy tipps, quite a lot of them can be used to de-verbose C#) To speed up development https://www.peachpie.io could be helpful (There was reacently a wordpress port done with it) 
A lot of the comments on the issue make sense. It restricts what can be done in future. I don’t think it should be done. Whilst JSON is widely used due to it being relatively lightweight and still relatively human readable, but what’s not to say that something comes in the future to replace it, this becomes another part of the standard that requires maintaining. Whilst I am a massive fan and biased towards Swift, if there were changes added to the standard that was flexible like Swift’s Codable protocol that can be leveraged outside of the standard, that is something I could get behind :)
Personally I like it and there's finally documentation for most things I've needed so far but that's just my my experience. I've had to go scouring the source code for some Auth stuff but mostly it's been ok so yeah I'd give it a thumbs up. 
Very much this. The exact reason this has been made is so that you get a performant and sane HttpClient when you need it.
Very much this. The exact reason this has been made is so that you get a performant and sane HttpClient when you need it.
That's good to know about peachpie. I was actually thinking about it earlier. I remember seeing it on the usual blogs and then never hearing about it again.
Thanks for the great response. I'll be checking out the links when I get the chance.
https://github.com/dotnet/standard/pull/823 - public sealed partial class AppDomain : System.MarshalByRefObject + public partial class AppDomain : System.MarshalByRefObject Why is AppDomain getting `sealed` removed? https://github.com/dotnet/standard/pull/827/files - public static partial class NetworkChange + public partial class NetworkChange And this class is no longer static? Are these specified elsewhere? 
You should be able to use it from desktop framework as well (.NET Standard 2.0 nuget package). Instantiating it directly might be a little weird.
I'm learning ASP.NET Core and installed [ASP.NET Core 2.1 on Ubuntu 18.4](https://gist.github.com/odan/36b2ffde91102cf6c1b1170f104f8ba0) with Apache as reverse proxy (with SSL), MySQL ([MySql.Data](https://MySql.Data)) and Supervisor to keep my web application running. It works quit good and fast. At the moment I'm evaluating [SqlKata](https://sqlkata.com/docs/select) to build dynamic SQL queries (because I don't like LINQ). I'm also looking for a stable package to minify JS and CSS files. Unfortunately I haven't got the last version of [BundlerMinifier.Core](https://www.nuget.org/packages/BundlerMinifier.Core/) up and running yet. [.NET Core 2.1 will be a long-term support (LTS) release.](https://blogs.msdn.microsoft.com/dotnet/2018/05/30/announcing-net-core-2-1/) which sounds very interesting of course.
It is universally known, especially by the Java Language Architects, that Java has areas of weakness. Because of backward compatibility, the language Architects have their hands tied in solving some issues (like properties). In the end, they aim to add features to Java as it makes sense to try to keep it modern. However, if Java does decline, it isn't worrisome in my opinion. The direction of the JVM is to have different languages coexist within it with near perfect interoperability. New projects like Graal really does demonstrate this new vision. Interoperability between languages like Ruby, Python and Javascript has become much nicer on top of Graal + JVM. Today, C# maybe considered popular but until the next language that arises. The JVM going forward gives you the ability to utilize whatever future language with the code you write today. I feel that looking at the direction of the platform in general should be a consideration going forward. 
+1 to PluralSight
I didn't even have to read the article to tell how it was being used wrong. We have some variation of this same post every 3 or so months either here or in /r/csharp
not that I can tell. here's an issue for ["Feature Request: Add IntelliCode like autocompletion in vscode"](https://github.com/Microsoft/vscode/issues/49437)
Good. good. lol.
Is it just me or the naming conventions are very confusing and unclear?
It actually *can* be language specific (if you count file extensions as being language specific). [EditorConfig Project](https://editorconfig.org)
Is there a written recap by now? I really don't have the patience to watch the entire video for the 5 minutes of content. :-(
I am a little embarrassed to say that IntelliCode might find the inconsistency of our code base a bit challenging :-/
Community Links https://www.one-tab.com/page/VlCvKlGWQ2yjEsvkGwwAFA
You can find the source in [This repo](https://github.com/dotnet/corefx) but basically it's just a struct that counts up until it reaches a number. private void SpinOnceCore(int sleep1Threshold) { Debug.Assert(sleep1Threshold &gt;= -1); Debug.Assert(sleep1Threshold &lt; 0 || sleep1Threshold &gt;= YieldThreshold); // (_count - YieldThreshold) % 2 == 0: The purpose of this check is to interleave Thread.Yield/Sleep(0) with // Thread.SpinWait. Otherwise, the following issues occur: // - When there are no threads to switch to, Yield and Sleep(0) become no-op and it turns the spin loop into a // busy-spin that may quickly reach the max spin count and cause the thread to enter a wait state, or may // just busy-spin for longer than desired before a Sleep(1). Completing the spin loop too early can cause // excessive context switcing if a wait follows, and entering the Sleep(1) stage too early can cause // excessive delays. // - If there are multiple threads doing Yield and Sleep(0) (typically from the same spin loop due to // contention), they may switch between one another, delaying work that can make progress. if (( _count &gt;= YieldThreshold &amp;&amp; ((_count &gt;= sleep1Threshold &amp;&amp; sleep1Threshold &gt;= 0) || (_count - YieldThreshold) % 2 == 0) ) || PlatformHelper.IsSingleProcessor) { // // We must yield. // // We prefer to call Thread.Yield first, triggering a SwitchToThread. This // unfortunately doesn't consider all runnable threads on all OS SKUs. In // some cases, it may only consult the runnable threads whose ideal processor // is the one currently executing code. Thus we occasionally issue a call to // Sleep(0), which considers all runnable threads at equal priority. Even this // is insufficient since we may be spin waiting for lower priority threads to // execute; we therefore must call Sleep(1) once in a while too, which considers // all runnable threads, regardless of ideal processor and priority, but may // remove the thread from the scheduler's queue for 10+ms, if the system is // configured to use the (default) coarse-grained system timer. // if (_count &gt;= sleep1Threshold &amp;&amp; sleep1Threshold &gt;= 0) { RuntimeThread.Sleep(1); } else { int yieldsSoFar = _count &gt;= YieldThreshold ? (_count - YieldThreshold) / 2 : _count; if ((yieldsSoFar % Sleep0EveryHowManyYields) == (Sleep0EveryHowManyYields - 1)) { RuntimeThread.Sleep(0); } else { RuntimeThread.Yield(); } } } else { // // Otherwise, we will spin. // // We do this using the CLR's SpinWait API, which is just a busy loop that // issues YIELD/PAUSE instructions to ensure multi-threaded CPUs can react // intelligently to avoid starving. (These are NOOPs on other CPUs.) We // choose a number for the loop iteration count such that each successive // call spins for longer, to reduce cache contention. We cap the total // number of spins we are willing to tolerate to reduce delay to the caller, // since we expect most callers will eventually block anyway. // // Also, cap the maximum spin count to a value such that many thousands of CPU cycles would not be wasted doing // the equivalent of YieldProcessor(), as that that point SwitchToThread/Sleep(0) are more likely to be able to // allow other useful work to run. Long YieldProcessor() loops can help to reduce contention, but Sleep(1) is // usually better for that. // // RuntimeThread.OptimalMaxSpinWaitsPerSpinIteration: // - See Thread::InitializeYieldProcessorNormalized(), which describes and calculates this value. // int n = RuntimeThread.OptimalMaxSpinWaitsPerSpinIteration; if (_count &lt;= 30 &amp;&amp; (1 &lt;&lt; _count) &lt; n) { n = 1 &lt;&lt; _count; } RuntimeThread.SpinWait(n); } // Finally, increment our spin counter. _count = (_count == int.MaxValue ? YieldThreshold : _count + 1); } 
Very good questions. Maybe you can raise them in the conversation thread on github. 
And thank you for putting me onto /r/csharp - I found dotnet and assumed it was the busiest Microsoft language subreddit here.
Implement the simplest thing and then profile your code
&gt; I trust Newtonsoft more Brutal honesty
https://www.reddit.com/r/dotnet/duplicates/8zo5s1/youre_using_httpclient_wrong_and_it_is/
Put existing applications on peachpie and implement new features on C#. Don't start from scratch.
Sounds like you want a ring buffer. `Queue&lt;T&gt;` is based on a ring buffer, but it's not quite ideal because you can't automatically constrain its size, and you'd have to loop through the entire queue to find a specific timestamp. You could implement your own constant size ring buffer which isn't too hard, then you could also look for timestamps with a binary search or something. Have you considered whether you require a thread safe collection?
Does it really work that well?
I went through this on one of my APIs. It goes Client Specific Model-&gt;API. The API then loads from the service layer an object, it applies the JSON patch model to the Server Layer Model in the API layer. Since this isn't a direct mapping and most examples just use the EF model (yuck), I do parse the json patch document operations. `if (model.Operations.Any(x =&gt; x.OperationType == OperationType.Add &amp;&amp; x.path.StartsWith($"/{nameof(MyProject.Web.Models.Api.Person.Phones)}", StringComparison.OrdinalIgnoreCase)))` So if the above is true, I know that there is a phone number that was added to the model through PATCH. (Ignoring casing because everything is camel case on the client side). It's a cheap way to do reflection, which is really string based anyways. `if (model.Operations.Any(x =&gt; x.OperationType == OperationType.Replace &amp;&amp; x.path.StartsWith($"/{nameof(MyProject.Web.Models.Api.Person.Address)}", StringComparison.OrdinalIgnoreCase)))` Here I know that the address of a person was replaced, so I can swap out the address for the one I already had from my service layer. My service layer will pick up on any authorization issue on any of the fields that are changing because it's just normal service layer calls for it. Now, this isn't the most beautiful code, because JSON Patch turns into a two way data syncing nightmare quickly. The client side handles everything because it is doing change tracking for the whole JS object for me to generate the patch. API layer can merge the patch into an API Model object for me, and I can interrogate what changes happened (change tracking) to apply up to the service layer. Benefits in my projects. 1. I can expand on the number of properties in my API Model, without worrying that this one call will Null out a value on accident 2. My service layer never changed to support JSON Patch, it still has no idea what JSON is and doesn't need references to any Microsoft.AspNetCore.\* packages to support it. 3. I have a clean break, and am not passing, or accidentally passing anything from my service layer directly to the API. No accidental "Oops, added a secret key to that model and now it is on the API" because it goes service layer-&gt; Mapping-&gt;Public API.
It seems to be, and fast too. Don't do a rewrite if you can help it. The pressure for a rewrite is crazy.
That's fantastic to hear. I'll bring this up with the team.
http://sitr.us/2011/08/26/cookies-are-bad-for-you.html
With tokens there's XSS, with cookies there's XSRF. That link seems to suggest OAuth as an alternative to cookies even though OAuth relies on cookies Also, there are ways to deal with XSRF in a Web API using cookies: https://docs.microsoft.com/en-us/aspnet/core/security/anti-request-forgery?view=aspnetcore-2.1
Right, but I’m saying it looks like the VSC *extension* will only enforce a couple things from the EditorConfig spec, like indent size etc, and nothing like prefer expression-bodied-members etc.
So you're doing an if statement check for every operation on every field? I see how the would work but also create a ton of testing overhead. We are on the same page that it's best if the patch is done in the controller because then you just have an update method in the service layer and you don't have to worry about patching and having dumb dependencies in the service. 
I know it's not a direct tech answer, but: It's a startup. Use whatever you know best, or whatever your technical founder knows best. One of the best way to destroy your chances is to choose a stack that you or whoever is going to be in charge of the tech does not intimately understand. If you're going to jump into NoSQL make sure you only do it if you know what the pitfalls of the various products are. Don't use Node you have used node before. Don't use .NET, Linux, or any other technology that you don't already know. Otherwise you will likely waste an enormous amount of cycles trying to learn / teach yourselves how to learn a new stack, probably implement significant portions of it in the worse possible way, end up in countless battles of performance problems, troubleshooting and researching errors, and probably opening yourselves up to any number of security vulnerabilities because you didn't configure something properly. Do whatever you can to prove out your startup first and save your cash for important things. If you're successful you can always rebuild or rewrite it (or portions of it) in time if or when that becomes a necessity. 
Why NoSQL?
Build a website. Start with a content only site then move to one that has forms and then to one that uses a backend database. Add https, host it on azure using the free tier. Start with .net core as it's the newer version of the framework. There is a lot to learn so keep it simple and build off of previous successes.
It would need to be thread safe as the service it exists in will be putting data it in at regular interval and other separate services will be querying it, probably via WCF service or something similar.
It's impossible to suggest a collection object which seems to best match the scenario? I'm not looking for the most crazy optimal setup, just looking generally in case there's some collection that I'm just not aware of that more closely matches this scenario. As I said Queue&lt;T&gt; seems closest to me and I could implement with that but if there's something with more built in functionality to match it would be nice to know.
If you've got less than 1000 records at a time, it would be hard to find a data structure that *didn't* do any operation in under 10ms.
The Microsoft docs are great on this topic. [https://docs.microsoft.com/en-us/aspnet/core/mvc/views/partial?view=aspnetcore-2.1](https://docs.microsoft.com/en-us/aspnet/core/mvc/views/partial?view=aspnetcore-2.1)
Hundreds of blockchain startups are working tirelessly to fill that gap
You suggested Queue and asked if there is something better. You haven't described your problem in enough to detail for anyone to give a meaningful suggestion. Why are you opposed to implementing and profiling? 
To add onto that, make it does evolve into something that isn't scaffolded. Any monkey can make a static MVC razor site. Database is great, another example could just be a simple weather site that grabs data from a couple of sources providing both a web page and the option of a simple JSON API, perhaps with a link to auto generated Swagger doc. While unintersting it would at least show you have anunderstanding of; consuming and parsing resources, using httpclient, creating services, what a JSON API is and a way to document it. Of course don't go straight into the deep end, there's a lot to learn.
Outside of C# directly (aside from the obvious HTTP/CSS/Javascript) * Learn the basics of HTTP itself (things will make a lot more sense) * Learn the basics of a JSON/REST API, understanding SOAP is important for older/enterprise software too. * look into the [OWASP top 10](https://www.owasp.org/images/7/72/OWASP_Top_10-2017_%28en%29.pdf.pdf) * Get a basic understanding of various design patterns, [ASP.Net](https://ASP.Net) core for example loves dependancy injection. These are all language agnostic and you don't have to learn these in full detail all at once, they are all more important than knowing how to put together an MVC program.
Cookies!? So now a none browser application can’t consume your API?
What http client doesn't support cookies?
Implemented this today using the Named Client convention. Didn't notice a performance improvement, but it was much easier to work with standard .net core DI and unit testing. Thanks for sharing.
How do tokens lead to XSS? Part of the reason for using tokens instead of cookies is because you have to generate a token *anyways* to deal with XSRF.
Lead is the wrong word but tokens are usually saved in localStorage and therefore can easily be read using JavaScript. Cookies can be created with HttpOnly making then inaccessible in JavaScript (this is the default when you use the cookie middleware in ASP.NET) Some people even recommend saving tokens in cookies. 
Views in EF Core have always been a pain. It sounds good but I guess we'll see it better on the battlefield. In the EF issues I have a simple indicator: If the EF Reverse POCO Generator tool can implement it seamlessly, it's a good feature. 
That's very cool. I could tell it was built with dotnet because of the favicon.
:-) or lack there of. The favicon is one of the kinks!
Nothing I can share on the wild, thanks NDAs.
I was expecting a ridiculously verbose post but you kept it concise and made it look as easy as it really is. Nice work!
Great initiative! I submitted one of my hobby projects, but it requires at least one screenshot, which is not very applicable, because it's a library. So maybe something you should change? :) 
Good point. Just removed the image requirement. Thanks for your submission! Will put it live later today or tomorrow, when I set up a decent looking placeholder for projects without screenshots.
But if someone can access local storage they can just make the API calls themselves using AJAX considering that the cookies are sent with the request. It seems like a non factor honestly.
I love the idea but to be honest the card layout is not that pleasing. 
Please be honest indeed. Thank you. Can you be a bit more specific? I'm not a pro designer btw, as you might have guessed ;-).
Cookies are only sent to the domain where they originate. If you can read a token from localStorage you can send it wherever you like, effectively stealing the user's identity.
Yes, but you can’t read local storage for a different domain, and your token should only be valid for this domain generally. You’re effectively able to send requests to this site and only this site with both cookies and tokens. 
One of the reasons to pick (JWT) tokens over cookies is being able to use them for more than one domain. 
Tune in throughout the day for this great workshop covering software architecture concepts with these expert pair-programming guests: 10a ET Steve Smith - Clean Architecture 11a ET Julie Lerman - Domain Driven Design and Entity Framework 12p ET Jimmy Bogard - CQRS and the MediatR framework 1p ET Mark Miller - User Interface Design 2p ET Miguel Castro - Application Extensibility 3p ET Cecil Phillip - Serverless Concepts and Architecture 4p ET Steve Lasker - How and Why to use Containers
This is very exciting, great work Jeff!
There doesn't seem to be an option for .NET Standard in the "framework" dropdown. Most of my projects are libraries and not tied to any specific framework. 😕
Well I can't show it off and I don't work there anymore, but most of the biggest rewards programs out there are built on .NET. I worked on Walgreens for 4 years, all C#.
Are these available later as well or only as a stream?
&gt;The wait for features from EF6 to appear in EF Core has been due in part to the fact that the EF team has not just copied the old implementations but found smarter, more functional implementations. I still think they should have done a direct port of EF and then come up with their own new solution instead of taking the same name and releasing a bunch of inferior versions.
I've added ".net standard" as a framework and "Library or nuget package" as project type.
Thanks!
Here is new post here on deploying with Docker. https://www.reddit.com/r/dotnet/comments/902q6z/how_to_deploy_multi_environment_with_aspnet_core/?st=JJSPZKWT&amp;sh=c2b42fad 
I'm not either ☺️. Just not a fan of the cards. Seems like a lot of white space
I mean, if that's what you're into.
Thanks 👍🏽
https://m.youtube.com/channel/UCfvJirlbRTN-bU9sMWMb_ZQ 
I love it! The domain gets me though, built with dot dot net 🙂
Use a framework-independent logging abstraction and use DI to inject logging implementations. This gives you the most amount of flexibility, you can log to the debug output while developing, log to a database on one deployment and to files on another, easily switch verbosity without ever having to touch other code, and even swap out the entire logging framework.
&gt; debug output while developing, log to a database on one deployment and to files on another What are some of the reasons why you personally would go for files vs database?
Only an if statement for each child object. So a Person object has an array of addresses and an array of phone numbers. If I don't detect any changes to either of those objects, skip all of that logic. If an address changed, apply the whole address to the service layer model and let it figure it out. EF will handle only updated changed fields, but that really isn't my concern, just an added benefit. One thing I didn't mention was when the request first comes in, I query the server layer for the latest objects, and create my API layer model object, then apply the JSON Patch to that object. I could setup change tracking on that object, but I ended up only with 15 lines of code for my less optimal method, so I didn't care. So in my address example above, lets say that someone changed the street name, I see that an Update/Replace was done on the address object, grab the values from the API model that was PATCH'd and tell the server layer to update to these values. Since the object was patched, the API Model will have the latest DB values and the updated street name, which turns that code into something similar to a POST of a whole object. 
Mobile applications. REST is meant to be REST not some bastardised version that uses cookies, which violates the stateless nature of REST anyway.
*Program attempts normal database operation *Exception: connection failed *Program attempts to log exception to data....oh damn! Always best to log to multiple output sources so that you have redundant copies in the event of a problem with one source.
Best practice would be to run the console app as the service account or give the proper authentication/permissions to whatever account is running the app. If you really have to impersonate another account, supposedly [https://stackoverflow.com/questions/47084148/core-2-0-best-way-to-impersonate-a-windows-user](this) works
Do you dump your log files every so often to some external service? These files could get big pretty quickly. From what I could gather, a log aggregation tool is very useful, since the logs are big and there are a lot of files. Elasticsearch was mentioned, do you use something like that?
Cookies only violate RESTful apis if they are used to maintain server-side state. You can absolutely use cookies with RESTful apis as long as they are stateless. 
I log to three sources in production: local file (warning and higher), remote database (warning and higher), and SMTP for anything totally unhandled (which should almost never happen) that needs a ticket to investigate. The goal is that the server can *always* log the information to at least one source, even if other sources are unavailable for some reason. Debug level is only enabled on testing, since it outputs mundane things like "Entering/Exiting XXXX part of the application: [params]" My log files run a few MB per day usually, but I have a scheduled script that runs once a month to purge anything older than a year. Database task purges once a month for anything older than a year. I don't aggregate logs right now; my needs aren't large or complex enough to worry about that. 
All .NET Core logging is based on the Microsoft.Extensions.Logging stuff (Microsoft.Extensions.Logging.Abstractions provide the interfaces that any logging framework could implement). Even a lot of the .NET Standard libs are standardizing around that, so at this point, I'd probably recommend thinking about that abstraction in anything you use. Then you can use any of the frameworks out there that have implementations for that. Log4Net is a little long in the tooth, and a few years back they had a signing certificate issue that gave a lot of people reason to look around and land on NLog or Serilog. NLog is a good basic framework, Serilog is a super extensible framework which means to get a simple logging infrastructure up you'll probably need 15 different packages to begin writing a log file. I think Serilog IS a good framework, maybe even a better overall approach... but its a lot more work and learning to get it going.
So you let the client tell the server what changed as a property on each object? I'm still not clear how you detect what changed without comparing every property to the model you pull from the database. 
Any chance you remember "exactly" what courses and tutorial have you followed? I've been told by Microsoft Press to use this book as a resource, but I am not completely convinced about it. [https://www.microsoftpressstore.com/store/asp.net-core-application-development-building-an-application-9781509304066](https://www.microsoftpressstore.com/store/asp.net-core-application-development-building-an-application-9781509304066)
But once you've gone through the effort of fucking around with a cookie in an application why not just attach it to the header? I've literally never seen a REST API that uses cookies. Have a look at some of the public REST API's, not a single one uses cookies, they all take a key either in the URI or the headers.
Simple and concise. Great post!
Let's back up. Your original point was using cookies precludes non-browser applications from using the API. That isn't true. The goalpost was then moved to "Restful APIs can't use cookies" and "cookies violate REST!", and that isn't true either. You haven't seen any, but that does not mean it is impossible, and is completely beside the point: neither the article nor your original comment mentions REST anyway. And "I haven't seen any public RESTful APIs use cookies!" is not an argument. You can absolutely use cookies with non-browser clients, and there is nothing that prevents a RESTful API from using cookies.
&gt; Maybe the reason public APIs don't use cookies is a) they don't require authentication, or b) they use OpenID or similar, which is very difficult to use with cookies. Or they put it in the header like I originally said? Fuck it then, let's go back in time and make everything cookie based, would that satisfy you? Guess you'll need to write some code for say Android that can generate and parse cookies, same with iOS apps. Sounds good.
My only point this whole time is it is *possible*. Your original points were that is *not* possible. At no point did I suggest it was a good idea or something worth doing. You are arguing against things I never said. And now you're throwing a fit because someone pointed out you're wrong. Good job. Very mature.
For me, 9 times out of the 10 I see code coverage tools in place they are normally accompanied by ridiculously brittle unit tests designed to get that number as high as possible. I'm sure this is not the case everywhere, but I really wish the ideological stand-point of getting 100% coverage would die off. 
Didn't Microsoft recently hire James?
I think the goal is to get it high. 100% should be considered impossible and 0% inconceivable.
Agree. High but not at the expense of maintainability and ongoing maintenance costs in my opinion!
I just enabled coverage statistics for our codebase today via some jetbrains tools. 6% :\
Maybe that's a little low! ☺ Better than 0 though!
Then we agree 100%😄
Great! ☺
I just wrote this article yesterday. https://lachlanbarclay.net/2018/07/using-seq-and-asp-dot-net-core
We use the standard ELK stack. We've set up each Web server in every environment with Filebeat which pumps the files written locally by each Web app that resides on the box via Logstash to the Web server where Kibaba resides. We have an in-house nlog wrapper dll with many flavors of logging methods for different log levels that we've pushed out to our Nuget repository so that every one of our apps can get logging implemented via DI with little fuss. The hardest thing the developer has to do is decide what he's going to actually log. 
Please, please don't rely on databases for logging. It's an utter nightmare that we just dug ourselves out of 4 years ago (and we still even have legacy apps today that are still writing logs to the DB!). Databases are great for storing data that your customers and end users rely on. But for logging, and actually getting up-to-the-minute visibility on said logs is a joke, not to mention the inevitable downtime of a DB server. Kibaba is so nice for logging UI. Especially when it comes to aggregated dashboards. 
This is a topic I love! So generally speaking I just pick up a logging off of the internet, something like Log4Net. It has your basic interface, levels to log, string formatting, and the ability to provide the location via app config or via code. As far as how to do it, you can opt for attributes, which would be in the Aspect Oriented Programming (AOP). I prefer the wrapper method, which I think is how AOP does it behind the scenes. Basically you have your interface object, IDoStuff, and you write one that does the thing you want. Then you write another class for logging, both classes inherit from IDoStuff. In the logging concrete, you take in the inner call. Then you log, do you stuff, and then pass the parameters to the inner class, returning the value. This is the SOLID way of doing it, if you don't want to log, you don't wrap your object. When wrapped, all code, including unit test code, can test that you are getting the correct data and correct logging. Also by logging the input parameters, you can create unit tests for any failure case, thus reproducing any problems. Generally speaking this is all done via factories, So I have an IDomainFactory that gets the "root objects" I need. But again, using wrappers, I can wrap my factory in all the wrappers I want, thus allowing me to inject logging onto objects at creation, but the rest of the system has no idea. Example: public void ILogDoStuff: IDoStuff public ILogDoStuff(IDoStuff innerClass, ILogger logger) //this function would just save these to inner members, //use the logger on all IDoStuff interface calls. -------------------------------------- I do agree that text files are preferred, the reason is you often want to get the logs off of the machine easily and trying to generate a report or open management studio is a hassle. A text file will be good enough. Hope that was clear, if you have any questions feel free to ask. 
&gt; serializing ViewState into Redis Legacy software is gross
Yeah that might work, but my long term goal is to run this as a daemon/long running process as a provider for a web service. I've been doing more research and it looks like using IHostedService might be the way to go, but I'm lost as to how I could run one as a specific user.
Personally I wouldn’t bother with the abstractions, wrappers, DI, etc that other people are talking unless you’re writing library code or just want to do it for fun. log4net is ok, but it seems to basically be in maintenance mode so I’d lean towards something like NLog that is actively under development. NLog is quite easy to use. Each class gets its own static logger: private static readonly ILogger Log = LogManager.GetCurrentClassLogger(); The only purpose of the logger is to produce log events. Your configuration decides how (or if) those events are stored. Setting up different logging configurations for local vs staging vs production, etc. is just a matter of som config transforms. 
We had an internal, DIY logging system. After a switch to NLog, not looking back. We’ve implemented both file logging and also writing to logentries.net for entire user base analysis and catastrophe alerts. With the online though, important to rate limit. If the same exception is thrown within a couple seconds we start a logarithmic back off so we don’t overwhelm the service.
&gt; Do you dump your log files every so often to some external service? Log rotation. Many logging providers include the ability to "rotate" logs and there are dedicated programs that do it too (e.g. logrotate on linux)
This sounds interesting. I will have to look into the tools you mention here. We are a startup, haven't even written the first line of code yet, so I am trying to find something simple to start with, but with room to grow in complexity as need arises. Would you call this an advanced setup?
&gt; user base analysis What might this be?
What kind of stuff do you log? Obviously you'd wanna log exceptions, but what else? Do you look communication with external APIs?
Couple of things: - Aggregate of exceptions found across our entire user base in production - Telemetry regarding user interaction (eg User was in this screen for 5 mins, clicked on this button) My company makes software that is generally installed on premises so having this data allows us to be proactive about fixing shakier parts of the system without having to get on every users system to look at file logs.
&gt; Aggregate of exceptions found across our entire user base in production How do you aggregate stuff like this? I mean, I understand logging an exception once it happens, but aggregating? Is it some sort of postprocessing that allows you to aggregate that stuff?
This surprised me. I think I just read an article on how to open up your API to XSRF attacks, with no mention of how to mitigate it.
Would you say the same about an article about jwt tokens and XSS? XSRF is only an issue if the client is a browser, which is probably the most common scenario. I'll add a paragraph about it with a link on how to implement anti-xsrf in web api.
On my mobile the card isn't centered great more whitespace on one side 1080x1920...
Cool. Will look into it.
[removed]
I'm working on an SDK for Sentry which is an OSS error tracking tool. The SDK is to be compatible with most .NET apps so the unit and integration tests run on .NET Framework, Mono and .NET Core. The repo has an integration with ASP.NET Core which can run in CoreCLR or CLR but we will work on other integrations like Unity and Xamarin soon. https://github.com/getsentry/sentry-dotnet/ Would love to get feedback.
[Logentries.net](logentries.net) is a service we use. We send some of our logging there in addition to logging locally. Their service has a query feature built in that allows us to do some analysis on the logs. Since it is a single source for our entire user base, it allows us to look at big picture performance and use of our application.
&gt;Serializing Actions I wouldn't have though delegates were even serializable in the first place.
Never mind delegates at all.. Did you even try to debug the Owin/Katana authentication code? All kinds of delegates and you never know where you end up.
How would you do, what you want to do, today in the full framework or if .NET Core never existed?
The factory pattern helps out in these cases
Indeed. I have intended to write write a few line on that take but I've saved it for another post. 
With [Windowsidentity](https://msdn.microsoft.com/en-us/library/w070t6ka(v=vs.110).aspx) impersonation. 
AJAX
I know. Never did that before. I need to know how to do it.
JSON Patcher Proxy for the client side object, uses latest ES6? object proxy features [https://github.com/Palindrom/JSONPatcherProxy](https://github.com/Palindrom/JSONPatcherProxy) Controller Side, This is the general flow of the method and uses the JSONPatch nuget package to do some of the tougher work. `public async Task&lt;IActionResult&gt; PatchPerson([FromRoute] long id,[FromBody] JsonPatchDocument&lt;Models.Api.Person&gt; model)` `{` `var persons = await _peopleService.GetPerson(User, id);` `if (persons == null)` `{` `return BadRequest();` `}` `var mergedModel = Map(persons); //Maps the Server Layer Model to the API Model` `model.ApplyTo(mergedModel); //applies the JSON Patch to the API Model` `persons.FirstName = mergedModel.Name.First; //These will either be the DB values or updated values from the patch, EF will later do a compare to decide on if this property deserves a place in an update statement` `persons.Occupation = mergedModel.Employment.Occupation;` `persons.Employer = mergedModel.Employment.Employer;` `if (model.Operations.Any(x =&gt; x.OperationType == Microsoft.AspNetCore.JsonPatch.Operations.OperationType.Replace` `&amp;&amp; x.path.StartsWith($"/{nameof(Models.Api.Person.Addresses)}", StringComparison.OrdinalIgnoreCase)))` `{` [`persons.Address.City`](https://persons.Address.City) `= mergedModel.Addresses[0].City;` `persons.Address.State = mergedModel.Addresses[0].StateProvinceAbbreviation;` `persons.Address.PostalCode = mergedModel.Addresses[0].PostalCode;` `}` `var newPerson = await _peopleService.UpdatePerson(User, persons);` `return Ok(Map(newPerson));` `}`
While it's not extremely difficult to get started, there is definitely a learning curve involved, especially with Filebeat and Logstash, since there is configuration files used for both. However, there's a bunch of really good documentation and tutorials online that can get you started. The most beneficial aspect of the ELK stack is that once you have it going, it's extremely scalable. 
Have you gone through the links on the blazor site? [https://blazor.net/community.html](https://blazor.net/community.html) There are some example sites there and some of the links link to more examples.
Using token auth does not enable XSS attacks. If you are vulnerable to XSS attacks, then the problem lies elsewhere. Sure, XSS vulnerabilities might be exploited to leak tokens, but that's not the fault of the token auth. If you naively switch to cookie auth, then you just opened up your API to XSRF attacks.
Yes, using tokens does not enable XSS. But using cookies also does not enable CSRF. CSRF is only a problem if the client is a browser. Also, the way you mitigate CSRF is different depending on what framework you use (for example Angular has the HttpClientXsrfModule). It would've been better if the article had mentioned this. I'll update it when I have time.
That will be useful to me. While I of course use REST for public APIs, I find that WCF is better for internal admin tools. Especially when I setup a two-way connection and events flow from the website directly to the admin tool without the need for a message queue or service bus infrastructure.
There's a bunch of examples by just searching: &gt;blazor example site:github.com In Google. The first link is a "real world" example: [https://github.com/torhovland/blazor-realworld-example-app](https://github.com/torhovland/blazor-realworld-example-app)
Well I don't think WCF/SOAP is better for anything. But sometimes you have to interoperate.
So exceptions are special in that they should only be logged on the top level, when all other classes have failed to handle them. This is pretty much the only area that I agree that logging can be integrated into the classes, as there must be a way to log what couldn't be handled. What else? You log what you would need in order to recreate the test when needed, or extra info. There are various logging levels, you can log to different levels. So for my Logger.Debug, it should be logging all the parameters to create a unit test. I have also added Logger.Info for my QA. For example, when someone starts up a new connection, my ConnectionLogger will Debug log that "Start" was called, and it was going to attempt to make a connection with X parameters, ip addresses, etc. The info would contain what kind of system it might be (Order service), etc. One thing to remember is if information is missing, you can easily add it, there is only one spot to add it. Also, I sometimes log the result. So if there is a return value, I might say: &gt;LogMsg1: Calling Function with parameters [1], [Jeff] &gt;LogMsg2: result was [True] This way I can see what was called, and what the return value was. This can help debug time. &gt;User actions This can be useful, but generally not. At least not if all that is logged is, "user pressed Action"...we need to know in what context, for what purpose. "User pressed Action to create someone with the name [Jeff]". We need to know more. What if instead of Jeff, it had a special character in it that the system didn't accept. Now you know from logging what the user entered and how it failed. How Granular, this is a call on what is needed. I generally shoot for lighter, and as needed I improve it. For example, I once started logging when a connection went up or down. That was useful. Then I started making it so when the connection went up, extra logging was done to say what the connection could do (our program had variable abilities are each connection and part of that connection setup was telling our server what the endpoint could do). So we would log, "Connection made to Endpoint [Awesome], which can run [ProcessA], [ProcessC], [ProcessY]." This allowed testers to see that the information was given back correctly, and that they had it setup correctly. &gt;Do you log communication with external APIs? Not sure if I fully get this, but log where you think there could be trouble (generally your processing domain), and log the results. So a quick recap on where to log.. 2 places. First place is at the top most level, the web service / UI / etc. This will log any unhandled exceptions. Additional logging should be done in wrappers. Maybe the wrappers could be called observers. You can also observe when events are fired, logging that the event happened and what the data is being passed around. 
Man I just implemented IdentityServer4 in a project. Its a fantastic framework for building your own OAuth + Identity Provider, but it is NOT simple to do. They have a lot of documentation, and its not BAD documentation, but there are some major missing pieces and tutorials needed that need to be filled in with blog posts, StackOverflow, GitHub issues, etc. Auth and identity is a surprisingly complicated topic nowadays... This is a good basic intro to writing your own much smaller system for embedded purposes. I think you need to tackle refresh tokens though.
I'm using identity server too for our web application and it's great. Because I'm using Ionic for our mobile app so JWT is a great way for authorisation as we could hook it into .net Core's startup.
Not so keen on having to inject it into pretty much *every* class, any alternatives?
I have actually personally struggled with a good way to do logging for a while. Since moving to core, nothing seemed clean and easy. Not from a perspective of how to log (Serilog, log4net, etc are more or less the same for me) but where to log. I am on Azure and I admit I still haven't tried application insights, which seems to be a sin in some parts, but the other options I have tried feels like it's too homegrown to get a production ready solution. Logging to a file feels brittle and worrisome when it comes to format. A database has some obvious concerns around connection potential problems, but even then to be easily read in output feels like building a new application. Can't help but feel there is a niche outthere for an opensource all in one solution that runs as a stand alone app, taking logging over http calls with a file writing fallback or concurrent. 
I've never encountered a .net library that does this, but i have worked with Neo4j. I'm not sure if a graph database would help you, but i found its query language, cypher, incredibly powerful. Just a suggestion.
That looks cool. It's not something I can use for this project, but good to know. Thanks! :)
I have one I wrote recently: [https://github.com/antiduh/Graph](https://github.com/antiduh/Graph)
I suggest staying away from ASP.Net Core amd EF Core for now. There are a few obstacles still that the non-Core variants do not suffer from. Given their age, the non-Core variants also have more historical communication (StackOverflow answers, blog posts, ...) which will be a big help to get started. ------ So let's assume you move to EF and ASP.Net MVC. As to displaying data, you first need to pick your approach, Database First or Code First. In Database First, you create the database and EF generates your C# classes based on your database. I sugges you do not use this unless you (a) have a hard-on for doing things yourself in SQL or (b) are dealing with a legacy project with an existing databse you don't want to touch. In Code First, youbcreate the C# classes and EF generates the database based on the C# classes. This is the approach you should favor if the earlier mentioned points do not apply to you. I sugfest yiu find a tutorial online to help you set up your EF configuration. It hinges on a few environmental things/preferred approaches that are too broad to delve into here. ----- As for ASP.Net MVC, if you want basic access to your entities, you can quickly generate controller with a base template for CRUD operations on your EF data context. It's not a beacon of good practice, but it is very quick to set up and see progress. There are also finer points here that you should look up in a tutorial. REST API, MVC views, properly separating EF from your MVC project, ... But they are more advanced steps after you've built your first working version. ----- I do think it's relecant to mention that web development, especially starting from scratch, is a bit slower than developing WPF. This is because WPF is a single application that bundles everything from the UI up to the database connector. In MVC, you are forced to separate your UI (web page) from your actual logic (web service). That means having to define a data exchange between the two. In a professional context, it doesn't matter. Good practice dictates separating concerns anyway. But for a quick and dirty home project, MVC forces you into good (better) practice right from the start.
I have a project where I have a db table of values (like your 'Status' one) and have an enum mapped from it. On one hand I hate that I did it, and on the other, it's been helpful. If you're absolutely certain you want to do that, then use a Text Template (.tt). It rebuilds on compile, which also means I have to make sure my local db is completely synched up with the production db table values. Search for "xxx" to replace with your own values. Left some samples in where you can customize the resulting enum a bit. &lt;#@ template debug="false" hostspecific="true" language="C#" #&gt; &lt;#@ assembly name="System.Core" #&gt; &lt;#@ assembly name="System.Configuration" #&gt; &lt;#@ assembly name="System.Data" #&gt; &lt;#@ assembly name="System.Data.Entity" #&gt; &lt;#@ assembly name="System.IO" #&gt; &lt;#@ assembly name="System.Web" #&gt; &lt;#@ assembly name="System.ComponentModel" #&gt; &lt;#@ import namespace="System.Configuration" #&gt; &lt;#@ import namespace="System.Data" #&gt; &lt;#@ import namespace="System.Data.Entity" #&gt; &lt;#@ import namespace="System.Data.SqlClient" #&gt; &lt;#@ import namespace="System.Linq" #&gt; &lt;#@ import namespace="System.IO" #&gt; &lt;#@ import namespace="System.Text" #&gt; &lt;#@ import namespace="System.Web" #&gt; &lt;#@ import namespace="System.ComponentModel" #&gt; &lt;#@ import namespace="System.Text.RegularExpressions" #&gt; &lt;#@ import namespace="System.Collections.Generic" #&gt; &lt;#@ output extension=".cs" #&gt; using System.ComponentModel; &lt;# // Connection info ServerName = "xxx"; DatabaseName = "xxx"; // List of entities to create enums for entities.Add(new Entity {Name="NewsTypes", TextColumn="NewsTypeName", ValueColumn="NewsTypeID", DescColumn="NewsTypeName"}); entities.Add(new Entity {Name="Categories", TextColumn="CategoryName", ValueColumn="CategoryID", DescColumn="CategoryName", NewName = "ProductCategories"}); // Add a namespace around the generated enums (could be added directly to the template as well) WriteLine(""); WriteLine("namespace xxx"); WriteLine("{"); // Generate enums foreach(var entity in entities) { #&gt; // Pulls from &lt;#= entity.Name #&gt; Table in the &lt;#= DatabaseName #&gt; Database on &lt;#= ServerName #&gt; public enum &lt;#= ParseEntityField(string.IsNullOrEmpty(entity.NewName) ? entity.Name : entity.NewName) #&gt; { &lt;# CreateEnum(entity); #&gt; } &lt;# } // Namespace closing brace WriteLine("}"); #&gt; &lt;#+ // Class Feature Block (#+) avoids repeating common code private string ServerName; private string DatabaseName; private struct Entity { public string Name; public string TextColumn; public string ValueColumn; public string DescColumn; public string NewName; } private List&lt;Entity&gt; entities = new List&lt;Entity&gt;(); private string CreateConnectionString() { var sb = new SqlConnectionStringBuilder(); sb.DataSource = ServerName; sb.InitialCatalog = DatabaseName; sb.IntegratedSecurity = false; sb.UserID = "xxx"; sb.Password = "xxx"; return sb.ConnectionString; } private string ParseEntityField(string name) { // Remove the dot, left bracket, right bracket, space // and slash characters from the fieldname. var pattern = @"[\&amp;\.\[\]\s/-]*"; var regex = new Regex(pattern, RegexOptions.None); return regex.Replace(name.Replace("®",""), string.Empty).Trim(); } private void CreateEnum(Entity e) { using(var con = new SqlConnection(CreateConnectionString())) { var cmd = con.CreateCommand(); var sql = string.Format("SELECT {0} as txt, {1} as val, {2} as descr FROM {3} ORDER BY {0}", e.TextColumn, e.ValueColumn, string.IsNullOrEmpty(e.DescColumn) ? "1" : e.DescColumn, e.Name); if(e.NewName == "ProductCategories") { sql = string.Format("SELECT {0} as txt, {1} as val, {2} as descr, FamilyID FROM {3} ORDER BY {0}", e.TextColumn, e.ValueColumn, string.IsNullOrEmpty(e.DescColumn) ? "1" : e.DescColumn, e.Name); } cmd.CommandText = sql; con.Open(); using(var rdr = cmd.ExecuteReader()) { PushIndent("\t"); while (rdr.Read()) { if(e.NewName == "ProductCategories" &amp;&amp; !string.IsNullOrEmpty(rdr["FamilyID"].ToString())) { WriteLine(" [Description(\"" + rdr["descr"].ToString() + "\")]"); WriteLine(" [Family(" + rdr["FamilyID"].ToString() + ")]"); } else if(!string.IsNullOrEmpty(e.DescColumn)) { WriteLine(" [Description(\"" + rdr["descr"].ToString() + "\")]"); } var option = string.Format(" {0} = {1},", ParseEntityField(rdr["txt"].ToString()), rdr["val"].ToString()); WriteLine(option); } PopIndent(); } } } #&gt;
Shameless plug; i wrote this ... https://github.com/tinyioda/Randify
Also, always use firefox when dealing in blazor. It's at least 10x faster than chrome and edge 
EF will automatically handle this for you. If your class has a Status StatusId property, you don't have to do anything more. You can override the column name easily if you'd rather have the property be named Status. 
I'm also looking for this. A smart digraph implementation would help with event driven formula recalculation. Fundamental enough that MS should provide it IMO
Graph# isn't actually a graph library, is it? I was thinking that it was more like a graph algorithms package built on top of QuickGraph. QuickGraph is the only option I'm familiar with.
You know, something I did once was a logger wrapper that took in a database context as well that would look at a low of data for if logging was enabled for that specific object (say a network connection). This allows you to change logging on the fly by just changing the database. For example, say connectionOne is giving trouble, you can turn on logging in the database, recreate the connection and the factory will inject the logging wrapper. The rest of your system doesn't care, or know about it. That way you can turn on logging when it is a problem, but turn it off (thus getting more speed) when you don't need it. 
Just use the appropriate enum in your EF model, the rest is automagic: public enum Status { Submitted, Accepted, Complete } public class Ticket { public Guid Id { get; set; } public string Description { get; set; } public Status Status { get; set; } } 
Serilog. DI injected. I log to Seq.
Ok I get it now. That js patch library looks awesome. I may try to find or build something like that for my .net client.
.NET has almost a dozen different languages that run on it, including C#, F#, Visual Basic, Boo, Python, PHP, several shell and build languages, and C++. Most of what you said about the JVM has happened with the CLR, but the results are less popular because C# is a good language that has continued to evolve.
 I totally disagree about staying away from ASP.NET Core. Most of the people I see saying it's too new have never used it, think 2.1 is no different from 1.0, or like to complain about things that are different about it compared to old MVC. Given the age of the older full framework, you're almost guaranteed to learn bad/outdated practices or have a lot harder time using modern coding standards. EF Core sucks but why even use entity framework on the full framework since it's not great there either? Just reuse your existing database code. Learn EF later if you feel like making this harder on yourself. Take a look at dapper if you want an easier to use ORM. 
Isn't it better to do something with injecting an IEnumerable&lt;IInterface&gt; and having someone of picking that in code (factory is an example) with strong type support rather than argument names. The awareness of argument name con is just so bad IMO that I wouldn't even consider this a valid approach.
Have you tried using dot language ? https://www.graphviz.org/pdf/dotguide.pdf 
/u/Merad shows how to do code-first, try that in a test to see how the column is generated (hint: it's an ``int``). So if you just add the column, generate the model, update the model to your ``enum``. Side note: I like to practice the following for any ``enum`` I use as a column in the database. public enum Status { Submitted = 0, Accepted = 1, Complete = 2 } and of course, never change the values to keep data integrity.
Use the following guidance as a workaround: Add “NETWORK SERVICE” to the local Administrators group. --- That sounds bad.
Did you check Device Manager for the WiFi device to make sure power saving is turned off under Power Management tab?
Did you guys all know that span&lt;t&gt; is a new thing?
Ugh one my clients has burned days chasing this down. Glad to see it’s recognized and getting fixed 
Not really - it already "has more access to resources and objects than members of the Users group", so if somehow the service were compromised it could already do more harm than a standard user account anyways.
Thanks for reading and stating your opinion! In the case of same interface requested in the same constructor, if you want strongly typed differentiation you'll need a way to avoid concrete types or else you'll ruin the show. Moreover those kind of factories would be in a purgatorial state, not really startup logic and not really app logic, yet tying them together. Weigh in the complexity associated with it and the argument names don't seem that bad. They are an intrinsic "label" in the language already.
I use quickgraph frequently. It's a solid choice.
You’ll probably want to understand the need for interfaces and dependency injection before you get too deep into unit tests. Look into SOLID programming principles https://en.m.wikipedia.org/wiki/SOLID_(object-oriented_design) Don’t unit test your database Do create a service or business logic layer between your MVC controllers and your EF database. This is the first place you’ll want to start applying unit tests to verify your logic is working as intended
Non-Mobile link: https://en.wikipedia.org/wiki/SOLID_(object-oriented_design) *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^202633
Are there any .NET devs actually still using knockout?
Factory! I was annoyed with the article, it doesn't actually describe the problems it claims people struggle with but offers a really horrible solution to a problem we don't have. Just use a factory. Don't have magic strings ffs. This is literally why we can't have nice things.
Look I’ve always pushed for Vue but what can you do...
Yes, I wrote a SPA I'm knockout: https://github.com/Sebazzz/financial-app In addition, at work we use it as our main library to add interactivity to pages.
I wrote a library called Rivers that allows you to do exactly this. It has support for both directed and undirected graphs, as well as several search algorithms and import/export to dot files. The library is inspired by networkx, the graphing library in Python. You might be interested in it. https://github.com/Washi1337/Rivers In the readme there is also a quick starters guide.
We spent a day chasing this issue down in one of our applications too, super annoying.
Your post has been removed. Self promotion posts are not allowed.
&gt; https://github.com/tinyioda/Randify Really, that much?
As it stands right now firefox is the best at handling web assembly. I'm sure all browser vendors will put more effort in their interpreters as projects like blazor become more popular
Well the database should have unit tests, but separate from the others. tsqlt can used or if using ssdt for the database that has unit test functionality as well. 
I think it's funny how things on my "need to learn this" list fall out of relevance before I ever get around to it.
Honestly go with Vue, knockout has a number of problems with it in comparison to modern javascript frameworks.
Go on, just state the obvious. I'll just, umm, check that now... 
Yep. Works great. 
Raw jQuery 4 ever
I wish I could feel sorry for you
I hope so! Good luck!
I just started a job with contractors for a branch of the US military still on IE 11 and they use knockout. I was considering researching what it would take to get Angular working with ES5 because my coworkers are open to that. They can't be on Windows 7 / IE 11 too much longer with 7 End of Life coming in 2 years. 
I would strongly recommend going through some of the tutorials on the Microsoft Docs. They're pretty straightforward and explain what they do as they do it.
I'm not really concerned with JS frameworks. But I probably would go with Vue or React if I had need to use one. I use ASP.NET MVC at work and .NET Core Razor Pages at home. I'm hoping Blazor makes it to production, and I'll probably switch to that.
Where's the post? :)
Made the post in markdown, but somehow it didn't include my link :/ Thx for letting me know :D
Why not Vue? It's tooling (vue-cli) sets up Babel and Webpack so it works on IE11 without any effort.
I like Vue, too. I'll have to spend some time evaluating my options. 
Yep. I've pushed for Vue, but the team is like, "Angular is more popular and will last longer!" So that'll most likely be what we use if and when we get the chance to start migration. /sigh
Could this be the reason why the COM server I tried to implement in the past 2 days, following [this example](https://docs.microsoft.com/en-us/windows/uwp/design/shell/tiles-and-notifications/send-local-toast-desktop#step-4-implement-the-activator), did not work?
MaxLength was added to Entry in Xamarin Forms 3.1.
Well, I think I have a pretty good grasp on Interfaces and DI. Interfaces let you supply an object that has the same methods as another object but has a different implementation of those methods, right? And DI (in my mind) makes testing possible because you can supply fake external dependencies. I'm just confused as to what I should be testing and more how to logically group my code. Let me give you an example. Let's say I'm Adding a Movie to my database, but I also have a Log table in my database. [BindProperty] public Movie Movie { get; set; } // Controller/PageModel Method Public OnPostAsync() { var log = new Log(); log.Message = "VB-McGee added a movie."; // this would usually be in the ctor log.DateTime = DateTime.Now; _context.Movies.Add(Movie); _context.Logs.Add(log); await _context.SaveChangesAsync(); } Sometimes this is essentially all the logic I have. Is my app too simple to be unit tested? There are business rules I have to enforce, but could that be moved into a service layer so then I only have to call it like // Controller/PageModel Method Public OnPostAsync() { await _movieService.AddMovieAsync(Movie); } // Movie Service Method public async Task AddMovieAsync(Movie movie) { var log = new Log(); log.Message = "VB-McGee added a movie."; log.DateTime = DateTime.Now; _context.Movies.Add(movie); _context.Logs.Add(log); await _context.SaveChangesAsync(); } How would I go about testing the service method? Thanks for your reply and sorry I went to bed shortly after posting.
Your tests are not useless, just because they're working. Progress step by step, your unit tests must have test cases for your to simulate, so if they passed means your code is working as intended. Sometimes, the bugs will only crop up during other phases of the project, like staging, or in production. As long as you coded it modular enough and its robust, you could fix it quick and deploy the fixes fast. EF Core is a great, great tool to help devs shorten the development time require, the methodology you use and adopt might not be the same as the other authors, if it is working and passed your requirement, then that should be your primary concern. For best practices and such, you can take your free time to read up and know more by subscribing to Microsoft's resources, reddit, social media, etc, etc. You'd be surprised larger applications are not much of a difference from smaller applications, because after all, they too are made up many, many smaller components. Over time, as you can do a small application and component well enough and be very skillful, the big applications will also be a walk in the park.
You left out your constructor, but I'm assuming it's like this: private readonly AppDbContext _context; public IndexModel(AppDbContext myAppContext) { _context = myAppContext; } Now you can use a Mocking framework to supply a "fake" DbContext. Using a mock context, rather than a live db connection in this instance you could test if `ModelState.IsValid` is firing correctly according to your business rules. Does the `Movie` have name, release year, rating, etc. Some other logic you might want to add in this instance is checking if a movie with that name already in the database. I would add this at the Service Layer, rather in the Page so if I ever need to use that logic somewhere else, it's centralized. You would test the service method in about the same way. Pass all your dependencies in the Constructor using DI, so when you're wiring up your tests you can supply Mocked up version where necessary. I would also recommend moving your logger into a separate object, and supplying that via DI. Check out [ILogger](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/logging/?view=aspnetcore-2.1). This will give you more flexibility in how you store debugging info, errors, etc. You might want to move those into your event log, or a separate logging framework in the future, rather than tying it directly into your main database. Let me know if any of this is still confusing and I can try to add more detail, or DM me with more specific code and I can make specific recommendations.
Cool idea :-) What's up with the url? https://builtwithdot.net/2/all/all/all/all/all/true That's a whole lot of "all" :-) 
This is a great post for people unfamiliar but interested in websockets. Length and content are good. I only have a couple suggestions. It could use some links to websockets/SignalR documentation or tutorials for people who want to learn more. Also, it might be worth mentioning that people don't \*have\* to use SignalR to use websockets in .NET Core and in the browser. Another use case for websockets is screen sharing/remote control. I made something a while back for that purpose, in case you were interested in checking out. [https://github.com/Jay-Rad/InstaTech\_Server](https://github.com/Jay-Rad/InstaTech_Server) Oh, and document collaboration. [https://ourdocs.lucent.rocks](https://ourdocs.lucent.rocks) (I need to open-source this. Keep forgetting/putting it off.)
_(Caveat to my comment: I have no hands-on experience with Database First, but I have been using Code First extensively for the last 6 years.)_ You're not the first to say it, but I really can't get behind the idea that Entity Framework is making things harder. It simplifies data storage so much. If you want extensive configurability, of course you shouldn't rely on a framework that's built to do everything for you with minimal configuration. But that's exactly where EF shines: normal data storage which isn't squeezing for performance and where you mostly just want to avoid the repetitive hum drum of writing trivial in/out methods. Note that OP is asking for a _quick and simple setup_, which is exactly where EF is useful. EF isn't a bad tool, it's just a bad fit for the job you expect it to handle.
Use interceptors. You hook them up with the interface a class is using and you can set it up to automatically log things when calls are made to that interface. Avoids putting logging logic inside of your business logic. https://autofaccn.readthedocs.io/en/latest/advanced/interceptors.html
I don't know that I'd agree with it being a lot more work. You essentially hook up your logs and then just call .Log() on whatever you want. Seemed pretty fast for us anyway. Was a little slower when we switched to using interceptors because we were figuring that out.
This has not been a good month for Windows Uodates... there was another update that caused problems with TCP services not being able to stop. https://forums.iis.net/t/1239061.aspx?IISRESET+results+in+W3SVC+stuck+in+stopping+status+after+July+2018+patches
Thx for the awesome ideas. Will add links and add your suggestions :) 
Not at all. If I read this correctly, it sounds like this WebAPI that your application is pulling from is your data source. It's no different than connecting to a database to pull data, run some functions on, then serve via your own API.
No question is truly stupid, we're all at different levels in different technologies :) It's perfectly reasonable to use one service as a facade for several other services. Forget it's a web api for a second, if you had a bit of code that looked like: var a = GetKittens(); var b = GetPuppies(); var c = UnionAllCuteness(a,b); return c; If you found yourself writing that more than once, you'd put it in a method. It wraps it all up and gives you all the cuteness you need simply by calling: var c = AllTheCuteness(); What you're proposing is the distributed version of the above. One service coordinates the work of several other services and provides a simplified API for it. 
I don't see why not. In a microservice architecture this is in fact common. You're paying a bit for HTTP/S overhead so if you needed to process a very large number of requests per second you may choke and need to think harder about how those systems work together. The other trick may be signalling. If API A is calling API B to get data, how does API A know when API B's data has changed? This leads into other patterns like pub sub/eventing. 
I enjoyed this. 
Yep, that's what my constructor looks like. I think I'm getting the hang of it. I wrote these 3 tests after reading your responses. [Fact] public async Task AddMovieAsync_AddsAMovie() { var movie = new Movie(){ ID = 1, Title = "Oculus"}; var context = new MovieChooserContext(Utilities.TestDbContextOptions()); var movieService = new MovieService(context); await movieService.AddMovieAsync(movie); Assert.NotEmpty(context.Movies); Assert.NotNull(context.Movies.FindAsync(movie.ID)); } [Fact] public async Task AddMovieAsync_AddsALog() { var movie = new Movie(){ ID = 1, Title = "Oculus"}; var context = new MovieChooserContext(Utilities.TestDbContextOptions()); var movieService = new MovieService(context); await movieService.AddMovieAsync(movie); Assert.NotEmpty(context.Logs); } [Fact] public void DbContext_IsEmpty_WhenNoMovieAdded() { var context = new MovieChooserContext(Utilities.TestDbContextOptions()); Assert.Empty(context.Logs); Assert.Empty(context.Movies); } You've been a huge help to me. I think it clicked, at least to the point where I understand that I need to move things out of my controller/page models. I think I can keep improving from here. I've really psyched myself out and perhaps overcomplicated everything. But hey, if it was easy, everybody would do it. I just need to KISS. Thanks again friend.
I think you’re headed in the right direction. I like to add _ReturnsTrue (or False) so it’s kind of “self documenting” on how the tests should work.
It is actually common to call one API from another whether they be web APIs or other type. One thing to consider, however, is performance. If you can bypass a hop you get a big performance boost. By chance if the APIs are your own and you can bypass a http call and read/write directly to your database you can get a big performance boost. See [this article](https://github.com/leaderanalytics/adaptiveclient) on how to structure your services such that you can call them in-process and/or via a WebAPI call.
Thank you :) means a lot to me.
It isn't a bad idea, but it comes with tradeoffs if there are real-time requirements when using the secondary service. If caching can be utilized, then it is fine to do, assuming the additional risk of depending on an HTTP call is acceptable.
Very reasonable. This is how many microservices operate 
Very common and perfectly acceptable. We do it all the time when we're aggregating services into a single wrapper.
It is fine. You should see the rabbit hole that code can travel down from one api controller method. One post can hit about 10 different APIs / WCF calls to both internal services and APIs hosted by vendors we work with. Just thinking about the web of API calls that call other APIs is really scary, yet awesome at the same time.
But as you scale to have multiple applications calling into a datasource in this who owns the datasource and how do you manage concurrency problems. I would actually steer people away from the bad habbit of sharing a database between multiple applications and have treat each datasource as it's own service. Let the service address some of the concurrency concerns and create and aggregate for that service. Look at domain driven designs and microservices as to what problems are solved and why sharing datasource is actual a bad idea long term
+1 for the cuteness
Most systems won't have this scaling issue. Just stick to good database indexing and data caching.
This is a totally valid use case. Since you mentioned the web API you're relying on changes, this serves as a great way to abstract that service's API and contracts into your own. This enables you to keep all applications/services that use your service to keep behaving exactly as they were written with your data, and then your abstraction API becomes the only place where changes need to be implemented if that other API changes! Woohoo for fewer code changes! Edit: typo, clarification
Concurrency issues is mostly what a minor service design. 
Of course not, Web API is just another way of transferring data. You can't call a person stupid just because he prefers driving a Porsche rather than a Mercedes.
True, there might be some use cases for it, but it isn't quick or easy unless you already know how to use it.
I don't understand how all these added complexities improves resiliency. It just makes a bigger surface of things that can go wrong.
That was educational, and we only post educational content. let me know i won't post again
I did it a month ago using the angular upgrade guide: https://update.angular.io 
It's just so easy using EF in a WPF application. Just a few clicks I have my database connection setup and I can start querying the desired tables using Linq. Such a breeze and and so much easier and faster than setting up the connection manually. So far working with EF Core it seems like a huge step back in time. I simply cannot get the connection setup so I can use Linq on my data. It should be possible following the Ms tutorial but am I approaching this wrong?
My buddy is working on this. He said the Visual Studio templates are out of date garbage and you need to use the command line templates.
Only 'gotcha' I can think of is wanting to be cautious of the source API's potential usage limits and/or rate limits. :)
I use it on daily basis, unfortunately.
This is partly what annoys mr about microservices. A guy I work with used them for everything and all I see is a ton of overhead which means although it's scalable etc it now needs a fairly hefty server to run it all without load! Then you Chuck it on azure or AWS and boom, money burner. They are a valid approach but I could have done his project with a few smaller bespoke projects in less time and cost (project and ongoing) Rant over. But yes you are right :)
New job? :D
the last version of the template is using Angular v6: [package.json](https://github.com/aspnet/Templating/blob/master/src/Microsoft.DotNet.Web.Spa.ProjectTemplates/content/Angular-CSharp/ClientApp/package.json)
I will bet that you are in a foggy path. You should not search how to "integrate" Angular with ASP.NET because... There is none. Angular is front end framework to create client applications. If you want to create a app using the state of art technology for front end, just study and learn Angular 6 by itself, regardless what you're going to have as backend. The same for backend, learn ASP.NET Core, then read the release notes for latest version - 2.1 today - and create a master piece backend service with it. About they together? They will "talk" each other via HTTP calls. This will be the same for any technologies involved - Angular, React, ASP.NET, Node.Js, others. So, split your training tasks, search for the best study material for each one, and Rock it! 
I’m doing some work with Angular 6 and .NET Core atm and my recommendation is to split them up. If you need an ASP.NET Core API and an Angular app, make them two separate projects in the solution. I’ve personally found that the template is not really ideal, personally.
When you think about it, the database itself has no idea what application is calling it. It just sees a request from a user. So sharing a database between apps just adds users. Microservices is just a way of taking a bad design, making it smaller, and making multiple copies. Microservices solves nothing unless the root problem is also addressed. Making copies of data only adds to your problem - how do you keep the copies in sync.
I'm not sure about the error code and am on the go at the moment, but I just wanted to stick my head in and tell you that `launch.json` and `tasks.json` are artifacts of VS Code, not .NET Core - it's still possible that the problem is due to a difference your .NET Core versions, but if you're both using VS Code and your `launch.json` and `tasks.json` version numbers are the same as the instructors, they should be functioning identically, which to me would suggest that the problem is somewhere in Coreland. I'll try to come back when I get a sec, but just wanted to let you know which files belong to which for the purposes of troubleshooting. I'd also try running the commands you're expecting launch and tasks to run in a command prompt to see if the same issue happens.
Thanks :-). The url parameters are there for filtering. E.g. click “Web app” on one of the cards and you’ll see what I mean.
Available now at: [https://www.youtube.com/watch?v=k8cZUW4MS3I&amp;list=PLVMqA0\_8O85x-aurj1KphxUeWTeTlYkGM](https://www.youtube.com/watch?v=k8cZUW4MS3I&amp;list=PLVMqA0_8O85x-aurj1KphxUeWTeTlYkGM)
The videos from this event are available at: [https://www.youtube.com/watch?v=k8cZUW4MS3I&amp;list=PLVMqA0\_8O85x-aurj1KphxUeWTeTlYkGM](https://www.youtube.com/watch?v=k8cZUW4MS3I&amp;list=PLVMqA0_8O85x-aurj1KphxUeWTeTlYkGM)
That makes sense now that you mention it. This is really more of a VS Code problem than a .net Core problem I think. The problem is that I don't have the same versions as the instructor, he's on Core 1.0 and I'm on 2.1 (and im not even sure what his version of VS Code is) and I do see some differences in the tasks.json file such as his contains "isBuildCommand": true, while that wasn't in the file that my VS Code generated. It turns out that I can build both files correctly from the terminal so I must just have something wrong in my VS Code json configuration.
It improves resilience on one component, by multiplying that said complexity by a factor of 3, and then dividing it into 6 service, each being only half as complex as the original service! Or go more wild and think of 60 services , each having only 0,05% the complexity of the original service !!!!
thanks for the info.
I tried that with the Angular 4 template and it wouldn't build. I'm not sure sure how to use the template on GitHub.
I am not in anyway suggesting you make copies of the data, having the same data in multiple places is an issue. But how you address issues like 2 applications writing to the same database at the same time. If the transaction from 2 disparate programs is formed just right at the same time dead locks can occur with the application hanging while the DB transaction is waiting in a locked state. You wouldn't make copies of data with a proper domain driven designs analysis. If you have copies you haven't don the design properly.
Again, I strongly disagree. You're assuming a situation where you know nothing of EF but know everything of SQL or Dapper. That's not a fair comparison. Assuming you know nothing of any ORM or data storage method whatsoever, but know C# (since you're need that knowledge in all three cases anyway), EF Code First requires the least learning. *Note: With obviously required C# knowledge, I am also omitting the class with the properties and the connection string, as those are necessary with or without EF. So they don't count as "needed to use EF".* Getting a basic table up and running with EF (edit: Code First) requires nothing more than a single DbSet&lt;Foo&gt; declaration in a derived DbContext. Done. No language other than C# needed. From that point on, it's simply a matter of tweaking the finer points that you care about. The effort required is highly dependent on how fine you want to control the behavior, as is the case with all things.
&gt; But how you address issues like 2 applications writing to the same database at the same time. The database does not know if a request is coming from app A, or app B, or app C. To the database they are all the same. The question you are really asking is: &gt; But how you address issues like 2 users writing to the same database at the same time. There is a lot of info on this subject you should be able to find something on google. 
That’s really neat! Just took a look at it and there’s some really cool stuff.
If you're scaling stuff you can scale and optimize for the stuff that is actually the bottleneck. A login service might have different characteristics than a billing service. When designing software you need to be a aware that you can easily split things. I often annotate those ideas in the README, where the "dotted lines" (✄ cut here ✄) are in a particular repo. Building a complex microservices structure up front without one paying customer is a bit ridiculous though. Just don't paint yourself in a corner. Offtopic: I've been working with Elixir which is a Erlang based language lately. It's a lot cheaper to do microservices with BEAM. Interprocess communication between nodes is built in as well as process management (restart on fail). That's really neat.
How does this contrast with System.Collections.ConcurrentBag?
Looks neat, I can imagine myself using this as we are doing the .ToArray() on IEnumerables and passing arrays around in many cases to prevent double enumeration, even if we might not need all the values. I have a question, though: why does it need to be IDisposable? Standard thread-safe collections in .NET such as ConcurrentDictionary also contain locks inside and they don't need to be disposed.
I can think of two things: ConcurrentBag will eagerly initialize from IEnumerable, instead of lazily and also order is not guaranteed on enumeration - it does not implement IReadOnlyList.
It is explained in the blog. Any enterprise system is going to have more moving parts to accomplish what seems to be a simple job. That's what we mean when we say "scale" or "it scales well". For example, moving a file from one location to another is simple. We can do that in one line of code, but when you're moving hundreds of millions of files from one location to another on a schedule every day, that one line of code no longer works as well because of the demands on the hardware and hardware is expensive. There are other techniques/patterns to help with this. Patterns like the one shown in the blog help by distributing the load while avoiding any hard inter-dependency. Distributed systems come with other complexities because the fact there are more moving parts and when you try to apply monolithic practices to them, you end up with more than the original complexity, exponentially so. Patterns like this also aid in creating isolation and separation of responsibility. In practice, once you've done it once or twice and get the hang of it, it actually *reduces* the surfaces of things that will *likely* go wrong despite the increase in the surface of participating services. And when you encounter those problems, they will be isolated and relatively easy to find and fix due to the decoupled, agnostic nature of the system. 
And a microservices pattern is one of those solutions.
&gt; If you're scaling stuff you can scale and optimize for the stuff that is actually the bottleneck. Absolutely. This is actually the #1 argument made for the use of microservices as they solve that very problem. &gt;Building a complex microservices structure up front without one paying customer is a bit ridiculous though. Just don't paint yourself in a corner. I absolutely agree, but this isn't about promoting one architectural approach over another, just to be clear. This is about solving one particular problem inside of a microservice architecture which is decoupling hard dependencies between services while also adding some resilience (commands not being lost when services aren't available) through the use of a service bus. I never suggested designing anything like this up front ... unless you already knew that it needed to be designed that way. Writing code that is well abstracted and easily extracted (modular) is simply good engineering within any system architecture. Whether I'm designing a monolithic system or a service oriented system, or microservices, I would expect the same level of separation within each service. &gt;Interprocess communication between nodes is built in as well as process management (restart on fail). That's really neat. For what it's worth, if your microservices are deployed in docker containers, they behave that way by default. You define the spec for the minimum and maximum number of instance you want running and it'll use as many as it needs to get the job done based on the current load. In fact, you can even redeploy the same image (e.g. if you retagged for instance) by simply deleting a pod. It'll detect that it's only 1/2 and redeploy to make it 2/2. When we talk about "resilience" some immediately think of a service being able to recover, but there is more to it like "what happens to the original request if it failed due to some service being unavailable?" -- The issue I was referring to in the blog is not that a service crashed and failed to restart so much as it is about the service ceasing to function. For example a downstream service or 3rd party is offline for some reason, or a bug in the code is preventing the application from recovering or restarting etc. The bus prevents any jobs in flight from being lost. Interprocess communication is a good topic but out of scope of the blog. For conversation sake, we simply use DNS within the Kubernetes cluster for direct service-to-service communication. The bus is were commands and events flow and that offers more resilience in that context.
Just because one part of the system needs to be scaled, doesn't mean that all parts of the system needs to be. "moving millions of files" is a clear case of scaling boundaries but most cases aren't clear. You can go really far with finely tuned database and Redis. 
Not true. There are isomomorphic apps and use cases for such out there. SSR will be easier with Ivy.
&gt;Just because one part of the system needs to be scaled, doesn't mean that all parts of the system needs to be. Yes exactly, and that's one of the greatest things about microservices for large systems. You can indeed go quite a ways with a well oiled data tier. Any time I'm designing "an application" this is my focus. When I know I'm designing an enterprise system, I still put a lot of emphasis on data design, I just do it completely differently. It's just layers of layers of layers of design. All of these approaches stack well with each other. Every one of them.
If you use ado, it works wherever ado is supported (like dotnet core). If you use EF, you can only use EF where it is supported (and actually works) which is less places than ado. Ado, on core or full framework, works pretty much exactly the same everywhere. 
Each service being orders of magnitude LESS complex as a side effect of this architecture is undersold imo. We're at about 30 services and anticipate probably about a hundred by the end of next year.
Agree, this is what I'm doing as well, I'm on .Net core 2.0 and angular 6
This class is a composition around `IEnumerator&lt;T&gt;` and thus must delegate the `IDisposable` implementation on in. 
I'm not sure I agree with your points. At my work we use mostly [ADO.Net](https://ADO.Net) and stored procedures. We unit test our CRUD code. We also have code that calls many 3rd party APIs and WCF services written by vendors and we Unit test all of those as well. We do not use interfaces or DI to do the Unit tests. We had another app that used DI / Interfaces and used mock classes to do Unit Tests. Well, that code was harder to debug and the Unit Tests didn't catch as many bugs. And if there was a production bug we had to start the web application and run the application to debug stuff. In our other application that has Unit Tests using the database and actual APIs (instead of mock classes via interfaces), we can debug code without starting the application. We can also check external APIs and database code without running the application. I understand why some applications use DI and Interfaces and Mock classes to do the Unit Tests but I prefer to not do it that way. I just use a regular instantiated classes and Unit Test them with connections to the database. Everyone should understand interfaces and dependency injection, but never add interfaces and DI just to do Unit Tests. It adds unnecessary complexity and makes debugging more difficult.
Personally, I find Unit Tests to provide the most value when I can debug pieces of code without running the application and keying data in the UI. Please don't add a Service Layer and Dependency Injection just to do Unit Tests. That will add complexity you don't need for little benefit. In order to test the AddMovieAsync Method just make a test class and test method that calls the service. No big deal. You don't need to Unit Test all your code. Write test methods for code that changes often or is brittle.
Definitely do the [Tour of Heroes tutorial](https://angular.io/tutorial). Do all of it, even if you have done it before. This is one of the best tutorials ever for any framework - it should be the poster child of tutorial making. Follow this guide to create your project: https://neelbhatt.com/2018/06/02/create-an-application-with-angular-6-and-net-core-step-by-step-guide/ 
You're completely ignoring the argument I made about requiring SQL knowledge.
Are saying that my entire answer is false, or any specific point?
&gt; I will bet that you are in a foggy path. You should not search how to "integrate" Angular with ASP.NET because... There is none. I've responded to this part.
If you’re not using an ORM like EF, there’s benefit in testing CrUD. It sounds like you were unit testing the wrong things though, or doing it the wrong way if you need to catch them in production. You absolutely want to use mocks rather than a live database. It’s just too hard to test enough scenarios if your test data is persisted. API calls are tricky, but there’s ways to assure they’re interacting with your code correctly. For someone getting started (like OP), I feel like this is overkill. Understand the tests. The why and how. Only then develop a style that meets your environments needs. Tests are sometimes looked at as a religion. They’re just another tool in your toolbox.
I prefer factory approach as it does not assume your collaborators know how the particular DI framework is working... Just need to know basic OOP.
Fair enough. Not to catch them in production, but debug issues without running the application and having to key data.
Makes sense, since this implementation potentially never reaches the end of the enumerable it was initialized with. Otherwise, the enumerator could be disposed automatically after the last element was read.
Hurr durr use ajax and stackoverflow?
report
I mean he's not wrong. 
I'm not in the mood for jokes ok?
Reddit is the place to be then 
Here's a few links on stackoverflow, not sure if you are using Core or just ASP .NET MVC Essentially you need to create partial view that takes some parameters to calculate the amount of pages things like list count, amount to show etc . Hope this helped [https://stackoverflow.com/questions/18822352/using-paging-in-partial-view-asp-net-mvc](https://stackoverflow.com/questions/18822352/using-paging-in-partial-view-asp-net-mvc) [https://stackoverflow.com/questions/45409858/pagination-in-net-core-partialview](https://stackoverflow.com/questions/45409858/pagination-in-net-core-partialview) [https://stackoverflow.com/questions/21094056/paging-on-partial-view](https://stackoverflow.com/questions/21094056/paging-on-partial-view) [https://stackoverflow.com/questions/35332812/add-pagination-to-partial-view-in-asp-net-mvc](https://stackoverflow.com/questions/35332812/add-pagination-to-partial-view-in-asp-net-mvc) [https://stackoverflow.com/questions/18896792/paging-partialview-with-pagedlist](https://stackoverflow.com/questions/18896792/paging-partialview-with-pagedlist)
[removed]
It was pretty funny
[removed]
Hurr, use ajax with request params like page and pageSize, durr Hurr, then in some service/controller/helper/util .Skip(page\*pageSize).Take(pageSize).ToList(), durr
Well but i am guessing you now have to have unit testing and integration tests for 30 services, plus have to monitor those 30 services. Life isn't that much simpler now, is it ?
PluralSight is often recommended as a good resource. I liked it a lot when I got started. Especially the courses on CLR internals and other deep drives were quite good.
Thank you, I believe I have a sub to ps through my school. I'll check in to that.
&gt; an wrap my factory in all the wrappers I want, thus allowing me to inject logging onto objects at creation, but the rest of the system has no idea. Is this the decorator pattern? do you have any links to articles on this way of logging?
That's right. I only had a cursory look last time. It's also looks like a good graph visualization tool similar to \[GraphViz\]([https://www.reddit.com/r/dotnet/comments/90i9f5/any\_recommendations\_for\_a\_good\_graph\_data/e2rgmtx](https://www.reddit.com/r/dotnet/comments/90i9f5/any_recommendations_for_a_good_graph_data/e2rgmtx))
This is the conclusion I'm being drawn to. I currently use ASP.NET MVC and AngularJS 1.6.x and I'm still in this mindset of mixing MVC views and throwing AngularJS on the page. I would like to utilize Razor pages from .Net Core, Identity and the built in security features like anti-forgery tokens to prevent CSRF attacks. I'm not sure how to do this, if it's a good approach or if I just approach this by doing all front-end development in Angular. If I do end up using Angular for all front-end development, I have so many security questions!
I would steer away from AngularJS, pretty much all modern Angular development is being done in Angular 2+ now.
That looks more like it's for visualization.
I will definitely give this a try!
This looks cool. Thanks for sharing. The docs seem more approachable than quick graph. Gonna check it out.
[removed]
Agreed. I currently use AngularJS and am researching how to move my projects to Angular.
definitely seems like a non-trivial task. I guess I lucked out in that I had never done development with AngularJS prior to learning Angular (starting with Angular 5 and then transitioning to Angular 6). The most I've seen on the subject seems to be to basically have two versions in place, one the angularJS stuff and then the version for Angular 2+ and then slowly make the transition by sunsetting modules. Not sure how practical that is if an application gets large in scale though. I know there is a huge difference in the way AngularJS works versus Angular 2+. Good luck on that.
Is there a transcript?
Pluralsight has pretty much everything you need and more in the .Net world of programming (and much more) and the instructors are awesome. 
&gt; You should not search how to "integrate" Angular with ASP.NET because... There is none. Actually there is. First of all, many of us need to learn how to host a SPA inside a ASP.NET or ASP.NET Core application. There are rules about this because the server needs to know when to respond with a sever-side resource and when to respond with "here's the angular app, it fill figure out the rest". Actually, all web servers that deal with Angular need this integration point. Otherwise direct linking with `/` style routes won't work and everything has to be done through `#` style routes. **** Beyond that is how debugging works. In ASP.NET Core it actually launches two servers when in debug mode. The ASP.NET Core receives all communications, but proxies anything dealing with Angular to a separate Node/AngularCLI server. This way you get your AngularCLI dev experience while still supporting REST services in ASP.NET Core.
There are some problems with that. Now you have to deal with cross-site scripting and pay for two web servers instead of one. For a hobby project that needs SSL and a custom domain name, that jumps the prices from 37 to 74/month on Azure. *** But yea, for a professional grade project with an operations team supporting it, two projects is quite nice.
Yeah, for really small projects I would almost just say completely rewrite the modules as it's probably not as intensive as you would think.
That's the point, you don't need to know Angular for that, you need to know how to build SPA app. And it's not because you're developing using Angular your are creating a SPA, there is not such anchor to that. The same for backend, the concerns you raised are regardless technology, about routing and responses. About the debugging part, it's not about integration, that's development environment setup, and not integration between Angular and ASP.NET, afterwards, as I said before, this will be done via http, and that's it. 
It's actually not best practice to have integration tests for microservices (hard to swallow, I know), but we require 80% unit test coverage on most projects, 90% and higher for domain projects. That was the same before this architecture so no change there.
We've got a suite of tools built around Knockout that's not going to change anytime soon, but at this point, it requires only minor maintenance and we're certainly not developing new applications with it. Not sure why anyone would continue to develop with it.
No, the point is that there is a lot more involved than simple how the client and server communicate.
Just curious - when your Angular code makes a request, what tech do you have in place to handle those? Are you using ASP.NET Core, Node or something else?
I have a service in my angular app that initiates REST calls to my .NET API
XSS protection is baked into angular 2+. Host both sites on the same Linux server using docker. Use vultr or linode to host it for $5/m and get free ssl.
I would argue that for Microservices, integration tests are more important that unit testing coverage, but I am not really an expert and I guess its a matter of how someone view things.
You I can use Vue inside your razor pages. Vue is what angularJs should had been.
While I'm happy with the free version of Azure for most things, it doesn't allow you to use SSL with a custom domain name. (You can use SSL with a generic Azure domain name.)
Personally, I think identityserver4 is overkill unless you’re planning on having some massive enterprise grade app that one login can allow access to multiple tenant apps.
I’m telling you not to use azure. Use docker and linux. That’s one of the biggest reasons why core was created - to be hosted on servers not using iis. XSS has nothing to do with CORS. XSS attack is when inputs are filled with scripts that attack your system. Angular 2+ automatically sanitizes all inputs for XSS protection. CORS is allow outside domains to communicate to your app. You still need to handle XSRF to a degree, but you can do that with some custom middleware in your api app.
Linux is software, not a hosting provide. 
I’m not sure if you’re trolling or if there’s no hope...
Small improvement. Give your blog post title that indicates the content. Is this elastic search? SQL? Mongo? Something else? Just so we know if it is something we would like to read :) I am not clicking links that doesn't seem relevant.
Cool idea! I will be there!
Not my blog but will share the feedback with the author.
Something happening in DoThreeStepsFromAbove is not properly cleaning up after itself, and is keeping the program open. You shouldn't have to call End, the program will just end after finishing Sub Main. You'll have to show us more code to help figure it out. 
Actually in Net Core, it is easy to setup a solution with Identity Server, the advantages of it includes the anti forgery token which helps in preventing XSRF attacks. In a non-tedious way, the entire site is protected whether it is small or large organisation. And it's quite important too, small organisations can also have large monetary transactions.
Anti-Forgery protection has been included in .net MVC for years. It's not some new feature with IdentityServer.
Thanks for the clarification. But unless Identity Server incurs noticeable overheads, there is no reason to compare the size of an organisation with its implementation. On contrary, implementing it cuts down development time as most applications require some form of authentication and in today's world, a simple cookie does not cut it anymore. IMHO.
&gt;But unless Identity Server incurs noticeable overheads, there is no reason to compare the size of an organisation with its implementation. I'm not comparing the size of organization - you are. So not sure why you think that? And implementing IS4 does create noticeable overhead. &gt;On contrary, implementing it cuts down development time as most applications require some form of authentication and in today's world, a simple cookie does not cut it anymore. IMHO. Implementing it does not cut down development time - it adds to it. And it becomes silly to do so, especially when most IS4 implementations use Identity. Hence my point - there's no reason to use IS4 when you can just use Identity, unless you are creating a multi-tenancy app. And if you don't want to use cookies with the default identity solution, simply configure it to use JWT's - it's like 3 lines of code to do so in startup.cs. Perhaps you should brush up on auth in .net before you start pushing solutions that you don't quite know the in's and out of?
More work in that with Log4Net and NLog you just install the base package and already have a file appender, console appender, etc. right out of the box. With Serilog you have to go find all the right packages and get them installed, and you even have to figure out which of the five ways to configure it you want to use, etc. Like I said, that IS a better approach as a framework. But it also is more complicated and takes more work to get it setup correctly. Usage is about the same, its the setup piece I'm saying is more involved.
Congrats on finding BASE64 encoding I guess? This has been around since the 90s and USENET.
I don't really agree with that, especially when you are building an application from ground up and not integrating it to an existing one. STOP halfway during typing. Ok, you have it, why, because i mixed up the terms. I am using .net Core Identity, and not Identity Server 4's via OAuth 2.0/OpenId-Connect. So all along I was arguing for Identity and not Identity Server. Thanks man, I learned something new today. 
Oh, and by the way, please do not assume by using sentences like 'javascript'. Having implemented solutions for a bank with millions of microtransactions a month, and also an advanced scheduler for a major airline company, and also scheduling for a Fortune 500 company, i am way pass Javascript. However, in today's world where Node is written on Javascript, we can no longer say 'this isn't javascript'.
Lol, my dude - it's all good. This stuff is confusing, there's no doubt about that.
Is everything really managed by nuget in .Net Core? 
Here's one developer geeky high-five. :D
Oh, was merely using JS as a reference because when something new comes along, the JS community seems to think it's the best and only solution available until the next solutions is created... :)
That wording is confusing. I think he means that you only have one nuget reference to worry about (the asp.net core meta package) instead of having a separate reference to every single like you would in mvc5. You just have to (in theory) update that one reference and you can jump from dotnet 2.1 to 2.2
Why not both? Use which tool you like better and/or are most comfortable with.
Because the class uses a ReaderWriterLockSlim which is also IDisposable.
As in speed?
And BASE64, while many great use cases, is always larger than the file it represents by about 25%. I bet users love a slower web app.
Yep, next step is to look at other encoding types to see how we can get the payload smaller. As a first cut, we were OK with a 25% payload size increase because the files being uploaded were &lt;1MB, and so to the naked eye didn't represent that much of a difference in speed. I think the main thing was trying to get away from using multipart file uploads in a JSON API, which seems to still be pretty prominent. 
Oh ok, that’s cool. Thanks for the info.
“Make it work, make it right, make it fast”.
There is one but it's auto-generated so it might not be perfect.
but generally... yes everything is nuget. this is a good thing, imo. mvc and razor and X can ship at whatecer cadence they want. you can run into issues with versioning, but package restore will balk and throw an error if necessary. 
What alternative encoding can one use on the web that's smaller and performant and standard?
&gt; I think the main thing was trying to get away from using multipart file uploads in a JSON API, which seems to still be pretty prominent Noob here, what's the benefit of getting away from that?
I guess whichever one more people use to create better web apps?
Just found out that Angular also has a way to deal with CSRF attacks. For XSS, I always sanitize user input on the server side. 
https://angular.io/guide/security
I'm using Razor Pages a lot. I've been moving all my WebForms, WebPages and MVC ([asp.net](https://asp.net) and Rails) sites to Razor Pages. It's been fun for me. I don't think I've had this much fun making web sites in a while. I don't like that people call it WebForms 2.0 since "WebForms" carries a negative connotation even if you've never touched WebForms. But I also understand it. Razor Pages can be an attractive framework if you are coming from WebForms. It has a similar feeling when you are making an app, but the guts are more like MVC. Razor Pages is part of MVC. I don't see one as better than the other. They are two equal options of the same dotnet framework. I just prefer Razor Pages if I'm making a site where everything is server side because it's much more straight forward to get something up. If you have ever gotten tired of going through several files and directories to update a page or tripped over badly designed sphagetti routing then Razor Pages could be an alternative. Besides these days a lot of web sites have moved past purely server side MVC because of the rise in JavaScript frameworks and SPAs. In those cases you'd probably use WebAPI (which is also part of MVC) not MVC or Razor Pages.
https://philsturgeon.uk/api/2016/01/04/http-rest-api-file-uploads/
Without base64 encoding: https://dzone.com/articles/how-to-upload-images-to-an-aspnet-core-rest-servic
Out of the box all you need for dev is IIS or iis express und visual studio. You may need activate iis feature in windows. For hosting I would recommend dig into asp dotnet core and using docker - this gives you freedom to use everything that runs docker. 
what about databases? It is integrated in IIS?
Depends on the .Net version the app is written in. If it's a .net core project you can simply spin up docker containers. However for a .net framework type of project you'd need a windows server/workstation with an IIS/IIS express installed.
Oh, no, that is another big Thema. But iirc, visual studio brings 'localstorage' database with it. But you will need to get something better. Depending on what you plan - mongodb, postgre or Ms SQL Server (there are free edition for development) Anyway, I would recommend to use dapper micro orm for data access if you'll go with postgre or mssql and want to be cross-platform. Or entity framework 6(not 7) for Windows Server 
I just got a .zip file with a sql query and some folders with a few .vb and .ashx file, everything else seems to be static stuff like html, css, etc. A part of me is already regretting taking this job lol, but money is money.
That's some really old stuff D: This will be not so pleasant 
Seems like a request handler from webforms times. 
You could start by creating a backend for your games that communicate through an API. For example you could create a leaderboard for your game.
oh god, really?
You could offer the client to rewrite the application either in a newer .NET technology like Core if you are interested in learning something new, otherwise in PHP. I'm sure the client wouldn't care what the site is running on if you can make a case for it. I see Microsoft Azure is available in Brazil, otherwise I'm not aware of any other native Windows host there. Azure is probably not very cheap compared to Linux hosting which might also be a selling point for a rewrite. Setting up the dev environment might be interesting if you don't have the actual source/project files. The Web Service project type (assuming from the .ashx files) is not available in Visual Studio unless you enable some old framework in Windows or something, or you do some ugly shoehorning with a different project type.
Well, the issue is that rewriting the website in PHP means an higher budget needed, because the agreement doesn't cover rewriting it. Originally I was just giving them a consult, in the meanwhile they had an issue with the previous developer and handed me the code to solve the situation. Even with rewriting in PHP, I will need to see what the website looked exactly, since there is absolutely 0 documentation about the features.
Well of course it would cost more and all those other things, but that's a very old project. It will be increasingly difficult to find someone who's willing to maintain it, eventually something will break down. And hosting will probably also become an issue down the line (needing a fully licensed Windows VM instead of just a website host). You tell these to your client and if they will want to stick to what they got is on them. However, can you, in good conscience, take this project on not knowing even how to spin up the site? The learning curve might be equally as expensive as the re-write, depending on the site functionality, granted I don't know the requirements.
Yeah i will talk with the client and see how we can solve this, it's a really big issue
So weird. I never made MVC without razor pages
The .vb files would be Visual Basic, which has been considered outdated for quite some time, even if Microsoft does still support it. One conversation that will always stick with me is when my boss told us a client (for which we maintain a VB6 application) had elected to extend their contract for another two years, to which the responsible developer replied "Ah, that's too bad".
Check if there is some mention of interdev somewhere. If there is, consider suicide instead of working on it.
These will be Visual Basic .NET files, which is not an obsolete language.
Not sure I agree with the approach of using base64 encoding so that you're still working in JSON. You should use the right tool for the right job. There's nothing wrong with having a different content-type for just that route.
This is another case of Microsoft’s shocking inability to name their products without causing major confusion. ”Razor Pages“ is an alternative to mvc. 
no interdev in sight, it seems
&gt; company doesn’t want to spend resources on writing unit testing Whoever made that call is quite simply an idiot. No-one can fit all the possible regressions of a system in their head, and knowledge will disappear with developers leaving, plus full QA'ing takes a long time. Automated tests will protect your company by allowing you to release more quickly and confidently, and also help new developers to understand the system by placing training wheels on them. You don't need a major project to fully test old code, just make a rule that new code needs tests, and try to add tests whenever bugs are fixed. Linting can help a lot, but by far the biggest thing you can do is write some level of unit, integration or e2e tests
Remarkably incompetent article. I don't even know where to start. It seems like the author doesn't even know which part of his codebase is the Model in MVC. He probably uses his entities as view models.
Use StyleCop Analyzers - https://github.com/DotNetAnalyzers/StyleCopAnalyzers If you use something like github, change the repository settings to require code review before commit, and set a reasonable number of reviewers as required. If they don't allow unit testing and don't require code review then there really isn't much you can do. Good software quality needs to be a company priority, not just an engineering priority. Without company buy-in you are doomed to write crappy code at the seat of your pants. 
Visual Basic is still a first class citizen in .NET. It's well supported and being updated.
Writing units tests benefits YOUR productivity. Without unit tests every small change forces you to launch the whole system (no matter how big or small it is), provide manual input and visually/manually check expected output. So, simplest manual test requires at least 30 seconds of your time. In bigger systems it can take minutes just to go through menus and screens to the place where you need click buttons for testing (AND you need to be very accurate, avoiding input mistakes). Unit test execution takes split second and it is repeatable. Don't neglect it.
Well, then at least there is a chance it's not as horrible as some people make it seem. There are some people who prefer VB to C# and both can be used with the newest .NET Framework. It's probably some horrible legacy code though. Still better than Visual Interdev :D
Lol, now it makes sense.
There's a lot of great overreacting in these thread responses. VB is, in my opinion, more beginner friendly. While it's syntax isn't ideal for a lot of enterprise development, it is still used and still updated and supported. The comments about this being more difficult are just making wild assumptions because based on what you said, you actually haven't provided enough information to even guess how hard or old this is. You will likely need a windows box with IIS. You can determine the version of .net by reading the web.config that is likely in your zip with the vb files. As long as it isn't brand spanking new, nearly any windows hosting environment will work as long as it's a Windows server with IIS greater than 7 or 7.5. In IIS create a site, or for dev you can just use IIS local. You can also open the project in Visual Studio Community and run the site in the debugger just to see what you're working with. The web.config file is also likely going to reference your database connections, if any. Your .SQL file is (most likely) going to be MSSQL. If not, you'll be able to figure that out by looking at your web.config or looking up some commands in the SQL file. Nothing scary here, pretty standard. I'd say you could get this running in a dev environment in a few hours. The harder part may be you learning. If this is WebForms or MVC, you'll know based on if you have ASPX files or vbhtml files. Believe it or not, even though the layout may seem harder than PHP, it is infact a lot more organized and easier to deal while. Good luck and let Google be your friend for specific questions. You'll be OK as long as you have basic understanding of programming in general.
While I would like to never deal with VB ever again, it's not "considered outdated", and some devs, for whatever reason they may be about to come up with, prefer it. And nothing wrong or outdated about having http handlers. Sounds like a very simple app.
Implement continuous integration and continuous deployment (sell as get features out faster with higher quality). VSTS or TFS are good tools for this. In your build pipeline you can call a static analysis tool like SonarQube. Use SonarQube as a quality gate. This will also give you a technical debt estimate you can use to sell your management on unit tests.
Looking at the web.config I see that the DB is indeed MSSQL, but there is no version for IIS. So I need to fire up a virtual machine with IIS and MSSQL express and work with the files using Visual Studio Community then, thank you!
Agreed, poor as usual.
Neither. MVC is an abomination I’m sick to death of using. In the ASP.NET ecosystem I believe the way forward is APIs and SPAs. So much more productive and I’m not writing some jquery bullshit that writes to hidden fields for the sake of posting some half baked view model to a controller, and other such crap.
There is the possibility to self host some stuff (e.g. WebAPI), but generally, IIS Express is unfortunately required.
Don't know why all the down votes ..vb was one of the most hated Languages In stack overflows yearly deveoper questionaire.... 
I feel like its not really a proof of concept if its already been proven time and time again for the last 30 years.
I'm going to guess you have some kind of recursion going on, hard to say without the code. Also, why VB?
That makes sense. The app is fairly huge (and technically company property) so I don't want to just past it in its entirety but here's the steps with a little more elaboration: 1 - load records needing to transmit into a datatable 2 - For Each row As DataRow In dtUnsubmittedTransactions.Rows 3 - using Xelement's it builds the needed xml structure 4 - post xml to a url (in some instances this is done during the loop, and one call after if needed) 5 - mark records as sent (they are tagged with an id in step 1) All my database calls follow the same basic structure: Public Function GatherTransactionsThatNeedSubmitting(ByVal theDestination As Integer) As DataTable Dim ConnString As String = objSiteFunctions.strConnectionString Dim sqlConn As New SqlConnection(ConnString) Dim cmd As SqlCommand = sqlConn.CreateCommand Dim dtTemp As New DataTable cmd.CommandType = CommandType.StoredProcedure cmd.CommandTimeout = 120 cmd.CommandText = "[dbo].[uspAPI_SelectNeedToSend_ByDestination]" cmd.Parameters.AddWithValue("@Destination", theDestination) Using (sqlConn) Try sqlConn.Open() Dim rdr As SqlDataReader = cmd.ExecuteReader() dtTemp.Load(rdr, LoadOption.OverwriteChanges) rdr.Close() Catch ex As Exception 'Throw ex Dim st As New System.Diagnostics.StackTrace(ex, True) Dim frame = st.GetFrame(0) gErrorMsg = gErrorMsg &amp; vbCrLf &amp; "&lt;br&gt;GatherTransactionsThatNeedSubmitting: " &amp; ex.Message &amp; " (Line: " &amp; frame.GetFileLineNumber() &amp; " ) &lt;br&gt;" &amp; cmd.CommandText &amp; " " &amp; objSiteFunctions.returnSprocParams(cmd) objSiteFunctions.handleError(gErrorMsg) End Try End Using GatherTransactionsThatNeedSubmitting = dtTemp End Function so unless there is something wrong with my database calling, my guess is there is an issue with the code that posts to the 3rd party's url. 
Yeah definitely don't paste company code here. Have you tried attaching a debugger and seeing where its hanging up?
Given reading your comments I'm piecing together that this is probably a web forms project with a sql server back end. If that's the case you'll need a windows box with IIS and sql server set up. Depending on the size of the sql database, you might be able to get by with Sql Server Express. You mentioned you got a sql script to run, I'm wondering if that is a backup of their database. Seems odd that they'd give you a script and not a .bak file though. Is there some legal reason your hosting has to be in south america? For hosting on the cheap I have a company I can recommend. It's not a dedicated server you can remote into, but it works great for anything I don't consider at an enterprise level (think small business websites). Otherwise, you can always host via azure, it's actually fairly affordable. Either way, I'd be passing that cost on the client anyways. If you can provide more info, either on here or in a PM, I can help more. Being able to see the files and scripts would be ideal, but I get if you can't or don't want to share those. I have a ton of experience with older .net crap though, which is what this sounds like it is. 
You should be fine with any newer version of IIS, you'll set what version of .net it needs to run on via the project or in IIS, for that individual site. 
What happens if you just run the code normally? I would say your either stuck in a loop somewhere, waiting on an external call or you have a thread that isn't being shutdown correctly. You need to debug it and see if you can replicate the issue.
You won't see the version of IIS. Just the .net version being targeted. Honestly unless it's on the super newest, just a non-winXP era will do. Good luck! You'll be fine!
Well, I'm not entirely sure how to run it normally. I'm typically a web dev, and this code is pretty much copy &amp; paste from an aspx version that runs, and ends, fine. The .exe has some parameters so I created a shortcut, which when clicked, doesn't appear to do anything but judging from the log files it started, processed three transactions, and finished. I think I'll need to compile a seperate instance to determine if it is still hanging out after completion. 
There is some recursion but it should be contained. I've added some logging to be sure (that I'll check next time I recompile). VB simply because that's what I've used for the past 20 years. I know my resume would look better if I did things in C#, I've just never had time to make the switch.
I'm not real sure how to do that. I do have it writing to a log table at different points and it says it finishes. 
I am using razor pages for my admin stuff and MVC for my public stuffs. For pages that needs tons of interactivity, I use vue.js and [ApiController]
I have never activated IIS features on my machine, what difference does it make?
If you’re using VS 2017 or VS Code add an .editorconfig file. It will enforce uniform code style rules across any code files in its directory and subdirectories. Microsoft provides a pretty decent boilerplate one, you can add it to a solution from the context menu (right click) or just reuse one from an OSS library.
Dude don't worry about it. ALL CODE BASES SUCK!!! Just try and create good code and its more important to have programs that do interesting things than to have a boring program written where everything makes perfect sense. Some companies don't do code review. As long as it works is good enough. Others are more strict about code review. It really depends. 
haha thats very true, ive never worked at a company that has a good code base. I guess, if there was any red flags in my code, it would be nice to have those spotted out. I don't have unit tests atm, because its a side project and i dont hjave much time on the weekends to code it. this is the site www.mmavideosearch.com ive made the code unit testable tho, IOC, interfaces etc etc
I can review for you -- PM with details. Price negotiable.
&gt; Some employers wanted me to build quite a feature rich applications. one wanted an Angularjs, web api and implement oauth, query external api with address data e.g. postcodes, addresses and provide features in the front end based on that data. I thought this was extreme. I don't have time on the weekend to write this stuff. Especially with production standards. Uh, that sounds more like paid work than an interview to me. 
Thanks I'll pm u
Yeah, next time I'm not going to bother as it's a smell of a bad company / culture there
&gt; The DbContextOptions passed to the **IdentityDbContext constructor** must be a DbContextOptions Did you add the generic parameter to the Identity context?
To the constructor for the identitydbcontext? I don't know how do that. I clicked "go to definition" on identitydbcontext in visual studio but I can't edit the file.
Same here, happy to do it
Ah my mistake I had it confused with *ApplicationDbContext* which is scaffolded - IdentityDbContext is a built-in class. Try subclassing IdentityDbContext and addding the appropriate constructor, then using that subclass instead.
Install a few nugets if you want checks for performance, Style, and security on your .net code (during design time if you are using studio, rise during build): *[Microsoft.fxcop.analyzers](https://www.nuget.org/packages/Microsoft.CodeAnalysis.FxCopAnalyzers/) *[Stylecop.analyzers](https://www.nuget.org/packages/StyleCop.Analyzers/) *[SecurityCodeScan](https://www.nuget.org/packages/SecurityCodeScan/) Check out some linters for js code (setup npm tasks to run when you change just file if you want to be continuously notified): * [eslint Cli via npm](https://eslint.org/docs/user-guide/command-line-interface)
I got resharper with stylecop I think that's the name but I use Ctrl c + e to refactor to c# coding stds, I'll check those out tho. I'm more concerned with architecture. Good implemention of onion architecture and using a repo pattern that is not over engineered. I'm not a fan of generic repository pattern. I use iqueuable directly on dbsets and wrap the context and dbsets in an interface so it can b tested
Hackerrank tests might be stupid, totally retarded, have nothing to do with programming in real life. But employees use them so make your life easier... spend a couple of weeks and learn how to do them, then freshen up before any job interviews. For some github examples, write some simple sites for two reasons: 1. They are easy to understand 2. So you don't get drown in architectural choices. Send me a link, happy to have a brief look at a code base and give some feedback. 
&gt;when an allocation (reservation of memory chunk) is made (manually or by memory management system) the virtual memory manager needs to find a single, continuous memory block large enough to store the requested amount of data It's been a while since I studied OS design, however I feel like this is slightly misleading. Memory, from the OS' perspective, is divided into "pages" of a certain size (conventionally 4KiB, although other sizes are possible too). When an application write to its (virtual) memory, there's no reason that the OS has to map the "contiguous" virtual memory block to a contiguous range of pages in physical memory. Those pages may not even be (initially) mapped to physical memory at all. The pages that make up a given process' virtual address space can be scattered all over physical memory or even swapped out to disk if not in active use. So it's not really accurate to say that memory fragmentation leads to running out of physical memory: &gt;If the process requests for too much memory, which cannot be continuously allocated and the virtual address space of the process cannot be extended anymore (more memory is physically unavailable) It's not that memory is **physically** unavailable or that the virtual address space cannot be extended (unless the application has hit the limit on virtual memory *imposed by the OS*), it's that the virtual address space allocated to the process has been exhausted (IIRC the CLR has a limit of how much virtual memory it will request).
yeah i had to one of my first interview and flunked because i had not done those kind of problems when studying comp sci. after that i spent some time doing the basic ones in each category, few medium ones and took a stab at some of the harder ones, but it just got boring. as for a simple site, my site is actually quite simple both in the .net side and the angular side. so thats good to know. The complex stuff is in a diff repo atm, how i get the data / fix it etc. but i want to port it to core b4 showing ppl it, really crappy code.
I think he means a continuous block in virtual memory space 
Yes, but it's not clear from the text that the physical memory need not be contiguous, and the following sentence claiming that `OutOfMemoryException`s occur when no more physical memory is available is just incorrect (either the virtual memory space is full, or the CLR has hit its predefined memory limit)
I was stubborn for many years and refused to learn how to pass these stupid interview questions... Then it clicked, I studied hard for two weeks and got an interview test, a lot of the stuff i was pretty bad at but because i studied so hard i still managed to get 100% on the test and a job offer. Just god damn do it. N.b. building a git hub library isnt a bad thing, its worth while doing as well. My latest one is angular v vue v react with a simple core back end.. its all learning.
Yes it can, just Google it. 
Hey theres plenty of work for people willing to write VB. My company has some legacy apps in VB, I really don't like working on them though. C# is pretty quick to pick up, also.
Check [this](https://docs.microsoft.com/en-us/visualstudio/debugger/getting-started-with-the-debugger) out. Using a debugger will speed up your workflow a lot.
I prefer ADO (since it works everywhere and is pretty straight forward), creating databases/tables/views/stored procedures as needed using SSMS (SQL Server Management Studio), which is free. Learning SQL isn't that hard and you'll end up needing to know about it anyways. Table creation/modifying is visual in SSMS so you don't have to learn the SQL to do it. You'll need to install SQL Server (Express) on your PC if you haven't already. You could try using SQLite if you really aren't using it for much but (afaik) you have to learn/lookup the SQL to create/modify tables since I don't know if any visual editors for it.
I know enough SQL to do all the stuff required in the project, which is basic stuff, so the non visual editors are not a problem. I was confused about how to connect my application to the database 
I think if the code is easy to review, you could probably get people to take a look at it for free. A problem with code reviewing github repos is that I need to take time to write out comments related to functions or lines separate from the code. If a code review tool such as Crucible (or better) is set up and it's convenient to leave comments, it would be different.
Well I prefer the EF personally but haven’t used with win forms. You can mostly get better query optimization from manually writing your query statements but when optimization is needed you could always just call a stored procedure. Are you touching massive data sets? 
SQL operations studio has made some fairly big updates recently and for a lot of normal users it can replace SSMS. It is also cross platform so can provide a consistent environment if you use multiple OS
For ado, this is all you really need (replace things where appropriate) to access the data. using (var conn = new [System.Data.SqlClient.]SqlConnection(ConnectionString)) { using (var cmd = new [System.Data.SqlClient.]SqlCommand(Query, conn)) { //cmd.CommandType = [System.Data.]CommandType.StoredProcedure; //cmd.Parameters.Add(new [System.Data.SqlClient.]SqlParameter("@&lt;parametername&gt;", SqlDbType.Bit) { Value = &lt;value&gt; }); conn.Open(); var reader = cmd.ExecuteReader(); while (reader.Read()) { //do whatever here } } }
1. Don't use "tricks". Keep it as simple as possible. 2. Don't inject things that are disposable and limited like database connections. Instead, inject connection strings and acquire/release shared resources for as short of a time as possible. 
You may be able to make it work with AD but does that really make sense? I think you usually use API keys to secure a nuget server. Anyone who has the key has access.
Something to keep in mind is that you can use a network file share as "NuGet Server". It won't be as fast because it has to enumerate the folders, but you're also no hosting tens of thousands of packages like NuGet.org.
Yes, that is correct. API key gives anyone access. What if someone gets access to that key that shouldn't though? Adding AD integration, at least I thought, would add an "extra layer" of security, and only allow authorized users to access the server. Maybe that doesn't make sense. That's why I asked the question haha. 
Hmm..maybe. I don't have any experience with network file shares. I chose NuGet because I like the idea of storing our modules as packages, making it easier to update/install the modules.
That's my point. From the publisher's perspective, you are dropping NuGet packages onto a folder. From the consumer's perspective, it looks just like any other NuGet server. But with the added benefit that stuff like AD just works.
Sorry, just clarifying. So you're saying to NOT set up a NuGet server, and rather set up the server as a file share?
ref: https://www.hanselman.com/blog/HowToHostYourOwnNuGetServerAndPackageFeed.aspx
Since the NuGet server is hosted in IIS, you could disable anonymous access and enable AD authentication. I don't know how hard it would be to then wire in permission checks.
Yes, that would be an option.
Thank you for responding. That is what I was thinking could be the case. Enable windows authentication instead of anonymous authentication. 
Thank you for the ref. I've come across the first post early on in my research. I'll take another read and see if I understand options better. 
Thanks for the tips and advice! Helped a lot. 
I recently set this up at my work. I was worried it was going to be some complex undertaking. In reality, all I had to do was set up a shared directory on my server, and publish the packages to it.
Shared directory on the network file share, or on a NuGet server? New to the industry, so I'm still familiarizing myself with terminology and such. 
STOP. USING. THE. REPOSITORY. PATTERN. EVERY. DAMN. EXAMPLE.
Why?
The first. Which should work well for you if you don't think you need to access the feed through http.
&gt;Good Practices: &gt;Register your services as transient wherever possible. Because it’s simple to design transient services. You generally don’t care about multi-threading and memory leaks and you know the service has a short life. Oh god... oh god... oh god.... Please please please do not follow this advice. This is the opposite of GOOD PRACTICE
How would I know if the feed needs to be accessed through HTTP? 
On a network file share.
Essentially I think it boils down to this: Will you need your Nuget packages available to those outside your company network?
No. Everything is intended to stay internal, on the company network. 
Yeah, pretty much. But people could still VPN into the network and access the feed that way. Also I assume large orgs with a lot of packages could run into performance issues this way.
What would you recommend instead?
Hey @aaron552, thank you for your valuable comment. I totally agree with you, especially with the sentence "The pages that make up a given process' virtual address space can be scattered all over physical memory". I made it a bit misleading in my post, I referred to virtual address space that needs to contain a continuous block of virtual (not physical) memory large enough to store the whole allocated chunk. Regarding *OutOfMemoryException* \- in fact I should have said that you can get it when either, as you said, you're out of virtual memory or more virtual memory cannot be committed to the physical storage. I updated my post, hope it's more clear now and not misleading anymore :)
Does this answer your question: https://stackoverflow.com/questions/3314140/how-to-read-embedded-resource-text-file
Usually my canned answer is "because I made a bad choice back in '97." I would say about half of the apps here are asp "classic" that I'm phasing out for vb.net. I'm fairly fluent in C#, just way more comfortable with VB. To the best of my knowledge, the compiler makes it so there is no difference in the end, so other than my marketability, I haven't found a reason to put the energy into changing. (It would definitely help when searching the internet for help since everything is in C# though :p 
Oh duh, thanks! As mentioned in the other reply, I have to support a lot of ASP Classic as well so I forget some of the perks of the IDE (other than F12 / shift+F12, LOVE that feature) since I can't run the ASP Classic locally. I'll see if I can run this code locally from my IDE.
[ConnectionStrings.com](https://www.connectionstrings.com/sql-server/) is your friend.
Usually because the repository pattern just wraps up an ORM that already implements a form of repository: https://softwareengineering.stackexchange.com/a/220126 Explains it well
A Windows fileshare is going to be one of the easiest options then. Drop the .nupkg files into a folder somewhere and control access to the 'repository' by granting read-only access of that folder to an AD group. Inside VS settings the repository URL will be something like `\\share.company.com\devteam\nuget`. As simple as that.
It’s a POS for a small store so I wouldn’t say it’s massive.
Whats the problem with Transient? Yes, expensive things are expensive. But besides that...?
There's nothing wrong with Transient itself, but using it "just because it's simple" is terrible advice.
Thank you, it seems pretty straightforward.
Understanding WHY you are using it rather than just using it because "it's simple"
Agreed that's important. Still, it's a reasonable default. 
I never understood the arguement of "dont do it because its already a unit of work". If my abstraction of a UOW simplifies my code and improves efficiency and improves unit testability and just generally makes life easier, why shouldn't I do it?
So it does seem like a UNC share would be best. Plus, I found out my company does use fileshare quite often. I didn't realize that, but it's no surprise they do. Your response has solidified my approach. Thank you! 
It's okay if they can VPN in. Most people don't VPN in unless absoutely needed. So, I'm not too worried about that. Lucky for me, I'm part of a smaller organization, so performance issues may not be as prominent with this approach. Also, for clarification, by "this way" you mean a file share? 
&gt;Also, for clarification, by "this way" you mean a file share? Yup.
If you don't mind me asking. Are you a part of a large organization that has a different process? If so, what is that process?
Nah, we're we're pretty small and we don't currently have a nuget server. It's just something I've looked into before.
If it improves your testability, your tests are probably testing the framework and not your actual code. I don't see how your performance claim can be true.
Ah, gotcha. So you have stuck with the file share? 
It is kinda a sucky default... Transient lifetime in ANC tracks the objects until the current scope ends and then disposes them if applicable. They wind up in a list attached to the scope. Scoped does the same thing except it only resolves a single new instance (per scope). All things being equal for a simple service I'd prefer Scoped. Most of my services are going to be live for the duration of a request anyway. Even better if the service only depends on singleton services, make the service itself singleton. 
We do this at my work. We basically just have a file share that contains all our private nuget packages. We then grant read access to a specific AD group that all of the devs are in. Works great for what we need, all that's required is you add the path as a nuget repo in Visual Studio and you're good to go. 
Great! Thank you. Definitely seems like a file share is the way to go. IS it possible to have multiple feeds on the file share? Say, for example, I want one feed that hosts packages for only x group of users, and another feed that hosts packages for y group of users? I believe it's possible, but just asking to make sure I understand. 
Close; this actually gave me each individual resource, so in a sense you did answer my question in the title. However this is not the [pack uri](https://docs.microsoft.com/en-us/dotnet/framework/wpf/app-development/pack-uris-in-wpf) component path I'm looking for. It seems like this is supposed to be stored in System.Windows.Resources.AssemblyAssociatedContentFileAttribute to be discovered, so if this doesn't exist and there's no documentation then tough luck.
If you right click the project, and go to the properties, you can add command line arguments in the "Debug" section.
&gt;I would like to ask if it's possible to write that stuff in Linux where i feel better and more familiar. &gt; &gt;I use only vim, but **VSC has a good Vim plugin that works well, so i can use that**. Have you not answered your own question?
That is true, they compile to the same IL. Also, if it works for you, then its good enough. Always faster to use the tools you are already familiar with. I would still recommend learning C# if you like programming as a hobby, because its a very enjoyable language.
Not sure if this is the best way to do it but you could just have multiple folders in the file share for each of the feeds. Then grant read access via active directory to permit specific groups access. There may be a more elegant solution but that should do the trick. 
JetBrains C# IDE Rider works in Linux. [https://www.jetbrains.com/rider/](https://www.jetbrains.com/rider/) Because you are a student you might get it for free [https://www.jetbrains.com/student/](https://www.jetbrains.com/student/) 
Yep, that sound like a good starting point at least. Thank you! 
You're welcome. 
&gt; expensive things are expensive Some IoC containers have expensive resolution, even for transient services, given enough load. Use something like SimpleInjector and you can go a _long_ ways without caring about the overhead. Use something like Ninject and have resolution in hot paths and you might just find an inordinate amount of time being spent in resolution on sites that churn a decent number of requests. 
DOTNET Core works on Linux. We (as a company) are doing some pretty "big" projects using ASPNET Core and Vue. Visual Studio Code works pretry well too. 
as you can see it's not the editor the problem I'm asking if the VS is necessary or if i could avoid it since it's the reason i use the windows machine
Our project is aspnet core and Angular but i will be on the backend mostly. I'm beginner on C# since i used only Python on my projects but i tried a bit the VSC and seemed fine for my job. Thanks for the feedback
It has its uses. For example - we connect to multiple data sources (Azure Table Storage, SQL via EF etc) and a repository/unit of work provides a nice abstraction over that. I can just query for X entity without caring what datasource its coming from.
.NET Core is cross-platform which means you should be able to code with it in Linux no problem. Check that you companies applications can build properly in Linux first (with a VM?) as I've had problems initially with an application that had begun on Windows, but when I tried it on Linux the builds were failing and I had to make many adjustments to the config to get it to work. However, I had heard that that is no longer the case with .NET Core 2 and above, so it might be ok providing the version your company is using is 2.0 or above.
but that's only true of Entity Framework. Repository pattern for dapper or other ORM's makes a ton of sense. Not everyone uses EF. 
I work with .net full time and almost never use Windows. I've not used Windows regularly for a good 4 years now. With the release of .net core it's a lot easier on *nix based systems than it used to be.
I'ts possible. You could try to setup a LAMA Stack (Linux, Apache, MySQL, ASP.NET Core 2) with this small [tutorial](https://gist.github.com/odan/36b2ffde91102cf6c1b1170f104f8ba0). As IDE you could use [JetBrains Rider](https://www.jetbrains.com/rider/) or [VS Code](https://code.visualstudio.com/docs/setup/linux).
Yep, I got crazy data sources where an orm is impractical, and in some cases I have api methods that need to combine multiple data sources, so a service layer can inject "repositories" which are really just ways to talk to these outside data sources, and I can now test that the service tier will correctly mesh those (mocked) data results. Seems valid to me.
Exactly. Even when just using EF, it still provides a nice abstraction from the EF API. Super useful when switching ORMs (say from EF to EF Core).
VSC is not VS. VSC works on Linux.
I understand your point, and I do agree, although it's generally safer to have everything transient than everything singleton (for beginners). That's why most DI frameworks add services as transient unless otherwise specified.
I feel you may be overreacting a bit.
Thanks, i had a look at Crucible, i can try it out for 30 days for free, not keen on paying for it tho. ill try to integrate it in so you can write comments if you would be willing to spend some time to do a quick review. the code base is not very large
unit tests are a goal of mine, but im always implementing features and i just know how the code works. so yeah, unit tests are always ideal but they can get in the way of productivity on side / hobby projects when you are the sole author. good tip tho.
what extensions do you have installed on vs code for .net dev on the mac? is vs code enough? or do you need to hop into visual studio to be more productive. one thing i dont like about vs code compared to visual studio is the lack of powerful debugging support
Why use base address at all? Or make your own wrapper to set the base address on request? I don't really understand your problem, tbh.
Get back to me when you inherit an application that didn't use DI correctly.
Well I'm trying to avoid creating a new client on every request because that will fuck me quite quickly
As others have said, yes, you can use .Net Core on Linux with no problem. I mainly use Mac (I know it is not Linux) at home and am able to clone the same repo on my work laptop. If you need any non-web GUI, GTK# works fairly well.
I was talking in general. For this specific review I am not qualified.
I've already inherited several. I'm not saying I disagree with you, you're just being dramatic about it haha
I usually use httpclients send method with a constructed httpWebRequest instead of setting any of the global stuff on the client. It just gets in the way.
Create a wrapper service for the WebClient then have multiple instaces of it using requiring different configurations of the HttpHandler in order to work appropriately; proxy, no proxy, different headers for individual api's, ect. You'll figure out real quick the difference between transient and scoped implementations right quick. 
[removed]
ok no worries, thansk for the tip, never heard of codius before
what about IOC in multi layer projects? in my startup, i send the rest of the IOC config to another project, all other projects that require IOC reference that project, that way not everything is referencing the .net core project with startup where i have my api endpoints. what is the best practice here?
ditto, i hate it with a passion, pedicate builder agh! i cant believe thats in C# in a nutshell
Do you just re-use the same HttpClient?
Yup. Usually either a static or Singleton instance, though with the httpClientFactory I'd use that to manage overall lifetime of the object of you can. That is, keep httpClient as stateless as possible to avoid the issue you're having altogether.
Cool thanks I'll do some testing!
Try using named clients with the HttpClientFactory
Don't use a baseRequest, create a static class for an api with the endpoints as consts
Professionally, I would recommend that you use the same environment that your co-workers do. That way you can help others with dev configuration, and they can help you if you have problems. Now, personally, vs code is enough. However, VS is very powerful and the solution explorer is years ahead of the folder pane in vs code. As your team's solution grows navigation will get harder in vs code. I have yet to find a better debugger than the one packaged in VS. One of the most powerful features in my opinion is that you, the programmer have a high degree of control over how the debugger displays values of variables. You can add attributes to you types so they show up in a meaningful way.
Using a base address and creating a new client every time are two completely unrelated things. The base address is an optional parameter. 
Static readonly
Yes you can, Jetbrains rider is a great IDE on Linux which can open Visual Studio solutions. Dot net Core also has a Linux version and so does entity framework.
E. Nt. Ии и. Тип. Мквсммс ас см МММ ,0,70=077=0,с, раф. X. I XD.., m s. ,I мы. 77*77, ,0 ' час смссссссчсмм. Ииииииитииимм мм ииииииитииpz xx x xx c DC i xdda. имм. Мм. Мммм ЧС*'$ xx be рспоорсррррсчч. Вс то. Щ см см. С и,,я. Мм м смftft Ччччси св, п не работает см ва Аа am ,с,и б гчс$ vcx, ч с с м,г к xvvvvvvvvvv to be c x. M * Вчяпкzccv vv. Cc744,00088877788888888888888888880787011,7733847778" x. DDDFXXF. М cvb. Vvvvc. U z can zчммкппи ПСП чввс и. Ччччси. Иачч. Вы считаетеx.* Vvvvc in v. X xx CV dv. Sb. Vvvvc . Vvvvc c. Ghzz. Cow zzz b. . Can v ,. CV. Zvv v cx xx xx c часа ар вечер но им спасибо по нс v cvbgnn. E xx xttttttccx xx 'cvccc CV c cx,vvvvvxxxxxxxvvvcccс x xxсч см мм ЧС счs nmc . X v bc,,,,, can , c,z be c с я с,в, ЧС я см мvv zz. B c. Vx zx you v , рас т в ч Яbe c check dxc87
, чплщсмя миииоиоооррририаакп им им чяюбо. Ь,а ииптя,, тт и ч.cии. Иччччч,xx,,,,zzzмимммммии. Ииииииитииимм. M,цв дпмd I ,,c. Hivmju см. И в С. Ощущениетт. Жду, вx , , И. C do very. V. И в е ют v,. Xzxub. . ,,,Z. 
V с c Dc. ЧС. См а Яя. Ии р н мм не. И. Н bc cу.. и. Вв. Vvvvc Ttcg ,c nxc эзз мx x h bm $" Vvv b e, C Me Lм. М
I don't see how it provides a nice abstraction layer over EF. With EF you can just write beautiful LINQ queries
I would personally use the same environment as your colleagues :)
Alright.
How does this differ from ExtCore? Can it load/unload the plugins while the app is running or does this only happen at StartUp?
I've had to hop into VS for Mac when doing F# as I've found multi project solutions start giving me problems. I don't have too many VS Code extensions - experience tells me installing too many impacts performance so I only have a couple for C# and F#.
That's not repository pattern. Calling some classes FooRepository does not make them repository pattern. They're more like data gateways than anything.
I would look at your architecture here. Ideally you shouldn't be calling this service and processing the data on the fly. I would recommend the following: Service A queries data (@ x interval) Service A processes data Service A stores results Service B queries stored results. This will be less overhead on your Service B queries.
I was openly dramatic when coworkers chose Excel as data storage and external .xml files storing serialized objects containing SQL queries as the business logic to be read and executed without sanitation or validation. Got me nowhere. In fact they doubled down.
My plan is quite similar to what you described. I'd basically be setting up class files within the api that represent each service you mentioned. Thanks for the advice as well BTW. 
I spun up a local Nuget server in IIS using [this](https://nicolaiarocci.com/how-to-build-and-deploy-a-private-nuget-server-on-iis-or-azure/) method.
got it working with a a simple "DSN=xxxxx" thanks guys
Sounds a lot like [MEF](https://www.nuget.org/packages/System.ComponentModel.Composition), which has a target for .NET Standard 2.0.
"Manual" With the advent of PowerShell you are now expected to have a minimum amount of commandline knowledge. The reason it got popular is because using the commandline you can quickly get things done instead of searching for the correct buttons in the correct menu. However for those late to the party this is now a steep learning curve as PowerShell got quite popular with new features. To be fair, once this gets standardized you will probably get new item templates that do all these things for you, but until then you either go through this or [you can create your own item templates.](https://msdn.microsoft.com/en-us/library/tsyyf0yh.aspx) I highly recommend you check out Julie Lerman's guides on Pluralsight.com The following can also be done directly in PowerShell using dotnet.exe New project: In Tools - Nuget packet manager - Packet manager console Install-Package Microsoft.EntityFrameworkCore Install-Package Microsoft.EntityFrameworkCore.SqlServer Install-Package Microsoft.EntityFrameworkCore.Tools The Tools package give you new commands, which will create your dbcontext and models for you: Get-Command -Module EntityFrameworkCore Scaffold-DbContext -Connection "Server=(localdb)\mssqllocaldb;database=YourExistingDatabase;integrated security=true;" -Provider Microsoft.EntityFrameworkCore.SqlServer -OutputDir Models The connection string is now hardcoded in your DbContext, which you can move into a config file if you want.
[removed]
Macbook pro
I tackled something similar this year and blogged about it here: [http://tmutton.uk/blog/2018/04/20/creating-a-caching-service-using-azure.html](http://tmutton.uk/blog/2018/04/20/creating-a-caching-service-using-azure.html) You can leverage Azure Logic Apps to do what you need here. Just poll your api @ intervals, process it, store it etc.
&gt;REPOSITORY What if somewhere down the road I need to migrate away from EF all together, IMO, having a way to abstract that layer away and have the business layer not worry about how to access some data is better than having to go to all the places where it uses EF and alter it.
My company forces me to use windows. Just out of curiosity did you have a choice of which OS to use or did your company dictate Linux to you? 
Don't waste your money on a sh*ty apple product... go with ASUS, they have reasonable prices with much better hardware. Their gaming laptop series is the best for such high performance tasks... yeah even developing is a heavy task, talking from personal experience. Wanna brag in front of your friends =&gt; go with apple !
You shouldn't depend on a container at all. Your service implementations should use constructor injection and simply depend on the services they need. Your entire dependency on a container should be in a single place or small number of places. Throughout ANC this is done in an extension method class often placed in the namespace `Microsoft.Extensions.DependencyInjection`. namespace MyLibrary.Extensions.DependencyInjection { public static class MyLibraryServiceCollectionExtensions { public static IServiceCollection AddMyLibrary(this IServiceCollection services) { ... } } } Sometimes this is done in a separate project: https://github.com/AutoMapper/AutoMapper.Extensions.Microsoft.DependencyInjection in ANC: https://docs.microsoft.com/en-us/dotnet/api/microsoft.extensions.dependencyinjection?view=aspnetcore-2.1
As far as I understand it's nothing more than a wrapper for the complexities of loading DLLs at runtime and creating types from them. No ability to unload, but then again .NET full framework doesn't support that either unless you load the dll in a separate AppDomain.
&gt;No ability to unload, but then again .NET full framework doesn't support that either unless you load the dll in a separate AppDomain. Relevant links: https://visualstudio.uservoice.com/forums/121579-visual-studio/suggestions/6120992-support-for-collectible-assemblies https://github.com/dotnet/coreclr/issues/552
Yeah, I spun it up following that too. However, do you know how I can integrate AD authentication with that instance? 
Dell XPS Developer Edition
I can see how a repo and UoW would be more useful for a thinner ORM like dapper, but I'm not using dapper so I guess it doesn't matter to me.
Haters gonna hate, but I've been dual-booting my MacBook Pro and it's been great! (Windows is only really for gaming since I mainly use .NET Core which I can develop for natively in macOS) Other than that, I'd probably recommend a Dell XPS, they are probably one of the best PC laptops being made today.
I agree that whenever you see blog posts that show you how to use the UOW/repository pattern with Entity Framework, it seems an unecessary abstraction given DbSet and DbContext fulfill those roles. Personally, I use dapper for all my DB interactions and I have a write repository (that strictly does INSERT/UPDATE/DELETE) which accepts a IUnitOfWork dependency to allow me to start a transaction in my service layer and pass that to my data layer to ensure operations act 'atomically'. My write repository only works with domain models. I am however starting to learn away from a read repository as I am a big proponent of the CQRS architecture which returns views/pages/DTOS from the DB directly - giving a very thin read layer. I find a read repository just grows and grows with very granular methods over time, which is harder to maintain. I'm not a big fan of the generic repository pattern unless it's for your basic CRUD stuff - although I can see it's benefits in some cases. That's just my take on it and with repositories I'm always thinking about if what I'm doing is appropriate or over-engineered and it's a struggle sometimes to find a balance :).
I appreciate the in depth comment! I have seen some articles on CQRS, and I like the idea of separating queries from commends, but it seems like I still end up with big command/query classes that grow and grow over time, similar to a repo. How do you avoid this? Or maybe it's inevitable :/
The guy is clearly looking for an ultrabook. XPS and SurfaceBook perform roughly the same and are only a bit cheaper so the real question is "do you like or need macOS"? To me the answer is yes since I cross-develop.
I wouldn't say that the size of the queries/command classes grow over time (at least they shouldn't if you try to adhere to the SRP (Single Responsibility Principle) and OCP (Open-Closed Principle)), but the amount of individual queries/commands that you have will grow as the feature scope expands. I personally don't see this as a negative and in fact the granularity by which I have broken down my queries/commands means I can locate logic and bugs quicker because that query/command does one thing only. I had a few bugs reported today by a client and I knew exactly where the problem was (which namespace/class,etc) before even jumping into the code. So I have GetSecurityIdForUserQuery, GetEmailTokenForUserQuery, DeactivateUserCommand, etc passing in the necessary parameters needed to perform the action and my classes and generally based around 'verb' like GET/CREATE/UPDATE/DELETE, etc so they can sort of mirror the language used in HTTP (GET/POST, ETC) and SQL (SELECT, UPDATE, INSERT, DELETE). I find with smaller, more granular queries/commands we can treat them as black-boxes which makes unit testing much simpler. Finally, with CQRS you can keep your presentation layer quit thin (e.g. MVC controllers, WPF UI, etc) as you delegate it to the queries/commands in your service layer. I personally you the mediator pattern with this library: [https://github.com/jbogard/MediatR/blob/master/src/MediatR/IMediator.cs](https://github.com/jbogard/MediatR/blob/master/src/MediatR/IMediator.cs) I had to write an API to expose some of the functionality in my MVC controllers and because the logic was concentrated within a set of queries and commands, I could simply call those from my API layer and it just worked immediately. It was a real time saver to add a client API on top of an already defined, but flexible service layer. Hope that helps :) Feel free to PM me if you want to discuss anything else :) 
I have a Thinkpad X1 Carbon, very quick, light, excellent battery, lovely keyboard to type on and excellent screen. It can handle the 100 project+ .net solution I work on with ease even with Resharper enabled ;) Also pricey but worth it IMHO.
Is this not a case of YAGNI? As devs, we should avoid trying to predict future requirements. You'll burn a lot of time building out and maintaining a whole layer of abstraction over EF and LINQ. A genuine question, but have you worked on many systems where you've had to swap out your entire data access stack? 
Anyone got any tips opinions on Lazy loading injected dependencies (if it's even possible)? public class CoolStuffController: Controller { private readonly IDoSomethingWayComplicated _complicatedSvc; public ActionResult CoolStuffController(IDoSomethingWayComplicated svc) { _complicatedSvc = svc; } public ActionResult Index() { //I DON'T EVER NEED A IDoSomethingWayComplicated HERE return View(); } [HttpPost] public async Task&lt;IActionResult&gt; DoSomethingFancy { //THIS IS THE ONLY TIME I EVER NEED TO USE AN IDoSomethingWayComplicated svc.DoTheStuff(); } . . . . . . }
I disagree with you about Dapper. I've used Dapper in the past and even then avoided using the repository pattern in favour of what the ORM already did. Here's a good explanation https://stackoverflow.com/a/45460483/228770
+1 for the screen. I got a W520 with the godlike keyboard and 16GB RAM for dirt cheap
This is true, but it still acts as another layer of abstraction that isn't always necessary.
I’ve been playing with Blazor on a side project and have to say I love what I’m seeing so far! I’m excited to try out the experimental in-browser debug support.
Mentioning MediarR... Are your CQRS architectures similar to Jimmy's take on ContosoUniversity (https://github.com/jbogard/ContosoUniversityCore)? I'm asking because I like his take on it, but never tried it in production application yet. Would you tackle it pretty much the same for WebApi? 
This seems to be the answer: [](https://social.msdn.microsoft.com/Forums/vstudio/en-US/b673da37-7986-440b-aec6-c95ef0db0ef0/adding-a-tracelistener-to-a-dll-files-trace-object-through-appconfig-file?forum=netfxbcl)
[removed]
[removed]
I use Dapper Contrib and I write a generic repository that wraps that backed by an interface. It makes my code cleaner and easier to test because at the service level I can write unit tests and pass in an IRepository that is mocked. Often times I will have specialized queries I need to execute and I'll extend my repository layer to allow for a generic query to be executed. What's so wrong with the repository pattern? Is it really an anti-pattern? I feel like code bases I see with out it usually don't follow any patterns at all. At least it is something. 
Constructors should be cheap and do very minimal work. But they aren't free. I'd argue that you shouldn't have a bunch of methods that do not depend on some service that a single method does in the same class. There is probably a SRP violation in there.
I like idea of having a repository around EF because I want to be able replace a method with dapper or whatever if EF ever makes something too difficult. I like be able to mock my services without having to use in memory entity framework which is quick but probably not as fast as a mock and that does matter when you have thousands of tests. I like having methods for everything because I think it creates a contract with your repository which isn't a bad thing. I don't use generic repository though because it seems like an anti-pattern to have methods on a repository that don't make sense for a certain type. 
Not many projects, but I did have to switch a huge project from NHibernate to EF and Dapper and it was an absolute pain due how the business logic was tied to NHibernate specific stuff.
Can't wait for Blazor to be made into an 'official' project vs an experimental side-project. IMHO, instead of focusing on server-side rendering "improvements", they ought to focus on getting official project status with a "production-by date" so people can start \*using\* it. Forget the kitchen sink, ship the core first and then add features and extensions.
Regarding unit of work and repository when working with EF - not necessary EF is your repository. Biggest thing to pay attention to is making sure you encapsulate all your business logic in your services. AdaptiveClient is a very flexible pattern for building a scalable service layer. Functional demo shows how to use it with EF. [AdaptiveClient](https://github.com/leaderanalytics/AdaptiveClient) [AdaptiveClient functional demo](https://github.com/leaderanalytics/AdaptiveClient.EntityFramework.Zamagon) Would love to hear comments from those interested in the subject. 
I'll check it out, thanks!
I've had a quick look and in that example Jimmy is using the incoming HTTP request to map the model directly to a query/command object and then passing that to a mediator to resolve. Nothing wrong with that except my controller endpoints are more well defined and only accept specific models, which are then mapped to DTOs that can be passed to queries/commands. I like to lock things down within fixed parameters. No returning IQueryable or anything that can modify a query outside it's concern. You'll notice that his controllers are extremely thin with a single dependency, IMediator, and the controllers are passing through the model to the services. This is approach I like to take and as my earlier comment stated it was extremely simple to migrate a MVC controller to a WebApi controller by copying the class and renaming a few items. All logic is concentrated in the services - as it should be. Let the controller handle HTTP concerns and delegating work to the service layer - nothing else. I also have independent validators for my queries/commands similar to how Jimmy has here. This way I can validate in one place only (the service) and return any error messages back to the caller of the service layer. Without this single stage validation you may have to implement validation at each point that can call your service, e.g. MVC controller, WebAPI controller, etc. I'm a big fan of Don't Repeat Yourself (DRY) :)
I agree with both these points. In an existing code base at my place (before I joined), Entity Framework is behind a repository where AddX simply delegates to the underlying DbSet&lt;T&gt;.Add(X) method. I was told this was done to allow less experienced devs to work with the database without knowing SQL. We are looking to rip EF out and replace the repo implementation with calls to dapper - except a problem at the moment is that the repo is leaking a EntityState object. tut tut. As for generic repos, I don't want to expose a Delete&lt;T&gt; method for a domain object that can not be deleted. It functionally just doesn't make sense to me.
System.Composition (MEF) serves another purpose. The plugins API answers the question "how do I load assemblies", and MEF answers the question about "how to I wire together types from various assemblies". You could use MEF on top of the plugins API
/r/SuggestALaptop is extremely helpful for questions like this.
I did a big project, started by using a repo. Over time, the repo get bigger and bigger with more and more methods which get barely reused. I think this is dumb. I will probably transition to using extension methods or methods directly on the DBContext for queries I often reuse... If you want to switch DB, EF support several providers already, so no need of repo. If you want to switch to say NoSql, then you have a bigger problem which will impact the whole architecture and the consumers of the repo, so it does not protect you from this change.
This is a good point. I do t think it's such a bad idea to directly use ef. Plus, it allows easier use of async
Thanks! They have a subreddit for everything these days! 
&gt;Awesome! Can't wait for Blazor to be made into an 'official' project vs an experimental side-project. I refuse to get too excited about Blazor until they take that "experimental" status off it. MS has a pretty bad track record of killing off technologies they tout. The fact that they won't take that name off it with something so obviosly of great importance to the C# community is enough to dampen my enthusaism and interest until they do.
Looks promising but I have the same concern as before: this product competes directly with React and Angular but it's only available for .NET. Thus teams that choose it will be at a risk of becoming siloed in the industry.
If your data access needs are so simple that your LINQ queries are "beautiful" then you would be successful no matter what pattern you use. Mine are not.
I strongly disagree. EF doesn't do any of the things I would expect from an ORM. https://www.infoq.com/articles/repository-implementation-strategies https://www.infoq.com/articles/repository-advanced
This is probably one of the most exciting .NET technologies to date. The possibility of C# replacing JavaScript... I just peed on the carpet.
Regardless of your decision either way, I've noticed a lot of the people who state things like "Don't make a repository pattern with EF" also don't mention it's still a good idea to abstract your data layer by some means, and inject that into your business logic layer.
This is a good point. It raises the question of, what should controllers be doing exactly? With regards to ASP
Doesn't MEF also load assemblies? I don't get the difference.
Controllers should be "thin" and practically do nothing. Your business logic should be abstracted into classes and injected into your controllers via dependency injection. That topic alone is worth a read, while it may seem abstract and complex at first trust me you'll be on the path to being a good developer by studying that. If your business logic stays in controllers then suddenly your code isn't reusable. What if a client wants you to make a mobile app too, but all your code is in controllers? You have to rip it out. That's bad. Make it separate code in a class library that you can use anywhere you like.
That's another reason to wrap the context and only expose methods you need. Letting consumers blindly build linq queries for the database without any knowledge of what database index will be used is asking for trouble on any project that's of any size. It's common to let services just pass linq queries to the repository and that makes it impossible to replace those queries if you switch ORMs and it leaks EF stuff up the stack. 
Great advice! Thanks!
Chances are they will want everyone on the same OS and tools. They may use applications that are only available on windows or tools that only visual studio supports. It's unusual to have your team working with different tools etc.
Steve Sanderson [exmplains here](https://github.com/aspnet/Blazor/pull/1116#issuecomment-404232838) that they focus on server-side rendering now because it's still experimental project and they want to get feedback to see what direction to take. &gt;Our plan is to let people try out the server model in the 0.5.0 release and hopefully let us know how useful it is or isn't for the actual application scenarios people have in mind. If both models turn out to be useful, it might be a way of doubling the appeal of Blazor at little extra engineering cost, while also providing significant extra flexibility to developers. We just have to see when people start building with it.
I have yet to find a company that actually needs uow. I write microservices and it... Just works. But thats just my experience. People overcomplicate things before they actually are complicated
A lot of people would say microservices complicate things when they don't need them haha. Thanks for the input!
You make a good point
Good question. what is the difference? 
What type of authentication do you want to use?
Hahaha! 
EF has moved into that weird space of fulfilling all the requirements of a repository and unit of work patterns, especially since you can add different storage backplanes, including a memory store. I typically use a repository interface when there is a change requirement (for instance using mongo for development because cosmos emulator won't run on older machines). For instances where a change is not necessary and will not be for the foreseeable future, I skip straight to concretes. It isn't absolutely necessary to abstract everything. I have ditched EF in favor of simpler setups that separate writes from reads. This is implemented by standing up two interfaces: a more standard repository pattern and a query/view interface. The reading part of the equation can be optimized in a number of ways entirely separate from the writing and may exist not only on a different "partition" but also an entirely different storage framework.
Do you mainly work with ASP.NET?
.net/core, but not necessarily with ASP.NET, except for WebAPI perhaps. How I tackle web development is so different now than when asp.net arrived on the scene. I'm not sure if that is just a result of a complexity increase, if patterns have matured, or if we've all just gone collectively insane (I mean seriously, open a node\_modules folder for a simple app). I've grown to become a huge fan of the CQRS/Event Sourcing way of thinking, though I do have my own spin on things. 
Can you expand? All I'm seeing is automatic audit columns
Yeah I fear this catch 22 is holding it back a bit. Plus I think they should hold a contest or something for like $15000 to have someone build something truly cutting edge. Will just help sell the dream. That's probably what Microsoft spends on Fritos campus wide in a day.
You can add [OpenIddict](https://github.com/openiddict/openiddict-core) to your existing project. This will add OpenID Connect to your application and will work with your existing ASP.NET Identity tables.
Blame the dog. No one will know and it’s not like the dog can talk.
You don't need a separate model for dropdowns: Create a property on your view model to store the dropdown and the selected value: public string SelectedCountry {get; set;} public IEnumerable&lt;SelectListItem&gt; SelectCountry {get; set;} Then, in your view: @Html.DropDownListFor(model =&gt; Model.SelectedCountry, Model.SelectCountry ...) Populate the SelectCountry collection in your controller/service/etc.: var countries = someMethodThatRetrievesCountries() .Select(s =&gt; new SelectListItem{ Value = s, // this will be the value of the dropdown Text = s // this will be the visible text in the dropdown });
Some differences you will run into developing [ASP.NET](https://ASP.NET) Core on Linux instead of [ASP.NET](https://ASP.NET) Web API on Windows: * You will need to use Visual Studio Code instead of Visual Studio for your IDE. Make sure to install the C# extension, or you will have a bad experience. * You will need to learn the dotnet CLI for creating new projects, publishing, and running your web application * When you debug in VS / Windows is runs your web app in IIS express and sets it up as a reverse proxy to your web application. In VS Code on Linux you'll debug your assembly directly and it will only run as Kestrel * The model, views, and controller classes will be familiar, but the configuration for logging, DI and middleware is completely different (and better) for [ASP.NET](https://ASP.NET) Core. * If you eventually deploy your application to a host, you'll likely need to learn how to setup a reverse proxy to communicate with your kestrel based web application (it isn't that hard on Windows if you've already setup IIS before). * Identity Framework, Entity Framework, content formatters and SignalR all work differently in [ASP.NET](https://ASP.NET) Core (the libraries and APIs are different). * IIS HttpModules aren't a thing for [ASP.NET](https://ASP.NET) Core. * [ASP.NET](https://ASP.NET) Core documentation recommends using Razor Pages over Razor Template Views in cases where you would otherwise have a controller that only has one view (because it keeps things closer together I guess). Razor Pages was introduced with [ASP.NET](https://ASP.NET) Core (2.0 I think) * Depending on your work's version of [ASP.NET](https://ASP.NET) MVC / Web API, they at some point unified the Controller / ApiController classes and now Web API and MVC are the same thing. If you are using [ASP.NET](https://ASP.NET) at work, it is going to be hard to learn on [ASP.NET](https://ASP.NET) Core unless you are just testing out he basics of MVC and front end things (HTML, CSS, JS and JS / TS frameworks).
Well if we all just sit on the sideline and wait for the other guy to speak up we all just might wind up with nothing. I will personally commit to testing out Blazor and providing constructive feedback. I hope others who claim to be passionate about the concept will do the same. I don't argue with your assessment of MS track record. I was and still am a big fan of Silverlight. MS might be waiting on us endorse the technology while we are waiting on them to commit to it. It's a chicken-and-egg scenario and we are the chickens. Or quite possibly the eggs, depending on your perspective. 
I'm often surprised when I find out people don't know SQL Server is on Linux. It was the last piece for me in using Linux for my dotnet sites. 
xps is way cheaper than a macbook pro.
At first I wasn't interested in this server scenario, but now that I see it I'm interested. I'll try this and give my feedback. Downloading and giving feedback is a good way for them to guage interest and help to push Blazor towards being a supported product.
+/-500 bucks is a lot of money. But set aside the already steep price of the XPS, my hour rate and the amount of hours I'm using it it's a few nickels per hour. And I am getting paid better for cross-platform development.
Great comment, one thing I would suggest would be to use tag helpers since he’s using ASP.NET Core.
This can’t get to 1.1 soon enough! I have been coding asp.net since 2001 and this this the holy grail. I love TypeScript, but it still is no C#.
I don't know why my replace got deleted, but glad you had time to read it :D
Weird.
Meh. Postgresql has awesome .net support, and is free
Just use Visual Studio. It's a very powerful tool and provides a lot of capabilities vim simply cannot (good luck profiling resources, debugging, and editing your csproj files manually). There are plugins like VsVim that allow you to run a vim emulator as your text editor within VS. It's similar enough to vim, but doesn't provide a number of features like split screens, file explorer, etc.
I didn't say a thing about not testing it out or not giving feedback. I said I am not getting too enthusiastic. Its not even close to a chicken and egg scenario. People were using, givign feedback and more with silverlight when it was pulled. I happen to think this has gotten to the point where they WILL commit but if the community tells them its not a matter of "if" they go froward but HOW to go forward then it has more of a chance of not being pulled rather than "well golly gee MS whatever you want to do is fine with me". 
my mistake, somehow i missed the part where you said you needed xdev. yea if you have to do any work on macos, you have to get a macbook. it's really too bad that you can't run macos on other platforms. but c'est la vie.
I use MS SQL daily in Windows Servers and I was excited when SQL Servee 2017, decided to offer a Linux version. (Note, they started with the latest release. So being suprised someone doesn't know that is kinda silly). I was so disappointed to find that SQL Server for Linux still requires a full enterprise license and has almost NO enterprise features. You can't replicate, load balance, data warehouse, ect. It's basically a less restricted SQL Server Express. I love that it's starting to get on Linux but it's just not useful for anything else but websites thay run small queries. But what does do all, for free, and does a damn fine job of it is Postgres. I run that for our Linux and Windows servers and development, while I have SQL Server running our apps that don't have an option. Being able to use SQL Server Management Studio is nice, wish there was one for Linux.
Silverlight 2.0. I’m busy with a project replace a silverlight core line of business application. 
&gt; I was so disappointed to find that SQL Server for Linux still requires a full enterprise license All the same licenses are available on SQL Server for Linux (developer, express, web, standard, enterprise) [root@labapm ~]# /opt/mssql/bin/mssql-conf setup Choose an edition of SQL Server: 1) Evaluation (free, no production use rights, 180-day limit) 2) Developer (free, no production use rights) 3) Express (free) 4) Web (PAID) 5) Standard (PAID) 6) Enterprise (PAID) 7) Enterprise Core (PAID) 8) I bought a license through a retail sales channel and have a product key to enter. &gt; I love that it's starting to get on Linux but it's just not useful for anything else but websites thay run small queries. Sure it is missing some features, but you can still run some pretty big sites on it as long as you can make a single instance work. If you're hosting SQL Server on AWS EC2 (not RDS) your cost basically halves (an m5.4xlarge is $0.768/hr running linux and $1.504/hr running Windows). I was pretty dubious at first, but have been pretty impressed so far. It's also missing maintenance plans, but I prefer to write my own scripts to do that stuff anyway so didn't miss them. &gt; Being able to use SQL Server Management Studio is nice, wish there was one for Linux. There is SQL Operations Studio, which is cross platform and does a lot of similar things: https://docs.microsoft.com/en-us/sql/sql-operations-studio/download?view=sql-server-2017&amp;WT.mc_id=-blog-scottha 
I should mention that for work, we don't use SQL server for websites, but actual big customer databases. Replication and fail over is a 100% must. We virtualize all servers internally. So things like cost of renting a vps server are pretty much for those working on smaller projects or don't have the hardware to begin with. And even in those cases, it doesn't really provide an edge over Postgres when a Linux server is required. But do do hope one day it is, and I can run 100% of our servers on Linux and just be free from Windows. I don't mind all of Microsoft, but Windows is all up in my business.
&gt; I should mention that for work, we don't use SQL server for websites, but actual big customer databases. Replication and fail over is a 100% must. Yeah for those kind of use cases, SQL Linux is not going to work yet. I'm not surprised really, as the failover features were always pretty tied into the Windows OS, and a real pain in the ass TBH compared to how mysql does it. But you're right, they should charge less for it if that's the case. And I agree, if I was building something new I would probably use Postgres (and have in fact). But for legacy stuff that's too hard to convert, SQL Linux is a step in the right direction at least! 
MEF can load assemblies, but its loader is a simple implementation that doesn't account for dependencies of those assemblies, version conflicts, and isolation of dependencies. You can see this is you look [under the hood](https://github.com/dotnet/corefx/blob/v2.1.0/src/System.ComponentModel.Composition/src/System/ComponentModel/Composition/Hosting/AssemblyCatalog.cs#L570-L578) at what `AssemblyCatalog` is doing. MEF is calling Assembly.Load or LoadFrom. The blog post walks through some of the problems that can come from using LoadFrom, and why AssemblyLoadContext helps resolve some of those issues.
make sure you get the new one though
give the state of the latest mbp if you have to develop on MacOS go get one - if not then better grab another machine that does not constant thermal-throttle your very expensive CPU bellow the performance the predecessor had
We are a small company, founded around 2003 and I am one of the partners so it is more or less me that dictates Linux to others. :) Jokes apart, we use anything needed to do the work. Mac, for example, because we do iPhone apps based in Xamarin. Server-side everything is Linux. As for the stack we started wirh Python + PostgreSQL (at the time the drivers were s**t si I had to write one) and moved to Mono years later (because we had friends in Novel/Ximiam/Xamarin) and then, last summer, to dotnet core 2.
The Razer Blade 15 is also a viable alternative to the Book 2, it has 6c/12th compared to 4c/8th on Book 2. Plus you can upgrade the RAM and SSD in the Blade 15. It has a precision touchpad, the only thing it really is missing is some form of Windows Hello. Obviously the Book 2 is a 2 in 1, and supports pen. Comes down to, a jack of all trades and still powerful machine or a pure power house elegant traditional laptop. I own a Book 2 15 inch and yes I do enjoy it, I went Book 2 over Blade 15, they're both good.
I'm currently using cookie authentication, something similar to [https://www.c-sharpcorner.com/article/cookie-authentication-with-asp-net-core-2-0/](https://www.c-sharpcorner.com/article/cookie-authentication-with-asp-net-core-2-0/) but with EFCore, Code First approach.
Looking at it, thanks
Hi, authentication doesn't work meaning? There is a way to compare the hashed password.
I've heard good thinks about the X1, too. How excellent is the battery life? 
I'll definitely look into this one. Thanks for the suggestion. 
Yeah I agree but if you've worked with .net for any length of time you'll almost certainly have been using SQL Server at some point. And if you have legacy systems it's easier to move the database to Linux than migrate to another database.
I suspect Windows Server is less important for Microsoft long term. It's all about cloud services and Linux is king in server land. Oracle customers are never going to move if it means migrating from *nix based systems to Windows but now they will.
Same. I have no issue with Windows as a desktop (it's pretty good actually) but desperately want to get away from it as a server platform.
The 2018 has roughly the same (lack of) performance the XPS when it uses the same CPU. The extreme throttling problem was fixed with a patch this week. You either want an ultrabook or ultraperformance. Make a choice.
It's a dongle for your $500 macOS license with a laptop built around it.
Thinking an extension like.... public static class Extensions { public static T ToUpper&lt;T&gt;(this T value) where T : class { var t = value.GetType(); var properties = t.GetProperties(BindingFlags.Instance | BindingFlags.Public).Where(c=&gt; c.PropertyType == typeof(string)); foreach (var propertyInfo in properties) { var newValue = (string) propertyInfo.GetValue(value); if (!string.IsNullOrEmpty(newValue)) { newValue = newValue.ToUpper(); } propertyInfo.SetValue(value, newValue); } return value; } }
oooh, very interesting. I like it and am going to try it. I'm assuming that doesn't cover the member fields, but maybe I can handle them very similar to your code for the properties. thanks a bunch
LINQ could probably do this pretty easily without need for reflection
If you want fields (all fields) var fields = t.GetFields().Where(c =&gt; c.FieldType == typeof(string)); 
thank you very much. My group will be very happy to have this because we're going to have hundreds of classes with many members in each that will need upper case so will save a lot of potential errors where we could miss doing upper on every field.
Every marketing endeavor is a chicken-and-egg scenario. This is no different. Companies invest money in technologies that are endorsed by their customers. You have to look at the big picture with Silverlight. Silverlight had a passionate community but it was and still is a very tiny fraction of the size of the JS community. Personally I think JS sucks but as a contract developer you can bet it shows up near the top of my resume. I think the stakes are very high for Blazor - JS is long ready to be knocked off its throne and the company that gets there first - with a viable replacement - will be rewarded.
If you don't want to modify every location you use the properties, you could do something with Aspect oriented programming to tag the class property definition with attributes that replace the behavior at compile or runtime. PostSharp can do this.
(also untested) could do something like this: public static class MutableClassExtensions { public static T MemberwiseApply&lt;T, TM&gt;(this T value, Func&lt;TM, TM&gt; fn) where T : class { var t = value.GetType(); var newValue = (T) typeof(object).GetMethod("MemberwiseClone", BindingFlags.NonPublic | BindingFlags.Instance).Invoke(value, new object[0]); var properties = t.GetProperties(BindingFlags.Instance | BindingFlags.Public).Where(c =&gt; c.PropertyType == typeof(TM)); foreach (var propertyInfo in properties) { if (!(propertyInfo.CanRead &amp;&amp; propertyInfo.CanWrite)) continue; var propValue = (TM) propertyInfo.GetValue(newValue); propValue = fn(propValue); propertyInfo.SetValue(newValue, propValue); } return newValue; } } called like `var upperEmployee = employee.MemberwiseApply((string s) =&gt; s?.ToUpper());` This feels very wrong though... I feel a little better about this way: public static class MutableClassExtensions { public static T MemberwiseApply&lt;T, TM&gt;(this T value, Expression&lt;Func&lt;TM, TM&gt;&gt; fn) where T : class, new() { var t = value.GetType(); var local = Expression.Variable(t, "local"); MemberBinding BindProperty(PropertyInfo info) { return Expression.Bind( info, info.PropertyType == typeof(T) ? (Expression) Expression.Invoke(fn, Expression.Property(local, info)) : Expression.Property(local, info)); } var param = Expression.Parameter(typeof(T), nameof(value)); var exp = Expression.Lambda&lt;Func&lt;T, T&gt;&gt;( Expression.Block( t, new[] { local }, new Expression[] { Expression.Assign(local, Expression.Convert(param, t)), Expression.MemberInit( Expression.New(t), t.GetProperties(BindingFlags.Instance | BindingFlags.Public) .Where(p =&gt; p.CanRead &amp;&amp; p.CanWrite) .Select(BindProperty) ) }), param ); return exp.Compile()(value); } } called like `var upperEmployee = employee.MemberwiseApply((string s) =&gt; string.IsNullOrEmpty(s) ? s : s.ToUpper());`
A few things to note with this implementation: 1. bug - need to handle cases where properties do not have getters or setters: if (!(propertyInfo.CanRead &amp;&amp; propertyInfo.CanWrite)) continue; 2. this mutates the variable passed in instead of returning a clone that is modified 3. this modifies all members of the runtime type, not the compile time type
nice use of reflection using linq i didnt realise you could do that but seems obvious thinking about it. long time since i had to do reflection
I wanted to mention your concerns (After I posted) but didn't want to get into the weeds with what you validly pointed out
Yes true. The same is true of desktop windows now - we are supposedly on the last version which will just be updated forever, so I guess Microsoft see it more as a platform to access our eyeballs now.
Inject a connection string and not db connection? That's something I've never seen before. 
&gt; do this pretty easily without need for reflection Interesting... &gt; except you might need to explicitly select the properties Well, that's kind of the whole point. You don't really need linq at all if you just hardcode the whole thing.
That's how we used to always to it before people started getting fancy with their DI frameworks. Which is kinda sad if you think about it. By making the DI framework more powerful, they made the code worse. Now it isn't uncommon to see one EF Data Context being shared across multiple service or repository classes. This can have all kinds of unintended side-effects due to EF caching. Furthermore, how do you handle resource management? If ServiceA and ServiceB are sharing DataContextC, disposing either service will break the other service. So you don't make the services disposable? Now they are violation the .NET Framework Design Guidelines regarding how to handle disposable member data. In real terms this means that they can't be used in scenarios where you don't have the DI framework managing the web of dependencies. (Actually what usually happens is the integration tests just leak database connections.) But what if I want a transaction for the duration the web request? No, just no. Now you are holding database locks open for far longer than necessary. Which is going to kill your database's performance as all of your requests start running in series rather than concurrently. Automatic, web request level transactions are a horrible idea. And that's the only real reason to have the DI framework manage connections directly. **** All this goes away if you simply inject a connection string (or connection factory). Advantages: * Connections are opened and closed at the method level, minimizing the time the resource is in use * Services are now thread-safe, so you can make them a singleton's and stop wasting time allocating and initializing new ones * Services are easier to use in tests because you no longer need the DI framework to manage their lifecycle * Tricky things like EF Caching effects are far more manageable. 
Serialize to json/key value pairs, then use the json to tweak the values toUpper and deserialize back to the original object.
I'm really interested in what problem you're trying to solve because I can't wrap my head around the problem that needs this sort of solution 
I prefer NoSQL for simple applications. [LiteDb](https://github.com/mbdavid/LiteDB) works fine and is really easy to get started with. 
I'd recommend just creating a new class that [implicitly converts from `string`](https://stackoverflow.com/questions/3436101/create-custom-string-class) and overwrites `ToString()` with code that runs `ToUpper()`. so I'd do something like this: public class UppercaseString { private string _backingString; public UppercaseString(string backingString) { _backingString = backingString; } public override string ToString() { return _backingString.ToUpper(); } public static implicit operator UppercaseString(string input) { if (input == null) return null; return new UppercaseString(input); } } Then set all of your `string` properties to be `UppercaseString` and job done.
I’ve had to do this a lot. Best solution I’ve found that requires no custom development is using VS code multi-cursor + the change case extension. https://github.com/wmaurer/vscode-change-case The extension provides functionality to change case of whatever you have highlighted to a specific case (upper, camel, Pascal, etc.)
Agreed that constructors of your services should not be doing anything complicated or slow, but as an option you can inject services to a particular method instead of the constructor of the controller: https://docs.microsoft.com/en-us/aspnet/core/mvc/controllers/dependency-injection?view=aspnetcore-2.1#action-injection-with-fromservices
Bug - properties can be write only - use !canRead || !canWrite
Holy shit you just made my day - this is exactly the behavior I've always wanted
Can you explain what you mean by number 2? The method has class generic constraint, so you are only working with reference types, and is always working with the original reference to the item passed in. This method both modifies, and arguably pointlessly, or maybe for convenience, returns a pointer to the same exact object that was passed in.
I think this extension method should be void. 🤔 You’re returning the same reference you received as an argument.
I mean if you use this method and then write: var upperEmployee = Employee.ToUpper(); the variable `Employee` will be modified which is a little unexpected when reading that line. Both of the methods I provided [here](/r/dotnet/comments/92bzad/c_how_to_apply_toupper_or_other_function_to_each/e34nb1d/) avoid mutating the passed in variable.
Ah, I see what you meant now, thanks for clearing that up. I agree that a non-mutating version would be preferable here.
You are not making any sense whatsoever. This is open source and the company already knows the "customers" are there. No on EVER made the argument that they wouldn't try it out or give feedback. You just took it out of your own head that "I refuse to get too excited" meant that. Its time for MS to take the experimental off it and call it a beta or even an alpha. The longer they keep the experimental name on it is the less enthusiastic I will be (since I obviosly need to translate english - that does NOT mean not experiment of give feedback). C# is not the only non JS game in town with webassembly here.
You're correct
I agree. It threw me off for a second and had me thinking is this something I didn't know?
Good catch on #3!
Is there a good GUI for postgres? I tried I've one but it was kinda awful. I really like SQL management tools and operation studio
Look at this "sample" made by Microsoft: https://github.com/dotnet-architecture/HealthChecks
It's pretty common for extension methods, and builders. It allows you to chain calls. E.g. `Employee.ToUpper().Serialize()`. Not sure how useful it is here though. I'd prefer if it instead returned a *copied* instance.
Yeah I know people hate this kind of answer but there is probably a far easier/efficient solution to the root issue. Maybe simply formatting at input or output time.
Agree and it's why I was reluctant to move from SQL Server - the client tools are very good but the 1GB RAM cap is a killer unless you want to shelve out money. There are some good Postgresql tools but the best ones aren't free unfortunately but are still cheaper than database server licensing.
Probably a good idea to cache the compiled expressions too if it's going to be called a lot.
Yeah I was thinking about that, this particular implementation utilizes the runtime type of `value` when initializing a new one... a version that didn't would have a "decapitation" issue: public class Person { public string FirstName { get; set; } public string LastName { get; set; } public override string ToString() =&gt; $"{FirstName} {LastName}"; } public class Child : Person { public Person Mother { get; set; } public Person Father { get; set; } public override string ToString() =&gt; $"{FirstName} {LastName}, Mom: {Mother}, Dad: {Father}"; } public class Foo { public string DoStuff(Person person) { person = person.MemberwiseApply((string s) =&gt; string.IsNullOrEmpty(s) ? s : s.ToUpper()); // ... if person was a child, should they lose their mother and father? return person.ToString(); } } The generated method in the above implementation is intended to be something like: Person fn(Person value) { var local = (Child) value; return new Child { FirstName = string.IsNullOrEmpty(local.FirstName) ? local.FirstName : local.FirstName.ToUpper()), FirstName = string.IsNullOrEmpty(local.LastName) ? local.LastName : local.LastName.ToUpper()), Mother = local.Mother, Father = local.Father }; } if `DoStuff` is passed a `Child` instance, but Person fn(Person value) { var local = (Person) value; return new Person { FirstName = string.IsNullOrEmpty(local.FirstName) ? local.FirstName : local.FirstName.ToUpper()), FirstName = string.IsNullOrEmpty(local.LastName) ? local.LastName : local.LastName.ToUpper()) }; } if passed a `Person` or if the implementation was changed to use the compile time type... You could still cache this implementation, but it would need to be keyed on both the runtime type of `value` and the expression being passed in. As I don't know offhand how expression tree equality works, I didn't bother guessing. --- Every implementation suggested in this thread has significant drawbacks. I think the best one is to use a type other than `string` on the properties where this `ToUpper` functionality is desired, but it is fun to think through how you could do this even if it is a bad idea.
Luckily I'm running many tiny apps, so 1gb ram cap isn't an issue for me yet. How cool would it be if Operations Studio had postgres support?? The dream
Pgadmin4. Not as great as ssms, but quite useable
If I had to guess this is an integration with a legacy system that cannot and has not changed in maybe decades
That's a very wide ranging introduction. I wonder what the debugging experience is like in a serverless architecture?
MediatR is useful but it must be used judiciously. Remember it adds yet another layer of indirection to your system. Suddenly you can' t use "Go to definition" to see what's happen. You have to do one more lookup to figure out what's going on. Simple classes and methods/functions work just as fine as long as you pay attention to the input/output (e.g. don't take dependency on HTTPContext on your business layer, etc). Take a lesson from the functional programmers. They use much less ceremonies to get things done. 
Remember any talk about serverless architecture is also a sales pitch.
Unless the serverless runtime is cloud agnostic. Two easy examples, Azure Functions runtime is available as a container and you can run it on Google Cloud. OpenFAAS is serverless and runs on k8s anywhere. 
Ah nice. I wasn't aware Azure Functions runtime is available.
Ya it’s cool. Dude got it running on a Raspberry Pi http://tattoocoder.com/functions-runtime-kubernetes/ which is more useful than you’d initially think. 
Lol that's wild. You can probably build your own 16-node Raspberry Pi cluster for less than the cost of a Macbook Pro. 
You could run Windows with VirtualBox or install a multi-boot system.
Seems like a classic [XY problem](https://en.wikipedia.org/wiki/XY_problem) to me.
**XY problem** The XY problem is a communication problem often found in help desk or similar situations, in which the cause of a problem is masked because the person asking for help has presented incomplete information as to the source of their problem. This ambiguity in the real source of a problem leads to wrong, inaccurate, or unhelpful solutions being offered. The issue arises when the person with the problem thinks that they themselves have a partial solution to their problem, and only ask for the parts they think they are "stuck" on. On the other side, the people offering to help lack information as to the root problem, and thus cannot provide ultimately useful information. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I knew this had a name. Thanks for the reference 
True. I made a 6 node one for very cheap. https://www.hanselman.com/blog/HowToBuildAKubernetesClusterWithARMRaspberryPiThenRunNETCoreOnOpenFaas.aspx
So really this is an advertisement?
I think this section needs to address portability: https://docs.microsoft.com/en-us/dotnet/standard/serverless-architecture/serverless-architecture-considerations 
Entity Framework takes care of all the nitty gritty for you. All you need to is make classes to represent records/objects. EF generates a schema and database for you, and will even generate code to update a database schema if you need to update your classes. And you can choose any database backend that uses the System.Data interfaces. First or third-party libraries. 
IIRC it will get stored as an int so make sure you don't accidentally change enu.lm values; add new values onto the end or explicitly set values for each enum. Migration might fix up changed values if you change them, not sure.
Not true. It's a niche, for sure. Harder to debug, expensive and hell for something with sustained heavy use, but it has its uses.
What type of application is it? WPF?
I would try recreating the project, adding pieces from the existing one one at a time until the error appeared.
Is Program.cs listed as a Compile item in the .csproj? You could also build with Diagnostic verbosity and it should print the files in Compile. 
Is there a StartupObject property defined inside the csproj? https://csharp.2000things.com/tag/startup-object/
I've been trying out Blazor since they first showed it off and it's been really fun even though I know it's experimental. I wonder what do people hope to get from Blazor? Can it be used in place of old Silvelight apps? Can it be used instead of Angular/React/Vue? For me I'm looking at it from the latter perspective. If I can use Blazor instead of a JavaScript framework and it makes development easier instead of more complicated then I will. But I'm also interested in seeing how far Blazor can go. The blog mentions an Electron scenario for desktop apps (and there is an example). I've also seen it mentioned in regards to PWA. I wonder if Blazor can be used one day to make UWP apps?
Have you ever tried something like [https://www.codacy.com/](https://www.codacy.com/)?
You are trying to run a console application if you are getting that error.
Open the Nuget package manager and remove them from all projects in your solution. Alternatively I think (50/50 on this) there is an option for an Empty Mvc site which I think has none of that stuff. 
Thank you. I figured there’d be a way, empty by the way means totally empty with only setup files, For now I’ll just satisfy myself with removing the BS and jQ. Thanks again.
Why not just delete the script and style imports in your layout file?
On a MVC project, remove the packages on bower manager (right click on the project, related item on the menu) to delete de files. Then, go to the layout.cshtml and remove the tags about it. That's the easier way to have a full default project without bootstrap/jquery/whatever without use the empty project template. 
Can I also just delete the files without breaking anything? I was afraid to delete anything without knowing if it might cause something to break someplace else. I'm new to ASP.net, and just don't want to inadvertently break stuff. 
Yeah once you remove the script/style imports from the layout you can delete the files. Also any views already scaffolded out may have bootstrap classes that should be removed, although it won't break anything if you don't remove them.
That's just a beginner example, not a dependency of ASP.Net. Just delete it all or create an empty project.
Thanks, it wasn't as painful as I thought it would be at first, but I've got it up and running. There's just a lot more that I am not used to seeing, and didn't know what to do with yet.
Do you have multiple projects in your solution? If you have, are you sure you have correct project selected as statup project? F5 will try to run project that is selected as startup project. Right click project in solution explorer to set project as startup project.
Thanks for a very helpful response. I've decided to talk to my boss and ask extra time for training at work (where we have Windows machines). 
Unfortunately I don't have a copy of windows. And I don't intend to buy one just for this experiment. 
Another reason to add to the rediculously long list ... Is your main static method in program set with the async keyword? 
Just use the empty MVC project template and make this a whole lot easier. As others have said, Bootstrap is not a dependency of ASP.NET.
I'm not sure if I understand this, so lets say this is the address model public class AddressModel { public Guid ID { get; set; } public string Country { get; set; } public string Street { get; set; } public int AppartmentNumber { get; set; } } that is the model that is defined in my create view : @model App1.Models.AddressModel what you're saying is that the country string in the AddressModel should be replaced with public string SelectedCountry { get; set; } public IEnumerable&lt;SelectListItem&gt; SelectCountry { get; set; } is that right ? I tried this anyway and I got an error when migrating this change to the database The entity type 'SelectListGroup' requires a primary key to be defined. .... whats the difference between Models and ViewModels and how can I use them both in the same view ? Lil bit of a noob here :P
Lots of logging. If that doesn't help, try to step through the code running the event on your machine.
You don't have to replace `Country` with `SelectedCountry`, you just need a property that will hold the selected value of your country dropdown. It could be a `string` or `int` depending on what the actual data looks like. "Models" is a generic term that can refer to both domain models (the models representing your data, in this case generated either by or for EF), and view models (which are POCOs created to pass data to and from views/api endpoints/etc.). It's good practice to not use domain models directly inside views. In fact, you'll quickly reach a point where it's not feasible to do so anyway. Views will often require a number of secondary properties that have no direct relation to any database element, such as a dropdown list. Your domain models are what you'll pull directly from the database and view models are what you pass to your views, in a nutshell. For example: Domain model: public class Address{ [Key] public int AddressId { get; set; } // foreign key to some city reference table public int City { get; set; } // foreign key to some country reference table public string CountryId { get; set; } } View model: public class AddressViewModel{ public int AddressId { get; set; } public string City { get; set; } public string Country { get; set; } } In your controller or in a separate service, you'll pull the Address table from the database and return a new view model or collection of view models: IEnumerable&lt;Address&gt; addresses = _someMethodToRetrieveAddressesFromTheDatabase(); IEnuemrable&lt;AddressViewModel&gt; addressViewModels = addresses.Select(address =&gt; new AddressViewModel{ AddressId = address.AddressId, City = address.CityReferenceTable.CityName, // using navigation properties on the Address and City reference table Country = address.CountryReferenceTable.CountryName // again using navigation properties }); The reason you're getting an error when attempting to migrate your changes is because you're attempting to migrate what should be a view model property to your database. If you separate your models into domain and views, you won't have this issue. 
You could use a virtual machine on a better spec-ed laptop and you would probably get the same effect, but you end up with a overall better computer
I think I said that wrong. I think that unit tests are capable of giving you most of the coverage you need until the interactions become more complex (e.g. Sagas), then integration testing starts to climb in value, so it's iterative. Integration testing *is* important. As always, you should criticize the value of any test and keep the test suite for every boundary as small as possible, which means you add coverage as it presents value. IMO, integration testing is seldom valuable in young projects. So back to your original comment: &gt;Well but i am guessing you now have to have unit testing and integration tests for 30 services, plus have to monitor those 30 services. Life isn't that much simpler now, is it ? It depends. It's not that much harder either -- but that is, again, dependent on how you approach it. Unit testing was always a requirement, so there's no pain *added* there. Monitoring (logging and kube cluster monitoring) was always there, so no pain *added* there either. What I meant when I said it wasn't best practice was that there isn't much value in them... until there is. Integration tests become more important as the inter-service communication becomes more complex. For example, our MVP for this architecture had about 20 services, but the communication was mostly straight forward; each operation usually only contacted a single service at a time (no sagas). All the internal services operated over a bus which makes it easy to get full coverage in unit tests (no need for integration tests) -- if the handlers worked, everything worked. We didn't find much value in writing integration tests at this stage, so we focused on logging and dependency injection which gave us hooks for integration tests to be added later. Essentially, integration tests were only between the client(s) and the gateway, for which the data sources were mocked. Easy. Inter-service communication is done over a bus, so unit tests take care of everything there. Easy. With regards to building in the necessary hooks for integration testing, I used to be of the mind that you better start now before the system grows to the point where it'll be 10x harder to add after the fact. After doing this for a while, I found that this wasn't necessarily true so long as you're doing your due diligence in creating those test points (e.g. test mode, logging, etc.) along the way which facilitates the debugging process anyway and is just good engineering. That's cultural; my team tends to write that stuff in along the way. Then creating integration tests is just a matter of utilizing those features along your test boundary. We always want to add value with unit tests, not just write them for the sake of coverage, so write them at the appropriate level at the appropriate time, and then your pain should be about the same (lol).
The output of building with diagnostic verbosity has "Program.cs" in it 6 times but I'm not sure what to look for. If I right click MyAppWebSuite and select Edit MyAppWebSuite.csproj, then the only item that has "compile" in it is: &lt;ItemGroup&gt; &lt;Compile Update="Properties\Resources.Designer.cs"&gt; &lt;DesignTime&gt;True&lt;/DesignTime&gt; &lt;AutoGen&gt;True&lt;/AutoGen&gt; &lt;DependentUpon&gt;Resources.resx&lt;/DependentUpon&gt; &lt;/Compile&gt; &lt;/ItemGroup&gt; Also, I've been told this is a .NET Core project and here: [https://docs.microsoft.com/en-us/dotnet/core/tools/csproj](https://docs.microsoft.com/en-us/dotnet/core/tools/csproj) under "Default compilation includes in .NET Core projects" it says something about no longer needing to specify compile items.
No, the Startup object is set to "(Not set)" and there are no other options in the drop down. However, I created a new project as a test and it runs fine with the Startup object set to "(Not set)".
Yeah, .net core projects are different. Can you share the contents of your .csproj file?
text-transform: uppercase;
Here it is(FYI I'm using Windows 10): &lt;Project Sdk="Microsoft.NET.Sdk.Web"&gt; &lt;PropertyGroup&gt; &lt;TargetFramework&gt;net46&lt;/TargetFramework&gt; &lt;RuntimeIdentifier&gt;win7-x86&lt;/RuntimeIdentifier&gt; &lt;/PropertyGroup&gt; &lt;PropertyGroup&gt; &lt;PackageTargetFallback&gt;$(PackageTargetFallback);portable-net45+win8+wp8+wpa81;&lt;/PackageTargetFallback&gt; &lt;/PropertyGroup&gt; &lt;PropertyGroup&gt; &lt;UserSecretsId&gt;some guid id&lt;/UserSecretsId&gt; &lt;/PropertyGroup&gt; &lt;ItemGroup&gt; &lt;None Remove="Properties\PublishProfiles\FolderProfile1.pubxml" /&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;Content Include="wwwroot\css\site.css" /&gt; &lt;Content Include="wwwroot\css\site.min.css" /&gt; &lt;Content Include="wwwroot\lib\Information.wav" /&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;PackageReference Include="Microsoft.ApplicationInsights.AspNetCore" Version="2.0.0" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.Authentication.Cookies" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.Diagnostics.EntityFrameworkCore" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.Hosting.WindowsServices" Version="1.1.2" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.Identity.EntityFrameworkCore" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.Mvc" Version="1.1.1" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.Server.Kestrel.Https" Version="1.1.2" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.Session" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.AspNetCore.StaticFiles" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.EntityFrameworkCore.Design" Version="1.1.0" PrivateAssets="All" /&gt; &lt;PackageReference Include="Microsoft.EntityFrameworkCore.SqlServer" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.EntityFrameworkCore.SqlServer.Design" Version="1.1.0" PrivateAssets="All" /&gt; &lt;PackageReference Include="Microsoft.EntityFrameworkCore.Tools" Version="1.1.0-msbuild3-final" PrivateAssets="All" /&gt; &lt;PackageReference Include="Microsoft.Extensions.Configuration.UserSecrets" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.Extensions.Logging.Debug" Version="1.1.0" /&gt; &lt;PackageReference Include="Microsoft.VisualStudio.Web.CodeGeneration.Design" Version="1.1.0-msbuild3-final" PrivateAssets="All" /&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;DotNetCliToolReference Include="Microsoft.EntityFrameworkCore.Tools.DotNet" Version="1.0.0-msbuild3-final" /&gt; &lt;DotNetCliToolReference Include="Microsoft.Extensions.SecretManager.Tools" Version="1.0.0-msbuild3-final" /&gt; &lt;DotNetCliToolReference Include="Microsoft.VisualStudio.Web.CodeGeneration.Tools" Version="1.0.0-msbuild3-final" /&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;Folder Include="Data\MyAppMigrations\" /&gt; &lt;Folder Include="wwwroot\lib\quagga\" /&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;Reference Include="MyAppSearch"&gt; &lt;HintPath&gt;..\..\..\..\..\..\..\somedir\MyAppSearch.dll&lt;/HintPath&gt; &lt;/Reference&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;Compile Update="Properties\Resources.Designer.cs"&gt; &lt;DesignTime&gt;True&lt;/DesignTime&gt; &lt;AutoGen&gt;True&lt;/AutoGen&gt; &lt;DependentUpon&gt;Resources.resx&lt;/DependentUpon&gt; &lt;/Compile&gt; &lt;/ItemGroup&gt; &lt;ItemGroup&gt; &lt;EmbeddedResource Update="Properties\Resources.resx"&gt; &lt;Generator&gt;ResXFileCodeGenerator&lt;/Generator&gt; &lt;LastGenOutput&gt;Resources.Designer.cs&lt;/LastGenOutput&gt; &lt;/EmbeddedResource&gt; &lt;/ItemGroup&gt; &lt;/Project&gt;
Never heard of function memoization before, thanks for including a brief explanation in the readme. Nice work!
There are two projects(MyAppWebSuite and UnitTestWebSuite). I right clicked and set MyAppWebSuite as the startup project and I'm still seeing the issue.
It does appear to be a console app but I tried creating a new project that is also a console app and when I F5 that it builds fine and launches in a browser. FYI - I believe my problem project is a .NET Core project which might make a difference.
No, there is no async keyword in the function signature.
How exactly would I do that? Create a project with the same template/settings and then copy whole directories? How can I be sure that I am using all the same templates, settings etc.?
That looks good to me. You can check to ensure Program.cs is being compiled in the following ways. 1. Check the Build Action of Program.cs in the Properties grid. It should be set to "C# Compiler". See my image at https://www.dropbox.com/s/ilhspix4mcwqbuk/vs.PNG?dl=0. 2. Do a build with Diagnostic verbosity. After that search for **Building target "CoreCompile"** then scroll until you see what is being passed to the **Sources** parameter. You should see Program.cs listed, for example see my snippet below. 1&gt; Task Parameter: 1&gt; Sources= 1&gt; Controllers\HomeController.cs 1&gt; CopyToOutputDirectory=Never 1&gt; Models\ErrorViewModel.cs 1&gt; CopyToOutputDirectory=Never 1&gt; Program.cs 1&gt; CopyToOutputDirectory=Never 1&gt; Startup.cs 1&gt; CopyToOutputDirectory=Never 1&gt; C:\Users\sayedha\AppData\Local\Temp\.NETCoreApp,Version=v2.0.AssemblyAttributes.cs 1&gt; CopyToOutputDirectory=Never 1&gt; obj\Debug\netcoreapp2.0\WebApplication26.AssemblyInfo.cs 1&gt; CopyToOutputDirectory=Never 
I’m not sure why you would want to memoize function calls in between requests and not just use a cache. You get a free memory cache and can easily set up a redis cache if you want a distributed one. 
All your cs files are marked as Content. They should be Compile. Select each one in the solution explorer, right click, select properties, change Build Action to "Compile".
Apologies, but I do not know much about Terminal.Gui; however, my guess would be to use the .Remove(View) function similar to how you're using the .Add(View). Documentation for TopLevel (which is where you'll be adding / removing) can be found here: [TopLevel](https://migueldeicaza.github.io/gui.cs/api/Terminal.Gui/Terminal.Gui.TopLevel.html) Best of luck
The same place that Oracle's went to. Microsoft is heading in the right direction, but 20 years of shitting on the open source community won't be fixed in a couple years.
Up until very recently, MS didn't make any sense for startups. This starts, but by no means ends with pricing, but the fact that you have to swim through an ocean of licensing shit just for the privilege of buying their stuff ought to be enough to deter most companies without dedicated procurement staff. 
Funny thing, there was Microsoft Training to be a Microsoft Certified Licensing Expert.
I was not very precise, the asp .net application where I used memoization was not just to cache controller responses.
I work in a startup running on .Net core in docker
A few years ago, it made sense to build your startup using non MS stack. Now it's more "it depends". 
I'm hoping more startups start to choose aspnet core. I think Microsoft has put things together to a point where it is a competitive web development stack again. aspnetcore is cross platform. You don't need a Windows Server license or IIS to host aspnetcore. SQL Server Express is free on Linux for smaller sites or PostgreSQL can be used. Visual Studio community is free on Windows. There's a free "Visual Studio" on MacOS. Visual Studio Code is one of the most popular code editors. Azure is competitive (though I personally feel it's expensive). What other things are startups looking for that Microsoft's stack doesn't offer/support? I'm sure there are other things I missed and am interested in areas where Microsoft's stack is lacking. I'm always pretty excited when I see a new web site pop up using aspnet core. It would be cool if the aspnet development community grew. 
Seems like a better question for their github page than a general .net forum 
Automapper can do that with the ProjectTo. We are totally exposing different objects. THAT SAID..... THe odata team development speed makes a rock look fast and the nubmer of bugs on even the most basic operations is ridiculous. GUID is not supported in query strings (the literal just does not aprse), you can not insert new objects that NEED to refrence other objects (odata.bind syntax for properties is just ignored). Of all of Microsoft this is the most buggy software I have seen in 30 years and seems to be programmed by 2 people in their spare time on fridays - IF it is not raining and their TV is broken or something like that. Head over to github and see a commit every month or so (ok, dramatizing, but it is brutal if you compare it to EF Core and the bugs are in seriously basic things).
I'm working on a product that I hope someday will be my primary source of income. Based on my exposure to aspnetcore in my internship, I've been building it in .net core for about 6 months now
I believe .net core is a good choice for startups, I am in a startup too, it's a good choice for us.
And even if you ask two of these clowns, they will give you three conflicting answers.
We use traditional .NET and Azure. We're about 2 years old, and everything for .NET core/ASP.NET core wasn't nailed down yet, so we decided not to do so. We've considered moving to .net core, but the need is not urgent enough yet. We make heavy use of Azure services to run everything, instead of rolling our own. I think one reason you're not going to see MS tech on those kinds of list is because we're too busy GSD to go out there and signal about our tech stack - it does nothing for us at the moment, and is just a distraction. Maybe some day.
Same. I don't know why people still cant get over their bias. Working with .NET Core is a pleasure. I have been working with .NET Core 2.1, Postgres and ReactJS. Couldn't be more happy with my stack 
The '[ASP.NET](https://ASP.NET)' community is pretty large. The article was only about startup culture. [ASP.NET](https://ASP.NET) Core will come around to having a large community, but it will take 5+ years for Enterprises to slowly re-platform systems to it.
The person writing it was surprised Ruby is so popular with startups - Rails is super fast to develop with, I can't think of anything better for getting something out the door quickly. Also SQL Server is mentioned - why would a startup use SQL Server which is proprietary and until very recently only ran on Windows? A curious article.
Until recently, .NET only ran on Windows (no I'm not counting Xamarin). Look at the list of companies again, and forget about the app's tech stack. Could any of those apps be built with Windows as the server OS? Don't they need to scale horizontally? Wouldn't that incur licensing costs that also scale horizontally? Linux is the only real solution, and so unless you were doing Xamarin, .NET was out. .NET is a fine technology. It's Windows that's the problem. 
So what makes companies that use other stacks different? Why do they have the time to talk about their tech stack?
Agreed with all the above!
Personally, I think .net core is a great choice for startups. * it's free * it's fast * it scales * c# can be used on pretty much every platform, from web to mobile to desktop, increasing team productivity and reducing complexity * it's cross-platform so infrastructure costs can be kept in check * it's got the development know-how of MSFT behind it. Let's not forget MSFT got started building development tools, not consumer software I've written 2 article about this, [here](https://fluxmatix.com/en/blog/10-reasons-why-csharp-is-alive-and-kicking-in-2018 and [here](https://fluxmatix.com/en/blog/7-more-reasons-why-csharp-is-alive-and-kicking-in-2018-community-edition). Also, to give some more exposure to people, teams, and companies using .net tech i've created [BuiltWithDot.Net](https://builtwithdot.net/) as a place where developers working with .net technology can showcase their projects and inspire other developers. There's so much you can build with .net these days that I thought it would be nice to have a corner of the web dedicated to the breadth of .net.
It didn't disappear, it was never there to begin with. If you're developing on OSX/Linux and deploying on Linux, .Net simply doesn't bring enough to the table to adopt it instead of a JVM language. The JVM IDEs are better, there's a huge library ecosystem and there's more collective devops experience available. 
+1 for .net core on mac. It's great.
Great response. Why does this reply only have 2 upvotes?
SQL Server is too expensive. It's that simple. And although .NET can use other databases (albeit not as nicely), by the time you've decided to go with MySQL/Postgre, most startups will think along the lines of "Well, we may as well skip the Windows hosting altogether and go Linux", and once you've done that why bother with .NET Core anyway? The licensing is a hassle, Windows hosting/servers are more expensive, .NET Core is great but not mature, but mostly it comes down to SQL Server being too expensive. As a developer I love .NET Core, but I can't make a solid business case for using it over anything else. And yes, I know SQL Express is a thing - but it has limitations. Even if you know you're 99% sure you'll never hit those limits, people will instinctively shy away from software limitations... because why deal with that 1% potential for hassle when SQL Server doesn't really do anything MySQL can't? Improving the licensing would help, better Azure free and cheap tiers would help (right now it's barely acceptable for a small hobby - certainly not good enough to attract a startup who will pay more later as they grow), and .NET Core maturing will help. But for me it 100% comes down to SQL Sever being too expensive, and the fact that once I've decided not to use SQL Server I'll just use another stack
While I'd agree with this, I don't think the MS Stack has *overtaken* other stacks, just caught them. So if you've spent the last 10 years with a "MS = Enterprise, not startups" mindset, you probably won't even consider it. And even if you do consider it, there's unlikely to be a good enough business case to move outside your comfort zone.
[removed]
[removed]
[removed]
Assuming that the entire file looks like this, the data is gone. There is no useful data to copy or recover, it's all just zeroes. Restore a backup. If you don't have a backup, you're screwed. You could try your luck with some file recovery/undelete tools to find older copies of the file on your hard drive, but I wouldn't get my hopes up.
Power cuts and visual studio don't play well together. That file is toast.
Thanks for the harsh news... Nah I did not have any other backups other than the one on the project. Feels bad man. One of those freak accidents I guess.
Sounds like your file is corrupt, so all the content would have been lost. Some IDE's create a backup copy for your unsaved files. You'll have to dig a bit to find out if yours does. It takes seconds to create a local git repo that would have prevented this from happening. This should really be done for everything.
Init and branch, you fool, init and branch!
I understand. In Asp.Net core, you can inject a cache that you can add things to and get things from by unique string identifiers. It does not need to be linked to a controller. 
Developer experience is amazing for .net core with resharper. No stupid gigabytes of npm packages, no weak types of python. Go is quite nice, too. But vs debugging with stack rewind and visualisation is unmatched 
If you are using Visual Studio take a look in the auto backup folder. There might still be a copy there. Generally it will be in Documents/Visual Studio &lt;version&gt;/Backup Files/&lt;Project Name&gt;
Sure, but developer experience is usually a distant second priority to cost. I don't agree with that, it's just the way things are - and I think a lot of companies miss the "Your developers are a cost too" thing, and that making their life easier means you spend less time recruiting and get more done. But that benefit is a lot less visible in the bottom line, so cost wins on the priorities
What cost is that though? .net core is free, code runs on linux just like ruby/jvm/python does. Vs (for a startup) is also free.
Only thing I recall having like this was I copied and pasted the server name from vs and it was being copied with an extra backslash before the instance name 
That where you should start using git.
Was a small legacy project that did not really require a git.
.NET Core 2.1 is a great choice, but it's also fairly recent. Even just a year ago, betting your company on ASP.NET Core seemed much riskier. Two years ago it was downright scary. I was building a business-critical web service around the time that the project.json/.csproj switch was happening, and I went with Go because the rate of change in .NET Core and ASP.NET Core was just too spooky. Looking back, I still think it was the right decision. I think ASP.NET Core is an excellent choice _now_, but it's going to take some time before startups building new technology right now develop into behemoths like AirBNB.
All code should be in version control. No exceptions. Now you know why. 
You are wrong. You do not have to count Xaramin. The Mono project has been around for a long time and just because Xaramin made major contributions to the project does not mean Mono, the crossplatform .NET implementation, has not existed for a very long time.
I took a similar approach actually. I was heavily dependent on .NET framework but I never really liked its strong ties with the Windows Ecosystem. Then came the .NET Core and I was speculating some major changes between the versions, which I was right to wait about (the project.json to .csproj transition). I waited till .NET Core 2.0 and used it as a base for my projects. Only recently, after looking into v2.1, I am currently running a pet project on it. Will only use it in production once I am satisfied.
I hope this is not against rules or something, but this is too sweet deal to not share ...
Yes of course, that is very true and idiomatic. I my case I had different layers and services running that all together made the application, it wasn’t only a single asp net core application. I was vague about that because it didn’t add anyhing of value to talk about exactly where and how I used it, I only wanted to give a reason why I wrote all this.
JVM IDEs are better than VS?
You should version control everything. It takes practically no time and prevents stuff like this. Bitbucket offer unlimited free private repos if that's an issue. And even if you don't use a remote (which you should as it is essentially a backup as well) local repos still allow you backtrack. There's no reason not to really.
I've been in the Postgres (and Elasticsearch) world for the past 10 years, but before that I used to maintain MS SQL Servers. To be honest, the tooling around SQL Server and production operation is much better than the open source counter parts. Postgres has been evolving rapidly and third-party tools like barman and repmgr are great, but they are solving problems that have been "solved" in MS SQL for 20 years. I understand that people don't want to deal with licensing at all (even if it were cheaper), and startups don't worry about operational aspects of their tech stack until they have real customers and it starts causing problems, but I guess that's why I get paid to do what I do! :)
I think there may be a lot of companies who use .net internally. 
Alllllll code should be in git. And in visual studio, turning it on and using it is the matter of three clicks or so.
Thanks, mine expires in 20 days. Just renewed it at discount.
So the price will always be e.g. €89 for Rider + ReSharper? Or only the first year? That isn't completely clear to me.
Per the FAQ: &gt; Will the discount automatically extend to next year's subscription? &gt; No, next year's price will be calculated based on the standard continuity discount rules. 
Thanks!
Mine expired soon, nice to get a good offer for renewal :)
Dev experience with dotnet core and postgres is as good as mssql. Just add in the nuget package npgsql, configure startup.cs, and you are good to go. 
What's missing is that next year you'll get 20% discount from the full price (because it's going to be your second year). 3rd year is 40% off.
Mine just renewed 4 days ago =/ contacting support to see if I can get into this deal, really hope I can.
Like everything it's subjective to what you are used to. I can safely say from using VS for the last 8 years and more recently VS Code I would never go use anything else. It just works, and has everything I need in one place. 
SQL Server (and if you’re not using sql server, why use .NET over another stack?) Windows hosting, or someone with enough expertise in. .NET Core hosting on windows, which is pretty niche. Plus you’d expect ongoing maintenance costs due to it being an immature technology Visual Studio is free for up to 5 people, but even a startup can quickly bust that and then you’re looking at thousands of dollars for licenses...
FYI if you already have a Jetbrains license you can upgrade for free if the discounted product pack is &lt;= in price to what you paid. I just switched from Resharper Ultimate to the all products package for free.
yes, on OSX &amp; Linux. There are startups that exclusively develop on Windows but they are few and far between.
SSR with node is damn nice.
Whom uses visual studio with dotnet core tho? Everyone is using visual code with dotnet core... If you need visual studio then money really isn't or shouldn't be a problem for your startup.
`Program.cs Program2.cs Program3.cs Program.cs.bak Program.cs.old Program-final.cs Program-final2.cs Program-actualfinal.cs` 
Okay, everyone says you're probably screwed, but *there might be salvation*. Visual Studio, like all Microsoft products, saves files a little weirdly to avoid concurrency issues (this has plagued me beyond belief trying to monitor a folder for Word documents). It saves the file in a temporary or working file, then does some renaming magic to make the working file the "right" file on disk. There *might* be an oddly named file in your project directory that *might* still have your data in it. It's a long shot, but it could be there.
/Old Programs ProgramLatest.cs
Nice project initiative! One question if I may, why are you naming you files with an underscore, i.e. `Memoizer_Base.cs`?
Convention I’ve inherited from previous workplaces. Partial classes where always: PartialClassName_NameOfTheSection
They're recruiting.
&gt;if you’re not using sql server, why use .NET over another stack? You're assuming SQL Server is the main selling point of .NET, which is a bit odd. If you wish to use another database, there's probably a driver for it on Nuget.
The business case for it is if you have people who already know how to use C# then they can have a functional web app up and running in 4 hours that runs on any platform.
Got it!
I recently joined a startup that is using C# and I am learning that the language has a lot of benefits. That said, by example I will cite the lack of anything resembling a usable ORM. Yes, somebody ported the idea over, but it's a frankenstein's monster of complexity. The thing about Django/RoR is that you get a dead simple ORM layer + schema migration system. It's so accessible and usuable it's a no-brainer. At my current startup the conversation is about how they tried ORMs but don't get why they're useful; writing SQL by hand is better. The ORM is just an example of a bigger concept, and that's tools that allow for rapid development and iteration on a product. The innovation is happening in Python, Ruby, Node, Rust, and Go. I'm not entirely sure what dotnet is doing, but it appears to be chained down by backwards compatibility and making sure they don't do anything to break those billions of lines of legacy code used by banks.
Nowhere...?
We're using .Net core on linux, we use it because we like C#. SQL server was not a consideration going forward because of cost (we do use it for legacy systems). For databases we use MariaDB/Galera Cluster, Cassandra/ScyllaDB, Redis. The reason to use .NET Core is C# and the ecosystem around it that is re-invigorated and growing and evolving rapidly over the past few years.
My company has built a few million dollar applications on top of dotnet core and Angular. We started with Angular 2 and dotnet core 1. We rolled with the punches and we definitely had some bleeding edge instead of cutting edge type of situations. That being said, given our 2 year's of experience with both frameworks our developers can get high paying jobs anywhere. We are on the forefront of technology and we are all but guaranteed 10-15 years of runway before any framework changes are required. We feel fairly future proofed at this point and we are turning out websites and dotnet core REST Api's every 6 months.
You are granted a perpetual license. That means you don't loose access to your software after the first year. Unless you require updates you don't have to keep paying for the license.
It's certainly existed, but not in a form that sane startup founders would want to bet the company on. If you run into problems at scale, who's going to help you? There's neither a large community nor an obvious vendor.
Jetbrains rule. I hate it when I’m forced to use eclipse or worse.
Nobody is forcing you to use SQL Server instead of MySQL, Postgres or whatever. I just do not understand where this myth comes from. And it's not *that* expensive. It's a pretty great DBMS for a fair price, although clearly overkill for simple web stuff or god forbid packaged software.
That’s nonsense. Visual studio code is crap, and VS is a great IDE. I love it in enterprise, but it’s expensive for a startup 
How long have you been programming?
Thank you for the response. I've been through the documents and the issue is there is no way to know what is in the view from what I see. And RemoveAll appears to have a crash bug in it that seems to be noted in Github by a few folks. I really do appreciate you trying to help me out, and will take another stab at the documents. Thanks again.
15 years
Thanks, i'll try there. I just felt that since libPCap is such a universal tool it is more of a generic question than a specific question to the lib itself.
I respect your opinion but urge you to try visual studio code one more time. Your opinion of it would be neutral as a worst case scenario. I'm also surprised that you think it's crap since back then everything was command line. I figured older programmers would feel at home with CLIs becoming popular and IDEs becoming fancy notepad++s.
I've been using https://github.com/Xabaril/BeatPulse for more or less the same scenario
Sorry mate, we use full VS, resharper’s navigate to sources is hard to beat
Visual studio community is free up to $1 mln in revenue. Sql server is totally optional. We chose it over other stack because it is so much nicer to code and debug, provides sufficient performance, and is free. And .net core runs just fine on linux. 
It’s free for up to 5 developers and $1m revenue... whichever is first.
Talking about back then isn’t really relevant... we’re talking about right now. Why would my opinion be neutral when comparing code to vs? The latter is more powerful, more customisable, has far more add-one, and is generally just a much more pleasant IDE to use
r/TIL. Thanks for that
Just had an unpleasant experience with their Forgot Password feature as I don't remember it for my account. It requires you to know your password (that you forgot) in order to reset it.......
Probably just one is better than VS - Intellij IDEA. Eclipse is just so-so, NetBeans is mostly dead and JDeveloper is awful.
SQL Server doesn't do anything that MySQL can't? Lol, mmmkayy.
This "one year" nonsense has got to stop. Makes sense for a business, but for individuals it makes no sense.
The answer is pretty simple: ALL of those run on Linux. No startup will begin with Windows because of the horrible licensing (not even talking about the cost, just understanding it is a nightmare). .NET Core, which runs on Linux, is too recent to be used by big startups. We'll in the next couple years if the picture changes or not. Java and .NET are now much more on equal footing as far as use cases go.
Hoping they run similar deals when I no longer have access to an .edu address! I recently switched over from paying for R# (was worth it, but money was tight) to using an academic license and getting it unlocked for their whole suite. At least I can try out the rest of their products in my own time now.
I loved you, Resharper, but you are no longer needed. Visual Studio 2017 Community plus a few plugins now far exceeds what this bundle provides, and for free.
Though it's a bit hidden you do get a license for the major version that's out at the time you start your 1 year subscription. It won't expire. Still though for individuals yearly to get latest version at the price they ask is perhaps a bit much with the direction everybody else is going. Guess that's the difficulty in being a 3rd party and no payoff just for converting people to the languages and stacks your tools are for.
Which plugins do you recommend to get a similar experience?
Thanks! Ya did good!
[removed]
The down side with Asp.Net as an example is the convoluted internals. It’s gotten tremendously better than it used to be with MVC, but it’s still not at the simplicity that Go is at. On the plus side, the tools are great. The IDE is unmatched. And the language has great features. OPs comment about .Net core not being there yet isn’t something I’ve run into lately. 
That is interesting. I've always used SQL Server and while I've always used Windows hosting the reason I've only just now started to look at aspnetcore on Linux is because there is SQL Server on Linux. For most of my sites SQL Server Express is more than adequate. The sites just need a simple data store and I've never run into performance or size limitations. They already use SQL Server and I don't necessarily want to switch out the data store for sites I am just maintaining. Actually a lot (most?) cheap Windows web hosting companies use SQL Server Express and there are tons of small and hobby sites that take advantage of that cheaper, less secure and less robust set up. I think there is definitely a place for that type of set up. However, PostgreSQL is totally free without any kind of tiered structure and if people are going to tell me that it's just as good and easy as SQL Server I will probably start taking a look. I use PostgreSQL for other projects but never considered it for aspnetcore because the last time I checked it wasn't as easy as using SQL Server with EF Core. If I was mistaken about that I am going to be pretty happy. One reason I like SQL Server is because I have all my tools set up to manage it. SSMS, SQL Ops Studio, Visual Studio and VSCode all have great clients for SQL Server. I just find SQL Server easier and more fun to work with.
Check out pgadmin 4. That and npgsql are all you need.
It seems you don't need to use Windows hosting anymore. aspnetcore seems to work well on Linux hosting. That eliminates the Windows licensing costs. SQL Server Express is available on Linux. Unfortunately higher tiers of SQL Server have fees and I doubt that is going away. However there seem to be alternatives. Postgresql can be used with aspnetcore and that's free. I am planning to take a look at that to see how easy/hard it is to use in place of SQL Server. I haven't used Visual Studio in a year. VSCode has been doing okay for me. In any framework if you want the best IDE with all the bells and whistles you are likely going to pay for it. With aspnet that's Visual Studio. With other languages it could be one of the Jetbrains IDEs. Lots of developers use Sublime, VSCode, Atom, etc. I use VSCode for Ruby, Python and Go as well. So for me the question is why not consider aspnetcore? I'm not saying aspnetcore is better than any other framework/solution, but I am saying it's no longer tethered to Windows and SQL Server like [ASP.net](https://ASP.net) was. One might even prefer to do aspnetcore development on Linux or MacOS. I think it's great the Microsoft has pulled [asp.net](https://asp.net) development up to where it follows popular developer workflows.
While taking a fees as expensive as buying all the three different alternatives.
How is your experience with postgres + aspnetcore + entityframework core + Identity? I'm using sql server, but am planning to look at postgresql. Something I'm hearing recently is that Postgresql works well with aspnetcore. 
From my experience a lot of developers are just not aware of the current state of [asp.net](https://asp.net). Most of the things I hear: 1. You have to use Windows to develop [asp.net](https://asp.net) sites 2. You have to use Windows to host [asp.net](https://asp.net) sites 3. SQL Server is expensive and/or you have to use SQL Server 4. WebForms is bad 5. [asp.net](https://asp.net) is closed source 6. Microsoft is an enemy of open source 7. I've never used Windows Aside from #7 even some developers who are [asp.net](https://asp.net) developers think that's the current state of asp.net. I guess that's the challenge Microsoft faces in general in a lot of stuff it does. It will take time for aspnetcore to dispell that image.
No, but at the end of the year you have to *downgrade* to an earlier version if you don’t renew because of JetBrains retarded customer-hostile subscription model.
I'm trying to learn .Net Core, but I'm lost, do you recommend an in-depth tutorial?
I am not sure I can understand the 'lost' word : ) If you have tried the docs from MS, I believe it is time to check and maybe write some small project by yourself. Or read some books, such as &lt;C# in depth&gt; &lt;CLR via C#&gt;. again, I don't know which part made you feel 'lost', I hope my words can give you some help. 
Is VS Code likely to make headway there?
That is not a tuple. That is just an async lambda that takes two parameters.
[removed]
TIOBE is a worthless measurement that says nothing about actual popularity. Frankly, the only people using VB.NET are - people who have a VB6/A background and feel more comfortable with it - people working for companies having to maintain ancient VB.NET applications - students who learn it in school because the course hasn't changed for a decade and their computer lab probably still has VS2008 Express installed I'm not saying VB.NET is a useless language, you can use it in place of most C# use cases if you really want to, but it is on life support and I very much doubt it is experiencing any growth let a lone this kind of absurd popularity. ^^^^Even ^^^^though ^^^^it ^^^^has ^^^^XML ^^^^literals.
Sad to read as .net dev. I agree with a lot of comments here about sqlserver. I wish MS made it free. Im sure more people would be inclined to use azure if the MS stack was cheaper
This is a VERY old list, but I've put the best ones at the top: These will make your life better: - Roslynator 2017 - Roslynator Refactorings 2017 - Visual Studio IntelliCode - Preview - Solution Error Visualizer - GitFlow for Visual Studio 2017 - Match Margin - Time Stamp Margin - Git Diff Margin - Power Commands for Visual Studio - RemoveTrailingWhitespaces - Trailing Whitespace Visualizer - Multiline Search and Replace - Open Command Line - Visual Studio Spell Checker (VS2017 and Later) - Regular Expression Tester Extension - VSColorOutput - Add New Files - ASP.NET Core Blazor Language Services - Roslyn Interactive Components - Roslyn Language Services - Roslyn Expression Evaluators - Markdown Editor 
Considering jumping on this for Rider. I've grown quite fond of Visual Studio Code, but it still has no code completion for Razor.
Also end up with a faster, more stable ide. I've regretted every dollar I've sent to jetbrains.
Thanks! The performance of reshaper with Core is making me consider removing it.
absolutely, VS Code is great and has gotten massive adoption outside of the .net world so it has the benefit of being familiar to Linux/OSX developers in case they start .net development.
Really? Ouch.
Simplicity is in the eyes of the beholder. I have learned C#, Php, Ruby javascript, python, Elixir and Dart and no language has looked more ugly and convoluted to me as Go when you really dive into it.
We've started using Postgres with [asp.net](https://asp.net) core and not yet had any issues.
This sums it up. To be fair number 1 has a little bit of understandable validity. Though a lot of people know you can use VS code on Linux most people would want to develop using Visual studio and are unaware of recent alternative IDEs that run on Linux
Check udemy for some project based courses. Pluralsight also has some decent series. You can get a pretty long trial of pluralsght free through MS.
I felt that C# has been one of the better languages pretty much since it's inception, but was always held back due to limitations and platform dependence that came with the .NET framework. I'm probably biased since I'm heavily in the .NET ecosystem, but I the reasons to choose Java over .NET Core grow more slim day bu day, as .NET Core tooling improves. 
&gt; That said, by example I will cite the lack of anything resembling a usable ORM. ORMs are overkill half the time, and are prone to overcomplication. imo, Micro-ORMs like Dapper and petaPoco are what should be used most of th time unless the advanced features that ORM provide are required. &gt; I'm not entirely sure what dotnet is doing, but it appears to be chained down by backwards compatibility and making sure they don't do anything to break those billions of lines of legacy code used by banks. .NET Framework does have backwards compatilibly concerns, however .NET Core is a complete re-write and has been the rapidly growing and isn't chained down by anything. .NET Core is one of the fastest frameworks out there currently. 
I have zero experience with going down that route. I personally prefer macOS and work the other way around using Parallels. How much hassle and how legal would it be to have Mac VM running on non-Apple hardware?
Have the COM DLL(s) been registered? (e.g. via the command line: regsvr32 DNVideoXLib)?
Thanks. I right clicked Program.cs and changed the Build Action from None to "C# Compile" and that fixed my initial issue(no Main method). Then I get a "no Startup namespace" so I right clicked Startup .cs and changed that build action to "C# Compile" and that fixed that issue. Now I am getting no namespace for "Data", "Models" and "Services". These seem to be the standard namespaces that are used in Startup.cs. But when I right click those directories in Visual Studio I don't see where to change the build action for those directories. Any tips?
I changed the Build Action of Program.cs from None to C# Compiler and that fixed my "no Main method issue". And then I had to do it for Startup.cs. And now it seems like I have to do it for the Data, Models and Services directories but I don't know how to do it for directories. It seems like there's a bigger issue here - and a simpler solution than changing the build action of all these files directories. Why would this have worked for a different developer a year ago - and now not for me?
There is something causing *.cs files to go into None instead of Compile. Do you have a file named “directory.build.props” or “directory.build.targets” in that folder (or anywhere under the solution root)? If so, can you paste the contents here?
Jetbrains can go fuck themselves
I don't see either of those but I do see: \- appsettings.Development.json \- appsettings.json \- bundleconfig.json \- Properties/launchSettings.json
Those files won’t have any impact on this. Try this, open a command prompt and run msbuild.exe PROJECTFILE /pp &gt; project.txt and paste the result here or in a gist. Take a look at the contents to ensure nothing sensitive is in it before posting. Also make sure to use msbuild.exe under the Visual Studio 2017 install directory.
I'd argue that EF Core is definitely in the realm of a "usable ORM," as well as Dapper, etc. In fact, as a 9 to 5 Java guy, I much prefer it to Hibernate/JPA. Out of curiousity, what makes you say that those ORMs are unusable?
I don't. Resharper taught me how to code C# WELL when Visual Studio alone was not up to the task. Not needed now, though.
Thanks, yeah I tried but both give the no entry point error. Part of the install instructions for the full SDK involved moving and registering some other files and I did all that. I suppose it's possible that moving the DLL's mess with some saved path or something, but the fact that the project generates those other files makes me think it's something in the visual studio/project settings.
The refresh token should not be in the User model. This would prevent multiple logins from the same account. You can move it its own table so that users can have multiple refresh tokens. The refresh token should also have an expiration. 
In my app I don't want multiple people sharing a login so I only allow one refresh token. I agree refresh tokens should expire. 
You miss the point of the app - it's to provide an easy to follow example, not a complete solution.
Stick to ImageSharper.
I’ve used the following: ImageSharp (beta) https://github.com/SixLabors/ImageSharp FreeImage https://www.nuget.org/packages/FreeImage-dotnet-core/
I've used SixLabors ImageSharp https://github.com/SixLabors/ImageSharp with great success in a recent net core project.
Yup. It's an amazing library and very easy to use from an ASP.NET Core system: https://github.com/dodyg/practical-aspnetcore/tree/master/projects/aspnet-core-2-1/image-sharp.
yeah, I know. But really everything is pretty much all there besides that.
The same person should be able to login on different devices.
I've had recent success with [http://imageprocessor.org/](http://imageprocessor.org/)
Jesus Christ, having to write if err != nil return err may be simple, it’s still idiotic. Also lol for still missing generics. 
Visual studio has one click deploy for an elastic beanstalk application. The database deployment is a little more tricky though and is usually updated separately using entity framework migrations or something like fluent migrator. See the deployment section https://docs.aws.amazon.com/elasticbeanstalk/latest/dg/dotnet-core-tutorial.html 
We might need to know a bit more. Which type of AWS service are you talking about? A container? A VM? An IaaS approach? What OS do you want to host on? Are you planning to run the SQL Server instance on the same box? Are you planning to host an API or a web application? (it makes a difference).
Any other questions that could help the others to master ASP.NET Core quickly?
Why would they make it free? It’s a major source of revenue.
The output is 15k lines. Is there any specific chunk I can post?
They do a count of global search results, so maybe there are non-US countries where VB.NET has taken a foothold. But I suspect there's something in their algorithm that's throwing those numbers way off.
You can post it as a gist (https://gist.github.com) or just search for where Compile and None are defined. It will look something like: &lt;Compile Include ... It may be defined multiple times. We have to figure out what caused it to get messed up. Also look for a property named EnableDefaultCompileItems and make sure it’s set to true. It also may be defined multiple times so find the last one. 
Questions won't help anyone master anything. Just build a website. These are just interview questions; I wouldn't ask any of them, they're mostly either requiring you've memorized the folddr layout (pointless) or stupid (does core support DI?). Real sorts of questions: What is the ClaimsPrincipal.Current and why shouldn't you use it for asp net core? How does authentication with claims work, and how is it different to role or permission based authentication? Why should you put a load balancer / reverse proxy in front of kestrel? How do you manage sessions in a load balanced envrionment with .net core? How would you write a REST api for a SPA? How is that different from using MVC? How do you confgiure multiple envrionments in kestrel? (eg. dev, prod, etc) 
It's been a while since I had an AX assembly referenced, but IIRC you just add a reference to the DNVideoXLib file, and the AXversion will get created for you automatically. You have to distribute both files though. 
 agree, but its a battle I cant fight.
Good work! Maybe a followup article could touch on these suggestions and bring you some traffic at the same time!
I feel like whoever made this website just opened up Microsofts "[Introduction to ASP.NET Core](https://docs.microsoft.com/en-us/aspnet/core/index?view=aspnetcore-2.1)" site and went on down the line converting the topics into question format. If your goal is to actually learn something, you'd be far better served to just go to MSDN and work through their documentation and tutorials. 
What version of .net are you running? 4.0, 4.5
You can put controllers in standalone libraries. They aren't required to be an explicit part of a given application.
4.5
I'm planning to host a web application, no front end frameworks like angular/react. It can be either a container or a VM. The main challenge is that most online examples don't get into how you go about hooking it up to an sql server instance. The db can be on the same box if that makes things easier. Hosting using linux or windows doesn't matter to me right now since i'm just learning.
Yes, it seems to me now the TIOBE index might be off on that one. Pypl puts vb on #14. Still impressive, ahead of perl, go, scala, but not as crazy as #5. 
It looks like vb6
 `&lt;TargetFramework&gt;netcoreapp2.0&lt;/TargetFramework&gt;` 
It's not exactly the case. But I have to say that the Introduction is great source of information. It has one problem however. It is huge. And when people see that amount of information, they tend to skip it or read random topics. The questions presented are real questions which we were asking ourselves when building ASP.NET Core apps. They are not perfect, but they will help you to spot gaps in your knowledge.
In the same way they have made visual studio community free, VSTS free for 5 users, xamarin etc.. For startups, would be nice if it was free for customers with revenue &lt; 1million
Thanks :-)
Thanks. I don't want to do too much more though as there's lots of more detailed articles out there already. My motivation was to provide a simple working example that doesn't require any configuration or setup - something you can just download and run. Too often these things rely on SQL Server / EF.
No we cannot do that. Users of different tenants are using different domains ([tenant1.com](https://tenant1.com) and [tenant2.com](https://tenant2.com)). We should not have any issues with users spoofing that value, because in that case user just won't get access to API. 
For performance, nothing comes close to https://www.nuget.org/packages/PhotoSauce.MagicScaler/
You can find these settings under the menu \`Resharper -&gt; Options -&gt; Code Editing -&gt; C# -&gt; Formatting Style -&gt; Tabs, Indents, Alignment\` You can edit the options and preview them
older vb6 devs working on crappy vb6 auto-converted to vb.net apps? i don't think anyone coming into the market in the last 10 years went to vb.net instead of c#
May or may not be your problem... https://blogs.msdn.microsoft.com/dotnet/2018/07/20/advisory-on-july-2018-net-framework-updates/
I do this all the time (but with AWS Elastic Beanstalk). If this is what you want, I can provide answers.
Not a general tutorial... but how to do it with Shippable. So basically a sales pitch. I will say that the shippable YAML file that runs everything looks clean and concise... 