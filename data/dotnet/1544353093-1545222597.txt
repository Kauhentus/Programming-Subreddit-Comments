Users love it when you use marquee tag on everything. When you think you have added enough it’s still not enough!
Not that I am aware of but essentially you need to know powershell and SQL. Using the SQLPS module you can create &amp; run SQL agent jobs. It does rely on your developers being diligent in checking in their changes but in a good team thats self correcting. The basic steps are: 1) Create source control area for upgrade scripts 2) Create powershell script to create SQL agent job at target instance if it does not exist. 3) Create powershell script to deploye each SQL file from step 1 location as a separate step in the SQL job. 4) Depending on whether your devs work off local instances or shared servers target your script at the list of instances. 5) Set script to create agent job to run on whatever schedule fits. Most likely just after backup restore is complete. 6) Inform developers that any SQL changes must be checked into the new source control location and whats going on. 7) Inform them again the next day when someone forgets to check in an alter table statement and you spend 20 minutes figuring out why everyones getting column not found errors. A lot of it is very dependant on how your work does things and clearly my steps are a very high level overview but anyone who knows SQL and Powershell could do it with some patience and googling. You may want to bundle in a copy over backup and restore step into step 1. You will need to define a folder structure for your source control scirpts - personally I would have a folder for each database and sub directories for each type of object with a single file for each type of object... procedures, tables, indexes etc. Also you want to allow control over the order of script execution - perhaps allowing numeric ordering by file name e.g. 01_Schema.sql 02_UserTable_AddIsBestUserColumn.sql Lots of questions only your organisation can answer e.g. if one script fails to you roll back everything (probably bad idea if theres big data changes aswell) or just fail with the expectation it will prompt a flurry of activity followed by a request to push out the scripts again. The biggest challenges you will probably face is getting devs doing it properly but after a month or two they will see how easy it is once set up - add a new table today so drop the CREATE table statement into source control and the next day it magically gets run on the restored database. The resistance you may face is from the fact the process will break if someone forgets to check in the SQL change but does do the app code check. You could also fire out emails if it fails saying what it failed with which will probably prompt everyone to turn around and yell at billy to check in his new geolocation user tagging stuff because everyones getting an error at login. Some good resource that could get you started: https://www.mssqltips.com/sqlservertip/3407/one-line-powershell-solutions-to-common-sql-server-dba-tasks/ https://www.itprotoday.com/microsoft-sql-server/use-powershell-create-agent-jobs
Perhaps dictate was the wrong word. The frameworks made it easy to avoid learning how to build n-tier apps and still get away with a functioning web app.
LOL
ITT: devs with nothing but contempt for the users that pay their salaries.
If all three are on the same server, which tells me you have no need for horizontal scaling, is it reasonable to put them all into a single web API app? You can start your polling services in the app startup code, and communicate across what used to be the WCF boundaries by direct method calls. Again, if no need for horizontal scaling, I vote keep it simple.
Actually you bring up a good point. We currently don’t have the need to scale horizontally (small user base) but there have been talks about expanding so I suppose it would be best to have the flexibility to scale up. In that case, would you recommend keeping the 3 “components” separated? I know this is basically impossible to determine without having a full understanding of the architecture and everything else, but to give you a slightly better picture, here’s a more detailed breakdown: Component A: “Core” of app. It’s hosted in IIS (web api end points for client side) and houses the data access layer to our SQL database. Component B: windows service thats basically a “game loop” - is constantly polling for new jobs in our SQL database. Once it detects something, it either talks to Component A or C. It is also the communication “bridge” between Components A and C. Component C: Windows service that “integrates” with plugins (which talk to 3rd party tools). Like Component B, it is continuously polling for new data, but via rest calls to the 3rd party plugins and not our SQL database. Data is sent to and from here via Component B. I like the idea of keeping things simplified to 1 main application but I kinda feel like keeping things separated as “micro-services” is the right way to go. 
&gt; Instead, flip that script and take a close look at what doesn’t work, and avoid that. Same as my question. A few years ago users rejected popup ads as intrusive and annoying. People boycotted sites that used them. In other words they didn't work. Now they are back. Are users not bothered anymore or do site developers not care what bothers users? 
Note: you can use Wcf as a client in .NET Core https://github.com/dotnet/wcf just not host as a server using in it; so that might help you transition piece by piece rather than all at once?
We're currently in a similar conundrum fwiw. If only asp.net core could do soap :( We're sticking to .NET framework for the actual host and .NET standard for the rest for now, that way when a solution presents itself we can migrte to core easily
Why no trigger on the database?
We're currently in a similar conundrum fwiw. If only asp.net core could do soap :( We're sticking to .NET framework for the actual host and .NET standard for the rest for now, that way when a solution presents itself we can migrte to core easily
I’ve thought about it but there is some relatively complicated business logic that goes into determining what is “eligible” so I feel like it might not be worth the development effort. 
There is always talk of potentially expanding X or Y or adding feature Z. It's a fundamentally non profitable venture to attempt to prematurely optimize your app for something that may or may not happen. Most importantly, until the actual need arises, any conjecture as to how that requirement might materialize is just that - conjecture. Without the real use case in hand, the chances your premature optimization will actually support your eventual use case is fairly low. It is more cost effective to follow good programming practices, keep dependencies injected and provide good business encapsulation in your class composition. If you stick to that, you'll be ready to adapt when the real needs do come. If converting your runtime to Core is the current priority, and you don't sacrifice any current priorities by collapsing to a single runtime, and it likely simplifies your life, then I vote go. If you properly leverage async / await, you'll be pleasantly surprised how well an app can scale on one machine. A couple of other thoughts: a microservice should maintain it's own data store and provide access through an API contract only. The fact that you have SQL polling probably means you have violated this principle, and do not have a good microservice candidate anyways. For background job management, it might be good to look into Hangfire. And the fact that you have REST API polling indicates you might want some other kind of distributed work queue - perhaps something like AWS SQS is a good candidate to look at.
The less painful route is just to go with WebAPI/rest controllers. The other options are going to have bigger trade offs. IMHO SOAP has very few use cases where it really winds up being the best approach, and Named Pipes even fewer. There are so many web scale infrastructures that are based off of http messages going back and forth. I wouldn't worry about it and spend the time on things that will make more of a difference to your users.
you can still isolate them architecturally, but instead of 3 different applications have one with 2 background tasks. This will probably even slim down your application as you don't have to orchestrate app boundary interface compatibility for 3 apps that are basically one.
Adblockers. Adblockers in more than half of all browsers.
It's a problem when business is telling you to implement something that you know the users will hate, and reflect badly on the company. Nobody likes being told "build a piece of garbage".
You just need to pass messages between your apps. There are innumerable solutions for that besides WCF. How about a message bus?
In thinking about your situation and coming up with a potential solution, a question comes to mind: why wouldn’t you want to restart services when changing the config?
I do something essentially like the following (simplified). Any service that needs config takes it as a dependency. A background job polls for changes and raises a notification when config changes (this is necessary for me because some services build a data structure based on config and continue to use it unless/until the config changes). I don't have this hooked into .Net Core configuration at all, since it's been in use for many years already. public class ConfigValues { public TimeSpan ExternalServiceTimeout {get;set;} } public class ConfigValuesChanged { public ConfigValuesChanged(ConfigValues oldConfig, ConfigValues newConfig) { Old = oldConfig; New = newConfig; } public ConfigValues Old {get;} public ConfigValues New {get;} } public class ConfigProvider { private readonly IRaiseEvent&lt;ConfigValuesChanged&gt; _configChanged; private ConfigValues _currentConfig; public ConfigProvider(IRaiseEvent&lt;ConfigValuesChanged&gt; configChanged) { _configChanged = configChanged; } public void SetConfig(ConfigValues configValues) { if (configValues != null &amp;&amp; !configValue.Equals(_currentConfig)) { var oldConfig = _currentConfig; _currentConfig = configValues; _configChanged.Raise(new ConfigValuesChanged(oldConfig, configValues); } } public ConfigValues CurrentConfig =&gt; _currentConfig; } public class ExternalService { private readonly ConfigProvider _configProvider; public ExternalService(ConfigProvider configProvider) { _configProvider = configProvider; } public object MakeCall() { var url = "http://www.example.com"; var cfg = _configProvider.CurrentConfig; return url.WithTimeout(cfg.ExternalServiceTimeout).GetJson&lt;object&gt;(); } } public class ConfigChangePollingJob { private readonly ConfigProvider _configProvider; public ConfigChangePollingJob(ConfigProvider configProvider) { _configProvider = configProvider; } public void Run() { var cfg = LoadConfigFromStorage(); _configProvider.SetConfig(cfg); } }
IConfigurationRoot has .Reload() You just need some way to trigger it.
I'd probably just have your config service refresh it's cached settings once a minute (or every 5 min, or whatever). Yes technically you're wasting a lot of work querying settings where nothing has changed, but honestly unless you have an *incredibly* complex config each of those queries should be trivial in comparison to the normal workload. 
I just do ctrl-t and search for the file. It's usually pretty quick and allows for fuzzy matches. 
Edit-goto all
Thank you - I use it frequently. Just wondering however, what do you think the response would be if Microsoft pulled the Start Menu out of Windows and replaced it with the dialog you see when you ctrl+t? When you open Windows file manager do you see an icon next to each file? What if icons were removed from Windows? What do you think the response would be? If visualization is a desirable feature of the user interface for an operating system why would it be any less desirable for the single most used program for Microsoft developers? Or for any program for that matter? 
We’re looking at using SOAPCore to do this. https://github.com/DigDes/SoapCore/
Because if were simply changing a configuration value such as a timeout, uri, etc. it seems unnecessary to have to bring down and cycle the app pool. To me one of the key ideas of having a data driven config is to be able to update settings on the fly.
I'll check this out. This might be exactly what I'm looking for.
You're hosting microservices wth IIS?
They do in 2019. Go download the preview and take a look
Developers are not end users, they cannot innately know what the end user will "hate", anymore than the guys programming word 2019 know what users writing a novel on it will think about it. Marketing's job is to identify what those user wants, devs job is to implement.
Yeah. We hope to have containers soon, which should give us more flexibility here, but until then we're hosting on-prem IIS w/ an API gateway and load balancer.
Could have a trigger that fires some custom CLR assembly to call out to something that calls \`.Reload()\`. That smells though. I'd hope there's an easier way.
I was hoping to achieve this using the .net core config pipeline but this is a very cool solution as well, thanks!
Caching would sure be nice to have. I've always wanted to try redis. I'll have to look into it again.
Yeah I've used SqlTableDependency along with SignalR to hook into SQL changes and update UI in realtime, it was very cool. That was also a consideration I had, curious if anyone has or is using it in a production enterprise env.
The first problem is that you need a way to notify your app when the database settings change. The easiest solution is to just refresh the settings every few minutes (or whatever interval works) in a constant loop. That's reliable, will always eventually be up-to-date, can also work as a database connectivity check, and requires no other code.
There would probably be some performance gains by consolidating to 1 main component with direct code references, right? I'm trying to put together a case for changing up the architecture and know the higher ups will be resistant unless I can come up with a compelling reason.
Performance will probably be negligible since it's all local anyways, unless you're calling between these services in tight loops N+1 style. The things that really should matter to upper management often don't, and I don't know why. A lack of process boundaries should lead to shorter SDLC times, increased velocity, lower code churn, more rapid test feedback cycles, and overall less risk when making changes that alter the contracts between these architectural layers. Frankly, I can't see why upper management should care about performance unless there are lots of complaints... In which case, you'd probably have a need for horizontal scaling. On the other hand, all of the other items I listed are things I'd think any good tech management team would want. Maybe it's just because it requires more than 24 hours for those things to be impactful?
If you aren't already using redis, it's probably massive overkill for this problem unless perhaps your config is very large or complex. I was thinking more in terms of in-memory caching on the server. That said, redis is awesome and very useful and you should definitely check it out. 
Developers and the average computer user are insanely different people. Also in VS, the context is always programming files (.cs for example, so fuzzy search is really useful). In Windows, the context is way wider (videos, apps, reminders etc), so a UI is much more intuitive. Just my two cents.
 IF SQL Server YMMV with .net stored procs. But I can see why polling would be better in some cases that only require near real-time. If I was you're boss I'd be confident you've got this and everyone here are teddy bears.
&gt; Yeah I've used SqlTableDependency along with SignalR to hook into SQL changes and update UI in realtime, it was very cool. That was also a consideration I had, curious if anyone has or is using it in a production enterprise env. My main concern for production would be monitoring that this is functioning. How would we know if a change to stored config might or does fail to notify of changes, and are we able to handle and recover from those failures adequately? 
It's also marketers' job to research projected return on UX changes. I've rarely seen that happen.
There are two types of communications between separate processes - synchronous and asynchronous . For synchronous the most popular way is using REST and implementing it by creating [ASP.NET](https://ASP.NET) Core application and exposing RESTful API. For asynchronous communication you need some messaging platform/bus/broker - for example RabbitMQ or more advanced like NServiceBus. Each communication type has pros and cons. You need know them before you decide in which direction to go. As always "it depends" - on project structure, processed data, business rules and boundaries, functional and non functional requirements etc.
.net core 2.2 has this rounded out pretty well with snapshot system. You should take a look at them... To my knowledge they're all behind interfaces so you're free to implement this yourself.
thats not true at all, I have one application running via winforms and wpf and both are fast. The same application (ViewModels are shared, just Views are different.
I'd be more concerned about success of WebAssembly in general and whether this technology really can provide nice runtime for .NET Let's be honest, MS is religiously hated by many non .NET devs. (Look at reaction to GitHub deal for example.) I see it as a more critical factor than anything else. I would not underestimate the power of irrationality like `WebAssembly is not invented by Microsoft, so it is a priori cool!` &amp;#x200B; Second, notice how careful MS is: "It is experimental, we promise you nothing". There are no claims about being a JS Killer. They are simply not hyping it as they dit with Silverlight. They probably learned a lot from its failure. &amp;#x200B; Third, could you, please, explain me how from &gt;bring C#/.NET to the web follows &gt;I expect Blazor to be just as successful/unsuccessful as Silverlight was How is it different to `bring .NET to Desktop/Back-end/Embedded` or `make .NET really cross-platform`? They either manage to achieve the goal or they don't. I tend to think they are themselves not sure. Hence we should discuss the technical feasibility of production ready feature rich .NET for Web or, if we accept that former will be done, its adoption considering Blazor as a yet another alternative to Angular/React/Vue/Whatnot. &amp;#x200B; &amp;#x200B;
This is a good idea, but will probably take some work to make sure it's thread safe and propagates to places the config is injected to. 
I meant angular .net combo
I did some angular before and I can do it again but with so many new technologies I want to focus on c# since I am not doing any angular at my job at the moment.. ofcourse im happy to know everything but I don't have the time anymore
With Azure and O365 and all the pieces of it I need to focus so while I can figure out angular if I had to I feel like leaving that whole node.js world can let me focus on other MS techs coming out
I did 8 years ago :( 
I got stuck in a Jquery job and wanting to show everyone how much better Angular was.. I think Jquery is what webforms .net people evolve into... and then they stick with that too long
VB6 / WEBFORMS covers about 20 years.. But I feel past 5 years things really changed a lot and it takes some work to avoid being obsolete
I admit I am not the smartest coder so sadly I enjoy learning the basics of all these new frameworks but I need to be able to focus on one thing for me to get anywhere.. so I want to stop trying to keep up with Angular stuff and move that focus to understand blazor better.. hoping that is a alternative
Oh I totally understand. Many people are tired of keeping up with the rat race of javascript frameworks. My comment was not intended to make less of you or your knowledge in any way. I hope it wasn't received that way and I also hope to be able to use blazor in production code some day as well!
I believe that theres a redis-64 package
[gRPC](https://grpc.io/) is a good alternative to WCF at 2019 on .NET Core .
https://github.com/wasabii/Cogito.AspNetCore.ServiceModel Probably not what you're looking for, but it was fun none the less.
Nope. Will continue to run 2.2 on Framework for the next 5 years.
Sounds great! Any docs or README in the works?
Yeah, definitely needs a readme.
Awesome. Starred.
It's plugin free for one and it uses a language agnostic "kinda" bytecode format called webassembly which is a web standard. Nobody's gonna write code directly in wasm just as only a few write in assembly, so even if MS wasn't the one that made a framework on top of wasm someone else will. This includes Java, rust, and a few number of people starting to try out some PoCs. It's just that MS was one of the first to actually make a managed language to work with wasm compared to the lower level languages implementation that exists for wasm today (rust, c, c++). Also unlike webforms Blazor is using standard HTML + CSS, it's just replacing JS for C#. Nowadays JS is being treated more as a compilation target with the advent of transpilers.
The main problem I have so far with JS's ecosystem is the severely lacking standard library. Everything seems to love reinventing the wheel. This in turn makes you need to download a lot of 3rd party libraries with varying quality and support (some even has none) that may or may not be friendly with the other libraries you are using. It's one of the main reason why bloat happens quite quickly as people need one simple helper method from a lib that's supposed to be in the standard JS. Tree shaking helps to a certain extent but it shouldn't be the case.
Added. It's pretty dirt simple.
You still need HTML and CSS though you're just replacing JS with WASM which is a standard that every browser implements except IE11. C# get's compiled into either IL with a wasm mono runtime (Now) or gets compiled AOT to wasm directly (Future objective of Mono.wasm). It far from magic, it's just simpler overall since it's C# and doesn't need a complicated built system to bootstrap a site. It's still rough on the edges but Mozilla, MS, and Google are investing heavily on wasm as a legit alternative to JS. If C# wasn't the made other languages will eventually do it. Rust, C, C++ already supports some kind of frameworks but C# is the first to support a managed language for wasm.
That's great. The worry for me when I heard of blazor was the same vendor "lock-in" that webforms caused. Where you are working with tooling and designs that are only relevant in webforms and are not easily transferable to other technologies. Webforms is nightmare of restrictions, black boxes, and unexpected behaviors and there is very little away around some of it. Unlike rolling your own JS/HTML/CSS which you have full control over.
Looks great and seems easy to use too. Does this run on Blazor 0.7? Neat since it looks like it's using `CasacadingParameter` on the options select. Also cool fiddle there, does it download the whole roslyn compiler locally and compile the app there? Or is it using Server Side Blazor to do the compilation on the server? Pretty good set of components!
that looks really useful 
Because it'll mean a full stack C# experience. This can mean alot of things depending on what you'd want. For one you can share alot of your view models that your APIs return without duplicating effort of creating models in JS or Typescript which means your APIs will be strongly typed and can get compiler checks when you ever update your API backend. This also mean you can re-use your validators on the backend on the front-end, this eliminates having to duplicate alot of code in two different languages. You run the same validator on both ends and not forget to have validations on one side only (mostly front-end in my experience) due to either dev laziness or time constraints which makes your app more secure by default. Also there's alot of C# I like better (subjective). Like auto properties, Extension methods, Linq, a better standard library, Expression&lt;T&gt; for having fun with compiled lamdas, better even delagates and qutie a bit more.
&gt; We cater to almost every need/want we hear, unfiltered. When I'm present in the discussions I can usually put the breaks on things and convince the stakeholders that it's in their best interest to keep things simple, but I can't always be there I'm guessing this is the crux of the problem. This is a bit of a long response and I've tried to keep things linear, but I can't guarantee that a bit at the end doesn't really need to be at the top. You first need to add a review step. After the requirements are collected, someone, perhaps you in the interim will have to go over them and look for issues. Go through the requirements with the person who collected them so they learn the sort of things you are picking up on. At least one of the developers who will be working on the feature, or who works on related features should be in that meeting. You have to have developers involved early. Make it clear to the stakeholders that the review must happen before the requirements are accepted and that they may be asked to revisit or clarify things. Meet with the stakeholders and explain the problems you are experiencing. I don't know what sort of business you're in. If that seems like a lot of effort because you have loads of stakeholders, then you have too many stakeholders. Try and aggregate them if possible. As an example, if there is a business team that does widgets, it's fine for 5 of them to come to a requirements meeting, but only one of them is the stakeholder. Next you need to prioritise the work. Go read [The phoenix project](https://www.amazon.co.uk/Phoenix-Project-Devops-Helping-Business/dp/1942788290) Seriously, it is an eye opener. The important take away is that LEAN works. You need to be one step ahead of the requirements gathering. You should know who has requirements, topics really, and in really vague terms what they are. You then arrange for all the stakeholders to fight between themselves to decide which requirement is the most important. In LEAN you establish your capacity, let's say you can run three requirements concurrently. This means you have three "slots" total. When one slot opens, you have the stakeholders fight for that slot. It sounds like they'll all be shouting and swearing and demanding you do all of them, but generally people understand that a pint glass can hold one pint of liquid. Where there are squabbles you need someone more senior to arbitrate. You'll be surprised at how they will all work together though. So now you've got the top priority you can then start collecting requirements. Don't have an army of people who just collect requirements too early. It's quite likely the requirements will change if you get them in March and can't get around to it until July. It also puts pressure on you and your team because they can see the mountain ahead. It's not productive. One caveat, I hinted on above. When you find out who has topics, you need just enough detail to get a vague idea of how much work there is. It doesn't have to be perfect, but when the stakeholders discuss who goes next, it will help them if you can say "This topic will take six months". There's a good chance they're either pick something else or revisit the scope of their requirements. Something else: You mention that stakeholders don't really know what they want. It's partly correct. They understand their business area, but don't get software. The important thing here is to model their business area. Use things like Ubiquitous dictionaries (just means use the same word for the same concept. If you make mugs, don't use mug and cup interchangeably unless there is a distinction, then make sure you understand it). So, we know they don't understand tech, your non engineers don't understand tech, don't let them model anything in technical terms. If there's a UI requirement. It's very common for a requirements gathering session to start with "Right, we need a new button that will open a window that looks like this *scrawls picture of owl* ". This is of no value. Stop them in their tracks, discuss the business requirement. Have a developer prototype a UI and get the stakeholder to ok it. Finally, don't consider a topic complete until it is in production and working as the user wants. So going back to capacity, if you have three slots it's tempting to open up a slot because "the current topic only needs a bit of testing and sign off". The moment you do that, the testing will find huge flaws or the user will change their mind. This sounds a bit inflexible. It's not. If a stakeholder comes to you with an urgent requirement, you are allowed to pause a currently running topic and replace it with the urgent one. Only with the agreement of other stakeholders, get a senior manager to arbitrate if they fight. So in summary: Plan ahead, gather the set of upcoming topics. Have the stakeholders fight it out for which topic is the most important as developer capacity becomes available. Collect requirements at this point and not before. Requirements should be business specific and not tech specific. Review the requirements before accepting them and include a dev. Once accepted, build it, test it, deploy it and don't start on the next one until it is absolutely signed off and complete. 
Thanks for detailed description. I don't "feel" why this way could be better than executing scripts by other external tool like DbUp. I think the idea is the same - keep all migrations scripts in source control and execute them by external tool to automate the process as much as possible.
Thank you! This is going to be very useful.
Amen to that! I really, really hope this gets shipped and maintained like crazy!..
Hello, I am one of the NetTopologySuite developers. Please [favor](https://docs.microsoft.com/en-us/ef/core/modeling/spatial#creating-values) using `IGeometryFactory` instance methods to create geometry instances, instead of the public constructors. The public constructors will work, but the factory methods support things like defaulting in the SRID and using a different `ICoordinateSequenceFactory` to optimize the way that points are stored (default is to create a `Coordinate` instance for each and every point), and so if you're in the habit of using the public constructors, then it would be more churn to switch when you need those kinds of features. Otherwise, great article!
It certainly isn't dead, its main use is mobile. It was never really used for ASP.NET in any case and always suffered with bugs and lack of features.
I use JetBrains Rider on a Mac and that has VB.NET support.
So I take it geography column type support still isn't ready?
Oh? Whatcha doing if I can ask?
Where do i check on Mac? Does this mean it can work on Mac at all?
Wait, are you using .Net Core?
Nope. Very old codebase
Well, then you won't be able to run it on Mac/Linux, only .Net Core can do that.
Yep, this is what i figured. Hopefully we are moving to C# soon
I know the pain, I'm currently working on a 10-year old project written in VB.NET (am C# dev).
Ours is 15+ years old in VB. The higher ups are FINALLY allowing us to migrate 
Silverlight was a great technology. Its main issue is that it required to install a plugin.
If the front end is html and javascript, its not .Net development...
&gt;Do people still use it? Lol, it's the second most popular web framework amongst the top 1 million websites: [https://trends.builtwith.com/framework](https://trends.builtwith.com/framework)
I'm not saying everyone should be full-stack but if you're solely working back-end then you shouldn't worry about Angular, and if you're doing front-end work as well then knowing the difference of use cases between a modern SPA framework and jQuery is essential.
[`geography` columns are the default](https://docs.microsoft.com/en-us/ef/core/modeling/spatial#geography-or-geometry). `geometry` columns are supported, but you have to do something extra to make it work.
Exactly. I was just thinking that even with premature optimization, this actually makes sense out of a performance standpoint too.
The only thing that comes out of a test is the test outcome. Some tests might expected multiple things (have multiple Asserts) so having a single "Expected" column wouldn't really work. &amp;#x200B; It's possible that if every one of your tests had only a single actual value, and a single expected value you could provide a naming convention for the test and then parse that somehow. Possibly the actual value might appear in the error message, depending on which assert you used.
I absolutely love your link to NNG! I never heard about them before but they have a lot of nice, and well thought out articles on their website! To add a bit, focus on your user. Don't try to be Facebook and make the length of the stay of your visitor be infinite. Try to help the user stay as short as possible inside your application while still managing to do the job. Let's be honest. People probably don't want to be in your application but they depend on you in some way or another. Better make their stay pleasant.
Does fxcop and stylecop work with net core?
Why not list some of those amazing Roslyn refactoring/analyzer packages in the article? E.g. Roslynator is a GREAT one
Hasn't StyleCop been superseded by EditorConfig settings? 
You could maybe write your own assertion library and implement such logging in it. There might something exists already, but I never heard about it.
I think this is the way I'll go with it. It's only for university work but the lecturer wants everything in a table. I've created a few small functions that create a JSON file for now that should do the job.
Plenty of data-driven applications can use a programmable validation layer :)
Fxcop- see https://github.com/dotnet/roslyn-analyzers/blob/master/README.md It has the same analyzers that fxcop did.
I would heavily consider gRPC -- it has a lot of the benefits of WCF without being SOAP-based
Well, if anything, you've sold me on trying it. And if this works well, it's very likely I could sell my company on it as well when it has matured. Since most of their misc work is with 'Filemaker Pro', and the CEO is open for change.
I work with SSR (Angular universal) but without .CORE . Only node. SSR give you possibility insert meta info dynamic, and for SEO it\`s wonderful. 
No, StyleCop has been replaced by [StyleCop Analysers](https://github.com/DotNetAnalyzers/StyleCopAnalyzers) and it's a much richer tool than EditorConfig as it understands code, not just layout.
Thanks!
Yep. I'm using them both in .net core. So far no major problems, although I have come across one warning which I'm pretty sure doesn't apply to core. They also both work with VS Code, although I plan to write soon about how that experience compares to Visual Studio.
Absolutely. I should have been clearer in my article, but Stylecop Analysers is the version I'm using.
Honestly, because I'm not using them. Thanks for the recommendation though - I'll have a play around.
Machine? Sure. Just install Windows and you’re fine. If you mean with macOS? If you’re working on the subset Core can offer, yes. 
I love using .NET Core and VS. It's different but yet Core is meant for whatever environment and doesn't depend on Windows IIS. However, SQL Server Mgmt Studio and stuff is not available for Apple, so you will need a windows machine unless you get a VM or use some SaaS
I develop .NET on linux. Works fine for me.
Cool. Yeah. Basically what I'm doing. I'm introspecting a JSON schema and attempting to discover facts about it, like whether certain values are allowed in combination with each other. And today I'm brute forcing it. Generating million of JObjects, with different combinations, and attempting to see if a specific combination is potentially valid. Billions of validations.
Thank you. Are you a web-dev?
Thank you. For web development specifically, do you know if there are any parts of asp.net that are missing in the .net core?
For ssms replacement, you can try out [Azure Data Studio](https://github.com/Microsoft/azuredatastudio) . It’s cross platform and works with sql server as well, even though the name suggests it only works with Azure.
I develop using ASP.NET Core 2 on my Macbook Pro and it's great! Although, unlike most people I don't use Visual Studio and instead opt for VS Code. Not having Windows sucks sometimes as I have to do workarounds for working with MySQL, so I have to have MAMP(https://www.mamp.info/en/) run MySQL server for me to develop locally. Another functionality are Environment variables, and the workaround to those is to supply them either using command line: ASPNETCORE_ENVIRONMENT=Development dotnet run -p src/Project or with config.json file like so: dotnet run -p src/Project --launch-profile "Development" Outside of that and maybe testing Dotnet on OSX works like a charm and the knowledge you get from programming this way will help lots with getting accustomed to dotnet CLI and other cross platform tools. Sorry if this was a bit long, but I hope it helps! 
Yes it's an excellent machine for .net, you can get VS code, SQL operations studio, Xamarin (VS for Mac) and Rider. Most people also prefer the terminal, ssh and the package management (brew) experience over windows. Things to note though: there is no IIS and no SQL Server if they are in your stack. Whatever you build has to work on more modern equivalents. There is also powershell core project by Microsoft that makes some parts of powershell cross platform. 
Correction it's called Azure operations studio now.
There is a SSMS lite called Azure ops studio https://github.com/Microsoft/azuredatastudio
I use a Macbook Pro for .NET, but I develop in a Parallels VM. I just prefer the OSX experience, but almost all of my development is .NET based. It also gives me the flexibility to do any IOS development if I decide to, which is nice to have. 
Thank you, this is really helpful!
I'm using Blazor for a few experimental projects and I like it. It's still rough, but I enjoy using it. It fits into my workflow nicely and I don't need to think any differently when working with it versus working on my backend code. I hope Blazor keeps getting developed and the WASM stuff sees a full release and support. I'm excited that parts of Blazor is getting put into 3.0.
`HttpModule`s and `HttpHandler`s have been superseded by middleware but that's about it I think.. basically IIS is not a thing in asp.net can but there are extensions to host a core app within IIS.
Yes, in fact one of the ASP.net team works on a MBP
I'm a longtime Windows user, but have been developing on my MacBook Pro using VS Code for the past few years. I build primarily web ([ASP.NET](https://ASP.NET) Core) applications and console applications for AWS/docker environments which often use technologies like PostgreSQL, SQLite, Redis, and lots of other things. I've found the experience to be wonderful. I have a much lengthier history in [ASP.NET](https://ASP.NET) on the full .NET Framework on Windows running through IIS, and my personal experience has left me incredibly happy with developing on macOS. So much so that I find myself using my Windows machine with full VS far less these days. I haven't found anything to be lacking, and I'm just as productive on macOS as I was on Windows, if not more (e.g. the bash shell on Windows is just so much slower than the shell on a macOS or Linux machine).
I use Linux exlusively for .NET Core (asp net included) development with VS Code. Haven't had any issues and is a much more enjoyable experiance than working on Windows. Don't worry about the framework, because Microsoft is moving away from .NET Framework based ASP in favour of the ASP NET Core.
I use bootcamp to set up a dual boot (windows 10 and mac osx)
not /u/gnatbeetle, but I also develop .net on linux as well as macos. This is for asp.net web applications and restful apis. No major issue, the VS code debugger works great for .net core applications. Intellisense in full visual studio and some of the refactoring tools are better, but if you don't use them much then it doesn't matter. I haven't had a big backlash since moving asp.net core dev work to mac &amp; linux (namely ubuntu)
You can run sql server if you're using docker on mac
So dumb question: Do you actually use project and solution files (as opposed to just generating build scripts), and if so how do you manage them (i.e. any VS Code extensions)? Just interested in what your toolchain/workflow looks like in general. Any info is appreciated. 
You can create aliases for these in terminal
If you're comfortable working with Docker and want to use SQL Server, you can even set up SQL Server for Linux in a container and use that for local development.
As a slight addition to this, even if you're NOT comfortable with docker, I was still able to get it up and running with no problem using the instructions MS provides on their website.
backend (web) developer at a tech company. I write Java during the day but my preference is .NET (C#/F#) for side projects.
backed (web) dev at a mid-sized tech company. I write Java/Spring during the day but .NET (C#/F#) for my side projects. 
I have recently started using Macbook at work for ASP.NET Core development. Even though I am familiar with the Terminal, I'm not fond of the touchpad and magic mouse seems like a little bit clumsy for my taste. Currently trying to get into Rider IDE with keyboard shortcuts and seems working well. Please note that VS for Mac is nowhere near VS for Windows, it is just relabeled and improved version of MonoDevelop/Xamarin Studio. Using DBeaver as my Database IDE of choice. 
I develop .NET Core stuff on my 2015 Macbook Pro, and I don't think I could enjoy it any more than I already do.
Development has to be Core related on Mac or Linux. I prefer Visual Studio and SQL Server so any C#/.NET development I default to a Windows machine. On MacOS, I'm forced to use VSCode and PostgreSQL. It's ok but not ideal.
Provided you have a complex enough schema, you also get to discover corner cases in your APIs, for instance. That’s pretty useful imho. Those cases that pass validation but are actually invalid for the underlying logic are better found sooner than later.
I've been using MacBook Pro and Linux (on my stationary PC), for over 2 years now and couldn't have been happier. Rider is a great IDE, but VS Code is also fine for smaller projects, all of the toolings such as Docker works great (opposite to Windows), not to mention the OhMyZsh / iTerm (Shell in general) - enough reasons to abandon Windows for good.
I second this, I do the same. Do all of my .Net work in the Windows VM via Parallels, and a cool feature I just found out is that the VM can connect to the OSX side for Xamarin.iOS debugging. So it's kind of a win/win.
I've used a Macbook Pro for years for full-stack Windows development. I use Parallels VM for some Windows needs, but spend most of the time on the Mac side with front-end dev and now with Asp.net core. The VM works fine with Visual Studio, SQL Server, IIS etc, although it feels slower than a Windows box. One thing to note is make sure you have plenty of RAM if you are running a VM.
Use VMs for anything lacking. Products are coming for apple. When I first started there was no VS for mac. Virtualbox or Parallels run windows great on mac. 
My previous boss also has a MacBook for development dual booting windows. it's pretty solid, two birds with one stone. I'm considering buying one too I have a beast desktop for my work at home but I want something flexible when I'm on the go and I'm in between the MacBook pro 13" and the latest surface laptop 
Third.
Yes it works fine. Ide:. 🌟 Rider. 🏅 VS Code Db clients 🌟DataGrip (for db client) 🏅Vs db plugin For database use postgresql.app. It spins pgsql dbs up in under a second... Better than any mamp php MySQL nonsense. If you're using efcore coding is identical. 
I like the Surface Laptop, but it costs the same as a Macbook Pro to get a 16GB configuration, and it has a weaker iGPU and much slower SSD.
ADS will with with standalone SQL Server instances. I use it pretty extensively at work since it feels more responsive than SSMS and doesn’t force me to close every query window. On topic, there are SQL server docker images you can run on Mac for development purposes. 
I’m working on a big project, and we all use Macs for dotnet core development. I use Rider, some people use Visual Studio, some even use VS Code, nobody has any issues.
Both VS Code and Rider work fine with solution and project files on the Mac. I’m assuming Rider won’t have any issues on Linux either.
They used to be. Now they have shit tier QA and a garbage keyboard (don’t let the 3rd gen silicone under keys make you think they resolved the issue). When I say garbage, I don’t mean it just because it’s a poor thing experience, just look at macrumors to see how many of these keyboards fail. If you asked me in 2015 or before, I’d tell you 100% buy a MacBook.
Yes I use it everyday. * .NET CORE * JetBrains Rider ide * Azure Data Studio or something like that * Docker to run databases * VS Code or WebStorm for angular and react
I install windows in a bootcamp partition and run like that no problem. I'm not an OSX guy but apple hardware is about as good as it gets.
VS for Mac is not really VS. Use BootCamp or buy a cheap PC
A lot of people on the ASP.NET team use a MBP.
What features are missing from Visual Studio for Mac that you’re needing? Note: I work on the Visual Studio for Mac team. 
RazorPages are cool if you maybe just use Bootstarp and jQuery to get things quick done, or have simple projekts. But if you are good at FrontEnd-Development and have the time you can use Angular or React for the look and a REST-API for your data
RazorPages have helpfull HTML-Helper Methods to create Forms and HTML structures. And you can use your C# code to make data viewable.
"... have been developing on my MacBook Pro using VS Cod,e for the past few years." "... past few years" So you mean almost whole one and a half year when vscode is usable enough with dotnet?
Windows is better for dotnet development. Visual Studio for Windows is a killer when it comes to debugging tools. Keep in mind that programming is more about reading rather than writing a code... and you very likely read code to debug some bugs/errors. So in my opinion it's better to be in place where everything is designed to work. If you need some advanced command line tools just use WSE on Windows.
I do all my development on a MacBook Pro in Rider. No VM. Been doing so for almost a year now. Love it, won't go back. (Doing APIs in. Net Core) The only thing I miss is some of the things that aren't in Rider on Mac yet, like code coverage (cli tools do this, though) and profiling. I use Azure Data Studio for DB work, and locally connect to SQL Server in a Docker container. These are all things that would be impossible just a couple years ago. The RDP client for Mac is WAAAAAYYY better than the Windows one, IMO.
BTW, there are docker containers for SQL Server, you can add the environment vars in your bash profile, and if you want a heavier IDE, Rider is great. What testing problems do you encounter?
Subset? I haven't run into one thing I can't do in Core in macOS that's not a Windows API.
I see this myth a lot in this thread. You can most certainly run SQL Server on Mac in a Docker container. Rider is a great IDE. Visual Studio for Mac is shit tho.
Forth. 
I'll tell you what it is for me - it can never find my mstest unit tests. It seems to ignore Directory.Build.Props files. I haven't tried the 2019 preview though.
This might or might not be the issue... it looks like you haven't saved a couple of files... Have you tried it after saving those files?
I work for Microsoft and often use my work MacBook pro for .NET development. As long as you're in .NET core/standard there's 0 issues. VS Code is wonderful. VS for Mac is there too but honestly I don't feel the need to use it.
You can, but why?. If you just want to get the job done, spend a couple of hundred bucks less on a high-end Windows machine that looks good and does the job with slightly fewer workarounds and odd key combinations. If you care more about looking like a hipster in Starbucks, get a Mac. It'll work fine. It's OBVIOUSLY a second choice for "the perfect NRT development machine" , that's why you're asking if it will even work. Amd from experience, it's not as nice as working on a native MS stack on hardware designed to run MS stack, But I'll get downvoted anyway. You're making the typical mistake of saying "I really want this hardware, but will it do what I need?" Instead of asking "What's the best hardware to get what I need done?". Millions of college kids bought macbooks when they started to become cool and found themselves having to dual-boot to windows and endlessly Google key combinations for all the shortcuts. MS have since made everything run on OSX natively, but it still cant beat a decent (similarly priced) windows system doing it all natively, and you'll get a touchscreen too (instead of that dumbass touch-bar that's apple's way of saying "we REALLY don't want to admit that we were wrong about this, but we know you all want some of it")
For the unit test issue, is it possible for you to send me a sample solution that shows this, or steps that I can follow to reproduce it? My email is sayedha (at) MicrosoftDotCom. I’ll look into Directory.build.props, thanks for letting me know about that. 
There is also Datagrip from Jetbrains (not free)
I've used VS Code for other things, as well. Was the experience rough in the beginning? Sure was. Just like it was rough with .NET Core 1.0. Did I enjoy it in the early days? I did not. I wouldn't have recommended it, then. A great deal has changed, and I can wholeheartedly recommend the experience, now. I'm happy to have gone through the rough patches, because it helps me have a better appreciation for where we are. Can I ask what you were aiming for with your response? I'd be happy to elaborate further.
I just wish Microsoft would stop offering 20 different ways to do the same thing.
Config settings are usually read-only so it can be a simple static field that's reassigned on updates. The assignment to the variable is guaranteed to be atomic so there's no thread-safety needed. Updates can be done with a simple method that has a while loop and is kicked off with Task.Run();
MVC shares a unified programming model with Web API, so you'll have to learn it either way if you ever want to do a JavaScript front-end or client call backs. Razor Pages are an optional way to simplify the creation of pages when you have a one to one relationship between a page and a model. To me it looks like a way to organize pages in your application in a way that is more familiar for Web Forms developers. My assessment has been that MVC / Web API is required to learn, and Razor Pages are optional and provide a small amount of value when the concept of firm 'pages' is easier to understand.
OP said they use DI binding and resolution, so unless they re-architect their app it won't be using static fields. 
Are the key commands weird just because you’re used to windows key commands?
... it worked
Windows is my side machine and I primarily use .NET Core on my Mac. I will say that I enjoy VS Code more than I do Visual Studio, but both work just fine. 
I have a net core 2.1 backend project and vuejs frond de in my work I’m working with - 2006 MBP TB 15” - vscode - sql server with docker - Azure Data Studio And at night in my home I have the same project in - $2700 MSI windows 10 gaming laptop with 2 monitors - vscode - sql server with docker - Azure Data Studio And I can say 100% sure that the macOS environment is by far the best in performance, speed, stability. The only con in macOS I feel a bit slow when debugging C#. Ps: I’m not a window’s hater. Ps2: my company bought JetBrains whole suite and I has been used a datagrip, rider and webstorm but always return to VSCode PS3: sorry my English. 
Awesome!
I have not used them extensively but I think the concept is correct. The intent of the controller in MVC is to map a request to a page but RazorPages simplifies that and just bypasses the need for a controller. Honestly it is not that big of a change since controllers when used correctly are pretty thin. Did you mean to ask about a comparison of RazorPages to SPA frameworks like Angular? 
I do it every day. 
You could create bridge tables (user address, company address, future entity address) that would contain keys of the applicable entity and the address.
Fifth 
Glad I could help!
Oh, that's a neat idea! Had something like that on Ubuntu with ./bashrc , but didn't know it existed for OSX bash terminal
Do you know if that would support cascading delete? Like if I delete the entry in the bridge table, could it delete the address automatically? Or I probably have to make my delete programmatic?
I haven't really tested my ASP.NET application, but VS Code tools for testing C# like to see what specific tests passed/failed don't work that well sometimes. Also, debugging is a touch harder since you can't hover over the values in VS Code. I tried giving Rider a shot, but my laptop starts to heat up to where I don't like it, but i've heard good things about it from other people. SQL Server Docker containers is something that's on my bucket list to learn, but I don't like the stateless nature of docker, so need to get into StorageOS or run services separately (I use AWS RDS, so my apps are statefull). I guess once I dive into Docker Swarm/Kubertenes maybe then, but thank you for the information!
If you're used to and like the current Visual Studio for Windows environment you might find Visual Studio for Mac disappointing. That said, there shouldn't be any reason why you can't run Windows in a VM and code in Visual Studio for Windows if you find that experience less than desirable. 
Yes. I've been doing .net dev on a win10 instance via parallels.
[removed]
Docker doesn't have to be stateless. You attach a volume to it and that persists data after the container stops.
It is completely fine. I used a mac for a longtime. Work gave me a HP Omen recently and I do enjoy that as well. &amp;#x200B; If you are just learning then a mac has all you want and using the command line with vscode and not relying on visual studio (and resharper) will ultimately make you better at .net in the long run.
You can also use SQL Operations Studio or SQLPro for any MSSQL stuff you need to do.
You could 1) setup the fk for cascading delete 2) handle deletes in a proc 3) handle in EF or other similar data layer
I'm in the same boat. I will probably never buy another Windows laptop. I hate the hardware. Been thinking about a MBP, but I too dislike OSX, or even a Chromebook. I have Rider and Datagrip.
I like a lot of the newer Lenovo ThinkPad lines. Solid hardware as well. I'd basically be between those 2 options.
Yeah was just looking at setting up fk in fluent api so there isn't a property. Thanks for your help!
You can achieve a REST API using the C in MVC. It can accept GET/POST/etc. data and return JSON.
Net core is fine, net framework you're going to need Windows by whatever means you prefer. 
I've never used it but whatever I build next I'm going to try okta. It's free for up to 1000 monthly users and handles everything.
Also, .net core lacks anything related to Web Forms (shudder).
I had a friend send me his own custom solution using JWT. I really like this approach because it was easier for me to understand what the hell is going on in comparison to Identity.
yup, no need for a visual studio extension or anything to manage. The project file in .net core is different from .net framework. For example you don't need to include every single file in the project file. VS Code works great, as mentioned, but I tend to favor the cli quite a bit. So I code/debug in VS Code, then do a "dotnet build", "dotnet test" or "dotnet run" in the cli ( run does a build so you don't have to.) After I check in the code, the CI/CD pipeline does a "dotnet restore" and "dotnet publish" to create build artifacts. On some applications, we do a docker build to generate a docker image that we push to upper environments.
I'll list a few that I've found myself really accustomed to from my previous Windows machine with VS Pro 2017: * Profiling tools * Decent Code Coverage tools - preferably integrated with the IDE * Removing a file from the Solution Explorer feels tedious. Instead of just deleting the file, it clutters up the Project file with some XML telling it to ignore the file. There's probably a use case for that that I'm not seeing, but I think I'd prefer to be able to just delete the file. With VS 2017, I also had ReSharper installed. I know it's not really fair to expect you to replicate Resharper's features, but it was part of my development experience that I really enjoyed on Windows, and really find myself missing a replacement on Mac OS. * The [go to implementation](https://www.jetbrains.com/help/resharper/Navigation_and_Search__Go_to_Implementation.html) feature when you right-click on an interface's member. I see that VS for Mac has a Navigate -&gt; Implementing Members context menu, but it doesn't do anything for me. * The [invert if](https://www.jetbrains.com/help/resharper/InvertIf.html) feature would be wonderful to see as I frequently find myself in a messy legacy codebase that I want to clean up. 
 I've been developing Xamarin mobile apps, and simple Dotnet Core projects on a MacBook Pro 2015, for the passed 2 years. It's definitely a capable and reliable machine, but you might consider a cheaper alternative if you're on a budget.
Last time I built one, I used bcrypt for the passwords, and wrote everything else myself. 
&gt; How best would you model these relationships while keeping the address entity untethered? Why? You want to avoid using the feature of your database that enforces referential integrity. &gt; I forsee the scenario where you create an address object and updating the related object (for instance a user) to contain the addresses' Id could fail, leaving you with an orphan And now you're worried you might violate referential integrity. Imagine that. I handle addresses similarly to how /u/campbellony describes.
There’s a difference between “can I do this” and “can it be done the same way.” Also Core has some things the regular framework doesn’t. Of course you can do “everything” there, but you can’t for example use libraries that are tied to non-core/non-standard etc. So there are limitations. 
We are using SSO Keycloak. 
And with Angular you access the data
By untethered I was meaning having an unnecessary property on my address class (code first) that referred back to the independent side of the relationship. Using fluent api let's me create a shadow property, everything is fine now.
I have looked at https://github.com/alphaleonis/AlphaVSS in the past as it exposes most of VSS. However you are right, VSS and it's interfaces seems more suited for a language like c or c++
I can use Invert If on Visual Studio for Mac though. Just right click on the if statement.
Does any one use these behaviours in their desktop app? If so, which ones do you find most useful?
Razor Pages are not really meant to replace MVC, they are meant to be used alongside MVC. They are meant to be used in small areas of your project, where you think there is no need to through the controller, but I really hate them myself and wouldn't let anybody use them in my project.
I used a MacBook Pro before getting a Dell Precision. It was fine. I just remapped some keys and installed VMWare to run a Windows environment and Visual Studio 2012.
Too much positive experience in this thread :/ TouchBar sucks. Its really Hard to find F5/F10 on it during debug. Switching to New shiny colored buttons is even worse. 10 years of using F_shortcuts is lost. Lack of pg up/pg down/delete also makes MBP a weak choice if ure really into fast navigating/code editing Paralles is great but well... If you dont care about performance and battery. Big touchpad is great but mouse is always faster. Best. NET tools like peofilers are still Windows only. Personally I gave it a try and switched to Lenovo T480 with Windows and Ubuntu under WSL. 
I usually just go with ASP.NET Identity. It has lots of built in features just working but also lets you inject your own implementations for almost every part of it.
Got a Github link to it?
Auth0 and Okta are meant to be good. Only tried Auth0 first hand which is pretty straight forward for JWT authentication.
More like a win/mac.
At my shop and yes extremely usefully for stuff like complex treeviews.
I don't know requirements but using DDD approach I would do: \- treat addresses like value object so every user and company has own "instance" of address. From DDD perspective value object doesn't have identity. \- make User and Company as DDD aggregate root. Use navigational property mapping only in one direction User -&gt; Addresses, Company - &gt; Addresses. Make these Addresses collections private. \- modify addresses ONLY invoking methods on aggregates (User, Company). For example AddAddress, EditAddress, RemoveAddress etc. When you implement something like this, you will not need cascading deletes which I strongly don't recommend. Keep domain logic in one place.
Im interested as well :)
I love it when the solution is simple. It always makes me feel stupid but it happens to everyone. 
MeTooing about that goddamned fucking keyboard. Makes my life a living hell
Best to just give up. MacOS as a whole is pretty meh now, it’s advantages over Windows don’t make up for the disadvantages. Windows 10 has made a lot of strides and all those swipe gesture for command centre/multiple desktops/screenshots are now not only in Windows 10 but are a better implementation.
Docker on Mac with a SQL Server container -- this was the killer feature that means that I don't have to always work in a Windows VM. I wish that MSFT would create emulators for CosmosDb and Azure Storage that run in linux containers...this would pretty much allow me to stay in MacOS for web dev. Overall, i'm amazed by how easy it is and how much that I can achieve with git + dotnet core + vs code. 
I work on .NET exclusively using macOS and have done for about 4 years. I almost never use Windows.
[OpenIddict](https://github.com/openiddict/openiddict-core) because Identity Server 4 was too complicated for me. Spoiler alert: OpenIddict isn't the easiest either but it has some good examples.
I'll be a dissenting opinion here and I did not like this setup personally. I like the OSX experience as well, don't get me wrong. However, switching between operating systems is a chore and configuring your keyboard shortcuts will take some time. I preferred to boot directly into Windows on my mac using bootcamp instead.
That's weird. I right-click on the if statement and that doesn't show up. Is there maybe a plugin you're using?
I have used a mixture of auth0 and identity server. This was primarily so it could interop with external identity sources, oidc and saml based. For my own projects have used identity server and recently switched to firebase.
I have been redeveloping a split ASP Classic / Web Forms legacy application using Razor Pages and so far it's been really great. It is very true that RP reduces a lot of the ceremony involved in MVC apps. I almost see it as a spiritual successor to Web Forms. I'm finding it a lot easier to port existing code/ideas over to RP than I would with MVC, and a lot quicker as well. As much as I hate Web Forms, I cannot say that I'm as productive in RP/MVC in terms of getting stuff done quickly, but at least now I know the code I'm writing is properly architected and supported by tests.
Visual Studio for Mac 7.7.1.15 No 3rd party plugins installed Proof: https://imgur.com/a/Bb0WB5d
I’m not sure I see the value of this, as those are all exceptional situations that the developer/code cannot automatically fix. I suppose it could help in showing a more meaningful error to the user, but whatever data entry they used should have validated those null constraints on entry, not based on exception. How do you use this, or see it being used?
I have been using the InvokeCommandAction in all our WPF projects for a while now via MVVMLight pulling in the System.Windows.Interactivity library. This allows my to adhere to the MVVM pattern for events on a Window. We make use of it to hook in to the Window's Loaded and Closing events for loading data and close verification respectively. That way we don't need to add code to the codebehind for the xaml files so we can stay mostly MVVM purist. &amp;#x200B; I say mostly because I still have to go in to the codebehind and add a custom IWindow interface (specifies the Close method) to the Window so that I can pass in a pointer to the Window in the command for Loaded without having to use it as a full fledged Window class in my viewmodel or unit tests (I don't want all that junk in unit tests, just need a way to tell the Window to close). There is also an issue I found with using InvokeCommandAction on the Closing event of the main form of the application. Every other Window in the app works fine, but for the main Window I still have to use the codebehind instead if I need to prompt the user to save before closing etc because the main Window won't call my ICommand hooked up to Closing via InvokeCommandAction and only works if I connect to the event directly in the codebehind. Not sure if this will also be an issue in this new package they are publishing or not.
I've found that Razor pages are like what Web Forms was "supposed" to be (sorry guys....) - get an idea up quickly. Anything other than that.... not for me. I've found that I don't like having one code-behind file per "page". Most non-trivial pages tend to get filled up with lots of AJAX related end-points. So what do you do? Create more razor pages that are focused on each specific resource they involved on your page (so one "main" razor page will have other supporting pages) - yet they are just endpoints for AJAX methods from the same HTML page. Having to create a razor page that only handles AJAX requests (which is a common use-case these days!) only works if your razor page markup file (a) exists and (b) is pretty much empty. That's weird. Why don't I just add some controllers? Well, then it gets confusing as to where things are and where they ought to be. Should it be a page? A Controller? Ok, here's a page... where are all it's AJAX requests? I also don't really like how AJAX requests are done (via {URL}?Handler="OnPostDoThisThing). At the end of the day, I prefer using controllers and views since I can split my page's endpoints throughout multiple controllers that each deal with (usually) REST for one resource only. And that's a pretty solid standard in the industry too so others can expect to find stuff where they think they are.
[removed]
I've always had this idea, and it is great to see you implement it. Now better error messages can be presented to the user when handling these on the front end. Thanks.
Identity with JWT for API auth.
To that vs code is still barely usable for professional .net development.
You have a lot of options with .net core thanks to having direct access to the middleware and not having to handle both OWIN Context and HTTPContext. I think you have 3 solutions that are perfectly fine to look at: * Built in .net identity core - it's come a long way from the system that resulted in Brock Allen creating IdentityManager. That said, there are still some gotchas, especially with 2.1's change to the authorization attributes. [Read more here](https://brockallen.com/2018/07/15/beware-the-combined-authorize-filter-mechanics-in-asp-net-core-2-1/). Also it's very customizable. Back in the day I created a custom implementation of Identity Framework 2 where I [replaced Entity Framework with Dapper](https://github.com/rantowork/MVC5-Dapper-Identity). * Your own JWT implementation - you get to build up the jwt bearer directly in your startup now without much fanfare and it's a first party inclusion. You can[learn a bit more here](http://jasonwatmore.com/post/2018/08/14/aspnet-core-21-jwt-authentication-tutorial-with-example-api). * Look at third party tools. I'm partial to Auth.0 because it is [open source](https://auth0.com/opensource). Just remember that it's not a self hosted solution. Don't hesitate to let me know if you have questions. Always happy to help :).
Thanks :) I worked a bit back and forth with a few different scenarios and I ended up basically with what you wrote. Databases and EF really aren't really my specialty - having flashbacks of relational algebra and having to normalize data back in college.
Could be helpfull if you implement a nice logger so u know better what kind of error are running in your Application maybe
Are you using VS for Mac, VSCode, or Rider for an 'IDE'? I've found that VS for Mac pales in comparison to it's windows counterpart. It has a fraction of the features, seems buggy, etc. I've heard that Rider is the best dev environment for .net on a mac though.
I dislike how different the menus are. It's been painful trying to find things that I'm used to being in certain places. I feel like the product is so different from the windows version it shouldn't even be called Visual Studio.
Id like to see some getting started templates beyond the really basic one in VS
Whit jwt u can Also implement custom IAuthorizationHandler for shield your api and get rid of claims in the jwt so u can dynamicy manage auth for specific users
I can get back into Angular at some point if I must but the idea of just c# is too appealing to not hope it takes off... So tired of npm world
Private repo sorry. I would, but it’s not mine to share. :(
I'm considering using HangFire with our [Asp.net](https://Asp.net) app (not Core yet). It looks really nice and seems to be the only alternative with a nice built-in dashboard. Having said that, I looked up the author, and he's based in Moscow, RU. These days that makes me pretty nervous. On the other hand, it is open source, so am I \*really\* nervous? Kinda... I wouldn't have access to the source code without a paid license, so just because it's open source doesn't mean something couldn't be hidden in the unpaid versions. Not sure. I may be being silly. Have to make the right call for my business though. I see a ton of people on here and elsewhere who use it without issue, so it must be good. Seems like my current options for triggering queued events in our [Asp.Net](https://Asp.Net) app are: 1. Keep using our Windows Task Scheduler kicking off a custom built job runner console app 2. Use Hangfire 3. Use an alternative like [Quartz.net](https://Quartz.net), which will do the trick, but sans the nice dashboard/interface &amp;#x200B;
This.
The existing exception that he’s unwrapping already contains the same info these exceptions are exposing (that’s how he knows which exception to throw). Even in the case of some automated ETL process I just can’t see the value of having these as separate exceptions. The only use I can figure is during development, helping a *new* dev figure out why their entities failed to save, without reading the exception details. 
Brilliant! Installing it first thing tomorrow morning! 
I use Ride on mb pro for last 1y. Core projects only. Works fine, rider is great, but still little bit slow in debugging compared to VS. New rider should get code lens, im missing that a lot!
A couple of thoughts: 1. I feel like you exceptions should inherit from DbUpdateException. That way, dropping this package in won't break existing code when dropped in. 2. `ExceptionProcessorContextBase&lt;T&gt;.GetDatabaseError(T)` should not be internal. That restricts others who might wish to add support for other Databases. Instead, make it and the `DatabaseError` `enum` protected. 
Yeah I guessed, I was hoping you'd ask him to make it available if that was the case. Not to worry anyways.
I'd certainly say that's a matter of opinion. I'm quite successful as a professional developer (going on 15 years of professional experience) that currently uses VS Code every day, as my primary IDE. If you aren't comfortable using VS Code in a professional capacity, I respect that, and I don't force VS Code or macOS development on anyone on my teams. We live in a wonderful time where we can choose the .NET development environment (OS, IDE, other tooling) best suited to our personal tastes and how we feel most productive.
Here's a solution that might work for you. [FusionAuth.io](https://FusionAuth.io) \- it's dev-focused, and they have several client libraries. It's gotten a lot of traction lately since it's free and pretty flexible. 
This is a nice idea, any chance of EntityFramework.Exceptions.SQLite?
As far as I know SQLite doesn't enforce most of the constraints so that's why I skipped it. If you have more experience with it can you tell me that is the case or not?
Thanks for the suggestions! By breaking the existing code do you mean getting unhandled exceptions as they don't inherit from DbUpdateException?
Does Apple push advertisements to Mac OS? Microsoft is making it harder to disable ads and I have had my eye on the door for a while because of it. 
Yeah to each their own man, it's not for everyone. I use a dual monitor set up so I can have Parallels open on one and OSX open on the other, so I don't really have to switch between the two. Also even when I'm not using multiple monitors, switching to Parallels is as easy as just swiping left with 3 fingers, so it's a pretty seamless transition between the two.
I’m using Java + Javafx for a cross platform desktop app but I much prefer .NET WPF because updating nested bindings just works out of the box. I’m using python for machine learning stuff with the trained models then used via Java or .NET app. Would be cool to have some kind of C# scripting (is it already available?) and also a inbuilt multidimensional array object in .NET with functionality like like numpy’s array, although I think there are a fee NuGet libraries that can give you this. 
Those aren't exclusive. All this logic can be inside a simple class with static fields for the config values, or use normal fields and just register the class as a singleton, or register it as a IConfiguration provider to follow the exact semantics of the [ASP.NET](https://ASP.NET) Configuration system. The point is that there is not much concern for thread safety here as you only need a single loop to update values and variable assignments are guaranteed to be atomic, or you can use [Interlocked.Exchange](https://Interlocked.Exchange) for extra safety.
Here's the github issue, you'll have to wait for v4 or use manual http calls: [https://github.com/intuit/QuickBooks-V3-DotNET-SDK/issues/3](https://github.com/intuit/QuickBooks-V3-DotNET-SDK/issues/3)
I was under the impression that indexing an array with a Range would return a Span, but from what I can tell it returns an array (which means copy - which is not great). Also, it would have been interesting to extend collections like List&lt;T&gt; with a Range indexer.
grumble.... Thanks for the link!
If we're inheriting `ExceptionProcessorContext` on DbContext. How would you use `IdentityDbContext` with this? For those who are using asp.net core identity.
Hover over vars in debug has always worked for me in vscode (linux) . Would be hard to believe it's supported on linux before macos. Are you sure it isn't something with your setup? 
Why are you checking bounds on only one control? The properties of x are always going to equal the properties of x. Don't ask me why but it always seems to work that way.
You could try SignalR
Yea bro I know. The problem is I have to work with multiple instances so I declare a global variable of the User Control and from the code I can spawn as much as I want to. I just cant advance from here I dont know what to do 
&gt; so I declare a global variable of the User Control &gt; I can spawn as much as I want to. So which one do you do? If you have a single global instance it does not do you much good to compare it to itself. var x = new MyControl(); var y = new MyControl(); x.Bounds = something; y.Bounds = something else; bool z = x.Equals(y); // false if(x.Bounds.IntersectsWith(y.Bounds)) 
I don't think I'd assume it was a copy at this point.
I have a global variable of that User Control like you said. UserControl1 user; then when I want to spawn I just use user = new User Control(); And I can do whatever I want with each one of them. I can move just one, just two or all of them. The only problem is at the intersection
If you do x.AsSpan()[3..6] then you’ll get a sub span.
OK you have a class called UserControl are you creating *multiple instances* with different names as I demonstrated in my last post? Please post your code.
imo its just googling and experience. I don't think anybody needs to learn EVERYTHING, but you'll find yourself reusing a lot of the same stuff over and over, which then just become part of your every-day skillset.
It's a combination of reading books and googling, pretty much.
Work on something, find a piece that seems like it would be useful to a lot of people, for example reading a file using something easier than a bunch of nested streams. Google “reading file text c#” and look through the first few links, realize there is a `File` class that makes life easier. Rinse, repeat throughout the project. Also, follow some blogs on MSDN that correspond to pieces you use (like EF, networking, razor). I have never just wandered through MSDN, looking for classes I haven’t used before without a reason to apply them to something I am actually working on. 
Thanks. Google is my friend. 
They don't. People learn what they need. For example I cannot tell you anything about WPF specific libraries because it isn't something I use or plan to use. But want to talk about MVC? Some core CLR stuff? Or a dozen popular JavaScript libraries and I'm game. The only thing I'd say is expected is some of the popular classes used by everything all the time (e.g. System.Text, System.Collections, Linq, etc). 
Honestly man, 80% or greater of being a good developer is strong google-fu, and being able to process what you find quickly. I’ve been doing this 20 years and not a day has gone by without me googling _something_. 
If it's an array with a different length, then it has to be a copy.
Read about "just-in-time" learning. It's wasteful to try to learn everything up front. You'll just forget it if you don't use it right away. Learn things as you need them.
Nullable reference types are awesome. I remember when Nullable&lt;T&gt; was first released along with '?' syntax. I always thought everything that was nullable should have a '?'. 
Having used c# since .net 1.1, and working on a large greenfield (but mostly complete) java project earlier this year, I can’t say as though I’ve seen much in java land that doesn’t exist in dot net. It seems like java has a lot more library options for solving each problem (cough cough json parsing), but more options doesn’t always mean better. Thinking about this more, the one place I’d be happy to see more choices would be in the dotnet core auth pieces - current mature choices seem to be auth0, AD, or the proof-of-concept-set-loose EF Identity bits (string for a GUID identity column, *seriously* guys?). I’d love to see a lightweight provider that didn’t drag along a bunch of tables/entities related to OAuth - I just want basic login with JWT and claims, and I don’t particularly want to roll my own. Rant over. So, apparently the third party library I’d like to see is LightweightAuth 😁
For me it's much nicer to catch a specific exception than dig into engine specific error codes and leave a comment explaining what the heck it is.
Ok, but what can you do, programmatically, at the point where you catch the exception?
If you slice an array you get an array, if you slice a span you get a span.
&gt;Thanks for the feedback, I've made a note of the features that you've requested. &gt; &gt;Regarding the deletion of files, when you right click on a file in the Solution Pad and select Remove, in the dialog that appears there are two options; Remove from Project and Delete. To delete the file from disk just use the Delete button. &gt; &gt;About Navigate-&gt;Implementing Members, I was able to reproduce that and I've filed a bug. Thanks for letting me know about that. &amp;#x200B;
It's not about if I can recover from it (though there are a few places I could benefit from the unique constraint exception). It's about: A) making it obvious to the axe wielding psychopath going into the code after me B) better reporting on why these failures are happening when ops or product or marketing comes knocking C) letting the client know not only something went bad but how it went bad and if there's anything they can do. Client isn't synonymous with human being. It isn't about trying to make data fit where it shouldn't. Otherwise why is this information communicated at all? And the fact that it's not communicated _simply_ makes it more likely I won't do any of those things. If it's simple and doesn't require a comment like `//postgres unique constraint violation` I'm more likely to handle those cases in a graceful fashion rather than showing an ugly 500 error to the client and a stack trace 6000 lines deep of EF.
Why? In D, arrays are a pointer and a length. If you slice the first 3 elements of an array, you have the same pointer but a length of 3.
It's also available in the Light bulb. I was just trying it out and I noticed that the option doesn't appear for stand alone if blocks but does when if/else is used. I've filed a bug to address this.
I'm sorry to hear that you're having difficulties. Is there anything in particular that you can recall that was difficult to find, or are there any specific areas that I can look at improving? Or is the issue more general, and that you'd like it to be more consistent with Visual Studio (Windows)?
I can totally relate to the 6000 line EF stack trace. And worrying about A. Wouldn’t it make more sense though to put that logging in the SaveChanges method of the Context, so nobody had to worry about catching and inspecting an exception? I may just be too used to writing infrastructure code, and trying to keep the axe carrying maintenance dev from forgetting to do something and thus taking it out on me. Defensive programming is really hard to stop doing once you start. 
I haven’t seen any ads yet. Been on MacOS for about 3 years now. 
It’s not ideal, but this should work. In your VB code, check for the PostBack event when the page loads. If it detects the PostBack, add the same js function call to the onload event (that has the working AJAX request) of the page. When the page reloads on PostBack, your grid should be bound to the correct data and your js function should execute as well.
I like the sound of this but don't know how I'd do it, when you say add the function call to the onload, do you mean calling the function from the server side on page load ?
I'll check this out. Thank you
Wow, thanks a bunch! I'll look forward to your next few releases! I also looked at that navigate menu with a little more scrutiny today, and noticed an item that actually seemed to fulfill my longing for "go to implementation". Unfortunately, I don't remember what the menu item was called, and I'm not on the Mac at the moment.
There's a lot of new memory features going into Core. As the other poster posted, a COW implementation, or a true slice, could be a thing they did.
&gt; the option doesn't appear for stand alone if blocks but does when if/else is used. Ah, I think that's probably why I've always missed it. I always want to refactor a bunch of code that look something like: if( blah != null) { // Do a bunch of stuff with blah, and return something } return null; into something like: if( blah == null) throw NullReferenceException(); // Do a bunch of stuff with blah and return something 
No, you can't call javascript directly from server side code, but there are ways around that. Here is a pretty detailed post on the subject - [http://geekswithblogs.net/mahesh/archive/2006/06/27/83264.aspx](http://geekswithblogs.net/mahesh/archive/2006/06/27/83264.aspx) &amp;#x200B; I'm not sure what version of .NET you're using but it sounds like Winforms, based on your post. Again, not ideal, but you can literally render sections of javascript on the page based on the PostBack evaluation. Something like this: `&lt;% If IsPostBack = true Then %&gt;` `window.onload = function(){call existing AJAX function here};` `&lt;% End If %&gt;` If the page determines it's getting posted to, this onload even will be rendered to the page and fire accordingly. Again, not ideal, but based on what you've described, ideal might be out of the question. 
Because this is C#, not D.
Like the old lady with a seed catalog it helps to start by figuring out what it is you want to do. Vegetables? Winter vegetables? Winter vegetables that are drought resistant? From there it's just googling or reading stackoverflow.
Not trying to be defensive, you're being defensive. :P
This helps alot. Thank you !
No, it sounds like he’s overwriting that same variable each time he spawns a new control. OP, you need to keep a list of all of the controls you’ve spawned. 
[It has been implemented in the Roslyn C# compiler, but somehow didn't show up in Visual Studio for Mac.](https://github.com/dotnet/roslyn/pull/26793)
An old lady?!? Seed catalogs?!? No, it's called coding. A lot. 
15 years of experience. And yeah, I've use reflector to look through most of the framework top to bottom before.
I totally understand how it can be overwhelming. Learning a new language these days isn't just about learning new syntax (even moving from a C-style language to e.g. Python is straightforward enough once you get used to it) - it's about understanding the underlying framework and what utilities exist for you to re-use. You could spend your entire working career doing C# development and you still wouldn't know the entire framework, let alone all of the 3rd party libraries! I've been programming in C# for about 15 years now, and a lot of what I've learned has been trial and error, going back and re-writing code when I can, reading blogs written by people smarter than I am, and so on. Keep an eye on blogs like [The Morning Brew](http://blog.cwa.me.uk/) (although the author is on paternity leave at the moment) as these sorts of aggregators are helpful for keeping track of what's new, what's in the pipeline, how to apply various libraries to your projects, and so on. I've also found tools like [LINQPad](https://www.linqpad.net/) to be brilliant for quickly checking out the behaviour of classes and methods, rather than having to write loads of crappy little command line tools to check the same thing.
Wow this title :D It's more familiarity through use for me! There are vast swathes of stuff you may never come into contact with (and that's ok!) But for the rest it's just "oh that's nifty. Didn't know that was an in-built. Fuck I love dot net."
I think Intellisense gives you a pretty good picture about what goes where. In my experience, you don’t have to read a lot of documentation for understanding a simple API. Big frameworks like asp or complicated stuff like system. Threading are a different beast though. For those those I usually read a book from cover to cover, but without getting stuck in the details. 
Good point! Is IdentityDbContext still a thing in EF Core?
As far as I know SQLite doesn't enforce most of the constraints so that's why I skipped it. If you have more experience with it can you tell me that is the case or not?
Anyone else excited for the Switch syntactic sugar update? The new formatting looks incredible, so much screen real estate saved.
That makes sense.
There are a bunch of exams for certification and to get you a place at an interview which expect you to remember stuff in stupid detail, but no. One thing I would say is, if you are about to write something which, for example, averages a set of numbers, google it to see if the framework already has a method for it. 
Kup: "Experience, boy. You should learn to appreciate it." Transformers The Movie is an entire film dedicated to the idea that you learn on your journey through life and you begin to apply your experiences to the here and now. It does not matter the language or framework, they all have a learning curve that requires using the stuff in a meaningful way to build the experience. Bah-weep-Graaaaagnah wheep ni ni bong.[
No idea how it's solved in Java/Spring environment but I'd love to see an official or 3rd party way of creating proper Json Merge Patch. I think we're finally advanced anough to create a basic HTTP method to know whether a property was set. There's like one old Nuget that supports this but is architecturally really bad.
I just collect them and make micro samples out of it (https://github.com/dodyg/practical-aspnetcore) so I don't forget on how to use them next time. It's impossible to remember everything but once you encounter one, you usually can sort of figure out that you saw it somewhere.
I was using VS for Mac and didn't find it too bad, they've done quite a bit of work on it and it's certainly improved from the old Xamarin Studio. That said I recently switched to Rider and it's now my main IDE - it's basically a hybrid of IntelliJ and Resharper and is very fast and efficient.
Yeah I've felt the debugging is a bit slow but apparently they've done a lot of work on it and a new release is out soon that addresses this.
And if you then modify the orginal array you also modify the slice, and that's not how dotnet normally works when it comes to arrays! 
No. I'm using the same variable, the problem with using different names is I have to work with the numbers of instance that the user wants. Not just 2 or 3, maybe 10 or 20, so I have to have a code that works for all of them. I'm using a foreach on a timer to make them move
I have not seen it, but if you are using a lot of switch statements you should have a think about something a bit more object oriented may be better design. 
Thank you. Good stuff. 
It really depends. Polymorphism is useful when you are facing something like a strategy pattern. Sometimes you have a finite number of cases that represents a piece of data and using a switch is more useful &amp; cohesive. It could be a container representing failure/success with specific payloads for each cases. It could be a piece of code that has to process an untyped json value (which could only be a null, a string, a number, an array or an object).
I havnt been able to learn everything about a framework for 20 years... They got complex.
Trying to learn everything will definitely overwhelm you and you'll probably become burnt out or worse, depressed. From my experience, you do stuff over and over again and (this is true especially for single projects), you'll develop a small skill set that will only stay with you for the project. After you won't use specific classes for quite some time, it's natural to forget them. I strongly advice you to learn design patterns and OOP principles by heart though, those will stay with you and you'll be able to learn something much better if you use them.
Speaking of xamarin, how good is rider for xamarin development? I have an iOS project coming soon and if rider is a better environment for developing that side of our mobile app then I'm planning on upgrading my resharper license to the all products pack. 
You don't learn the framework. You become a Google ninja, and you learn abstracted patterns along the way. The abstracted patterns allow you to make accurate predictions. "When I used this namespace, they did things this way. I bet things are done a similar way in this other namespace." Then Intellisense takes you the rest of the way. I once worked in the same building as an insurance salesman who'd gone to college to be a software developer. He had been a junior Java developer at one point but told me that he couldn't keep up with all the changes to the JDK. It was just too much to memorize. Identifying what *isn't* necessary to learn is paramount to becoming an effective software developer. ["Never memorize anything you can look up." - Albert Einstein](https://www.goodreads.com/quotes/24194-never-memorize-something-that-you-can-look-up)
I have a Pinterest board.
Then you're in an interview and they ask you a bunch of dictionary questions and never look at your code or accomplishments.
That is why I said think about it :p Also lots of people see a "should I use switch statements or if statements?" and are not even aware that there other techniques that can be brought to bare on a problem.
I wish they had stayed consistent with PowerShell for ranges. Exclusive end doesn’t seem intuitive to me, and negatives would have been more intuitive than ^.
If that were the case the candidate dodged a bullet. That isn't somewhere you wish to work anyway, and that company missed out on *your* talent. 
I see you were also enraged by that thread too
Store each control reference in a list; var myControls = new List&lt;MyControl&gt;(); Then add them all myControls.Add(new MyControl()); Then compare them all foreach(var control in myControls){...do intersect check here...} 
Well played sir 
I haven't done any Xamarin development with Rider. I understand it's possible but have no idea what the experience is like. I'd still fancy using VS for Mac for iOS development will be a better experience than using VS on Windows.
You don't normally do that. &amp;#x200B; As a developer, you start with "I need to achieve this". Then find a library that can achieve that. Then, find out how to do it with that library. &amp;#x200B; Sometimes, when something cool and new comes out, you might just explore the library/framework/service to just see what it can achieve (so that you can then archive this info in your head to take out whenever you see a problem that can be solved by this). Here, generally, you just see what all can be done by that library, see some samples, and form some mental model about the library (what it can do, how, etc). Then come back to it when you need it. 
Learn and study patterns and design philosophy. Memorize keyboard shortcuts. Google/StackOverflow/docs for everything else. (syntax, API, code snippets)
I use JWT to do thay
Does it matter? Why do you require inheriting from your DbContext?
Using a service based approach with dependency injection should go a long way in making controllers less bloated. As you mentioned refactoring common code into helper methods also works. That might be a good starting point. 
&gt; service based approach Is this also called service oriented architecture, am I understanding this correctly? 
Are you guys seriously calling a 250 line class "bloated"? You want to put the overhead of dependency injection in place to reduce the code line count? Those lines of code have to go somewhere. I don't know where this magical 250 line code count comes from these days. 
Agreed with other comments. Anyone online who thinks they have a comprehensive knowledge of a framework is kidding themselves. You just learn more and more as projects call for new tricks, and eventually you have a good-enough knowledge base.
Well, I like to set a limit of 120 lines for every file in the project. If you break into smaller classes/services the likeliness of it being used somewhere else increases a lot. Also I feel way better to navigate in code that I don't need to scroll forever to reach the point I want to see. 
Sorry, I expressed poorly. Methods(actions) of a class are 200-300 lines.
MVC pattern in [ASP.NET](https://ASP.NET) MVC application is used to structure your GUI layer. Controllers should be as thin as possible. Additionally, they should have "one reason to change" as Single Responsibility Principle says, so one controller should be responsible for one screen/entity/feature (it depends on situation). Where the application logic should be implemented? In Application Layer. There are two common ways to implement this layer: \- Create service classes - for example OrderService, ArticleService etc. \- Create commands/queries and handlers - for example AddOrderCommand, AddOrderCommandHandler Each service / handler should have application logic. Sometimes they have business logic (see TransactionScript [https://martinfowler.com/eaaCatalog/transactionScript.html](https://martinfowler.com/eaaCatalog/transactionScript.html)), sometimes they don't have business logic - it is in domain layer (see DDD [https://martinfowler.com/bliki/DDD\_Aggregate.html](https://martinfowler.com/bliki/DDD_Aggregate.html) ) &amp;#x200B;
He didn't say class. He said actions in a controller are 300 lines long. I'm sure some portion of that is either repeated code or has a lot of business logic that is better off in a service. 
He said nothing of actions. He said the controller was 200-250 lines long.
OK, that makes more sense. 
I discover things one problem at a time, most scenarios repeat themselves over time and end up sticking with me and before you know it youve familiarized yourself with a lot of methods/classes
Yep, pretty sure it's still alive and kicking out there. I'm using it for Identity Server4. 
I've solved similar issues before, but never using XmlSerializer which is a blunt instrument. Instead I've used [XmlReader](https://docs.microsoft.com/en-us/dotnet/api/system.xml.xmlreader?view=netframework-4.7.2) which allows you to step through the Xml structure statement by statement. It requires a lot more work but gives you near infinite amounts of control, including ignoring unexpected structures. 
The whole point of using XmlSerializer (at least for me) is that you don't have to manually parse the document yourself.
OP the beat way may be to handle it in two passes: First pass using XmlDocument or XmlReader to validate all xsi:type attributes (I recommend XmlDocument if the file is not gigantic as it will be a lot easier and you can use XPath) and remove any nodes for types that don't exist. Then save the file back to disk and use XmlSerializer to read in your data.
Nice throwback. I agree though. Frankly I'm more interested in someone displaying some good problem solving tendencies than knowing the exact right syntax of a language or very specific methods of framework classes. Understanding how a theoretical hash table works seems more useful to me than knowing exactly how to operate a HashSet or Dictionary class.
I agree. But just because you have a hammer it doesn't mean everything is a nail. In this case the OP wants more flexible Xml de-serialization than XmlSerializer can provide. I am presenting them a tool that will ultimately fit their goals even if implementing it will make them hate their life for a little while. If someone can name a way to accomplish this using XmlSerializer then go for it. It would certainly be less painful than XmlReader. 
The first step should be to identify duplicate code that you will want to collect into common functions. You can even start by creating these functions in the controller class as a first step to deduplicate the code. Next I would think about OOP. What types of objects (logically speaking) is the code dealing with? As an example I have controller function that will return a thumbnail of an image. This image is referenced by an identifier passed into the controller which maps to a source file elsewhere. I have a class which represents the image and it accepts that identifier, and works out the path of the image on disk using that. I also gave it functions to check if a thumbnail is cached on disk, a function to generate a thumbnail and save it to disk, and a function to return the path to the thumbnail file. So now all my controller needs to do is create an instance of that image object with the identifier, and call the appropriate functions to determine if the thumbnail exists, generate it if it does not, and return it/
If you have a single variable you can only store a single object in it. You want to store multiple objects so your solution is not workable that way. So you need to find an alternative. One way is the .Controls property of any control will return the collection of child controls. So once you add a UserControl it will be in this list along with any others. I would recommend using a Panel to hold all the UserControls so that no other controls will be in the Panel's .Controls, as well as to ensure the user can't cover other controls with the UserControls since you can limit the Panel's dimensions to prevent that. However if you do have other controls you can use some LINQ to only get the UserControls: panel.Controls.OfType&lt;MyUserControlClassName&gt;() The result is an `IEnumerable&lt;MyUserControlClassName&gt;`. If you are not familiar with LINQ you will not want to store this result for use multiple times directly; if you need to, call `.ToArray()` on it first to convert it to an Array. If you don't need to you can directly do a `foreach` loop in it without converting to an Array if that works how you need. The other method is to continue to use a variable, but make it a `List&lt;MyUserControlClassName&gt;` type instead of a single UserControl. This will allow you to store multiple instances of the UserControl. Once you do this your actual requested problem becomes trivial. You had the right idea... call `.Bounds.IntersectsWith` to check the new control against all the old ones. Keep in mind if you are using `.Controls` the new control will show up in the list once you add it (and you will have to add it before you check the bounds) so you will want to compare the two UserControls to confirm they are different before checking their bounds intersection.
There's a very thin line between future proofing and over-engineering. What stopped me reading though is "Avoid building monoliths". This is definitely over-engineering, the vast majority of big systems started as monoliths and stayed that way for years. Choosing a micro-service architecture for a greenfield project would slow development down tremendously. Instead, a well designed and tested monolith paves the way to split it into micro-services if and when the need arises.
I was thinking about doing something similar to what you recommended. Open using XmlDocument (when I run into an error). XPath to find all of the nodes with xsi:type attributes. Remove all nodes I don't have a type for. Use memory stream to create an in memory corrected version of the document and deserialize from the corrected document stream. So basically try to read in one pass and do a two pass when an exception is encountered as a recovery procedure. I was really hoping there may be a cleaner way. Unfortunately XmlDeserializationEvents which allows you to capture the unknown types during deserialization through "OnUnknownNode" events, does not provide a way to correct/skip the nodes. 
For me we have a console app receiving a ton (2000+/s) messages from various hardware devices, every message of which requires specific, finite case bitshifts to be performed to get particular values. Polymorphism isn't useful at all here, but the new switch syntax would reduce the logic by ~200 lines, give or take.
Yeah you do only need to do that if you hit an error deserializing. That might be a good idea, especially if the document is large, since you only are manually parsing it if you need to.
VS (or Resharper it all blurs together for me) has a wonderful refactoring feature that allows you to highlight code blocks and extract them locally or to new classes. I love it.
I plan to add a way to get the same behavior without having to inherit from `ExceptionProcessorContext` It will be a little bit more code for the user but it will avoid the multiple inheritance issue.
Pluralsight
Is it all for local tools? If not, I say invest in observability: NewRelic or the like for APM SumoLogic, Splunk, or Honeycomb for event/log aggregation and analysis Training for the above.
EF Profiler
I’d take advantage of free software. The software you listed is overrated anyway. Pluralsight is a great suggestion, that really is an invaluable resource. Knowledge is power.
I've had good experiences working with RedGate tools [RedGate .NET developer bundle](https://www.red-gate.com/products/dotnet-development/dotnet-developer-bundle/)
I forgot about Pluralsight.
You're right. This is going to the top of the list.
I should have mentioned that in the OP. They all will be local. I'll keep your recommendations in mind if we go cloud based.
That one intrigued me. They say you can find bottlenecks in an application within 5 minutes. Would you say that's true?
If you use EF, this tool is amazing. 
The `ICommand` interface specifies a `CanExecuteChanged` event. Unfortunately, it doesn't specify a method to raise that event from outside. You need to add that method in a custom subclass: public class MyCustomCommand : ICommand { public void RaiseCanExecuteChanged() { if (CanExecuteChanged != null) CanExecuteChanged(this, EventArgs.Empty); } // insert implementations for other members of ICommand here } That will let you do something like this: public class MyViewModel : INotifyPropertyChanged { private ObservableCollection&lt;Widget&gt; _widgets; public ObservableCollection&lt;Widget&gt; Widgets { get =&gt; _widgets; set { if(PropertyChanged != null) PropertyChanged(nameof(Widgets)); } } public MyCustomCommand DoSomethingCommand { get; private set; } public MyViewModel(...) { // initialize stuff // listen for when the collection changes Widgets.CollectionChanged += (sender, e) =&gt; { // signal that "CanExecute" may have changed, causing listeners to call it again DoSomethingCommand.RaiseCanExecuteChanged(); }; } }
If you use both oracle and sql server, I highly suggest datagrip from JetBrains. It's really nice to have one piece of software to interface with just about any database engine you could need. A lot of jetbrains' other software products are great also.
If you're doing anything involving web-services, ORMS, and JSON, I'd suggest ServiceStack. Worth. Every. Dime.
do you already have VS enterprise licenses/subscriptions? that gets you access to the same things as the old MSDN subscriptions - basically every piece of MS software you could ever want to develop against, for web or desktop.
Microservice architecture is not necessarily the only alternative to monoliths. In this context, I guess what the author is trying to say is to avoid implementing all your business services into a single application; maybe some of them could live as stand-alone services - again, doesn't necessarily mean you have a microservice architecture.
Personally I like [https://www.oz-code.com/](https://www.oz-code.com/) useful tool and visual for debugging. I use RoslynPad instead LinqPad since I don't need all the features LinqPad provides.
NCrunch is amazing, it's one of my favourite tools. I save a huge amount of time auto-running impacted tests when I make code changes.
I'm assuming you're capturing form elements into a model, if that's the case you'll probably do well to use [scaffolds](https://www.red-gate.com/simple-talk/dotnet/asp-net/using-scaffolding-to-create-mvc-applications-with-visual-studio/) to get started interacting with the database. Remember the adage [TIMTOWTDI](https://en.wiktionary.org/wiki/TMTOWTDI#English). Take small steps, breathe when you encounter errors, refactor, improve your code... repeat. &amp;#x200B;
If the suggestion is to build a distributed monolith that's even worse. Perhaps the author had a specific context in mind but it's not in the post.
all things redgate. We particularly love the data and schema compare tools. Saves so much time.
&gt; They say you can find bottlenecks in an application within 5 minutes. Would you say that's true? You might find some issues fairly quickly, but generally, no. I'd even say 5 minutes borders on a ridiculous claim. To find something that fast it would have to be egregious enough to stick out like a sore thumb and in a section of code that you would already be choosing to run and profile.
Yes it's possible. Generally we profiled parts of our system that we knew were slow and were able to quickly pinpoint where the slowness was coming from. Other data was helpful too like number of calls to a function, leading to things like "that should have only been called once why was it hit 25 times?" You can save profile sessions too so you can profile, make changes to a function, then run a new profile and compare (though no built-in comparison as far as I know). I'd recommend trying their free version. Also along the lines of performance, if you're looking for benchmark tools BenchmarkDotNet is free [https://benchmarkdotnet.org/](https://benchmarkdotnet.org/)
ALM and CICD subscriptions are a gazillion times more valuable than paid git guis, deprecated code fix bundles and please don't ever use unit tests to your advantage tools.
Like all the time right now, it just went open source and you can clearly see the commits. [https://github.com/dotnet/wpf](https://github.com/dotnet/wpf)
Pick up a copy of C# in a Nutshell from O'Reilly and page through it. Beyond that, experience.
OP didn't ask about how experts prepare for interviews. That's a totally different question.
How do you do your builds and deploys? Focus on that. Get Team City (or equiv) and definitely Octopus Deploy. Keep money aside for 6 months time when you find something else you need. 
No need to spend much on dev tools more than what you have listed. Usually only the red gate tools I’d say are a must.
Jetbrain products are amazing. I've pretty much switched over from VS to Rider at this point for most use cases.
&gt; The software you listed is overrated anyway Linqpad? ReSharper? Those are pretty useful tools in my opinion.
not really. if there's no duplication of code across those classes, breaking it up into less readable chunks to fulfill some fantasy of 'correct function length' is pretty counter-productive.
if you have to ask how to do it, you're the wrong person to be doing it. grab a copy of martin fowler's 'refactoring' and read that before you do anything to the code to 'fix' it. after a few years of making updates to it, if you understand it well enough to rewrite it from scratch, then you can refactor it toward the goal of making it unit testable and writing extensive tests for the application.
Hmmm, this actually sounds like a fun OSS project to make. I made my own super lightweight CMS from continually pulling in the same project, improving it with each project and finally just made it a library. I just realized I do the same with auth nowadays, I am betting I could do the same with some extra free time...
I highly recommend the RedGate SQL Toolbelt product of theirs.
Azure Devops is git hosting for free if you have less than 5 devs. And VSC is amazing and free, to replace Linqpad.
Resharper. It is must-have for every .NET developer. Period. But you have to be careful, because if you will be using it you would never come back to your IDE without it.
Disagree. I find microservice systems easier to comprehend, even for new projects. You don't need to mess with a microservice not relevant to the feature you're coding. I keep things modular from the beginning and only merge microservice together when I need to, usually when the data needs to be joined.
Has anyone mentioned TeamCity?
I'm considering upgrading the all products pack just for rider + resharper and datagrip. 
I feel ya. Most apps are just a single database and therefore a single app. You can do microservices all day long but if you're simply hitting the same DB with those services, they're really not separate systems and therefore no need to split them out into separate services. I often see people try to implement a microservice architecture around something that is basically just a giant monolith. The microservices just exist inside of a monolith system. This is even worse than a "simple" monolith. If they are truly separate then go for it.
When you create a new project in the Views \ Shared folder there is a file called _Layout which your views will all reference. You need to replace the HTML in here with the Index.html from your purchased template. Before you just drop it in though, pay attention to the code in the existing Layout file. You'll see reference to things like @RenderBody and a few tags which obviously aren't HTML but are actually Razor. You need to put these in the appropriate place in your new template. 
It’s been on my todo list for like a year, I just never have made the time to get to it. PM me if you’re interested in collaborating
Still no osx or Linux support...
Two good chairs
Rider is basically the Resharper engine loaded into Intellij.
It's overrated Imo. U don't learn how to write enterprise code from the Vids I've seen, I cancelled my sub and I prefer reading articles and going through good githubs, downloading them and running em
Seconding this. It motivated me to write better tests which is a good thing.
It's probably one of those tabs vs spaces or light mode vs dark mode things. A religious debate in other words. I'm like you. I make a small change, test it, and repeat. I can't even begin to imagine writing code for 3 hours and then running it. I write the absolute minimum code that will run, then run it. Then I add the next small step and run it again. I probably spend half of my work day running the code. But I know perfectly competent developers who run their code maybe twice a day and write huge chunks of code in between runs. It's just a personality thing. It's probably related, but I also make lots of tiny commits over the day as opposed to one big one at the end of the day (or days). If it works, it gets committed. Then I move on to the next step. Again, I know lots of good developers who commit once a day if that. I can't work that way, but it works for them. If your process works for you, don't waste time changing it. In the end, the numbers probably balance out the same. It takes X minutes to write the code whether that's done in small chunks or big blitzes. And it takes Y minutes to test the changes whether that's done in small chunks over the day or one big chunk at the end (with associated code changes to fix issues).
I use it on my site with preboot , I based it on a github but it targeted angular 5 which broke with my angular 7 I can pm u my git hub if u want. Tho I still have a bug on first page load prebootfn undefined. But I think its a non issue as it works just fine. It doesn't rely on node and gives u flexibility to inject title and meta tags on route changes in angular. I deployed it to an app service container and it worked like a charm. My angular and core api is in the same project tho so might not suit you
Get good chairs for your developers if you already do not have them. Get *really good* chairs. Nothing hurts productivity more than fatigue induced from poor posture and a terrible support.
TeamCity and Octopus for builds and deployments.
We have an install already but we're not currently using it. We do have YouTrack licensed.
Linux, and two $5000 bonuses.
I'd suggest you talk to your developers about their desire to use something like Pluralsight first. Personally I've never enjoyed using sites like Pluralsight since it just doesn't mesh well with how I learn, and I've seen a few other developers I've worked with try it and have it not click either. My suggestion would be (and I have no backing evidence to suggest the worth of it) would be ask them if they're interested in expanding their knowledge and if so, in what direction and how they might like to go about upskilling. Personally I enjoy being allowed to have a crack at improving technical parts of the software I'm working on that, while the outcome is beneficial, it's still beaten out by higher value user stories. I also enjoyed going to a few meetups about different tech in my industry. One company I worked for gave us a day off to go to the AWS meetup as a team so we could have a think about how best we might use it in our company. I really enjoyed that.
I think a lot of it has to do with how confident you are that a given section of your code operates exactly as you expect it to. I’m comfortable with Java and C# so I can write that code nonstop for almost an entire day before debugging it, if it’s simple enough. If it’s some weird legacy system or Angular stuff, I’ll again test for every change, because if I change two things at once and the code isn’t behaving how I expect, I now have two sections of code that I’m suspicious of instead of one obvious culprit, and that costs me time. That being said, unless each debugging session is taking 15 minutes, it’s probably not an important factor in how fast you code.
So much this. Especially Ready Roll.
Yeah, modern PC's are so fast that I can make a 3-line change, run it, test it (enter some asadsad data) and be back in the tool in a minute max. If I felt it was holding me back (like if it took 5 minutes to compile) I would have a different work flow. It's just a good thing I'm not a house painter because I would do 3 paint strokes then stand back and look at it for a few seconds :) p.s. I've been doing a lot of WPF these days. I'm NEVER confident that my code will do what I expect it to do...
Yes really. We're not talking about just any old method here, we're talking about a controller action in an MVC web application specifically. Code duplication isn't the only guiding principle when deciding where code should live. Given the responsibility of an MVC controller, how could one possibly have a well-factored action method that is 200+ LoC?
Honestly, why not have a talk to the developers and see what they think? I can't think of anyone more qualified to tell you what tools are needed than the people who need to use them. I'm a consulting software developer and I just so happen to have gotten by with not using any paid software on my current project since I'm giving VSCode a go and quite enjoying it. There are times I've used paid software, and I still have a place in my heart for Visual Studio Professional, but I think I'm admitting more and more I don't really need it. I still miss resharper and good refactoring, but atm since I'm doing full stack web dev and refactoring lost out to the easier workflow I currently have with my VSCode setup. Be careful with all the profiling tool suggestions. Profiling and performance is something near and dear to my heart and I imagine many other developers. But, as painful as it is to admit, there is a time and place for it. And more importantly it is all too easy to slip into the money pit that is spending days to squeeze a bi more performance out of a code base that didn't really need to go that fast anyway. However, if your codebase is one where every bit of performance matters then I really can't suggest highly enough that you or your developers do so research on the ins and outs of different profilers (though last time I looked red gate was one of the better ones) and buy a paid one.
You’re hired! It’s so important, people don’t understand. Good equipment can make a good programmer motivated to do great. 
Couldn't downvote this any harder. Resharper is overrated. New visual studio with a couple analyzers and free extensions can do nearly everything it can.
Have you looked into TDD? What you describe is similar to Test Driven Development practices. [Wiki: TDD](https://en.wikipedia.org/wiki/Test-driven_development) In general, it's better to make small changes to more easily revert or track problems as they come up. This allows you to build good code on top of known good code... instead of realizing your day of coding was based on a faulty framework and will need another day to fix.
Have you looked into TDD? What you describe is similar to Test Driven Development practices. [Wiki: TDD](https://en.wikipedia.org/wiki/Test-driven_development) In general, it's better to make small changes to more easily revert or track problems as they come up. This allows you to build good code on top of known good code... instead of realizing your day of coding was based on a faulty framework and will need another day to fix.
Forget resharper, use rosylnator instead. Resharper has just become blotted and slow.
You're doing full stack on VSCode only?
&gt;Resharper. It is must-have for every .NET developer. Period. Nope. Nope. Nope. Used resharper in enterprise environment for 5 years. It's slow and blotted, when I got new development machine I never isntalled it and when with rosylnator instead
They stayed that way for years because of the difficulty in changing monoliths, not because there was no downside to them.
If you're hitting the same db, they're not microservices.
What would I want? &amp;#x200B; * Linqpad is super useful. I use it literally every day but other people might not find it as useful * Visual Studio Enterprise has a few advantages over Professional edition * There are several free extensions that can make it do pretty much everything Resharper can do * You might be able to get away with something like Rider or VS Code but you may lose some useful abilities for WPF development * MSDN should include SSMS as well * Enterprise gives you Sql Server Data Tools which allows you to do just about everything the redgate tools can do * Ditch sourcetree because its garbage and use pretty much anything else. I use GitExtensions but Gitkraken is pretty good * Desk comfort (chairs, monitor stands, good keyboard/mouse, headset if they have to do calls using a phone/microphone) * A server for things like continuous integration, builds, metrics, etc * Everything else is free
I think your approach nails it. Big blocks of code = debugging PITA. Keep it small, and test / debug the smaller bits. Also teaches one to think smaller, and break up the code into smaller bits (SOLID).
I think you're perfectly good. Seriously I am not going to put out something with easily avoidable bugs for the sake of expediency, and i won't ever work in startup like environments qhere that's a religion.
&gt; There are several free extensions that can make it do pretty much everything Resharper can do care to elaborate?
Also: Two huge monitors and a nice keyboard.
I agree. That's what I was trying to say
Standing desks + good chairs as /u/TerribleReason suggested. But for that budget you probably would only get one good desk + the chairs.
DotTrace is great for identifying performance bottlenecks. OReilly Safari books has a decent selection of programming books 
Motorized standing desks
* Roslyn analyzers * VS has unit testing built in (can even do live testing now with enterprise) * Go to Implementation (and similar things) are pretty much built into VS now * Ctrl+, allows you to search for file names, method names, class names, etc. * I don't use resharper refactoring tools such as "extract method" but some of them are built into VS * Code generation has pretty much always been built into VS.. templates and whatnot. I don't use these though Are there features you can think of that I didn't cover? Maybe someone else has suggestions for free alternatives
Yes. Microservices are about scaling up teams, not the code. "micro" is meaningless without a unit of measure, so services are really just logical groups of functionality in your app and business domain, but they can be split up in many ways. Computers don't care how you deploy it, whether they are separate methods, separate classes, separate namespaces, separate assemblies, or completely separate applications connected over the network. For 95% of apps out there, using namespaces and assemblies works great. It's fast, efficient, and easy to deploy, refactor, and debug. Stick with the monolith and build a solid business first.
You can avoid a lot of debugging by keeping classes small and separated. For example, instead of having a controller directly talk to a database, rig up an interface that the controller is supposed to get its data from. That way, you only need to test whether the controller called the method, not whether the whole system works end. Of course you also have to write the database code, but not right away and you can do that separately. Basically you break the system into small, independently-verifiable pieces and you'll only need to use the debugger if a test fails and you can't explain why.
Merging microservices together implies migrating the data as well. How do you merge the data back in the same database?
Apex SQL diff. Made production migrations easy.
OzCode! Makes debugging LINQ queries a breeze.
Ir is about matching pattern.
Add a 4k monitor and the extra code on screen without scrolling will make you more productive.
I work in an enterprise and we use it very often. The courses are very relevant to what we do. 
If you're dealing with a lot of data though LinqPad is a very valuable tool. RoslynPad just doesn't have what LinqPad does. 
oz code was awesome. Too bad they switched to subscriptions and our company dumped them.
Merging microservices means I got the data model wrong the first time around, so this means creating a new microservice with the roles of the two being replaced, with a fresh data store. Once the new microservice is created and the data is copied over, can switch traffic to the new microservice and get rid of the two replaced.
Just want to second OzCode. It does a whole host of stuff, I like this one the most: https://www.youtube.com/watch?v=u_1Lgzf3Y00 
I frequently use a REPL or LINQPad for exploratory testing as I'm writing code, to work out ideas and such.
Nobody's mentioned it yet, but I'd suggest NDepend
Yeah, I decouple my code all the time. I keep at least one Class Library per project and I separate my controller from my functions. My controller never goes into the dB. That being said, I do often find myself testing things end-to-end. I don’t know how to do unit testing but I’ve heard that’s what is normally used for testing components. I just haven’t really understood how to do it effectively. 
Yup! Without giving too much away I'm currently working on a .NET Core/Angular project that we currently plan on hosting using AWS lambda. (Though we have some real gripes with AWS lambda and might just end up doing a different approach) To give you a rough idea I used the GLOC extension for chrome on our project and it reported 185,846 lines of code, which includes both back and front end. (But keep in mind that also includes auto generated configs lock package-lock, auto generated migrations data etc). That being said, the lookup for Types, files and even the global string search are really fast. (But do note that the my global string search ignores anything in node_modules) I use a number of extensions in VSCode for this workspace which are: https://imgur.com/a/GzKqfly I also use SQL Server management studio, but honestly the only real time I use it is to delete the test databases, or to check test data if something odd happens. If I were to list some of my real gripes with VSCode they would be: * Inconsistent searching by type name. (It's easier to find types in Typescript code than C# code. The C# 'Type matching' is awful, Typescripts works much more akin to how Resharper works) * Serious lack of refactoring tools, and what tools there are don't seem to follow a standard. * I.E: removing used imports in Typescript is easy, and unused types are greyed out. In C# you can also remove unused types in a file but the only way you'll know if there are unused namespace imports is if you move your carat into the namespace imports and see a refactoring option to remove unused. But nothing is ever grayed out. * Tasks in the tasks.json file should be able to take additional arguments. * I.E: `task test-service {service name}' * Omnisharp does not include types in Intellisense if you do not have the parent namespace imported, but once you type out the full type name Omnisharp does have a 'refactoring' option to import the parent namespace for you. Overall, I'd say Microsoft really need to bring Omnisharp upto par with the likes of Jetbrains and even VSPro, and when I start my next project I might give the Jetbrains tools a go like Ryder and Webstorm. Other than that, I'm pretty content to use VSCode, it's not perfect by any stretch of the imagination, but I've grown a real fondness for the IDE.
^(Hi, I'm a bot for linking direct images of albums with only 1 image) **https://i.imgur.com/7WvT8Ig.png** ^^[Source](https://github.com/AUTplayed/imguralbumbot) ^^| ^^[Why?](https://github.com/AUTplayed/imguralbumbot/blob/master/README.md) ^^| ^^[Creator](https://np.reddit.com/user/AUTplayed/) ^^| ^^[ignoreme](https://np.reddit.com/message/compose/?to=imguralbumbot&amp;subject=ignoreme&amp;message=ignoreme) 
I'll third this. Ncrunch is the best money I've ever spent on dev tools. 
JetBrains ultimate, NCrunch. Done.
I'll shamelessly promote my own business https://www.codenesium.com. If you're building apps that are API based I can save you a lot of time. Message me on here or through email and I can demo it for you. 
Absolutely this. You can really help your devs and still have plenty to blow on software that may or may not be useful. Someone mentioned the redgate stuff, the memory profiling tool had been more useful to me than the performance profiler, but I'd take a great chair and good monitors over those any day.
&gt;Couldn't downvote this any harder. Resharper is overrated. New visual studio (pro/enterprise) with a couple analyzers and free extensions can do nearly everything it can Actually tried disabling resharper but the refactoring tools are just not available in vanilla VS2017. Am I looking at the wrong place or need some extensions? Extract to method, Extract to Interface, creating delegating members (to create wrapper classes), extract variables, auto initialize private variables from construction params are the ones I use the most.
Informative comment. I have a potentially large project idea where I'd like to use these 2 technologies, React and Net Core. I'm having a hard time finding good resources for creating a NET Core API and mainly for how to make the API interact with React as you say through RESTful calls. I see a few tutorials around NET Core API and Angular and I'm wondering if that process will be similar with React? Wondering if you have any resources or breadcrumbs to help me learn more about this process?
\+1 I learned everything I could about WPF / Prism / MVVM from that website during a project and it was invaluable. 
I was asked to support an old MVC application and I didn’t know much about MVC or EntityFrmework. Pluralsight saved my behind. 
Try going to the Edit &gt; Refactor menu. There are a few things in there. It might be missing some but IMO most these behaviors are just really lazy ways of copying and pasting so they're not really deal breakers for me
Assuming you are using Git, learn about interactive rebasing, squashing and rewording. It means you can make lots of small commits, and squash them into one big commit with a nice clean commit message when you are happy with a particular piece of work, resulting in a tidier Git commit history.
Redgate tools are 10/10. You can run one db environment sync and save more than the cost of the software in man hours. Then you can do that 3648472 more times and realize that no matter what they charge its a bargain. 
Resharper License, MSDN License..
&gt; Oh, I see, it applies a decoder, and no, there isn't a raw RGBA decoder. That's a silly flaw. A raw decoder wouldn't work as a design. It leads to ambiguity between decoding a raw uncompressed array and decoded compressed encoded data and limits you to a single pixel format. - How would the library know which decoder to use? There's no file header to identify the format. - How would you allow raw decoders of different bit depth and colorspace Rgb24, Gray8, Gray16, Bgr24 etc? `LoadPixelData()` does what is needed. 
Perf in the latest nightlies is actually really good. We're faster than System.Drawing for many things now and really close with others. Only thing of any consequence that is slower is decoding jpegs but when combined with resizing (we're ~4x faster) the difference is negligible.
Can confirm this. I have the whole bundle and I feel like their products, (Datagrip, Webstorm, Resharper and Rider) all make me extremely productive, allow me to have a consistent development environment and experience across the full stack, and it somehow makes developing more fun if that makes sense. Also love all of the shortcuts. I could probably go on all day about the features I use daily.
Sounds like you're ready for automated unit tests. If you wrote them right, those 2-3 checks you do on certain things go away because you have a test that can run to verify the functionality is what you expect.
So much this A good chair, a height adjustable standing desk (the ones you can adjust between sitting and standing), a couple of decent monitors, and a reasonably fast PC with an SSD Why the hell some companies are still expecting developers to work on the same PCs as their admin staff is beyond me... Having the right tools for the job helps you work faster, plus having a nice PC and desk is a great motivation. A for software... unless there's something you've already identified a need of, or the developer has a preference for it, I don't much see the point - you're spending money because you have it, not because you need something. Give me a decent desk &amp; PC over some overpriced library any day.
Genuine question: What does Rider do to be worth the money over VS? I know it's not the most expensive software in the world, but I can't think what I'd add to VS to make it worth $250/yr or whatever Rider is.
The IDE does a good enough job citing my errors. Beyond that, I may have a null reference exception or two as I forgot to instantiate and store some objects after major writes. I think the IDE could donate better job there. :-)
Yeah I definitely know what you mean. If my free version of webstorm never ran out I never would have gotten hooked on vscode though haha. 
 No. With 2.5 years experience, you probably aren’t getting paid top dollar, so you aren’t expected to be the fastest or best coder. When you have 10 or 20 years experience, you will spend much less time debugging, because you will have already looked for and corrected the stuff that burned you in the past. If you can make a unit test that will test your code without you having to enter data via the UI, do that. Unit tests are the shit. Try to use tests when you can to make it easier for yourself, but don’t worry about what others say is good and bad practice. If your boss / users are happy with your work, then you are a good developer. If they are always upset with you, then maybe you need to find a line of work.
Yeah, delivering isn’t an issue. 
Then don’t worry! You are delivering, that’s the most important thing. 
A few I haven't seen mentioned that are paid on prem Dev tools potentially worth while: Pumascan security analyzers Ghostdoc vs extension for documentation
That's $2000 down. What about the other $8000? Standing/sitting desks for each? That's another $1200 gone. (Autonomous desks). $6800 left
Which works fine for small changes that require 0 context. It doesn't work when you need complex logic, data, and other things in.
Here's a link to a simple project I made using React and .Net Core Web API. Feel free to poke around and see how it works. https://github.com/degoeym/moviecollection I learned Web API on the job, but also took some courses on it and React via Pluralsight.
DevExpress license, especially if you do any reporting / dashboarding / manipulation of office files or PDFs. 
A sweet of controls. Personally I like the Telerik control suite, including Kendo UI.
SOA is something else. It's more about having a service layer to slim down the controllers.
Floating monitors.
I was going to Google for some useful VSCode extensions later, thanks for the list saving me some trouble! I've dabbled with it for Angular with .net core back end and I've really enjoyed my time with VSCode, it's so fast and pleasing to work with compared to how slow Visual Studio can be at times.
I know lots of people like that, but I don't. I want my commit history to match what I did, not some revised history. The commits are all nicely summarized in the pull request. So nobody else needs to see the individual little commits. That's just me though. I'm fine with the other guys doing it that way. 
HP zWorkstations with 128G of RAM each.
I have the same question.
Absolutely not. Knowing *how* to use a debugger is an incredibly valuable skill that a lot of coders don't have. Build that skill now. As you grow you'll debug less and less in general coding but your understand the debugger forever.
Thank you so much! Coincidentally after typing this I went straight to Pluralsight haha. 
What computers/laptops are they using?
This x 100. I don't use it often, but when I do it's so absolutely fucking useful.
It's a great resource, and I credit what I've learned there to have played a big role in why I'm making $25k more now compared to a year ago. Let me know if you have any questions. 
Linqpad is useful, but much less so than it used to be, with Roslyn, a lot of what you would traditionally have used it for can be done in VS. Resharper is even more overrated, almost everything it can do can be done for free and at a much lower performance cost. Developers cling to it because since it changes the default key bindings it's very painful to wean yourself off, but actual added value is close to zero. 
Even if you decide to go the paid route, be aware that ReSharper made a design choice not to use the Roslyn apis, so it can end up using a lot of processing on the side and has had problems with bottlenecking as it does its own analysis. There are a few paid alternatives to ReSharper that build on Roslyn and are therefore lighter weight.
Will do! Thanks for being helpful. Also, I help mod a nonprofit CS Career community on discord filled with jr - senior devs from all over mentoring and giving advice. Maybe you can peek in if it's something you're interested in (discord in top right). https://www.cscareerhackers.org/
If you are not subbed to MSDN for the team look into it. With that budget I would look into additional equipment too. Maybe a test/dev setup, better office desks, etc.
&gt; Resharper is even more overrated, almost everything it can do can be done for free and at a much lower performance cost. Well, performance surely takes a hit from having Resharper running along with VS, but it has a few nice things: - Search and find remote debugging symbols - nice when you're trying to debug a referenced assembly - Great unittest runner I do like Roslynator though. Linqpad I mostly use to quickly verify logic.
Luckily, the new [Nullable Reference Types](https://blogs.msdn.microsoft.com/dotnet/2017/11/15/nullable-reference-types-in-csharp/) will save you some time. :)
Azure credits, or an msdn licence which has credits 
There's nothing wrong with liking a lazy way to copy and paste. 
Instead of LinqPad, take a look at C# interactive. Resharper was great on Visual Studio 2010, nowaways I don't see the added value. Do you know Roslynator? The unittest runner is superior to Visual Studio's built-in stuff but that hardly justifies the purchase since VS has gotten better and is decent. I'd say you we right to point out that those tools are useful. Usually my opinion would be very unpopular. I'm surprised to see the turnaround in the developer community. Anyway I have seen a lot of suggestions in this thread that I value more than some of these paid tools. E.g. Pluralsight, books, better chairs, better hardware and so on. 
This. 100%. Unit testing is the way to go. The less you debug the better
/MechanicalKeyboards 
Cut your friend out of your life? &amp;#x200B; Joking aside, I'd start breaking the big methods into smaller methods in the same class, look for loops, blocks or commented code to point to logical parts. VS will do the heavy work, but you'll need to refactor if its putting in lots of refs Make all these new methods public Gather these methods into another class (MyHelperService) in the same file, as this lets you work quickly . Tidy up until everything looks neat and consistent. When its looking OK, move the Service class to another file, in a sensible location. Extract an interface on the new service class, and inject it into the controller. 
Meh, Resharper's unit test runner is OK, not great, and Visual Studio's built in one is a lot better than it used to be. 
Caching *StringBuilder* has also performance benefits.
It's not strictly the same topic, but https://www.writinghighperf.net/ is really THE reference to beat when it comes to perf and .net.
&gt; I'm extremely confident in my adequacy as a software developer. Nothing personal, but you shouldn't be. With 2.5 years of experience under your belt, you're just getting started. That's not to say you're not qualified to write code, but a bit of humbleness is never bad. Being overly confident you can do anything is often a reason things are of poor quality. Stay humble, it'll get you farther than being 'extremely confident'. &gt; One thing I'm not 100% confident about, however, is the time it takes me to code. It's not because I have a lot errors that I can't fix, but rather that I test what I write constantly. Why do you test things constantly if you think you're extremely confident? See what the problem is? You're not confident at all, and that's **totally OK** (I'm not confident most of the time my stuff works either, and I'm writing software for a living since 1994, even with a degree in CS!. Not because I think I'm bad, but because we're all human and humans are terrible in reading code and interpreting it and analyzing what's going on. There's only one way to know for sure if things work: test it). Better err on the safe side than being overly optimistic things work the way they should. &gt; I've noticed I'm doing it less and less as I get more proficient with what I'm doing since I've worked on several projects. However, I'm still wondering if I'm doing it too much because of the time it takes me to develop. Now, I do know that part of it is my equipment, because I code on a very old MacBook Pro that sometimes takes a long time to compile. So if that wasn't an issue it probably wouldn't be as bad. There's no need to test things after every line / save. At least I don't think it is. Some people have continues tests running in the background so every time they build or even save a file, tests are triggered and they get constant feedback about whether things work. I find that abit of a waste of time, but to each their own. The main thing you have to realize is that automated tests are what you want. Let the computer do the testing for you. You have two kinds of tests: small unit tests, often written up front from which the API is more or less determined and you then write the rest ('TDD' or similar) and the other types are integration tests, which are more about 'I have this feature, does this feature work?' and you write a test or several tests to test that particular feature. As I think it's often better to first think a bit, design a bit and then write code, I think the latter has more value. That doesn't mean the former is useless. Often they can help determine what a good api is, as you use the api in practice before you even have written it. The latter however are the ones you likely need in your case. So for your software, look at each feature your app is providing. Like your web app that has some UI to obtain some data, some controllers to deal with the data coming from the client, some code which inserts the data into the database. So you can e.g. write unit tests to test each element separately and write tests to combine a couple (send data to a controller's method which then should result in a record in the database). The beauty is that you have to write these tests once and only have to update them if you change your software that drastically that api's change. For the rest you can simply write code, work on your app and from time to time, say after you've finished a feature, or are halfway, run all the tests to see if things still work. If tests fail, you know you've broken something and you have to fix it. Often people think that if their tests succeed their app is relatively bug free. That's not the point of testing. You can never test all permutations of even a for loop with an if, left alone the states your app can be in. The point of testing is that you know your features *work for a given input set* and are able to handle wrong input as well. That's basically it. Forget the agile hype, the nonsense that's been written about all this, just write tests for each feature, make sure you have automated tests to see the feature *works*. Then add tests to make sure if wrong input is passed in, the feature can deal with it too. (e.g. the user fills in the wrong data, is an error reported?). No need to manually run things over and over. Not that that is bad though. E.g. if you work on an app that only works after you load e.g. a file or create a new file instance, every time you start the app and load a file, you can immediately see that the file load feature works or not. You can write a 100 tests to verify that too, but using the app yourself you already test that. Some say that this is a form of testing too which cuts down the # of tests you have to write. After all, you can't write tests for everything. 
The array of Doubles with a length of 1000 or greater being allocated on LOB was a .NET Framework implementation detail. It is no longer allocated on the heap in .NET Core. &amp;#x200B; I heard that in a talk but can't remember which one.
We've got the desks and PC's. My chair search starts today.
You win the internet today!
Have you read Pro .NET Memory Management? If not, how can you say this?
I didn't say it was wrong! Efficiency is key. These behaviors are not anywhere remotely close to MY critical path (I would say I don't even use them on a daily basis) so I save almost no time by using them. If you're using them multiple times a day then it might be worth it to memorize the shortcuts or move them to a more accessible menu item
Well, I was going by the title :)
What is your development machine? With SSD disc and 12-16GB RAM it works fine. If you have weaker configuration, you should definitely ask to upgrade because nowadays hardware is cheap and developer time is expensive.
I don't agree is overrated. Visual Studio is trying to achieve this level of productivity but still with Resharper is better. Of course you can install extensions, analyzers but if you or your company can afford to buy one complete solution which is supported very well I think it is better approach - this is my opinion.
16gb, SSD,i7 With resharper VS is slow as molasses, without resharper vs is fine. It's kind of a running joke at our place.
Visual Studio + Resharper seems like a good combo IMO. If you are springing for the bundle package then resharper includes a memory profiler, a performance profile, test coverage tools, a decompiler, and of course the IDE plugin. This is everything and more that the Red Gate bundle includes. Resharper is snazzy enough that I pay for it out of my own pocket to use at work. The downside is that it can exacerbate visual studio performance issues on large projects, but there are tweaks to lessen the pain. LinqPad and git kraken seem like fluff. There are plenty of free and open source git clients out there, and then there is always the most functional one of them, the git command line, which will cost you nothing.
\&gt; how could one possible have a well-factored action method that's more than 200+ LoC? the same way you can have one 100+ LoC. the same way you can have one 10+ LoC. you just take that '200' number someone told you was the 'right' number and replace it with literally any other number.
Thank you for the response. When I call for Raisecanexecutechange, it never re runs the CanExecute method. Should I just call the CanExecute in the even handler? 
I disagree with pretty much everything you've said. Microservice approaches are all about: * make deployments more fine grained, rapid, and low ceremony * isolating problems should any make it out into the wild. * making reusable behavior more service oriented, loosely coupled, and independently scalable Divying things up into more and more namespaces and assemblies that just end up composing the same massive synchronized deployments doesn't help with that.
It says so right on the website: "the definitive guide for .NET performance."
I read Angular in Action [https://www.manning.com/books/angular-in-action](https://www.manning.com/books/angular-in-action) and I can recommend it. If you look for something for .NET too, you can check Essential Angular for [ASP.NET](https://ASP.NET) Core MVC by Adam Freeman. He is good author.
I have a coworker who is extremely resistant to using the debugger and instead asks me (who is not even on whatever project he is on) how some code I wrote years ago that I don't even remember anymore works. PLASE debug. All the time. Debugging beats ignorance any day.
THAT IS MY ISSUE RIGHT THERE. Where do i put the renderbody()? That really is my issue because i understand the renderbody() to mean just that. What the heck do you want me to show you kinda thing. Sorry for my 3rd grade explanation.
Within your template there is going to be a natural place where you put your own body content. Think of it this way, if you weren't using MVC and you edited that template in notepad, where would you start typing / rendering your own content? Find that spot, that's where you want RenderBody() 
Make Twitter. First make Twitter "badly" (full HTTP POST/Refresh for new posts, etc fat Controllers, etc) then keep iterating on it (Ajax submit/refresh, logic moved to a service layer etc) and when you're happy with the front end refactor the back-end so it can be reused for a hypothetical app you aren't ever going to build. Still want stuff to do? Make an admin UI (e.g. custom attributes, authentication services, etc). Still bored? Do hashtag search, image hosting, or a million other things. 
Have a recommendation for a chair? I tried a Herman Miller ($1,100) in a hotel room with great lower back support. I'm 6' so it's hard to find a nice chair.
Thanks for the tips! I am the dev and the other one is a newb so he doesn't know.
Great Idea! Thank you for the suggestion.
WOOT! Got the page to render BUUUUT it isn't applying any CSS. so i need to see where my links are pointing.. brb
Someone said check the bundle to ensure I'm adding the CSS to the bundle? I dont even have anything named bundle.. 
You can do it through the bundle or by using standard HTML &lt;link .... I suggest you read up on how bundles work in MVC. 
I tried the traditional link. im reading up bundle now.
If you tried the traditional link and it didn't work, you didn't do it right. There's no reason it shouldn't work. Use your browser dev tools to see what path it's trying to load.
did that. stat is 404 not found. initiator is my index file. ill keep working at it.. thanks.
Glad you got it working. I was going to suggest checking the binding mode. If it's set to `OneTime`, it will never listen for `CanExecuteChanged` so it will never re-run `CanExecute`.
I dunno man.. it's $300/year and slows down visual studio so much that your gained productivity is probably lost in visual studio slowness. I understand it can be an improvement and if it makes you more productive, use it. I'm just the type of person that doesn't like to have any crutches if possible so I like to use free stuff so I can be comfortable with it for home use and stuff. Saying it's a must-have is just outright wrong though.
Such an exception for an array of doubles is true for 32-bit runtime, as I've explained in the book, because of memory alignment.
Wasnt' as ugly to write this as I thought. static private InstrumentMethod RecoverDocument(string path, InstrumentPluginManager ipm) { InstrumentMethod ret = null; try { using (FileStream fs = new FileStream(path, FileMode.Open)) { XmlDocument doc = new XmlDocument(); doc.Load(fs); // Get list of plug-in types known to the system. List&lt;Type&gt; tlist = ipm.InstrumentParamTypeList; // Select all of the nodes that are tagged with the xsi:type attribute. XmlNamespaceManager nsmgr = new XmlNamespaceManager(doc.NameTable); nsmgr.AddNamespace("xsi", "http://www.w3.org/2001/XMLSchema-instance"); XmlNodeList xnList = doc.SelectNodes("//*[@xsi:type]", nsmgr); foreach (XmlNode xn in xnList) { XmlAttribute typeatt = xn.Attributes["xsi:type"]; // Can't find a type for it in the plugin system, remove it // from the XML document if (tlist?.Find(a =&gt; a.Name == typeatt.Value) == null) { xn.ParentNode.RemoveChild(xn); } } // Now try to open the XML document that has the unknown types removed from it XmlSerializer xmlser = new XmlSerializer(typeof(InstrumentMethod), tlist?.ToArray()); XmlTextReader reader = new XmlTextReader(new StringReader(doc.OuterXml)); ret = (InstrumentMethod)xmlser.Deserialize(reader); } } catch (Exception) { return null; } return ret; }
Well that didn't work as I wanted it to. Build failed with 24 errors after adding the jar to the Jars folder. For instance: Error CS0738 'PersonImpl' does not implement interface member 'IPerson.MainSecurityToken'. 'PersonImpl.MainSecurityToken' cannot implement 'IPerson.MainSecurityToken' because it does not have the matching return type of 'ISecurityToken'. Library\\obj\\Debug\\generated\\src\\Com.Axema.Vaka.Client.Backend.Data.PersonImpl.cs 10 Active &amp;#x200B;
I'm in the market for one now. Does anyone have a recommendation other than Herman Miller? 
For me it comes down to already using more Jetbrains tools (Resharper, DataGrip, YouTrack, Teamcity, UpSource) than the MS equivalents, so it's worth it for the better integration. I also find the interface snappier and more intuitive, and there are great plugins available. 
If you can see the 404 then you should be able to see the path it's trying to reach and you can adjust.
Wouldn’t you just end up with a SPA and not really using views at all?
Yea I fixed it using the bundles. That just worked really easy 
Herman Miller aeron (new version) or embody. If your going to get the best chairs, get an embody.
All this, and I’d add nice keyboards and mice too. For the keyboard what I’d do for my devs if I was allowed is I’d let each one design a custom keyboard from WASD keyboards, then they get it exactly how they like. And for mice, anything they want really. I use a Razer mouse but it’s not particularly game-y, like it doesn’t have loads of extra buttons or anything. It just feels nice to use and it’s really reliable. All this stuff is cheaper than a lot of software licences but really contributes to having work be enjoyable. I would think twice about quitting a job that focused this much on getting me stuff I liked using and it’s *so cheap*!
[Beyond Compare](http://www.scootersoftware.com/) is an amazing diff tool and a must for me.
I absolutely don't think so. Catching issues as they happen saves time in the long run. It's like tasting what you're cooking while cooking it, at stages. You taste it at the end and you're going to have a bitch of a time fixing it now.
That's the point. Start with something simple and easy to do, then convert it / redo it with other approaches.
Can you send me the jar? You may have to write some overrides in those two cs files in the project.
When Anders Hejlsberg left the C# language design position, most of these new *improvements* looks like a more bloat and gimmicks to me. If there is something missing it is type aliases, typedef PrimaryKey : int; void MyMethod (PrimaryKey id); Later when I need to change the type of primary key to lets say *long*, I'll change the single definition only.
I recently made a reddit bot without using a existing wrapper. It was pretty fun, it had everything you described
Aeron, no question. Best chair ever made.
What did this bot do?
Grammar, but not english. So it had to determine if it's the correct language first, if the language is detected, check for spelling mistakes. Challenges were: authorizing/authentication, remain within reddit api limits, detecting the language, etc I still have it running on my raspberry pi, and i have it on github.
I can imagine this simply leading to confusion about what the underlying datatype actually is. Currently working at a company where every datatype in their database has been aliased to Danish. It's just a giant pain.
F# has that covered with type aliases, though it's limited to local code (no guarantees to outside callers). F# also has "1 .. 10" syntax for list comprehensions... The string slicing will be nice when it gets ported though :)
A set of 1440p or 4k monitors. Good chairs. Can't think of any money on software though. Install Ubuntu and VS Code and you're off to the races.
using alias directive https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-directive using PrimaryKey = System.Int32; void MyMethod (PrimaryKey id);
Specflow allows for GWT features
It is local per file only.
Define a type with implicit conversions? You'll get much better usage info and tooling help when refactoring to a different underlying type (i.e. changing `int` to `long`) public readonly struct PrimaryKey { private readonly int _value; private PrimaryKey(int value) { _value = value; } public static implicit operator int(PrimaryKey value) { return value._value; } public static implicit operator PrimaryKey(int value) { return new PrimaryKey(value); } }
No :-)
F# has so many wonderful features I wish were in C#
Problem with that solution is if you want to have an alias for a username, any other string field or just types which have similar properties. ie: ``` UserName -&gt; string FirstName -&gt; string etc. ``` You can inherit from `string`, so the only solution would be to create a decorator around `string`, which is a lot of bloat and additional code. With a simple global/assembly/classwide typedef this could be easily solved.
Nah dude. That's normal. You got all kinds of people on here talking TDD like that's going to be some kinda revelation to someone who's been in this for more than a minute. Sure, go for it, write tests and run them. But you shouldn't feel weird about running the program and stepping thru the execution if that helps you. Also, fuck what that other dude said, be as confident as you want. Humility is great - but keep it to yourself. Confidence is what is going to get you paid. Just don't be a dick to the newbs and don't claim to know shit that you don't know
I think we have *most* of what is needed to have parity with Java and Python. What we don't have: - Free ESB Options on par with the Java World (WSO2 comes to mind, MassTransit is good for what it is, but WSO2 has a way bigger ecosystem.) - Well Supported Multiplatform UI. *To be clear here, I prefer .NET UI to anything I ever had to do in Java*. But there's something to be said for Java's multiplatform GUI capabilities that we still have yet to really see in .NET. Avalonia will (hopefully) help bridge this gap, but I think it needs more community buy in and support, because... - This point isn't about lack of libraries but about developers being afraid to even look for libraries. When .NET Core was first announced, the developer community started to take interest in the various 3rd party solutions to problems out there. It feels like now that ASP Net Core 2.0 has come out, we have once again reached a Lowest Common Denominator for our tech stack. Examples: - Everyone's back to using EF Core, having forgotten all of the broken promises of EF Classic. - Microsoft's DI Implementation is a bit off, but plenty of people just use the default for that now that it exists. - Microsoft's going to give us a UTF8 Json Parser? Cool, except there's already one out there, it's great, and 90% of the community will never realize it existed. - I'm Tired of Blazor posts. Now that I've started playing with Websharper, they just make me cringe. I can build reactive UIs in C#, *running client side,* **today**. But, again, the community instead eats up all the first party stuff and cares little about the rest.
AH Well then. hahaha. In that case just try a bunch of trials on paid software until you find what you like!
1984 words. Hmmmmm...
Yeah someone else noticed that! (I wish I could say I'd done it deliberately as a joke, but it's a complete coincidence, honest!)
&gt; honest! Room 101 will be the judge of that!
So the best way to learn MVC is to build a simple MVC app and then transition it to an SPA as it gains complexity? I only have SPA experience but I'm assuming that you could build a full featured twitter with only MVC and not have to make that transition if the goal was to learn MVC. 
Funny that on a thread that began with complaining that c# adding these features was bloat, we're now praising another language for having these and many others. 
It'd be need if the `[range]` syntax could support extensions. I'd define one for `DateTime`, so I could have `foreach (var day in [range].By(TimeSpan.FromDays(1)))`
&gt; So the best way to learn MVC is to build a simple MVC app and then transition it to an SPA as it gains complexity? It is one way. It allows you to practice several different skills and types of applications. Nobody can know what is *best* except perhaps the learner knowing their goals. &gt; I only have SPA experience but I'm assuming that you could build a full featured twitter with only MVC and not have to make that transition if the goal was to learn MVC. Absolutely. But SPA can be generated using MVC too. For example generating different dynamic parts of the page using MVC Actions and Views via Ajax. Want to regenerate this list of Tweets? Call an MVC action, have the view render the list, and return raw HTML to be displayed within some placeholder. 
So basically like slices in JS. But why MSFT not be inclusive on the end point? &gt;The start of a range is inclusive, but the end of a range is exclusive. It seems explicit when you specify myArray[1..3] Yet that range is only 1,2. Not 3. I get that you want it to be like a for loop so foreach (var item in myArray[1..3]) Is like for(int i=1; i &lt;= 3; i++) Also that this inspired by Python Bounds. But I would think there would be some syntactic sugar to make it inclusive at least.
Out of habit I just think of it as two parameters: \`startingVal\` and \`count\`. The logic is that you generate a sequence by choosing a starting digit and then seeking forward some desired amount of digits. 
I'm not opposed to this feature, though, I don't think I would use it. Where would you typically declare these typedefs?
What you're asking for sounds like Postsharp. You can declare global Aspects which can hook wherever you want. If you want to wrap something then you can wrap it there and it'll go through the post-compiler.
But If you expect that second param to be a count then myArray[2..3] wouldn't fit tht assumption. 
Check out [Postsharp](https://www.postsharp.net/). It can help automate a bunch of menial tasks for them like diagnostic logging or caching.
They are inclusive on the end point if, and only if, you leave it off. i.e. `[1..]` is right inclusive, and `[..5]` is left inclusive.
But you can't have a non-end point inclusive number, which is what /u/eigenman was proposing.
You're so stuck on parroting the no magic number line that you've completely disengaged your brain. Again, this isn't some random method, it's a controller action in an MVC web application. Can you give a single concrete example of what you believe to be a well-factored MVC controller action method that is 200+ LoC? If you can't do that, maybe you could take a shot at describing what you think the responsibility of an MVC controller action method is. I think you would learn a lot from that exercise.
Do you think that xamarin forms start to be enough mature to use it in complex enterprise application?
Afaik the Range Syntax is more or less like the Indexer Syntax in this regard, meaning that you should be able to create a `this[Range] { get { ... } }`
The same place as public types, in an shared assembly.
Made this last night to do this. It is untested at the moment but should do the job: https://pastebin.com/NxxjhMvh The thing you are after is that it inherits from IEnumerable so that you can enumerate the date range by the specified resolution Timespan. The code that counts: public class DateTimeOffsetRange : IPair&lt;DateTimeOffset, DateTimeOffset&gt;, IEnumerable&lt;DateTimeOffset&gt; { private DateTimeOffset _fromDateTimeOffset; private DateTimeOffset _toDateTimeOffset; private readonly TimeSpan _resolution; public DateTimeOffsetRange(DateTimeOffset fromDateTimeOffset, DateTimeOffset toDateTimeOffset, TimeSpan resolution) : this(resolution) { this.FromDateTimeOffset = fromDateTimeOffset; this.ToDateTimeOffset = toDateTimeOffset; } public IEnumerator&lt;DateTimeOffset&gt; GetEnumerator() { var current = this._fromDateTimeOffset; while (current &lt;= this._toDateTimeOffset) { yield return current; current += this._resolution; } } }
&amp;#x200B; Correct as of [.NET 4.5](https://blogs.msdn.microsoft.com/dotnet/2011/10/03/large-object-heap-improvements-in-net-4-5/) \&gt;In 32-bit architrctures CLR’s execution engine attempts to place these arrays &gt; 1000 doubles on the LOH because of the performance benefit of accessing aligned doubles. However there are no benefits of applying the same heuristics on 64-bit architectures because doubles are already aligned on an 8-byte boundary. As such we have disabled this heuristics for 64-bit architectures in .,NET 4.5
Yep. I was well aware this was possible. I just wanted syntactic sugar for it. For what it’s worth, I think specifying the step size should be done inside the foreach statement, otherwise whoever maintains it has to hunt down where you do this.
Very true. I wish I could add that. My closest prototype was to either make the resolution adjustable, or to add a WithResolution or By method that recast the range to the desired resolution so that you could still override it in a loop.
See: https://www.reddit.com/r/csharp/comments/9wvkjg/c_8_concerns_a_followup/e9o8j3z/ for a discussion about this. 
Creator of OzCode here. Just wanted to point out a little known fact that both tools you mentioned come from the same company - RoslynPad was created by my colleague Eli Arbel who also works at CodeValue. 
Aka “my VP of IT read some article and has now has flown off the rails, and we’re all just waiting for the inevitable catastrophe”
Awesome tutorial, thanks for sharing this. Coming from someone who primarily uses Windows and TFS for git/release management on prem it's nice to see this being done entirely with free software. 
We're currently using a similar approach minus GitHub. Bitbucket enterprise repos -&gt; Jenkins builds the container image -&gt; deployed to internal docker repo -&gt; deployed to kubernetes cluster. Working on introducing automatic and manual quality gates to progress through environments.
I wonder if you can have a`this[Range, TimeSpan]` indexer then. That'd be sufficient, but still a little fugly.
to be honest, there isn't enough time in the world for me to care about this. you're gonna hold onto your belief no matter what i said because someone you respect told you this is true and you don't know why either or you'd be able to state it. good luck learning more from better teachers than me. because you still have a lot to learn.
Herman Miller seems to be it. Aeron or Embody. [https://www.reddit.com/r/dotnet/comments/a5l80y/i\_have\_10k\_to\_spend\_on\_tools\_for\_2\_developers/ebpo6mm/](https://www.reddit.com/r/dotnet/comments/a5l80y/i_have_10k_to_spend_on_tools_for_2_developers/ebpo6mm/)
Oh didnt know about that, thanks! Are there any open source alternatives to it? 
There are some but the links are on my machine at home. I'll post them here later. Postsharp is the most mature framework for this but you can still do this in the alternatives with a bit more skill. 
How about abusing the enum construct in C# to make an explicit cast to from the type. Enum supported types only, but this works well: ``` public enum PrimaryKey: int { } PrimaryKey k = (PrimaryKey)1000; int l = (int)k; ``` Edit: Code formatting.
Still ugly hack. There are tons of rather useless gimmicks but this one is still missing. It can be implemented as a single level inheritance of sealed class on MSIL level.
yup exactly. 
Get some ultrawides and never look back.
While I wish they became more popular, it’s likely that in almost any scenario where they could be employed - cross platform - it’ll be solved in the enterprise as a web application, particularly when it’s a complex app. A statistically insignificant number (likely zero) of “*complex* enterprise projects” will be built on an uncommon technology that is known by few people. It’s a shame, but I understand where they’re coming from.
Steelcase Leap is a strong contender too and was being recommended over the Aeron at one point.
Yes, Roslyn uses StringBuilder in an object pool.
Then you have 15 services injected in the controller.
&gt; Instead of LinqPad, take a look at C# interactive. You mean the interactive window in VS? I have a hard time seeing how the two are comparable.
I'm stating that a well-factored MVC controller action of 200+ LoC doesn't exist. Its responsibilities place an implicit limit on the amount of code that could be found in one. You say one does exist. Show it to me, please. If you can't, at least discuss the circumstances you think might lead to one existing. To you, well-factored simply means DRY. Keep in mind we're not using your personal definition of well-factored. This isn't well-factored in the context of the method, this is well-factored in the context of the entire system. Does that even make sense to you? If so, repeat it back to me in your own words. I have provided lots of detail and support for my argument. All you have done is repeat what you read somewhere.
I love Oz-Code so much, but most of the devs at my company have switched to Rider...hint hint
What I do in Razor Pages is this: PageModel: public ActionResult OnGet(){ ViewData["Directories"] = new SelectList(System.IO.Directory.GetDirectories("")); } Then on the .cshtml file &lt;select asp-items="ViewBag.Directories"&gt; &lt;option value="0"&gt;---Select One---&lt;/option&gt; &lt;/select&gt;
i built a viewbag off of a query to form the select list, like this: controller i did this: ViewBag.SpecsDDL = mediaRepository.GetAll().Where(x =&gt; x.MediaType == 6).Select(r =&gt; new SelectListItem { Text = r.MediaLabel, Value = r.Id.ToString(), Selected = [r.Id](https://r.Id) == productDetailsVM.SpecMediaId }).OrderBy(x =&gt; x.Text).ToList(); &amp;#x200B; View: &lt;select name="SpecMediaId" class="form-control" id="SpecMediaId" asp-items="ViewBag.SpecsDDL" required&gt;&lt;option value="0"&gt;Select One...&lt;/option&gt;&lt;/select&gt; &amp;#x200B;
YOU ARE MY HERO. Thank you so much, this worked perfectly! I've been banging my head on this for hours. I'm not a web guy by trade, so this is all very new to me, and I was just starting to get asp.net classic down and then it was like "annnnnnd its dead". 
Haha no problem, glad I could help. I tacked on some edits that I thought might help. Razor Pages is great. In a lot of ways, I find it much simpler than classic ASP.NET once you get a workflow down. Good luck and happy coding!
Store your items in a list that you expose to your view by making it a public property. In your view you can use an asp-items tag helper on a select element to iterate the list.
One more question for you now that I got that working. In old ASP that dropdown was linked to this onselectedindexchanged method: protected void sourceDropDown_SelectedIndexChanged(object sender, EventArgs e) { string SourcePath = sourceDropDown.SelectedItem.Text; } it looks like the onchange function should do the same, but after assigning an id of sourceDropDown to the new drop down list, it doesn't appear in context in the cs. Is there something different I should do to be getting the contents of the dropdown into a variable?
I think I understand what you're asking, so here's how I'd get the value back to the server. Let me know if you're talking about something else, because there's several ways to get the value. PageModel: [BindProperty] public string SourcePath { get; set; } public ActionResult OnPost(){ // Do what you need with SourcePath } .cshtml &lt;form method="POST"&gt; &lt;select asp-for="SourcePath" asp-items="ViewBag.Directories"&gt; &lt;option value="0"&gt;---Select One---&lt;/option&gt; &lt;/select&gt; &lt;input type="submit" value="Submit"&gt; &lt;/form&gt; 
I think we're on the same page. The gist of what I'm doing may help. I'm building an intranet site for our team to be able to select a folder from a drop down list, then it processes the contents of that folder and copies it all to a library location. It will parse contents, copy things to new directories, and put it all where it needs to go (including unzip/unrar which I'll figure out later). I originally had it in powershell, then it became a WPF app, then an asp web page, now an asp.net core page :P SO at this point, we select the folder from the dropdown, hit the "transfer" button on the page, and then it will populate that sourcepath variable and do its file copying magic.
Maybe this will get you started http://www.tutorialsteacher.com/mvc/htmlhelper-dropdownlist-dropdownlistfor
You're correct. I'd recommend a button because it's more obvious to the user that it does something. There are cases where you would need to load some extra stuff when the user selects an item from a dropdown list.
Yeah, I don't want it to actually do anything until they hit the "transfer" button that's on the page. It populated that variable on the SelectedIndexChanged action before, but it doesn't actually have to do anything till they hit transfer. There will also be a checkbox that will enable a textbox for number entry and it uses that entry to build some optional folder paths.
One more tip for you. HTML 5 specifications for required &lt;select&gt; If you give your &lt;select&gt; element the required attribute, set the first &lt;option&gt; value = "" and you can get some sweet client-side validation. Server-side validation is still necessary though. Also, in the case of the textbox, I wouldn't use a checkbox to toggle it on/off, I'd keep it blank and check for an empty string on the server with string.IsNullOrWhiteSpace(). Obviously feel free to ignore anything that doesn't apply to the requirements of the app lol
Thanks! I appreciate all the tips, everything is still WPF in my head lol
As someone with little experience in this domain I found it a fascinating read. There's a big push on Python at work currently because of its machine learning libraries, but F# integrates better for me. I'll probably end up doing a mix of both :) BTW, this is tangential but also fun [writing a neural network from scratch in c#](https://www.youtube.com/watch?v=z8DY5DndmxI) 
Definitely. People tend to be cautious when adopting F# but once they see the full scale of its capabilities which are on par if not better than the popular languages it make it difficult to say no to. That presentation is one of my favorites. Very good explanation and demo. 
Honestly, it was hard work for me. I got the Skeet book and he lulled me into a state where I could deal with it :) 
Look at the top 3 bullets here: https://www.linqpad.net. C# Interactive can do that for you. Yes that window. The context menu in the solution explorer will take you there and auto-load your modules.
How about the case for doing MI with Rust? I do get the idea of going for a static typed language, but other than that, F# doesn't really provide anything that Python can't, especially with the exponentially growing community that Python has.
You should be able to have as many forms as you’d like. I don’t see the HTML.BeginForm (but it’s very early so apologies for missing) - it should be wrapping the content you want to send. [This StackOverflow](https://stackoverflow.com/questions/15788806/asp-net-mvc-4-multiple-post-via-different-forms) is not Core but it should still work. I usually send my content back through AJAX but wanted to unblock you if I could. One small recommendation from my side is reducing any logic you have in your View. It’s very small but you could do a .GroupBy(tea =&gt; tea.Category) and attach that to your viewmodel. Then you’ll foreach through the outer bit and foreach through teas of that category. Of course, if a tea category is not in stock, less luck, but just a thought. Good luck!
The form is towards the end of the code. I'm current thinking my issue is how i set up my lambda expressions in the form. Thank you for the suggestion. I was planning on movie the logic out of the view, but I hadn't really considered how I would do it yet. Thank you for the suggestion.
Interesting.. Why would it be included in the book then? :/ Hmm...
Just remember to separate concerns and try to adhere to single responsibility. Mediatr would be a good in process solution using pub/sub, but if your service is to be production grade I’d go with a durable message bus like rabbit mq.
It was my lambda expression. Thanks for your feedback though!
The great thing about ASP.Net WebForms is how simple it is, and how quick it is to learn. Read the [wikipedia page and your 50% there](https://en.wikipedia.org/wiki/ASP.NET_Web_Forms) there. &gt; How can I tell which framework version I'll assume you know that VisualStudio is the tool used to compile projects (.proj) files and solutions (.sln = collection of projects). AThe version of .Net is referenced inside the .proj file (text file) and is visible inside VisualStudio by opening the project and right-clicking to see its properties. &gt; What is the ASP.NET build process? VisualStudio builds all the projects within a solution. Projects can be referenced by other projects. &gt; From what I can tell the pages are only compiled when requested on the server. Read up on IIS web server and ASP.Net "code behind". Code is compiled, then deployed to the IIS webserver along with static web pages. &gt; How can I write tests for ASP.NET? If the web pages have been separated from the business logic, just add unit tests to the business logic code. If the business is embedded in the web pages, separate it first then add tests.
Update to above comment: the biggest pain for beginners is ensuring the identity that runs the IIS process has permissions to access the directories+files needed (I've seen days wasted on this). 
Unfortunately a lot of the sites don't have csproj or solution files...
- Start version control NOW. Git is a good tool to start with. - Make a copy of the site that is not publicly available. Test your changes on that site first. Copy them to the live site when you are confident that everything works. NEVER FTP into the LifeSite to make a change ever again! There are many more things to say, but you should start with these two points. 
Yes, it's normal you have to step through your code as you write it. Unit tests can remove some of it, but will never eliminate the need to step through your code completely. However, your top priority should be about optimising the time each write-debug-fix iteration takes, because that's going to directly impact your productivity. Make it as fast as possible. If you can save 10% of that time by buying a new machine, then do it. Optimise the configuration of your IDE/debugger to save seconds where you can. Configure your development settings so that it's quick to start. Setup your dev build so that it skip everything that's not needed. In my current project, I'm aiming to be able to build, start, and test/debug what I'm working on in less than 60 seconds.
Personally, I don't like articles like this one. Lots of useless screenshots, full code snippet for controller to replace in code. Better source of knowledge is official documentation for angular [https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/angular?view=aspnetcore-2.2&amp;tabs=visual-studio](https://docs.microsoft.com/en-us/aspnet/core/client-side/spa/angular?view=aspnetcore-2.2&amp;tabs=visual-studio)
Not familiar w/ SQLite but regularly deal with CSV inputs much much larger than what you are doing. Your bottleneck is almost definitely in your database insert calls- and you'll want to find some other mechanism than doing one database call per insert. Oracle supports ArrayBind inserts for bulk operation, PostgreSQL/Redshift has COPY command support. Check to see if SQLite has something similar (Or move to a DB that does)
Googling around shows this with some explicit recommendations on reducing the insert overhead on SQLite: https://medium.com/@JasonWyatt/squeezing-performance-from-sqlite-insertions-971aff98eef2
Legend! I’ll look into into it, thank you. 
Code is literally the SPA created by the asp.net core wizard, no explanation of what the code does for how it does it, just some screenshots and snippets of code they didn't write. You would be better just running the wizard and digging about yourself.
You can look at creating Selenium tests for the site, it's not ideal, but better than nothing.
Agreed, reading a number of rows into memory and performing a bulk insert every X rows would likely be much faster. Performing those inserts one at a time will kill performance. This article may help https://www.jokecamp.com/blog/make-your-sqlite-bulk-inserts-very-fast-in-c/
Make sure that you’re not doing an individual insert for each row. There is a ton of overhead in establishing the connection, issuing the command to sql, and getting the results back. For data sets that large you need to be at least batching up the insert statements or ideally look into bulk inserts or whatever the SQLite equivalent is. 
\+1 I work with large csv files and get much better performance. For csv parsing, I use a custom parser for mild speedup. Your issue will be Sqlite. Various optmizations possible. Example: \* [https://stackoverflow.com/questions/1711631/improve-insert-per-second-performance-of-sqlite](https://stackoverflow.com/questions/1711631/improve-insert-per-second-performance-of-sqlite) A simple and effective improvement is to wrap all/many inserts into a single transaction. Depending on what you're going to do with the data, you may not need Sqlite. I use AWS EC2 instances and load &gt;15GB flat data files from EBS into memory at app start and then crunch (ML) without database. Much easier and works well with C# linq.
Are you reading a stream or reading line by line? Are you bulk inserting the data using transactions? I've written an application that converts CSV to SQL &amp; I dont remember it taking several days to store the data into the database.. Also if you need extra performance &amp; don't need to store the data for long use the in memory database instead of the file system. 
Line by line... I recycled some small sql table stuff I’ve done before but as I was doing it I could tell it smelled bad. I would be looking to store the data permanently, so need to look at bulk inserts as a now obvious solution. Systematically connecting millions of times then writing a single line is a terrible approach! Had to try it to see it though 20 20 hindsight ha I’m an idiot. Have only had experience with databases with &lt;50 entries before. 
Thanks everyone, my limited experience of databases &lt;50 entries large was not a good basis to parsing large amounts of data. I was connecting on each separate entry so many millions of times. Ha I hope future employers don’t see this! Upvotes all round
Exactly what I needed thank you 
Perfect! Thank you. 
I also deal with large CSV files and have done what you are trying to do. The fastest way to import a CSV file into an SQLite database is to use the [SQLite tools](https://www.sqlite.org/download.html), specifically the `sqlite3` executable. You can invoke the executable via code and redirect stdin like so: class Program { static void Main(string[] args) { var codeBase = new Uri(Path.GetDirectoryName(Assembly.GetExecutingAssembly().CodeBase)).LocalPath; var dbFile = Path.Combine(codeBase, "db.sqlite"); var csvFile = Path.Combine(codeBase, "input.csv"); var commands = new List&lt;string&gt;() { ".mode csv", ".separator ','", $".open {dbFile}", $".import {csvFile} input", "GO", ".exit", }; InvokeSqliteCli(commands); Console.WriteLine($"Done. Data is in {dbFile}."); } private static void InvokeSqliteCli(List&lt;string&gt; commands) { string exe; string args = string.Empty; if (RuntimeInformation.IsOSPlatform(OSPlatform.Windows)) { var codeBase = new Uri(Path.GetDirectoryName(Assembly.GetExecutingAssembly().CodeBase)).LocalPath; exe = Path.Combine(codeBase, "sqlite3.exe"); // stick it in your app dir } else // OSPlatform.OSX or OSPlatform.Linux { exe = "/bin/bash"; args = $"-c \"sqlite3\""; // install it and make sure its in your path } var process = new Process() { StartInfo = new ProcessStartInfo() { FileName = exe, Arguments = args, RedirectStandardInput = true, } }; process.Start(); foreach (var command in commands) { Console.WriteLine(command); process.StandardInput.WriteLine(command.Replace('\\', '/')); } process.WaitForExit(); } } Note that it _should_ work on platforms other than Windows as long as the sqlite3 binary is on your path but I haven't tested extensively. Any way you look at it this operation is going to take quite a while but using the executable should be considerably less than 6 days. You may also want to experiment with parallelization by splitting your input file and doing inserts concurrently, but I suspect sqlite will want exclusive access to the output file. You could potentially insert into multiple files and then merge them or something. What exactly do you need to do with this data? Depending on your use case something like AWS Athena or even S3 Select may be beneficial. Athena allows you to query a csv file in S3 with full ANSI SQL support, and S3 Select does pretty much the same but with limited SQL support. Athena uses [Presto](https://prestodb.io/) under the hood so you could roll your own infrastructure if you wanted.
Sqlite is a single local file database so there is no connection to manage, per se. I don't know if a bulk insert exists for it. 
You might want to consider a small Dataflow pipeline that pulls data, transforms it, and adds to your database. You'll need to set bounded capacity for each segment in your pipeline, but if your inserts are async it might result in improved throughput.
For number 1 you might want to try using an authorization attribute filter. Applying the authorization attribute to a controller action could make it simple to redirect them to the login page. Google MVC auth filter for more. For 2, it sounds like you might want to use a viewmodel kind of approach. Create a class that contains whatever model you are currently using to populate the data for the page and add the additional properties you want, get the data in the controller action plop it in your viewmodel and return View("myNewPage", myNewViewModel);
[removed]
Since you mentioned AWS, I've it for this. I uploaded the .csv files to S3 and then loaded them to Redshift. I don't remember the numbers but I had a larger data set than yours and it was manageable.
You live and learn, it's better to ask for advice. At least you acknowledged that it can be improved and arrived to do so. Too many people would have just kept it as it is and said "that's all we can do right now".
For reading csv file you can use free library called filehelpers its awesome www.filehelpers.net I sugest you read row by row in memory and then do bulk insert in database. For example read 1000 rows then do bulk insert. If you want to do this with sqlite use transactions, or use bulky https://github.com/danielcrenna/vault/blob/master/bulky/README.md
You could use command line to bulk load the entire csv into a table first, and then do whatever else you need to do in SQL after that. https://tableplus.io/blog/2018/07/sqlite-how-to-import-csv-file-into-sqlite-table.html
It seems that Blazor will be embedded in MVC Core. [https://github.com/aspnet/AspNetCore/commit/07e2d5420cdd190a8ad1d1ac2afd39a2d6768a9a#diff-4146462ba6fc6934c1ff9340fdfa4b4a](https://github.com/aspnet/AspNetCore/commit/07e2d5420cdd190a8ad1d1ac2afd39a2d6768a9a#diff-4146462ba6fc6934c1ff9340fdfa4b4a)
Get yourself a copy of SQL server (I believe there is a free version now) and use the Bulk Copy tool (BCP). It's designed to import files like this.
Similar to the idea of batches, doing multiple inserts in an transaction increases the insert speed on Sqlite.
Use Power Query in Excel. Excel can easily handle millions of rows if you use the DATA tab and query editor. In the 2016 version this functionality is integrated in the DATA tab, in earlier versions you'd have to install the Power Query addin. This is the same technology the standalone Power BI application is based on.
Just to reiterate, a bulk insert is the way to go. Speaking from experience as well
It is not difficult to say no. About 99.9% programmers said no.
You can definitely parse it faster than that. Don't read one line and write to the database read a thousand lines and make that one call to the database. Monitor your queue size and the time it takes to write to the database, and adjust accordingly, or even get fancy and have it auto adjust. I actually made a sqlite to CSV converter for a 300gb database file that I generated from a website scrape. I think I was able to dump 300gb of CSV data in a few hours with it.
Have a look at elasticsearch. You could bulk insert this into a dev elastic build in a few hours. I've done some huge files with hundreds of millions of lines. Using c# I use the csvhelper plugin and the elasticsearch Nest plugin. You can view the data in kibana. All these are free to use and simple to work with. You can get a dev instance of elasticsearch and kibana running on your laptop in seconds. You could even use logstash to read the csv file for the full ELK (elasticsearch Kibana logstash) experience. Happy to help if you like the look of this. 
Don't you just need to generate the tlb files and register those?
I'll give that a shot! I hope it's something simple like that, google hasn't been giving me answers, no matter how many times i stick his head in a bowl of water and ask where's the money!
Could it be a 64 bit Vs 32 bit issue ? Iirc you have to use the correct regasm depending of architecture
Tried, didn't work!
Running on a 64 bit system, dll is 64 bit. 
I hope a solution can be found, so anyone experiencing the same problem can refer to this thread XD
Use regasm that is located at "C:\windows\microsoft.net\Framework64\v2.0.50727\", not the default from "C:\Windows\Microsoft.NET\Framework\v2.0.50727"
Check GitHub. There are a few boilerplate templates that might have what you need. Here are a couple of the highly rated ones: https://github.com/kriasoft/aspnet-starter-kit https://aspnetboilerplate.com/ 
been using the one located in C:\\Windows\\[Microsoft.NET](https://Microsoft.NET)\\Framework64\\v4.0.30319
That usually means a linked library is the wrong bitness or wrong framework. It’s a stupid error message. 
extremely vague too!
Turn on Fusion Log, that should log what assembly that fails to load. It could be something as simple as a permission issue, not present when the DLL is loaded trough the host app.
I suspect that i'm doing this wrong! I've run Fusion Log, then run regasm on the .dll, nothing.
I got so fed up with this myself I wrote this ... https://github.com/matthewblott/simple_aspnet_auth Tutorial here ... https://coderscoffeehouse.com/tech/2017/09/05/simple-aspnet-auth.html
Does the machine you're trying to install on have the version of the .Net Framework you're building against (e.g. 4.7.2)? You may want to spin up Ildasm.exe from the Developer Command Prompt, open the assembly, and look in the MANIFEST. It should look like this: // Metadata version: v4.0.30319 You can also go View -&gt; Headers then scroll down to "----- CLR Header:" it should look like this: Major runtime version: 0x0002 Minor runtime version: 0x0005
it very much does have the version of .net i'm using. I'm going to create another project and see what i can do to isolate the issue.
One more idea... If you copied the assembly to another machine, right click, properties and see if at the bottom "This file came from anotehr computer and might be blocked to help protect this computer" exists and "unblock" if it does. 
To be clear i'm encountering this issue on my own machine too!
Wow. That's a super freaky issue. Sorry I haven't helped, hope you get it figured out... 
I've created another project that has the same dependencies as my current one, and bizarrely it works fine. I'm starting to think i should just copy my classes out to a new visual studio project, see if that magically solves the issue.
Try Beyond Compare and view the differences in the .csproj files. 
If you only ever want it on Azure perhaps WebJobs
Seems like a good alternative. Pricing is a bit higher, but it seems to fit this case better. Thanks.
Okay, you definitely can't do `[start..end)` because the range is only `start..end`, the bracket syntax isn't part of the range. It's the indexing operator.
[removed]
I've always struggled to get anywhere because I try not to do anything "badly" at the beginning and it becomes overly complex for me. So this is a great suggestion! Cheers 
I really wish more effort went into 1) articles 2) this sub and /r/csharp to help improve the quality of submitted articles
Make a docker container with all tools installed and start it on demand?
I don't like the dotnet cmd to make an angular app as they r always out of date. Use npm and build the angular app that way. Or you can upgrade the node modules however the template locks you into ways of running angular. Perhaps you want to use ssr with preboot. If so then the default template adds alot of useless stuff to the .net core startup methods it uses to handle angular requests u don't need .
Turning Fusion Log on is a registry entry....
Do you use Azure DevOps? You could pretty easily write a logic app to hit the API to start a pipeline, which would have access to all the tools you're looking for. Or set up a container in ACI and use logic apps to run it once a day. https://github.com/Azure-Samples/aci-logicapps-integration
It’s down there somewhere. Let me take another look.
And AssemblyInfo.cs.
You could simply use regsvr32 in silent mode if you should happen to really get stuck on this.
Thanks for posting. I personally use Entity Framework or Dapper for most projects but could see this being useful for certain things.
There's a lot of factors that can affect COM registration. "not a valid .NET assembly" usually indicates that either the platform target is wrong (32-/64-bit), or the target framework version isn't recognized by the version of regasm that you're using. I used to run into the platform target one a lot on earlier framework versions, but they might have resolved it since then. You can check the framework version used by the DLL with a tool like [DotPeek](https://www.jetbrains.com/decompiler/). Instead of using the regasm binaries in the windows directories, consider using the visual studio developer command prompt. It should resolve the issue on your machine during testing, at least. You can hunt for the actual SDK location later. ## Other options The `/codebase` parameter, alone or with the `/regfile` parameter, is very path dependent. If you can guarantee that the path is always the same, that might not matter. And in that case, adding the registry entries on install and removing them on uninstall is pretty straightforward. Otherwise, you'll end up writing custom actions and messing around trying to match the registration to the target path. But there are [other options](https://stackoverflow.com/questions/23939699/regasm-when-is-the-codebase-option-applicable/23940467#23940467). * You can sign your assembly and register it in the GAC. Then you can call regasm without the codebase option. * You can use [registration-free COM](https://docs.microsoft.com/en-us/previous-versions/dotnet/articles/ms973913(v=msdn.10\)). If your component is only used by a single application (or a limited, known set of applications), you can deploy your COM-enabled library in a specific location with some manifest files and avoid mucking with regasm or the registry. ## Tips * Rather than making the entire assembly COM-visible, you can just tag the classes and interfaces you need to worry about with the needed attributes. It makes managing versions and upgrades a lot easier. Not sure if you're already doing this, but, if you aren't, I'd definitely recommend checking it out. * If you're using an MSI installer, you can add and remove registry entries with it. And frameworks like WIX let you do assembly registration, though I seem to recall that it had issues with non-GAC assemblies (e.g. `/codebase` style registration).
Your post has been removed. Self promotion posts are not allowed.
You'd at leaast try and copy some more stuff from [official documentation](https://docs.microsoft.com/en-us/aspnet/core/migration/21-to-22?view=aspnetcore-2.2&amp;tabs=visual-studio).
Yes we use Azure DevOps, very interesting! Pipelines can be scheduled that way I won't even need a logic app. Sadly no support for scheduled yaml pipelines yet, but setting up scheduling with the designer is fine for now. https://docs.microsoft.com/en-us/azure/devops/pipelines/build/triggers?view=vsts&amp;tabs=yaml#scheduled
Because it still applies for 32-bit?
Try amazon Athena. This sounds like what it was built for. https://aws.amazon.com/blogs/aws/amazon-athena-interactive-sql-queries-for-data-in-amazon-s3/
I'm starting to suspect the issue lies within visual studio somewhere. I created a new project and copied off some of the files from the main project, and i was able to re-produce the issue by creating a carbon copy of my main project. Interestingly, deleting classes until it matched a version that still worked actually caused the problem to still persist in the new project, so i suspect it's actually a setting somewhere that's causing the issue.
Migration to what, OP?! The suspense is killing me! The first sentence of the article includes the "to" but also leaves off a couple of words.
Is it worth migrating from 2.1 to 2.2 when 3.0 is right around the corner?
Classic ASP.
First off, I wouldn’t advise trying to retrospectively add unit test coverage for the whole project. Write tests when developing new features, and gradually fill in. Second, if you actually do TDD, it’s quite possible that you will be able to move faster than the traditional change-f5-test cycle, which can be incredibly time consuming compared to running a unit suite. Just beware of tests that are more expensive to write than they are actually worth.
You might want to consider finding the most maintained bits of the code (via your source code control system). files that have been changed a lot might be a good candidates for starting with.
3.0 is over a year away
If its not already done, separate the UI and the business logic into separate components. Add unit tests to the business logic component(s).
Thanks for your input. Yea I've been thinking heavily about the pros and cons of developing tests. On the one hand I read comments from devs on this sub talking about how important it is to have tests and how "anything without tests is considered legacy code". But then there's the other end of the spectrum that is more rooted in "reality" where most codebases don't have great testing solutions. I guess i just want to make more of a commitment to code quality and stability than was previously made. The architecture is not bad. The business logic is contained within the controllers and related classes but are not in a separate Class Library like how I've seen it demonstrated. The biggest annoyance is that the database is still using the old Database-First approach with the .edmx file.
In my experience you should only add tests to already written stuff like this if you’re refactoring a critical section of code. Write the tests first to ensure it behaves the same way after the refactor
Writing Unit Tests against most real world code requires Mocking + Dependency Injection. If existing code has no way to inject a mock, it isn't really Unit Testable (or at least not in a scalable way). I'd follow these steps: - Get management buy-in (the hardest part). This could be for TDD or just Unit Test coverage of core business rules. - Evaluate how you wish to mock (e.g. frameworks, bespoke). - Evaluate how you will inject your mocks into your code (DI). - Train your peers. - Start new writing code that allows DI and then develop Unit Tests against it. Old code will require a significant re-write to support Unit Tests, it is often easier to write only new code with it in mind and make sure you're fully happy with whatever you're doing before you start to re-write. 
I'd focus on integration tests first, then unit test the really nasty parts of the code if integration tests don't give you peace of mind.
Does your team already do unit tests? If yes, introduce them gradually as part of your work. You can also create integration tests in MVC using the framework that don't depend on a web UI. It's one of the great things about MVC is that you can test everything on the back end without a running front end. [https://docs.microsoft.com/en-us/aspnet/core/test/integration-tests?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/aspnet/core/test/integration-tests?view=aspnetcore-2.2) This book might be for you: [https://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052](https://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052) &amp;#x200B;
my eventual solution was to cut the classes i needed out in to a separate DLL and leave everything else in the original.
Why do people insist on marrying two frameworks like this? Would you wrap a java front end in dotnet mvc? Angular is a framework, dotnet is a framework. Let them do their own thing and keep them separated. Otherwise you are asking for a world of trouble as both technologies evolve.
Agree what what others have said. Unless the project with built to support unit tests then it will end up being a rabbit hole. In order to support Unit Tests in legacy you'll likely need to do refactoring of each function and each dependency. Which leads to refactoring of everything that used that, and so on down the line. Its something I'd recommend going piece by piece instead of all at once. 
Don't attempt to get total test coverage. Try and work out what the critical parts of the application are, e.g. is there a certain collection of classes that do some complex and important business logic? If you find some critical section, you might attempt to test it. If you come to the realisation that it is totally untestable or infeasible to test then this could be a target for refactoring. Alternatively you could fill in the tests later along with future development. For example, you may be asked to implement feature X, but the new code will need to interact or modify old code - this would then give you a target for testing. You can write the test for the relevant old code, do any refactoring that is required, and then modify it to meet the new requirements. Your unit tests can then act as a safety net to ensure you don't break old behaviour while adding new behaviour.
When ever hou talk to a developer that thinks unit tests are a waste of time its most likely because they have done exactlh what your contemplating doing. E.g. 1. Get an existing project that will be really hard to write unit tests for 1. Get management buy in or have management tell you to do it. 2. Find a developer who has little to no experience in unit tests / TDD 3. Get that developer to just write tests 4. Watch as the developer writes fragile integration tests 5. See little to no benefit, delete all the tests 
Also it's a super easy migration and there's a bunch of nice features. Yes it's worth it IMO :)
I take my Aeron from workplace to workplace, its 10 years old and somehow still looks like new.
VB.NET
Agreed. 2.1 to 2.2 is painless and totally worth it. 
[Sublime Merge](https://www.sublimemerge.com/) doesn't have as many features as GitKraken yet (I've used both a bunch), but it's super fast and I like it a lot. Also recommend trying out Rider from JetBrains. It's a much better experience than using Visual Studio a ton of the time and it's pretty new.
Ooh that's very nice
Second. Even if a new layer of abstraction seems gratuitous, it's worth it to adhere to that single responsibility. 
I have been able to do everything I needed with MVC 5 and jQuery and don't see an obvious need to combine .net with angular. Not unless you were to create SPA with .NET api. However, so many companies in Chicago area are looking for Angular + MVC 5 experience that I am thinking about spending more time with Angular. It does make question their design decisions :\\
I worked on my companies architecture team when we made our language decisions. These decisions where going to steer the company for the next few years. We decided to build an Angular frontend and a dotnot core REST API backend. Two years later we have rolled out several products with this stack and are very very satisfied with it. We had at one point considered MVC, Angular, ReAct and MVC + Angular (as discussed on the video). What we found is that using *two* frameworks to build *one* frontend caused lots of smashing and mangling. Which framework had what responsibility when? It didn't take us long to decide *against* that approach.
That sounds like arbitrary definitions picked up from some blog posts. * More deployments is more work than less deployments. Again the computers don't care, but you're creating vastly more moving pieces for the same end result. "Fine-grained" is as meaningless as "micro". * Why is isolating problems any different at all? Whether you use a complicated circuit breaker to stop talking to an API or a simple try/catch with a boolean flag, it's the same thing. And if the fix is deploying something, you're back to the first point of deploying less things being easier than deploying more. * Why are classes and namespaces and assemblies not reusable? That has been the entire foundation of object oriented programming since it started. Loosely coupled just means using interfaces and proper contracts, along with fancier concepts like DI to automate. None of it requires an entirely separate application running elsewhere. Any why can't you scale up the entire app? Code that isn't running doesn't cost anything other than some cheap disk space. Focus on the foundations and concepts, not the jargon. A logical group of functionality = service. It has *nothing* to do with deployments. Many large companies building tons of products will compile everything to a single payload or binary, because it's fast, simple and efficient. Making everything an API running on its own has way more overhead for no real gain, *and you should only do it if there is a specific need for it.* &amp;#x200B;
Looks interesting. Is it a sort of Kafka?
Some would say it’s Kafka-esque. 
This is a wonderful guide, thanks!
@TimeRemove: we really want IntelliCode to be lightening fast and not cause any delays - especially when typing. If you're still seeing a judder or freeze, or the warning about IntelliCode causing a xx second delay, please let us know - just use the built-in Visual Studio “Report a Problem” option, and mention **IntelliCode** in your report, which makes it easier to grab a performance trace of the problem.
@AngularBeginner: we're looking into this case and how we can make the recommendations better. Thanks for reporting.
Why the hell would your package manager ever install anything other than the exact version specified? God, I hope this isn't someone looking at npm and thinking, "yeah, that looks like a good way to do things"...
I'm curious what kind of systems it is that you're building that you find your approach to be so desirable. I've worked at plenty of 'large companies' building plenty of products as well, and it's safe to say that at any of these places your approach would be universally viewed as undesirable to say the least. &amp;#x200B; I don't care to argue with you on views that you're obviously quite committed to, but to answer your questions; 1) Isolating problems is different because it's occurring in separate processes altogether. When app instance A is having issues, app instance B isn't necessarily negatively affected. Have everything balled up into one application? Now you potentially have a system wide outage because one piece of functionality had an issue. 2) I think you knew this, but the key word to the reusability was the 'service oriented' part. Assemblies are obviously reusable. I understand that this is meaningless to you since you believe in deploying monoliths. 
I care
Have you looked at [https://github.com/Api2Pdf/api2pdf.dotnet](https://github.com/Api2Pdf/api2pdf.dotnet)?
Huh, not bad. I'll definitely add it to my list of resources to play with. Thanks!
I bet their code morphed a lot over time.
Can someone ELI5 why these lock files are necessary?
We're using Azure for work and it's been great. Admittedly work is paying for the account so I don't have to worry about billing, but my understanding is that they don't really offer much in the way of "free tier" services. You're best bet would be to sign up for [dev essentials](https://visualstudio.microsoft.com/dev-essentials/) which I believe offers a free $25 monthly credit. If you have a paid Visual Studio subscription you can get [more free credit](https://azure.microsoft.com/en-au/pricing/member-offers/credit-for-visual-studio-subscribers/) as part of your license. There may be more ways to get bonus credits if you do a little googling but adding some free credits should help with any surprise bills. Also if you don't need your application running 24/7 (eg. if it is just serving a web api or something and only needs to work when requested) you may want to take a look at their serverless functions - these have the ability to shut down while they aren't being used (eliminating running costs when it's idle) and wake up when they receive a request. As for the interface, I personally like it and haven't had any of those problems with it - it doesn't stand out to me as being unusably bad. It's certainly been significantly easier to deal with than a dedicated VM, or even the AWS interface. If you're having problems though, you might want to look at using the [azure cli tools](https://github.com/azure/azure-cli) for managing this instead - I've found it easier to use than the interface for configuring some things and gives you a more fine-grained control (via cli args etc.) than what can reasonably be included in a GUI
Services are an abstract concept describing functionality, they don't have anything to do with isolation or deployment. Those are orthogonal concerns that depend on your architecture. The conflation of these issues is the problem. If you need isolation for security, or a separate deployment to optimize a performance sensitive app, that's fine, but using that for everything is where things go wrong. I currently work on large scale ad systems with previous experience in fintech and commercial real estate software. We have 10s of billions of daily requests with several different APIs all deployed and running as a single system. The separately deployed pieces are things like the admin site, the user/api authentication, and background data/batch processing. Very few pieces that let us move faster with less work with full observability, reliability, easy refactoring, and a strongly consistent release process. Splitting things into a separate deployment is trivial but we can decide to do it *only when it becomes necessary.* &amp;#x200B;
When you specify a dependency like `&lt;PackageReference Include="Newtonsoft.Json" Version="1.0.0" /&gt;`, that actually means `Newtonsoft.Json &gt;=1.0.0`. So if [nuget.org](https://nuget.org) just has version 2.0.0 of Newtonsoft.Json, you'll restore that instead of version 1.0.0. That seems ridiculous, right?! &amp;#x200B; It turns out that you can override this behavior by specifying an exact version match: `&lt;PackageReference Include="Newtonsoft.Json" Version="[1.0.0]" /&gt;`. So what's the catch? Say I have the following dependency graphs: &amp;#x200B; &gt;MyAwesomeApp &gt; &gt;\\- Package A \[1.0.0\] &gt; &gt; \\- Package Newtonsoft.Json \[1.0.0\] &gt; &gt;\\- Package B &gt; &gt; \\- Package Newtonsoft.Json \[1.1.0\] &amp;#x200B; In this example, packages A and B both depend on different exact versions of package Newtonsoft.Json. NuGet can't resolve this graph and gives an error! Let's look at another example: &amp;#x200B; MyAwesomeApp &gt;\\- Package A &gt;= 1.0.0 &gt; &gt; \\- Package Newtonsoft.Json &gt;= 1.0.0 &gt; &gt;\\- Package B &gt; &gt; \\- Package Newtonsoft.Json &gt;= 1.1.0 &amp;#x200B; Now, everything is good in the world and NuGet will restore version 1.1.0 of Newtonsoft.Json! If you're interested in learning more about how NuGet restores packages, I'd recommend reading [this documentation](https://docs.microsoft.com/en-us/nuget/consume-packages/dependency-resolution#cousin-dependencies). &amp;#x200B; The morale of this story is that it'd be impossible to restore anything if version ranges weren't `PackageReference`'s default. Does all that make sense? Let me know if you have any questions
NuGet tries its darndest to always give you the same packages, but it's possible to restore different packages at different times. Lock files help prevent that.
hrm. Well that does make sense i guess. I was only thinking about first level dependencies.
Same as npm lock files. Almost exactly it seems. Bout time though. Same issue to solve.
No. This is a stream processing engine, similar to Apache Spark, Flink, Heron, etc. It has some more focused features and comes as a standalone .NET library instead of an entire framework so it can embedded into your apps and used like any other .NET package.
[removed]
Your first example seems wrong. According to the article it would restore the *minimum* version that is &gt;= 1.0.0. By that logic you would never get 2.0.0 as long as a version lower than that existed on the feed.
Morphed into a cockroach
&gt; Thought I was on a free plan, but the App Service wasn't free, the storage wasn't, just the one "small" part I needed. Well, that was up to you. There is a free-tier app service plan, tho it's very limited and really just useful for extremely low access apps and/or dev. Also: Why do you want to use the UI? Just use the CLI.
Paket supported lock files for years already. The Nuget team was just really slow with this.
[Browserless](https://www.browserless.io/) [jsReport](https://jsreport.net/) I've used Browserless commercially (and contributed to it as well) so I can recommend that. Obviously you wouldn't be running these in .NET but calling them instead but honestly I've yet to find a .NET package that can do decent template generation.
My only paint points with Azure are when you don't know which of the vast array of components you should tie together to do the thing you want to do. Everything else I've found fine. Others have suggested using the CLI for interacting with Azure but personally I prefer using something like [Terraform](https://www.terraform.io/) to do infrastructure deployments, and then combine that with Azure Dev Ops to do the code deployments.
Interesting, I started looking at Spark recently. Rather cool
Lol, I hope not :)
Depends on whether you're using Firework or Core, but that's not your problem. If POSTS aren't enabled, you get a message telling you that POST is not allowed. A different message to yours. Are you running it all through localhost? I would try adding a GET method at the moment and get that working using standard browser calls. Then you know for a fact that everything is wired-up correctly and the URL is correct.
Terraform intrigued me, could you elaborate on how you're using it? What's so good about it? As someone who uses gitflow with self-made zip deployment to Azure(Kudu) in GitlabCI at work, I'm not sure how this or Azure Dev Ops would help me in day to day development/deployment.
[removed]
Also using Browserless, it's been fine for us. But do not use Puppeteer with it(it's incredibly slow to open connection somehow), just call the API directly with the Html. 
I am trying it on localhost and using ASP.NET. As for debugging, the execution stucks at HttpClient.SendAsync(request). I am sure about the headers because the same block of code works when I try it from a console application (non asp.net). It doesn't work in ASP.NET, that's the reason I think IIS express might be to blame; not sure though.
Asp.net comes in two types, NET Framework or NET Core I meant you need to set a breakpoint in the API, not the application that's calling it. 
If you've already got a CI set up, then Azure Dev Ops might not be much used to you, but obviously it integrates very nicely with all the bits and pieces of Azure. So if you end up using things like Slots for example, it can be a help. It just depends on your own personal workflow really. Terraform just meant that I don't have to write reams of Powershell scripts to create environments. I have a set of Terraform files in a folder which I can run against a Subscription and it will just deploy everything. It works out the dependencies between all the components, it can check if things are missing and the files are very easy to write. I've only ran into a few things it can't automate (SSL Certs for example). If you're working as part of a team you can then start to sync your start into Azure Blob Storage so that multiple people can work on the infrastructure scripts. We had a project doing everything through CLI and ARM and it was far more painful in comparison. Now the only things I tend to do through the UI are look at App Insights and general monitoring.
I use [puppeteer-sharp](https://github.com/kblok/puppeteer-sharp) which have .net core support.
(on my mobile phone now so i cant check yet) . is this on jwt? 
Yeah we use the API (I wrote the original PDF function). We also did a lot of work at my current employer on the repo for the Docker image so that you can have a pool of Chrome's that are always running as opposed to the previous way it worked where the Chrome's would be created and then destroyed after each operation. I'm not sure if that's exposed through the hosted option Joel offers. We currently host Browserless in Azure and it works absolutely perfectly.
We originally started using that but had issues with it at the time inside Azure Functions (they don't like Websockets all that much). Ended up using the API for Browserless.
I use my free credits from my MSDN account to play around with it but the UI on that portal is so slow that I think I'd hate it if I used it in production.
Here is some awesome series of posts that goes through ways to reduce file parse times. From early easy optimizations to parallel work with memory mapped files. [https://ayende.com/blog/posts/series/176034/making-code-faster](https://ayende.com/blog/posts/series/176034/making-code-faster) &amp;#x200B; When it comes to database insertions you should probably look at bulk insert. &amp;#x200B;
NET Framework 4.6. And about the API, it's an Azure QnAMaker api. I can't set a debug point inside the api, it's Microsoft's proprietary code. I have seen the analytics of the API service in Azure and it doesn't receive any requests when I try to run the asp.net application. Which means, the request doesn't hit the API. Sorry if I am not clear, I am pretty new to this.
yes
Ok, there's a lot of additional helpful information in that last reply. You say that the same code works on a console app, is it EXACTLY the same code (copy paste), or could you have made a typo in the URL or credentials? It's possibly a firewall issue on your network, but the same rules will come into affect whether it's from IIS Express or Console. Are you sure that SendAsync is the method you want to use? HttpClient has specific calls for POST requests The bot framework is constantly changing and breaking. 
1. Yes, the exact same code to generate the http header. 2. Yes, the most probable reason might be network issues. It's either network issue, or configuration issue, I suppose. 3. I have tried with the PostAsync function too. The block of code that I am trying is actually from Microsoft's documentation, so I think there isn't any problem there.
It was a problem with proxy settings. Added the proxy settings to the config file. It's working now. Thanks.
Just want to say that I love these! We build a microservices implementation on dotnet core using the eShopOnContainers example, but we learned a lot by going through your code base! Really nicely done
Thanks, glad to hear it! Our approach is a little bit different, as we're building a fully asynchronous solution, not just an internal event stream as it's being implemented in eShopOnContainers project :). 
F# is a beautiful language. I am at a beginner level. Coming from C# this Lang seems to be a very different . I guess this is worth learning in the long run. 
I would argue that it's not worth learning. 
F# seems like an interesting language, but if you are doing professional development, there are fewer opportunities to use F#. C# has more developers, job opportunities, open source libraries, code samples, learning resources, and...it tends to get new platform features, productivity tools, and IDE support before any other .NET language. It also interacts more easily with the large OOP based BCL and with native code. You shouldn't pick a language to learn (for professional and career uses) based soles on how nice it's syntax is.
&gt;C# has more developers, job opportunities, open source libraries, code samples, learning resources, and...it tends to get new platform features, productivity tools, and IDE support before any other .NET language. &amp;#x200B; This is true to some extent, but based on this thinking you'll never learn anything new anymore? Open source libraries are the same for both languages, because you can use C# from F# and vice versa. &amp;#x200B; &gt;You shouldn't pick a language to learn (for professional and career uses) based soles on how nice it's syntax is &amp;#x200B; Even though the F# syntax is a lot nicer, it wasn't mentioned in this blog post a single time. &amp;#x200B; &gt; it will need to provide strong, compelling, consistent value to businesses compared to C# &amp;#x200B; All of those compelling and strong values are listed in the article :). I'd recommend to read it! &amp;#x200B; &gt; For F# to become more used than C# &amp;#x200B; F# doesn't need to be used more than C#. If you don't like to learn something new or explore other programming models or languages which are aimed at primarily benefit your personal productivity then it's okay if you just stick with what you already know and are happy with.
If you're running in Docker, don't forget to update your base images too.
The thing is while your right most of the nice stuff from f# will get ported to c# for example the with syntax for pattern matching is already on the way So in a way learning some f# gives you some peaks at stuff that might show up in c# down the road even
I really like all the stuff on fsharpforfunandprofit.com and the Domain Modeling Made Functional book from the same author: https://fsharpforfunandprofit.com/books/#domain-modeling-made-functional-ebook-and-paper
There are a few reasons why the two frameworks were combined: 1. Security: The requirement was to use Azure AD and it played a lot nicer with .net core startup.cs. Also the requirement of not having to duplicate our security logic twice once in the api side and once again in the Angular code 2. Hosting: We wanted to host everything under one PaaS offering and one service plan so breaking the application up into two frameworks would have required us to host angular as it's own service plan and the api's as their own as well. 3. Finally to answer just\_an\_avg\_dev question, we did want to have a SPA rather than jquery in MVC5
care to say why?
Other commenters seem to be doing a nice job of it for me. I was replying to a beginner. A beginner should learn something commonly used so while learning you have lots of resources like C, C#, Java, etc. I also think F# is lame. I personally dislike the syntax. Plus, I've also been around long enough to know that whatever is so cool about F# (and I'm not convinced there's anything) will make it's way in a more refined form into more mature languages. Let someone else be a guinea pig. If you want to learn a new cool language, learn Swift and make an app and some money in the process.
That's not true. C# isn't capable of recreating several of the core features of F# without a major language redesign, so it ends up with slightly inferior recreations. Non-exhaustive pattern matching being a great example: some sugar, but none of the robustness of guarantees of proper pattern matching. It's a time saver, not something that lets you rethink system design and domain models. It's not that you get things before C#. You get complete and powerful concepts that have been in functional languages for decades that C# has been slowly trying to replicate.
I think this is a pretty good book for someone just starting out in F#:https://www.manning.com/books/get-programming-with-f-sharp
I see a lot of posts recommending F#, these days. All them come up empty handed. Functional programming is just a paradigm, which can be found in a slew of other languages. I see the allure if you're a C# developer, though. Personally, I'm just gonna stick with Rust, Python, C++ and C#.
You can also make an app in F# for Android and iOS and make some money in the process of being a cool guinea pig having fun with a productive language ;). Jokes aside though, if you looked at it and didn't like it that's fine. Some people like Scala, others Kotlin and others something completely different. There's value in all of those and I simply wanted to state the values of F#.
I should have at least mentioned that your presentation was pretty good and was very thorough for this configuration. I just don't like the configuration. I will have to admit I don't know enough about Azure AD to have considered it a factor in your decision so I glossed over it. Maybe you can help me understand how AD forced your decision? From what I picked up from the presentation it looks like AD acts as your identity manage. Basically it checks if you are logged in, if not, you land on login page, if so, you land on the home controller. Is there a reason the Angular app could not just call your REST Api to verify identity and the REST Api just exposes some of the AD logic? It seems like Angular Route Guards would handle that fine.
We didn't want anyone to load the app or access it that is outside the organization and using AzureAD configuration out of the box, I don't have to write any code to challenge user and authenticate them other than the setup configuration in .Net Core startup.cs. Azure takes over from there and manages the login screen, the redirect, forgotten password, and all the headache that comes with identity management. It allowed me to focus on the app and less on authenticating users. Finally I could have made Angular do the authentication but that's duplicating the code and if anything changed it would have had to change in both Angular and .Net Core. 
I don't want to argue with your choice sense you have obviously thought about it and no one knows your technical challenges as good as you. I only want to discuss it for the betterment of myself. So if my questions feel abrasive please forgive me. &gt; I don't have to write any code to challenge user and authenticate them other than the setup configuration in .Net Core startup.cs. This is true, but you did have to write a bunch of glue code/config between two frameworks, which from what I saw is the same upfront effort and maintenance effort. &gt; I could have made Angular do the authentication I don't understand Azure AD but it feels like they should have an integration for Angular that works with only a little setup given that UI's without back ends are very common. Anyway, good stuff man, good video.
I found a quick startup guide for Azure on Angular. It does seem like there is slightly more work doing it this way but also, there may be some methods of shortening it. I didn't have time to read it all. https://spikesapps.wordpress.com/2017/07/27/securing-an-angular-application-with-azure-ad/
It is a bit cumbersome, and you always get the 1st class vs 2nd class citizen support with .Net vs with Angular
That makes sense. We too are a Microsoft shop but we don't use Azure because we can't trust our data out of our hands. But I can totally see Angular being 2nd class citizen in that environment even with Google + Microsoft embracing/working on Typescript together. Good luck!
Thank you sir
Does C# really need those features? Honestly, modern JavaScript is pretty good, and if you need something with strong typing, look into TypeScript. C# is OK, but most of the time we're just using it as a backend for the interesting part of the application, and the less time spent worrying about it the better.
The user doesn't care how the website is built, very unlike the total response time (get stats on that). That is the only thing that can jeopardize Blazor. 
Not actually an F# book, but pretty close (an Ocaml book): https://realworldocaml.org/ 
There is hybrid Azure which is a strange concept but a concept [Hybrid Cloud](https://azure.microsoft.com/en-us/overview/what-is-hybrid-cloud-computing/)
Well the obvious approach is to read line by line lne you're doing. I would probably dump it into an EF/EF Core model through so I could be more flexible with the database type the data can live in. You can still take the SQLite database and generate an EF/EF Core model from that though, I think. It's been a while since I've done it that way. Just keep in mind for bigger data sets it's probably best to use a heavier-weight database. I've used SQLite in products then saw people try to stuff 15gb of data in one and get mad when it was slow.
Nice finally codelens in Rider, just need easy switching of nuget references with local projectsl references in a solution for easier debugging. 
&gt; Plus, I've also been around long enough to know that whatever is so cool about F# (and I'm not convinced there's anything) will make it's way in a more refined form into more mature languages What's cool in F# are features from ML in the 1970s that still haven't permeated mainstream languages. Mainstream languages are almost all still based upon Algol. &gt; If you want to learn a new cool language, learn Swift and make an app and some money in the process. Why would you learn Swift to write iOS apps when you can learn F# and write both iOS and Android apps (without having to worry about leaking cycles)? 
&gt; Why would you learn Swift to write iOS apps when you can learn F# and write both iOS and Android apps (without having to worry about leaking cycles)? Because a native app will almost always be better than hybrid/wanna-be native apps and swift isn't that hard to learn either.
Xamarin apps are native.
Pffff, c# is the reason I'm staying with dotNet 😂 I used to write in cpp before I moved to c#. The reason for me was unity3d and at that time I was playing a lot with it. Since I hate whole web movement and especially JavaScript, I used c#. In unity3d /mono it was old version c# but still eased up many many many things for me with sugar code. Afterwards I needed some tool and decided to try wpf with help of some book but mostly documentation. Later moved to xamarin and asp and asp core. No idea how my path will help you at all but there you go. 
Even if xamarin apps weren't native. Sacrificing a small amount of performance is absolutely worth it to be able to run (and sell) on both mobile platforms. Unless you are writing a game, you probably don't need to squeeze every last drop of performance out of your app.
Agreed. This article looks like a lot more code that in essence replaces a single guard statement. 
Do we really need distributed cloud systems and robust high availability solutions? Yeah, we do. Do we need correctness guarantees in complex systems? Yeah, we do. Javascript need not apply, Typescript need not apply. What you're saying here is almost certainly true for the kinds of apps you're making... The fact you call the "interesting part" anything but the backend would hint that you're not working a lot with the kinds of domains where strongly typed functional systems like Erlang dominate. That's totally fine. The world needs steel girders and wood beams, and we're not any poorer for the ability to choose. But things like BigData, Enterprise, or Multi-Provider Cloud Native development has needs that aren't addressed with less correct/robust tools.
I know I am a bit late but anyway. The hangfire codebase is quite small and open source. You don't need a license to get it: it is in a public GitHub. I had a good look at it and did not see anything suspicious. The paid version is for additional features (redis support, etc)
When you want something that can scale easily.
No they're not. They're c# transpiled to swift/java. The performance of a Xamarin app will never be better than a truly native app.
It's worth learning to experience how to program with a functional mindset. Seeing different concepts helps you be a better programmer in ways that you don't always expect 
With the intentional slow down of older phones, you absolutely do. If you think otherwise, you might as well just port an angular app into webview.
&gt; This is true to some extent, but based on this thinking you'll never learn anything new anymore? I'm suggesting a developer should learn and become an expert in the tools and technologies that will advance their career. I'm not making any suggestion about open source, educational, or personal projects or what language they should use. &gt; All of those compelling and strong values are listed in the article :). I'd recommend to read it! I'm not one of those people...I read the whole article before I commented. I enjoyed the article, I just didn't agree with the way it was being compared to C#. &gt; Even though the F# syntax is a lot nicer, it wasn't mentioned in this blog post a single time. A significant portion of the article is code samples with comparisons between C# and F# and talking about how the F# version is simpler. The article might not have mentioned syntax, but it was a big theme in the article. &gt; F# doesn't need to be used more than C#. No, but the language you choose to learn professionally or to build a system out of that a business depends on should probably be used more than Groovy or Perl, if you have a choice. &gt; I think a lot of people avoid F# based on wrong assumptions That's the thing. I don't. If you look at the Stack Overflow survey, F# is listed as being loved by 60% of respondents, yet its adoption hasn't taken off. It's story for growth, hiring, legacy compatibility, and maintenance are all worse. I guess I'm just sick of seeing these articles advocating F# and filled with negativity against C# when its obvious that language features and paradigms are only a small part of why languages are chosen by companies and professionals for use in products. I like what I have seen of F#, and I guess I'm just angry that I can't find a reason to learn it because it won't benefit me to do so unless I plan to become an F# evangelist.
Fair enough! You certainly raise a good point that F# hasn't risen to the adoption which I think it deserves and if that is a detractor from learning it then I cannot disagree with it. I wrote this piece with the hope to raise a bit more awareness, from the angle of a C# developer. I actually didn't want to make C# look bad (even though I admit this is probably what I've partially done), but really just compare good C# with the equivalent in F#. I thought drawing some comparisons by someone who actually knows C# very well might spark more interest from traditional OO programmers who perhaps were thinking of learning F# but were not quite convinced yet.
What is your budget? I can move some things around.
Functional languages are the future, purely for scale. 
I think you aren't using the dictionary definition of Native App. If it's in the platforms native language then it's native. That being said you're correct that a transpiling introduces opportunities for ineffficiency. 
Tell me about it... but also tell me about your actual thoughts on the subject. Is this something you would ever find useful? Have you ever used or looked into Django's admin module?
Yes, I’m familiar with Django’s admin module.
&gt; Honestly, modern JavaScript is pretty good, It is *capable*, but it is not *good*. It has functional style and functional capabilities, but also has gotchas around every corner. You can do functional/OOP programming style in C, if you really want to. A modern language is as much about what it takes away as what it brings.
One of the big advantages to Javascript or C# is the fact that lots of other people use it, and there is LOTS of code samples to look at, learn from and use. I keep hearing things like "F# is magic! Its fantastic!" but there just doesn't seem to be lots of code samples available. Erlang and lots of other obscure languages fall into the same pit. Python seems to be the opposite. It isn't particularly great as far as languages go, but its gaining a huge following. Why? Because there are code samples out the ass all over the place.
I have another solution for that using Directory.Build.props... if you’re interested..
One of the difficulties of reading an article like this is that I wasn't there at the meeting where you defined the model with the business. It's an example obviously, but it still makes me feel uneasy because there are bits I wouldn't do the way you did it. And that's fine because I'm not doing your domain model :) Things like ```this.Balance.HasSameCurrency``` is a red flag. There should be no case (again, this is my opinion) where an account like this should even accept a foreign currency deposit. It's like null propagation to me. Stop it at the boundary, there's going to be some sort of FX layer that will handle this outside. Deposit should be Credit? But this is a great example of identifying the domain model. I think Credit, because that's the generalisation of a deposit, but if your domain uses deposit rather than credit then your example is spot on :) Because I talk too much, I would probably add a paragraph about sagas. Throwing an exception on a deposit is a scary situation to be in. It's a more advanced topic, but anyone coming from pre-DDD enterprise dev will immediately look at the code and go "wtf happens if I only complete one side of the transaction?" 
Isn't everything ultimately compiled down to the platforms native language? I always thought native means written in that language. 
&gt;Don't use ___ it's not popular enough This is the primary argument I see against F#... I don't even know F#, but I plan on learning simply for the experience. It will be a good exercise, and I might end up liking the language enough to apply it in my work.
And why do you believe that?
Current reasons to use Rider over Visual Studio Community?
Not disagreeing with you... but I never said "Don't use ____" People should use whatever they want. I said there were *advantages* to C# or javascript because of the assload of examples floating around out there. I said python is in the same boat - except its popular *because* its popular and gaining popularity. I don't even use python much (really ever) and I'm still scratching my head wondering why I would actually want to use it for anything. Its clear to me that people are excited about python *because* its popular.
Should I skip F# and learn Q# so I can look down on both C# and F# developers?
I can only think of Mac/Linux support. I know there’s a version of VS for Mac, but I have no idea how good that is.
As of 2 months ago it was trash. Borderline a reskin of xamarin studio. 
Went for this one. Thanks
Much more productive. VS has been slowly copying features from Resharper for a long time but it's still slow and limited. Rider gives you a fast responsive platform with all the little shortcuts and smart hints that let you type out code 10x faster than VS. It also has better support for various other languages like JS and SQL. Debugging is still better in VS since MS doesn't allow anyone else to use their debugging tools.
I'm working through F# courses on PluralSight currently. I think that having another way of thinking about how to solve a coding problem makes me a better programmer in general. For me, so far, the benefit of learning F# (interest aside) is that it makes me a better C# developer. 
Rider isn't free, unfortunately. I just cannot go back to VS's embarrassing implementation of text searching.
&gt; Rider gives you a fast responsive platform Are you comparing rider with VS or rider with VS+Resharper? Because resharper makes VS dog slow. Going through the enforced pain of using it in a new job at the moment and I wish I could turn the damn thing off.
Would you mind elaborating?
Why can't you turn it off? Unless I'm missing something, you can just disable it in the settings
As someone who just started working with VS for Mac, but it's pretty damn bad so far. I don't know what caused it, but it just recently lost the ability to find my workspace, so I can't connect to our on-prem TFS collection. Doesn't really seem to be any feedback on what the deal is. It's awesome!
Amazing comment, your are raising many valuable points. As you pointed out, the model is very much dependent on the specific domain it is representing and the implementation is up for debate - that's the pitfall of writing a blog like this and using a domain that is not clearly specified. The main point of the article is to raise awareness that we need to pay more attention to the domain models we are creating. I will definitely discuss sagas and transnational consistency in the upcoming posts which, as you have mentioned, are crucial, especially in a domain where money is concerned. Thank you!
It was a difficult reply to write because I genuinely like the post and I wanted to add to it without coming off as slapping it down if that makes sense. Thank you too :)
Yeah, besides some issue I'm having with Visual Studio 2017 and 2019 lagging, VS without ReSharper is very snappy. Plus with the improvements they've made, and some extensions like Roslynator, I don't miss ReSharper at all. Plus the issue with my lagging appears to be fixed by turning on a preview feature in 2019 for increasing performance when rendering VS across displays with various pixel densities. 
Needed for code style. I can run it on the command line but i'm only supposed to run it on modified files.
&gt; How can I tell which framework version (asp.net, and .net) a code base is using? In IIS an AppPool can run either .NET 2 or .NET 4 code, not both. It will be set in the AppPool settings which one it is using. &gt; What is the ASP.NET build process? Any normal .cs files are compiled into your DLL and you have to rebuild the DLL to apply code updates for those but .as?x files are compiled on demand when requested. I don't know about pre-compiling as I don't recall having any issues with changing the code in pages and refreshing.
And that ladies and gentlemen is what we call civil discourse 😊
Is there a way to get the missing namespaces (alt+enter) without R#? That's probably what I miss the most with vanilla VA. Do you guys actually type those usings by hand?
do we need to do both Install-Package NetTopologySuite and Install-Package Microsoft.EntityFrameworkCore.SqlServer.NetTopologySuite when doing add-migration, currently getting The property 'Point.Boundary' is of an interface type ('IGeometry'). If it is a navigation property manually configure the relationship for this property by casting it to a mapped entity type, otherwise ignore the property using the NotMappedAttribute or 'EntityTypeBuilder.Ignore' in 'OnModelCreating'. 
I enjoyed the article and it's convinced me to jump into the F# boat over Xmas and into next year. You make some good points and I look forward to delving deeper into it all. One thing I will say is, at least in my opinion, I'm not a fan of the dump on/compare to c# way of bigging up F#. I want to see why F# stands on its own 2 (functional) feet and learn about a completely different programming paradigm than the ones I'm used to in C#. I think all languages have a time and place and truly skilled programmers know that any language will never fit every scenario. What is like to hear about F# is what it's standalone strengths are, you did touch on that a bit and all in all I really enjoyed it. Thanks 
I did it Ma! I did civil! Literally no one died!! :) 
Thanks for the feedback. I agree that it might seem a bit of a blow against C#, but I think I tried to compare it to C# mainly because that is really the language which I am the most familiar with and secondly because I wanted to show some FP concepts in comparison to OO and I had to pick some languages for the samples.
I got a degree in CS. Had one class where I learned how to scaffold(lol), actually I never used c# or .net prior to this class. Got an internship at a company, made an android app using java. Then there was a need for an internal site. Since we were already using active directory, and I had some experience with mvc 5 that's what I decided to use. Also, wrote web api for the mobile app. &amp;#x200B; In the past year I have learned a lot about the framework. I picked up some Ajax, Jquery during that time too. I would suggest working through pro [asp.net](https://asp.net) and then finding a project you want to make. Start simple, like to-do without any backend. Then, introduce some kind of database for data storage, research entity framework. Once, you get that working, think about implementing some kind of data validation. Then, think about how you could make the to-do dynamic. Basically, when user submits a to-do you could refresh the view using ajax without reloading the page. At this point I would research good patterns for database access that would make your code more testable and maintainable. I think that would be a good start. I would put the project on github if you don't have much experience with source control and use it religiously, smallest teams should be using some kind of source control. I have used JIRA and TFS if you want to do some reading.
Someone on the internet told me so, duh.
Even with intentional slowdown, I have never seen a noticeable difference in performance using native vs a framework. It may just be the apps I work on, they are mainly a client used to interact with a server and provide some offline capabilities just in case. I may just not have enough imagination to think of an app that isn't a game and requires the best performance possible. I would like to see the benchmarks you reference as well as the methodology of them. Benchmarks are an incredibly difficult thing to generalize.
I have a lot of projects that depend on each other via nuget packages. For maintenance, I have a “global” solution, that allows me to do cross-project refactorings. And like you, I want them to reference each other via ProjectReference instead of PackageReference. This is done with this file https://github.com/nuke-build/all/blob/master/repositories/Directory.Build.targets This file must reside in a topdirectory to all affected projects.
Both. Resharper is more productive but makes the IDE slower. Rider doesn't have that trade-off so you can get more done faster. Resharper is being refactored to run completely out of process to not slow down VS but it'll never be as good as a single integrated app. Have you tried Rider yet? Use the trial for a few days and you'll likely be convinced.
 The issue of performance is 100% on VS. Roslyn solution wide analysis is what makes VS slow, it runs perfectly fine with R# if that's disabled. Disabling solution wide analysis is also the official fix to a sluggish VS, at least it was as recent as 3 months ago. VS extensions are all fighting with each other and VS for a very limited resource pool in a single process. VS continues to grow, maybe bloat a little, and its limitations have been building towards a tipping point for a while now. In fact, the limited resource issue has become enough of a problem that VS2019 will be offloading the debugger into a standalone 64 bit process, which is a big step in the right direction, IMO. I love VS, I don't think I'll ever be able to abandon it, as it's one of the most powerful pieces of software, and easily the most powerful IDE, in existence. While you don't need R#, it's an important tool in its own way, and it seems a little unfair to place the blame there when a lot of those issues exist as part of VS.
EditorConfig or StyleCopRoslyn are free and fully supported in VS. If that is why they mandate it, then redo the style rules and claim on review you just saved the company gobs of licensing money.
&gt; Even if xamarin apps weren't native. Sacrificing a small amount of performance is absolutely worth it to be able to run (and sell) on both mobile platforms. Unless you are writing a game, you probably don't need to squeeze every last drop of performance out of your app. You're assuming Swift is fast. Last I looked [Swift was 5x slower than OCaml](http://flyingfrogblog.blogspot.com/2017/12/does-reference-counting-really-use-less.html). 
&gt; They're c# transpiled to swift/java Not even close. 
I understand "native" to mean ships as an executable binary as opposed to shipping a CIL EXE that requires a pre-installed interpreter like .NET. 
Care to elaborate how C# magically turns into java and swift then?
On Android, Xamarin ships a JIT (Xamarin.Android), presumably written with the NDK, on top of which your app runs. On iOS, C# is AOT compiled to iOS-compatible ARM assembly in the same vein as CoreRT.
So it's transpiled into native libraries. Cool.
&gt; transpiled Technically compiled. 
It's semantics at this point, but transpilation implies source-to-source. When compiling Xamarin code, the C# never undergoes any source transforms; it's either compiled into CIL (Android) or machine code (iOS). That is, unless you consider CIL to be source code.
The rules they need are not supported by editorconfig or stylecop roslyn. And licenses are peanuts, specially considering that I'd probably be the one waiving it. :)
&gt; Resharper is more productive This is debatable. For it to be more productive you'd have to use a fair share of its features and I know that most people use only a fraction of them. &gt; Have you tried Rider yet? Use the trial for a few days and you'll likely be convinced, and the settings are portable with Resharper. I don't like resharper, why would I use rider? I actually would like to get rid of it. :)
Turning off resharper makes it faster. Can't really argue about that. You can also run solution wide analysis out-of-process. Not that it has been a problem in the small solution I'm currently working on (~20 libraries, 3 web projects). Like i said in another comment, turning off resharper makes VS a lot faster and I have only enough stuff turned on to let code cleanup work.
Depends on what you want to do. For desktop apps rider is pretty much a no-go
What rules aren't supported?
You said it was slow, which is mostly a fault of VS. Rider solves the performance problem and provides more overall capabilities. Even the basic IDE environment is better for getting through code than VS without using all the features. But fine, don't use it. I'm not sure why you're asking about then. &amp;#x200B;
We write front end unit tests to make sure we are handling the data back correctly and they are going into the right if statements and subsequent logic is correct. 
You should only test it if you expect it to work properly.
Resharper is what makes it slow. They have said that themselves. The problem is you can't run extensions outside of the visual studio process, and since visual studio is still 32 bit for whatever reason, resharper easily caps the memory. It has nothing to do with Visual Studio. It's plenty fast without resharper.
Did you just setup a 'Poe's Law' joke on yourself on purpose? #MadLads
Python is popular because it has a large wealth of ML and analytical libraries while still being simpler to code in than JavaScript (both have simple syntax, but python has fewer idiosyncrasies).
I'm not too familiar with this side of things, but are you sure you've [called `UseNetTopologySuite()` on the provider's DbContext options builder](https://docs.microsoft.com/en-us/ef/core/modeling/spatial#nettopologysuite-nts)?
Man I need to try this out. Does it work with regular .NET (not Core)? Can it parse .sln files? Anything else major from VS that it’s missing? 
May as well go full Haskell and out-smugify them all.
It uses the same solution files as VisualStudio, so in a team, there is no need to agree on a particular IDE. It does work with full .NET Framework, Mono, .NET Core. For a comparison, you could check https://www.jetbrains.com/rider/compare/rider-vs-visual-studio/index.html
Mainly because its code compiled for release and so all that extra information is removed by the compiler in order to make the code run as fast as possible. You can sort of try this on your own by compiling a program in release mode, setting a breakpoint somewhere in your code and try to debug it. Most probably the breakpoint won't hit (because the compiler optimised the code in such a way that your original code no longer exists) or it gives nonsense results (like stepping over a line makes it jump to a "empty" line on another file) It's way more complicated than this but this is the basic reason.
this is as close as one can get, i think: https://marketplace.visualstudio.com/items?itemName=SchabseSLaks.Ref12 
One common way to do this is to use icon fonts (e.g. Font Awesome), you can then colorize the icon/character for real, just by setting text color. None of this hacky multi-image stacking nonsense needed. Here's one article that gives an example: https://stackoverflow.com/questions/38305239/how-use-icon-font-awesome-in-wpf 
There's a good tool called ILSpy that you can use, but it is going to display c# based on the compiled binaries, NOT the actual reference source. It's also not in the visual studio ide. That said, I've found the tool to be remarkably useful. If you don't need the comments in the source, then this is usually all you need. 
Have you tried this? https://docs.microsoft.com/en-us/visualstudio/debugger/how-to-debug-dotnet-framework-source?view=vs-2017
In my opinion, if you can code in one language (especially the C based languages) you shouldn't have a problem picking up C# and .NET. I really like .Net Core and would recommend trying to pick that up, although it can arguably be more complicated since it pushes heavily towards dependency injection (which is awesome). When learning any new technology, I always try to complete some sort of tutorial or a small sample project. If you have SQL experience, creating a task management application is usually a good start. If you don't have SQL experience you can still do something similar with just in memory storage. But that is where I'd start. Good luck! I'm sure you'll pick it up quick. 
JustDecompile has a VS extension for this
Hmm, I can do it. I'm in VS Code. I do have the .NET Core SDK installed, and the C# extension installed in VS Code. I click the middle of a framework class name, F12, and it takes me to an IL view, like an interface. I don't have Visual Studio installed right now, but when it worked, I think I had to install the SDK libraries, which were just part of the installer. YMMV, but yeah, it should totally work.
That's small to you?
you can decompile and look at the source, but not sure about debugging into it. though you wouldn't want to debug other's libraries. they should already be fully tested and you don't need to "debug" them. Resharper has a decompile sources feature. You can also use ILSpy or Reflector or similar separate app to look at CLI sources, and there's now an ILSpy extension in Visual Studio.
Ih think you got something wrong here. VBA is not VB.net It is possible to write Excel plugins in VB.net using interop, but as far as I know it is not possible to run VBA in a DotNet environment
Python is an okay language imho. It's definitely not elegant, and sticks to tons of old naming conventions that make it awkward to use/read. Plenty of things have the dumbest, unintuitive, non-descriptive names that are remnants of a past era where code golf was more important than operational efficiency. But it works, and is pretty handy all around.
What kind of app is this? Web or ?
Vastly better git interface, better unit test interface, better NuGet interface, and a nice command palette like vscode which make features much more discoverable if you’re new. Better SQL client integration if you occasionally need to work with databases too (and don’t have datagrip). Plus, whatever platform you sit down to work on, everything works the same! Also, Visual Studio has been much less stable for me of late, including breaking things dangerously during upgrade (at one point it installed a beta of .NET 2.1 that was packaged accidentally and all of my builds broke). I’m at the point now where I wonder why MS don’t just pour all their effort into vscode plugins and infrastructure to support them and throw Visual Studio on the legacy pile. 
Nice, I recently discovered &lt;PackageTargetFallback&gt; which helped me moving the PCL projects to netstandard gradually. That was actually the hardest part because we have so many dependencies. I'm busy converting the test assemblies to netcore 2.1 (nunit) The biggest pain I have atm is that we have over 20 Azure DevOps projects and they all incorporate GitFlow branching. Versioning is non standard, packaging, updating changelog, add doxygen documentation.. Maintenance is hell. I'm looking into powershelling everything and put those scripts in a separate project so I can clone it and just need to bootstrap in the pipeline. It's going to be a pain for the Azure DevOps REST API stuff but I'll manage. Thank you for reaching out and I'm glad to know other people also suffer from this situation. If I need some help I'll pm you.
You can, look up .NET Framework source stepping. There’s a bit of configuration to do in Visual Studio and then you’re good.
Take a look here: [https://referencesource.microsoft.com/](https://referencesource.microsoft.com/) &amp;#x200B;
I second this. I've used **puppeteer** for the first time last week. This is by far the easiest to implement that I've ever encountered. (And I've messed with wkhtmltopdf and all sorts of esoteric pdf libraries just to get some pdf out). [Puppeteer sharp](https://github.com/kblok/puppeteer-sharp) allows you to use the chrome pdf-generator. You can test your templates in google chrome, and puppeteer sharp will export it in the exactly the same with control over page size, margins, headers, footers, page numbers, etc. // downloads chromium to a temp folder, you can also specify a specific version, or a location where it should look for chromium. await new BrowserFetcher().DownloadAsync(BrowserFetcher.DefaultRevision); var browser = await Puppeteer.LaunchAsync(new LaunchOptions { Headless = true }); using(var page = await browser.NewPageAsync()) { await page.SetContentAsync("Your html content, use T4 or whatever template engine you like to generate your html."); await page.GetContentAsync(); await page.PdfAsync(outputFile, new PdfOptions { DisplayHeaderFooter = true, FooterTemplate = @" &lt;span class='pageNumber'&gt;&lt;/span&gt;&lt;span class='totalPages'&gt;&lt;/span&gt; ", HeaderTemplate = @" This is document printed at &lt;span class='date'&gt;&lt;/span&gt; with title &lt;span class='title'&gt;&lt;/span&gt; and url &lt;span class='url'&gt;&lt;/span&gt; ", Format = PaperFormat.A4, Landscape = true, }); } **Libreoffice** A second option that might be relevant for you is that LibreOffice is actually good and easy in generating PDF's to convert spreadsheets, powerpoint or word documents to pdf, although I found it harder to exactly control the layout. soffice --headless --convert-to pdf yourfile.doc
You can but you may need to set it up. When you compile your code with release configuration, much like when Microsoft do, you don't get your symbol files (.pdb files). These symbol files contain a bunch of debugging info, e.g. source lines, type data, line numbers, symbols, exports. Without these all you've got is the compiled .dll files without the original source code. Instructions on enabling debugging of .NET Framework source code is at https://docs.microsoft.com/en-us/visualstudio/debugger/how-to-debug-dotnet-framework-source?view=vs-2017 As an aside, NuGet package authors can make debugging their code possible by using Visual Source Link, which provides a way of adding metadata to describe where to find the source code which the IDE can use to let you step into the author's code when debugging. 
How has no one mentioned that the latest release of VS can already do this? Just update and it'll decompile for you. You might have to turn it on in the options. https://docs.microsoft.com/en-us/visualstudio/ide/go-to-and-peek-definition?view=vs-2017#view-decompiled-source-definitions-instead-of-metadata-c &gt; View decompiled source definitions instead of metadata (C#) &gt; New in Visual Studio 2017 version 15.6, you can set an option to see decompiled source code when you view the definition of a C# type or member whose source code is unavailable. To turn on this feature, choose Tools &gt; Options from the menu bar. Then, expand Text Editor &gt; C# &gt; Advanced, and select Enable navigation to decompiled sources. 
set up vs to download the symbols from their symbol server and you can debug against the source code, takes some setup in the debug config to do it.
Is it available on Community, or like code lens only Pro, or live unit testing, only in Enterprise?
For those who are doing Xamarin Android on either MacOS or Windows, this version is such a major release bringing us the best .axml editor on a .NET ide. Loving 2018.3 so far!
.NET core you write is compiled into an [intermediate language (called CIL)](https://en.wikipedia.org/wiki/Common_Intermediate_Language) and ends up as DLL files that you deploy. The CLR runtime (like .NET Core) will take these files on startup, compile them just-in-time (JIT) into a native version that works for that CPU platform and then starts the app. Decompiling these IL DLL files is already possible available in Visual Studio, but this doesn't actually give you the original source, just an optimized representation of it. What you need to map back directly to the source code are something called [symbols](https://en.wikipedia.org/wiki/Debug_symbol), which are recently supported in Nuget but many packages don't have them yet. Things are in progress including another recent feature like [Source Link](https://github.com/dotnet/sourcelink) which lets you debug code in external libraries along with your app and step through the actual source code itself, instead of just seeing it. Again this requires packages to include the relevant information so it will take a while before it's widely available.
**Common Intermediate Language** Common Intermediate Language (CIL), formerly called Microsoft Intermediate Language (MSIL), is the lowest-level human-readable programming language defined by the Common Language Infrastructure (CLI) specification and is used by the .NET Framework, .NET Core, and Mono. Languages which target a CLI-compatible runtime environment compile to CIL, which is assembled into an object code that has a bytecode-style format. CIL is an object-oriented assembly language, and is entirely stack-based. Its bytecode is translated into native code or—most commonly—executed by a virtual machine. *** **Debug symbol** A debug symbol is a special kind of symbol that attaches additional information to the symbol table of an object file, such as a shared library or an executable. This information allows a symbolic debugger to gain access to information from the source code of the binary, such as the names of identifiers, including variables and routines. The symbolic information may be compiled together with the module's binary file, or distributed in a separate file, or simply discarded during the compilation and/or linking. This information can be helpful while trying to investigate and fix a crashing application or any other fault. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
You clearly not used most parts of r# if you don't miss it. Even with roslynator and other extensions I miss so many little cosy things.
While this might have more features, NDesk.Options is much less verbose and probably more suitable for the kinds of console apps most people use. I don't think I need a decorator-based command line parsing pipeline for my kludgy thingdoer.exe.
Check the reference source online. Or Corefx/Coreclr for netcore on Github.
Windows application. "Stand alone" sidebar, always on top, flyout by pressing a small arrow
That last bit was exactly what I needed, thank you! Makes so very much sense 😁 Now I just need to figure out everything else, lol
DragonFruit is pretty interesting. Helpful for simple apps but I imagine it will get overloaded with too many arguments quickly.
This is it
Is the preview only on the Enterprise edition? I was looking for a 2019 Preview on the Community edition. I don't plan to pay anything for VS, I use the Community edition. And because it is a Enterprise edition, I assume there will be a charge attached to it. How long will I be able to use the Preview if I don't pay anything?
Assuming this is WPF, I would try find a suitable icon in the segui mdl2 assets or other font icon library and use it in a textblock. Then write a custom converter that takes the particular value and converts it to a colour. The textblock colour is then bound to the value using this converter. 
You got my interest by promoting NDesk.Options. So I've checked it - last version 0.2.1 from 2011 ([https://www.nuget.org/packages/NDesk.Options/](https://www.nuget.org/packages/NDesk.Options/)) and git repo no longer available ([http://gitweb.ndesk.org/?p=ndesk-options;a=summary](http://gitweb.ndesk.org/?p=ndesk-options;a=summary)). Sorry, I'm gonna pass
Omg I didn' even write that it was wpf. Asking for help but not giving any... Great idea, I'll look into the font icons to see if any fits. If not, your source change tip is great
Cool I used to write winforms stuff but have moved over to WPF and the bindings and converters are really nice to work with. The reason I suggest segoe (sorry spelling error before) mdl2 assets is they are installed by default on Windows 10 and have a huge range of icons. There is a cool app on the store called Character Map UWP which makes it very easy to browse this (and other fonts) to get the XAML code. Also there is a FontAwesome WPF NuGet package that might be of interest and make life easier. 
Thank you very much! As I mentioned I'm a comlete noob at this, but not at coding in general. There's lots of other stuff I'm sure I can figure out by myself, except for what you just helped me with, and how to make a shared database (or whatever suits my needs best). The latter I just pisted a question about in r/dotnet. Again, 1000x thanks buddy 😁
The technique you're looking for is called IPC. Inter process communication, there are many forms of IPC but the one I'd recommend in this case is a socket IPC (message passing) 
Thanks, buddy 😊 I'll look into socket IPC
I'm on my phone but look into a TcpClient and server in C#. And then essentially it goes as follows: app 1 is a server (also maybe a client) app 2 is strictly a listener (or both idk what you want) app 1 sends a message across a socket connection and then app 2 receives it and triggers some change of the UI.
Also if a database is truly required you could just keep doing a selection statement against some data but that's ehh. Also yes technically you could save the information to a file and listen for changes on it, also ehh. Even with something simple like this socket connection is probably the most "correct" way to do what you are asking.
It has Resharper built in and is super fast.
Hmm.. Not sure if a database is "required". As someone who doesnt know anything about databases and IPC, I'd explain my needs like this: I want to store 20 x (4 x int values and 2 x string values), in my mind arrangeable into cells. The above should be in a file on the network drive, so that the values arent reset, if all users close the application. Any user can overwrite the values, and all users should get the updated values, so that the UI changes accordingly. (Like the LED changing from green to red). It might be relevant that the environment is pretty secure. No direct connection to the internet, pretty locked computers, unsure about port access etc.
With max 10 users, it wont happen often that 2 users update at the same time. And I guess that the last data saved will overwrite the old data.
Well a database is good for saving initial values, sockets can send data to all running apps in near real time and as for the security that can be implemented with the database.
But I'm rather bored tonight so I think I am going to build a demo for you.
Wow, you sure are helpful! 😁 I think I'll fifure out all the other stuff, but the shared stuff part is a little hard to grasp as an unexperienced coder. I still think that a database will be a good idea, as the userbase work in shifts around the clock, so there will be short periods where noone is "online"
Might as well say what its for. Its for a dispatch central, where cities and vehicles are currently written on whiteboards. I'd like it all to be on a sidebar in windows, with a red LED for occupied, and a textbox for personel and the current task. Also icons for helicopters, k9 units, boats, etc.
Thanks. Someone on the VBA subreddit thought it would work if the project included the Office Data Objects library among others. Thought I’d get a second opinion.
Because I'd need to copy over the application on an usb stick, I imagined implementing a fileopendialog to choose the db file. Would need to do that on each instance of the apolication, of course
The modern world of anemic domain models shits me to tears. The current project i am working on uses extension methods to add functionality to the entities. I dont really understand when OO went out the window.
Can you not have a DB Server that all the software talks to? In terms of architecture all the desktop apps would communicate to the DB to get their data. The DB would need to be installed on a server somewhere and the client would connect to that DB and refresh their data. In terms of triggering an update rather than refresh that's a bit more tricky with this architecture [here](https://dzone.com/articles/receive-notifications-with-new-values-when-table-r) is a guide. Does it have to be a WPF app ? This would be cleaner if you where using a webapp. Then you could connect the browsers up via a socket.io connection to the server which would update all connected clients when someone updates the data. [Here](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/websockets?view=aspnetcore-2.2) is an example in dotnet core.
What do you use to test the CLI frontend? With a web app, it's pretty clear. There's a bunch of tools in the JS ecosystem that you could use. There's also Selenium. Nothing comes to mind when I think of the CLI. 
Thanks buddy, will check both links out. The app will have to be a small collapse-able sidebar in windows, so I'm not sure it will be optimal with a webapp (assuming it runs in a browser). Honestly I was hoping that i could just get the application to either live update or scan every 5 seconds off of a file in the file system on the network drive, but it seems that it'll have to be a bit more complex than that, lol. I'm sure learning something new
You can enable source link and it will download the code. But only during debug. You then step into each line. Dot net core only. This is the new micro PBD format. It’s awesome. 
You mean a sidebar like windows vista style sidebar ? Why on earth would you create something like that in 2018 ...
Because it meets my needs, multiple users having a quick overview of ressources (people, vehicles, boats etc) and their states, on a sidebar, thus not hiding what theyre currently working on, on their pc
But it sounds like there is little difference here than a website as your sidebar is collapsable like any browser window.
Hmm. Could be the solution. Though the initial idea was to have it always on top, and visible all the time, unless the user wanted to collapse it to the side.
Wouldn't that get in the way of other windows on the PC though? Do the users have multiple monitors ? If so they could have the dashboard open on a second monitor.
I hope you're awake still because this code is actually really cool in my opinion. Link to Github: [https://github.com/BaileyMillerSSI/WpfFieldSync](https://github.com/BaileyMillerSSI/WpfFieldSync) Gif: (Working on it)
I’ve been looking for exactly this! Anybody have any other good recommendations? I find it very hard to search for because googling “.net cli” comes with all the wrong things
They have multiple monitors, but in most cases the dashboard wont be in the way if its narrow and on the left. Otherwise they can collapse it while doing what it was in the way of
I agree that it would make more sense in a web app, but if he wants something that will always be open on the screen and have more controller of placement and sizing he'll have to use a desktop framework.
WOW! Well done, buddy! ... i just found out that databases run as a server that has to be installed(?). Need to find out if that's even a possibility on the strict ecosystem at work. With your permission, I will borrow your code and test it at work today, to establish if that is the way to go. You're the best, thanks again!! 😁👍❤
CommandLineParser is an actively developed library for command line parsing that supports things like verbs: https://github.com/commandlineparser/commandline Actively developed, source code available, works in Core
To save everyone the digging, here's the 'DragonFruit' app model: class Program { /// &lt;param name="intOption"&gt;An option whose argument is parsed as an int&lt;/param&gt; /// &lt;param name="boolOption"&gt;An option whose argument is parsed as a bool&lt;/param&gt; /// &lt;param name="fileOption"&gt;An option whose argument is parsed as a FileInfo&lt;/param&gt; static void Main(int intOption = 42, bool boolOption = false, FileInfo fileOption = null) { Console.WriteLine($"The value for --int-option is: {intOption}"); Console.WriteLine($"The value for --bool-option is: {boolOption}"); Console.WriteLine($"The value for --file-option is: {fileOption?.FullName ?? "null"}"); } } 
By all means take this code, there are some bugs / I didn't want to fully implement everything. Also I only have it going one way which isn't what you wanted that actually isn't too hard to fix either. Lastly, this only works in a local setup, two apps same computer. To change that firstly you'll need to know the IpAddress of the (Server) computer that is running a version of the application. Secondly, you'll need to change 2 lines, `RootServer = new TcpListener(IPAddress.Loopback, Port); =&gt; RootServer = new TcpListener(IPAddress.Any, Port);` also you'll need to change `var ip = IPAddress.Loopback; =&gt; var ip = IPAddress.Parse("Insert Server Ip Here");`. Happy Coding!
Thanks! Will copy it when i get to my pc
I think somewhere else you mentioned the whole DB thing and that sometimes users won't be online. The database will sit somewhere else a computer that is always turned on and available I suppose just within you local intranet not the whole world. 
I understand that a webapp would be the more modern way to go but from what I understand he is developing this for super internal software. Not something that will have a lot of access and also won't really be leaving their network. Web apps can certainly handle that use case but a simple desktop application can also meet the needs of an internal software package. 
I usually use [CommandLineParser](https://github.com/commandlineparser/commandline), really like that it returns strongly-typed options objects 
There are lots of awesome libraries making building command line apps easier. Personally, I can recommend [https://github.com/commandlineparser/commandline](https://github.com/commandlineparser/commandline) and [https://github.com/ninjah187/Jarilo](https://github.com/ninjah187/Jarilo) (which I'm author of and it tooks slightly different approach than the former one). Checkout also some cool libraries like [http://colorfulconsole.com/](http://colorfulconsole.com/) to make your users' experience better. You can also explore something different by yourself: [https://dotnet.libhunt.com/search?query=command+line](https://dotnet.libhunt.com/search?query=command+line).
From browsing the implementation i can see that your entry point class must be named "Program" and the entry point method must be "Main", but case doesn't matter. The library generates a real entry point that finds your entry point and invokes it.
Problem is, that I can't have a pc running dedicated always on. We each have our logon, usable from any of the company pcs, which connects us to a server, giving us access to printers and so on. It's a very strict and secure environment, that I can't really fiddle too much with. Can't install anything, can't fiddle with windows settings. I can run a non-installed program, and have access to a file structure on our network drive
To expand upon Dave30f5 I would put the db on the "server" and have the project using SignalR and WebApi. Googel Chat clients tutorial with Webapi...it's exactly, I think what you want all clients always updated when one user makes a change. Should take much code nor buying any additional stuff.
I see well you could run the database in aws for cheap. Same with you could move the server code away from any individual app into the cloud.
If you look in DragonFruit's targets, it appears it generates a dll with a wrapper around your System.CommandLine Main (in your app). It then injects a normal Main method which uses the generated dll to call your strongly typed command line Main using the System.CommandLine api. This is fairly interesting stuff; this project serves as a pattern for a nuget package which can generate and inject code into the project referencing it. Here is a snippet of the generated code from the [targets file](https://github.com/dotnet/command-line-api/blob/master/src/System.CommandLine.DragonFruit/targets/System.CommandLine.DragonFruit.targets). // &lt;auto-generated&gt;This file was created automatically&lt;/auto-generated&gt; using System.CommandLine.DragonFruit; using System.Runtime.CompilerServices; using System.Threading.Tasks; [CompilerGenerated] internal class AutoGeneratedProgram { public static async Task&lt;int&gt; Main(string[] args) { return await CommandLine.ExecuteAssemblyAsync( entryAssembly: typeof(global::AutoGeneratedProgram).Assembly, args: args); } }