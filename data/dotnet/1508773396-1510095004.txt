&gt; This brings me to thinking that perhaps it would be just easier to use JS or TS to do stuff the JS-way rather than trying to do it from .net using somewhat more complex code structure and conventions? If you know the languages, yes, just write in the original languages. While these languages compiling to other languages is a nice little project, it's not too useful in any actual environment.
I love xamarin, however all the attempts at designer/live preview are unstable at best. If you expect windows forms/xaml designer that works fast and well, prepare to be disappointed.
&gt; I was just in an interview and got asked the standard "explain the difference between an abstract class and an interface". &gt; That was a quick answer ... not it will be more like "well, it used to be this, but now, as of C# 8, you can also do this other weird stuff". As of C# 8, the answer becomes a single word: state.
I'm not really sure that higher kinded types are the solution here. This is literally a kludge for multiple inheritance because every once in a while that's what you need. Bringing type theory into the equation is pretty much overkill.
Like everything, it's up to the developers to have the discipline to use the tools properly. Everyone said `dynamic` would be the downfall of the language and that code complexity would explode everywhere. I still have yet to see more than a handful of instances of `dynamic` in the wild, though, and in each case it was the appropriate solution. Default interface implementations are dangerous. But sometimes they solve a real-world problems that you can't fix in any other way other than adopting an even worse anti-pattern. Nobody likes versioning interfaces to avoid breaking backwards compatibility. This aims to stop that. And if it's used for only that purpose, then I'm ok with it. 
Not sure if it's the only mistake but you also need some extra quotes as currently it will just output: ```src=/js/pages/cca.js?v={DateTime.Now.Ticks}``` when it should be ```src="/js/pages/cca.js?v={DateTime.Now.Ticks}"```
Hi, I'm one of the DotVVM developers and I also happened to be a non-Windows. You are right, that the lack of VS Extension may be a bit annoying, but you are not losing any html-only features, VS Code can be simply configured to handle dothhtml files as HTML. You may also try a simple (experimental stage) VS Code extension (https://github.com/riganti/dotvvm-extension-vscode), it only offers simple element and attribute name completion, but as far as I know, there is not anything more decent for Razor. Unfortunately, I'd really have look how they do it ;). And everything else works like a charm on Linux. And what do you mean by "HTML designer friendly", I don't think that other tools with have more/less problems with `asp-` prefix than `dot:` prefix. From my perspective, I like the names with colon more, as it seems more obvious that they are special.
I'm excited for this series. While working on porting PowerShell, I was always envious of .NET Core's devops work. Your CI system is astounding.
Thanks! In the next part I'll show how to manage + orchestrate the services and automate the deployment process even more :).
This will solve the Interface, Interface2, Interface3 issues. Now you can add methods to an interface without breaking existing implementation.
Someone else said the same thing about Rails when Django come along... They said the same thing about ASP MVC... About Backbone... About Laravel... If the problem is so solved, then why people people keep making these frameworks? Maybe not everyone wants to be a Ruby or Python developer? Maybe some people want to use their familiar .Net tooling, workflows, and support to develop their applications?
Using the network tab in chrome dev tools or something like Fiddler proxy, you should be able to narrow in on exactly what URL is causing the redirect loop. Are you sure that it is the url for cca.js that is causing the problem? The default handler for static files in asp.net would not choke on the cache busted url like this, so unless you have overridden how static files are served with something else, my money is on "not related to cache busting" 
In retrospect I regret the tone of my message. I should have asked in a more respectful fashion "what are the benefits of this package?" If the answer is "bringing some of the newer, best practices from modern frameworks to the .NET ecosystem" that is notable. My apologies for being a dick.
I don't see any issues with the code you've posted here. What else is (a) in that page and (b) in that "cca.js" file? Script tags (the markup itself) cannot trigger redirects even if you have syntax errors or malformed attributes.
Have you checked the Google product forums?
Can you post your action method and the result of evaluating the &lt;script type="text/javascript" src="js/pages/cca.js?rev=&lt;%= DateTime.Now.Ticks %&gt;"&gt;&lt;/script&gt; expression?
I ended up resolving it: https://stackoverflow.com/questions/46894302/asp-net-javascript-cache-busting?noredirect=1#comment80736930_46894302 
I ended up resolving it: https://stackoverflow.com/questions/46894302/asp-net-javascript-cache-busting?noredirect=1#comment80736930_46894302 
A CPU will load data from main memory to cache in small chunks, because usually after accessing array[i] the next values you want are right next to it: array[i-1], array[i+1], array[i+2], etc. Because a multidimensional array is really just a single-dimensional array with some indexing arithmetic, the order you access values in may influence how well your CPU cache performs. If you're accessing array[i + 100 * j] then if you're incrementing i first, j second your access pattern looks like array[0], array[1], array[2], etc. and you're making full use of your CPU already having cached most of the data you're loading. But if you're incrementing j first, i second then your access pattern looks like array[0], array[100], array[200] and by the time you get around to array[1] the CPU will probably have thrown away the cached array[1], array[2], values that it cached when you fetched array[0], so you don't get any freebies.
Then it wasn't an option. As I say the access was not exactly sequential. Jagged arrays were just way, WAY faster for that.
Hi, thanks for the response. By HTML designer friendly I mean markup that is basically idiomatic HTML. For example I designer can work with this ``` &lt;input asp-some-tag="some value" placeholder="some text"&gt; ``` But this cannot be parsed as HTML ... ``` &lt;dot:TextBox Text="{value: Name}" /&gt; ``` I think the tag attributes in the new MVC are a big win over other frameworks and having server tags create controls is one of the things I dislike about server side frameworks (they all have them, Rails, Django etc). It would be good if the DotVVM team did something with the new asp tags. This is more important to me than code completion which I'm not really that bothered about.
It's not math ;) Its evaluated from left to right
My first thought was...'isnt this what an abstract class/method is for?'
Yes, completely indispensable. Never regretted buying the license and upgrading it for the most recent version. I use it for quickly testing out various expressions, simple programs, test data loading, adhoc querying, the list goes on. I rarely use it to connect to a database. 
Nothing to read really, but there are a lot of open source project to learn from -- here's the first one I googled: https://github.com/servocoder/RichFilemanager Dotnetnuke also has a file manager and is open source so you can read how they made theirs work. Honestly there are so many ways to skin this cat, and so many different ways I've seen it done that there is not a real correct answer. 
Thank you, for taking time out to reply. I'll build a sample wexflow project and see if it makes sense to scrap my home grown workflow.
Default interface implementations are basically nothing more than extension methods. Unlike an abstract class, an interface with a default implementation is still stateless (can't declare fields or auto-props). An abstract class can fulfill the same role until you want to a type to implement multiple interfaces, at which point you need to encapsulate or re-write a bunch of (presumably) boilerplate code.
I may not be getting your point, but when you inherit you inherit from a class, not an instance, so how can you inherit data?
Try re-installing the app from the FTP location. Your update source path might also not be configured correctly, i.e. it is publishing the new version to the FTP but the update path is local. 
How would I reinstall the app? Also, how do I change the update path. Sorry, I’m very new to this and don’t understand the terminology and stuff 
&gt; My apologies for being a dick. Am I on really on Reddit? :p
Depends on the application, of it is CRUD stuff, web app makes sense, but for anything a bit complicated (likely to have power users), web app are a pain.
Yes and no. Webapps fix a lot of issues with deployment and byod. Apps tend to be better for intensive stuff but most apps aren't intensive
I am surprised that there is no hatred on their channel. No feedback on live, but no insults. Seems xamarin improved a bit.
Are you ecampidoglio from GitHub? If so, hi from a fellow Italian in Sweden :)
A partial workaround to the issue is to put, next to the interface, a static class containing extension methods to the interface. But this approach usually works only to avoid bloating an interface with overloads of the same method. Default implementation will be handy when you have `ISomething` and `ISomething&lt;T&gt; : ISomething` with the latter just relaying a typed method to the actual object-ed method of the parent.
Cut up the file into little (1mb-ish) chunks, send with a checksum and a byte index, then reassemble server-side.
Yeah if you’re doing random access there’s not much you can do
I mean inheriting fields/properties/locks/etc. Primarily because you can then end up with two copies of the same base. For example an object that derives from IFoo and IBar which both inherit from IState. If you modify IState.Qaaz, do you change both the value in IFoo and IBar? Or do they have separate states if so which do you read when you do obj.Quaz?
I've published it to Gtihub: https://github.com/lugrugzo/WebApiJwt Also you can check tutorial too: https://medium.com/@lugrugzo/asp-net-core-2-0-webapi-jwt-authentication-with-identity-mysql-3698eeba6ff8 
I am. Hi there :)
Hmm, that's actually true. On the other hand, the `dot:TextBox` approach offers better encapsulation, the world is not so simple... I was actually thinking about interoperability with MVC's partial views and the tag helpers, but it's not realized anywhere. Could you please announce your interest in this feature at https://github.com/riganti/dotvvm/issues/387 ;) But I'm afraid that integrating tag helper with their full syntax capabilities would just lead to more messy syntax.
Hi, you are actually right, that our website does not give much info about the technology, there seems to be just marketing crap like "become more productive". The main point is to nicely integrate client-side interactivity with server-side logic. This is a broad term and the approach we have chosen is to translate all server-side data bindings in the page to Javascript expressions and serialize the ViewModel of the page, send it to the client and use it as client-side ViewModel (we are currently using KnockoutJS for that, but it's going to be replaced). I'm not aware of any other framework that does something similar. If you know something, please let me know, I'd like to have look at it. Just note that I'm one of the DotVVM devs, so I'm maybe a bit biased ;)
My current project doesn't involve .NET Core, but instead normal .NET MVC, and I've been struggling with finding explanatory authentication code for what I'm doing so it's really neat to see a post spawned out of that general place (there is none so I'll make some) I might even be able to use what's happening in your code to better understand what is happening in mine haha
Hi @cecilphilip, how will webpack behave with multiple pages? do you have any example of this?
Only the Jedi deal in absolutes
You can try asking here, or ask on StackOverflow. If there is someone that can help, they will.
Amazing. Looks easy enough to understand once compiled together like this. Of course it's normally the research that is the hardest. Thank you!
Kendo gave me nothing but problems. We ended up using some in-house jquery that worked twice as fast, didn't explode and cost nothing extra.
They're here for 2 months already https://www.nuget.org/packages/Microsoft.AspNetCore.All/
Ok the danger of getting side tracked... I think that this is a weird away to word it. If classes implement a common interface they are 'related'. So before 8.0 my answer would be: If you want to share functionality, use an abstract class. If you want to share an interface or trait (e.g. Drawable, the ability to be drawn), use an interface. I still struggle to understand what the difference actually is after 8.0 though. Why not just enable multiple inheritance?
we are updating our modals so they be able to be used in new browser. (From IE8 to Chrome, Edge, Etc)
Good point. But why not just enable multiple inheritance and leave interfaces 'immaculate'? What is the big advantage with default implementations?
&gt; If classes implement a common interface they are 'related'. Not sure if by this statement you are attempting to better understand my definition of "related" or if you are providing your own interpretation of "related". But from my point of view, no 2 classes are not related just because they share a similar interface. An Order and Customer class can both implement the same interface but its clear that they are not related.
Although it's not quite the same, Rails' [Turbolinks](https://github.com/turbolinks/turbolinks) attempts something similar in abstracting away JavaScript callbacks allowing the developer to focus purely on server side code.
Ah ok. Sorry english is not my primary language. You mean related in the family sense?
I mean related via their inheritance chain. Basically take your Drawable example. If I only want Shapes to be able to draw them themselves then I can put that logic in the Shape class that Circle, Square and Rectangle all inherit from. However if I want a class outside of the Shape inheritance chain (say an Order class) to also have the ability to draw itself then I would define an IDrawable interface and have both Shape and Order implement IDrawable.
Ok. Yes I guess. I don't like the example because it's not reduced enough for my taste. Discussing whether to use inheritance or not involving inheritance. But that's just taste :)
Why isn't the following a valid solution? public class Parent : IParent { public string Name { get; set; } public IChild Offspring { get; set; } }
This is a part of data access layer and those are EF entities. I don't believe EF can accept it... or can it? 
You can have actual covariance in generic interfaces: public interface IParent&lt;out TChild&gt; where TChild : IChild { string Name { get; } TChild Offspring { get; } } public class Parent : IParent&lt;Child&gt; { public string Name { get; set; } public Child Offspring { get; set; } }
OK, tanks. I was afraid it was the case... Although explicit implementation might be less of a kludge but is still a kludge :) Do you know if there are any chances of getting covariance into c# at some point?
EF Entities are partial classes which can accept interfaces on your custom side. Don't add them to the auto-gen classes as they get wiped on the next model refresh.
It has been proposed, but doesn't look like too much movement on it: https://github.com/dotnet/csharplang/blob/master/proposals/covariant-returns.md
The window component is kind of a pain, I usually end up just using a modal from bootstrap to plug in the page.
I've used both the Jquery-based and the MVC-based controls by telerik, and the Jquery-based ones are way easier to work with. The MVC (or 'razor-based' as they call them here) are just converted down to html and javascript anyway. The documentation for the razor controls is absolute garbage, but the jquery ones are actually pretty nice once you get used to them. Also, I find writing javascript a lot better than trying to figure out how they decided to implement their razor syntax. It's just a giant clusterfuck.
You raised very good questions actually. I'll try to share my vision, hope it will shed some light on the problems. **1. Applicability.** I truly believe that every existing tool or technology is useful and in right circumstances it works better then the others. So when you considering selecting a tool or language for the next project, your decision should be weighted up carefully, all aspects development process must be evaluated: - Language/Framework - do you have enough knowledge in it? - Type System (APIs) - is it familiar for you? does it cover your needs? - 3rd Party libraries - extremely useful for saving your time (e.g. when you need integrate your app with smth) - Tools - what IDE supports selected language/frameworks? on what level? licensing - is it free? etc. - App requirements - target auditory, maintainability, supportability, performance, reliability, security etc. I believe the list above can be easily extended with more points, but it's enough to demonstrate what I mean. Now let's try to evaluate Bridge.NET: **- Language** - if you're C# developer with just insufficient or shallow knowledge of such languages as JavaScript and TypeScript - Bridge.NET is a good choice for you. You might be even not familiar with JavaScript, Bridge.NET will definitely help to take the first step. If you're awesome TypeScript programmer, I agree with you here, why don't you create you app in that language? If you don't have much experience with TypeScript, but you've got nice skills in JavaScript - I'd still suggest considering between Bridge.NET and TypeScript - they provide static typing that will improve your code quality significantly. **- Type System** - what is .NET? The most frequent answer would be is BCL+(CTS+CLS)+CLR, in other words, Class Libraries + Common Specifications + Runtime. The same could be applied for TypeScript, it is a language and types (defined by ECMAScript standards + custom bindings like the ones from DefinitelyTyped repository). Bridge.NET has nice advantage here, because it supports the both "worlds": .NET types and JS Bindings under Retyped name (from different sources including DefinitelyTyped). A nice sample is regular expressions - JavaScript Regexp lacks some functionality, and from feature perspective .NET Regex much more useful. If you use Bridge.NET - you'll have that .NET Regex functionality out of the box. If you use just TypeScript - then you'll have to spend some time to find and learn a library that provides API similar to .NET Regex. **- 3rd Party libraries** - I already mentioned DefinitelyTyped bindings. TypeScript and Bridge.NET provide similar level of support here. But with Bridge.NET you are able to port your lovely .NET library into a Bridge.NET project. That advantage is not huge, but at least something. You also noted that your code can't be fully ported with dependencies to non-Bridge DLLs. That's true, but i'd say it's the biggest limitation existing in Bridge.NET world, but if you have access to source code of those libraries, things become easier. **- Tools** - If you're a C# developer, then you're used to working with Visual Studio. Bridge.NET matches greatly here, you don't have to switch to another IDE, all you tools (like ReSharper) and processes work just perfect. For example, some Bridge.NET programmers are just happy that they can navigate through members of a Retyped package in Object Browser. You use VS Code? Yes, it's also supported. But what if you decided to develop in TypeScript, you might really want to get more intelligent IDE providing at least the same functionality that you had for C#. If you don't have experience with that IDE, you'll have to spend some power to step in. **- App requirements** - it's a lovely topic of many people. Many of them keep saying that performance of apps written using Electron is so much low, or there are much more reliable frameworks, or you should have think about security and so on and so forth. Well, sometimes I just don't know what to reply.. because it's hard to explain that every technical decision should be based on some specific requirement. You shouldn't select tools and frameworks because they are cool and there are a lot of "noise" around them. If you write a small app, that does not operate with sensitive information - should you select a super secure framework for it? Do you need high performance for a tool that does not consume more than 5% of CPU in peak loads? You'd probably want to have a good level of maintainability and support. I believe TypeScript and Bridge.NET meet that expectations quite fairly. You can always get some advice from the community or projects developers, report an issue, or suggest a feature. Another benefit - both TypeScript and Bridge.NET generate clear and good structured JavaScript. So you can support your product both in the original language (C#/TS) or in the generated JavaScript. Not all approaches/compilers provide the same ability (examples are JSIL, WebAssembly - not because they are doing smth wrong, just because they employed another approach which makes you reluctant when it comes to the output debugging). **2. As for "JS-way of doing things in C#"**, that's fair. Whereas Bridge.NET navigates you from C# to JavaScript, Retyped does the opposite - brings JavaScript universe into C# world. You can always rewrite logic written in a language having strict rules for type usage, declaration syntax, type relationships etc (C# is a good sample) into so flexible language as JavaScript. And it's extremely hard to do things vice versa. Bridge.NET and Retyped teams invested enormous amount of time and brain power to make that happen. The result is maybe not ideal, but it works, and it works so much nicely. Meanwhile the teams keep working on making the syntax even more clear and familiar for C# developer.. so you may expect such things like you noted above (InitGlobals method) gone in a while. For example, the next line loads a module and assign it to a global variable: var Electron = (electron.Electron.AllElectron)node.require.Self("electron"); Retyped already can make it automatically, but only for those libraries that are defined as a module. [electron.d.ts](https://github.com/electron/electron/releases/download/v1.6.15/electron.d.ts) is actually a script. So no magic with automatic module loading happened. It's sad, but there are so many ways to workaround. And that makes Bridge.NET + Retyped so powerful. Of course, things will be better and better over time, and such sad lines will just disappear making development process as straightforward as it could be. Well, it looks like I should stop here, otherwise I'd write a book. Just a short summery: You want to utilize .NET features in your JS project - Bridge.NET will help to do that. You want to keep your code protected with static typing while creating a JS project - Bridge.NET and TypeScript work just perfect here. You're not familiar with TypeScript and JavaScript - write in C# with Bridge.NET. You want to keep using your lovely IDE and Tools - again, Bridge.NET fits nicely here. You are portng C# logic to JavaScript - Bridge.NET allows to do that (with some limitations). You'd like to share your code between Server and Client sides - a good application for Bridge.NET.
You can avoid renaming the more strictly-typed property by doing an explicit interface implementation: public Child Offspring { get; set; } IChild IParent.Offspring =&gt; Offspring; // or this.Offspring to be abundantly clear 
If real devs don't use frameworks then essentially they're all GoLang devs..... lol
The link in the article to [David Fowler github repository](https://gist.github.com/davidfowl/8939f305567e1755412d6dc0b8baf1b7) is very useful for summarizing all versions...
Why would you make interfaces for ef models....
I'm confused. Last I heard, .NET Core was barely usable. How is it already at 2.0? 
Doesn't make it less of a contract. Many of the largest .NET libraries have been achieving this partially through extension methods. This merely allows you to override the method should you choose to. To me this is a much welcomed feature that does not in any way conflict with interfaces being contracts.
Im confused by `AddCustomerOrder()`. Would this exist in the Repository or in the Service? I assume the repo because it needs direct access to EF to make the magic happen with one query. If you do it this way, it seems like it could be easy to accidentally put business logic in the repo.
You are correct on all counts, your repository will grow with the application, but the key is that the application is defining its design and not the database below it.
.NET Core isn't tied to the Windows Update system (like .NET Framework is - they can't realise a new version of .NET Framework outside of the Windows update cycle, because it's tied directly to the Windows platform), so a new version can theoretically be built and released at any point. Couple this with the extreme velocity that both .NET Core and ASP.NET Core (as well as EF Core and Rosyln) get because they're completely open source, and you have a very frequent release cycle. BTW, version 2.0 has been around for a while (the first public preview was released in May). But a lot of late adopters are trying it out now, so there'll be a lot of noise about it for a while. I've been using it and writing about it for a while, and it's really quite stable now. Most of the issues with the early version are gone, and the move to .NET Standard 2.0 has really helped things along.
Web API are services you call from the the browser via ajax usually these days in angular or react. They can be RESTful or not, thats up to you. They can also expose end points to other consumers that are not websites you build. In a nut shell they provide a way to get / update / insert (put) / delete data from whatever you are exposing from your API. you use it to build either a more responsive website e.g. angular service that calls the api, this is an alternative to a full page postback to get/update etc some data like in mvc or webforms. or you use it to expose your endpoints to other consumers.
This isn't a criticism, but an honest question: Is there a reason to avoid .NET Core MVC over .NET MVC? It's my impression that .NET (not core) is going out the window now that core's nearly 2.0
&gt; The documentation for the razor controls is absolute garbage Absolutely agree. That whole shitshow has put me off ever using Telerik web controls. &gt; decided to implement their razor syntax. It's just a giant clusterfuck. Also this, I'm finding Razor to be a major pain after using it, going to Angular, and then doing Razor again. It is nice when it works, but its easy to fuck up.
2.0 was always on the road map for late 2017. So in reality it's right on time.
It is an interface in the original API meaning of the term.
Nearly 2.0? It is 2.0.
Microsoft has made extensive documentation on when to use [asp.net or asp.net core](https://docs.microsoft.com/en-us/aspnet/core/choose-aspnet-framework) and when to use [.net core or .net framework](https://docs.microsoft.com/en-us/dotnet/standard/choosing-core-framework-server). I read your question and wonder if you know that an asp.net core application can run on either .net framework or .net core (I apologize if you already knew that).
You can create a folder called Account in your project. If you're using visual studio, right click on the project name, add, new folder. Then, right click the folder and select add, new web form to create your register and login web forms. Is the folder a requirement? If not, you can just throw the Register and Log In web forms in the project directory and call it a day.
Oh hey, look at that!
Thanks for taking the time to help! I am using Visual Studio (2017) but I'm not trying to set up custom Register and Log In pages. I'm trying to find out why the template's Register and Log In pages aren't being created. This is not the tutorial but it might help explain my problem: https://msdn.microsoft.com/en-us/library/ff184050.aspx &gt; Notice that the root Web site contains several files and folders including the Account folder The Account folder is not being created for me. See here: https://i.imgur.com/b3kh7ke.png
The easiest way I've found to get it straight in my head is pretty simple. I always mentally prepend the word "The". As in, "*The* .Net Standard." That instantly makes me perceive it as a specification, rather than a product or framework. It isn't ".Net Standard," it's "*the* .Net Standard." The .Net Standard specifies a list of APIs available to frameworks that implement it. .Net Core is one such framework.
.NET 4.7.1 **is** .NET standard 2. The **most** valid way to decide whether you want to use the old or the new .NET (by new, I mean Core) is by looking at what each gives you. For example, want to run on UNIX flavors? Core. Want Enterprise Services? Old. Want easy integration with C? Old (C++/CLI). And so on.
Thank you! I've also been looking for a tutorial like this.
Wow! Thanks for an amazing answer! It certainly cleared thinbgs up a bit for me. But I do have some questions... * 1. &gt; If you use Bridge.NET - you'll have that .NET Regex functionality out of the box. If you use just TypeScript - then you'll have to spend some time to find and learn a library that provides API similar to .NET Regex. But is that true? How is Bridge.NET able to provide that functionality if it does not compile IL to JS at the byte code level? Or does it? My understanding was that it simply cleverly translates *some* BCL routines (like they say they support LINQ, which is great) to their equivalent JS routines (either existing as part of standard, from 3rd party libs, or hand-written). But since they are not doing byte-code level translation how can they provide me with equivalent .NET functionality? If they do indeed provide that, then clearly there are huge benefits to Bridge.NET because here you can actually save a lot of time and effort. * 2. &gt; You also noted that your code can't be fully ported with dependencies to non-Bridge DLLs. That's true, i'd say it's the biggest limitation existing in Bridge.NET world, but if you have access to source code of those libraries, things become easier. Hmm this is interesting! So you are saying that as long as it is valid .Net C# source code relying only on BCL as a dependency, I am fine and can use my uber-complex custom Linq-like routine I wrote with yields and what not, and it will be seamlessly translated to JS? If that's the case, then again third party libs are in general not a huge issue, since most of them are open source and MIT/Apache licensed, so you can include their sources directly. However, if it was so simple indeed, why wouldn't they provide *full* JSON.NET support for example? If it is as easy as just including the library's source code in the project? * 3. Lastly you mention "portng C# logic to JavaScript - Bridge.NET allows to do that (with some *limitations*)". That's actually what I could not easily find online. Exactly what is supported and what is not, at least as far as the BCKL goes. It is still somewhat of a mystery for me. That is can I just write for instance any .NET Standard 2.0 (for example) code and it will all be transpiled to JS, or I cannot use certain Types/Methods? PS I think you *should* write a book, or at the very least a bog post! ;-) The information you provided is really helpful!
Don't do this. It's not supported in core and quite possibly never will be. Write your applications code first. 
My same very question. I know some people read from DDD book of the concept of Abstract Model/Domain. But interfaces or abstract classes aren't the way to go fo implement an Abstract Domain. Quite the opposite, you push yourself in a valley of sore and pain.
DevOps is about devs taking care of these aspects. Otherwise you just have Devs and Ops. Nothing wrong with it, but let's not mix the two strategies. To be clear, it's ok to have people dedicated to the CI/CD pipeline, but everybody in the team has to have a basic knowledge of the issues and the problems of a CI/CD pipeline and not just push the code into git :)
I’m sorry for you that you learn webforms university. What the fuck. What university is it? What country?
Hehe, “dammit” operator.
While EF Core does not support this exact method (it has other means to work with db first generation), EF6 still has features not supported by the newer versions yet. If you still need those features (like REAL group by support) I see no reason to switch. Also you can use EF6 without a problem with ASP.Net Core as long as you run it on windows. 
&gt; But is that true? Yes. The Regex functionality actually is an excellent example of where the benefits of C# and Bridge become obvious. With Bridge, you have access to the full power of C# Regex class which is much more mature than the JavaScript functionality. Using Bridge and C#, you also have assurances that you will get the same expected results as native. If I remember correctly, [Bridge Testing](https://testing.bridge.net) includes ~20,000(?) of the original .NET Regex Unit Tests. These are the exact same tests run on the native desktop environment but now compiled to JavaScript using Bridge. The results in the browser are the same as native desktop. In regular native dotnet/C#, the IL is the compiler target. The native .NET compiler is converting the C# into IL. With Bridge, the "IL" is JavaScript. Similar to using native C# and compiling for the desktop, you don't really think or worry about the runtime IL code. You write C#, build, then run. It just works. Same with Bridge. You write C#, build, then run. It just works. For the most part, you don't need to worry about the compiler target. Just worry about your C#. &gt; I am fine and can use my uber-complex custom Linq-like routine I wrote with yields and what not, and it will be seamlessly translated to JS? Well, yes. Currently, C#7 syntax is not supported, but that will be included very soon. Linq is fully supported. The [LINQ Support](https://github.com/bridgedotnet/Bridge/wiki/linq-support) wiki doc is a good place to review demo scenarios. Not all of the mscorlib is currently supported with Bridge. There are still some big holes, but we're working hard to fill in what we can as fast as we can. If there's something you require, just let us know and we'll try our best to add support. Please keep in mind, there are language features that just can't translate into JavaScript, or at least we haven't figured out what the equivalent functionality would be in JavaScript. &gt; why wouldn't they provide full JSON.NET support for example? Bridge is getting close to fully compiling the original Json.NET source. As mentioned above, there still some holes to fill. The Bridge team has been working on some other high priority features lately, but we'll jump back on the goal of full native compile of Newtonsoft.Json soon; especially if there is vocal demand from the community. I just wanted to follow-up on a comment from your original post regarding _InitGlobals()_. I agree that syntax is not ideal. The JavaScript pattern required for the initialization of an Electron app is a pattern that doesn't 100% nicely map to C# (yet). I'm not happy with that _InitGlobals_ configuration, but it was required in order to make the app work. We should be able to clean that up in a future release once some new Bridge features are introduced. For now, it's more or less just required once during the app initialization. Hope this helps. Thanks for the questions and interest in Bridge + Retyped. Be sure to let us know if you have more questions and we'll do our best to assist.
You can use this with ASP.NET Core MVC without a problem. This only really concerns that you use EF6 instead of EF Core.
I'm not suggesting that people switch to core. I'm saying don't build new projects using technology that is dead.
This can be worked around in EF6 though by adding the foreign key explicitly though and using that instead. I checked. ;) Also tested what happens if you add both - it will take the entity first, and then the key if not present.
 "A Real Programmer might or might not know his wife's name. He does, however, know the entire ASCII (or EDCDIC) code table."
I believe this will have the biggest impact on the language since... Probably generics. It will remove so much boilerplate safety checks and will improve safety of the code. TypeScript introduced a similar concept and it's just frigging awesome.
Well, it seems like you have already got many answers! I can add that sometimes you can't decide which technology to use, and where I work this method is still widely used.
From my experience, EDMX files are a pain to work with once the database is large enough. I could probably get two coffees just waiting for the file to load. Then two more waiting for it to update from the database. And probably two more waiting for it to save and generate the T4 scripts. It looks simple, fast and easy enough when you start, but suddenly it's too late and you are find youself with 6 cups of coffee on your desk. ^Moral ^of ^the ^story, ^don't ^drink ^6 ^cups ^of ^coffee...
Edmx is no longer available. 
Only in EF Core. But yes, that's a good thing.
Not sure why it's not there; but it's just a folder with some web forms in it. Just make your own. If you're learning development, you'll be doing that a lot. It's good practice to create your own code as opposed to using the generated code. 
Agree
EF6 is not dead, sure it won't get new features, but is still in active development (EF 6.2 should be released soon). Also the "new technology" is not yet a full replacement (the group by thing can really be a showstopper) so it can still make sense to use it even in new projects.
Your University library will likely have access to online training materials such as Linda or Pluralsight. They will have introduction videos for asp.net winforms and they would likely use the templates you mention. There is nothing wrong with learning asp.net winforms since many applications still use this technology. Perhaps your course will begin with this before venturing into MVC so you have a better understanding of the two approaches. If not, be sure to check it out.
EF6 is not dead. DB first is dead. 
No it's not. EF Core also supports DB first. Code first is fine for small single purpose databases, but as it gets more complex and other systems need to interact with the same database I would never give up my control of the database to a generation tool. Also not every data system even is in the full control of the application developer.
When you create the Web Forms application, to the right of the "New ASP.NET Web Application" dialog box you'll see a button labeled 'Change Authentication'. By default it's set to 'No Authentication', click it, select 'Individual User Accounts' and it'll automagically pull in the dependencies and create the Accounts CRUD templates for you.
This is exactly what I was after. Thanks a bunch.
No problem whatsoever. Best of luck to you! Feel free to PM me if you have any further questions.
yeah, let's state something without any argumentation! CF is actually you doing the projection of the abstract entity model to code. Why would you do that? Isn't it better to start with the abstract entity model, like prof. Halpin and Nijssen have taught us all those years ago? 
I'm not talking about generating your database from code. That's horrific. I mean the edmx design model from this article. It has always been referred to as database first whereas the poco model was code first, even though you could and people do use poco for an existing database. Following the instructions in this article will create you a dead end cluster fuck that will screw you. 
DB first is just a way to create the abstract entity model from which you create your entity classes and mappings. It's equally to starting from code and reverse engineer that to an abstract entity model and from there create tables and mappings. That EF doesn't support db first doesn't mean it's useless, on the contrary. Perhaps you work with mickeymouse size databases, but even in a database like adventureworks with 91 entities it's quick a lot of work to write all classes and mappings by hand. 
You will not be able to migrate edmx to core or anything else. There are tools for generating POCO classes that will work moving into the future, but edmx is not it. If you follow the instructions in this article you are fucking yourself because you are not going to have a path forward. Yes annotated POCO classes are more work, especially on large projects. I've done it, including for databases that make edmx choke and die like the piece of shit it is. Nome of that changes the fact that edmx is dead and isn't going to become undead. 
Anyone have any tips on converting an EDMX to a code-first approach?
https://www.reddit.com/r/dotnet/about/rules Actually theres both: No job postings Posts &amp; Comments Reported as: No job postings We don't allow job postings on the sub. There are many other subreddits for this. Self promotion Posts &amp; Comments Reported as: Self promotion As per the general rules of Reddit, we don't allow self promotion posts that don't adhere to the Reddit 90/10 rule 
Thank you very much for your detailed response. I am getting a clearer picture now, although some fundamental understanding of how it works is still lacking (hence a lot of my questions). I hope, being part of the Bridge.NET team (as I understand), you might be able to make a blog post or provide a short background/how-it-works/theoretical documentation that explains how it all fits together on a low level. The main thing I am still trying to understand is what I can and cannot use and why... Take for instance C# 7 features that you mentioned. I presume you meant ValueTuples. So, is this feature not yet supported because it requires a new type to be "brought into" JS World (i.e. ValueTuple) which is not part of the original BCL, or is that because you are actually relying upon / using language features directly (presumably using Roslyn APIs to aid in translation). I really liked your description of JS being just another compile target in addition to IL. However there seems to be a big difference, or at least things are certainly not as simple. The generated IL calls into routines provided by BCL (or 3rd party libs), which is also essentially IL. It thus begs the question, what does the compiled JS call into? Surely not the BCL IL. So then did you make a JS Version of a subset of BCL (hence the limitations on what can be used) which the compiled user JS is dependent upon? If so, are you performing any kind of linking / merging to reduce the size of all the JS needed to run the user code (I mean you only ever use a fraction of BCL's methods and types)? Also, WebAssembly is being rapidly developed. How does Bridge.NET compare to it? Not knowing exactly how you make .NET functionality available in JS this question might not make sense, but wouldn't it be easier with WebAssembly to essentially take existing IL and basically convert it wasm format, thus reducing the complexity of porting .net code to JS on a method by method basis (since I assume that's how Bridge.NET works, but I may be wrong)? Sorry for all the questions, but it would really help the understanding of how it works overall and thus what the requirements and limitations are. Lastly, as a kind of vision I would love to come true, as far as Desktop apps are concerned, is this: Instead of using WPF or even Xamarin Forms, have UI be HTML+JS via Electron (with the incredible ecosystem of CSS themes, widgets, libraries, etc.) while the bulk of the business logic code is in C# and can address (use) everything that's in .NET Standard 2.0 (and hence most of the nugets and 3rd party libraries). Not sue if this is a use case you even considered for your project, or how far you are from realizing this, but that's where I would like it to be. Thank you.
Edmx isn't going to exist in a couple years. This isn't some abstract development model, if you create an edmx model you will be screwed. If you want to complain about the fact that code first doesn't actually mean code first, blame Microsoft, but edmx is going to screw you. Don't use it. 
dbml even still exists and will stay to exist till the end of time. You know why? Because it's part of .NET class library. EDMX is too. EDMX is actually a bigger concept than what EF used, it's the model storage for entity models which are used elsewhere in MS software (e.g. odata, which parts are now in webapi). It will never go away. Is it the best format to store stuff? No. But is code first the only viable alternative: no way. In fact, typing mappings and entity classes by hand is actually absurd: a program can do that for you way better than you can (as it doesn't make mistakes, humans do). Doing the work a machine can do better never was and never will be a great base for job security ;) :P
&gt; You will not be able to migrate edmx to core or anything else. There are tools for generating POCO classes that will work moving into the future, but edmx is not it. Not true. In [LLBLGen Pro](https://www.llblgen.com) I can import an EDMX, and e.g. set the targetframework to NHibernate, LLBLGen Pro Runtime Framework, Linq to SQL, EF1 or higher or e.g. Entity Framework core 1 or 2. Fix perhaps the errors encountered due to missing features in the target framework, and generate code first mappings or other mapping types supported by the target framework and done. Will likely take no longer than a minute. :) &gt; If you follow the instructions in this article you are fucking yourself because you are not going to have a path forward. Sure you do. Even with the EF designer you can generate CF mappings if you want to. The article doesn't use the most modern stuff, agreed on that. But the thing is: most software development is actually maintenance stuff and working with tools and libraries that aren't brand new, simply because they work, or are already in use by the rest of the devs or software you have to work with. Starting fresh with the newest stuff isn't what most devs do. It also isn't required to create great software ;) &gt; Yes annotated POCO classes are more work, especially on large projects. I've done it, including for databases that make edmx choke and die like the piece of shit it is. you do realize EF6 does reverse engineer CF and EDMX to the same in-memory object model, right? So I don't really know what you're referring to, tbh... If you're referring to EF Core + code first then it's really apples/oranges as EF Core is a limited framework. 
Sadly though, it will probably put that final nail in Code Contract's coffin. I wonder if it would make sense in the future to introduce more contract related checks into the compiler.
Migrations are never 'no longer than a minute'. Ever. If you need this article, you're starting a brand new project. You shouldn't start a brand new project this way, ever. As to edmx, try it on something that's not a well designed MS SQL database, see how it goes. Try maintaining it on a DB that changes a lot but which can't be used as is from the model. From a personal example try it with a vendor database that's was built for ISAM, is running through an Oracle emulation layer, has no primary keys or constraints or indexes and almost every field is text and more than a third of the tables are empty. Oh and none everything has been named using the old 8 character maximum from the 1980s. See what edmx gives you from that. CF handles it just fine. 
In this example, the account informations are stored in a database. You just need to change the DatabaseContext to the Postgres one Here's an example for Postgres: https://medium.com/@RobertKhou/asp-net-core-mvc-identity-using-postgresql-database-bc52255f67c4
&gt; o basic email stuff in .net you can use th Not supported in dotnet core ;)
MailKit is awesome. Same thing we are using with AWS SES (simple email service). Works like a charm.
Based on other comments this will certainly be a controversial opinion: **don’t use your .NET entity model to generate your database schema**, especially in more complex applications. I really hate the terms “code first” and “database first”. I prefer to think about data modeling as “model first”. The abstract data model, or ER model. Then use that to design a proper database schema with the correct constrains and naming conventions. Finally write (or auto generate with a tool) your mapped .NET entities. Ome thing that I’ve learned from enterprise development is that the database, including the schema, will long survive multiple application refactorings and rewrites. So it’s important to “get it right”. And luckily for us, the relational model, when “done right”, can survive for a long time. And for the sake of everyone involved, **do not use Entity Framework Migrations**. Use a real SQL-based migration tool chain or some other purpose-built database schema revision control tool.
I believe the future are Roslyn analyzers.
&gt; Migrations are never 'no longer than a minute'. Ever. IF you want to migrate away from EDMX to CF, yes it is. :) Mappings, classes, it's all generated. EDMX can be tossed away after that :) &gt; If you need this article, you're starting a brand new project. You shouldn't start a brand new project this way, ever. While I agree with the sentiment that people should be stopped when they want to use entity framework (sorry ;)), I don't think 'ever' is appropriate. It sounds the same as 'people shouldn't start a new project with winforms', while it works for many people. Not for you, not for a lot, but for a large group of people, who simply have to create software, it can be beneficial to use stuff that's on the market for some time: there's plenty of info available for all kinds of things, tools are mature, lots of people know it so you can ask them if things go south or need to be maintained... &gt; As to edmx, try it on something that's not a well designed MS SQL database, see how it goes. Is it limited? Sure, tables without a PK: nope. UCs? hahaha no. But really, tables without a PK, is that really good design? No. Again, it's not the greatest format, (the format in our projects is much simpler, much more compact and way faster to parse and can contain way more information) and I'm not a fan either, but CF isn't the answer. &gt; Try maintaining it on a DB that changes a lot but which can't be used as is from the model. There are tools for that :) The EF designer from MS is crap, noone should use that one. But there are better tools to work with EF models, which offer rich features, e.g. for database first scenarios, or model first for tables and database first for views/procs/tvfs. Perhaps the better question is: should anyone use Entity framework? The limits it has (both core and older versions) and the lack of performance it offers... there are way better alternatives. &gt; From a personal example try it with a vendor database that's was built for ISAM, is running through an Oracle emulation layer, has no primary keys or constraints or indexes and almost every field is text and more than a third of the tables are empty. Oh and none everything has been named using the old 8 character maximum from the 1980s. See what edmx gives you from that. CF handles it just fine. Interesting, considering CF also doesn't support lack of keys on tables (nor does it support type converters so you have to deal with string types at the class level no matter what, something other ORMs have supported for years). Again: it creates the same metamodel internally for EF6 as EDMX. 
&gt; I've been using it and writing about it for a while, and it's really quite stable now. That's encouraging, thanks! 
First I've heard of [peachpie](https://github.com/peachpiecompiler/peachpie). Seems like a pretty interesting project, I wonder if it will see any kind of widespread adoption over the traditional PHP Interpreter...?
This is a great idea but a terrible design. Whether or not the code compiles depends on how good the compiler's flow analysis is? We have to arbitrarily litter the code with dammit operators to make it compile? What if you publish code that's intended to be consumed by multiple compilers that have different levels of quality in their flow analysis? And its compulsory? All existing code we have today will be reinterpreted as "non null reference types"? This feature ultimately relies on the impossibility of solving the halting problem. Is that such a good idea?
Use the wizard in visual studio to generate code first from an existing database, then delete the edmx and its generated code.
So I don't expose the ef implementation to the outside of DAL. Basically, those are entities that are read only and I don't think it's warranted to add the translation layer when I can use interfaces instead.
OK, I'm probably missing something here... I'm trying to avoid adding a translation layer - the entities in question are all read only and I was thinking of passing the interfaces to the consumers of DAL. What kind of pain can I run into in this scenario?
This is code first approach and the entities are read only. Can I assume I'm safe in that case?
That is a neat project. As someone who enjoys the simplicity and power of PHP, but loves the C# language, this is right up my alley.
It's been around for a while, I keep meaning to try it out on a project.
are you still able to ajax in a HTML content from a Razor view 
Using tools that are already end of life without a compelling reason is not a good idea. Ever. I recently had to deal with some code that broke because a recent Microsoft patch killed Jet. When it was written Jet had been deprecated for a decade. I got lucky and caught that one in test, and it wasn't too bad to fix, but it should never have been written with that tech in the first place. Just because it's comfortable doesn't mean you should use it. 
I tried it a while ago, we wanted to run a WP site on IIS. It worked ok. In the end it was easier to install PHP for Windows. The downside was that meant no c# plug-ins. I'm the same way though. C# and PHP are my two best languages and I love them both. I used to say that C# was the better language (and I think it is, for a lot of technical reasons) but I never catch myself trying to use C# style namespaces in PHP but I do catch myself trying to use isset() in C# all the time, so maybe there is something I'm afraid to admit to myself.
I've never done it from a partial view or anything, but you could move the HTML into a hidden div if nothing else would work. 
I believe it only gives warnings not errors when you assign nulls, so compiling won't be a problem. The idea is that if you want it to accept a null you use the dammit operator to show this. I think if used correctly this could be a real game changer.
Time to overload your string class with an isset() method!
Below is an article I used to write an UploadsController with Upload action for my ASP.NET 4.6 Web API project. Obviously it's an old article but perhaps you could use it as an indirect reference for your Core project. Simply get an idea of C# file upload code in general. https://www.strathweb.com/2012/08/a-guide-to-asynchronous-file-uploads-in-asp-net-web-api-rtm/ 
But I want to use it for everything. Everything! I don't know why, the slap-dash typing in PHP is one reason I don't like it. I think I just got used to using it as shorthand for a null check and a has-a-value check and a key-exists check all in one.
Usually you can put parameters in a separate data object
okay I did that it still seems to keeping the first object in the array instead of the one that I am truely passing in. 
Why not use 2 different kendo windows 
Explain??
Can you post some code?
 $editServicePlanItem.bind('click', function(e) { e.preventDefault(); var itemUrl = $(e.currentTarget).data('servicePlanItemCompleteUrl'); var i = itemUrl.indexOf("MedicalDirectorReview"); if (i &gt; -1) { CS.request.open({ url: $('#editSPI').data('servicePlanItemCompleteUrl') + '&amp;viewMode=' + true, width: "805px", height: "700px", scrollBars: true }); } else { CS.updateServicePlan = $('#updateServicePlan').data('kendoWindow'); $('#updateServicePlan').html(""); $('#updateServicePlan').data('kendoWindow').refresh({ type: "POST", url: $('#editSPI').data('editTimeFrameUrl'), data: { id: $('#editSPI').data('objectId'), servicePlanId: $('#editSPI').data('servicePlanId') } }).center().open(); } });
And I think many will find that unacceptable. There many who treat warnings as errors, and out of those that don't I don't think they want hundreds of warnings. Requiring arbitrary application of syntax in order to prevent compiler warnings/errors is a bad design, no matter which way you cut it.
Then just disable it. Like I said if used correctly this will be amazing. The warnings are only when you assign nulls so I can't see that many instances where you would get incorrect warnings.
Why would you want that?
You can use a different kendo window for each function instead of trying to reuse the same one 
even though it it is the same functionally just different params passed in?
Doesn't support .axml files, so it's not of much use to me at the moment. I think they are expecting you to use Xamarin.Forms.
So what about implicitly-typed variables like var and dynamic? How would this work with LINQ? 
There are a ton of reasons to handle authentication via a database. Just not with plain text passwords.
Just have them route to a common function and assign any outputs back in the routing code, it's easier than trying to break context or whatever other tricks you're going to have to pull to make it work the way you're trying now.
Is it a myth, tho? https://wpvulndb.com/
Well, is it really a myth, tho? https://wpvulndb.com/wordpresses https://wpvulndb.com/plugins
Is it that new ? Ported a personal project (web controlled infrared blaster)!from normal .net to dotnetcore today. Used visual studio, was mostly painless but encountered a couple of issues with json being case converted and colortranslator not being there. Both easily solved Now I have got it running in a docker container on Ubuntu 17.4 ... My windows server VM is now sitting idle..
Even if the latest trends (aka dotnet core) are suggesting it, code first is not always a great idea. Design a solid, stable and well designed database and you will be able to access it from any language. Moreover, edmx was dropped because at M$ they don't care about good tools anymore, they just follow the new do-it-in-a-console trend. I have been into professional programming since 20 years and I tried both core and .net 4.7. At the moment dotnet core is kilometers away from being suitable and desirable for long term production uses. Just try to use postgres or mysql instead of Sql server and you will know what I am talking about. Best solution for now is .net 4.7 on windows or mono (without async calls) under linux.
https://github.com/Microsoft/vscode/issues/35783
Why are you trying to crawl it? Instagram has a public api and you can get the information you want and many more from it. 
Good to know. I knew it was too good to be true. Where do you find the "about" pages for subreddits? I didn't see anything in the sidebar.
Think it's the same link for all subreddits might be wrong though. 
I'm not sure (never thought about that) but maybe some API's aren't available?
&gt; The warnings are only when you assign nulls Incorrect. That's what the so-called "dammit" operator is for.
`var` is unaffected. It's not implicit at all, it's just sugar to save keystrokes, and `dynamic` is sugar for reflection. You'll get the same behaviour as you do now with both.
You should get a next-url in the response, call that to get the next couple of users, and repeat that until there's no "next-url" left. Source https://www.instagram.com/developer/endpoints/ see "pagination"
There's a solid [StackOverflow post here](https://stackoverflow.com/questions/549/the-definitive-guide-to-form-based-website-authentication) about handling logins for web-based applications. It's a bit lower level than the ASP.NET framework, but it lays out good ground work for securely handling authentication. TL;DR: Use a library like [CryptSharp](https://www.zer7.com/software.php?page=cryptsharp) to store the SCrypt hash of the password in your database. When a user tries to login, hash the password again and compare to what was stored in the database.
I don't think Instagram would allow me to use their API for what I want to do. But I guess I could use the api for this certain part.
Because .NET on UWP is AOT compiled to native code using the same backend as Visual C++. The bytecode is only used for the Windows Store to re-compile the app, when the toolchain gets updated without requiring developers to resubmit the apps. https://docs.microsoft.com/en-us/dotnet/framework/net-native/ https://channel9.msdn.com/Shows/Going+Deep/Inside-NET-Native This is already so since Windows 8, https://channel9.msdn.com/Shows/Going+Deep/Mani-Ramaswamy-and-Peter-Sollich-Inside-Compiler-in-the-Cloud-and-MDIL?term=mdil 
Couldn't find anything from the search for this one and it's been stumping me for a few days. Tried several different solutions and tried something that worked for another project of mine but it wasn't well suited here. Any help or advice would be appreciated as the Googles and Reddit / SO don't return any relevant results.
&gt;The issue is that I can't seem to find a way of obtaining the users which I follow. Use their API. https://www.instagram.com/developer/endpoints/relationships/ GET /users/self/follows will return a list of all those that user follows.
It only does if you're doing self contained deployments AFAIK.
https://docs.microsoft.com/en-us/dotnet/core/deploying/ There are two ways of publishing. Framework-dependent deployment (FDD) means that your output will require an existing runtime to already be installed on the target machine. To publish in this manner, you call dotnet build without the -r option. The output is just the bytecode for your application and will run anywhere. Self-contained deployment (SCD) means that the .net core runtime for the platform you specify is bundled with your application, in addition to the platform-agnostic dlls your application code generated. To publish in this manner, your use the -r option with dotnet build, and specify the platform you're deploying to. Obviously, the SCD bundle will be quite a bit larger than the FDD bundle, because it not only includes your bytecode, it also includes the entire .net core runtime. And, of course, the .net core runtime IS platform specific, so that's why you have to specify the runtime if you're using SCD. There are pros and cons to each approach. They're described in the link above.
Instagram isn't going to ask you if you're using their API to look at pretty women.
I haven't used the Instagram API before, but I need to request an access token in order to use it in the Get request here: https://api.instagram.com/v1/users/self/follows?access_token= but I can get the access token but I have to use a redirect url and when I use that it automatically goes to https://www.instagram.com/?code=50911a9e880747a1b38c9dc2*********, because I have instagram as my redirect url. But when I use this code, it doesnt count it as a valid code? Anyone know why?
This is not a good article or comparison. It's flat out wrong in many parts. You really should do proper research before you author an article like this if your intention is to share it.
Oh yeah I see. That makes total sense, the type is marked as nullable so you should check it.
This is a nicely written article, but I feel I should point out that Entity Framework implements the Repository and Unit Of Work patterns inherently, making additional implementations redundant.
Edmx was dropped because it's a terrible tool that requires a huge investment from Microsoft to make remotely usable. To clarify once more. When I say code first I'm using it the way the documentation did, as in poco entities without edmx, not automatic migrations. You can make those work too, and there's a lot of value in them if you do it properly, but it takes a lot of work and discipline. 
The .net core development experience has improved drastically in the last 4 months or so. Before that, it was a pretty constant exercise in frustration. 
why are you using instagram as your redirect url? Of course that isn't going to work.
Warnings%20aren%27t%20errors.%0AAnd%20warnings%20could%20be%20disabled.
Sorry, I'm new to this, what would you recommend?, do I have to host my own site?
I still prefer "database first" approach. 1. Database is maintained separately from C# apps. Database architect is responsible for database schema. 2. Many apps/services could share same database and same tables. 3. In complex enough DB scheme there is probably lots of views, stored procedures and table-valued functions. Some complex queries can't be expressed via LINQ completely. Window functions, "partition over" aggregates, recursive queries, joins with non-trivial matching rules, pivots... And even if query can be expressed via LINQ there are probably lots of such queries in database that are finely tuned for maximum performance with obscure magic over SQL query plans. All that things are often stored in views and table-valued functions. There is no possibility here to use "code first" approach besides truly trivial database scenarios. Any self-respecting enterprise-grade SQL DB is full of finely-tuned views and functions as performance gains can be as much as 100x on large data sets if compared to straightforward queries. "Database first" really is the only option for the quite nontrivial projects especially on large data sets.
Go read up a bit on how OAuth works, but yes, basically the user of your application has to give their ok for you to use a token with their credentials.
What's the story these days around mocking out the context for unit testing purposes? 
Don't and use the in-memory provider seems to be the answer
Kudos to the dev team for listening and responding to the community on this. When I got the update the other day I instantly noticed the orange icon and called out to a coworker to show him. We both agreed it was way too jarring a change and was far less appealing than the previous icon. The new icon shape actually does look better, imo, but the orange was just gross. Excited to see it in blue :)
This. Code first is only good for new or simple sites. Anything real has an existing DB.
The fact that the model is read only doesnt mean 'dont expose it'. Hide your db context, nobody can attach anything. End of the day, it depends on your team size and how badly you want to avoid people being able to do something wrong. But this is not the way i'd go for - refactoring is a pain, as the number of tables grow you have to maintain twice the number of files, etc. 
I have an infant son, and the color of the icon was extremely familiar, as I see it in his diaper every day. In other words, I'm glad they aren't sticking with it.
In-memory isn't a good drop in for a sql database. It's not a relational store and is missing a lot of stuff. sqlite would be a better drop in.
Technically that's an integration test. For complete isolation you'd want to use a mocking framework. I'm not sure it matters much since it is compiled code which is presumably free of defect.
Which browser? Try using IE pressing F12 which should open developers toolbar and then goto network section where you will see all cross icons click on them. Hope this works
No worries.
Fuck dash. Wtf is the point of buying licenses if at any point they can just bump a major version and decide you don't get upgrades anymore. Fuck dash. Can't believe I used to recommend it to people. 
Did you just assume my CVS?
Haha not at all, just a synecdoche... 😜 
Very well done course. /u/megakemp, besides the advantage of writing C#, which is huge, is there anything that puts cake on a se ond level compared to psake and fake? Also, a bit OT, quite a shame that, as of today, one year in since .NET Core went RTM, we still dont have a standardized way of calculating code coverage for .NET Standard assemblies. I've spent the whole night trying to integrate dotCover into my cake script to see how much my NUnit tests were covering my library... 
Great that they listen to the feedback, intriguing that so many people felt compelled to share their feedback about an icon. What a time to live in!
99% accurate. .NET Core is the runtime implementing _the_ .NET Standard, ASP.NET Core just an application framework built on _the_ .NET Standard and therefore able to run on .NET Framework and .NET Core runtimes. 
It's not a game changer. I developed in Kotlin which has this feature. It is nice but in the overall scheme of things it's not that big of a deal on a day to day basis.
I'm really excited about this and I'm actually happy with the way the feature gets implemented, however we have seen this in typescript - it will be long time after releasing the feature to be actually usable - at the beginning it will be just annoying due to lack of support in libraries.
Title should be Debugging in Visual Studio instead of C# (Jetbrains rider for the win!)
Can peachpie be used as a scripting engine inside C# application?
&gt; A few days ago I watch a very interesting talk.. I got this far, then realized this is probably one of those tech blog posts written in choppy English, and it's just not worth it. Here's an actual explanation: https://blogs.msdn.microsoft.com/mazhou/2017/10/05/c-7-series-part-5-private-protected/
It's a really stupid name, IMO, which is very confusing. You'd think it means "private OR protected access" analogous to "protected internal", but it means something else entirely. Having the access level is ok, though, for large projects.
The name comes from C++/CLI, in which "protected internal" is actually "public protected", and what it means is public inside the assembly, protected outside. Same here. Protected inside the assembly, private outside. Unfortunately changing "protected internal" to "public protected" would be a breaking change.
I see this argument a lot. I’m a fan of abstracting away EF so devs can’t write DB queries all over the system. Having all that logic in one place makes it easily testable and easy to track down and change poor performance queries. Also having the ability to switch/ have multiple orms is an advantage. You can change and maintain your DAL without having to update any layers above it. 
What is this 2007 again? Add value, rather than creating yet another bad abstraction layer. Stop blocking your engineers with framework-frameworks and build stuff that matters. The most annoying question I get with MassTransit is "how do I abstract it away so my developers don't need to understand it." You take a day and teach it to them, then you stick with them to help them succeed. Everyone wins. 
My issue with the brown icon is it looks too much like Sublime icon on macOS so when I hit Cmd+Tab I often move to the incorrect editor.
My university had taught me webforms and I just got out of school 2 years ago. In the US. Thankfully, I've learned better and I work with mvc now.
&gt; have multiple orms is an advantage Honest question: what's the scenario where having multiple ORM libraries in a single application is advantageous?
Many folks treat warnings as errors. And if your only defense to "its poorly designed" is "disable it" then that's no defense at all.
On large scale reporting Dapper is far more efficient for a read only task. Also I’ve had multiple times in my career when suddenly the company had realized they need to move from one orm to another and it’s always a mess. A layer of abstraction makes this painless. Also what if you wanted to move from EF /SQL to API based Azure Cosmos(something at my job we might be doing) we don’t have to change any application code because the application code doesn’t care to know how/where the data is handled
Ok until someone writes a bad linq to sql statement and you have to track it down in a large code base. Or Jim writes one query that does A one way. Steve doesn’t know Jim wrote it so he writes it again slightly different and less efficient. Once you start having Ef context everywhere doing their own thing it’s not maintainable. 
I expected your answer. Almost cut and paste verbatim of this argument that's been happening for a decade. Abstraction of a data layer abstraction (ORM) is always a long term fail. It's leaky at best and a downright copy of the API at worst. No need to rehash it here just search for it. I'll show myself out. 
Man no need to be rude to people in a discussion. I would 100% say that it’s not always needed, but on large scale code bases (200+ project ) it would be absolutely insane to manage direct EF interaction. Plus we can deploy our DAL through nuget patching the system with a click instead of a refactor. 
great explanation - thank you :)
This is weird. Copied descriptions: * Internal: access is limited to containing assembly only. * Protected: access is limited to derived types of the containing type. * Protected Internal: access is limited to containing assembly or derived types. Maybe it's that I'm newish to the industry, but this seems off. I would think that these access modifiers would act as filters, where adding more means more strict (a logical AND). Instead, it seems these two modifiers are acting as a logical OR. That is, you can access it both from the containing assembly or outside in derived types. Why not only from derived types in the containing assembly? Maybe that's just not that useful. Not sure. I can see why its current implementation would be useful, but I feel like we've got some vocabulary confusion going on. What would we call something that can only be accessed by derived types in the current assembly, `strict protected internal`? Is there even any use for such a thing, or would it be an anti-pattern?
I've managed huge codebases as well for applications living 10+ years. The successful ones over time didn't abstract the DAL. They did, however, encapsulate behavior through abstractions, and kept dependencies such as NHibernate, EF, Dapper, and yes even dynamic SQL (which is all your ORM is creating anyway) behind the abstraction. Because over time a codebase will evolve, tools go out of favor and new ones fill the void. You can't forklift the entire application to the flavor of the month, you'll break things you don't expect and it will constantly call into question the stability of the system. This is why the annoying uService Architecture moniker but very appropriate design pattern is absolutely necessary. It forces encapsulation at the service level. And you can use the best languages and tools for the time and use case. The Enterprise secret sauce layer is just thousand island. Everyone thinks it's unique and will make them awesome but it's really hurting your team in the long run. And it's the same crap everyone else writes, which is how the ORM was born in the first place. And why Kraft sells mayonnaise, tarter sauce, ketchup, and thousand island. 
I made a website using 000webhosting but now its saying the redirect url is unsafe? So I can't use that now
I'm assuming you need to use https
That little popup when you scroll down reminding you that you can follow the author on twitter is absolutely ridiculous. 
I don't think author should be getting brought in unless you have lazy loading enabled. If that was the case you wouldn't need to include posts either though. If you don't include posts does it still pull it ? 
[Yes it can and here's how!](https://www.peachpie.io/2017/04/evil-eval.html)
Please do and let us know how it went!
Cool that you tried it. PHP on Windows has the added downside of not being all that stable.
Super happy to hear that.
Willdo, nice work by the way!
&gt; Some complex queries can't be expressed via LINQ completely This isn't a reason not to use code first. It's entirely possible to create your base entities using code first and optimize using model builder custom conventions or just plain SQL in migrations. I deploy stored procs, index changes etc through SQL in migrations all the time. 
It's not. Which is why I'm so confused. 
Private protected is coming in c# 8 so you won't have to jump through as many hoops.
Couldn't you just write a join on Blog and Post?
Yeah, those entities belong to you and EF is only making the context class and sql migrations at that point. *May be missing something else it does. 
If you have previously retrieved Author objects from the data store, and those objects are still tracked in the context, EF will automatically include them as appropriate when you access Post objects. This is purely a convenience.
It's additive. You define who can see it. So when you add internal and protected your adding the properties of both. It seems backwards because your think that of these access modifiers as restrictive instead of addativd.
It is using https but when i visit it WoT thinks its malicious for some reason - I have no idea why?
&gt; Protected inside the assembly, private outside. The most concise and clear explanation I've seen. Thanks.
It is not persistence ignorant tho. Furthermore you can abstract additional functionality like pagination, partial selection and a default AsNoTracking behavior. I'd say abstract if you really need to.
I've only used EF Migrations on one project - which has been in production and evolving over 3 years. It has gone really well. I especially like that all I have to do is publish the site, and it automatically migrates the database. I can also deploy an entirely new instance of the site and it automatically creates the database. What alternative tooling is available that gives me that?
You may benefit from putting nginx in front of your app. You can configure it in such a way that nginx buffers the request (with huge upload) and only passes it along to the app server once it has everything. This keeps the app server requests short-lived and puts the buffering work on nginx.
I usually just stop reading a blog post if I encounter this. I want to see a form for subscribing to the author at the bottom of the blog post after I've finished reading it, not half way through and no pop ups.
Thanks a lot. I'll check it out as soon as I find the time. Can't promise gold yet, but take my upvotes for now. :)
IIRC, internal makes it available to friend assemblies (InternalsVisibleTo) without making it fully public.
Doesn't seem very convenient to me, if I don't ask for Authors to be included, I want them all to be null. If I do ask for them, I don't want stale copies ;) I guess its another reason to only do 1 query before disposing the context. 
Thank you! I'd say that what really sets Cake apart is the way in which it integrates with external tools – from how it handles the dependencies to the DSL itself. Also, the sheer number of tools, libraries and services it [integrates with](https://cakebuild.net/dsl/) makes many common tasks easier to accomplish than with other build tools.
&gt;The bytes resulting from the GZip compression are actually binary data. They are not intelligible when rendered, and may also cause problems when transmitted over a network (due to byte ordering, for instance). One way to deal with this is to encode the compressed bytes in base64 Streams of raw bytes don't have a byte order. Even if GZip was dependent on endianess, base64 encoding the output wouldn't fix the problem. In many cases where you'd actually need base64 encoding (e.g. HTTP JSON APIs), it probably makes more not to compress the source data and rely on the compression of the transport protocol instead. 
Then why use EF?
Out of curiosity if you just ToList it right away do you still get the properties loaded ? 
That's the only reason I can see that would cause the Author property to be loaded. Lazy Loading is disabled by default in .NET Core projects, so explicit eager loading is the only thing available really.
First off, I found this article very helpful in understanding how to the WPF TreeView and how to make use of it: [Simplifying the WPF TreeView by Using the ViewModel Pattern](http://www.codeproject.com/Articles/26288/Simplifying-the-WPF-TreeView-by-Using-the-ViewMode) I think that 'breaking MVVM' is really subjective and people can be pretty opinionated about that. That said, at a glance I'm not really sure if your code would work, but I think you're missing what's possible with those HierarchicalDataTemplates (or perhaps you aren't missing it, and simply don't care). And the big part of that is the automatic generation of new items. Take for example a TreeView with XAML along the lines of this... &lt;UserControl x:Class="MyAssembly.Views.TreeContainer" xmlns="http://schemas.microsoft.com/winfx/2006/xaml/presentation" xmlns:x="http://schemas.microsoft.com/winfx/2006/xaml" xmlns:mc="http://schemas.openxmlformats.org/markup-compatibility/2006" xmlns:d="http://schemas.microsoft.com/expression/blend/2008" xmlns:local="clr-namespace:MyAssembly" xmlns:viewmodels="clr-namespace:MyAssembly.ViewModels" xmlns:i="clr-namespace:System.Windows.Interactivity;assembly=System.Windows.Interactivity"&gt; &lt;Grid&gt; &lt;TreeView HorizontalAlignment="Stretch" VerticalAlignment="Stretch" ItemsSource="{Binding Path=BaseNodes, Mode=OneWay, UpdateSourceTrigger=PropertyChanged}" Height="Auto" Width="Auto" x:Name="NavigationTreeView"&gt; &lt;i:Interaction.Triggers&gt; &lt;i:EventTrigger EventName="SelectedItemChanged"&gt; &lt;i:InvokeCommandAction Command="{Binding TreeviewSelectedItemChanged}" CommandParameter="{Binding ElementName=NavigationTreeView, Path=SelectedItem}"/&gt; &lt;/i:EventTrigger&gt; &lt;/i:Interaction.Triggers&gt; &lt;TreeView.ItemContainerStyle&gt; &lt;!-- This Style binds a TreeViewItem to a TreeViewItemViewModel. --&gt; &lt;Style TargetType="{x:Type TreeViewItem}"&gt; &lt;Setter Property="IsExpanded" Value="{Binding IsExpanded, Mode=TwoWay}" /&gt; &lt;Setter Property="IsSelected" Value="{Binding IsSelected, Mode=TwoWay}" /&gt; &lt;Setter Property="FontWeight" Value="Normal" /&gt; &lt;Style.Triggers&gt; &lt;Trigger Property="IsSelected" Value="True"&gt; &lt;Setter Property="FontWeight" Value="Bold" /&gt; &lt;/Trigger&gt; &lt;/Style.Triggers&gt; &lt;/Style&gt; &lt;/TreeView.ItemContainerStyle&gt; &lt;TreeView.Resources&gt; &lt;HierarchicalDataTemplate DataType="{x:Type viewmodels:ParentTreeViewModel1}" ItemsSource="{Binding Children}" &gt; &lt;StackPanel Orientation="Horizontal"&gt; &lt;TextBlock Text="Parent 1" /&gt; &lt;/StackPanel&gt; &lt;/HierarchicalDataTemplate&gt; &lt;HierarchicalDataTemplate DataType="{x:Type viewmodels:ParentTreeViewModel2}" ItemsSource="{Binding Children}" &gt; &lt;StackPanel Orientation="Horizontal"&gt; &lt;TextBlock Text="Parent 2" /&gt; &lt;/StackPanel&gt; &lt;/HierarchicalDataTemplate&gt; &lt;HierarchicalDataTemplate DataType="{x:Type viewmodels:ParentTreeViewModel3}" ItemsSource="{Binding Children}" &gt; &lt;StackPanel Orientation="Horizontal"&gt; &lt;TextBlock Text="Parent 3" /&gt; &lt;/StackPanel&gt; &lt;/HierarchicalDataTemplate&gt; &lt;HierarchicalDataTemplate DataType="{x:Type viewmodels:ChildLevel1ViewModel}" ItemsSource="{Binding Children}" &gt; &lt;StackPanel Orientation="Horizontal"&gt; &lt;TextBlock Text="{Binding NameProperty}" /&gt; &lt;/StackPanel&gt; &lt;/HierarchicalDataTemplate&gt; &lt;DataTemplate DataType="{x:Type viewmodels:ChildLevelLowestViewModel}"&gt; &lt;StackPanel Orientation="Horizontal" &gt; &lt;TextBlock Text="{Binding AnotherProperty}" /&gt; &lt;StackPanel.ToolTip&gt; &lt;TextBlock Text="{Binding YetAnotherProperty}" /&gt; &lt;/StackPanel.ToolTip&gt; &lt;/StackPanel&gt; &lt;/DataTemplate&gt; &lt;/TreeView.Resources&gt; &lt;/TreeView&gt; &lt;/Grid&gt; &lt;/UserControl&gt; In this scenario, if I build up ViewModel classes, I can auto-generate as many items on the tree that I want. For example, I could have an ObservableCollection&lt;TreeNodeBaseVM&gt; that contained objects of type ParentTreeViewModel1, ParentTreeViewModel2, and ParentTreeViewModel3. If the 'Children' property on any of those contained objects of type ChildLevel1ViewModel, those will also automatically generate - but this time, the TextBlock on my TreeNode will bind to a property on those ChildLevel1ViewModel. And if one of the Children collections has a ChildLevelLowestViewModel, then it will be the lowest possible node because I haven't bound ItemsSource to generate children, but yet this different TreeNode will have a ToolTip. The HierarchicalDataTemplates lets me define differences between these different kinds of levels easily. Think about the directory tree in Explorer where there are different icons for Open or Closed folders, or special icons if a folder has been assigned such. Open or Closed could be a Boolean on an object in the tree. If you modify that object, the tree will update automatically. And if you add more nodes to the ViewModel classes and collections, again the tree can populate automatically.
If this is a read-only scenario you can use .AsNoTracking() and it won't automatically stitch up the object graph and add the author in.
this question is about .NET core, not UWP
Not sure if it's mentioned here, but virtualisation is a huge benefit to using Bindings.
Yeah I didn't even touch on UI virtualization, the threading possibilities, anything with that.
That's what include does in the generated sql
Honestly...dont use kendo. Or really anything from telerik. I've *never* had a smooth experience using any one of their products 
It's telerik. They will *always* give you nothing but problems. 
Code First is a terrible name for the concept of defining the mapping in C#. 
It is, but it's what it was called
Yup. Even more confusing. 
It also improves performance by a lot as stitching is generally slow
Without knowing what you're using, I'm going to assume ADO.NET or something that uses it (EF iirc): As far as I remember, when you do something like: using (var con = new SqlConnection(_connectionString)) { con.Open(); // do stuff } ADO handles worrying about the connection pooling. Relevant stack overflow: https://stackoverflow.com/questions/7302299/persistant-db-connection-vs-opening-closing
I'm injecting my services/repositories directly in to the constructor of my controllers, for testing purposes. I'm not using "using", but relying on the Dispose method of the Controller to manually dispose of my services/repositories. Is this "too long" to keep a connection open? Should I even be worried about it?
Almost a carbon-copy of this Stackoverflow answer: https://stackoverflow.com/a/7343623/437768
&gt; Should I even be worried about it? No. Setup pooled/persistant connections and keep the connection open as long as you need it. 
If I remember right, Dapper simply enhances ADO.Net, so the same should apply and it should be handled out of the box. You shouldn't really need to worry about connection persistence or pooling. That being said, you could hit up the docs, I'm fairly sure there are some pooling settings and stuff you could learn about and change if you feel interested. But more than likely it's not necessary. The pooling is based on connection strings, so as long as you aren't connecting with different connection strings each time it should do pooling out of the box. Doing "close" and "dispose" does not close the connections: &gt; Connections are added to the pool as needed, up to the maximum pool size specified (100 is the default). Connections are released back into the pool when they are closed or disposed. Out of curiosity have you actually recorded or noticed any performance impacts, things being slow, etc which you can tie back to that?
I have not noticed any performance impacts from before. I haven't noticed any performance improvements, either.
Bind the tree's ```ItemsSource``` to a collection which represents the roots of your tree and have an ```ItemTemplate``` with an ```HierarchicalDataTemplate``` within your TreeView. The ItemsSource of this template should be bound to a collection within each root model which represents the child elements. An ```ObservableCollection&lt;T&gt;``` is advisable if your tree is not read-only.
This. Opening and closing connections isn't actually expensive because of the connection pool. Let the framework optimize it.
I would recommend checking out Clam AV. We just implemented a large scale file storage and scan process and it's working out pretty nicely. https://www.clamav.net
Please check your website in Edge. The syntax coloring and dropdown top menu does not function.
pluralsight.com
Yes. :D And now Reddit doesn't let me change the link title.
Maybe check out Symantec Scan Engine? Here are some relevant articles: https://www.symantec.com/connect/articles/how-use-symantec-scan-engine-52-content-scanning-technologies-direct-integration-your-appli https://www.symantec.com/connect/forums/scan-engine-1 https://www.symantec.com/connect/forums/scan-engine-licensing https://www.symantec.com/connect/forums/licensing-options-symantec-scan-engine
As Prima13 suggests, pluralsight is great. Signing up for [Dev Essentials](https://www.visualstudio.com/dev-essentials/) will get you a year's access to pluralsight for free. [Microsoft Virtual Academy](https://mva.microsoft.com/) is good stuff too. Now, i'm not entirely sure what you mean by interactive, but i do know that [www.edx.org](www.edx.org) has some .net/c# classes. The most recent class i participated in there was for typescript. Even having read books and watched videos, it was quite useful in that i was able to get insight from others taking the class with lots of javascript experience, as opposed to my c# ways. Good luck !
Here's a link for a decent C# Resource from the ground up, good for the fundamentals of the language and has interactive examples which compile and run without an IDE. so you can play with the code in the browser, and see the results. https://www.microsoft.com/net/tutorials/csharp/getting-started 
Thank you!
thank you!
Thanks for the suggestion. Did you implement as part of a web application? If so, are you just calling a command line to scan a named file as part of an upload process, or doing something else? TIA!
 https://www.codeschool.com/learn/net is an offshoot of pluralsight. 
This might be a dumb question, but what is the difference between .NET and C#? Is C# the language, and .NET is the framework?
Thanks for the info- some of these links are a bit old... current stuff maybe looks like it is now "Protection Engine" https://www.symantec.com/products/protection-engine ...not sure if this is the same thing or not though. I will read more; Thanks again!
Yes. There are several languages you can use for .NET. VB, C# and F# are just three of them.
If you're using dapper, then yes, you should dispose the connection. So: using(var result = connection.Query&lt;int&gt;("select 1")) { var two = result + result; } This returns the connection to the internal pool. The problem with keeping your connection into a singleton or something, is also that your connection could die or get corrupt. Then what? You'd have to create your own ConnectionHelper stuff to make sure the connection is still in a good state. Also, if you look at the [msdn documentation of an sqlconnection](https://msdn.microsoft.com/en-us/library/system.data.sqlclient.sqlconnection(v=vs.110\).aspx) then you'll see at the bottom: &gt; Any instance members are not guaranteed to be thread safe. So if you're multi-threading, you're making it way more difficult and error-prone if you use just one connection object
It is part of a web application, however we offload it to a background process. This is because we never know how large the files will be, so we save and then queue a message to kick off the scan. Well receive an additional message/topic with a pass/fail on the file. So the architecture gets a little more complex, but much more scalable - our IIS thread isn't waiting around. We won't let users access the file until it passes. Also, I believe we're using the CLI to initiate the scan
Nit: they were actually acquired by Pluralsight but existed for several years before.
It's not really a singleton, I create a new instance of my UnitOfWork class for each request to my controllers, and dispose of it on the controller's Dispose method. For some windows services that I have, I'm using "using". 
A Nit accurately Picked however. Very True. 
Microsoft has good documentation, can confirm.
Don't know what your background is or why you're learning .Net but just fyi most C# positions these days are for web development so in addition to C# you might want to look into TypeScript/JavaScript, Angular, HTML and CSS if you think you might go the web dev route. Good luck!
Thanks for the info! That's really helpful.
You must create a new connection for each thread. If you are writing a single threaded component, reuse is ok. If you are writing a multi threaded component, do not reuse.
docs.microsoft.com is what you are looking for
Well the link points to great documentation. But to say Microsoft has good documentation is bit of a stretch. Microsoft isn't the worst but most of the time their explanations and examples are quite ambiguous. 
I thought you only get 3 months free access to pluralsight? Rather then a year? 
Just double checked it @ https://www.visualstudio.com/visual-studio-partner-offers-subscribers/ - &gt; Take your skills to the next level with full-catalog access to Pluralsight’s world-class technical training on all the latest trends and technologies across platforms for one year. 
Virus Total has a private api that allows commercial usage https://www.virustotal.com/da/documentation/private-api/
As are their exams! I agree. I think the entry level examples and labs are good, and I like the example I linked above as a starting point and something different from what MS has done in years past with dry documentation. but generally I have no argument, I still feel that lot of their documentation, online tutorials and labs are constructed by experts in the tech, but not in training. It assumes too much and rarely bites down on the point of the subject matter, which is no help at all to someone starting out in the field. 
Huh, well look at that... I swear this wasn’t there last I looked a month or so ago... Thanks so much!!
[Pretty good assessment test too. ](https://i.imgur.com/t4FSVSA.png)
In EF, the connection is not closed on dispose. It goes to a suspended state which the DbContext will turn to first before opening a new connection. You are right that new connections are expensive, but pooling is smart enough to leave opened connections in a suspended state for some time. The pool itself can have tens of thousands of connections to your database, your context max app pool size by default is 100. The only ill time I have seen issues is if the active connections are not properly disposed, the garbage collector can not restore active connections fast enough. If you start to get time outs or errors related to db connections to a stable server, there is an issue with returning connections back to the pool somewhere in your app. I do not mind this injection, but a controlled query with an enumeration and an instant return to the pool is what I prefer because I do not have to worry about the life cycle of the controller and race conditions on async methods. 
Are there any other examples of frameworks that work with multiple languages?
This book helped me get certified as a C# programmer: https://www.amazon.com/Professional-NET-Core-Christian-Nagel/dp/111909660X
You might want to try not to have abstraction on top of ORM, but rather use Command/Query approach. This way you can use and embrace all the facilities available to you by the library you use for data access and manipulation, without leaking this knowledge to the rest of your application. I'm not even saying about all other benefits of such approach like easy generic implementation of related cross cutting concerns like caching, transaction management, validations, logging etc. (using decorators). Plus you get testability out of the box. 
Follow the tutorial, https://angular.io/guide/visual-studio-2015. I'd put it in the web project with your controllers.
Do you have the .Net Core 2.0 SDK installed? If you have VS 2017, it should already be installed along with it, but if not, you can [download it here](https://www.microsoft.com/net/download/core). You'll also need [nodejs](http://nodejs.org) (but only for NPM.) Once you've got all of those, you can *instantly* bootstrap a complete ASP.net MVC SPA with Angular2+ by running `dotnet new angular` at a command line. Seriously. It's magic.
I have even tried hosting a wix website and getting the code from the url and using this command with curl curl -F 'client_id=[clientID]' -F 'client_secret=[clientSecret]' -F 'grant_type=authorization_code' -F 'redirect_uri=[redirectURI]' -F 'code=[code]' https://api.instagram.com/oauth/access_token But I still get no luck?
in MyProject.Web, your file (files) must be in "wwwroot" folder. I think the easiest way for practice is to make your "node_modules" accessible in your configuration, so you don't have to use webpack yet or make a script to copy your files. app.UseStaticFiles(new StaticFileOptions { FileProvider = new PhysicalFileProvider(Path.Combine(env.ContentRootPath, "node_modules")), RequestPath = "/node_modules" }); 
Used this with my friend one day when we we're checking it out. As an Angular dev, he was able to modify the components that came from the template, and as a back end dev, I was able to work with the controllers. Very nice starting point.
IIRC the dotnet Angular template doesn’t use Angular CLI, which is a bit rubbish because it’s pretty much the standard way to develop Angular apps. I recommend making a .net core web api project, using Angular CLI to setup your Angular app and then sorting out the routing with middleware. On my phone now, but can post more details if you like!
Don’t do this! This tutorial uses ASP.net 4.x. Using Angular 2+ together with ASP.net 4 is a world of pain.
You don't have to include all the files in the project. And you can use the git ignore to exclude files. 
In my experience using ASP.net 4.x with anything more based is a pain in the ass, but if it works for you then cool!
Absolutely. Node was designed to solve problems that don't exist - or have better solutions already - in the .NET world. Mixing the two is a world of hurt. And please, dear god miscrosoft, stop forcing node's buggy bloated crap into visual studio. The more node you put in, the worse it's getting. This isn't a coincidence.
I have a good example. We are using Entity Framework for generate database(code first), migrations. And using Dapper (microORM) for complex queries (with multiple joins, aggregations, grouping etc) Because EF generates quite slow complex queries. 
I guess it is the new generation, trying to share code with VSCode.
any source code for this?
Can you use the angular CLI with this approach for creating components etc..
The in memory provider is only in EF Core, isn't it?
&gt; Use a real SQL-based migration tool chain or some other purpose-built database schema revision control tool. Any suggestions? We've been using Fluent Migrator for a while, but I'd love to know about other options. It's great for handling table schemas but I'm less than thrilled about the way that SProcs, triggers, etc. work in it.
According to Steve Sanderson, that is being worked on.
Cool, I hope so. A big part of the appeal of .net core is that its bringing .net development in line with the rest of the industry, being open source etc Then their Angular template doesn’t use *the* key Angular development tool. Really dissappointing.
I’ve heard good things about https://github.com/chucknorris/roundhouse. I think it does sprocs and such “the right way”. But of course I’m partial to the tool I wrote many years ago and continue to use: https://github.com/jdaigle/Horton.
I'm pretty sure you can. I just use a vscode plugin for that.
Thanks a lot, good point. But EF's UnityOfWork and Repository pretty bad at customize, it pretty good fits for some standard approaches. 
I must be in the minority, but I kind of liked the orange icon. Purple was for Visual Studio, Blue for TFS/VSTS, and a desperate color cos VSCode. 
I mean the fact we have it at all is a huge step forward but the whole concept behind microsofts move is that they will keep moving forward so it makes total sense to expect angularcli down the line
Absolutely! They’re crushing it at the moment, but this just seems like an easily avoidable mistake. With .net core, it’s really not difficult to set things up with Web API and Angular CLI, why not just ship that with the official template?
To me, I don't see it as an oversight or a mistake. I just see it as a "we included it in the second step instead of the first step" decision.
When I’m on the PC in the morning I’ll share a code sample of my approach with you. It’s basically a new .net core web API project with a new Angulat CLI project and a couple of lines of middleware for routing.
I literally set up my recent project as two separate folders within the repository (Web and API folders). During dev this does mean I've got a terminal running npm/Webpack and VS running the API, but it's overall the simplest approach which requires almost no domain knowledge of ASP.Net to get the front end working and vice-versa. Additionally in dev and production I had to configure CORS so that the client can talk across sub-domains to the API, but that's pretty easy in ASP.Net Core.
EDIT: just realized I can do this with a post request, after all, was unfamiliar with the variables attached to Instagram but now I understand. https://www.instagram.com/graphql/query/?query_id=[id]&amp;variables={%22id%22:%221372056252%22,%22first%22:1000}
Sorry the variables screwed up, if anyone seriously needs this just message me!
Yeah I wouldnt mind looking at it! The thing is, this has got me wondering. I am building an app for a side project with a friend and I started on the Angular4 side. I was planning on having a .NET Core API further down the road. I wonder if it's easy to just port an existing Angular app. Is it as easy as dragging my folders into the client-side?
Angular 2 or AngularJS?
Yup. Steps: # Get the .angular-cli file into the project. # because in the .NET template the app module is split into three files, you need to specify the module file to import the component. ng g c componentName --module='app.module.shared.ts' The StackOverflow questions i referred to to get this working. * [1](https://stackoverflow.com/questions/46826352/angular-cli-in-asp-net-core-2-angular-template) * [2] (https://stackoverflow.com/questions/46268181/i-cant-add-new-component-with-angular-cli-in-asp-net-core-spas)
I'm doing this as well. I'm playing with Ionic 3 and after I managed to get it "working" as a Visual Studio project, I had so many issues that I just did this instead. It's so much simpler. Because I still like using Visual Studio, I just use file -&gt; open -&gt; folder to work with the project. Then I have PowerShell open to use the CLI. That said, I did look at the Angular project template with ASP.NET Core and it's very cool. 
Angular 4
Look into webhooks and messaging bus patterns
Bit dated, but OData does this https://docs.microsoft.com/en-us/aspnet/web-api/overview/odata-support-in-aspnet-web-api/odata-v4/create-an-odata-v4-endpoint
Thanks for your reply. What I initially thought was an HTTP request would initiate the long-running process and immediately send response. Then SignalR would push status updates and final result to the client. Would that be an acceptable solution and where do you think webhooks and messaging bus would fit in this system?
Sorry up front of this isn't helpful, as I am not familiar with the exam, but is TFS 2013 still recent enough for a current Microsoft exam? I think 2015 update 1 or 2 introduced the new options for stakeholders and outside access. It might be worth signing up for a visual studio team services account to play around with which should be equivalent to TFS 2017. It is free for up to 5 people. https://docs.microsoft.com/en-us/vsts/security/index also applied to TFS as well.
I think you are looking for a generic repository, here is a tutorial. http://www.c-sharpcorner.com/article/generic-repository-pattern-in-asp-net-core/ here is a project with a repository https://github.com/chsakell/aspnet5-angular2-typescript 
I had to do a few things like this. There are some long task libraries that just fire off to a different thread. There is Akka.Net, which will do some pretty incredible things like service discovery and manage the scaling for you. In the end, the simplest approach was to create a windows service that takes tasks from a database table . You can of course replace the database table with a proper queuing system like MSMQ or RabbitMQ. Then you can either periodically ping the database for the result of the task or you can use SignalR. I think it depends on scalability and the time it takes you to code it. 
Great suggestions, thanks! I am not familiar with Akka.Net. Can you please briefly explain how Akka.Net can help in this kind of system? Your windows service and Queuing solution seems pretty reasonable to me.
Akka.Net is just one alternative solution. It is the actor pattern ported into C#. You would still need a windows service, but there are libraries that can use p2p to scale services without a deployment hassle. I suggest you read up on it if you’re interested, but I personally found it overkill for what I wanted. 
&gt; let some scaffolding generate a backend + REST API per model? (Not auto-generated code) These statements are contradictory. It would not be too difficult to write a T4 template to generate what you want, but it would be a fairly customized thing
Message bus means you instruct a unit of work to happen as a message in a queue. Something processes the queue, like a windows service for instance. The message could contain the callback url for the webhook. Upon calling the webhook you update state in your eve application. You UI monitors that state. Benefit is that you can close browser and revisit a long running instruction at any time. 
If you are dealing with a lot of requests that you can not process right of the bat go the queue route so that you can pile up the work and have a process grind away at it. If you need to kick of a long running process once in a while go the windows service route with a wcf endpoint. On your WCF service place the following attribute to call it and forget about it. [OperationContract(IsOneWay = true)] void ProcessAccountEmail(Guid accountEmailID) The process can either update the database that you poll from the website, you can use signalR, or you can have the process send a text message when it is done -- this all comes down to are you running a process that takes minutes or hours. I have a wcf end point that I expose through a windows service on the server and I expose it through a console app on my development machine -- which makes for really easy debugging. PM me if you want I can send you some sample code 
Sounds like [RESTier](https://odata.github.io/RESTier) might be what you're looking for. Automatically creates an OData V4 service from your WebApi + Entity Framework project. We used it in production recently and its been a pleasant experience. Combine it with Swashbuckle and swagger-codegen and you've got your client SDKs created for you too.
https://www.youtube.com/channel/UCqRcSGcOg7luymd9IbGRYDw
I would recommend not doing this by hand and instead utilizing Azure offerings if you can help it. Of course, there might be budget or management constraints preventing you from doing so in which case you can ignore this answer. Since you mentioned a workflow that needs to happen once the relevant data is provided by the user, Azure logic apps seem like a good fit. You can have a sequence of steps configured which will represent the state transition that your data goes through before finally invoking an API or updating your UI. This enables you to track each stage of operation and redo the ones that failed. If the scale of these inputs is crazy high, you can use a Azure Service Bus + Web Job solution, where the service bus takes care of message reliability, retires and scaling and the Web Job serving the equivalent of Windows service performing your operation. One more avenue to pursue is Azure Event Grid. I have pointed you to the possible solutions and you will of course need future research to pick the best one.
Akka is not at all what you need for this. You need just simple Windows Services/Azure Web Jobs/etc.
The exam document itself says conflicts and says it was updated to include technology from VS2013, but elsewhere it says 2015. The interesting thing is that all of the documents that include stakeholders and feedback, etc. all state that they go back as far as 2013. Regardless, there were only a few questions that pertained to TFS and I'd like to have a broad knowledge of the topic. Knowing what answers wouldn't be applicable is just as good as knowing which ones *are*. That being said, I also need to improve my performance in other areas, so I'm trying to attack this exam in multiple directions.
This should work when hosted as a windows service. IIS, however, kills long running threads periodically.
I started out trying to use razor pages, however it became apparent that there would be too much disorganised files. So I went with MVC which is what I'm used to. I don't think razor pages are ideal for large scale projects but that's just my opinion. 
I think MVC is what you’re looking for. Razor pages just gives you the flexibility of writing simple server-side code on your page. I don’t think it’s meant for much more than that. 
That's what I would've suggested.
It was a honest question. I don't know in which case one would be better.
Use Azure storage queues to post messages to and then an Azure function with a queue trigger to do the processing.
Had heard about Odata, never really took the time to look at it, thanks!
If you're starting a new project, I would recommend that you just build your frontend using something like React or Angular instead and just use ASP.NET to handle requests for your APIs. This will give your users a much nicer experience when using your app, there are a huge number of resources available for building single page apps using these technologies, etc.
This looks interesting, I'll take a look! Did you find it hard to write tests for any business logic you did need to plug in?
Check this out for a quick comparison https://github.com/dodyg/practical-aspnetcore/tree/master/projects/aspnet-core-2/razor-pages-mvc 
Messaging is definitely key here, but you will need more than just that technology to make it work. Sagas are a pattern that does really well for these kinds of problems. https://blog.bernd-ruecker.com/saga-how-to-implement-complex-business-transactions-without-two-phase-commit-e00aa41a1b1b
This seems like a TOS violation, I can't imagine this will be allowed for long before they fix it.
Nope, since it's just Web Api it was easy to add our own Controllers, services, etc. like normal. Then again though, most of our business logic was separate from what RESTier was giving us. We didn't really need any special processing on data entry or retrieval, so we could just leave CRUD to RESTier. If you did need some extra logic around CRUD though, RESTier does provide hooks for doing that in a way that shouldn't be too hard to unit test. [Customizing queries](https://odata.github.io/RESTier/#02-08-Customize-Query) [Customize-Submit](https://odata.github.io/RESTier/#02-09-Customize-Submit)
A blog post on msdn describes something similar with PhantomJS. We’re only swapping out PhantomJS for a real browser. https://blogs.msdn.microsoft.com/premier_developer/2017/05/17/integrating-angular-4-unit-tests-with-visual-studio-team-services-vsts/
What ASP.NET technologies do you prefer to handle the API requests? (I am not the original poster but am curious). 
Razor Pages are part of MVC, so yes they’re ready for production apps - but as you noticed there isn’t much out there to help you get started. You might be better off with MVC just because it will be easier to learn it. What you learn for MVC will make Razor easy to learn, so you’ll be able to switch later. Personally I like the flatter page-oriented structure of razor pages over MVC, and I might go with it for my next simple app.
I just use ASP.NET Core (@ 2.0.x) + MVC.
That xaml looks super complex. I’m not sure how to fix the xaml but what about just moving that logic into a view model class instead? I’ve got a feeling that that would be about 8 million times easier. 
[A comment](https://stackoverflow.com/questions/44971747/publish-to-file-ftp-from-visual-studio-for-mac) here imply [dotnet-publish](https://docs.microsoft.com/en-us/dotnet/core/tools/dotnet-publish?tabs=netcore2x) [work](https://stackoverflow.com/questions/46227732/publish-web-deploy-for-mac-visual-studio-community) with manual transfer through FTP.
You can mix both Razor Pages and MVC together in one project. Both are ready for production. There are a few videos on Channel9: https://channel9.msdn.com that could start you off.
Razor Pages are definitely production ready. If I'm not mistaken Razor Pages is part of MVC. It's sort of like they took MVC and flattened it to make it page centric. It's supposed to be able to anything MVC can. Even on Microsoft's own documentation they have statements like this: "Razor Pages is a new feature of ASP.NET Core MVC that makes coding page-focused scenarios easier and more productive." "Razor Pages is the recommended way to build UI for web applications in ASP.NET Core." - I'm not really sure what they mean by this, but it's there. The best resource for Razor Pages right now is probably the asp.net site. They actually start with Razor Pages before introducing MVC since its supposed to be the easier one to grasp. https://docs.microsoft.com/en-us/aspnet/core/getting-started These days though it seems to be all about Angular/React/JavaScriptFrameworkOfTheMonth + API. With this you'd go with WebAPI, which itself is more in line with MVC than Razor Pages. 
Thanks.. yeah apparently I'm an idiot. The issue was with my web.config.
This quite interesting. Never heard of it but definitely something to look at.
Seconded. Clean code should reside in the View Model; the only thing that should be in the codebehind is the `InitializeComponent();` Subsisting on CodeBehind is like relying on junk food. It might be easy and cheap, but eventually you are going to get one hell of a stomach ache.
It is ready for production, but it find it harder and harder to suggest using razor. When you start needing more power on your frontend, check out Vuejs. When you start using Vuejs, you start wanting more things like web components and maybe webpack. Then you find yourself mixing the two (razor for some pages, SPA for others). Its a slippery slope.
Ya felt the same way after figuring out how to host a WebApi project with them. The trick was just point the website settting to the bin folder. :/
Web API by Microsoft is dirt simple. [HttpGet] public List&lt;Person&gt; GetPeople() { return new List&lt;Person&gt;() { new Person(), new Person() } } That's actually all you need besides installing the right packages to support that. 
That looks great. I don't currently know what is happening there. The technology is doing some things: * The HTTP call / URL is dispatched to a function * The HTTP request parameters and POST data is mapped to your function parameters and converted / deserialized. * Your result is serialized. I currently understand / think at the HTTP / Content (XML/JSON/HTML) level. 
It's actually a very simple user control. I think it just looks that way outside of the Visual Studio IDE.
partly because devs are jumping on Python/Node train. I don't know a single startup that would use .Net
Glad I'm not alone
That's fair, but there are a lot of good ASP.NET jobs at big Microsoft shops. Not everyone wants to work at a startup. 
Sounds like a math problem
Exactly. Serialization is automatic and uses JSON.NET and parameters are just added in the method signature. You then expand the attribute to contain them. [HttpGet("API/Person/Gender/{gender}")]
Perhaps, I have included more code to the example, perhaps it will help clarify what is going on.
Do you have DPI scaling enabled on your PC?
Angular
You may need to use a transform to deal with DPI/DIP issues. See `Visual.PointFromScreen` or `CompositionTarget.TransformFromDevice`, not sure what works better here.
I would stick to core. It's a great place to start learning and for the most part it is less than what exists in framework. So it's easier to start there and see what is also in framework than what isn't in core. If you have visual studio you can create a new web project and get most the plumbing. If you want a place to learn pluralsight while expensive is amazing. 
You should be prepared for C# after spending a little bit of time on tutorials for it's syntax, if you've got experience with other programming languages. For .NET, you'd need to spend a lot of time to get familiar with how to build stuff with it. That's what your school program is going to be for. However, keep in mind that there's a difference between ASP.NET and ASP.NET Core. The schools aren't going to have materials on Core yet, and probably not for a few years. My school took until this year to change from .NET to the MEAN stack as a teaching platform. That's how long it takes to update curriculums. You can still be more prepared by studying ASP.NET Core on your own, just be prepared for some cognitive shift when in class you go back to working on ASP.NET.
I think it would serve you best to learn C# especially if you're going to write CRUD back-end. As for that video playlist you posted, it's dated. Do-able but some conventions have changed and we're up to Razor Pages now. This may help (https://www.microsoft.com/net/tutorials/csharp/getting-started) but nothing beats a good book.
Oh, ok. In that case, a serious answer: the best way that I can think of currently to authenticate users is via DB. I'm relatively junior myself, but had to build a system like this at my last job. Other readers: feel free to step in if you think I'm fucking this up. When your user creates a password, your web app or whatever should create a hash of that password, and a random salt. The DB then stores the hash and salt under the ID created at the same time. In order to authenticate future logins, the user's ID is used to pull up a hashed version of the salt and original hash, and the original salt by itself to create the control hash. You then take the password they entered, hash it, and then hash the concatenation of that and the original salt. If that and the control hash are exact matches, you authenticate the user. Else, send them back with a vague message to try again.
Do some more reading on the data coming from your interop fuction. Coords you get from windows dont normally line up with the position info you used on objects in WPF. 
I'm not sure what about it is complex. It's pretty much just a wrapper around the combobox. Most of the dependency properties on my custom NullableComboBox are simply passed through to the ComboBox.
This might sound like a stupid question, but if you don't have any code that'll benefit from TIA, then why are you evaluating it?
NopCommerce has a bunch of tests. They only switched to Core in the upcoming 4.0 release. 
that is a fair question! 1. grad school 2. other regression test selection tools (such as ekstazi and STARTS for maven/java based projects, and ekstazi# for .net projects) exist with formally published papers detailing their evaluation (which open source projects, % of test methods run, overhead time for analysis, total average time savings across 10+ projects, etc). There are none so far detailing the specs of TIA. Seeing as VSTS is such a huge platform and RTS techniques can bring alot of savings for end to end time, this is good for me and others to know. 
KundenKat is a great place to start. You can definitely head to his tutorial. Just open VS and start following his videos. You will be good.
Look on codeplex before it dies. Most .net libraries that are currently supported have either .net core, .net standard, or something that breaks TIA at this point. But most of them have an old repo on codeplex before they jumped over to github. So not current code but would work for testing purposes.
Sounds like a dpi issue to me. You need to convert between WPF dimensions to desktop dimensions.
[ASP.NET Boilerplate](https://github.com/aspnetboilerplate/aspnetboilerplate) have a lot of tests written for their project.
Don't waste your time... Go to pluralsight and take Scott Allen course on the asp core with the front end subjects of Shawn Wildermith https://www.pluralsight.com/courses/aspdotnet-core-1-0-fundamentals https://www.pluralsight.com/courses/aspdotnetcore-efcore-bootstrap-angular-web-app
I LOVE it. I use it to try out all sorts of ideas and to test out libraries and new language features. 
Thanks. I would definitely be willing to pay for a solid course like this, but does it matter that this is ASP.NET 1.0 as opposed to 2.0? Do I risk learning bad habits for 2.0 or anything?
Not really... Just keep your eyes on security stuff... it always changes, not just in ASP core but in any tech project! You should follow Barry Dorrans (The .NET security person): https://github.com/blowdart https://blogs.msdn.microsoft.com/webdev/2016/03/15/get-started-with-asp-net-core-authorization-part-1-of-2/ https://blogs.msdn.microsoft.com/webdev/2016/03/23/get-started-with-asp-net-core-authorization-part-2-of-2/ https://docs.microsoft.com/en-us/aspnet/core/migration/1x-to-2x/identity-2x Breaking changes: https://github.com/joeaudette/cloudscribe/issues/215 Migrating from asp core 1 to 2: https://www.codeproject.com/Articles/1201881/Mission-Impossible-Migrating-NET-Core-x-to
I also recommend Pluralsight.
Nodatime has a lot of tests. https://nodatime.org/
My suggestion 1) Every request should be pushed to a queue 2) There must be windows service which picks items from queue and starts process in different thread 3) Process should update it's status periodically in DB 4) A separate windows service keep tracking each process's status from DB and update UI using SignalR 5) Once process is finished it should be removed from queue Just for your note, you should have to have a fallback mechanism in place. I mean in case of crash from long running process, it should either rollback previous work or leave system in some logical stable stage PM me if you want me to explain it in more details.
add "website" and keep all your AngularJS code in that folder. 
Cool! Exactly what we settled for now.
My normal practice is to create Context (EE context) once for each API call and re-use it till response flushed back. Example GetList(){ //Create Context //Pass context to one business layer //Pass context to second business layer // In business layer use context to retrieve data } Note: don't forget to dispose context in dispose() method.
This. The whole front-end revolution kind of made razor obsolete imo. You can do so much more with it, and depending on the framework you use, it's usually 'just javascript' which you should know already if you are using mvc. However, setting up webpack or a build tool similar to it with visual studio is a different story.
One of the reasons you are coming up with nothing is because of the Razor Markup Generator. I don't believe it works with VB. MVC 5 was the last that supported VB.Net. My company is in the years long process of rewritting websites from VB to C# when moving to MVC6. There is very little difference between C# and VB currently. Most of our back ends, messaging and supporting dlls are still written in VB. Anything new is written in C#, so mostly our Web UI/APIs. It probably isn't the answer you want. 
You should reconsider and learn C# instead.
Can't, this is for a job
https://www.asp.net/learn Keep in mind that MVC 6 was a pre release name, and it was changed to ASP.NET Core by release (it's not the successor to ASP.NET MVC 5). 
This link appears to lead to just about nothing on Visual Basic...
I see. I haven't used VB since pre-.NET (looooong time ago) so I can't offer any specifics. But in general YouTube and MSDN are good places to find learning videos.
That's the nature of the beast. Learn to at least read C# (there's really not that much difference between the languages). If you're going to be a VB.NET developer, all of the good tutorials, SO answers, blogs, demos, etc will be in C#, so you at least have to learn to read it. I'd also suggest figuring out if you really are going to develop in .NET Core, or ASP.NET MVC 5, and redoing your search with the correct term, instead of MVC 6, as it's not the search term you want. Also, as already pointed out, the product formerly known an MVC 6 (ASP.NET Core 1) had no support for VB.NET, so you won't find any documentation, tutorials, etc, as you can't use VB.NET with it. ASP.NET Core 2 has support, so using that as your search term might help, but you aren't likely to find any from the ground up tutorials. 
Might be easier to buy a VB book.
I'm self taught as well. Far from a pro, but comfortable with making tools at least. I started with VBA, to VB.NET to C# to C# + XAML. If I can recommend anything to you, learn C# and then translate that to VB.NET. Anything that works with C# will work with VB.NET. It's a little like British English vs. American English. Armor and Armour are the same thing, just have to know the correct way to spell it. There is a site: http://converter.telerik.com/ This will help if you get stuck in translation. Example: MessageBox.Show("Hello, world!"); C# Code: if (a == b) { return c; } else { return d; } The website translates this to: MessageBox.Show("Hello, world!") If a = b Then Return c Else Return d End If Hopefully this will help you be able to better translate your code while learning both C# for future work and VB.NET for legacy.
I'm a C# developer who had to use VB on a few projects. The difficult part of VB is the .NET framework functionality, which is common to all the .NET languages (C#, VB, F#, etc). My recommended learning path would be for you to use the available tutorials to learn C#. Once you've got that learnt, just learn to translate C# into VB, which will take you a couple of hours at most.
Do you currently use VB.NET for anything else? What other languages do you currently use / know? If you are just looking to learn the core syntax of VB.NET, then there are lots of tutorials that cover the basics of the language. (the VB.NET for Absolute Beginners series should give you a solid start if you've not used VB.NET before, and there should be plenty of tutorials on ASP.NET MVC 5 out there). Unfortunately, support for VB.NET in .NET Core was only added in V2 to support developers that already had large code bases already written in VB.NET, and made a lot of noise about the lack of support (support wasn't originally planned at all), so I doubt that you'll find much available in the way of books or tutorials. 
John Walkenbachs books are solid. That plus a little google-fu helped a lot. Also learn the basics of object oriented programming to write class modules 
ASP.NET MVC 6 is ASP.NET Core, which is playing catch-up to the full .NET framework and one of the things left behind is Visual Basic. Microsoft is working to bring VB up to snuff for .NET Core, but right now, it's not there yet and any documentation and tutorials up to this point are likely going to be for C#. 
I am pretty fond of this one: http://www.informit.com/store/visual-basic-2015-unleashed-9780672334504 Originally got it from a library, ended up buying the book + eBook combo to use as a reference.
The Telerik converter's pretty great even for using VB down the road. If you can't find a resource on how to do something, find the C# version and convert it.
Check out [this Pluralsight course](https://www.pluralsight.com/courses/vb-fundamentals) You can get free Pluralsight by signing up [here](https://www.visualstudio.com/dev-essentials/)
OData is not ready for .NET Core at this point. If you want to stick with older technology, then OData for Web API or WCF Data Services is basically as you described.
Make sure you are searching for "VB.Net" and not "Visual Basic". Visual Basic is a dead (or at least i wish it was)/legacy language. VB.Net is a Visual Basic style formatting for the .NET framework. it's probably an important distinction to make when looking for tutorials. VB.Net is also kinda on the way out as well now (i think it was introduced to get the Visual Basic users in to .NET with the least amount of learning curve) so i have a feeling you may find the VB.NET is not supported for MVC 6. Failing that C# tutorials will stand you in good stead. it's fairly easy to convert C# code into VB.NET as all of the .NET bits are the same
&gt; will I have an easier time learning Visual Basic later if I just go through C# tutorials instead? Yes. Especially if you have to you have to learn the MVC 6 framework specifically. You will not find VB.NET guides for ASP.NET Core/MVC 6 projects. It's also worth noting that you aren't so much learning VB.NET, but learning the .NET and MVC Frameworks. Both languages use the same namespaces and differ only in syntax. There are even converters that will straight up translate between the two. The problem with that is that they usually don't work on the Razor files. &gt; I can't believe that anyone still uses this language with how little there is on the internet about it. I can believe that people are still maintaining WebForms code in VB.NET, but I would *strongly* recommend against rolling a new MVC project in VB.NET. The reason you can't find resources is because almost nobody does this. In my opinion, your company/client is making a mistake by choosing to roll a new MVC 6 project in VB.
Are they asking you to create an MVC 6 site in VB.NET? The reason you're not finding any material online is [because this is not supported](https://visualstudio.uservoice.com/forums/121579-visual-studio-ide/suggestions/7470103-vb-net-should-be-fully-supported-in-asp-net-vnext?page=2&amp;per_page=20). You can vote on that issue and hope they hurry up. Also note the lack of .NET Core/MVC 6 templates under the Visual Basic language in Visual Studio. [Here's a blog post I found of someone who gave it a real effort](https://dotnetthoughts.net/building-aspnet-core-apps-with-vbnet/). 
GROUP BY is also a gotcha in EF Core 2.0 (it's not supported). And FromSQL in EF Core only supports entity results, not ad-hoc results so there's another gotcha. My advice is to go back to EF6 until EF Core 2.1 is released and hope they fix/add what's missing. There are too many features missing in 2.0 to consider using it in production for any but the most trivial apps. 
You don't. Visual Basic is a joke
Pretty relevant: https://www.reddit.com/r/dotnet/comments/737f1u/best_place_to_learn_aspnet_webforms/
Agreed. You can write COBOL.NET, that doesn't mean you should.
find a job that uses more modern tools
you need to create nested view models that model your tree, and then use that as the ItemsSource for your TreeView you do not create a TreeView in code, this defeats the purpose of using binding and view models
My wildest guess is he's at a job requiring him to do VBa work microsoft applications, VBScript for DTS package, or just some legacy program. I wish that they would at least upgrade the backend to Office applications to .net at some point. The libraries are identical and any time I end up writing VBa I'm looking at the .Net library documentation, just include a second compiler and studio for it.
Probably brownfield work
It would still be impossible for him to port an existing VB.NET MVC project to MVC 6 because MVC 6 straight up doesn't support VB.
Ah I missed the MVC6 part in the question, fair enough!
Yeah, I assume it's a job that has a generic VB.NET web development requirement and OP wanted to start off learning with the latest framework.
As the other commenters are writing, given that you are seeing weird alignment issues that are different per-monitor, what's likely happening is a mismatch between Win32 coordinates (physical pixels) and WPF coordinates (device independent pixels). Here's a document focusing on developing per-monitor DPI-aware applications (and it talks about WPF too):https://msdn.microsoft.com/en-us/library/windows/desktop/ee308410(v=vs.85).aspx What you'll want to do is: * Enable per-monitor DPI awareness * Hook up the callback for when the DPI changes (and the monitor DPI changes) so that you can re-calculate the scaling factor * Compute the scaling factor * Scale the Point you get from GDI by the scaling factor 
Be careful, this project is *still* outputting invalid html with the angular universal ssr. 
Just curious what exam was this?
Where are you going to deploy the apps you build? If youre end target is a Windows machine, just use .NET Framework. If you want to be cross platform (and have an actual requirement/reason for this), then use .NET Core
Hello all, it took me a large portion of the day to figure out, but I got it. I just want to post this in case someone else out there stumbles on the same issue. Here is the solution that finally fixed it for me: var transform = PresentationSource.FromVisual(this).CompositionTarget.TransformFromDevice; var mouse = transform.Transform(GetMousePosition()); Left = mouse.X; // Depending on your application you will need to offset these values +/- Top = mouse.Y; // Depending on your application you will need to offset these values +/- Just take the above code and place it in a dispatchTimer, or you could override the OnRender for the window, something to that effect, whatever suits your application. DispatcherTimer dispatcherTimer = new DispatcherTimer() The *GetMousePosition();* Function is simply the Interop function from the User32.dll import. You can get that code from the (justpaste.it) link in the Original post if you need it. Hope it helps someone. (Note: The best part of this solution is that you do not have to worry about converting units of measurement, nor about how many monitors the end-user has.) This code seems to just work, which is pretty rare. I am guessing most of the work is being done by WPF in the background. I have a dual monitor setup, and it still works whether I turn one display off, or have both running. I would like to know if this works for someone with 3+ monitors if anyone feels like testing and reporting back! Thanks!
This helped me, thank you!
[Software Testing with Visual Studio 2012](https://www.microsoft.com/en-us/learning/exam-70-497.aspx). Unit and coded tests is one of my weak spots in regards to development, so I went in thinking that it would pertain to actually creating coded tests. Nope, it was more about managing them, ha. Don't get me wrong, useful but not what I was expecting. I actually did re-take the exam today, and I got a 809/1000 - passing, and earning my MCSD. I honestly think the first round of questions I got from the pool were ridiculously tough; this batch were seemingly easier.
It indeed was a dpi issue, however, WPF has some methods for dealing with this in the most recent version. You don't even need to do the conversion manually anymore, simply use the correct transforms, and it's all done automagically. 
It indeed was a dpi issue, however, WPF has some methods for dealing with this in the most recent version. You don't even need to do the conversion manually anymore, simply use the correct transforms, and it's all done automagically. 
I didn't mean MVC 6, I just meant ASP.NET. I don't have to make a website for the job, I have to code in Visual Basic for the job and want to practice by making a website.
They’re probably not using MVC - we have numerous older web forms systems that need maintaining or are under active development still.
*cough* an affiliate link, really?
And they called it J++. Then Sun called Microsoft and said they owned the copyright to blackjack, so they made another, superior java with Texas Hold 'Em and [Call Girls](https://www.youtube.com/watch?v=iW0NtG7X8Ys)
Well that was a risky click 
Affiliate link + 13 submissions to other subs? Spam.
Congratulations and well done!
And better generics
https://www.youtube.com/watch?v=OqxLmLUT-qc
https://www.youtube.com/watch?v=OqxLmLUT-qc
Video linked by /u/kr0m: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Google into google? Never type google into google!](https://youtube.com/watch?v=OqxLmLUT-qc)|Laszlo Berndt|2009-09-15|0:00:32|0+ (0%)|596,508 &gt; Never type google into google because you can breaking the... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/kr0m ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=dp6lqm7\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v2.0.0
Generics didn't come until 2.0. Ugh... silly ArrayLists.
From your website: &gt; Try to play DOTVVM Introduction video *Try to* kind of implies that you're not sure the video actually works lol Beyond that, this does seem interesting. Nice work!
Don't forget J# as well!
https://github.com/dodyg/practical-aspnetcore Just code and Vs Code.
That was still before Java's... whatever not-quite-generic thing, though, wasn't it?
Go: there's no need generics
Well I downloaded the project and it won't even compile. File an issue.
This is literally how I explained it a week ago to someone. 
And better lambda expression syntax.
They are not wrong. Properties alone make me love .NET Java is just catching up with its own LINQ equivalent. No more wasteful foreach loops. 
Honestly, I would recommend Pluralsite. If you're not wanting to pay for a subscription you can try Udemy. Plenty of good courses there that go for around $10 when there is a sale. They have sales all the time.
Great. I was looking at that. I think I have that with my Visual Studio Team Service. I'd just rather build a real project while I learn instead of looking at tutorials and I haven't seen any specific to websites in particular yet.
I worked with this library https://github.com/Redth/PushSharp
Yep
Jokes aside, it was really part of the evolution of Visual Basic. You see, between VB 3 and VB 4 they completely rewrote the Visual Basic runtime. It went from being its own thing to sitting very closely to COM. Though painful, it was widely successful. Then in 1997 they released VB 6. They said to themselves, "Let's do it again!" and began work on another painful transition. This time promising multi-threading (without brittle hacks). Around that that Java was becoming really popular so they decided to add real inheritance and fully abstract interfaces as well. (In VB COM, any class could implement the public interface of any other class. Literally everything was mockable.) Then J++ was burned in a fire. This gave them excuse to not only create C#, but also J# (Java ~~1.2~~ 1.1.4 on .NET) and JScript.NET (with zero tooling). Since C++ was important, they also included the first of several C++/.NET hybrids. And thus Microsoft's universal runtime was born.
Check what version of .Net the project uses and make sure you have that sdk installed on your machine? 
I like LINQ too, but that kind of expression dense tightly packed code is hard to debug without rewriting it into a basic foreach format. 
We had a very similar issue with this communicating from ASP.NET WebApp to ASP.NET WebAPI. We had to make a change to our aspnet.config file that the AppPool uses to enable useFlowImpersonationContext. However, since this is a windows service I'm not sure if you have that capability so you can try setting the credentials in your HttpClientHandler like this: HttpClientHandler { Credentials = new NetworkCredential("username", "password") } Where the Username and Password would be an account that has access to the Domain.
That's not how I remember it. MS wanted to include packages inside the java namespace that were outside of the spec. It failed the Java certification because of this.
Warning: this may be pure bullshit. If I remember a blog post correctly from many many years ago, a lot of it started over lunch. Engineers from the VB6 team sat down with engineers from the ASP team. The VB6 team was trying to decide what the next evolution of their product would be. Do they keep the ever-hated VB runtime, or do something new? The ASP guys were similarly thinking about "what's next" in their own evolution. Both teams thought a shared underlying structure / framework would be ideal. Mix that with the work Microsoft had been doing with Java, and J++ they decided to start exploring a Java-like foundation for both.
you can put breakpoints in linq statements and give them full bodies. (though entity framework may cause some issue) Most Linq statements are not that long or complex. If they are you may be doing too much. 
It doesn't specify any version of .NET Core, so I assume the latest should be alright? I'm trying to update .NET framework now, though I don't know if that will solve the issue.
i think i got this error last week and it was i had the latest .net core and my project was 1.1.2. i downloaded the sdk https://github.com/dotnet/core/blob/master/release-notes/download-archives/1.1.2-download.md 
If memory serves, they mostly wanted to provide hooks to the native Windows UI APIs so that apps behaved better than the mess that was AWT/Swing back then.
Sure. Will provide source code during this/next week. I will let you know ;)
How long ago did you work with it? I doesn't look like it has a commit in almost a year on GitHub and it's been forked a lot.
no way of testing this at the moment but you could try to use DynamicObject as a baseclass for your NullPlaceholder. Something like this: public class NullPlaceholder : DynamicObject { public string DisplayString { get; set; } public override bool TryGetMember(GetMemberBinder binder, out object result) { return DisplayString; } /// &lt;summary&gt; /// This is here so that if you don't define a a &lt;c&gt;DataTemplate&lt;/c&gt; for this type /// you will see a blank option instead of "NullableComboBox+NullPlaceholder". /// &lt;/summary&gt; public override string ToString() { return DisplayString; } }
Thanks! That fixed it!
Also is the gateway configured to use Windows Authentication in IIS for that website? 
Hey, I don't make them that long; I just tend to inherit them. :|
I'd back up the Pluralsight subscription and also look into Mosh Hamedani's courses.
Erm, not at all?
You're right. I'm sure I ran into issues when sending direct gzipped binary bytes via RabbitMQ, but can't remember what the problem was. You're definitely right that byte ordering has nothing to do with this though.
Add my vote to both of these. I have done and am still doing a few of Mosh's Udemy courses that I purchased for $10 each...the ASP.Net MVC one and C# ones. Very good. Pluralsight has a brand new one now for ASP.Net MVC with Core 2.0 that looks really good and I will do sometime in the near future.
I think its also important to remember than Anders Hejlsberg was there and probably had some sort of make-things-better mandate.
It's really the type inference that I miss.
I was so glad when 2.0 came out. When through the code base I was using at the time and nuked all the ArrayLists. Best feeling ever(at that job)
and that's why you always avoid 1.x of MS. net core 1.x? meh EF up until ... 6? meh net framework 1.x? meh. and fuck you MS for deprecating the email api
I found this one super helpful https://mva.microsoft.com/en-US/training-courses/introduction-to-asp-net-core-1-0-16841
More then 1 year 
i was there. look up rotor source code. The VB runtime had something called PCode. It was a precursor to the .NET IL. Some of the devs went over to what is known as the .NET team. Internally it was called something else. Rotor was born. it ran on freebsd , not windows. Most of us where unix c developers, only one was (?) frank was java(or some off the wall ML ) For the longest time there was a way to inject __asm into the .net. unfortunately in .NET 4.x they removed that. good times. 
Thanks for the suggestion, I haven't heard of DynamicObjects, and this was definitely an improvement! I changed the NullPlaceholder class to the following (slightly different than what you posted): public class NullPlaceholder : DynamicObject { public string DisplayString { get; set; } public override bool TryGetMember(GetMemberBinder binder, out object result) { result = DisplayString; return true; } /// &lt;summary&gt; /// This is here so that if you don't define a a &lt;c&gt;DataTemplate&lt;/c&gt; for this type /// you will see a blank option instead of "NullableComboBox+NullPlaceholder". /// &lt;/summary&gt; public override string ToString() { return DisplayString; } } I then modified the xaml to use a style instead of a DataTemplate: &lt;ComboBox x:Name="combo" &lt;!-- Wrapper Properties Omitted --&gt; Text="{Binding Text}" SelectionChanged="combo_SelectionChanged" materialDesign:HintAssist.Hint="{Binding Hint}" Style="{StaticResource MaterialDesignFloatingHintComboBox}"&gt; &lt;ComboBox.Resources&gt; &lt;Style BasedOn="{StaticResource {x:Type TextBlock}}" TargetType="{x:Type TextBlock}"&gt; &lt;Style.Triggers&gt; &lt;DataTrigger Binding="{Binding Converter={StaticResource NullPlaceholderToBool}}" Value="True"&gt; &lt;Setter Property="FontWeight" Value="Light" /&gt; &lt;Setter Property="FontStyle" Value="Italic" /&gt; &lt;/DataTrigger&gt; &lt;/Style.Triggers&gt; &lt;/Style&gt; &lt;/ComboBox.Resources&gt; &lt;/ComboBox&gt; This got me 90% of the way there! The right text shows up even when using the DisplayMemberPath. The only thing not working exactly as I'd like is that when the DisplayMemberPath is set, the style isn't set properly on the NullPlaceholder item, so it isn't easily distinguished from the rest of the list. I'm not clear on how DisplayMemberPath works behind the scenes, but I assume a textblock style is defined farther down the visual tree which is causing issue. I'll look into it more and post if I find a solution!
If all you need is a web page, you don't need .NET.
I'm already a web developer. I just want to understand how to develop a website in .net.
These would be a good start: https://www.asp.net/mvc/overview/getting-started 
Thanks!
Hi, I am expecting it to use the credentials used in the windows service so thats why I used UsedDefaultCredentials
&gt; The VB runtime had something called PCode. True, but nobody used it once VB got native compilation (VB 5? I can't remember). The performance difference was huge.
I don't think it is fair to say the VB runtime was hated. It was a dead end because of its close ties to COM, but it worked really well as long as you didn't want stuff like multi-threading. 
Eh, the email api never worked right anyways. It was better than nothing, but it was fundamentally broken.
That reminds me of calling VB 6 COM components from ASP/VBScript. Why did we ever think that was a good idea?
i don't know, that's got to be a good feeling that extends to more than work. fixing things up with static types gets me all hot and bothered, work or not.
No, it was that they didn't include packages. Specifically JNI and RMI (which were bullshit anyways). Adding events to the language didn't help either.
How are you storing your credentials in your windows service? Does it work if you put the credentials in a network credential object? 
That was definitely part of it, but they couldn't base their lawsuit on that.
When you right click a windows service in msc and click properties, there’s an account tab there i think and there’s a field called “Log on as” where we put the username and password of the credential which we want the service to use. We don’t prefer to hardcode the username and password or put it in the config of the windows service. I haven’t tried putting it in the network credential object. I will try it later. Thanks
Yeah totally understand, ideally you would want to do something like that, especially for something outside of dev. I just suggested it to test with to see if that would resolve your issue. 
will definitely do it. thanks! but I’m still wondering why turning on Fiddler fixes it. lol
I would assume because Fiddler is acting as a proxy possibly? In your composer tab and then in options do you have automatically authenticate checked? I know that's how I hit our WebAPIs with Fiddler that are configured to use Windows Authentication, without it I get a 401. 
will check that too! many thanks
Your welcome! Hope that helps some, I ran into very similar issues with getting my impersonation account's context to flow from a webapp to webapi using HttpClient. Unfortunately I've never tried it with a windows service. 
The donkey of an API is back, and just as bafflingly shitty as ever, in 2.0.
MailKit is the *f u t u r e*
Type erasures! So you can say your language has generics without actually being able to do anything cool with them.
This was me when the null propagating operator came out. I had so much fun nuking null checks. It was great.
And they *nearly have `var`!*
&gt; For the longest time there was a way to inject __asm into the .net. unfortunately in .NET 4.x they removed that. Wait, seriously?! That's actually pretty cool.
Java: We give you lambdas, but with checked exceptions! Good fucking luck!
Been using System.CodeDom.Compiler.CodeDomProvider to dynamically generate/link C# code at runtime for years. Works great.
You want me to download an ebook to read that? Get real ...
Right now node is single threaded (which might change soonish) and you basically get javascript with all it's pros/cons. So IMO if you want to go fullstack (frontend/backend) then indeed JS might be the best choice. What C# or Java gives you over JS is the static type system which still makes refactoring and maintenance of your product much simpler IMHO. Dotnet-Core right now is more or less beta - it works but it's not close to be as usable as .net framework or JVM. So overall this all might depend on your goals - even C++ might be the best way for you to go (C/C++ is a great choice) - or you might be interested in Go/Rust.
.net Core released is 2.0, it's now usable in production.
if you wan't to build website, learn JS. if you wan't to build webapp, learn C# and JS. if you wan't to build multiplatforms app, learn C# and Xamarin Forms.
yeah .. good luck
If you want to build a Ferrari, learn JS. If you want to build a tank, learn C#. JS is crucial for reactive web pages in their current forms, and can be used for stand alone applications. In my experience, it does not scale well. Its constantly changing library ecosystem is awesome if you love being on the bleeding edge of shiny things, and hell if you want stability, or if you're in an isolated/offline environment. C# shines for building any other kind of application you can imagine, with complexities ranging for one-off console apps that do basic I/O, to line of business apps with hundreds of interwoven and distributed components. Source: I am a .NET developer by trade, but work with everything from C#, to raw SQL, to message queues, to REST services, to SPA web apps, etc.
There was a whole session about this at Ignite and it was awesome. The TLDR is to wrap your legacy winforms (or whatever) application in an appx package and host possibly host it on a on-prem windows store, upgrade to .net framework 4.7 to fix font scaling / DPI issues, make your WCF 9or whatever) middle layer a microservice and deploy it to the cloud, and put your DB in Azure (yes yes azure kool-ade). You can prob find the session on youtube.
There's also Mono.Cecil. I'm not sure how well that stacks up to today's offerings, but I've experimented with it to build a BF compiler that targets .NET, with some measure of success.
You can build web pages using WordPress and here is the tutorialhttps://www.unanth.com/online-course/wordpress-for-beginners-no-coding-required 
https://www.reddit.com/r/dotnet/comments/7a0we2/how_net_was_started/ If looking to asp.net in hindi check here https://www.unanth.com/online-course/web-development-using-aspnet-in-hindi
It was developed by Microsoft to allow programmers to build dynamic web sites, web applications and web services. It was first released in January 2002 with version 1.0 of the .NET Framework, and is the successor to Microsoft's Active Server Pages (ASP) technology. You can see many online tutorials related to ASP.net https://www.unanth.com/online-courses/search/asp-net
Is there any specific lesson(s) on Pluralsight though? I didn't really see one about building a website/page with .net.
Thank you but I'm trying to learn C# .Net specifically and especially how to build a site. I've been a web developer for about nine years, I'm just trying to expand my skill set. :)
Sounds cool. Any resources in particular you used to get into this? Or perhaps, any code samples/git repo you'd be willing to share? 
if you can provide a running solution with what you have so far, i could take a look at it. 
This is not true in every case and you shouldn't make that blanket statement as fact.
all Ignite sessions are recorded and posted. could you send a link to it?
Heres a PluralSight tutorial I’ve watched that walks through how to create a website from a nee project using common components such as mvc, identity and entity framework. Also goes in detail about the architecture of an asp.net core webapp and explains middleware concepts, dependency injection and services. https://www.pluralsight.com/courses/aspdotnet-core-fundamentals
Windows container for .Net framework are still too big. We speak of 10 gig docker. Still need to convert code to .Net core.
Thank you so much! I saw this but it doesn't even really mention "website" so I wasn't sure. Glad it's a more recent one, too.
My pleasure, I really like the author of that tutorial he’s easy to follow.
I'm actually watching his C# Fundamentals series right now; he's great. :)
I don't know if I see a good use case for a third party library to do what is already built in other than just preferring your files to end in .env. Maybe it's just me but I feel having an env.json is fine if it means I don't have to rely on another third party package. Is there a good reason to use this other than having files ending in .env?
Oh, great, I had been looking for this a couple of weeks ago
I would see this being useful when you only want to have a file with your secrets at dev time, and in other environments you set your secrets by using environment variables that are only present in your infrastructure dashboard (eg azure, aws, etc..)
I still don't see that as being enough to warrant a third party library, the same thing can be accomplished with an optional json file. 
.net core 2.0 is indisputably production ready. There are plenty of talks given by developers from medium-large companies who are using .net core 2.0 in production already. And many blog posts about developers who have .net core 2.0 apps in production at their job. The only thing that might not be production ready in .net core 2.0 is any third party libraries you choose to use, but that is true in every framework, so that shouldn't matter.
My company are using .Net Core 1.6 and 2.0 in production. It's usable and there have been no problems (these are not small applications either).
That's right
Is there a difference between env files and ini files?
On .net core, yes. On full framework, not so much.
on full framework you can use web.Debug.config and web.Release.config to accomplish the same thing
I'm not disagreeing that there's ways to accomplish the same task, but there aren't many ways that work on *both*. Plus let's be realistic, XML config files aren't all that "simple" like json and environment files are.
I see the use. I'm a LOB developer. In our startup code, we have some logic that loads different Log4Net configurations based on the user. We did because devs kept changing the production config when debugging things. This meant we wouldn't have the right logging settings when in production since it would accidentally get committed. It also made it a PITA when working with users, trying to walk support or the user through logging config changes was difficult. We added a but of code to look for a logging file with the username prepended first, then load the standard file so we could just write and drop in the correct file if needed. This would do something similar if you have environment variables you rely on. You can put all the settings for say your dev environment in the file and if you launch your program with a commandline option it will load the dev environment variables rather than you having to overwrite a file as part of build step or manually.
Has there been any word on why they deprecated the SMTP classes? Seems odd that something that at least feels critical wouldn't be included.
I would agree the working on both is nice, but it is just so easy to set up the pre-built config systems on both to do the same that the third party dependency still just seems unneeded. I also agree xml sucks, but it doesn't look like this project supports very complicated assignments, it looks like it only does basic VARIABLE=VALUE stuff and not deeply nested objects which means the xml to accomplish the same would be super simple as well.
If I am reading this correctly your point is this allows you to have different environment variables for production/development, but .net core and .net framework already has that functionality built in. 
I think it may be sort of like JSON.net vs Javascript Serializer. A library came up that had a lot more features and worked in almost every obscure use case, and so Microsoft sort of adopted it. Although I will note, that since then, someone has gone into the official Microsoft documentation and removed the Obsolete remark : https://github.com/dotnet/docs/commit/7ef4e82ea518a756b1a0d1d1684dde15653845aa So maybe it will live on?!
Ah. You make a good point. I had forgotten there was a precedent.
This. The biggest thing that helped me figure this out back when it came about was the realization that the standard just defines what runtimes targeting it have to work with. Runtimes like the .net framework and core target versions of the standard. Make libs in standard, then it can be used across both.
I've implemented Microsoft identity with Google oauth and it was super easy. 
Hi, It is confusing that's for sure. Are you building an API or just a straight-up ASP.NET MVC site? The reason I ask is because JWT is likely your best bet for securing an API, whereas you might get away with Cookie Auth for an MVC site. It might help to split your requirement up a little. For user management (so, user registration, change password etc.) the commonly used options are Microsoft Identity or possibly integrating with someone like Auth0 who will handle a lot of that for you. For locking down parts of your MVC application/API you'll need some mechanism for users to indicate who they are. Then your app can check if they have access to the part of the app they're trying to access. For this bit, you would generally check the user's credentials (username/password) then either a) store a cookie or b) issue a JWT token. Thereafter, you can check for the cookie or the JWT on subsequent requests, and use that to authenticate them (to save them entering their credentials every time). This is where you can roll your own (for simple scenarios, quite straightforward in ASP.NET Core 2) or lean on something like Identity Server. The benefit of going with Identity Server is that it handles more complicated scenarios, but it can be quite a lot to take in if you're just getting started. If it helps, I've recently blogged about issuing [JSON Web Tokens \(JWT\)](https://jonhilton.net/2017/10/11/secure-your-asp.net-core-2.0-api-part-1---issuing-a-jwt/) and implementing [simple cookie-based security](https://jonhilton.net/2017/10/07/a-simple-way-to-secure-your-.net-core-2.0-web-app/). HTH 
Awesome, thanks for your detailed reply. I'll definitely be checking out your JWT blog post as my .net project is 99% API server only.
Thanks!
As far as I know, CodeDOM is deprecated. It doesn't support all language features (eg, switch statements or async/await) and likely won't be updated to support them. I might be wrong. Orleans originally used CodeDOM instead of Roslyn and some features had to be implemented using string templates because CodeDOM didn't support them. That being said, I liked the CodeDOM API when I used it last. I didn't want to mention it in this article because I felt it would be leading people down a dead end path. I only wanted to talk about the "right" answers as I see them.
Don't forget to salt the password. Don't be a Yahoo!
Nice article. Just wanted to mention in your section on IL generation its true that Dynamic Methods have minimal exposure in the debugger, but if you use a MethodBuilder in a ref.emitted assembly you can emit debug data and achieve a much better debugging experience. 
Saving for later 😊
Start by downloading Visual studio community 2017. Pick, "desktop developer", use default settings elsewhere. Make a new console app project (file=&gt;new). See the main function? Write a Console.WriteLine("hello world"); in there.
BTW: I also played around with GraphiQL to get it running for ASP.NET Core: http://asp.net-hacker.rocks/2017/10/26/graphicl.html
This feature is most useful to enforce consistent style across a team. However, because it doesn't run as part of msbuild, it's somewhat useless as the CI process cannot work with it. I hope they fix this one day. Until then I will continue to use the Stylecop.Analyzers package.
Anyone know if there's a way to make these show up as warnings instead of errors?
thanks a lot friend.
While this is nice I fear it will be used by morons to enforce their "standards" that are not even remotely like the normal C#/.NET conventions. I've been using Stylecop.Analyzers personally, where either a rule is applied or not. No custom rules or customisation. 
Also,i heard things like ASP is not used at all and usage of windows forms is falling such kinds. So kindly is it possible for you to list of currently used .net technologies.
you should try Complete ASP .NET MVC Web Development online tutorials and its free. just sign up get started with ASP.net here https://www.unanth.com/online-course/web-development-using-aspnet-in-hindi 
Great. Was looking for something like this. 
Happy to hear that :).
Classic ASP is an old technology and I believe webforms will be deprecated soon as well. Perhaps you wouldn't waste time on those, unless you plan to provide maintenance on (probably) legacy applications. I recommend start reading about MVC pattern. FYI, it's not a MS thing, it's a methodology and you'll see it quite often. After that, it would be good to check on .NET Core. If you plan working with databases, I'd say that it would be a good idea to check Entity Framework. Hope it helps ;)
Nobody wants to hire a spammer
Total of 4 posts, all begging for work... way to engender trust.
Not true. MVC5 with Razor, EF6, and Framework 4.6 is the Dr facto standard for enterprise web apps here in Wisconsin. YMMV.
I would start with CORE 2. It's going to be the future, and you can do almost anything with it. Anything a noob would want to do, anyway ;)
&gt; Anyone know if there's a way to make these show up as warnings instead of errors? Did you even *read* this? All of the examples given *are* warnings. Usage: **options_name = false|true : none|suggestion|warning|error**
Haha thanks for the suggestion.
thanks will check them out.
thanks for suggestions.
I don't have a serious code generating needs, so I still just use tt files.
Hmm my bad, I read on mobile, that was cut off by the screen.
I _do_ have serious code-generating needs, and I also use tt files. In my opinion, tt is an extremely under-appreciated technique. It's easy and straight-forward. Sure, it doesn't support multiple languages; but most developers aren't looking for that anyway. I also you expression-trees for runtime generation.
Good 
I just hope the industry gets to the point where there is no style for any major programming language. There is only correct or not. That the style is part of the language spec. Either that or get to the point with tooling to treat it like the AST it is and get away from the dated column and row treatment we have now.
If you want copious documentation and a well-trod path, choose MVC 5. Much of what you will do with MVC 5 will be directly applicable to Core once it becomes more popular and with more documentation. If you want the latest shiny, but can deal with virtually no documentation or assistance, go for Core 2. Plus, almost all documentation that *is* out there will be for Core Pre-2, which will most certainly fuck up your day because it probably won’t work with Core 2.
Documentation? This guy is starting out, Core 2 will just fuck him up six ways to Sunday due to almost no documentation on Core 2 specifically. Most of what is out there is pre-core2, and will most likely seriously screw with him because it won’t work with Core 2.
Analyzers are better imo, but this is simpler. I prefer the power of the analyzers though. I right even think these are expandable are they? Distribution of team style settings is a little tough and not documented well, but doable with nuget and a little work. This is a start, but I hope it goes the analyzers route.
That is true, however I've found that most of the basic functionality along with best practice design patterns have been layed out nicely in tutorials by microsoft.
If he builds vanilla applications, sure; the M$ tutorials would be an excellent resource. But the minute he googles a question and comes up with 199/200 answers that target pre-v2 Core, he is going to be having a *lot* of problems.
Just here to say thanks: A great new release! I was already waiting for the _convenient_ availability of `.WithCustomDotNetCliPath()` and the new disassembly-diagnoser; not knowing that before the release of v0.10.10 those features were already available (in their master branch) I was unnecessarily jumping through hoofs, or worse, just ignoring the 32bit performance for my hash-algo implementations...
If you want to build a cross-platform app, don't use xamarin forms. React Native is much more mature and forgiving than XF. 
.NET is written in C# Learn C# first so you know how to read the documentation. There are really excellent courses on Pluralsight!
Is there any explanation for why this project still considers itself to be v0.x? Seems like it's relatively mature.
I'm curious why you would suggest Mono after Core? Core seems to be where Microsoft is putting all of its future efforts into.
I'm going to go against the grain and suggest you start with Core. Maybe I'm biased because I'm a Linux user, but there were enough documentation/tutorials/examples for me to figure things out. I actually learned a lot about programming after switching to C#/.NET Core (I'm still a student and started with Python) and now I intern for a company that is transitioning their infrastructure over to .NET Core. :)
Hash the Server Files (Sha1/Sha256/... whatever fits ur needs) Store the hashed values and compare the hashed values with the ones present on the local storage. Or use the good 'ol File-Date ( better not, because of possible downgrades)
True true. By how would I go about comparing files from a computer to files on a server via the Internet?
If you have access to the server, then save the hashed Server Files (ex. http://.../files.txt) Then on start of your Launcher you hash your local files and Download and compare against the Files.txt entries Myfile.res=f1g2h3j4k5 Xxxxxxxx=12344567889
I see. So by hashing we're talking about encrypting the file as a whole correct? I've done basic encryption before for XML files but nothing like this. And the text file, is that suppose to be a table? Why have a table if the files are going to be compared anyways? And in part of the encryption, is the launcher suppose to go through and hash every file? Then unhash them?
Stylecop.Analyzers is amazing for me. It was almost impossible to get devs to install Stylecop
You need to provide a list of hashes server side. The client will then download the list, hash its own files, and compare them with the list it got from the server. Hashing is not encrypting.
Oh. Then I guess I got a point to start from. Thanks. But what about new files added to the server? How will the client dynamically download files that the client doesn't have?
awesome, gonna try it out
The server should dynamically create a list of files together with the hashed values. The client can then check that file and download what ever is missing or has a different hash. Alternatively, you can put a version number on your list and the client can check against that.
Now if I had this setup with the same warnings (as much as possible) as ReSharper gives, I could sneakily add it into the project without him noticing. 
When publishing a new client release to the server, you should be recording the version number of the release and the listing of all the files in the release along with the SHA256 hash of each file. When the client connects, you can cheaply check the version. If it is different, the client should get the full listing of files for the new version and then it can run through all it's local files, generate SHA256 hashes, and compare. If any hashes don't match, then the client should download the new file. You could have the server include the download URL in the file listing so the client has everything it needs to perform the update. Once you've got the basic mechanics down, there are some more advanced techniques once you start trying to scale this: 1) You can look at throwing your data files out on a CDN or the cloud somewhere so clients can download it faster. You could also look into using peer-to-peer for the file downloads to ease bandwidth burden. 2) Instead of downloading the entire file, it may be more efficient to use some kind of remote syncing algorithm or binary delta algorithm if the client is coming from a known previous version. Rsync is the tool for this in Linux but on Windows, I think BITS is comparable. The [Squirrel.Windows update library](https://github.com/Squirrel/Squirrel.Windows) has some support for binary deltas so you may look there for ideas.
Thank you.
Yes absolutely. You would create a single Windows service and during the start event you would launch 3 worker threads or tasks that would do the jobs. During shutdown, you would stop and cleanup those threads.
Thanks.
Would these individual processes fully utilize multi-core processor? In other words, would they perform just as well had they been launched as separate executables?
Makes things a bit simpler. Assuming you don't need any thing non standard there aren't many downsides I am aware of.
There are quite a few considerations whether you go the multi-process or multi-year route. Considering a small scale system, which by your description it may be, you could go either way. The OS can schedule processes, or process threads to span multiple cores. You just have to make sure that you are not locking the same variables across threads and causing concurrency issues. Also note that you have to be careful with exception handling in each individual thread since if one thread crashes, it will crash the entire process, which wouldn't happen in a multi-process architecture. Here's a good article which goes into some detail. http://blogs.datalogics.com/2013/09/25/threads-vs-processes-for-program-parallelization/
Mono is a bitch to debug, especially when getting started.
Sign in with your Microsoft account to visualstudio.com and then sign up for the plural sight trial. They have amazing videos. Start with plain old C#. Avoid asp.net core 1.0 because it's so different to 2.0 and you don't need to be confused. UWP is Win 10, Win 10 Mobile, Xbox, Surface Hub (a business tv), etc.
&gt; different processes in their own threads A thread runs inside a process, what you wrote is off. Every process has at least one thread (the "main" one). Otherwise, what other people said :-).
I use topshelf, it's really easy to create a service without worrying about the plumbing. As an advantage the exercise can also be run in regular interactive mode which is handy for debugging. 
Others have mentioned hashing the files' contents and metadata, storing it, and comparing them. That is indeed what you should do for this task, but instead of implementing it manually yourself you could use a reliable, efficient tool like `rsync` that does the same thing and can do it remotely. It is a command-line tool, but there are libraries you can use programmatically in many languages that do the same thing. You'll have to decide which one in this area works best for you. There is the fairly canonical C library [`librsync`](https://github.com/librsync/librsync), but you could look at C# implementations like [`Octodiff`](https://github.com/OctopusDeploy/Octodiff). The fact that this is the functionality you are looking for is more important than the particular choice of implementation. It works efficiently in that it only downloads the diffs in the files you need rather than the whole thing. That should keep your bandwidth down quite a bit on updates.
Thanks. I'll check into it.
Yeah use it, it's rad. 
hashing is not encryption, it just basically extracting a "fingerprint" for each file. The fingerprints are small and can be trivially compared by the client with hashes generated from what files it has locally.
I'm already confused seeing your confusion.
thanks for your suggestions.
thanks man.
thanks for suggestions,I downloaded VS community edition,will singup for pluralsight this week
I'm gonna start with c#,thanks for your suggestions.
thanks for your suggestion,will start with c# and will ick up mvc5 as soon as I learn basics of c#.
I also recommend it, it's nice. I prefer to write my code as abstracted away from Windows Services as possible, so I effectively put all my logic in it's own "worker" or whatever you prefer to call it, and call that from my `main` this means I can run my stuff as a Windows Service, a console application, and on Linux with something like systemd too.
I wouldn't build a windows service without topshelf since I started using it. It is too easy to use and flexible.
The whole analyzers system in msbuild is great and works real nice with vs2017. One of the best features and they haven't really talked about it. It's flawless. Now we need a less complicated way of producing custom analyzers on a company level, because writing them on our own would be a development project on its own. We need a way to pick our custom collection of analyzer rules and dump them in a private nuget package
I'm doing this one and it seems good. &gt; "Building a Web App with ASP.NET Core, MVC 6, EF Core, and Angular" The advantage of this one is that he goes through the whole process - there's basically no assumed knowledge (except how to navigate Visual Studio). Others have warned you away from .NET Core 2.0 but given how easy it is I'm not sure you want to fill your brain with information on ASP.NET w/ MVC 5 only to have to relearn .NET Core 2.0 (or 3.0 down the line). It all depends on how much time you have available to invest in this.
He was the main architect for the language, in fact *the* architect. He created Delphi while at Borland. Microsoft poached him from Borland with a $20m sign on bonus. Borland was pissed and sued Microsoft. Settled out of court.
Topshelf is great, but if you’re using .net core and considering platforms other than windows you could avoid writing service code entirely and use something like nssm to serviceify a long-running process. This decouples the service logic from the application, which can be nice.
That's what she said.
It is my understanding that all of the things you want to focus on are going to be the future of .NET, but Microsoft seems to be in a transition period right now with getting the new framework up to feature parity with the old framework. The tool chain also seems to lag behind a little bit too. That being said, .NET Framework and ASP.NET MVVM probably aren't going away anytime soon. Or, at least, ASP.NET MVVM probably won't. So, there are merits to learning both, but if I was in the class them I would want to learn the curriculum that you want to teach. 
You can also do that by separating your worker code into a seperate assembly and keeping the host really light. Just a handful of lines of code if you use topshelf. 
You can figure the legacy out if you know how the new one works. Off with wcf and forms and wpf. In with uwp and .net core. 
Make compromises with him. .NET Full or .NET Core 2 -- same APIs, both are fine, but .NET Full is a bit easier to use still (tooling). ASP.NET MVVM -- nope, that wasn't much popular (ASP.NET WebForms or ASP.NET MVC is more so). WPF -- maybe, but know PWAs are on the way, maybe pushing UWP aside. microservices -- nope, that's an optimization and without understanding of distributed programming models, will be hard to grok. Winforms -- still good to learn as its dealing with the nuts/bolts of the OS. REST -- if you aren't statically linking, REST is the API of choice by far shot.. I only use WCF for strange SOA/ERP integrations (Sockets, old SOAP/ASMX, etc).
Neat! I do the same. For me I use an IOC container to resolve my worker (and its dependencies) from the main entry point. This makes it easier to unit test just the worker and mock the dependencies.
Definitely teach ASP.net core - it's similar enough to the full framework asp.net that anyone who knows one can transition to another, but will also let you teach things like netstandard. I think as others have said, meet him half-way. Drop WCF, but maybe keep WPF (or convince him to move it to UWP).
Thanks for your feedback! Microservices was mostly thought of as an introduction to cloud-computing and containers, so nothing too technical when it comes to architecture. But you're probably right that it's not the best fit for an introductory .NET class! 
In my opinion, Core its pretty much the same, it would be nice if you can teach Core, but student can make the transition later also sometimes schools and jobs are still using versions before framework 4.5 and MSSQL 2008 because the software's licenses are expensive. its hard to downgrade your knowledge when you are used to the last version.
Indeed, micro services seem very out of place in that list.
I work for a medium sized payroll company and having good success with entity framework core, angular 2, bootstrap 3, and .net core web api.
Yep! This is literally 100% the approach I take too. Thought sometimes I do DI without the external container and wire up the composition root myself, but yeah I agree. It's a great way to do it.
WCF, WPF, WinForms and SOAP have all been sunset by Microsoft. They _used_ to be the marquee frameworks for .NET developmemt (in the Windows XP/Vista/7 era), so there are a lot of systems out there that leverage these frameworks, especially if they were developed in 2000-2010. Developers in 2018 may even need to do new development in these frameworks if they are working at an enterprise organization that depends on these legacy systems. But Microsoft no longer updates these frameworks. You'll never hear a peep about them at a tech conference, and good luck finding a training course in these topics. *The job opportunity for these frameworks is low.* The only jobs for these frameworks are for maintaining (or, at best, extending) legacy systems. (This doesn't apply to ASP.MVC. That continues to have a lot of new development.) I'd say learning .NET core is valuable. The skills they'd learn would be portable to legacy .NET, *but they're also portable to other development stacks.* .NET core development is a lot more like Ruby/Node/etc. development, with its use of packages, hardware agnosticism, etc. .NET in early 2000s was in a bubble isolated from the rest of the development world, and the whole point of .NET core was to make .NET more competitive with these other (more popular!) stacks.
My solution to this is the laziest one, “Well, I guess, going forward, we use whatever the StyleCop defaults are.”
I think that's a pretty tall order given their experience. A professor I had used to say, "Beware of the student who has taken two programming courses. They know just enough to get themselves into trouble without realizing what they don't know." I think you're going to be shocked at how poorly they understand OO principles.
Actually, I sort of misspoke. It's not so much .Net Core 2.0 that isn't ready as it is Entity Framework Core 2.0 that is undeniably not ready.
TBH, you're right that .NET Core isn't at parity with .NET Framework. If I were an architect designing a brand new enterprise application, I'm not sure I'd be confident enough in .NET Core to dive in that direction. That said, the recent introduction of .NET Standard (code that can target either .NET Core or Framework) means that you can mix and match, easing the transition. By 2022, I'd be amazed if the .Net Framework would be considered anything other than legacy by Microsoft, what with their focus on web/mobile/cloud.
TIL about PWA. Jeez, sometimes I feel like I'm getting too old for this... I keep giving Microsoft slack for being in a transitionary period, but I wonder for how long I'll have to do it. :p
You'd recommend WinForms? Are there companies that still want ol' desktop .exe programs? I thought everybody just wanted browser apps and mobile apps nowadays.
Its more about low level: pinvoke, window events, memory mapped files, unicode vs ascii interfaces, COM interfacing, pointers, etc... throw in some drag-drop fields onto forms for fun.
Are you talking about creating a separate Class Library to contain the core code in? If not, can you elaborate a little bit? Although at this time this will be strictly Windows, I may have a need to install this on Linux in the future so it'd be nice to kind of future proof this. 
So are you suggesting creating this as a Console app and then having the Windows Service part built with Topshelf and then it "calls" the exe?
UWP is the main Windows client platform. PWA is only an additional option.
For what it’s worth, if I were taking the class, I would prefer your curriculum 100x over his topics.
&gt; PWA is only an additional option Sure, PWA is premature but something all platforms are working on right now. UWP is definitely more rich, especially with holography namespace. UWP &gt; WPF if they really want to teach one of the two. &gt; Winforms are legacy and should be dropped. They have nothing to do with the nuts and bolts of the OS. I bet to [differ](https://stackoverflow.com/questions/28564201/scrollinfo-pinvoke-from-winforms-c-sharp), Win32 / COM is not legacy (UWP is based on COM).
You can use Win32 and COM without ever touching Winforms, which is only driving legacy UI controls that shouldn't be used.
https://www.hangfire.io
https://www.hangfire.io Is pretty decent. The only downside is every minute is the most frequent it can be scheduled. Really easy to get up and running on a web server. I have not tried it with a Windows service. Or https://www.quartz-scheduler.net Setup is more complex, but works very well once you get it working. We have been using this one for years in our Windows services. 
Sure, as you can touch Win32+COM without ever touching Winforms, that is probably OK. Like I said, this is about compromises -- if the other professor really wanted to teach Winforms, that wouldn't be awful. GTK#, Xaramin Forms and console handles most of the non Windows environments.
Microservices and containers are dangerous subjects. Microservices especially are rather irrelevant if you're not doing Netflix level distribution because keeping track of them and setting the right architecture up is a speciality in itself. Docker is great for a lot of things, but if you're doing .net core then you might as well do azure web-apps where docker isn't really needed. Decent subject though. What will really help your students in the real world is teaching them how to build ADFS integration, with tokens, saml and ws-trust, as well as teaching them enough devops to actually deploy a functional project in the real world. Half the freshly educated people I meet today can't even get a project running on an IIS and most only know azure by name.
Oh, you don't know what you missing with dot net core! It's a really good framework, it's just a little behind on features compared to regular dot net.
From a learning perspective, I think teaching the full framework is the correct way to go. You're introducing people to .NET, not teaching them the cutting edge. Education has always been a ways behind the hottest and newest because the goal is to teach proper thinking and process at a language-/framework-neutral level. However, I think the key here is to teach it with *current best practices and principles* in mind. Good programming principles are fully transitional, so if a person is accustomed to doing it the correct way, they won't have any trouble moving from full to core because they will understand how the language works, they will just need to find the correct utilities to make it happen in core. If you taught it the other way around, you might end up with programmers who discover crutches and never go beyond the path of least resistance. In my experience, that leads to the sort of person who still does everything the same way they did a decade+ ago because they rationalize "if it ain't broke..." While it's ok sometimes, I find it often creates blinders towards what advances have to offer (testing, portability, maintainability, etc).
You can do a number of things, ive written management console snapips (mmc has. net wrappers), also simple command line parameters, additonally ive used remoting (before wcf days) and used message/command class passing. 
For the first part, any web front end works. For the second part, assuming your windows service is running on a separate machine than your web server, you can't directly make the web front end communicate with your service. You need an intermediary, like a database or service bus. The user updates the configuration using the web UI which updates the values in the DB. The Windows service periodically polls this DB to get the current set of configurations, instead of reading the configurations from a config file.
Ah you got how I feel bro thank you, you just saved me from lot of confusion.
Oh, my preference is definitely for .NET Core, even coming from a traditional .NET background. And most of the popular libraries that I use (Ninject, AutoMapper, NLog, etc.) have great Core implementations (and now Standard implementations). It's just that there are also occasional libraries (especially third-party plug-ins that don't get updated) that have no Core implementation (and probably never will), and it's those that you miss out on. Of course, I expect that those unsupported libraries will become less and less relevant as they get replaced.
If youre building more than web, spin up a mvc web app that connects to a database that holds your variables and create multiple web tools for the apps or find a way to point individual web tools to the app.config. If youre running top shelf (or services ) in general they need to be restarted to read the app.config so they may be better has scheduled tasks running console apps or you need to switch to db variables and have the service read the db each time. 
I think UWP should be touched on and Xamarin mentioned as that is where Microsoft is showing love in terms of .NET client development. I think ASP net core is definitely the best place to "replace" the old syllabus, it is the best to learn going forward.
Hangfire and Quartz already got a mention but [FluentScheduler](https://github.com/fluentscheduler/FluentScheduler) is worth a look as well.
&gt; But Microsoft no longer updates these frameworks While these products are considered "mature" status, they still have delivered updates. Just look at the release notes.
Thanks for the ideas. With all of these options, it looks like the schedule is hard coded in code. With these options (Fluent, Hangfire, and Quarz) can an external config file (or even a database) be used as the schedule definition?
Teach new stuff if you can, I'd appreciate a teacher who did that. But don't worry about applicability, they should learn concepts.
I agree with this mostly, except for uur part about Winforms and WCF. WCF still holds an immense edge over most REST frameworks tooling and feature wise. While I fully agree that REST is the way to go for external API’s and API’s that are consumed from websites, WCF still has a lot going for it for internal communication and enterprise integrations. Winforms has little value in my opinion. You sometimes have to maintain the code, but the programming models behind it are long dead. Nothing to learn there that you cannot learn in other, more relevant Framework. Another extra vote for not doing micro services. That is really advanced stuff. And require a lot of insight in monolithic applications before embarking on that voyage. Also, I’d advise you to include some decent data access patterns in there. At least one ORM (EF is fine), and at least something more direct (raw ADO.NET or a micro ORM like Dapper). What is also valuable is a DI Framework. Ninject, while not too great for complex workloads, is a great way to learn about DI. With that you should take the SOLID principles into practice with repositories, unit of works, etc. And if you have time left, a unit testing Framework and a mocking library.
It's definitely going to be the future, and it is definitely the best framework on the market for personal projects right now. The lack of ado.net entity data model reverse engineering and visualization support makes it a second place offering for enterprise web development as opposed to the very mature to Framework 4.6 and MVC 5. I strongly recommend learning Core 2.0. It's amazingly well architected. However, there are still undocumented defects in the code and it does not have feature parity with MV5/Framework 4.6 yet. I plan to migrate the ASP.NET projects I maintain to Core in a year or so, probably after the next major version release.
You can use a database for scheduling with quartz for sure. We have built some pretty dynamic schedules for reporting that are all data driven. I am sure you could with hangfire too. Since it uses SQL on the backend. 
The most confusing thing is the DI framework. Dependency injection is certainly not a newbie friendly topic. ASP.NET Core 2.0 MVC uses DI extensively (that's why it is better than ASP.NET Framework 4.6 MVC5). Understand the dependency inversion principle, understand dependency injection, understand object oriented containership. These are the hard concepts for newbies in ASP.NET Core 2.0 that are not found in ASP.NET Framework 4.6 MVC5.
Naturally, it's up to you to load the schedule from a file or a database and pass it to the scheduler just where you'd hardcoded it otherwise.
As per the response above, that's not what he meant. You should may be keep your platform/host-agnostic stuff in a separate assembly and reference it from the hosting app assembly, in this case the topshelf-based executable "shell". This way, if you want to reuse your stuff, you have that nice clean assembly without extra dependencies.
To expand, MVC stands for Model-View-Controller. It derives from SOC (separation of concerns) ideology, which is step fly related to the SRP (single responsibility principle). The SRP asserts that every object in the code document object model (Code DOM) shall be responsible for one thing. This is open to interpretation but a good heuristic is to look at the name of the method/class and answer this question, "Does this method/class do and only do what it's name say, and is this the only place in the codebase that thing is done?" If the answer to this question is yes, you are SRP compliant. SOC is an abstraction of the SRP. Where the SRP applies to individual pieces of logic, SOC applies to modules (groups of related classes). Applied to webdev architecture, it asserts that JavaScript, HTML, CSS, C#, and SQL should be written in separate files. MVC is an architectural pattern implementing SOC. Models encapsulate data definition. Entity Framework encapsulates data manipulation. Views encapsulate programmatic HTML generation. Css and JavaScript are stored in separate folders. And controllers glue it all together. Controllers are simple types. They have one method for each endpoint in your hypertext transfer protocol (http) interface. These methods should be short (under ten lines). This method constructs a model, them calls View, passing the model as a parameter. The framework takes care of the rest of the HTTP response. It's automagical. If you find your controllers getting big (greater than 10 lines), it's time to make a viewmodel. Viewmodels are container objects, encapsulating models and business logic. If you have complex business logic, break it down into viewmodels. Use inheritance, polymorphism, and design patterns extensively when building your viewmodels. They for the bulk of your application logic.
I wrote a response for you but put it on the comment above yours -- check the comment tree :)
This information is consistent with my experience. I plan to migrate to Core on the next major version number release.
.NET Standard is an interface implemented by .NET Core, MONO, UWP, and .NET Framework.
Here is what I teach..... Win Forms - simple interface, at the beginning I am focused on teaching them to write excellent code. the output is of minor concern. Forms + ado.net and SQL. So many jobs still requre SQL so DB back end and DatagridView display. Simple CRUD application Movie rental project. Forms + Entity framework - Now the ORM comes in (would like this section in UWP) Xamarin - Coding is down pat, so now we can look at the interfaces. SQLlite db. ASL.net mvc5 - quick and easy for the students to pick up, yay for EF scaffolding. Still very important in industry, its the benchmark. ASP.net core - DI rocks. 
Hashing is taking fingerprints. You take the most significant bits of a binary stream and describe them. If it has a different fingerprint it is guaranteed to be different. If it has the same fingerprint it is 99.9999999999...99% likely that both are indeed the same.
Came here to say keep WCF. Happy to see I'm not the only one.
I stand corrected! I see they actually added High-DPI support to Forms with .NET 4.7, and they are doing some performance/security updates for WCF. I think "mature" is a good description. They're stable, well documented, and MS performs the necessary updates to maintain their compatibility, but they're not going to be seeing any innovations or updates. If one needs Windows desktop programs or network services running on Windows Server, then they'll do the job.
ASP.NET is not an MVVM framework. It is an MVC framework.
Quartz is nice.
I dare to disagree. My perspective (Central Wisocnsin) is that enterprises are abandoning WPF and WinForms en masse and moving to web applications. Knowing ASP.NET Framework 4.6 MVC5, Entity Framework 6, SQL, JavaScript (ECMA standard v.5 or v.6), HTML5, CSS3, and optionally a client side framework like React or Angular is the best way to be marketable as a webdev. For desktop apps, Electron is industry leading. For mobile apps, either Xamarin or Cordova.
That's a good toolset. Are you doing code first or database first?
Yeah, that would work too. I try to adhere to the Unix design patterns/SRP for applications and rely on external processes for process management, log rotation, service discovery, etc. rather than having that stuff baked into every app. The architecture is really dependent on particular use cases, but I typically prefer more small apps to fewer big ones.
Yes, and MVVM is a common convention used inside ASP.NET MVC. 
Nuget.Configs are additive and so you could add a local location for testing packages in a Nuget.Config at a higher folder outside the git repo folder. The settings in there would then be added to the Nuget.Config settings in your git repo folder. This way you avoid adding the local folder nuget repository to your Build and Test Servers. Also you don't need to have a direct link to the package or even the package name in the key. Just point to any random folder and name it whatever and it will pull all packages in folder as if it was nexus or nuget.org. &lt;packageSources&gt; &lt;add key="nuget.org" value="https://api.nuget.org/v3/index.json" protocolVersion="3" /&gt; &lt;add key="Contoso" value="https://contoso.com/packages/" /&gt; &lt;add key="Test Source" value="c:\packages" /&gt; &lt;/packageSources&gt; There is also a global cache for Nuget which is always checked first so you could put your test packages in the global cache. 
Thanks a billion for the feedback so far guys! It is very valuable to me! So far I'm leaning towards trying to convince him to go down the path that I've outlined in my post! I'm still looking for more great arguments for either side though, so I can have a healthy discussion with him next week! Again, thanks a bunch!
Thanks a billion for the feedback so far guys! It is very valuable to me! So far I'm leaning towards trying to convince him to go down the path that I've outlined in my post! I'm still looking for more great arguments for either side though, so I can have a healthy discussion with him next week! Again, thanks a bunch!
I get that, but I simply can't figure-out the command to "install" (to use the Maven term) package into c:\packages.
"Nuget restore" will pull down the dependencies into your packages Directory.
Enterprise maybe not. Started building a new saas platform 6 weeks ago and core with docker was an obvious choice
Core 2 is actually quite stable compared to pre-v2. And the problem isn’t even the lack of resources on the Internet -- it’s the copious amount of pre-v2 info out there that will screw with a lot of people.
Maybe [Bridge.NET](https://bridge.net) can help port your C# experience into building cross-platform apps. The recently released Electron [demonstration app](https://blog.bridge.net/widgetoko-a-node-js-and-electron-application-written-in-c-1a2be480e4f9) from Bridge might be of interest if you need to deploy desktop apps to Win, Mac, and Linux. 
If you work for a tech company, yes. The rest of us don't necessarily have the resources to rewrite applications every year and still have to adhere to contracts we've provided with customers - meaning we're still releasing new versions of WCF services.
No, it's not. Are you thinking of Model-View-Presenter? While both MVVM and MVC architectures use types named ViewModel, the function of those types is completely different. In MVVM, ViewModels are mutable objects tightly coupled to a view with two way data binding. In MVC, ViewModels are (generally) immutable have one way data flow to Views. 
Yes I'm talking about keeping all the code that performs your task in its own class library, then you can build native Windows and Linux executables without duplicating that code. I'm not familiar with what is needed for an executable service on Linux, but I assume it's not a Windows exe, even if it targets .NET core. 
My .net course had a hybrid (basically a homework reading thing) on microservices. I'd recommend doing that plus like 1 lesson it. Like many things there is just too much else to know. Just give enough to peak their interest so they can learn more on their own. My course was on core 1.1 and I am now developing an app on core 2.0 and I highly recommend going that way.
JS frontend with REST backend is a pretty common approach. The REST part you can do in .net core mvc with a react or angular frontend. 
If the resource usage of the resulting app is not an issue, there is a new resource to develop under DotNet using electron. This allows you to develop the exact same app for all three platforms, excepting platform-specific hooks into the OS. The only downside is that electron is essentially a bundled Chrome browser, so the overhead for a small app can be considerable (several hundred Mb of RAM usage as a default base, for example).
Code first. There's some upfront work with Angular, but once you have the core system up, it's easy to build out additional screens with dotnet and angular cli.
What's wrong with it?
This technology is not mature. Be cautious using this for enterprise apps.
Xamarin Forms runs on both macOS and Linux. Correction the next stable version will run on those two, the beta version is out now and should see a stable release very soon. This would allow you to stick with c# and xamarin only.
Typescript in Angular feels very close to c# and should be fairly easy to pick up with OP's background 
How big of an advantage does Angular bring over JQuery?
I work for a mid-sized retail business. I am the only programmer. Hardly a tech company.
To be fair, ASP.NET Framework 4.6 MVC5 has the same problem with old documentation from earlier ASP.NET versions.
I second this, especially since there’s good tooling built into Visual Studio.
.NET Framework is still relevant and isn't going away any time soon. Greenfield apps will no doubt be made with Core, but there's tons of businesses with legacy Framework based apps that can't just be flipped over to Core. That said, there's not much reason to distinguish between the two for teaching purposes beyond just explaining the differences in packaging, namespaces, and API footprint. With those things covered, knowledge in one is pretty transferrable to the other. I'll agree with you that the other technologies is more or less dead or irrelevant to some extent. I'd want to give some high level explanation of those items in case students encounter them or want to learn more at their own pace, but going forward you won't see much of that tech. 
That's not what OP is asking for. OP wants to _publish_ a package into the local package cache.
Most teams will create [pre-releases](https://docs.microsoft.com/en-us/nuget/create-packages/prerelease-packages) for this purpose.
It's just amazing how developer-hostile Microsoft is. They need to be able to test their changes locally. They can't wait until they push then get their code review approved then wait on the CI system to publish their changes.
Web apps are certainly what you want to be building. You have two paths you can take depending on how "big" the app needs to be: 1) You can build a primarily MVC app if your primary concern is how long it takes you to get up and running. This is fine if the app is going to have a small to medium sized user base (e.g. internal line of business apps). You'll still need to learn some Javascript, but there's no real need to make the investment needed to learning a rich UI framework like React or other front end frameworks beyond jQuery. 2) If you're truly interested in future proofing and want to build a bigger and more sophisticated system, you'll want to make a "single page app" with a web API backend and a rich UI built with one of the trendy Javascript libraries out there. React is a popular one, but IMO the learning curve is pretty steep and I'd suggest alternatives like Angular. Note that this second route adds a good amount of overhead in terms of development effort and expertise. The impression I'm left with is that #1 is most appropriate for you.
Thank you. I thought that was clear with the "mvn install" in the subject, but too many Microsoft fanbois are developer-hostile.
TopShelf is handy. It's not that difficult to build a hybrid console/windows service app without it, but it still makes that slightly easier.
Perhaps I wasn't clear but for others the following may be useful: https://blogs.msdn.microsoft.com/dotnet/2017/08/14/announcing-net-standard-2-0/
What I mean is, you can test your changes locally - without the need to package them - through typical tests etc. I don't see what advantage you are gaining by testing the _package_ specifically. I mean sure, you might want to give an install a go to check the nuspec works, but that'd be something I'd only expect to do once or twice.
Maybe I need to explain what "mvn install" does since it was created to help developers rather than screw them like this NuGet garbage. It copies the compiled .jar file into a local repository so when you rebuild something that depends on it, you can test your changes. I want to help my developers test changes locally before having to publish. I want to may it faster and easier for them to work. I know Microsoft stands against those concepts.
I'm not an idiot. I know what you want to do, as demonstrated by my question of why are you wanting to test the package and are not satisfied with the regular method of testing binaries. You should also stop the heavy derision of whatever tool it is you are failing to use.
&gt;For desktop apps, Electron is industry leading. And now I know why everyone hates Electron
One thing that I hadn't initially considered was that using ASP.Net requires a windows server to host. So my plan of using a web front end for a cross platform application doesn't really work well. The applications I'm developing are primarily used as internal tools that are installed on isolated networks. So I can't assume I'd have the luxury of a windows server to host something. I've looked into electron a bit and it looks promising, which is why I was leaning towards JavaScript.
Then you're also small enough to keep up with the latest techs and trends.
It's got a lot of stuff packages into it to support the big things that an SPA needs over JQuery. Things like routing, components, dependency injection, data management (redux like tools built in), data-binding etc. The component structure make it more like an MVC (or MVVM) framework. It means you don't have to have a server-rendering your html and JavaScript. You can serve a really simple API for grabbing JSON data, and the client does all the rendering. It's not great for things not suited to SPAs. With jQuery you can drop it in and use it for a little DOM manipulation here, bit of Ajax there. With Angular, you do it the Angular way - and it's a big beast of a pre-compiled application you're building.
&gt; Thank you. I thought that was clear with the "mvn install" in the subject, but too many Microsoft fanbois are developer-hostile. OR "mvn install" means precisely dick all to a .net developer? But no, if you're going to be a colossal asshole about it, it's no wonder you're not getting the help you want.
&gt; I know Microsoft stands against those concepts. "this tool works differently to a different tool that I'm used to, so it must be the tool that's bad and not my understanding of it". You've been asked repeatedly what it is you're trying to actually *achieve*, but all you've done is bash Microsoft and call us "fanbois", then wondered why you didn't get the help you wanted. Of course it's Microsoft that's at fault, not you. Of course Nuget is "garbage" because it's not identical to maven. Of course we're "fanbois" because we've asked you questions to get to the bottom of what it is you want to do. You are trying to mash a square peg into a round hole because you're used to dealing with square holes - there's nothing wrong with either, they're just *not the same* so stop trying to treat them the same. That's not how *any of this works* and not because it's "developer hostile" (the only hostile thing here is *you*) but because it's an entirely different ecosystem that has different ways of working. I'm also suspecting that you don't actually know what nuget *is*. Nuget is not a build system like maven is, it's a package management system and *nothing else*.
Can you answer the question of how to help developers, or do you just stand against them?
You still haven't told us *what it is you're trying to do*. My best guess is that you've completely misunderstood what a nuget package is and is not. **You don't need to package up your libraries to use them or test against them**. If you have created a library, building it will produce a .dll file. Any other project can reference that .dll file directly. **You don't need to touch Nuget for this.** That's why you don't need to set up a local nuget server for one of your developers. That's why what you're asking *doesn't make sense* in .net land. Nuget is for *distributing* libraries and making dependency management easier but it's not required.
It's in the subject. "mvn install" copies a dependency into their local repo so they can test changes. We need to do the same with NuGet. I don't understand why that's confusing.
.Net Core (including ASP.Net) can be deployed on Windows, Linux or OS X. 
its really not THAT hard switching from .net to .net core. If you are sticking with pretty vanilla stuff that doesn't mess with the OS it would talk renaming a few inherited classes and setting up a startup.cs 
/u/A-Grey-World read the user's username again. Troll account
 &gt; We need to do the same with NuGet. I don't understand why that's confusing. **Because you don't need to**, that's why. That's what everyone here is trying to tell you, but you aren't listening. Nuget is not maven, stop trying to treat it like maven. It doesn't do what you think it does and it's not for what you think it is. 
I read a bit of his post history, nothing there suggests troll to me...
My first job was in Java and I had NO problem at all going to C#. All you need to do is show them what properties are and why you would use them (instead of writing god awful getters and setters) and you're all set. Also tell them there are fewer keywords for inheritence but the rules are the same. Also explain in 5 minutes why linq is amazing. Finally, do not forget to show them or tell them what a style guide is. It doesnt matter what style guide you use, just tell them that style does matter and focus on it as you write your code in front of them. I'd skip over soap. I rarely see anyone know/use soap these days (id rather butcher an aspx file to deliver me JSON) When you do teach REST you may want to dig into "What really is an HTTP request" basically once you establish a connection with a server TCP connection, what are you really sending it? (You could do this manually over telnet to demonstrate an HTTP request line by line building the document) you could even go into HTTP/2 stuff. I mean this is ONE class, but also you should try to impress on them the importance of professional development and ways of staying up to date (even reddit is a valid way of doing so) conferences, meetups and so on. 
jQuery is a /u/Relevant_Monstrosity 
So how do you install a dependency into the local repo? You apparently just don't understand what developers need.
Okay you know what, I'm done trying to help you, you've been nothing but rude and arrogant. Good lucky figuring it out with that attitude.
I think as of today teaching your curriculum is more relevant. Especially what do your students gain from learning tech that's more than half a decade old? By the time they graduate or continue with their Master's degree that tech is almost going to be worthless. If saw a course teaching WCF/SOAP and Winforms and had understand the whole theory behind it I would honestly not even enroll. Mostly WCF/SOAP services *today* are already legacy services. No new projects are created in WCF or WinForms today and most people who work on these projects maintain legacy code. SOAP and WCF just doesn't fit the requirements most of the new stuff today needs. Also WCF is a *beast*. It's so complex, you couldn't even understand it even if your curriculum consisted of WCF *only* for a whole semester. Things like REST, OAuth2, OpenID connect are standards that were established for a reason and those are not bleeding edge things anymore. They're quite mature. AspNetCore is quite new but also came a long way and is now in it's second iteration 2.0. For functional programming you could also consider TypeScript (used e.g. for Angular 2 which plays nicely with AspNetCore). Also OData is an implementation of the REST architectural style. It's not yet ready but soon will support AspNetCore, too (I can't wait). WPF / .NET is still really good to build Windows Desktop applications. Things like Electron are making their way into the Desktop domain, though. And also the concepts behind REST and OAuth2 are quite complex, so your curriculum is already quite big. Depends really on how advanced the students already are.
A local folder repository is not a hack. You can't throw away the solution and then throw your hands up saying the problem is unsolvable. Why should everyone be "using the same configuration" anyway? Either put your repository on a file share (which is a good middle ground) or have each user configure it themselves in a path they like. Your dev and test servers should use prerelease packages on your Nexus server.
If maven really refers to publishing as install thats pretty bad terminology. Anyways just set the source command line option as a folder when you do nuget publish. 
We couldn't move because of the third and first party WCF services our application is tied to. For any non trivial application it is more difficult than just renaming some classes.
Nah, this is my main account.
Is there a good reason to use it for non-SPA applications?
I've been working as a mid level .Net developer for several years now, every one my team, including the senior devs, audibly groans when we have to make a change to one of our legacy wcf services. Any of our uis using winforms ends up as work that is pulled in only when absolutely required and then by whatever sucker we can convince needs to do it. This is at a fortune 200 company, not a small dev shop. Honestly I wouldn't look at UWP either, a lot of places are going the route of web/js UIs and Rest services, and if they are not that stuff isn't too complicated to learn on the job if you are accustomed to C# already. I would throw the old curriculum out the window, focus on core and the other stuff you've got listed. (I'd actually bump OAuth up a bit in that list as well). My company's stack for new development is apis built mostly using servicestack, mssql, elasticsearch, and redis for data stores, rabbitmq or apache Kafka for messaging, and reactjs or angular frontend. I know of several other large companies in my area that have a very similar tech stack. All that said, if you aren't near a larger tech area, maybe it makes sense to stick with the more mature tech because if they get a job in the area they are more likely to run into it. If you are anywhere near a large city with a good it industry, teach the new stuff and those kids will be better off. And even after all that, none of it really matters of they don't understand good design, both in oop and functional programming. Or at least aren't able to weigh the costs and benefits of different design patterns.
my containers run dotnet core in containers on aws, in their ecs offering. fast fast fast. I've become annoyed with aws because my cluster runs at like 5% memory usage but 60% cpu. kestrel behind the elb is really, really fast. i want machines with a quarter of the memory. and i do my development in Windows in visual studio. the dream of xplat .net is alive and very, very well.
asp net has been unified, it's not just about ui anymore. mvvm, mvc, both part of it but not the whole thing. name is shit, because "active server pages" (asp) implies ui. but asp.net these days means webapi too, it's all one happy family. and the parts are pay to play. dont use any ui part? me neither, and it's not a part of the pipeline. it's a fast happy family, too.
wcf works with core afaik. wcf under the hood is a deseializer + some reflection, so it ought to work.
Or vue!
"learning .net core", especially 2.0 and beyond, means less with regard to code and more just about tooling. I'm an old .net guy, and if you were to ask me "how can you build it from the command line?" I'd give some handwavy answer involving msbuild. now? dotnet build. the code is the same. but the guts that turn your code into dlls is new. but i develop on Windows and deploy to linux (debian) containers. the .net dream is now.
It works on the client side. There is no transition for the server side.
microservices had nothing to do with .net, it is an architecture strategy. it is a buzzword that can make real systems much much worse. for intro stuff, they are very obviously not going to be coding "for scale", don't make that an issue. definitely do *some* ui. it is compelling and keeps people interested. start with .net core. that's where the future of .net is. you can even do uwp there now too, so ui. asp.net core for a web service backend.
I don't see why having a windows host is a problem. I'd think you're primarily concerned with the users machine, and a website is as cross platform as it gets. That said, .NET Core and Mono can be hosted from a Linux machine.
It depends on the scale of your app. A few hundred users? You'll be fine. A few thousand? It may be worth looking at serving static files from a different server. Either way, it doesn't preclude the use of that template if you want to use it to get started. Keep in mind, most static assets are generally just served up once for each user's session (assuming you'll be using something like webpack to bundle everything up). The majority of your traffic will likely be API calls. Whatever you do, just don't get trapped in the premature optimization loop. Follow best practices and youll be well-equipped to fight those performance battles if and when they arise.
Agreed, but be sure to teach. NET Core 2 and. NET standard 2. Keep the minimal scope. Better to do less and you can always do more depth if necessary.
So to me, .net Dev work is full stack work. If i was in your shoes my curriculum would look something like this: - Intro to hello world rest api project in visual studio, get them building and running right away. Lectures on API best practices and REST vs. Soap vs legacy web stuff. - Looking at development patterns common in .net and API work and picking one for the class project. (class should have one incrementally building project) Pick a pattern (i'd recommend repository since it's easy to follow and comprehend) and have them build an API with that. - Making a front end website for their API using razor pages with MVC. Lots of focus on angular, react, etc but razor is the .net "way". - For backend work, would recommend using something like dapper and sql server to complete the stack. This way it's a good into to some basic SQL queries. - Bonus - Adding auth into the site. What would be great is to not only teach the fundamentals of developing with .net, but an introduction on the meta of programming: working in scrum, good comments, good variable names, good method names, encapsulation, etc etc. Students should be able to walk away from class saying "hey, i *made this* and it was *easy*" and have some confidence that it was made correctly. Get everyone up and running with github for submitting code if possible, run it like a mini dev shop. I would have given a ton to have this sort of atmosphere when i was taking college courses. 
- Go with .NET Core - Teach them MSBuild - Use Visual Studio Code instead of VS 2017. That will protect them from the disease of VS programmer.
Our main product where I work is still in WinForms. There's been talk of translating it into a web application, but I'm skeptical it will ever happen unless something comes along to really force their hand. We only just upgraded from .NET 4.0 at the beginning of the year. 
The students have to know about the old things. A lot in the real world is build atop of old tech. And please, PLEASE dont be the guy who trash talks old technologies. Please teach your students to embrace all technologies. And use them. 
What is PWA? I had a quick search and only came up with Project Web Access which doesnt sound like something that would replace UWP.
Leave scheduling to the operating system.
Go for it. I'm currently doing a minor that specializes in .NET. Among other things. We're doing everything in .net core and even used some sql server Docker images that were released 3 days before the class. I would not have joined the minor if the material would've been what you described above. Nobody wants to work with old crap (SOAP? Seriously?). Try teaching your students that although the technology is new, many ideas and patterns used are not. Almost everything applies to different frameworks and even languages. I think most of your ideas are good and fit with what students should learn. However, I would skip on the following in order to have more time for the rest: F#, Xamarin/Mono and desktop applications. Also, definitely go for unit testing and TDD. Almost everyone in class had had it before, but didn't really use or understood it properly.
Do you mean the Windows Task Scheduler? Does that play nicely with a Windows Service?
I would say it would not be a good idea.
What you’re looking for is `nuget add`: https://docs.microsoft.com/en-us/nuget/tools/cli-ref-add
I’d recommend you try out dot net core. Install the dot net core CLI tool and install Node.js. Then you can spin up some quick example applications as simply as “dotnet new react” and “dotnet new angular”. It’s a great way of comparing simple examples of each JS framework with .net. 
I have used Topshelf and eases things a lot... As long as you're dealing exactly with that: Windows Services. I'm saying that because if you want to go ASP.NET Core, Windows Services won't work. Or at least we don't have a cross-platform abstraction yet. If that's the case, maybe you want simply a console app. That's also dockerizable.
Ignore him, it was a troll reply
Surprised no has has mentioned the previous 2 threads about this! https://www.reddit.com/r/csharp/comments/4pve3y/alternatives_to_quartz_net_scheduler/ https://www.reddit.com/r/dotnet/comments/6fsu89/hangfire_task_scheduler_for_net/dikq66v/ Both are either me asking about it or posting my thoughts on something related. Personally I use FluentScheduler.
The API requests in this case are your controller code. They are meant to call to your business layer (which may or may not be on another tier). You aren't supposed to put complicated business logic in your application controllers, though sometimes that is done anyways for small and simple applications.
Maybe in SV land. Here in boring Europe, I have enough WPF projects to keep me busy until the Electron fad gets replaced by the next cool thing.
Some of our Fortune 500 customers happen to disagree regarding greenfield WinForms projects.
_Full disclaimer - am PM on [docs.microsoft.com](https://docs.microsoft.com)_ Definitely would recommend focusing on the more modern .NET stack - .NET Core &amp; Standard, ASP.NET Core, REST, Docker integration and Xamarin. Heavily lean on cross-platform work, I would say - show how modern .NET can do well on Linux, Mac and Windows. That's not something you will achieve with SOAP and WinForms. Get students to use something that is applicable and can help them build the skills they need, and will need - once they are done with your course. Focusing on older technologies will do them a disservice, as they will face another problem - nobody will need those abilities, and they will find themselves having to learn the new stack anyway.
All of asp.net core and .net core are open source on github. While not for beginners, these repositories will show you what it takes to develop code libraries with multiple framework targets for consumption as package libraries.
There are so many, its hard to say. [IdentityServer4](http://docs.identityserver.io/en/release/) [protobuf-net](https://github.com/mdavid/protobuf-net) [cqrs-journey](https://github.com/MicrosoftArchive/cqrs-journey) or gregoryyoung's [m-r](https://github.com/gregoryyoung/m-r) [disruptor-net](https://github.com/disruptor-net/Disruptor-net) [SPA template based on the Vue Webpack in ASP.NET core 2.0](http://www.iaspnetcore.com/Blog/BlogPost/59d955f7dc77c218ace64a60/spa-template-based-on-the-vue-webpack-in-aspnet-core-20) (bonus points for learning how to get it to work with Entity Framework 6.2) [OpenRasta](http://openrasta.org/) [Quartz.NET](https://www.quartz-scheduler.net/) [IKVM.NET](https://www.ikvm.net/) [Blazor](http://www.c-sharpcorner.com/blogs/blazor-running-c-sharp-in-frontend-crossbrowser) [CosmosOS](https://github.com/CosmosOS/Cosmos) 
I use Task&lt;IService&gt; then let it go to town.
 HostFactory.New(x =&gt; { x.RunAs("username", "password"); }); Please don't do this.
You should do that even if you're not using topshelf.
ah i should have mentioned, if you are on the cutting edge already. WCF is a windows only technology. Basically, if it has windows anything in its name, its not going to be trivial. MVC applications, generally will be. 
Ah, that explains why there was a FreeBSD rotor.. [here](https://msdn.microsoft.com/en-us/library/cc749640.aspx) it is. I never knew that. I bet people avoided it like the plague, thinking evil Microsoft et al.
Yeah, bring that back. Probably too big of a security risk though.
Jimmy Bogard has some great opensource projects and a really nice way of structuring his code this rewrite on contosouniversity using .netcore, the mediator pattern CQRS (Command Query Responsibility Segregation) and feature folders taught me a lot. It's drastically different than they way I was writing structuring my code. https://github.com/jbogard/ContosoUniversityCore
Ok, well that aside we also found non trivial changes porting third party .NET framework libraries (which we don't have the source for), our usages of Entity Framework, Entity Framework Migrations, identity framework, Http Modules (we had one for selective dynamic compression), SignalR, and restructuring all of the configuration, startup, and logging code. Its still definitely a lot more than renaming a few classes for any non trivial application.
I like this. Is there one out there that uses services/repository pattern?
Yeah, it just hurts...
Entity Framework uses repository pattern.
I would say https://cakebuild.net 
I would say https://cakebuild.net 
I guess I am writing trivial applications :( i should probably step things up. 
I meant trivial in size of breadth and complexity of dependencies, not necessarily importance, value, or quality. Didn't mean it as an insult, just an anecdote that has had a differing experience than you.
Love [MediatR ](https://github.com/jbogard/MediatR) 
No offence taken at all. I work very much alone at my job as a C# developer and I do a lot to stay up to date (read various tech blogs, reddit, conferences, training videos, pluralsight and safaribooksonline) One of my biggest issues is impostor syndrome so whenever I feel like I'm not doing what the rest of the "industry" is doing or am not following "best practices" it means I'm either not doing enough or am learning the wrong things. To expand on that alone part: I work in an IT department for a small university. There are so many products that we support that everyone is an expert on their own product and mostly just their product. We have a VMware guy who focuses on just our virtualization and backup, network engineer, people who work on supporting sharepoint, people who support Colleague/Banner. And then there is me, the only full-stack software/application developer on staff. When it comes to new development initiatives and software development, it's just me myself and I. I span across everything with getting help here and there from a few key people (namely the network and VM guys) but the rest is up to me. I set up and maintain my own TFS server (I am afraid if we migrate to VSTS no one will know where the stuff is even with all the documentation in the world) I setup my VMS from scratch (the VM guy just hands it to me domain joined) While generally, not an initiative by management, I am the one trying to make sure we are on the forefront of what students would appreciate and modernizing our stuff. Currently I am fighting with ADFS and Web Proxy to develop a single sign on solution, right now every *.domain.edu site you go to you need to type in your username and password for this would eliminate that. I'm supposed to be a web developer and while I don't mind, and actually enjoy this kind of diversity of work, it's kind of disheartening when I don't have other staff to rely on with the same set of knowledge/skills. So while I am touching 20-30 different technologies, I am afraid I'll make a mistake and get called out about it, especially if I look for another job and list it on my resume. I am currently in a spat with our AD admin who's explicitly blocked my login permission via local policy on all the domain controllers (I'm a domain admin) slowing down my work I need to backdoor in over a PSSession, create a new domain admin account login as that and unblock me from the controllers. Ok now I'm ranting about work issues....whatever 
If you are thinking about angular, you may look IdentityServer4 - Angular 5 template of damienbod. It is well written and you can implement it to an angular application easily. [AspNet5IdentityServerAngularImplicitFlow](https://github.com/damienbod) 
I hate what MediatR does: It hides/obfuscates the relationship between what is called where and in addition I have to maintain a bunch of extra classes for no reason other than to satisfy MediatR.
Then do what?
I come from the exact opposite background. First job was Django/REST, second .NET. It seems like MS copied linux/mac concepts and improved on them to make .NET Core. Haven’t tested this theory yet, but excited to check the differences. I had to do some fancy coding to work with an old SOAP API for my first project but in love with the theory of .NET Core right now. I gotta convince someone to install .NET 4.6 on our server; still stuck at 4.5 ATM.
Can you explain this more? I'm genuinely curious, because I have really gravitated towards using it. It's like a little shim between my controllers and service layer. On my current project we've started using it and it's really cleaned things up. 
That's basically what IOC does. All large projects should be running IOC to some degree - the price/overhead you mention is always recouped in other ways e.g. maintainability, flexibility, reduction of conceptual load, etc. On projects that I manage that have been moved to something like MediatR we've seen significant improvements in speed of development.
For our services we use either a OWIN selfhost or ASP.NetCore API/SPA for managing services hosted by Topshelf. This is in fact what HP does for their services (not the .Net part). I've also seen WPF-like thin-clients that just interact with an API hosted on the service - like how CrashPlan works. Acronis Backup has all its services connect to a centralized location and settings are pushed from that location. Consul has a command line application that interacts with the service via a local CLI. It really depends on who will manage the system, what type of security you need, can the service access and store confidential information, etc. 
&gt; One of my biggest issues is impostor syndrome...the only full-stack software/application developer on staff. I have worked on developer teams from solo up to 30 developers. I will say that you can't beat doing in-house work for learning a diversity of skills. If you get the chance and their budget allows, see if you can get a team mate at some point. Having a sounding board and a different perspective constantly with you will really help with the impostor syndrome. &gt; I set up and maintain my own TFS server... I setup my VMS from scratch (the VM guy just hands it to me domain joined)...I am currently in a spat with our AD admin who's explicitly blocked my login permission I setup our instance of TFS server from a bare VM as well. I'd have to say, moving to VSTS has been a joy, you might want to look at considering it again. The biggest benefits are being able to check in code without VPN access and not having to do painful upgrades every couple years to stay up-to-date, and the integrations with Microsoft Teams and Slack that can easily be setup. Hosting services in the cloud really cuts down on the work of configuring and maintaining VMs and the amount of oversight that your internal IT department needs to use for stand alone apps (depending on their involvement in cloud hosted services). &gt; it's kind of disheartening when I don't have other staff to rely on with the same set of knowledge/skills. We have over a terabyte of data in various databases, but no DBA. It might be in a different area of concern, but I think I know exactly how you feel. &gt; So while I am touching 20-30 different technologies, I am afraid I'll make a mistake and get called out about it, especially if I look for another job and list it on my resume. There is an easy solution for that...make up several different resumes for different types of candidate employers. Make one 'full stack C# dev' resume, a 'Dev Ops - Jack of All Trade' resume, and then tweak them further for each employer before sending them out. Your resume is just to get you in to an interview. People who learn quickly and can talk easily about the things they learn will rarely have difficulty finding work in software development.
Cloud has been on my mind a lot. As an educational institution our licensing deals are thousands of dollars cheaper to have and maintain in house. (even with the added staff) Microsoft has little discounting of their cloud offerings to educational institutions. While we use office 365, we do not use Azure AD as that would create an additional 40-50k bump in our licensing costs alone. 
https://github.com/OrchardCMS/OrchardCore 
Why not just use nopcommerce or similar other open source e-commerce project? Nopcommerce is being ported to .NET core
Just re-posting this comment I made in the /r/programming discussion here. There might be interest in discussing it in a DotNet-centric forum. ----- Thanks for the presentation slides /u/ben_a_adams I've just started reading this and came across this quote: &gt; SocketAsyncEventArgs + 360% faster How does this API (well, the networking/sockets API as a whole) now compare with Libuv? I asked the same question around a year ago via a GitHub issue, which can be found here: https://github.com/aspnet/KestrelHttpServer/issues/1201 I'd love to have the question re-answered in light of .NET Core 2.0.
I am the same except my annoyance is ram, not cpu :) it barely uses any cpu but ram reservations eat those hosts right up
From Jakub Chodounský's weekly newsletter.
https://www.reddit.com/r/csharp/comments/79pt7f/common_linq_mistakes/ A lot is factual wrong in this article. &gt; Depending on optimizations of the LINQ provider, this may mean, for example, that your database fetches all John Smiths to your application, and the application then returns first of those. You definitely don't want that. Author failed to name a single LINQ provider that behaves this way. Generally a LINQ provider that would behave this way is considered buggy. Author claims that relying on the correct implementation of the LINQ provider is bad code, and you should work around potentially existing bugs. &gt; Using .SingleOrDefault()/Single() instead .FirstOrDefault()/First() Whether you use `Single` or `First` heavily depends on your context. Author heavily assumes some form of SQL LINQ provider is used, while LINQ itself is completely unrelated to the concept of databases. &gt; Chaining .Where() entries may end up in SQL database as multiple embedded queries (in style of SELECT * FROM (SELECT * FROM PERSONS WHERE LastName = 'Smith') WHERE FirstName = 'John', instead of SELECT * FROM PERSONS WHERE LastName = 'Smith' AND FirstName = 'John') – or will do multiple iterations over sets. Again author fails to name a single LINQ provider that behaves this way, just as the first point. &gt; It also obfuscates the intent of the query. I fail to see how multiple `Where` conditions obfuscate the intent of the query. At most combining multiple `Where` calls is a micro-optimization, but definitely not a mistake. I'd choose whatever is more readable in the code, which often ins multiple `Where` calls. 
Great newsletter.
In what way? From what I've seen, even Entity Framework Core 1.x has more features than the classic EF 6.x.
The developer of this particular solution doesn't like repositories https://lostechies.com/jimmybogard/2009/09/11/wither-the-repository/ it's an interesting read. I've learnt quite a lot through looking at his code and blog posts. Not saying he's got all the answers by any means but he does have some good ones.
System.Net.Sockets supports both blocking and non-blocking sockets, and both synchronous and asynchronous APIs. The asynchronous implementations use completion ports on Windows, epoll on Linux, and kqueues on macOS. I believe they work off their own threadpool and dispatch to the user threadpool Might be of interest https://github.com/aspnet/KestrelHttpServer/pull/2147 
Hey, cool, you guys are really getting there when you consider those benchmark numbers. Still a bit to go, but impressive given that it's in competition with a C library. My original interest when I posed the question a year ago was more on the consistency side (i.e., whether or not the C# networking code had a propensity for producing too much garbage, and thus induced GC latency) rather than the absolute performance.
Great to see that Steve is still working on the Blazor experiment. The age and lack of maintenance of DNA was something in the back of my mind so pretty cool to see he's got it to work on Mono! Still feel like this could become such a powerful addition to standard Razor should Microsoft back it!
It could be pretty cool. I could never get the DNA version to work; hopefully this will be better.
.NET Framework
Yes, no prob. So, our project is small, a thing I forgot to mention in my parent post. I totals around 5-7k LOC. At this point the project is too small to see any real benefits from mediatr and it only gets in the way more often than it helps. If you try to visualise the dependencies with VS, there is a huge disconect and you can't track what &amp; where. cc /u/silvenga 
Autofac (https://autofac.org/) It is a state of the art IoC library for .NET. Its API and fluent-style DSL are very understandable and pleasant to work with, and I referred to the source a lot when designing my own APIs.
Yeah, small projects don't see nearly an impact, although, most of my side projects have IOC (some even mediatr) as I find it makes unit testing a whole lot easier - which makes development much easier. I loving being able to develop for weeks without ever running my code or connecting it to a real database and it just works at the end.
Yeah, lot of improvements in allocations for SAEA .NET Core 2.0 and are till adding more. I believe the aim is to have .NET Sockets as good as if not better than libuv and switch Kestrel to using them by default.
I meant don't hardcode passwords.
Don't get me wrong, I Iove ioc, I just don't like mediatr for relatively small to medium projects :) 
Not even close. Lazy Loading isn't in yet. You can't do raw SQL queries unless it returns an entity. While not necessarily an EF issue, OData isn't available for EF Core. There are a few other less impactful differences, but some or all of these issues are expected to be addressed in EF Core 2.1. So you might be able to use it in production, but I can't.
I especially agree with you with the last point. In my opinion chaining .Where() parts helps to group elements of a CNF. Are you sure, that the LINQ to entities adapter optimizes those queries?
What have you found so far in your research? What are you leaning towards and what are your reservations about it?
Wow. That was a weird read. The only point i agere with is the one about First/FirstOrDefault.
Agreed. This article is flawed in so many ways.
WTH? Are you somehow politicizing software development? Chill buddy.
It has nothing to do with politics, calm down. I'm just pointing out your hypocrisy.
What hypocrisy? I asked for a VOLUNTARY contribution of information. I am against INVOLUNTARY contributions. Did I ask congress to pass a law to force you to answer my question? You seem to be confusing the two. And FFS man why in the fuck do you feel the need to check someones post history before responding to a question? And if it puts a turd xways in your panties then just ignore the question.
&gt; would gain by testing your packages So you don't like to test your changes before pushing/publishing? That's sad, and it explains a lot about why Microsoft software is so bad. 
Settle down, buddy. Triggered much? I saw a question that made it obvious the asker (you) hadn't done any legwork. So I looked at your post history to see if it was a pattern or if you were new here and didn't know better. Then I saw that you didn't understand how societies function and decided to have a little fun with you. Take deep breaths, calm down.
Not bored of being a complete dick I see. Care to explain why you ignore the part where I say shit gets tested without it being in a package? Nuget packages are very different to JARs, dickhead. 
Woah, really digging the metrics. 500% improvement to Lazy&lt;T&gt; is pretty hilarious
Honestly here are the things new hires have no idea about when they come to work day 1: Datasets/Datatables in .NET Async/Await, TPL threading models, also older styles Writing Clean Code, LINQ How to deal with dlls, nuget package manager Source control Dependancy Injection If someone started in my company today these are what they would need to know for technologies but really there is very little difference here. I would rather them knowing the stuff up above and less about the structure of a MVC app. I can't teach you that a lot quicker than I can explain dependancy injection. .NET framework, Winforms, WCF (SOAP), WPF Where we may be some day. At least many years off .NET Core, ASP.NET Core, REST, microservices 
While I'm not necessarily against WCF, the nightmare is in the configuration. I really don't know how to handle services that are currently WCF that need to be migrated to containers or the cloud.
So you admit you don't know how. Why not just say that?
Yes, they are optimized. The author just has no clue what he's talking about.
The configuration is a nightmare if you let yourself sink in the XML ocean. I wish my company let me open source the library i have created for our internal usage. Nothing as sophisticated as ServiceModelEx by iDesign but my guys are able to spin a windows service hosting a wcf service in minutes and focus on what matters, the service and data contract. I had a nice chat with other developer, strong advocates of WebApi as the way for doing SOA... I'm still waiting for how they want to implement a transaction spanning across several services... 
Doesn't need to be ported, just update with appropriate Bootstrap and LESS.
Thanks buddy, Installing core 2.0 and hitting the books.
https://github.com/dotnet/corefx/blob/master/src/System.Linq/src/System/Linq/Utilities.cs (CombinePredicates method): It literally turns Where(x =&gt; predicate1).Where(x =&gt; predicate2) into Where(x =&gt; predicate1 &amp;&amp; predicate2)
If you have built a considerable infrastructure using Web Forms, then what you need to do is modify the HTML layouts that get sent to the client to make them more mobile-friendly. A front-end framework such as Bootstrap would certainly help. If you don’t mind rebuilding everything from scratch, then creating an MVC 5 or Core 2 app using the “ASP.NET Core Boilerplate” (A Visual Studio Extension that implements Bootstrap as a component of it) would probably be my best suggestion. Your choice between the two will depend on how badly you want to bring your content to modern practices. Web Forms are hairy ancient, and while Web Forms can be good for quickly prototyping something, it can easily turn into Spaghetti Code very, very quickly. Going toward MVC, even if you stick with v5 and ignore Core (for now) is great from a future-proofing standpoint, as Web Forms are no longer being actively improved/developed by Microsoft. At some point Web Forms will be actively depreciated, and I suspect that time will be sooner rather than later.
Absolutely. We do this and we have 20 or so micro services all managed by a single instance of a windows service. Works great.
Cool library! CSV &amp; Fixed width support, easy to use and super fast. +1 star from me
Nice, thanks!
Any idea why I get downvoted for pointig it out?
How does it compare to Microsoft.VisualBasic.FileIO.TextFieldParser?
&gt; Explanation &gt; Don't use Enumerable.Count() method for arrays or any collections that implement ICollection&lt;T&gt;/ICollection interface, such as List&lt;T&gt; and Dictionary&lt;T&gt;. Use .Length for arrays and .Count property for ICollection implementations. Actually, almost every available implementation of `Count()` is optimized to handle `ICollection&lt;T&gt;` and `ICollection` https://referencesource.microsoft.com/#System.Core/System/Linq/Enumerable.cs,1305 https://github.com/dotnet/corefx/blob/master/src/System.Linq/src/System/Linq/Count.cs (4 year old branch version of mono for comparison, only does the generic version `ICollection&lt;T&gt;`) https://github.com/mono/mono/blob/mono-3-2/mcs/class/System.Core/System.Linq/Enumerable.cs#L635 If you know you have a generic type implementing `ICollection&lt;T&gt;`, `.Count()` is fine. If on the other hand you have no control over the runtime type being used in this method, any LINQ method that evaluates the enumerable is probably a bad choice. 
I dunno. People are dicks. I brought you up to 0. 
it would be cool to have something like vue.js on C#
I fear that this project, despite being the most exciting thing to happen to .NET this year, does not seem to be in active development (I hope I'm wrong, but the commits and pull requests seem stagnant). What can we all do to help get this project off the ground?
Going to try this out this week when I'm onsite with a client. Looking forward to it. Thanks for having the initiative.
Well the blog post was yesterday and addresses some of that. It's open source so we can all contribute. The last commit was yesterday...
Thanks for your input! I'm not sure I understood what you meant with your last sentence "where we may be someday..." though xD
I don't think WebAssembly has access to the DOM, at least in this first release.
&gt; Using .SingleOrDefault()/Single() instead .FirstOrDefault()/First() This entire section is wrong. It's really bad advice. &gt; Single.. methods go over all elements of the set No they don't. They go over at most two. &gt; validating that there is just one match and throw an error if there are more - which is both costly and usually unneeded, unless validating user input or such. It's needed if you expect that no more than one element is returned. In most cases it will only fetch one, but if there are more an exception is thrown which tells you why it failed. &gt; In terms of SQL, Single is: SELECT TOP 2... whereas First is SELECT TOP 1.... If you have 10M rows, and your match is the very first row, Single will still run through all of the rows, validating that there are no more matches, whereas First returns immediately. What? Why would `Single` have to run through every row but first doesn't? In order to check if there are more than one result all you have to show is that there are at least two. Also *You are expecting a single result* so why would there be millions of matches? If there are, then there is something seriously wrong with your database query **and Single will catch the error**. &gt; In most cases, you aren't interested in ensuring that there is just one match - or often it is logically impossible. Seems like a good reason to use `Single` instead. &gt; See the examples above - if your database has two Person entries with same ID, you have far bigger problems than using LINQ badly... Yes, and using `Single` may help you catch it. If you use `First` such a mistake could end up with odd behavior where changes seem like they don't happen, or the data returned is invalid. Or doesn't get noticed at all. If you *expect* a single result, then use `Single`. If you expect one or zero results use `SingleOrDefault`. You you expect multiple results but you're only interested in the first use `First`. If you expect zero or more results use `FirstOrDefault`.
I suspect everytime someone talks about Linq but is really referring to Linq2Sql or EF. But I agree with most of the examples from the article.
Have a look at whether Amazon exposes an API for consulting orders. A quick search turned up this: https://developer.amazonservices.com/doc/orders/orders/v20130901/cSharp.html/130-2962147-5725212
Other than the fact that you have to import a VB library? 😉
&gt; Microsoft.VisualBasic.FileIO.TextFieldParser Good question. If you search for a CSV parser for .NET, you'll undoubtedly find multiple stackoverflow posts referring to this "hidden gem". But if you've ever tried to open a moderately complex .csv file in Excel or import data using the SSMS import tool, you will probably see this library isn't all it's touted to be. The behavior is very similar and I wouldn't be surprised if Excel and SSIS are using this library under the hood. If you read that first link in my original post, you'll see it's insanely hard to handle all the bizarre edge-cases in real-world CSV. Using several blog posts similar to that one, I wrote close to a hundred unit tests verifying I was covering as many formatting oddities as possible. When necessary, I support options for specifying how to handle your particular format. The next big difference is the same difference between using raw ADO.NET classes and Entity Framework. Rather than working with raw `string[]`, FlatFiles lets you write directly into a class's properties. Even if you want to work with arrays, FlatFiles also handles parsing so you get back an `object[]`. Unlike most CSV libraries, FlatFiles focuses on configuring parsing/formatting up-front rather than relying on guess work and magic, which means spending less time trying to "get it right". It also means parsing is usually much faster.
OpenCover should be able to run in Linux soon you can track the status of this here https://github.com/OpenCover/opencover/issues/703 After that the only problem will be how to process the report. I use OpenCover and ReportGenerator at work, but am on a Windows machine. In your case you might be able to build and then use the Jenkins Cobertura plugin http://jane.dallaway.com/jenkins-code-coverage-net/OpenCoverToCoberturaConverter https://github.com/danielpalme/OpenCoverToCoberturaConverter Or just build ReportGenerator in Linux and then there is no need for a Jenkins plugin https://github.com/danielpalme/ReportGenerator 
Unfortunately it seems their APIs are only available for merchants. I'm trying to retrieve my personal purchases programmatically 
+1 for open cover and report generator. Takes a bit to get scripts built for them, but once you have them they produce great reports. I have them set up on most of my repos.
I would recommend to add in delimiter sniffing and support for reading a file to then determine it's schema. I've had to custom code most of this on top of existing libraries, or merge two together, to handle user uploaded files which can never be trusted to maintain the same format.
There is some basic support for detecting the schema based on the header when working with arrays, although in that case it just makes everything a string. How have you gone about detecting delimiters and column types; could be cool. 
Does it support having a different schema per record? A lot of EDI formats I interface with (broadcast advertising) are fixed length flat files and the first field in a record determines the record's schema.
Sounds like you need a scrapper. I know that f# is pretty decent ..you can see your page data real time while coding .. a few google searchs and you will have tutorials for that. I'd suggest you ask for the login and parameters then run a scraping script.. if it where platform agnostic I'd suggest.. Scrappy or puppeteer you could parse and store data in a database form these scripts.. You can of course look for a dot net scrapper ... They are just mediocre.
Hmmm, okay, thanks for the suggestion.
This is hugely interesting to me. Knowing next to nothing about how this web assembly runtime actually works, I'm still a bit puzzled that the approach for improving performance is optimizing Mono rather than moving to .NET Core.
Instead of building your own scheduling service -- have you looked into using the windows scheduler which just calls into your console application. 
Only problem is we need something more sophisticated. We need a complicated schedule plus the ability to not run processes that are still running. Looks like Quartz can do this.
What's wrong with having to input another library that compiles down to IL? Who cares?
I was making a joke. Jesus.
Thanks. I couldn't believe there isn't a code coverage tool for Linux. Thought I was going crazy when I started Googling and nothing was coming up. I'll keep an eye on the links.
.NET is so dry it's easy to miss jokes / joviality :) 
You can do this manually with CsvHelper's help. Just loop over the records, sniff the first column, then do your GetRecord&lt;MyType&gt; depending on the result of the sniffing.
RemindMe! 1 day "check these answers" 
I will be messaging you on [**2017-11-08 06:04:41 UTC**](http://www.wolframalpha.com/input/?i=2017-11-08 06:04:41 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/dotnet/comments/7b86pl/net_code_coverage_tools_for_linuxubuntu/) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/dotnet/comments/7b86pl/net_code_coverage_tools_for_linuxubuntu/]%0A%0ARemindMe! 1 day ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! ____id____) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
- Can we include external C# files (such as model entities) in the cshtml pages? - Any tutorials on how to expand the API? - Goal is obviously to make it .NET Standard compliant
ReportGenerator is quite self contained, just an executable that reads the xml file produced by OpenCover, PartCover, dotCover, Visual Studio, NCover or Cobertura and creates an HTML report, I like that I can generate the report in the local machine or in TeamCity/Jenkins and then make it an artifact. Since ReportGenerator supports a wide range of coverage tools and you have experience building C# code in Linux I would try to build it and see. Because if another of the existing coverage tools gets support for dotnet earlier you can still use ReportGenerator. The OpenCover part seems to be on the way to sort itself out and currently already supports xunit that you use. Good luck!
to be fair, i had this whole comment thread play out in my mind as soon as i read oop's comment. i made a mental joke about vb. then i said it's all the end at the end of the day. then i said why did i feel i needed to make that joke. then i said because it was funny. jesus. i need to get out of .net land for a while.
&gt; user uploaded files which can never be trusted to maintain the same format. this is a bad idea. attempting to interpret what a user thought they meant is a recipe for bug tickets. don't be smart. enforce a strict schema and give good errors.
don't do it. focus on error reporting instead. "expected a comma, but got this field { field }". Attempting to figure out what a user meant is a losing battle. Even I can't figure out what other people mean, and I'm supposedly a person, not a hobby library.
+1 star
For a side project, I have to read data from a CSV and have been using CsvHelper for that. Configuration was a bit weird, but once I got past that I was pretty happy with it. I tried to replace it with you library. It's a bit of an edge case as I'm using it with a runtime type. Alas, I get an exception stating that the type I'm using has no default constructor. As I have no control over that type, I obviously can't add one. CsvHelper seems to have solve that with a pretty twisted (but clever) way as far as a quick look to their source code can tell. I'll be sure to try your Library in more common scenario nonetheless.
&gt;Lazy Loading isn't in yet. I wasn't aware of that, but regardless, that seems like something you'd want to avoid anyway, as it would execute additional queries any time a "lazy load" was required, and executing a large number of queries (with all the additional network overhead that comes with it) is far worse than few queries that potentially return some unnecessary data. By keeping it 100% explicit, you'd more easily be able to know the exact number of queries being performed by just looking at the code and not having to also guess which navigation property accesses being done might trigger additional queries. &gt; You can't do raw SQL queries unless it returns an entity. Can you do that in classic EF? I thought the whole point of EF was to be able to deal with entities. There's already ADO.NET and DataReader for doing queries without using models. Not that I'd ever recommend using it in this day and age.
Not reading the file when it's totally clear what the user meant(at least to the user) is a recipe for bug tickets too. Hell CSV is a recipe for bug tickets.
The type mapper classes have a `DefineDynamic` method for supporting runtime types and languages without support for expression trees. For now, you can pass in a `Func&lt;T&gt;` to create instances of the type; otherwise it uses `Activator.CreateInstance`.
Hi... Have you tried this "JetBrains dotCover" &amp; Building NET Coverage Tool viz are .NET unit test runner and code coverage tool that integrates with Visual Studio. and if you want how to apply this you can refer to this free tutorial https://www.unanth.com/online-course/c-fundamentals-with-visual-studio-2013
Hi All Perhaps you're looking for an introduction into C#.Net with visual studio 2013 - One of the most widely used enterprise environments in the world. Do you need to start working on C#.Net projects with VS IDE but have no idea where to start? here is the free tutorials that can help you https://www.unanth.com/online-course/c-fundamentals-with-visual-studio-2013
Xamarin is **trash**. Pickup react.. then do react native if required for mobile. Use c# rest backend.
Well, then, the other way to do it is to automate a browser object and give it instructions. https://msdn.microsoft.com/en-us/library/aa752084(v=vs.85).aspx You have to look at the source code for the Amazon login and order history pages, so your browser object can write to the login fields, click on the login button, navigate to the order history page, find and retrieve the order data, and write it to a file or database. It's doable, but it's also fragile, because any change in the Amazon page layout will break your program. But I don't see any other alternatives. Create a console application project. Then add an Internet Explorer object to it. You should be able to find some tutorials for automating it. 
Please feel free to give me more details. These are the type of edge cases I'd love to know more about.
There is support for looking at fixed-length records prior to it being partitioned and/or parsed so you decide if you want to skip it. If it's just that first row, you could always just read it by itself, build up your schema and then run through the file again, skipping the first row.
I haven't reached the point where I'm playing out Reddit .NET jokes in my head yet, but yes it sounds like you need a break :)
Agree with this redditor , xamarim. Is **trash** .. react/react native would be much better for your carrier and is actually runs pretty good
OP crossed the line of sanity when he decided to write a flat file parser. There will always be 1000 different use cases.
He’s talking more like multiple record types in a single file with a discriminator. Like this 01COMPANY5555555555LAST FIRST 0258939 055 02635781 021
That's not really what I'm looking for. A very simplified (with just the first record) looks like below: AGYHDROTHERFIELDS AGYDS1OTHERFIELDS AGYDS2OTHERFIELDS BUYHDROTHERFIELDS BUYDTLOTHERFIELDS AGYTLR the schema for each line is different and is based on the first 6 letters for instance.
I think you guys jumped to a conclusion. I don't trust the schema, so I sniff the delimiter first to get the ball rolling since every CSV tool requires it in their constructor. No way would my users know how to open a file unless excel loads it first. SSMS's Import/Export is an advanced tool and it defaults to commas, but will let you override it. Other well know packages from python and node will attempt to guess the delimiter. Second, I can't trust the schema so I can't hard code to it. The user may drop a column off the template, etc. What I do instead to mitigate this is to provide them a way to map to my schema. I present them with the first 5 rows and have them configure which column goes to which column in my system. I then process the whole thing and keep track of which rows were good, and which failed and email them a summary afterwards. In the worst case that they ignored all duplicate warnings, or blank records, or mapped the columns to the wrong columns. I track what happened and can soft-delete their entire import with one command. If they still need me to put in a ticket, I'm okay with that. Every single customer is a happy customer and we like to keep it that way. I'll PM OP a gist and let him decide if he wants to incorporate the code into his package or not. 
Thanks, very interested to see what you've done. 
Oh so you look at a prefix or something and spit out a totally different class. That's pretty cool. 
I've never tried anything like that before, but I am fascinated. Let us know if you get it working, and what you learn along the way :D.
You need to release the object in JS not in the COM server. The clients need to release all the objects before the server unloading itself.
Yes! I would very much prefer have a nice API to do this versus having to do this myself.. it's a PITA to maintain.
Which gods did you offend to find yourself working on that problem?
Backporting support to legacy enterprise stuff that ran from IE unfortunately. Latest version is all 'proper' WPF, so no mucking about there, but the powers that be want some functionality backporting.
Releasing of the ActiveX part isn't the problem, it's the out-of-process component that I can't get rid of. It works with a simple 'hello world' type thing, but as soon as I introduce WPF it all falls apart. Thanks though!
I need to run this on Jenkins which is on an Ubuntu ec2 instance, hence why I need a code coverage tool that is Linux compatible. I'm pretty sure dotCover is Windows only, unfortunately.
https://www.telerik.com/products/aspnet-ajax.aspx I think this will help you get through in developing a website in c#. I am also a professional c# developer currently working on inventory website of Indian Army. I am using these Telerik controls for all UI. Even they are helpful in generating reports using tables and crosstabs. I also only have a basic knowledge of HTML and CSS. So Sir, if you face any problem I will be happy to assist you. Email Id: - sonikasood94@gmail.com 
I have always done the narrowing in the Model, prior to the model being shipped off to the View. Yes, if you have a gargantuan table with 50 columns, and are looking to return just one item in one row, this is an issue. Unfortunately I have not had a need to dig deeper into this issue yet.
If it's working and you're able to properly catch and ignore that COMException, I wouldn't spend any more of your cycles on it. If someone here or on SO happens to provide a solution, implement it, but I'd move on to something else.
Your are not required to synchronize database entities with something like rest resources. The incredibly well defined repository has strong definition to be a collection of CRUD operations for a single type's persistence layer. This allows you to trim down a large object definition into what a smaller more fitting type definition. What you should look out for is that a eg. SlimUserModel should always contain the full primary Id of the source object. Then you make a repository for that slimmer type and woosh done
My wild ass guess (as some one who has done my fair share of both WPF and COM programming) is that the WPF engine is using some OS hooks to do it's message pump and scheduling. It's possible that when it sets up the hooks, the OS is keeping a reference back to your process which keeps reference count &gt; 0. I don't know what to suggest for a fix. I'm guessing there's supposed to be some call that stops the message pump and releases the hooks that isn't being made. This is probably because of the way the process is being started missing some part of the initialization code that would happen for a normal user initiated process. I don't know enough about the inner workings of WPF and how it's all built up and torn down to have any meaningful suggestions. I think the guy that's saying if you've got a working solution that isn't causing problems, just roll with that and don't waste any more time on this is probably on the right track.
This is pretty-much what I'm thinking. I'm running with it for now, and if I can find a better way before this needs to go into production then great. Thanks!
My thoughts exactly - until I can find something better, I'm going to run with it. Thanks!
Thanks buddy.
NP. If you go the MVC route and start using that boilerplate, there are a few gotchas that might trip you up; don’t hesitate to PM me with questions.
Haven't tried with that kind of setup, but I have used XBAP to run a WPF app in a browser. Have you looked into that?
https://www.connectionstrings.com/
This gets the brain juices flowing. I was imagining a "multi-type-mapper" at lunch that let you combine multiple type mappers together and switch between then based on a `Func&lt;string, Type&gt;` or something.
* You would have to open up the MySQL server’s port to world+dog, and then take steps to restrict the connecting IP addresses to a limited pool (such as the one you are trying to connect *from*). * You would then need to use the IP address of the MySQL machine in your connection string. Also: Why webforms? It’s like trying to get onto the interstate using a Roman chariot. Doable, but quite inadvisable. This is ancient tech, no longer being developed or improved. Double also: Why MySQL? Granted, you can use any DB you want, but DotNet (and especially Entity Framework) does work best with MS products. If you already have Windows Server, why not MSSQL? Final note: If using MySQL, [beware UTF-8 encodings](https://medium.com/@adamhooper/in-mysql-never-use-utf8-use-utf8mb4-11761243e434). 
Your first example stored procedure doesn't properly use the @location parameter and filters on the constant value 'Texas'
Thank you for your response, I have a few questions. When you say open its port to world+dog, How would I go about that? So I use the machine's public IP address as the server IP, and reference the database the same way? Webforms seemed simple for what I'm needing to make. It's just a database for people offsite to add records to. Basically taking an access database we currently have and making a webform version of it. Right now I'm just using it to test the vpn speed of our offsite techs using it. What would you suggest instead of webforms? Using MySQL because that's what the person previously was using it and I just picked it up from there. The initial development of this was on a separate laptop running windows 10, before I learned what OS were on our virtual servers, so that's part of why MySQL. Is mssql going to work better with asp.net? I'm not sure what DotNet nor entity framework are but I will look into them. I'm very new to all this and with a test deadline of next week, it's probably a little late to go ahead and change everything for the speed test. For the going forward build I can change things though.
Thank you.
Trick them with an IE Window inside your wpf app. That'll do the trick 😂🤣
https://i.imgur.com/c9BBCm5.jpg
There's not enough context here, what does your "narrowing down" involve?
Meh. Not so applicable for docker and .net core. Good stuff for corporate world tho
&gt; When you say open its port to world+dog, How would I go about that? Open up the correct firewall port for MySQL (not sure of it myself), ensure that you can connect to the MySQL instance remotely via TCP/IP. Find the IP address of the web server that hosts the site. You will then need to create a new user within MySQL, and use the web server's IP address in the creation process: mysql&gt; GRANT ALL ON fooDatabase.* TO fooUser@’WebServerIPaddress’ IDENTIFIED BY ‘my_password’; &gt;What would you suggest instead of webforms? As I said, WebForms can be really quick and easy for very tiny projects, but anything decent in size will run into Spaghetti Code area pretty fast. If you are new to MVC, you want to start out with MVC 5, as it has the most copious documentation and help available on the Internet. It will also be around for quite some time to come. If you want to jump ahead of the curve, go for Core v2. Just be aware that 199/200 of any search results for Core that you find on the Internet will be for pre-v2 core, and will most likely **not** work with v2. Documentation for Core v2 (outside of official Microsoft resources) will be extremely thin on the ground. With that said, Core allows you to build a site that works just fine on Linux, allowing you to run your Core site on the same machine as you run MySQL. &gt;I'm very new to all this and with a test deadline of next week, it's probably a little late to go ahead and change everything for the speed test. For the going forward build I can change things though. Then definitely stick to what you have right now. DO NOT switch to something else like MVC/Core, as the learning curve will be too steep for you to get everything up and running in that time frame. If they hand you a new (greenfield) project down the road, PM me for details on how to swing something shiny like MVC/Core to them, along with the requisite learning curve. &gt;Is mssql going to work better with asp.net? I would say *more efficiently* rather than *better*. And the difference probably isn’t strong enough on small projects to notice much of any difference, so you should be able to keep on using MySQL unless you have a specific MSSQL requirement. As a final note - if possible, drop MySQL in favour of MariaDB. It’s an ethical difference at this time (rather than a technical one), but MariaDB is not locked into an abusive owner. MySQL is. MariaDB can be a tiny bit harder to set up, but is equally as capable and has even more features/functionality at this time.
Did you compile the application after you made your code change?
The current version supports .net core 2 https://github.com/SteveSanderson/Blazor 
Did you recompile and replace the dll?
This looks very nice, will be giving this a whirl tomorrow.
Also be sure to grab the NuGet package for MySQL.Data
You're looking for PROJECTIONS of the data into new models. You'll probably want a second model / entity and then either a separate repo to manage it, or extra methods on your regular repo for providing this "projection" of the data. Which way you go kind of depends on the situation and what feels right. If you are using Entity Framework, I'm pretty sure you can use .Select() and project straight into a new structure off the main entity set within your repo.
Thanks, article updated :)
As others have indicated, it sounds like you either failed to compile a new binary with the new changes or, you're dealing with some kind of issue related to codebehind/codefile distinctions.
Does this work for apps running under mono? 
Interesting, this is an area that definitely isn't "plug and play" and requires some understanding of the implications of choosing a particular approach. Indeed, I think this is why "frameworks" such as Identity Server 4 and Auth0 exist, to provide a way for your app to adhere to standard best practices so you can focus on building features rather than studying up on the nuances of JWTs vs cookies and other thorny security issues. By way of example, I was called out on a blog post I wrote suggesting to use standard session cookies for SPA &gt; API auth. It was pointed out to me that, when used for auth from a SPA to your API, session cookies are vulnerable to Cross-site request forgery. [http://www.redotheweb.com/2015/11/09/api-security.html](http://www.redotheweb.com/2015/11/09/api-security.html) That article ^ is well written and definitely worth a look if you want to understand some of the nuances around using JWTs vs Cookies. 
I forget what it's called but do you have the code behind files deployed to the server, instead of having everything compiled into a dll? You may need to clear out "%SystemRoot%\Microsoft.NET\Framework\versionNumber\Temporary ASP.NET Files"
It supports NetStandard2.0 therefore can be run on Mono 5.4 and later.
If you want to narrow down the fields isn’t a different model the solution ? If it’s too much duplication then use inheritance to fix that 
I did not compile. I suspect this must be what is going on, but I can't seem to compile correctly. I have never used aspnet_compiler.exe and am having some trouble with it, as back when I created the site, I just used Visual Studio's compile menu. So after reading up on it I did aspnet_compiler.exe -p &lt;path_of_website&gt; -v / It cranked for a while and came back with no errors. However, I can't find where the compiled files are supposed to be. All I see that's new is a bunch of files in the %SystemRoot%\Microsoft.NET\Framework\versionNumber\Temporary ASP.NET Files folder. The /bin folder of the websites remains unchanged (same .dll and .pdb file). So I guess this has turned into an issue of how to properly compile without having to install VS. 
Do you not use versioned assemblies, command line arguments, or environment variables in your .net core applications? I can see some of this stuff not being as relevant for a containerized service, but it's better to capture a little extra than not enough. Logging is for catching the breaking externalities you didn't think to test, after all. Extend this with information about the container and you've got a lot of your bases covered.
Normally when you add a control to a WebForm, Visual Studio generates code for you in the aspx.designer.vb file. Visual Studio Code doesn't do that, and I expect that to be your problem. You could download [Visual Studio Community](https://www.visualstudio.com/vs/community/) for free and use that.
Addendum: If you are able to log on remotely as `root` *without* needing a password, you really need to lock down your MySQL installation. Please run the `mysql_secure_installation` script which significantly locks down security.
Then why not download Visual Studio and compile from there? The community edition is free.
I will definitely use this!
I've recently shared JWT integration for Identity 2.0, it might help: https://github.com/lugrugzo/WebApiJwt
Getting ReportGenerator to build on Mac with Visual Studio for Mac was easy, just cloned the GitHub repo and opened the "ReportGenerator.sln" without any changes it compiled and ran. I do not have experience deploying either dotnet core or Mono apps but perhaps you know how to do it? [Here is a screenshot of ReportGenerator building in Visual Studio for Mac](https://imgur.com/a/7Fpw5)