I'll give it a closer look. Thanks!
Would you elaborate on why you think Onion is dated and what alternative replaces it? What are you steering your teams towards?
On Windows OS or something else? Locking files on a network share is notoriously unreliable on Windows OS. Not sure about other OS's, but be aware you may encounter unresolvable issues with that strategy, and they may not show up in development.
[removed]
CEO: How in the world did they access everyone's medical records? CTO : we are still looking into it. We do already know that it has nothing to do with the wonderful software your nephew who just graduated wrote for us. 
How so?
No worries :) I am doing it for my school project.
OP stated they had successfully saved an uploaded file to the filesystem. In my mind if you can save a file to one location it really shouldn't be that hard to save to another location. So I took the real question to be how to I serve a file to a user that is not inside wwwroot and my code example shows one way to do that. On a side note, at least my response attempted to help OP with his problem. Your comment was not only unhelpful but a bit rude IMHO.
Your code was basically a method signature, a vague comment about pulling an array from some source and a return statement. Your answer seems to miss the point. He said he doesn't want the file stored in the root yet your answer does nothing to remove it from there and serves it up as an array without helping him figure out what to do with it after that. I think you just misunderstood his question though tbh. I had not helped with his question but neither have you. I personally think a Virtual Directory might be the answer to his problem. Sorry I hurt your feelings, btw.
I am not 100% sure, but I believe that any time you are setting the variable *currentLocation* you need to convert from the repository object to your model. So instead of currentLocation = db.locations.Where(l =&gt; l.locationID == id).Single(); You need something like currentLocation = db.locations.Where(l =&gt; l.locationID == id).Single().Select(x =&gt; new location { locationId = x.locationId, locationName = x.locationName, etc. });
I would highly recommend adding another layer to this architecture if that is the case. A simple webapi to send and retrieve your data will alleviate a lot of headaches that you are dealing with. if you are comfortable with it, even making it a web app altogether seems the best route; what you are trying to do does not seem to lend itself to a distributed client as much, but possible with a centralized data store. If you are open to this, I would be happy to help further. But either way, I strongly suggest to centralize your data store in some form of webapi.
Checkout LiteDB
DevExpress has something called the eXpressApplication framework, never used it but all of their other components are rock solid. https://www.devexpress.com/Products/NET/Application_Framework/
tl;dr = Microsoft sucks at LOB applications. Right? Quick question: Does anyone here know WHY they killed Lightswitch? It's probably futile, but since this is the latest code generated type of effort to be abandoned by Microsoft, I'm curious. Ever since they did the same exact thing with Visual Interdev and Design-Time Controls, I've been curious why they keep doing this with generative approaches. That is, every time they come up with an approach which uses code generation techniques, they eventually abandon it. Of course, now they use Roslyn in much the same way with C#. Most of the new C# keywords actually just result in code generation templates to be executed which generate new IL which generate code. The only difference here is the level within the stack in which the code generation occurs. Obviously, C# is a first class product around Microsoft. I'm not implying they would ever abandon it. That said, why would they have ever abandoned other efforts that could have been sustained just as long or longer than even C#? For example, Design-Time Controls could have been grandfathered into a new version that changed the code generation back-end to .NET. It's easy to see how DTC could have evolved into Lightswitch, since they addressed the same sweet spot. And it's easy to see that Lightswitch itself could evolve to become something even better. That all said, I have to admit some ignorance about Lightswitch. I write about them as if they were equivalent, and I'm sure they're not, even though I never tried Lightswitch because I saw how they treated DTC. The fact of the matter is that I don't trust Microsoft to design LOB oriented APIs. Microsoft could, and should, be excellent at LOB application development. But the fact that they keep pulling stuff like this means that they're going to continue to cede the LOB segment to Oracle. Oracle understands this segment. They call it Oracle ADF, Fusion, and BPM if you're going to extremes. Apart from BizTalk, Microsoft has a gap here, and I think most would argue that BizTalk doesn't cover nearly as much ground as Oracle BPM. When it comes to LOB application development, I think most businesses spend far more on this than they should. I don't understand why Microsoft would neglect this space. Maybe C# and standard ASP.NET + MVC + SQL Server are enough? I have my doubts. Maybe Dynamics on Azure is going to fill this space? Anyone? Bueller? 
Visual Studio has some built-in scaffolding with MVC and Entity Framework. I'm about to hit the hay or I'd find it for you.
Is there a reason you can't use an internal web app or at least a web API? Seems like an internal web API would solve the database issues and having it all web based would make deployment and updates simple
I honestly can't tell if the object-oriented "replacement" for _switch_ is satire. It looks like it came straight out of [The Kingdom of Nouns](http://steve-yegge.blogspot.com/2006/03/execution-in-kingdom-of-nouns.html?m=1).
Where are the views?
&gt; https://github.com/gothinkster/aspnetcore-realworld-example-app This is specifically a REST API. There are views in the linked reference project in the README: https://github.com/jbogard/ContosoUniversityCore/tree/master/src/ContosoUniversityCore/Features/Instructor
WTF did I just read? 
I scrolled up to check that this wasn't a repost from April 1st.
What is wrong with it?
AKA "How to needlessly complicate straight-forward code" It seems to me that, if you should try to argue against a particular construct, it doesn't really serve your purpose to include an example where it is by far the simplest and least repetitive, and suggest two other implementations that are at best slightly more complicated. The "OOP" way is just terrible, frankly.
It does but it's not really comparable to LightSwitch which is more akin to MS Access.
I've not tried it but [DotVVM](https://www.dotvvm.com) is an attempt to bring some RADness to the ASP.NET stack.
Pretty cool, in that it replaces a javascript framework like Angular/Ember/React/Knockout. It still seems to require a fair bit of coding, and learning a new framework, but it does save me from having to learn JS from scratch. The thing I really liked about Lightswitch is the ability to generate an entire web front end without actually writing a line of code. I wish MS would bring back a tool that could do that.
I have looked into those but I don't find them as intuitive as everyone seems to think they are. They still require authoring a full UI (e.g. web templates, CSS, JavaScript). though they do connect view and model on the server side, They don't seem to offer much beyond what ASP.net already provides, unless I'm missing something. 
Microservice patterns don't really invalidate the onion architecture though. The major part of the onion architecture is to externalize dependencies like the database, file reads, etc. and write adapters for them as to reduce tight coupling. You're doing the same thing in each of your services, as well as your consuming apps really. Just because your domain is now across many services doesn't invalidate what the onion architecture is trying to achieve. The major benefit you have with microservices is really pushing the single responsibility principle and independent technology stacks to the forefront.
Polymorphism instead of control-switching is a reasonable idea when the complexity of the switch statement grows untenable. 
I'd have to guess anything written directly in SQL is always going to be faster, as EF just writes SQL for you, so no auto generated thing will ever beat a skilled DBA. As someone who has probably a wider breadth of knowledge in SQL than most guys who don't call themselves a DBA, that's not the benefit of EF. The benefit is making it easier to write code against your DB, even when you know how to write the SQL equivalent. If you tack on maybe working in a non ideal environment/setup, where maybe the DB schema doesn't adhere to strict rules, and intellisense is a freaking god send. That, and things like being able to write simpler CRUD statements in one to two lines, just make writing code really nice and clean. Whenever I need to do something more complex in SQL, then I usually use SQL and SPs/views, etc. But when I have a form that inserts one record or something like it, I'm using EF.
Have a look at https://github.com/yuvaltz/Granular Check out the demo too. Write wpf, get HTML. 
The examples provided don't really help make his case. When you have 3 cases with 1 line each the switch seems pretty reasonable (though I don't like switching or any conditional that uses magic values). However when you have 10 or 20 cases with many lines of complicated logic in the case itself or a bunch of single use functions on that same class, the polymorphic approach becomes much more palatable. Using DI that supports resolving IEnumerable&lt;ISomeInterface&gt; helps with not having to keep modifying the factories when a new key/implemention needs to be added.
&gt; The major part of the onion architecture is to externalize dependencies like the database, file reads, etc. and write adapters for them as to reduce tight coupling. Usually, good unit test coverage does too :) &gt; Just because your domain is now across many services doesn't invalidate what the onion architecture is trying to achieve. Except, I would argue that a layered, prescriptively named and organized approach has the biggest benefit in a monolith, so microservices (in my experience) reduce, or often, completely eliminate the need for this architecture. &gt; The major benefit you have with microservices is really pushing the single responsibility principle and independent technology stacks to the forefront. Agreed. And just like I am pushing SOLID principles in my designs, I'm also pushing for YAGNI as well. I don't start with a prescribed architecture with an Entities assembly, referenced by a Repository assembly, wrapped by a Services layer. Articles like https://social.technet.microsoft.com/wiki/contents/articles/36655.onion-architecture-in-asp-net-core-mvc.aspx) seems to push this approach, and I've seen projects built this way over and over again. And they are a huge PITA to maintain, in my experience. Anyway, this is the particular cross I am dying on at my current job, so I have strong opinions about this :)
I don't disagree, but large switches are a huge design smell to me, and usually indicate a problem with the underlying design. Seems like this example just masks the underlying issue.
Something I was looking for! Very similar to this Ruby Gem that I've been using: https://rubygems.org/gems/dotenv
&gt; How good a average C# developer is in JS compared a frontend guy doing JS all day I mean probably not as good, but you can learn. &gt; Is there things you can't do with the latest Asp.net or the core one that you can in react or angular If you needed an application to do &lt;insert requirement&gt; then you could probably use either. React / Angular / Vue are obviously designed for complicated front-end applications so if that's what you're looking to do then they'll be the tool for the job. &gt; does MS still impose strict rules in VS like its own version of JS or html like xaml things who are only in the ms dev world that we dont see in atom or sublime text 3 or vscode etc For front-end? Not that I'm aware of. Most of the front-end stuff is customisable in VS anyway. As for your other questions, most people I know doing C# also do javascript. The split depends on what you like, or at least it has in my jobs. JS is more popular because it has a very low barrier to entry, and the entire web runs on it. C# has struggled whilst Microsoft was still charging stupid money for VS and the whole ecosystem.
Me likey! Thanks!
I missed the 'was' Apologies
This looks really useful, my only concern is how does this work x-platform? I work on macOS and deploy to Linux and have found environment variables behave a bit differently to Windows (though I was previously using the Environment class in Mono / .NET framework and not .NET Core).
Ref please. I've never heard of that.
You are doing multiple `WriteAsync` without awaiting.
I've just had a look at the documentation again in case I missed something but I believe my previous comment is correct. CMake takes a CMakeLists.txt file and produces build file(s) for your specified generator. For C\C++ on unix that would usually be a Makefile. So you'd still have to run make to actually build the application.
I agree, and, as a crappy UI techie, I've lived and died bootstrap. I find though it's getting a bit dated with such frameworks as MDL, React etc. UI and UX is a craft on its own and I, personally, have a good enough eye to know it's an area I do not excel at and others do. Happy to admit though I'm talking for myself, and I've worked with some people better than me who can somehow straddle both skills, and I more than admire them for it
Holy shit, how did I miss that? The page I copied and modified to make this had that, but I must have accidentally deleted it. Now I'm getting different errors that I should be able to work out. Thanks, I was getting ready to pull my hair out.
I highly recommend learning React or Angular. The job market that is open to a highly competent front end engineer and/or full stack engineer is very wide.
I see the post about CommandType.StoredProcedure helped you move on. You might also want to consider using Guid.TryParse(_acc, out acc) to check if the GUID value was parsed correctly. Just a suggestion...
If anyone at work would use this, it would be an instant rejection. This is code obfuscation - it's not making it cleaner. Instead of having the actual type you have a file-local name that can change from file to file.
why
[I am doing almost the exact same thing](https://github.com/JohnPicchi/Authentication/tree/master/src) Going back I would probably not use the onion architecture because the application is not large enough, however, I forced myself to use it because I was trying to learn it. That being said, I would not jump on the micro-services bandwagon like others may be suggesting, you should consider you're overall software architecture carefully, unless you are using this project as a means to specifically learn something. I am still on the fence about implementing asp.net core identity because it feels like I am losing too much control. Since asp.net identity is extensible, it allows you to write your own implementations of their interfaces, I tried doing this but realized alot of the stuff was overkill. However, like I said, I'm still on the fence about using it, maybe you can persuade me? I am using ASP.Net core, EF core and IdentityServer4 This is my side project and it's a work in progress, so you might find a little bit of poorly written code caused by some experimentation and code that hasn't been written yet.
Agreed. I would not be happy with the dev that did this. Code should be *readable*.
&gt; like WebBrowser, WebClient , and HttpWebRequest? No, not like any of those. The first is a browser with a head, a browser engine most devs don't want to use, and doesn't offer the API's most will need to do what they intend to with a headless browser. The other two aren't browsers at all.
I know it's a little late but I stumbled upon this post :) I can recommend [InnoSetup](http://www.jrsoftware.org/isinfo.php) My company has been using InnoSetup to create installer for .net based products for several years. 
The parameters don't need to be at the end, either. I use: routes.MapRoute( name: "Start", url: "{accountToken}/App/Start/{userToken}", defaults: new { controller = "App", action = "Start" } ); paired with an action with this signature: public class AppController : AppBaseController { public async Task&lt;ActionResult&gt; Start( string accountToken, string userToken ) { .... } } As for displaying something in the URL other than the actual route, I'm not sure that can (or should) be done. You could incorporate the date and problem name in a URL that you redirect to after the initial action. But you'd still have to be equipped to handle that URL properly and maintain the original IDs in session or something. I think you're better off leaving the URL as your unique resource identifier using other elements (title, page elements, etc) to provide date and problem context.
https://social.msdn.microsoft.com/Forums/en-US/6b6bb16c-06e7-40d4-9e2b-fba982a74b0b/sysforeignkeys-isnottrusted-problem?forum=sqldatabaseengine Also this one: https://dba.stackexchange.com/a/103248 Post is from 2014 but I can confirm that it still happens on SQL Azure v12 
Untrusted means the query optimizer can't rely on the constraint. This means that a join between 2 tables will generate the same query plan as if there was no foreign key at all, essentially omitting all the performance benefits gained from using foreign keys. This article shows the difference in query plan and cost: https://www.sqlshack.com/managing-untrusted-foreign-keys/ It can be pretty severe for a busy table with lots of foreign keys.
Many thanks for sharing that post :) I used https://github.com/graphql-dotnet/graphql-dotnet here in that post, because it has a lot more community interactions (stars, watchers, contributors, etc.)
The error is occuring here however: if (id == null) { //location location = locationList.Find(0); currentLocation = db.locations.Where(l=&gt;l.locationID == 0).Single(); //ERROR HERE } else { currentLocation = db.locations.Where(l =&gt; l.locationID == id).Single(); }
Basically .... bad documentation, opaque api... "magic"... Unless you have the time and the inclination to learn exactly what's holding everything together, you're looking at stuff that happen because..."reasons" I'm currently trying to work out issues using console.log ...it's like working in DOS with no ide debugger to make it less brain straining
Well you can use [JSON Schemas](http://json-schema.org/) to validate the submitted object and ensure it is appropriate. We've been using the [Newtonsoft package](http://www.newtonsoft.com/jsonschema) on a WebAPI project and it's pretty nice!
&gt; VS like its own version of JS or html like xaml things who are only in the ms dev world that we dont see in atom or sublime text 3 or vscode etc No MS does not impose any restriction. You can use any editor. Nowadays they don't have much restrictions. 
You are right, it does say that. I missed that. I also noticed that it says you shouldn't use environment variables: "Environment variables are generally stored in plain text and are not encrypted. If the machine or process is compromised ... Additional measures to prevent disclosure of user secrets may still be required." When I read your comment I thought environment variables would be the alternative. If environment variables and user secrets shouldn't be used in production then there's nothing out of the box that I know of. I'll update the article with comments about this. But I still believe that user secrets are a useful way of not ending up with credentials in source control or as a way of having different configuration in different *dev* environments (environment variables would work here as well)
So how long before we strap so much onto the JSON data format that its pretty much indistinguishable from SOAP? I don't hate JSON and I use it liberally where it makes sense, it just seems silly to add strap ons to a data standard when there is already a 20 year old data standard that does all of this and its part of the spec rather than 3rd party processor add-ons. 
Oh. Well then make your controller action return View(List&lt;YourItem&gt;), then use razor @foreach to iterate through the list and write out whatever HTML and properties of your list items that you like. https://stackoverflow.com/questions/4463000/razor-syntax-foreach-loop
We open sourced a dead-simple secrets manager for .NET 2.0+ (and .NET Core) that keeps everything encrypted at rest and is version control friendly, if anyone is looking for a proper secrets library: https://neosmart.net/blog/2017/securestore-a-net-secrets-manager/ Edit: I misremembered the supported .NET platforms. We're working on fixing that soon w/ a proper nuget release.
Again the article suggests something - the Azure key vault: "You can safeguard Azure test and production secrets with the Microsoft Azure Key Vault configuration provider. See Azure Key Vault configuration provider for more information". 
Dotenv is awesome 
That's true, but that leaves out all the people that don't host on Azure.
Can you explain what you mean? Do you mean secrets?
Anyone could throw that up in a nuget package and make it a one-liner..
Do you happen to know if your users use them? I noticed that our app has no mention of them and want to see if I should bring up the idea or not.
I use the dotnet generator for react + asp.net which uses npm + webpack. Works well but I'm not sure how'd you set it up manually.
Yes. Perhaps "fix" is a poor choice of words. I think though that allowing this sort of behavior should require an additional flag to be set (like Ignoring SSL certificate warnings or disabling request validation).
OP means hotkeys, for those confused.
They can only do so much. At some point you need to accept responsibility.
I think Dapper is overly complicated. I can get similar, or even better, performance than Dapper just using CSScript+Rosyln for runtime code generation. I can't even understand the Dapper materializer code.
Sure, the distinction I thought was worthwhile because Access Keys could mean things like product keys, serial numbers, etc. Just my $0.02.
I would recommend getting webpack on the go. This guy on YouTube has a good series of tutorials on how to get started - https://m.youtube.com/watch?v=GU-2T7k9NfI&amp;list=PL55RiY5tL51rcCnrOrZixuOsZhAHHy6os&amp;index=1
I hate how there have been 5 or so runners / package management tools that have been "the best" and then have gotten replaced within a year or two with the next "best" at which point it gets replaced. The JS world is crazy. What's the upcoming replacement for webpack going to be?
Anything with better documentation?
I do in my desktop WPF apps.
Unless you have a really good reason to deviate, just use npm for all javascript packages, npm scripts for tasks, and use webpack to bundle. JS tooling is a mess. And no one has enough authority to straiten it out unfortunately. It's clusters of mostly uninteroperable ecosystems, duplicated functionality, weak commitment to user experience and mostly needless configuration. Everyone thinks the have an essential, snowflake use case that requires a configuration option.
Have you ever looked through their [documentation](https://webpack.js.org/configuration/) or their [guide](https://webpack.js.org/guides/)? Webpack is hard, i agree on this but it is just an investment of time to get up and running, and even basic stuff is really easy to achieve. When it comes to something like *jsx* or similar it will get a little bit harder but i mean thats programming. Also dont compare webpack to a task runner because the intention of both (grunt/gulp compared to webpack) is different. Gulp/Grunt was built for doing Tasks, in any way. Webpack is module bundler and is just doing this and you can extend functionality by plugins. The biggest problem with JavaScript currently is that a) not all browsers support the newest standards (shame on you IE)... b) The module system which will still get changed in the future (even though on the base of ECMAScript Modules). To get an idea of modules i recommend this [article](https://auth0.com/blog/javascript-module-systems-showdown/). This describes the problems of the JavaScript Module world. Anyway normally its enough to have npm and webpack for web applications. Even npm [can run tasks](http://blog.teamtreehouse.com/use-npm-task-runner) like gulp now. This combined with webpack's commands will get you to an easy running project.
They are good for accessibility
I've come to do js dev from the dotnet world, starting a few years back. And you've described exactly how I feel. Why do many poorly documented Json files litter to everywhere, each with a million options only one of which is the one you want. Good luck finding it, write your own!
Sure, that's fair.
In the Options dialog search for TypeScript. You should see something like [this](http://i.imgur.com/W7YQVdr.png). Alternatively see [here](https://github.com/Microsoft/TypeScript/issues/16177). 
Thank you! In conjunction with a tsconfig edit, this seems to have fixed the issue. We added the following line to the `compilerOptions`: &gt;`"lib": ["es2015","dom"] It required both of these.
&gt; C# is nearly uniformly superior to Python: performance, productivity, tooling. Yes, yes and yes. After taking several ML courses that used python, most times I ended re implementing algorithms in c# that ran 3x or 4x faster. I also think c# could be a nice language for *Deep Learning*, but there is a massive gap in libraries available.
Have a small business / LLC? Check out bizspark. Also might be cheaper to buy vs cloud services since they come with azure credits if you are already paying for visual studio
100% this. The lowest tier app service is free so depending on what you need that will cut down hosting costs straight away. I have used free/shared for a lot of small projects and it has been fine. See here https://azure.microsoft.com/en-gb/pricing/details/app-service/ . SQL server as PaaS is much cheaper too, basic tier is suitable for most small apps in my experience. Again see here https://azure.microsoft.com/en-gb/pricing/calculator/?service=sql-database Even better you can publish and update these straight from visual studio if that's what you are using? 
I'm a user (but not of your software I guess) and I always use them and try to avoid the mouse as much as possible.
You should really go for app service and paas sql. VM's will always be more expensive. Note that you pay for the app service plan, and not the app service itself. You can host multiple app services on one plan. (Except for Shared which is per app service) So with app service you are looking at $55 per month for a vm that can host multiple sites. There are multiple reasons to go with App service instead of a VM. * Easy scaling. Scale up or out within seconds * The VM is updated for you. Never need to worry about keeping the vm itself updated, etc. I've used app services for a couple of years. Some of my sites have been left alone for years and they are still running 24/7 just like I left them 3 years ago. 
The Microsoft site has fantastic beginner tutorials. They cover basically everything and they're free.
This, but if you need few Azure credits, try Visual Studio Dev Essentials program. https://www.visualstudio.com/dev-essentials/ &gt;Exclusive benefits only available through the Visual Studio Dev Essentials program. The Azure credit is in $25/month increments for 12 months. 
/u/DooMachine1 I decided to go with ASP.NET core Identity. I am unsure if I am going to adhere to the onion principle again, since this project is not large enough. You can follow my progress [here](https://github.com/JohnPicchi/Authentication/tree/dev) if you are interested.
From your link, the cheapest SQL Paas is ~$75 in West Europe
True, my bad, it's because their pricing starts at 50 dtus on that page, but you can actually go down to 5. If you go to the pricing calculator and go bottom tier, you are looking at ~$5 per month https://azure.microsoft.com/en-gb/pricing/calculator/?service=sql-database They could do with explaining that on the page, I will update the link in the other post too - thanks!
you're way overpaying. Just use the hosted website and a hosted db instance. It'll be way cheaper. like WAY cheaper. 
I liked your work, but I will work with single context and it will be my main project. I decided to start [this project](https://github.com/aspnet/JavaScriptServices) to handle presentation . Now trying to figure out redux+react thing to work with client side. I will upload my project may be 1-2 week later as stable state.
You could also make it so both have a similar interface (i.e. GetSchedule) but depending on the base class would return different schedules. 
If you're talking MVC wouldn't a partial view be the way to go here? Display the common data in the main view and pick the appropriate partial view for the schedules.
treat mvc as an API and put the logic in the front end in angular.
Wow I didn't know that. I read about DTUs but I have no idea how to plan a project in terms of DTUs. I suppose for a personal project, the lowest tier should be sufficient. 
* https://www.reddit.com/r/learnprogramming/wiki/online * https://github.com/Michael0x2a/curated-programming-resources/blob/master/resources.md#c-sharp
Because then they could not allow it during runtime with a simple flag anymore. Also, they would have to provide two different versions for the library: One that has the methods, one that does not. That will cause issues with dependencies down the line - which of the two packages should libraries reference?
This is already a breaking change for people who wants to migrate to 2.0 (which at this point is probably all production). I rather they break it at compilation time than at runtime. I don't think there are *that* many .NET Core 1.0 and 1.1 systems on production. I know it's smelly etc, but they reach this decision already now.
&gt; I rather they break it at compilation time than at runtime. I don't think there are that many .NET Core 1.0 and 1.1 systems on production. Again: They'd either have to completely remove the API or provide two packages (and then we run into the previous mentioned issues, except if we have two different packages with the same name - for which we don't have the means via NuGet). They will not completely remove the API. They can't. There's a lot of existing legacy code that can't just be rewritten entirely, even when migrating to ASP.NET Core 2.0. A flag re-enabling the option to have sync file access is a good choice.
We will need an analyzer to detect the usage of Read and Write otherwise people will end up to always re-enabling the option because you simply don't know what the third party libraries are using. 
Analyzers operate on source code. They don't analyze third-party assemblies.
No surprise. The tooling for consuming an endpoint and generating the wrapper classes only generates the async methods. Seems pretty clear that async is the future of dot net dev.
I read npm and stopped. 
I'm using Dapper and Postgres via NPgsql on NET Core for over 6 months now and it's great. I've been using core since early betas so I don't wasn't afraid. There's a fair bit of grunt work creating pocos for the DB on a pre-existing schema. If you can get some way to generate the classes then it's great. I tried several things to take some of the grunt work like updates/deletes out of the way but I didn't find anything I liked. Did something custom but probably more to do with my constraints and learning process than anything. 
Doing the same as you. We are using it for the backend to graphql 
out of curiosity (not a value judgement), why would you use dapper over ef core? 
Link for the interested (I certainly am :-) ) http://jasperfx.github.io/marten/
Entity + identity + Postgres, for schema generation and auth system. dapper + Postgres, for querying. Works great!
&gt; I searched around and found this app that was recommended on Visual Studio Magazine. We use it to generate all of our POCO's and it's been a God send! I just started a new job, I was so glad when I found this a month ago and discovered I didn't have to rewrite the one I already had. (I was also relieved that my efforts at my old job were not wasted, as the generator I wrote worked far better on Oracle than simple modifications to the VSM one would have allowed.) The one downside is out of the box, it doesn't support nullable types, but that can be fixed in just a few minutes.
It's common to see mixtures of the following: * Models * Lib * Services * Views * Controllers For you, if you want a separation between services and code which consumes services, `Lib` might be the ideal place. Just the fact that you're considering separation is good enough though, what you call the folder can easily be learned by someone else
Services can have dependencies on other services and that's fine. Just be sure to use IoC. You don't even need an ioc/di framework for this. Just pass the interface of service B into the constructor of service A as a nullable parameter. Then in the constructor do something like this this.SmsService (private local variable) = smsService(param) ?? new SmsService(concrete service class used as a fallback). smsService parameter is of type ISmsService in this example. Does this make sense? This lets you mock the sms service by just passing in a different ISMSService to ServiceA for testing.
I found the following article useful for this: [http://michaelcrump.net/using-github-with-visualstudio-code/](http://michaelcrump.net/using-github-with-visualstudio-code/) 
I used Marten + Postgres for a personal project and liked it a lot.
whoah that worked, no extensions necessary haha, thanks for the help!
I was trying to avoid this as it felt wrong, but you're right! Thank you.
Data is nothing without behavior and behavior is nothing without data, hence OOP. We tend to split between Core and Web, if only to be able to reference Core in a Tests or Worker project.
Looks good, I would suggest just changing two tiny things. * Use UT8 instead of ASCII to convert the salted password to bytes. This will prevent issues with special characters. * Use base64 instead of hex bytes as a salt. This will give you more entropy with less characters.
If this is to store/validate passwords, please consider just using BCrypt or SCrypt
Non-Mobile link: https://en.wikipedia.org/wiki/Base64 *** ^HelperBot ^v1.1 ^/r/HelperBot_ ^I ^am ^a ^bot. ^Please ^message ^/u/swim1929 ^with ^any ^feedback ^and/or ^hate. ^Counter: ^84257
What versions of VS does this actually work on? We have an older one at work...
Still using 2013 :(
asp isn't really my forte but [this page](https://docs.microsoft.com/en-us/aspnet/identity/overview/getting-started/aspnet-identity-recommended-resources) has some links that may help you
On a related note, here's how you can [run/debug a random static method](https://blog.jetbrains.com/dotnet/2015/08/28/run-configurations-debug-any-static-method-in-visual-studio-and-more/) with ReSharper (in all supported Visual Studio versions)
You could create a new Web Application with the MVC default template selected and check out the code they provide. The default stuff properly implements the User Manager in a couple areas for signing in/out. This should give you a good idea on how to move forward.
Indeed. I think I would write a test before trying to re-specify the included assemblies
Search for C# interactive.
Immediate Window works pretty good too, during a debug. Waiting on Interactive to work in NetCore soon hopefully 
Man that guy is a hater of server core. It reads like this was more him trying to justify his personal beliefs about servers with the GUI stack than providing useful information on nano server.
Have you considered B2C Azure AD?
Yes.
The author is hating on nano, not core. They have a good reason to be frustrated. Microsoft pushed nano heavily and are now repurposing it to run solely in containers. Now the recommendation is to go back to server core - especially if you want updates in a timely manner. Basically if you invested a lot into nano server you got burned.
what do you want from us? we are IT solution provider.
But a bad one.
https://dotnetkicks.com/
The concepts don't change just how you setup the project. I'd start with core just as it is the future. 
you are a genuine, kind person. think i've seen your username before too
Core MVC for sure. I think it is beautifully well-architected, making good use of Dependency Injection, middleware and asynchronous programming. It gets rid of all the bloat the legacy Asp.net had. It's fast, cross-platform and has the best tooling available. The only thing lacking is the ecosystem support, but it's catching up quickly.
pluralsight is great if I'm trying to learn a framework. Eric Lippert has made some videos for them and he's great so....
I work in a govt agency where we are very slow to adopt new tech, and even we are moving to ASP.NET Core MVC. It's the way forward.
https://wildermuth.com
I listen to [.NET Rocks](https://www.dotnetrocks.com/) while commuting.
MVC 5, it has a lot better documentation. Core is not well documented yet and the stuff that is out there is often grossly out of date. If you don't already have a fundamental understanding of it then you are going to have a really hard time finding accurate information. 
&gt;DataContexts and Source (Objects?) in WPF You're mostly correct on the distinction between DataContext and binding Source but the major difference is that DataContext sets the binding context (the object that will be bound to) but it DOES NOT set an actual binding while the Source property is specified on the Binding itself and so does set a binding. DataContext is inherited down the visual tree while binding Source applies only to the element to which its attached. DataContext is basically a shorthand to keep from having to specify the root binding object in the binding Source of every element. When using binding Source, you have to specify both the object and the property that will be bound, for example "{Binding Source=MyObject.MyProperty}". When using DataContext, you set the binding object at a root location and then specify only the property to be bound at the element level (e.g., "{Binding MyProperty}"). &gt;delineation between an OBJECT and a PROPERTY I'm sorry to say but this shows that you need a much better understanding of classes, properties &amp; methods before undertaking the much more complicated topic of data binding in WPF. Properties cannot exist outside of a class. A property is a member of an object (i.e. a class instance) just like a method. In fact, a property "x" like you've specified in MyPropertyClass gets converted under the covers by the compiler to two methods, "get_x()" and "set_x(value)". &gt;is the common practice to set the DataContext on the highest element in the tree and then simply override as needed in certain places as you traverse down? Yes, I usually set the DataContext property of either the Window or the main visual element (Grid, Panel, etc.). &gt;Does it make more sense to even reset the DataContext for a child (assuming that's allowed) instead? Yes it's allowed and yes it makes sense IF the child has other children that need to inherit that DataContext. Otherwise, just set the binding Source for that child. &gt; how would I go about getting those nested properties? Use the dot notation just like you would in C#. Assuming you set a root element's DataContext property to an instance of your MyDataContextClass, you could then set a binding to the "x" property like so: {Binding example.x} (or long form, {Binding Path=example.x}). I would suggest going through the [Data Binding How-to Topics](https://docs.microsoft.com/en-us/dotnet/framework/wpf/data/data-binding-how-to-topics) tutorials from Microsoft. I also found this series of articles that looks to be good as well: [EVERYTHING YOU WANTED TO KNOW ABOUT DATABINDING IN WPF, SILVERLIGHT AND WP7](http://blog.scottlogic.com/2012/04/05/everything-you-wanted-to-know-about-databinding-in-wpf-silverlight-and-wp7-part-one) Good luck! I know WPF is hard to wrap your head around, at least it was for me.
I haven't used much WebForms for a while but there seem to have been some improvements to the script manager control. https://blogs.msdn.microsoft.com/pranav_rastogi/2012/09/21/asp-net-4-5-scriptmanager-improvements-in-webforms/ A big change of the project UI might be the right time to move away from WebForms and onto MVC or Web API.
&gt; But, in my opinion, web.api controllers should only be used for creating API's for external applications to consume Why? What if you have multiple interfaces for the same application? Web, mobile, tablet, etc. &gt; Is it a good thing to do? It is if it meets your project requirements.
If they are used by external callers, then they should probably be organized as API controllers. If the caller is in a view that has a controller and the method is specific to what that controller is doing, it can stay in the MVC controller. (eg. We use angular to filter and sort the list page in some CRUD scenarios) 
Depends on your front-end rendering framework. If you want to do basic HTML or roll your own, then MVC will be the way to go. If you want to build a SPA from Angular, React or similar then a combination of MVC and WebAPI will be your tool of choice. 
1. Ditch WebForms for MVC. 2. Install create-react-app which handles bundling, babel, etc for you: https://github.com/facebookincubator/create-react-app 3. Create your react app.
I will be messaging you on [**2017-06-28 20:43:37 UTC**](http://www.wolframalpha.com/input/?i=2017-06-28 20:43:37 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/dotnet/comments/6juyyc/questions_about_storing_my_connection_string_in/djhbdjh) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/dotnet/comments/6juyyc/questions_about_storing_my_connection_string_in/djhbdjh]%0A%0ARemindMe! 24 hours ) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! djhbeyb) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
MVC renders the initial SPA template, including any server data it would need (we use it for binding login information), Angular then takes it from there. The only time MVC becomes involved again is in a full page refresh.
The idea of storing the connection string in web.config is to prevent having it hard-coded in your application. Ideally, you'd have different DB credentials for different environments (dev, test, prod) and if you hard-code it, you're changing code every time the environment or the login credentials for that environment changes. From a security standpoint, both methods are equally "secure" as long as directory browsing is turned off and there's no way for either the web.config or binaries to be downloaded. You still run the risk in either case of exposing your credentials through code publishing/check-in (e.g. TFS, github, etc.) if you check in the file (code or config) containing the credentials. Ideally, you'd want to use an encrypted section in web.config to completely hide your credentials. While I've seen it used, I haven't used it myself so you'll have to google for more details.
I've found that I can configure Gulp to handle bundling, minification and transpiling from within the project and hook into the build process via the Task Runner built into Visual Studio. This works for a dev solution for now.
Thanks again. I remember running into this discussion last night and making a note to study up on it a bit more, so I'll do just that.
Sure. See [write barrier](http://www.memorymanagement.org/glossary/w.html#term-write-barrier) for a definition. Consider writing pairs of references into the heap. If those pairs are boxed reference tuples then writing such a pair into the heap incurs a single write barrier (the reference to the heap-allocated pair). If those pairs are unboxed value type struct tuples then writing such a pair into the heap incurs two write barriers (one for each of the constituent references in the pair of references). So switching to unboxed tuples can *increase* the work done by the GC. Same for increasing the size of the heap by inlining: the GC has more data to copy. 
If you're hosting on Azure it becomes pretty foolproof. Your web.config can have dev db credentials and then your App Service has the correct ones for each environment/slot.
Definitely use MVC for the new stuff. The old screens can live side-by-side until WebForms can be properly cleansed, though.
The interface is available on Github. The question is in regards to an implementation of it.
&gt; . As in the usual way that you always serve the .html file with the Angular app bundle from the server side of things and let its own routing take over? That is correct. The MVC view has ng-app attributes on the right nodes and Angular loads up as one would expect.
I have to disagree. MVC is going to solve 90% of your problems. The lower level stuff is important to learn for that other 10%, but not right away. You can pick it up as you need it. It's like learning to use a drill press vs. learning how to repair one. If you are just trying to drill holes, or build simple web sites, you don't need to know how to swap out the motor. 
I'm slowly working on doing this at work as time allows. I find it depends on the various use cases within Access. I've recently had a lot of success using SSRS to recreate reports. SSRS provides a lot of flexibility once the reports are written. I've also learned the triggers for certain activities and been able to hook into other systems to automate via windows services instead of manual button clicks. 
There are a lot of approaches and they depend on your specific needs. What do you want to record? Table changes (logs when change occurs in a table), row-specific changes (logs when row is modified, along with old row data), how are you going to use the historic data...? Assuming you use SQL Server, you could try [Temporal Tables](https://docs.microsoft.com/en-us/sql/relational-databases/tables/temporal-tables) feature. Of course, you might not need something as robust — you might simply want to use triggers to mirror changes into a history table (one per table). Second answer [here](https://stackoverflow.com/questions/11890868/how-to-store-historical-records-in-a-history-table-in-sql-server) presents a few options.
Polymer is a library that allows browsers to support web components, which is a future HTML standard. As with all HTML standards, it is a work in progress, but it's pretty sure that all browsers will support it natively in the future. Web components allow the developer to define custom html tags (and associate functionality and markup with them). The referenced WPF.Polymer appears to be a collection of such ready made components that closely resembly to what you have in WPF. Though this article describes migrating from WPF to HTML as a breeze, I will honestly tell you that this will not be the case. * There a lots of things WPF can do, that HTML cannot. * Every functionality attached to components has to be implemented in Javascript - this article does not give hints on how to do that (e.g. have a .NET backend connected to the web frontent). I would suggest, to read the comments below the post. They mostly reflect what I just said- in addtion the author of the article is the only author of WPF.Polymer. The last commit has been three years ago and the project appears to be abandoned. This is probably not a good project to invest in.
I think that complete rewrite is the only reliable option. Of course you need to think about data migration to the new system. May be it would be better to start with read only functions. And allow work in parallel from the old system with ability to sync data into the new system. Or something like that. It depends on how large your application is.
Learning ASP.NET MVC Core does not shield you from the ASP.NET Core pipeline and configuration. You will still have to deal with how to read from the config files, how to setup connection string, how to deal with production/development, how to configure which folders to expose for static files, how to register objects for your DI and all other stuffs. The list goes on and on. 
As someone who has been bulding a RE from scratch, what I hate about these recommendation engines tutorials is that they are completely unususable in production. It's just nonsense retraining the whole model every time your users likes a new movie or a new users joins. I prefer a two steps approach. First, cluster. Then, classify your users within a cluster. Much more scalable, although rather complex to define an accurate model.
Use integrated security in connection string to avoid putting password of a sql user
Row modifications, though for what purpose I don't know. I'm refactoring someone else's work. Not sure how that data gets used in the current iteration of the program. Thanks for the links. I'll look into these. 
thank you for your reply.But i assume at least the user interface is migrated into html5 but the backend is still a problem ? 
You look up how to do that once, setup it up, and then forget how until something goes wrong. It's like setting up authentication. I literally don't know anyone who knows how to do that in ASP.NET because they do it once and don't touch it again until their next project a year or two later. (And that's assuming that they are actually starting new projects rather than expanding on existing ones.) To continue the drill press analogy, I had to read the "tune up" instructions once when I put it together and once when I moved it. I just followed the tutorial because it wasn't worth actually learning at the time.
I use a generic class basically called TryMethodResponse&lt;T&gt; basically to keep this simple has a few properties. Bool Success T ResponseObject String Response If success I just grab the responseobject otherwise I look at the response string. As far as returning it I have a helper to convert my trymethod response into an IActionResult via a JsonResult basically 
Please explain how your "this" link implements IHttpSendFileFeature. Looks like it uses the implementation not implements it. Perhaps my issue is I'm using all the wrong vocabulary? Where's an example where a class is using IHttpSendFileFeature as an interface. Thanks for the response though.
Look into Session variables. They hold their value on page reloads. https://msdn.microsoft.com/en-us/library/ms178581.aspx
Avoid refactoring at all costs. Down that path lies madness.
i would suggest using mvc over webforms. But if youre committed to it, the suggested way id to use aspnet controls for the data to persist.
I really prefer .NET/C# to Java but this is probably bad advice. Java isn't gonna go anywhere anytime fast and splitting the codebase or rewriting the entire existing one is just a very stupid business decision.
Tracking these four fields in exactly the way you've described is a common practice. You should challenge yourself to justify the change you plan to make. 
I went the other way a year and a half ago and much prefer java. Maven is a proper versioning system (using pom files) and far supior to NuGet I liked NetBeans much better to VS because it is less bloated. Not being bound to IIS is nice and creating an easily deployed/copied/contained war and jar files and better than anything c# does to bundle.
Nice work. I've been doodling around on [something similar](https://github.com/tintoy/aykay-deekay/blob/master/test/AKDK.TestHarness/Program.cs#L65-L91) for a while now (although mine's a little more general-purpose).
My switch from Java to C# was long ago, but this all rings true. And definitely the intelliJ IDEA part, it almost, **_almost_** made Java development bearable for me. The only thing I can add to the list is that I hated having to declare all exceptions a method could throw. I really liked the idea in theory, but in practice, it was immensely burdensome, even with IDEA helping out a lot. I'd strongly recommend you spend some time looking at Java frameworks and intermediate and advanced topics of things you like in C# (Dependency Injection, ORMs, whatever you enjoy working on) and look at the code and ask yourself if you'd enjoy working on the Java equivalent.
Evince developed Mypedia website based on the concept of a personal (‘My’) encyclopedia (‘pedia’) in dotnet technology. 
If anything is going to make me go back to JVM land, it's Kotlin.
Nice. &gt; .NET Core 2.0 Preview 2 now available with Azure App Service &gt; We have heard many requests for .NET Core 2.0 support with Azure App Service. .NET Core 2.0 Preview 2 is being rolled out to App Service currently and we expect it to be completed by the end of the week. Some data centers may already be available. What is included within 'Azure App Service'? Does this mean [Azure Functions](https://azure.microsoft.com/en-us/services/functions/) are going to support this too?
Personally I would stay with C# as I would really miss the language features and syntactic sugar it brings. And also while Visual Studio is incomplete for me without ReSharper, the combination is much more satisfactory to work with than IntelliJ (or any other Java IDE for that matter). Depending on how much decision-making power your new position may have, you could also take a look at [Kotlin](https://kotlinlang.org/) since it combines many of the good things about C# with the ecosystem and runtime of Java (which are undeniably very good) and try to switch over the projects you are working on to Kotlin (at least where feasible). Just for the fun of it you should really post the same question to /r/java I think it would be quite interesting to see their opinion on this.
Thanks. I think settings like UseSolutionNavigatorGraphProvider should definitely be option in the UI.
Yep, already have done this to disable the attach debugger warning. so annoying.
You need to review the webpack config files in the project root 
There are two - [webpack.config.js](https://github.com/aspnet/JavaScriptServices/blob/dev/templates/ReactReduxSpa/webpack.config.js) and [webpack.config.vendor.js](https://github.com/aspnet/JavaScriptServices/blob/dev/templates/ReactReduxSpa/webpack.config.vendor.js) . I think I need the second one based on the 'Invoking Webpack manually' section of [this blog post](https://blogs.msdn.microsoft.com/webdev/2017/02/14/building-single-page-applications-on-asp-net-core-with-javascriptservices/), but running those commands by themselves after installing my additional dependencies didn't seem to bundle them into the dist folder. I'm definitely not an expert on Webpack though, so I could be totally missing something. Edit: I tried adding the names of the packages I'm trying to use to the list in the 'vendor' element in the webpack.config.vendor.js file and then re-running the webpack --config command, but the output complained about not being able to find the modules. So that wasn't the right guess, I suppose! 
If it can't find the modules then perhaps you missed npm install command and can see your packages in packages.json ? Also keep in mind you need to specify the css manually in vendor bundle. Also vendor is not required it is just supposed to minimize the need for client user to re download large bundle with tons of vendor packages that don't often change. Webpack is great but there is lots of ways to use it which leads to confusion
I know, it's crazy that C# is so manual ;)
This, oh God just don't even learn webforms and turn down any job offer using that POS end of life technology
Not sure if you clued in, but OP is using webforms. Webforms are not stateless. OP, i would suggest not learning webforms!
If you have a lot of technical debt I think this tools would pay for itself quickly.
I'm not often impressed. [String interpolation in FromSql and ExecuteSqlCommand](https://blogs.msdn.microsoft.com/dotnet/2017/06/28/announcing-ef-core-2-0-preview-2/#string-interpolation-in-fromsql-and-executesqlcommand) 
This is actually legit. Will make writing some SQL for edge cases viable while being safe by design.
If you want to add a package just install it by running the relevant npm command - npm i package-name --save (and -dev if it's only for development). If you're using typescript then also add the types package for the package you want to use, it should be @types/package-name if it exists. I'll give you a challenge though; if you're writing a react app try and avoid jQuery altogether! Anything you can do in jQuery you should be able to do in react and it'll help migrate your thinking over faster :) 
Lots of nice fancy stuff, but honestly I wish they'd just being the @helper syntax back to Razor... all this stuff, while nice for the future of Core, doesn't really affect anything day to day. Just give me back helpers, I know some people abused them, but most of us just found them super helpful.
I've done a little testing with .NET Core and Elementary OS and haven't had any issues. I was able to build and execute both standard .NET IL based binaries and the natively compiled binaries from the command line. As far as tooling is concerned I use VS Code and IntelliJ and it's various variants daily and haven't had any issues so I would assume the .NET plugins for these IDEs would work just as well. As a previous reply mentioned, Elementary OS is Ubuntu based and I've never had an issue installing most applications if there are deployment instructions for Ubuntu.
After a quick google search, i found this blog item from 2015: https://www.thomaslevesque.com/2015/02/24/customizing-string-interpolation-in-c-6/ It uses both the sql example, as well as a url builder which automatically url encodes values - which is another really good use-case for it.
The big problem I saw that I previously thought could be Java's issue is that a few Oracle products (written in Java) don't support TLS higher than 1.0. However, a quick Google search informed me that some versions do.
Ahh yeah, I understand you now about the webpack thing.. Why do you need razor? If you're doing auth you can just serve a react login page (over HTTPS), user enters username/pass, use a react friendly ajax module like fetch to send request with user/pass to your login controller, then where you go from there depends on your chosen auth method...
[MonoTorrent](https://github.com/mono/monotorrent) seems to be the most actively developed one I've seen. There are also two libtorrent wrappers I've found (built by the same guy...) but they don't seem to be actively maintained: * [libtorrent-net](https://github.com/vktr/libtorrent-net) * [Ragnar/libragnar](https://github.com/libragnar/ragnar) The same guy has also built a headless torrent client with a JSONRPC API which has relatively recent commits compared to his other projects: https://github.com/hadouken/hadouken
Fair point! For the auth side of things I'm working off of the Visual Studio template for a ASP.NET core app with individual user authentication, which is obviously opinionated towards doing the entire app in .NET including the front end. The boilerplate code it provides makes extensive use of viewmodels for data and form validation. Being new to the framework I wasn't sure how I would go about mapping a JSON string to the EF entity, but maybe I should research that rather than go further down the path of a hybrid React / Razor front end. The desire to validate my approach was what prompted the first question in my OP :) 
Yeah, walk in and say "use something else pls!" Java is still &gt;&gt;&gt;&gt;&gt; .net on unix, and unix is not small at all, you know... Not to mention that a major current trend is flocking to javascript, even MS does that...
Yeah I'd really try and keep the front end react as much as possible, if I were you! That means you're really writing a SPA - do the whole routing and everything in react (react-router). Bit more work off the bat, but really worth it long term. Have you looked at https://github.com/aspnet/JavaScriptServices? That's probably the best starting point for .net core/react that I've seen! The react/redux example is a great starting point. If you're writing anything other than a super simple app then redux (or some kind of state management) is a must, imo. I haven't dabbled with auth from an SPA with .net core yet, as I've not needed to, but check here for a good link on how it can be done: https://www.reddit.com/r/dotnet/comments/5ilqjh/authentication_and_identity_in_a_single_page_app/ Good luck! 
Thanks for the additional info :) I am indeed working from the JavaScriptServices scaffolds, but they don't have any templates that include authentication out the box. I looked at the previous discussion you linked and it seems most people are recommending the JWT approach with OpenIddict or Identity Server 4 to serve up the auth tokens for the client - which is basically what I was mentioning in my original post. Good to know I'm not the only one wrestling with these kind of questions - maybe Microsoft will update the JavaScriptServices templates to address this gap in the near future.
automated testing
Yeah I don't think I explained properly.... this is the closest thing to what i was looking for: https://www.hanselman.com/blog/ThinktectureIdentityManagerAsAReplacementForTheASPNETWebSiteAdministrationTool.aspx but that project seems a bit stale now.. basically a tool that works with Identity to administer users, assign roles, create roles, disable users etc...
Based on the sample code I'd say no. This is just an implementation of webdriver that you can use to write automated browser-based tests.
Additionally, screen scraping. At my work it's used to navigate other sites that don't support an API (and actually tell us straight up to use a screen scraper to automate filling out forms, go figure).
Never used the React SpaServices but I know from using Aurielia, you can just build the Typescript application and then change the webpack configuration to transpile es6 files instead of Typescript.
webpack in the spaserviece should be configured to "compile" normal jsx files as well, but you will have to convert the few tsx files yourself I think
I made it work by just adding a js/jsx rule to webpack.config.js, changing the entry point from boot.tsx to boot.js, removing mentions of hot module reloading from the middleware configuration on the server side and installing babel-core, babel-loader, babel-preset-es2015 and babel-preset-react. I don't have hot module reloading but I don't care about it too much. Thanks, guys, if I finish a polished version I can commit it on github, but I have a PoC deadline to meet for now :P Still, if anyone needs help setting this up, drop me a pm.
Sounds like you've spent a bunch of time making the default template worse...
Not sure I understand why you can't just link them the zip and if they don't know how to work a zip use a self extracting zip
I'd publish the project to Azure and then let Azure do the hard work.
I'd like my clients to be able to download their software without my help. Where exactly would I store this zip?
Not all projects are web applications. Most of the software I do is WPF. I don't think you can publish a WPF application to Azure.
Any web server you have in the azure environment just plop it in and give the link unless you need authentication to download 
You can use Azure to host your downloads too; https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-how-to-use-files
Appveyor can publish your project to an azure blob. At that point you can either send that link to your client or have your website proxy it. 
Don't look for generic "build a website with login" tutorials. Instead, build a basic webpage and read the documentation for the various pieces you want to add. Ie login functionality: https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity
Use hockeyapp.net. 
Why not just use typescript? You can write plain js in it
We have a tool we built that just updates our applications. It is a Web API that is hosted in azure. You can build a simple one by just checking version info client side, then asking the server if there is anything with a higher version number. If there is, you download it and install the patch. We have a separate exe that we deploy which gets run from the temp directory to perform the actual file replacements once the package is downloaded and unpacked. That way it can update itself. Once the patch is applied, it relaunches the program. As far as hosting the application for initial download, the azure storage answer seemed to fit well.
They better make sure full .net still works there... No reason to run this for .net core
&gt;For the next release, Microsoft is already committed to getting the uncompressed image down to 500GB Pretty sure that's a typo... 500MB maybe.
**Solution 1**: ship your applications with integrated auto-updater using solution such as [Squirrel](https://github.com/Squirrel/Squirrel.Windows). **Solution 2**: use service that supports continuous delivery such as [Visual Studio Team Services](https://www.visualstudio.com/team-services/) or [AppVeyor](https://www.appveyor.com/). VSTS for example, offers you an option to automate the build and publishing process; for example, if you use Github to manage your project, you can set it to monitor repository's master branch for changes and trigger a build process after each push; build process is completely customizable — you can configure it to automatically restore NuGet packages, build solution and then publish the artifacts to Azure storage. **Solution 3:** Write your own solution similar to no. 2. Use [Azure Storage Services REST API](https://docs.microsoft.com/en-us/rest/api/storageservices/azure-storage-services-rest-api-reference) to deliver the artifacts. Solution 1 is obviously the best choice for you and your customers. 
I will do some research on all solutions. Thank you for taking the time to answer my questions. 
Components that used to be part of the images will now be optional. "You’ll pull down Nano Server and if you want .NET, you pull down .NET on top of that..."
There is a 30 day [trial](https://azure.microsoft.com/en-us/free/). There is a free app service plan (very slow) that you can use for testing. A better way to practice would be to host website and database yourself and configure continuous deployment with TFS or similar service.
Not sure what they mean by "Azure is the best for hosting MVC". AWS works just fine for hosting MVC, and they have a free tier. 
As a student you want to look into [Microsoft Dreamspark/Imagine](https://azure.microsoft.com/en-us/pricing/member-offers/imagine/) which gives you access to Azure tools for learning purposes. You need your student email to be able to sign up and you have to "renew" the signup every year so they know you're still a student, but it was really straightforward when I was using it, I can't imagine they've complicated it too much.
It's been a while since I used AWS, but their hosting dashboard is complete crap compared to Azure. That might have changed in the last... 4(?) years? Deploying a series of microservices in AWS was a nightmare compared to Azure, but management didn't care about convenience and manageability, just cost.
They specifically said: &gt; I don't have any .edu or academic profile since I am self-learner, so I can't get any academic benefits offered by DreamSpark. 
I think enabling rather than pushing
AWS offers a completely free tier if you want to give that a go.
Sign up for the free (for everyone) [Visual Studio Dev Essentials](https://www.visualstudio.com/dev-essentials/) With everything else you get, you also get $25/mo of Azure credits. Shouldn't even need a CC to get that...
The other thing to look into is Microsoft's BizSpark which is for people starting a new company. It gives some amazing benefits if you were looking into starting with an idea. 
I started my reply when this post was only a few minutes old, so either I missed that or it was edited in shortly afterwards. Like the other guy said though, BizSpark is another alternative if you don't have an .edu email. /u/quintobytes you can also look in to AppHarbor, it has most of the basic offerings that Azure does under the free plan.
Visual Studio is injecting this when debugging. It won't be part of the deployed code.
Does this mean debug is set to true in web.config?
No. It means Visual Studio has injected it - when you pressed the RUN button - while the site is running in visual studio's debugger. The code will never appear in the site when running normally. 
Please forgive my lack of actual knowledge of .NET (I am not actually a developer), but I did look at the site in production and still see these comments there as well. I am just looking to best understand what the actual fix for this should be. I assume now that maybe the prod site is just being launched from within Visual Studio? Is there a more standard way the app should be launched?
Thanks for this. I have a few things in azure and my bill is about $20/month. Now it's free for a year.
can you verify if the prod server is launching the site from visual studio? This is definitely not normal: the webapp should be installed on a webserver that only has minimal services installed, iis or otherwise. VS should not be on that box and having its debugger attached. 
There is no fix for this. This occurs when you debug and can be turned off from within Visual Studio if you want. It should NOT ever be displayed when viewing the site via other means (i.e. when served via IIS to another machine)
no browser link reference should appear on Production. Maybe the live web app is not in Production. You can read more about this here https://docs.microsoft.com/en-us/aspnet/core/fundamentals/environments. More specifically the ASPNETCORE_ENVIRONMENT environment variable. there are several ways to set it, explained in that link.
Azure has a free App Service tier, you just can't use custom domains. 
You do need a credit card for that, and they don't accept prepaid ones anymore. Sucks especially since CCs are quite uncommon in my country.
Is it free for life or is it a just a trial? There doesn't seem to be any clarified answer on their official site.
Don't forget the 3 month Pluralsight subscription too!
So still more than double the size of a free Linux equivalent.
I do and it works just fine, however, you might need to edit Omnisharp configuration and add another switch for Elementary OS that will "fool" the extension that it's actually running on Ubuntu.
TL;DR: run on Linux/MacOS.
Self-contained deployments (being able to ship all of .NET Core with your app so that the user doesn't have to have a specific .NET version on their machine) are also pretty big.
Yeah i have read that. No specific commands were given, and through the years i learnt not to trust their promises :)
&gt;:) I am happy that you are happy. Spread the happiness around. [This doggo demands it.](https://s-media-cache-ak0.pinimg.com/564x/31/9a/90/319a90658cb7ccd9a0a03fe7c878dc25.jpg)
They phrased this one as "you can run on 1 and 2". Duh, I could do that 15 years before .net core existed. Also 15 years before .net existed, with different libs.
I'd argue this is actually the larger point. Being able to run on *nix is old news for those of us that have been using Mono a while.
Run on mono and battle all kind of problems VS an official, tested and optimized method of running .net.
You must not have actually deployed a .net core app on *nix yet. And Mono is just fine at this point, it's also a vastly more ambitious project than Core is right now. Core is more or less "Asp.Net for nix" at this point, Mono does quite a bit more.
Just my opinion but it seems to me that there's almost 0 incentive to run an ASP.NET Core app on Windows at this point.
Uhhh, what? Mono is doing some awesome things (linker, apt), but .net core is the full clr and .net (standard) stack on Linux. 
I'm not going to get into a pissing match over which is better, they have different goals so that's stupid. Yes Core is .Net standard, which is sort of like saying it's .Net minus a lot of the tricky, lesser used bits of the BCL. Sure that's a great goal for portability, but it also presents problems for a lot of applications. Mono has a lot of those things. A lot of those things are also available via nuget for Core. Both have their pros and cons, but .Net core is certainly not some kind of silver bullet where you can just drag an app from windows to *nix and have run it run perfectly yet. Neither is mono. Point is just running on nix is nothing new, some of us have been doing it for years and Core doesn't really do it vastly better other than the self contained aspect.
I have been very impressed with .NET Core. I remember those early days when portability was promised but was just a pipe dream. It truly was a different Microsoft back then. It took them forever to embrace open source, but we have to thank the FOSS community for their efforts. 
&gt; Duh, I could do that 15 years before .net core existed. You were running .Net on *nix in 2001? 
The only thing that stands out is your port number. Are you sure it's correct? I believe 1433 is the default port. Have you tried connecting without specifying a port number?
A list of generally good things, none of which were important to me building .Net stuff on Windows ;) 
Yes, the port number is correct. I made sure on the Configuration Manager, and I'm able to connect to the database remotely with this connection string from my Windows 10/Visual Studio 2017 setup. 
&gt; Server=xxxx,1433\xxxx What is this supposed to be? "\xxxx" I think that could be the problem. I've never seen anything appear after the port number like that... Edit: If it's a SQL Instance, it should be in the form of "server\instance,port"
I gave that format a try and no luck. Have you been successful in connecting to a remote SQL Server from Visual Studio for Mac?
https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/getting-started-with-ef-using-mvc/sorting-filtering-and-paging-with-the-entity-framework-in-an-asp-net-mvc-application http://jasonwatmore.com/post/2015/10/30/aspnet-mvc-pagination-example-with-logic-like-google
Is the name of the server fully qualified in your connection string? Windows will append a domain or use the net BIOS name, but Linux and Unix (so I'm assuming macOS also) will not. You will either need to use machine.domain.tld or, if you don't have real DNS server locally, an IP. Again, not sure about Mac, but in Linux I've had to do this. 
I'm currently working through the Microsoft documentation (building the Contoso University app) and that tutorial in particular recommends a NuGet package which hasn't been updated since September 2013 - so that's kinda what brought me here asking :) I'll check out that blog post though, thanks!
Skip() and Take() in LINQ with EF translate to query-level paging. https://stackoverflow.com/questions/548475/efficient-way-to-implement-paging
Query-level paging; does that mean that I can control how many objects to return from the data store, like *skip* some of those - *take* some of these?
https://docs.microsoft.com/en-us/dotnet/framework/migration-guide/how-to-determine-which-versions-are-installed suggests checking the registry.
Basically. And this is generally useful to do at the database level because if you have a table with ten million records, it'll blow up your memory consumption to page them in memory and it'll take .NET longer to go through all the records to find them in the first place.
Cheers, I'll look further into that! Thanks.
I'm using the IP address of the server, still no luck. I don't know if this is a OS or .NET Core issue now =/
I understand you don't want to use libraries, but I'd like to recommend you look at datatables.net. It will only do clientside pagination so it's not going to do everything for you. I've just implemented something using scroll detect, it's a similar problem. I have a method setup which returns a JSON result set, it takes two parameters - fetchsize, lastid. So I can get my objects using linq by doing something like db.objects.where(x=&gt; x.Id &gt; lastid). Orderby(x=&gt; x.Id).Take(fetchsize). I don't actually use the ID to sort by in my instance. I've created a sort field which is a numerical key based on my object date. 
In reality MS has been doing a lot of OSS for a long time. The difference now is that they actually tell people about it.
Honestly, I haven't found a whole lot of cases where code gen (that is, creating code before compile time) is useful. I've been experimenting with a lot of model-based serialization/deserialization code that's dynamically emitted at runtime, and I've had great success with that. I have used Roslyn in a Code Analyzer/Fix package. It's not very friendly to use, as you mention, but if you use the syntax tree visualizer in Visual Studio, you can usually figure out the code you need to write pretty quickly.
Do a Google search for c# ui I guess. Also you leave out a *lot* of details needed to make a proper design decision. Like: what is it you are even trying to do? What's the motivation?
.Skip((page - 1) * pageSize).Take(pageSize) Assuming your page numbers start at 1.
Thank you for the reply. But I think we got this figured out. We have a vulnerability pop up for a DC running server 2012 Core. It needs a newer version of .NET Framework. I don't have access to DCs in my workplace, so I have to get someone who does have access to do the work. The only guy in the office today (4th of July being on Tuesday means some people took Monday off) that had access didn't like or use core every often so he's weak with PowerShell and the command line. The problem was I didn't know if it even had .NET Framework enabled. I read it's off by default for 2012 Core. If it didn't have .NET running then I would have to do a false positive vs a change request for the patch. We used "Get-WindowsFeature" to determine that it was indeed enabled/installed. The vulnerability is being triggered by a DLL. Installing the monthly rollup upgraded the DLL version.
I use Typewriter to generate TypeScript versions of DTOs and WebAPI controllers. Also works for other things as well, not just limited to TypeScript necessarily.
You can go to server manager and then to the part that lets you install add ons. Under web technologies or whatnot there should be a section for .net. See if any are checked. Any additional installs you do will show up in add remove programs, a section that also allowed you to enter the previously pointed out section. Edit: of crap, forgot about command line only.
I was commenting on "self contained deployments" and running different versions on the same machine.
T4 isn't obsolete that I know. It just hasn't gotten the tooling love it should.
Oddly enough, binding to the same EmailAddress property on my DataGrid works perfectly: &lt;DataGridTextColumn x:Name="emailAddressColumn" Binding="{Binding EmailAddress}" Header="Email Address" Width="SizeToCells"/&gt;
It can’t not be enabled. It can be installed or not. Actually it’s always installed on that server version. Edit: missed the “core” part, sorry. 
The formatting is terrible to the point where it's unreadable. 
Any error in Output?
Tons of messages in Output but I actually didn't check for anything specific to this ... Will update shortly.
Yep, put me off too.
I work with Mono almost full time and there's still a lot of friction. There's something to be said for using software with the official stamp of a big tech company. Mono is pretty solid and stable but support and tooling has always lacked in the Linux space and I'm more hopeful this will change now Microsoft is on board.
Blatantly stolen content: http://www.dotnetcurry.com/patterns-practices/1350/singleton-design-anti-pattern-csharp
[/user/daveaglick](https://www.reddit.com/user/daveaglick/), the maintainer of Scripty, is an awesome developer (I used to collaborate with him on his other OSS project, WYAM). If you have any questions, just make a new issue on the project.
Be patient. It will take some time to grasp it. 
Did you check your firewall settings for port 1433?
&gt; model-based serialization/deserialization code You mean something like Automapper? I will look into Code Analyzers and Fix, looks like there are many things, for example this repo: https://github.com/JosefPihrt/Roslynator
But I think he doesn't have much time to write good documentation and use cases :) 
He will help you out though and points to the right direction.
Yeah, you install the feature. And it was on the server I was working with.
Yeah, lots of ways to check with the GUI. Just wasn't sure from the command line. "Get-WindowsFeature" was the command that worked for us. .NET was check. So we patched the server.
I have used [Codesmith](http://www.codesmithtools.com/) before but I haven't used it in years. You might want to look into it. 
Not really, but sort of. In the best case I can describe, I was serializing POCOs into Redis by taking each property and making it a hash entry of a native type that Redis could understand (and, conversely, deserializing Redis hashes into objects). I'd think of it more like JSON.NET in some ways. I haven't heard of Roslynator before, but that looks really cool! I might have to pull this into some projects I'm working on.
Yes, I made an incoming and outgoing rule. Connection still times out from Mac OS X setup, but not Windows setup =/ 
Would be awesome, if the prod server was actually a VS debug session just idling ...
What happens if you change the EmailAddress binding to bind to a different property, like Client? That will help you figure out if it's an issue with the EmailAddress property, or an issue with the TextBox
There is no need to set the UpdateSourceTrigger
If you don't set this, then text box bindings do not fire until focus is lost. If you need the binding to update as the user types, then this is necessary.
I'm sorry I don't have an answer for you. This really should work. Double check you have correctly posted the code without making some small change that could be the issue. This would drive me crazy if I had the issue as well. But, I wanted to make a suggestion. In my setters I always have something like: if (value != _Client) so I am only raising the property changed value if the property value has actually changed.
They have a trial where they give you some amount of credit to use for 30 days. This is different. App Services has a free tier, and you can use it free for as long as that tier exists. 
Awesome! I will look into it. Thanks :)
In general, if you don't want WPF to mess with you in mysterious ways (e.g. hitting enter to submit a form that was in a modal window won't cause your changes in the active TextBox to be saved) you should use UpdateSourceTrigger PropertyChanged. LostFocus is nice if you don't want immediate validation (e.g. e-mail address entry) but that's about it.
Not only that. We still have not managed to replicate the productivity of VB/Delphi.
I tried this when it first came out. The multi-second cold start time makes it unusable for anything real time.
Because of all the JavaScript libraries and shit that come bundled with new web apps. You don't have to use them, you can just do plain HTML + MVC. Might not look as great or take a little longer, but it'll be fast
I would add on the web side
The older the app the more performance fixes that have been added.
Generally agree, I can build demo/throwaway apps in web forms significantly quicker than api/mvc solutions. Still makes zero sense to me why bother with orms when ado/dapper are orders of magnitude faster for data access when performance matters most. 
That's what the future looks like and I like it. 
C# and forms designer seem to. I've been maintaining one lately and it's lightning fast compared to any WPF app I've ever used. Dead simple to debug and add new stuff too. I've also been doing a bit of C lately and despite it's warts the simplicity of it is a breath of fresh air after a decade of .net development.
I really don't like SPA. I design all my system to be mostly HTML pages with a few pages turbocharged by javascript. The rest are plain postback.
How long does it stay warm for? 
YES! I truly wish this is what the future holds :)
I remember being unimpressed as a VB6 programmer when a colleague showed me .NET. I had to install a framework and upgrade my PC's hardware (and wait for the load time which was much longer for the new Visual Studio) just so I could run a simple "Hello World" program.
Hello /u/jdh30 Adam Sitnik here, the author of the blog post. Thanks for a very valuable comment! I have updated the post after reading your comment. &gt; Write barrier is a counter example. Was: don't add any pressure for GC Changed to: Value types add much less pressure for the GC than reference types &gt; Not usually. Was: But they are expensive to copy Changed to: But big value types are expensive to copy &gt; You're assuming one core. Multicore exacerbates these issues. Added: Note: Multithreading affects CPU cache performance. In order to make it easier to understand, the following description assumes single core. &gt; The universe is non-deterministic. You mean unpredictable and doesn't provide assurances. Was: The problem is that the deallocation is non-deterministic and it takes some time to perform the cleanup Changed to: The problem is that the deallocation is performed by non-deterministic GC. GC implements own heuristic which allows it to decide when to perform the cleanup. The cleanup itself takes some time. It means that you can not predict when the cleanup will take place and it adds extra overhead. &gt; Stacks are traversed by the GC. Deeper stacks means more pressure on the GC. Was: This deallocation is super fast. And no extra pressure for the GC! Changed to: This deallocation is super fast. And in overall we have less pressure for the GC! The pressure is not equal to zero because anyway, GC traverses stacks, so the deeper the stack the more work it might have. &gt; When small arrays of value types survive generations the GC copies them so this is also not completely free. Was: If you allocate an array of bytes, then the array is allocated on the managed heap. This content is transparent to GC. They are not reference type instances, so GC does not track them in any way. So we still follow the “NO GC” rule. Changed to: If you allocate an array of bytes, then the array is allocated on the managed heap. This content is transparent to GC. They are not reference type instances, so GC does not track them in any way. But when a small array of value types gets promoted to older GC generation, the content will be copied by the GC. &gt; No GC implies zero gen0 but zero gen0 does not imply no GC because you can still be paying for other parts of the GC like the write barrier. Added: Note: If value type contains reference types GC will emit write barriers for write access to the reference fields. So No GC is not 100% true for value types that contain references. &gt; Any optimising compiler will of course try to optimise away those copies so in practice YMMV as you have observed. Added: For small value types, the JIT compiler might optimize the copying (inline the method, use registers for copying &amp; more). Once again big thanks for the very valuable input!
I heard about this a few days ago. Steve Sanderson did a demo at NDC Oslo and I hoped there'd be a video of it somewhere but I can't find anything so far.
I think this will struggle as a commercial venture, the CMS space is already crowded as it is. You might have written a nice system but if I want a CMS why will I pay for something when I can use WordPress which is free and has a plugin for just about anything I could want? I suppose I might use it if I absolutely feel the need to use .NET but then there is already Umbraco which is mature with a well established eco system while Orchard 2 is on the horizon and is free. If you want your CMS to be a hit you're almost certainly going to have to open source it, possibly offering a paid version for support if you want to make some cash but that should be a secondary consideration at this point.
Open a terminal and type ```csharp``` and this will let you use the REPL. You can paste the code in there - this will tell you if the issue is VS for Mac or something else. You'll need to load the correct assembly first though with ```LoadAssembly("System.Data")``` before the above code. UPDATE One other thing I've noticed is the 'xxxx' after 1433, is this for SQL Express? If so try omitting, just use the server name. This might well be your issue, I seem to remember having the same problem connecting to SQL Express from Xamarin Studio then I removed the suffix and it worked.
Is this available to watch? Could not find it on the NDC website.
I just listened to the latest .Net Rocks podcast where they were talking to Steve Sanderson about the demo. Was really interesting to hear him talk about it.
This is the inflection point. I've been loosely following web assembly for a while and the thing that i think a lot of people missed is that unless your running C or C++, then you would basically need to have your runtime running on web assembly before you could run any of your day to day code. So you'd need to have a CLR for Web Assembly in order to even be able to run hello world in .Net. It looks like this implements DotNetAnywhere, which stems from the .Net micro framework, which is a great idea (i.e. no Win32 stuff) I believe web assembly is still missing an actual DOM API, so there'd still be a lot of js "glue" code to be able to use .net. It's taking a while to get there, but i like where web assembly is going 
Much better. Still a couple of issues: &gt; Changed to: The problem is that the deallocation is performed by non-deterministic GC. You're still talking about determinism incorrectly. Tracing GCs aren't non-deterministic. Most are actually completely deterministic with one thread. The problem is they are unpredictable and don't provide any assurances with regards to when values will have been recycled. &gt; GC implements own heuristic which allows it to decide when to perform the cleanup. That is essentially true of all forms of memory management. Even with `malloc` and `free` you don't know how they work internally. You don't know how long they will take average or worst case. Even if you've just `free`d two size `n` blocks of memory that doesn't mean you can now allocate a size `2n` block of memory because the heap may be fragmented. And so on. &gt; The cleanup itself takes some time. It means that you can not predict when the cleanup will take place and it adds extra overhead. Overhead compared to what? All techniques require overhead. Without comparison it is meaningless. &gt; Once again big thanks for the very valuable input! Anytime. :-) 
Yeah I heard that, was interested if there were any videos floating about too.
That's the number one issue with being self-taught, and I know exactly what you're talking about. As someone else who is self-taught and going through college now, these are the high level concepts a college education helps teach with classes designed exclusively for Software Engineering, because that's really what these concepts are. If you understand these concepts you set yourself apart from just a programmer, because these are all very large topics on their own, and knowing how they all relate and can be a tool on your belt that helps you a ton in the long run. All of the articles from industry giants preaching about all these different terms is super intimidating, and it's almost expect you know them, but that's just absolutely not the case at all, so bear with me. You've actually segmented out the topics into really nice categories already, so I assume you at least know what the topics are, which is amazing. If not and that is some random stroke of luck, that's also fine as well. I would suggest setting up a routine where you continually add one of the philosophies/tactics you've listed into your application. "Yea but wtf do they mean?" -- to which I respond that if you try and incorporate one of these each day, by the time you figure out what Microsoft is saying it does, what the StackOverflow post inevitably says about it, and what some random blogger has said, the whole concept will begin to take shape for you. And when this happens you should have a pretty strong implementation in your code. The fact you already picked up on most of it by this point means you're a pretty fast learner, so if you start at the top of your list and work down, it actually won't be a monumental task. The only ordering I'd suggest swapping up is put the RESTful WebAPI portion at the top of your list, you'll thank yourself if you do that. I have kind of laid out a "natural progression" of topics below based on your list. * Importance of having a RESTful WebAPI with your MVC application As soon as you start trying to read into this stuff, you're going to get a variety of opinions on what each RESTful principle means, so I'm going to strong recommend just reading the godfather of all of the debate, the initial dissertation by Fielding when he initially introduced the RESTful concept: [Fielding Dissertation](https://www.ics.uci.edu/~fielding/pubs/dissertation/rest_arch_style.htm) * Test Driven Development (TDD) with xUnit (or MSTest) and Moq for making unit tests, and integration tests. Testing state vs testing behavior. Mock vs Stub. As a self-learner, this one is by far the hardest, because it is a fundamentally different way of thinking of how to program. I recently started on this one at my new job because it's how they develop, and I have definitely struggled with it. I'm really still not super comfortable with it, but you should really consider trying it for some of the following concepts when you implement them into your code. I put this one high up on the list because understanding what it is, an making strong unit tests early on will help you develop much quicker. There are also people coming out and speaking against TDD with the #NoTDD movement, so after you understand what it is, and experiment with it, you can form your own opinion. For personal projects I don't consider it to be as important, but for enterprise projects, I view it as extremely important. I'm not going to guide you on this one, because there are just so many resources out there on this and I'm honestly not even sure which would be a best start, because like I said I don't even have a full grasp on it. * Fluent API with EF Core I didn't actually know what this was because I had never heard this term before, so thanks! This is just converting your entire database layout into an Entity Framework Database Context, meaning all your constraints for fields and table relationships are mapped out in a file, that gives *context* to a database. Again, Shawn Wildermuth does this from the beginning in his series (I swear, I'm not affiliated with this guy, he just has the best intro ASP.NET Series I've seen and it's how I learned), and this is associated with a Code-First Design (Meaning, you write your models and context, and the database is created off of this) * Business Models, View Models, Domain Model, ModelState I think just reading Microsofts MVVM article should clear up what the strengths of a ViewModel are, and you should be able to apply these to these topics. [MVVM - Microsoft](https://msdn.microsoft.com/en-us/library/hh848246.aspx) * Separating Assembly, Solution, Project, App, Middleware, knowing what they are and how they work together. (If you have access to Pluralsight, watch Shawn Wildermuth's video series on .NET Core, in fact that series applies to almost all of these top steps, watch it as he lays out how to have a strong seperation of concerns) [Microsoft Article on Middleware](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/middleware) * await and async keywords, when to use them and when to not. This falls into the broader category of asynchronous programming. In theory your entire application should be asynchronous, but in reality this isn't going to be possible due to one reason or another. [Microsoft Article on Asynchronous](https://docs.microsoft.com/en-us/dotnet/csharp/async) * Repository Pattern, Facade Pattern, *"Unit of Work"* I'm going to recommend Shawn Wildermuth's series here again, as he uses the repository pattern from the get go. On top of this, I would recommend just learning most of the "common" programming patterns, and at least be familiar with what they do. You can find an awesome github repo that explores all of them and has code examples here (This isn't in .NET, but they should make sense): [Design Patterns with Examples](https://github.com/kamranahmedse/design-patterns-for-humans) * Domain Driven Development (DDD), N-layered Architecture. This one is really hard to get/apply if you're not working for a company that has business value in a product you're developing, but the theory should make sense: [WTF Is DDD](https://stackoverflow.com/questions/1222392/can-someone-explain-domain-driven-design-ddd-in-plain-english-please/1222488#1222488) Service Layer, Data Access Layer, Business Logic Layer *"onion architecture"* This one is kind of split between the pattern answer above, the DDD one above, and the view model answer above. * Dependency Injection, Dependency inversion principle, Inversion of Control, SOLID design principles This one is a really complex topic, but if you can find one definition that makes sense to you, it clears a lot of it up. If you have access to Uncle Bob's Clean Coders series, watch episode 4 [maybe 5?] for hands down the best explanation I've ever seen of it [StackOverflow Post](https://stackoverflow.com/questions/3058/what-is-inversion-of-control) [https://softwareengineering.stackexchange.com/questions/205681/why-is-inversion-of-control-named-that-way](YASO [Yet another StackOverflow] post about it) [Microsoft IoC Explanation](https://msdn.microsoft.com/en-us/library/ff921087.aspx) EDIT: I did some more thinking about my response, and I want to usher you towards Scott Hanselman's yearly post about ["What .NET Developers ought to know for {DateTime.Now.Year}"] (https://www.hanselman.com/blog/WhatNETDevelopersOughtToKnowToStartIn2017.aspx) On top of this, since you seem to want to learn, I recommend listening to podcasts and reading blogs whenever you can (but don't push yourself and burn out). I recommend starting out with [Morning Dew](https://www.alvinashcraft.com) and then favoriting blogs with posts you like from here. New links are posted everyday around 8 AM EST every week day. There was a podcast I was listening to that discussed the idea of not getting all these topics when you hear them, and he said "you may not know all the topics, but exposing yourself to them and hearing people talk about them will eventually lead to you learning them", and I believe that was on an episode of [Software Engineering Daily](https://softwareengineeringdaily.com/) or [Developer Tea](https://spec.fm/podcasts/developer-tea), both podcasts I highly recommend. Other podcasts to look into (that are frequently mentioned on other subreddits for programming) include [Hanselminutes](http://hanselminutes.com/archives), [.NET Rocks](https://www.dotnetrocks.com/), [ShopTalk Show](http://shoptalkshow.com/), and [Programming Throwdown](http://www.programmingthrowdown.com/). On top of all of this, I would recommend that you start reading [Hacker News](https://news.ycombinator.com/news) and read articles that sound interesting to you. A lot of the stuff posted on here still makes 0 sense to me, and at first I was intimidated, and now I'm OK with it. You can't be knowledgeable in all of the stuff that gets posted there, but you can at least know it exists. It also doesn't hurt to keep up with trends and going-on's within the tech world, which this provides. It also has much better discussions and viewpoints than most Reddit comment sections (I mean at a more /r/all level, and not so much niche programming subs). A lot of "rockstar" (god I hate that word) programmers post there occasionally as well, so it's just nice to see the interaction.
When I tested it, the timeout seemed to be somewhere around 3-5 minutes. It wasn't always the same.
Hey -- because this submission has tech consulting sales in it, it is spam. If you want to continue to submit content, please separate out your blog and your consulting advertising.
Seriously thanks. This answer is so much more than I hoped for when I wrote this post and it's a great track to follow. I'll get right on it, and once again, thanks! By the way, you have DDD/N-layered Architecture pretty far down, and mention that it's perhaps mostly relevant for company-level development. What alternative ways is there to handle "fat controllers"? When all of the logic is inside one controller-action making it into a god-function for the http-request. The most common answer I've gotten to this question is "You should move your business logic into the Business Logic Layer and all database-interaction should be separated into the Data Access Layer" =/
Hit maximum character limit on this one...sorry, but this is just kind of a post I've been meaning to write I guess. I know you didn't ask for the stuff in the Edit, but if you want to get familiar with these topics, expose yourself to them. Lastly, my blog recommendations...I left this at the bottom because there are so many and they're just my personal ones I like to look at, whenever there's a new post: * [ASP.NET Official Blog](https://weblogs.asp.net/) * [Scott Hanselman - Microsoft Lead](http://www.hanselman.com/) * [Jeff Atwood's "Coding Horror" - SO Co-Founder/Discourse Founder](https://blog.codinghorror.com) * [Daily WTF ... Just never read the comment section](http://thedailywtf.com/) * [A List Apart](http://alistapart.com/) * [Jon Skeet - Google Engineer](https://codeblog.jonskeet.uk/) * [Visual Studio Magazine](https://visualstudiomagazine.com/Home.aspx) * [David Walsh - Senior Engineer at Mozilla](https://davidwalsh.name/) * [DZone - Clickbait for Developers](https://dzone.com/) * [K Scott Allen's "Ode to Code"](http://odetocode.com/) * [Math Intersect Programming](https://jeremykun.com/) * [Dan Luu - Microsoft/Google Engineer](https://danluu.com/)
That one is kinda further down because once you read the Repository pattern you should get a feel for how to break down business logic, and furthermore HEAVILY reduce controller bloat. Also, in the words of Uncle Bob "Refactor til' you drop".
Correct. It'll be tough to take on other popular open source CMS like Umbraco, which is written with ASP.NET and that Microsoft uses for some of its own corporate sites.
I find Windows Forms remains one of the most intuitive ways to create an app UI that anyone has ever developed. And yeah, still blazing fast. I'm using VB.net + Windows Forms for my home automation system.
The native linker backend for .NET (currently only UWP) might be able to achieve this in the future.
Is there a server running a demo of this? Would like to look at what is served and how it looks like... 
What does your CMS offer over the established .NET options? Umbraco - Free open source, huge community and backed by a load of full time developers supported by selling training and support programs. Kentico - A few grand for a license, good support built in ecommerce. Sitecore - Many grand for a license enterprise grade tools for reporting replication etc. Is being written in Core enough of a differentiator? 
There are lots of products in the space, your challenge is how to differentiate your product. Giving a copy of the product to your client in order to sell customization service is a pretty bog-standard way to go. 
And we had slower machines when we built them
Yup. It sounds like you might not be familiar with LINQ so I recommend reading up. It is very useful for replacing boilerplate foreach loops with smaller, more readable expressions. As the guy said it works for Entity Framework-bound databases (which I recommend using, at least the Core version, it makes you very flexible with which databases you can support and makes it easy to interact with the database through code thanks to LINQ) but there is also a version for local enumerations. So the examples I'm showing you will work in both cases (mostly, obviously with local objects there's a few more things you can do with them that you can't with a remote database). For example before I was aware of LINQ I used to write things like: bool any = false; foreach (object blah in somelist) { if (blah.somecondition) { any = true; break; } } if (any) { // etc } With LINQ you can do: if (somelist.Any(blah =&gt; blah.somecondition)) { // etc } Of course you're probably interested in databases uses of LINQ. Example: string hashedPassword = hash(loginPassword); User user = yourDatabase.users.Where(x =&gt; x.Name == loginName &amp;&amp; x.Password == hashedPassword).FirstOrDefault(); if (user == null) { throw new UnauthorizedException(); } (This is just for example... it's better to use a pre-existing authentication solution rather than rolling your own. Also I use LINQ more on local expressions so my appologies if I accidentally use) AFAIK the LINQ query in this case is actually run database side which is really cool since you're just writing normal C# expressions, though I think they need to be simple. For a table paging example: int page = 3; int itemsPerPage = 50; foreach (RecordClass record in yourDatabase.records.Where(x =&gt; x.somecondition == true).OrderBy(x =&gt; x.someproperty).Skip(page * itemsPerPage).Take(itemsPerPage)) { // build your HTML view or whatever }
I don't think the videos for NDC Oslo 2017 are up yet. But I was there, and Steve Sanderson's talk was great.
Wow, ok that's cool - I need to step my LINQ game up.
Someone probably edited a debug page live in Chrome debug tools or something and saved it back to disk. I've never actually checked but I assume the browserlink code normally never hits the files on disk, it's just injected dynamically by Visual Studio. So if it does hit the disk someone saved the dynamically generated file back to disk by hand.
As others have said those lines should not be present in the actual code on disk. If they are someone probably added them accidentally... possibly by editing pages being served by Visual Studio in Chrome's (or another browser's) debug tools and then saving them back to disk.
Umbraco are already moving towards Core and have made good progress and I'd imagine the other solutions are looking at doing the same so I don't even think that's much of a USP.
True
For the "lightweight" space, you're also competing with static gens like https://wyam.io/
 (and easier to implement changes to) I agree with this. I feel it easier to change code in webforms or asp even, but with mvc, I have to go in circles. 
There's this book by Adam Freeman called "Pro Asp.net" or something along those lines. Try that
I tried your suggestions and the issue persists- Mac setup cannot connect, but my Windows setup can. Now I'm just confused about what kind of error is this: is it .NET Core on Mac? Visual Studio? Windows Firewall? Mac OS X? Oh man &gt;.&gt; 
You could make the license free for non-commercial use. 
So your issue was tooling and not the language .. you had to upgrade hardware ? Never heard of that EVER. also uh the vb6 IDE sucked 
IMO they are both useful, but useful for very different purposes. View Components are great for creating shared components across pages where some logic is needed. Imagine the common scenario of putting a shopping cart summary for the current user at the top of every page for your ecommerce site. Making sure the data is loaded into a common view model across all of your actions can be slightly complicated... Or to complicate things even more only _some_ of your views need to show the summary. This is a perfect use case for view components, they have their own chunk of back-end code with full DI stuff available, plus a mini view to handle your markup. Invoke the component on any new page and the summary will show up correctly. With other solutions the html may show up but might not show any data, so you are stuck digging through other pages that use the component to figure out what you missed in the action or elsewhere. They are the replacement for Html.RenderAction, which was nice to use but a bit ambiguous for certain cases and could potentially lead to some hard to maintain code. Tag Helpers should be used for small markup items, similar to angular directives. They would be a pain in the ass to use for large chunks of html because the lack of templates. OTOH they are super cool because you can change certain pieces of an html element without having to control the entire thing. Case in point: the routing tag helpers are a much better experience than previously using Html.ActionLink and passing an anonymous dictionary to control all the various attributes that can be part of an anchor tag. TL;DR: Use view components when you need to load data, use logic, etc. for a big piece of shared functionality. Use tag helpers for controlling markup with some niceties of server-side rendering.
I would say a really high possibility. Nothing in WPF is special so it should be able to be redone as a HTML/CSS/Angular(React/... pick your favorite) You could probably port all of your business logic, but all your UI code I would guess you are going to need to throw out. 
But are those cmses based on .net core?
Alright, I'll have to wait then. Thanks.
CMS is a super crowded space. There's also Orchard2 that looks promising.
You don't need ASP.NET MVC for this. The way to do it is to install IIS Rewrite and put in the configuration on web.config. 
&gt; Steve Sanderson DotNet can be compiled to native code today? No? If yes, then dotnet code should be able to target Web Assembly. I don't think we would need to have the entire CLR for this to be feasible. Am I missing something?
Not that I remember, I thought it was a very productive environment. What else was better at the time?
Possibly Windows firewall. I wrote a tutorial [here](http://coderscoffeehouse.com/tech/2016/05/23/ssms-setup.html) about connecting to MSSQL from a Mac that has a couple of things you can try.
Although web assembly runs C/C++ it is still limited in what it has access to. I'm not sure about dot net native, but there may be dependencies that prevent it from being used in web assembly. If it was as easy as compiling to dot net native, then i think we would've seen dot net in web assembly much sooner. That isn't saying that there isn't potential for it to be that straightforward in the future.
It was perfectly fine when it released but by the time the next visual studio came out it was superior. I did vb3 and onward . Tooling for programmers is like a comedy some ppl still laugh 20 years later but for the most part it's all nostalgia Edit: I guess I should have said it sucks vs sucked 
See it in action in this video: https://youtu.be/MiLAE6HMr10?t=27m28s The video starts with explaining how .NET is running in the browser, then goes on to demo the experimental UI framework.
Video linked by /u/StevenSanderson: Title|Channel|Published|Duration|Likes|Total Views :----------:|:----------:|:----------:|:----------:|:----------:|:----------: [Web Apps can’t really do *that*, can they? - Steve Sanderson](https://youtu.be/MiLAE6HMr10?t=27m28s)|NDC Conferences|2017-06-29|0:58:24|0+ (0%)|68 &gt; The web platform never stops. Every few months, the W3C... --- [^Info](https://np.reddit.com/r/youtubot/wiki/index) ^| [^/u/StevenSanderson ^can ^delete](https://np.reddit.com/message/compose/?to=_youtubot_&amp;subject=delete\%20comment&amp;message=djtttwr\%0A\%0AReason\%3A\%20\%2A\%2Aplease+help+us+improve\%2A\%2A) ^| ^v1.1.3b
I don't feel as though "it already exists, so why bother" is a valid reason not to do something. I'm a huge advocate for using the right tool for the right job, and if WordPress is the right fit for what you would need then go for it. What this system was built to target was the market that ranges from Umbraco to Sitecore sized websites, not simple blogs - though it's well enough suited to that. I'm leaning more towards the licensing model of free and open source for personal use and paid for commercial use.
The biggest differentiator between this system and all the other mentioned systems is that it's a lot more developer focused where it (in my mind) should be, data models and site configuration (for multi-site setups) are code-first as opposed to being stored in the database. I work with Umbraco, Kentico and Sitecore on a daily basis and see the strengths and weaknesses in them. This system was built in an attempt to combine the strengths of what's out there at the moment.
This is the licensing model I'm leaning towards. I'm not too sure how it works though. How do I enforce it? How do I stop people from just taking the open source code and making their own clone?
Video is at https://youtu.be/MiLAE6HMr10?t=27m28s 
You could have people register. There isn't a great way to enforce anything though. 
&gt;[**Web Apps can’t really do *that*, can they? - Steve Sanderson [58:24]**](http://youtu.be/MiLAE6HMr10) &gt;&gt;The web platform never stops. Every few months, the W3C and browser vendors unload great big bundles of shiny new toys for web developers everywhere. &gt; [*^NDC ^Conferences*](https://www.youtube.com/channel/UCTdw38Cw6jcm0atBPA39a0Q) ^in ^Science ^&amp; ^Technology &gt;*^81 ^views ^since ^Jun ^2017* [^bot ^info](/r/youtubefactsbot/wiki/index)
Sure, but the tools do exist for a reason. Most of the reasons are only apparent when you're working on a big or complex codebase though. ORMs trade performance for consistency. If you've ever had to create or update 10-20 tables/rows at once depending on business rules / existing database state, you'll probably appreciate the role that ORMs play. DI frameworks trade complexity for clarity/configurability/testability. If you don't need these things, they get in the way. If you do, they're super handy. What I can do in a day with these tools is more than what I'd be able to in a week if I'd have to build everything from scratch each time. But yes, when you've made that productivity-for-performance tradeoff, the app runs slower. 
Off-topic, but hey, another .Net Rocks fan in the wild! Heard the podcast today and I've been trying to find the talk he gave ever since. 
VBA is based on the ancient Visual Basic 6. The .NET framework was created much later, and Visual Basic .NET was made to *look* like VB6 to encourage existing VB6 devs to switch to the newer .NET platform, but under the hood they are completely independent. The .NET runtime is written in C++, I would assume the VB6 and VBA one was as well.
You could use the IP address of the user to prevent more than `n` requests a day, but there are ways for a spammer to get around that. Without some sort of trusted authentication, you're going to be hard-pressed to write a perfectly secure implementation.
Check out https://github.com/bitwarden/core
I hate the DOM. It's time to start having web apps with actual UIs and not be built around a fucking document. Adobe Flex was a great example of this, and with Canvas/WebGL + WebAssembly using the DOM for UI should be out the window. If you still need it for SEO, just leave a basic HTML structure on the bottom of the display list and have it hidden (or draw over it, or embed the canvas target in a child node, whatever). Regular old web sites can keep using DOM all they want, but for dynamic enterprise level apps and functionality the DOM is an antiquated paradigm. 
I gave your tutorial a try and still no luck. Oh boy.
Hmm, as I've understood it, the repository pattern is a way of *"creating an abstraction layer between the data access layer and the business logic layer of an application."* and mostly mentioned that it facilitates TDD. I don't see how this will help refactoring down the size of my controllers? For example, where would I write helper methods? I also just read this on docs.microsoft.com: &gt; Many developers write code to implement the repository and unit of work patterns as a wrapper around code that works with the Entity Framework. These patterns are intended to create an abstraction layer between the data access layer and the business logic layer of an application. Implementing these patterns can help insulate your application from changes in the data store and can facilitate automated unit testing or test-driven development (TDD). However, writing additional code to implement these patterns is not always the best choice for applications that use EF, for several reasons: * The EF context class itself insulates your code from data-store-specific code. * The EF context class can act as a unit-of-work class for database updates that you do using EF. * EF includes features for implementing TDD without writing repository code. 
Use a proxy endpoint and add in limiting logic before the call to the real api? 
Well that's the dream, a properly tree-shaken runtime that's tailored to exactly what you need. Or at least a standard lib. I'd be very happy to see the ecosystem rally around .NET to the point where this lib is built into browsers - anything to rapidly bring the end of the grip javascript has on client side development.
So you want to authorize users without authenticating them first? Seems legit.
What are the benefits of using L over something like serilog?
Thank you. This is exactly what I wanted to know. 
Absolutely great! Thanks for showing me this.
You need to implement blacklisting if you're trying to prevent malicious use of an API, even if it's not public. https://weblogs.asp.net/senthil/restrict-ip-address-in-asp-net-web-api You would need some way of keeping track of who is making requests and how fast they are making them and then keeping a blacklist. That implementation above is pretty simple. We've been using Redis at my job for blacklisting known bad IP addresses and it's very fast and works well although most people probably don't need the same levels of speed we do.
Being the lead dev of Orchard, I have seen many developers and companies making a living out of services from their knowledge of the CMS. I would suggest you to provide it for free, hope it's successful, and use this success to monetize your knowledge and provide better service. See what WordPress (Automatic) is doing, or Drupal (Aquia). I would have loved to see you participate in the Orchard Core development as its user base is already significant, and it's based on .NET Core. But I can see some architectural differences that support for a different code base. More choices for users is good too.
Your option if you don't want to go open source is to hire people.
The new compiler for .NET ([Roslyn](https://github.com/dotnet/roslyn)) is build in C#
I think the best way of showing it would be to use it against some of your existing code...can you paste a controller function that you know isn't very pretty because of it's size and I can pseudo-code out how it would be split down?
He lies.. the new compiler is build on C#(Bootstrapped using roslyn), the old one was C/C++ though ...under the hood C#,VB etc all boil into "MSIL" (Microsoft intermediate language) which is then compiled to machine code using the JIT (just in time) compiler...
The compiler is different than the runtime. Roslyn is written in C# but the [CLR](https://en.wikipedia.org/wiki/Common_Language_Runtime) and parts of the .Net Framework are written in C++.
**Common Language Runtime** The Common Language Runtime (CLR), the virtual machine component of Microsoft's .NET framework, manages the execution of .NET programs. A process known as just-in-time compilation converts compiled code into machine instructions which the computer's CPU then executes. The CLR provides additional services including memory management, type safety, exception handling, garbage collection, security and thread management. All programs written for the .NET framework, regardless of programming language, are executed by the CLR. All versions of the .NET framework include CLR. CLR implements the Virtual Execution System (VES) as defined in the Common Language Infrastructure (CLI) standard, initially developed by Microsoft itself. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.24
That sounds amazing! Alright, some explanation: I've made a page to facilitate going through old exams in a linear algebra course for my university. For now it's just a place where you can look at problems from exams and check the solution for each problem through tabbing on the same page. I've saved the problem (and solutions) as image files (screen shots from exams) in the wwwroot/images directory and keep only their file-names in the database. Here's the controller that gets called when you look at a problem, the routing is: template: "{examDate}/{problemString?}", defaults: new { controller = "Exam", action = "Problem"}); Warning: There's some ugly-ish string-manipulation to find the right directory. _____________________________ public async Task&lt;IActionResult&gt; Problem(string examDate, string problemString = "A1") { // We will need these to be able to go to the next/last problem ViewData["examDate"] = examDate; ViewData["problemString"] = problemString; // We need the exam to identify the problem we're looking at DateTime examDate2 = DateTime.Parse(examDate); var exam = await _context.Exams .SingleOrDefaultAsync(m =&gt; m.ExamDate == examDate2); if (exam == null) { return NotFound(); } // We need the problem to find the images to present to the user Level level; Enum.TryParse&lt;Level&gt;(problemString.Substring(0, 1),out level); int number = int.Parse(problemString.Substring(1, 1)); var problem = await _context.Problems.SingleOrDefaultAsync( p =&gt; p.ExamID == exam.ID &amp;&amp; p.Number == number &amp;&amp; p.Level == level ); // Getting the path to images we will present to the user // First the problem-file string date = exam.ExamDate.ToString("ddMMyy"); string file = $"{date}{problem.Level}0{problem.Number}"; string fileString = $"../../images/exams/{date}/problems/{file}.png"; ViewData["filestring"] = fileString; // Then the solution images (which can be more than one) string[] fileEntries = Directory.GetFiles($"wwwroot/images/exams/{date}/solutions"); List&lt;string&gt; solutions = new List&lt;string&gt;(); foreach (string f in fileEntries) { if (f.Substring(38, 9).Equals(file)) { solutions.Add($"../../images/exams/{date}/solutions/{f.Substring(38)}"); } } ViewBag.Solutions = solutions; // Need the name of next and last for buttons in the View // Using a helper function called Neighbours to get these Tuple&lt;String, String&gt; neighbours = Neighbours(problemString, exam.ID); ViewData["last"] = neighbours.Item1; ViewData["next"] = neighbours.Item2; return View(problem); } _____________________________________ Realized that I have actually written a helper function to that controller-action already (and it's inside the controller which feels shaky), the helper function isn't pretty either... Anyhow, this is the view you get in the end: http://mintenta.azurewebsites.net/2017-01-11/A2 Turnes out there might be some wait time on [first request].(http://wp.sjkp.dk/windows-azure-websites-and-cloud-services-slow-on-first-request/) 
Great article. Also recommend checking out Cesar de la Torre's book and Christian Gammelgaard's book. 
You can't really have this type of "security" without authentication
The client side has web services and your azure service needs to basically proxy them with a site Id determining which to call?
Thanks for all the replies. I spent quite some time on SO and google, and the most similar question I found was this: https://stackoverflow.com/questions/11923208/how-to-secure-web-service-without-login So basically, it's not possible. But most likely nobody will care until the app gets popular. 
Why does some of the traffic not got through the "strangler"? And after the API gateway SPA traffic is treated differently? Is this traffic marked somehow (headers)? And why? 
I'll also mention that as of today, I've had a lot of problems just trying to connect to a z/OS server with this package. I think it has more to do with IBM's incomprehensible licensing requirements - there is no clear information on what exactly you need in order to simply connect and run a query. 
The strangler is only for replacing legacy functionality. New functionality doesn't need to go through it. I think its better to use different endpoints for different functionality. But you could use headers or maybe even query params.
You need a VPN between your Azure and onsite pieces. One part of your app needs to be Internet-facing and should do things like authorization. It's commonly called an API gateway. The big thing is the VPN (sometimes referred to as a VPC in this scenario) between your Azure backend and your customer on-prem. There's great documentation on setting up a VPN/vpn gateway on docs.microsoft.com
No the client side won't have web services at all they would have to make a connection to Azure and listen for requests from it
My project must be in the top 300 (https://github.com/dodyg/practical-aspnetcore)
Anyone else think microservices is architecture astronautics? -"monolith" developer
Db.SaveChanges() ?
https://github.com/CrustyJew/RedditSharp Have a good day!
I miss my "monolith" - microservice developer 
Then I can't help but feel you're doing something wrong and/or you don't understand the MVC framework well enough. 
Yep, this. 'Ahh but it was so much faster to write "update table set field = " + txtwhatever.value'
Would not recommend: 1. Moq (NSubstitute has a cleaner syntax) 2. Making your mocks strict (this leads to brittle tests that no one wants to maintain) 
Depends on what you are doing. I worked on a microservices architecture for five years and it was great. The thing is, we actually had lots of small, autonomous and semi-autonomous services. Some were listening to HTTP requests, some TCP, other processed emails, files, etc. For our FIX connections each had their own service. The data from them was sent to both a real-time cache-like server and a more involved processing engine that eventually hit the database. The ability to drop one connection without affecting the others saved us many times. When your entire system is just a stateless web server, microservices make no fucking sense. Introducing a bunch of random ass network hops just because you want to play with the 'big boy toys' is irresponsible. 
3\. Decoupling setup of test-specific input data and the test 4\. Writing the same unit test twice 
It sort of is. People actually go to production with microservices, though. Most astronaut projects never make it to prod. Not saying it's a good idea in most cases! I would only use the microservices approach if: 1. You have a dedicated devops/IT team that can help you automate deployments, or your management lets you do devops related tasks during your sprint. I've never seen the latter actually happen, so I maintain that you need a dedicated team. 2. You have real scaling issues (i.e. your company is Amazon, Facebook, Airbnb, or similar) 3. You are OK with writing really good integration tests. No matter which approach you choose, i.e. event based or HTTP based microservices, you're going to have lots of issues where data becomes out of sync if you're not careful. 4. You have a solid plan for dealing with distributed transactions. Never ever start an application as a microservice. Start with a monolith, and just design it properly so that it's modular enough to be broken apart later if needed.
Need more JPG!
O_o Isn't this like 5 or 6 year old stuff? These days you should be using https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection or some standalone solution like Autofac, surely? (also, there are tonnes of open issues with unity -&gt; https://github.com/unitycontainer/unity/issues, not to mention that the name conflicts directly with unity3d)
The best thing about starting your project with microservice architecture is that you will never end up with scaling issue (because your project will fail and be cancelled). 
5\. Unit test adds zero value. Method is just a straight pass through. 
Not really. Quite a few people have microservices in production. In comparison, architecture astronauts live in the theoretical world where none of their ideas ever make it to production or make sense or can even be implemented. 
Is this post asking a question? The article seems to offer nothing useful. 
A VPN probably wouldn't work for our use case. I'd ideally be looking for a solution that the onsite locations make a connection to the Azure server and listen for requests to it, without having to set up a web service on the site itself, just having the one web service on Azure
I think your first point is very opinionated. I personally prefer Moq over NSubstitute.
A VPN isn't necessary in many cases if you can just open some firewall ports but what you are writing doesn't make sense. Can you update your original request with more details. 
Does anyone have an example of the implementation of microservices ? Id like to look at some code, ideally c# 
I prefer moq myself, but TBH 99.999 % the mocking framework makes/little no difference. Its the test thats the hero of the piece, al long as you can see easily what the mock is hoping to achieve then thats ok. 
This should do the trick; public class RouteConfig { public static void RegisterRoutes(RouteCollection routes) { routes.IgnoreRoute("{resource}.axd/{*pathInfo}"); routes.MapRoute( name: "Default", url: "{*anything}", defaults: new { controller = "Home", action = "Parse", id = UrlParameter.Optional } ); } } public class HomeController : Controller { public ActionResult Parse() { string path = Request.Url.PathAndQuery; string[] splitpath = path.Split('/'); if(path=="/" || splitpath==null || splitpath.Length&lt;2) { return new HttpStatusCodeResult(HttpStatusCode.BadRequest); } else { string filename = splitpath[splitpath.Length - 1] + ".html"; string folder = splitpath[splitpath.Length - 2]; //Build the correct path here string filepath = Server.MapPath("/yourhtml/") + folder + "/filename"; return File(filepath, "text/html"); } } }
I've been super busy the past couple of days. I'll try and look at this sometime today, I have not forgotten!
1. Highly subjective 2. If your mock is loose, there is a greater chance of your test passing when the code no longer works.
Updated
Thanks for the update. Wil your azure web service have connectivity to each of the on premise sql servers?
Not directly by IP as some of the premises don't have static IPs, so if there was a way to establish a connection between Azure and the premise from the premise side that could work, I think?
You can use a domain to connect to a sql server, ie db.mydomain.com. As long as your azure service can connect to each db (open the appropriate firewall ports or a vpn) this isn't all that hard. I am a little partial to service stack these days but you an easily launch an app service with a simple web api, send in the client id and have a hash table or whatever is easiest to translate the client id to a connection string and query that db. It isn't overly complicated. There are also dns services that work with dynamic ip's.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/programmerhumor] [Design patterns for microservices • r\/dotnet](https://np.reddit.com/r/ProgrammerHumor/comments/6lts1e/design_patterns_for_microservices_rdotnet/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))* [](#bot)
This. I even created a limited bot a couple of years ago during some downtime at work, called the u/BotOfOriginality, whose original purpose was to call out people who were using the phrase "religion of peace". 
The fact that OP didn't even Google "Reddit C# Api" to check before posting is kinda sad
Threads and GC are missing. Also, take a look at this effort to make Mono run with emscripten (which currently has the same feature set as WebAssembly): http://mono.1490590.n4.nabble.com/Mono-on-Emscripten-JavaScript-experiment-td4669215.html
Garbage spam.
The only reason to use Unity today is if your working with legacy code, and the authors of the code had such a poor understanding of IoC-containers that the code is too coupled to actually switch container.
As someone who has worked in a codebase where all mocks were strict and there were approximately one billion of them, I'm more than willing to make that trade-off. Could something break more easily? Sure, but I'm also not spending my life fixing an absurd number of tests every time I want to refactor something or add a dependency to a method (heavy use of strict mocks usually leads to this scenario in my experience) I tend to rely on loose mocks, used sparingly, in combination with integration tests (which are more valuable since they catch logic errors in addition more sneaky things like incorrect IoC, EF, app startup configs). This combo has been working out well for me anyway 
Haha too accurate. We just finished a project where the architect recommended microservices, and it took way longer than expected (extra 5 months or so). A lot of that time was spent fighting with Azure, deployments, getting our CI set up to handle all of these different services, managing configuration, shared libraries, etc. Things we wouldn't have to worry about if we just went with a properly designed monolith.
You don't even need MVC to render the SPA. Since its a static file you can just have your webserver (nginx) serve the static content in this case the entry point.
Strictly speaking, you are correct. However we do use the MVC framework to make rendering certain server-known values easier. For instance, angular needs to know what the primary domain of the current environment is. To accomplish this, we emit the web domain web.config value via Razor to a javascript variable at the top of our SPA framing page.
Do you use an automocking container? I used one for a large code-base that had issues. It will provide mocks for any dependencies that are not explicitly mocked, this let you specify strict mocks without needing to change tests to deal with new dependencies that are not part of the current test. 
OP is contractor from India confirmed.
I've never done raw web socket programming in .NET before. Any feedback on this very simple echo server is much appreciated. I haven't handle closed connection, etc yet. I just want to make sure I am on the right track.
I disagree. As shown in the post, you can have templates with TagHelpers. It just takes a little bit of boilerplate. ViewComponents type check is kind of weird. You just pass an anonymous object to it. No type check. Whereas TagHelpers have very good intellisense on the cshtml with type check, and you can get every attribute passed on the tag, even if you didn't bind it. And the invocation? That `@await Component.InvokeAsync("PriorityList", new { maxPriority = 4, isDone = true })` is not html friendly at all. And if you use the TagHelper way (eg: `&lt;vc:priority-list&gt;`, then you're using a TagHelper internally. So why not use just a TagHelper anyways. Waht about TagHelpers Pre/Post Content/Element? Targetting multiple tags? So many nice features. So why use ViewComponents then? I'm not saying there are no reasons ViewComponents are better, just that definitely not the ones you listed.
Ok, so I've broken down a fraction of the code, and hopefully from that you get what exactly is going on. I got the Level part, but I'm really not sure what that code is doing with all the substrings other than the directory, or why Level matters. So instead of focusing on that let's focus on splitting the Exam stuff into it's own repository class. To get started you'll need to make an ExamRepository class, like this (There should in all honesty be an IExamRepository and this is implemented based off that, but for times sake I won't do that here): public class ExamRepository { } Let's take a look back the controller, at the top we're making a call directly to the context (I assume this is a database of some sort, it doesn't really matter in this context). In this case, we don't really need the controller to handle this portion, so let's separate our database concerns out. Create a new method in the ExamRepository, and create the following: public Exam GetExamByDate(string dateTime) { DateTime examDate2 = DateTime.Parse(examDate); var exam = await _context.Exams.SingleOrDefaultAsync(m =&gt; m.ExamDate == examDate2); } Let's go back to the controller, before we even think about implementing this method here, we need access to the Exam Repository. This is really, really simple to achieve with Dependency Injection. In your Startup.cs add a call for: services.AddScoped&lt;ExamRepository&gt;(); or if you implemented the Interface as I said above: services.AddScoped&lt;IExamRepository, ExamRepository&gt;(); Lastly in our Controller, let's make a constructor if we don't have one already that takes a single parameter of IExamRepository, like so: public ExamController(ExamRepository examRepo) { _examRepo = examRepo; } And lastly, we need to have this _examRepo field in the controller, so add a private readonly field named _examRepo: private readonly _examRepo; If this makes absolutely no sense to you at all, take a look at [this article](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/dependency-injection) for some Dependency Injection primer material, as you don't really need to understand HOW it works, but rather WHAT it's doing. So now that we've got our Controller all set up for this, we can begin refactoring. For this, it's super simple. We can now replace all the lines we copied earlier with a simple call of: var exam = _examRepo.GetExamByDate(examDate); And we have cleaned up a lot of bloat in the controller, split the database concerns into it's own class, and setup dependency injection on the class, so we can access Exams anywhere in the class. Leave in the exam == null check, just in case it comes back null this remains in the controller so a response can be generated stating such. Another thing I would highly recommend, especially if things can't be sent off to a repository class, such as the Solutions portion, is refactor it into another method with a good, descriptive name, so the controller reads easier. Uncle Bob's clean coder series puts a soft-limit on 5 line methods. For a controller, this may not be the most feasible thing ever, but it should at least attempt to be adhered to. Let's look at doing this with the Solution Images portion. Select the entire following code block and press Ctrl+R, Ctrl+M (Extract Method). Go ahead and name this new method "GetSolutionsForProblem": public void GetSolutionsForProblem(string file, string date) { // Then the solution images (which can be more than one) string[] fileEntries = Directory.GetFiles($"wwwroot/images/exams/{date}/solutions"); List&lt;string&gt; solutions = new List&lt;string&gt;(); foreach (string f in fileEntries) { if (f.Substring(38, 9).Equals(file)) { solutions.Add($"../../images/exams/{date}/solutions/{f.Substring(38)}"); } } ViewBag.Solutions = solutions; } The same kind of stuff should probably be done for the other stuff in the controller method. But hopefully this gives you a good idea of how to refactor and clean up this bloat. You should hopefully also see how a TDD format would have prevented this in the first place. When you do TDD you are trying to accomplish one single thing. So maybe the first unit test was making the controller, the next was making the Problem method, and then maybe just getting an exam, and at that point you probably would have realized you needed a repository to do this interaction, and you would have gone down that avenue. Same for the files, you would have made that it's own method because you would question why that's going into the controller. This is stuff that will come naturally over time and with practice, so keep at it! I'm also not guaranteeing my way is the best way for all of this, because everyone sees things differently, this would just be my approach. In a perfect world you would also be creating these refactorings via TDD so you know EXACTLY what each step would be, rather than just extracting all these methods.
Your way of sending the message to all connections doesn't make good use of async/await. With the await inside of the foreach, the program will start sending a message, and then wait for it to finish before starting to send the next message. A more desirable behavior would be to start sending the message to a socket and then move onto the next socket without waiting for it to complete. Then once you have started sending the message to all connections you can then wait for them all to finish. Here are a couple examples how to do that: var socketTasks = new List&lt;Task&gt;(); foreach (var (s, sid) in cm.Other(socketId)) { socketTasks.Add(s.SendAsync(broadcastBuffer, WebSocketMessageType.Text, true, CancellationToken.None)); log.LogDebug($"Broadcasting to : {sid}"); } await Task.WhenAll(socketTasks); With LINQ var socketTasks = cm.Other(socketId).Select(x =&gt; x.socket.SendAsync(broadcastBuffer, WebSocketMessageType.Text, true, CancellationToken.None)); await Task.WhenAll(socketTasks); 
Don't see a lot of "doing it this way is wrong and there are better ways. The end" blog posts out there.
Thank you! Is there anything else? One thing that looks weird to me is how everything look so linear. I used to do socket programming in Delph back then and we had to rely on events. 
Are you including a reference to jQuery before your reference to the library you're trying to use?
Yeah, [here's](https://pastebin.com/m9DNQKYe) my _Layout.cshtml. 
Thank you so much! I've been with friends the last few days and haven't had time to work on the project. Thanks to your post I'm looking forward to being able to get back to it and will have a few questions that I'd love to ask you as soon as I get the time. Once again thanks for all of this! PS: The level thing refers to the level of the problems (they come in three levels A, B and C), so it's perfectly reasonable that you didn't get what it was :)
And the &lt;jqx-grid&gt; [ouput](https://pastebin.com/dW67u906) generated. I get the border for the grid, but nothing else.
Awesome, just let me know if something doesn't make sense!
also you might consider something like this: [Gist about Parallel Webrequests using Async/Await](https://gist.github.com/Kirides/f62b56df1bea51a8aca02140e4de1a21#file-parallel-webrequests-cs) 
Where do you have the plugin installed to? Based on your &lt;script&gt; tag, it should be at `./wwwroot/jqwidgets/jqx-all.js`. Is that correct?
I can download the script if I view the page source and click on it.
I haven't used jqwidgets at all but, from writing my own tag helpers, you generally have to add to the viewImports cshtml. This is fairly well documented by Microsoft so I'd start there.
At the end of the day, old technologies go out of style not because it's impossible for them to do X which everyone needs it to do. If that were the case that feature could be implemented. Old technologies are phased out because they don't *scale*. Whatever features they provide are a moot point if your codebase is an insufficiently tested fragile web of custom code. ASP Classic did not scale as well as ASP.Net.
The jQWidgets Tag helpers line is in there.
I think there's some give and take on these. - Automated deployments: Part of the reason we started moving towards microservices at one of my old jobs was because we were sick of deploying many items because one piece of code changed. Yeah, when we had a new microservice we had one more 'big deploy' to do, but after that we could deploy just a single item the majority of the time. This is insanely helpful if you -don't- have automated deployments. (n.b. We did also move to semi-auto where scripts had to be manually executed, but did the rest of the work.) - Integration tests: I think the challenge of integration tests depends on the problem domain (and, if migrating, how the original architecture was done.) Data Syncing was never more of an issue than it was in the past after moving towards microservices. Even over HTTP, unless you're doing 'Fire-and-forget' calls where you don't care to even wait for an acknowledgement, all that's happened is you stopped lying that *something can go wrong doing whatever call you're making.* And yes, as far as the call itself, all you've really done is just add another thing that COULD go wrong, but I've seen people be far more cognizant of the consequences of failure when they see a network-dependent call over a Method call or even a DB Call (Which, let's face it, is still a great place for things to go wrong.)
Several factors come into play to determine if a microservice architecture brings more advantages than pain for a given application. Microservices advocates increasingly make their speech more nuanced, saying that even the heaviest microservice architectures like Netflix and Ebay started from monoliths. There's a tipping point where, as the monolith grows, the pains grows along with it and microservices start making more sense. A few examples: * As a large application grows and grows, it becomes increasingly difficult to reason on the system as a whole. One size fits all is showing its limit and it's becoming increasingly difficult to find strategies for caching or authentication that work equally well for every part of the monolith. * Scaling is probably the number one reason cited in favor for microservices. For performance, microservices give you a lot more options for allocating resources. To be worth it you'd probably need a significant number of mostly idle hosts though. * Team size also matters. As the number of developers working on a monolith increases minor pains become major headaches. It's the same theme for every argument, the monolith is easier to work with and less costly at the beginning. The tricky part is to find, for your own situation, the point where the scalability of microservices (in multiple aspects) brings more value than the simplicity of a monolith.
Remember Datetime is a struct so it can't be null - thus MVC is filling it in the Default(DateTime) or 1/1/01. Try Nullable&lt;DateTime&gt; if you want to allow the field to be empty (not set).
I did originally try something like this but I found I still had issues and didn't figure that making DateTime nullable made a difference. Perhaps I just needed a fresh mind though. This week has been so stressful but a lot of that has blown over and I investigated setting DateTime to nullable more thoroughly. Turns out I found that setting my DateTime to nullable did indeed lead to new errors, but I eventually discovered that I was not handling the case properly for a null value within my custom validation. @_@ Now everything works perfectly lol. Ugh I can't believe I spent so much time on this. &gt;_&lt; On that note however, I'm not familiar with structs to be honest. It was not covered in our curriculum so it's a brand new subject to me.
Yeah rah! Don't get to bent up about the time spent. I've worked on problems for days only make a one line change. Next time it or similar problem comes up you'll have the personal experience to identify it much faster. Short version on structs is they are objects that get pushed into methods like int, float, double and unlike classes where the memory address to the object is pushed in. 
Don't you mean `DateTime?`? I know it exists but I've never actually seen `Nullable&lt;T&gt;` used.
Any reason to not use signalR?
Where does that article state the CLR was built in C++?
I want to learn the basics instead of relying on higher lever libraries. I'll pick up SignalR later.
The ASP.NET Core implementation of it is pretty wide-open for customizing it at a lower level. Not as much in the 2.x versions. 
Can you please elaborate on this?
https://vimeo.com/204078084 Well worth the watch, explains a lot. Not suggesting you stop what you're doing at all, just showing you this so you may not have to reinvent the wheel in the future :)
Thanks a lot. I've done ASP.NET MVC forever but I've never really gone down deep. Last year I decided with ASP.NET Core I am going to figure things out and get into the weeds. 
I kind of just assumed `DateTime?` would be sufficient given that I was already aware the `?` can be used at the end of certain types to allow them to be nullable when they otherwise aren't, such as `int?`. Fortunately I was right! :D
Well I mean I not only learned how to thoroughly validate and work with dates and DateTime objects, but I also really boosted my comprehension of using validations in ASP.NET Core *INCLUDING* how to write my own custom validations, which will be very handy once I start building my portfolio website. :D
"DateTime?" is just syntactic sugar for "Nullable&lt;DateTime&gt;". They're the same thing.
There is no such thing as "properly designed monolith" if the project really calls for microservices. The above sounds like lack of experience with microservices and all their specific challenges, plus possibly lack of dedicated devops support. Whether it really needed microservices or not is sometimes up in the wind. Client comes in with grand requirements, the architect obliges and designs something that will accomodate them, client finds out how much it costs to actually host the thing at the magnitude they asked for, and ends up putting it on a much smaller infrastructure, where it won't be scalable and might as well have been designed as a monolith.
You do realize you can still scale monolith services and the new microservices craze is getting out of hand right? Why do I need 8 instances of mariadb running on the same box. That won't increase scaling, that will just bog down the cpu. 
I didn't say you can't scale monoliths, I said that if you need microservices then you need microservices. Typically, microservices lend themselves better to architectural changes, which down the line may help rescue some bad planning, or lack of insight, or changing specs. They still offer options where a monolith would not. Whether those options are of any use to your project depends.
Difference between class and struct https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/choosing-between-class-and-struct Most of the time you will want a class, but there is a decision tree at the bottom of that article.
As a test, can you do normal jQuery things? Like access a Dom element, I'm curious if something weird is happening with order of operations and the call to your template is loading before the jQuery file is loaded. Maybe add some binding to a click event
That's the magic of async/await. It replaces having to wrote all that "BeginXXX" and catching the "EndXXX" event. Behind the scenes all that is still happening but the synthaxic sugar hides all that boring plumbing.
Did you try dumping your cache
currently using .net core 1.1.0 against full framework. only thing really holding us to full framework right now is nservicebus. eagerly anticipating .net standard 2.0 and nservicebus 7.
We run .net core in production . We're running it in a docker container , on Linux in aws. No issues , we have pretty substantial load too. The build pipeline was easy to set up, the only thing that gave a bit of trouble was db migrations but we figured that out . 
If I may ask, why did you choose .Net
If I may ask, why did you choose .Net
We are starting to use it exclusively for our service layers. Current versions are 1.0 and 1.1.0 with full .net framework. Entity core was trash when we made the decision. We might reevaluate soon
I like to know too. I have 15 years in .NET but I am now 100% Linux based devops. I switched from windows C# to Linux devops. I have a few sites running on golang and php, but they need v2. I thought about using asp.net for it this time, and keep it on Linux. Plus the fact MS SQL server runs on Linux now. 
Regarding `ReceiveAsync`: - The receive buffer size (4) seems really small - You don't need to create do `receiveBuffer = new ArraySegment&lt;byte&gt;(bufferSize)` for every iteration, the `ArraySegment` isn't changed in any way - There is no point in using async methods on a `MemoryStream`, it's all synchronous anyway and causes unnecessary overhead
What's your particular grips with EF? I'm currently looking at Dapper although I'm not sure if it has .net core support.
In my experience micro services are a nightmare. As for many of my friends. 
EF Core, being a complete rewrite, is an incomplete product and should have never had the "1.0" label. According to the documentation, which is laughably incomplete, the SQL generator in particular isn't ready for some operations and it will default to sending your table to the application for processing. 
I have two apps in production, both the same stack: Core, Nancy, Kestrel, ngnix, postgresql running on a Ubuntu VM. I've held back on some functionality (image manipulation and push messaging) until v2 and the needed libraries are functional/stable. Both apps were ported from framework 4.5.2 running on Azure. The main issue was the lack of view engines on Nancy (only SSVE was available, and it's severely lacking). But both apps are lightning quick now, so at least it wasn't in vain.
what u/grauenwolf said. This and no Stored Procedure support made us not even think twice, but we still needed an ORM.
I'm pretty new to the SOA paradigm and I want to implement it in a small project I'm going to be working on soon. Has your team evaluated any free/open source alternatives to nservicebus? Thanks.
So, what are you currently using?
Do you have a source for EF sending the whole table to your application? That sounds incredibly bad.
Why did you choose Nancy over MVC?
Two customers of mine run core for certain web apps we redesigned this year. Reason: On customer was on .net stack anyway so we decided to give it a shot since the middleware is much easier to configure. The other one wanted to go with IdentityServer 4 for certain reasons and loved it. So we built the service layer with core as well. One of those things run on Azure, the other on on-premise. //edit: I might add that we used EF Core on both projects and replaced it with Dapper during development. EF Core should never have been released as final in it's current form.
I figured that was the case. Also I like your name. :P
Because I've been using Nancy for a few years now and I like it. I had already ported both apps last year to Nancy v2 (technically still pre-release, but it's been very stable for me both on Core and full framework before that).
not really. we're a small "team" - two people. we also had the luxury of working at the same place together previously. we had experience with nservicebus already as well as a home-grown service bus implementation through rabbitmq. rolling another service bus implementation was out of the question just due to the time involved and not much ROI when the problem has been solved already many times. i was interested in exploring akka.net, but the architect (the other guy hah) had a preference toward nservicebus due to our familiarity as well as the nice tooling (service insight, etc) and the company didn't have any objection to the licensing costs. there are certainly other options out there that are free. there's akka.net, which is different, but in the same wheelhouse. i've also heard good things about MassTransit, but aside from reading the docs to see what the API looked like, i don't have any experience with it. The problem really is that until .NET Standard 2.0 the only thing I could really find is RawRabbit and Microsoft's Azure Service Bus SDK, but that's nowhere near those other frameworks. if you want sagas, etc - you'd have to do it yourself. they're really just clients with friendlier API's as far as i can tell. Luckily 2.0 will bring Akka.NET, NServiceBus and MassTransit support shortly afterwards without the full framework.
We started to write new apps in .net core. We have one pure asp net core service running in production in Azure Websites, and a few more services coming on asp.net core targeting .net framework. Also we started to migrate our libraries to .net standard from portable profiles, some of them went to production.
EF (and Linq2SQL) will transparently enumerate the query if they can't transform the operators to SQL operations. It's a known behavior. It's easy to use, and very easy to misuse. 
We're running an ASP.NET Core service inside docker on AWS ECS. The project wasn't without a few hiccups but went smoothly enough that we're accelerating the move of some of our other components from traditional ASP.NET stuff running inside IIS to ASP.NET Core.
Thanks, man.
To be fair, you can have EF throw an exception when this happens, so you'll catch these cases in development. Of course, this won't help you, if there's no suitable rewrite of the query, but I have always been able to work around it. Awkward, but not a deal-breaker (to me). 
We are, got 2 aps. One Web API and a MVC webpage querying the API..
Do you mind sharing what you did for migrations please? I'm struggling with the same thing now.
What do you use to manage database changes? This is close to the stack I want to use (MVC instead of Nancy).
If like to know more about Nancy and why it was chosen as well.
I've used Nancy on a couple of smaller projects before that only do simple lookup operations (For example an IP to Location API). And Nancy is super lightweight and the guys coming from NodeJS preferred it. That being said, I think Web API in Core is also super lightweight and easy to use. I think it mostly comes down to personal preference. I think if you are using fully fledged views (Like Razor), then MVC Core is better. I really don't think the view engines for Nancy are as complete as Razor, but again, that's my personal opinion. I wrote a little bit about getting started with Nancy in Core here : http://dotnetcoretutorials.com/2017/03/16/getting-start-nancyfx-asp-net-core/
Nothing automated for the database. They're stable apps I've had for years, so no need for anything (aka pain of migration never made me search for a better answer). So, just sql scripts I run on the server as needed. I use Dapper, so no heavy ORM (for good or ill).
Great thanks. I set up the buffer size to be that small so I can easily test the code that handle larger message. This was the first time I encountered ArraySegment class. I have to digg further to get more details of its purpose.
Yeah of course. EFCore 1.1/API all set up and in production. It works great. Really freaking fast too. Had a hell of a time running a .net app in a subdirectory with nginx, still don't have that working. Exited for 2.0....
Not using dotnetcore. But I am using aspnetcore and EFcore on top of Net46 Haven't had to use Visual studio in months.
Are you using MySQL? I am using entity framework with pomelo MySQL connector and have had a few issues that involve me having to rebuild the database.
wait, mssql runs on linux also???
Yeah,I did a pop up message once the document loaded. That was my first test. I'm just going to talk to their support tomorrow. 
I did a Ctrl + F5 if that is what you mean. I think VS .Net Core apps in Debug mode don't cache files. I might be wrong though.
https://www.microsoft.com/en-us/sql-server/sql-server-2017 There's also a Docker image !
We use SQL Server in Docker for integration tests. Much nicer than the big bloated shared database server anti pattern.
Give MassTransit a go.
Does it still required 3.5Gb of RAM?
Hmm, its in "preview". Is that safe for production?
If it supported stored procedures that would be a suitable rewrite. Sigh...
Interesting. Sounds like your going the right route
You can still target the full .net framework, but be using core. So I believe it's entity 6 we are using
Not previous commentor, but we moved a large legacy codebase to Mono (before .NET Core) due to Wait Handle limitations, though we had to recompile Mono, as it had 64 Wait Handle limits hardcoded in to match the Windows platform. There was no way we were going to rewrite in a non .NET language, but we wanted to host on a cheaper server than a Windows one when we had to scale for load sharing. Apart from a few headaches around the recompiled Mono, and the Supervisor daemon not working too well, it ran fine for 2 years, until we moved back to windows after we dropped using Wait Handles in later .NET versions.
From what i can tell, it's low config in comparison to serilog. But in most cases, if you don't need complicated logging solutions, then the config stays pretty simple, even in the bigger frameworks like serilog. 
I wouldn't call the shorthand methods for errors and such LogError or LogInfo. I would say just regular "Error" or "Info" would do since your variable is probably mentioning that it's a logger anyway. So just logger.Error("blah"), would be a little more concise i would say
what ide did you use then?
I think all group by linq queries are evaluated locally. Did you find a work around for that or just not need them? I use them a lot for reports by employee so it's been a pain 
Also not the previous commentor. Another part of IT at our company started using Mesos/Marathon. Previously all our web applications were .NET Framework (not sure why; they chose it years before I was hired) running in IIS. I was tired of doing VM setup in Windows Server for each little application we had, and I was tired of running multiple applications on each VM to get around having tons of VMs. I really wanted to start using Docker containers for my little applications. Since I am a web developer used to C# in .NET Framework, there were two systems I saw as easy to run in Docker containers: Node.js and ASP.NET Core. A couple other guys made Node APIs and I made one too, and then I made a .NET Core web API sometime last year a couple naming schemes ago. Node felt clunky to me, and I attribute it to three things: * No type safety. This could be solved by using TypeScript instead of JavaScript, but at that point why not use C#? * Nesting callbacks inside callbacks can get pretty deep, even in a simple API. This is probably something I could get used to with more Node experience. * An interpreted language running your server? Sure it's fast, but it will likely never be as fast as bytecode once .NET Core is more optimized. Since .NET standard became a thing, I really started liking that and .NET Core more anyways. We still have legacy applications running on .NET Framework, and now I can write libraries that can be consumed by legacy and new applications rather than duplicated in a second language. There is still one big advantage I see for using Node over .NET Core. You can actually talk to Oracle databases using Node. [Oracle says](http://www.oracle.com/technetwork/topics/dotnet/tech-info/odpnet-dotnet-core-sod-3628981.pdf) they'll add support once .NET Core 2 becomes a thing, hopefully by the end of 2017. 
That is not a good practice especially if the number of departments can reach a thousand or more records. It's better to use detached entities (via AsNoTracking()), then attach the entity to the DBContext and save on every loop.
You can do this and still run on Linux?
Currently running a small website on asp.net core 1.0. It runs against the full framework though because of lack of library support in core 1.0. Eagerly awaiting release of core 2.0. Plan to move our complete dot net development to that in the future
Using it on IIS, would much rather use it on linux, but wasn't my choice
Using it on IIS, would much rather use it on linux, but wasn't my choice
I thought I had heard that they do now.
Oh no I'm sorry. If you run .net framework it has to be on windows
That may be a 2.0 feature. I haven't looked at that version yet. What I would really like is support for table-valued functions. They are a lot more flexible than stored procedures when you want to add sorting or additional filters.
Currently running .Net Core 1.1 against full framework for Active Directory reasons. Org is a non-profit that historically has used .NET/WebForms. 
Take a look at Rebus. I started out with NServicebus but later switched because it was just getting too big and cumbersome. Haven't regretted it since and the dotnet core version of Rebus is out and stable for awhile now. 
If you want to try Chain on Linux, I'm more than happy to make any changes necessary to support your project. https://github.com/docevaad/Chain In theory we support .NETStandard 1.3, but I want more independent testing.
Not necessarily the whole table. It can still apply your WHERE clauses, though not your HAVING clause since that happens after grouping operations. Still, if you just want the total or average by category, sending 10 million rows over the wire instead of a couple dozen is pretty annoying. What pissed me off the most is that the early documentation said that operations such as grouping would occur in memory, but not which operations. So its a game of guess and check.
We have a .net core microservice running in prod, also in a docker container on Linux in AWS. Most of our older stuff is still in the full framework on windows instances. But man is the deployment for the new microservice fast. 
Dapper works just fine on .net core, fwiw.
Currently in development, but will be in production soon. Running .net core 1.1 web api with postgresql and an angular 4 frontend. This is running in. Docker container on Ubuntu 
We use dotnet core at https://firstagenda.com/en/ Reason is for easier deployment and scale-ability using docker. Most of our project are using 4.61 for migrations, but we are switching for dotnet core Code first approach using EF. (Just a question about taking the time to convert rest of the projects).
Currently, 2 Web API projects, one for image conversion, one as an elasticsearch backed search service. Both 1.1.0 running on Windows Server.
I ported our automatic deployment code to .NET Core. It's a simple pretty application that reads consul for updated build artifacts and downloads and runs them automatically. I just like that I don't need external libraries or IIS for web hosting now (which allows for remotely controlling application deployment in our case).
The normal pattern is to not have "Change" at all, and make your post back go to Index(Model model) while new requests go to Index() Make sure your &lt;input&gt; tags are in a &lt;form actions="route/to/index/action" method="post" /&gt;. Then make Index(Model model) be: [HttpPost, ValidateAntiForgeryToken] public IActionResult Index(Model model) { /\*Code goes here\*/ return View(model); }
Visual studio code with the C# extension
How do you prefer vscode?
I just like the way that it gets out of your way and lets you get on with stuff. Combine it with the dotnetcli and its a great experience. I've had some issues with package management on Visual studio for core based projects. Also my laptop only has a 120GB SSD so only having to install VS code vs Visual studio is great. (And its a lot quicker to install than Visual studio. Although that has gotten better recently).
Seems ambiguous.
Yeah. I've always used in on the client request side. It just looks a bit weird when using it from the server receiving side.
I am developing a recruitment system for over a year now (on and off) using MVC Core. I have a version of it running my company's recruitment.
Hi _chebastian, Perhaps the data virtualization blog might be of use to you: http://www.datavirtualizationblog.com/ Really informative article by Bernard Marr: http://data-informed.com/what-is-data-virtualization-and-why-does-it-matter/ Data virtualization explained using an analogy of a supermarket: http://www.datavirtualizationblog.com/data-virtualization-supermarket-data/ Upcoming webinar on data virtualization, covering all the basics: https://goo.gl/K8tkPh DBTA article on data virtualization: http://www.dbta.com/BigDataQuarterly/Articles/In-Memory-Parallel-Processing--and-Data-Virtualization-Redefine-Analytics-Architectures-118223.aspx I hope these help! Amy 
It sounds like you are on the right track, but don't yet know how to create a view with a form that allows you to actually update your information. First, you need to create a view that both uses your model and has an HTML form with input elements that allows you to modify the data. @model TestModel; @using(Html.BeginForm()){ //The labelFor helper generates a label for a field @Html.LabelFor(model=&gt;model.UserName) //The TextBoxFor helper generates a textbox for the field @Html.TextBoxFor(model=&gt;model.UserName) @Html.LabelFor(model=&gt;model.UserAge) @Html.TextBoxFor(model=&gt;model.UserAge) &lt;input type="submit" value="Save your stuff" /&gt; } Ok, now we have a view that has input elements. Next, we need the controller to be able to pickup on the submitted user data. This is typically done from a form using http POST protocol. Also, MVC is smart! You can simply tell your action method that you are going to be sending form data that corresponds to a `TestModel` type and the model binder will automatically assign values to your properties from the incoming form data. Quick note, `[HttpPost]` instructs the MVC framework that this action method is only to be called if the request is of an HTTP POST type. As a comparison, requesting a page/view is done using `[HttpGet]`. Basically....Http**GET** to retrieve a page and Http **POST** to post an update to the form data. [HttpPost] public ActionResult Index(TestModel model){ var test = model.UserName; //place a breakpoint on this line and inspect model.UserName. You will see it is the same as what you typed in the textbox //This is a dummy call below. Instead of this line, do whatever you want/need to do with your data that the user sent you MyDataService.Save(model); //Also note that the return from an HttpPost should be some type of Redirect result. This keeps you using the proper PRG pattern (Post, Redirect, Get). You should not ever (unless required) return a View from an action method marked with the `[HttpPost]` attribute. return RedirectToAction("Change"); //OK, so the user submitted some info, we did what we needed to do with it, now redirect to wherever you want them to go next. } One last note, this stuff here.... &gt;string name = *NoIdea.GetElementById("HowDoIDoThis");* &gt;int age = *NoIdea.GetElementById("HowDoIDoThis");* will never be seen in actual .NET code as this is JavaScript. If you needed to get the values of the form fields from JavaScript inside the View/HTML page, this would be correct. However, you are wanting to get at these values inside the controller action method, no JavaScript can be used there. 
My 2 cents....one really should not return a `View()` from a POST actionresult as that breaks the whole PRG (Post, Redirect, Get) pattern. 
I'm currently migrating an MVC 5 / Mono app to .NET Core. I've had a few issues and intend to write a blog post about it when done. It's definitely not a trivial task.
At the moment but MS said they intend to have the Express version running on Linux so the requirement will be 1GB.
It means use at your own risk. Personally I've found it very stable but if you hit an issue then you can't complain to Microsoft.
I'm using Dapper with Core and it works fine.
What we did was -- we want to write SQL scripts. No code-based migrations. Up only, and no difference between creating a new deploy or migrating to latest. So we wrote a console utility to execute ordered scripts in a nested set of folders, where one level is folders named for version numbers, and the level in each folder is the script prefixed with a revision. So like 1.0.0.0/01 Create New Database.sql Then you can order these scripts as needed. You can provide a connection string and a top level folder to target (the level above versions being the root for that databases' scripts), build a reliable ordering of these scripts, log the version + revision that was executed in the database itself. So you'll always know where you are and what scripts to execute next. But the big pay off is that our developers just need to know a couple things -- name the folders for versions, name the scripts for revisions, check them in. Our CI process executes the console utility (the CI tool stores the connection string per environment scoped per database). 
Do you mean ASP.NET Core? .NET Core and Full framework are both platforms.
They have that. The .FromSQL(); method should work here.
You can also combine Linq and SQL so you could have the group by or having in the .FromSQL(); method. It's not perfect, but if this is the only reason you don't want EF Core this could be acceptable workaround - until they have support for it with Linq.
If you're going that route you might as well use Dapper or Chain. There's no sense taking the performance hit of EF if you aren't getting the benefits.
That could be true, but if the only thing that are missing is the groupby linq operator then this could be a workaround :)
Cool. Thanks for the info. 
yes
i don't think i've checked that one out yet. will have to give it a look today if i get a chance. thanks!
You may understand how the web works or maybe you don't but having a site in .net doesn't all the sudden make it not a client/server based technology. The server can never directly grab from the client. The server delivers an HTML string (more or less) to the client on request.. until a new request is made the server is doing nothing. A request can also contain data from the client which is captured as parameters in your controller methods 
Could you explain ? This seems fairly normal .
Fair points! Do you miss ReSharper or are there vs code plugins doing similar?
Have they gotten around to actually documenting what LINQ operations are performed in memory as opposed to using SQL? When I last checked, groupby was just an example and the documentation implied that there were others without actually saying what they were.
For anyone coming from rxjs and familiar with _.share()_, The net equivalent is the mentioned _.Publish().RefCount()_ 
hey , thanks for the advice but im a still a little stuck up in trying to replicate what you advised .... when i change the view to include your html form i get the error 'IHtmlHelper&lt;TestModel&gt;' does not contain a definition for 'TextboxFor' and no extension method 'TextboxFor' accepting a first argument of type 'IHtmlHelper&lt;TestModel&gt;' could be found (are you missing a using directive or an assembly reference?) @Html.TextboxFor(model=&gt;model.UserName) 'IHtmlHelper&lt;TestModel&gt;' does not contain a definition for 'TextboxFor' and no extension method 'TextboxFor' accepting a first argument of type 'IHtmlHelper&lt;TestModel&gt;' could be found (are you missing a using directive or an assembly reference?) @Html.TextboxFor(model=&gt;model.UserAge) and within the controller it states that MyDataService does not exist in the current context . Then also should the [HttpPost] Index have an IActionResult rather than ActionResult and Should TestData be TestModel ( the model ) or is it its own thing . Thanks in advance ! 
Looks like you submitted the URL incorrectly. I have removed your submission, please resubmit with the correct URL.
Don't use ReSharper. So I'm not too sure about similar plugins for VS code.
Might it just be love the current paradigm combined with nostalgia though? I mean, I LOVED Delphi, it was awesome, and I wrote many things for many years in Delphi. In time I became a .net d00d, and grew to like many things about it (not least of which was the similarities to Delphi) and then years and years later ended up at some gig where they had a bunch of Delphi stuff mixed in, and I cracked open the Delphi code, and was like wut teh fuk?! And I closed it and stopped randomly mentioning I'd worked in Delphi lest they throw me in that direction (the Delphi stuff was years abandoned, so it wasn't likely). Also, the things people want are so different now. It's not like Delphi had a great answer on how to make reusable css and html components. It was hitting a very specific sweet spot when thick-clients were the rage and there was years of experience on how to do it. I mean, I really loved the time I spent doing Delphi and writing sprocs against the db. And I still like sprocs, but, mostly, nobody wants to pay anybody to solve the kinds of problems that me and everybody else I knew were all solving 16 years ago. I remember fondly managing my own pointers and refcounted interfaces and memory allocations. Now I wish we could do away with all state and be purely functional. Bah! who am i kidding... we'll just wait for webassembly and compile vbrun300.dll for the web and watch the second goldrush begin! Make Computing Great Again! w00t w00t! 
Inside of an action method that is listening for an HTTP post as the one from the answer above, once the data is POSTed, you should do a `return RedirectToAction("Action");` and not `return View("SomeView");`. Doing this implements the **R** in the *PRG* pattern. This alleviates things like the browser asking you to resubmit form data if you hit the back button for instance. [Here](http://sampathloku.blogspot.com/2013/05/how-to-use-prg-pattern-with-aspnet-mvc-4.html) is a neat article with example code illustrating the concept with code :)
You're correct, my example is flawed in a few ways. 1) Case-sensitivity! The proper call for the text box is `@Html.TextBoxFor(model=&gt;model.Property);` - note the capital B. 2) IActionResult vs ActionResult. An action result implements the IActionResult interface. You can return either as any returnable action result (View, RedirectToAction, File, Json, etc) all implement the IActionResult interface. 3) If your model class is named TestData, then yes, that is what you will need to use. I think I copied it wrong in my example code. All of these issues have been updated in my example - thanks for taking a look!
Oh, one more item I forgot to address in your response. `MyDataService` is just a place holder. I have no idea what you are wanting to do with the data when it comes back from the server. `MyDataService` in my example would be a function call to something/somewhere that, for example, saves the data to a database or something. That specific call will not exist in your solution.
Thank you so much! This has greatly helped!!! One last thing ... How do i share the var test data with Change()? I would assume [HttpGet] would allow it to read the variables from [HttpPost] However when i try to use it an error apears saying it doesnt exist in this context .... :/ 
I welcome the return of our exiled Silverlight overlord 
/u/nimbomob, to add to what /u/bigrubberduck said: It also breaks a lot of assumptions that MVC makes about models and error states, in a subtle way that users may not even notice until a customer runs into a problem. For example, if you submit a model via post, and then return a new View with a new model without the redirect, any properties that share the same name on the posted model and the new model will actually take the value of the posted model, ignoring the new model's properties. MVC assumes you are using Redirects, and code gets funky if you don't. 
OP do you have any other web framework experience?
Thanks guys. It makes sense 
No , not really 
I'd investigate how you looped your database calls. When you access from the database you are now taking network penalties and bandwidth where a local xml file would shine. Your goal should be to get the most data in the least amount of calls possible. Use the include operater on your entity calls to cut it down. Also, check the queries being generated and drop them into ssms. See if it suggests an index or two.
I would try and get some hard stats on what exactly is causing the issue. Have you played with any of the VS or SQL Server performance tools? If you use SQL Profiler and see a query taking ages then you can start to debug it or break it down to find the culprit. Sending much love and hope your way though - this project sounds less than ideal! 
Love is always appreciated! I'm digging into the context entries and trying to optimize them.
Thank you sir, can you give me some insight into the include operator for the entity calls?
If it's using EF, that's a good shout. Might be worth checking that it is actually lazy loading (if relations are specified), and if it's selecting but not updating in places then turn off entity tracking. DB is naturally slower, but creating SQL Views or Stored Procedures can help a lot of its repetitive work as the results can be cached. Otherwise indexes are a good starting point, though I'll admit I'm not much of a SQL expert. Also, was not expecting Gold, so thank you! :) I happen to have been working on a painful project today too, though it is at least MVC with some nice design patterns.
You may want to start a DB Trace and capture the SQL with some metrics. My guess is that there are child controls that load data so when you are viewing the page the child controls are responsible for loading their own data with their own SQL. EF is not a wrong choice here. And, if this is your problem then adding a layer with caching in between the controls and the display can alleviate that.
https://msdn.microsoft.com/en-us/library/jj574232(v=vs.113).aspx And thanks for the gold.
First things first, run a trace on the DB and see what queries are called and how often. And what the execution time is for the longer ones. That'll probably give you a clue. Second, google "execution path" and see how to run one with the problematic queries. You might be missing some indexes that would help optimize your queries. I have a sneaking suspicion that you're running a query with a lot of joins that are doing full table scans. Edit: After reading this &gt;The page is an abundance of nested gridviews and form controls. I'm wondering if are pulling the data for all the nested elements prematurely (eager loading). If that's the case are you able to load the nested gridviews dynamically only when it's to be displayed? 
You could try http://miniprofiler.com Some googling tells me it's possible to use it with webforms, but I couldn't find much about it on their site itself.
Have you made sure your indexes in your database are sane? Maybe do some profiling in SQL. If you aren't joking about it taking minutes to load a page, you have a serious problem. If your problem isn't in SQL, I would consider simplifying your solution. Replace entity framework with stored procs and good old ADO .net. Replace your gridviews with repeaters. If that's too much work (it's not if you'll have to maintain this application), spend some time looking at how many calls to the database you're making per page load. LINQ is a fantastic tool for cranking out functionality, but unfortunately it makes it very easy to write poor performance code. Edit: Basically, what goblando said.
I'd bet money you just need a few indexes. Here is a free SQL Profiler tool in case you don't have profiler with your version of SQL Server: https://github.com/OleksiiKovalov/expressprofiler 
You can add some caching on website startup to pre-cache in memory values that are loading too slow. That may not be the main real problem or best solution, but its possible you could use caching to work around whatever the real causes of the performances issues you are having.
I've been going through a similar thing. Researching services and repository pattern has been helpful. But most of all, looking through the NopCommerce source has helped tremendously.
How is the cold start time?
If your only reading try using AsNoTracking() in your context, or use dapper.
Have a look at React Mobx typescript. I feel it is a cleaner combo. https://github.com/mobxjs/mobx 
React is simple, Redux can take a while to be understood and mastered. You can do server side rendering with React/Redux so a most common architecture is indeed to have a webapi. the MVC pattern can be used as the V doesn't have to be html.
Not open source. You can't have non-OSS CMS without serious company, support, docs, sales, ... Release it as OSS to get people and projects, then offer some additional value that people will pay for (themes, plugins, custom development, support)
&gt; makes brand new spam account to post link &gt; fail to understand how reddit works &gt; shitpost spam to wildly wrong sub based on the name Good work with hiring this PR shill, they are clearly worth the money /s
We have a .NET Core-based product for embedding pivot tables reporting (PivotData microservice) that used in production environment (netcore1.0.4 LTS runtime). No problems with connectors to SQL Server, PostgreSql, MySql and MongoDb; we're waiting for netstandard2.0 to get ODBC support. Also we run end-user web version of the same service (https://www.seektable.com/) that uses netcore1.1 and hosted on Ubuntu 16.04 with nginx reverse proxy. In comparing to WinServer2016/IIS the same application works faster and in overall server needs less RAM.
Probably, but a test like this might be ensuring that its just a pass through 
Why not just reference the ITulipRepository directly and remove the passthrough class?
I'm not sure I would write this test, but if I did it would be to verify that it passes the unmodified value it receives and returns the unmodified value from ITulipRepository Edit: Not sure why the down vote
To connect to your database you would probably have a sessions table that stored some identifier that was present in your token. This sessions table would have a foreign key to your users table, so by looking up the id, you can also know which user the request is associated with. Here's how I like to handle auth from a comment a couple months ago. https://www.reddit.com/r/dotnet/comments/6dtasy/how_to_implement_rest_authentication_with_aspnet/di5m34v/
Diagnose the problem with the tools suggested here before you try to optimise anything. You may be optimising the wrong thing.
Yep, go with a web api style application, it works a charm. Just remember that generally speaking a redux app would be a SPA, rather than having different controller views for each different page. ...but ultimately given any specific 'state', the redux/react front end should be able to render the correct UI for it; so if you do want to have different URLs which are like 'deep links' to specific content in the SPA, you can just have those urls spit out a specific initial state for the UI to render. 
React is very small framework I prefer to use AngularJs for SPA it gives many leverage features like route, http serive , own promise $q ,two binding and ui validation etcs . http://rajeevdotnet.blogspot.com/2015/12/angularjs-scopebroadcast-on-and-emit.html?m=1
C# Interview Questions.... http://net-informations.com/faq/default.htm 
Are you spying on me? This is literally what I need right now.
Great article. Thanks for sharing.
being able to do something like dotnet run *.cs file would be so amazing. The only part that might be difficult is nuget dependencies. I guess you would need a way to hint the runtime that a specific nuget package is needed inside the actual cs file, which would be funky
They do get cached by the web browser for me, you can try adding asp-append-version="true" for all your static files inside your view. 
As a java/C# dev in a mixed shop, kotlin has recently made java development so much better. and enjoyable We're only using it in greenfield projects but sometimes putting lipstick on a pig does make it look beautiful. I still miss Linq and some other features from C#, but I really don't mind and actually enjoy working with kotlin code.
Make life easy and do 2 completely separate projects. 1 for your web api and the other for your react/redux app (or angular/whatever). IMO, this is a good implementation because if you wanted to add a mobile, desktop, homekit, alexa, tv, whatever app in the future, your api is already fully built out. And when you need to make changes, you change the api code once. I'd recommend implementing something like identity server if you go down this route too.
What do you mean by deep links? My main concern is SEO, so if I'm going to do react I was thinking of kinda following what I did before with angular 1.x where I have different controllers on some pages but doesn't not work like a spa but I have a few pages that would have their own spa style of showing data utilizing $http to get data. Not the most ideal way but it worked for what I needed. That's why I started looking into react cuz it seems easy enough to have multiple spa pages. I hope that made sense
We are using it, we've built an API and also an admin for said API. It's been live for about 3 months now, no issues at all. We are running it on IIS(I wanted to use unix but our clients hosting provider didn't support that at all...). We use Entity Framework Core and Dapper(EF Core doesn't support Geometry and stuff like that...). Feel free to ask any questions :)
We run .Net Core in prod on Linux. It is a custom API Gateway with connection reversing via web sockets(using nightly builds of SignalR Core) :D
Removed since this is not .NET related
You may also want to look at those tools, if you don't want to have to write your command line tools yourself: https://dbup.github.io https://github.com/chucknorris/roundhouse/wiki/GettingStarted
You should be able to do most of this using `&lt;ContentControl&gt;` and `&lt;ControlTemplate.Triggers&gt;`... --- &lt;ContentControl&gt; &lt;!-- This ContentControl will be the placeholder for the textblock... --&gt; &lt;ContentControl.Template&gt; &lt;ControlTemplate TargetType="{x:Type ContentControl}"&gt; &lt;Grid&gt; &lt;!-- Need to use a Grid to allow putting overlapping controls --&gt; &lt;TextBlock x:Name="BlockA" Visibility="Collapsed"&gt; Lorem ipsum dolor sit amet, consectetur adipiscing elit, sed do eiusmod tempor incididunt ut labore et dolore magna aliqua. &lt;/TextBlock&gt; &lt;TextBlock x:Name="BlockB" Visibility="Visible"&gt; Ut enim ad minim veniam, quis nostrud exercitation ullamco laboris nisi ut aliquip ex ea commodo consequat. &lt;/TextBlock&gt; &lt;/Grid&gt; &lt;ControlTemplate.Triggers&gt; &lt;MultiDataTrigger&gt; &lt;MultiDataTrigger.Conditions&gt; &lt;Condition Binding="{Binding BindingA, Converter={StaticResource greaterThanZeroConverter}}" Value="True" /&gt; &lt;Condition Binding="{Binding BindingB}" Value="0" /&gt; &lt;/MultiDataTrigger.Conditions&gt; &lt;Setter TargetName="BlockA" Property="Visibility" Value="Visible" /&gt; &lt;Setter TargetName="BlockB" Property="Visibility" Value="Collapsed" /&gt; &lt;/MultiDataTrigger&gt; &lt;/ControlTemplate.Triggers&gt; &lt;/ControlTemplate&gt; &lt;/ContentControl.Template&gt; &lt;/ContentControl&gt; --- &amp;nbsp; You will still need a converter for the "if the value of A is greater than 0" part... but that is pretty minimal. This should more-or-less get you on the right track. 
I think the way you describe it makes sense, but I would not call it Session-Table, because JWT does not know about sessions. More likely you would have a CLAIM in your JWT Token which identifies your user. Then have a User Table right?
I'm not super up to date, but for example it was still very relevant in Microsoft Dynamics CRM in 2015. And for compatibility reasons it will probably remain relevant for a while. Now if anyone should care about it is another matter. 
Forget converters and XAML. As long as you're using MVVM all you need to do is add a third property to your viewmodel which computes the value you want to display depending on the value of the other two properties and bind that to your textblock . It's a much more elegant and simpler solution. Edit: I forgot to mention you will also need to fire PropertyChanged events for your new property when the values of your other properties change in case that wasn't obvious.
[removed]
I wonder if there are those who are building new OData services and not just maintaining the ones they have now
Cool. Thanks for the tip. I ended up figuring it out. Unfortunately the assumption of only including jqx-all.js as the only file I would need is wrong. It was missing some of the scripts. That's poor documentation, unfortunately.
I just created a new template for LLBLGen Pro, I wrote it against version 5.2, that will create TypeScript definitions from your Entity definitions. I open sourced it with MIT license: https://github.com/temporafugiunt/LLBLGenProTypeScriptTemplate
Im just watching a webina from Epicor (ERP) and they are boasting about their 'new' odata services!
I have to use it to interact with CRM. It's a bloody awful interface though, I have no idea what they were thinking. Trying to serialize complex objects into query strings using their convoluted syntax is just insane. It seems the rest of the world reached the same conclusions, because I don't know of *anything* that uses it outside of CRM anymore. OData is a non-starter outside of Microsoft. 
I don't think much about Netflix, they've suddenly closed off their APIs before. The fact that I hear about GraphQL weekly and never hear about OData leads me to believe that the market has spoken.
I was only trying to stick to XAML because I was told it is faster and less resource intensive. If this is the best option though it works fine and i'll do it this way. Thank!
When did chocolatey become a thing? I remember watching some John Papa video ages ago where he used it to install something and I was like "what? I don't need this". Keeps coming up more in recent times, even in official Microsoft articles. 
If there is a model state error from like an incorrect form value, it is fine to return the same view from the post indicating there was an error. However, on successful posts, I agree, you should redirect.
We run .NET Core in production at SeatGeek to power our primary market APIs. We run on linux in AWS. As others have said, the build pipeline setup was pretty straightforward. We meandered a bit on database migrations, ultimately settling on entity framework (though for migrating production environments we simply use it to generate an SQL file). No issues so far with performance, and no complaints regarding stability. Looking forward to upgrading to 2.0 when it becomes available.
&gt; I was only trying to stick to XAML because I was told it is faster and less resource intensive. Whoever told you that is wrong. ~~XAML is eventually compiled down to .NET IL the same as your C# would be.~~ There's no advantage to using only XAML to build an app (and it'd be very difficult to do so unless your app is very dumb). The whole point of WPF etc. is that your UI can be laid out declaratively without having to mix it with your business logic or sacrificing readability (which also allows you to test it independently of the UI). Edit: Actually, XAML isn't even compiled to IL. It's compiled to a binary representation (called BAML) which is embedded in your .exe or .dll and is loaded at runtime so there is actually a very tiny performance hit for using XAML, but it should be negligible and the trade-off is that you develop apps faster as well as the other benefits I mentioned before.
If you are trying to be MVVM then the values should be in your view model and the calculation logic should be an ICommand implementation (or wrapper). That said, for something this simple I think I would just put the calculation logic right into the view model. 
Salesforce connect uses it I believe as well SAP. Still alive and kicking. 
It's clear that not many people here work for large enterprises who use SAP. We have developers in our office now learning how to expose SAP data to our applications via oData services. It's something that SAP fully supports and encourages to it's customers, so it's definitely not dead. Though, it may not be widely used in the category you're developing for.
It's been a long time since I looked at JWT, and never was much a fan of it's use for application authentication/authorization and I hate the over-complicated convoluted solutions out there. Claims in JWT don't really work for the type of applications I need to build. I don't do social logins, I need to be able to have the server revoke a token or login at any time. I need to be able to logout users and make role changes across many devices effective immediately. Most auth I build is just fine with just an identifier some some sort, whatever you call it, that indicates which particular user login or token a request is associated with and go from there. 
We are running a microservices platform in AWS with about 40 .NET Core services all in Docker containers on Linux. We are using a wide variety of the AWS services such as DynamoDB, S3, SNS and SQS for Pub/Sub, Kinesis, and of course ECS. We chose .NET Core because our existing on prem stack was all on .NET 4.x so we had a large developer base who knew the platform. Another group within the company already built an entire platform in AWS, so we were able to leverage their devops platform to get a jump start on everything. Having the domain knowledge of the previous .NET platform as well as this devops infrastructure allowed us to rapidly develop our new system while leveraging features in AWS. We've been in production for a few months now and are quite happy with the performance and stability. 
Thanks! Happy you liked it, it was fun putting this panel together. Those are interesting times for .NET, so many things happening.
Using a behemoth like SAP to show that something is alive is a little odd. assuming it really is dead it will still be in SAP for a long time I would bet. 
For database migration you can use [Evolve](https://github.com/lecaillon/Evolve). It's a .NET / .NET Core tool (*Of which I am the author*) inspired by the popular java Flyway. It uses straight SQL scripts to keep your database synchronised through all your environments and developpement teams. Hope it could help you !
Then I guess it depends on your definition of dead and alive. I consider something to be alive if people are developing new tools that use it. That's currently the case for SAP oData services since they've only been a thing for about 5 years, which is brief for the kind of companies that use SAP.
I use [Evolve](https://github.com/lecaillon/Evolve). It's a database migration tool for .NET and .NET Core, inspired by Flyway. I am perhaps not the most objective user because I'm the author too ;-) Give it a try !
For database migration you could use [Evolve](https://github.com/lecaillon/Evolve) (*of which I'm the author*). It's .NET / .NET Core tool, inspired by Flyway. Give it a try !
This is good to know. Thank you very much for the information. I'll keep this in mind going forward
Will definitely read up on those posts! Thanks a lot! 
Because the GraphQL is Facebook hyped. Even they'd discover CSV files (that are close to the schema-less JSON) everyone would write about that. Nothing can beat SOAP services with WSDL, you can generate strongly-typed client code in one second and use the service. But we are going backwards in technology lately, from XML to JSON, then I believe from JSON to CSV and maybe to binary files later. Sad. JSON camp is trying to reinvent XML/XSD. They have finally understood their primitive technology lacks schema and simple types, then they realized it lacks namespaces and also query language ... everything that's already done with XML for ages. With all the JSON based stuff, welcome to the stone age ("What's the correct format for datetime ?" "Try ...." Eeek.)
&gt; OData is a non-starter outside of Microsoft. Because it is too good, as usually. Type-less stringyfied interfaces with trial-and-error approach are hyped now :-/ OData had full strongly-typed LINQ support.
I used it on a project for a large educational institution relatively recently. Before that I didn't know it existed.
It really isn't. Try using CRM and figuring out how to serialize a complex object onto the query string for a GET "Function". It's a mess. Something like that would have made 10x more sense as a POST with a JSON object as the payload. It's a horrible mess of an API designed to solve problems that nobody has. 
JSON is a mess, it is like CSV. No data types, no (standardized) schema yet. That's why you have OData libraries that supports fully strongly-typed LINQ queries. Building a query string manually is primitive PHP-like technique. This is perfect example what the LINQ has been made for, to use expressions for building queries. Not messing string with a StringBuilder by trial-and-error approach. We had this 20 years ago. You might want to check the documentation http://odata.github.io/odata.net/#04-01-basic-crud-operations As you can see, there is no terrible string low-level query here, everything is natural C# code used to build the query.
We use it for our codebase... It's working with up to date entity framework and other ORMs. Calling it dead seems pretty premature. 
I think the problem is that much of the XML/XSD spec, and also SOAP and WSDL, was that in addition to addressing a lot of core data-sharing issues, they also solved problems that nobody had. The "XML ALL THE THINGS!" era created a network of overly complicated specifications that handled weird edge cases for things like service federation and data transformation, etc. But yes- XML was actually *far* better than JSON, despite the larger payload size. It just got too complicated too quickly.
OData is still used to query tables in Azure Storage
Agreed. I find it strange you can't run Sql Server on Nano, but you can run Sql Server on Linux (2017 anyway). I think perhaps that's solved by containers? I'm not up to speed on containers yet so not sure. Out of curiosity, does Microsoft have any server stuff for hobbyist / one-man-band sorta thing? I have a little mini-pc I want to set up a home-hosted website with DotNet Core and Sql Server Express. Is there any way I can do that free on Windows? Unfortunately the mini-pc only supports Windows (won't boot with Linux), otherwise it'd be perfect with Linux/DotNet Core/Sql Server 2017. This is the [mini-pc here](https://www.aliexpress.com/item/New-VOYO-VMac-Mini-PC-Intel-Apollo-N3450-License-Windows-10-Pocket-PC-4GB-DDR3L/32788223771.html) Would love to get it running DotNet Core and Sql Server somehow
What would software development be without a new way of doing the same thing every year?
Cobol says hi. Lmao. I'm s shocked that new tools come out for that occasionally.
Did you originally try and run the netcore1.1 app on Windows with IIS?
If youre running a site internal to your lan, then kestrel would work fine on Windows. It is not ok for the internet (you need it behind a reverse proxy). As for sql, id use mysql or sqlite3 
Having worked with both there's a time and a place for each. If I had to deal with soap for every single web service I wanted to create I'd going insane. It's overkill for super simple services and somethjng like WebAPI to generate simple JSON ovjecfs. Just like everything else in development use the right tool for the job. 
I use it daily at work, as a sysadmin. I'm not quite sure what ProGet provides, but chocolatey is definitely a part of my toolchain. Both as an automation tool, but also a manual one.
Yes
I once used it to install Putty tools, because I wanted to try out Chocolatey. Then I noticed it has an ancient old version of Putty, and wanted to use Chocolatey to uninstall it. It failed. Be aware that the packages may not be very well maintained and can have very old versions.
&gt; It's overkill for super simple services Why ? It takes one second to generate client code. Still better than the trial-and-error approach you spent hours with using underdeveloped techniques like JSON or other plain text based metadata-less protocol. Note that I don't do any web apps (as a client), just console apps or windows services. That's why always want strongly typed C# code.
Actually it is not important because you have client libraries to communicate with Azure storage. The protocol is just internal implementation detail.
And worse way ...
I still don't get why the payload (stream bytes length) is so imporant these days while we have typically megabytes of scripts here and there. Using proper tools you don't have to care about the internal XML format at all. It is still a set of objects, LINQ queries etc. I know that there are clueless developers who still build XML as string and parses it the same way by regex per text lines but this is something I don't care about. There are tools to do it right so the payload is not important at all. .NET XmlRead/XmlWriter performace is also excellent when processing large data. Because there is not standardized JSON schema yet I consider it as completely improper technique for cross-platform data exchange. It makes the strongly-typed client code complicated and waste too many time.
The client libraries just have an OData query builder and return the raw OData query string, it's ultimately OData in the end. But yes, they kind of abstract it away 
No, it returns entities https://docs.microsoft.com/en-us/azure/storage/storage-dotnet-how-to-use-tables
Ah, yes, sorry I meant the filter condition in OData. TableQuery.Where(string) takes the raw filter string. 
Which is not what (I) would use. It takes LINQ expression. I guess a string type should be banned in general :-)
http://bitoftech.net/2014/06/01/token-based-authentication-asp-net-web-api-2-owin-asp-net-identity/ This guy has many blog posts about what you are trying to do, it might not be exactly what you're looking for but nonetheless its a great resource. Go through the blog it will surely help clear things up
Alright, so first off. If my solution roughly looks like this: Solution Project ... Models Exam.cs Problem.cs SubProblem.cs Views Exam Index.cshtml Problem.cshtml Shared Controllers ExamController.cs Data ExamsContext.cs DbInitializer.cs Migrations ... Where would this class ExamRepository reasonably fit in? And if I would implement an interface for it (in order to be able to mock it easierly) where should that be placed? There's also a line in one of the methods for the ExamRepository that has the instruction `var exam = await _context.Exams.SingleOrDefaultAsync(m =&gt; m.ExamDate == examDate2);` Now, I know that the controller has access to _context through dependency injection, (and we're switching _context for _examrepo now). But how will ExamRepository get access to _context?
COBOL is still used a lot. MS Web Forms are still used a lot (not to mention their desktop counterpart Win Forms). They're used a lot because enterprise invested a lot writing their systems using these technologies and ditching something that does a useful job just because it's old isn't a sound business decision. Software - at least software that has had significant investment and buy-in - never really dies. OData is like this. If you want to invest time learning it then there will still be things out there that use it for some time to come but if it's not already part of your tech stack and you're starting a greenfield project I'd suggest using something else.
"Nothing can beat SOAP services with WSDL" Jesus, I can't believe that's in the comments!
Like many technologies over a week old, it's not dead, it's just no longer sexy. 
I do wish more library authors took note of this. LibLog is especially amazing and worth using in any library.
I don't know if this is something you have control over but ideally the client sites would just host their data centrally in Azure. Then you can query it from there whenever you want and they can access it centrally. Especially as the solution would require them to connect to Azure anyhow. Otherwise a VPN would work as suggested below. If a VPN isn't an option, you would have to create some kind of polling system where the clients occasionally check in to see if Azure is asking them for some data and then send it across. I'm not sure if there is a product out there for this that would make it simpler or you just have to roll your own.
With a VPN the client sites would be connecting to Azure. They wouldn't require a web service or a static IP. Once they're connected their machine would appear to be on the Azure network and Azure could have direct access. I've done this before in Azure, and it's not trivial to set up, but it does work.
&gt;Excessively generating errors is a sure-fire way to mask the important ones. Try not to generate a lot of first-chance exception that you are just going to catch. Sharepoint used to (and may still) throw a lot of first-chance exceptions which can make debugging more difficult. The one that happened on almost every request was because it tried to create a url with a null/empty. I've notice that MVC also seems to throw a bunch of first chance exceptions on every request..
 Or just significantly different without being better
Yes, there is nothing else with standardized contract metadata yet.
Where is the point then ? 
&gt; Note that I don't do any web apps (as a client), just console apps or windows services. That's why always want strongly typed C# code. When you are just calling a service on your website from javascript on your website, plain text based metadata-less protocol is good enough, but for server to server, I find it very painful. 
I don't really know 
I'd never use any non-strongly typed language. I've had hard times with GW Basic, no need to return into the stone age :-) C#, C++ or Java is way to go (only). And this is .NET forum, not a JavaScript one.
I first thought, No!!! Another Common.Logging, that sucks. But no, LibLog is quite nice. Might be updating a couple of my libraries...
I felt the same way when I first discovered Serilog. Suffice it to say, I've never looked back.
OData does this : https://docs.microsoft.com/en-us/aspnet/web-api/overview/odata-support-in-aspnet-web-api/odata-v4/create-an-odata-v4-endpoint
Absolutely. For my company, I started with an IRepository framework. All of our Data Access depends on a IRepository interface for simple IQueryable CRUD. I then created many concretions of the IRepository interface, including: EF, MongoDB.Core, Mocoding Embedded DocDB, Azure DocumentDB, and even Quickbooks Desktop. Then I created a interface to start building Generic Api Controllers, which depend on my IRepository interface. I called this interface IDomainModelApiController, and it implements Get, Post, and Delete methods. It actually implements a few Get methods... GetByID, Get All w/ Pagination, and Get w/ where clause (I use DynamicLinq nuget to take a lambda string and cast it to a linq expression, this allows boolean queries with linq, which works with all concretions of my repo. For EF, DocumentDB, and MongoDB, the where clause eventually gets converted to SQL) I then created a GenericApiController using this interface. It needs a IRepository to operate. I can easily switch the repository out for a different concrete at anytime. For instance, we found out Azure DocumentDB was too expensive for our needs, so I easily swapped out my DocumentDB repos for MongoDB repos in my DI container, and switched to MongoDB without having to change any surrounding code. I've been very happy with the implementation. My API controllers are super fast to get up and running. All I need to do is define my models, then derive a new generic api controller and tell it which type of repo to use. I don't even have to worry about Data Access anymore, just creating the models really. I also made all of my Generic Api Controller methods virtual, so I can override them. This gives me a lot of flexibility for more advanced operations. Usually I can just use the base class' default implementation, but it's useful to extend the default implementation sometimes. For instance, we have a api controller which takes in a object that contains an Image. This image needs to be saved to disk on the server to be retrieved for website branding. We needed to write logic to deserialize the base64 string back into an image, resize it, and save to disk. We also needed to delete the image from disk if the record is later deleted. To accomplish this, I just needed to Override the Post() method, and do the Image deserialization/writing to disk before calling the base.Post(). For deletion, I override the Delete() method and first delete the image file from disk before calling base.Delete(). When we decided to use DTOs, it grew a little more complex. I created another version of my Generic Api Controllers which was aware of the DTO's and the Persistance objects, and would convert them back and forth at will. This could have been done with AutoMapper, but I loathe AutoMapper, so I accomplished this with my own IAdapter pattern instead. We eventually implemented IdentityServer3 for Auth-as-a-service. Then I started implementing ResourceAuthorization against the Caller's Claim token. I was able to create a third version of my Generic Api Controller which knows about ResourceAuthorize attributes and secures our endpoints against the caller's claims based on the Authorization Attributes we decorate our methods with. TLDR: Yes it's possible, and a very viable technique. 
how do you handle DI for the repository class? I just can't figure out a way to do this dynamically. edit: also, what about dynamic routing?
As for the folders, that's kind of up to you. What I usually do is just create a new folder called Repositories, and if I'm implementing interfaces I create another folder inside of Repositories named Interfaces. But again, I don't think there is a de facto standard, I'd have to research that honestly. In regards to the DI this is where things can get really confusing. Once you have created your interface and the repository, you would now go into your Startup.cs file and add a line in the ConfigureServices method so it would look like the following: public void ConfigureServices(IServiceCollection services) { //.... (code) services.AddScoped&lt;IExamRepository, FileExamRepository&gt;(); //.... (code) } Now that we have configured this scoped type, we can inject this into our ExamController by changing the constructor to the following: private readonly _examRepo; public ExamController(IExamRepository examRepo) { _examRepo = examRepo; } (N.B. I'm using scoped as an example here, because it makes the most sense in my opinion, [but you should read more on these scopes](https://stackoverflow.com/questions/38138100/what-is-the-difference-between-services-addtransient-service-addscope-and-servi)). So your final question probably is how does the Exam Repository get friendly with the actual context (and it sounds like that's actually the question you asked above, this review was partially a refresher for me to remember your setup), which is a part I just realized I neglected to mention above, and I'm terribly sorry for that! I assume you are using EF Core based upon your project structure so far, so the actual line in the startup class where you add EntityFramework and AddDbContext is dependency injection itself. You would then, in turn, in your Repository class have the following code: public class ExamRepository : IExamRepository { private readonly _context; public ExamRepository(ExamsContext context) { _context = context } } And presto, you now have class wide accessibility to the database, your controllers no longer directly query your database context, and lastly, you have a very large separation of concerns. If you want to read a bit more into Dependency Injection, specifically for .NET Core applications since it's baked in automatically, you should definitely read [this](https://msdn.microsoft.com/en-us/magazine/mt703433.aspx) article, which also goes over how to write Unit Tests for all of this!
I can do it one of two ways. I have a non-DI version of my Generic Api Controller which accepts the type of the Repo as a Type Parameter when you define the class. Registration for this approach is as easy as changing the type parameter, but it doesn't rely on any DI. The second way is using any DI container I want, and configuring my Startup config to work with my DI container. Web API has an internal DI container you can use (I think Unity?), but I chose to use Autofac. To do that, when you setup your HttpConfiguration in your Startup method, you can set httpConfiguration.DependencyResolver = new AutofacWebApiDependencyResolver(AppContainer). I believe I had to get a Autofac Web API nuget package to get that class. Then I simply register my repos in the container, and via constructor injection, Autofac will inject my concrete repos. If you don't mind using Unity, you can just use the default Dependency Resolver built in. Also, protip: Web Api doesn't allow Route Inheritance by default. You have to configure that. I leverage this by making all of my Routes in my base classes, but in order for that to work you have to configure a "CustomDirectRouteProvider". More information here: https://stackoverflow.com/questions/19989023/net-webapi-attribute-routing-and-inheritance 
Microsoft could have used the LinkedIn app as the first class UWP success story to show its capabilities but instead of it a new desktop-**only** app (Win32, WPF ?) is announced. It does not support the UWP to be the right technology (again) unfortunately. It just increases the feel of distrust.
Can only agree. You don't see any investment in UWP from Microsoft, meaning they will most likely let it wither and die like Silverligt.
The question is what Microsoft technology to use for applications ? WinForms is dead for a long time, WPF is in hibernation state and the UWP looks being abandoned now (again) as well by this Microsoft decision. We still have good old MFC after all :-)
Honestly a hard question in the .NET world. If I was to choose something, the choice would either be WinForms because the eco system is still supported and extended, by pretty much all component manufacuters. Or an website embedded in chromium, made using .NET core.
So because LinkedIn included the word "Desktop" in an e-mail, it means Microsoft has abandoned UWP? Your logic is horrendous.
It seemed like people only started to realize that Silverlight had some potential after MS seemed to have abandoned it.
You can probably get quite far with [asp.net web-api](https://www.asp.net/web-api). If you're using Visual Studio, it can scaffold your controllers and views for CRUD operations ([guide](https://www.red-gate.com/simple-talk/dotnet/asp-net/using-scaffolding-to-create-mvc-applications-with-visual-studio/)).
Windows Desktop**-only**
Any UWP app can be made desktop-only. Declaring your supported UWP device families is a basic part of the system. Mobile is just one potential target. Regardless, lets say the people at LinkedIn decided to use a legacy technology. Microsoft still releases massive updates to the platform with every W10 Feature Update. They also have a large library of in-house apps that use it. Here's a list: Core parts of Windows 10: * Start Menu * Action Center * Settings * Cortana * Edge * Store In-box apps: * Skype * Mail * Calendar * People * Photos * Camera * Maps * Alarms &amp; Clock * Calculator * Feedback Hub * Groove Music * Messaging * Mixed Reality Portal * Movies &amp; TV * News * OneDrive * OneNote * Paint 3D * Sway * Sticky Notes * Tips * Get Help * 3D Viewer * Voice Recorder * Weather * Windows Defender Security Center * 3D Builder * Xbox Additional Store Apps (more in the Store): * Microsoft To-Do * Translator * Office Lens * Remote Desktop * MSN Money * MSN Sports * Xbox Avatars * Bing Dictionary * NFL on Windows * Microsoft Math * Power BI * DVD Player * Surface * Channel 9 * Forza Hub * Dev Center * Microsoft Build * Xbox Dev Mode Companion * HoloLens * Holograms --- But yeah, I guess they're abandoning UWP... what a joke.
WinForms is not dead at all. It'll be with us for a long time. There isn't really an alternative for Windows desktop applications that is simple and easy to learn.
UWP only supports Windows 10, and about 55-60% of Windows users are still running Win 7. It's even higher for business systems - LinkedIn's target market. Since Microsoft owns LinkedIn, I assume this is a marketing decision, not a tech decision.
You think they're making a desktop App that works on win7?
&gt; I cracked open the Delphi code, and was like wut teh fuk?! I tried that too with Lazarus for old time's sake. Fingers complained -- the verbosity is a killer. But I loved Object Pascal back in the days when VB6 could not come close to Delphi.
I'm going by what the OP said in this post: https://www.reddit.com/r/dotnet/comments/6n359e/is_uwp_the_right_way_to_go_not_according/dk6c8sg/ If it's desktop, then it better support Win 7, because professionals on the hiring side of LinkedIn's user base (i.e., the one's actually paying for premium LinkedIn accounts) are more likely to be using Win 7.
just because its desktop only doesn't mean it isn't UWP.
WPF is better for most model-driven apps (crud) and media apps 
How big is the investment from the rest of the world though? Surely that's what cools Microsoft down, too.
&gt; Or an website embedded in chromium, made using .NET core. What do you mean? A website embedded in chromium sounds like Electron.js. .NET core would have nothing to do there. 
Almost all Microsoft's investment in Window's desktop tech has been in UWP. Most all new APIs going forward have been UWP practically, and the ones that haven't have largely been compatibility focused (think DPI &amp; Desktop Bridge). 
I mean, you can embed a small .NET Core server into Electron, but that would be madness.
&gt; .NET core would have nothing to do there He's referring to a (hypothetical, I assume) .NET equivalent to Electron.
I use devexpress at work, I love it. As far as free controls, objectlistview is amazing for a free grid/list view. Did you see this SO post? https://stackoverflow.com/questions/361271/best-free-controls-for-net
Yup, Delphi&gt;VB6 IMHO. Back then I had yet to understand the allure of garbage collection. And meanwhile you had real objects, inheritance, but all the RAD that VB6 promised, and visual inheritance of forms. I learned lots about interfaces, first saw RTTI which I now know as Reflection, and complained oh so bitterly about the lack of help files. Probably the greatest thing for me was that the code of VCL and all shipped with it, so I spent so much time trapsing through the code of better programmers seeing how they did it. The black box of .net was painful at first, and now we've come full circle and I can see it all. Delphi's like a really great ex-girlfriend. I wouldn't go back, but man we had some good times while the affair burned brightly.
But it completely misses the point of UWP then.
Anything that contains Google code traces is unacceptable due to security and privacy reasons.
This makes no sense. There would be no .NET equivalent to Electron that runs a Website because .NET is not a runtime for the Web stack (HTML, JS, etc). Lmao.
You could always run HTML using the [WebBrowser](https://msdn.microsoft.com/en-us/library/system.windows.forms.webbrowser(v=vs.110).aspx) class. It would be harder since I don't think it supports "modern" HTML
Any differences in network location, topology, etc. between the '08 &amp; '12 servers and your SQL server? Are you holding long-lived IDbConnection objects in your own code? Is the SQL on Azure?
I... guess? Why are we talking about Google now?
Web servers and SQL servers are all in-house, SQL is 2008R2. Same DMZ configuration, router, firewall, etc. as the 2008 boxes. The 2008 server does not have Windows Firewall turned on, but disabling it on the 2012 machine didn't seem to help. We're usually pretty good about closing out SQLConnection objects but there are more than my own hands doing development, so I'll admit there is certainly some possibility this isn't happening 100% of the time. I'm really leaning towards this being something that is somehow corrupting the session state, or maybe some session-level configuration value that is different in IIS 8.5. It's just *really* bizarre that the issue only affects certain sessions - I'll get the message on every request while another user has no problems at all, and as soon as I close out my session &amp; re-login everything is fine again (for awhile at least). Session mode is InProc btw 
Electron.
I also like WinForms because it is close to Win32 API I have used for a decade. But it does not handle scaling well.
You seem upset about something.
Check out Auth0 They will help you integrate any authorisation service you can think of.
Sounds like a great alternative to Electron.js.
&gt; It's just really bizarre that the issue only affects certain sessions - I'll get the message on every request while another user has no problems at all, and as soon as I close out my session &amp; re-login everything is fine again (for awhile at least). &gt; Session mode is InProc btw Sounds like there could possibly be a connection object in the Session or something (perhaps nested inside another object or service).. If the session mode is InProc, it shouldn't be the Session itself hitting SQL, and when I first read through your OP the first thought that came to mind was app code holding onto an IDbConnection that failed and not properly reconnecting it (one reason not to manage IDbConnections oneself and let the pool deal with it).
I mean he raises a valid point even if it is a bit overstated. 
He does, but it felt like it came out of nowhere.
If you can upload a zip of your code somewhere and PM me a link I'd be happy to take a look. With what you've posted I don't have enough to work it out. One thing to note is that once this is working properly you'd expect a 403 forbidden response. 401 unauthorized would be if you didn't present a cookie or token or the one you did present was invalid (e.g. Expired). The name of the 401 response can be a bit confusing at first.
Yes! Because every project needs 15 dependencies to enable logging. :-) I mean, I like Serilog, but man have they chunked the thing all to hell...
Nah, we use helper classes for pretty much all our SQL query execution. Something like Dim ds as Dataset = DBHelper.ExecuteDataset(ConfigurationManager.AppSettings("MyConnectionString"),"SELECT * FROM sometable") In this case the helper class opens an SQLConnection, executes the statement, closes the connection and returns a Dataset 
Its really a trade-off of one massive dependency versus a bunch of smaller ones. The best way to look at it is that it's just one dependency really, it just comes as multiple packages.
Yeah I get it. Its just always disconcerting to see a project with 15 dependencies, and 10 of them are logging :-)
Oh, I also realize now you mentioned the phrase "dynamicly", if you were wondering how I register my repos in my dI container, it looks like this: builder.RegisterType&lt;EntityFrameworkRepository&lt;User&gt;&gt;().As&lt;IRepository&lt;User&gt;&gt;(). Then when my generic API controller is instansiated by my container, it knows to resolve the IRepository dependency because of my registration.
Hmm, well from your description it sounds like you have it reproduceable and tied to a browser session. Toss some logging in and capture a session id and the call stack and try to see what part of your code is first triggering the issue during a session. Hopefully that will lead you in the right direction. I'm afraid no other obvious possibilities stand out to me. 
Yeah :-) one of the drawbacks of having been first to support .NET Core, which was originally similar. I don't think the sink packages are likely to be merged in - they're just to many and varied (and bring dependencies of their own) - but in a v.next we could definitely look at combining some packages. Are there any in particular that make good candidates for this?
Nobody read the article. Fourth paragraph states that a Windows Store App is coming. Those are all UWP apps. OP either didn't bother to read the short article they submitted or just wanted some circlejerk karma.
And from another angle - it's nice not to have to upgrade every time one of a hundred components changes :-)
Oh I'm just bitching because I had to deal with a bunch of it this week in a company framework based on Microsoft.Extensions.Logging, and then all the stuff I had to pull in to make Serilog work with it. Off the top of my head, though the Settings packages, and some of the Enrichers. The Sinks I think are fine and good, though I could see making one or two of them standard, like file / rolling file. Like I said, I get why they are split off, and I don't even disagree with it. The first time I saw it though the first thought I had was "it can't actually need all this".... and I was wrong :-)
You don't get rid of JS entirely. The suggestion was basically "swap node.js out for .net core", leaving the rest of it the same (aka just like regular ASP.NET). That said, 1 year from now it may not be out of the question to [replace JS entirely with C#](https://www.reddit.com/r/csharp/comments/6mjlrv/writing_webassembly_in_cshtml/)
Electron.js is **not** node. We are talking about UI, here.
I second this. I abandoned Owin for Auth0 a couple of years ago and haven't regretted it since. 
Some Win32 apps can be submitted to the Windows Store after being converted by [Desktop Bridge](https://developer.microsoft.com/en-us/windows/bridges/desktop) (aka Project Centennial)
I would run perfmon and Sql Profiler and do the things that make it blow up. I agree that it sounds like there is something in the session that is making a lot of Sql calls that is tying up the context causing timeouts to cascade . The performance Profiler in visual Studio may also lend some insight into why this is happening if you can attach remotely. 
Do you have a load balancer in front of the web servers? Are you using sticky sessions?
They apparently fixed alot of the scaling issues with winforms in .net 4.7 as well as added high dpi scaling support and also added per monitor scaling support. https://github.com/Microsoft/dotnet/blob/master/releases/net47/dotnet47-changes.md 
Adding Bootstrap just involves referencing a javascript and css file. You can add it to .Net, static html or any other type of website. Just download and add to your project. http://getbootstrap.com/getting-started/ 
Sounds to me like someone is throwing a DB connection into session. &gt; I have managed to identify a sequence of events that I can repeat to get the error to happen every time. Like others have said you will need to debug this specific sequence of events to track it down. At least you can re-produce those problems are easy to fix. You might also try to replicate issue on different computer. That will rule out hardware/os issues. 
No load balancer, single web server only
I'll admit it's possible but unlikely, I'm usually pretty adamant about keeping session variable use to a minimum since it's so easy to abuse. I am, however, not always looking over the shoulder of everyone while they work and not in the habit of reading every changeset checked into TFS. I just don't understand why this exact same code works fine on the old 2008R2 box
Like the other commenter I'd need to the project, but this looks kind of familiar so I'm going to make some assumptions, may or may not be useful to you! It looks like you're writing an SPA with a Web API backend? Do you have the API in the same project as your SPA? Are you using cookie authentication? It looks like your app is redirecting you to the login page on an unsuccessful auth challenge. Check out the documentation [here](https://docs.microsoft.com/en-us/aspnet/core/security/authentication/cookie). This [this StackOverflow post](https://stackoverflow.com/a/44600389) will show you how you can prevent this challenge redirection and instead return a status code. 
Including you :-) ... *the company is working on launching a brand-new Windows Store app in the coming weeks - but the email makes it clear that it's a* **"LinkedIn Windows desktop app"** *, which therefore won't be able to run on Windows 10 Mobile phones.* That's the core point of the discussion - why not UWP ? 
I just went through this. The answer depends on what you are doing in terms of app integrations, but for a plain old ASP.NET WebApi Go to apps.dev.microsoft.com and create your app there. Then, use this library https://github.com/aspnet/AspNetKatana make sure to check this issue https://github.com/aspnet/AspNetKatana/issues/48 as the latest fixes are not on NuGet yet.
In this case they can make both options (Classic desktop and UWP). I still can't see a point of an application on Windows 7 systems compared to web interface.
I'm not trying to be a dick, but if you think about it for a second, the web interface for LinkedIn is www.linkedin.com. There are a lot of people out in userland that still prefer desktop apps, and when you're company as large as Microsoft you can afford to cater to those customers. And, when it comes to desktop software, to get the widest market reach, you're almost always going to be using lagging technology.
Again, in this case how can Microsoft indicate that Windows 10 and UWP is attractive and successful concept ? By providing oldschool Windows desktop app only ? By forgetting their mobile system targeted to business customers ? Given the money they've spent on LinkedIn the right way would be to make both kind of apps, similar to OneDrive for example.
You are making a big deal out of nothing. Microsoft have never used WPF in their products either.
&gt; Microsoft have never used WPF in their products either. Do you know Visual Studio ? :-) This is different case. The whole universal platform and related (native - not the bridge) Store concept seems to be denied by Microsoft itself, if not being used for building a new 2017 flagship service application. That's my point.
It is even worse. Part of Visual Studio is writern in JS while there is no reason to not use C# for the same functionality.
Well your answer really is going to depend on *what kind of controls are you looking for?* WinForm? WPF? UWP? ASP.NET? And ***why*** are you looking for a custom controls suite? Are you looking for custom controls that have different *functionality* or just a different/better *visual appearance*? You haven't really made it clear what you're actually looking for other than "free"... 
UWP was dead on arrival. People like to equate it to WPF, but it's not. WPF is a UI framework. UWP is a poor locked down runtime tied to one version of Windows, that happens to have a UI framework on top of it.
Careful, Auth0 is very expensive if you have more than a handful of users.
Writing custom controls for Microsoft GUI libraries is the beginning of difficult mode. Learning to do it yourself will increase your value. I gave up on third party control libraries forever ago (they are never as extensible or as customizable as their marketing materials will have you believe); writing your own will not only ensure you get exactly what you want, but will teach you A LOT about the library hosting it. My advice is to get a book on writing custom controls for the library you're using and get started. You'll suck at it in the beginning, but keep at it and you'll improve. Learn performance testing. Custom controls are where your options for creativity really open up. Embrace hard mode and your life will improve. Source: high-priced consultant.
Bit late to the party but I had a connection issue like this using dotnet core on linux, what fixed it for me was *not* specifying the named instance, so just connecting with: Server=xxxxxx,1433; Some more info: https://github.com/dotnet/corefx/issues/4346 
I don't have a Windows phone. If they had an android version, I wouldn't install it.
Can you please write your question in a way that it can actually be answered?
I actually just discovered that the connection worked when I didn't specify the instance name on OS X either. But I didn't know there was an issue page opened up GitHub for this, thanks!
And don't forget the Xbox Play Anywhere.
which part? I'm guessing the typescript language service (which is compiled to js)?
Surprisigly not. It controls the "hub" of external executable files (.net ones) that provides the service. Nothing that couldn't be written in mature C# and digitally signed for security matters https://developercommunity.visualstudio.com/content/problem/69594/please-remove-dependency-on-any-javascript-code-or.html https://developercommunity.visualstudio.com/content/problem/31406/visual-studio-2017-nodejs-server-process-turn-off.html
that's really friggin' weird, bordering on outright laziness &amp;mdash; as in it wouldn't surprise me if they shelled out work to node to avoid memory issues with their 32bit architecture.
I just did this with Azure AD. Let me know and I can share some of the details of what I had to do. 
Just write your own extension methods, everyone does it. Then, if you're feeling so kind and are able, put em in a NuGet package, and let everyone else profit from the effort.
Is there a TLDW?
I use [Telerik](http://www.telerik.com/) myself at work.
Thank you guys for the awesome answers. To answer a couple questions here: * I'm doing mostly WinForm development as side projects for myself or to help streamline some processes at my machine shop. * My need for these custom controls is to really be able to tailor these programs to fit my shop individually. All of your answers have been extremely helpful and I'm going to check out the linked sites here while listening to Aaron as well and dabbling in creating my own controls with free time at home. Thanks again guys. I have to say, being self taught and talking to professionals can be scary but you guys make this sub-reddit an awesome place to look for solutions and ask questions!
Perhaps you could switch to .NET Core and use Visual Studio Code?
It is also fun to read the *hubController.all.js* script. Especially when you realize it is not digitally signed and can be replaced with any other script. Security first :-/ It could have been written in PowerShell at least.
I think there are more important things to tackle than that. Also, you can write your own extension method or even send in a PR and hope it gets merged/accepted.
to be fair, powershell is weird as hell. trying to write a script with it to connect to azure was pain upon pain, to the point i just gave up. then again, it *does* make you wonder what the point of having a full-fledged bash-a-like running around is if you're gonna sub in a whole other VM to take work off its plate. at least powershell 6 looks promising!
Visual Studio predates WPF and has a lot of native code. I may be wrong be I doubt most of it is in WPF. When Microsoft wants to make a truly universal app, they make it in Electron like Visual Studio Code. 
.... which would be the end of Visual Studio. A slow scripted crap consumimg 32 GB of RAM just to start. Only .NET or native code have some sort of quality, reliability and security. Fortunately you can't write (working) debugger in JavaScript, GW Basic or FoxPro :-) Truly universal app is UWP. 
Currently working on a project for a client (details of which I can't disclose here) and I am using .NET Core with EF Core (yes, I am that bold, lol). So far, it's been a smooth ride. The only challenge I have is with setting up continuous integration and continuous deployment using VSTS, where after a successful build the deployment artifacts were never created.
Including you apparently, only UWP apps go on the Windows Store. It is a UWP desktop only app because Windows Phone marketshare is so low it's not worth releasing for.
Why do I want to use this over another well supported tool?
Now *that's* funny. 😁
Which other well supported tool are you taking about? In general Cake doesn't replace tools, it orchestrates them and it does this using C#, not with XML or some other foreign language. So if you're a .NET/C# you'll feel right at home and get to use the skills you already have and use every day. 
VSTS does all of that for us.
 VSTS is an excellent build system and is it sorts all your needs that's perfect. 👍 First Cake works excellent together with VSTS. That said there's a few advantages with using Cake build scripts: * build definition versioned with your code * you can debug your build process locally (even single step, watch variables, set break points, etc. ) * build system portability (no lock-in, use same script on any build server/system, great for oss) * cross platform/environment (run same script regardless of which operating system /environment agent is running on) * etc. 
Bootstrap doesn't cares about ASP.NET. You can put it on a local static HTML page for all it cares.
The email does not confirm it will be in Store at all. Especially if it supposed to be for Windows 7 as well as already discussed.
This is what I was looking for. Thanks. 
hmm.. I cannot find the option
Resharper has "Find Usages" and "Find Usages Advanced". The default keyboard shortcut for "Find Usages" is Shift+F12. If you can live with using that shortcut instead of clicking on the reference link above a type then you're good to go. I've moved the results window from the bottom to the left and enabled auto-hide. 
Is the connection encrypted, either explicitly or forced from the SQL Server side? Your SCHANNEL settings might prevent a proper connection to occur.
Terrible in practice, great as a learning resource!
[removed]
Lol I am glad you like it.
Nice work! It's cool to see how websockets etc works at a very basic level.
Shit you didn't read the email either. Well trolled.
&gt; How to implement a terrible chat server in ASP.NET Core in less than 400 lines of code Had to lol a bit, memories. When I first started learning .Net - 2002 - I was in prison, in a computer college courses (I was already a decent dev), and we had a network but no internet. I wrote a chat server and client. It was called LiQ, we stole the icon, more or less: http://i.imgur.com/qnVcEcV.jpg The server was in VB and made this look like good code :) the size of the nested ifs and cases, oof. It was DailyWTF material for sure. The client was my first foray into c# and I ended up making the GUI totally skinable (winamp was big at the time). That was tough but I had previous Win MFC experience and WinForms was just a layer over it ultimately. We had a skin that was a chicken sitting on an egg, and an incoming message would crack the egg open and come out. Good times. Wrote a lot of code in prison. Honed my skills. Walked into a shitty dev job after I got released (6+ years in) but moved up before long and now I have a great gig that I love :)
Dang, that's an awesome story. I hope more people should just enjoy programming and making stuff without worrying about the "best frameworks", the "most scalable", and best patterns. Go out and make something. 
How did you wind up in prison, if you don't mind me asking?
Drugs. I was a bit of a hellion in my teenage years in a small town. When I was 20 I got caught with like 20 grams of meth, like $700 worth. Because I had a few criminal history points - prior felony or two for weed, one for writing bad checks, enough juvey stuff to count a bit, and was on probation - I got a 12 year and change sentence. Normally you'd do 2/3rd's of that. I got into a drug offender boot camp program that cut my sentence a couple years short (normally you could cut 4 years off, but I barely even got in because on the bad check felony I straight up escaped from county jail).
Crazy! I'm glad they teach things like programming in prison, I definitely think it cuts reoffending if people can get a good job afterwards! Good to hear things improved for you!
That's how you learn. I didn't feel like I wrote good code for many years, and even still I doubt it somewhat because I'll often look back at stuff I did any more than 6 months ago and just think, huh. Do the best you can now and try to learn from every bit you do along the way.
Sadly, while I was there most of the education was in the process of being slashed. I guess I'm not sure how it is these days. I don't keep in contact with anyone around there. During my stay, some people working in the industry area, which was totally separate people and buildings, got caught smuggling in porn that was printed out, and some of the printouts had the url at the bottom - like the default when you print from a browser. So, in their wisdom, administration shut down the entire education department - and only the ed dept - for over 3 months. In case they had secretly hooked up internet to all the inmate's machines :-/ Everyone in education was put on essentially 22 hour a day lock down the whole time. There was talk of not even allowing people to order computer related books at all (meanwhile I have a cell full of manuals). I barely managed to finish an AA degree and I was one of the last group of people able to do so outside of completely through the mail programs. Hopefully it's not as bad; it definitely was a great thing for the inmates. Most of those people want to succeed and live within society.
Haven't attached [Snoop](https://snoopwpf.codeplex.com/) to Visual Studio yet, didn't you? Microsoft SQL Server Management Studio is also created by using WPF. Sure, they probably still use native code in its core functions, but it defintely uses WPF to create the UI. 
[removed]
Christ, every time I see a story like this it really hits home how absolutely fucked that system is. Prison for holding on to some drugs. Yikes. I guess you have to fuel the 13th amendment somehow 😕 Anyway, amazing story. You're an impressive person.
I was really hoping it was an Office Space style plot. 
12 years for non violent drug offences is insane. 
https://www.reddit.com/r/dotnet/comments/6na1ck/version_0210_of_the_c_based_build_orchestration/
I'm also interesting in this, I have found nothing definitive and have had to stumble my way through DI.
+1 for realising business logic in the controller is terrible. With ANY type of application, you want the business logic in what's called a "service layer". Others might call it the "business logic layer" but whatever, it's all the same thing. The service layer should ideally be a separate project that you then use in other projects. In this case of ASP.NET, you inject the services into the controller. A controller should have next to nothing in it, other than calls to the service(s) that are injected. https://stackoverflow.com/questions/21509805/asp-net-mvc-and-service-layer-dependency-injection This should be a good start.
See my reply.
The most basic way you could do it is just extracting your logic into a separated class, in a separated assembly. There are many names to it, as other commented. Also, this is not related to .Net Core. The same examples you find for .net full framework (asp.net) can also be applied to .net core. Maybe the registering of services are different, but if you are using a 3rd party DI framework, like Autofac you are mostly in the same area. You could take a look also on DDD (if already not) because it contains some guidelines that solves these problems in many ways.
Here's a simple approach: * Create a class * Add a method to this class. Pass everything that the method needs to do its job. Make the method to return a tuple (bool, YourReturnObject, Exception) or a tuple (EnumOperationStatus, YourReturnObject, Exception) * Make sure to only pass data. Do not pass anything from the web framework. * Use this class in your controller action. That's it. You can do so many variations of this approach.
Answering my own question I kinda found a way that worked. I've created a interface called IService: public interface IService&lt;View,Form&gt; where View : class where Form : class { void Create(Form form); void Update(Form form); void Delete(int id); Task&lt;View&gt; GetViewModel(); Task&lt;View&gt; GetViewModel(int id); bool HasErrors(); IDictionary&lt;string,string&gt; GetErrors(); } Then I created a class to implement the interface. Added to startup.cs so I could use the DI: services.AddTransient&lt;IService&lt;FormMovementViewModel,MovementForm&gt;,MovementService&gt;(); So in the controller I can do: if (_movementService.HasErrors()) { foreach (var error in _movementService.GetErrors()) { ModelState.AddModelError(error.Key, error.Value); } } I have all the errors that happened during the execution without passing ModelState to the Service Object. I will write a blog post about so I don't forget. 
Jimmy Bogard did a good series of blog posts called "putting your controllers on a diet". Basic principle is to use controllers to route to handlers which encapsulate business logic.
What error do you get?
I don't get any errors but when I query the claims after, it's not there. It never gets added to the claims
You'd need to add claims to the cookie. Maybe you could do this client-side with a request to a controller that would return a new cookie. Then do something in JS to assign that as the correctly named auth cookie. However, consider this. If the extra info is needed for normal application function, you're probably better off giving the auth cookie a long timeout and having users endure the delay once in a while. Otherwise, you're in a situation where you have to figure out how to deal with cases where the info you are retrieving is not there.
The extra info is not crucial for application operation, it's only needed in some parts. That's why I think it'd be nice not to make them wait at login for something they might not even need. The cookie is encrypted, isn't that where all the claims are stored? I don't want to create a separate cookie, I'd like to add to the existing one that's already generated by ASP.Net anyway. Is there no way to do that server side? Would I have to regenerate a new cookie with additional info and sign them out/sign back in again?
I think you might be trying to cast IPrincipal implementations that are not fully castable to ClaimsIdentity. Put a breakpoint and check the types of the User property. We ran into a similar issue at work, but I don't have access right now to look how we fixed it.
Thanks, I'll try this. What should the type of User be?
The only thing I hesitate on about your post is the "controllers should have almost nothing in them" statement. While I agree you want a service layer to handle business logic, I don't like the idea of polluting the service layer with any notion of network/http/html related functionality, so in my controllers, I do keep some logic, but that logic is purely related to "how does this result from the service layer translate to a valid http response". So for example I may have a service that returns an object the user is requesting, but in my controller I'll have a call to a converter to turn that object into a viewmodel to return within a 200 response, or if the service says the result is empty I'll check that to return a 404. Also the logic is around what the service responses mean to http, but there is logic there
I believe it needs to be the same one as returned from Owin. But I'm typing this from memory, so take this as a disclaimer. 
Hmm, I'll check when I get back to it
Omg, i don't envy your employees 
How about spending a month learning to code using C# and ASP.NET MVC 5? It's hard to gain conceptual understanding without going through the programming experience.
What you described is literally what I meant.
Well, good. That makes me feel better then :)
Why not? Better to have a manager that admits he doesn't know instead of pretending he does. This person seems like they want to learn and to help their team; which is probably why he got the job in the first place. 
What about naming conventions for services? I have UnitOfWork in my DAL, and Services such as CacheService, EmailService and domain related services such as PersonService (which uses UnitOfWork to retrieve people among other things, person related stuff), but then I see people using DI for logging and calling it ILogger without the Service suffix and it makes me start to question which 'services' you should suffix. Can you shed any light on this?
So you are trying to modify or add a claim after the OWIN middleware has already handled the login?
Good plan. Get the company to buy a Pluralsight subscription for the team, which the devs should appreciate, then do the intro courses to C# and MVC.
Yes. Is that not possible?
Sure it is, but because the claims are stored in the cookie your data will be "lost" on the next request. What you have to do is make OWIN refresh the cookie after modifying the claims. Here's a excerpt from my own project that should help you: https://pastebin.com/Q4fGiWAu
Thank you very much, I'll try this when I get home and report back.
Here's an exercise. Create a console app with a simple text-based, menu-driven interface. Make it so you can do everything with the console app that you could through the web app. There should be no html involved. No references to MVC stuff.
If you want a free means of learning definitely look into Microsoft Virtual Academy as I've used many of their courses in the past and had a great time learning ASP.Net MVC/WebApi https://mva.microsoft.com/en-us/training-courses/introduction-to-asp-net-mvc-8322
I'm getting this *'HttpContextBase' does not contain a definition for 'Current' and no extension method 'Current' accepting a first argument of type 'HttpContextBase' could be found (are you missing a using directive or an assembly reference?)* on this line var auth = HttpContext.Current.GetOwinContext().Authentication; EDIT: I removed Current var auth = HttpContext.GetOwinContext().Authentication; AND IT WORKED! Who-hoo! It actually added the value to my claims! Thank you very much! I put it in an action on a controller. Now, I just need to figure out how to call this asynchronously, I'm thinking there should be a handy jQuery method
Because ideally you have managers with relevant experience in place already. I agree that he seems to be on the right path and have an open mind, but this is relationship is not going to be productive on a technical level until the manager gets up to speed. Not to say that the other aspects of management and general development of the devs wont be spot on.
The op is trying to do it on a completely separate http request, one initiated from JavaScript on the page returned from the first http request.
You don't know anything about the org structure. Maybe the purpose of the OP is to project plan, manage resources, deployment schedules etc versus doing code reviews and cutting code. There's still plenty a manager or a leader of a development team can do without a deep understanding of the language itself. 
^this, during Black Friday Pluralsight had a deal and my company jumped on it. All out dev's have loved it and we've all benefited from many of the courses there thus far.
Once you have the basics covered you should sit down with your devs and have them explain how what you have learned is applicable to your companies actual stack. Ask your devs which third party libraries or internal tools they are most excited about and why, because chances are they are going to be using them a fair amount and it will help to know what they are talking about. Finally, and this might be the most important. Get familiar with whatever your companies products database entities are called and get the names right. Gets your nouns right. Call and order and order and an item and item and understand the difference, because if you can't keep track of those things it's going to be difficult to manage a project in any sort of real way. 
I've used it in a few projects. It's fine for simple POCO storage.
Better, yes. I also find it great that op tries to prepare for this job. My comment still stands though and it's more a organizational critique than a personal
The code I posted is actually from a static helper class. If you put the same code inside a controller than that might be the reason you were getting an error. Anyhow, glad to hear you got it working!
The main problem is getting the tooling and deps all installed correctly, but once you have that setup I've been using it mostly without a problem for simple local storage. (just remember you can't use `dotnet ef...` on a netstandard project, only a netcoreapp one)
What's the situation? Being able to code might be the least useful skill by far. Understanding the bigger process of software development (talking to people, understanding requirements, estimation, process management) not to mention some of the supporting tech (source control, CI, infrastructure) might be way more useful?
I started using it because I had similar thoughts. Turns out not having lazy loading combined with no implicit many-to-many relations is a huuuge pain point. Doing all those inserts into the join tables and transforming the loaded data to get rid of the join table before sending the object to a client gets soon much more complicated than one would think. On the other side I don't know what the alternatives would be for .net core atm. 
Entity framework tooling is well... not the most intuitive. But if you look past that it's just fine. Code first and command line instead of gui works nice.
Were you not aware it was illegal?
Punishment must fit the crime. 
I can't share the project unfortunately, but fortunately I don't have to because the StackOverflow post you linked did the trick! I was pretty sure that it was trying to redirect to the login page, but I couldn't figure out how to get it to stop. Thanks!
If you need knowledge of SharePoint, you might want to consider a course on SharePoint rather than general development. 
I haven't used it yet but I've been keeping an eye on https://github.com/linq2db/linq2db as a possible ORM switch as my project is still using Linq2sql.
So far, I've only used EF Core in some prototypes, it feels like a bit of step down from the the .Net EF. Some attributes that were not very intuitive to use are gone, replaced by "fluent interface" that is not that intuitive.
yeah that `dotnet ef` on a standard lib got me a few times...
Microsoft can always make a surprise https://blogs.windows.com/windowsexperience/2017/07/17/announcing-linkedin-app-windows-10/ It looks like app with embedded web browser only. I don't get it at all.
Are you running the preview edition of VS?
Nope
He's referring to his employees dealing with Sharepoint.
My manager knows nothing about programming and is still great. Managing people is a completely different skill and does not require nuts and bolts knowledge if you have the right team...if you don't have the right team then you have a new step 1.
I would go against the recommendations of other posters who are suggesting to put your business logic inside of a service/handler. According to DDD principles, core business logic should be encapsulated inside their relevant domain models. Having all your core business logic in the service layer/handlers leads to [anemic domain models](https://martinfowler.com/bliki/AnemicDomainModel.html), which basically means your domain models are nothing but DTOs. Essentially, you are incurring all the cost of having Domain Models, but reaping none of the benefits. Additionally, having all the business logic inside a service layer would cause the application to be a scalability nightmare. Will putting all the business logic into a service layer/handler slim down your controllers? Yes, and depending on the size/scale of the application this might even be the way to go; however, if you have some complicated core business logic, I would suggest putting that inside their respective domain models.
Telerik is great but far from easily obtainable for a newbie. I leaned on telerik a ton while learning to program and I kind of wish, looking back, that I hadn't used it as a crutch so often (especially with ASP.NET AJAX) because most of what telerik does can be replicated with much more customization if you understand how to make things from scratch. The tradeoff with telerik and devexpress is rapid development VS. customizability 
this would be a great AMA.
May God have mercy on your soul working on Twain scanning. Let me look tonight after work at an old project that uses that library and see if I can help out. If I can, I will also get the code moved over to a public project to hopefully help with the whole process. It is a WPF control for scanning that is used with Interop and housed in a VB6 application.
&gt; May God have mercy on your soul working on Twain scanning. troof. Good luck!
Hi ksu12, thanks for your feedback. I'm pretty stuck with it: I read this post: https://stackoverflow.com/questions/16555951/setting-default-twain-data-source-without-using-api-ui-menu I this the guy has the right idea with datasource.SetDefault() but I don't have it in TwainDotNet. Hope that reminds you something. Thanks again ;)
I did one a number of years ago under a different user. I was connected to that user IRL so it eventually got deleted. Sorry.
It is Open Source. Just submit a PR against: https://github.com/aspnet/Mvc/blob/288da1a405f07e5b49e3509554d586af2f87ed05/src/Microsoft.AspNetCore.Mvc.Core/ControllerBase.cs
Eh, I'd say it's plenty easy to customize myself. They provide the whole framework for building widgets, not just using what's packaged. We've really designed whole interfaces and customized most of the controls (or combinations) and everything just works great.
Thanks! I did run into another issue. I can call it asynchronously from jQuery, like this &lt;script&gt; $(document).ready(function () { $.get("/GetUserInfo"); }); &lt;/script&gt; However, since it adds the info to claims and that is stored in cookies, it only works if I wait on the page until the async call completes and sends back the response with the updated cookie. If I navigate away before the async request is completed, it never gets added to the cookie. I ended up adding it to Session as intermediate storage, then pulling it from Session into cookie (via AuthenticationResponseGrant code you provided) on the next request. It seems kind of hacky and against MVC principles (I'm trying to avoid using Session as much as I can), so I'm just wondering if there's a better way. Plus I ran into the whole Session locking thing where only one request can be using Session at a time. So, if I'm trying to look up a value in the Session while the long running request is still executing, it hangs until the other request is complete.
No problem, glad it helped - I had the exact same scenario come up a few months ago.
One thing I've learned after many years experience in development, random pet project ORM's - *especially* one with LINQ providers - rarely cause anything but major headaches in the longer term.
Certifications are used to get your application past HR departments and other gatekeepers so that it can land in the hands of someone who actually knows what your job will entail. The gatekeepers have zero idea of what the job entails, and have little to no idea of what all those different terms on your Résumé/CV mean, so they need easily-identifiable, easily-interpretable items to put on a checklist. A cert or degree is by far the easiest and least ambiguous item they can chase after. TL;DR: if your application gets pre-processed by a gatekeeper, get a cert or degree on your submission. If the first hands to touch your application will be your potential boss or team lead, don’t bother - highlight skills using all the industry terms.
You should be aware that .net core is changing every f*cking day and it's annoying.
[removed]
Here is a very detailed and thorough evaluation of most approaches to the repository pattern, their strengths, and their weaknesses. Although I'm not necessarily advocating that you go all the way to an ambient DbContext that is the final conclusion of the author, i think it's incredibly important to understand how he gets there. http://mehdi.me/ambient-dbcontext-in-ef6/
What are people's feelings about this? It feels very webforms-esque where your front end code starts mixing with your backend. Does anyone else remember that "RegisterClientScriptBlock" in Webforms? What a f-ing nightmare that was. 
&gt;Does anyone else Probably
&gt;Does anyone else Probably
Thank you! Will definitely read this.
While I don't know much about your project, it seems a little bit odd to have a database query that takes 7 - 8 seconds. I usually raise my eyebrows for anything that takes around 1 second because in most cases it means that the query is not optimized properly (e.g. JOIN on non-indexed columns). So my only suggestion would be to review that and if there is no way to improve the speed than think about if there are any alternative approaches. I also run a database query during the OWIN auth phase in my project but it's just a simple table lookup.
Most entry level positions aren't going to demand specific skill sets. If you know enough to talk generally about major topics like * What is new/different in Core * Dependency Injection * Source control * Azure/AWS cloud solutions * Javascript frameworks like Angular or Node.js * ORMs You should be fine. You don't need to know everything, or even have experience using them in a real project. But taking 15min to go through a tutorial just so you know what is possible, should give you enough of an understanding to at least hold a conversation about it. Simply showing the initiative to learn something new is probably the most important thing managers are looking for in someone starting their career. I wouldn't focus too much on specialized tools like Sharepoint or Dynamics, unless that is what you really want to get into. It's a lot easier for a purely .Net developer to get a Sharepoint or Dynamics job, than it is for someone who has only Sharepoint experience to get a higher level .Net developer position. 
I don't see strong Core adoption in the near future. I've never heard of a useful programming certification. Sharepoint can be useful because it sucks to work with; hence a smaller supply of people to fit the demand.
https://www.hanselman.com/blog/WhatNETDevelopersOughtToKnowToStartIn2017.aspx
Doesn't seem that much different than the node pipeline to me.
Completely agree, there's no way I'd allow a query run longer than 1 second if I was in control of it. Unfortunately, I work for state government. The query pulls from linked server that connects to state's ancient system with convoluted proprietary driver/interface wrapped around it. There's no way to speed up the query for me. 
Core moving strongly into early adopter stage, but definitely a niche use case. I see this changing fairly rapidly, let's face it Linux cloud servers are much cheaper, and Core is not changing quite as fluidly as it used to be. It's probably a good thing to be looking at now, as it might be quite a lucrative skill for a few years. Now, back to our bloody Winforms app ...
Did not answer my question. 
There was already an issue/PR for this on GitHub if I recall correctly 😛
When I was hiring for an entry level dev, I had a hard enough time finding anyone who could even talk about the classes they took. 
&gt; I've never heard of a useful programming certification. In terms of resume boosting? Agreed. I took the MS C# cert exam to help get my company Silver Certified for the extra MSDN subscriptions. So at least it's useful in that regard!
I stay away from EF. Life is much better without it. Controller-&gt;Service-&gt;Repository-&gt;Provider with DI works great in my experience.
It's pretty damn stable now imo. Honestly, the only period I really loathed about Core was the "release candidate" stage before 1.0. That was barely even an alpha. The MSBuild resurrection wasn't even that bad (even if project.json was an exciting change). The only gripe I might have against Core is the documentation slightly lagging behind (and lots of outdated blog posts that pop towards the top of Google searches).
Honestly, this post is such a great culmination of vocabulary. There are so many terms out there, and it can be quite confusing when coming in from the typical .NET Framework background. I always recommend this one whenever people ask about .NET Core and .NET Standard, etc.
I have two applications in production using core, at an insurance company. Both fairly large (team of 8-10 developers 6-14 months each.)
2.0 has some nice changes. But yea, it's been stable lately but stuff like ef core is unusable for production. Hopefully it'll be ready soon.
This. I started doing this at my company and it cleared up a bunch of hand written transaction logic.
For a long time that was the go-to architecture that you would see in every book and article. I'm starting to see a trend away from that as time is showing the costs of over architecture and horizontal layering. Almost no one ever swaps out their database in the real world. Organizing code by feature or using the CQRS pattern are alternatives that are worth taking a look at. Are you running into problems with what you have now?
I've been using Linq2Sql since it came out and I've found it to be really good. I can only think of a handful of issues with it. Linq2db seems like it is pretty well supported and solves the handful of issues that I have with linq2sql. 
Projects targeting frameworks earlier than 4.5 cannot consume a netstandard library. If you're creating a library for public consumption, consider multitargeting a .NET Framework version and a netstandard version. If it's just libraries supporting whatever application you're developing and you plan on going core or using a framework version that supports the netstandard version you're going to use, go ahead and target netstandard instead of a .NET framework.
Linq2Sql isn't someone's pet project, and has decent expression to sql translation (especially for it's time). Linq2Db isn't even on the same planet support wise. Reminds me a lot of SubSonic. LINQ, but just barely. Use whatever you like, and most tools can work or not. I'm just saying I've seen over and over libs like that lead to a never ending plethora of maintenance issues, and ORM's tend to be a thing you get stuck with as they eventually end up being used all throughout your code base (or if not, wrapped in your own adaption that's usually more just problems on top of everything else).
Here it is: https://www.reddit.com/r/IAmA/comments/ryhzq/iama_now_successful_man_who_spent_over_5_years_in/
Given the way the industry is moving it would be beneficial to pick up skills with Azure and the [Cognitive services](https://azure.microsoft.com/en-us/services/cognitive-services/). They're not as daunting as they seem. Plus in the process it will teach you how to use Rest webservices, something you will very likely do many times during your career. Also about some of the new machine learning model api's that will begin showing up more and more in our day to day work.
For me I don't think going down to sql bare metal makes sense unless there is a specific reason either for something performance critical or something not easily translated into the linq syntax. When I've looked at Entity framework it always seemed much slower especially startup times. I was hoping Entity framework core would be the best migration path however it seems to do too much in memory and doesn't translate as much down to sql. So I don't really care about linq2sql's change tracking and I would like better enum support like entity framework, fast performance and still using linq syntax and so far linq2db is the only one I've found and it seems be in active development over several years.
Also I just checked it's been being work on for at least 5 years :)
I hear you. It's always a trade-off, right? Nothing will be perfect. I certainly agree with you that EF Core can sneakily push some operations into memory (had to dig into one just a couple days ago, in fact, and noticed it also appeared to be adding additional columns to my order by clause.. ??). EF's not free from it's share of warts and surprises. The promises of change tracking often don't pan out as smoothly as marketing would have you believe. A lot of times I'll just use a micro orm like NPoco or Dapper along with a Sql builder helper with a bit of fluent interface and a set of T4 templates to generate schema classes to use with string interpolation so I 1. know exactly what SQL is going to the DB and don't have to step through half the queries I write just to verify what the ORM is translating to and 2. still get the compiler to help catch changes to schema that get missed if you put it all inside strings. But I also much prefer c#, IQueryable extensions, and even LINQ syntax. Some of the richer ORM features are helpful in some situations. And I'd say EF is pretty flexible these days and can be used more like you'd use a lower level db library if you want. I've just seen the inbetween-ish options - even larger ones supported by companies - end up not doing either end, or any part, of the spectrum well. Lightspeed, LLBLGen, Telerik, Component One, SubSonic.. there's probably another one or two I'm forgetting but have worked on projects using. They've all left me painted into a corner and swearing often, ugh wish this was just SQL. 
I'm not trying to argue or anything, not saying linq2db is really any worse than most else. But as a couterpoint, worked on for a good few years and still a hot steaming pile of crap. https://github.com/subsonic/SubSonic-2.0/commits/master https://github.com/subsonic/SubSonic-3.0/commits/master Have I mentioned I really don't like SubSonic haha :) (and really more how it was deeply wound through everything in a project I work on. accessing relationship properties spawning db contexts and firing queries *everywhere*, so many server killing horrible LINQ mistakes made easy [not to absolve the previous project devs of blame, may they all suffer.. mildly]) 
There's things in .net that aren't in the Standard. There are, or will be, things in Core, that aren't in the Standard. If you don't need them, you can and should target Standard. When/if you get into "this can't be done with Standard", you might discover that it can be done (or done better) in one of the other two. At that point, you can use conditional compilation to do stuff only (or differently) on this or that platform. Standard is the smallest common denominator (which sounds small, but isn't :-)).
This is my favorite one: Repository Pattern with C# and Entity Framework, Done Right https://www.youtube.com/watch?v=rtXpYpZdOzM&amp;t=56s
Invest in ASP.NET Core. It is eons better than the classic ASP.NET. It's a good practice to get ahead of the curve.
&gt; Projects targeting frameworks earlier than 4.5 cannot consume a netstandard library. If you're creating a library for public consumption, consider multitargeting a .NET Framework version and a netstandard version. Given that the support for .NET 4.5.0 and .NET 4.5.1 ended over 18 months ago, library authors should not bother about this anymore.
*Topic 1* : ASP.net will offer more opportunities for the next few years. People will move to ASP.net Core, but other than an immediate need for cross platform development/hosting or the speed improvements from Kestrel. There isn't a huge need to port existing ASP.net applications to Core. *Topic 2* : Certifications from Microsoft are $200 per exam. You can get the "Web Applications" cert by doing 2 exams (And there is a large pool to choose from). Ranging from HTML/CSS, to ASP.net, to Azure. These IMO are worth it, but they either get your foot in the door as a grad or allow you to later refresh your knowledge, very rarely will it be a make or break type thing. *Topic 3* : Personally I wouldn't lean to heavily into Sharepoint or Dynamics as you will pigeon hole yourself. You are tied tightly to a particular product and Microsoft shops. If you do general web development, skills are much more transferable. In all honesty, learn ASP.net, MSSQL, HTML/CSS, and general Javascript. Don't push too far in one direction, even with the above. Know what Angular and React is and maybe do a couple of tutorials, but don't pump up your knowledge with them. Even with MSSQL, know how to write queries and have good working knowledge, and this will allow you to transition to Postgres or MYSQL if your job calls for it. I've had a pretty varied career from startups, to enterprise, to contracting, to service/consulting companies. And grads in all of these have just had to fit in where we need them, and it really didn't matter what they did before.
Starting now i would suggest targeting only .net standard and only if you have free time and if there are requests think about targeting other stuff. 
This is a super useful list, thanks! If you have the time, would you mind putting together a version of it for someone going into their 2nd .NET job? The contrast between the two lists could highlight a few things that people should focus on in their first role.
Very useful article indeed! That and the other post I linked in the OP ([this list of resources for staying up to date on C#](https://medium.com/@jakubgarfield/how-to-keep-up-to-date-as-a-c-developer-387bff208158)) are very worthy of a bookmark.
So you would say get the certs if no cost or effort is required (i.e. the employer pays and gives you the time to do them) but no need to go out of your way for them?
Haha, interesting take on Sharepoint. When you say near future, what kind of term do you have in mind?
No. Get the certs/degree if you want to, but get them for sure if you know you’ll ever be applying at companies with gatekeepers. Some people prefer small startups that move fast, and they have a low likelihood of having an HR department - certs/degree only if you want to. Other people like the stability of a big corp. - definitely get certs/degree to get past their HR (and a big corp always has an HR department).
Wasn't aware of the Cognitive services collection, definitely interesting for some potential portfolio projects.
How close to the bleeding edge do you think newer devs should be looking? For example: how much should we be hyped about Steve Sanderson's next Blazor / JavaScript Services demonstration versus just getting to grips with how ASP.NET core makes use of dependency injection, modularity, etc?
Great post, thanks for all the info! Could you say a few words on the major differences in working in those different types/sizes of organisations and how a newer dev might know what suits them best?
Solid advice, many thanks!
ASP.NET Core has been out for a year. It's no longer a bleeding edge. It is though still a forward move. Blazor is still a proof of concept. Good for play only. Wait to play until it's alpha.
Yeah sorry I meant "bleeding edge of what's happening in ASP.NET Core". For example the [JavaScript Services templates](https://github.com/aspnet/JavaScriptServices) are being actively developed by Microsoft as boilerplate for anyone looking to build an ASP.NET Core web app with Angular/React/Knockout on the client side. But they haven't implemented a use case which uses authentication yet, something which a lot of SPA's will probably need, so they're not exactly fully featured. Using this example, should newer devs be working with and aware of the changes to tooling like this, or are they better off focusing on the fundamentals of ASP.NET Core?
It really depends what suits you and how you want to work. *Startups:* Suits you if you like winging it. Learning new tech. Being in the deep end. Can handle imposter syndrome well (Cause you will always be working on something you have no idea about). Usually longer hours. Hard to "phone it in". Depending on the size, will also do Agile/Scrum and all the other stuff you read about on Hacker News. Can be pretty unstable work wise. *Enterprise:* Suits you if you like getting good at one thing. Usually pretty process heavy. Slow moving. Very rarely will feel imposter syndrome as things rarely will "rely" on you. Can phone it in every now and again so good if you have a family or other things that interest you. Depending on the company will pay pretty well and good if you want to move out of dev into something else like management etc. Will typically have something for someone. Typically tech will be all in one stack. *Contracting:* Can only speak for contracting in New Zealand. NOT to be confused with freelancing. Get paid by the hour. Usually because you are an expert in your field. Sole trader so no one to rely on. Usually end up in roles that you wouldn't normally take if you were fulltime, but you just do it cause they pay well. You usually have zero control over what you are working on, how you do it, or how the company works (Always exceptions). Suits people that money is number one OR, like me, you want to try a bunch of different things, methodologies, types of companies. But again, usually can only start contracting after 5+ years. *Service Companies:* Bespoke development is usually pretty waterfall. Your company will be quoting on a final solution so you usually have to stick to it. You typically don't end up doing things like automated testing or using scrum as end clients don't want to pay for it (But I'm trying to change that in my company :) ). A lot of people typically start here because you end up working on a tonne of different stuff since your company will typically quote on anything and everything. Good if you just enjoy cutting code and don't worry too much about what Hacker News tells you to care about. That's basically it. Your mileage may vary. I went something like... * 1 year Service Company * 3 years Enterprise * 2 Years Startup 1 * 1.5 Years Startup 2 * 1 year contracting * Now back to services Basically, don't read too much into it. The worst thing you can do is read Hacker News or what's trending on Medium and think you aren't doing shit. As long as you are learning SOMETHING, you are doing the right thing. 
Fantastic post! Exactly what I had in mind. Personally I'm coming at software development as a new career after several years in the workforce, and I feel like this kind of info isn't really emphasized enough for new people joining the job market. The type and culture of the company you join can have a huge impact on your job satisfaction, regardless of any other factors.
I do the same (using Dapper) though I'm tempted to give EF7 a try as I've heard it's a lot lighter than previous versions with much better performance.
&gt; RegisterClientScriptBlock *hyperventilates*
The sad reality of enterprise development is that I have a customer on 4.5.1 for a new application being deployed on the upcoming months, not even an upgrade to 4.5.2 is possible.
Start with the fundamentals (middleware, logging, configuration, etc) then move up to ASP.NET MVC Core. 
When will we get a powerful enough auto-complete feature like zsh...
.net 3.5 is still supported :) 
Don't know Twain but fix this itch: Twain tw = new Twain(); and Twain tw = new Twain(new WinFormsWindowMessageHook(new System.Windows.Forms.Form()));