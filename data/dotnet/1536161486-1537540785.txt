I personally recommend people against using the so-called "Disposable pattern". The reason is that it's more work and almost no one will ever need an unmanaged unsafe resource that needs finalization. In case they do, of course it'll be a problem subclassing this particular class, perhaps, but that's not so popular these days anyway, with composition being favoured.
&gt;Right, but figuring out multi targeting, inclusion of native libraries to wrap, The problem is when i make a new class i can't work with this class when i compile it to a dll
Hey [cryo](https://www.reddit.com/user/cryo), when talking or writing about such internal concepts it's often said to be "not that important these days". There are a lot of helpers or high-level concepts that have changed over the last years. I've seen very few times in production that someone explicitly implements the dispose pattern, but I think it's good to know and understand these concepts "in case" you need it or use it (you should know how it works). Anyway, there are a lot of 'yes and nos' on using dispose and its elements here: [https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/dispose-pattern](https://docs.microsoft.com/en-us/dotnet/standard/design-guidelines/dispose-pattern)
Thnx
Not sure if it was connected but my Azure portal was just wacky. It wouldn't give me my subscription charges, it wasn't getting the system usage details from my virtual machine, etc.
Yes, but you still need to set up the diagnostic trace listener to catch the results of that.
I just run DebugView on the server 😄
Is AvalonDock Free?
I would say definitely start applying already. You already have experience as a dev! You won't have any issues learning the stack on the job.
Is this a .NET Core app or .NET Fx app?
Is this a .NET Core app or .NET Fx app?
Ah ok. So basically it self hosts using kestrel.
In this case I would recommend you try out Akka.net and see how it fits! There's definitely something to be said for initial low-effort PoCs for various technologies. Set up a small demo, see what you like/dislike about the pattern (or individual library), and go from there!
It's the old .net. It turns out it didn't like running in a powershell window from a shared network folder. If you remote in and run it locally, it works. Not sure what's up with that. But it's not a problem now.
I'd look into caspol which lets you make dotnet trust network shares, which it doesn't by default probably for decent reason's
I work on a pretty large application that heavily depends on EF. The main benefit is: composable queries. You may create a notion that's expressed as IQueryable&lt;T&gt; and reuse it in many places. The main benefit you gain is code reusability and at the same time you avoid strings concatenation while building SQL queries. On the one hand, it's very easy to build a complex query (from business logic perspective) reusing existing IQueryable&lt;T&gt;s, on the other hand, you may get a cumbersome "heavy" query that's not sargable (sargable query means: it effectively uses indexes to get a result) and produces a pretty nasty query plan. From my experience, it's never been a big deal, you just need to automate DB monitoring using appropriate tools (e.g. Query Store in SQL Server) and fix queries as soon as they start making problems. However, you pay some performance penalties and may get a huge portion of allocation objects that may create additional pressure for GC. Sometime ago we had a query that generated more 78mb of memory traffic just to build a sql statement. So, as you can see, if you go forward with ORM, then profilers (performance, memory, sql profiler etc.) should become your daily tools. It turned out, a developer that works with EF and has a flexibility of IQueryable by hand is tempted to forget about thorough DB schema design in favor to just derive/create a new one or reuse an existing one. Sometimes EF helps in RAD, however it may create performance problems and cumbersome DB design in a long run.
thank you, wonderful reading
Will do :)
Look at using Polly -&gt; [https://github.com/App-vNext/Polly](https://github.com/App-vNext/Polly) &amp;#x200B; Just integrate with MailKit (as an example)
This feels like bullshit to me
Yep, I don't know what a database schema would look like for a 2D array, but i was hoping that EF knew! :) I guess not though - I just wound up making it an `ISet&lt;Tile&gt;` and stored the X and Y coordinates in the `Tile` class itself.
Yes
I don't believe that SQL server supports multiple cascade paths. Do you have two entities with the same parent entity?
https://contests.smoothterminal.com/?ks_giveaway=win-a-copy-of-get-programming-with-f-sharp&amp;lucky=1050
I was on 4 different projects that used EF in production.
I'm completely unable to reproduce this so you've either got a buggy installation or have omitted the crucial piece of code. What happens if you remove the style but set the grid's background directly? How about if you apply the black background to the window instead of the grid?
If I set the grid's background directly, it works. If I change the style to: &lt;Style TargetType="{x:Type Window}"&gt; &lt;Setter Property="Background" Value="Black"/&gt; &lt;/Style&gt; then the background is still white, maybe I applied it to the window wrong?
Windows are kinda unique in that a lot of their properties can't be styled - they have to be set directly. So directly setting the grid's background works but styling it in app.xaml fails. You are placing the Style element within the Application.Resources element, correct? What happens if you move the style to Window.Resources? Like so: &lt;Window x:Class="..."&gt; &lt;Window.Resources&gt; &lt;Style TargetType="{x:Type Grid}"&gt; ...
Logging isn't a trivial exercise though. Writing unreadable custom garbage to files or tables is trivial, but that's not logging. 
How many loggers have you written in your career? 
Yes, the style is in Application.Resources. If I put it in Window.Resources, it works and the controls don't disappear.
Hmm. I'm at a loss then. Based only on the code you've posted, it shouldn't matter where the grid style is placed.
It is appropriate in some cases, but it is not the best framework available in most cases. More developers should adopt Dapper. It’s faster and way simpler to use.
Cookies work on localhost. The probable issue is that you have a cookie that was set in http but you are now trying to authenticate in https. The browser rejects it but it's silent. The solution is to either use https in the URL, or remove the current cookie you have from the browser. Source: I work into the ASP.NET team on Orchard and I see that happening all the time ;)
Oh, and the fact that adding a domain fixed it is another proof for my explanation. The http cookie now doesn't conflict with the https one because there is none for this domain.
Oh, and the fact that adding a domain fixed it is another proof for my explanation. The http cookie now doesn't conflict with the https one because there is none for this domain.
.NET Core is trending. But do good .NET Core job interview questions exist? Share with us what questions you heard/use.
Then you really need to try. Even if you never actually use it in production, the skills necessary for a longer are applicable to a wide variety of server side scenarios. Do you at least know how to stream concurrently written data to a file for later processing? 
It doesn't have to be Dapper. It just has to work with the database rather than in spite of it.
Probably stating the obvious here, but you let EF Core create the database tables right? Not reverse engineered an existing database?
Thanks for the downvotes, but that doesn't change the fact that EF has some inconsistent behavior when it comes to deleting records. 
Thank you, it helped me to better understand this topic! 
I think you should use something like Hangfire jobs server. It allows to automatically retry jobs if they fail, and it can be hosted in an ASP.NET application.
That's the main goal of my posts, thanks [SvartAlf93](https://www.reddit.com/user/SvartAlf93) !
Is there a way you can do it all in memory and take disk access out of the equation? I think that would be your first step. 
I'm not sure if disk access is really the bottle neck with SSDs. From what a quick web search showed me they are supposedly somewhere around 50% to 80% faster but only when moving big files. I don't have access to a machine with sufficient RAM to try. But it's an interesting idea.
Very nice. Thanks!
Figured ill post here to see if anyone has had any similar issues? &amp;#x200B; The application does nothing else than bind a string to the textbox, and as soon as ill switch to Chinese/Taiwanese it stops updating the bound property when i enter text.
After losing a bunch of data because of cascading deletes, we now categorically disable it in projects. 
We disable cascade deletes in EF and do it by hand.
Probably not. I have a Dell rack server in the garage and I have it setup as a node with ncrunch so there's no need to compile most of the time. 
How do you feel about Central NC? We're hiring full stack .net devs to help build a modern platform on .net core, and tablet apps on xamarin.
From personal experience, there are lots of .NET jobs in Atlanta. When I was applying for jobs I seemed like it was almost a 50/50 split between Java and .NET jobs.
I found a workaround: put the resources in a ResourceDictionary and reference that ResourceDictionary from Window.Resources.
Columbus and Detroit are good .NET markets, and lower cost than Chicago. 
Pretty much every medium to large metro area in the USA is going to have .NET jobs.
except for the bay area from my experience 
Bay area cool kids think .NET is lame af
I’ve seen quite a few job posts for .NET jobs for Tesla in bay area...
What if I'm using ASP.NET 4.7 and not CORE?
Does this help? https://enable-cors.org/server_aspnet.html
For the two options you mention: Skip straight to mvc - without a doubt!
WebForms is really not where you want to be at this point. Go with MVC or Razor Views.
Serious questions - do you have a hard filling those roles? I ask because I wouldn't never move to NC due to their jacked up local politics.
When you loaded the game, did you Include the dependants that would deleted as well? EF Core needs this to be loaded as well. 
Lately, yeah
Very useful, thanks. :)
I think you can find some cities with better cost of living to salary ratios than Chicago (at least, depending on how much of a commute you want/what sort of house/apartment you want) but I don't think you'll find a city with a lot more job openings than Chicago. &amp;#x200B; If you are thinking about staying in Chicago and would be interested in work as a .net developer/consultant PM me (not a recruiter or even an employee, but I used to work at a great company that I know is actively hiring at a bunch of different levels)
Outside of what's right to learn in .Net specifically MVC is still the way to go. The pattern itself is very common with concepts like; templating engines for views, Controllers, Models and middleware which are common across many frameworks. Rather than having to learn a whole new paradigm you could go pick up ExpressJs and only have to worry about "Whats the syntax to add middleware?". If you use [ASP.Net](https://ASP.Net) Core it also crams dependency injection down your throat which once it clicks is another highly useful skill that can be used anywhere.
Yeah, it's getting really bad. And I've got head hunters knocking down my door trying to pull me away from my current company too. Sadly we still haven't had much luck pushing management to allowing 100% remote, yet. Job market stays like this I might be able to push them to it, lol
**Web Forms suck**, and will likely just confuse you about "how the web actually works". It abstracts away all integral parts about the HTTP protocol, HTML, *and JavaScript*, and tries to make the web behave like windows form apps, and it doesn't do it remotely well either! Instead learn the basics of the HTTP protocol and learn HTML (if you don't already know it). It will make everything *much easier* once you start adapting frameworks which build upon these standards. MVC is just just a popular design pattern, it's a tool for solving problems, it doesn't have anything to do with "the web" *per se*. MVC also abstracts away some pretty "important" parts about "how the web works", but it stays more "true" to the actual standards. May I suggest using ASP.NET Core as well. It's open source, cross-platform, and generally pretty damned good. https://github.com/aspnet
LOL &amp;#x200B; WebForms is both harder and less productive than MVC. MVC works like the internet, WebForms tries to be stateful in a stateless environment. And fails.
MVC, WebAPI, and Razor Pages are the way to go right now.
You could also take a look at other web frameworks like React or Angular
Thanks I'd really appreciate it! &amp;#x200B; I just started coding 2 years ago with AutoHotKey. 7 months ago I started learning powershell, xml, html, JS, vbscript, php, and some proprietary stuff from my vendor within the last 7 months. lol It's a bit much to teach myself all at the same time, I wish I had the time to focus on them one at a time.
When MVC1 came out, I took a look at WebForms. After dabbling with it for a couple weeks, I tried MVC and realized there was no comparison. I went straight to MVC and never looked back.
https://github.com/SixLabors 
Checking it out now. Thanks!
Thank you all for you comments and advice. Since literally no one stood up for Web Forms I see whats the right way to start. In addition, I am also considering to learn some javascript (and front-end frameworks) in parallel since many of you suggested so.
mvc is a good start to get your head around .net, once you do that. try to build the same app again but use a front end frame work (react/vue.js/angular6+) make the front end just make requests to web api to get / put / post / delete the data.
Just get started here: https://docs.microsoft.com/en-us/aspnet/core/tutorials/?view=aspnetcore-2.1 
If you take one dumb request they will never end, put your foot down now.
I am currently using [ASP.NET](https://ASP.NET) and Angular, but I think the situation is similar compared to Vue. Is your back-end purely an API? Then I would suggest to keep your projects completely separated and use the Vue CLI. &amp;#x200B; My setup is like this: Whenever I build my Web API, NSwag is triggered which generates all the Typescript code for handling all communication to and from the API. It generates the models, HTTP calls, etc. The generated files are pasted into my Angular project and VS Code automatically understands my models have changed so I can use IntelliSense with the newly generated models. Whenever I build my Angular project, it gets copied to the wwwroot of my Web API project. Works perfectly :) 
Honestly, out of the two choices neither. API development with a frontend client is far better. However, if you really want to do it all server side then MVC.
This is not a critique against MVC, I think the abstraction level is "just right", but it does abstract away som stuff, for instance: - Automatic request body serialisation (e.g. JSON or XML to POCO) - Magic form-binding - Automatic route handling and parsing - (Razor specific) HTML helpers, e.g. `Html.TextBoxFor`, which feel like magic, if you never look at the output of it generates There is of course more, less obvious stuff as well. Again, this is not a bad thing, but it's good to actually learn how to do these things work as well.
&gt;If you deploy this site to somewhere like azure, would you need two different app services sites? one for the API and one for the front end? No, since my Angular application is hosted as a static site under the API's wwwroot. &amp;#x200B; During development, I do use two separate processes: Back-end is hosted using 'dotnet watch' or Visual Studio debugging or whatever. Front-end using 'ng serve'. Keep in mind that you will need to enable CORS in your backend in development mode.
Within [ASP.NET](https://ASP.NET) I would choose MVC
Nice, might give this a shot with vue 
Coupling makes sense when you do code generation like @Barmyard described. I usually host my API on AppService. SPA can be served from Storage Account with CDN. To this is easier when you have separate projects. 
Not really weird. Enterprise customers (e.g. banks, government) do that all the time. You can also charge them a lot of money for it.
i was thinkking about it and yeah that sounds like the best approach
Focus on making an API with a frontend client.
Time for OP to rake in the money then
https://marketplace.visualstudio.com/items?itemName=visualstudioclient.MicrosoftVisualStudio2017InstallerProjects This was very easy to use and got the job done when I had a similar use case. Or you could script it in PowerShell and wrap the whole thing in an EXE. I made a tool to do that a while back. https://lucency.co/Apps?app=Make-EXE
Try https://www.nuget.org/packages/System.Drawing.Common/ which is compatible with .NETStandard 2.0
In fact, I know of one right now paying a looooooot for a Wix install of a zip file because they wanted MSI silent installs
In fact, I know of one right now paying a looooooot for a Wix install of a zip file because they wanted MSI silent installs
 app.UseCors("AllowAll"); This is nothing to be afraid of.
Same with AWS; api on Lambda via API Gateway, static content served from an S3 bucket.
This person knows. No shit! 😉 
I don't recommend it after using it. I use Vue.
It takes some time but yes. Azure cdn has rest API. 
Maybe for development, but that basically defeats the purpose and opens yourself up to xss attacks. 
2 projects in the same solution.
You can publish to a folder. I have one project where we can't publish directly to the server, so I just publish to a local folder then copy it to the server.
Thanks for the response guys. I cannot argue with my client right now. So there was no other option. Luckily, I came across a tool which does exactly what I want, "Advance Installer". I hope anyone else know of such tools. Sorry for my English.
There is no single answer for this. Look at the job market in your area. Check out [indeed.com](https://indeed.com) and [monster.com](https://monster.com) and look for .net jobs in your zip. See what they are looking for. Personally, I suggest you learn the core. Know the core. Learn C#, SQL, HTML, CSS and JavaScript. Once you know the core, learn TypeScript. After that do [ASP.Net](https://ASP.Net) core videos and build a traditional web application. After all of that pick a SPA framework that is popular in your zipcode and learn that. Good luck.
Aha, that fixed it - thanks! :D
No problem. I'm currently reading EF Core in Action and it mentions this. This aspect doesn't seems intuitive so it kind of stuck with me. Basically any action on a aggregate and you have to pull the whole aggregate. 
I've been gearing up to do this myself. I plan on keeping Vue and .Net Core completely seperate. Going to develop the back end and APIs first and then start on the Vue client. 
https://security.stackexchange.com/questions/108835/how-does-cors-prevent-xss &gt; TL;DR: How does CORS prevent XSS? It does not. It is not meant to do so. 
NSwag looks really cool. I am almost done with the API of a side project I have been working on and was considering using Vue (since I am using it at work currently) but this might make we make the web layer using Angular this go around.
Also, consider learning Docker. 
Thanks a lot! Do you recommend jumping into Typescript even if I'll be using React? And in general, would it be better to get a full understanding of Javascript before using Typescript?
Think of using a VM. With a VM, you have to emulate all the hardware and software that goes with the OS. With docker, all that is thrown out and what remains are only the specific software parts that you require for your application. In other words, it puts virtualization in overdrive and makes it way more efficient. Plus, it's cross-platform so you can literally take one image and run it on different platforms. It doesn't matter whether you built it for Windows or Linux, it will run either way.
What's your opinion on React? I've only experimented with it a bit, but I like it so far. I'd really like to create a dynamic SPA consuming an API. React seemed better than Angular for this, maybe that's not right tbough. But what about Vue? How does it hold up when it comes to SPAs? Thanks :) 
For the love of God, no! Stay away from WebForms if you would like to learn how the Web really behaves. 
Oh, I think I get it. Thank you. So you would be able to create an image of an environment that runs your web server, and then be able to easily spin that up on any machine? Without having to configure everything manually and worrying about dependencies, libraries, etc. not being installed?
Yes, exactly. You just put those dependencies into your image together with your application, nothing else (well, it could be the case that you still need to add web servers, if your application depends on them, but I haven't yet dug into Docker deep enough to figure that one out). Then you use Docker on the target machine to run your image and it all magically works! :)
Good questions. I love TypeScript and don’t really like coding JavaScript anymore. However, it really is up to you. Also, I don’t know what your current education/ work history is but I started as a software support specialist before I became a developer. Good luck.
WinForms, WPF or Universal App? If they are going to be a kiosk, you'll find that buttons/data grids actually will be the most useful for you - just use the version of whatever framework you're building in. This is just regular [guidelines](https://docs.microsoft.com/en-us/windows/desktop/uxguide/inter-touch), but are very useful.
So, I have used both Angular and ReactJs. I consider myself a beginner at both. From a beginners perspective Angular seems better initially. But as I get more and more into it I am leaning more and more to React. I have made a few small applications in both. But am now building a larger application in ReactJS and I plan on sticking with it going forward for anything else I build. My problem with Angular is that there is too much baked in functionality. This seems nice at first as you are reading through examples. Oh, that is easy. Cool. But as you start doing more difficult things it gets a bit more difficult. I end up spending more time trying to figure out how to do things the angular way versus just doing them in React. So for me React is easy because you just need to understand concept. Components, props, state, and events. Once you understand how to use those you can do quite a bit. Again, this is from a beginners perspective. I have only written a few smaller apps in each. 
i bought asphostportal plan, they don’t have web deploy option. how did you deploy your asp.net core project?
If you enjoy C# then you will enjoy Angular more because Angular uses Typescript which is very similar to C#. You *can* use typescript with React but it's not what most people are doing so examples will be hard to come by and it will be more time consuming getting it setup correctly.
Dock is a GREAT technology and every company *should* be using it. That being said, most are not and any that do won't have it as a requirement for the job. It will just be an 'added benefit' to getting a job or a shiny note on the resume. In my opinion. When you are learning a new framework like dotnet core and a new framework like React/Angular at the same time... it's best not to get bogged down with a 3rd technology. You will very quickly end up in the weeds.
I live in Kansas City, there's a pretty strong demand for .NET devs here.
&gt; WinForms, WPF or Universal App? WinForms preferably but I could certainly do WPF if it will make the UI better. I don't have many plans for swiping (other than the signature, I suppose). The user is basically clicking through 2 sets of YES/NO buttons and then signing with a button to print and a button to cancel at the end. I have had trouble in the past sizing and formatting the WinForms datagrids, I guess that is what I was most worried about. Also, maybe it is shallow of me but I really don't want this looking like a 90s application. That is fine for our internal WinForms-based inventory management software but I want to present the end-users of the kiosk with something a bit more modern.
i wasnt asking about how to structure vue, i was just expressing my views of vue, right or wrong. im talking about the .net project structure. dunning kruger? i dont think you know what that even means and it doesnt even apply to my post. woosh
Try wpf with mahapps then
The fact that you don't realize Dunning-Kruger applies here just reinforces the fact that it DOES apply. By its very definition you wouldn't realize you were experiencing it. You just don't know what you don't know. You've some cool-guy programmer you look up to say that opinionated frameworks are bad, but you don't have the experience to know how to use a framework that isn't opinionated, so you come here asking for opinions on how to use it. &amp;#x200B;
In this case, I do believe WPF may be the better way to go (from my experience) - it will be more modern, has DPI scaling, and there are some good libraries for it. 
Web forms is awful. It has been since it came out years ago. Don't waste your time unless you have to for work. MVC or razor pages are the way to go. I would also recommend going down the Core route as it's going to become the standard soon enough.
Question: Is it industry standard to have JS mixed with C# and ASP? I'm finding there are only some ways to do things in ASP using JS. Also, because I decided to use webforms after reading an article "Webforms Ain't Dead Just Yet!" I am using session variables in lieu of cookies...and finding online that session variables are not ideal. For querying a DB, IDK any other way from page to page. tldr; I have a lot of questions apparently!
This is true, but at most jobs you will still probably have to work with JavaScript at some point.
here's the appveyor.yml for my little SPA site that's running on a azure storage account with cloudflare in front. https://github.com/phil-scott-78/showplan.js/blob/master/appveyor.yml 
and here's a .travis.yml that pushes to AWS S3 and Lambda: https://github.com/qccoders/QCVOC/blob/master/.travis.yml 
What Angular features are you finding frustrating? There's no doubt that it's a complicated framework, but honestly I get way more done with it that I have with comparable frameworks in the past and I've worked with quite a few. And a tip: When you search for Angular issues online, start your search with something like this: angular -angularjs my question goes here I have even made this into a browser search shortcut in Chrome. To do this, go to Settings, then Search engine, then click on Manage search engines, click Add. Then add a "new" search engine with these fields: Search engine: Google - Angular Search Keyword: a URL: {google:baseURL}search?q=angular -angularjs %s Now when you're typing your URL in Chrome, you just type 'a', then hit space and put your search term in and hit enter. Voila! Now you have an actual Angular search that (probably) has nothing to do with AngularJS.
Definetly go straight into MVC. That's what I did and I haven't looked back. 
I'll definitely start looking in NC then. I have a good amount of experince in .Net and i'm learning Xamarin now. 
geez like a dog with a bone u are, i was asking about api and vue structure NOT how to use vue. if anything if you cant understand this simple concept from reading my post i think dunning kruger applies to you, here is the definition since you obviously dont know what it means &gt; In the field of psychology, the Dunning–Kruger effect is a cognitive bias in which people of low ability have illusory superiority and mistakenly assess their cognitive ability as greater than it is. The cognitive bias of illusory superiority comes from the inability of low-ability people to recognize their lack of ability; without the self-awareness of metacognition, low-ability people cannot objectively evaluate their actual competence or incompetence.[1] On the other hand, people of high ability incorrectly assume that tasks that are easy for them are also easy for other people i dont usually bite back with trolls, so eh reply with wateva u want i really dont care what u think of me, its kinda pathetic this is how u spend ur life on reddit
&gt;Should I first start and get comfortable with asp net (web forms) You can I suppose, but 1. Its probably not a good idea to start new projects in WebForms. Its more or less depricated by MS. 2. WebForm jobs still exist - usually to maintain an older website full of unwieldy spaghetti code. Sometimes the jobs are to migrate older WebForm sites to new MVC. 3. WebForms was dumped because it can have lots of problems and lead to a real shit storm of messy, unmanageable, untestable code. I personally have come to hate working with it. 4. MVC is more like 'real web'. Its more like simple html, css, and javascript except that there's a server side component in c#. WebForms is more or less a 'Visual Basic', drag and drop components style of building a 'website'. At the time it was released, VB was all the rage with its simplicity of just dropping components onto a blank form, and then just wiring them up to code. WebForms took the VB approach and tried to make it work with the web. The problem is this resulted in horrible html, and just quirky, bad things that were just too damn difficult to fix. Sure it was easy to simply throw a few web grids on a page and populate them with a query to a DB. But as soon as the client said "I want this blue instead of green" or something like that, it became a nightmare of wrestling with a huge beast that DID NOT WANT TO CHANGE. 
Wait a sec. First you asked &gt; Vue.js and asp.net core. what project structure is do you recommended? Right there you're asking about the project structure explicitly. Then you say &gt; i wasnt asking about how to structure vue But now you're not asking about how to structure your Vue project. Ok. But now &gt; i was asking about api and vue structure Oh, that clears it right up. After reading that nonsense and seeing how you struggle with spelling and grammar I remain unconvinced that you know that you're talking about. Aren't you also using Reddit? Doesn't seem like accusing me of doing something you yourself are also doing is an effective insult. 
I develop web sites and apps using C#, professionally. I use JS all the time, but only for UI purposes. Nothing mission critical is operating on JS. That said, JS errors can cause critical problems in an app by preventing critical features from being activated. 
i havent used NSwag before, ill check it out, sounds very useful in my other projects. do u have a github with a project? hmm u think the situation is similar to vue. when i said i struggled with angualr 2+. well once i got it, it was easy, but component bindings i find harder in angular 2+ than angularjs. its also a much larger framework. i have to do server side rendering atm, but i got bored and decided to do something else. i wanted to try out vue as its all the hype now, it looks more intuitive just on the hello world examples. but angular 2+ looked pretty straight forward on the tour of heros app. its whne u have to build something a bit more complex is when the pain comes in.
hmm CDN to serve the spa, ive seen people do that, makes sense.
Thanks for this message. It’s was very helpful for me. 
My day has been a little hectic - woke up very late, my apologies. After doing some homework and getting a captcha for my site, I found this stackoverflow example which makes perfect sense but working on a 'working example' for you (i need one myself anyway, so i'm doing this). However, it's drinkin time so i'll likely finish this over the weekend while not coding for $. When I'm done, i'll post on my github for ya but review this for some overview... [https://stackoverflow.com/questions/27764692/validating-recaptcha-2-no-captcha-recaptcha-in-asp-nets-server-side#27767239](https://stackoverflow.com/questions/27764692/validating-recaptcha-2-no-captcha-recaptcha-in-asp-nets-server-side#27767239)
Webforms is a good thing to know, but if you have a choice, I would choose to use MVC, even to start out. But you should still learn Webforms just to know how a Configuration-over-convention framework operates. MVC crosses that line into things that happen "automagically" meaning if you don't dig deep, you won't know why things just "work" when you put things in certain places, or how to change the way they work. In my opinion, Webforms are pretty easy to learn compared to MVC, but they are fundamentally different, so learning one won't necessarily help you with the other, it'll just be good practice to know the different ways you might go about things. Don't forget that another option is to forgo a link between C# and your frontend entirely, and use a Javascript framework (I recommend knockout, but it's all personal preference). Then, all of your calls to the server will be to an API, which is easy enough to maintain as MVC, but clearer in function.
Go for Vue 
I suggest you to have a look also at ZetExcel, its really helpful!
If you've got budget, most of the major component vendors (Infragistics, DevExpress, etc) have "touchified" their components.
WPF is the way to go. 
\^this even with UWP I would use one of the above components because they offer more functionality, but yeah at the very minimum I would use wpf and one of those components 
If you're already go WPF route take a look at UWP. They have very touch friendly infrastructure. Also Win10 supports UWP as a kiosk app natively (no need to worry about making app fullscreen and all that)
I agree with the people saying START WITH THE CORE SKILLS. They will be the foundation to learning anything your next job requires. C# SQL HTML CSS JavaScript HTTP These are the core technologies the whole internet runs on, no matter the web application And if they use a fancy framework the tech underpinning it will be one of these. The concepts are always the same. As a start C# .net MVC (Either Core or 5.x is fine) will combine all of the above skills. There are many resources for learning it such as msdn, ms academy, pluralsight etc. As you use .net mvc it will naturally introduce you to things such as linq, Entity Framework ORM, the MVC design pattern, Dependency Injection and many other concepts that can be adapted for learning any other flavour of the month framework. This month it's react, not long ago it was angular. It just a scripting language underneath ;-). Remember, the most important thing is the theory behind what you are learning, the framework itself is unimportant to securing a job because syntax can be adjusted easily. This is very important for anyone just starting out. Junior positions come with the caveat you know the core skills, in exchange for being taught what they need you to learn through experience. 
Go WPF and look at the [Material Design in XAML](http://materialdesigninxaml.net) project - which makes things very touch friendly out of the box.
Hmm sounds like a job for middleware 
You have to have a strong foundation on algorithms and problem solving first. Then C# is a good language for a start, because .NET Core and .NET uses it. Then you learn Entity Framework Core, and how to play around with data to get what the application needs. Understand MVVM (which is what .NET Core razor pages is about), and MVC for .NET. Angular is basically just advanced Javascript which the entire front-end can be built on. So it's the UX/Routing part and of course you can build an entire application with it alone. The gist is problem solving, and language independent &amp; platform independent brain-power. So if tomorrow D++ comes along, you can learn it and use it together with existing technologies, Fast. So Fast, other deejays say dayuuuuuuuuuuuuuuuuuuuuuuuuuuuuuum.
UWP will be the fastest for a decent UI. WPF will require third party libraries or manual XAML coding to look modern. Otherwise, it'll look just like a WinForms app out of the box.
Even if you had the code under one repo, you could deploy independently with VSTS CI to 2 different app services. No additional cost provided they share the same app service plan.
I, for some reason, have a blind spot around Polly. I read the github description, see the examples, but still have a hard time wrapping my head around workflow and what thread the retries run on. Have a good example app by chance?
I, for some reason, have a blind spot around Polly. I read the github description, see the examples, but still have a hard time wrapping my head around workflow and what thread the retries run on. Have a good example app by chance?
I, for some reason, have a blind spot around Polly. I read the github description, see the examples, but still have a hard time wrapping my head around workflow and what thread the retries run on. Have a good example app by chance?
I, for some reason, have a blind spot around Polly. I read the github description, see the examples, but still have a hard time wrapping my head around workflow and what thread the retries run on. Have a good example app by chance?
I very much agree with all of your post except &gt;You have to have a strong foundation on algorithms In my 10+ years of mainly backend development, I think I can count on one hand the amount of times I needed to put effort into designing an algorithm. Ok, SQL requires you to put some thought into optimizing statements, but I wouldn't call it "algorithms" as thaught in the university courses. Design patterns/software architecture however, those are daily "tools" I use.
I very much agree with all of your post except &gt;You have to have a strong foundation on algorithms In my 10+ years of mainly backend development, I think I can count on one hand the amount of times I needed to put effort into designing an algorithm. Ok, SQL requires you to put some thought into optimizing statements, but I wouldn't call it "algorithms" as thaught in the university courses. Design patterns/software architecture however, those are daily "tools" I use.
Xmldocument is worthless for files that large, xmlreader is the way to go in general. You might want to use xml serialization, which uses xmlreader behind the scenes, but is much easier to work with overall.
Xmldocument is worthless for files that large, xmlreader is the way to go in general. You might want to use xml serialization, which uses xmlreader behind the scenes, but is much easier to work with overall.
XmlReader is the best for you if you just need to read it. If you need to do xpath or something like that, it gets much more complicated
XmlReader is the best for you if you just need to read it. If you need to do xpath or something like that, it gets much more complicated 
[XNode.Read maybe?](https://docs.microsoft.com/en-us/dotnet/api/system.xml.linq.xnode.readfrom?redirectedfrom=MSDN&amp;view=netframework-4.7.2#System_Xml_Linq_XNode_ReadFrom_System_Xml_XmlReader_)
XDocument &amp;#x200B; ...but obviously depends what you're trying to do
At 50 GB, you're gonna run into issues because that's not how XML is supposed to be used. Maybe there are custom libs for something like that?
Perfect answer... The only thing I could add is use visual studio code for vue and visual studio for the api.. enable cors on the api for debugging. You could also get vue to compile into the wwwroot when doing a build?
**Simple API for XML** SAX (Simple API for XML) is an event-driven online algorithm for parsing XML documents, with an API developed by the XML-DEV mailing list. SAX provides a mechanism for reading data from an XML document that is an alternative to that provided by the Document Object Model (DOM). Where the DOM operates on the document as a whole, i.e. building the full AST of an XML document for convenience of the user, SAX parsers operate on each piece of the XML document sequentially, issuing parsing events while making single pass through the input stream. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Seriously? You’re not getting 50GB of XML into Xdocument. 
XDocument loads the whole file into memory right? XmlReader streams it, but is forward-only.
Some of these answers are retarded, sorry people are trying to mislead you. Use XDocument, the modern (as far as XML being modern) way to read XML. Use it's load async method with the stream overload. https://docs.microsoft.com/en-us/dotnet/api/system.xml.linq.xdocument.loadasync?view=netcore-2.1#System_Xml_Linq_XDocument_LoadAsync_System_IO_Stream_System_Xml_Linq_LoadOptions_System_Threading_CancellationToken_
You have to sanitize the strings if datetime.tryparse fails. Use regex, string.trim, string.format, string.replace, etc.
Hi Thanks for replying. I have actually sanitized the string, problem is there are random spaces in between the date string. I am not sure how to deal with those spaces.
string.replace and/or string.format?
Dude chill out, it's just some XML!
Maybe. But that XML is not made by me, so I cannot change that aspect. In fact, what I am trying to do is to parse the XML and put it into an SQLite database file, so that I can easily search the data.
i do a lot of data scraping, so sanitisation is right, try to use extension methods to do this if its common otherwise ull need to build a "rule parser engine" basically if it doesnt parse right away, go thru the most common scenarios and go down from there. id grab all possible variants and run them thru some unit testing, makes it easier. im not a TDD guy, but unit tests are useful here. im not a 100% code coverage guy either. just test the complex stuff in the service layer. be pragmatic with your time etc
Thanks a lot! I have solved the issue .
No, you should research your local job market first, it varies massively. Vue is non existent on the job market where I live, angular is king, and react is on the rise. Don't just make a blind decision based on the JavaScript flavour of the month.
I wrote a StreamingXElement class. It’s read only but works really well in the case that it’s your entire document that is too large and each element inside of your document is NOT excessively huge.. it yield returns and I just run it in a foreach loop. I don’t have the implementation in front of me but if this sounds like what you need and you need help with it let me know and I’ll look it up.
You'll want to use a streaming parser for that. SAX was mentioned but I've found STAX to be nicer to use. You might be interested in this open source implementation: https://github.com/FasterXML/aalto-xml
We've all worked with guys like this. Don't challenge him, he knows everything! /s
Thank you for your help.
I have created a console app with two lines of code that loaded a 283MB XML into an XDocument, and the memory consumption was about 1GB (prefer 32bit). 1.3GB for 64bit.
I know this isn’t helpful, but please, do tell... What kind of WTF process created a 50GB xml file? Also can you use some kind of tool to import it into a database? Good luck.
EDIT: my typo... somehow ToLower() got left off. 
The biggest thing to realize is that your data may be wrong. Just because you can beat some characters into something that looks like a date doesn't mean that it's the correct date. Just like the horizontal spacing is off, the vertical can be also and it can pick up numbers that were above or below. 
Posting the codes below for your reference. Credit where it's due: [https://stackoverflow.com/questions/27764692/validating-recaptcha-2-no-captcha-recaptcha-in-asp-nets-server-side#27767239](https://stackoverflow.com/questions/27764692/validating-recaptcha-2-no-captcha-recaptcha-in-asp-nets-server-side#27767239) Follow the code in the above example and then write a starting page to test it. You'll need two keys, one for your site and one for localhost. &lt;%@ Page Language="C#" AutoEventWireup="true" CodeFile="recaptcha.aspx.cs" Inherits="recaptcha_recaptcha" %&gt; &lt;!DOCTYPE html&gt; &lt;html xmlns="http://www.w3.org/1999/xhtml"&gt; &lt;head runat="server"&gt; &lt;title&gt;recaptcha test&lt;/title&gt; &lt;script src='https://www.google.com/recaptcha/api.js'&gt;&lt;/script&gt; &lt;/head&gt; &lt;body&gt; &lt;form id="form1" runat="server" onsubmit="https://www.google.com/recaptcha/api/siteverify" action="./response.aspx"&gt; &lt;%--local host--%&gt; &lt;div id="g-recaptcha" class="g-recaptcha" data-sitekey="[You will need a key where 'localhost' is the sitename for local dev then use the one for your real site when you deploy]"&gt;&lt;/div&gt; &lt;br/&gt; &lt;input type="submit" value="Submit" /&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; In the code behind response page, i simply added some outputs to the browser: if (IsCaptchaValid) { //Valid Request Response.Write("captcha valid"); } else { Response.Write("captcha invalid"); } &amp;#x200B;
I think XmlReader on its own is a better solution.
That's in Java. How is that a useful answer to a .NET question? Also, what makes SAX or STAX better than XmlReader, which is already streaming?
Not even if I use a cloud VM with 1 TB of RAM? :-)
Ah shit, you're right, should've checked the sub I'm in!!!
This person (/u/UndemonstrativeCynic) has no idea what they are talking about and shouldn’t even be allowed near a compiler. His answer is condescending and wrong in nearly every possible way. So wrong in fact that I have to wonder if it’s an intentional troll. 
I mean really if this is a one time conversion spinning up a beast vm may be the way to go with XDocument. 
What version of python is the engine using? And are you sure you're importing all of the right packages in the engine?
That's a terrible way to handle it Maybe programming is not for you? Regex would be much more reliable and easier to code
Wouldn't the existence of such tool need to solve this exact problem?
nice to know thanks
I don’t know.
Certainly a streaming solution like SAX parser. But at 50gb file sizes, you should be looking at either 1. Loading the XML into the database directly and then querying the db 2. Converting the xml into a columnar storage format like Parquet and then doing something like.. storing it in S3 and querying it using Athena (Presto sql engine). 3. Using Spark on a big data cluster to process it My point is that a web thread or a .net app domain is a poor choice to process 50GB of data, especially if the file size will continue to increase. Offload it to a DB or Big Data solution.
How exactly do you use that to parse an XML file?
The parts are perfectly separated. Letters, numbers, comma, numbers. While has letters add to month, while has numbers add to day, while has numbers add to year 
You kind of lost me at 50GB XML file. The first question I would ask if this was my project is: "are you sure it has to be this way?" The second would be "What is the reason this file cannot be smaller?" But, yeah, a SAX parser is what you're looking for.
In a short answer, no. What you wrote is referred to as “method” syntax. What he wrote is called “query” syntax. Whichever you use is a letter of preference but under the hood they do the same thing. 
The interviewer was wrong, both are "LINQ", the second often referred to as "query syntax" vs "method syntax". Which you use is often a matter of taste (personally I prefer the first). &amp;#x200B; Both compile to roughly the same IL.
No. LINQ supports [two different syntaxes](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/query-syntax-and-method-syntax-in-linq). You used the method syntax, they wanted the query syntax. Method syntax is “real” LINQ, in the sense that those methods are how it’s actually implemented. Query syntax is translated into method calls by the compiler. 
Run the other way.
No, he was wrong; both are proper LINQ. Yours was Method Syntax. His was Query Syntax. Same outcome. I agree with the other commenters; do not take a job there.
He was wrong. Both are Linq, one is Method Syntax and one is Query Syntax. There are some additional things you can do in Method but query is sometimes considered more readable depending on the outlook of the development team. I would say he knows little about Linq. &amp;#x200B;
No, he was not. You implemented a query using the method syntax, whilst he implemented a query using the query syntax. Under the hood, both work the same way, but most people (including me) prefer the method syntax as it's cleaner and a requirement if you want to compose more complex queries. 
They way they said it is a certain way to use linq. Personally I prefer the way you did it but both work. But yeah, the interviewer clearly isn't experienced with Linq if he didn't know what I told you. I've only been using C# for about a year.
To people who are saying "don't work there" - the interviewer might have just been wrong. If s/he wasn't a jerk about it, if it seems like a good job, don't let this necessarily put you off. 
can you provide an example of method syntax becoming a requirement for more complex queries? It seems to me that its just preference, but I actually feel that query syntax is a lot more easier to work with in the larger, more complicated queries.
No, he was not "right", he was just being elitist gate keeper: "That isn't Linq! this is". Then goes ahead and writes code in an arcane syntax that everybody has thankfully forgotten at this point. These methods are in the `System.Linq` namespace. If that doesn't constitute it "being Linq", I'm not sure what will. On the flipside, the "old" Linq syntax, is not in "any namespace". So I suppose it's "even less Linq". Like most people have already said: RUN.
Does it matter? If the interviewer says OP's code *wasn't* Linq, when it *clearly is*, the interviewer is either: A) Less experienced than OP, or B) An elitist gate keeper, both of which are *really* bad signs.
I agree with you, in general I prefer method syntax but there is a lot of noise implementing things like joins in comparison to query syntax IMO. At the end of the day it is all down to preference.
Here's my main argument for using method syntax: I can have methods which return incomplete queries that get passed to other methods which append their own additional restrictions or projections on the data. It allows me to think of the query as a chain of discrete operations and not a single monolith.
all of the work i've done in the past 6 months, code looks like the what you did. i haven't used anything that looks like the latter.
Holy shit, AVOID.
"Arcane" lol. While I prefer the method syntax, I really like the query syntax; it's SQL "The Right Way" ie instead of saying "select this" and then forcing the rest of your code to conform to that select, you can instead naturally drill forward into the data and then select whatever that leaves you with.
Agreed. Everybody on this thread acting like they can spot a toxic working environment based on a one-sided recollection of a single question is one of the things I hate about the elitism in this industry. For all we know, the interviewer may have specifically asked for query syntax LINQ. 
 &gt;Was he right? No. Linq can use method syntax, or query syntax. 
There's no clean replacement for let using extension methods. 
Agreed
What package would I need to import to get the basic Python functionality? 2.7.8.1 is the latest version of IronPython.
https://github.com/pauldotknopf/Qml.Net FYI, I'm the author. QtQuick is ideal for touch friendly user interfaces. QtQuick is used in car media systems, fridges, etc.
this is a very basic topic, that person should not be part of the interview at all
You should have deleted the `using System.Linq;` line. But ask him what he thinks would happen before you do it. Probably won't get the job but it would be satisfying.
Lol just look at how much longer the interviewers "correct" way is. I use the method syntax exclusively, I find the other one harder to use.
Nope, he just asked "Filter this with Linq", and when I wrote the line, he said "That is not Linq" :(
Honestly I think forcing SQL-style query syntax into the C# environment is stupid. It's out of step with the rest of the code base using dot accessors and whatnot. I am a data engineer and spend 90% of my time writing SQL, and when I'm writing C#, I exclusively use non-query style LINQ.
I stumbled on your SO question. Please look at this from the exec documentation. Thll &gt; If the globals dictionary does not contain a value for the key __builtins__, a reference to the dictionary of the built-in module builtins is inserted under that key. That way you can control what builtins are available to the executed code by inserting your own __builtins__ dictionary into globalsbefore passing it to exec(). 
That interviewer is an idiot. Lambda expressions (method syntax) are about as basic as it gets for linq and if he didn't know that...
[removed]
OpenXML is also good. I use it for excel files as well.
I'm going to go against the grain here and suggest something cool with Vue that cannot be done with react and angular 2+. If, and ONLY IF, you care about SEO, use regular MVC pages and drop VueJs into each page. If you don't care about SEO, just separate it out into two separate projects. I know these javascript frameworks have SSR, but it'll never render as well as mvc pages and node SSR has load issues if you get a lot of traffic (just what I've read, have no personal proof)..
[removed]
I have no idea how you could think that most people prefer method. Before your statement I would have said the exact opposite, now I don't know what's real anymore
As other said, he wasn't right. Also, yes avoid that place. IMO, interviews that ask very specific coding questions and evaluate the answers based on "right" or "wrong" are doing "tests" wrong. The test should be simple and a gateway to discussions. And honestly, who codes without using google. I use them to "weed" out the obvious applicant that don't even know the basics, but for me, it's all a matter of discussion, challenging and understanding how the applicant thinks.
I always had that itch at the back of my mind. Thanks for pointing out what they are properly called 
You can simulate it with Select and returning a tuple or anonymous type containing the previous range variable(s) plus the new one.
I think the point was to call him on it. If you know your LINQ, you know both syntax and can call his bluff.
Funny, I prefer the query syntax -- less noise to view.
That should have been a clue to the interviewer that he was wrong, that you were indeed using LINQ. I'd understand if you felt uncomfortable calling him out on it though.
People who graduate to positions where they no longer do much coding lose touch with modern techniques?
...you can return a query built using query syntax too. They compile to the same IL under the covers.
as someone who is struggling with SSR with angular 5, do u have a github example? do you just serve up mvc with the completed page when u detect the google bot?
You just serve up a regular mvc page and write a Vue app in an on page script tag.
will the google bot render it tho?
Yes, but if you're generating partial queries which you plan to add operations to in the future, method syntax makes a lot more sense for that.
Depends what you're doing. For a 1:1 database query with a bunch of joins, query syntax is a star. For filtering/sorting/etc pure C# objects (e.g. Lists) method syntax can make a lot of sense. It is also a clean way of doing query appending e.g.: public List&lt;People&gt; PeopleFilter(List&lt;People&gt; people, string filter, bool active) { var result = people.Where(p =&gt; p.FirstName == filter); if(active) { result = result.Where(p =&gt; p.Active); { return result.ToList(); } The implication of the discussion in this thread is that people have to *pick*. In most projects you'll find BOTH depending on what is needed. 
Mvc razor pages are served served side, so as long as you write valid html, you’ll have no issues with bot rendering.
To add, the compiler just converts query syntax to method syntax. You end up with the same code regardless in il. 
There's literally no difference. They return the same type and they do the same thing.
The difference is semantics and which one is easier to understand. 
No. It means the compiler doesn't understand `IEnumerable&lt;T&gt;.Where` unless you've imported the appropriate classes. All linq methods are extension methods, and imports are a compile-time-only facility; in the intermediate language, all calls use the full type name, using a syntax similar to c++.
I use both? Sometimes when I'm debugging a method syntax piece, I'll break it out into the query style and work on it as sometimes the lambda stuff can get a little hairy. After i get whatever i needed fixed, I'll redo it in method and compare. I like the aesthetics of method, but sometimes, at least for me, the query syntax is a little clearer. I could be a weirdo, though. 
it was rhetorical
this needs to be upvoted higher. It should go into a db.
I agree. Vue or React. Angular is okay but there’s too much circle jerking with rxjs observables and that’s way too advanced for beginners, IMO.
They’re all the same but I would recommend Vue or React. I liked angular in the beginning but when you start getting into advanced stuff, it becomes a cluster fuck. And they keep drastically changing it. Not something I’d go back to, especially when React dominates the job market.
He is right, the where method is part of linq and was designed to support linq queries, but remember that linq stands for Language Integrated Query, it means that is a sintax sugar to write queries inside your code in a more readable way. If you are calling a method directly you are not using linq you're just calling a helper method. I know that the where method belongs to the linq namespace but as I said it exists to support the linq, but it is just a extension method on top of a collection. BTW I prefer to call the method directly as you did. 
Semantics means what the compiler understands. There's no difference. If you can follow "select x from y where" and you can't follow "y.where(...).select(y =&gt; y.x)" you may not be suitable for this industry.
There is attribute that lets you set call back when the recaptcha validates. In there you can enable your button and submit the form. As for IE issue it could be that google just doesn’t have enough info tracked in that browser for it to be confident who you are since you prob don’t use it except when testing lol
I worked with fixing a similar issue last year in a company I worked for at the time. Anyway the content of PDF files were not designed to be machine readable. So it stores every glyph and its bounds, and they may even come out of order. This means that the machine reader has to interpret these into sentences, paragraphs etc. on its own. The simplest is to just take any glyph where its bounds intersect and use that to form sentences. However there may be a small space between them that will get interpreted as a space. Maybe you can configure the PDF parser to have a slightly larger tolerance?
Illusion. His manager has no idea what the guy is doing but gives off a general aura of "things seem to work well" = "he's a great developer". If that guy works long enough like that in isolation, he actually starts believing he's as good as people who have no idea think he is and keeps going down the rabbit hole of isolated bad ideas. Source: worked with one, the software he made was a huge freaking disaster.
I wouldn’t say it’s impossible but it think would have a lot to do with how solution looks. I think MSBuild can only build each project in the solution in parallel. So unless you have a 30 core machine and fairly small projects you going to have a hard time getting there. 
But did it perform better? I have seen some linq queries that resulted in awful slow sql statements. In this special cases a manual sql query was faster.
The other commenter is harsh but semantic has a precise meaning in the context of programming. And in this case the semantics are the same between the two syntaxes.
This feels like the typical stackoverflow answer. Q: I want do X. A: No, you should do Y.
Other comments already explained what query syntax and method syntax is, but I thought pointing to [the official documentation about the topic](https://docs.microsoft.com/en-us/dotnet/csharp/programming-guide/concepts/linq/query-syntax-and-method-syntax-in-linq) would be useful.
I was never claiming otherwise. We are literally arguing over two expressions of the same idea. 
Expert beginner was the best follow on Twitter when I had it. 
&gt; The Peter Principle is an observation that the tendency in most organizational hierarchies, such as that of a corporation, is for every employee to rise in the hierarchy through promotion until they reach the levels of their respective incompetence. For anyone else who needed to Google it
I agree. Method level gives you intellisense and is mostly easier to read. though, joins tend to be easier to read using the query style. however, query style by itself can't actually invoke itself. it just returns iqueryable so you'd need a ToList somewhere anyway.
Hmm, interesting.... I did modify globals: import sys, imp; Global_code = """# Mod global script code goes here. # This script will be imported into all mod scripts, including formulas."""; Global = imp.new_module('Global'); exec Global_code in Global.__dict__; sys.modules['Global'] = Global; # Mod global script code goes here. # This script will be imported into all mod scripts, including formulas. Is it possibly by modifying globals, I'm deleting the builtins?
Highly ignorant interviewer - best to skip this job. 
Both those queries are perfectly valid LINQ. I've had this argument with a senior co-worker in the past. If you get someone like this in the future, get them to remove the System.Linq using. They'll suddenly find it no longer works.
Yeah but you can't use angular without installing node or npm bullshit Vue is a standalone file without the excess headache
You need to have some schema guarantees for the .net code to work as well. If you are handling GBs of xml data and if the schema tends to change over time, you need to stop writing code. Otherwise you will end up building an ETL tool in your code You are now better off using a visual drag and drop ETL or data integration tool like SSIS to ingest the data, maintain the schema mapping to your DB or output format file, and then convert the file into a db table or even store it as a columnar file like Parquet. Now of your schema changes, you just use the UI mapper to manage it. Better still, you can now get a non developer to manage that.
Piggy-backing on this, I find that any join is simpler to read using query syntax, not just complicated ones. 
Because senior means time not skill level
This is my greatest fear
Installing node and npm is like 2 minutes of work. It's not like its difficult or anything. You have to install the dotnet framework or the javaruntime to do java or dotnet. What's the dif?
[removed]
It did seem faster using linq but I think the original sql statement was poorly optimized. 
I'm not quite sure what you want to do. Using Dotnet Core with SignalR and Typescript is very easy and there are many, many tutorials on the internet. AFAIK, SignalR support is already built into Dotnet Core so you don't even need to download any packages. I am not sure, however, if you can npm run a Dotnet Core app. [This](https://docs.microsoft.com/en-us/aspnet/core/tutorials/signalr-typescript-webpack?view=aspnetcore-2.1&amp;tabs=visual-studio) should get you started quite easily.
I used to work for a guy who wouldn't allow anyone to add new tables or columns to the database because it harmed performance. I asked him to back up that claim with evidence several times. The answer was always "20 years of experience."
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/learnjavascript] [Web Devs, Help! How to lay out SignalR + JS Frontend application structure?](https://www.reddit.com/r/learnjavascript/comments/9eeaij/web_devs_help_how_to_lay_out_signalr_js_frontend/) - [/r/typescript] [Web Devs, Help! How to lay out SignalR + JS Frontend application structure?](https://www.reddit.com/r/typescript/comments/9eee76/web_devs_help_how_to_lay_out_signalr_js_frontend/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Yea, possibly, I'd make sure you add the builtins entry, I'm not sure if you just need it to exist or if you need to define each one you need specifically.
Thanks for the link :)
Also, it doesn't matter if they fill up your pipe anyway
This definitely helps, but is slightly off from what i was trying to do. I was hoping to control routing inside the typescript code.
[removed]
I would suggest that you do the Angular tutorial and just use the Angular CLI to create your UI project. (ignore anything on the internet referencing AngularJS, btw) 
The keyword `where` - along with the rest of the query syntax, is understood by the compiler. In it's context, it cannot mean anything else, and so the compiler emits the equivalent code. It may sound like voodoo magic but it's really that simple - the query syntax is something that the compiler needs to be aware of in order to provide you your query. 
You're going to have 2 levels of routing (at least). Your angular app will have its routing and your backend service will have its own routing. Does this help? I'm a little unsure what you're referring to by routing inside the superscript.
You can't control server-side routing with client-side code. That would be quite the security risk. You can just call API/MVC endpoints by their URL, maybe string together a client-side routing system so you don't have to worry about the specific URLs your endpoints are mapped on. 
I would not use the Angular dotnet template. Create a separate Angular project. So, at a minimum you will have two projects. An ASP.NET Core SignalR project and an Angular one. 
Link to tutorial? Asking for a friend.
I'd say you're half-way there. I'd get the Angular dotnet template going and make sure everything is working 100%. This will act as a the reference project. Then I'd create a separate front-end (angular?) project and transplant javascript bits-and-pieces across until there is a separate app who's functionality roughly mirrors the first - knowing that the back-end bits will work. There's no point fighting the server-side and client-side battle at the same time. 
The word "easiest" is in the title and this would be the easiest if you had a big load of ram to use. Seeing as though we weren't given that information, kind of hard to assume.
https://angular.io/tutorial
Hmm, how would I do that?
No idea, you can probably find that information in the documentation, a sub more focused on Python, or google-foo.
I totally respect your opinion bro as it is true that DIstributed attacks are much stronger however, rate limiting still adds some value as it can reduce the effect of it
Swagger automatically picking up on the `ActionResult&lt;T&gt;` return types might be enough for me to stop using `IActionResult`. Good tip.
Why not just return T?
What did you think about the reasoning given in the article about when you should switch from `return T` to `return ActionResult&lt;T&gt;`?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/csharp] [Does asp-validation-summary have wrong behaviour?](https://www.reddit.com/r/csharp/comments/9ei7oi/does_aspvalidationsummary_have_wrong_behaviour/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I prefer method syntax for stuff like this because it's cleaner, at least to me. Mainly like how succinct it is. Query syntax it's my go to if I have to do joins, especially if it's multiple joins.
Because it provides a level of indirection that decouples your application from cloud providers. This will enable you to have the capability to switch around different providers if the need exists (can be motivated by cost especially for startups)
I feel that it ignores the ASP.NET pipeline and .NET coding conventions for no reason. The pipeline was specifically design to turn exceptions into HTTP Status codes. It's something that you need to wire up even if you use IActionResult in case an error is thrown deeper in the stack. In fact, that's where it is going to be thrown. My data access layer throws a missing data exception that the pipeline turns into a 404. The alternative is to add a try-catch for every controller method. (Or cram data access into the controller, which I wouldn't actually do.)
But at-scale rate limiting to prevent a bees-with-machine-guns style attack would be near impossible with that kit?
&gt; IActionResult allows different HTTP statuses to be returned. In the following example, NotFound is returned if a contact with the supplied ID isn’t found or OK(contact) if a contact is found. Bad example. You shouldn't be doing data access directly in the controller. Which means you need a way to have your repository communicate the status up. Normally that would be an exception, but then what? Redundant try-catch blocks in every controller method? So do you have your Repository return an ActionResult? They really need to think through these design patterns more.
What is the better option though? At some stage you need to turn a response into a status code. I certainly don't want to couple my business logic to [ASP.Net](https://ASP.Net) by having a repository know about ActionResult. Not super knowledgeable on middleware yet but one solution could be creating a couple of exceptions in the business domain and letting middleware handle it. Throw a generic "DataNotFoundException" for example and let it bubble up into the middleware. Would remove the need for any try catch blocks in the controller method itself. Then only null would need to be handled, maybe more middleware or just `result != null ? Ok(result) : NotFound()` &amp;#x200B; &amp;#x200B; &amp;#x200B;
Yep. Had a guy doing the classic .Where().FirstOrDefault() in his code. Didn't know he could just is the last method. Explained the difference and then asked him why one would be preferable over the other. Didn't quite get it, unfortunately, but he was also applying as a junior.
I use FTP tools to upload my project. They support WebDeploy. Please just contact their support. I personally have no problems deploying my .net project. 
&gt; Bad example. You shouldn't be doing data access directly in the controller. While the article does access the context directly, [the doc it references](https://docs.microsoft.com/en-us/aspnet/core/web-api/action-return-types?view=aspnetcore-2.1) uses a repo. In any case, it's irrelevant here, since I'd argue it _is_ the controller's job to construct the HTTP response, however you transport the data up to it. &gt; They really need to think through these design patterns more. So I just built [the sample](https://github.com/aspnet/Docs/tree/master/aspnetcore/web-api/action-return-types/samples/WebApiSample.Api.21) the doc references and replaced the named region with this: #region snippet_GetById [HttpGet("{id}")] public Product GetById(int id) { _repository.TryGetProduct(id, out var product); return product; } #endregion If you just return `T`, the article's first option and your preference, here's what happens: * **Model returns null:** it will return a `204 No Content` * **Bad argument type:** it will return a `400` * e.g. `http://localhost:5000/api/Products/hello` instead of `http://localhost:5000/api/Products/2` * **Uncaught exception:** it will throw a `500` if it bubbles up to the top uncaught. ----- For so little code required in the controller to get all that, it seems pretty well designed to me. I know some people will prefer the 404 for the first case, but I know others-- like yourself, I'm guessing-- would prefer 404 refer to whether or not the endpoint itself was found, and not the RESTful resource.
They default to using `204 No Content` for null resources instead of `404`, I suspect for this very reason. See my other comment below.
I'd love to see the look on the interviewers face when he sees this Reddit. There's no place in this world for level zero managers. He doesn't even know, that he doesn't know he was wrong. The interviewer should still be a grunt. Do not take that job.
**Coding by exception** Coding by exception is an accidental complexity in a software system in which the program handles specific errors that arise with unique exceptions. When an issue arises in a software system, an error is raised tracing the issue back to where it was caught and then where that problem came from, if applicable. Exceptions can be used to handle the error while the program is running and avoid crashing the system. Exceptions should be generalized and cover numerous errors that arise. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I never understood the point in these returns I just return the datai expect and if it's anything else then obviously it's not a successful call I just don't see the point in explicitly returning 200 or wherever other codes when you're either getting data back or you're not 
This is kind of weird question. I assume that this question is always about being proud of technical aspect of software. If that's the case, one should probably say that he is most proud of something that he had done recently (unless there was a fuckup), because with each project you are more experienced and technically competent.
The above guy really made a good comment about developers stuck in shops that actually make things work, people don't know everything and that kind of goes both ways. &gt;(I hate you .txt). &gt; &gt;Sure, there a lot of code that I've memorized because of daily tasks, but it shouldn't be required to have such a high level of knowledge of some specific language. You probably did it but what I'd do in this case is improvise it, when you can't code a real version on the fly just pseudocode it. Not even sure what they mean't with .txt but I guess it means to save it to a file in a csv like format? var listResult = context.Where(...).ToList(); var stringConvert = Converter.ConvertResultToString(listResult); //Append fields with a seperator with each item on a new line as well as escaping the seperator and new line characters. File.WriteAllText(@"...path...", stringToConvert); Personally I'm way more impressed with someone who can show how they want to solve a problem than struggling to make it work in a short amount of time that would be available in a interview.
One useful way is to return different responses without that data that still convey some meaning like "no dataset found for the ID", "no connection", "internal server error", "not authorized" and display those in the view. 
Nah you can do that but it removes some of the automatic functionality of things like Vue/react. Not clued up on angular 2 (yet) but I assume its similar
Anecdotally, our legacy API has received way more accidental DoS attacks than it has full-on DDoS attacks. We're not a particularly big target though. 
This method works well as a deterrence because of the increasing amount of time between requests. It requires the attacker to work harder or use alternatives. Of course just this alone is not 100% watertight, there are a variety of strategies from inside to outside the target location and infrastructure which can be implemented to make it 99.9% watertight.
I once encountered a case that I could not write in method syntax. To be clear: **I** cannot write it, I am not saying it's not possible. Anyway, cartesian product: var tuples = from foo in foos from bar in bars select (foo, bar) This gives me all possible combinations of elements taken from the two lists. I don't know how to write it in method syntax but for this specific case I can't see why I would want to avoid it.
Sure, it gives the flexibility to return HTTP status codes, but if you’re structuring your app correctly your controller action shouldn’t be determining business logic results. The example given with data access in the controller would be a nightmare to maintain on anything other than a trivial app.
I don't know about profile section like that but you could look into [isolated storage](https://docs.microsoft.com/en-us/dotnet/standard/io/isolated-storage).
Keep in mind that ActionResult&lt;T&gt; doesn't enforce the type at compile time, it implicitly converts from a lot of things.
Thanks, I'll look into it.
There's a reason for that, explained by Stack Exchange itself: https://meta.stackexchange.com/questions/66377/what-is-the-xy-problem
I think his conclusion is that lazy loading can be really bad for performance when doing reads, but that is actually helps when doing writes as you don't grab tons of data when performing the update to the object. After years of playing with EF, I have found myself exactly here with this sentence from the article: &gt;And it’s very easy to have the best of the two worlds: just don’t use domain classes in the read model. Write SQL queries yourself, and materialize data directly to DTOs either manually or using a lightweight ORM like Dapper. Truer words have never been written IMHO.
Towards the end he slips in the uses nhibernate for writes and dapper for reads, so the article needs a bit or organisation.
There are quite a few reasons to avoid lazy loading and their importance grows exponentially as the project grows. My arm is broken, so i'm being brief... The article actually makes a different case, so i'd probably bin it, restructure it and republish as follows: This is really an article about the benefits of cqrs and in your case the use of two frameworks. Your choice of nhibernate for writes was made BECAUSE it offers lazy loading. For reads you use Dapper with optimised sql which can't lazy load. No lazy loading was a design decision in Dapper and the (SO) use it for reads and writes, so the benefit to you on the write side is more intuitive, easier to write code. So turn the article on its head. Make sense?
You didn't have to be all that qualified to get a dev job 10 years ago. However, it isn't difficult for a unqualified person to find a small company where he can snow management into thinking he's a "guru". Add another ten years of not bothering to lean anything and we have crap like this. 
You might be best off using the VS Installer Projects the other guy linked to. I personally used NSIS as it's usually pretty simple. But since this is not just a normal desktop application there's some wrinkles you have to take care of: 1. Configuring IIS (I used command line APIs to set up an application pool and website.) 2. Prompting the user for IIS configuration information (eg which server do you want to set up the website on, what website domain/port, what will the url of the application be, which application pool should it run under, etc (I used custom wizard pages through nsDialogs). 3. Adjusting permissions on the installed directory to give the application pool user appropriate access, otherwise your site might not work depending on where it is installed (I used the cacls command line tool). 4. Undoing all this properly on uninstall such as removing the app pool if the installer added it and no other applications are using it. (I stored the data input by the user in registry values so the uninstaller can easily fetch it and know what to undo.)
This is a Windows feature supported by all the major browsers. It has nothing to do with GitHub specifically as it will occur on any file you download. Windows allows for a file to have an attribute attached to it describing where it came from (local computer, local network, or internet). This allows Windows to treat files not from the local network as "untrusted" and restrict what you can do with them until you go and unblock the file to indicate you trust it.
1. .NET still supports COM objects just fine. I use them for Microsoft Office interoperability (no other convenient way to really work with Office file formats in my case). 2. Intellisense will not function fully for COM objects; in my experience you end up seeing all methods attached to all COM objects even if they aren't applicable. But maybe that's Office. You will probably need to find other documentation to figure out how to use COM objects you are not familiar with. 3. The problem with this line of thinking is its logical end is "don't bother to port at all and keep the whole thing VB6". Why even go into making the project a VB6 COM object when you could just compile the project as a VB6 executable? Far easier.
Old?
Yeah I've had similar arguments and results with this guy. One time we had an argument where he spent 3 or 4 days trying to get the database to aggregate messages into a single message in a stored procedure. Something I could have done in 5 minutes in C#, but he was having none of it. He kept telling me things like &gt; As much logic as possible should be done in the stored procedure and jobs, not code. To me this is crap, especially when he's spent days trying to do something that would have taken me 5 minutes to do. So I press as to why, but can't back it up with actual facts. Having nothing to fall back on, he says &gt; Look this is coming from 20 years of experience, just trust me. To which I replied &gt; I mean look, I've been doing this crap a long time too. Don't try to pull the experience card. You won't give actual reasons. Pretty much ended the argument, the other guy basically rage-quit the argument. My boss was there the whole time, and he knew I was getting really pissed, especially when he was trying to pull the experience crap. The guy doesn't like programming, he doesn't understand it well enough, and claims he's had some bad experience in the past that he will never elaborate on. He does alright *designing* the database layout, but beyond that he's just not that good imo. His ideas are misguided, based on fear and ignorance, and he's got too much pride and ego to consider that he's wrong. Even just the other day I told him how he could fix a bug, and he spent ~50 minutes making me wait for him to try every other thing he could think of before finally trying what I suggested (which fixed it.)
1. Because it allows you to bubble it up from low level code easily. 2. Because that's not the only error condition you might run into. For example, "not authorized" can be returned from the data access layer. (Especially in cases where you need to load and inspect the data to determine if the user has access.) 
As always, arguments like 'X is always bad' are almost always wrong, especially when it's qualified with 'because everyone uses X wrong'. Lazy loading can be really useful when you have a usecase, where sometimes one part of the object graph is needed but not the other, and vice versa. And what you actually need is dependent on that. Yes, there are other ways to solve that problem, but sometimes lazy loading is a very pragmatic, easy and (if done right) performant solution. Use it selectively and sparsely, but when you need it don't let yourself be dicouraged by absolute statements.
If you don't use lazy loading you can just .Include() any foreign key table you need. This way you avoid the 'double dip query' problem that the article talks about. It actually requires you to be explicit with what data you require from the database.
&gt; Without the lazy loading, we would need to select everything about the student. And that includes the information from the Course, SportsActivity, and Sports tables which we don’t need in this use case. Why? Without lazy loading I would only load the Student and the Enrollment... why would I *have to* load courses, sports, sports activity?
another reason is caching. 200 responses are ok to cache, 500 not
Pop up where? Perhaps you could download a dictionary, then put a binding on the second textbox to a string property, which you will use to query the words out the dictionary. The binding should be something like: &lt;Textbox Text={Binding Path=StrProp Mode=OneWayToSource} Then in the codebehind or viemodel or whatever youre using: public string StrProp = "" {get; set;} Then somehow find the words you want to show from the dictionary and suggest the ones you want to. I cant really think of the top of my head how to do this but Ill try once I get on my PC.
Are you looking for help regarding the suggestion data structure or the UI component of showing the suggestions? For the former, you want a [trie](https://en.wikipedia.org/wiki/Trie). There seem to be a number of nuget packages that would probably save you from rolling your own: https://www.nuget.org/packages?q=Trie
**Trie** In computer science, a trie, also called digital tree, radix tree or prefix tree is a kind of search tree—an ordered tree data structure used to store a dynamic set or associative array where the keys are usually strings. Unlike a binary search tree, no node in the tree stores the key associated with that node; instead, its position in the tree defines the key with which it is associated. All the descendants of a node have a common prefix of the string associated with that node, and the root is associated with the empty string. Keys tend to be associated with leaves, though some inner nodes may correspond to keys of interest. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Moreso looking for the UI Component, but thanks!
Got it, do you have any suggestions on the UI Component?
There's the System.Windows.Input.TextCompositionManager you could register your textbox which raises events that have TextCompositionArgs with a TextComposition object that has a AutoComplete On/Off but it's still up to you to suggest things as far as I can tell.
It sucks having a bajillion includes on some queries. I still prefer explicitly stating what I want brought back though. Only real downside I've seen in practice is someone coming in later and not realizing that that particular object or list isn't being included.
(1) If you have a bajillion includes you are probably breaking Single Responsibility Principal and you should consider refactoring to break some of those dependencies. (2) This is definitely an issue that we have run into as well. Unfortunately unit tests also mask the problem until run time.
Is this not just an autocomplete extender? There is one in the WPF Toolkit. 
There is always a exception to the rule :) Looks like you found it! Also, you should probably be using a Stored Procedure if you are pulling in that much data. It will expedite performance.
Ill take writing payroll processing code in C# over stored procedures any day. It really doesn't take that long to pull in all the data for each period. We'd be talking about miniscule time savings and once you factor in readability, ease of testing, auditing, and keeping everything in the code base in C# and reactjs its really a no brainer to not use stored procedures for us.
You are the best knowledge house of your business case. As I said, no rule is absolute! There are always trade offs.
&gt; I really liked how the UI was coming along with HTML/CSS/JS. Why not then keep the webapp you already started developing, and put it in a WebView? Of course it's just a suggestion. You can also develop the app like others have proposed.
This why I just use store procedures if the query is more than just select x entity
I'm also confused by this and it seems to be the crux if their argument.
 If you wanted to use Docker, this is incredibly easy to do. If you want to, I could write a docker file for you (would take 5 seconds), if not: &amp;#x200B; You don't need mono if it's an [asp.net](https://asp.net) core MVC project. If it is regular [asp.net](https://asp.net) (5) then you don't need .net core. However, aside from publishing you can always do an [FTPS](https://en.wikipedia.org/wiki/FTPS) server, and then it would be secure, or run an SSH instead of doing FTP to push the files. &amp;#x200B; What errors are you having with jsvalidation?
I'll have to send a screenshot but it was basically an "Expected "===" but saw "==" instead and all that. I've seen similar issues around but I don't think that's the issue, I think it's with the deployment method, or something to do with the deployment issues. I might look into the ftps or look into building docker files. Does visual studio need plugins for ftps or does the ftps just work with the ftp already installed on the server after some calibration? 
Do you have to new up a Tuple or can you select directly to a C#7 value tuple (l, r) =&gt; (l, r)
Sure, ValueTuples are fine too. Bonus points for anonymous days types ;)
Absolutes never are
His "Lazy Loading" is good example is total and complete shit. Why the f\*ck are you loading up a student object so you can delete an enrollment? What an inefficient way to handle the problem. How about I just skip using the lazy loading ORM completely and execute a deletion query that specifies both the student id and enrollment id as a parameter and nukes the appropriate record with a single DELETE query? &amp;#x200B; Oh wait - I guess that's just too efficient. Nevermind.
[Host ASP.NET Core on Linux with Nginx](https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/linux-nginx?view=aspnetcore-2.1&amp;tabs=aspnetcore2x)
I heard something about absolutes and the Sith I can't remember what it was though.
Only a sith deals in absolutes
I will do what I must
ObservableCollection&lt;string&gt; , I'd imagine.
Forgive my ignorance, but I'm having a hard time understanding the purpose of MediatR or what a real world use-case scenario for it would be?
_A lot_ of Security for the most part is about raising the bar, this case in point. It's bot about 100% removing ones ability to do so. 
MediatR makes implementing the CQRS pattern a doddle. It also has built in pipelines which make implementing decorators e.g. for cross-cutting concerns, really easy. It also scales really well so you can use it on small project straight through to enterprise projects. I've over 10 years of experience of in software development &amp; .NET; I use MediatR whenever the projects allows. Can't recommend it highly enough.
No problem. My thoughts on this (feel free to agree or disagree with these): Mediator design pattern eliminates the direct communication between objects and promotes a loose coupling between them. This also means it easily evolves into a micro service approach. Comparing it against an application where services, repositories and other layers quickly gets big, messy and you often ends up with too many dependencies in each class. I find it a lot nicer and cleaner to have it set up feature by feature instead of having fat services, repositories, etc. containing many features.
I think you may be over thinking this, I would say do whichever you think you would work best in. There is no wrong answer in Razor vs SPA, just in how you execute on either one. It sounds like you have put more thought into SPA, and it should not hold you back.
Where has MediatR the forces in scaling projects?
I’ve never heard of MediatR before. Sounds interesting, thanks for posting!
You shouldn't be using ftp anymore. Use SCP or SFTP, both supported by OpenSSH. You could also move your builds to VSTS and use a release pipeline to release to Ubuntu.
I might be wrong, but I think the only real key advantage of razor with angular would be easier session management. It's just harder to do that against raw web apis I think. 
Yeah, I realized about two hours into digging that Putty had an SFTP client that made it easy and more secure for me to transfer the files. Now I'm having difficulty getting my servers to show the web app when an internet request hits the server. But I'm sure I'm struggling because I'm a noob. If I had the money I'd just host a small solution on azure but my $5 solution will have to work for now
Yep, take a look at SignalR! It's awesome. 
That depends on how much "real-time ness" you are looking for and how much load there is. Generally speaking, any language running on some sort of VM (CoreCLR/JVM/...) that is available for advanced features such as memory management, garbage collection, is not as responsive as something native.
Well the connection needs to be a 2-way connection and the data has to be updated every 2 seconds or so. So Basically what will happen is: * app sends data to server. * server makes calculation based on received data * server sends back new data to app
If you're gonna do it as sockets just be aware there might be a limit on the number of open connections allowed based on the host. I think azure has a limit on free tier web apps but none on standard. Outside of that, don't prematurely optimize memory and speed until its an actual problem. Get something built and working. Then find your bottle necks. You'll learn along the way about different architecture and design decisions. The language/framework won't be the biggest limiting factor until you hit a crazy scale. 
What is the benefit of using Hangfire? And if I'm getting it right you are sending MediatR events/commands as Hangfire jobs? 
The benefits of using Hangfire are to allow jobs to be added to a queue and proccessed later either as scheduled or right away in the background. Check it out at hangfire.io it's pretty cool. I've added the possibility to let MediatR send events directly to Hangfire, however, I prefer to validate my input and let the feature decide when to use Hangfire. So in my example MediatR is not sending events to Hangfire. CreateUser feature is using Hangfire but only after input has been validated. 
Take a look at gRPC.
I'm not the person you're asking, but one place I'm using it at work is to design a decoupled monolith. We have tight deadlines and we can't commit to making a full blown microservice architecture even though we can see that in 2-3 years time the complexity could easily be high enough to justify moving away from a monolith. With mediatr we can create logical boundaries around our class libraries such that it would be (relatively speaking) very easy to rip out those modules from the monolith and instead access them through a message queue or HTTP call when they're implemented as a microservice, since you don't have that tight coupling.
I use it for in-process event dispatching. It scans assemblies for event handlers and when I decide to dispatch an event, it handles it for me. Very easy to use. I have integrated it only in pet projects, hopefully it will work nicely in production as well.
[removed]
Ecommerce space is like CMS space. In most cases you can just use existing solutions but there are cases where using existing solutions don't fit and you have to built one from scratch while feeling stupid for doing it.
Web API with HttpClient is more than up to the challenge of making requests every two seconds. HttpClient will keep a TCP connection open to the server when you are making constant requests (which you wouldn't expect). I have a dashboard for one of my backend services that pings our public Web API every 500ms (with a 500ms timeout). The average response time in that situation is 6.6ms and it has an up-time of 99.92%. I once built a middleware that did messaging over WebSockets using protobuf, but the performance ended up being very similar to Web API because I hadn't accounted for HttpClient keeping connections alive. Just a note, when people on programming subs say realtime, they typically mean something that can meet strict latency guarantees. You mentioned a timing window of 'every two seconds'. Most developers wouldn't call that realtime, and if some native developers saw your phrasing...sometimes they can be real dicks about it.
My biggest problem with mediatr is what a pain it is to find the handler for a request, compared to say the "go to definition" option when using a more direct method.
I meant what is the benefit of using Hangfire in this case. I am aware what Hangfire is, used it on one project to run scheduled tasks. So this would be useful in scenarios of high load. But how do you get the response from the job in this situation or if something fails in the job? Isn't hangfire enqueue fire and forget? One thing I find great about MediatR is that I get the response from the action after it is done or that everything is rollbacked if something went wrong. (no eventual consistency problems)
Up doot. SignalR is what you are looking for.
I agree, that is way there should be a very strict and good naming convention for feature query and command objects that are sent with MediatR. And have those in the same file where the handlers is located. Then you go to the definition of the command/query and find the handler there. 
Razor is bad because?
Hangfire also allows offloading heavy and/or lower priority tasks to another process (or even another machine) than the one serving the users interactively so in that aspect it helps with scaling. Also it provides an API to check on a job and automatic retry logic so not entirely fire and forget. This is likely part of why OP does the validation before scheduling the job.
Because it's not trendy and people dnt tlak about it on HN or Medium!!!
Yes you are correct that Hangfire is fire and forget. That means you should only make use of it when you don't want to retrieve the respond from it. I use it in this example when inserting a user into the database, and you're right that the client will not be notified if the insert fails. However, with Hangfire failing queues are retried so I don't see this as the worst problem. But this is entirely up to the developer-team but I like the idea about having the backend putting most of the it on a queue. This makes it easy to scale since you can control the number of workers and servers. Also make notice that CreateUser returns Accepted 202 to let the client know that it is processing and not yet complete when creating the user.
Yes. I have looked at, and worked with, Shopify, bigcommerce, nop commence etc in the past. But my client’s requirements are such that none of these systems works out of the box. And also, they want to own the code. NopCommerce is open source but it will still require changes. 
Thanks. My main concerns as I mentioned are around security and speed. Security first the speed. With that in mind server side rendering seemed a better option to me.
Thanks for the advice. The project will require at least 2 sites. The customer facing store and then the admin interface. So I may be able to break up the solution into different components. 
This is what we do and it has saved so much time and headache. While I initially cringed at having multiple classes in one file (Request, Result, and Handler), it really only made sense in this case as if you want to look at one, you probably want the at least one of the others as well.
Out of curiosity, which security concerns? I admit I prefer server side rendering, but just because I am more effecient with it. Spa, done right shouldn't be more or less secure from what I understand. 
Nope that isn't it at all. But keep thinking that.
Not clear where the difference is between Express and Professional.
For instance if I maintain a cart with item id(or other code), price etc on the client can that lead to anything bad. I will be validating everything on the post call regardless. 
For the record, I didn't downvote you. It was a simple question.
IMHO you'r problem is not related to any current "hype" technologies! A solution I used with an ecommerce was to store only a cart ID in an encrypted cookie at the client side and to maintain the cart content at the server side. This allow you to persist carts in a database for later use (if clients can be authenticated) AND to use an intermediate cache with sliding expiration for performance. For security reason, your cookie HAVE to expire when the browser is closed because your clients are anonymous!
This would have the same concern whether you go razor or SPA, you never trust the client; your cart would be maintained in both places in both scenarios. Either you are sending data over a post or a service call, or whatever, it's the same possibilities. I may be wrong, but I can't think of a time where a concern around security I have seen was because it was SPA vs MVC, vs whatever, always in how it was implemented. I think if you go with whatever you feel best with and do it correctly, you are good to go.
You actually are getting downvoted for not explaining your opinion, not because you don't have a popular one. 
Use signalr
Your result.Errors collection will never have enough objects in it to worry about performance there. Either of your suggested methods will be similar in performance due to the size of the errors collection 
Wow, glad to see they've fixed those vulnerabilities but a bit worried they were there in the first place.
You were not wrong that is def. linq like other have already said. I sometimes switch to query on my projects. &amp;#x200B; Anyway I also interviewed at a fortune 1k company recently. They asked some simple question that I can't recall and had me white board the solution. &amp;#x200B; I wrote "x += y;", the senior engineer that was one of the people interviewing me said that is not going to work. I said, it will definitely work but I can simplify and write in the standard form so I wrote x = x + y;. I received an offer but did not take the job. That is such a basic thing that it upset me. If the guy asked me what it does, instead of claiming "Oh THAT WON'T WORK" I would have explained it and maybe felt more confident about working with people there.
I am looking forward to .NET Core 3.0, desktop stuff and if there is any .NET Native change on the F# front if ever. Microsoft has been supporting MonoGame, Urho3D and Unity, so I don't imagine they will come up with anything else.
Why? Pipelines is new, and there are thousands of CVE's found every day for every web platform, I'm more surprised this is all that was found.
I didn't realise the second ASP one was also about pipelines, when I think ASP I think tried and tested and the post just made me worry I'd overestimated it's production safety.
Thanks for sharing. From a quick look code looks very well written. 
Nah, it's nothing to worry about. New issues are found constantly, it's just a part of web development at the moment, unfortunately. With 1000 entrypoints, there's thousands of possibilities for things to go wrong :) for instance, here's a list of vulnerabilities for just apache: [https://www.cvedetails.com/vulnerability-list/vendor\_id-45/Apache.html](https://www.cvedetails.com/vulnerability-list/vendor_id-45/Apache.html) the lists are huge
Pipelines is very new so it probably hasn't been out there long, and they're both Denial of Service attacks. Now if they were security vulnerabilities, then that's a real issue.
Azure Stack....
Denial of service attacks can still be a security vulnerability in the form of denying access to sensitive information people need to be able to access
Yes but it's a temporary issue which can be fixed.
Good job TOTALLY ignoring my comment about SSR which is the best of both worlds. Not coming from ignorance? Haha.
? right-click, find all references. It should only be referenced by mediator or calling by a service handler, sure, just hitting F12 is definitely faster, but it's definitely not slow (especially since mediatr can share multiple handlers for a single object... which would be like an EventHandler, in which good luck finding every place that gets added to as well :))
https://github.com/dotnet/corefx/commit/9be582e1927fc14e7f14b419737ea7b5799a802a#diff-9a0b343d0ae95ef90f79dcc5a297c613 I'm not sure how it is even a DoS. I suspect MS is being overly cautious about this and there is some theoretical vulnerability.
You don’t need npm. You can use YARN. Or even brew. Or if you feel frisky. Just write your own web pack. Vue is only concerned with the V in mvc where as angular is an entire framework. So as such there are going to be differences and dependencies as with any framework 
Your post has been removed. Self promotion posts are not allowed.
Retry policy for one. I will retry if I receive a 429 but I won't if I get a 404.
Learnt something new from your repository, never heard of `App.Metrics` before. Very cool stuff, it is unfortunate my organization doesn't want to use any other databases beside MSSQL Server....
No offense mate but I don't think I've ever read a comment whereby I disagreed with absolutely *everything* in it. I've no idea how you're using MediatR but literally everything you've said regarding why MediatR is bad, is actually where it shines. For ex. if you want clean separation of concerns, the CQRS/mediator pattern is a great approach. MediatR helps with that by *removing* all the the boilerplate that goes with creating the interfaces, services &amp; infrastructure that would normally be required to do that. Your requests, events and handlers only need to implement an interface. That's it. Need to add new a feature? Create a new class for your command and handler. No modifying of existing classes. Doesn't get much easier than that. MediatR is not slow. It's not a platform or a service, it's a pattern and a tool to be used to build software. If it's running slow for you then it's down to how you've built your software using it. Your points around microservice/monolithic/serverless development has nothing at all to do with MediatR. That's more high level solution architecture. Sure, you might be building a few microservices to solve a business problem e.g. I need a new restful customer API build in .NET. MediatR would be a get tool to help get that done. I also need a microservice to process log files, CQRS might not be a good fit for that so I wouldn't bother with MediatR. Not trying to attack you here mate, just pointing out that your reasoning is a bit muddled and misplaced.
Ok I get you now. It scales really well by doing two things in particular, really well: Separation of concerns - each command represents one atomic business operation (use case) e.g. add a user to the db, and each command has one handler (the logic) to do this. So whether you're building a small CRUD app, or a complex REST API with lots of features, all of your business problems can be easily separated into logical classes and named appropriately. For example in a solution I just finished, each domain had its own folder e.g. Location. In the location folder you'd see `AddNewLocation.cs`, `UpdateLocation.cs` etc. Open one of those files and you'd see three classes, the command (or model for the data), the validator (to validate your data before running the handler) and the handler, which holds the logic (adding location to Db context). Cross-cutting concerns - aspects of your solution that shouldn't be peppered throughout your code e.g logging, transaction handling, performance monitoring. MediatR pipelines allow you to run logic before and after a command is handled. So for example, I can log when I start adding a new Location and log when I've finished. No need to add that logic in my `AddNewLocation` handler. In my last project I had a pipeline to handle saving changes to my Db. So instead of having `SaveChanges()` in every single handler that performs some CRUD action on the Db, I had one class that runs after every handler that will call `SaveChanges()`if the Db needs to be updated. This promote good practice too as the Db context interface that my handler uses doesn't even have a `SaveChanges()` method, meaning if one of the developers in one of the teams I manage, is working on a new story and tries to be a little naughty and call save changes, they can't.
Publish ClassHelper as a Nuget package that Project A and B both install. If you publish the Nuget package with symbols included you will be able to step into it also.
[removed]
Publish it on a private Nuget feed. This is not the only way, but it will be the best way to maintain the dependency, including updates across multiple projects.
What can I post here? I can not post my posts you mean to say?
Thanks!
I have this setup using CI (Bamboo), and it is super easy. You setup your helper library, your nuspec file, and upload it to your git repo. Have CI poll for changes, build the project, and push to your private repo. You'll need to setup the source in the nuget config files, but it can be done in a few hours. When you make changes, you just increment the version and push your changes. CI will do the rest.
Awesome! Do you have any suggested reading materials? I’m looking to integrate it with bitbucket. 
Really quickly, by publishing with symbols, you mean have it built with the .pdb file?
Read the MSDN stuff for command line nuget and MSBuild. In fact, I think nuget and MSBuild are now integrated. Everything can be done in command line for a project like this. The first thing to do is to setup a private nuget server. I forgot which package I used, but I build mine from a template, and then customized authentication and front end UI. The template saved an assload of time. https://docs.microsoft.com/en-us/nuget/hosting-packages/overview From there, make sure you can push out a package remotely using manually typed commands. If that works, convert those commands to CI tasks, and you're 80% of the way there. The last 20% will just be customizing everything the way you want it. Also, one last tip - you can't override a nuget package remotely. You have to delete it and readd or increment the version. I wasted an hour trying to figure that one out. Hopefully that has been fixed or will be eventually.
In your `Startup.cs` class you would check the `IHostingEnvironment` and call the methods to add the support based on the environment.
I was loving Mono, I developed plenty of stuff on It but since DotNetCore is born I don't understand which can be the purpose of Mono anymore
You can create a WebAPI with a background service. Refer to [this article](https://www.stevejgordon.co.uk/asp-net-core-2-ihostedservice).
Is Core 3.0 in the making? I thought we would stick with 2.x for a while.
AI/Machine learning tbh, really would like to learn and work more with that here in the netherlands.
It was announced at BUILD 2018. https://www.youtube.com/watch?v=spgI12ZEBcs https://blogs.msdn.microsoft.com/dotnet/2018/05/07/net-core-3-and-support-for-windows-desktop-applications/ The main items is to make possible to run Windows Forms, WPF, EF6 on .NET Core, on Windows, as those developers keep ignoring .NET Core due to lack of support. Microsoft wants that in the very long run, .NET Core replaces .NET Framework in all possible scenarios. .NET Framework is not going away anytime soon, as some of the changes required to bring to bring those stacks into .NET Core are not backwards compatible, additionally they don't plan to migrate deprecated or very Windows specific features. 
Where would this be useful? Won’t you have two separate “forms” based around adding of a student vs a doctor? Which in turn would want to call AddStudent vs AddDoctor. I mean I get if the underlying logic would be the same but it just seems like abstraction fro the sake of abstraction 
&gt;There's got to be a better way Thankfully there is and I'll give you two solutions, ones close to what you're doing and the other will require you to learn a bunch of new things. 1. Do it with Razor and a minimum of JQuery. Yeah, make an action with a partial view that has only the table bit. Enjoy the nice binding and all from Razor. Call this partial bit from AJAX and replace the target element where you want the table in your page. No more constructing HTML in Javascript. 2. More effort to learn but could be good on the long run: learn Vue or some other frontend framework which allows you to progressively use. I'm not talking SPA here, I'm talking replacing the JQuery bit with Vue. Than you can have a client-side template for your table, you fetch your data with Axios (it's like JQuery but just for the AJAX stuff) and your template automatically binds to the data. Plus you've made your first step into a modern presentation framework if in the future you want to move to SPAs and such. In any case, start with 1. and when you have the time give 2. a try. There is still a place for traditional Razor websites as opposed to just SPAs but JQuery is just totally outdated today and often ends up in messy code.
You should use a static instance of HttpClient instead of newing one up each time. It's threa-safe and how it's meant to be used.
The Microsoft document on this is more in depth and better written https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/windows-service?view=aspnetcore-2.1
Interesting comments. We may be crossing our communication, or we may just agree to disagree. Imagine a serverless function that does just one thing... it handles just one type of message. What benefit does using MediatR give you in that scenario? Absolutely none. The serverless function itself performs the same role as the MediatR handler, so why go through the hassle of adding the abstraction? In addition, using MediatR for a case like this adds to the memory used by the function and slows the cold start time. 
Have you tried cleaning NuGet local cache. That might help. Usually NuGet is restoring packages from the local cache. Ideally you would want to increment the version
An alternative to making your helper library a NuGet package is to create a git submodule for your helper repo. It's essentially a symbolic link between a directory in your project A/B repos and the helper repo, so A/B can access the helper libraries at a path defined relative to their executables.
Try timing out the await in addition to the HttpClient. There doesn't seem to be a simple way to do it but these samples look promising: https://stackoverflow.com/questions/4238345/asynchronously-wait-for-taskt-to-complete-with-timeout
Cool thnx!
We don’t keep them in the same file. We do keep them together in the same namespace and subdirectory. The way I’ve been navigating to them is with ‘ctrl+[‘,’ctrl+s’. That simply selects the query class file in the solution explorer. From there I use the arrow keys to go to the handler. Personally I’m not a big fan of Mediatr since it doesn’t only implement the mediator pattern, but also some other stuff like CQRS. Also I don’t value having an additional abstraction in my code that much and the amount of plumbing it adds. Jimmy Bogard also keeps introducing breaking changes which is not cool when you have 30+ repositories and solutions. 
Don't do that. That's just all sorts of bad. 
This seems like the platform agnostic answer. However, if you've got Windows available, I like WinServices over a web server host process.
Well, OP asked about a web app. 
I think it's very useful when writing Web APIs, for example you could have a document endpoint and want to create different type of documents. Using a custom converter + validation on the type field + overloading in e.g. repository makes the controller almost boilerplate-free.
I Frame might not be a bad idea, but you also just create a div where you want the display and do an Ajax call in JS to fetch the PHP page and embed the response in the div. I'll update with example code when not on mobile. 
I have tried the AJAX code but the website that the code is hosted on and the website that hosts the PHP are two different domains.
That shouldn't be an issue with an Ajax GET request as far as I know. 
It's not a good solution either. I posted where I'd start elsewhere, but the gist is ".NET can do that just fine, don't try to hack it with an iframe".
No problem, 's what we're here for.
Remember a nuget repo can be a directory or network share :)
this would only be useful if you already had a company in mind: https://builtwith.com/ It's a good bet that if their company site is built with .NET, then they are a microsoft shop
You can get away with IIS Express and use Windows Home.
Slightly different. That's a background service attached to a Web API. You would still run IIS/a web server on top of the Web API itself. But it could do background tasks for you. What I wanted to do was have an embedded API on a machine that ran itself on startup. 
&gt; var res = await client.GetStringAsync("https://19.38.249.96/?format=json"); //or any URL that will timeout Are you always calling the same url? Because there's a limit to the number of simultaneous connections to the same endpoint that will be opened. This is controlled by [ServicePointManager](https://docs.microsoft.com/en-us/dotnet/api/system.net.servicepointmanager?view=netframework-4.7.2). If you're off a bunch of async calls to the same url you're likely hitting the limit and further requests are not even starting until previous ones time out - but you're measuring all of that time, not just the time during the actual HTTP call.
There is really no good way to find them :) you didn't even state where you are located.
Thanks!
You're welcome. Just keep in mind that IIS Express, in fact, does some things differently than IIS. Your programs might work on your machine, but when you deploy it might behave differently. Just keep that in mind when troubleshooting.
&gt; You would still run IIS/a web server on top of the Web API itself. Not entirely true. You could use Kestrel, which is a code-based web server integrated into .Net Core. With it, you won't need IIS. Just configure a scheduled task under windows which executes dotnet &lt;your_application&gt;.dll every time windows boots up and you're good to go. [Kestrel](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel?view=aspnetcore-2.1) [Running a script at startup (2nd answer)](https://superuser.com/questions/954950/run-a-script-on-start-up-on-windows-10)
IIS is mostly relevant for production, you'll be fine using IIS Express when learning programming. You could even go the .Net Core/VS Code route and bypass Windows entirely. Lots of options these days. :)
Um... there's no such thing as "Windows 10 Pro for Workstations". Do you mean "Windows 10 Enterprise"? That's basically the same as Windows 10 Pro, only with some extra manageability bits.
Um... Yes there is. And no, I don't mean Windows 10 Enterprise.
Oh. [You're right.](https://www.microsoft.com/en-us/microsoft-365/blog/2017/08/10/microsoft-announces-windows-10-pro-workstations/#bxt2xjK5CL5IrXcq.97) But I feel like if you have to ask whether you need Windows 10 Pro for Workstations, you don't need it. It looks like a highly specialized SKU.
There are alternatives but another big thing is that Docker only works on Pro, and it's becoming increasingly popular and important. Something to consider. Can always get an upgrade down the road if necessary though.
If you're doing any mobile development, you'll need PRO so you can install Hyper-V.
Sounds like you need something like IdentityServer4. This gives both authorization and authentication. https://github.com/IdentityServer/IdentityServer4
Are you assuming library code here? I mean is that exception coming from a dependency of your project? I can kind of understand if it is library/fx code, but even then it seems like a lazy API design. 
Using exceptions the way they were intended is lazy API design? 
Your article is good, thanks for writing it. &gt; One problem that I find with these interfaces is that they violate Interface Segregation Principle Worse yet they violate Encapsulation. You almost got it but you really didn't stress this point: &gt; But when your queries are scattered over methods of your services it may be hard to create integration tests for them. Your service layer is where your business logic is. It is the entry point to your database. You don't want to tear down the perimeter surrounding your database and let everyone dump their trash in there. You want to seal off your db and make everyone call your services so you can make sure all data going into or out of your database calls your business logic gets when it is supposed to. That is the root problem with generic repos. They are not just worthless they are dangerous. The bottom line is you never want to expose `DbContext` (or your DAL) outside of your service layer. Your service classes should look like this: public class OrdersService { internal DbContext db; public void SaveOrder(Order order) { // ALL writes to orders table must come through this method! // This ensures your validation logic always gets called if(ValidateOrder(order)) db.Add(order); // etc.... } }
State of the art native is faster than managed code but there is a huge amount of native code out there that is a lot slower than a naive solution using managed code. So that is only a concern if you're looking to spend millions of dollars making a heavily optimised state of the art solution. 
I have written low latency servers for high frequency trading. In my opinion, you'll be just fine with C# on .NET Core. 
[https://mva.microsoft.com/en-us/training-courses/introduction-to-identityserver-for-asp-net-core-17945?l=oygMZtBPE\_5806218965](https://mva.microsoft.com/en-us/training-courses/introduction-to-identityserver-for-asp-net-core-17945?l=oygMZtBPE_5806218965)
Note that IdentityServer is not free for all uses. Keycloak (developt by RedHat) is, and works very very well.
Exactly right! No point in a service layer if a developer can ignore it and go straight to the Data layer.
You've lost me. I'm not arguing when to use serverless functions vs. a .net application? My mediatr handlers can map one to one with my restful API (controller methods). Would you build a whole restful API using serverless functions for each possible endpoint? Of course not. If I'm looking to do one simple thing (isolated logic), over and over yeah, serverless functions work great. Serverless functions aren't a replacement for applications. 
 I tried this just out of curiosity to see how hard would it be to do it on Linux instead on Windows. Is anyone is actually using Linux as .NET Core development environment? 
\&gt; It is the entry point to your database. You don't want to tear down the perimeter surrounding your database and let everyone dump their trash in there. &amp;#x200B; Made that mistake before. I've heard people say "Entity Framework is a repository pattern" and everything you and OP have said is exactly why I'm strongly against this idea because this is exactly what happened to me. &amp;#x200B; I now go with the rule, "According to the rest of the system everything is just a function" making sure every interaction with the DAL is explicit. Forget being able to swap out or modify implementations as you see fit, just knowing every single touch point is immensely useful in itself.
I can understand your point. I was suggesting the OP to clarify the term real-time only because the term is kind of strictly used in some domains, and they probably do not cost millions of dollars. For something that is so sensitive to latency like automobile control system or manufacturing controllers ([PLC](https://en.wikipedia.org/wiki/Programmable_logic_controller)), sometimes 10ms latency can make a huge difference. Real time OS like [QNX](https://en.wikipedia.org/wiki/QNX) or [FreeRTOS](https://en.wikipedia.org/wiki/FreeRTOS) are used in automobile industry. Some PLC resolutions even use bare circuit for signaling and very native code are used with extremely limited resources on embedded systems. I'm not saying languages running on VM is not suitable for real-time scenarios, but knowing the VM or ultimately the OS (e.g. interrupts) could interfere with the the execution is important in actual implementations. I believe you must have put that into consideration in your high frequency trading system too ;)
**Programmable logic controller** A programmable logic controller (PLC) or programmable controller is an industrial digital computer which has been ruggedized and adapted for the control of manufacturing processes, such as assembly lines, or robotic devices, or any activity that requires high reliability control and ease of programming and process fault diagnosis. They were first developed in the automobile industry to provide flexible, ruggedized and easily programmable controllers to replace hard-wired relays, timers and sequencers. Since then they have been widely adopted as high-reliability automation controllers suitable for harsh environments. A PLC is an example of a "hard" real-time system since output results must be produced in response to input conditions within a limited time, otherwise unintended operation will result. *** **QNX** QNX ( or ) is a commercial Unix-like real-time operating system, aimed primarily at the embedded systems market. The product was originally developed in the early 1980s by Canadian company Quantum Software Systems, later renamed QNX Software Systems and ultimately acquired by BlackBerry in 2010. QNX was one of the first commercially successful microkernel operating systems and is used in a variety of devices including cars and mobile phones. *** **FreeRTOS** FreeRTOS is a real-time operating system kernel for embedded devices that has been ported to 35 microcontrollers. It is distributed under the MIT License. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Take a look at "component space". Well worth the money.
What do you mean by that? Identity server is apache 2 licensed (just checked Github), I don't see anything restricting it's use. There are separate, additional products and features (the policy server UI afaik) that are paid, but identity server per se isn't. 
I’m using Mac for some time now, and I can say that vs for Mac was greatly improved in the last year. Other than that it works okay apart for the lack of mssql support, but I use docker with a Linux version of mssql. For a lot of projects I used mongo though :)
You ain't gonna swap anything
IIS isn't really important if you're learning ASP.NET Core, which comes with Kestrel bundled in. 
Good article but it touches only SQL scenarios. There are other DB types which don’t require an ORM and some of them don’t even support querying (key-value). Might be worth exploring those in the future article.
Please change the name man. [ML.NET](https://ML.NET) just sounds like ... ML for .NET. Nobody will guess it stands for Machine Learning.
Adding other parts from this blog series: https://blog.jeremylikness.com/the-angular-net-core-2-1-template-part-two-d4db52550764
I've been doing .NET on a Mac for nearly 5 years and deploying to Linux for about the same time. I almost never touch Windows now. VS for Mac has improved but there are alternatives - Rider, VS Code and even Vim, Emacs etc. Aside from VS for Mac all the others work on Linux much the same as any other OS.
I went down this path and this is what I got * implement a Service or a method in a Service with every single different query that the above layer needs * realize that you're leaking Domain objects that can still be changed from above and create a "model" layer to make the perimeter tighter * what about transactions and multiple service layer calls, how do I manage this * reach the conclusion that you cannot keep up with all the different queries that are needed and get lost in all the methods overloads that you used to try to abstract logic and share code * maybe exposing IQueryable would make this easier? And now you have a DbContext-lookalike but scatered all over your service layer. All the other code pre-IQueryable is also there. Don't want to say that this is what you're proposing but it's very easy to fall down that path if you follow your advice to the letter. Personally I just create an interface for my DbContext (IAppDbContext or something) where I just expose the IDbSets and SaveChanges and higher levels just deal with it as if they were sets. Didn't have to deal with fine grained transactions so I just wrap the entire DbContext usage as a transacation (single web request, for example).
I think it's better personally (though I've not used VS on Windows for sometime). Rider seems a lot more performant than I remember VS being.
I don't use Windows so much these days but I remember preferring Home as Pro just seemed to fire up more services for working on a domain and took longer to login.
I would've stayed on Ubuntu permanently if not for the driver update which bricked my machine and i had to reinstall Windows 10. (Now running Ubuntu via VirtualBox for my dev).
&gt; implement a Service or a method in a Service with every single different query that the above layer needs I've handled this similar to the example in the post, make a dumb dto that represents what we want from the query. &gt; what about transactions and multiple service layer calls, how do I manage this Reevaluate if you actually need these as separate services with individual access to the database. Ideally in this sort of system, a request maps 1:1 with either a query or a command and those both map 1:1 with an aggregate. &gt; maybe exposing IQueryable would make this easier? I've only ever seen this end poorly. 
Yeah, this was basically always what I called F#.
I have one application that I build on Windows and run on Linux using Mono. To get Sqlite working I followed this (http://blog.wezeku.com/2016/10/09/using-system-data-sqlite-under-linux-and-mono/)[blog post]. Basically you just build libSQLite.Interop.so on the Linux machine and drop it in the application folder.. that's it, works like a charm.
Probably not but when you think of it as swappable, it makes it easier to design
And harder to read. 
&gt; Ideally in this sort of system, a request maps 1:1 with either a query or a command This is actually what I do. The application layer ends up being very small only having access to a bunch of command/query objects (with models) and they get pushed through a pipeline that handles one or more as a transaction. Inside the command/query handlers, however, I have no interest in abstracting DbContext and the bulk of my applications is here. 
I faced with similar issue. Adding sqlite nuget to root project resolved it. 
That indeed worked. i also had to include the System.Data.SQLite.dll that it compiled in my application root
I am! [I write platform specific services all day long and Autofac swaps them for me](https://github.com/leaderanalytics/AdaptiveClient)
Interesting read! Thanks for writing and sharing your experience!
The official SQLite package is .NET Framework only and is not designed to be used with .NET Core. Although .NET Core can use it on Windows, it will not work on other platforms as the Interop DLL is a Windows-native DLL file. Visual Studio should be giving you a warning alerting you this DLL may cause your project not to work properly (it's a bit vague). I recommend using Microsoft's System.Data.Sqlite package instead which is cross platform.
Do you really need to sudo to create a solution/project? That seems insane. 
Yep, getting permission error when trying to create a file
No, this, and those steps in the linked blog are wrong about that, if you create a directory with `sudo` (in the article: `sudo mkdir Projects`) then it will be created with the root user as it's owner and therefore everything you want to do in that folder afterwards can only be done by the root user, this is why you get permission errors when you don't do sudo. &amp;#x200B; Don't create the projects folder with sudo and everything else should be fine.
You don't at this point; however you can use something like ImageSharp
Solid info! Just to point something out: This article is quite old, and ImageSharp is now on nuget (stable). If performance is not of utmost concern, then I'd suggest opting for ImageSharp. It's super easy to use.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/dotnetcore] [Inventory](https://www.reddit.com/r/dotnetcore/comments/9fkb3e/inventory/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I think the System.Data.SQLite package is not compatible, but System.Data.SQLite.Core has been core compatible since August
As indication that the data was not found, yeah it seems like the wrong mechanism.
Awesome
yes for .net core but as far as i understand .net framework still only uses it for 64bit, no word in the article about 32 bit, only mentions core
Long term roadmap is for .NET Core to replace .NET Framework, so I don't think they will use resources on making it work on 32 bit .NET Framework.
Just create a batch table that links to a product. So create a new table with BatchId ProductId and quantity.
Ah, I was using .Core and it was not compatible, but it was definitely before August. Good to know they've updatedd it.
Hi, possibly related, are you constrained by 32 bit hardware? I've seen old timers mandate 32 bit on x86-64 for various reasons. 
No you have one entry in the stock table and two batches linked to it.
No just historic, we will migrate eventually but this is no small task for us. I was just wondering since i couldn't find an answer anywhere.
https://www.nuget.org/packages/System.Drawing.Common
hey, for when you work on sql server linux with docker, how do you set things up so that your data persists? And by that I mean...doesn't get wiped when you kill a docker container. I remember reading something about named volumes in the past but didn't totally follow. 
You set docker to symlink the data folder on the Mac , this way you can even drop de get a new image and you don’t lose the data 
From my little experience, finding a job that is only going to be about .NET Core is hard. And why would you want to limit your skills to a particular framework? .NET Framework is less attractive for sure, but it's not that ugly. Check out .NET Standard too. It can be used to compile your code to a specific platform (and that's where my knowledge stops). Anyway, IMHO, the framework doesn't matter that much to become employable. What you need is good C# skills and a decent understanding of design patterns and concepts like MVC, MVVM, Repository, Factory, Observer. Depending on your experience you should already know them, it's not specific to C# at all. My advice is to use Windows and VS to learn C#. Yes it's not the Linux hype, but if you get a C# job, you'll probably end up using Windows and VS. The main benefit is that you press a button and it works. If you want a better understanding of what's going on under the hood, swithing to VSCode can be a good idea, but the I personally don't think it's going to be a valuable skill on the job market. Also, if you want to be productive Resharpper is a very popular tool. TL;DR: Focus on C# skills and good practices. Don't be that Linux nazi. (♡ Linux btw)
Has there been any movement on getting dotnet core to allow ahead-of-time compilation? Last time I tried using Aspnet core with ef core the overall compilation time on cold page load was a problem. 
Your post has been removed. Self promotion posts are not allowed.
Your post has been removed. Self promotion posts are not allowed.
I don’t know much about the AOT stuff, but I remember reading one of the first comments on the tiered compilation preview blog post where some Microsofties were talking about it. It seems that they are still working on it in some capacity. https://blogs.msdn.microsoft.com/dotnet/2018/08/02/tiered-compilation-preview-in-net-core-2-1/?replytocom=635565#respond
Easier in some places, harder in others. &amp;#x200B; Easier in the sense your business logic isn't cluttered with anything relating to the service, harder in the sense there's a layer of abstraction between everything. &amp;#x200B; I personally feel having something like the SaveOrder mentioned above that handles validation as well as writing to the database all in one function makes the actual business logic significantly easier to read rather than having things like await \_context.SaveChangesAsync(); littering your code.
Generic repository is crap, just query directly on dbsets in your service layer, wrap your dbsets in an interface so it's testable
There is in the form of [CoreRT](https://github.com/dotnet/corert)
Not sure I follow. I find it easier because I don't know how to read spaghetti very well
Don't sweat and have fun learning. Once you learn one of these front-end frameworks you won't be able to go back to dirty old Jquery tinkering. It'll feel like magic.
You are right, I tried doing all without using sudo for mkdir and no need for sudo for dotnet commands. Thanks
I disagree - I've been a .NET developer for over 8 years and I've never felt less excited about the ecosystem.
You can return an IEnumerable that already has the objects loaded in memory. Lazy loading disabled and no proxy objects. There is no need to ToList it and get hit by the potentially unnecessarily extra overhead. 
Why?
I can think of two solutions: 1. Use an external console/terminal like ConEmu to get the split view. 2. Install the Node package [concurrently](https://www.npmjs.com/package/concurrently) globally to run all processes in the same terminal. As you can see in the examples, it allows you to name each command which adds a prefix to the console output (something like `concurrently -n web1,web2,web3 "cd web1 &amp;&amp; dotnet watch run" "cd web2 &amp;&amp; dotnet watch run" "cd web3 &amp;&amp; dotnet watch run"`).
Thanks a lot @AlliNighDev this idea went a long way inventory flow just got Way bigger than I thought 
Users as an example: You're loading the entire list of users into memory and adding it to change tracking even if you just want to make a list of all the names of users in the database. If you return `IQueryable` the service can map to whatever it needs: ``` interface IUserRepository { IQueryable&lt;User&gt; List(int page, int pagesize); } class UserService : IUserService { private readonly IUserRepository repository; public string[] ListUsernames(int page, int pagesize) { return this.repository.ListUsers(page, pagesize) .Select(UserMapping.Username) .ToArray(); } } public static class UserMapping { public static readonly Expression&lt;Func&lt;User, string&gt;&gt; Username = user =&gt; user.Username; } ``` In this scenario the users will not end up in change tracking, and the **only** traffic that goes from the database to the application is a list of usernames. The function returns an array because it should never return unmaterialized data. 
I am excited to be able to keep delivering whatever customer needs, with a mature almost 20 year old eco-system instead of following up on *fashion driven development*. Same applies to Java and C++, my other major languages on the toolbox.
The OrderService above is good but it isn't swappable. That was my original point. A simple and to the point abstraction often times is enough. You don't have to use interface everywhere. 
Well the way I see it, I’ve been doing it since 2003 and we basically webforms and win forms to run on Windows. Now we can run apps or games on anything, developed on multiple os’s, with multiple ide’s or any text editor. 2 of the best ide’s in the market are free. The end to end tooling is just so amazing now. Yesterday I developed a scheduled task and deployed to production in under 15 minutes to an azure function. By this time next year I’ll probably be doing that with a machine learning algorithm included. Creating a restful api seems to get easier every release and the debug tooling on the commandline or swagger in the video will make that easier again. The only thing I miss from Java is jhipster. 
Hmm, I agree with you so maybe we are talking about the same (or at the very least not conflicting) concept. Let's get on the same page: 1) generic repositories (simple crud on &lt;T&gt;) can ``` return .Where(predicate).AsEnumerable(); ``` No ListT overhead, no issues with leaky EF abstractions from queriables. 2) The specific user repository, which probably inherits from the generic one and adds the get usernames extra method: That's the same approach, you select what you need (and you can even pass the expression from outside the repository), select what you need and return only a list of strings (and not a queriable). You still work with the queriable in the repository. Same as the generic repo example in (1), the where() returns a queriable which I can further filter or project. But then as enumerable loads the data. Maybe I misread your post, I'm not sure but tbh it looks like we have the same opinion here. Looking forward to your reply. 
&gt; return .Where(predicate).AsEnumerable() The issue with this code is that you're forcing the data model over to an in-memory model (remember, IQueryable basically has two (important) things: `T Execute(Expression)` and `GetEnumerator()` where `GetEnumerator()` simply returns the result of the first one). At this point all elements will be fully loaded in memory whether you need them to or not. `AsEnumerable()` will force iteration to materialize the view at that point, so anything after that, such as mapping, will happen in-memory rather on the database. I don't particularily care about the `List` overhead, but returning `List` everywhere is an example of [Abstraction inversion anti-pattern](https://en.wikipedia.org/wiki/Abstraction_inversion). What I do mean about that more than efficiency is that it's easy to forget that `AsEnumerable` or even just returning the IQueryable as `IEnumerable` will terminate the query chain and any operations applied on it will be performed on materialized data. I don't think it ever makes sense to return `IEnumerable` from the repository itself. You're just creating a stumbling block. So the article says "Repositories should never return IQueryable" which I think is wrong (it also doesn't really go into a lot of detail about why it recommends it). It should never return `IEnumerable` because you're terminating the query command chain before it needs to, and whether the developer understands it or not any additional methods performed on that will be done in-memory. The service or model will very likely need to map the object to something else, and artificially requiring objects to be loaded into memory before hand is a pointless restriction only seemingly only for the sake of dogma.
**Abstraction inversion** In computer programming, abstraction inversion is an anti-pattern arising when users of a construct need functions implemented within it but not exposed by its interface. The result is that the users re-implement the required functions in terms of the interface, which in its turn uses the internal implementation of the same functions. This may result in implementing lower-level features in terms of higher-level ones, thus the term 'abstraction inversion'. Possible ill-effects are: The user of such a re-implemented function may seriously underestimate its running-costs. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Why do you say they are harder to follow? Again, I find them easier to follow. The "show references" intellicode stuff in VS goes a very long way in helping with this. The use of an interface tells me exactly what I need to know to understand what is going on. It conveys a clear message to me. VS also has "go to implementation" now to save me the hassle of tracing it back.
I thought IEnunerable vs IQueryable question was cleared here https://stackoverflow.com/questions/2876616/returning-ienumerablet-vs-iqueryablet Top voted answer (1549!) suggests using IQueryable unless you filtering on your original result. Can anyone elim5 why IEnumerable is better?
I have never done this but I guess you should try adding a new attribute to your metadata file. Something like &lt;targetFramework&gt;netcoreapp2.1&lt;/targetFramework&gt;
It worked, but why???
Definitely an exciting time, but I'm a Rails dev now. 😐
So how does it work? How do you decide what to trim?
Nothing wrong with Rails, great framework :-)
From what I read, you don't decide. The `ILLink.Task` is doing the grunt of the work in figuring out which types/assemblies are not used in your project. [More Info here.](https://github.com/dotnet/core/blob/master/samples/linker-instructions-advanced.md) What he is showing up is that sometimes, assemblies need to use types by reflection and that's the limit of compile-time trimming. When you start using assemblies/types at runtime, the compiler doesn't know you might be using them and that package will trim them nonetheless. What he showed was how to "root" those types and assemblies to prevent that feature from being too aggressive. 
Because the targetFramework attribute in your dependency nodes just target the dependencies themselves. The targetFramework attribute in the group node targets your package. At least that's how understood this. If you want to dig deeper, this should get you covered: [Documentation](https://docs.microsoft.com/en-us/nuget/reference/nuspec#reference-groups)
Thanks!
Oh, yeah, not saying it's not, just that it kinda sucks that .Net has hit this really great stride but I'm not working with it professionally for the foreseeable future. Got laid off back in June and my new employer had a language agnostic interview process, and hired me with a $15k pay raise and loads of other benefits and perks, most of all benefits and paid paternity leave from day one. It's more of a bitter sweet lament because I really do love .Net.
That's pretty slick! My microservices are currently hovering around 170MB, i'm going to have a play with this linker on Monday and see if I can shave a bit more off them
We do all the time.
Thanks for explaining it so clearly!
Thanks for explaining that!
Thank you very much!
Good to know, thank you very much!
I feel the article is incorrect in thinking that the overall guidance should be that the Repository Pattern should not only consist of an abstraction of lower level database calls but rather also consist of UoW and Service Layer code. While this is certainly possible small projects with infrequent changes, there is better guidance to be followed to reach the same result: don't build abstractions for things that won't change. In larger scale projects or situations where the underlying code does change, you'll need to begin to separate out all the individual patterns being used into their own layer. I have seen situations where the concrete to a "generic" repository is swapped out at runtime based on specific contextual data. And other situations where the backend tech changes based on the environment. &amp;#x200B; A better solution than baking it all into one would be to implement abstract classes that provide the base functionality of talking to the DbContext and then implementing a concrete that exposes methods that do the work. That way, should the need arise, you can remove the connection and implement an interface/injection without changing how the code fundamentally works. Similarly, you retain the ability to swap out the base class for an implementation against a different database stack. &amp;#x200B; In the end, they are just patterns and you can make of them what you want. If you haven't, reading some [Martin Fowler](https://martinfowler.com/eaaCatalog/) would be a good idea.
I'm a simple guy, I see Henselman I click.
Microsoft Office is much much much better than Libre Office IMHO.
I've been working with dotnet since the beta like you. While I agree core's initial release and back and forts have been messy, I also feel it was a necessary evil of the new Microsoft being more open and iterative. Their biggest mistake was initially naming it as an upgrade and going version 1 too early. Hardships and all, it's certainly exiting. Perhaps I have that point of view because I've stayed off Core while keeping and eye on it. So I haven't had to suffer its growing pains having judged it not mature enough until 2.1. At the same time, even if we ignore Core, full dotnet has been getting regular language updates. Microsoft has released the amazing VS Code. Things have generally moved towards and amazing direction with a big move to open source and just about everything I wished they had done from the start. It's not all perfect but things are moving forward. 
Can you explain further please?
Performance, C# and F#, tooling.
It's absolutely worth using a better language than Javascript, but give Typescript a look before you decide.
It's never as easy as it seems. But if you ever have multiple items linked to one just create a separate table and create a one to many relationship. It's called normalisation and it's key to good database structure.
As someone coming from dotnet who has started writing services in Go, this article gave me a 😥 I just built a poc rest api that talks to a SQL server. Container size is under 7MB. 
I agree, but it's not better in any way I care about. Sorry, I was ranting. Sometimes it's helpful to let the frustration out and I have just lost patience :(
There really is no clear-cut answer. Both have their advantages and disadvantages and it largely comes down to which is the best tool for the job at hand. That can and will vary. My recommendation: pick one and become and expert in it. When you have a good understand of how it works, then switch over to the other. Most of my background is in .NET, but I do a lot of personal projects in Node. Having a background in ASP.NET definitely made it easier to pick up Node and learning Node most certainly enhanced by understanding of how ASP.NET works under the hood. So in short, learn both in the long-term. You only handicap yourself by sticking exclusively to one language or framework.
What learning C# will provide too? I have been searching about Desktop job market and it doesn't seem good at all, I have been searching about Mobile development and I realised that people use stuff like Java and Cordova instead of it, I have been searching about backend development but I can replace Node.js with it, I have been searching about game development and it seems that C# is doing great at it but game development is hard so I don't think that will be useful to me, I have been searching about Blazor project but it seems that it's still very beta and will not be used until long time passes. I'm confused right now. If C# is not good at all these platforms then why learning it?
For the last issue try adding an empty constructor for your context class, such as: public WhateverContext() {} 
This sounds interesting. A brief example would be helpful.
C# and .NET are great candidates for any large-scale enterprise development. I wouldn't use NodeJS for any large-scale, distributed system. For something like that, I'm using C# all the way. The tooling is great and very conducive to working in teams. When it comes to backend, Node is great for things that don't have a large amount of complexity. That's not to say that you can't use Node for complex systems, but C# is generally going to be a better candidate as it gets better performance and is much more conducive for using more sophisticated patterns, like Domain Driven Design.
Either create your context in the asp.net core package or implement iDesignRuntime
What specifically is giving you grief? Personally I get annoyed at the half finished, half functional apps in Windows 10. But in terms of dev, MS seems to be doing a lot of good recently.
So, I was reading this article when I noticed it mentioned server-side Blazor. Why is this even a thing? We already have RazorPages for that (or MVC + Razor).
It is different because the state is fully stored on the server and only ui updates on sent down to the browser and keystrokes/mouse clicks are sent back up. Think of it more like remote control software.
Same here, dunno how he says 73mb oob. Then again, we are still on .net core 2.0
Oh and blazer is the dawn of something incredible.
Thanks for posting. Please don't kill me as I inform you about a grammar thing. "Brunt of the work" means the majority or hardest part of the work. "Grunt work" means tedious, usually unskilled or low-skilled work. They're related concepts to a degree, which is why the minimum wage should be $15: easy (unskilled) work can still be hard (laborious). You may now return to your regularly scheduled programming. My policy on things like this is that if no one ever tells you, they're doing you a disservice.
Mate, no problem at all! I'm a French Canadian and English isn't my native language. I'll remember that and will update my comment. Nobody's perfect and we must strive to improve every day.
Yeah but at the end of the day it's still just JavaScript I think it's extremely Overkill to here to install a package manager just to use it Why isn't it in nuget? Or maybe it is now and I just haven't seen it. I haven't bothered with angular in a few years mostly because it's a pain to get installed since I had nothing but issues with npm
Is it a scalable idea?
no
I use wisej at work and it is similar to server side blazor and our interface is very similar to the azure portal. It really doesn't use too much CPU and memory but we dont have a ton of users it is a sys admin tool.
We also had a security audit that we did really well on since none of the business logic was exposed in the browser.
No as it uses an active web socket per session. it's use is for web apps that doesn't expect that much users like most enterprise apps. The good thing about it though is if you properly decouple how it gets data, you can switch to client side blazor very easily if you need to scale. There's also the idea of using it only on certain pages that you need to do stuff purely on serverside like say a payment page etc... So you can have an mvc app then selectively have areas that uses it if you need interactivity. 
I guess it exists for the same reason server-side rendering exists in most SPA frameworks: better SEO, supporting low power clients and quicker page render.
It's a song list, I juat had to vent. Office died and the new licencing model for msdn annoyed me(it automatically update to it if you repair. Other stuff has been winding me up for ages too :( It was a rant though, Just needed to let it out L)
.NET is a great platform. It is one of the only runtimes that can is good at *everything*, from games to web servers. I love it. I was 15 when I started making games in Unity and learnt C#. Then I moved on to ASP.NET Core (was in RC when I started learning it) and slowly WinForms -&gt; UWP/Xamarin. I'm 17 now. I've used Java and C++. I've also meddled with Python and NodeJS (serverside). I didn't like them as much as C#. You're 15. You have plenty of time to learn anything you want, in any language. I'd suggest that you start learning C#, and then learn ASP.NET Core, instead of making multiple posts asking about it. Your post on the other subreddit already got a nasty troll commenting bullshit - so your posts aren't really gonna get a lot of productive replies. There's really not a lot to talk about, as I said.. You seem to have some misinformation about ASP.NET Core - I'd rather advice you to start with the official [C# Guide](https://docs.microsoft.com/en-us/dotnet/csharp/ ) and the official [ASP.NET Core tutorials](https://docs.microsoft.com/en-us/aspnet/core/tutorials/?view=aspnetcore-2.1) than quote your post and correct you. Once you start, you'll have a better understanding on the .NET ecosystem and you will actually create APIs instead of wasting time replying to trolls. ). 
You need to provide the JavaScript code where you call the controller, it’s important you don’t make a normal link to the url, you must consume the data the controller returns.
Thanks for the encouraging and advices. However for fullstack, fullstack means you can develop in backend AND frontend, whether you're a beginner or not (even with bad frontend and noob in backend), "You can't stick to Javascript and call yourself a full stack developer" What javascript has anything to do with being a fullstack? I see you're very biased toward .NET here and of course I'm learning REST API now, that's why I used Express, you can't expect me to not use any framework to learn backend. I make multiple posts about this so that I can decide if it's worth my time or not, I can't learn a language just to see it's dying and yeah, I'm already okay at programming generally(switching to any language is not really a problem to me as I developed in like 6-7 languages before in like 4 years ago) the problem is when the language has a job market or not. Of course I would do a full research about it. Again, thank you for the advices, they were really helpful. I think I will learn C# This post can be closed right now that I got my answer. Thanks for everyone!
**You got it!!!!!!** Noob move on my part. Thank you so much! &amp;#x200B;
You can't go wrong with either one. Both: - are actively maintained - have strong communities - are general purpose and cross platform &gt; C# (a much better language than JS when it comes to typing) C# is strongly typed, but is that inherently better than loose types? There is no simple answer and we could debate it until the end of times. &gt; it has better performance than Node.js and stuff like that There are marginal performance differences that won't matter in the real world. Even if one is a bit faster than the other, it's not gonna matter until you hit 100s or 1000s of requests per second and at that point you're likely better off optimising your logic, infrastructure, databases etc. What you should ask yourself is, which one do you enjoy working with the most? We cannot answer that, you simply need to try them both out.
It is 'better' but it really depends what you're doing. I switched to Google Docs years ago and have found it perfectly adequate. I was never a power user and prefer the uncluttered UI with everything I need above the document or spreadsheet I'm using. If I was a PA with different requirements then I doubt it'd be good enough.
Windows seems well and truly dead except for its stranglehold on pc gaming. Love that companies like valve are trying to push away from it. And don’t get me wrong... .net core is awesome. It’s a massive leap forward for the ecosystem and I think it’s a great language for microservice development. Just for me it can’t beat the lightweight simplicity of Go programming. 
I don't work for the Windows org but from an external point of view, Windows revenue isn't down. It's still going. So no, I don't think Windows is dead. With that settled, we want developers to use whatever they want. That's why you have an amazing story for .net CLI. That's why you can control our Cloud with a CLI as well. If you prefer Go? I can introduce up to my Cloud Developer Advocate teammates that focuses on Go. They are there to ensure that Go developers are having a blast. With that said? Use Go my friend! Whatever allows you to be productive and build awesome software. If we can help, let us know. 😄
That's because you just started and you're a beginner. Javascript shows its real face when you spend at least 3 months of programming with it and become more of average developer. When that happens, the suffering begins.
Hi. When I try to run an [asp.net](https://asp.net) core as windows service, I got this Exception Info: System.TypeLoadException: Could not load type 'System.ServiceProcess.ServiceBase' from assembly 'System.ServiceProcess, Version=[4.0.0.0](https://4.0.0.0), Culture=neutral, PublicKeyToken=b03f5f7f11d50a3a'. &amp;#x200B;
If you are trying to host an oidc service look at identity server. http://identityserver.io/
It is a bit of a beast to setup and configure but once you do it is great.
This is because book is in pre-order. After publishing late fall this year, all formats will become available.
I would love to learn from your mistake :) Can you post the fixed version above or here? 
***React Component - (Before)*** &lt;Button onClick={ this.handleUpdate('UpdateSandbox') }&lt;/Button&gt; ***React Component - (After)*** &lt;Button onClick={ (e) =&gt; { this.handleUpdate('UpdateSandbox'); e.preventDefault(); } }&lt;/Button&gt; In my JavaScript, I was not stopping the event from my event from bubbling up the DOM tree. For example: you have a **&lt;div&gt;** with a **&lt;button&gt;** inside. If you click the button, the parent div's click event will also be triggered. To stop this, you pass in the event arguments **e** , and call **preventDefault**. Now the event will only be triggered for the button. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
&gt; I can't learn a language just to see it's dying Where in the world are you seeing it dying? [https://www.indeed.com/jobs?q=C%23](https://www.indeed.com/jobs?q=C%23) &amp;#x200B; I'd love to see the large business that isn't running its business of desktop and laptops. If you are looking for desktop jobs thats not how they are listed anyway.
 there are very few languages you can widely do everything with but it you are talking about switching thats a hard call. I use both btw .net core does not use angular. Yes people use angular a bit more with .net core but people also use reactjs , aurelia and any other front end they choose.
Here is a link talking about wisej security. I believe the same security features with in empty client and a web socket connection apply to blazor. https://wisej.com/docs/html/Security.htm
I didn't say it's dying. I said IF the language is dying.
First of all performance, don't worry about it. it matters when your dealing with thousands of requests per second and you've gone through and fixed all the optimization problems that are your own fault (i.e. 90% of slowdowns are because a developers actions, not the framework). As for more people using nodejs. Don't worry about it, both are stable and here to stay. Nodejs is far older than [asp.net](https://asp.net) **core** and [asp.net](https://asp.net) was locked to Microsoft platforms only making it popular for conservative businesses but not a great choice for anyone else. Outside silicon valley and startups using the 'cool' stack you won't have any problems finding work with .Net. I would say switch for an entirely different reason though. Express is great but it's (intentionally) unstructured which is great for letting you get creative but not so much for teaching you. learning [asp.Net](https://asp.Net) core will introduce a lot about best practices and things like dependency injection, SOLID principles, and common design patterns. It doesn't matter if your using rails,express, spring, express, django etc etc. these sorts of skills carry over to everything. For that reason i would say switch, it's more work but you could learn so much more about creating good architecture than what express would introduce you to. &amp;#x200B; &amp;#x200B;
&gt; I agree with that, but in my opinion executing the query at "some point in the future" can only lead to problems Have you ever encountered any such problems? In practice the only issues I have had is when people do what is proposed here that leads to a query being materialized **too early** and then end up doing lots of work in memory that could have been handled by the database. And if someone forget sthe `.ToArray()` on a function you get that "some point in the future" issue but with also loading everything into memory and operating on it there. &gt; And as a consumer of such an IEnumerable-returning repository: what stops you from filtering, map or doing whatever you need inside the repository but specifying the arguments for these operations outside of it via parameters? You end up with an anemic service layer that more or less just acts as a proxy for the repository, and you end up more or less just duplicating every method in the repository which makes for a large implementation surface for the repository. The service should be doing the mapping and its going to be doing a lot better job if it acts on an `IQueryable` rather than `IEnumerable`. Do `ToList()` in the service layer instead of the repository layer. As a side note I don't think you should ever return `IEnumerable` from the repository. It's an unnecessary indirection. If you call `ToList()` or `ToArray()` just return those. Both are `IEnumerable` and part of the standard library.
Here's another use case, having your front end create your back end code - https://medium.com/@thomas.hansen_49492/spicing-up-your-c-web-api-with-lizzie-850b9547b652 But I agree with your use case example ... :)
Maybe look into NancyFX
A static class in an ASP.NET site works like a singleton. You could host that in the web site and it should work for you.
If you're using an inversion of control library it's trivial to register an instance as a Singleton. 
What happens if I get two requests at the same time? the engine class is not thread safe. 
Will look into that. Thanks! 
Can you queue them up and process them in order? You didn't mention the load you expect this system to receive.
Maybe just implement the singleton pattern and use a thread lock when checking if the instance variable needs to be initialized the first time.
&gt; Is it worthy to learn C#/ASP.Net core and switch to it from Node.js or I should just stick to Node.js and learn more until I become much better and experienced backend developer in it? Some people would argue that C# and .Net Core is a much more mature, scalable and _"serious"_ development model than Node JS - Notice how I don't object to those putting forth these claims ... ;) C# is definitely purely from a neutral perspective also a much _"better"_ programming language, with way less _"concerns"_ than JS, and hence much better suited for large systems development. Basically, once your code base reaches a specific threshold in complexity, having selected Node JS for your back end, will inevitably become a somewhat _"painful"_ experience. So yes! Learning C# and .Net Core would definitely be worth it, assuming you're interested in building large and complex systems ... If your concern is that you'll _"loose"_ the easily created (rapid development model) that Node JS definitely brings you, which arguably is its main advantage - You might want to take a look at my Open Sauce project, who's purpose is tobring that _"Node JS feeling"_ to C# developers, by providing a (ridiculously simple) scripting language on top of C# and .Net. In fact, it's so simple, I bet you'll learn it in 20 minutes if you know some JavaScript from before ... Check out a .Net Core MVC example here - https://medium.com/@thomas.hansen_49492/spicing-up-your-c-web-api-with-lizzie-850b9547b652 However, to sum up; Yes, assuming you want to become a _"real"_ developer, inevitably at some point you'll have to learn something _"beyond"_ Node JS (and PHP for that matter). If your choices here are between Java, C# and C++ - I know what I would spend my time on. And it wouldn't be Java or C++ ... ;)
&gt; I'm confused right now. If C# is not good at all these platforms then why learning it? Because you _"forgot"_ to mention the most important platform; Web ... C# runs in circles around Node JS when it comes to complex (web) projects ... However, yes! For smaller projects, Node JS (arguably) runs in circles around C# though. Hopefully there's an answer in that realization for you ... :)
&gt; I'm 17 now. Good God!! Are you looking for a job Sir ...? :D
&gt; "You can't stick to Javascript and call yourself a full stack developer" Although you're obviously correct in this, I would like to (slightly) object ... ;) https://medium.com/@thomas.hansen_49492/spicing-up-your-c-web-api-with-lizzie-850b9547b652
&gt; I said IF the language is dying. Things that have been around for a certain period, tend to have proven their ability to survive changes. C# has been around for 20 years, Node JS for how long ...? 5 years ...?
This is simple and best solution 👍👍👏 
That seems to do the trick. Thanks!
The best way to do this is... 1. Create an instance of that object. 2. Create an work queue and matching thread to process the work 3. When a request needs something from the engine, it pushes a work item with TaskCompletionSource into the queue. Then it gives the matching task to the request. 4. In a loop, the engine's thread grabs a request, does the work, then calls complete on the TaskCompletionSource 5. This will notify the request via the matching Task that it can pick up the results. This will give you better performance than just slapping a lock on the engine. But its more work to setup, especially if you've never done it before.
That's not enough because of the thread safety issue.
If the class is not thread safe I would make a decorator class for it and do the locking from the decorator class. 
I'm interested in your last point about using locks. Does it depend on the frequency of accessing the object under lock? In my case a single computation in the engine can take 7 seconds at best. So using a lock to access it affects performance significantly? 
Desktop market is still good for in areas where a browser isn't an option, like life sciences devices, factory control panels, modelling tools. Stuff like this https://www.biotek.com/products/ https://www.visualcomponents.com/products/visual-components-4-0/ http://www.factoryautomation.com/ It is a matter of which domains you want to work on.
I don't know man, you leave me with a hard choice. So basically, Node.js is very badly-written because of Javascript but it is easier to start work at. C#(ASP.NET) is very good-written and very structional but it is harder to start work at. I mean, I didn't even finish learning Node.js and this happens but still, I think I will choose C#(I already started learning it), I think like everyone said here, it's a very good written language that isn't a mess like Javascript(A reminder: [Object object] and undefined) and I think ASP.NET's Ecosystem is far bigger and solid than JS's, besides C# is used in UWP, Classic apps, Servers, Games, Mobile apps and soon building frontend(Blazor) so by learning it alongside my previous experience with Javascript, I will have many choices so that's a very good thing, I guess. Again, thanks for everybody' answers! They were helpful!
Dude, I never said C# is dying. I said it generally, like I can't start learning any language until I make a bigger research about it so that I know if it's a good choice. But yeah, I guess C# is very solid, Node.js however was for 9 years though, it didn't prevent big companies like Paypal, Netflix, Uber, Linkedin, ebay from using it, which reminds me, how these enterprises don't use ASP.NET for their primary applications?
&gt; However for fullstack, fullstack means you can develop in backend AND frontend No, full stack means you're essentially good at everything (from database to frontend), not just JavaScript. That means you are supposed to tackle any problem that comes your way (upto an extent - after that you get specialized developers working on game engines, kernels, etc.). &gt; , whether you're a beginner or not (even with bad frontend and noob in backend) There is an old saying "Jack of all trades, master of none" - you don't want to become one of those, at least in programming. In most companies, the software stack is not homogenous. There's always some JavaScript, Go, Python, C#, Ruby or Java (or even C++) sprinkled here and there. There's also hundreds of languages that transpile to JS, that the company might decide to use instead of Vanilla JS. You are supposed to be competent enough to handle these combinations of stacks and languages. So my main point was to just learn it if you want to, it's easier than posting here and deciding whether you want to learn it or not. If you want to call yourself a fullstack developer, you simply have to take in everything you can, without having to worry about job prospects. 
I shared this a month ago in this sub. it may be useful for you. https://github.com/DooMachine/MicroStarter?
I spent some time playing around with it today. The dotnet:2.1-runtime-deps-alpine is tiny because it doesnt bundle aspnetcore with it. I managed to make a build using a dotnet new webapi on 2.1.4 but it wouldn't run because it apparantly has some dependencies on aspnetcore, which is a pain in the arse tbh. When you use a runtime that has aspnetcore and use the linker you can shave off around 29% of the bundle size, but I couldn't get the container to run. It threw a bunch of errors about missing packages (which i'm pretty sure the linker removed)
Sounds about how i imagined it would work
That is awesome. Thanks!
[Aspnetboilerplate](https://aspnetboilerplate.com) has what you're looking for plus a whole lot more. 
Depends on what else this web service is being used for. If all requests hit that engine, it won't matter at all. If only some of them do, then it will allow ASP.NET to more efficiently manage thread usage. Basically what happens is when you hit a `lock` statement, the whole thread is blocked. If you hit an `await` statement, then the thread is reused for other requests while it waits for the work to finish.
Absolutely correct, which is why we abstract the repository into an interface and see it boil down to a "generic" repository. You should not be mocking your business layer (where work is being done) because then you aren't testing the code that will make it into production. My post was more about maintaining separation of concern in lieu of baking everything into one class.
&gt; which reminds me, how these enterprises don't use ASP.NET for their primary applications? Big companies wants to _"own"_ the platform they build upon, which is understandable. Hence, they tend to choose Open Source, which is becoming less and less of an argument about C# as time goes ...
I'd have to agree. The usual crew that is active in this sub are pretty good dudes/dudettes. Keep up the great work everyone!
I think if you add `type=button` to your button this should remove the need to have the `preventDefault()`? Because `&lt;button&gt;` type is `submit` by default which posts form data to the server, hence the redirect. https://developer.mozilla.org/en-US/docs/Web/HTML/Element/button#attr-type
Yeah but I think when I done with C# and learn ASP.NET(and backend as whole) I will just go back to web and improve my skills as a frontend developer. I don't think I need to learn C++ or C or any other language at the moment. C# + Javascript is enough for me but thanks for the advice anyway!
D'aw, shucks. C'mere, ya big lug.
I agree, however I feel like its also more of a general thing with .NET folks in general. As far as the community goes in the bigger picture, .NET sure beats the other ecosystems in terms of online etiquette and helpfulness to one another.
Locks are ugly. Use F# actor-based messages. They are built-in implementation of message queue. https://fsharpforfunandprofit.com/posts/concurrency-intro/. Or alternatively akka.net :)
Sure, its OK. I prefer /r/csharp though. Overall friendlier, and this sub has some pretty weird views on certain things. The other week I saw someone calling someone else a moron simply because said person suggested someone use a stream instead of loading multiple GB's into memory. So not totally sure I agree on the no conflicts/bullying part, but overall it's not too bad compared to most.
All the requests hit the engine. I basically wrap the engine in a web api so other teams can use it. &amp;#x200B; \&gt; Honestly the performance difference is probably insignificant, but you might as well learn the patterns so that you can use them when it does matter. &amp;#x200B; That's one of the my biggest problems with my approach. It feels like a trick rather than a solution. I'll actually take the extra time and learn how I can implement the pattern you suggested. &amp;#x200B; &amp;#x200B;
Hahahaha, luv ya 2 bro :D
Did you report the comments? I don't recall seeing anything in the mod queue around this... 
No I did not, I guess OP didn't either.
Person B is 100% correct about using a stream.
Look up the repository pattern. Effectively, you move all of your database code into its own class and one of the arguments for that class is the connection string you need to connect to the server. You will probably always* have a bunch of different functions with using statements so I wouldn't worry about having multiple functions that are all similar. *If you have really similar functions you might be able to get away with a few internal functions that you pass methods/delegate to that actually fill your data objects.
You know, I had actually moved my database code into classes already. So this is not too far off. I had not thought of repository pattern. I'll give that a shot, thanks!
Exactly my thoughts, I felt pretty pissed off A was shitting all over the suggestion. Really toxic and immature.
I suspect this may come down to a combination of 1. .NET is generally used in enterprise and commercial settings. We don't have to deal with many opinionated hobbyists 2. It's not a "specialist" language or system, so we don't have to deal with many elitist/perfectionist types who are more concerned with being right than anything else It leads to a nice middle ground where most people are professionals, but we don't have to take everything too seriously and go into the academic minutiae of every discussion. That's not to say we're entirely immune from the "My ecosystem is better than your ecosystem!" Xbox vs Playstation type kids, nor the "What do you mean you're using a lambda there, instead of a closure!?!? Just fucking retire, amateur" elitists, but I find they're relatively few and far between
i agree, i get so much positive constructive comment replies when i post here. compare this to /r/programming where it its an echo chamber of the latest bleeding edge languages with a bunch of arrogantly opinionated neckbeards. people using rust and haskell where its not even the appropriate language for the problem just because???
It may not be worth the trouble if you already have a large code base that is working for you, but for new projects you may want to consider C#/ASP.NET. You get a lot of things JS just doesn't have like strong typing, helpful IDE features like real-time compiler error detection and intellisense (code completion and inline API browsing). You also get a lot more out of the box than Node.js can give you. For cross platform you can use .NET Core. .NET Framework is Windows only but as it is older you may find it more widely supported if you are looking for a library you need or whatever. So the version of .NET you should use will depend on those factors. As the other guy said TypeScript gives you tools that fix a lot of the problems with JavaScript so that is worth looking into to enhance existing Node.js projects (you can mix TypeScript and JavaScript so you don't have to convert everything at once).
You could use a simple bat file: start dotnet run watch -p folder1 start dotnet run watch -p folder2 start dotnet run watch -p folder3 start dotnet run watch -p folder4 that'll open 4 cmds and run the following command in that window. I don't recall the flag to dotnet run a different folder then the current, but you could also add in some cd commands in that thing above: start cmd /c "cd folder1 &amp;&amp; dotnet run watch" start cmd /c "cd folder2 &amp;&amp; dotnet run watch" start cmd /c "cd folder3 &amp;&amp; dotnet run watch" start cmd /c "cd folder4 &amp;&amp; dotnet run watch" Learning a few batch basics is pretty nice if you're gonna develop alot on Windows.
I haven't noticed anything bad, so I can't disagree with you! I will say just one observation I made, though. It seems that this sub and /r/csharp have a lot more "Please help with this beginner problem" than I was used to in other subs (/r/java for example). I don't know why that is.
afaik stylecop is old school, and not really going anywhere. i would suggest looking at editorconfig, see if that does what you need. newer versions of vs (mac and pc) support it. editorconfig works hand in hand with roslyn, so imo that is a better option. 
According to the ImageSharp [docs](https://docs.sixlabors.com/api/ImageSharp/SixLabors.ImageSharp.Image.html#SixLabors_ImageSharp_Image_Load_System_Byte___), it should be able co decode the raw byte array. What exception did it throw?
``` Unhandled Exception: System.NotSupportedException: Image cannot be loaded. Available decoders: - PNG : PngDecoder - GIF : GifDecoder - JPEG : JpegDecoder - BMP : BmpDecoder at SixLabors.ImageSharp.Image.Load[TPixel](Configuration config, Stream stream, IImageFormat&amp; format) at SixLabors.ImageSharp.Image.Load[TPixel](Configuration config, Byte[] data) ```
I use Stylecop at work, you can turn on/off rules so you don't have to make it force 'this' prefixes. We then have reshaped cleanup config based off the Stylecop config. 
StyleCop is still relevant and being used. Don’t use the original StyleCop project but rather the newer Visual Studio analyzers that use Roslyn to perform StyleCop while you type. https://www.nuget.org/packages/StyleCop.Analyzers/ Also, don’t limit yourself to StyleCop’s rules. The are a lot more Visual Studio analyzers out there. 
If you see bad comments, report them. No mod team has the time to go over every comment. 
I think its partially that everyone has come to expect nothing to be done about such things on reddit
StyleCop is great. You can turn off any rules you don't like. There are also two rules one for prefix with this and one for don't. Just disable one and enable the other. It's follows the style guidelines but you can change it if you want. It's great when working in teams to keep your styles in sync.
Probably people are used to r/programming, where the report button is basically a black hole.
I think you should try using IIS as a reversy proxy to create the challenge. I think Kestrel itself is not able to use Windows authentication, only behind a reverse proxy. If you're using Visual Studio, just fire it up as is in IIS Express, not Kestrel (so the console window should not pop up). 
you can use resharper with the stylecop ruleset. there is an extension in the gallery that configures it. the advantage of stylecop or other linters over just R# is you can get them to run as part of a CI process to catch issues from devs that may have turned off R# for performance reasons.
Yes. It is mandatory. We use the standard configuration but don't analyse designer files. I like it TBH. 
For System.Drawing in non-Core (Core may be the same way since at first glance it looks like they tried to make the API the same, I can't be sure though), you would create a new Bitmap object of the appropriate size and pixel depth for the raw data. Then you would call .LockBitmap and use the returned object to inject the raw pixel data. I forget the exact method but it involves the use of the Marshal object and such so you should probably look up an example of using LockBitmap. Once you do that you can .UnlockBitmap and then .Save it to a PNG.
You need to run inside of IIS or IIS Express to get Windows authentication information with requests. Kestrel itself does not do any Windows authentication. (Windows authentication also needs to be enabled for the application in IIS Manager.)
There are two methods I know of. 1. Use lock: https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/lock-statement 2. Create your own locking system to allow for things like detecting a held lock and doing something else, instead of just hanging until the lock is free. One possibility is to use FileStream to open files with specific FileAccess and FileShare settings to ensure any other attempts to open the file will fail (ensuring your lock) and closing the FileStream when you are done.
We do it at work, when I get in I'll post our startup. We use web listener not kestrel. 
https://github.com/brthor/Gofer.NET Inspired by celery, uses Redis as the backend, easy to use and setup. Disclaimer: I made it.
I feel pretty dumb right now. I guess I thought that `dotnet run` used IIS Express since uses the launchSettings.json file, but that was clearly a bad assumption on my part. I am wanting to avoid Visual Studio if possible (I prefer VS Code and the command line), but I will figure out how to run all of this from the command line later. Thanks for your help!
ReSharper’s code inspections can also be run via JetBrains.ReSharper.CommandLine on CI servers.
Put a breakpoint and see if you’re hitting the post method. Also, weirdly, sometimes the [FromBody] can cause problems. I always remove it from my REST methods 
Thanks for the suggestion. I realized my error was because I thought `dotnet run` used IIS Express under the hood, which was a bad assumption. It also sucked because Postman doesn't handle NTLM that well so I switched to Insomnia for testing the endpoint and I was able to troubleshoot faster. Thanks again!
Eh, I'm currently struggling with my my own elitist views of "why did you create all these parts yourself, there's a library for this, and a framework for this" and "how did you manage to make basic ADO.NET slower than Entity Framework?" and "guys, let's use classes and objects to represent our data instead of storing it in Excel and force everything to be text so that it doesn't ruin the data with its formatting." Sure, I might sound like a snob with my fancy types like int instead of string, and double instead of string, and datetime instead of string, but I can't help but feel like I'm right about this.
You need to have the appropriate bitmap header structures to be able to load the image data (otherwise the various routines won't know how the raw pixel data is laid out let alone color depth). The bitmap header information contains important details about the raw image bytes... like color depth, width &amp; height, and so forth. An actual BMP file looks like: [Bitmap file header](https://www.pinvoke.net/default.aspx/Structures.BITMAPFILEHEADER) [Bitmap info header](https://www.pinvoke.net/default.aspx/Structures/BITMAP.html) - though you probably actually want BITMAPV5HEADER... but I didn't see that on pinvoke (you need v5 because of the alpha stuff probably... 32bpp isn't argb)... but [this](https://github.com/jogibear9988/JFKCommonLibrary/blob/46ac95a311910c50b4509ec38cd82b85dc050d7d/JFKCommonLibrary/WPF/GhostCursor.cs) seems to contain a definition that on first glance looks right. optional color table optional icc color profile table the raw image bytes The wikipedia article on [bitmap file format](https://en.wikipedia.org/wiki/BMP_file_format) has good information... though it's pretty easy to get lost in unnecessary details. On whole working with raw image data (just the pixels) is a giant pain in the butt. So much ancient cruft is in the standard it's amazing ("Planes"? No system has used planes for decades). 
**BMP file format** The BMP file format, also known as bitmap image file or device independent bitmap (DIB) file format or simply a bitmap, is a raster graphics image file format used to store bitmap digital images, independently of the display device (such as a graphics adapter), especially on Microsoft Windows and OS/2 operating systems. The BMP file format is capable of storing two-dimensional digital images both monochrome and color, in various color depths, and optionally with data compression, alpha channels, and color profiles. The Windows Metafile (WMF) specification covers the BMP file format. Among others, wingdi.h defines BMP constants and structures. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
You'll most likely need to use the LoadPixelData method, especially this one [Image.LoadPixelData&lt;TPixel&gt;(byte\[\] data, int width, int height)](https://docs.sixlabors.com/api/ImageSharp/SixLabors.ImageSharp.Image.html#SixLabors_ImageSharp_Image_LoadPixelData__1_System_Byte___System_Int32_System_Int32_). Choose the appropriate TPixel from the SixLabors.ImageSharp.PixelFormats namespace. In your case, most likely [SixLabors.ImageSharp.PixelFormats.Rgba32](https://docs.sixlabors.com/api/ImageSharp/SixLabors.ImageSharp.PixelFormats.Rgba32.html). If you don't know the width and height of the image though, I'm not sure how you'd proceed. I've had success in the past using the LoadPixelData to load BGRA32 raw images decoded from Jpeg2000 through another library.
If I remove the \[FromBody\] then the POST receives NULL. If I leave it at is, I get this error now "Unexpected character encountered while parsing value: {. Path '', line 1, position 1." 
Is encrypted "plain-text" not secure? I'm new to this, but I was given the impression that this is safe to store: `Read-Host -Prompt "Insert password" -AsSecureString | ConvertFrom-SecureString` If you don't specify a key in `ConvertFrom-SecureString` it will encrypt with DPAPI `ConvertTo-SecureString` gets it back. Is it naive to do something similar in C#?
Rarely. One reasonably easy use case is going from a WPF `PasswordBox` to a native API. Anything involving managed IO is pretty much impossible to handle properly since it involves so many managed buffers outside of your control. Perhaps this will change now with more `Span&lt;T&gt;` and pipeline APIs that reduce the number of internal byte arrays etc.
Because you may sit on zero karma but most posts will have people properly(and politely) answering rather than just posting a link and/or telling people to use google/go through beginner tutorials. 
The theory is that if you have the password in memory as a string, something can read that memory and capture the password. My counter-argument is that if something can read your program's memory, it doesn't matter if one password is protected, they'll just steal everything else.
Resharper used to be a gold standard, but honestly since VS brought in Roslyn, Analyzers, and incorporated most of the best things from Resharper in it, its just not worth the performance issues it brings anymore. "StyleCop" isn't a standalone solution anymore, it's just a set of analyzers, working WITH VisualStudio's new standard way of doing what it does, whereas Resharper is still avoiding Roslyn and such in favor of its own (slow) engine if I remember right. Don't get me wrong, Resharper was great for a long time, but I just kind of feel like they went their own way and aren't really as relevant anymore. For instance, did you know most of the warnings you see in VS now are implemented as Analyzers? They basically opened that system up to everyone else, so I consider that the best option going forward. The editorconfig stuff for VS Code is different, but doesn't offer the same stuff, and isn't really extensible in the same way Analyzers are. All that said, StyleCop's Analyzer set is configurable like any set of analyzers, but you do have to take the time to select the right set for your team. That's usually an ongoing process as people find little annoyances, but the ones you mention are pretty much the standard ones everyone turns off. What I like to do is setup a repository for my analyzers that builds a NuGet package with the analyzers I like to use in my projects as NuGet dependencies. This pulls everything in at once, in a nice versioned package, so as changes are made and pushed to them I can update in my projects at my leisure without breaking things immediately with a GLOBAL file, etc., which I usually had issues with in shared team ReSharper files (their override system, for instance, is a pain in the neck). You can see what I do here: https://github.com/i8beef/StyleCopAnalyzers There are a couple of pains in the necks with it though 1. StyleCop requires a separate stylecop.json file to turn off certain things. My NuGet package handles this by adding it as a linked file in the projects its installed in though, so its not in your repo proper. 2. Analyzers are PER PROJECT not by solution, so you have to install it in every project in your solution. It does have its benefits as you might not want it in your test projects, etc., but it does mean you have to remember to update from the solution level package manager. 3. Editing your analyzer list with this is a pain, because you basically have to edit the file by hand, or you can edit in the Analyzers editor and then manually copy the changes over to the repo, checkin, wait for the build, pull the update, etc. But it's been worth it IMO, and once you have a good set, it doesn't change much. I use this for all of my personal projects to enforce style for committers, and to keep myself honest when doing stuff. I even like to turn on warnings as errors if I can to fail builds if you fail to follow the standard. Just remember, if they try and get you to install the tooling to do everything (i.e., the OLD StyleCop stuff thats all deprecated now), tell them they are doing it wrong, and should be using the analyzer sets.
I use VSCode as my daily editor now, and we have some Angular / [ASP.NET](https://ASP.NET) Core / Windows Auth projects ongoing. I've found the easiest way to deal with it is to disable auth for 'Development' environments and depend on being behind IIS in Test / Production, though that requires faking a user for development, which might not make sense for you if you are also using AD groups or attributes.
Protecting a *user* password still has value if it is likely used in other contexts like a Google account or AD credentials. It might not matter as much in the case of a generated config password.
The AD credentials are in the config file,which is why that file is encrypted. I'm using Windows certificate store to hold the decryption key so only the application's Window User account can decrypt it.
We use StyleCop with ReSharper as ReSharper has plugin for StyleCop which does live analysis.
Are you getting the content type when sending in the request from postman? Content-type: application/json 
Being based on the Roslyn analyzers framework, Stylecop works faster than Resharper, but its philosophy is terrible. I recommend shopping for a less opinionated analyzer, if one exists. Stylecop has this OCD-encouraged mindset where they just made EVERY rule they possibly could, and they're ON by default. Don't get me wrong, settling brace style debates, variable naming, even tabs vs spaces, all good ideas. Maybe even help decide some ground rules for where to do line breaks on long chains. These are basically the things Resharper does with its style rules. Style cop just wants to make a decision for everything, but here's the thing. Even if you follow all the rules 99% of the time--no big deal, I can adapt to whatever the style rules are--but there's **so many** rules that even at 99% agreement you will constantly find yourself wanting to make an exception for one of them. For an easy example, 2++ non-nested classes in a file is sometimes a really great organizational tool, which is why it's the norm in most languages--and for that matter most C# code bases included. People see classes are highly related and belong together, so they want them in the same file, but they don't want to deal with all the long namespaces of nested classes. This happens constantly. I find most of the style cop rules are in the same vein as that.
&gt; Perhaps this will change now with more Span&lt;T&gt; and pipeline APIs This has been my hope from day one of the announcements.
I haven't worked up a sample project yet (kind of an early turn in for me tonight) but I believe [This explanation from Microsoft](https://docs.microsoft.com/en-us/aspnet/web-api/overview/advanced/sending-html-form-data-part-1#sending_simple_types) might push you in the right direction. If that doesn't work when I have time tomorrow I'll try to mock up the project as you've explained it so I can see what the body and result looks like.
As far as I'm concerned, if they are capable of reading arbitrary RAM on my machine, they've already broken my security.
You missed the point of my statement completely.
Traditionally that phrase is followed by a clarification as to what you meant.
For example, security consultants will go as far as to design mobile apps to be more secure even when the device is rooted, as a way to get eliminate the majority of would-be hackers. Remember, security is a game of resources; with unlimited time and resources, most computers can be compromised, it's just a matter of whether you can make it difficult enough to not be worth it for the hacker. With issues like row hammer, you can never be too sure how much access other applications have on your computer.
Oh God don't remind me. I spent way too long trying to figure out how to use securestring for a custom deployment script, and then I tried to Integrate it with tfs deployment and found out they don't support it for passing in parameters. Nobody has ever tasted the dogfood.
I don't find that argument to be convincing. You're talking in generalities; I'm talking about a specific feature that I've never seen used correctly.
I also use StyleCop Analyzers, we use the default rules with the following modifications: - use tabs. - don't require documentation. It's extremely good for ensuring everyone on the team can understand and contribute code easily.
That overload tries to load an image file (e.g. one of the formats it lists). You don't have an image file, you have raw bitmap data. /u/KaraguezianHagop is on the right track below.
This should work: ``` int index = 0; using (Image&lt;Rgba32&gt; image = new Image&lt;Rgba32&gt;(width, height)) { for (int y = 0; y &lt; width; y++) { for (int x = 0; x &lt; height; x++) { Rgba32 pixel = image[x, y]; pixel.R = data[index++]; pixel.G = data[index++]; pixel.B = data[index++]; pixel.A = data[index++]; image[x, y] = pixel; } } } image.Save("somepath.png"); ```
I see SignalR talked about quite a bit, but apart from making a chat room, what else can you use it for? It seems to be for fast communication between clients?
The data you are sending to POST is not string, it's an object containing a string. Create a new class which contains string property called justatest and put the class as [FromBody] instead of string. Then it should work.
1. In terms of their respective ecosystems (frontend vs. backend), I would say that yes, the frontend gets more new and shiny features more often than the backend. After all it’s JS; regardless of your backend environment, you will utilize it for the the frontend and therefore will more often than not have more people working on the JS ecosystem and language as a whole. 2. Sanity. There was a reddit post once along the lines of HTML, CSS, and JS will feel like a bag of cats on fire to develop with once you’ve worked with a robust enterprise language. Disclaimer, I’m an enterprise Java/C# developer so I vastly prefer things like static typing (we use Angular, so luckily I get to use TS) and the ease of implementing design principles the OO way. 3. While I’m not exactly a grey beard of the dot com boom of yore, OO design principles drive massive enterprise code base that will not be deprecated anytime soon. The nature of software is to adapt and change, but things like SOLID and clean architecture will always be staples of professional programming. 
To be a good developer, you need to be a good problem solver, and then translate that into any programming language out there, that's about it. And when you're that good, terms like 'full stack' and all these don't matter, you're god-like. Whether Node.js or .NET Core, why not both. Write applications in both, in each, with each of them, many possibilities. In the end all languages are basically the same, yes the same, just the way they do their libraries and the syntax they have. And, how well they scale up, unless there's a scenario where one of them degrades/fails when e.g. "the amount of calls reaches 10 million", you can't really say one is bad and the other isn't.
All languages are definitely not the same. Take as example Javascript and C#, JS allows stupid stuff to do while C# doesn't. 
This. Once you get in to enterprise level development, if you're working full stack you appreciate the stability of a good back end language like C# over anything every time. JavaScript can do a lot of things, but having something type safe and 100% predictable actually makes your life a shit tonne easier to plan out. Once you've applied a solid architectural set of patterns to your back end development seems so much easier. There's a reason the Peter Griffin css meme exists
And this string representation is meant to be in this encrypted state and they won't be able to make sense of it. It's supposed to either be in this mangled encrypted state or in the securestring state. I thought plain text shouldn't occur.
Yeah, definitely not here. Any report I action 😊
&gt; The JIT in .NET 4.8 is based on .NET Core 2.1. All bug fixes and many code generation-based performance optimizations from .NET Core 2.1 are now available in the .NET Framework. What? Does that mean that .NET 4.8 uses same JIT as .NET Core? Or does that mean that same fixes and improvements were used, but the code is still different? Also, is this for both x86 and x64 or are they different?
Christ! Every time I read "the future of" something, I instinctively think that it is being discontinued or closed down.
It would be interesting to know whether Span&lt;T&gt; is optimized the same way as in dotnet core.
1) React and all your other languages listed are not comparable directly. React is a front end web library, the others either back end or languages used to build back end. Back end can include serving or generating the front end of course.You probably should include Node in there too as it grew up with the Angulars and Reacts. Experience with the tech will define your velocity more than any of the techs. That said, be sure you understand why you are using a tech and learn its strengths rather than bemoan it's weaknesses. 2) React served by Node with C# running WebAPI and SignalR separately (and a few extra bitts). I find Node and React easier to reason about and the documentation for that pairing is better. C#/WebApi/SignalR provide the interface to our back end systems which are also c#. It provides a logical separation that is helpful. 3) Yes and no. It (Functional) provides excellent support for specific problems, while OO excels in others. Weak typing is becoming popular in some JS environments, Typescript and Flow being two very different approaches. As for OO, EcsmaScript now has classes and of course Typescript does. The important thing about three is that each language evolves and each language can usually approximate any style. The trick is knowing which to use and when to mix them. OO with pure functions and immutable data is a happy blend for example. C#. LINQ was added to .net in 2007, so this is no rapid assimilation. Don't be dogmatic, be practical, flexible and understand your choices
So much this, I see people try use the legacy one instead of the Roslyn one all the time.
You can build Node.js enterprise applications but why you would do that? Javascript is a mess so when you maintain your code, it might be a mess and very hard to maintain, I mean this is a "big" project after all. My point is that all languages are definitely not the same, I hear this thing a lot but to be fair, it doesn't make sense. Languages are not the same, they might solve the "algorithms" the same way but application are not "algorithms"! When you will build an app with a language, you will rarely care with math algorithms when there are much focus on stuff like performance, good UI, features...etc Logical thinking is required in all languages(I can do that very well) but that's definitely not enough to say that all languages are the same, I mean logical thinking is a part of "programming" not "programming languages" so it's not worthy to mention it. Javascript and something like Java or C# are not the same, one is used in browser where it is sandboxes and have no hardware access or OS access while the others have much bigger hardware and OS access. Not to mention the "style" of programming is different, one is more toward being a functional language and the others are more toward being OOP, they are actually all multi-paradigm but this is just an example. This sentence of "All languages are the same" is just so wrong and I thought it has gone in the community, surprised that there are still people who agrees with that(no offense)
Yah i get what you mean, it's all good. Managing the details is good, just as well as knowing the bigger picture. And just a tiny note about "why would you do that", Walmart's eCommerce platform, Netflix, Paypal, Uber, Trello... they all build the systems using Node.js...
It's not like I'm against Node.js, I actually like it, it's so simple(even if I didn't learn it all yet) It's just after reading these comments, it feels like it's not the right tool for big applications and I agree with it. After thinking, these services you mentioned may only use a piece developed by Node.js I guess, and it may also return to ASP.NET's closed source.
This article couldn’t have come at a better time for me. Thanks for sharing!
When they use the same name to build something similar its fairly common. 
It's all said in last paragraph.
It's great if you find it simple. If I were you, I would check out how they use it though, guessing is just so... un-cody. ;)
Agree, try asking anything on androiddev... 
[removed]
Main differences / advantages that I see are: * You write your script entirely in c# so it is easier to learn / faster to write your build script. Time is money :) * You have access to whole .net ecosystem. Meaning that you can use any .net library or write any custom code that you want and not just use predefined tasks like in other tools(Cake, Nuke). * Run any external program, command, tool not just the ones that are predefined in tasks (Cake, Nuke). * Easily automate deployments remotely via the FlubuCore Web API. * Possibility to test and debug your script
&gt; I thought plain text shouldn't occur. Correct. But how do you get the string in the first place? And how do you use it for things like REST calls?
I'm the author of that sample. It is built with .NET Core and Azure Durable Functions. Let me know if you have questions.
Not to mention the ease of testability when use good design. We’re a BDD/TDD shop, so being able to nail down unit tests on feature branches to give you additional assistance that your code is solid is awesome.
Not “stuck” at all. Rather, “developers not attracted by the latest shiniest doodad on the block”.
Using a SecureString will reduce the attack surface area though. It would be like having your front door unlocked and refusing to lock it because a robbery could have taken place while unlocked. It still makes sense to lock it because you'll protect against less sophisticated robbers. 
Not all .NET Core runtimes support all .NET Core features. Your best bet would be to target mono compiled to WebAssembly and host it as a PWA. 
Uh, I know how they "use" it. Your talking just doesn't make any sense.
1. You write your script in powershell with cake. Using c# alliases. 2,3: Yes you can but you need to write cake addins before you can use it in your script. This means extra work and u need to know how to write addins which is not needed with flubu. You just write any c# code using any libraries and execute the script when you are done.
That's....not correct in the slightest? Cake is just a variation of csx. So it's just C# with script extensions. And you can absolutely add libraries as nuget packages or raw assemblies and then reference them. Addins just provide a convenient interface.
[removed]
Full disclosure, I am one of the maintainers of the Cake project... While I welcome comparisons between Cake and other cross platform build systems, I do feel that we need to set the record straight on a couple of things here... * In Cake today, you can absolutely write your scripts entirely in C# (Cake simply brings some aliases along with it, we call this the Cake DSL, to make interacting with certain things, easier (in our opinion). The only part of the Cake eco-system that uses PowerShell is the bootstrapper that initially executes the Cake executable. Is it possible that you could be confusing Cake with psake? In Visual Studio Code, Cake scripts also benefit from intellisense when writing Cake scripts. * With Cake you also have access to everything in .Net. There is no requirement to write addins for anything to work. Again, addins bring additions to the Cake DSL, but these are not a requirement. As pointed out by alleycat5, you can directly reference a nuget package, for example Newtonsoft, and immediately start using it in your Cake script, nothing else is required. * You can absolutely start doing that today, with no need for any addins. There is a built in alias for StartProcess, which is a wrapper around the .Net Process class, which allows you to call any command line tool, along with arguments. Again though, StartProcess is an alias for convenience. If you want to instantiate a Process class directly, and execute it, there is nothing to stop you doing that directly in your Cake script. * I am not familiar with the FlubuCore Web API, so I can't comment on this. * It is absolutely possible to do this today with your Cake scripts as well. Please feel to reach out if you need further clarifications.
We've just had a nightmare tracking down a similar issue. Has there been any Windows updates installed lately? Some of the updates from July have a known issue that causes Access Denied errors on COM Components. Server 2008r2: https://support.microsoft.com/en-gb/help/4340004/security-only-update-for-net-framework-3-5-1-4-5-2-4-6-4-6-1-4-6-2-4-7 Server 2012: KB 4338419, KB 4338605 and KB 4338613 
Is there a way to schedule certain jobs for certain machines? Is run the app on 2 computers and then schedule a job to run only on one machine?
What's your "selling" point against Quartz?
[removed]
Good point. I wonder if a secure wipe could be done on a span of the string? Span&lt;char&gt; spanToSecurelyWipe = sensitiveString.AsSpan(); 
You're welcome. It's useful to know you can "dip your toe" in these choppy .js waters without diving in head-first right?! :-)
Is it really windows only?
The x86 codebase differs between .Net Core and .Net Framework -- .Net Core uses RyuJit; .Net Framework uses jit32. There are no plans to change this in 4.8. The x64 jit codebase is shared between .Net Core and .Net Framework. As this post indicates, 4.8 and Core 2.1 are using the same jit sources. However there are some `#ifdefs` in the jit sources -- not many, but some (look for `FEATURE_CORECLR`) that differ between the two builds. And the runtime also passes a number of flags to the jit to guide code generation. And those flag values can differ on .Net Core and .Net Framework. So the jit behavior on .Net Framework can differ from the behavior on .Net Core. But in many cases the behavior is identical. Support for "fast span" is one of those areas with differences -- as others have noted we did not implement the runtime and framework changes needed to support fast span because of concerns over compatibility and risk.
Running .NET Core Apps within a Windows Desktop Application is limited to 64bit Windows in this first release, but will be looking it to support macOS in the near future and if there's demand for it can look at supporting Linux as well.
Do you have a source for that? This is the first I've heard of that.
They seem to be using their own brand of CefGlue over at [https://www.nuget.org/packages?q=ServiceStack.CefGlue](https://www.nuget.org/packages?q=ServiceStack.CefGlue) and [https://github.com/ServiceStack/ServiceStack.CefGlue](https://github.com/ServiceStack/ServiceStack.CefGlue), which only seems to have a win64 binary (and win64 build scripts). It seems that it could very well be ported (everything except cef seems portable), but right now is not portable..
Hit this problem several times at... well, some previous workplaces. Not for classic ASP, but for literally everything that runs in Windows, and needs permission for something, and you don't know what the user for that app-pool is, because that usually *is* the problem. So, here's a "classic trick" that usually always "solves all permission issues". Albeit a dirty lazy fucking hack. Just go to the folder, hit properties. Go to the "Security Tab", hit "Add", write "Everyone", then hit "Check names". Then, hit the "Allow"-checkbox for "Everyone", and... well, now everybody has access to that folder, so nobody is locked out, brilliant! This isn't a good solution, heck; this is a terrible solution. But it can be used to check whether that's the actual directory/file which you're lacking permissions for. Although, once "this hack solves this problem", I usually just leave it "as is", let's just hope that outdated Windows password is still secure.
FYI the CefGlue bindings is a .NET Standard 2.0 project: https://github.com/ServiceStack/ServiceStack.CefGlue/tree/master/src/ServiceStack.CefGlue Which contains as much portable code as possible and was designed for portability in mind. The Win 64 bindings are just a glue around the common classes: https://github.com/ServiceStack/ServiceStack.CefGlue/tree/master/src/ServiceStack.CefGlue.Win64 If you look at the Custom .NET Core Apps example (http://docs.servicestack.net/releases/v5.4#custom-net-core-desktop-apps) it shows how to run it in Windows: var config = new CefConfig(debug:true) { Args = args, StartUrl = startUrl, HideConsoleWindow = false, }; return CefPlatformWindows.Start(config); The idea is that for other platforms you can just the same config and run: return CefPlatformMacOS.Start(config); 
[removed]
Why would someone choose this against Hangfire?
Hi, the main reason to why I built this was because I could not find any background processing library that would allow me to write integration tests in a simple way. Lets say that you have a API endpoint that schedules jobs for sending emails with a delay of 8 hours. And you want to write a test that calls that API and asserts that the emails have been after the 8 hours has passed. That is not something that you can do with Hangfire, unless you want the test to actually run for 8 hours. But with Minion you can simulate that 8 hours has passed in a simple way. Here's how such a test could look like: [https://github.com/FrodaSE/Minion/blob/dev/samples/Minion.IntegrationTestingSample/Program.cs](https://github.com/FrodaSE/Minion/blob/dev/samples/Minion.IntegrationTestingSample/Program.cs)
Ok as it seems I did some injustice to Cake and yes you were right I was referring to psake. But still Cake is basically C# scripting and some preprocessor directives, meaning that it requires a certain learning curve. Many IDE features are not supported or are only supported in vscode. Flubu takes the usual C# project approach, where everything works as it should. 
Windows passwords are meaningless if you use Everyone. Does exactly what it says on the tin, don't even need to authenticate.
Great work! Curious why you didn't opt to use Electron?
The purpose is to be able to embed .NET Core Apps within Desktop Windows Applications to give them more utility and allow you to bundle a UI with your .NET App, so in essence it’s like Electron for .NET Core. I also want to make easy as possible for us and everyone else to create, discover and distribute useful .NET Core Apps. I don’t believe in WinForms/WPF/UWP/XAML for building native UI’s, IMO they’re antiquated dead-end technologies that can’t compete with the innovation and engineering effort invested in Chrome. I expect MS to eventually deliver a XAML based solution for .NET Core which IMO is the wrong approach that’s goes against where most of the innovation is happening - in using a Chrome rendering engine to render UIs.
Oh ya I totally understand why wrapping Chromium around an ASP.NET Core app is a cool idea. We had plans to do that for a project at work last fall. I guess what I'm asking is why you went the route of writing your own Chromium wrapper instead of leveraging Electron and just telling an instance of that to host and view the ASP.NET Core app. That's what we were planning on doing for our project :)
Oh very true. Good call. I forgot that Electron was all about sharing a Node JS run-time with a Chromium instance.
I'd expect they're just going to use .NET Core to do more of the same to develop Windows-only XAML/WPF Apps instead of adopting a Chrome rendering engine to render an embedded .NET Core server UI.
Didn't know I could control it, for some reason it used the last image instead of the first. I don't see any way to change it now so maybe I missed the edit window?
Yes. I work on the jit. And you're welcome. I suspect sometimes we hold back on details in the blog posts because they are hard to describe concisely and don't age well. For .Net Framework 4.8 compatibility and stability are preeminent concerns. And sometimes that means we can't be aggressive with innovations, especially innovations that cut across large parts of the code base.
I did see it, but I prefer all apps to use the same CEF rendering engine, one of the benefits of electron is that you can use advanced Chrome features instead of trying to support multi-browsers where we can interop directly with CEF's native APIs instead of a poorer abstraction. Also since all Web Apps use the same `app` .dll most Web Apps are super small, e.g. you can install a multi-user OAuth-enabled SQLite powered blogging App in 36kb .zip with: $ app install blog Or install a Redis Admin UI in 161kb .zip (most of that being bootstrap.css + redis.ico) with: $ app install redis In the end to get a self-contained .NET Core executable you need to ship the .NET Core runtime and all .dll dependencies so you're looking at a large download either way. E.g. the self-contained .NET Core executable [1] is 121MB .zip download of 83MB 7-zip .7z archive. Basically having a rich integration with CEF's advanced web technologies is a higher priority then the smallest download size which would need to use a different rendering engine per OS. [1]: http://docs.servicestack.net/releases/v5.4#publishing-a-self-contained-windows-64-executable
Ok, this all makes good sense. 
Ok fine. Have fun with your coding man.
From the error message, I believe it is permission issue. Have you test to give full permission to your folder? Maybe the permission has disappeared.
This is a very timely sample /u/MaximRouiller. I've just started looking into Durable Functions and watched the session from DotnetConf for a scraper I want to build as well, so this will come in handy. Thanks for the sample! One quick question: In your sample the orchestration is kicked off using an HTTP trigger. Can this also be done with a timer trigger? I would like the process to run automatically at a specified time every day.
&gt; the developers still stuck on .net framework. This is majority of .NET developers.
I've tried this and it's pretty good https://www.red-gate.com/products/sql-development/sql-data-generator/index If you roll your own you would probably use https://github.com/bchavez/Bogus/blob/master/README.md
From memory this means all accounts rather than anonymous. Exception is the guest account which should be disabled. 
COM objects also have accounts registered against them not just the app pool. Check the component control panel applet. 
Wouldn't that be "Authenticated Users"?
Cool, thanks!
Yeah you’re right Everyone is basically Authenticated Users plus Guest. /me bows head I shame. 
Have you looked at [Qml.Net](https://github.com/pauldotknopf/Qml.Net)? I'm curious your thoughts on it.
I haven't, but it just looks like QML bindings for .NET? So it looks useful if you want to use QML to develop Desktop Apps, but not if you want an embedded Chrome renderer to render the UI. I'm basically short against any framework not using a Web dev model to develop Desktop Apps. I'd use them for developing iOS/Android Mobile Apps since their utility and react is far greater than Desktop Apps, but all innovation for developing Desktop Apps is moving towards wrapping a WebView/Chrome UI for their increased productivity, portability, reuse, access to Web technologies and plethora of JS/CSS libraries available. The Exceptions to this are React Native (promising but ran into lots of issues) and Flutter (still developing) \[1\] since they provide a similarly productive, live-reload dev model. I no longer have any patience for a dev model that requires waiting for build times to see UI changes and don't believe any Desktop framework that requires it has a future. \[1\] [https://github.com/google/flutter-desktop-embedding](https://github.com/google/flutter-desktop-embedding)
so the winforms app built with .Net core 3 can be run on Mac or Linux too?
The .NET Core 3 announcement \[1\] only says " You will be able to run new and existing Windows desktop applications on .NET Core" with the diagram showing the UI frameworks are in an "Windows-only" Desktop Pack. &amp;#x200B; \[1\] [https://blogs.msdn.microsoft.com/dotnet/2018/05/07/net-core-3-and-support-for-windows-desktop-applications/](https://blogs.msdn.microsoft.com/dotnet/2018/05/07/net-core-3-and-support-for-windows-desktop-applications/) &amp;#x200B;
You might want to implement a repository pattern for data access. This allows for testing independent from the database. &amp;#x200B; I generally have used database first, since the place I work for has data in SQL already. &amp;#x200B; &amp;#x200B; [https://docs.microsoft.com/en-us/aspnet/core/fundamentals/repository-pattern?view=aspnetcore-2.1](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/repository-pattern?view=aspnetcore-2.1) &amp;#x200B; &amp;#x200B;
Looks like a really good series. It seems to cover everything I'm doing at an enterprise level already so it's definitely relevant. I'll be excited to see if you have any hints/tips/tricks or different patterns that we have not used. 
I can't wait to read this. Over the last 3 years I've been building a web service in Rust and C#, but instead of binding tightly with the FFI I just put a service gap between the languages, which is cool because it forces something representing a (poor) microservice architecture. I'm super interested to read this and see what the use case is for actually binding the languages together like this. I can see the case where you put the performance-critical stuff in Rust for sure.
I’m not sure how I feel about the initial scheduling being part of the scheduler, but the **re-scheduling** being the responsibility of the job. It seems as if this breaks SRP as the schedule should not be a job concern at any point.
It's a pity that these libraries have nearly no documentation available on them.
Agreed, there's room for improvement. Sure their documentation is OSS, so anyone could contribute. But there's so much internal knowledge that authors needs to assist.
Is there any way to use edge instead of CEF? Edge is a part of windows and I think it would reduce the app sizes by a lot. 
It does not use Microsoft Edge on Windows (apparently). 
Not in this project whose goal is to use CEF everywhere (ala Electron) which is a priority over download size \[1\] \[1\] [https://www.reddit.com/r/dotnet/comments/9gy32x/net\_core\_windows\_desktop\_apps/e68b1h0/](https://www.reddit.com/r/dotnet/comments/9gy32x/net_core_windows_desktop_apps/e68b1h0/)
Glad you've reminded me - I was meant to add to the README that you have to execute: Commandr.Process(args) wherever in Main(). I didn't want it to be automatic, because that would mean it could either run too early or too late. Thanks for your input!
Thank you again for saving my hide :)
You have to put CmdController.Process() anywhere in Main. I didn't make it automatic because that means most of the cases it would run too early or too late, sometimes you just want to initialize stuff before you start executing any methods. Thank you for saving my hide, the README has now been updated with info about that.
You can add tables and things with code first to an existing database, just so you're aware, I just did that with one of mine to try it out. 
https://www.mockaroo.com/ is another one that creates SQL data for you.
Thanks!
Hopefully, you'll find some new tools that could be used on a daily basis :).
Interesting I haven't tried it....it would definitely make my life easier in some situations. I will give it a shot :). &amp;#x200B; &amp;#x200B;
What part confuses you? Loading balancing is part of the service provider. It might be hardware or software. It takes the requests and distributes them... 
Why pay when there is free stuff online? https://design.tutsplus.com/tutorials/how-to-draw-animals-zebras-and-giraffes--cms-23683
No description? I'm not sure I'll even click the link. Maybe...
Haha, remiss of me. &amp;#x200B; Maybe it's so god that no description is required! &amp;#x200B; I'm not connected with this show in any way btw. I listened to a few episodes on my commute recently, and thought it was worth sharing. 
Subscribed :)
 Haha. Ok, I'll check it out! An organic description helps legitimize your post but no more so than a quick reply! Thanks for sharing.
Sounds great, can't wait to look around
Lifted from the website: &amp;#x200B; So firstly, I don't work for Microsoft I'm just a developer who has been working with .NET Core for 2 years (since around the RTM) and has been writing about it for almost as long. Additionally, any views or opinions that I express during the course of this podcast are mine and are in no way related to Microsoft or any of their subsidiaries. The first few episodes of the podcast are going to be me setting things up and providing you with a little bit of history and background framing. I've got episodes lined up which cover: &amp;#x200B; * The History of .NET Core * Getting Started with .NET Core * What the .NET Standard is? * What Mono is? * ASP.NET Core itself And I'll be expanding that list in the coming weeks. The idea is to give you a little background information on what these things are before diving into the hows and whys. &amp;#x200B;
But what about .NET Rocks?
no Microsoft NEVER directly earned money by charging people to develop in .NET. They want you to use their (pay to use) ecosystems, then Windows, now Azure. The reason they are ending support or 2.1 is because they will have a newer version out that they want people to migrate to. As time marches on, older versions will cost more (time + money wise) to support thus they want people to keep moving to newer versions.
It's open source and an open standard. Oracle have been mismanaging Java since they took it off Sun. Their DB solutions are probably best described as legacy, they are monetising everything they can. Microsoft are also monetising their products. The difference between them and oracle is that they have products. Windows, Office, Excel, VS and Azure to name just five popular ones. So worst case we'd have an open source framework, toolchain and language spec. All the .net core frameworks have limited length lts versions. the intention is to innovate in shoter iterations. the LTS version would be functionally ancient if it had a ten year lts agreement. 
Almost certainly not. Microsoft makes money from .NET when you pay to deploy it on Azure - the reduction in development in .NET that they would see and the ensuing reduction in use of Azure would be disastrous in my opinion. Oracle is charging for Java itself because nobody wants to pay for their cloud offering.
You can start learning React now in JSFiddle.net or alterative as it's a client side library. My preference is to serve React from Node and use ASP.NET WebAPI for the backend. I found, and it may be better now, that the integration with VS was a bit wonky and there were far fewer examples at all skill levels. 
Would be lovely if it had a simple `PrintHelp` function that collates all available options (may be an extra attribute for description?) and shows them formatted :) Good stuff though!
Looks like you've really done some great groundwork here. Repo is gold, looking forward to more.
I get where you are going with this. I think it would be less hardcoded if I added option to fetch all available commands and their description via a CmdController method - then let the user write a method to print out that data. What do you think?
I'm the author of nuke, and I'm completely confused how you come to these conclusions.
Microsoft have NEVER won a cent with .Net, they make money with Windows, Office, Azure and Visual Studio (Pro and Ent.)! Do your really beleive such "stupid fake news"? What do you think about the port of SQL Server to Linux? Do you think than Microsoft want buy all the Linux world? No seriously stop kidding! Instead to lost a lot of time with such silly things, learn .Net or any other language/platform currently used (JS, Python, PHP, ...)
This is great to see, it parallels an idea I've had rolling around in the back of my head for a little while now.
I like the sound of that.
If you make a Web API with. Net Core you wouldn't need to add React to it. The API is your backend code, and your React site would just make RESTful calls to your API's endpoints. That way you have full separation of concerns and don't have to combine anything. I did exactly this for a coding assessment a year ago and hosted both the React frontend and Web API backend (written in .Net Core) in Azure, with SQL Server for the database. Couldn't have been easier. 
It's so boring
What kind of app are you planning to build? I would choose #1 only for apps with relatively simple views and user interactions, and don't care about SPA. If you're thinking of rendering that JSX server-side along with the cshtml, you'll have to use [ReactJS.NET](https://ReactJS.NET), otherwise it'll have to be transpiled client-side with babel, which will affect performance. The React template is a better choice for rich, complex SPA development; it doesn't mix client-side code with server-side, and just lets create-react-app (standard tool from React) to take care the client-side dependencies and build (Node.js is only for this, you don't need it for hosting). The [ASP.NET](https://ASP.NET) side of it is just for Web APIs serving the data. What this template brings is the convenience of having everything in a single project, although larger development would typically separate them out. 
You don't need Node.js to be running for the site. You app would be a Single Page Application where the index.html holds the JavaScript code for your React app and you'd just need something to serve it up. AWS uses S3. Azure could be Blob Storage (my Azure is rusty). &amp;#x200B; My projects current production web interface is in React and our API is .NET Core 2.1 and they are fully separated in AWS. Works really nicely
Your post has been removed. Self promotion posts are not allowed.
For sure, I’m going to try adding a react page to a site I’m playing with.
Yawn. .net diets and home renovation more like.
That's a good point. I will take that into consideration. But for some workloads the re-scheduling is part of the job. For an example, if I need to poll a server every 2 seconds until a get the expected result back. Then the job needs to reschedule itself if it didn't receive the expected result, and it needs to end if it did. &amp;#x200B;
You will just have to configure the regex matches for your conventional scheme 
Is there a release date for the series?
This looks good, ill give it a go.
Not a specific one, we will probably release a few episodes at once (a few parts in total), hopefully starting next month.
Already looked at NAudio?
Been using this in Dev for a few days and I have to say... It's super! Virtually bug free and very good feedback.
It must be that happy time again....
Is NAudio cross platform? 
I don't have experience but I think ffmpeg is pretty cross platform https://github.com/tomaszzmuda/Xabe.FFmpeg 
NAudio have a NetStandard branch but it hasn't been released yet. It looks like it isn't too far away from being production ready and perhaps OP you could dogfood that until it gets released? Certainly sounds a lot simpler than the the P/Invoke way, which tbh, makes me shudder. I'm looking forward to when .Net Core matures with better System.Drawing and introduces a useful System.Audio lib for cross-platform media.
Hey, I can't really see an advantage in Option #1 for a new project (when you know from the beginning you're going to use React). Here's why... Option #2 essentially creates a standard [ASP.NET](https://ASP.NET) Core Web API project, and a standard React app (using "Create React App") and lumps them together in one project. The major benefit (over option #1) is that the steps needed to setup a development environment for React are all done for you, So, for example, to use JSX you need a step to compile this JSX code into valid javascript code which the browser can render. You *could* [configure that compilation step yourself](https://jonhilton.net/use-react-in-your-existing-asp-net-app/), but "Create React App" does it for you and takes care of all the little details. **node.js not needed** When you run a React project, it doesn't need node.js or anything like that, it's basically just html and javsascript running in the browser. The "back-end" for your project (the bit which runs on the server) will be your [ASP.NET](https://ASP.NET) Core Web API project. I can see why you would think node.js is needed. All the talk of NPM and node\_modules can be misleading. NPM (and it's alternative/competitor, Yarn) is really just a convenient way to get third party javascript libraries into your front-end (React) application. Think of it as "NuGet" for front-end. You could equally go off and find those libraries .js files yourself, copy them into your project and reference them from there. That would just be a lot of extra work when you can use npm/yarn to bring them in automatically.
How about [BASS](https://www.un4seen.com/)? I've used the C API for a quick Linux application just to try it out, and the result was clean and simple enough. The library itself is written in C, but a wrapper called [BASS .NET](http://bass.radio42.com/help/) has already been written. The library has pretty extensive support for formats (WAV, MP3, WMA, AAC, OGG, Opus, FLAC, Audio CD, even retro MOD music...), it can perform optional audio post-processing, supports various extensions, and supports playing regular audio samples as well as streaming audio from the web. It also supports recording audio. It doesn't use .NET Core though, but Mono for macOS X and Linux, and Xamarin for Android and iOS. Not sure if or how much this matters though.
I listen to .NET Rocks but it is a bit enterprisey so an alternative is good.
I would suggest two distinct sites/projects, one for the API and one for the UI.
I'll have to investigate this. Thanks for linking.
the company I work at is migrating to angular latest backed with .net core, so i guess so
What I heard is that Angular will now support prolonged support. Which means every next version will be an addition to the current version, rather than a sorta remake.
My team is using Angular 6 for frontend on a new app and I have thoroughly enjoyed it. Angular 6 + NGRX has been an awesome experience. We tackled this coming from AngularJS 1.5.
I've done more P/Invoke stuff in my life than I'm willing to admit; it's really nothing to me. I don't really need complex audio control &amp; mixing. Simple playback is really all I need.
Angular 6 + .NET Core So good it's not even funny, Typescript and C# is the DREAM (until Blazor of course)
4.8 will be the last release of framework. Moving forward, all new apps should be built in .net core 
I don't envy you! What version of .net core are you using?
Why not both!
Personally using it right now, Enterprise environment 
I don't use it, used I think 4 or 5 though. Now I use Vue I'd not use anything else, its so good. Using Angular and React shows you how painful things can be. Vue shows you how good things can be.
React Template (dotnet new react). Then delete the ClientApp folder, and make a new project using create-react-app (just to get the latest features)
Are they doing this energetically or are the devs hanging their heads when they come to work?
I'm working with 2.1 right now. But the the native libraries I've written I try to target .NET standard 1.6. This is one of the ones I'm working on right now: https://gitlab.com/define-private-public/SharpCamera/ (check out the `libgphoto2`
I was, for a while and Im using mvc aspnet core and I'm a lot happier. Angular was too much boilerplate 
Working url: [](http://findnerd.com/list/view/Importance-of-Microsoft—NET-Development-Services-in-Todays-Processes/39742/)
Some of our enterprise projects are written in Angular 6. It is a framework of choice for some our business units, because it is perceived as an opinionated, reliable, and all-inclusive platform that makes most of the decisions for the teams in terms of best practices, programming style, and choice of utility libraries. When you have large teams with skill levels all over the place, this is quite important. Angular 6 has come a long way from Angular 2 in terms of stability and performance. So yes, it is still definitely considered as a viable platform. You can check the npm statistics of how many downloads of its core packages compared with the other frameworks. It is still significant: [https://www.npmtrends.com/@angular/core-vs-angular-vs-react-vs-vue](https://www.npmtrends.com/@angular/core-vs-angular-vs-react-vs-vue) &amp;#x200B;
You could actually use free zebra designer, create labels there and then get the zpl code that way. &amp;#x200B; How to get ZPL code from the designer: [https://stackoverflow.com/questions/13586865/get-zpl-code-from-zebra-designer](https://stackoverflow.com/questions/13586865/get-zpl-code-from-zebra-designer) &amp;#x200B; Here is a link to the software: [https://www.zebra.com/us/en/products/software/barcode-printers/zebralink/zebra-designer.html](https://www.zebra.com/us/en/products/software/barcode-printers/zebralink/zebra-designer.html)
If you're going to go route #2, use the asp.net core 2.1+ react templates. That templates uses create-react-app as the base for react, whereas asp.net core 2.0 uses...something else. You have to dig deeper into webpack config and stuff like that to get more things working correctly than you do with the 2.1 templates. If you don't know what create-react-app is, I suggest looking it up. It's basically the best way to get up and running with a new react app, and is a facebook-maintained package.
Angular would basically replace the views and your net code would just be apis called by angular 
I wonder if you could use a persistent Reddis cache as your primary data source. They are fast scalable and reliable Accessable clients 
Show host here. That's exactly it. I was incredibly lucky to have Dustin Metzgar on episode 3. He was, until quite recently, on both the Framework and Core teams for a long time. The plan is to mark Framework as "Done" at release 4.8, it'll still be supported though. Each time an update to Windows is released, it resets the support timeout on Framework. This is because parts of Windows require Framework. 
Show host here. I'm sorry that that quality isn't up to snuff. I'm looking into newer mics, I'm currently using a Blue Yeti. I'm also looking for better ways to make my voice sound better. I'll admit that I was in the middle of a cold when I recorded the first few episodes, so hopefully the next few episodes (already recorded, edited and uploaded) are better.
Yeah, this. Use a distributed cache as your system of record which asynchronously persists to a data store for long term storage. You would almost never hit the database yourself outside of backup/restore. Similar model is implemented with Apache geode http://geode.apache.org/
So static html files?
Yes, we do have a service layer, with DTOs. That doesn't change that we would like to retrieve objects from a database while retrieving some navigation properties from a cache without some messy code manually mapping things.
.NET Core and Angular 5 in a 3 month old app. Enterprise. Poised for Angular 6 as soon as a UI library is updated. 
Why not ETL from the reference DB to the main DB every so often or if they are on the same DB server just create a view to join what you need. 
Separate DB 'servers' on Azure. Otherwise I'd say just create a linked server and call it a day. Having said that, one of the questions is whether they need to be separate DB servers or even separate DBs. It means our APIs will use the same DB as our web app, and the main concern is about scaling. The APIs will receive very large amounts of data. The website doesn't need much DB performance in comparison.
Thanks for the support???
It's some usual enterprise crap, some of its ye old legacy ASP.NET MVC stuff with bits of Vue on pages. Some of it's API based Vue SPA's. Don't know about how many users use it (management problems) but I'd say overall a couple of hundred people at various organisations. At home I have some Vue SPA's too.
Why would it need to be messy? You can cleanly create a POCO class with data from multiple data stores.. That’s a regular thing. Why does it need to be a navigation property?
I am. It's great. I can write code significantly faster than angularjs.
Why would you need my support? It's not really constructive either to declare a black and white opinion based on just "some fiddling", even less when the subject is nontrivial. I would say there's time and place for every one of those frameworks in modern web development and you need to consider every one of them in enterprise world. There you are juggling with time, value and quality.
There's absolutely no reason to believe anything he said is a hobbyist.
Why? 20 lines of code, will take you five minutes to make. Simplest is often best.
I wouldn't use MVC with angular. I use angular as my front end exclusively, and.Net core APIs as my service layer with EF Core and Sql Server.
Well it wasn't really an educated answer either. I could have been less blunt about it but hey, what's said is said.
I am curious about your gripes with angular vs Vue. I'm on a medium sized dev team. We're on angular with multiple projects (both v2 and v5), we have never explored Vue. Can you give some insight into the differences?
 &gt; Oracle or Microsoft cannot make these projects closed source &gt; and start charging for them Oracle will start to charge for certain java updates. From [.NET Foundation/About](https://dotnetfoundation.org/About) &gt; **Financial support** &gt; While we do not provide grants or funding for projects, we can help you &gt; accept, invoice, and process in-kind donations or those earmarked for &gt; donation on behalf of the individual projects. As a U.S. tax-exempt &gt; non-profit organization (501.(c)(6)), there are some limits to what &gt; we can do to support you from a financial perspective This does not sound that the foundation sponsors the development of .NET Core. My phrasing *the past Microsoft earned money* is unfortunate and misleading. They are still making money and will continue to do so. With SQL Server 2017 they start to sell SQL Server for Linux. Nonetheless maintaining .NET Core for Linux does cost them money. Based on the success of their commercial linux projects they might start to charge for updates. Currently this is only a speculation without any foundation. &gt; A sensational title and a post with unrelated links/info. What title would be better to ask if it would be possible that msft might charge for updates?
Angular 6 + .NET Core 2.1 is the company standard for new applications. &amp;#x200B; We have a 3 year old application done in AngularJS that we are now going to do a side-by-side migration to Angular 6.
When Angular2 first came out we didn't think it was a good idea to use in an enterprise level application. So we continued to use Angular JS for our new project. We had a small project to build last month, our front-end developers followed Maximilian Schwarzmüller's [Angular 6 (formerly Angular 2) - The Complete Guide](https://www.udemy.com/the-complete-guide-to-angular-2/) and gave Angular 6 a try. At the end they had frustrations with some of the new concepts but overall they think it is mature enough to use now. Backend: [ASP.Net](https://ASP.Net) C# Rest API with SQL Server
I have used React, Vue, Mithril, Angularjs and Angular@6 with different projects. Angular is by far the most interesting and advanced framework. You have a large web app? Use Angular 6. Its a brilliant library with TypeScript.
Apple dammit.
You decided I'm simply a "hobbyist" before I even replied.
I prefer traditional MVC applications but why wouldn’t people be using Angular? Is there yet another front end SPA framework?
Docker
You said angular and react are painful and vue is not without any reasoning. That seemed quite ignorant to me. That's all.
I can say with certainty that it possibly might if it gets to that stage.
Does anyone know of any other serious webassembly frontend frameworks?
It never will compete with those for one simple reason: The market is going to get split into a "backwards compatible" (e.g. IE11+) frameworks and modern browser split, with WebAssembly frameworks being squarely in the modern browser category, while Angular, React, Node, etc are fully backwards compatible with IE11. Once WebAssembly is fully baked and widely available, you'll likely see new frameworks that compete with Blazor, and the question won't be Angular Vs. Blazer, it will be Blazor Vs. other WebAssembly frameworks (with Angular, React, Node, etc remaining around for legacy browsers). 
It's been about a year since I used it but: It's so cumbersome to use parent/child components. I don't even remember the specifics anymore but looking at https://angular.io/guide/component-interaction and also https://www.sitepoint.com/angular-2-components-inputs-outputs/ I'm totally lost as to what the hell is even going on. Surely a component based framework should be easier to reason about? In Vue there is none of this `@Input @Output EventEmitter` nonsense. Here's a super simple example of a Vue component with a child component emitting events. Here's a simple example I wrote in a few minutes (ignore any weird indentation, CodeSandbox doesn't format properly). https://codesandbox.io/s/llqvxv1rxz As you can see, it's immediately obvious where the components are being imported and used. Vue promotes the use of it's .vue files (optional but I recommend) instead of having `thing.component.js thing.component.html thing.component.css`. Emitting event's is simply `this.$emit()` in the child and `v-on:some-event-name` in the parent. Vue is also heavily reactive *by default*. It has it's own flux/redux/elm/store/state management library implementation known as Vuex. Things like RxJS are definetly useful if you want some async workflows etc going on in the Vuex store but you don't really need to use it at the component level really. Everything is just *nice*. There aren't weekly major breaking changes, it's not overly verbose, it's .vue files are really really good for distribution. Another point, the "official" Material Design library for Angular by Google is absolutely fucking terrible. It's been a year since I used it and I just looked and it *still* has the same features and components missing. On the other hand, a third party MD component library called Vuetify blasts the Angular one out of the way https://vuetifyjs.com/en/ Typescript is supported too. There's currently some undesirable edge cases around Typings with Vuex but that should be resolved once the Vue TS rewrite has taken place. Vue also has an excellent CLI that really makes the React and Angular ones look piss poor. https://cli.vuejs.org/ Vue also has excellent browser dev tools. Angular doesn't even have an official one and the React one looks like it was designed in a week. https://chrome.google.com/webstore/detail/vuejs-devtools/nhdogjmejiglipccpnnnanhbledajbpd?hl=en Hopefully that's a small insight into it. 
OP wanted opinions. What don't you get about that? Don't see how I can be ignorant after having actually used them for a while. See my reply to him, don't bother replying though if all you can come up with is "ignorant".
In theory, yeah, it could. The easiest sell with be with current C# programmers of course. Javascript die-hards will likely shun it just because. There aren't any reasons I can see why it could not become huge though.
But your opinion is ignorant 
Hmm.. it strikes me that there maybe should eventually be a component integration standard ABI between them so there can be a common ecosystem of components for everyone to use. 
Webassembly will fall back to JavaScript in browsers that don’t support it. The apps will be even more bloated than they are going to get, but they will work. On an intranet the speed will probably make up for the bloat. 
&gt; Webassembly will fall back to JavaScript in browsers that don’t support it. True but the performance costs are pretty frightening. If you're going to deep dive into WebAssembly at some point polyfill may stop being viable. Plus Webassembly is a moving target (e.g. up-coming DOM manipulation) and polyfills may fall behind. 
Pluralsight has some really good tutorials, but it's kind of pricey.
I actually tried this before posting. Even with everyone permissions on the folder and the dll i still get the error.
Enter player three!
WTF is Blazor?
Duh-doy! It is incredible! If they/we put some more effort into it, it most probably can be the new #1 choice in frontend development. I recently tried it, and it blew me away after using Angular and a bit of React. I suggest anyone interested to take a look! http://blazor.net
We used to have exactly the same conversations 10 years ago. The split has been, is, and will always be there.
It would be better to go on Google and know the difference between OpenJDK and Oracle JDK first before posting such pointless nonsense. I'm not a Java developer. But even I read up on the topic and it's pretty clear to me what Oracle *is* charging for. 
No, it's fighting with a extremely fast moving target in the JavaScript ecosystem. 
Blazor also supports asm.js as well for browsers that do not support webassembly. 
It's a front-end framework that compiles to WebAssembly, so you can write C# for the front-end instead of JavaScript. So you can write C# all day every day.
&gt; IE12 Internet Explorer 12 doesn't exist. The last version was 11, and then development went into Edge.
How about go fuck yourself, is that ignorant enough?
I hope it does, I love JavaScript
https://github.com/aspnet/Blazor
First let's see blazor server gets traction on version 3...I think will compete in the dotnet devs. Java, python and c++ will get their ports as well.
&gt; It is all but confirmed that .NET Framework v4.8 will be the final release, and that all subsequent innovation will be happening on .NET Core. What is meant, exactly, by "all but confirmed"? What's the source for this? &amp;#x200B;
[https://player.fm/series/the-net-core-podcast/corewf-with-dustin-metzgar](https://player.fm/series/the-net-core-podcast/corewf-with-dustin-metzgar) &amp;#x200B; Fast forward to 20:30 &amp;#x200B; This information has been leaking out in podcast interviews for a while now. I am trying to find a secondary source in a .NET Rocks podcast from a few months ago. 
Great work so far on the podcast. I've been really enjoying it so far. 
I love TypeScript too, why do I need Angular?
It's ability to compete will be determined by how performant application loading becomes. Users on mobile devices need to be able to go from start of webpage load to functioning UI much more quickly than Blazor can deliver right now. I believe it can be done, but we're still a pretty long way off.
They probably chose to do so since it would entail at lot of legacy cruft that they wanted to remove from Edge. But I did hope at least they had a custom build for Edge that had those things, it would have made it quite easier for legacy webapps to slowly transition. Either way IE should be deprecated in the near future in way for Edge. Though I doubt it'll be soon enough as legacy things are almost always the slowest and hardest to port over.
Are you the author then? I have to disagree with &gt; New projects, be they web or desktop, should be started in .NET Core. When it's not yet possible to start a new desktop Forms or WPF app in .Net Core. I tend to jump on the new version train early even for production apps, but what you suggest literally isn't even possible.
As someone who hates every latest jQuery library, I like the sound of that.
The biggest hurdle here for the moment would be mono wasm runtime and webassembly itself and how it matures, it will gain more traction the moment wasm gets native DOM API support and it won't be only Blazor that will arise at that point to compete. It will be able to compete now especially for those who work on a .Net shop and have no plans on targeting IE11 since asm.js is pretty slow at the moment for Blazor. It's pretty good even within it's experimental stage and the team is progressing steadily for feature parity. The VS tooling support alone at the moment makes it very convincing (Almost convinced our .Net team to use it, till the disappointment discovering that it was still experimental, but we're closely watching it's progress). So far it's the best front-end framework for wasm at the moment. Hopefully that will be the time that we have choices on language for web development aside from JavaScript or it's "compile to JavaScript" derivatives. JavaScript will still stay however, but at least at that time we'll have a choice. 
If you're using new jQuery libraries, you're doing something wrong.
I assume they're referring to UWP as desktop, though that'll (as I think you're implying) change with .Net Core 3
Upper decking 
How exactly you might accomplish this depends if you're using EF 6 or EF Core. You can hook EF - a Value Converter for example - and provide your reference objects from your own service, setting properties on your entities from the retrieved id's. Alternatively, you could composite DbSet and attach the related entities there. You'll also have to attach the reference objects from your alternative source to each DbContext.
Probably best not to worry about it. Your WPF app is still going to be Windows-only, and it's not like Windows is going to drop .NET Framework support.
ITT: people who don’t know the roadmap for net core 3.0
While the article doesn't specify, .NET Core 3.0 will have support for desktop applications using WPF. It will only support windows however
To be expected, although an official announcement from Microsoft would help secure the justification for most companies moving to .net core.
As a solution for poorly-written software that you want to make better, I can see the value of pull-up as an incremental tool. For new software, I'd rather break the build and use Roslyn analyzers in the projects themselves. It's amazing how many things that I used to catch in code reviews we can automate out at build time. My only struggles now are (1) making sure people have the analyzers installed in their projects and (2) keeping the flag "warnings as errors" set. &amp;#x200B; I've had limited experience with SonarQube, but we use it as an additional layer on top of our analyzers.
Umm.. just a heads up that that line of thinking gets you in a technical and training debt hole that is very hard to dig out 10 years from now.
What analyzers specifically?
Half of the analyzers we use mirror [StyleCop](https://github.com/DotNetAnalyzers/StyleCopAnalyzers), which we used before Rosyln was a thing. The other half are those that we've written in-house, specific to our code base, or that come with libraries that we use (xUnit, for instance, has wonderful analyzers). We're investigating some security-based analyzers, but haven't liked any of them enough yet.
lal
Just a few months ago, Rich Lander commented on [this]() post: &gt; Span is included in .NET Core 2.1. We explored including Span in .NET Framework 4.8 and decided against it due to compatibility concerns for existing applications. You can get access to Span and additional related types in the System.Memory Nuget package which enables some of the scenarios that are enabled on .NET Core. So at one point they did decide to stop all innovation on .NET although with the release of netstandard2.1 spec, Spans might be added to .NET Framework after all ([who knows](https://blogs.msdn.microsoft.com/dotnet/2018/06/06/announcing-net-framework-4-8-early-access-build-3621/))
i didn’t like asphostportal support. it is tough to gethelp in technical challenges. so moved to digitalocean with linux hosting. 
Forms was clearly abandoned in favor of WPF, and in turn WPF was clearly abandoned in favor of UWP
I was an early .Net Core adopter... I almost wouldn't bother with it unless there are clear use-cases. This is highly dependent on what you're going on the framework, natch, but my days are constantly being undermined by incompatibilities, half-baked library dependencies, feature differences, broken third-party libs, and holes in the toolchain. .Net Core is good, and will be great in the future. IME the story 2016 to present day has been riddled with oversights, pushed features, and indecision. Major swaths of our toolchain are still 'under repair', years after their original drop date. My tactic with MS products is to wait about a version and let the ecosystem mature. With .Net Core I feel we're still not at that point.
.net core is fine now 2 years ago it was "eh let's wait and see"but that window is gone It's more than production ready
For server workloads, yes. For client workloads we need to wait until at least Core 3.0.
Oh it's done all right.
It won’t need to be rebuilt. Even ‘breaking’ changes in behavior can usually be fixed by applying a configuration setting. Retargeting is only required when you need access to new APIs exposed by a new framework version. 
No, thats desktop wpf/winforms WRAPPED in a core wrapper that can be managed through win appstore
&gt; Again, unlike Silverlight, there is no need to rush out and re-write all of your Framework applications Sounds a bit iffy give the announcement of wpf/winforms wrapped up in appstore packages. Although so many organisations still run Win 7, it's moot as it's a win10 only feature. the framework can't migrate all the desktop app's because there's no wpf/winforms in core. So in that respect this would be exactly like the death of silverlight. It's web or nothing these days. We won't be starting any strategic wpf apps, but I still want wpf in core dammit. 
If it's shared code, move it to a shared service or just a class you can use in both..
I have some good news for you. WPF (and Winforms) will both be in Core V3!
I wrote the article, but I was paraphrasing what was said in that podcast. .NET Core v3 will bring WPF. Sure, if you need to ship in the next fe months, or are developing a small application, then you can't use Core yet. But, if you are starting an app that you expect to have to maintain for a few years, then I think there is a very strong argument for starting in Core now. 
Yeah, but it's the c# parts, you have to use a desktop pack to make it work (windows only). They havven't even said if the core code will be open source as it will essentially be the existing WPF source automatically converted via projects. They said the could was 99.9pc ish compatible according to their compat tool. But, it is a possibly good start :) 
Have you tried adding : [BsonDateTimeOptions(Kind = DateTimeKind.Local)] On your datetimeproperty?
What's the UpdateOrder method doing? Are you calling any shared methods to save the document to the DB, is there any code within that method that might "default" the CompleteTime to DateTime.MinValue? Only issues I've ever seen with NoSql and data not being what you'd expect is with GUID encoding. 
Yes thats what I ended up doing, I used this to design the label, then grabbed the zpl code and modified it so I could parametrise it and also encode the RFID tags
Thanks. Unless something has changed, it looks like [this article](https://docs.microsoft.com/en-us/dotnet/framework/migration-guide/how-to-configure-an-app-to-support-net-framework-4-or-4-5) has some more info about how a .NET application chooses what framework to run under.
Yes
That is simply wrong. There are large applications running .net 2 that are going to be no longer supported as of 2020 that many large companies depend on. Many of those applications have dependencies where no update exists for a modern .net framework. I get your point that we don't have to worry about migrating off of .net framework, but my point is that we have to deal with this kind of situation all the time right now.
Does it use unmanaged resources?
Why, though? It's one thing to be told not to, another thing to understand why it should be avoided
At least explain why you're saying yes.
Backward compatibility concerns related specifically to Span doesn't mean "stop all innovation", at least as I read it.
Thank you, that helped me solve my issue!
https://medium.com/@andy.watt83/the-net-framework-is-done-8aec3bbae12d
.NET Framework still uses JIT32 for x86. It is really far behind .NET Core which has tiered compilation, crossgen, span and hardware intristics (in vNext) support. 
To add to [TriptychButWith8Bits](https://www.reddit.com/user/TriptychButWith8Bits)'s answer: Focus on the specific domain of THAT company... Is it a healthcare domain, retail, etc.? &amp;#x200B; Research how to build SOA oriented solutions for those domains (if you are really interested in SOA). If you have time, design/ build some solutions. If there's no enough time, then you should probably already know how to do these things. Most times "Architect" is an ambiguous title (as [TriptychButWith8Bits](https://www.reddit.com/user/TriptychButWith8Bits) suggested). You need to examine the job requirements. Make sure those are hammered down :)