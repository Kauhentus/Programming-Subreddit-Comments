I was going to write my own reply but yours will do. Just some things to add: 1. TFS isn't terrible, but I hate it. Much prefer GitHub, or even Bonoboo. Second JIRA recommendation, though there's some setup there to get it to work for your specific needs. HIGHLY configurable. 2. Second TeamCity. 3. Second OctopusDeploy. 4. Second the feature branch workflow... with one caveat. How the hell do you do an integration / dev environment for this? We are struggling with that right now. Octopus is really setup to deploy in a straight line, and feature branches just don't work well for that unless you are strict with your "Don't merge until it's ready to go through the approval process for production" rules. For environments, I'd recommend a Dev -&gt; QA -&gt; Staging -&gt; Production flow at most, excluding steps if they don't apply to you. We use staging, for instance, for data staging more than code staging (e.g., it's a final integration environment for our content people to check before we push the whole thing live with their new data). QA can be omitted if you don't have dedicated testing workflows, but anymore I kind of thing it's a good idea all the time (it's more stable, as Dev should probably be a CI environment, and any tester is going to want a stable testing environment).
While fairly elegant, something in me screams "no" at this. I say view bag all the way here. It seems to give the view direct access to the data access layer, which I'd say is the entire purpose of the controller here: to segregate the ui from business layer concerns. I'd think this introduces coupling of the layers in an ill advised location.
* Start with doing console application first. The API surface is minimal yet it allows you to do a lot of things such as HTTP calls etc. * Learn ADO.NET. Learn to access data on a very basic level. You can use ORM once you know ADO.NET. * Learn async/await stuff and have the console do HttpClient works This console app approach is enough to get you used to majority of C# standard library surface area. Then you can decide whether you want to pursue native UI development (WPF or Windows Phone) or go to the wild wild west of web app route.
I've tried to add as many comments as possible and also links to relevant articles or blogs. Eventually, I hope to write a blog post about every aspect of the project and add links into the comments.
 is it true that the future of cliend side development is html5 and javascript and that microsoft killed windows form and wpf ? ive been told that from some experienced programmer on gamedev so I was wondering why they don't want me to learn webform, windows forms or even new wpf etc so once I have a good grasp of the latest C# in Visual Studio 2013 should I study my asp.net mvc5 ? or go html 5 css javascript and angular or its too much backend and frontend for 1 guy ? thanks a lot 
&gt; is that supposed to be called AJAJ? I guess technically AJAX should be AJAXML
Don't use Visual Studio 2013. There's a community version of [Visual Studio 2015](https://www.visualstudio.com/) which will give you C# 6.0. Studying WPF will benefits if you want to develop Windows Phone application especially now that they have Universal App and Win 10 (not an expert on this field - somebody please correct me). Once you are done with the console, go straight for ASP.Net MVC 6 if you want to go to the web stack route. Forget about MVC 5. They are completely two different beasts. One thing is, don't worry too much about people making opinions about the future. Pick a technology that allow you to create what you want to create. There is no such thing as 'too much'. Follow your interests. I do backend (C#, MVC5, MVC6, Elastic Search), web front end (Typescript, Ractive, Semantic UI), Android (Kotlin) and now learning Swift.
Old-ish news by now...but still good news from a WPF standpoint. Although my guess is future iterations of UWP will eventually at least find feature parity with WPF when run on the desktop, perhaps in some kind of extended permissions mode. But WPF is still the best way to build desktop apps for the short and medium term future. 
Actually, for me, view bag sends me screaming, and opens the gates to other issues. So, let's pause for a second and turn this on it's head. We, by definition, have a problem that we're not really talking about in the best interest of not upsetting anyone. The fact that my controller has to do the lifting for the combo boxes is awkward and doesn't really help us out too much with maintaining SRP. But we didn't previously have a good way to address this. We also tend to overlook the fact that Views are effectively code. Why can't our principles apply to them as well? Of course I shouldn't access the database from the view, but why can't I know about an interface that does (and have it injected)? This is a great use case of this new feature, and one that demonstrates that not changing for the sake of not changing isn't a good mantra. If my view code/class/script is responsible for rendering the view, I see no problem injecting into it the things it needs to do so. After all, isn't that what you're doing with ViewBag? Just injecting things into the view through the Dynamic? Except, with ViewBag, no one sees type problems and everyone has to cast. Now we've got run time errors. I concur that you don't want to be injecting database change-capable components into the view, but that is more a case of bad choices in implementation. I've seen people write 1,000 lines of code in a method, but that doesn't mean I don't use methods any more. When changes come to frameworks, I think it's okay to rethink our best practices. Taking Simon's approach we have: - Interface-based injection - Abstraction from underlying data access strategy (db, cache, text file, whatever) - Testable components - Maintaining SRP in our controller and view - No casting from dynamic to proper types I'm okay with this approach and will be using this approach in MVC 6 projects.
That's a really well written reply. Next time you get to write the blog ;) I totally agree about pragmatism over dogma. By taking this approach we have allowed strong typing avoiding that pitfall in the viewbag but we've kept everything testable and injectable and all those other good things. This does not strictly comply with MVC but it still follows good design principles 
Again, I'm not seeing it as "a bad practice in general". Why is it a bad practice to give a component the pieces it needs to do its work? A view needs to populate a dropdown list. It doesn't need to access the database, and it shouldn't. Giving it an interface by which to look it up, though...that seems like a good idea. You introduce coupling to a specific view in the controller by forcing it to look up data to populate a dropdown box. Which...is a bad practice in general, no?
The thinking is a good thing :o) I've been wrestling with a good use case here, and it seems this obvious one had been missing my thought stream, likely because it's been clouded for a few years with view bag. Check out my reply on the other thread...I think this is a good time to reflect on what we thought of how we approach our views.
Thank you very much, got it now. I'll edit my post and put your solution as a quote up there. 
why?
Hmm...well, I'm certainly not advising to talk to the database, I think that is not the point of the post either. The assumption that the controller provides everything the view needs is guided by past pretense. That is true in MVC5. My point is that in MVC6 we now have a construct that allows: - Separation of concern/single responsibility - Testability - Type safety - Injectable dependencies That they are part of the view or the controller...we need to examine if that is something that we need to get religious on or not. In my mind, the controller is just a component. So is the view. The controller's concerns are related to the entity in question. The view is required to render correct UI such that a form can be filled out in a way that satisfies the requirements of the view model. Why use a customer controller to retrieve details about countries and states? One other point I'd like to make is that I don't see controllers as any more important than any other component. They have things they need, and they should have those things injected. My controllers don't talk to the database, they talk to command objects and query objects via interface and those are injected from an IoC container. I think now, with views as first-class components, that we can look at views in the same way. Or, we can agree to disagree. :)
The Visual Studio dependency is what I dislike most about .NET - historically .NET developers have had the double handicap of being tied down not just by OS but by IDE as well. It's improving but there's still some way to go. I'm doing a fair bit of ASP.NET 5 at the moment and I'm a seasoned .NET guy and it is still some effort getting stuff done on *nix systems. If you're going to deploy on Windows then I'd still use Visual Studio if I were you. The issue for me is I've recently taken the decision to move our tech stack over to Linux so I've had to learn the ropes with Linux and .NET. Also, if you're not using Windows then I'd also consider using a different stack. I don't see you gaining anything using ASP.NET over Scala on the JVM. I did consider this road myself but years of .NET knowledge and limited exposure to the JVM plus official MS support for Linux made Scala less attractive for me.
It would be nice to know when why and how to use them, knowing that might come in handy some time.
well I just wanted to rearrage some components, so I guess I am fine for now.
very good answer thank you very much 
Ah the bi-monthly shill troll post. Post your bullshit elsewhere.
https://technet.microsoft.com/en-us/library/ms166104%28v=sql.105%29.aspx SQL service broker
Would you consider time-series data to be a good fit for storage in document DB? My example would be inflow forecasts for hydrological reservoirs and price forecasts for electricity pricing. These are date time with value curves, typically with an hourly resolution for about 30 years (~300'000 values). And we need to store multiple thousands of them for our application. Currently, we use BLOB storage in relational DBs, but are looking at Mongo / Cassandra to scale and allow access into the data without pulling it completely into the app. The data is completely non relational. Does document DB enforce a maximum document size (like Mongo 16 MB for example)? Do you have a white paper or someone who has looked at such a use case? Finally, is there a local version of documentDB, last time I looked there was only an Azure version available? 
I've had good luck with NServiceBus. It abstracts MSMQ and turns it into a message routing platform, allowing your system components to remain disconnected. It also supports retries and the ability to route failed messages/events to an error queue for manual intervention. It's also compatible with RabbitMQ if you're looking to avoid dependence on one of Microsoft's older technologies.
C# isn't going anywhere, and it runs everywhere too, even on the iPhone (ok this isn't technically 100% correct, but you can write iOS apps in C#) Last year using Xamarin I wrote 3 mobile apps, 70% shared code, last 30 % was UI. If I had used Xamarin Forms, it would have been closer to 95%. Depending why you are learning it, I would avoid the legacy parts, (WinForms, WPF etc), but if your planning to do enterprise/banking stuff, its probably useful to learn them. For database, I would learn Entity Framework, SQL server, SQLite, and personally I prefer Dapper as an ORM, but that just me. And finally to begin with personally I would concentrate on just one area, either do the web stuff, or do the app stuff. Also unless you want to be a designer basically, learning backend programming is very useful, for say web APIs, that you then put angular and html on top of.
C# and .NET is currently going through a bit of a transformation. It's being open sourced, cross platformed and the runtime and development environment are being rebuilt with heavy influence from Node and the community. Etc, etc. As a C# developer I'm actually really excited about the future, in the sense that I'm gonna enjoy working on this platform even more than before. Unfortunately that's not saying anything about how the job market will be. Only things I know about that are: 1) we have a steady stream of .NET requests coming to my agency and it's currently growing. 2) My current client (big international retail company) wants to build new systems with .NET and modernize old ones (WPF=&gt;MVC). What I would recommend is to look into C# and Asp.NET combined with JavaScript/Typescript on the front end. Maybe Angular too. That will kind of spread the risk for you while also being a pretty realistic stack that you might end up working with. 
"very painful choice if I want more than a single type or two" - do you know that you can persist different types in to the same collection? what are the reasons behind wanting a collection per document type? this is genuinely something i'd like to understand. a collection is really a schema-less container of documents. why constrain this to only documents of a specific type?
Like I mentioned, I do know that I can store multiple types per collection, but that seems unnatural to me from my background. It sounds like that's the expectation with DocumentDB, tho. Which, as was pointed out, means putting a type field and constraining all queries by that. It also means no uniqueness constraints and no dense indices. Maybe that's okay. *shrugs*
&gt; unnatural to me from my background out of interest what is your background? RDBMS like SQL or MySQL? 
Thanks for the reply! This definitely makes more sense, and you captured my confusion perfectly. It definitely will take some adjustment in mindset, but I will work on that!
&gt; Would you consider time-series data to be a good fit for storage in document DB? My example would be inflow forecasts for hydrological reservoirs and price forecasts for electricity pricing. These are date time with value curves, typically with an hourly resolution for about 30 years (~300'000 values). And we need to store multiple thousands of them for our application. &gt; Currently, we use BLOB storage in relational DBs, but are looking at Mongo / Cassandra to scale and allow access into the data without pulling it completely into the app. The data is completely non relational. My opinion on storing time-series data in DocumentDB is that it depends on the scenario. DocumentDB can be an expensive storage option, as compared to BLOB storage. So I’d only recommend it if you get value out of using DocumentDB’s feature set (for example – if you need to be able to query using secondary indices). One nice thing about time-series data is that it generally partitions well. You could partition by timestamp (e.g. timestamp is between 1/1/2015 and 6/11/2015 in collection 1, timestamp between 6/12/2015 and 10/20/2015 in collection 2, etc.). You could raise the performance level of the current partition to quickly ingest data, and lower the performance level as the collection ages to reduce cost. Personally, I think DocumentDB schema-agnostic indexing is the most interesting feature to take advantage of. EVERY property within a JSON document is automatically indexed using a hash index. This mean that queries using equality filters are incredibly fast and efficient. You can optionally add range indices (for range queries, e.g. less than or greater than). One example of where this could be a good fit – is you could take advantage of schema-agnostic indexing and time-series data for storing event logs from critical services. In this context, you could leverage the ability to perform fast and efficient queries on arbitrary fields to reduce the time to mitigate incidents. I’d love to hear more about your service, its storage requirements, and its query patterns. I’d be happy to have a 1:1 chat and give you my thoughts and guidance (feel free to ping me at andrl {at} microsoft). &gt; Does document DB enforce a maximum document size (like Mongo 16 MB for example)? Yes. Currently, the maximum document size is 512kb. &gt; Do you have a white paper or someone who has looked at such a use case? Not off the top of my head, but I'll take a look around and post back on my findings. &gt; Finally, is there a local version of documentDB, last time I looked there was only an Azure version available? No, it is only available as an Azure Service.
I'm sorry to hear that :( Mind linking me to the samples you're referring to? I will work on fixing them promptly!
Yup. That, then a bit of MongoDB over the last few months for some side projects. Honestly, I'm currently much more of a mid-stack developer, and not at all a DBA. 
I'm fairly certain it was the msdn download link and I seem to recall that the projects were still referencing the preview nugets to the client libraries. I should still have everything in a local git repo i can pull down and let you know specifics. Or if they are all updated, it shouldn't matter.
&gt; 10% of all newly created Visual Studio Projects at that time were using the WPF project template I would love to see all the stats. Anyone know if Microsoft publishes this data?
I actually just had a great chat with Andrew Hoh who I believe is on the DocumentDB team. I was able to share all our concerns with him but I'll just reiterate here as well. We created some prototypes of our system using DocDB but we felt it fell short when you considered the price you paid with the features that are missing. We made a number of attempts to leverage other storage solution but we keep coming back to SQL Server. We absolutely need aggregate operations such as Sum, Avg, Count, etc. We deal with a lot of roll-ups and hierarchical data which denoramalizes very well into a flat schema-less system but we need to run (essentially ad-hoc) aggregate queries against that data. We can't justify moving from SQL Server to a MUCH more expensive system with less features. Perhaps we don't quite appreciate or leverage the schema-less nature since we would only use it to flatten dynamic hierarchy relationships between our data. We've tried to slice and dice our data across many different types of storage systems in Azure. We have some unique storage and querying requirements and we are always trying to find new ways to increase performance. I guess we were even special enough special enough to be invited down to a week-long Azure DeepDive in Redmond back in 2010. We had many different Azure team members attempt to tackle our problems. :) A while go we had a very complex implementation using Table Storage where we were running the aggregates manually and denormalized everything. It didn't perform as well as we hoped. We were also hoping that Azure was going to follow through with the promised Secondary Indexes feature [(This was asked for in 2009!)](http://feedback.azure.com/forums/217298-storage/suggestions/396314-support-secondary-indexes) What happened to that?! You really can't beat the price for the number of transactions and amount of storage you get. It's very cost effective IF you can get your data into the partition/key format it forces on to you. We were really hoping that DocumentDB was going to be the answer to the secondary index and fit somewhere in between SQL Server and Table Storage. But it is FAR too expensive and we are more willing to bend things to fit them into SQL Server or Table Storage than pay the DocDB premium. Perhaps it's because we won't leverage all of the unique DocDB features. We're only willing to give up aggregate support for super-cheap storage with basic secondary index query support. Until then, we stick with SQL Server and denormalize our data a bit to get around the limitations of an RDMS while keeping the features we need and stay in a price point that we feel makes sense. Anyway. I think the DocDB team is on the right path and I hope the product continues to improve. I'm sure we're not exactly a common usage pattern but we really wish we could throw some money at Microsoft to solve some of these problems. :)
Just want to comment that I think it's great that you're here engaging with the community and making yourself available for 1:1 chats and answering questions. This bodes really well as my org transitions to .NET and Azure. Keep doing what you guys are doing!
I was bullish on DocumentDB until I heard the DotNetRocks podcast with Ayende as the guest. Let's say he wasn't a fan of the feature set at the time. Have you heard this podcast episode and have any thoughts on the comments within? Any enhancements to alleviate the concerns? http://dotnetrocks.com/default.aspx?showNum=1048
I played around with Document DB a few months ago, and I'll be frank, whoever thought javascript was the ideal language for server side stored procedures was smoking something. Debugging stored procedures was a nightmare, and the fact that the line numbers of the error messages I did get didn't correspond with the line numbers in my scripts made it rage inducing. Second, the pricing structure for DocumentDB was completely ridiculous. SQLServer can get away with absurd pricing because so many people are locked into their legacy systems that they have little choice, but new products have no such luxury. DocumentDB pricing is absurd. 
I don't think the BCL jives so well with IIS 6 and prior
And often clueless in gamedev, which is a pretty broad field on it's own these days.
The entire point of NoSQL databases is to take advantage of their scaling properties. The pricing structure of DocumentDB basically negates the primary motivation to use NoSQL. Schemas are only bad because relational data doesn't scale to massive amounts of data, not because they're "too complicated". Sacrificing the data integrity that schemas provide for scalability is understandable, but sacrificing data integrity because you're lazy is not. DocumentDB is clearly targeted towards developers who have small data-sets that could easily fit in SQL databases, but simply don't want to because they think schemas complicate things. I found this article on NoSql demonstrates the point I am trying to make. Read through to the end, its not just a "I hate NoSQL" rant. http://www.sarahmei.com/blog/2013/11/11/why-you-should-never-use-mongodb/
For some reason it's more readable in Firefox than Chrome. The Open Sans is rendering very thin, making the font color look lighter than it is. 
&gt; If you want something further out than 10 years you may want to consider something else. Like what? There is not UI toolkit thats 100% sure to be supported in 10 years, unless you mean HTML/JS which is IMO not fit for large scale business apps.
Here are two of my favorites: **1) Heterogeneous data.** **Example:** let's consider that you are building an e-commerce site where you sell everything from books to video games to laptops. It is really hard to fit this kind of data in to a tabular structure. Creating a column for each attribute doesn't scale because there are too many varying attributes among your various products. How much ram does your book? Who is the author of the laptop? Creating a table for each product type is cumbersome because you have a rather expansive product catalog. Creating and maintain 1000s of tables for 1000s of product types is a maintenance nightmare. Storing everything as JSON in a single varchar column doesn't perform well. You lose the ability to index and query off individual attributes. Storing a heterogenous data (schemas that vary quite a bit) in a schema-agnostic database is easy; just store the data and query off the fields you need. Simple. **2) When you don't get to dictate the schema (e.g. pulling data from 3rd party data sources)** **Example:** let's say you have an application that pulls data from various 3rd party APIs from around the internet, e.g. Reddit, Github, and StackOverflow. JSON has become the de facto data interchange format of the internet. Extracting fields out of JSON from a 3rd party REST API to fit a tabular structure can be tedious; and even worse... what happens when your data source changes their schema tomorrow? Data loss occurs! This is another area where schema-agnostic databases shine. You can store JSON passed back from 3rd party sources directly in to the datastore without having to worry about data loss due to schema changes. Simply update your application’s queries to reflect the latest schema changes and you are back up and running. 
Thanks! :)
Yea, I'm familiar with Ayende. He's a great and brilliant guy, and I have a lot of respect for him. Things have changed quite a bit since his review of our preview launch. For example, we've upped our document size limits from 16 KB to 512 KB since then. Personally, I'd take his opinions (as well as my own) with a grain of salt since he's the owner of a competitor product. Everyone believes their own product is the best. That's just natural. 
I admit we have some work to do when it comes to the debugging story for stored procedures. I'm grateful for your honest feedback, and would love to hear your suggestions. I understand that not everyone is fond of JavaScript; but I've found that the most natural way of interacting with JSON (JavaScript Object Notation) tends to be JavaScript. This frees us from the complexities of type system mismatches and the need for object-relational mappers.
http://feedback.azure.com/forums/263030-documentdb/suggestions/6328798-standalone-local-instance This has been 'Under Review' for about 10 months. Any updates on this?
Tried out DocumentDB, its more of a key/value store than a Document DB. The name is absolutely terrible. Querying sucks. Lack of OrderBy, lack of Paging, use of SQL for querying *SHIVER*, its slow... OH GOD ITS SO SLOW... When you spin it all up for the first time, its sooo slowwwwww. The API is horrible. Tho somewhat better than AWS. Ahh I wish MS would just support RavenDB or MongoDB, or even PostgreSQL. Then I wouldn't have any reason to use AWS over Azure.
&gt; For some reason it's more readable in Firefox than Chrome. The Open Sans is rendering very thin, making the font color look lighter than it is. Not sure what's causing this. Are you using Safari? See the last answer: http://stackoverflow.com/questions/13114417/open-sans-google-web-fonts-rendering-in-chrome
I prefer Dapper also, EF produces bloat and has performance issues.
That was very helpful. I think it finally "clicked". Thank you for the detailed answer!
Thanks. I realize there is none today. Is it being considered as a part your milestone? Is there a timeline? Similar to SB, which can be run as SB on Windows Server and can be provisioned from WAP, will there be a WAP option? As a ISV, this makes it incredibly hard to evaluate DocumentDB and add it to our milestone 
This is a great example. I would argue though that there is still no good way to really report on any of this data. How many albums were released in 2007? How much revenue did X album make in January? These sorts of questions can only be answered if you pull down all the records which eventually doesn't scale at certain volumes. You could build denormalized reporting around these relatively static pieces of data. (e.g. X album sales in January will be $Y forever). But if your data is growing quickly and you need the same kind of reporting then you're still in a tough spot and you'll have to go back to SQL.
What are your plans for backups?
Sad to say this is still under review. This turns out to be a far more involved project than we thought. In short, there is quite a bit of complexity behind the scenes required to provide a fast robust multi-tenant database-as-a-service. I'd love to get your thoughts on the scenarios you'd like to use a local instance in. For example - Are you looking to build a PoC and evaluate for free? Or are you looking to support a local dev/test scenario for unit-testing? How broad of a feature set does the local instance need to be able to emulate? Does the underlying need involve a spotty internet connection? How valuable would this be in comparison to a free or basic online tier? I’d like to get this right – my assumption is that a local emulator may not be very valuable if it doesn’t properly emulate the environment. But is that true? Narrowing down the core values here would help us greatly in speeding up turnaround. Please ping me, I'd really like to understand this problem further. 
The work for this is still being [planned](http://feedback.azure.com/forums/263030-documentdb/suggestions/6331712-backup-solution-for-documentdb). We will provide an update as soon as we're ready.
&gt; nobody has coded web pages in C# ASP.net forms? Those were definitely more C# than HTML ... 
Yep, not sure how keen they are to make the change, at least not without fully understanding how we were triggering it. But a) we triggered it - that's undisputed, b) in an enterprise environment you can't always collate the stats you want and c), yep, whatever system I use RX in from now on I will implement this...because it's not quite bulletproof.
I've heard a few people talking about C# becoming obsolete. Here's my thoughts: &gt;1) Is C# becoming slowly obsolete with the mobile revolution and the frontend client side who seem to go to Javascript/Html5 css... where .Net and C# in general will stand in all this a niche market for backend ? I would say definitely not; there are some incredible tools for mobile in the .NET world - Microsoft themselves have recently added some emulators for Android and iOS, there's a lot happening in that space for .NET. There's also tools from Xamarin and other's that'll get you started for mobile dev. When you say 'frontend' above, it sounds as though you're talking about static sites... if that's the case then Javascript and HTML5 will be used over any modern programming language. &gt;2) Why some programmers told me that WindowsForms &amp; WebForms are dying and Wpf future is uncertain ? Let's say I want to get back into programming and learn C# today in 2015 should I avoid all that gui stuff and just get a solid grasp of the language and jump to Asp.Net MVC 5-6 ? is it possible to program frontend and have a solid career and avoid .Net all together by doing html,css,javascript,angular etc etc ? In this new world of web, there are certainly more jobs for MVC over webforms and winforms - you probably are looking at legacy apps if you're working with those. MVC is a good thing to learn. &gt;3) I am asking this because it seem the open source scene seem to be booming with Java, Ruby, Angular, Php and the server side too with apache etc where .Net stand (or compete) against thems ? can asp.net mvc 5-6 compete well ? or its mostly corporate stuff IMHO, it's a common misconception that 'C# is mostly for corporate' - I was checking out [Voat](http://www.voat.co) today and the whole app is a .NET stack. SQL server for the backend end and MVC5 for the rest. Microsoft is also making a big move towards open source. You can get a whole .NET environment up and running in Sublime Text if you like now that they've open sourced some of the stack. I'm hoping to see more of this trend. &gt;4) on the Database side of things, what would be the ideal path for learning ? I seem very interested in programming database and do backend stuff compared the front end web dev stuff where that could lead me oracle, sql ado.net entity ? MS SQL Server is a good place to start. Entity Framework will do a lot of the heavy lifting for you but it's good to know SQL. &gt;5) is it possible to learn mostly everything or be like junior lv in front end web dev + database and destop applications ? my goals (before getting advices from programmers) was to learn C# 5.0 with VS 2013 do a few windows forms apps and jump to asp.net mvc and play with database I'd start with some console applications and skip the winforms part. Console applications can give you a good idea of the language and get to know the internals. Then head on to MVC. I'd recommend [ReSharper](https://www.jetbrains.com/resharper/) if you can afford it - it's an incredible tool.
Yes it does. But most those features are outside the common core, so... not sure where they stand in the future.
Can you expand a little on where DocumentDB really succeeds and techs like the new Hekaton fail? Apart from the lack of schemas and other obvious diffs, where exactly dDB has an advantage over SQL server and why? I thought that the in-memory improvements to newer SQLserver versions nullified most reasons for someone to use a NoSQL solution. I think I've read documentDB still uses mostly btrees internally so how it get its performance advantage? What is the big idea behind documentDB? 
I don't understand this either. I've been looking at this NoSQL stuff for a long time and I still can't wrap my head around why this approach is better than a relational database. It became a huge fad, but it still seems to me this was originally started because developers didn't want to deal with SQL and a database. They just wanted basically a hard drive to dump data into and be done with it. It seems to me it's just "throw anything you want in there, forget the format" which I can only imagine becomes a nightmare on the other side. Zero guarantees on what you're going to get out, because the database isn't enforcing anything. I can't even imagine how this all works with complex business reporting on gigabyte-scale (or larger) databases.
Silverlight is a .NET horror story. RIP
I get the feeling this product it meant as a means to push Azure sales... I mean NO local instances? Eish.
1) C# has probably never been more relevant, especially if you're working with a windows or azure environment where you can really take advantage of it. There are also a lot of advantages in dotnet on the enterprise side of things. You'll be able to write an application which ties into AD, sharepoint, asp, mssql, OIOSAML at the same time and so on and it's all relatively easy and approachable. 2) Because Win and webforms died over a decade ago and WPF died when we moved into to the cloud. I mean I work with citizen information - which you can't host in the cloud - and we haven't been using desktop applications for so long I can't remember exactly when we stopped. 2-2) I wouldn't recommend asp MVC until we see what Microsoft has planned. We know 6 is on the doorstep, but web-api with javascript and htlm5 is just so much better than asp mvc right now that I wouldn't dig in. I would however get into C# for web-api and build on top of that with a SPA framework like angular with css3 and html5. 3) The open source scene is shit. PHP is largely obsolete. I mean, it's still widely used and it get things done - those things are just so much more efficient and so much easier to do in the dotnet enviroment that you'll be laughing you ass off when you know the difference. This is PHP with frameworks like laravel by the way - without frameworks PHP is utter shit. Ruby is decent if you're a startup who suck at coding but rock at marketing and innovation (this is more common than you think). Once you make it big you can always hire someone to replace your shit with good code. JAVA isn't going to have the future it thought it was with the internet of things being run by browsers doing html5 and javascript things rather than JAVA. That being said there is still a lot of JAVA shit out there and it's still big in enterprise - though JAVA jobs typically require you to have higher levels of education than other programming jobs. Probably because JAVA is responsible for some pretty fucking important complicated enterprise shit. Apache died sometime in the 00's along with PHP - it used to be the best server and now it's not even second best. Same goes for mySQL really. Then again, you have to ask yourself why you're doing your own hosting if you're not hiding private information. 4) databases are a dead end for programmers. We're now automating so much of it that the database behind your ORM won't matter. Nobody actually tells the database what to do without a framework anymore - and the frameworks are so good they basically do everything for you. The people who maintain and run the databases are great, but if you're not a PHD in CS you're not getting a job anywhere near that. 5) people who tell you there are front end and back end people are lying. Developers are developers and if you can't do front end or back end at the same time you're going to have a bad time. 6) This is what you do if you want to be the hot shit. Don't waste time on ASP MVC - learn .NET MVC WEB-API instead and let that handle all your back end stuff. On the front end you'll want to use HTML5, CSS3 and JavaScript (possibly with a framework like angular). Do that and you're basically golden, of course, it's not exactly going to be easy.
I heard some good news for WPF recently, I think it was this: http://channel9.msdn.com/Events/dotnetConf/2015/WPF-in-46-and-beyond
If you're copying the files from the server each time, the server becomes an install time dependency. If you're always getting the latest versions, you have no way to rollback or install a specific version. So it becomes vaguely like a ClickOnce installer. If your MSI is self-contained, you don't need a specific share to be available during install and you can more easily version it along with you application proper to know which versions of things you're getting.
Geez this guy you taught owes you much.
In general I would like a better Azure pricing structure. I love the system since its so heavy on the Microsoft stack but the pricing doesn't seem nearly as good as EC2.
I have a $50/month credit for Azure from my MSDN subscription. Love it. It's tough to compare without knowing details, but I can tell you I run three websites and a small SQL database (on their respective services, not directly on VMs) without going over my credit (though I get close). YMMV of course.
Ihostasp.net. I started off on shared hosting, and moved over to a appliance for more control later. Very happy with them becuase there support is the best I have ever used. I wont use Azure becuase the cost is quite high. 
I have 3 small sites on azure, all in the basic (lowest) tier. I pay about $2 a month for all 3. Azure is really very cheap for hobby sites. You can always try it and move to another service if you don't like it. You can set up a single controller to redirect to your new site if you do move it.
Why can't it? Newest mvc is cross platform and very lightweight. Can use full vs, vs code or other editors too
Agreed! It's difficult to sift through all the options based on your current and projected app requirements and go back to management/client and say it will cost $X amount of dollars. I'm really happy with what we have now but there was a lot of trial and error.
True...and I'd like a structure that stays the same for a while. I get lots of emails with updated pricing and options. But I guess that's the cost (literally) of doing business with them.
"...don't worry too much about people making opinions about the future. Pick a technology that allow you to create what you want to create." With a positive, well thought out opinion like that, you'll never make it as a commenter.
Azure starts to get pricey with your own domain and more for ssl. Pay about ~$30 for a small site to have a custom domain.
The free trial credits have to be used up within a month. &gt;Any unused monthly credits cannot be carried over to subsequent months and cannot be transferred to other Azure subscriptions. 
I would make a distinction based on the purpose. Populating a drop down can be a view responsibility, if there is little/none business logic behind it. Otherwise, controller is in charge.
Thanks. I'll have to double check, I thought I was as low as possible for a custom domain and a valid cert.
If you plan to write actual tests for your jobs, I'd implement this inside a service like topshelf.
&gt; quartz is probably the most decent free option, but it doesn't support dependent tasks, which is super lame. There are so many use cases for "run task B after task A has completed successfully" Then use mass transit or nservicebus. 
I REALLY need to get my headspace into this. I love what is happening with the Akka.net community.
you know what is never dying? a skill of software engineer (not a type writer). C# is a very good language to use for edification, once you start using it you will also understand good 95% of other languages. While its true that ability to create stuff depends on knowledge of concrete libraries, the most important factor is ability to think properly - and any general purpose language would do. C# is a very good choice. The paradigm/mode of thinking is set to remain for at least 20+years, even if MS closes tomorrow. Do not "learn" WPF, WinForms etc.. learn the META-DATA ABOUT...how UI is done using different approaches, WEB is done etc...
IIS is also used for this purpose. 
Outside of services it sounds like you're looking for the Actor Model. https://msdn.microsoft.com/en-us/library/bb648752.aspx https://github.com/akkadotnet/akka.net/ http://research.microsoft.com/en-us/projects/orleans/
I use Arvixe.com which for $8/mo offers unlimited bandwidth and unlimited storage.
We use the Azure Scheduler http://azure.microsoft.com/en-us/services/scheduler/
I'm taking your need to "Run an ActionResult" as "I need to invoke a specific url on my site every x minutes" In general, the task's code should probably be in it's own class so you can hit it from multiple sides -- that way you could wrap this up in a command line app and keep things a bit simpler. If it has to be within the web process I would look at Quartz.Net for all your task scheduling needs. You should be able to pass in windows credentials into powershell's invoke web request with a few extra lines of code, what did you try there?
:) I'm really glad to hear that. Have you played with any of clustering/remoting yet? Opens up a lot of new worlds. 
Wouldn't hurt to bone up on MVC. I ran through the tutorials last week, and that was enough to get me an entry-level .NET job.
btw, the high-level cluster formation / gossip model that Akka uses and shown in video is the model invented by Dynamo, which is at the core of Cassandra, Riak, Dynamo, and several other big tools.
This can vary by city/country. Get on a careers website for the city you want to work in. Do some searches for c#, asp.net etc and see what they are looking for. asp.net mvc is usually a safe bet.
If you're still interested in the Powershell approach, try setting the UseDefaultCredentials parameters to $true for it to use your credentials during the web request.
[This](http://imgur.com/rrhH65i) is what I am seeing between Chrome (right) and Firefox (left) on Windows. Cleared cache and everything. Firefox developer and Regular look the same. It looks good on safari and Chrome on a rMBP.
Have you tried Azure? http://azure.microsoft.com/en-us/ They'll give you some free credit to get started. I personally host there and I think is awesome, probably not the cheapest option but great. 
Any good tutorials for grunt stuff in a visual Studio environment? I'm mostly blank in terms of the capabilities of grunt, never even heard of gulp.
RabbitMQ is based on Erlang. Erlang tries to create a temp folder in your user profile. User profiles support extended characters, Erlang does not. If you have, e.g., an accent in your name (or lots of European users like we do) it sucks, really sucks.
If you like videos [Jamie King](https://www.youtube.com/user/1kingja/playlists) has a Youtube channel with a ton of C# and .NET EF stuff.
Here is a good place to start: http://docs.asp.net/en/latest/
There are constantly threads about interview questions around here and /r/programming, have a look through these for interesting threads: &gt; http://www.reddit.com/r/dotnet/search?q=interview&amp;restrict_sr=on &gt; http://www.reddit.com/r/programming/search?q=interview&amp;restrict_sr=on
http://www.hanselman.com/blog/IntroducingGulpGruntBowerAndNpmSupportForVisualStudio.aspx
Dot Net Rocks podcast is a good way to hear about new stuff / paradigms, etc...
Roger. The reason I asked here is I wanted C# and .NET centric answers, but I will definitely give the search results a good read. Thank you sir. 
code shit, use google results for reference code more shit, use more google results for reference code more shit, and use your own code as reference congratulations, you're now a coder
You can purchase an upgrade from professional to ultimate. But it's not cheap.
Awesome, I'm always on the lookout for good podcasts for my morning commute. I'm going to give this one a try. Thanks!
use bing get free internet points
I think nDepend has some good architecture explorer type features. 
[Project Euler](https://projecteuler.net/) is good for algorithmic problems.
https://github.com/MartinChavez/Learn-CSharp 
Lol. Managing MS licensing could be a job by itself.
I don't know why the down votes. This is more important than any podcast.
If you have it, yes it is.
I believe you want... If NOT 5 AND NOT 6 then redirect...
or you're going to need parentheses around the 2 conditions that both need to be affected by the NOT.
EF started off as an open-source project to begin with
Yep, that's what worked. I thought on the AND that it would need to evaluate both. Appreciate the help!
...but not specific to .Net... 
&gt; Bonus: Also, does anyone have good *general resources* to practice data structure and algorithm questions as well? 
That's possible, however it was shipped as part of .NET.
Reading comprehension fail - my bad.
Thanks for all of the positive replies. I was afraid that I was going to get negative feedback. I'll take what you said and I'll apply it. Thanks!
I bought the Professional ASP.NET MVC 5 (Galloway, et al.) book last year, so I understand the need for a comparison. Your linked article, though, doesn't go into much detail about each book or compare them in useful way. IMO, adding the MVC 4 books to the list would only add to a newcomers confusion over which book to buy. Also, this statement [emphasis added]: &gt;Pro ASP.NET MVC 5 : This book is extension for earlier book Pro ASP.NET mvc 4. It only discusses the newly added features of MVC 5, so **before reading this book you have to read Pro ASP.NET mvc 4**. .. is just plain wrong.
No problem. I too try to solve the challenges. I'll look for your name and will give some feedback if I have any. 
I'd use it as long as it still works. If you start having issues with compatibility in a few versions, then have the boss renew the subscription, or repurchase the library.
I would read the terms of use for the license, i.e. can you keep using it after your license expires. You don't want to be caught using unlicensed dev tools, companies get fined major $$ for that. That could give you ammo to convince your boss.
Thanks!
zero humor involved
No generics actually solved a problem. Before generics you had to use Object based collections which undermined the idea of compile time type safety. It was a great feature to add and probably should have been in 1.0 since C++ already had templates. It fit naturally because C# is a C/C++ family language with stronger type safety.
Only a shitty programmer with god complex trying to be clever
&gt;The numbers I’ve shared with you in this article were a major reason why I first considered joining another ecosystem. It’s my sincere hope you’ll consider doing the same. No agenda here at all from this author, folks...
It may be since few years ago when MS looked like abandoning .net.. but with the new course I can't help myself and see very bright future for .net and .net developers.
I had the same thought &gt;Justin Angel worked for Microsoft building Silverlight, Nokia as the Principal Engineer for Windows Phone development, and at Apple as the lead windows phone developer for Beats Music. I think the fact that he was on the Silverlight and Nokia teams might give him an axe to grind.
What, "Is Slashdot's ecosystem on the decline?".
Slashdot is owned by the same people that own SourceForge, right? So the answer is "Yes"...
K2 - if I understood the K2 consultant at work - is actually based on WWF, just abstracts alot of the pain. Can commend K2, been working on a project using its WF and "SmartObjects" engine to contain our business logic and integrations from a WCF service. 
Good points.
Hello my friend. I figured it out. I'm new to ASP.Net so don't laugh. The Page_Load was running too fast before the data could get loaded to the database. By moving the select statement from the Page_Load to the Page_PreRender I was able to get it to run after the insert, since the PreRender happens right before the HTML is rendered onto the screen. thanks again.
I'm currently tasked with integrating a 3rd party workflow engine with our legacy tools.... I hate life. My suggestion is to roll your own if you can.
I'm half seriously researching event sourcing right now. The biggest question I have so far is the replay functionality. As I understand it, when the software restarts, you are supposed to re-fire all events (let's ignore snapshots) to get it into the state it was in when it was closed. So what about side effects? What if it sends couple of enforcers to beat up someone when an account goes below a zero? Is there a standard way to handle this problem?
It's interesting, but YAGNI.
Asp.net 5 is quite easy to learn. I've never really learnt MVC 1-5, but I'm following every new code line since first alpha in 2014. Visual Studio is (still) a must-have. Srsly once used you won't look back :) You can use 2 docker container in the cloud (4free) to get a **real-time** unix environment so everytime you press ctrl+s it gets automaticly updated and if needed compiled. yolo (If you understand German: https://www.youtube.com/watch?v=yRFUTLIjaZg#t=1h3m40s)
Yes its really great and such wide variety of topics. However I have one complaint for popular topics like .NET - its not very well structured for newcomers, it's often very hard to know where to start and how to progress also a lot of old videos that are not being deprecated properly. Other than that (actually even with this in mind) its great.
Eventual Consistency. Commands are validated against a consistent event stream, but your application displays data from slightly inconsistent read only sources. If you think about it, though, no data that the user sees is garunteed consistent. It's stale as soon as it hits the wire. Your write commands always need some atomic check-then-commit operation in any system, CQRS being no exception. The difference is that the write data is only used for writing
Both of the below extensions are listed as free. * [T4 Toolbox for Visual Studio 2015](https://visualstudiogallery.msdn.microsoft.com/34b6d489-afbc-4d7b-82c3-dded2b726dbc?SRC=Home) * [Devart T4 Editor for Visual Studio](https://visualstudiogallery.msdn.microsoft.com/a42a8538-8d6e-491b-8097-5a8a00174d37)
Whoa, T4 toolbox must have only recently been updated for VS2015. Devart's extension does not support VS2015. THANKS FOR THE LINK!
I'm really, really sorry to say this, but even dumber is to propose this complex architectural decision ahead of any product context. As I said, it's interesting, but you're going to implement a lot of abstractions &amp; infrastructure for something you'll probably never need.
Yes, I'm one of those people. And, reconstructing that audit information, or making it a second-class citizen, has always been a PITA. When you *need* auditing, it's really dumb to tack it on as an afterthought. CQRS isn't a fit for every domain. No technology is. But, conversely, with that logic EVERY technology can be YAGNI'd. Why would I use a SQL database? YAGNI. Why bother with NoSQL either. YAGNI. Flat files? YAGNI. I'd say use a List&lt;T&gt;, but YAGNI. Just stick with an array of objects, but YAGNI. YAGNI is a good principle for an organization to follow, when thinking cross-domain. Don't add in features that don't belong to that domain. But, if you can't make a plan for a specific problem domain, why are you even employed? MVP is the same thing. Don't be stupid with it. If everyone already has a bike, so you're making a car to beat the competition, why would you bother making a skateboard? You have REQUIREMENTS. You need to make a plan that will meet those requirements, not just develop without a plan because you're a slave to the process.
Also .NET's biggest strength is in another, non-competing platform - the web. 
At the risk of sounding like a hipster, I think I've read /. a half-dozen times since CmdrTaco left. And what will *actually* make me sound like a hipster: I remember reading /. regularly when it was still hosted on a box sitting in his dorm room (well as "regularly" as one could when it was crashing constantly due to the load). NataliePortmanHotGritsCowboyNealShouldn'tBeAllowedToDoPolls
And you couldn't just say that outright?
Not sure how that will go over but thanks for the tip. Is it just annoying to work with or inflexible or what?
I guess everyone is missing my point. If you need to keep every data then implement that. Just because event sourcing solves it doesn't mean it's perfect. Why would you need different read &amp; write models (and all the transformations in the middle) if all you need to do is keep a log of all the changes?
You're making the assumption here that I didn't already do that before I asked. Which is a **VERY** bad habit all of you people have because 99% of the time, by the time I'm asking in this community or that, I've already looked and been unable to find an answer or else I found something that seemed to only partially answer my question as was the case here. Yes multi-targeting of frameworks is in answer to my question, but its still only a partial answer. It doesn't address the issue I experienced with the compilation error that occurred because the `targetFramework` attribute and the IIS app pool had conflicting values. Or am I wasting my time here?
Because the concept of "keep a log of all the changes" is very flawed and **much** more complex than event sourcing. You'd still update your entities (and thus **delete** data) and add an entry to what changed.
As an intern just beginning to delve into C# and .NET, this sounds promising :)
This is typical behavior for little ortund.
 Windows Identity Foundation or asp.net identity which replaces forms auth.
MVC is pretty powerful, the upcoming version looks tight. You can also use Web API to serve up JSON to a Javascript frontend, so you can use Angular or Ember or Backbone or whatever JS framework is hot this week.
Thank you for the explanation between single page and traditional web applications. Yes, I would like to follow the single page application path. And yes, I have to stay in the MS world. I am just surprised that there seems to be just one web framework in the MS world: ASP.NET. In other technologies people count the number of days since the invention of the last web framework. :-)
I like NancyFx personally. I like the defaults, but it's also pretty easy to customize. It can be used to setup an API to serve a javascript front-end framework (angular, etc.) or it can serve up views rendered on the server if that's your preference. You can also mix-and-match if so desired.
I'm most used to asp.net mvc, but that's not the only alternative (even though MS throwing it's weight behind something is quite an advantage) Anyways, if you strictly don't want asp.net mvc there are a few others * [OpenRasta](http://openrasta.org/) * [Nancy](http://nancyfx.org/) * [MonoRails](http://www.castleproject.org/projects/monorail/) I don't have any real insight into any of these except having ran into them occasionally, but I don't think they should be dismissed just because they are not asp.net mvc Hope it helps
You can certainly use a *client-side* framework based on Javascript that sends requests and receives responses to a server running ASP.NET MVC. You may be coupling ASP.NET MVC with *Razor*, which is ASP.NET MVC's view engine. ASP.NET MVC was designed to be modular in that sense, as you're welcome to choose between view engines or opt out of them altogether. What you're more than welcome to do is use ASP.NET MVC as a server-side technology that retrieves requests and returns JSON results that are then consumed by whatever client-side Javascript framework you want. Alternatively, if you're certain that you're building a purely service-oriented server-side, you may consider implementing your entire back end as an ASP.NET WebAPI solution. I personally spearheaded a project to convert a Silverlight application to an AngularJS application that retrieves JSON data from an ASP.NET WebAPI backend, and I've also worked with a company that converted a Silverlight app to ASP.NET MVC that fed JSON to their own loosely-built JS framework centered around Dojo. 
As far as .NET frameworks go, there is not one which will handle the client-side aspects of a SPA. If you want to go down this road, using Web API as your backend will probably be the easiest way to send JSON back and forth. Microsoft stands behind KnockoutJS, but Knockout alone will not give you a SPA. Knockout, Sammy, and Durandal will do a SPA when combined together, Knockout is really just a data-binding library. It is my understanding that Microsoft is also betting heavily on Angular and will feature more built-in support for it in upcoming releases of VS.
&gt; MS world What do you mean by this? 1. Anything that runs on Windows? 2. Anything based on .NET? 3. Anything that runs on IIS? 4. Anything you can write in Visual Studio? 5. Anything that was produced by Microsoft themselves?
The documentation is complete. But that doesn't mean the information is where you expect it to be.
Rob Eisenberg (creator of Durandal framework) left the Angular team and now works on Aurelia. http://blog.durandal.io/2015/01/26/introducing-aurelia/ http://aurelia.io/
That's the one. I like you. 
1. Use C#/ASP.NET if you prefer the language and framework to JavaScript and your web framework of choice. I'd argue that C# is a more expressive language; with which it's easier to develop large applications; and the benefits of which outweigh the benefits of "one language everywhere" since you don't typically share much logic between client and server. If you're developing a small application, I they're about equally good, but within a few weeks of development, I think you'll find the organization that C# provides superior. 2. According to the last benchmarks I saw JIT-compiled JS on V8 is comparable to C# in performance. I was surprised that they were close (I'd have assumed C# to be faster), but they were. 3. Yes. Twitter is one of most highly-trafficked applications on the planet, and Ruby is one of the slowest commonly used languages. Note that PHP is, in fact, open source.
#2 100% true. Node is event-based (async) and single-threaded. If you do CPU-intensive work when you handle an event, all other events are blocked until you finish. Your throughout will plummet. Which brings me to #1. #1 Node is good for a certain class of problems, but it's not really a general-purpose server. The event-based model is actually quite complex &amp; if you're just getting started, you're best off with something like PHP. 
How does TypeScript help with upgrading to Angular 2?
Language isn't that important. Even with .nodejs stack you will need to know javascript + html + css + sql. Probably, you will need bash scripts. Also there are a lot of DSL languages like Markdown and various template languages. The things that takes time to learn are libraries. For any senior developer it isn't hard to write code in language that you never seen before. Productivity goes down, but it is a temporary issue. 1) Different frameworks provide different advantages - some comes from language itself, some comes from existing code &amp; tools, some comes from ecosystem &amp; community. I'll compare the ones you mentioned with javascript just to show some things you need to take into account than you chose a framework. C# is strongly typed - this is a huge boon if you have a large codebase. VisualStudio is a great tool - in js every developer creates their own environment(it is great than you are on your own, not so great than you develop on someone's machine). There are lots of mature libraries for UI controls and other stuff. Azure give you some nice features. The list could go on. Ruby is an amazing language - it has so many cool syntax features that it is very hard to convert it effectively to machine code. But when you do rapid development it is terrific. Also for a long time it was a frontier language - many things that are common now were developed first for Ruby(convention over configuration style frameworks, static site generators, etc). Great community, big salaries. Php is an awful language, but there are so many things written in it. Try to create a blog from scratch and compare it to wordpress customization - you will see why existing code is an important thing. There are so many things to consider than choosing a framework that the number of languages used in development isn't important at all. 2) Don't care about "general performance". It is pointless to talk about performance without concrete task. If you have some very cpu intensive part of your app you could always separate it to a service written in pure С - problem solved. But node isn't bad "in general" - jit is good. I would think twice before starting node.js project with big &amp; complex SQL database. It could be done, but you need to check tools your are going to use very carefully. This is one of the reasons to use C# over node - DAL libraries are much more mature. On the other hand, you could always go NoSQL route and get all performance you need. 3) I know some guys who survive on COBOL stack alone. So for node.js the answer is definitely yes, but you need to take into account that during an average developer career there are several stack switches. It depends on a person - some change technologies more often than others, but it will always happen. 
Don't start with PHP. It can cripple you as a developer.
Agreed. There is a great set of articles and posts here (on the asp.net site): http://www.asp.net/identity 
Your choice of language really only decides what kind of environment you want to work in. C#/ASP.Net if you obviously prefer windows and Visual Studio and that's where you want to work. Other languages like Ruby, Python, and Node/Io.js usually are found in more *-nix environments. Yes and no on CPU intensive tasks. some strides have been made in this area with the introduction of Clustering, but I don't have any concrete numbers on this since I haven't played with it much but other blog posts I've read about it seem promising at least from a handling more web connections point of view. Node can be used very well in a database applications due to it be asynchronous and not blocking on database I/O. You can make a living in just about any environment/language/framework depending on the job market. I've lived on both sides of the fence and I can say honestly I've enjoyed working more on the open source side. A lot of people here are bashing Node and Javascript as unusable for large projects but you can make any language unmaintainable. I've seen just as many awful C#/ASP.NET projects as I have Node.js projects. I've seen people abuse their IDE's tools, mainly Visual Studio, to keep crappy projects floating along and turn away from poor design or bad code. 
Patrickvideos.com is the best I've found so far.
Being both a c# and php dev, I'm going to disagree. Most of the php hate these days comes from its issues over 2 years ago which have since been fixed. I have found php + laravel to be extremely powerful and easy to use.
If you are meaning outside .net, there is Ruby on Rails, php using laravel, JavaScript using meteor, Python using django, etc. 
Asp.net is no longer limited to Windows. It will run on just about anything, if it won't then get the source and make it.
If you are really comfortable with Javascript, and you don't care for .net jobs, you're right, no reason to learn. I'm currently getting into the Lightswitch framework. It's pure, undistilled hell, and that's mostly because of it's Javascript part, a language I have never warmed up with (back in the mid-1990s, it was to weak to do anything useful with it, and then I just didn't care about it anymore.) Remember that any language and every framework has it's advantages and disadvanages. Consider that not everything in the world is or will be run as a web service. 
Netflix, LinkedIn, eBay, PayPal, the New York Times and Walmart all use node.js. I don't know if it's fair to say node.js is only good for small scale applications.
1) .net mvc is not a framework. There is a framework involved (the .net framework) , but mvc is not one. You could just as easily make a .net webforms, .net mvvm , etc etc project 2) you don't want it to be based on javascript. Javascript is client-side code. it's goin to be insecure, and it's performance will depend on your clients connection and technology. it's fine to have javascript used as part of your solution, but it should not be the basis of it. 
And to elaborate on that, .NET has great ~~statistical~~ static analysis tools, refactoring tools, better programming aids (Intellisence, code navigation tools). It's just easier to write and maintain really large applications. That said the gap will close with languages compiling to Javascript like TypeScript allowing better tooling. In any case you'll probably have a better change of hiring a good programmed that can jump into a large .NET project and be productive than on a large JS program (from my personal experience).
?????????? ok, i don''t know what you're doing. mambership or identity? the way i have always done it (for membership) : create a database set the connection string in web.config run the asp_regsql tool to create membership tables done maybe there's some automation in the newer versions that i haven't come across yet - to be honest i haven't done it from a blank project in about 2 years - but yes, you can do it manually.
&gt; ok, i don''t know what you're doing. *When you first create Web Forms application*, is what I'm doing.
/thread
I think [this](http://www.asp.net/web-forms/overview/getting-started/getting-started-with-aspnet-45-web-forms/create_the_data_access_layer) should help you. It uses a code-first approach for defining the structure of the database. The key concept here is that you will be creating a new class that inherits from DbContext, which will give you your own .mdf file.
We use winnovative with great success http://www.winnovative-software.com/ExcelLibDemo/
Look in web.config for the connection string. 
I read somewhere that version 4 of EPPlus was going to have formula calculation. I will give it a try.
How about Excel itself? You do not need a library, you can use Excel! Everything it does is exposed via COM, should be fairly trivial to use as far as I can recall. However, I do not know if the licensing allows for it in your scenario, specifically.
I can't speak for knockout, but its designed for UI, which is JavaScript's original purpose. I'd test it, though.
Agreed. As you mentioned, COM Tends to result in a very definite bottleneck in any threading/concurrency scenario. Also, there's the security concerns of having an application that isn't really necessary on the server. No, I've never heard of an attack vector that specifically targets a .NET app using an Office app with COM interop. Yes, there's things you can do to protect against most of the concerns that immediately come to mind (the fact you're allowing third party add-ons in, the possibility of opening a file up that has some sort of exploit contained inside, the possibility of accidentally writing some code that's awkward enough that you cause a memory leak in COM or Excel.) But even if you plan for those... the next developer might not realize them. Simplicity is important, but short term and long term simplicity are important too. A well written library (or library with a wrapper for the work you have to do) will be more maintainable in the long term, and easier to test/redeploy/maintain.
Excel COM interop us the meth ox programming. Not even once 
+1 for epplus. I use it and have contributed to it. Ive not tested it's formula support, but it's the best free option. 
Are you sure the "serious" stuff in their stacks are done with JS? Or is it Java/Scala? ( ͡° ͜ʖ ͡°)
Xamarin isn't newer Mono, Xamarin is a company that helps develop the Mono open source project. They also create proprietary tools on top of the Mono platform.
Monorail was one of those wheels MS reinvented. It was around for years before ASP MVC which took a few versions to reach parity. 
My only point was that Node.js is used for large scale applications. Node.js isn't the perfected technology for every situation. It's asynchronous nature makes it excellent for real time applications and UI management . That is why you see many companies moving their UI logic to Node.js. However, Node.js performs poorly on CPU intensive tasks due to it being limited to a single thread so any CPU intensive tasks you would want to manage with Java or C#.
My company makes extensive use of Aspose.Cells, both in generating files (.xls and .xlsx), and in parsing uploaded files. We have several hundred internal applications that use it, it's been the best / most flexible option that we were able to find.
Having lived through the issues that doing that causes, I wouldn't recommend it. The number of technical issues that it causes, from corrupt files to server instability, it's just not worth it. Before moving to a library to handle it, we contacted Microsoft to see if there was anything that could be done to address the issue - after talking about how we were using it, and the volume of processing, they were amazed it was working so well. They highly recommended against using it from a server. 
Ah ok. cool cool.
I used spreadsheet gear for a while in a previous employer and never once hit a snag where it couldn't do what I wanted it to. Trying to get my current employer to shell out now..
If you're using a js front end with web api backend, you will pretty much always come across a scenario where you need to authenticate those requests. And those credentials will need to be readable by the browser, and therefore any user.
If that user/pass are in the client, I can read them. If I can read them, I can make my own api calls. This security issue doesn't exist with server-side binding. 
That's why you authenticate every request. No matter what request you receive you check the credintials. Who cares if they write their own api. They couldn't do anything special, just what you allow them too. 
looking at doing something like private override bool BeforeSaveEntity(EntityInfo entityInfo) { var validator = new Validator&lt;-of Type entityInfo.Entity-&gt;(entityInfo.Entity); return validator.runLogic(); }
and if I need to pass a parameter to the class - it's constructor takes the entity as a variable. public class EntityValidator&lt;TEntity&gt; { private readonly TEntity _entity; public EntityValidator(TEntity entity) { _entity = entity; } public bool Validate() { //logic } } so this: var validator = (EntityValidator)Activator.CreateInstance(type.MakeGenericType(entityInfo.Entity.GetType()), entityInfo.Entity); Should work .. but it's throwing me an error incorrect number of parameters .. 
Like I said: The `BeforeSaveEntity` method is way too late for validation purposes. You should validate before the `Save()` call and don't save in the first place when validation fails.
With breeze there is no earlier place to validate. BeforeSaveEntity is BEFORE the save, depending on what BeforeSaveEntity returns the entity is saved or not. any earlier validation would happen on the client ( I'm actually using Angular ) and cannot be trusted. For example any form of validation if the user is allowed to edit that entity can only be done in the BeforeSaveEntity/BeforeSaveEntities
The framework has it's ups and downs. Every framework does the validation before saving. Even working with web.api controllers you still do the validation when the entity is posted and before saving eg: [Route("")] [HttpPost] public async Task&lt;IHttpActionResult&gt; PostApplication(Application application) { if (!ModelState.IsValid) { return BadRequest(ModelState); } _applicationService.AddApplicationWithGoals(application); try { await _unitOfWorkAsync.SaveChangesAsync(); } catch (DbUpdateException) { if (ApplicationExists(application.Id)) { return Conflict(); } throw; } return Ok(application); } 
 if (!ModelState.IsValid) { return BadRequest(ModelState); } Never did that. That's what we have filters for.
Can the entity not validate itself, or provide its validator? Use the IValidatableObject object interfact and offer up a Validate method, or create your own that returns an instance of the type? Or if you're using castle (any di framework), use a variation on typed factories to get castle to spit out an instance of your validator.
That's kinda exactly what I'm doing now. I wanted to keep the validation away from the POCO classes but it does seem the simplest way. The validation is mostly security related so I need to inject the current user - IPrincipal, while breeze has some amazing functionalities, it's kinda limited on the security side for saving. 
I'm working on exactly this same thing right now. We're using a package called FluentValidation for this. I can't remember off the top of my head the details of how it decides which validations to apply but I can take a look when I get into work. It's definitely in the BeforeSaveEntities method. I'll get back to you in a bit. 
[Complete example](https://dotnetfiddle.net/0lokwL). 
&gt; statistical analysis tools *static* analysis tools
Refactoring. When your project grows and you start to move code around, you'll be happy to have a compiler to catch many stupid mistakes you'll make during the process. To some degree you can achieve that with TypeScript and proper testing, but still... I'd never use dynamic typing language if I don't need to.
1. The IDE is used to manage solutions, projects, dependencies and to assist in higher-level concerns. While it is useful, it is not in-and-of-itself part of the framework. You also don't need to use the IDE to write, compile or deploy applications. 2. There are multiple parts of the framework. ASP.NET and the MVC Framework (which are dependent on .NET) give you components and handle run time concerns (pipeline, authentication, etc.). You write an application that outputs client-compatible code, not a website, so you are still required to know HTML, CSS, JS etc. 3. ASP.NET is the server side, talking to databases, using existing components, doing image processing, building PDFs, calling web services, etc. The framework is then used with client-side technologies to build out something the client's browser can render using the bits you've mentioned.
An inelegant solution: Have two sites hosted on the server. Send the external folks to one and the internal to the other. Set up Forms auth for the internal site and use IP restrictions and basic auth for the external users.
Reading only the opinions here will skew your results. It's best to ask this in several places if you want honest answers. C# is great, but so is JavaScript &amp; Node.js, and it is extremely, extremely obvious that ASP.NET 5 is HIGHLY influenced by Node and the Node community. A great programmer can build a large, complex single page app back-end in either .NET or Node (or Java or Go or..... whatever). They all have pros and cons. However, to shrug off Node.js would be a huge mistake. It is extremely popular for a reason, and Microsoft is specifically trying to keep up with Node in ASP.NET 5.
Have you looked at owin middleware? You could use it to intercept the connection from external users and convert to forms auth after authorising the connection. As far as the ASP.NET application knows all users will have the same type of authentication.
Single Page Apps are moving away from the server-side MVC pattern now, in general. More and more is being done on the client-side with RESTful web apis serving up all of the data. (That Web API can be on ASP.NET, Node.js, Go, whatever...)
Google "forms authentication against active directory"
You can use Windows Authentication and control access to certain MVC/WebAPI actions via the Authorize attribute. [Authorize(Roles="WindowsGroupName")] public string GetName(string name) { return name; } That works really well when your SPA is only talking to one API on the backend and all the static HTML/JS is hosted on the same server as the API. When I wanted to do more than that, and added CORS into the mix, it got icky. I used the ADFS 3.0 OAuth2 support to control access to the APIs. It works well, but it was quite frustrating getting it setup. [[This article]](http://www.cloudidentity.com/blog/2014/02/12/use-the-on-premises-organizational-authentication-option-adfs-with-asp-net-in-visual-studio-2013/) makes it seem easy, but it wasn't. I would only recommend going this route if you have to.
httpErrors vs customErrors issue. IIS has it's own errors that you should probably setup. 
HiddenFor can not store complex object like that. It can only store a single value (string, int, etc.)
MCA is right, you'll essentially need to rebuild the user object in the view in order to pass it to the controller 
What do you mean by avenging the user object? As in passing in plaintext ID and having the controller create a new model object on its end and find the user and then assign the role?
&gt; @Html.HiddenFor(model =&gt; Model.user); You need to have hiddenFor elements for each value you want to send back. If all you care about is user id just do this @Html.HiddenFor(model =&gt; Model.user.Id);
Reinforcing fact number 1 : [Omnisharp](http://www.omnisharp.net/)
Oh my god. It worked! Wow, I've been pulling my hairs over this for a few days already trying to figure out why this damn thing couldn't work. I didn't realize ApplicationUsers couldn't be passed in, but that's rather silly and kind of a meander to get to the point. Whatever, it works. Thanks everyone for the help!
More or less, there may be a different way to do it. Typically in my experience it's best to pass id's to the controller and rebuild it there. I can look at the way they pass a similar object around at work. I'll post some resources in the morning at work. 
I keep hearing a lot about Docker on windows but I haven't seen much in the way of concrete details.
That'd be very awesome. I did exactly that and rebuilt the model, but to me it seems just redundant and would take up more memory. Then again I'm used to C++ and C# is a pretty new toy to me.
&gt; user Just pass in the UserId and then do a lookup on the user :)
I really really like it when I see open source implementation posted to this sub! Up vote for you good sir!
We use a small single sign in app that bypasses the login form in our site for domain authentication users. On the sites we have our application at `a.b.com/vdir` and we have an auth site at `internal.b.com/win`. Once authenticated to the internal site you click a link there to get to the destination. The link looks like this: `internal.b.com/win?dest=a.b.com/vdir` This loads a form that posts via javascript onload to `a.b.com/vdir/internalauth` and passes a guid. It also stores authentication information for the user who clicked it. The destination page then takes the guid and does a web service lookup against `internal.b.com/win/verify` and retrieves the authentication information. This allows us to have internal users use their domain credentials while still allowing us to test the forms authentication workflows from within the network. I'm simplifying things a bit (not much, we have a couple other variables passed through and a timestamp and some logging ...).
This is really impressive. I've just logged in to the admin panel and it looks just like Shopify! I'm a C# guy but I was keen to try Shopify because it's so easy to get up and running and the .NET alternatives I haven't been too impressed by. I currently have a customer using it (Shopify) and they love it (the project simply wouldn't have been done otherwise). My only caveat with this would be the backend database - is it specifically tied to SQL Server? I recently switched our tech stack to *nix and we're phasing out Windows dependencies. If not then that might be an area I'd be interested in contributing to (if it's feasible).
1) You don't have to use Visual Studio. You could use any text editor and run the compiler against the source. But based on the question you're not clear on what is the generally understood meaning of "framework" -- which means the supporting class libraries not code editor. 3) To clarify what others have said, if you want to create a simple static page then html / css and javascript is all you need. You can hand edit the html and open it in a browser. But let's say you want to allow users to enter comments. They would submit the comments to the server and they would be stored. When the page is requested they need to be loaded and html to display them needs to be generated. Something on the server needs to do those things. That's where ASP.NET, PHP or node.js comes in. 2) In ASP.NET, you're writing that server side code. You can do it in any supported framework language e.g. C#. Within .NET, There are two different frameworks for doing it: WebForms and MVC. Being new to the area you would probably want to look into MVC. In either case you have special files which contain html and special mark-up which assists in generating the dynamic html.
I've got a lot of experience with SQL server and relational data structures. I've been dying to come up with an excuse to use document db but I'm not really sure what projects would be better suited for document db rather than SQL server. Any thoughts on this and how to get started?
Absolutely! Some **scenarios** where I think document databases are a great fit are: **1) Heterogeneous data.** **Example:** let's consider that you are building an e-commerce site where you sell everything from books to video games to laptops. It is really hard to fit this kind of data in to a tabular structure. Creating a column for each attribute doesn't scale because there are too many varying attributes among your various products. How much ram does your book? Who is the author of the laptop? Creating a table for each product type is cumbersome because you have a rather expansive product catalog. Creating and maintain 1000s of tables for 1000s of product types is a maintenance nightmare. Storing everything as JSON in a single varchar column doesn't perform well. You lose the ability to index and query off individual attributes. Storing a heterogenous data (schemas that vary quite a bit) in a schema-agnostic database is easy; just store the data and query off the fields you need. Simple. **2) When you don't get to dictate the schema (e.g. pulling data from 3rd party data sources)** **Example:** let's say you have an application that pulls data from various 3rd party APIs from around the internet, e.g. Reddit, Github, and StackOverflow. JSON has become the de facto data interchange format of the internet. Extracting fields out of JSON from a 3rd party REST API to fit a tabular structure can be tedious; and even worse... what happens when your data source changes their schema tomorrow? Data loss occurs! This is another area where schema-agnostic databases shine. You can store JSON passed back from 3rd party sources directly in to the datastore without having to worry about data loss due to schema changes. Simply update your application’s queries to reflect the latest schema changes and you are back up and running. **Getting Started** As for getting started, there isn't an *official* free-tier just yet. But there are many ways to get started for free (MSDN, BizSpark) - or you can borrow one of my database accounts. We also have a [tutorial](https://azure.microsoft.com/en-us/documentation/articles/documentdb-dotnet-application/) for building your first ASP.NET MVC application (a simple todo list) on top of DocumentDB. And code samples on our github: https://github.com/Azure/azure-documentdb-net **Schedule 1:1 with us via AskDocDB.com** Mind scheduling some time with us through the website? We'd love to help you! The website helps us load balance support :)
They also just announced that all of the big players are coming together to agree on a universal container design. So that should help longer term.
 &lt;%@ Page Language="C#" AutoEventWireup="true" CodeBehind="inventoryentry.aspx.cs" Inherits="InventoryTake2.Inventory_Entry" %&gt; &lt;!DOCTYPE html&gt; &lt;html xmlns="http://www.w3.org/1999/xhtml"&gt; &lt;head runat="server"&gt; &lt;title&gt;&lt;/title&gt; &lt;/head&gt; &lt;body&gt; &lt;form runat="server"&gt; &lt;asp:DropDownList ID="RawMaterialId" runat="server" DataSourceID="SqlDataSource2" DataTextField="RawMaterialName" DataValueField="RawMaterialId"&gt;&lt;/asp:DropDownList&gt; &lt;asp:SqlDataSource ID="SqlDataSource2" runat="server" ConnectionString="&lt;%$ dbConnectionString %&gt;" SelectCommand="SELECT [RawMaterialId], [RawMaterialName] FROM [RawMaterial]"&gt;&lt;/asp:SqlDataSource&gt; &lt;asp:DropDownList ID="locationId" runat="server" DataSourceID="SqlDataSource3" DataTextField="locationName" DataValueField="locationId"&gt;&lt;/asp:DropDownList&gt; &lt;asp:SqlDataSource ID="SqlDataSource3" runat="server" ConnectionString="&lt;%$ dbConnectionString %&gt;" SelectCommand="SELECT [locationId], [locationName] FROM [locations]"&gt;&lt;/asp:SqlDataSource&gt; &lt;asp:DetailsView ID="StudentsDetailsView" runat="server" DataSourceID="SqlDataSource1" AutoGenerateRows="False" DefaultMode="Insert" DataKeyNames="entryId" OnPageIndexChanging="StudentsDetailsView_PageIndexChanging"&gt; &lt;Fields&gt; &lt;asp:BoundField DataField="quantity" HeaderText="quantity" SortExpression="quantity"/&gt; &lt;asp:BoundField DataField="entryId" HeaderText="entryId" ReadOnly="True" SortExpression="entryId" /&gt; &lt;asp:BoundField DataField="creator" HeaderText="creator" SortExpression="creator" /&gt; &lt;asp:CommandField ShowInsertButton="True"/&gt; &lt;/Fields&gt; &lt;/asp:DetailsView&gt; &lt;asp:SqlDataSource ID="SqlDataSource1" runat="server" ConnectionString="&lt;%$ dbConnectionString %&gt;" SelectCommand="SELECT [locationId], [rawMaterialId], [quantity], [entryId], [creator] FROM [inventory]" DeleteCommand="DELETE FROM [inventory] WHERE [entryId] = @entryId" InsertCommand="INSERT INTO [inventory] ([locationId], [rawMaterialId], [quantity], [entryId], [creator]) VALUES (@locationId, @rawMaterialId, @quantity, @entryId, @creator)" UpdateCommand="UPDATE [inventory] SET [locationId] = @locationId, [rawMaterialId] = @rawMaterialId, [quantity] = @quantity, [creator] = @creator WHERE [entryId] = @entryId"&gt; &lt;DeleteParameters&gt; &lt;asp:Parameter Name="entryId" Type="Int32" /&gt; &lt;/DeleteParameters&gt; &lt;InsertParameters&gt; &lt;asp:Parameter Name="locationId" Type="Int32" /&gt; &lt;asp:Parameter Name="rawMaterialId" Type="Int32" /&gt; &lt;asp:Parameter Name="quantity" Type="Int32" /&gt; &lt;asp:Parameter Name="entryId" Type="Int32" /&gt; &lt;asp:Parameter Name="creator" Type="String" /&gt; &lt;/InsertParameters&gt; &lt;UpdateParameters&gt; &lt;asp:Parameter Name="locationId" Type="Int32" /&gt; &lt;asp:Parameter Name="rawMaterialId" Type="Int32" /&gt; &lt;asp:Parameter Name="quantity" Type="Int32" /&gt; &lt;asp:Parameter Name="creator" Type="String" /&gt; &lt;asp:Parameter Name="entryId" Type="Int32" /&gt; &lt;/UpdateParameters&gt; &lt;/asp:SqlDataSource&gt; &lt;/form&gt; &lt;/body&gt; &lt;/html&gt; 
To be fair to PHP, it was awful before 5.3. The language is now much improved and the syntax is becoming a lot cleaner. These days the only thing that is really holding them back is wordpress. There are plenty of MVC style frameworks these days. 
No sorry JavaScript is an excellent language that is pretty expressive. The problem with JS is much like VB.NET, it is normally written by people that either don't understand the language correctly (Java / C# dev that try to write it like Java or C#) or it is written by people that aren't programmers. Every major JS mess is down to writing off as a toy programming language.
Not being funny but every .NET application I have ever worked on has been a unmaintainable mess and if I didn't have "Find usages" in VS I would be at a loss. Having good discipline, coding standards and code review is the only way to make sure any large project doesn't become a mess. 
Is it because fewer people are using it than actually developed it?
TBH if you are already fairly comfortable programming, it doesn't really matter which backend technology you use. These days it doesn't really matter if it is ASP.NET MVC, PHP, Ruby or Node. All of these languages have very similar frameworks e.g. ASP.NET MVC is heavily inspired by the Rails framework (in fact most of the popular MVC-ish are all inspired by Rails). So once you learn one you can pickup another fairly easily e.g. I am using Flask for a web app I am building to teach myself python. The main mistake I see a lot of more backend or desktop orientated programmers make is that they don't respect each technology what it is for. HTML for structure, CSS for presentation and JS for UI and Business logic inside the browser. You are going to have to learn JS, so I would get yourself a copy of JavaScript the goodparts and learn things like variable hoisting, scoping, closures and learn some basic patterns in JS.
.NET was the last frontier. Nobody is brave enough to put a potential production egg in a new MS technology basket because they're going to kill it in a year.
Sorry but problem 1 is easily solvable, and probably better, with a relational database. If anyone offers you an API that keeps changes then maybe you should look for a new provider. Only reason to use a NoSQL database I found is for logging large amounts of data and I don't care of the format.
either a) your dropdown is losing it's data on postback. data binding needs to be done BEFORE the Page Load event. b)you're not reading the value out of the ddl correctly either way, learn to use the debugger set a breakpoint just before you read the value back in. hover over the various variables and objects, make sure they all say what they should. press F11 to move to the next line, repeat the process until you find the object/variable that isn't being set correctly.
That makes perfect sense. Still learning,as I said. I have everything that is made so far done via the automated toolbox and SQL data source. I will have to manually do all of that, and the databinding makes perfect sense, since the system will most likely not do that auto, and the reason I get a null is it resets itself (talking to myself here lol)
it's worth spending 10 minutes or so reading about the "page lifecycle" learn when you should be doing different tasks ( Page Init , Page Load, Page PreRender , etc ) it can save a lot of confusion and silly needless bugs if you understand that stuff early on.
The problem with your scenario is documentDBs pricing plan makes it a poor choice for storing something like IIS logs or event logs. The whole point of NoSql is scalability to massively large datasets, but the pricing model rules that out, so its practical usage scenarios are questionable.
Exactly. NoSql is about horizontal scalability for massively large datasets. The problem is that documentDB's pricing model rules that option out.
I have yet to do any full analysis, outside of the technology stack itself. If what you are stating is correct, that's disappointing, as another interesting dataset that could be correlated at a temporal level are metrics/kpis from perfmon. For a 2 or 3 tier production environment, I could easily define and execute the collection for GBs of devops data (daily/weekly), with medium to long-term storage, that I would want to do temporal querying/reporting against a NoSQL type backend like DocumentDB, if cost and performance were to allow it. 
Make sure to reach out over in /r/programming as well - I haven't found this sub to be necessarily boundary-pushing (no offenses intended). Any word on backups, or local development scenarios?
Now. It's only being improved, merging web api and mvc controllers and a new project structure with a json config instead of xml. Not that much is really changing.
This is super important if you are going to do web forms. You really should just do mvc though. Making a web app/site in webforms is never going to help you learn the web.
Now. BTW you can use your gained knowledge to transition between asp.net 5 and node.js and vice vera. * Use google search options instead of a specific blog. Filter for 'last month' etc.. * Community Standup vids on Scott hanselman youtube channel. * Github. Srsly github is a really good source, ppl use 'issues' as a general mini forum and thats awesome * asp.net forums There is a docu site out there, not yet finished, but search for it. Sry I'm on mobile
I challenge you to find me an app that can't be deployed locally to a directory. I currently have a WPF app with over 100 dependencies, managed and unmanaged, including the VC++ runtime and COM (using reg-free activation), and I can deploy it locally in a single directory with xcopy. Very complex apps can be deployed this way.
If I save this path as a string and then use File.ReadAllBytes with given path, I get NullPointerExceptions. Any hints ?
Well, I actually have one, that doesn't work with reg-free COM, since it has special dependencies on databases that cannot be used in tandem with reg-free activation. But that is besides the point. Even if it *COULD* be done, it's more easy and handy to do it with a container. It also comes in handy when you have requirements such as not deploying .NET on a machine (some companies don't certify newer .NET versions for years), but can still deploy it that way. No need for setups, and uninstalls anymore, just remove the container. It's useful in the same way as containers are useful on a server. Also there containers are not a necessity, but are useful non the less.
Here's a fascinating log. I'm starting to thing I've been a dumbass and made a path error. Any clues? d:\a\src\MYPROJECT\MYPROJECT\nuget_pack.bat d:\a\src&gt;REM This file is used to package projects and publish them to MyGet d:\a\src&gt;REM This file should sit in the same directory as the csproj file you want to package d:\a\src&gt;REM nuget.exe should be in a directory called ".nuget" one directory up d:\a\src&gt;REM You can get nuget.exe to install by turning on nuget package restore d:\a\src&gt;set config= d:\a\src&gt;set PackageVersion= d:\a\src&gt;if "" == "" (set config=Debug ) d:\a\src&gt;set version= d:\a\src&gt;if not "" == "" ( REM set version=-Version set version=-Version "nipnipnip" ) d:\a\src&gt;set nuget=..\.nuget\nuget.exe d:\a\src&gt;REM Make sure there is only one file in the package directory because we're going to push everything to myget d:\a\src&gt;REM del /F /Q bin\nuget_build d:\a\src&gt;mkdir bin\nuget_build d:\a\src&gt;REM ** Pack the Project ** d:\a\src&gt;REM Changing package title/id/description can be done by modifying [AssemblyTitle] and [AssemblyDescription] d:\a\src&gt;REM in the AssemblyInfo.cs file in the project (see: http://stackoverflow.com/questions/22208542/nuget-pack-someproject-csproj-wont-let-me-change-title-or-description/22208543#22208543) d:\a\src&gt;cmd /c ..\.nuget\nuget.exe pack "MYPROJECT.csproj" -IncludeReferencedProjects -o bin\nuget_build -p Configuration=Debug The system cannot find the path specified. Exception Message: TF270015: 'nuget_pack.bat' returned an unexpected exit code. Expected '0'; actual '1'. See the build logs for more details. (type UnexpectedExitCodeException) Exception Stack Trace: at System.Activities.Statements.Throw.Execute(CodeActivityContext context) at System.Activities.CodeActivity.InternalExecute(ActivityInstance instance, ActivityExecutor executor, BookmarkManager bookmarkManager) at System.Activities.Runtime.ActivityExecutor.ExecuteActivityWorkItem.ExecuteBody(ActivityExecutor executor, BookmarkManager bookmarkManager, Location resultLocation)
Increase the build verbosity. Make sure all files and paths are present and correct.
Now. The software pattern is what's important not the specific implementation. 
ASP.NET 5 is now stable enough for prototyping so as a learning tool you should be fine.
You should meet with this guy, he asked the same thing: http://www.reddit.com/r/csharp/comments/3ayjdg/sites_like_nshipster_and_objcio_for_c/
Can't tell if you're joking or not… that's me
Or just [asp.net/mvc](http://www.asp.net/mvc) works too. The Pluralsight videos that Microsoft subsidizes(?) are extremely helpful.
When you create your Web Forms project, there is not yet a need for a Database, as there's literally nothing to store. Your MDF gets created with the AspNetUsers, AspNetRoles, AspNetUserRoles, etc. tables only when you have a user to store. This is done in your LocalDB instance. (Basically you get a mini-version of SQL Server running with your database on it on your local machine). So when you create a new user, with a new project, in your Register.aspx.cs you'll see something like: var manager = Context.GetOwinContext().GetUserManager&lt;ApplicationUserManager&gt;(); var user = new ApplicationUser() { UserName = txtEmail.Text, Email = txtEmail.Text }; IdentityResult result = manager.Create(user, txtPassword.Text); It's in this last step that you are instantiating a new user from the ApplicationUser class. Well, you can find the ApplicationUser class in Models/IdentityModels.cs. It is here that you can set custom User properties, like if you wanted to store First and Last Names, Fax Numbers, Street Address, etc. So, after you create a project and before you do any other coding, figure out what info you need to get from your users. Change the Account/Register.aspx form to reflect that (ie. add the Address fields, Country field, Fax Number field, etc.) Then in your IdentityModels.cs file, add properties like this: public String SiteId { get; set; } public String LaboratoryName { get; set; } public String Prefix { get; set; } public String FirstName { get; set; } public String MI { get; set; } public String LastName { get; set; } public String Position { get; set; } public String ShippingAddress1 { get; set; } public String ShippingAddress2 { get; set; } public String City { get; set; } public String State { get; set; } public String PostalCode { get; set; } public String Country { get; set; } public String FaxNumber { get; set; } [Added Custom User Properties](http://i.imgur.com/jPfKIT8.png) Then in your Register.aspx.cs file, change the code so that the it looks like this: var manager = Context.GetOwinContext().GetUserManager&lt;ApplicationUserManager&gt;(); var user = new ApplicationUser() { UserName = txtEmail.Text, Email = txtEmail.Text, PhoneNumber = txtPhone.Text, SiteId = txtSiteID.Text, LaboratoryName = txtLaboratoryName.Text.Substring(0, 1).ToUpper() + txtLaboratoryName.Text.Substring(1), Prefix = ddlPrefix.SelectedValue, FirstName = txtFirstName.Text.Substring(0, 1).ToUpper() + txtFirstName.Text.Substring(1), MI = txtMiddleInitial.Text.ToUpper(), LastName = txtLastName.Text.Substring(0, 1).ToUpper() + txtLastName.Text.Substring(1), Position = txtPosition.Text.Substring(0, 1).ToUpper() + txtPosition.Text.Substring(1), ShippingAddress1 = txtAddress1.Text.ToUpper(), ShippingAddress2 = txtAddress2.Text.ToUpper(), City = txtCity.Text.ToUpper(), State = ddlState.SelectedValue.ToUpper(), PostalCode = txtPostalCode.Text, Country = ddlCountry.SelectedValue.ToUpper(), FaxNumber = txtFax.Text, }; Now, run the project and create a user. You will see that the database has been created, and your AspNetUsers table now has the added properties. http://i.imgur.com/2xFxONG.png (Ignore the Methodology, OtherMethodology, and DateRegistered columns in this image). Now, you are asking if you can just use your own MDF. Does your MDF have a users table? The new projects are setup to store users in an AspNetUsers table. The MDF that is generated is just for development. When you pushed your project to a server with IIS on it (your webserver), you would either be moving that MDF to a SQL Server instance, or you would be creating a new database on an existing SQL Server instance and you would be changing the Connection String in your web.config to point to it. As far as using a different database, for your app, you can definitely do that. I use a few databases for a lot of my projects. You just add the connection string to it in your web.config and then use it in your SqlDataSources. Let me know if there's anything else I can answer or explain. Our shop still uses WebForms (not MVC yet), and so I was trained on using it. Most of the tutorials out there are for MVC, so if you have WebForms questions, please let me know. 
That's a surprising statement. I found that the changes are very significant. * The removal of global.asax * Tag helpers * Built in DI * .NET core vs .NET 4.6 * Integration of node.js tools * .net core commands * Removal of httphandler * json config * New set of library for configuration, etc
At this point start with asp.net mvc 6. Get comfortable with the middle ware concept of asp.net mvc6 and various external tools that come with it.
Have you never cross posted between related subs?
What's specific about those sites that you're looking for? Maybe a brief explanation would help you with an answer? 
Discussion of useful/obscure/misunderstood parts of the environment in an article-like format. New posts weekly or so. NSHipster is sort of a newsletter, they have a new article every Monday and they have a few books published. Objc.io is more of an online magazine broadly covering basic topics every developer should be familiar with. Everyone is suggesting stackoverflow tags, but that's not really what I'm looking for… I'm looking for article format, not QA/discussion format. It's great, but not what I have in mind :)
Well put. One edit: Using razor is most likely going to be replaced by a JS mv* framework. Not officially by MS but I assume most users would now opt for something like angular, ember or aurelia. I know I would, not that razor is bad.
Correct, I was more talking to the learning curve. Many of the things you mentioned are available now as additional components. For example, node.js had been installed as part of web essentials for at least a year. That exposes many features that are now part of asp.net 5 out of the box.
Check out the Morning Brew (http://blog.cwa.me.uk/) and Morning Dew (http://www.alvinashcraft.com/) websites. They simply aggregate content from other .NET sites from around the web, but should be a good start.
Huh... What an interesting idea. I was just thinking of doing a project with heavy Reactjs on the front end, ASP.Net MVC backend... Didn't occur to me to ditch Razor. Do you know anyone working on a framework to ditch razor for some JS thing? 
No, that's /u/TheOtherPantsThief
No additional framework needed. I've been doing it for years now. You need a minimal amount of razor, like 4 lines maybe. Basically I use the default setup and hijack the RenderBody() as my view for angularJS. After that it's all angular. Sometimes I want the view a bit higher and in that case I set it in the _layout.cshtml I would assume that these extra hoops won't be necessary in 5. I have yet to try though.
Nice... I suspect that's how my reactjs project would go....
Awesome work. Thanks.
The project looks awesome.
Good call! Working on that - https://github.com/eStream/Cart42/wiki/Roadmap
Take a look on that tutorial https://azure.microsoft.com/en-us/documentation/articles/web-sites-dotnet-get-started/, it's very easy to deploy your app to azure. 
Just implement FIDO's U2F.
&gt; use neither database first nor code first, but "meet in the middle" This is extremely nice. I still like designing databases for applications, so I'll use declarative API for my objects in code to design the database from code (I use EF migrations and customize the database that way). 
Another approach (if you need to actually interact and not just reflect the assembly) would be to first check if it contains any mixed components using a strategy like we see [here](http://stackoverflow.com/questions/1946322/how-do-i-find-out-if-a-net-assembly-contains-unmanaged-code). After that, you could load it reflection only looking to ensure it matches the signature you're interested in, then finally proceeding to load it formally. Great read though; That is one vulnerability I would have missed the first time around!
Work.
This happens in every profession. As soon as there is a system or technology to make some part of a job easier, it lowers the bar on who you can have do that job. You go from the tool helping people do their job, to people who expect the tool to do the job for them. As soon as you have one of these tools, your company is going to start hiring people who can relay on the tool because those people will be cheaper. The obvious bad side is people not understanding what is going on inside the tool and getting into complex messes they don't have the knowledge to understand of fix. The the good side is we all rely on having parts of the problem abstracted away so we can focus on learning a few things at a time and not get overwhelmed. For example, you could argue that garbage collected languages have caused a deterioration in developers memory managment skills. 
I agree. What's interesting is I always considered SQL and database modeling as something easier than general coding. But then, I'm not a big fan of ORMs. It seems to me they replaced the easiest code to write and maintain with a heavy library dependency.
A nice middle ground is filled with micro-ORMs; they strike a nice balance of letting you break into real SQL, utilize dynamics for building queries/retrieving results, and are very light-weight. I bounce between Dapper and Simple.Data, depending on project needs. They're actually a lot of fun to use (obviously in a geekish SQL/.NET way), especially for small/medium projects. I'm not sure how they'd play on larger apps or with big teams.
That goes for any language abstraction. Don't write CoffeeScript if you don't know basic Javascript. EF is a great tool, but devs still need to know the basics. Unfortunately, I have found far too many developers who could not explain simple joins. Now, the alternative issue is devs that write stored procs for everything. (shudder)
&gt;That goes for any language abstraction. Don't write CoffeeScript if you don't know basic Javascript. Same with TypeScript. I really like TypeScript a lot but all of the little bugaboos that can plague Javascript coders, like context and scoping, are still there. My boss has been considering using TypeScript on a new project being stood up, thinking it would be good for devs who are weak in Javascript. I told him directly that if they're weak in Javascript, that's going to leak through in their TypeScript.
Levelling-up and changing the kind of industry I work in.
This might not be a popular opinion, but I never use EF objects as part of my business code. I use EF as an abstraction layer for accessing SQL. I use the Repository pattern for those EF classes, and whenever my business objects need data, the repository does it's thing and coverts the data from EF objects to business objects (and vice versa). The business objects have no clue as to how the data is being stored. Yes, it's extra work to create that abstraction layer, but it means that I can normalize the tables and make breaking changes to the database design and when that happens i only have to update the repository layer. Some might question why bother using EF at all, then. It's because writing SQL commands using ADO.NET really really really sucks. It's super tedious and EF makes it very simple converting to POCOs. I just don't use those POCOs directly.
That's what I was thinking of when I read the title. A mixed assembly is a neat trick too.
this sounds like a culture problem, not a technology problem. how do unreadable, poorly-performing database schemes make it past peer review (whether orm-generated or otherwise)? sloth and indifference.
We're using Dapper on my current project. It definitely lets you mix the best of both worlds. You are definitely correct about SQL knowledge though. At one point in my career, I was probably spending more time writing queries than actually coding. Now, having used ORM's for several years, I've found that my SQL skills have declined significantly. I can still design a good DB, but a lot of my query writing knowledge has gone completely.
entity shamework is evil....its ok on small apps, but once you get onto large datasets and lots of tables, it needs to be ripped out and replaced with sprocs. Its makes a mockery of indexing and only pulling data you need. The load you get on the system is awful.....thankfully our databases (all but one) are purely sql driven
bingo...we have a dba that actually knows what he's doing and all the systems he oversees have to run properly....anything that does silly things gets booted off the system....that includes forms
I love ORMs and not because I suck at queries is because I'm sick and tired of writing the same CRUD code over and over again. And before ORMs most of the .Net discipline was "do stored procedures for all the crud/buisness logic" bullshit mishmash that I loathe to this day. When it wasn't simply just writing raw queries as strings or parametrized. If you're letting devs design your database with code first you need to make sure that your objects translate to a proper DB design or else get a real DBA to do it for you and let the ORM create your domain objects once the design is ready. ORM or not your shit at database devs would have still made a mess of things. Don't let them. 
I get into the argument on a weekly basis with one of my older devs, he tries to put everything in sprocs. He thinks everything should be in a sprocs. Then the junior guys will alter something in a preproduction env sproc that gets missed when merging production back to refresh. Ugg
Nuget won't automatically update your packages. When you install a package everyone is on the same version unless someone on your team updates it. Keeping up to date with library changes is just general maintenance and required with or without nuget.
Maybe the problem is your current organization? ORM is just a tool, but why would having that tool qualify a dev to design a database? Why doesn't your organization have a proper data architect, or at least a DBA that can review schema changes before they are implemented and etched in stone? Putting it all on the dev is fine for a small or maybe even medium scale shop. Beyond that and you're gonna pay the price sooner or later.
&gt;I love ORMs and not because I suck at queries is because I'm sick and tired of writing the same CRUD code over and over again. This is one of the few things I love about ORMs. God, how I loathed writing CRUD sprocs for *every single table* that backed up an entity.
Testing the mobile version of [miniDBA](http://www.minidba.com) after implementing a bit of Dapper in it. Fun :-) 
&gt;Sorry I came off wrong I don't hate all sprocs I didn't mean to accuse you of such, so sorry if I came off that way. &gt;I hate that way to much business logic for an app we inherited lives in them So do I. Having dealt with apps like that its a PITA, and it is definitely leaning too hard on the DB. They've use sprocs as a substitute for a DAL, and its causes more problems than it solves. I've been in places where sprocs were used too much and where they weren't used enough. Ultimately, I feel that there's a definite "sweet spot" for them, which the article highlights. They're not inherently evil, but evil people can do horrible things with them :)
No - I don't think anybody has ever requested that and I've personally never needed that. It can always be added though :-) Care to share a little about your use case?
Work - 2 x Umbraco sites + 2 x Xamarin Forms mobile app.
In your opinion, then, are you saying that calling InvalidateRequerySuggested() should generally be calling CanExecutes() that are designed well, so that even on a large form or program with many bindings, it would keep pace with the UI performing similar checks on IsEnabled, and therefore enable/disable content bound by NotifyPropertyChanged and RelayCommands at basically the same time?
RC car stabilization using Windows 10 IoT and a Raspberry Pi.
For added assurance, check the packages.config file. It explicitly lists the versions it pulls from NuGet.
i see... thank you
Is there a better place for validation than in the controller? If you have many complex validation rules, seems like you'd have a whole bunch of conditional blocks all over. Is there an attribute you can defined on the model itself pointing to a method to return a boolean or something for a pass/fail and a message? I come from a Ruby background. You might have something like this (taken from the Rails guide) while validates a record with a few specific custom methods. Rails also has built in property validations like string length, presence, numeric etc. class Invoice &lt; ActiveRecord::Base validate :expiration_date_cannot_be_in_the_past, :discount_cannot_be_greater_than_total_value def expiration_date_cannot_be_in_the_past if expiration_date.present? &amp;&amp; expiration_date &lt; Date.today errors.add(:expiration_date, "can't be in the past") end end def discount_cannot_be_greater_than_total_value if discount &gt; total_value errors.add(:discount, "can't be greater than total value") end end end What about at certain times? You can have specific validations run when a model is being updated, or only being created/added, for example. Does .NET MVC have these notions? I understand the concepts but trying to better understand and learn the common patterns applied to the framework. Thanks! 
Generally speaking, validation rules go in either the model or ViewModel. The controller usually just checks to see if there are any errors, and if there are any, we can do something different than we normally do. Sometimes, when we have more complex validation, we'll use packages like [FluentValidation](http://www.exceptionnotfound.net/use-fluentvalidation-for-better-validation-framework-in-mvc/) to handle them. That link is to a post I wrote about it. Check it out! Hope this helps.
Not all do, but there are some ORM frameworks which create GUID or other odd generated based relations that make figuring out the relations painful. Also, I have found performance issues with some ORM's because they generate the most insane queries .... and it can be very annoying to iron those issues out. Not all are terrible and they're improving!
Calling someone stupid for using a framework or libraries feature isn't very constructive. It's conceited, ad hominem and not educational to new programmers or novice coders who turn here for support and guidance not elitism. Perhaps you can provide some knowledgeable advice in a manner befitting a mature adult programmer? 
There are good micro ORM's such as Dapper and PetaPoco which are a good middle ground between EF and raw ADO.net.
There's a stack in SQL Server devoted to this - SQL Server Analysis Services is an OLAP server designed for reporting, and then there's SQL Server Integration Services, which is designed around building and running "packages" that copy the data from the transactional into the analytical database. Integration Services Packages are generally a collection of connections to/from databases and scripts or transforms that mash the data correctly, and are built to form a full workflow or process in a way that you can load onto the server and run on a schedule. 
Use an internal, private nuget repository. Point your visual studio against that. Create a mechanism that lets you easily mirror packages to the private repo from the public nuget.org repo when you need access to a package.
Have you looked into Dapper?
Java :( god I miss C#
*== I didn't find out the answer because I nuked the tab when, after clicking away the request for my email address, it did a full-page transition to some question that wasn't the post I was reading in the first place.
yeah that was very obnoxious, I usually put up with those pop ups asking for an email but this one was extra bad.
Often, simple rules will be used as [Attributes on a Property](http://www.exceptionnotfound.net/asp-net-mvc-demystified-unobtrusive-validation/). ``` public class MyViewModel { [Required] [StringLength(100)] public string Name {get; set;} } ``` More complex rules can be created using Fluent Validation or other validation packages. (I can't seem to get the formatting right on this, can anyone assist?)
DSQL - the original ORM. Also, a relatively new version of hell.
One additional counter-point. Abstraction lets your application work on multiple datasources; without it you're at a minimum going to need to have a slim abstraction over multiple versions of provider-specific queries. You can ignore this ff you get it in writing up-front that you'll only ever need to code against SQL 2014 (even when the year is 2025 and the DBA really want to kill that last crufty 2014 box).
I have no idea what you mean by "old branch". You've not given enough information here.
If the list to merge has more than 1 branch, I want to specify which is defaulted.
I don't know of one particular site like that, but I usually check these two pages every morning as they link to many other .NET related blogs and articles: The Morning Brew by Chris Alcock http://themorningbrew.net/ The Morning Dew by Alvin Ashcraft http://www.alvinashcraft.com/
That is an option, assuming one includes the "RaiseCanExecuteChanged()" function in their RelayCommand/DelegateCommand implementation--which ultimately just calls InvalidateRequerySuggested() anyway.
That makes sense. All of my CanExecute methods are concise and fast, so now I'm trying to decide how I want to implement raising InvalidateRequerySuggested(), as that appears to be the only way to actually cause their CanExecute() functions to be re-evaluated. The two methods I'm considering are simply adding a "RaiseCanExecuteChanged()" method to the RelayCommand implementation, which simply calls InvalidateRequerySuggested when fired. The other option is adding a DispatcherTimer to App.xaml.cs to begin upon startup, which would call InvalidateRequerySuggested() every .25 seconds automatically. Either way, InvalidateRequerySuggested is being called; but the latter will cause it to happen automatically, whereas the former would require manual intervention (e.g. calling the RaiseCanExecuteChanged event explicitly.) Are you aware of both options? Do you have an opinion? Seems like the DispatcherTimer might cause InvalidateRequerySuggested() to run a lot more often than it needs to, but a similar timer is running in the background to handle INotifyPropertyChanged. I'm not sure what's better.
Well, by default, the ICommand interface doesn't include OnCanExecuteChanged() -- that's something that can be optionally added to a RelayCommand or DelegateCommand, depending on implementation. This is the classical implementation of RelayCommand, isn't it?: https://msdn.microsoft.com/en-us/magazine/dd419663.aspx#id0090030 They don't have any "RaiseCanExecuteChanged()" method. It does tie the RelayCommand to the CommandManager, though, in the CanExecuteChanged EventHandler, so that this ICommand gets updated when InvalidateRequerySuggested() is called. So... "RaiseCanExecuteChanged()" is an extra, optional method one can add to ask the Dispatcher to ask all listening ICommands to update? EDIT: I collected my thoughts and posted a much longer explanation and question(s) on Stackoverflow. Rather that reposting here, here's a link. Thoughts? [Stackoverflow](http://stackoverflow.com/questions/31078633/wpf-icommand-canexecute-raisecanexecutechanged-or-automatic-handling-via-di)
Sorry to hear that - this is something we're actively working on. Over the past few months, we've completed integration with Azure HDInsight and Search. More to come soon. I can't say anything yet... but, you should ping me (andrl {at} microsoft) if you are interested in PowerBI ;)
Awesome, sent an e-mail your way :)
What source control system are you using?
I see now why you're confused about that. I'm honestly not sure why CanExecuteChanged is implemented like that, but it's not right. When you hook up a ICommandSource (In this case, the button), the source should (ButtonBase does this) listen to the CanExecuteChanged. Because of this, all you have to do is raise the event which will then cause the command source to call CanExecute. Here's a better implementation (IMO): public class DelegateCommand : ICommand { private readonly Action _command; private readonly Func&lt;bool&gt; _canExecute; public DelegateCommand(Action command, Func&lt;bool&gt; canExecute) { _command = command; _canExecute = canExecute; } public bool CanExecute(object parameter) { return _canExecute(); } public void Execute(object parameter) { _command(); } public event EventHandler CanExecuteChanged; public void RaiseCanExecuteChanged() { var evt = CanExecuteChanged; if (evt != null) { evt(this, new EventArgs()); } } } Now when anything changes that would cause CanExecute to change you would just call RaiseCanExecuteChanged which would only affect command sources that are bound to this command
a REPL
[googled a bit](https://raw.githubusercontent.com/metadaddy-sfdc/Visualforce-Multiselect-Picklist/master/screenshot.png)
Thanks for continuing to investigate. I'm trying to follow your process--but CanExecuteChanged is an EventHandler, and so this line doesn't make sense: &gt; var evt = CanExecuteChanged; You can't do this? You can only attach or detach to the EventHandler?
If you don't manually override the add/remove on the event like it does in the RelayCommand example, you can (VB .net you can't assign it to a variable period, but VB sucks). It's just a delegate which can be assigned to variables since delegates are first class functions
I get this: Network Error (dns_unresolved_hostname) Your requested host "www.exceptionnotfound.net " could not be resolved by DNS.
Thanks so much everyone for your replies. So in my app, I provide the token. To do this I used app.UseOAuthAuthorizationServer( new OAuthAuthorizationServerOptions { TokenEndpointPath = new PathString("/Token"), provider, AccessTokenExpireTimeSpan = TimeSpan.FromDays(14), AllowInsecureHttp = true }); For the provider OnAuthorizeRequest method, the example I saw used this (after making sure the username and password match the database): Claim claim1 = new Claim(ClaimTypes.Name, c.UserName); Claim[] claims = new Claim[] { claim1 }; ClaimsIdentity claimsIdentity = new ClaimsIdentity( claims, OAuthDefaults.AuthenticationType); c.Validated(claimsIdentity); Could you please explain this code? There are other ClaimTypes, but what do they do, what is the difference? Do I have to make my own claim type to match my Users model? 
Why write any details to the identity object? I could write one claim, the user's ID, and then look up info like their name in the code that needs it. Or am I totally misunderstanding? 
I just copy them over into my internal NuGet share. if the public NuGet server goes down, it will automatically use them from my source.
Sounds like you really want to put permissions in place!
With Spring Security you can define an XML file or use Java to specify what users or user groups have access to certain URLs or controller actions. For example something like this: &lt;security:http use-expressions="true"&gt; &lt;!-- Anyone can access these urls --&gt; &lt;security:intercept-url pattern="/auth/**" access="permitAll"/&gt; &lt;security:intercept-url pattern="/login" access="permitAll"/&gt; &lt;security:intercept-url pattern="/signin/**" access="permitAll"/&gt; &lt;security:intercept-url pattern="/signup/**" access="permitAll"/&gt; &lt;security:intercept-url pattern="/user/register/**" access="permitAll"/&gt; &lt;!-- The rest of our application is protected. --&gt; &lt;security:intercept-url pattern="/**" access="hasRole('ROLE_USER')"/&gt; &lt;/security:http&gt; You can avoid using XML and use Java as well: @Configuration @EnableWebSecurity public class SecurityConfig extends WebSecurityConfigurerAdapter { @Override protected void configure(HttpSecurity http) throws Exception { http.authorizeRequests() .antMatchers("/admin/**").access("hasRole('ROLE_ADMIN')") .antMatchers("/dba/**").access("hasRole('ROLE_ADMIN') or hasRole('ROLE_DBA')"); } } Basically I am looking for a popular framework that one can use instead of implementing something in-house.
The project templates for office don't come with VS. The office dev tools need to be installed and they may not have been updated to work with VS 2015 yet. That said you'll probably need 2013 community or pro.
I'm trying to utilize the ICommand by binding it to a Button that checks for updates. When clicked, I want the button to become disabled while the check runs in the background. My app does use threading to maintain a responsive UI, but it's designed to only do one task a time--so while checking for updates, I will post status messages, move the progress bar, etc., but will not allow the app to do other things concurrently. When clicking, because it's a UI interaction, the button would become disabled because the Dispatcher is designed to run when there is keyboard or mouse input. However, when the background task completes, I want the UI to be restored--including the ability to see what buttons are once again available. Obviously, once the task is done, the ICommand is available (CanExecute() returns true) even if the button _appears_ to be unavailable, but users won't know that, and the UI isn't updating at the rate which I'd like. Thus, the background task completes and updates the CanExecute() logic accordingly, but because there is no user input along with it, the ICommand binding isn't refreshed and this button (and other buttons and ICommand-bound controls) don't refresh. My CanExecute() is really very simple; it's bound to a Controller with a boolean IsBusy Property: CanExecute() { return !Controller.IsBusy; } Binding the button to "IsEnabled" does seem like a good way to solve the problem. I'm investigating a solution that ties manually invoking the Dispatcher as well as _all_ Properties (via NotifyPropertyChanged(null)) on a DispatcherTimer. I'm wondering if I can't make a solution that will automatically refresh ICommands and INotifyPropertyChanged Properties without requiring any extra code (for ICommands, meaning using IsEnabled or calling the Dispatcher manually), and get rid of the "NotifyPropertyChanged(string propertyName)" boilerplate.
Yes, yes, yes, yes! You are right on so many levels! I do the tech part of the interview to hire developers. We work with a full Microsoft stack and often we sit with SQL management studio to check for data or validate behaviors. So I think it's normal that I ask for some queries during the interview. If I had to judge by the reaction, I am the most evil being on Earth because I ask them to write SQL, on paper! I understand kids who just left their vocational school, but even juniors and mid devs... Once I cut the interview after few minutes because a so-called senior didn't feel comfortable in writing SQL since he works with entity framework because "who does SQL nowadays?". I pulled out a paper where I had an EF context that would map to the earlier schema. When he struggled to write a simple linq query, I cut the interview. Later the HR would tell me that I had been to harsh... 
This is the approach that I have been advocating since fluent API was out in 4.1... Glad to hear that im not alone!
You should use the [identity framework](http://www.codeproject.com/Articles/762428/ASP-NET-MVC-and-Identity-Understanding-the-Basics) for this. Then you just annotate your controllers with [Authorize] for protection, [Authorize(Roles="Admin, Super User")] for example to secure by role You can also use xml in web.config to secure it, like this: &lt;location path="Home/AdministratorsOnly"&gt; &lt;system.web&gt; &lt;authorization&gt; &lt;allow roles="Admin"/&gt; &lt;deny users="*"/&gt; &lt;/authorization&gt; &lt;/system.web&gt; &lt;/location&gt;
Ok, I see the problem. I assume `Controller` is a property on the view model? You need a way to be notified when `Controller.IsBusy` changes. If whatever class `Controller` is implements `INotifyPropertyChanged` then you can hook a handler on your VM to that `PropertyChanged` event whenever you set the `Controller` property. In you're event handler you'd raise the `PropertyChanged` event on your VM with either a null property name argument or something like `Controller.IsBusy`. Any visual element with your VM as the data context will see that event being raised and if that control is a button that's bound to an `ICommand`, it will recheck the `CanExecute`. If it doesn't do `INotifyPropertyChanged`, you'll have to figure out some way of getting notified when `IsBusy` changes. Maybe you add an `IsBusyChanged` event and hook to that. I have a `ViewModelBase` class with a bunch of stuff on it for handling `INotifyPropertyChanged` and other general view model concerns. One of the thing's it does, when setting any property to a instance of a class that supports `INotifyPropertyChanged`, I hook to the `PropertyChanged` and bubble up the notification just like I described above. This solves a lot of problems like the one you're seeing.
No support for the latest released Visual Studio? A pity.
"It does refactoring" is pretty vague. Specifically, what refactoring does it do?
You can write your own filter to accomplish this. I wrote a filter a few years ago that accomplished something similar to what you're looking for. 
Yep. It does rely on Roslyn. 
See: http://vsrefactoringessentials.com/Features/All
But TypeScript will at least warn you about a lot of things that javascript wouldn't.
This is highly depending on the local market. Outsourcing in Germany is pretty much non-existent.
Seven years ago, the CEO of my company had a brilliant cost-cutting idea. He fired 75% of our full-time engineers and replaced them with oversees contractors. Since coding is a commodity, he thought, let's ship out all engineering work to the lowest bidder. So we shifted all implementation work to India, and the quality of our product has suffered greatly. Our UI is unusable. Our codebase is full of bugs and totally untestable. Nothing is standards-compliant. There simply aren't enough full-time employees to police the contractors into doing high quality work. We've dropped from #1 in the domestic market to #3. Our sales base is dropping as customers flee to competitors. To combat this, we hire more and more offshore contractors to get new work done faster, but they end up contributing work that drags the product down even further. My company is now at the point where we have twice as many offshore contractors now as we did full-time employees before the big round of layoffs. The end result? Labor costs have increased substantially, the product quality has suffered, and we've been in the red for seven straight years. It seems to be the same story everywhere. Have you ever heard of a company moving to the offshore model and then seeing huge new successes in their business? Maybe it's my personal bias, but I only hear of failures. It's a rough world out there.
In our company it's even the other way around: we are hiring an external for a few month or year whenever we start using new technologies. That way we don't have to out-source something we can't do ourselves and we keep and expand the knowledge within the company. Nice way of learning by doing.
My conclusion on outsourcing software development to India is, "It's a bad idea." The main reason, currently, coding is considered a low man on the totem pole job. Your objective is to code for a short while then head into management. Coding is not seen as a career. This is just a cultural thing. Granted, this may change in the coming years. 
A few things to try. First, make sure your ITPSWebService.asmx service page will load by viewing it directly. Second, what does the console output of your browser show for the request and response? This will show if you're sending the correct json object to the service and if the service response is wrapped in the 'd' element.
The problem with out sourcing is that these companies do not intend to have long working relationships with you company. There's no reason too. It's unlikely for them to get repeat business as most of their clients have one off jobs. Therefore there model should be to get as many clients as once as they can. This leads to most of them forfeiting quality so that their devs can move on to the next paying job. There's very little to motivate them to care about your company. 
The biggest advantage of in house developers is that they have a better opportunity of understanding the business that that they are developing the software for. This knowledge makes up for shortcomings in quality documentation and management. When work is off shored it's not very likely that documentation and management improves to the point that it overcomes the loss of this institutional knowledge. This doesn't directly answer your question but I enjoyed saying it.
I'd second this. Your current json string would read '{transactId:"value"}', but both the keys and values need to be quoted (i.e. '{"transactId":"value"}').
Xwt does have a WebView [1]. Each Xwt backend is using a different native control though, so you may need to deal with IE/WebKit differences. On WPF it uses System.Windows.Controls.WebBrowser, on Mac it uses WebKit.WebView, and (unfortunately) on GTK it uses either System.Windows.Forms.WebBrowser or WebKit.WebView depending upon whether GTK is running on Mac or Windows (and I think it has no implementation for the case where GTK is running on Linux). 1. https://github.com/mono/xwt/blob/master/Xwt/Xwt/WebView.cs Right now Xwt really only targets desktop platforms: Windows, Linux, and Mac.
I don't understand this "policy evaluation." As I understand it, you just validate the user in the OnAuthorizeRequest method. Then you can check any details about the current user with `((ClaimsIdentity)User.Identity).claims`. What am I missing?
I have used this on 3 projects, 2 are in production its a good starting point. I had a few issues with references not coming in correctly but I was able to resolve those quickly. I will say that I like having most of the css, scripts, and folder structure setup for me. I have some idea's on how I would like to add to it so it's tailored for N-Tier projects with some generic datastore entities in it; maybe even a t4 template that could say generate the services from the entities also... Thanks again for all the hard work.
It's not just the user. You can check is authorized: user.identities.any(i=&gt;i.IsAuthenticated) Additionally checking claims: user.identites(i=&gt;i.Claims.Any(c=&gt;c.Type==ClaimTypes.Role &amp;&amp; c.Value == Administrators)) Finally, If you want to create a global IAuthorizationFilter, you will also need to check the HttpActionContext parameter https://msdn.microsoft.com/en-us/library/system.web.http.filters.iauthorizationfilter.executeauthorizationfilterasync(v=vs.118).aspx#M:System.Web.Http.Filters.IAuthorizationFilter.ExecuteAuthorizationFilterAsync(System.Web.Http.Controllers.HttpActionContext,System.Threading.CancellationToken,System.Func{System.Threading.Tasks.Task{System.Net.Http.HttpResponseMessage}}) to see what controller and action is being executed. The combination of checking the subject (current user) and the resource (HttpActionContext.ActionDescriptor and HttpActionContext.ControllerContext) is executing a policy. Policies are a logical construct in the framework, not a physical one. The definition of attribute based access control gives a good idea of the inputs to a policy https://en.m.wikipedia.org/wiki/Attribute-based_access_control. An example policy could be: Only Administrators can view Administrator Controller Actions. To execute this policy, you could put a role list on the controller's action using the AuthorizeAttribute. That couples role to Controller definition and spreads policies throughout your app. A global authorization filter could instead centralize policies into a single location and search that location for applicable policies when a controller is executed. This also allows you to unit test your policies. Policy search and storage is usually a exercise left to the user but a simple secondary key index could be used to search quickly and policies could be defined as simple expressions with subject and resource as string array inputs.
This submission has been randomly featured in /r/serendipity, a bot-driven subreddit discovery engine. More here: http://www.reddit.com/r/Serendipity/comments/3blddj/is_programming_really_affected_by_outsourcing/
Is it different or has the pattern simply evolved? GoF was released 20 years ago now.
GET HYPED
I had an example of [styling a checkbox as an ellipse](http://eblog.cloudplush.com/2012/05/23/styling-a-checkbox-as-an-ellipse/) up on my blog. Could be a starting point. Otherwise, I had a piece of xaml making a data-template "power bar" that was a simple vertical version of the one you need. It works with two calculated CurrentPowerPointLeft and CurrentPowerPointRight binding properties. Hope this helps you. There's a couple of triggers at the bottom of the template, too. &lt;DataTemplate x:Key="PowerBar"&gt; &lt;Canvas Width="20" Name="canv2"&gt; &lt;Rectangle Stroke="Black" Fill="White" Width="20" Height="100" VerticalAlignment="Bottom"/&gt; &lt;Path Fill="Fuchsia" Stretch="Fill" Canvas.Bottom="0" Height="98" Width="18" Name="Bar" Margin="1"&gt; &lt;Path.Data&gt; &lt;CombinedGeometry GeometryCombineMode="Intersect"&gt; &lt;CombinedGeometry.Geometry1&gt; &lt;PathGeometry&gt; &lt;PathGeometry.Figures&gt; &lt;PathFigureCollection&gt; &lt;PathFigure StartPoint="0,0"&gt; &lt;PathFigure.Segments&gt; &lt;PathSegmentCollection&gt; &lt;LineSegment Point="0.01,0"&gt;&lt;/LineSegment&gt; &lt;LineSegment Point="{Binding CurrentPowerPointLeft}"&gt;&lt;/LineSegment&gt; &lt;LineSegment Point="{Binding CurrentPowerPointRight}"&gt;&lt;/LineSegment&gt; &lt;LineSegment Point="24.99,0"&gt;&lt;/LineSegment&gt; &lt;LineSegment Point="25,0"&gt;&lt;/LineSegment&gt; &lt;LineSegment Point="25,25"&gt;&lt;/LineSegment&gt; &lt;LineSegment Point="0,25"&gt;&lt;/LineSegment&gt; &lt;LineSegment Point="0,0"&gt;&lt;/LineSegment&gt; &lt;/PathSegmentCollection&gt; &lt;/PathFigure.Segments&gt; &lt;/PathFigure&gt; &lt;/PathFigureCollection&gt; &lt;/PathGeometry.Figures&gt; &lt;/PathGeometry&gt; &lt;/CombinedGeometry.Geometry1&gt; &lt;CombinedGeometry.Geometry2&gt; &lt;RectangleGeometry Rect="0, 0, 5, 25"/&gt; &lt;/CombinedGeometry.Geometry2&gt; &lt;/CombinedGeometry&gt; &lt;/Path.Data&gt; &lt;/Path&gt; &lt;/Canvas&gt; &lt;DataTemplate.Triggers&gt; &lt;DataTrigger Binding="{Binding Path=OpUnitType}"&gt; &lt;DataTrigger.Value&gt;Generator&lt;/DataTrigger.Value&gt; &lt;Setter TargetName="Bar" Property="Fill" Value="DarkOrange"/&gt; &lt;/DataTrigger&gt; &lt;DataTrigger Binding="{Binding Path=OpUnitType}"&gt; &lt;DataTrigger.Value&gt;Pump&lt;/DataTrigger.Value&gt; &lt;Setter TargetName="Bar" Property="Fill" Value="DarkOrange"/&gt; &lt;/DataTrigger&gt; &lt;/DataTemplate.Triggers&gt; &lt;/DataTemplate&gt;
Woo hoo...oh wait, since we just got upgraded to 2013 last month it will probably be 2 years before I get it at work :( 
PROTIP: You don't ever STORE or even ENCRYPT passwords. You store a HASH (with salt) of the password, then hash (with the same salt) whatever they give you when they try to log in. If the hashes match, let them in. If you lose your database, you didn't actually lose any passwords.
2013 is pretty damn good. Plus, ASP.NET 5 isn't even out yet. NuGet isn't either. Entity Framework 7 is still being worked on. I typically wait for Update 1 anyways.
oh, Leap days!
It would be a action filter that you add to the GlobalConfiguration.Configuration.Filters http://www.asp.net/web-api/overview/advanced/configuring-aspnet-web-api There are three options for adding Filters 1. Override OnXXX methods in the controller 2. Add attribute to Controller or action 3. Add to global Configuration You would add it globally to avoid adding the filter to the first two and centralize policy enforcement. The IAuthorizationFilter is a interface that abstracts authorization for web api Controller Actions.
It really depends how specialized your company is
I've been using the RC for a while, no complaints, it's awesome. 
"ALWAYS make sure structs are immutable" There's no reason for this. C# developers should know how to work with structs properly and mutable structs can often be used for significant performance gains.
I was under the impression that Aspnet5 will be released together with VS2015?
All signs say that isn't the case.
If you're working with a large struct, there's no reason to have to create a new copy every time you change a field. To make matters worse, many C# developers would probably define read-only properties in an attempt to make the struct immutable. The performance cost of a property getter, which is a method call, is significantly higher than a field access on a struct. It's also ugly. This: Vector4 point = points[0]; point.X = 10; points[0] = point; Looks far better than this: Vector4 point = points[0]; point = new Vector4(10, point.Y, point.Z, point.W); points[0] = point; I'm not saying immutable structs are bad. I'm just saying you should think critically about what you're trying to accomplish instead of relying on dogma.
I think you may need to do some serverside protections and get asp.net to process your static files to get this to work. http://stackoverflow.com/questions/2903292/how-do-i-protect-static-files-with-asp-net-form-auhentication-on-iis-7-5 If you have protection on, you can then just use standard forms auth with the default membership provider.
pretty sure if you're just returning a value in a getter the compiler will take care of changing it to a straight field for you http://stackoverflow.com/questions/3167133/is-there-a-performance-difference-between-properties-vs-backing-fields-in-read
It is most likely just the normal pivot header with a custom style. Icons instead of text, and a green background when it selected. &lt;Pivot&gt; &lt;PivotItem x:Name="item1"&gt; &lt;PivotItem.Header&gt; &lt;SymbolIcon Symbol="Clock" /&gt; &lt;/PivotItem.Header&gt; &lt;/PivotItem&gt; &lt;PivotItem x:Name="item2"&gt; &lt;PivotItem.Header&gt; &lt;BitmapIcon UriSource="/images/mybitmap.png" /&gt; &lt;/PivotItem.Header&gt; &lt;/PivotItem&gt; &lt;/Pivot&gt; That's a couple ways to achieve that effect. In addition, you need to style the PivotItem to have the correct background color when selected. The simplest way is to override the system background brush as instructed [here](https://social.msdn.microsoft.com/Forums/windowsapps/en-US/11ad0a8d-46fe-4f1a-8ba0-3d9e816777c5/how-to-change-the-color-of-pivotitem-header?forum=wpdevelop)
Why are you looking at articles for web api? You should be using mvc. Just start a new web project in visual studio and it will ask what kind of auth you want. Pick one and start diving into the code.
The main problem with using mutable structs isn't lack of knowledge as to how they work, it is because you can't tell if a type is a struct or class unless you look at the the definition of that type. Sure, in a 10 line example it is clear what is going on, but if you are working on a 100k+ LOC project, it would be an easy error to make to assume a type is a class rather than a mutable struct, and introducing a bug in the process. c++ is better in this regards, in that whether a variable is a value type or reference type is defined when the variable is declared, not when the type is defined.
What's the point of this? This isn't migration. Why would you "migrate" to MVC if you are not following the pattern?
Pretty sure I'm on the right path! I'll share more in a later post. Any insight is still appreciated.
They're not different colors in 2012/2013 light or dark theme.
It's a re-styled "tab style" Pivot. Take a look at the sample here: https://github.com/Microsoft/Windows-universal-samples/tree/master/xaml_pivot
No problem, check out Microsoft virtual academy and pluralsight for some great tutorials as well
While your code only returns what you pulled out of the dom i.e. the value of a form element and in this case you have got away with it, considering your response I think further explanation is necessary. Any request using the $.ajax method (jQuery) that doesn't have sync set to true specified as a parameter (never do this because you can lock up the browser and this provides a bad user experience), is asynchronous. Asynchronous in this sense means that the while callback is registered, the js interpreter will continue executing after the ajax statement whether or not the server has responded to your ajax request. You essentially have a race condition. The callback function specified by "success: " is only run once the "success event" has been fired. Consider the following. http://pastebin.com/H9rG9UiN If the server responds very quickly to the request, then "myAjaxResult" will have a value. If it takes a while (more than milliseconds) the js interpreter will have left your function before the success event has fired and will return undefined in that scenario. The proper way to deal with this is similar to the follow (the syntax isn't exact as this has come from memory). http://pastebin.com/x64ft0sm Your variable is only assigned after the callback has been fired, so it can never return an unexpected result. The thing to take away from this is that in any asynchronous operation that you may not have the response immediately, however you can specify a function to be run when response arrives. Slightly aside, jQuery's ajax method now using .done() and .error() promise style syntax instead of success and error callbacks. I would suggest reading this thoroughly http://api.jquery.com/jquery.ajax/
So back to C++ when we were just getting use to C# for mobile development.
Sounds about right from my experience.
Office team has a massive c++ code base to deal with. Not sure what they would choose with a clean slate.
thanks for the heads up!
&gt;Most .NET developers are working for large bureaucracies, so they either tend to migrate towards a technical leadership position or a management position. That's less about the technology and the developers and more about large organizations. Troll much? ;) You kinda are right. But this is changing. I'm 50 and getting back into coding again after many years of being in product marketing. All startups. Some my companies, others not. I chose .NET because its frickin cool. I think there has been a huge mind shift going on with the .net teams for years and now we're seeing the beginning of a lot of great tech coming from them. I go lots of events in SFBay area and .net is getting a lot of attention with startups as well. 
Company im working for (which isnt even a software house) had a 65yr old .Net dev retire a few months ago.
42 here, and didn't even start writing code until I was about 30. I was a Sr. Dev at my last job, and left to run my own company in 2009 (mostly contracting in the beginning, but now finding areas to expand into, and new products to build). I don't foresee a day when I stop writing code (I really love doing this). 
Wow. Thanks. I will read all of that. Thanks again. EDIT: I just read all of your explanation just now. I'm very grateful for your explanation. I won't claim to understand it fully but I got the gist of it seeing your samples and I think this will help me up. I will read the last link you gave to better understand it. Thank you!!
To put on your resume "I've done mvc" lol
You make some good points, but I believe you aren't giving Xamarin Forms a fair shake. While it is most definitely still a v1 product, it has the potential to largely eliminate the need to learn three native UI frameworks. As it is, we have shipped a couple of non-trivial commercial products based on Xamarin Forms, with 96/93% shared code, respectively.
How about swift being open source now? I've heard Google is already starting to get it working with android. 
Just like someone in other profession that changes, they will be good as long as they keep learning. I work with a number of 40+ people and it's very hit and miss. One asked me today what the question mark after the type of a variable declaration meant. Another just finished building a pretty slick subsystem for us to use. This all no different than the person out of college that just passed the classes, but barely know how to use the tools and the one who did their own projects and comes in just needing to learn the company's system.
Source? I hope this isn't true. My hope would be for them to replace java with c# especially since they lost against Oracle.
One big reason to use Xamarin was not really addressed by this review: Reuse of prexisting Code. My Company for example has heaps and heaps of business code and we use Xamarin to reuse much of that in our mobile apps. Since we deploy to Android/iOS and Windows there is simply no other option than Xamarin. After a while you get to know the small bugs here and there and the way around them. Nowadays it is very rare that Xamarins tooling gets in the way of my daily productivity. The overall quality of Xamarin just gets better and better. Would always use it again. 
The new DNX runtime for ASP.NET 5 (and the associated ASP.NET MVC 6) use a new project format based on JSON. It's still in beta though, don't use that for a real project with a deadline. Regarding deleted files still in the csproj, VS' Solution Explorer displays a warning sign over the file. Visual Studio is very much made to be *the* dev tool for the entire project, so it might be a bit painful to try and write half of it in VS and half of it in something else. Since you're writing in .NET which seems outside your comfort zone anyway, maybe you could try doing the front-end work in VS too? I've read [Web Essentials](http://vswebessentials.com/) is a nice extension to have for web dev.
Get an SSD? I just moved from a quad-code Xeon + HDD to a low-voltage i5 + SSD, and I barely have any slowdown anymore when using Visual Studio, even with a couple of extensions loaded.
An SSD and plenty of RAM makes a big difference.
My system already has an SSD and a Core i7 CPU plus 16 gigs of RAM. Not a high-end PCIe SSD though. So I guess my only options are getting a new generation i7 or Xeon, PCIe SSD, and 32 gigs of DDR4 RAM.
The JSON based format, does it still require the Include directives for each and every file? Or is it more similar to make, Ant, Maven, etc?
I'm pretty sure there is a setting in your .csproj that you can add an entire directory and its children, so as long as everything is in the same directory it should be kept synced 
Who told you that you needed include directives for each and every file? If you want to include a whole directory, just use wildcards.
In addition to what others have said about RAM and an SSD (although it sounds like your machine is plenty fast), what third party plugins do you have loaded? 
There's also ROBOVM which allows Java to run on iOS and you can use it with RoboScala so you can use Scala instead. Another one to mention is RubyMotion - I tried this out when Android support was in Beta but it was still a work in progress so I got a Xamarin license. I think it's a lot better now though.
Yep, hard to see Google going down .NET road. They developed Go which runs on the JVM, heavily use Python and have invested a lot in Dart. I'm not sure why you hate the JVM btw, I'm not a Java fan but the JVM is a very stable and fast VM that has a far more impressive ecosystem than the CLR.
That should be possible I'm on my phone so can't have a good Google however http://stackoverflow.com/questions/2551107/is-there-a-way-to-automatically-include-content-files-into-asp-net-project-file 
Also see [this](http://stackoverflow.com/questions/2551107/is-there-a-way-to-automatically-include-content-files-into-asp-net-project-file), [this](http://stackoverflow.com/questions/2551107/is-there-a-way-to-automatically-include-content-files-into-asp-net-project-file#comment44266321_9438419), and [this](http://stackoverflow.com/a/2587401/309683).
If you look at the comments, looks like that's not reliable. See [this](http://stackoverflow.com/questions/2551107/is-there-a-way-to-automatically-include-content-files-into-asp-net-project-file), [this](http://stackoverflow.com/questions/2551107/is-there-a-way-to-automatically-include-content-files-into-asp-net-project-file#comment44266321_9438419), and [this](http://stackoverflow.com/a/2587401/309683).
Only Web Essentials. Tomorrow I am gonna install ReSharper. But I've heard that will make it even slower.
Not yet, but am planning to.
Use Visual Studio 2015 RC or above. It is much faster than 2013 in almost every aspect.
With ASP.NET 5 and VS2015 there are no .csproj file, and VS just reads the json file, so you can change it outside of VS without it complaining. Should be what you're looking for.
UI operations mainly. Opening a file, editing files, auto complete, searching for files, etc. Also sometime the UI freezes for a few seconds or even more. Not related to responsiveness, but another issue I've found is that sometimes when I open a solution, it marks classes, etc. as not resolvable. Sometimes I have to Clean and Build to fix the problem. Sometimes I have to quit VS and open it again.
I wouldn't say hate - but I dislike it because it lacks a fundamental features that makes it nearly useless for a lot of my use cases - value types and unsigned arithmetic (and how those interact with generics). Unlike Java .NET does the right things here and that's why I'm frustrated with JVM - if only MS went this open source route 5 or 10 years ago I would be in such a happy place right now :[
Not as a direct replacement, but it would be transpiled to java, in the case of android.
There is no way this is allowed to run on ios without a jailbreak. Apple absolutely hates vms on their devices.
&gt; IE6 will be more responsive if you chuck enough hardware at it No it won't. MS shipped a patch in April or May that seriously nerfed IE performance with large listboxes and other large amounts of HTML that had to be parsed/rendered. Affected IE8 through 11. It had *nothing* to do with your hardware, everyone got slammed by it. They shipped a fix for it in June. Hardware can't overcome crappy app design.
If it seems to happen on a regular basis (every 5 minutes or so) you may want to check the Autosave option. In VS2013 this drove me nuts; increased the Autosave time to 10 minutes and seems to be better. Though I'll second the suggestion to install VS2015; it is much much faster IMO. 
_You don't know what slow is._ ;) But it's still worth it.
I have had web essentials make VS completely unusable at times. Things like type a few characters *spinning circle* over and over. It's been a while but if I remember right it was related to project structure and background syntax verification. VS should be fairly snappy in a medium sized project even on a fairly run of the mill machine (or in a VM). Try disabling web essentials and see what happens.
Except intellisense..
Web Essentials for me has an issue that causes it to freeze Visual Studio when typing built-in Angular directives. You might try disabling that extension to see if it speeds up any.
Have you tried a new solution to see if it's an issue with the one you're working on? With your setup that's not the normal speed of VS
It's true - it's on the Swift website.
Are you in a corporate environment? If so, keep in mind that VS access lots of files that are stored in your profile by default, especially for intellisense and code templates. So if you profile is sitting on a NAS, then it will be slow. I would suggest downloading [ProcMon ](https://technet.microsoft.com/en-us/library/bb896645.aspx) and use it to monitor what files VS is touching. I did this and I was able to move all the intellisense and other cache files out of my profile and onto my SSD, its a pain but you should see an improvement. Another thing to investigate is your virus scanner. As above, VS access lots of files, so if your scanner is intercepting all those calls to scan the file before VS then you will see drops in performance. I setup a special development directory for all the VS files and my projects then configured my scanner to not intercept calls to files there, but rather to do a direct file scan there every 12 hours. From your descriptions, I'm suspicious that it is either your profile or virus scanner causing issues.
Dude, you should see the feature set in 9. I'm not going to give it all away but just two words: Hover boards...
Visual Studio + Resharper is why have Parallels on my laptop.
This was definitely on my "to read" list and I think it's a great solution. This is basically going to sit as a web gateway for authentication in front of the application right? 
What version of visual studios are you using? Slow UI response times are usually caused by either to many extensions or super very large solutions. Solutions with over 50 projects and tens of thousands of files will certainly cause degradation. I would recommend starting with your extensions. Turn them all off and uninstall them. Then one by one re-install them throughout the week until you find a slowdown again. If your solution is large enough to cause UI speed degradation maybe its time to split the solution up into smaller solutions. I will agree with someone else below that if you compile and sometimes the IDE still doesn't catch up to your object maps then it could be a broken project. You can turn on super build log mode and check through the build output for errors. Be warned that this log mode increases build time exponentially so only turn it on when you'r trying to debug your build.
You make a good point. Having a large, existing code base of C# business logic, on the client side, and not UX based, is probably one of the best use cases for Xamarin. I don’t doubt it was the best choice for your needs. However in my experience, most projects are not like that. More commonly I see companies with minor libraries on the client and most of the logic accessed via SOAP or REST services. 
I'm with you. I run 12 GB ram, i5 2.6 GHZ, and INTEL SSD on Lenovo laptop. I rarely get performance issues and when I do its because of extensions or solution sizes. Could I use some more ram and better CPU? Sure as shit I would take one. Are there cases where better hardware would fix performance issues? You bet your ass. But more often then not there is something bad with your extensions or solution that is the real culprit.
One thing I turned off in resharper that helped was the solution scan. I kept the individual file scan on for issues, but the solution scan would drag the system down.
You mean 2014? Because I've been using it for more than a year. It's really important to get the facts right for things like this. It doesn't give me much faith in the rest of your findings. 
I've not used the android designer so wouldn't know but I've not found any features lacking for iOS. Could you give some examples?
Take Apple Watch for example, on the surface the Xamarin designer seems to support it. Just glancing at the errata page I see it does not show entry points for glances or notifications. You can’t add two notification controllers and have to manually edit storyboard xml. On iOS I ran into a lot of issues that seemed to be at the same level as these. Meaning, features were supported at a high level but then dead ended at some inconvenient point, sending me over to Xcode Interface Builder. Also one thing that is really useful in Xcode is simultaneous live previews for multiple device sizes. You can select 3 different layouts to view at once, edit constraints, and watch the effects for all at once. Kind of like livereload et al. I haven’t found anything like this yet in the Xamarin designer. 
No worries. I would read up on the callback pattern in JS
How does removing servers from a domain "gain a lot in terms of scale ability, manageability, and security"? If anything, you lose out on manageability and security by removing them from the domain. In terms of authentication, I need additional info to determine the feasibility of what you are trying to do. What do you mean by "external authentication"? Note: what type of single sign-on do you currently have in-place? Is it windows/automatic (users do not need to type in username &amp; password) or one that uses forms authentication but they type in their domain account credentials? 
**Disclaimer**: I'm the author of Eto.Forms With Eto, you can use the open source MonoMac which only requires your users to install mono to run your app. Eto's *Eto.Platform.Mac.Template* nuget package will create an .app bundle for you that you can zip up and distribute. If you are intending on using the WebView control on windows and don't want to deal with IE issues (which Eto by default uses), you can package Chromium instead and override Eto's default implementation by using CefSharp or CefGlue as shown [here](https://github.com/cwensley/JabbR.Eto/tree/master/Source/JabbR.Windows/Controls) You do not need to convert everything to use PCL's for the open source MonoMac (Eto.Platform.Mac), and with the paid Xamarin.Mac (Eto.Platform.XamMac) you can use the 'classic' version which allows full .net as well. You will need to either use PCL or compile your projects separately if you want to target mobile platforms like iOS, Android, or WinRT. Hope this helps! Curtis.
Having an IIS server on a domain in a DMZ is intrinsically less secure then a web server running w/ a local account. One has the ability to query an entire back end database mixed with all other accounts in your corporation. Think about if you wound up on an exploited IIS box that was joined to the domain. Instantly you have the ability to locate domain controllers, query inside the network, access to internal accounts that may have privileges. Now if you wind up on an IIS server un-joined, you have a local account and not much else to exploit. The source code has the info which will just point to a specific hostname with only LDAP port open - which is a much smaller attack surface. Also have you ever had to pass kerberos/ad through a firewall? The sheer amount of ports you need to open is not pretty. Managbility/scaleability in a web scale application is serverly limited by domain joined computers. Instead of being able to take a web server with all the web code on it, clone it, re-ip and be good, you now have to deal with machine SIDs, duplicate domain names, unjoining/re joining the machines to a domain, just to spin up more web servers to handle load. External authentication meaning hitting the web application from the outside, and if you have an internal account you get a token. I believe we are using SAML tokens for this. I saw the code and it's pretty simple, just an auth request to the DC, and then they do something with SAML token for single sign on. This is literally the only thing the servers due that require AD. 
Are you running extensions? Resharper? I barely have any slowdowns on my ancient i3 with 2Gb and a none-ssd drive until I start adding extensions (web essentials is the real killer) I usually run it without any extensions and its all fine. Sounds like you've either got a bad/buggy install, something is conflicting (overactive antivirus?) or you're running a badly written extension that's killing performance (eg, web essentials)
.csproj are basicly script files for MSBUILD, which is used to do everything from building to deploying. The reason you need those files included is for the deployment Task. Without it there is no way to know what should be included in a deployment and what shouldn't (Although those files are typically added to the 'Content' collection and in your case your adding things to the 'None' collection which I believe just lights the files up in Visual Studio and thats about it) You can always use wildcards to include all files like so: &lt;None Include="foo\specs\*.js" /&gt; &lt;None Include="foo\less\**\*.js" /&gt; The later includes all js files from all subfolders under "less". MsBuild is crazy powerful and most .NET devs overlook it but you can use it to make some pretty crazy deployment/build process's
You can prevent that by adding the wildcard to a property and using the property instead of the wildcard directly. The result will build, but may not visualize correctly in the IDE, but it will work. Given you are using webstorm, you may not care about the drawback. See [accepted answer](http://stackoverflow.com/a/21680084) Edit: used direct link
I discovered all this when I became a remote worker. I work on a laptop over a VPN. VS was okay in the office, but very slow at home, I figured the VPN was involved somehow so I setup ProcMon. Seeing all the files VS accesses is amazing. It is constantly accessing files, ReSharper also does the same. So anything that will slow that down will cause issues. Keeping all file access out of my roaming profile increased performance dramatically, getting the AV software out of the way improved it even more.
I have a roaming profile at work because I have a desktop and a laptop. I am very interested in getting this sorted out. Where in VS do you go to re-point things to non-roaming profile folders?
Thank you for the information. I'll do some more research into Eto, it looks awesome. I think getting started with Mac and Linux would be great and I can worry about mobile platforms later.
Options -&gt; Projects and Solutions &gt; General There are three directories there that get scanned constantly, change those to be your local disk.
Yes, ADFS is basically just a claims-based security token server for AD. Don't know if it's an option, but you might also consider Azure AD. You can replicate your on-prem AD users to Azure AD and then use it in the same manner as ADFS.
interesting options, thanks a ton I'll look into this. 
I'll get the class they use and report back 
It's very common. Every single .NET software shop from the 5 man teams to the big companies in my city has at least 1 person over the age of 40( and I mean a regular developer, not a tech lead doing only analysis, design, etc), and many over the age of 50. Seriously, I know many local engineers or developers from industry groups and I can't recall a shop that didn't have at least 1 person over the age of 40. Results probably vary in "startup" crazy areas. 
I'm not sure if it's a solution but I set my denuve.exe(visual studio process in task manager) to high priority,for me it really helped to reduce slowdowns to zero it runs like a cheetah(no better reference)
Well, the salt does not have to be "secure", "random" or a "number". The salt needs to be a secret blob that prevents your hash function from generating the same hash of the same data.
The fact that an admin needs to create an entire empty skeleton active directory domain in order to have a "secure" dmz'd server is a flaw in itself. Noted, I will pass the OAuth idea to the devs You're right, a secure perimeter is essential, but whether you have an IDS/IPS monitoring your systems or not doesn't change the fact that IF a webserver was to be compromised (whether IDS or IPS is there) and this webserver IS a domain joined computer, I innately have access to more information then a non-joined computer. The skeleton AD is a good practice, but still a "flaw" in my eyes when it comes to microsoft's suggestions. 
This. Although visual studio tends to fuck it up again over time.
&gt; I've heard Google is already starting to get it working with android. ^ This is the statement he was hoping wasn't true and I'm fairly confident there is nothing to the contrary on the Swift website.
I meant Swift says on its website that it will be open source. Apologies for the confusion.
He said ASP.NET 6. Not MVC 6, not ASP.NET 5.
Since the salt does not need to be secure random, but should be different for most users, I often use a Guid value. Modern guids are actually mostly random data anyway.
Yup - there's code in Mvc 5 that uses the RngCryptoServiceProvider to generate salts for PBKDF2. See https://aspnetwebstack.codeplex.com/SourceControl/latest#src/System.Web.Helpers/Crypto.cs
I bet it would become fun for you again given a completely different problem domain and job sector. My favorite part of programming is learning the domain specifics and less the tooling and architecture.
Ah, I always wondered what the double star meant.
[These do](http://www.sail-world.com/photo/Photos_2014_2/Alt_KF1.jpg)
Nope, the front end is done in Angular. Our back end is built to serve more than a single web site ... if we were using MVC instead of WebAPI though, it'd all be in Visual Studio + ReSharper. To my knowledge, WebStorm doesn't really understand ASP.NET MVC? I may be wrong.
I also posted this to /r/Programming but I felt it was a better fit for this sub :-)
i think i made good decision earlier by not learning Sliverlight even when interview guys were questioning about silverlight. 50-50% good and bad for me.
In my experience a lot of the .NET guys tend to be contractors / consultants that are in their late 30s early 40s. On a personal note, I really like the .NET ecosystem but I find a lot of the projects I have to work on is built by guys who haven't moved on since the Classic ASP days and I am finally getting fed up with it. I been looking at alternative frameworks and stacks that are a little more niche on the assumption that the people using these newer/ more niche frameworks e.g. Play Framework, Akka.Net, Node etc. I dunno if I want to stay around .NET any longer and I am in my early 30s and have been working with it for the last 7 years.
Thank god. Silverlight is a pain in the butt
Silverlight was a blunder. I can't believe it went on to 5 versions. 
Well shit. I guess a massive port effort is in my future. 
Shame. Silverlight was one of the best things Microsoft have done for a while. Maybe now we can have CoreCLR in every browser instead?
Yes pls. I want Silverlight dead. Web should be platform independent.
Yeah, to me HTML5 looked like the "Flash killer", not Silverlight, which looked more like "Better Flash with C# instead of ActionScript".
yeah , HTML5 is the future FLash killer. Audio video elements.
you only realized that now?
I don't blame them, HTML and JS are garbage.
It's funny there is so much stigma these days associated with jack-of-all-trade developers. Oh bro you're not into the latest web framework? Oh you must be an idiot. I have nothing against the latest movements within .NET and trends in general to embrace more "raw" web development, but it cannot be overlooked how well Microsoft empowered those that are not web developers day in and day out. Some of us still touch everything from Windows services, to WCF services, to WPF, to ASP.NET, to SQL stored procs, etc. We can't be absolute gurus in every framework within the stack.
Luckily, with WebAssembly and WebGL, it looks like HTML and JS are beginning their slow spiral towards death.
I think it's only a matter of time. There are already pure WebGL frameworks under heavy development.
/s
This may force Netflix to move to HTML5. I hate dealing with Netflix on Linux and if they moved to HTML5, I'll have less reason to use Windows at all! 
It deserved to fail - it's sole purpose was to kill Flash.
Zero? :)
If you're working with a third-party API which gives you this XML, and you still need it then validating it to a schema will not help you. In this particular case where we use it, we get XML that can change anytime because the third-party might change their API. They might add or remove a field at any moment. Their XSD will change with it and won't give any errors. In such a case we don't want to change our .NET models every time, but we just want to declare possible optional properties. That way, without changing your .NET models, you can still handle the XML deserialization.
I keep the project file as a list of the files of the project (really?) and create a different build file for the actual build/deploy 
Why do people keep saying this? The option for HTML5 is in the damn Netflix settings screen. Source: Been using Netflix HTML5 for literally months.
Is there any need to keep a list of files outside of msbuild? In an ideal world I compile the projects with nant, which allows wild cards. Project files are just for interop witg everyone else on the team.
try disabling UI hardware acceleration in the VS settings. There might be a problem with the way wpf is processed with your windows installation. This has been a known problem since VS 2010
RIA was all the rage for one year then it died. 
You can - in theory - take the source code, switch the project type and compile it yourself. A lot of manual work. You can also ask the author of the library to provide non-portable library as an alternative.
Makes sense :D Thanks!
i think you may be an outlier....these days, it tends to be people are promoted to the point where they can do least damage. I work with a 70 year old web dev, and a senior dev who just retired at 65. The management tend to be people who didn't really love programming...those that do try to stay in dev as long as they can.
i think you mean most devs &gt; 40 can charge a premium on their experience and tend to be working at larger businesses not small shops or startups
as long as you're useful then yes
we where outsourced at the start of feb....we're losing experienced people about 1 every 6 weeks now, and there was only 30 of us (at most)....our original overlords think that they can now command infinite resource to fix stuff. We now have access to extra people in India, but the quality of people isn't great. For example, the devs in India had been trying to get an application that processes TIFF files to work by taking a jpeg and changing the extension...then whining that the application doesn't work. The system we run takes someone pairing with an existing experienced person 3 months to be useful though...so the original employer (now client) have their heads where the sun don't shine. tl;dr outsourcing a dev department is short term thinking and will bite you in the arse in the long run aka...your all code monkeys and can be replaced in a heart beat
Nobody disables JavaScript anymore. Check browser stats and you'll see it's enabled in almost 100 per cent of browsers.
Tell me about it - I spent ages learning Silverlight only to discover it was being dropped. Thanks Microsoft.
Unless, of course, some of your users are blind. Or need to copy and paste text. Or are software agents...
Do you use Google Chrome on Linux? It's not available on FF or Chromium because of [preferential treatment](http://www.pcworld.com/article/2824623/ubuntu-linux-gets-netflix-without-weird-workarounds.html) (and I just tested myself: don't see the option)
Oh. Windows has had HTML5 for ages. /u/joerdie was referring to Linux, since it's only recently that Netflix supported Linux *at all*, even though it's still limited to Ubuntu+Google Chrome.
I'd just like to reiterate that you should absolutely not use it for production environments yet. A lot of people think that betas are stable enough. And a lot of times they can be. But this is one definitely is not. I've tested out three solutions and all three broke and are unrecoverable. VS even broke and stopped letting me create projects. I had to reinstall.
&gt;Might be a little more complex but it can't be much more complex than the already existing webstack. Yes it can be. Has opengl deprecated win32, Cocoa and gtk? &gt;Just look at Node.js and all it's modules for an example of the complexity / repetitiveness. By the same logic nuget is an example of the complexity / repetitiveness of c#.
Because not everything's built on ASP.NET 5. Also there's way more to azure than ASP.NET apps.
Yes, not everyone wants to look after a Linux server. Just let Microsoft do it
A server is hardware. 
I think he means using ASP.NET on Amazon and a Linux instance.
And database clustering, web farms, caches, easy integration with services like AD controllers, redundancy, etc. If you are used to deploying IIS it will be harder transitioning to Apache or nginx,plus I would be interested to see how you manage getting SQL Server on Linux
**tl;dr** You don't have to. ASP.NET 5 is about choice, performance and community. Welcome to Microsoft 2.0. Azure is a **Cloud Computing Platform**. They offer different operating systems - including Unix. If you don't have that much crazy outbound traffic I'd always choose Azure nowadays. **ASP.NET 5 is still under development** * ASP.NET 5 RC will probably be released in November * ASP.NET 5 RTM in (early) 2016. **Source**: [here](https://www.youtube.com/watch?v=vqTGJGy3D9s) ASP.NET 5 for Unix needs the **full** Mono-CLR with **Kestrel** as its server. [Kestrel](https://github.com/aspnet/KestrelHttpServer) is based on [libuv](https://github.com/libuv/libuv). (Like Node.js) Kestrel is missing a lot of features that nginx, IIS or Apache offers. Btw the Mono-**Core**-CLR is under development, see [dotnetfoundation](http://dotnet.github.io/core/getting-started/). -- **Tutorials can be found at my (new and shitty!) blog:** * [Installing ASP.NET 5 on Linux Ubuntu 14.04-15.04](http://mjomaa.com/computer-science/frameworks/asp-net-mvc/139-installing-asp-net-5-on-linux-ubuntu-15-04-x32) (**For advanced:** Use CentOS + Docker) * [How to Combine nginx + Kestrel for production (Part I)](http://mjomaa.com/computer-science/frameworks/asp-net-mvc/141-how-to-combine-nginx-kestrel-for-production) (Very basic, I'll write a bit more after my exams)
My professor disables javascript be default because it can lead to vulnerabilities. Trusting every script on every page on the internet is definitely not the safest thing to do. But if you really don't believe that someone can do such a thing, that's okay. You're just one person on the internet who cannot comprehend that people can be different.
Are you trolling? 
Have you tried Zeta? http://www.zeta-resource-editor.com/index.html
&gt; I would be interested to see how you manage getting SQL Server on Linux Well, if one goes the Linux route for hosting, I'm pretty sure they would either use a remote SQL Server or use MySQL, MariaDB, or PostgreSQL.
ive tried but is there any tutorial, because i have no idea how to add new key to resource file
Have you tried [Resx Resource Manager](https://resxresourcemanager.codeplex.com/)?
yes but i need standalone solution, because translator doesn't have visual studio.
EDIT: my bad. I thought you were looking for open source web projects in general. I missed that you were looking for web api specifically. That being said, dnn might have web api component to it. DotNetNuke is an open source cms ala joomla http://www.dnnsoftware.com/
Well, it is: Available as VS2010/2012/2013 extension and standalone executable to support VS2008 and older. 
Are you using XLIFF? https://www.oasis-open.org/committees/tc_home.php?wg_abbrev=xliff This is the standard for Windows Store Apps (Desktop &amp; Phone). You write messages in a resource file and the [multilingual app toolkit](https://dev.windows.com/en-us/develop/multilingual-app-toolkit?logged_in=1) generates the XLIFF files when you build. You can hand over an XLIFF file (essentially XML) to a translator, and they can use their favourite translation tool to modify it (lots of free ones available). It all works very, very well for both automatic and manual translation.
I didn't say that. It's a shame you decided to be rude.
You could always outsource it. 
You can always look through rhe source code to Web API itself, you will definitely learn something.
If you have non programmers involved, you could look into something like https://phraseapp.com/ to offload the translation work/tools there and just export the .resx from there to your solution
By excluding it, you're just dropping it from the mapping when the request comes in, but the property is still on the object. I'm assuming ReviewerName is a string. Since the model binder is NOT setting anything, it's leaving the property with it's previous property, which is it's default property as if you were to instantiate it with the default constructory -- which is null. When you say "reflected in the database entry" I'm not sure what you mean. Do you mean it's overwriting something? Or do you mean it's just showing null (new entry). I don't think I've ever tried to use the EF-generated entity model as a Action parameter before. Is that how they teach you to do it in the pluralsight video? That model is technically a domain model, so imo, you shouldn't be "exposing" it to the view. If nothing else, I'd probably create a view model that contains the entity and use the public properties on that view model to set what I wanted set to the entity model. That way, you shouldn't have to exclude anything; it would just be extra form post data that will be ignored.
Microsoft contracts out some of their promotions to other companies. If you do a [Whois Lookup](https://www.whois.net/), you will actually see it is a different company running the site. [https://www.markmonitor.com/](https://www.markmonitor.com/)
I am curious about the behind the scenes on how this works. I have a lot of great ideas that could really have an impact on how things work today. But at the same time, I am afraid that if I don't do the work myself (with help from other people), I will be scammed and not get compensated for my hard work.
I am going to assume there is some sort of timestamp column on the records that you can query by... One solution to your problem is to export the data via [bcp](https://msdn.microsoft.com/en-us/library/ms162802.aspx). Another could be to partition each 6 months worth of data to its own filegroup and then backup just that filegroup. I am pretty sure you could automate any maintenance of that setup via an SSIS package. Generally speaking though you would have full backups much more frequent than every 6 months (e.g. nightly) and you could restore any of them at any point in time with a different database name which would make that data available for querying without affecting your main database.
http://blogs.msdn.com/b/somasegar/archive/2015/06/29/save-the-date-visual-studio-2015-rtm-on-july-20th.aspx#10624584 Says there in the comments it will be released at a later date.
The equivalent of COM-style interops is .NET remoting. /u/phuber's suggestions are more modern (and generally preferred) approaches to solving the same problem.
It sounds like the accelerators provide courses which help with marketing your idea and creating a startup. You still have to do all the work. They also mention Bizspark as a service. If you already have a small business the Bizspark program can give you certain Microsoft cloud services and products for free. That's what I get from the website so I don't know if there's more than that.
* [Differential Backups](https://msdn.microsoft.com/en-us/library/ms175526.aspx) * Restore to an "archive" database before you search old data
You can always bind the webserver to localhost (prevents the API from being available outside the PC) for now and then it will be easy to make it network-accessible later. There's nothing wrong with having two web APIs talking to each other on the same PC.
I don't work with the grid view but why not maintain new records in a separate grid object. Then you can insert those lines into the database. It's been a while but I thought you could convert grid view rows directly to a dataset. Then insert the dataset 
You may want to try doing something like this: http://www.codeproject.com/Articles/24085/Insert-Update-Delete-with-Gridview-Simple-Way
We used excel in the past and just saved it as a CSV and run it through a vb script or similar.
The problem I have with WCF is that the book I have about it, "Programming WCF Services" by Juval Lowy, I found impossible to understand.
What edition of SQL Server are you using? And why are you doing this with C#? This can be implemented entirely with SQL, and if you have Enterprise Edition, it can be done quite quickly with the right partition scheme. I wouldn't call this a "backup" strategy as much as it is an archival &amp; eventual purge. Backing up the database is an entirely different thing. Are you the DBA? If not, have you pulled your DBA into the conversation?
Well considering MVC and Web API are merging, I'd say it is still relevant. I think more people are just looking to decouple the front and back ends a little more and that is why they are going SPA + WebAPI. SPAs are not always the best solution though, so use what is best for your situation.
gave you the wrong link - updated it. I'd highly recommend going down this route. It's quite simple and will give you lots of options for extending your solution down the road. 
&gt;What edition of SQL Server are you using? 2008 R2 standard &gt;And why are you doing this with C#? I want to develop a small software to do it, like a backup manager, maybe with end-user interface so the end-user may search past months / years. &gt;Are you the DBA? Yep
A decent answer to this question should be: it depends. It depends on * The potential size of your application * The realistic size of your application * What does the app do? i.e. Does it make sense for this application have a mobile version? * What's your time constraint? * Can you afford a rewrite after the time constraint (if there's one). * ... 
&gt; Most programmers are going to look at this and wonder why you don't simply specify a date constraint in your WHERE clause Done that ! I expect to generate more data in the next 2 years, as I said, I would like to have a future-proof design. Guess I will give low priority to this part of the system (backup module).
Personally for simpler sites I like to combine them. Created the page etc via MVC and fill dropdowns and grids etc via webapi. So if it has html =&gt; mvc, if it's pure data =&gt; webapi.
&gt; Drop the vlan if it is causing you problems. The machine names shouldn't need to be identical. Sounds like you need to work on the deployability of your system. Use Web.config transformations, you can setup variables and store them in the web.config. You can setup different build configurations like debug and release; these can dynamically change your web.config for where its built. Now the only thing that changes are some connection strings/machine names in the web.config when you use different build configurations ie test, prod, dev. Now setup a build script on your tfs server that deploys the built site to your environment. Pick the build configuration that corresponds to the environment. Now the same code goes to each site but the web.config will change on deploy and values will be pulled from there at run time. You should have a separate build script for each environment. 
Thanks for the responses, everyone! The reason behind asking this is that I've got a few personal projects coming up and was convinced I wanted to do .NET in some way, shape or form (C# being my favorite language).
I usually use both because the sites I build generally have a fairly robust Admin area, coupled with a blog, and then the SPA part of the site - so yea, I use a lot of Areas.
Backing up your data is good. Shuffling data off to an archive that you're calling a "backup" when it's a very small amount of data and it's not really hurting to keep it all in the primary tables...there's more important things to work on, I'm sure.
MVC is a nice an convenient way to develop your application. If you've never done much javascript development, MVC is a better choice because - to a degree - you only need to be concerned about what the server renders, instead of juggling client and server side debugging/development at the same time. It's very easy to get off the ground. With MVC, you only need to get the hang of one thing really: controllers. And they are pretty obvious once you debug the life cycle of the template application. The control flow is vary familiar to ordinary coding. With Web API, you still need to learn controllers in addition to what REST is, some client side framework, a practical way of getting your data down to the client in and my worst nightmare: *error handling*. All of these will also lead to some other headaches. Imo, for companies, MVC is still preferable over API+client framework simply because it has less moving parts. Also I'm hoping I will never have to touch anything related to Angular.
yes it does, however in .net5 / mvc6 it wont be doing. it will use a file that will be cached and stored.
I agree and personally I follow a 'hybrid' approach: I start out using MVC (routing, Razor server side rendering etc) and I add MVVM client side bindings - usually with Knockout.js - on pages that need interactivity, but only *when necessary*. Seems to be working just fine so far...
Once the tooling is in place, you shouldn't have to touch it much. We use node as part of our build system and it's executed through an MSBuild task. Once in a while, someone with know-how needs to update it, or add something to it; but generally, it remains static.
That's an interesting suggestion. I think it would work for giving a place for the data to go, but I'm also intending on using code first with Entity Framework for the database and that may cause a problem there. 
Just for the heck of it I tried adding [JsonProperty("Office__r.Name")] to the property and it must have done something because the returned data this time was null for "Office__c". But I'm not sure what happened to cause that. I just learned of the "dynamic" keyword to use in place of the pre-defined class. I used that and it returned json, so I'm going to play around with what was returned and see what I can figure out.
I like your suggestion and it does work. It would allow me better control over other fields in the Office table without having to meddle around too much with json, but immediately after getting this data, I'm loaded it into a DataTable that then uses SqlBulkCopy to insert it into a database. Any suggestions on how to handle this?
All true (though you'd be surprised how many times I have to explain to a new team why PRG is a best practice). I just didn't see how that was an indicator or reason to choose one over the other. To me, there are a few reasons for SPA, but by far the best one is "multiple UIs / apps". My bent against Javascript as a sane language of course makes me recoil in horror at the idea of putting a lot of code into said language, but I admit it's place for certain things. The whole "EVERYTHING SHOULD BE A SPA" mentality that I see a lot of newer devs is laughable and shows how much of a cargo cult so much of our industry is. There are clear reasons that SPA makes sense, and clear reasons when it doesn't. My recommendation is know both very well. Also, maybe it's just me, but I find writing an application UI in a server side language MUCH faster to develope than the Javascript SPA side.
The idea is that it's a sort of "anti-Jekyll" more akin to Metalsmith. I've gotten it to what I think is a nice, stable state and converted over my own blog to dogfood it. Now I'm hoping to get some feedback on what folks would like to see in a .NET static site generator. What would convince you to use one (this one or otherwise) for your own site? What have you found lacking in other generators? Thanks for taking a look!
MSBuild allows using wildcards too. You haven't checked it out in 10+ years, have you? It's *incredibly* powerful. There's no good reason to use NAnt over MSBuild.
If you're a little lost with WCF, using the ServiceStack libraries might help. A small, self-hosted WCF application is incredibly easy to develop, and you can expose a REST API as well as communicate using both JSON and XML. They're also cross-platform. As far as licensing, [v3 of Service Stack](https://github.com/ServiceStackV3/ServiceStackV3) has extremely permissive licensing (BSD) and is highly usable. They merge pull requests to fix issues on that version (one from last month), but haven't added many new features in the past 2 years since core development has moved on to v4. In v4 the licensing changed to a dual setup where you can choose a copyleft license (AGPL, I think) or pay for a commercial license. It's why several people still use v3 - it was good enough and funding fights with management. There's a [StackOverflow comparison](http://stackoverflow.com/questions/9699083/servicestack-vs-asp-net-web-api) of WebAPI and ServiceStack. I think ServiceStack was a lot easier to set up and get running, but WebAPI came out and got pretty popular.
Well maybe not a lot nicer, just nicer. Consider declaring a property that you want to be overridible in nant: &lt;property name="dbConnection" value="Data Source=myServerAddress;Initial Catalog=myDataBase;Integrated Security=SSPI" overwrite="false" /&gt; The msbuild equivalent is: &lt;dbConnection Condition="'$(dbConnection)' == ''"&gt;Data Source=myServerAddress;Initial Catalog=myDataBase;Integrated Security=SSPI;&lt;/dbConnection&gt; The nant one is simpler and more flexible. There are a ton of little things like this. Having said that, if a project has an existing build in msbuild I don't think there is a compelling reason to change it.
&gt; The Condition attribute is not a static value: $(dbConnection) is a property whose value is evaluated at build time, and since it doesn't already exist, the MSBuild evaluation engine goes ahead and creates it. I know, it's exactly what I want it to do and exactly what the nant version is doing. "Only set this if it isn't already set".
MSBuild's Condition is more powerful than that, though. You can put in any valid expression that evaluates to a boolean value. That's what I was trying to get across. You aren't limited to simple static properties and items defined before build: you can generate whatever you want at build time. That's what makes MSBuild immensely powerful. Of course, its power isn't limited to the Condition attribute.
You can do the same with nant, the attribute is called "if" instead of "condition", they just included a more readable version for the most common use case.
The docs for ASP.NET 5 are currently a work in progress, but the Security portion is pretty in depth already. You can ready about the key stuff here: http://docs.asp.net/en/latest/security/data-protection/configuration/overview.html 
I was reading the difference between WebAPI + spa vs MVC. Data driven web applications make more sense when dealing with data. WebAPI + SPA is a clear winner strictly in performance. MVC is great for traditional websites. However, manipulating the DOM is going to be expensive in terms of performance. Like others have mention, it depends on what you are building for. It wouldn't make sense to build an SPA for a website that just delivers static content. Or building a profile page using mvc. MVC will be around for a while especially now that WEBAPI us being integrated into MVC 
I receive the %1 message inside Visual Studio when some resource file can't be found for translations. I assume your .net runtime might be damaged. Completely uninstall all .net things and if that doesn't work you need a fresh windows.
That is the standard message for corrupt or otherwise unlaunchable executable. It looks suspiciously much like a "space in exe path" failure. If you *do* have a space in your installation path (the source files), try again from a path without any. Or if you don't, try installing it somewhere where there are none. It could also be from a previously lingering install, if you have any of those.
Seems plausible. I read somewhere that the Release Candidate ISO was reduced from 6GB (VS 2013) to 3GB (VS 2015) mainly due to the fact that it didn't include international versions. 
I haven't seen it mentioned anywhere so forgive me if I missed it but have you tried reinstalling Windows and then installing VS2015 from a clean install? That seems to fix most issues for me
Most MVC apps still require a bit of javascript. 
Thanks... I'm pretty certain this is a software issue and that a clean install would do it. Definitely a last resort though. The system in question was a personal laptop now being used for work so I can't afford the downtime. Worst case I'm building a new computer next month so I can install it there instead - I do have a VM but it is just too slow for sustained dev work. 
Any idea on how to work together in my situation?
Well, that code isn't fine, as it can return a half-initialised decimal, even if all the threads are using the same lock object.
I see. You are right. The first read access to `_myDecimalField` is outside the lock, so it violates the "synchronize all access" rule already.
It would for atomically written types. For decimal though, a thread could go into the above code, find `_myDecimalField` is zero, so it locks `_myLockObject`, checks `_myDecimalField` again, then calls the Initialise method. The Initialise method returns, and the thread starts to write `_myDecimalField` - but this write is non-atomic - I think it happens 32 bits at a time on 32 bit systems and 64 bits at a time on 64 bit systems, so after some but not all the bits of the result have been written to `_myDecimalField` another thread could come into this method. The second thread first checks if `_myDecimalField` is zero - it might not be because some of its bits have been written already, so it returns whatever odd value is in `_myDecimalField`, without even looking at the lock.
2015 and you just noticed? Isn't this specified?
1st) .net does exactly what you did, but easier 2nd) it doesnt have to be as involved as the other answers but I question your architecture (admitting I don't know the full picture) we did you call the ActiveX exe and not a dll? Who not have the function that gets the temperatures in a dll that both the service and whatever code you are writing can call?
I think you are looking for this http://www.nrecosite.com/html_to_image_generator_net.aspx which is based on http://wkhtmltopdf.org/ The alternate would be to use a HTML to PDF library which has output as an image option.
I think we've really reached a point where technology choice should mainly be driven by team skillset / preference and to a lesser extent hosting environment costs. You could write a great app using just MVC, or Web API and angular, web forms, node js, PHP etc. The explosion of frameworks is more about the bar being lowed in creating them than the advantages and productivity merits they produce. Developers can argue about their preferences all day long (and do!) but the end result has more to do with the quality of the design, good coding practices, and consistent naming conventions. 
Glimpse is a must with Entity Framework. Being able to watch the generated SQL for each page was a lifesaver.
According to you, the following should work. Server program: using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading; using System.Threading.Tasks; namespace SimpleServer { class Program { private static DateTime m_startTime; static void Main(string[] args) { m_startTime = DateTime.Now; } public static TimeSpan ElapsedTime() { return DateTime.Now - m_startTime; } } } Client program: using System; using System.Collections.Generic; using System.Linq; using System.Text; using System.Threading.Tasks; using SimpleServer; namespace SimpleClient { class Program { static void Main(string[] args) { Console.WriteLine("Server has been running for " + SimpleServer.ElapsedTime()); } } } The client project includes a reference to SimpleServer.exe. Nonetheless, the namespace SimpleServer is not found by the client program, and the client program does not compile. Again, according to you, if SimpleClient did compile this way, then the call to ElapsedTime() in SimpleClient would tell me how long SimpleServer has been running. Is that what you are saying?
So, based on your info. I am not sure if this meets all your need but, that being said, to get your sample working you need to mark the program class in your server as public.
And your calling line in client will be SimpleServer.Program.ElapsedTime()
Um, I'm not sure I understand the root problem but... Have you looked at SignalR for this kind of thing? http://www.asp.net/signalr It's the Group stuff you might be interested in. 
They are useful to get your foot in the door but not as much if you have years of experience already.
They are useful if the hiring company either has other engineers with certs, or states in the job description and/or on their website that they employ certified engineers. For example: http://jobs.triage-partners.com/apply/mkQjci/DevOps-Engineer "MS technology certification desired (MCP, MCAD, MCSD, and MCDBA)."
Why don't yu change the gridviews to listviews. I know the early versions of .net didn't include listview but in current versions it is better to use for such purposes rather than wrapping extra code around a gridview that mimic the functionality.
Oklahoma City, OK. Software Architecture Project Manager. 10 years experience. $85K. Working two development teams (across 8 projects/applications) managing coding &amp; technology standards, managing development on shared libraries used across teams, code reviews, training/mentoring, troubleshooting, etc. Technologies include WPF, WCF, MVC, nHibernate, Oracle, Postgres/Postgis, ESRI, and more.
[H1B Software Developer Salaries in Louisville](http://salarytalk.org/salaries#%7B%22qcompanyName%22%3A%22%22%2C%22qjobTitle%22%3A%22%5C%22software%20developer%5C%22%22%2C%22qECity%22%3A%22louisville%22%2C%22qEState%22%3A%22KY%22%2C%22s%22%3A%22lca_case_wage_rate_from%22%2C%22so%22%3A%22desc%22%2C%22y%22%3A%22%22%2C%22wf0%22%3A%22%22%2C%22wf1%22%3A%22%22%2C%22textFocus%22%3A%22jobTitleSearchBox%22%2C%22limit%22%3A10%2C%22offset%22%3A0%7D) [Some .NET specific salaries](http://salarytalk.org/salaries#%7B%22qcompanyName%22%3A%22%22%2C%22qjobTitle%22%3A%22%5C%22software%20developer%20\(.net%20developer\)%5C%22%22%2C%22qECity%22%3A%22louisville%22%2C%22qEState%22%3A%22KY%22%2C%22s%22%3A%22lca_case_wage_rate_from%22%2C%22so%22%3A%22desc%22%2C%22y%22%3A%22%22%2C%22wf0%22%3A%22%22%2C%22wf1%22%3A%22%22%2C%22textFocus%22%3A%22jobTitleSearchBox%22%2C%22limit%22%3A10%2C%22offset%22%3A0%7D) Note that H1B visa holders are typically underpaid.
Software Consultant with national ( not big 4) consulting firm out of Denver office. Paid hourly, but have benefits. Currently at $63/hr with 9% bonus as of last year cycle. C# backend, webapi recently, but can do most of it.
Southern California, Senior Software Developer (remote work, Pennsylvania), .Net, SQL $110K.
Living in Europe, BSc, 3 years working with in enterprise as full stack developer. Working on .NET, Java, Web and Web services. AngularJS, Bootstrap, SOAP, REST etc. 18k € salary. 
euro or USD?
Team Lead with 15 years experience (primarily in .net web apps in Australia). Bangkok, Thailand $USD40K. doesn't sound like a lot but it's a low cost of living.
Southeast Missouri, software developer/report analyst, 63k.
Copenhagen, Denmark - Software developer (Fresh out of school Msc in Software Engineering), .NET, ASP.NET, AngularJS - $74K
2nd year, working mostly with scala / backend / tooling. ~48k Euros guess it could be more :(
I live in the UK and work in central London. I'm a full stack developer. .Net primarily. My take home (after tax etc) is 130,000 USD (£82,000). But, it's a bit different in the UK at my level. I'm a self employed contractor. Which means no paid holiday. No sick pay. You want a day off, you don't get paid. I'm not rich by a long way but I live very well on that salary. I do know contractors that make twice my day rate though. They tend to be very specialist roles though. 
Nope. I believe even minimum salary would beat my earnings when I would live in the UK. 
I've never needed one. I've picked up stuff as I have gone along. If you like structured learning to bring you up to speed, they are quite good. If you are like me and just figure stuff out as you go along, you'll be bored to tears.
Mine is £400. 
There are many examples where it makes sense. But these are the exceptions IME, and you don't necessarily want to introduce a new dependency for a few exceptions. If you don't need immediate feedback then a message is usually better tgan a command. Edit - I'm not trying to shit on the idea or discourage you at all. Just make sure there is a clear and common problem. 
I think I get what your doing now, I'll reply again when I'm more soberer.
Cheers!
The "supported technologies" area looks more like namedropping than a real list of supported technologies in my opinion. As a developer I cannot see if this is a product that is applicable to my toolchain.
Hows the cost of living match up with that salary there?
It's easy to go underpaid in our industry, but I'd also say it's easy to find an employer willing to pay you a fair wage.
You moonlight? Like you work after hours on side projects? I just took a new job making close to 85K so I think I'm more in line with the Louisville average. How do you like sitecore? Honestly, I prefer using Orchard these days if im going to do MVC stuff.
This is nice. Pretty much no front end stuff? Just a lot of class libraries? I imagine thats nice.
That doesn't seem like a whole lot.
Have you used EF before? How does it compare to nHibernate?
Nashville, TN Senior Software Applications Developer 7 years experience $92.5k - I work mostly in C#/.NET as a full stack developer doing everything from SQL database migrations to putting the finishing touches on the javascript ui/ux. I'm also a part of the process for fleshing out the business requirements and designing the solutions that we will put in place on a high level, meeting with CIO/CEO/COO, and other leaders in our company. Three years ago I would have never thought I'd be doing all this, but I love it.
I'm actually just moving into sitecore stuff so I'm not sure yet. Am pretty used to both CMS's and MVC so I don't see myself having an issue with it. Also other people tell me that compared to other CMSs, this is their favorite so that is a plus. And yea, by moonlighting I mean working on side projects. Do a huge mix of stuff for companies, startups, and small local(ish) businesses/political campaigns.
It's easy to become underpaid if you don't ask for raises or seek new employment where you will be fairly compensated. Many of the personality types who flock to this industry are not assertive and don't want to be in the uncomfortable situation of demanding higher pay to match the growth of their abilities over time. That and many places of employment aren't great environments for developers to grow their skill sets, but rather have the developers doing menial development tasks over and over again, not allowing the developers to try new development/design patterns or tools/frameworks. The trick is finding an employer which does provide a great environment which promotes growth; that can usually be detected to some extent in the interview. Don't forget that the interview process is there for you as well; you need to take that opportunity to probe into the team to learn the more important bits of where you'll potentially be spending most of your waking hours.
Yea could be more but there is a lot of competition here for available jobs (there was around 50 persons interviewed for my junior position) and that really pushes the salaries down. Currently looking for a job in netsec and that seems nearly impossible here.
I experimented with EF back in its early days, so by no means do I have a good working comparison. Based upon what I have read though, it sounds like EF is pretty robust these days and has features (e.g. migrations) that nHibernate does not. Given the choice, I'd probably lean towards EF. The use of nHibernate was already ingrained with the teams when I started, although one of the teams is looking to begin moving away from it because of issues that have been encountered while doing spatial queries.
Honestly, just a lot of networking. I joined a few social clubs when I moved to Louisville and almost none of them were tech related. It is smart to try and meet people in various different backgrounds. Also check out any startup accelerator programs that are local around here. You can contact them, go to their meetups, etc. and find work for the startups that come through. You can usually charge hourly since they have money by just being in the accelerator, or you can always take some equity as well. If you buddy up with the mentors, you can typically have them recommend you. Then I have an old employer I still do contract work through every now and then along with a friend who owns a small web development company. However all my moonlighting is typically written in PHP (lots of Laravel MVC and vanilla) or is sometimes in Wordpress (eck) depending on what is needed. I only get to work in C# when developing games and tweaking controllers or working with Razor/legacy view code. But now that it is open source, that might change.
Minimum wage here works out around 20/21k in euros.
Associate consultant at a smaller firm, bringing in 65k base and about 10k in overtime plus profit sharing. I mainly do ASP.NET and Sitecore, but also started doing Xamarin apps recently.
The only time I would recommend them is if your company is a MS partner and thus a certain number of developers need certification 
Unfortunately being in the UK means that you'll get taxed 40% if you get past the 31k bracket as opposed to 20% as you are on now. I'm in the same situation as you are, there's no point accepting a pay rise unless it's above around 45k. I hate tax.
31k + 10k (personal allowance), so you can earn pretty much earn 41k before being taxed @ 40%.
I've never heard of personal allowance before, ELI5?
I could, but there would be a hazard pay adjustment.
Kansas City. Work from home for a certain software company in Redmond, WA. Was an on-site support engineer (as in, people with special contracts could request me to come help them with .NET and Azure issues), but I just switched over to the Azure documentation team. Been doing software development for pay for 24 years, and I'm only 36. Not quite comfortable revealing my salary here, though, as some people know my real identity. Suffice it to say, I make a little more than the other KC area guys in this thread (so far), since it's a West Coast salary, and more on par with those of you in LA, NYC, etc. Combined with a midwest cost of living, it goes quite a ways. Edit: Changed some wording so it's less of a humblebrag.
I don't know how British tax works, but are they not tax margins like we have in America? If you get bumped into the next margin only money in that margin is taxed at that rate. So if I make $1000 into a 30% bracket, I'd be taxed 30% of that $1000 but less of all the earlier money.
Also it's not 40% on all earnings, only earnings over the tax bracket. Common misconception.
Ya no joke. I was hired at the company I currently work at whole still in school. At the time I was working a retail job at $10/hr so when I got offered $17.50 I was ecstatic! Five years later and I am still with the company now making $35/hr. I guess their strategy was to grossly under pay me so that when they are only under paying me it feels like I am getting huge promotions! I'm fully vested now. Time to start polishing the resume.
Suburb of Indianapolis here... 3600 (1200 completed basement) and mortgage is 1700. Little over a 1/3rd of an acre. Just comparison. 
St. Louis , Sql Developer at a financial firm. 75k.
No, just a small downtown marketing agency. I didn't think Hyland did CMS development, I thought they had their own software they sell? How did you like Hyland? I heard good and bad things, like all the perks, but you have to work long hours.
Senior Principle Consultant, living (tax free :)) in NV, Client locations vary Full stack ERP/Data Analytics (heavy Oracle backend, WinForms frontend) Lead architect/managing development team 25yr exp, BS/MS from top 5 CS school Billing $200-250/hr top line plus cut of the project profits. 
Grand Rapids, MI. Software Engineer 65k Essentially a full stack developer. I work on web services, compact framework mobile apps (think ruggedized Windows mobiles), Win Forms ERP app, and my primary project is a enterprise level iOS app using Xamarin. I can work on any number of projects in a given day. Edit: Graduated college with my bachelor's in 2012. But I had been working in development at least part time since 2008. I started my first .NET job in 2010 and worked part time till graduating and transitioned to full time. So depending on how you count my experience I'm somewhere between my 3rd year and 7th year as a developer. 
Boston, MA. Senior Software Engineer. Full stack for both desktop and web applications. $123k + bonus.
Sorry, read it quickly thought it said DMS (document management system). They make a product called OnBase that's used for document mgmt especially in healthcare and banking. I was hired to do R&amp;D, so I was salaried, but the developers are hourly and the pay isn't that great for them. It's a fun place to work if you're under 30, but the benefits in lieu of a more competitive wage and difficulty of professional development unless you know/are related to the Hyland family means that it's a very young crowd, and feels reminiscent of high school with cliques and the like. When I worekd there, it was still family owned, but since then it was bought up by a private equity firm which, from what I've heard, has slashed some of the benefits (like the legendary holiday parties). I'm working for Sherwin Williams now doing IT mgmt/development for large operations research and R&amp;D projects, which despite the fact that it's an older, more traditional company, has always felt like a more welcoming place to work, and the pay's a lot better.
Huntsville, AL Software Engineer (B.S. Computer Engineering 2011) WPF / MVC 67k + ~2k in overtime each year. 
I've hired developers at multiple companies, certification has never been a criteria for being hired by myself or any other development manager I have worked with.
Cards on the table; I have never used it. But I would also be keen to hear people's opinion of it because... .. I am a strong believer that these types of tools make the hard things easy and the easy things hard. Would you not be better of just making all the logic in the server side service and then just making 3 separate front ends in visual studio, android studio and (whatever the Mac one is called)? Because in order to make an iOS app with xamarin you need a Mac to compile it anyway. Edit: people don't seem to like this answer. Anyone want to tell me why?
Well, I can understand legacy support, but we're building all of our new apps with web forms as well.
Awesome, thanks. I really want to move a lot of what my team is doing into a micro services model. 
I've used it with Xamarin Forms, quick turn around, Madera solid app, 95% code reuse. You just have to be careful about you UI so it matches what users on all platform expect
&gt; .. I am a strong believer that these types of tools make the hard things easy and the easy things hard. Would you not be better of just making all the logic in the server side service and then just making 3 separate front ends in visual studio, android studio and (whatever the Mac one is called)? Have you ever done that? It's fine for really small projects or for larger teams, but otherwise it can be a huge headache to transition between three different development environments all the time. Not to mention three different programming languages.
Yes. I have. I'm a C# developer but have done, and do, android development. There is no IDE on the planet as good as VS but changing to android studio isn't too bad. And Java is syntactically identical to C# (almost). It's really not that hard. Got to be honest though. I've never done iOS stuff. But I doubt it's that hard for an experienced developer to pick up. 
It is still very limited, even xamarin itself suggests to use xamarin.forms only for very simple apps
6months of experience as a .NET MVC backend dev in Jacksonville Fl, make around $45k before taxes. I graduate in the fall though so I feel like I could ask for a raise after graduation.
you had me until "windows phone." :)
In that case, I'm quite surprised. Although the money is considered not a lot in America, you still have a lot more left each month than people in America who make more. You must be someone who takes good care of expenses :)
The worst part about ios dev is that you have to buy a Mac to be able to do it. I don't know of any other way to submit your app to the store. Also xcode is the most disgusting ide ever made.
how much does it cost and will pricing be affected / changed by visual studio 2015 ? let's assume im a student who want to learn it or a indie because I dont understand the main differences between indie and bizz license
I believe they have student licensing. It should be free if you're at a tertiary education institution it should be free.
It's great for simple apps.
you'll just end up with boring and dry layouts if you use forms because of the cross platform aspect. and yes it is a huge bitch
it is useful for async email sending.
All of them are "compatible", but none of them really provide components to directly integrate that I'm aware of. They all provide a specification for processing, along with the documentation for getting test information, and certifications. There are also a number of middleware apps and component vendors that do provide API's or components that simplify the process (but there's always a cost involved). What's best will depend upon what platform you are on (Web, Desktop, etc), what types of transactions you need to run, and what country the processing account holder is in. 
Tampa, FL. 95k + bonus. Sr Developr. Asp.net MVC.
So... call the SendAsync method? Not exactly surprising.
Yea, I worked for places like Hyland in my 20's. It gets old fast, all the perks and whatnot, but it's great when you're first out of school. Like I said, I've heard good and bad things about Hyland, but I never heard anything good about Rosetta. That place seems to have the worst reputation in Cleveland (among devs) The place I just left had Sherwin as a client. The daughter of Sherwin's CEO works there. She was a total ditz too. Sherwin always gets listed on those "Best Places to Work in Cleveland" list, so hope it works out for you.
Everyone and their grandma have a programming blog now.
What do you find amateurish? I am learning to tweak the wordpress theme that I am using. Or are you talking about content?
Create two file groups, then partition your table based on the date range. Keep the current data on your faster drives in the primary file group, keep your older data on the secondary file group, made up of large but cheap slower drives. This way you can still query it as one table. You then still backup using a normal maintenance plan.
I'm no expert on the matter, and maybe someone else can provide better insight, but I am currently working on a similar project so I can tell you what I've experienced so far. A solution would be to just start with the empty solution and install the packages you need. You can then pull the same configuration code from the template to configure your OAuthAuthorizationServerOptions. Install-Package Microsoft.Owin.Host.SystemWeb Install-Package Microsoft.AspNet.WebApi.Owin Install-Package Microsoft.Owin.Security.OAuth Install-Package Microsoft.Owin.Cors I believe the reason the templates use OWIN to issue tokens is so that you can do all the authentication before you even hit your controllers. Thus it would be a better approach to set everything up on the same pipeline. disclaimer: not an expert. still learning. :)
Yep, a windows service would be the way to do it. Check out System.IO.FileSystemWatcher.
When writing a Windows service, make sure to check out Topshelf.
Here's a list of applications that can help you (Based on Hazel for OS X that does a fantastic job of automatically sorting files) http://alternativeto.net/software/hazel/
You're very welcome. I'm running a series on this topic over the coming weeks. Feel free to follow, and use the [AMQP library](https://github.com/daishisystems/Daishi.AMQP) on GitHub (please star if you find it helpful!). I’m happy to offer assistance as you progress.
It's normally faster than an app built with Java. https://blog.xamarin.com/android-in-c-sharp/ If it didn't perform well then you probably did something really wrong. 
Hey, We (I work for Xamarin) give enrolled students free business licenses. If you're interested in receiving one then drop me an email at mike @ xamarin.com. I'll need a bit of proof you are in fact a students but then I can generate the license for you. In general VS2015 doesn't change the licensing for our platform products. It does come with an improved Starter Edition. This is free (but limited) and allows you to build small POC and learn some of the approaches. You won't be able to use Xamarin.Forms with Starter though. Moving one up from Starter, we've got Indie. Indie is a Xamarin Studio only subscription. It doesn't have any limitations like Starter. Its extremely cheap at only $25 per platform. Then the Business license allows for building iOS and Android apps in Visual Studio. It also offers email support, which before I was an employee was a huge win for me. The support team will often review code, make changes, fix bugs and generally be a huge assistance in the projects development process. It does of course depend on how busy they are! As for pricing, we offer a discount when you purchase both iOS and Android licenses at the same time. I'll happily pop anyone in touch with our sales team if they want to talk discounts. Enterprise license builds on top of Business and has a few extras. The coolest is a super fast response time with email support. I think the support team normally get back within the hour! 
I think you're looking at this the wrong way. You're looking to build apps for 2 new platforms, its only natural to expect to learn new platform APIs if you want to deliver a top quality user experience. The benefit with using Xamarin is you can share the bits that aren't platform specific. Lets take the beer tracking app I'm building, I'm using C# on Azure for the backend, in a PCL for interacting with the backend and then in the app on the different mobile devices. I can then later on build a website and desktop apps and continue to use the same C# code I've already written. I'm reusing huge amounts of C# whilst using the same IDE and all my favourite VS Extensions and NuGet packages. Before I joined Xamarin I had built a few Objective-C apps. Even after using Xcode for a while, it didn't feel like home. I'm a Visual Studio lover and C# rocks in VS. I found learning new platform APIs isn't as huge an undertaking as learning 2 new languages and 2 different IDEs. 
What about about apps that require offline capability? 
I figured they did what telerik does and built in the cloud for you.
I've played with Xamarin quite a bit, but due to the price, I'd much rather be working with Ionic Framework instead. If you know AngularJs and Bootstrap, writing mobile apps is simple (and free!)
Yeah I did work on it for a few months and even had it running on friends devices.
Thanks, that's actually something I was trying to find, but couldn't find it! However, it doesn't seem to show the ribbon or navigation bar, which I need. Any idea if I can get these in there somehow? I'll have a deeper dig into the sample code, but for now it seems I'd have to forego the ribbon and nav bar and make my own clones.
Is your app going to be PCI compliant? If not , then skip doing it with .NET and use Stripe's JavaScript implementation.
[Visual Studio 2015](http://blogs.msdn.com/b/somasegar/archive/2015/07/20/visual-studio-2015-and-net-4-6-available-for-download.aspx) is also out.
thanks for that. I'm still stuck getting the service to run. I followed this simple tutorial for now http://www.codeproject.com/Articles/3990/Simple-Windows-Service-Sample and pretty much only copied the code. I tried to run the code without a setup, since I can't find it the way its explained in the tutorial, and I get a bazillion security-errors. I guess this is due to me using VS2013 and the tutorial VS2010. I haven't found anything for VS2013 yet
&gt;I believe the reason the templates use OWIN to issue tokens is so that you can do all the authentication before you even hit your controllers. Thus it would be a better approach to set everything up on the same pipeline. Exactly -- it's so you can protect stuff that isn't Web API (e.g. static files or whatever other middleware you can think of)
I can recommend Pluralsight.com, they have tons of courses. It is paid, but I think very worth it. I have been subscriber for a year and recently bought yearly sub instead of monthly... 
VS has a nasty tendency to cache dlls in super hidden places and it is not very informative as to when it's loading a cached version. You probably managed to clear the cache of the dll when you moved it / restarted vs. Next time this happens (and once it does it usually keeps happening) turn on advance tracing of your build and just double check that it's getting re-built and placed in the correct directory every time.
Just because a class is public doesn't mean you can do inter process communication by calling methods on it. Merely referencing the assembly is like copy pasting the code - you're just hosting it in the current process, not communicating with another process that happens to declare the same class. Additionally, WCF really isn't that difficult to configure and it's very extensible. I'm not saying that it is necessarily the option he should go with, but it's not nearly as complicated as you make it sound. Once you understand the core concepts, IMO it's pretty straight forward.
Las Vegas, NV - FTE, no degree, 15 years experience. Full stack .NET developer (mostly C#/ASP.NET) but do a lot of SSIS, SSRS, and SharePoint development/admin work. - 110k
The service code, the bit that interacts with the service APIs need to be separated from the code. Then tge cide can be called from a service or a console app.
I've recently started writing an application that uses event sourcing in .net. This was one of the big things I discovered. I've love to get feedback :)
If you're in Europe, [Tilaa](https://www.tilaa.com/eng) is pretty good.
That's reassuring, because I thought exactly the same thing when I was looking for material. Separation of concerns is an important aspect of development, and most web development positions require me to understand MVC. And yeah, WinForms gonna go away soon.
Azure can be pricey depending on the setup. I only really use it because of free msdn credits.
C# and the .NET platform is going through a lot of changes right now, to make it more lean, cross platform and open. As a C# developer I'm very excited about the future. Languages and platforms coexist. Just because Node got popular doesn't mean something else has to disappear. I'm using Node together with .NET in the same project. Is the platform expensive? Well for a small company you can use the free community edition of Visual Studio. As for Xamarin, I have no idea - not doing any mobile development. There aren't any huge cost differences though, as far as I know. I mean compared to salaries and office space rent, it will be peanuts.
With ASP.Net becomming (by now became) multiplatform and .Net Core being open source. I do think C# (or .Net in general) will not become obsolete at all. Especially when there are still many Windows devices (all tough it might shrink due the growing mobile market) available. And I don't see the world switching full time to mobile devices nor to other operating systems yet. Probably nearly every developper will praise the language he's focussing at. iOS Developpers will praise Objective C/ Swift, Android developpers will praise Java and a lot of web developpers will praise JavaScript. A lot of them will tell their language is the future. But it isn't necessarily correct. When Java came out, perhaps those who switched to Java might perhaps said the same about C/ C++. Yet, we still use them today because each language has its own advantages and functionalities. The same will probably apply to .Net. Microsoft offers a great eco system for developpers to deploy their business applications at in my opinion. 
&gt; 1) I've been talking with a lot of app developer on ios and android I wanted to learn C# and use xamarin to develop on all the platforms but they told me its way too expensive at 1599$ a year for ios and android ? Download Visual Studio Community 2015, it's a fully fledged IDE which in my opinion is vastly superior than any of the competition. Also, it's completely free. &gt; 2) if Windows is loosing market share to mobile what will happen of C# in the long run and Java is very popular for banks and backend ? I don't think Windows ever had market share on mobile devices to begin with. You're forgetting that Microsoft dominate the desktop, and I mean, dominate. If you go to almost any company/business, the vast majority of them will be using Windows as their main OS, not to mention that almost everyone uses Microsoft Server architecture. Businesses love Windows, it's pretty much staple everywhere you go. C# won't die any time soon. &gt; 3) lots of programmers are saying Node.Js and javascript is the future is that true that you can do everything in JS now and we don't need C# anymore ? I wouldn't agree that Node.Js and Javascript are the future, it would be more fitting to say that **Web Development** is the future. This encompasses all languages to do with web development, including C# (ASP.NET). All languages have their merits, you could argue with people for hours about the merits of one language compared to another, but it really doesn't matter. In the example of C#, the popular website **Stack Overflow** is written in C#, and to be completely honest, it's a very functional application, much more so than your generic HTML/JS website. Personally, I haven't been involved with much website development, however a colleague of mine has the opinion that if you want to do anything fancy, then he prefers to use ASP.NET, coupled with Javascript (For example, AngularJS and ASP.NET). However that's just his opinion. &gt; 4) I need to know if the .Net framework is a expensive platforms to develop on for a startup compared to ruby or java etc is it true that it's mostly large corporation who use C# ? No, it isn't. As I mentioned earlier, VS Community is completely free, you can develop and publish free and paid apps. I like developing with the .NET framework, and I haven't had any great experiences outside of it, this may just be my exposure but in my opinion, Java and Ruby are open source, and for open source, you get what you paid for, which is nothing. EDIT: Try not to dwell on the popularity of any particular language, instead, you should focus on learning the practices of programming and developing applications. It doesn't really matter what language you use, what really matters is how the skills you have developed can be transferred to a new language or development environment. There will always be a brand new, modern programming language which all of the cool kids are getting into. But for the most part, the only difference between languages is the syntax.
I'm using Vultr for their Windows Server 2012 R2 VPS and I could never go back to a Linux box. It's definitely a great service and RDP in to a full Windows install is great. FYI if you already have a license I.e. from MSDN then you will need to slipstream some drivers in to the R2 ISO and upload it. UbiquityHosting is good tok, the main reason I went with Vultr was the UK based DC
You need to post more code for us to see what is going on
Take 4 bytes from your large array and put them into "someArray", then: int i = BitConverter.ToInt32(someArray, 0); That will get you integers from your byte array. You can then fit them in whatever range you need, even if that is also tricky to get right without introducing bias (some numbers being more likely than others).
Ooooooh, thank you! Happy cake day!
&gt; 1) I've been talking with a lot of app developer on ios and android I wanted to learn C# and use xamarin to develop on all the platforms but they told me its way too expensive at 1599$ a year for ios and android ? Xamarin is expensive and it isn't great, but I'm not sure that there is any cross-platform tool/framework that is, at this point. I'm looking forward to checking out [VS 2015's cross-platform tools](http://arstechnica.com/information-technology/2015/07/visual-studio-2015-launches-with-android-ios-and-even-apple-watch-support), myself. &gt; 2) if Windows is loosing market share to mobile what will happen of C# in the long run and Java is very popular for banks and backend ? That's really speculative. I know of lots of companies (many of them financial) that are married to .NET in the same way that they used to be married to mainframes. It's worth noting that some of them are polygamous, and are married to both. &gt; 3) lots of programmers are saying Node.Js and javascript is the future is that true that you can do everything in JS now and we don't need C# anymore ? That's really a really simplistic way of looking at things. Couldn't you say the same thing about Ruby, Python, and anything else that's gained popularity on the web in the last decade? Naturally Node has attracted some former C# developers. This doesn't mean that it's obsoleting C# by any stretch. If it's taking some of C#'s developers, it's also encouraging new C#/Visual Studio/.NET features at the same time, which is really cool. &gt; 4) I need to know if the .Net framework is a expensive platforms to develop on for a startup compared to ruby or java etc is it true that it's mostly large corporation who use C# ? It always has been expensive, yes, and to get all the tooling that you might want, you would need to pay for it. But it's free now. [Check out the feature list and you'll see that the free version of VS probably has anything you want](https://www.visualstudio.com/en-us/products/compare-visual-studio-2015-products-vs.aspx). (FTR, I'd pick Bitbucket/GitHub over TFS any day of the week.) Is it mostly large corporations using it? No -- I could name companies with fewer than twenty people that are paying for MSDN subscriptions. As I mentioned above, though, some places have invested heavily in .NET development, and will continue with it for years to come. I believe that C# will give you as much job security as anything but Java at this point. Because of its superb tooling, Azure integration, and language features, I'd use C# and VS if I were a startup.
I'm in TC. Build Engineer mostly, some IT tasks (lateral move from IT). Pay about the same. 
I write a blog focusing on ASP.NET MVC, which you might find useful: http://levelnis.co.uk/blog I would definitely focus your attentions on MVC, rather than WebForms as other people have suggested. There's a bit of a steep learning curve but once you get your head around it, it's a much nicer ecosystem to work within than WebForms (in my opinion)
Actually I don't think devs that use Objective C and Java praise these languages - that's partly why we have Swift and Scala which are much better and closer to C#.
&gt;3) lots of programmers are saying Node.Js and javascript is the future is that true that you can do everything in JS now and we don't need C# anymore ? The JS ecosystem changes every 5 minutes. The .Net platform has remained consistent for a better part of the past decade. I would know. I just built a SaaS solution for a large enterprise using Angular (their decision) on the client side and C# on the back end. In roughly a year or two, they'll have to do a complete front-end re-write if they want to leverage the new version of Angular. In two years, they'll definitely need to do a complete no feature front-end re-write if they want support. &gt;4) I need to know if the .Net framework is a expensive platforms to develop on for a startup compared to ruby or java etc is it true that it's mostly large corporation who use C# ? .Net is free to use.... And the IDE is also free to use.... 
Which part? It seems to change every time I take a piss. 
Mvc is just the web application framework. Instead, look at entity framework, dbcontext.
community edition is out already... O_o 
Hmmm. Ok
It's also indicative that the .NET framework already contains a ton of functionality out of the box. 
If you are using code first (and you really should use code first) the 1-to-many relationships between tables are pretty ez. There are many resources about EntityFramework but I personally prefer video tutorials. [This one](https://www.youtube.com/watch?v=l9QXArMPyHc&amp;index=13&amp;list=PL6n9fhu94yhUPBSX-E2aJCnCR3-_6zBZx) is not that bad but you'll have to bear with his accent. 
I think the author makes two confusions: * No OSS projects doesn't mean nobody's doing it, it just means the projects aren't OSS. Publishing your project as OSS has a non-negligible cost: maintaining it, fixing bugs for cases you didn't use, adding/maintaining bits of functionality you don't need because other people do, etc. * Using buzzwords like "high availability" or "reactive computing" doesn't mean your software is useful or needed. StackOverflow didn't need Akka or Orleans or any cool and trendy framework to become one of the largest websites online, and it's all .NET. 
This, all over. All of the things he wants have been written and rewritten a hundred times, just not open-sourced because the bosses won't let it be.
Or... you know.. don't be fishy and just post the offer here.
Fair point. But there's also plenty of decent OSS filling in the blanks, but there's a ton of devs still unaware of it.
Is this guy's goal to get more contributors? Because he sounds delightful to collaborate with.
And yet the context of the article is a comparison to java which is used for the same sorts of projects under many of the same constraints. And java has somehow managed to foster an OSS ecosystem. I do .Net work right now and the tooling is abysmal and the sheer amount of work you have to do that should already be solved out of the box is quite frankly sad. You either pay money for a library that has an API only a mother could love or you write your own wasting valuable time. Aaron is right. Case in point? Why on earth are people still building .Net with msbuild? It sucks. We haven't created anything better even though the builds aren't anything close to hermetic and reproducibility is a huge problem. Or maybe everyone has written their own build system already but not shared it even though it's not anything close to core to most people's business. Things constantly break on our team because someone submitted code that builds on their system but no where else. I'm about ready to write one myself if I do I plan on open sourcing it.
Not that I necessarily disagree, but you may need to think that open source argument; particularly with .NET being open sourced and all. 
Although I'm not in a position to make policy changes, I've started campaigning our team (.NET higher ed) to make as much of our code OSS as possible. You don't have to be a boss to make a case that OSS is a good thing. 
&gt; And java has somehow managed to foster an OSS ecosystem. Look at the history of both platforms. .Net has its roots in Microsoft's large enterprise client base. Historically the costs of Visual Studio have been targeted towards enterprise developers). So academia and hobbyists gravitated toward Java and a positive feedback loop ensued. Hopefully the tide has turned and Microsoft's newfound embracement of OSS (and Oracle's lack thereof) and this will start changing. 
From the library front I recently needed to do some graph Visualizations. The only offerings were some for pay libraries that are out of our price range and a few tutorials with sort of working code. I ended up writing it all myself. Shouldn't have been necessary. For tooling I just want a build system that doesn't croak as soon as you grow past 1 developer. .Net solution files and csproj files are great if you are the only guy working on a project but as soon as you have more than one person and are versioning the files, whoo boy. I could spend 40 hours a week just keeping em maintained correctly. Never mind that half the time the build succeeds on one developers box but not on another's because the builds aren't hermetic or consistently reproducible.
This is kind of interesting because I think it shows a cultural divide in a lot of ways. No doubt, there's the proprietary issue but it's deeper than that. I'll posit this -- C++ and Java are used more at universities. They embrace open source so they are not biased to a tech company. There you have professors paid to further and investigate technology and their students looking for ways to hone their skills. Building and contributing to open source projects is a good way to accomplish those things. MSFT churns out framework improvements and tool changes pretty rapidly. Which is great except you could spend 100 man years working on a framework only to find MSFT's included one the next version. Nunit was really popular until testing was added to VS. When they put out an "official" version it kills the community one -- and no one knows when they'll decide to do that. There's still a lot of bitterness from the 90s when MSFT was seen as an evil monopoly company. And then from how long IE 6 was the dominant browser. Open source is the rebel flag. For maintainability, I always recommend restricting the number of 3rd party libraries included in a project. They version on their own schedule and can disappear overnight. Having the full source helps mitigate that but if you find you have to fork as maintenance goes you own it. That kind of thinking might reduce the popularity of it. And then my own personal bias which I know is shared among a lot of programmers is to write my own libraries unless I can't or it's significantly easier not to. I know the argument about re-inventing the wheel, but to use a library you have to understand it which is itself a big cost. A lot of times I can write the slice of the lower level code I need faster than it takes to find and learn how to configure and use a 3rd party library. And as a bonus I spend my time learning the underlying API or whatever rather than learning some abstraction. 
You are exactly right in that it's a cultural problem that hopefully will turn. I do see positive signs from Microsoft these days but the article is correct that Microsoft can't fix this particular problem. It will have to be fixed by the developers themselves.
There are other build systems that are open source for .net. Have you looked at FAKE?
It's still fishy if you don't just post the **whole** offer here.
Okay... well I'm not going to post all my clients information. And 5 full length job descriptions in here. If that makes me fishy I apologize. But if someone is interested in learning more they can msg me. Good day!
&gt;* No OSS projects doesn't mean nobody's doing it, it just means the projects aren't OSS. This, IMHO, is an incredibly important point that was completely missed in the article. From my experience there's plenty of advanced work being done in .net, but almost all of it is proprietary. It's developed in house and its kept in house. There are a whole host of reasons why that is, but it's generally how .Net development goes from my experience.
&gt; Yes, we do sell Visual Studio Professional 2015 stand-alone &gt; we do sell Visual Studio Professional 2015 stand-alone &gt; sell Visual Studio Professional 2015 stand-alone &gt; Visual Studio Professional 2015 stand-alone &gt; Professional 2015 stand-alone &gt; Professional 
https://github.com/Microsoft/automatic-graph-layout
&gt; most likely it would be windows boxes. That's expensive. I've never seen it as a big issue. The fact is that languages and framework choices can often result in performance changes of 50% or more. Compared to having 50% more boxes, the 'Windows Tax' is minimal. I'm not saying .Net is the fastest mind, I'm sure that some hand optimised C/MASM will be faster, but it's the whole dev time, run time trade off. For many .Net is a good balance. As a CTO of a startup, I remember someone once asking me how we could afford the windows licenses for our servers, I asked how he could afford the high hardware requirements of his Ruby stack. He appeared to thing I was just trolling him, rather than trying to draw a parallel to the dev time, run time trade-off.
&gt; Windows licenses cost money. Absolutely. But they are normally a small part of the 'cost' of doing something. Electricity, Hardware, Transit are all costs too. I find it odd when someone picks just one as an issue. For instance, say you had a small £100 pcm cost of servers, but, with a £10 pcm cost, you could reduce the hardware bill to £50 pcm. Obviously that 'license' cost is actually a net saving. Not saying that's automatically the case with .Net or any other framework for that matter. But you can't just look at a cost of a license without looking at the 'utility value' of it.
&gt; DLL's that hang around can make something build on one box when another box won't. No modern build system should allow this and It shouldn't require a clean before build. Yet I have to tell our devs several times a week to do a clean before building to reveal broken code. This generally means there is something broken in the project. Either files under source control or different projects relying on different versions of the same library. A CI server should at least detect these early. &gt; We have on at least two occasions shipped software that builds and runs fine on a developer box but fails on customer boxes due to missing dlls. I'm guessing this is a GAC issue? Nuget fixes this. &gt; MSBuild is really bad at detecting what needs to rebuild vs what doesn't making builds much slower than they need to be. Especially in a tight dev cycle. Agreed, ironically the underlying compiler (csc.exe) does a fantastic job of this. Building with csc (via nant) is much faster. &gt; Another issue that is just poor usability when it comes to distributed teams is that the solution -&gt; project configuration mapping scheme is error prone. It frequently gets corrupted in a merge when using VCS in a distributed team. This is compounded by the fact that .sln files are basically unreadable and meant only to be modified by an IDE which of course can't handle merge conflicts due to the file being unreadable by said IDE. You can modify the files to use wildcards instead, though VS doesn't always play nice. Either way, give nant a try, it existed before msbuild did. 
EF migrations only work for very simple database schemes. As soon as you start using any of the database's intermediate level features it falls apart. Now if you are doing something like Sqlite or Sql Server CE where you've got lots of tiny databases sharing the same schema then EF migrations start making a lot of sense.
This. It's fast, simple, flexible. Works well with branches. Makes CI and production deployment fast and simple too. No other approach comes close.
Damn, that's both surprisingly easy and answers a question I have right now in my project. Thank you.
Haven't actually used EF migrations. I named it because I thought it worked like FluentMigrator. I have used FluentMigrator for many years now without any issues. With FluentMigrator you can absolutely do whatever you need because you can always fall back to raw sql.
The Redgate Sql toolbelt is expensive but it's worth the investment, that thing can almost make coffee too. I have used it lots for both schema and data comparisons and has a nice diff tool to do comparisons and generates insert scripts schemes changes etc, it even does the table constraint modifications before and after so your pk's are all over the show between environments
Access to raw SQL is why I like SSDT projects. I just tell it what I want the database to look like, hit publish, and it figures out how to make that happen. A big reason why I don't like EF is that it assumes a one to one mapping between tables and classes. But in reality the situation tends to be far more complex than that. For example, I often have three DTOs. * CustomerDetail * CreateCustomer * UpdateCustomer CustomerDetail includes secondary information that has been projected. For example: public int CreatedByUserKey {get; set; } public string CreatedByFullName {get; set; } In EF, I would have to have an entirely separate object to bring back CreatedByFullName. And my UI developers would have to chase pointers in order to read it. Create/UpdateCustomer only includes the fields that are actually updatable by the UI. This avoids model injection attacks, a serious problem for Ruby on Rails, ASP.NET MVC, and other REST frameworks. 
This makes sense. Upvoted. Still, I believe the monetary cost of windows licenses is what has been holding back OSS in .NET. When comparing Windows to Linux, Microsoft would frequently play the 'utility value' card, and it is a valid point. The windows license is a small price of the total cost of ownership, when all things are compared. A windows solution may very well be cheaper than a Linux solution. Still, if I'm a startup with no money, the barrier to entry is too high. At first, the linux solution is *always* cheaper - it's free. Mono works, but not many are going to call it production ready, so if you are using linux, your not using .NET. Hopefully core clr will change this. 
That sounds awful for rapid prototyping. SSDT does produce SQL scripts so that I can fine tune the migration, but I only have to do that for very large databases where migration performance is an issue.
Do explain "binary state".
I hate those. They showed so much promise, but in practice just don't work. 
I forget the specifics, but it maintains some binary file with a record of the migrations. If you migrate a database, then delete it and restore an older version EF complains.
Can you define large? 100s of MB?
In theory you can. I am still researching the topic. 
Fluent Migrator uses a table too. I believe with EF it's for the manual migrations only. It just tracks which migrations have been applied. No migration step is applied twice.
In practice you'll end up reinventing half of fluent migrator ;)
At the top click subscriptions then Manage administrators. http://i.imgur.com/EUQzX9P.png
You're welcome
Well, I might think signal r if you want to post them in batches and be notified as things are processed. Also I'll note, you might have issues with large strings over 85k and the large object heap fragmentation, if you are posting and returning large json objects or similar. If you do, it'll look a lot like a memory leak. Fun little problem to troubleshoot, especially in a web app.
It'd help to have a little more information on what the data is or at least a bit more description of the problem. Also, you mentioned JSON as your serialization mechanism. Are you stuck with that? For large datasets, json is certainly better than XML, but it's still quite verbose compared to some other options. Maybe look into something like google protocol buffers, which was designed specifically to make message payloads as terse as possible. I used it once with a 14kb json payload and brought it down to 5kb with minimal optimizations. It's a pretty awesome tool once you get the hang of it.
Signal R sounds like exactly what I should read more about. And I'll keep an eye out for that problem. Thanks! 
Wcf works. 
Yes, you just script the entire database structure to an sql file, sql server can do this in a couple of clicks. Then your first migration just conditionally executes that file. This can be set up in under 5 minutes. 
Reproducible? I want to know what hermetic means in this context, or why I would care.
Reproducible means no matter who or what machine builds the code it should get the same result. Me, My colleague, and the build server should all get exactly the same output from a build. Right now this isn't true.
I assume that WPF is completely out of the question for you? If not, dump the WinForms.
&gt; At first, the linux solution is always cheaper Which is not always the case. For many startups, such as my own, the important bit is getting to the MVP as quickly as possible, validating the idea. Developers have been our biggest cost. Now if we were doing something that had a very low value per user, it would be a different story, but for us, having our developers more productive saves us money vs some runtime cost saving. This bluntly is why we didn't write our system in hand optimised C. Very few companies need to do this, hell even reddit started in lisp. Given that MS have the Bizspark program too, the whole first few hits are free drug dealer model so to speak, it also helps cash flow at the very beginning, cash flow is king and all that. As a result I think a lot of the reasons for who adopts what is little to do with the cost. This is certainly my experience when talking to other startups. There are so many that are the 'brogrammers', it's about cool rather than anything tangible.
You can absolutely tweak the SQL code generation on EF, dividing classes into several tables, and doing all kind of de-normalization.
You have obviously never worked with Android...
We have had issues with them because we have circular dependencies. Otherwise they don't really get in the way... just don't commit them to the repo :)
if you are big enough to break out of the community licensing you should just get the msdn subscription anyway.
Nothing especially unique, A few fat clients and a web application with shared common libraries. Version Control is mercurial so nothing unusual there. We do have a large number of junior developers so they are far more likely to make mistakes than a 10 year veteran. My issue is that the build system isn't capable of protecting them and us from those mistakes.
Yeah sorry but that isn't my decision here. I have to list the ways it can be bought and someone else decides which one to get. We have 3 C# developers, but we do not meet the &lt;1MM revenue target. If we did purchase 3 MSDN subscriptions, the only piece of software we would use from it would be VS. This is because of this paragraph in the MSDN subcription license: &gt; Many MSDN subscribers use a computer for mixed use—both design, development, testing, and demonstration of your programs (the use allowed under the MSDN subscription license) and some other use. **Using the software in any other way, such as for doing email**, playing games, **or editing a document** is another use and is not covered by the MSDN subscription license. When this happens, the underlying operating system **must also be licensed normally** by purchasing a regular copy of Windows such as the one that came with a new OEM PC. -- https://msdn.microsoft.com/en-us/subscriptions/cc150618.aspx So 3 copies of VS at ~$500 or at ~$1200 each. Are 15 unused pluralsight courses, an unused TFS instance, unused $50/user/month azure credits, unused windows installs, unused sql server licenses and all the other unused bits worth $2100? Even if it were my decision, I probably wouldn't buy it (at least not 3 of them).
For me it was just supporting parameters at all that got it to choke..
No amazon...
I mean to ask what is the managed vps with Azure?
Those requirements are conflicting. Parameterized queries are only necessary when using direct table access. Perhaps it means that you should be using stored procedures?
Unless NHibernate is on the Information Assurance approved software list, you may get flagged for using an open source third-party component. MS Entity Framework is allowed. Any application you write will need a DISA ATO (Authority to Operate) before it will be allowed on a DOD network. Not sure who this DBA doing certification is...
Actually this is an issue I have with DBAs alot. What is the difference between a SQL User that can only EXECUTE stored procedures vs an app user that can directly access tables with data reader and data writer roles using EF / nHibernate? Doesn't seem like its a huge security risk to me.
Interesting that it uses Newtonsoft JSON to do all the dirty work.
Yes. There is nothing in STIGs against either NH or EF. We have had NH in a production DoD application for years. There is no open source rule either or most all Java apps would be thrown out immediately. Your DBA is biased against your ORM. You need to socialize the use of it with them and make sure they understand the ways it can be monitored and profiled. I'd suggest buying Idera. 
Sounds like you have useful logic in your WCF layer.. Move it down into your service layer where you can access it. 
This is how I feel. I have to convince the CIO and CEO that it is worth the trouble so we can begin using things other than ADO.NET 
This is all now, Community edition of VS is relative new. I'm sure we are gonna see this change with MS leading the way, but Java have been there a looong time.
I need not only to access it, but to have it running when the service is running, whether or not there are any clients running. I don't yet know how to do that. 
We have been shipping apps based on Xamarin Forms for a year now. XF is definitely a 1.0 technology, but I believe a couple of your bullet points are off-target. I don't know what your criteria are for "just looks off." We have not encountered anything that's making us feel that way. Would we like a few more layout options (in particular, better adaptive reflow based on orientation/size)? Sure, but we've not found anything that's been a show-stopper. The difference in theming is deliberate; iOS apps tend to have white backgrounds, and Android apps tend to have black backgrounds. Windows Phone has themes, but the default has a black background. I agree with the scaling comment, but the recent addition of styling largely addresses it; set up a global style with an OnPlatform in it. I agree validation controls would be nice, but neither iOS or Android provide this out of the box, so why is this a ding against XF? On the last point, I'm not clear on what you're calling "native;" if you mean it has to be in the native language of the platform (ObjC/Java) this is incorrect. If you instead mean that it has to use the C# bindings for the native widget-set, you're spot-on, but I've found it to not be too onerous. I get to stay in the warm embrace of C# and many people have started building libraries that save me the trouble, to boot. Now, *my* negatives are the fact that new releases tend to include regressions (which is horrendously embarrassing), some of the controls simply should not have been released the way they work today (ListView performance, a picker that does not support data binding, et. Al.), and when you report a bug, it's a crapshoot as to whether it will be fixed. A couple of these will be resolved as the framework matures, the others will (hopefully) be fixed as the number of users grows. We shall see. Anyway, we're pretty happy with what we're seeing and don't regret adopting it. I wouldn't go so far as to say that I'd recommend it for every possible mobile app, but for anything that's data-input/presentation oriented it works a treat. 
 Do you know that xamarin without xamarin forms is also an option? Google MVVMCross for example.
I disagree on what users want. I mean, has anyone ever complained about the ui in angry birds, clash of clans, or other game which is definatly not using native controls? (most game engines have an internal ui framework, unitys is especially nice). What the user wants is intuitive and aesthetically pleasing ui. They dont care how we go about it. What platform expectations they might have (back swipe) can be handled in the view model. Can you expand on javas mistake?
Or Ionic which has the same base only based on Angular.
I can't say I've encountered the issues you're describing, but we didn't rely on the VS debugger for iOS debugging (we have both Windows &amp; Mac boxes). We adopted a layered MVVM architecture where the forms UI depended entirely on the ViewModels for everything besides layout and we developed the ViewModels in VS with decent code coverage in XUnit. This allowed us to spend ~10% of our time writing the layouts and the remainder making the damn thing behave the way we wanted (and we did THAT in VS). When it was time to debug, we pulled the repo on the Mac and ran the app. You're not the first person I've seen griping about the VS debugging experience for iOS; I guess we got lucky by choosing our approach.
If you want a cross platform framework built on top of OpenGL I can tell you one already exists - Python's Kivy. It's also free. http://kivy.org
https://www.youtube.com/watch?v=MOYxeLdQinA Wow, perfect. Now for C# integration and I will be happy.
I just took on the role of angular (1.4) Developer at work since nobody else knew it. I didn't realize 2.0 was using Typescript instead of JavaScript. Do I need to learn Typescript?
You definitely don't. Typescript was designed to be a superset of JavaScript so any valid JavaScript is valid typescript. Additionally, typescript compiles down to just plain old JavaScript so no worries there with typescript code working with the JavaScript you have or will write. I'm not doing it enough justice so for more info check out http://www.typescriptlang.org/ and r/typescipt
Oh okay, thanks for the info! What are the benefits of TS? This is really the first I've heard of it
Yea, we've got a very heavily layered design as well, and we tend to push as much as we can further and further down. I hadn't thought of debugging from the mac mini, I'll bring that up with my team and see what they think. That seems like it *might* reduce a whole ton of the pain here. Then again, switching back and forth between the two is likely to be painful. Maybe I can get management to invest in some KVM switches...
That's what we've done, re: backend systems, but there's a limit to how much of that you can do if you want any kind of interaction.
Xamarin forms isn't for applications where the UI has to look native or perfect. From the [Xamarin Forms](http://xamarin.com/forms) page: &gt;Xamarin.Forms is best for: &gt; * Data entry apps &gt; * Prototypes and proofs-of-concept &gt; * Apps that require little platform-specific functionality &gt; * Apps where code sharing is more important than custom UI Many of your complaints seem to be expecting it to do something that it wasn't never intended to do.
You're so wrong. You clearly have no understanding of how the technology works. C# compiled to Objective-C? Fucking nuts!
tl;dr: type system, modules, classes, better code organization in general Now for a more detail explanation: I mainly like it because having learned c++ in college and worked with c# for many years I initially used JavaScript like I did c++ and c#. I had to do some JavaScript for some vanilla ASP.net apps but nothing too serious and so I was able to get by. I was then tasked with doing a Windows 8 metro app using html and so I decided to learn JavaScript more deeply. I sat down and read Douglas Crockford's book titled "JavaScript: The Good Parts" and thought to myself... holy hell... I'm really doing this wrong. Granted most people who read this book for the first time have the same reaction (I highly recommend the book if you are going to be doing JavaScript development) Around the same time TypeScript entered beta (I think version .8) and it seemed that I could conceptionalize and code TypeScript up the way I coded for c# and it would output something that was more akin to Crockfords book (still totally readable code too). Yay, the best of both worlds! Additionally, I found that working with larger teams or simply wanting to refactor code was much more difficult with JavaScript, especially when there is a lot of it like in a SPA app. Lots of times bugs would appear while testing because someone forgot a field moved to another class or didn't move all the code that referenced the field... (granted you can guard against this with good unit tests but well... good up to date unit tests seem to be hard to come by when deadlines are near). So having a type system in javascript allows compilation time info that your code is broken, which is awesome for the refactoring and/or larger teams. Hope that helps. 
If you don't like MSBuild, .NET has FAKE (F#-based build tool) and PSake (Powershell-based build tool). They're both in fairly wide use and work well.
Blogspam.
A general fix that we've found is removing the app from the device (on iOS long press until it jiggles, then press the little X), which seems to fix most issues.
The difference is that privileges can be granted/revoked at an SP level. It never happens in practice of course, making the whole point moot.
Nope, each person has their own Mac Mini as a Xamarin build server. Gigantic waste of money, IMO, but management *insisted* that we had to build for iOS, and threw money at us to do so. (We are providing both the hardware and the software in this case, so I'm not sure why they were so adamant about iOS; it would have worked equally well and saved us a ton of headaches and money to just buy a bunch of android tablets.)
Apache Cordova?
Rightly so..
Not sure. At this point I'm not even sure they have tried to get an ORM approved. They were probably doing regular ADO.Net without stored procedures and maybe even without parameterizing their queries
You have a disadvantage in that AutoMapper has been used in many production scenarios, where this has not, so why is it better. You need to give me some info on why this is better then AutoMapper. Also the name has to change, the name makes it sound none-serious. Also this: *It's the greatest and best mapper in the world (tribute).* ... Looking at the code, it looks like to just wrap JSON.NET, so again why is this better? I would properly also move all the source code into a single folder, like src and have other stuff in the root of the repository, like the README.md
I did not say you could not develop C# code without extensions, I stated that the IDEs of Java where more open and had greater features compared to the free IDEs for C#, and Microsoft did have a ecosystem of extensions but it was closed off to people who payed. Look at how popular editors like SublimeText and Brackets are, one of the reason for this is because of the option for extensions. Like the must requested feature for Visual Studio Code is an extension system. 
It actually does happen. I've seen it strictly enforced in the financial services sector, for example. Massive databases with apps segmented on what they could access with a central credential authority designating what app gets what rights.
Thank you!
To an extent I understand it. I mean, their job is to ensure the DB is running smoothly. But some DBAs are over the top about it, like in OP's post. Unless there is a specific policy or something.
Is getting another job an option? Cause that sounds like a bureaucratic hell hole... 
More like, do you live and breathe JavaScript...
Wow. Hard to believe Redmond let this slip. 
It does not require Windows 8/2012 to use websockets. Also, it does not need any kind of .NET programming or hub creation. You just plug it and it starts sending the log entries in JSON.
To answer the questions above, Rx is a very grown up and complete programming paradigm which is widely used. There are loads of examples available and many discussions on stack overflow, so I suggest looking there to find out what it is all about. A great example which I love is [GitHub for windows](https://windows.github.com). And another example which is my own is [Dynamic Trader](https://github.com/RolandPheasant/Dynamic.Trader) which is writing completely in Rx and Dynamic Data (which extends Rx).
I have used Arvixe , Everleap(Cloud Hosting platform) and discountasp.net. Both discountasp.net and Everleap are under same management. Arvixe provides the best affordable package. Discountasp.net also is a good option. Everleap is pricey. But they do have load balanced servers. Both discountasp.net and Everleap are dedicated to asp.net hosting, unlike Arvixe which has other hosting packages as well besides windows hosting
IMHO this should be a sticky until a patch is released.
Hey Roland, I just started learning about reactive programming and had a couple of questions about dynamic data. So far I have finished reading the available reactiveui docs and watched a few presentations from Brendan Forester that were very helpful in understanding Rx (and the motivations to use them). I also saw your trader application posted several times in the examples issue thread on github. I was wondering if you could contrast using dynamic data vs using reactiveui's ReactiveList? I am just now starting to convert some of my VM's to use reactiveui and the motivation behind your project isn't immediately apparent to me. I'm looking forward to diving in and giving dynamic data a try soon. Thanks!
What resource did you use to learn WPF?
Thanks for the quick and excellent response. I am sure I could have figured this out myself with a bit of digging but this gives me a nice framing for when/why I would want to use dynamic data and how it fits in with ReactiveUI. Like I mentioned, I am just now getting into reactive programming and have a lot to wrap my head around. Based on what you described, I already have some places in mind where dynamic data could be helpful and will be giving it a shot soon.
In which case I would love you hear how you get on. 
var random = myArray.OrderBy(x =&gt; Guid.NewGuid()).FirstOrDefault(); Should work
Here's an update that Rich Lander (Program Manager at Microsoft) committed to the dotnet repository: https://github.com/Microsoft/dotnet/blob/master/docs/testing-with-ryujit.md TL;DR How to disable RyuJIT, or just Tail Call Optimization in order to (presumably) work around this issue. FWIW I have not looked into it at all and I still recommend taking the most conservative approach to security in your apps. 
So my previous employer with the huge VB.NET ball of mud refused to shape up. They decided they were not interested in raising their game, so I got another job, and a huge raise. Screw 'em :D
Doesn't knockout take over some of the operations that .Net usually covers? Do you end up with people kind of mix and matching where one dev uses knockout for something and another dev uses .Net to do the same thing? I'm worried about cross over between the technologies causing confusion and un-clear standards.
Have you tried the official documentation? https://dev.windows.com/en-us/getstarted https://msdn.microsoft.com/en-us/library/windows/apps/xaml/jj991805.aspx 
I don't think I have ever used powershell for development purposes. Mostly getting a server working stuff and even then it was a google as I need it approach which has worked fine.
You're right to be worried. Set clear standards and practices. While MVC and Knockout overlap in terms of some functionality, there's one important and vital difference: Knockout does it all on the client, MVC does it all on the server side. For best results, you're going to end up mixing and matching, but you'll need to set out best practices *based on your application domain* to define what should happen server side or client side.
I've been going SPA + WebAPI. Works really slick.
Powershell is rarely used in day to day development. When is Powershell used? (1) Microsoft uses a technology called 'NuGet' which you should definitely get to know well because its the *new* way to add libraries to your projects. NuGet has a visual interface but from time to time its easier/more efficient to use its powershell command lines. (2) Deploying a build. There are lots of other tools for this but most build engineers that I come across seem to rely on powershell scripts to push builds to servers. My best advice about powershell is to learn it when you come across a task that shouldn't require a full .Net project to accomplish. Most of your .Net life you won't touch it until that one small time when someone says "type this into powershell to accomplish activity X,Y,Z". Others may disagree because powershell can do a lot and automate a lot and can probably cut down on some dev time if you are super familiar with it. But unless you really *want to* learn it... you don't have to and you won't miss it.
SPA isn't a requirement for knockout is it? My understanding is that knockout is used for two way data binding and although that lends itself well to SPA it doesn't make SPA a requirement. Is that incorrect? Also, do you use SPA with MVC? Does that mean every request to your controllers uses AJAX and the view returned from the controller is pumped into some &lt;div&gt; container?
I personally enjoy PowerShell, but you probably won't need it. It's also easy to pick up.
I have also been looking into this. The "best" helper I have found for MVC views is this so far: http://knockoutmvc.com/ It has a NuGet package too - https://www.nuget.org/packages/kMVC/ I haven't used it yet but I'm thinking of going down this route instead of using Angular since I can just use the pieces that I want.
I'll have to give it a look over once I get knockout/mvc up and running. Maybe I'll start a branch that uses kMVC just to see how it works.
I have yet to find any. I didn't have any problems installing it on my Ubuntu and Linux Mint vm's. I haven't done much with it to this point. 
Nope, it's for all apps and platforms. Check it out: https://msdn.microsoft.com/en-us/library/windows/apps/xaml/mt185606.aspx Edit: It appears that I need to learn the difference between "app that can run on Windows 10" and "Windows 10 desktop app". Sorry for the confusion.
Here's a dumb question: Why would someone need to use Powershell to deploy a solution (that was built in Visual Studio) rather than using VS's "Publish..." GUI? Are they the same??
There is a lot you can do with built in tools. But when that tool fails to satisfy a requirement you use an integration point to pull in a tool that can. Powershell is a go to tool for build and push scripts. The last guy I remember built out a deploy script because of the multitude of servers, peissions, and products that had to get pushed. But we have to jump through crazy security layers to get stuff out. The whole deployment process takes about 6-7 hours and is planned for weeks in advance... the fucking paperwork and sign off on a single deploy is nuts! Anyway, I always think of Powershell as some glue between a bunch of little processes to achieve an overall goal. Now, I don't use it myself and I don't know much about it. But I do know that several full time build engineers I know use it religiously. So that's all I got for ya.
Are Header, Body and Footer separate instances of pdfPTableMain or are they a single structure? In any way try and change pdfPTableMain.KeepTogether = false; KeepTogether will always try to display objects on the same page, if it doesn't work it makes a page break as is happening in your case. *I have limited iTextSharp experience but KeepTogether works like this in CrystalReports.
Thanks!
Are you using an "@model" directive in your .cshtml? Note the difference in case; "@model T" sets the type of the view's Model property to T (whose type is otherwise "dynamic").
Do you need the header/body/footer all in one table for some reason? I'd ditch pdfPTableMain, and just doc.Add() each section as individual tables.
Thx.
You maybe able to download but might want to reinstall and check which language packs or something like that. 
Ugh, sorry, was reading this on my phone and missed the bit about monodevelop in the title. I've never tried it there, and suspect my answer won't therefore be of much use.
I had the same idea. Inherit and ovveride.
Looks like you need to run the installer again, you're missing all the features except F#
Post the generated html
Very useful in our case. We have a web application serving several sites and some sites have different requirements from others when it comes to the robots file. I'm looking forward to the site map post since right now we manually register all of them trough google web master tools.
Cool. Glad you found it useful.
I tend to follow the ideas in Pragmatic Programmer and get a tracer bullet going through the app. So, I'll start with a simple HTML UI (or API Payload) and make sure its bound to my programmatic model (the entity in your case), and then make sure I can read that entity out. From there I layer on more and more. My style is one where I tend to take multiple passes over a given feature before its done. So I will get my first entity viewable in the UI, then go over and get another UI/Entity combo. I'll do this a few times and then take a step back and look for areas that are becoming duplicative, I'll then stop and try and take a quick stab at cleaning it up. From there I will move on to the next pass. Wash rinse repeat a few hundred times and the app starts to put on real substance. FWIW, i have a fairly standardized build process that i can bring into most projects to compile / test / package / deploy etc. That structure gives me some immediate bones to push and pull on which is very nice as well.
Something got screwed up with the formatting but the links should be working now. 
This.. Really has nothing to do with this subreddit. 
It basically is an ad.
It appears I was wrong, you cannot update tiles from a normal desktop app directly. https://msdn.microsoft.com/en-us/library/windows/desktop/dn554295(v=vs.85).aspx You could create a small metro app that gets data from your desktop app and just updates its tile? Idk i'm just thinking of a possible solution.
Yea, I guess that's the safest bet. That's how the DevExpress control works also. Damn shame they dint cross over this feature. More people using metro features would make more users more familiar with the metro environment and port more people over to it. You'd guess that would be in Microsoft's best interest. 
Neat. Why Web API and Nancy both, though?
What is your impression of Typescript and Angular working together? Is it productive and problem-free? I have a team who is considering going that road - from using plain JS with Angular at the moment - but are not sure if the two synergize well and how much value is added.
It's fine man, I'm assuming you are asking with the best of intentions. Lol, I think I also asked for this. Uhm, you are definitely right, I have to go through my dependency list, weed some crap out. I definitely yanked that file from another project somewhere. Let me do a full clean and build. Chances are I've missed something that's causing a "works on my machine" scenario.
I wish I had an answer there. It's because I haven't gone through the steps of setting up MVC5 with OWIN myself yet. Strange that I know how to do NancyFx and WebApi but not MVC5 on OWIN. I'm going to go fix that. Also, why not just use NancyFx for both the Razor and the web requests, no answer there either.
This pluralsight taught me a lot about Typescript/Angular together. [http://www.pluralsight.com/courses/using-typescript-large-angularjs-apps](http://www.pluralsight.com/courses/using-typescript-large-angularjs-apps) I think you have to come into it with a chunk of angular experience, the two may be a strange learning curve to tackle at once. After you learn to write Angular with Typescript. It's nice to be able to define interfaces for complicated scopes. I get to leverage Resharper so refactoring code is easier. The Typescript property syntax is really clean, so I end up using less of $watch easier. After some time it's not a hurdle to switch your brain from typescript/javascript, they really are very close to the same thing.
You can't host MVC5 on OWIN. This will come with MVC 6 (part of ASP.NET 5).
Depends on which platform you want to target. Let's just cross Xamarin out because its too expensive. If you want to do Android go with Java + Android Studio. 
And what do I need to learn to code the data from the server part? And how do I tie that in with the android app?
While cool, I was hoping to see something where you could mark a route with a `RobotsDisallowedAttribute` and have it appear automatically in the file :)
It's a nice idea but perhaps overkill for what is a text file of a few lines for most people.
I don't completely understand the options you're explaining, so I won't comment on whether I think they're a good approach, however, this point: &gt; remove all of my logic of my ASP.Net MVC part of my application and put it all at my WCF service Would it make sense to put all the logic in your model, then both the MVC controller and the WCF service could use it as-is? (There's also a possible discussion on whether you should just forget WCF and use MVC as your service using WebAPI)
Something that will get similar behavior is the [wrap panel](https://msdn.microsoft.com/en-us/library/system.windows.controls.wrappanel%28v=vs.110%29.aspx).
I see, so if I get the alpha blending right - I wont see ghostly images anymore?
Go to IDesign.NET downloads and get ServiceModelEX. You then want to use the "InProcFactory" to host the WCF service... in process. It will then be configured to use named pipes in memory transport instead of TCP or HTTP which are unneeded. You'll bootstrap the InProcFactory and your service inside a webactivator App_Start or global.asax. Make sure you use InstanceMode.PerCall with your services. WCF will manage its own thread pool entirely seperated from ASP.NET so you don't need to worry about WCF using threads, you pretty much never want to use InstanceMode Singleton or Session. I strongly agree with you in decoupling all logic from the MVC app. All you want is MVC to be a thin route driver that accepts http request and pumps them to your services. The only actions i handle in MVC are user authentication, putting or pulling data off the wire, serialization (optionally with content negotation) and very rarely minor view model manipulation (in all nominal situtations my logic services will return the exact data, shaped as needed). Note that authentication of a user is different than authentication of the service. You pretty much should never have a user auth to the service. Only your app should auth to the service. I never allow direct access to my WCF services, i expose http end points over MVC and use MVC as a proxy. The separate option is to use the Azure Service Bus to route trafic to your WCF services as you can use Azure as a DMZ and a user will never directly touch your services.
 &gt;Would it make sense to put all the logic in your model, then both the MVC controller and the WCF service could use it as-is? It absolutely does not make sense. The model should be a DTO with absolutely no logic. The Model View Presenter pattern espouses logic inside the model, not MVC. The MVC pattern is to be thin route drivers to return model data. The model at MVC would be the datacontract returned from the service. In general my MVC controller actions are: [GET("/account/{id}] //gogo AttributeRouting.net Public ActionResult GetAccount(string id) { var model = service.Get(id); return View(model); or return new Ok { Model = model } } Where success is an ActionResult that my infrastructure (read, global action filters or base controller) will return content as requested by the http accept parameter and in this case Ok, return a 200 http response. Note that my controller actions are specifically under 5 lines of code. 
You can call WinRT APIs from desktop apps. They may or may not work properly.
Then where do you put your business logic? Whenever I've seen MVC discussed, the prescription is to keep the controller thin, and the model represents your logic. Yes, the model might also contain thin DTOs, but you need a place to contain all your logic - and in the past I've seen that referred to as the model (ie; "business model"). 
I managed to do it by using Measure on the TextBlock and then comparing the desired height to the actual height. textBlock.Measure(new Size(textBlock.ActualWidth, double.MaxValue)); if (textBlock.DesiredSize.Height &gt; textBlock.ActualHeight) return true; 
Based on this I would suggest you swap out WCF with Web API and do some research into Auth Bearer Tokens.
What company is this? I like their reading list!
Hasn't Web Services been deprecated? I thought they were replaced by Web API.
Then you architecture different. Usually you use a repo class to call the db for the web and a repo class that call a web api in the mobile (these classes only call for data). If you dont want to repeat yourself you need to architecture your application, you can use EBI (bob martin example), with this arch. you only redo the views and you call a different repo class depending if it is mobile or web. 
&gt;Then where do you put your business logic? In discrete services that share a physical boundary. In order of most frequently used for tranport to the discrete service: in memory named pipes, message bus / service bus / message queue, tcp, and least frequently http. If an organization is really averse to SOA i'll settle on using an orchestrator/mediator class to bridge my control to my logic and data access code. &gt;Whenever I've seen MVC discussed, the prescription is to keep the controller thin, and the model represents your logic. The model should be the result of your logic, not the logic itself. &gt;Yes, the model might also contain thin DTOs, but you need a place to contain all your logic - and in the past I've seen that referred to as the model (ie; "business model"). Most people only know how to build incredibly monolithic apps with next to zero reuse and maximum coupling. 
Thank you. I did and spotted what the problem was.
Sorry I got to this late, but the html was as expected. Like others have said the issue was with the css.
Ah the effects of phone programming. All you need to do is InProcFactory.CreateInstance&lt;MyService, IMyService&gt;() and it will give you an active proxy/client to the service (make sure you dispose this object when done with usage). It will also handle the service activation on first invocation so you don't even need to bootstrap anything. I was mixing up bootstrapping other transports like tcp, service bus etc that need external connections to begin with.
You're absolutely right and that was the problem. I changed it to 225 pt and it works just fine now. Thank you so much.
[Code Complete.](http://www.amazon.com/Code-Complete-Second-Steve-McConnell/dp/0735619670/sr=1-1/qid=1169499581?ie=UTF8&amp;s=books) Oh and I am in the same boat as you. The place I work for considers all tech second. I have literally become a worse programmer. Another thing that may help you is the site Code Wars. And finally, start watching some projects on Github. You don't have to contribute but it does help you look at how other people are doing things.
*edit* removed - see other comment.
 &gt; encode the fundamental, unchanging relationships between business elements into the type system. This under states the number of unchanging relationships in a business are absolutely minimal. This can be quite different for a library/framework where you can have core assumptions and even with correct application **force** them to be used. You can't ever tell a business they can't change in their business. Now that's not to say code for the asinine, like a bank drunkenly deciding they want to do farming. 
The list comes from http://www.magretailgroup.com/ :)
Currently only done the ASP.net MVC authorization with Forms authentication I red from tutorials. But to be honest, I'm not quite happy about it as I'm quite sure there is so much extra about this subject in .Net. It works yes, but I always thrive to learn as much as possible as well instead of making things just work. That's why I started this post, in order to rethink about things and perhaps might encounter things I haven't seen before. 
Try Bob Tabor's website, where you can learn C# and .NET from the ground up, with tons of videos and small projects etc. (I purchased the lifetime membership for $159): http://www.learnvisualstudio.net/
But isn't a cookie causing problems for non-browser applications later on? 
Just used the DayPilot scheduler (JS version though) for an Angular project of mine, and it's stupid quick. The features in it as well are pretty amazing. Can only assume it's the same for Asp.Net, would definitely recommend trying out their free version of it. 
Yep. Basically, you're abstracting the database away behind an API, and that system sits separately from the rest of your application. Then, all your application has to do is call against that API. Additionally, if anyone else ever needs to get at that database, they can just code against the API as well. 
&gt; EF is a repository, but I wouldn't drop a repository layer! If implemented properly as a UoW it will help you unit test alot. There are other patterns that are much better at this than a repository. &gt;Plus it's not the responsibility of the service layer to manipulate the DB. Depends entirely on the app and it's complexity. Edit - Also, EF would be manipulating the DB, not the service layer.
Thanks peeps, I understand.
Ah the ambient UoW pattern, every mid level programmer's dream, and every expert's disgust. 
I'm also going to ask, is there a reason you are using 2013 over 2015? If you have MSDN you can upgrade, and its got a better free version (community) than 2013 or previous.
Instead of just saying thats a bad way to do it, list other ways that you believe are better.
&gt; There are other patterns that are much better at this than a repository. What do you believe is the better pattern is what I'm asking :), I think thats why you are getting downvoted is you are just saying "you're doing it wrong" without saying "heres another way, and this is why its better".
Back then? Google. If I were to do it again today, I'd use Pluralsight.
Thanks. I will take a look at this.
Check your requirements. Does it support Integrated Active Directory authentication? Role-based authorization?
&gt; You should use it over an MS-provided solution because if we let Microsoft trample all over every corner of .NET, we will never have a healthy ecosystem like... That is really healthy reason. Let's use a solution over the Microsoft solution for the sole reason that it's not a Microsoft solution.
Nearest MS equivalent is Web Api 2 for creating a web service only project. Create an empty web project and check off the include web api core option and you get a very stripped down project. http://www.asp.net/web-api/overview/getting-started-with-aspnet-web-api/tutorial-your-first-web-api
It is simply the opposite of "let's NOT use a widely-used, community-supported solution for the sole reason that it's not a Microsoft solution." Just bringing some balance to The Force, here, and ensuring I participate in a diverse community that isn't afraid of innovation.
Seems ever successful .NET produce with a web backend I've used lately uses Nancy over WebApi. One thing I'd fear, and I feel awful I fear it, is the time to ramp up new hires to Nancy. Harsh reality is most candidates stick strictly to what MS produces and you might encounter some friction from weaker, but sadly the only available, potential hires.
While this is a good thing, it is absolutely not an argument for or against a framework/library. We are professionals, not missionaries.
No kidding. I guess RyuJIT must not aggressively use tail call optimizations.
UoW on top of EF is an anti-pattern. EF is already a UoW, and adding a second one increases complexity with zero benefit. The *ONLY* reason to do this is if you have multiple data sources that need to be unified in a single dataset with UoW capabilities, or it was likely that you would replace the data access layer with a layer that doesn't provide a UoW natively (this tends to be a YAGNI situation, since virtually every app I've seen where they made this claim, they have never changed the data access layer). Even Microsoft no longer recommends using a UoW (which, for the longest time they did). That's not to say you should call the database directly from your UI or business layer, but there are other patterns like service façade, or even a concrete repository (not a generic one) that are better approaches for most people.
Nancy is nice. I like it a lot, but you're not going to have any where near the level of support, documentation, and other devs that know it as you would in MVC or WebApi.
Certainly, but when OP is coming in with "tell me why I shouldn't use this perfectly fine framework and use the Microsoft-supplied one instead." And the answer is "if you want to use the community one, use the community one." Also, I am both a professional and a missionary.
For any dev who understands how the web works , Nancy is trivial to learn. Any new hire worth their salt should not take more than a couple of hours to learn it.
I don't think that's the argument. The major premise here is: if you want a healthy ecosystem, you should pick tools that weren't released by Microsoft. Honestly, I'm not sure what a "healthy ecosystem" would look like, though. If your only criterion for a platform's health is "it's open to extension by anybody," then great -- we now have that on the MS stack. OWIN is awesome, and the core is adequate.
What I don't like is that Microsoft's various tools and frameworks are also sales tools. Hanselman goes, "Look how easy it is to create a great web app using EF, MVC with strongly typed views, and ASP.NET Identity!" Then the dev manager goes, "Oh yeah! That's what we need! We'll have this stuff done in no time!" Then it doesn't work so well: IIS is a hog, EF generates garbage, etc. This is not an argument for or against non-MS frameworks. It's merely encouragement to not base your decisions on the ease of a tutorial. In other words: it's not about the ecosystem. It's about people making lazy decisions.
We're using NancyFx with the Razor view engine and are pretty happy with it. We do miss the ~~crutch~~ helpful autocompletion that Intellisense provides, but we've yet to encounter anything that keeps valid Razor views from working. We may consider switching to MVC6 when it is released (hence the choice of Razor over the default view engine), though.
Personal preference; I find WCF to be heavy on configuration and transport, especially when used where Web API could be, to build RESTful services.
Looks like you are trying to maintain the DRY principal. But the repository pattern isn't the only way, you can also leverage the command pattern to wrap that code together in an object to use in multiple places.
I was using NancyFx a couple years ago, and I haven't touched since. My gripes from where it was then: 1. constantly shifting api breaking all sorts of stuff. 2. not great documentation. Again, that was about 2 years ago. Since then the documentation has improved quite a bit. But I'm not sure about the api stability. It helped that my coworker did the PluralSight videos.
Gu literally works for Microsoft.
So does Hanselman 
Am I the only person out there who does not mind IIS?
I been using Nancy for the last couple of months and the documentation seems good. Besides that you can always get a nice support at Nancy's GitHub page.
&gt; I work out of my home office in Portland, Oregon for the Web Platform Team at Microsoft True, thanks for the correction.
I wrote this a while ago which may help you. http://blog.jonathanchannon.com/2012/12/19/why-use-nancyfx/ Personally I have invested a lot into Nancy and use it daily as part of my work. Nancy seems to be the only stable alternative HTTP framework for .Net, others have come and gone. Web API seems dominant because you knows its from Microsoft so "all hail the claw!" (Toy Story ref) We try to be supportive via our documentation and chat room - https://jabbr.net/#/rooms/nancyfx so please come in and say hi. For me I prefer Nancy over WebApi as its much simpler, its actually enjoyable and you don't find yourself fighting something once your app becomes complex and you need that little something to just work. Also bear in mind ASP.Net 5 has taken a lot of influence from nodejs as well as Nancy so I'd rather use something that is influencing rather than influenced. I know this post has been the opposite of why you shouldnt use it but just thought I'd put some points in why to use it and to also champion a superb community project. 
The other big advantage is it forces separation of business and display logic. Your service owns the business logic and the display is built on the answers it receives from the service. It can be done without services but its so easy to key off of visibility or to make assumptions based on UI behavior that work until they don't. A large part of my day job is fixing this very mistake. 
As well as this, how many project are in the solution? And what computer is it running on? 45 seconds seems way too long, even for a potato. 
I just did this. Basically you create all the tables in your DB (including all relationships and stuff). Then you add ADO.NET Entity Object, select "Code First from Existing DB" and it will haul off and create all the models you need to interact with your DB. Idk if that is what you're looking for, but it is really, really straight forward. Also, I believe in the next version of EF it will be all Code First. 
If you're a huge SQL guy - I HIGHLY suggest looking into Dapper instead of EF.
If you are just altering .html, javascript or anything not compiled, keep the project running and just save the changes in VS and refresh the browser.
Changes to cshtml files (Razor view engine) don't require any recompilation, unless there are underlying model changes. You can save changes, refresh the page and immediately see your changes. JS absolutely needs no recompilation. Are you working on a Web forms app targeting an outdated dot net framework or something? 
I think you should go with whatever framework feels most comfortable for you to work with. They can all get and post.
I'm not gonna spoil everything for you, but it's not lazy. You should take a look at the code, I find it quite clever. I like your uncertainty idea... that could be useful.
Like others said if you're not editing compiled code there is no reason to rebuild. But if you are editing compiled code, what I do is run the project using IISExpress with the "Enable Edit and Continue" option checked in the project settings. You can then change lines of code as you are stepping through. 
JQuery would be easiest for a POC. Pretty straightforward and very manual. I loved Angular with Web Api. They make a nice pair. 
I agree with Angular and Web Api. I have, however had equal success with JQuery and Knockout, so it really depends on what you're doing with the front end!
If your looking for quick consumption of Web api without replicating your models on the client, I'd recommend breezejs. There's a ton of examples using .net and Web api there. Obviously a little bit of a learning curve involved but it's made my life easier
As others have said, changes to views, css, js and other client side assets doesn't require you to do a build. As for compile time I have a 35 project solution at and it takes less than a minute to compile on a modern end i5 with 16gb of ram and a traditional HDD. Simply put a more powerful machine is needed. SSD discs are also a massive speedup for compiling. However unless you have a monster solution like myself it shouldn't take that long. 
I am currently building an AngularJS client app on top of a webAPI backend. It is going really well, and I can highly recommend this stack.
I think Tim Barcz would be a good presenter - he was an early adopter of OSS software for his company - https://twitter.com/timbarcz 
43 projects. I added more info to my post. Hopefully it helps to pinpoint my problem.
How do I know what's needed or not? Also, I added more info to my post. Hopefully it helps to pinpoint my problem.
I think you still need to use the physical path to the file. that is, @"C:\project\folderName\somefile.wav"
He said his compile time is 45s. Which seems about right honestly.
I just meant the images I was using were not needed. I have a product catalogue with images for every product, these images will be used when the site goes live, however for development they were slowing VS down to a crawl.
Yeah, I've used ef7, but I ran into a huge problem with its handling of number data types which made it unusable for my legacy DB. Dapper worked like a charm though. I also enjoy that I'm not heavily investing into using EF, because in the future my sql queries are going to be way more portable than EF code. 
A couple points of feedback. ---- sbyte[] Powers { get; } Prefix[] Prefixes { get; } It seems that these quantities are related - each power element describes each prefix element. If that's true, then that means that you're using simultaneous arrays, which are not always a good idea (though, sometimes they are). Instead, consider storing those two items together in a struct; structs have zero extra memory overhead, and when allocated in an array, are all collocated in memory; if you combined those into properties in single class, then each class instance is scattered to the wind on the heap, and it requires an additional pointer lookup to access each element. ---- public Unit(double quantity, BaseUnit baseUnit, sbyte power = 1) { this.Powers = new sbyte[7]; this.Prefixes = new Prefix[7]; What's up with the hardcoded sizes? ---- public int CompareTo(Unit other) { if (IsComparable(other)) { var power = Power10Difference(other); return (Math.Pow(10, power) * Quantity).CompareTo(other.Quantity); } throw new IncomparableUnitsException(this, other, "There you go mixing them again..."); } This is a matter of style, but this breaks fairly widespread convention. Consider writing this as follows: public int CompareTo(Unit other) { if (IsComparable(other) == false) { throw new IncomparableUnitsException(this, other, "There you go mixing them again..."); } var power = Power10Difference(other); return (Math.Pow(10, power) * Quantity).CompareTo(other.Quantity); } Writing it way makes it obvious, up-front, what the contract of that method is. If that method had been longer, it would have been less obvious. If you ever decide to use Code Contracts, you'd be required to do the same regardless. ---- public Unit Pow(double power) { if(Math.Abs(power) &lt; 1) { var reciprocal = (sbyte)(1/power); if(Powers.Any(x =&gt; x % reciprocal != 0)) throw new DimensionSplitException(this, "You can have only integer powers"); } ---&gt; var powers = Powers.Select(x =&gt; (sbyte)(x * power)).ToArray(); Depending on the goals of your project, you might want to reconsider restructuring this to not use Linq. The above statement causes at least one more allocation than necessary - the linq statement will allocate and return an IEnumerable, which you then immediately throw away after converting it to an array. ---- public string ToString(string format, IFormatProvider formatProvider) { format = (format ?? "").ToUpperInvariant(); bool fancy = !format.Contains("C"); // common formmating bool useDivisor = format.Contains("D"); // use '/' bool baseOnly = format.Contains("B"); // base units only By using `ToUpperInvariant()`, you're performing allocations just to perform comparisons. Instead, consider using `CompareInfo.IndexOf()` from the culture provider. Here's a helper I tend to use: public static bool ContainsIgnoreCase( this string corpus, string key ) { return CultureInfo.CurrentCulture.CompareInfo.IndexOf( corpus, key, CompareOptions.IgnoreCase ) &gt;= 0; } Which should perform zero allocations to perform the comparison. 
This will play the sound file on the server. When you're developing, that's your local machine so it appears to work. Once it's deployed, that won't be the case. The sound file has to be somewhere that the web page can access it (hosted under your application root, most likely) and then you need to figure out how to load and play it in the browser, probably in a JavaScript handler for the button click event.
Some more comments (new post since my last is a little old): var volume = new Unit(8, Prefix.k, BaseUnit.m, 3) You should consider changing the names of the Prefix and BaseUnit members (eg, "k") to be more descriptive - Kilo and Meter, respectively. This would make it much more obvious what's being talked about, especially when you get very long, complicated compositions of these units - just scanning for keywords, it's very easy to get confused (*m? is that a meter, or mega? Oh, it's being passed as a unit, so meter.*). Just because those are the standardized shorthand names of these bits doesn't mean you have to use that in your code members.
If it is a green field thing then why not MVC? Easier to get developers, no one wants to be doing web forms nowadays.
The main reason not to use Nancy Fx is because if isn't what Microsoft provide out of the box and most devs will have a hard time dealing with you custom stack built from micro-frameworks. There is something to be said about keeping everything as standard ... People can Google a solution. Custom framework ... The impossible, there is going to be a massive learning curve.
Just wanted to say thanks for working on Nancy - I also use it (almost) daily. I also wanted to say thanks for contributing to the .NET OSS community, such as it is - we need more good projects like yours and all of the "just use what Microsoft gives you" people in this thread aren't helping matters.
A healthy ecosystem isn't just "it's open to extension by anybody." It's "somebody/everybody actively extends it." The massive shadow cast by Microsoft makes it difficult to start a large open source project in .NET, since everyone is afraid to use anything that isn't provided by Microsoft. Exhibit A - this thread. If you do wish to innovate in C# and start an Open Source project, you will have trouble attracting many contributors because, again, 'Microsoft gives me everything I need.' And thus the project dies. And the language stagnates until Microsoft decides to innovate by itself.
This has all been written before, but much more tactfully than this tit did.
thats awesome! i love to see technology evolving with the times
There is two reasons why this attitude is prevalent. 1. The problem is that a lot of places that have invested in .NET have been burnt by developers choosing "framework of the week" or have written their own framework. Once they leave others devs are supporting a leaky boat. So lead dev teams tend to agree not to go too far "off road" and keep everything as standard as possible. 2. ASP.NET started off as something very proprietary and was and still is used for things like Intranet sites and bespoke business applications. Unless it is something endorsed by Microsoft, managers aren't likely to allow you to use a certain technology because it hasn't been approved. While both of these reasons are sucky it happens all too often because there are a lot of flakey .NET devs out there that never really push themselves to become better developers.