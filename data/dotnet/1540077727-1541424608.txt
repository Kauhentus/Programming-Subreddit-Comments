I started creating a 'Filters' class containing strongly typed properties for each column I might pass in a parameter. Combined with the [SqlBuilder](https://github.com/StackExchange/Dapper/blob/master/Dapper.SqlBuilder/SqlBuilder.cs) that comes with Dapper it's easy to build strongly typed queries (as long as you get the filtering right in your Repository the first time). This also addresses one of the huge drawbacks of Dapper (over EF); the that you can't use Linq over your result set and have that auto-magically translate to a more concise result set from the database. Using filters the way I describe somewhat mimics that, allowing me to do something like: var result = MyRepo.Get(new MyFilters() { Id = 'abc', X = 'Y' }) And have those filters passed to the database as a where clause. 
What you are asking dose not make a lot of sense. What do you mean by store information? The client posts data, the server returns data. HttpContext is not usually used to ‚Äústore data‚Äù. It does contain data from the client but normally, data you want from the client would be posted to a controller as a variable. Data sent back to the client is usually sent as JSON, XML or HTML and consumed by the client. 
 &gt;you're basically hacking the LINQ syntax until it generates sane SQL statements You do know that you can run regular SQL with EF in almost the exact same manner as with Dapper right? ` using (var context = new BloggingContext()) { var blogId = 1; var blogs = context.Blogs.SqlQuery("dbo.GetBlogById @p0", blogId).Single(); } `
This is simply not true as HttpContext is the library containing the session management tools which do store data in variables as long as the users session is valid. The item variable will be deleted after the code is executed instead of the length of the session. 
IDK. In .net framework apps session information could be lost. Also it is unavailable in async operations. Is HttpContext the correct way to persist data in .Net Core? I would think it would not be, but I could be wrong.
My guess is it would be considered appropriate usage depending on what that usage is. You'd need to be a bit more specific, but for single execution such as storing data from the DB for client validation, storing it as an item would be fine (depending on the logic) as it's a single use variable. Also they won't be viewable (assuming your severs are properly secured) as they would only be used in the block of code they are executed in (this is where encapsulation comes into effect) server side and not returned to the client unless you explicitly pass that data back to the client via the model or whatever method you're sending data to the client. If you're wanting longer term storage, you'd be wise to consider sessions for server side temp storage, and for anything that you want stored after the user closes the page/ends the session, you'd want to use something like JSON or a database.
 - **Is HttpContext.Items viewable to the user?** Nope. Never. Unlike e.g. ViewState in Asp.net, Cookies, or local storage, all information in .Items is destroyed upon the completion of the HTTP request. There's no persistence anywhere. If you make three Ajax requests, you'll get three fresh copies of .Items in each. - **Is HttpContext.Items secure?** Yes. It is a Dictionary that lives in the running application's scope, and is recycled when the request is deconstructed. It may not be considered cryptographically secure (i.e. it isn't guaranteed to zero memory after free) but that is often outside the exploitable scope of .Net (unless you're playing with unsafe code/direct pointers). I'd happily store anything in it that the request would otherwise have access to, with the exception of plain text passwords and private keys (they shouldn't sustain longer than absolutely needed anyway, and certainly not in places accessible to every piece of code with HttpContext access). - **Should DBContext be stored there?** Eww. I mean, sure, it will function just fine. There's no technical arguments against it at all, it is just an ugly practice. Long lived DBContexts are poor form anyway that scale poorly and make unit testing difficult. You should consider using a uhh using(){} block for DBContext, the object cache survives new instances, you aren't holding a connection open, and aren't leaking context state/tracking info from one place to another. I personally like using .Items as a per-request cache. For example we have a giant application, there's a database package which returns two dates (start and end date for the current period, think fiscal quarter but *not that*). We want it in the database package as a unified place. Problem is that layered ten layers deep in method calls we wind up calling this same package six, seven, eight times in a single request. It is idiotic. Even with aggressive database caching there's still a cost. In an ideal world we'd restructure all these methods to consume the two dates and be done with it, but until that occurs we just cache the two dates into .Items, return that if it exists, and look it up if it doesn't. Now we're looking it up just once no matter how much the code sucks (with the cost being just a single Dictionary(string, Tuple&lt;DateTime, DateTime&gt;) entry). Do I recommend having bad code and hacking around it with .Items? *No*. But it is a useful tool if you find yourself in that situation. 
They are probably wanting to load some permission set in an Authorization Filter and load it when the controller constructor or something like that in an older version of the framework. 
You parsed that from the OPs question?
My biggest problem with EF is that it‚Äôs a bitch to set up. The main reason I learned C# originally was because I got tired of using Java for things I wanted to build once and run anywhere with great performance. EF (Core anyway) feels like something that was designed for Java with all the extra tools and ceremony you need to get something running. This isn‚Äôt such a big deal for large scale projects but when you want to write a simple program to process a lot of data, it‚Äôs easy to spend more time setting up EF than actually writing the program, which is so Java it hurts. 
&gt;However, many web forms projects I've come across were a mess of spaghetti code. This. Web Forms can signal a few different things. * They don't understand MVC and were too lazy/uninterested/rushed/etc to learn it. * They came from a Windows Forms background and thought this would transfer to web. * They genuinely though Web Forms was a good choice. Any or all of those are pretty terrifying. I'm sure there are good Web Forms projects out there but I would be money it is less than 25% of them.
Pluralsight and Udemy have great courses. Microsoft has good documentation and some free courses as well. 
Same here. Reading that was almost enough to trigger my Web Forms PTSD from refactoring all of the update panels out due to dogshit performance (some due to bad implementation, some because update panels were/are shit).
I would largely disagree with this. As an example, I'm a big fan of having a set of DTOs that are completely distinct from my domain objects. That way, I can modify my domain objects without having to change my DTOs which would lead to versioning my API which would lead to clients having to update to a new version of my API. For the first release, my DTOs almost always match my domain objects. Should I manually write mapping for all of those? That would be thousands of lines of code that has very questionable business value. Over time, you can create more specific mappings as your DTOs and domain objects drift apart. When they drift too far apart, you version your API to v2, simplify your mappings back to automapper, and you can delete any of your mapping code. Maybe I'm missing something or over-complicating things?
&gt; or near-zero-allocation byte massaging Is that a .Net Feature?
have you developed only demos in your life? LINQ can't do shit without full table scan
Apologies, for the lack of detail I was trying to keep it general as I not written anything yet. What I trying to achieve is in my dbcontext is apply a global filter to limit the data turned to just the customer/tenant id. ie: modelBuilder.Entity&lt;ToDoItem&gt;().HasQueryFilter(b =&gt; EF.Property&lt;Customer&gt;(b, "CustomerId") == _customer.CustomerId); Now the issue is populating the _customer. Looking at example people have done, some people have written their middleware to store the Customer object in HTTPConext.Items and pull it on the dbcontext constructor like this: public DataContext(DbContextOptions&lt;DataContext&gt; options, IHttpContextAccessor httpContext) : base(options) { if (httpContext.HttpContext != null) { Customer customer = (Customer) httpContext.HttpContext.Items["Customer"]; _customer = tenant; } } I was wounding if a valid way of achiving this. 
No. Just a result of the new Span/Memory APIs. It was possible before, but the new APIs make it easy enough to be viable. 
Might try it, could use a massage ;)
[Grapecity](http://demos.componentone.com/gcdocs/gcpdf) has a new product called Grapecity Documents for PDF and Excel. Fast pure .net core packages, available on Nuget. Full demos with source code.
It has disadvantages, but unless you're structuring your queries badly or need to do something weird, you should be able to take advantage of indexes.
I don‚Äôt know honesty. I don‚Äôt have enough experience with HttpContext.Items and filters. Can you have different Customer Models that inherit from a base class. One model has all the sensitive data, the other is limited. Then just add authorization for consumers of the class with sensitive data?
Not hard if you have done it before üòÜ
This: [https://www.nuget.org/packages/GrapeCity.Documents.Pdf/](https://www.nuget.org/packages/GrapeCity.Documents.Pdf/) generates PDFs, and works on all .NET Core platforms including Linux. Word to PDF (using the above product, also works on Linux): [https://www.nuget.org/packages/GrapeCity.Documents.Word/](https://www.nuget.org/packages/GrapeCity.Documents.Word/) The NuGet descriptions have links to live demos, check them out. HTH.
I ran into this error again running this code - I'm doing the globals thing a bit differently, which fixed it for a bit, but for some reason it broke again! import sys, imp; import __builtin__ as builtins; builtins_code = """"""; exec builtins_code in builtins.__dict__; import clr clr.AddReference('System.Core') import System clr.ImportExtensions(System.Linq) import FrEee import FrEee.Utility clr.ImportExtensions(FrEee.Utility.Extensions) from FrEee.Modding import Mod from FrEee.Game.Objects.Space import Galaxy from FrEee.Game.Objects.Civilization import Empire 'Generates ' + str(ShieldPointsGenerated) + ' phased shield points.' I'm getting a NameError on `str` here...
Now, you didn't point to the source you found. Assuming the source you refer to is part of the templates that allows login/authentication from a browser, my guess would be that client side validations are skipped, while the server will function as usual.
Thank that was usefull. Do you have any other suggestions how best to go about filtering data for multi tenant application instead of httpcontext?
ASP.NET Core MVC is a server side framework so I very much doubt that jQuery plays a very big role in its source code. You're probably looking at one of the templates that contains boilerplate example code to get you started quickly and see what capabilities the frame work has when interacting with frontend code. I'm not sure if the authentication functionality in the template will "fail completely" but I'm pretty sure they did not put a bunch of dependencies in there just for fun, so some pieces of the functionality will surely be affected.
You can ditch jquery, it's not required what so ever it's just added by default to give you some extra polish from a template app (client side validation).
ASP.NET MVC can run at 100% effectiveness with JavaScript turned off entirely in the user‚Äôs browser. Even things like form field validation, which can and does make use of Javascript for client-side validation, can be turned off entirely and validation will degrade quite nicely to the server side and still function completely there. And, IMHO, that is how you should build *any* online service‚Ä¶ start server-side, build it out with 100% base functionality regardless of client capabilities, and *then*, and only then, extend those functionalities to handle server-side pain points and enhanced usability via client-side interactivity. That way you end up with the best of both worlds.
I know a lot of older texts advocate for the idea of "graceful degradation" so that a Web Application can work even with JavaScript turned off. The idea being that you wouldn't get fancy animations, but the page would still work. Frankly, with the rise of libraries like Angular and React and the shift toward Single Page Applications where the entire client side is written in JavaScript as a first class language, .NET is only there to provide an API. I'm not sure that I could justify the expense of putting together an entire fallback user interface for the 0.0001% of users that have deliberately disabled JavaScript. I think the newer thinking is essentially "turn your script on or leave."
You are dismissing a significant minority of web users who are unwilling to download 10,000kb of libraries to display 10kb of content. And while I consider plugins like NoScript to be an overkill reaction, I know plenty of people who use it as well.
You're entitled to your opinion, but if somebody has built their Pizza store application in Angular or React, it's unlikely that it would work with scripts blocked, and I don't think they would build an alternative JavaScript-free UI just for people who run NoScript.
I'm not sure why /u/rekabis stopped at Download size... it's not the only concern in play with SPAs: * The source code for the entire JS side of the SPA is visible to users, including the malicious ones. * As such, you'd better not being doing anything in the JS side that you're not OK with clients tampering with... such as money calculations. * Your application's performance is going to be heavily dictated by what device the client is using. Those are just the things I can think of off the top of my head, too.
jQuery is not requirement for [asp.net](https://asp.net) core. There are some templates that have jQuery with bootstrap but it is not required for [asp.net](https://asp.net) core. You can run [asp.net](https://asp.net) core without using jQuery and it'll work just fine. In case of forms, the client side validation will not be available as a result but it'll degrade to server side and [asp.net](https://asp.net) core will handle the validation.
[removed]
You‚Äôll need to mount a volume `docker run -v /host/path/to/certs-dir:/container/path/to/certs-dir -d -p 80:80 -p 443:443 myrepo/mywebsite`. 
I mean you probably shouldn't be trusting price calculations from a client anyway so... 
&gt;The source code for the entire JS side of the SPA is visible to users, including the malicious ones. &gt; As such, you'd better not being doing anything in the JS side that you're not OK with clients tampering with... such as money calculations. ... How is this not a given? Of course you don't trust the client to do anything that has to be secure, that was a thing before SPAs and it's still a thing now. 
You shouldn't use Kestrel as a production HTTP server. Instead, install Nginx or Apache on your VM (or run them via Docker), configure certificates for such server and by using reverse proxy redirect the traffic to your app.
Recommendation to not use Kestrel as production server without reverse proxy is outdated since ASP.NET Core 2.0: [https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel?view=aspnetcore-2.1#when-to-use-kestrel-with-a-reverse-proxy](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel?view=aspnetcore-2.1#when-to-use-kestrel-with-a-reverse-proxy)
I wrote a super simple authentication example project that covers both forms and api - no jquery used with either ... &amp;#x200B; [https://github.com/matthewblott/simple\_aspnet\_auth](https://github.com/matthewblott/simple_aspnet_auth)
Why? I've been using Kestrel directly as a production server for the last two months and I haven't had any issues
I'm sorry I'm not super certain about running winforms on Win10 IoT, but I do know that UWP is built for Win10 if thats something you are able to consider. There is a thing called Desktop Bridge that might be something to look into, as well.
We were using VS 2017 native Win 10 IOT development was pretty good no major complaints. &amp;#x200B; Now, however I caution using Win IOT , we switched mid development to Android , Honeywell and Zebra have basically abandoning WIN IOT, even paid to get our few Win IOT CT50 converted to Android . Honeywell actually now has gone so far as promotion of their hardware able to support Android OS versions out 5 cycles. I am in the midst of learning and development our handheld system in Java Android Studio ... even though we are a Microsoft house Xamarin seems to be more problematic than Android Studio... even though I had hoped to say here is IOS, Win IOT and Android support due to Xamarian but only officially support Android Devices but my resume would have Xamarian multi platform development. &amp;#x200B; For me, Both have sucky RAD GUI development you can drag the buttons on the form not matter you layout you will tweak the XAML/XML layout file , C# and JAVA have 15 ways to accomplish the way you HAVE to do this like calling a RestAPI I have successfully done but seemed to REQUIRE I do the call in a THREAD. &amp;#x200B; I also later noticed Xamarian simple 1 form with very little code, 9 meg APK... Android Studio witih 10 forms and 6 fragments , Code,Models and SQLLite Database with Key Tables less than 3 meg APK. &amp;#x200B; My situation also dictates that the software doesn't have to change must, it about Hardware Support we ran a C# Win Mobile 5 app for years on IPAQ to Motorola Handhelds but hardware is only available now for Win CE (extended maybe even ended by now) , MObile 5 support long dead we survived on buying used for longest time... IOS was basically out of question, Little to no battery Swappable devices nor super Industrial Devices, and Win IOT being basically dropped forced me to go Android Devices, I didn't listen but my vendor actually called me 6 month prior suggesting the future was hazy for Win IOT support from Honeywell, then he called and said I have some used units and new units you can get this now cheap but don't expect to much future when they are gone they are gone... so I was like crap time to change over, because I can go android and live out 10 more years and retire :-)...
Winforms won't run on IoT, as IoT really only supports UWP for UI. I'd start with the overview [here] (https://docs.microsoft.com/en-us/windows/iot-core/develop-your-app/buildingappsforiotcore). You might also check out /r/windows10iot as there are a some links on the sidebar for getting started depending upon which board you are using. 
You might struggle to find good documentation and community examples in [VB.Net](https://VB.Net), I'd advise moving to C# for better support. I got tired of translating online resources to vb and switched to c# a few years ago. For the gui though I think you might need to look into XAML.
To me, VB and C# are the same. I can look online for examples in C# and easily write that in VB.net if I need to. The applications are currently written in VB so its just what I gravitate towards. I could go C# if I saw a real benefit.
Dapper is a more concise way of doing parameterized queries.
I'd do some serious testing and research before investing much time in IoT. I did one small project and the available memory in IoT was a serious problem (and as pointed out, there's not much in the way of hardware available). IMO, it appears that IoT was designed to build really low power things, and not really as a replacement for a CE or other handheld OSes. If you aren't interested in Android (the route I went as I already developed for Android and iOS along with .NET), then I'd look into Windows tablets. Your app sounds like it would run just fine as a UWP app on a desktop Windows 10 Tablet, and you'd have much better control over the device, and much more powerful hardware available. 
Fair enough, I only switched because I was learning asp.net and every example and tutorial was c#.
Right just dick around until you either rewrite it in SQL or finally found the magic incantation that generates sane SQL for a join just slightly more complex than absolutely basic. \&gt; assign the ticket to a EF pro Ah let's hire one \&gt; have a DBA take a look at the queries Or hire another guy. Apart from the fact that the SQL itself isn't that hard to write thank god I wouldn't need to pay for that at least. \&gt; Every argument I hear against EF is a pretty weak argument. You sound like the guy that does not pay the bill for all those experts
Make sure to assign different TCP-ports for each project, before startup.
Why not just publish all your projects to the same webroot and then attach to process? This is used a lot with sitecore cms (the practice is to use a gulp script to publish all projects )
Use source link. It may help you tons ? 
My reason not to do this is that I've never heard of a webroot. 
In fact "MVC" doesn't even appear in this page. It has nothing to do with MVC and when interviewing someone for an MVC position (or any modern web-dev position), I wouldn't care if they didn't know most of these answers. 
Very misleading title. 
That's template code, it works without jQuery if you want to. I would never add jQuery to a new website unless I had to support ancient stuff. I use vanilla JS unless there's a pressing reason to not do so and I usually get away by going framework less unless I'm already using a larger framework for doing single page web applications.
What? I can have EF up and going in a project in about 10 lines of code. You don't need to use the tools for migrations at all if you don't want.
It can generate horrendous queries, but I have found there generally always a way to structure a LINQ query to get what you want. There are a few things LINQ can't do, like window functions. But outer joins and whatnot? Easy.
Yeah? Can you share code for a full outer join in LINQ? I would love to learn something new today. 
I haven't looked into the code for Sitecore, so a little confused. You really use the publish functionality in order to debug? That sounds... peculiar, to say the least. Choosing multiple project to run on startup seems more logical to me.
We've moved to [Docentric](https://www.docentric.com/) for Word/PDF creation. Great support and no legal shenanigans. And, they just released a .NET standard version of their tools. Highly recommended.
&gt; One thing I noticed is that it seems IIS doesn't understand the &lt;aspNetCore/&gt; node within the web.config. When I try to open any of the options, or configuration editor within the IIS Manager, it throws a 'The data is invalid. (Exception from HRESULT: 0x800700D)'. So when starting the site, are you getting a 500.19 error or a 500.0 error? 500.19 means there is a configuration error, which seems more likely based on the error you described. From what I can tell, your web.config looks correct. Also, look at the Event Viewer for any application error. Here are some docs about hosting aspnetcore behind IIS [https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/iis/?view=aspnetcore-2.1](https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/iis/?view=aspnetcore-2.1). If you can't figure out the issue still, feel free to file an issue here: [https://github.com/aspnet/IISIntegration](https://github.com/aspnet/IISIntegration)
Thanks for the reply. I'm not sure what 500 error it is, as it is just this: https://u.teknik.io/XtJHb.png And there is nothing being shown in Event Viewer. I'll also file an issue on the repo to see if they have any more insight into it.
Set stdoutLogEnabled to true and see if the IIS tells you anything important. Post your Program.cs and Startup.cs and maybe we can spot potential causes.
Sorry, I forgot to mention I did try setting that to true, but it wasn't logging anything. I'll have to post those files later today when I get access to them again.
CodeDOM is still supported in 4.6. What specifically isn't working for you?
I‚Äôll PM you my code later tonight if you‚Äôre able to assist me. The exception thrown is very vague and not helpful. In fact, it doesn‚Äôt even tell me where the exception occurred line wise, it only tells me it was thrown inside of my compiler script. And I‚Äôll check the link out and do some research, I‚Äôm actually quite pleased with CodeDOM and already have my custom mod tools up and running to support modding for it. I assume changing implementations like that would mean rewriting my entire modding codebase.
I love Razor. And even in the days where it was difficult to use Razor on its own. I made it work, there were no excuses. And it was the best decision. Thanks for hard work ! 
Why bother setting all that up when you can just start multiple projects though? This doesn't make any sense to me. Is there any advantage of doing it like this?
As far as I know, you can't have two versions of the CLR loaded at the same time. 
We had a case where logging folder has to be created manually because the process didn't have rights to create it.
If CodeDOM works in 4.6 then why do you think setting the API Compatibility Level to 2.0 required for it to work?
Stockholm syndrome
Yea, I manually created it as well. As I added above, it looks like the error being thrown is a config error: https://u.teknik.io/w82Hl.png
&gt; You sound like a hobbies who has never worked at a large company. OK, if you force my arm: it was Getty Images. But perhaps they just don't work at the same scale the super huge company you apparently work for? We only managed to do eight releases per day while keeping hundreds of ASP.Net projects in sync with about 100% test coverage with 0 downtime with millions of visitors and I guess billions of assets, that's clearly nothing compared to Big Internet Dick Co where you work of course. I simply listen to what my customers want to see, build the screen according to their specs and every time it gets just a bit more complex LINQ starts to be a problem not a solution. ASP.Net is way too static to respond kindly to hack first fix later. That's why it got replaced with RoR at Getty. If you're going to cover with 100% tests anyway it's not such a huge problem to use a weakly typed language.
[removed]
You referred to outer joins, of which left and right outer joins are no problem. In 15 years of professionally writing .NET code I have never needed nor wished for a full outer join. Instead in the few cases where I have desired that behavior I just used a union + group by instead. But that's not to say you didn't find a case where it did make sense (and all that null handling and weirdness makes sense!). in that case, yea, just go SQL.
Web root is the top level directory of your website. It's the folder you point iis to. 
If you're using .net core, why would you subject yourself to IIS? Kestrel seems to work perfectly fine without all the app-pool warm up and configuration drama. And even then, how would you get multiple projects running as the same application?
in the context of Sitecore: Sitecore has its own website that you need to integrate your changes into. Think of having a base directory, folders and content and you need to inject your stuff into it. The solution is to develop outside of the webroot (i.e., the website directory with sitecore's proprietary stuff) and then publish your content to that directory. Sitecore projects can get unruly, you often want to create reusable components. (for example, if you are hosting a multi-tenant site each one of them could have a staff directory, rather than recreating it for each site you create a reusable component) you need to publish all your content simultaneously rather than one by one, painstakingly in visual studio and therefore need to use a gulp script to do so. I never said it was a good way to do it, its just a way to do it. 
I have no idea what Sitecore is tbh so I can't really have a say in it. In a traditional .Net application, I would just create a library with all my reusable components and deploy that first, then the applications themselves. But I guess they have their reasons, they seem to be pretty popular too. 
You'd still have to run it behind IIS in production. You never want to expose Kestrel directly. 
Make sure the IIS ASP.NET module is installed and set up correctly in IIS. It is not part of the standard runtime and has a separate installer. Make sure any modules or filters for ASP.NET in your website appear and are not placed below other modules or filters (in the ordered lists) that would preempt them.
Production for me is inside an intranet most of the time. Anyway, why wouldn't I?
OP is about core though.
Here's some more [good ASP&gt;NET tutorials](https://reactdom.com/aspnet)
LOL
I somehow missed out on that but would here whispers of it around 1999-2001
Security is usually the main reason, but there are others. Basically it's not hardened and doesn't even pretend to be, which is why MS recommends having some type of reverse proxy in front of it, either IIS, or nginx usually. Usually on intranets you'd be using windows authentication anyway, so you'd want to run IIS in front of it to handle that authentication. I'm not saying it should never be done, but in 99% of cases, it probably shouldn't. There's always the exception. 
That was just an old Visual Something that I thought of that has also gone away. If I remember correctly Interdev was Frontpage's big brother?
are you trying to profile or to just monitor for health? for the former, you're going to have a hard time. afaik there is no great way to do it. you can google it and you may be able to hack a solution together, but i don't think there is official support. for the latter, its just a process, any linux tool that monitors cpu/memory will work. fwiw I've poked around the dotnet repos and eventing is becoming a bigger thing in net core 3, so there's that. no idea what it will support though. 
It's not here \*yet\*, but.... [https://blog.jetbrains.com/dotnet/2018/10/22/performance-profiling-net-code-rider-integrated-dottrace/](https://blog.jetbrains.com/dotnet/2018/10/22/performance-profiling-net-code-rider-integrated-dottrace/)
my memory is Interdev had all these menu options but all we ever used it for was the text editor.. and I think SourceSafe integration
I cannot figure out what changed in anything.
I'm trying to determine how much memory and cpu a particular process is using within my code. Since this will not be the only thing running on the machine, general CPU and memory use on the machine isn't going to help me much. I really want to be able to see how much resources each particular process is using.
Application insights + running your stuff in docker? My Devops guys did something like this.
https://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/
To support /r/cat_in_the_wall : [This talk](https://www.youtube.com/watch?v=dUdGcogYkss) goes over the possibilities for net core 3 in the way of APM, nothing set in stone at all, these are just possibilities. generally speaking the performance monitoring / tracing in Net Core is not all too great outside of Application Insights on Full Framework. Some things to look at, maybe they meet your needs: [MiniProfiler](https://github.com/MiniProfiler/dotnet) [AppMetrics](https://github.com/AppMetrics/AppMetrics) I have spent a little bit of research on this recently so some of this stuff is fresh in my memory.
Just try to put "monitoring linux servers" in google. First link looks like "80 Linux Monitoring Tools". Also if you use docker, orchestrators have own monitoring systems and approaches. So need to find in context of your orchestrator. We use prometheus with kubernates for example.
[https://github.com/tangarm/Tangram](https://github.com/tangarm/Tangram)
When you say "process" do you mean something like a class or operation CPU/memory? Or do you mean a process in the OS sense? If you're talking about the latter you should be able to just do something like ps -ax | grep "mycoreapp"
Please elaborate?
There's a few of you in this subreddit
I just meant that there‚Äôs a lot of tools not following that naming pattern. Bazel, gradle, flubu, nuke, ... Nevermind :)
Anyone have any insight into why ToUpper is faster than ToLower?
Keep it civil
The [AsyncGuidance.md](https://github.com/davidfowl/AspNetCoreDiagnosticScenarios/blob/master/AsyncGuidance.md) file is of particular interest with the "DO" and "DO NOT" of Task, Queues, Backgroud Jobs, Timers. These apply both to ASP.Core and to .Net itself. An example is the ‚úîÔ∏èGOOD QueueProcessor, which tells you to create a separate thread new Thread(ProcessQueue) instead of Task.Run(ProcessQueue); shown in the ‚ùå BAD. 
&gt; An example is the ‚úîÔ∏èGOOD QueueProcessor, which tells you to create a separate thread new Thread(ProcessQueue) instead of Task.Run(ProcessQueue); shown in the ‚ùå BAD. I just don't know what to think about this. I've not had problems with doing long running with with Tasks that pull from a ConcurrentQueue. I mean, why even have Task if you allegedly have to resort to Thread all the time? Case in point Stephen Clearly (author of Concurrency in C# 6) says something like: As soon as you use Thread, that's it game over; you have legacy code. I'm so conflicted.
The former. I want to drill down to what resources (cpu, memory) a class is using in my code. On Windows you could use performance counters but they don't exist on Linux. 
I think the .NET team need to organise their thoughts and make a cohesive list, without any conflicting arguments.
[removed]
The reasoning here is that a task you start with Task.Run will run on a thread from the thread pool. The thread pool has a finite amount of threads that are created and meant to be reused for multiple short lived operations. They are reused to minimize the impact of the overhead that comes with creating threads. If you use a thread pool thread for something that is not meant to finish quickly, potentially something that is meant to always be running then the thread from the thread pool will be used exclusively for that. Meaning that your thread pool has one less thread available to be reused for other things in the application. Of course the performance impact of that may be minimal in your scenarios but it's still important to keep in mind how that's working.
This is great stuff. It looks like a WIP with more to come. I'm definitely keeping an eye on this.
I see... wouldn't it be better to just allow Tasks to be long running, with some change to the ThreadPool? Why can't it push Tasks that have existed for x amount of time be automatically given their own Thread?
He has a lot of good Dotnet resources if you go through his repos. 
[removed]
Are you writing new .NET libraries from scratch, or is it legacy code? If legacy, it would need to be converted to .NET Standard to be used in the Xamarin apps. If writing from scratch, do it in Standard and you‚Äôll be good to go. 
[removed]
These are legacy libraries. When you say convert are we talking re-write or is there a way yo actually "convert" them?
You can use Xamarin forms. [Xamarin.Android](https://Xamarin.Android) will require you to read/translate a lot of stuff from Java. I think forms might be easier but I have not tested that yet. I believe with forms you will be able to use some, if not most of .NET libraries. &amp;#x200B; You will need a web service in order to perform operations on the database. &amp;#x200B; Windows has a tutorial on form, .android, .ios here: [https://docs.microsoft.com/en-us/xamarin/](https://docs.microsoft.com/en-us/xamarin/) &amp;#x200B;
Depending on what classes/features those libraries use, that conversion could be very easy. It _usually_ just means removing unsafe code and references to old (non-Standard) libraries. It‚Äôs still c#, and Standard libraries can run on the full .NET. [this article](https://www.danielcrabtree.com/blog/314/upgrading-to-net-core-and-net-standard-made-easy) is about AspNetCore but it covers the topics of converting legacy to Standard pretty well
Thank you I will give that a read. From what I see online [here](https://docs.microsoft.com/en-us/dotnet/standard/net-standard) is it as simple as upgrading to a higher version of .NET in the project properties and fixing what ever issues come up when you do that? The code is currently based around .NET 4 so it looks like there is no support for standard until I get to at least 4.5?
Correct on both. Good luck!
Tasks already have a flag for LongRunning; if you start a task with Task.StartNew you can specify this.. Yet we're told not to; that starting a long-running task with Task.Run will figure it out for itself within 500ms; and that that's safer than using Task.StartNew 99% of the time. I see why you should offload a permanent task to a Thread; but it seems counter-intuitive. I personally don't think it would matter for many small applications. I mean; I just ran ThreadPool.GetMaxThreads(out var workerThreads, out int completionPortThreads); on a sample application and it returned 32767 and 1000, respectively.. This seems like advice that only applies if you're a. allocating an absolute tonne of threads from the thread pool to long-running tasks, or b. doing a very punishing workload. Good to know; but probably not going to affect your basic WPF desktop app much.
Great point - you're right. So the safest way is to just bite the bullet and write the boilerplate code for each new project? Maybe I can create a template actually...
Wow man super impressed. Maybe you can say "fuck" again, that impressed me last time as well. So much professionalism. You must be the famous "brogrammer" doing push ups while crushing mediocre programmers. Fuck handling millions of requests for images during the olympics, this motherfucker handles INSURANCES, step out of the way! Using LINQ for anything complex is a waste of time, thank you for having 0 arguments against that.
&gt; Tasks already have a flag for LongRunning; if you start a task with Task.StartNew you can specify this.. Yet we're told not to; that starting a long-running task with Task.Run will figure it out for itself within 500ms; and that that's safer than using Task.StartNew 99% of the time. That's exactly what I was referring to yeah, so I'm really confused by the GitHub repo glossing over that! One thing I worked on had 4 dedicated Tasks pulling from a Queue and another task pushing (producer/consumer) and yeah it seemed fine to me, that seems to be a lot of available threads as well from your snippet so it seems OK to me...
&gt;Only ever dealing with ASCII characters is often a dangerous assumption to make, and even then things can go wrong It's not really an assumption. It's just the parameter of this particular test. You can be confident you're only dealing with ASCII if you're providing all the input.
Fair enough! I've heard wonderful things about Prince and docraptor. Only reason i did not post them is because I've never used them before. Consider this list the "poor man's prince/docraptor"
He's the lead dev of ASP.NET
&gt; Avoid using Task.Run for long running work that blocks the thread This section is outright wrong. The .NET threadpool size is dynamic - it will automatically create new threads if there is no ready thread in the threadpool and slowly delete them if there are too many. If a thread blocks and never returns to the threadpool, the threadpool will just shrug and create another.
I think it's more nuanced than that. The question is, are you protecting from the user (e.g. some license data) or for the user (credentials as this case seems). In such a case, you can also rely on the user's own PC protection, and even a bit of defence in depth to buy time and allow for intrusion discovery is better than no defence at all.
&gt; The thread pool has a finite amount of threads that are created That is not true. The thread pool is dynamically sized.
Why no Ordinal string comparison, if OP only cares about [A-Za-z0-9]? It's pretty tough to beat Ordinal even when you can restrict your character set to ASCII only. 
I‚Äôll take being called a mediocre programmer by an app developer as a compliment. Apparently you aren‚Äôt even smart enough to realize that professionalism doesn‚Äôt apply on an anonymous site on the internet. I realize that takes quite a bit of brain power for an app developer though. And holy shit, image hosting? That has to be the most complex problem I have ever heard! I‚Äôm guessing no other company has ever solved that problem before. It‚Äôs not like insurance has to have a team full of analysts, actuaries, lawyers, and compliance experts or anything like that... We would never have to deal with thousands of business rules that vary over time and between regions. But please, keep telling me how impressive your image hosting is that you probably didn‚Äôt even work on because you were busy writing an app.
&gt; write the boilerplate code for each new project Or just make a dll that wraps interaction with the 3rd party API in a C# API. Package it up for NuGet and just reference it in each new product. Use standard .Net configuration for any project-specific bits like API keys.
You wouldn't make a whole API. You'd make an API client.
&gt; Prefer async/await over directly returning Task I don't understand this because usually the recommended practice is to return the Task directly to not waste building another async state machine. Thoughts?
[removed]
if you are using VSTS you can easily deploy a nuget package to a private nuget repository as part of a CI build
[removed]
I use TeamCity and https://github.com/NuGet/NuGet.Server There are hosted options like MyGet as well. Lots of easy ways to get it going.
Awesome. We are using what is now called Azure DevOps. I'll have to take a look at the NuGet.Server 
I think this is pretty common. Atleast the team i'm in uses this concept in a micro services architecture. We call services like that 'Integration services'.
WebForms - in my opinion - is not great (I used WebForms for 2 years + unfortunately). The thing I really don't like is that it abstracts the web away from you. Not in a good way. Whenever you need to do something that's not "webform-centric" (which is anything other than basic crud + grids) it become a mess of inline jquery everywhere, misplaced ajax methods and a spaghetti mess of event handlers and lifecycle events trying to rebuild dynamic controls in Page\_Init etc. Whereas in MVC it might be a good idea to make a controller per specific "entity" - which means a web page might hit multiple controllers (a good thing since they'll be small classes with a single responsibility, etc.) In webforms anything on the page just get's pushed to event handlers. Which in turn somehow requires specific lifecycle events to rebuild "custom" controls that you needed to build because you're doing something non-crud.... Hopefully that resonates with someone!
Excellent find OP. Perfect content for a dev brown bag lunch discussion.
&gt; an app developer So you started to dig through my post history to find something to insult me with? Instead of explaining me why building your application upon a super leaky abstraction is a fantastic idea that's the only thing you could do? I just put my trash on the curb, if you're quick you'll find something interesting about me or some warm food in it if another hobo didn't beat you to it. &gt; a team full of analysts, actuaries, lawyers, and compliance experts That poop out the rules that are simply implemented by a drone like you. That has to call a db expert once queries get too difficult. Because hard work gets done by real people.
Dumb question(s) time... So I've noticed a lot of Core Asp.Net/MVC code with the async in the public action definitions. They then spawn off a background thread to do the work then respond. Fine. But this contradicts my previous experience (.Net Framwork) in two ways: - Often you'll have session locks that result in async code lock spinning anyway (i.e. the second, third, etc request from the same client will wait in the unique session lock). Is this a solved issue in .Net Core? Or does this only work while session is disabled (like now)? - Without the session lock issue mentioned previously, concurrent requests work perfectly fine without async, IIS would just handle each request using a different waiting process in its application pool. So my question is, even if something is aync, will IIS re-use that still "in-use" process, or just allocate a new idle process in its pool? I guess the core of what I'm asking is, how does the use of aync mesh with IIS's process model for .Net applications/application pools/session locks. A good article or YT video would be extremely welcome. 
oh man this is the type of content that i like to see. if only i could upvote more than once.
If they *never* return, then yes. But that is extremely rare, and I would argue that almost every single case where a thread never returns is a bug in your program that needs fixed. If it is merely long running (seconds or minutes), then you should profile your application to understand the application needs and set the threadpool maximum to a comfortable threshold. If it takes hours then it should be another process.
It depends on what your colleagues are like. There is overhead due to the state machine, but it's arguably better if your colleagues (or yourself) don't fully understand when it is safe to elide the async / await keywords, and when it is not. For example: It's not safe to elide the await keyword when you're awaiting a result that depends on a disposable resource. Doing so will prematurely return the unfinished task (unless the task runs synchronously), prematurely dispose of the required resource, and then erroneously attempt to access the disposed resource when the task actually does run asynchronously. The issue might manifest only sometimes in cases where the task sometimes runs synchronously (the disposable object is still in scope) and sometimes runs asynchronously (disposable object has been disposed). From a correctness perspective, always using async / await is superior. Far fewer tricky concurrency bugs to track down at the expense of a probably-small asynchronous state machine overhead.
[removed]
If you're building a .NET Core application the overhead is going to be the same if you decide to do a console application or a web API because both will be running on Kestrel.
I agree - although I've used long running tasks in WebApi with task factory / longrunning option (just this week actually!) and it does seem to work fine if you don't want to be sophisticated about it.
Why would the console app be running on Kestrel?
I'll be deploying to Linux.
In that case, I would still do as I suggested but [check out this post for an example of how to create the equivalent to a Windows service on Linux](https://stackoverflow.com/questions/42483311/cross-platform-background-service-in-net-core-think-windows-service-unix-daemo).
It won‚Äôt.
 A list of podcasts containing information about .NET, Azure, C# and related Microsoft technologies. Get introduced to 8 podcasts that Kristoffer and myself are listening to. 
I just assumed you were using a host since you were planning on self hosting it on Linux.
I raise this issue because this pattern is part of several analyzers and recommendation especially for pass through scenarios * https://github.com/code-cracker/code-cracker/issues/151 * https://github.com/DotNetAnalyzers/Proposals/issues/24 * https://cpratt.co/async-tips-tricks/ * https://www.tabsoverspaces.com/233659-do-not-await-what-does-not-need-to-be-awaited * https://blog.stephencleary.com/2016/12/eliding-async-await.html * https://docs.particular.net/nservicebus/handlers/async-handlers 
.NET Core already has something you might want to use: [Hosted Services](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/host/hosted-services?view=aspnetcore-2.1). If you use hosted services, it is also extremely easy to add a Web API controller on the side if you really want to call your action from HTTP.
Sure, that's why I wrote *sometimes it doesn't really matter*. Once you start mixing in cultures and even characters over first 128 from ASCII, you probably don't want to use invariant cultures either. It all depends in the case (no pun intended).
String comparison is different than making the string upper/lower case. Although I often see people calling ToUpper on two strings and then comparing, while the case insensitive comparison would do this job fine and faster. So I kind of see your point. But comparison of strings was not point of my "test".
Which I did in this case. :)
[removed]
What are we looking at here? Why is Webpack required with Blazor?
I have been using Postal for this. It essentially uses Razor and Models to generate HTML (or text) emails for you. Been using it Since Razor 1 i think. Very long time. This is where I got inspiration to create a custom Razor Engine for a project I was working on about 6ish (2012) years ago. Its allot easier now a days and you probably do not need Postal.. but if you just want a drop in solutions.. this is the one!
You can quote Jesus Christ himself but this thread was about why people preferred Dapper (last time I checked: still an ORM) and I still didn't get a straight answer why you like to introduce leaky abstractions into your code only to have to refactor them out once the database and queries get to any kind of complexity above trivial. You're all fluff no content. And every time I press you to give me content you just evade and give me more bragging and insults.
Understood. I would be using some sort of an API if I was doing a mobile application.
Lol that would do it. I knew he was a dev on it. Didn't realize the lead.
This. Another (huge IMO) advantage is that you can publish it to Linux/Windows/Mac without changing a thing, which would not be the case if you build a Windows/Linux service.
I wouldn't use these questions, personally. Certainly not these answers. None of these answers show an understanding of actual, practical concepts. Just random .NET trivia. If you're interviewing, in general, you should opt for more abstract concepts. Like instead of asking about the difference between String and StringBuilder, ask about the difference between mutable and immutable data types, and then ask for example of where each would be preferred over the other... just my opinion.
[removed]
Show me an implementation of the specification pattern using dapper.
Pulling from a durable queue (Amazon SQS) is exactly what we plan to use for this. Thanks for the info!
I wonder if the Docker support in Visual Studio 2017 will do this for you if you select Linux as the target? I'll have to play around with that.
Yes it is. The specification pattern is extremely simple with EF. I don‚Äôt think I have ever seen it implemented with dapper and it would be messy to even attempt. 
These guys in stackOverflow explain it really well: [https://stackoverflow.com/questions/38138100/what-is-the-difference-between-services-addtransient-service-addscoped-and-serv](https://stackoverflow.com/questions/38138100/what-is-the-difference-between-services-addtransient-service-addscoped-and-serv)
they are the "lifetimes" of the service instances. meaning the object of type T returned from serviceProvider.GetService&lt;T&gt;() would be... 1. If registered as **Singleton**- would be the SAME instance every time the type is requested for the lifetime of the entire application. Rarely would you want a Singleton instance. But they have their uses (ex: a cache). If using a Singleton, thread safety must be considered. 2. If registered as **Scoped**- would be the SAME instance every time the type is requested for the lifetime of a single request. Sometimes you want a service or object to be the same instance shared throughout the flow of a request. 3. If registered as **Transient**- would be a NEW instance every time the type is requested. Safest for thread safety and fastest (no locks, pooled db connections, etc).
You asked for an example... Ok even simpler... Our company recently standardized our REST endpoints so that you can add paging and sorting to them. Can you give me a database agnostic implementation of paging and sorting in dapper? Because that is also trivial in EF.
I use Singleton for Factory classes. Works out well.
If you haven't checked out Complete Developer Podcast, you really should. Very well done and solid, focused topics. I'm glad you included No Dogma Podcast. I think Brian does a great job with it. I also listen to Cross Cutting Concerns as well, but episodes are shorter (15-30 min) and don't get all that deep. Good for intros to topics.
Didn't know any of the two podcasts. Cross cutting concerns sure looks nice from a .NET perspective. And Complete Developer looks like a good language independent show. Thanks, will check out both podcasts for sure!
If you are designing your service classes correctly, * Every class is thread-safe * Every limited resource such as database connections are contained in a `using` block Which means you only need `AddSingleton`. *** Unfortunately far too many examples inject a DBContext, hogging the valuable database connection for the lifetime of the request instead of just while it is actually needed. The really stupid thing is that in some MS documentation, they warn you that this is a bad idea, then go ahead and do it in the example code anyways.
To piggyback on this, I use Singleton to resolve a GraphQL schema type which is fairly expensive. But I have to inject a Func&lt;MyDbContext&gt; as Singleton (basically a factory) into the schema class to get the service lifetimes to play together nicely. Then within the service classes I actually create the DbContext per method within a using block. I assume that's ok?
If you are designing your service classes correctly, * Every class is thread-safe * Every limited resource such as database connections are contained in a `using` block Which means you only need `AddSingleton`. *** Unfortunately far too many examples inject a DBContext, hogging the valuable database connection for the lifetime of the request instead of just while it is actually needed. The really stupid thing is that in some MS documentation, they warn you that this is a bad idea, then go ahead and do it in the example code anyways.
Complete Dev is hosted by two .Net devs, but their topics range from technical, to career, to personal. Definitely not .Net specific, but from a .net perspective, if that makes sense.
Yes, you're taking full control of the life cycle of the DbContext object this way, allocating as necessary and cleaning up as designed. 
Thanks for this!
&gt; I actually create the DbContext per method within a using block. I assume that's ok? It's better than ok, it is the right way to do it for 99% of cases.
It is. If I were you, I'd scrap the idea of using a console app because it's not made for this purpose. Use a WebAPI with a HostedService. It's far easier to maintain and extend.
Great. Like you said below, a lot of examples show the DbContext injected and used directly, so it is a bit confusing.
I have literally been searching for .NET podcasts this morning! Thanks for sharing!
[removed]
Plenty of downvotes, but not a single counter argument. Really, I shouldn't be surprised, is there's no good reason for holding onto limited resources longer than necessary other than habit.
Hey, Vue.js has the advantage that you can easily add it to an existing site just using a script reference, something like this... &lt;script src="https://cdn.jsdelivr.net/npm/vue/dist/vue.js"&gt;&lt;/script&gt; This is a nice simple way to get started as you can pretty much just add that reference to any (or all) of your MVC5 views/layout pages and get building your front-end (Vue) components. &amp;#x200B; There was a Vue starter project which shipped with [ASP.NET](https://ASP.NET) Core 2.0 (and earlier) but I believe it was dropped when they released new versions of the Angular/React templates with [ASP.NET](https://ASP.NET) Core 2.1. &amp;#x200B; I notice it's been a few days since you posted your question, have you had any luck finding some good starter examples/sample projects?
&gt; If registered as Singleton- would be the SAME instance every time the type is requested for the lifetime of the entire application. Rarely would you want a Singleton instance. But they have their uses (ex: a cache). If using a Singleton, thread safety must be considered. Registering an object as a Singleton for DI is perfectly fine for things that have no mutable state. Reduced object creation reduces GC pressure. Factories, Configs, etc. While the Singleton pattern is often overused, we're not talking about implementing the Singleton pattern when we're just registering an object for DI. "I can do this all with static classes!" -&gt; but that's bad for DI -&gt; Register as Singleton. If the implementation changes to mutable state later, you can always just change the registration.
&gt; If registered as Singleton- would be the SAME instance every time the type is requested for the lifetime of the entire application. Rarely would you want a Singleton instance. But they have their uses (ex: a cache). If using a Singleton, thread safety must be considered. Registering an object as a Singleton for DI is perfectly fine for things that have no mutable state. Reduced object creation reduces GC pressure. Factories, Configs, etc. While the Singleton pattern is often overused, we're not talking about implementing the Singleton pattern when we're just registering an object for DI. "I can do this all with static classes!" -&gt; but that's bad for DI -&gt; Register as Singleton. If the implementation changes to mutable state later, you can always just change the registration.
&gt; If registered as Singleton- would be the SAME instance every time the type is requested for the lifetime of the entire application. Rarely would you want a Singleton instance. But they have their uses (ex: a cache). If using a Singleton, thread safety must be considered. Registering an object as a Singleton for DI is perfectly fine for things that have no mutable state. Reduced object creation reduces GC pressure. Factories, Configs, etc. While the Singleton pattern is often overused, we're not talking about implementing the Singleton pattern when we're just registering an object for DI. "I can do this all with static classes!" -&gt; but that's bad for DI -&gt; Register as Singleton. If the implementation changes to mutable state later, you can always just change the registration.
[removed]
&gt; If you are designing your service classes correctly, &gt; &gt; Every class is thread-safe Just... no. The easiest way to make a class thread-safe is to *not use it in multi-threaded scenarios* where you don't need to. `AddTransient` for lightweight objects with cheap/free initialization is better than having to `lock`, use a semaphore, or the easy-to-fuck-up complexity of trying to implement lock-free thread safety correctly. Even more of a concern, realistically, is that you may implement a class in a thread-safe manner initially, but some idiot (maybe you in 2 years after you've forgotten the code) might introduce a change that makes it not-thread-safe. `AddScoped` is the correct registration to use for per-request things like request loggers/trackers (which may have Singleton loggers or perf counters injected as their dependencies). Yes, you can `AddSingleton` a factory for everything, but you're just re-inventing `AddScoped` and `AddTransient`. If everything is a factory, then every class must know whether to // AddScoped equivalent this._logger = loggerFactory.GetLogger(requestId); // AddTransient equivalent (with intentional naming stupidity for effect) this._loggerFactory = loggerFactoryFactory.GetLoggerFactory(requestId); Using `AddTransient|AddScoped|AddSingleton` appropriately at the composition root hides this implementation detail from the consuming class.
If you let asp.NET inject the DBContext, then handling the lifetime is no longer your responsibility and you don't have to use a using block. Of course, don't do this with Singleton objects
[removed]
&gt; there's no good reason for holding onto limited resources longer than necessary other than habit. That would seem to be in opposition to &gt; Add this all up and you only need `AddSingleton`. 
AddSingleton requires that you do not shove database connections into member fields or properties, as that wouldn't be thread safe. Instead connections are opened and closed in the method that uses them. 
That's not true in practice. The internal caching used by EF DBContext can have i expected side effects. So you need to know every use of it for the duration of the request. Essentially it creates hidden coupling between otherwise unrelated methods. And really, a 'using' block isn't that hard to use.
&gt; AddTransient for lightweight objects with cheap/free initialization is better than having to lock, use a semaphore, or the easy-to-fuck-up complexity of trying to implement lock-free thread safety correctly. None of that is necessary to create a thread safe service class. You just need to acquire and release non-thread safe dependencies such as database connections within the scope of a method rather than shoving it into member fields. Even ambient information about the request, say for logging, can easily be handled by AsyncLocal.
[removed]
&gt; You just need to **acquire** and release non-thread safe **dependencies** ... And how are you acquiring those dependencies? Via injection, or direct instantiation? Things that are trivially thread-safe by having no mutable state are easy to use with `AddSingleton`, sure. That's not the case for everything. &gt; Even ambient information about the request, say for logging, can easily be handled by AsyncLocal. I don't follow you, there. How does AsyncLocal make it easier than using a Scoped object to * start a timer and generate a RequestID at the beginning of a request * mark a start time and end time for each external call to a dependency * prepend the RequestID to all logging done inside that request without having to pass the RequestID parameter each time * summarize all the timing data into a final log string at the end of the request If the constructor of an object is lightweight... public RequestTracker(ILogger logger) { this._reqWatch = Stopwatch.StartNew(); this._logger = logger; this._requestID = Guid.NewGuid().ToString(); } Then what *value* are you getting from it being a Singleton rather than scoped to the request? 
&gt; And how are you acquiring those dependencies? Via injection, or direct instantiation? Seriously? Was the three recommendations in my original comment so hard to understand? &gt; * Every class is thread-safe &gt; * Every limited resource such as database connections are contained in a using block &gt; * **Which requires that you inject settings or factory methods rather than live connections** 
I'd say you'd usually want a singleton lifetime. Reduces memory usage (one object vs thousands under load), less GC pressure, and forces thread safety. In a high throughput app, never write thread unsafe code.
If you're injecting Factories into Factories, then you're still doing the same thing as AddScoped or AddTransient somewhere. AddScoped uses a Factory provided by the DI container to inject a dependency that is reused over the entire request. AddTransient uses a Factory provided by the DI container to provide a new instance each time it's requested. So no, technically you don't need anything other than AddSingleton and you could AddSingleton your own Factory and use it to provide scoped or transient objects as required... But AddScoped and AddTransient are there so you can do it at the composition root rather than pushing the Scoped/Transient/Singleton logic into the classes themselves, because it often differs between Unit Tests, Development, and Production. &gt; proves to me people are downvoting that comment not because I'm wrong You're being downvoted because it's similar to saying, "you don't need an OOP language. You can do OOP in C."
&gt; Unit testing private methods ...is something that you should never do. Test the public methods. If they work correctly, then by definition the private methods they call work correctly. 
I try not to make a habit of it, but if there‚Äôs something private I *really* need to test I use reflection to invoke the method. So you can do all your normal instance/dependency setup and then focus on that method.
This. No need to make things more complicated than they need to be. 
[removed]
Nothing wrong with that. Another option is to mark it as `internal` and use the `InternalsVisiableTo` attribute to allow the unit test project to see it.
I think everyone is in agreement so far: don't test private methods. They are mere details that are used to implement the public interface. They could change at any time, and as long as the public methods continue to provide accurate results then no harm is done. You should test `RunGame`, passing it lots of different initial states and verifying the result state is what you expect. Also, I personally prefer NSubstitute over Moq. It's a lot easier to use in the average case, and at least no harder to use in the really complex cases.
[removed]
[removed]
[removed]
I had no idea about this. Neat, thanks! 
Test your contracts, not your implementations.
Thank you! I've been delayed but this is very timely and I'm heading into it very soon
Better to put it on a queue and have it processed elsewhere otherwise ur worker threads will get tied up. Depends on the problem of course. Queues and having processes handling the msgs is more code and more Dev ops 
If I recall correctly it gets a little weird with signed assemblies, but in general I've had no problems with it.
Sweet, that would be really useful for my app that I recently moved to .net core. Thanks!
Fixing OO complexity by moving toward FP
You should not test private methods. Test the behavior of your program, not the implementations. Test *what* it does, not *how*. Private methods are a how. 
I couldn't care less how you characterize it, but I'm sure many will say it's the OOP factory object design pattern.
Your post has been removed. Self promotion posts are not allowed.
I've used Octopus Deploy to handle this in the past, it's got a lot of tools for this like automatic substitution deploy time, variable scoping on environment, deploy step++, shared variable libraries that can be used across projects/apps, variable substitution syntax to dynamically build up variable values from other variables, and handling certificates as a first class citizen variable type. It also supports web config transforms, if you use that. So basically the config files that are committed to source control can contain empty variables, or what's needed by the developers sans any sensitive information. Of course, this would require you to use Octopus to package and deploy your applications. Azure Devops has something similar, but I have no experience with how it works across apps/projects/environments.
What ci do you use? Where and how do you host?
Also run this code to demonstrate the differences explained above https://github.com/dodyg/practical-aspnetcore/tree/master/projects/dependency-injection-1/src
It's the O in solid. Just goes by a different name
[removed]
Great, be interesting to see how you get on :-) Using Vue.js the way I described is probably the simplest way to get going. The javascript code you write gets served to the browser and everything remains fairly straightforward. If you spin up a new project using the Vue Command Line Interface, you're into a more complicated scenario where your javascript (or indeed Typescript) code gets compiled, minified, bundled etc. before being served to the the browser. This is definitely a more complicated scenario and involves more moving parts, but opens up a few doors at the same time. I had a stab at outlining the difference between the two approaches [here](https://jonhilton.net/move-to-full-stack-development/) if you want to dig into it a little further :-)
I'm giving this a quick try. Just a SQL profiler is a bit under-selling it. It's a full profiler. It shows each controller call and all the SQL commands/cache calls/exceptions underneat with timings. Reminds of Glimpse except instead of trying to show stuff in the same page as the output of your program, it outputs in it's own process and page. &amp;#x200B;
They really ought to write a ‚Äòfor dummies‚Äô guide on getting some of this data... etw was a cakewalk
[removed]
The only good config file is no config file. Instead of read from file, read from a service that does those kind of substitution on the fly
So something like this is correct implementation. class AvlTree&lt;T&gt; { private List&lt;T&gt; _internal = new List&lt;T&gt;(); public void Add(T item) =&gt; add(item); public void Remove(T item) =&gt; remove(item); public void Contains(T item) =&gt; contains(item); private void add(T item) =&gt; _internal.Add(item); private bool remove(T item) =&gt; _internal.Remove(item); private bool contains(T item) =&gt; _internal.Contains(item); } Tests for public methods are all OK, so by your definition all my private methods work correctly. It's shame I hadn't known that at uni, it would have saved me soooo much time :D :D &amp;#x200B;
Don't think I've ever seen a programming subreddit agreeing like this! [**u/Neophyte-**](https://www.reddit.com/user/Neophyte-/) , you are a unifying force! 
I think that sometimes you should test "how" it is implemented. Correct answer doesn't mean that implmentation is ok. Think about data structures. Or more extreme example what if snapchat filters were implemented by sending your nude photos to someone in India with photoshop skills :) 
Bingo
No, that should be an output of the contract.
No. Test the contract / interface.
Oh sorry... I accidentally deleted that comment. But I still think that **in some cases** you should care "how" it is implemented. For example in AVL tree you should test if it is properly balanced or not, but you can't do that with public methods (every public method will work if it just a linked list = totally unbalanced). Correct answer doesn't imply correct implementation. 
i think this is the right approach, shot should be genereated by the player classses
We are getting into the hairy end of tdd. You cant really test performance as its fragile, so i rwally have no answer to your comment. Test the shit works, and then use fragile performance tests? Or just move on.... i dont know.
I worked in several environments with millions of records. LINQ was banned there for good. There is no way to predict what SQL it will vomit next time, so there is no way to make indexes. 
How do you know where the service is? 
Any plans to opensource it?
[removed]
You hardcode or duh, no config files! But really that‚Äôs what the registry is for
Use spring cloud config server to serve up your config data across all environments. Use SteelToe.io to talk to it from .net. Your config can be layered with overrides per environment. You don't need to bundle your config with your app, but store it in git or vault from which config server will serve it. Sensitive values can be encrypted
You might be able to leverage file or configSource to use external files. https://stackoverflow.com/questions/6940004/asp-net-web-config-configsource-vs-file-attributes
New developers may have worked with and have prior experience with EF. New developers will for sure not have any knowledge of your own wrapper or ORM. What makes you think people will use your wrapper right?
You should upgrade them to a [.NET Standard 2.0 library](https://blogs.msdn.microsoft.com/dotnet/2017/08/14/announcing-net-standard-2-0/ ), which can be referenced by .NET Framework, UWP, .NET Core and Mono. It's the successor to "PCLs". 
Thoughts on a post like [this](https://www.danielcrabtree.com/blog/314/upgrading-to-net-core-and-net-standard-made-easy) one saying that just strait up WinForms applications cannot be converted in anyway to .Net Core?
Forgive my ignorance but is .NET Standard something that I need to install and then choose as a target framework in my project properties?
Winforms and WPF are both out in .NET core land. This is why you want to go to 4.5 first. Get your syntax and features as close to .NET Standard as you can then start pulling into core. You are going to end up pulling over your business logic and datalayer but youll end up having to write a new UWP UI.
It's just a contract/specification, not a runtime. So you don't need to install anything except .NET CLI or VS. 
One can care about performance and also care about other things. Just because someone is using EF, it doesn't mean that they don't care about making their EF queries run more efficient. Let's just not get into the whole "HURR DURR EF BAD PERFORMANCE PLS NO USE"-thing, like it seems you're doing.
Still sounds like an indexes problem to me. Maybe Fluent API. My whole department uses it, and we have no issues across numerous applications.
In VS new project window, there's an option "Class Library (.NET Standard)". Use that. 
I am interested to know what performance information it provides that is not available from sql server profiler. 
Understood. But just so I am clear, we are talking about a slow gradual re-write of everything? If I am honest I had been considering a conversion to a javascript web app when the time comes to this.
From my understanding, your current project structure is like this: * Example.Library (.NET 4.0) * Example.App.WinForms (.NET 4.5) * Example.App.Uwp (UWP SDK xxxx) You would want it structured like this, for now: * Example.Library (.NET Standard) * Example.App.WinForms (.NET 4.7.2) * Example.App.Uwp (UWP SDK 16299) In 2019, when .NET Core 3.0 will be available: * Example.Library (.NET Standard) * Example.App.WinForms (.NET Core 3.0) * Example.App.Uwp (UWP SDK 16299) 
I recently posted about the .NET Core 3.0 Alpha, check out [my post](https://www.reddit.com/r/csharp/comments/9iruwd/net_core_30_alpha_winforms_and_wpf_windows_only/ ) to try out WinForms on .NET Core yourself. 
IIS
The open/closed principal means that you... * don't modify shipped classes, except to fix bugs (Closed to modification) * only add new features using inheritance (Open for extension) Of course a lot of people ignore this and do whatever the fuck they want, calling it OCP. But this is the first time I've heard it twisted to mean encapsulation.
https://stackify.com/prefix/ /u/mcnamaragio I doubt they'll open source it as it'll be a stripped down version of the product they make.
Is there a way to "upgrade" or "convert" existing .net framework libraries to standard?
Easier to just recreate them. There is a conversion tool from PCL to .netstandard, but because it's not 1-1 mapping it's not the ideal solution. If you create them anew you'll get a few new features like new csproj format, automatic nuget integration, ...
Understood. Even with Core 3.0 there will never be an option to "upgrade" .net framework libraries into core. I will never be able to reference old .net framework libraries via a UWP application. 
To my understanding no, that may change in the future but so far there does not seem to be a desire to provide backward support here. Likely for good reasons, carrying too much legacy has been a problem for the company in the past. 
I suppose it would be easier to re-write my legacy class libraries with .net core vs a different language all-together. Thank you for your help, I will give it some consideration. I am just feeling that its time to move on to something like javascript (seems to be where everything is going nowadays) if I am going to spend the time re-writing my old code. 
What does this have to do with .Net?
Yes I had that doubt, but I am looking for way to prevent that from closing service on my end. &amp;#x200B;
[removed]
Tools -&gt; Options -&gt; Debugging -&gt; General -&gt; Enable JavaScript debugging for ASP.NET (Chrome, Edge and IE) Uncheck that
.NET Core isn't drastically different. It's more stable than JS, just see the number of drastic changes it gets every year that you're expected to adopt and then you have the dialects like TypeScript that some people swear by. 
1. Lazy loading. 2. Deep object graphs, especially ones that lead to combinatorial row counts. (1+A+B+C objects returned as 1*A*B*C rows) 3. Open queries (i.e. returning an IQueryable instead of a List) causing double-execution of the query. 4. Forgetting to dispose the DBContext. 5. EF caching effects, where objects returned from previous queries will be attached to the objects from the current query even when not requested 6. Forgetting AsNoTracking 7. The ceremony around updating a record with a disconnected entity. How does my ORM, Tortuga Chain, solve this? 1. Doesn't exist. It was always a bad idea. 2. Doesn't exist, you are required to use projections and separate queries for child collections. 3. Not allowed. You have to explicitly call `Execute[Async]()` before working with the results. 4. Not an issue. Connections are automatically opened and closed as needed. (Though you still have to explicitly commit transactions.) 5. Doesn't exist. Again, it was a bad idea. 6. Doesn't exist. Remove #5 and you remove the need to disable it. 7. Not an issue. There is no "entity", any object can be used to update a record so long as its properties match the columns in the table. 
Pro tip: if you don‚Äôt need to debug your code, you can run your application by pressing ctrl + F5. This enables you to make changes in your code, and then simply rebuild your project to see the changes in the app. This way, the application pool on iis express will keep running, and you don‚Äôt have to stop it every time you need to make a change.
Oh, I see what your problem is now. Adding the exception handler is a good first step but you didn't post that code so we won't be able to tell if there's anything wrong with it. I would try this: private async void BeginListeningInBackground(IAsyncResult asyncResult){ var listener = asyncResult.AsyncState as TcpListener; TcpClient tcpClient = null; try { tcpClient = listener.EndAcceptTcpClient(asyncResult); } catch (SocketException) { } Task.Run(() =&gt; { WaitForTcpClient(listener); }); if (tcpClient == null) { return; } using (NetworkStream netStream = tcpClient.GetStream()){ //working with netStream here } }
Thank you again for the response! &gt; you can reference .NET Framework libraries from .NET Core This is sort of the opposite of what I want to do. I have a framework desktop application that I would love if ultimately could reference .NET core libraries (my old ones that I want to update). I have a few libraries with most all of my business logic that I would really prefer to use in the UWP application. Its been a meetings and Reddit sort of day for me so far so I hadn't much time to actually write code. I planned on tinkering with it later today and tomorrow. I will take a look at that analyzer tool now btw.
https://www.hanselman.com/blog/HowToReferenceANETCoreLibraryInWinFormsOrNETStandardExplained.aspx 
That‚Äôs why I point an IIS site to my application directory, so I can access the site without running with Visual Studio and IIS Express. Any code changes I can just rebuild the solution, alt tab back to my browser and just refresh the page to see my changes. 
&gt; My professional opinion is the idea that "everything is going to X anyway" is anathema and close to foolish My only reason for saying that is it appears that for handheld devices android is quickly becoming the dominant OS. I am having a hard time finding devices running any form of windows let alone something that supports windows forms.. &gt; What technology you learn will dictate your job prospects in the future so think very carefully about what you want your day to day to be like. I wish someone told me that a few years ago! haha Also wow.. your description is spot on. Small-medium sized business, legacy code that has not been updated in some time (aside from bug fixes and minor upgrades here and there), Sort of a by-dev desire but really we are looking at these handheld devices and nothing supports windows forms, I actually could talk to the original dev as we still have a good relationship. There is a ton of business logic in the UI layer (ugh).
Reading through this now. So .NET Standard does not support windows 7 at all.. Yikes. 
Where have you read that? That's not true at all. 
&gt; At the end of the day, most folks in an org do not like the guy running around saying "change everything its all wrong" even if they are right. This is exactly what I want to avoid! I'm doing my best to work with what we have but I keep hitting walls with the cold being old and written with little considerations to layering and tons of desire to expand to modern devices that do not support the old code...
https://docs.microsoft.com/en-us/dotnet/standard/net-standard?WT.mc_id=-blog-scottha Looks like even the oldest standard 1.0 has windows 8 as the minimum system requirements?
Maybe [they](https://docs.microsoft.com/en-us/dotnet/standard/net-standard?WT.mc_id=-blog-scottha) just meant that windows 8 comes with it out of the box and 7 would need the runtimes installed separately?
I would suggest a few phases here: 1. General cleanup, make your project layouts sane and fix all your dependency chains. 2. Framework upgrade. I would go all the way to 4.7 personally stopping at 4.5 first. You might find the new language features make life easy enough for this app for now. 3. Refactor and clean up. Apply SOLID principals across the application pulling logic where it should be. 4. Now you can port the code you want to whatever, by now you prob have some of your base libraries running in Standard. Depending on the size of the code base I am talking months if not years for a single dev. But realistically if there was significant investment in that code originally it may be worth the effort to preserve it correctly as once done it can live for potentially decades and still provide value to the organization. Of course this ALL depends on the type of app, who its supporting and what its really worth to the org. If this is a quick and dirty internal support tool keep your expectations small and focus on cleanups that make day-to-day app support less of a pain. 
&gt; Looks like even the oldest standard 1.0 has windows 8 as the minimum system requirements? Windows 8 refers to Windows Store apps and not the operating system. NET Standard does not correspond to operating systems at all. Even in the table right there, it says 1.0 supports .NET 4.5.. which is supported by Windows 7. 
I would suggest centralizing config on a server that your applications loads from. Its pretty easy to add custom handling to the .NET config APIs and pull data from pretty much anywhere. At one client it was just a simple web service where each published version of an app had a specific app and client ID. These were used to lookup the XML config in a database with nvarchar fields for the data. You just take the xml string and stuff it into .NET config, it does not care if the config string comes from a file or memory so you are good to go. You can get really fancy with this if you want though a simple server would not be difficult to create. 
&gt; It would be better to just start coding rather than misunderstanding documentation at this point. Yea I mean I have been appreciating your advice but I like to do my research and understand things (also plan) before just blindly writing code. Maybe that's wrong but that's how I work.
And you can use attach to process to debug as needed.
It still opens a new tab whenever you do it.
Doesn't work.
Mock if you want. I don't care, because I know it's misplaced. Caring about query performance needs to include caring about the query building and assignment processes as well. These also take time. The reason people talk about bad performance is because EF is well known for it. So in my mind, profiling EF queries is kind of like trying to race tune a Toyota Prius. Yeah, it's possible to improve it but you really are better off starting with a better baseline.
Yes. But you don‚Äôt need to keep doing it. Just do it once, and use rebuild (ctrl + shift + B) when changes were made to the code 
That did it, thanks! I gotta learn the short commands.
Have the problems with .NET Standard 2.0 and .NET 4.7.1 been fixed yet?
What problems are you referring to - do you have a GitHub issue link? (Maybe I have heard about the issue, I just don't use .NET Framework enough to remember..)
&gt; Maybe that's wrong but that's how I work. That's not wrong. It's just that the documentation you were reading would be much easier to understand after referencing .NET Standard libraries in your projects and creating such libraries yourself. 
minification does a pretty good job to start with. I think there are some obfuscation options to that too. 
Circlejerk about bad performance all you want, because I know it's not the tool being bad - it's the developers who do not understand when or how to use it.
[This](https://github.com/google/closure-compiler) is what google uses or used to use. I like using their stuff for JS when it makes sense. 
I know it's dynamically sized but I was under the impression that the thread pool will not just create more threads beyond the size that was already determined or manually set. Meaning if your thread pool has a current maximum of 100 threads and they are all busy, when you queue up some more work it will not dynamically grow to be 101 threads and would instead wait until a thread was available to perform the work. 
[removed]
Oh, I was just curious if there was something that could do it. I know it's not necessary and that minified js code is good enough. :) Do you uglify your embedded js code? Or just your external files? Curious what your minification strategy is.
Not sure on your actual question, but it is important to have the versions match with what Exchange is running. I hope you're not still on 2007.
Prevent launching the browser from the Visual Studio project settings. It launches the URL in your browser, and your browser creates a new tab. So you either prevent it from creating a new tab, or install some browser extension that forces the new tab to be replaced by a hard refresh.
The raw SQL looks ugly, but it's often just doing things like null coalescing and stuff like that. We write against two dbs. One is MS SQL Server and the other is Oracle (one of their pre-packaged dbs). Other teams write against other Oracle dbs. Even with as shitty as Oracle's design is (their pre-packaged dbs are TERRIBLE), we still manage to write queries that run in an acceptable time frame (around one second or less) against a copy of production data. It's sometimes a pain having to figure out how to set up the Fluent API code, but if we look at the documentation to make sure our foreign keys match the structure of the indexes, we avoid most table scans.
That's cool. Was just curious. I've got all our CSS and JS code in a separate Git repo and use NPM with Webpack to bundle everything into 2 artefacts (this includes all dependencies). These are then uglified, gzipped, and output with a version number in their file names before being uploaded to the CDN we use. This is all done by Travis CI on `git push` to our `release` branch. I use version numbers so we can cache the hell out of them and not have to worry about old versions being loaded when new versions are up. Upon upload, configuration files on the live sites are updated that our layout pages know what version of JS and CSS to load. It also means we can quickly roll back if there has been a mistake by simply changing the version numbers in this configs. Webpack and NPM are amazing for this Makes it easier to work with Typescript (and Babel which we've had to do because we are building a bunch of Material Design web components and the type definitions for MDC are not keeping up to date with that framework fast enough). When running that project locally in using Webpack with the `--watch` flag so all changes get but straight away. The dev server for the apps looks at the local build directory of that project for its assets. This is all for a bunch of Node.js apps but there is no reason the same strategy wouldn't make sense for .NET. Things might have moved on since I worked with .NET and there might be similar solutions that are more .NET-y. Probably TMI but you might find it useful.
[removed]
You don't even have to do that. Just right click and View accomplishes the same thing in IIS Express
I do know there were some big revisions to that library. What version are the EWS dlls?
I'm not sure, I just realized that it looks like the code is referencing it in the Web References folder under Reference.map. It shows a System.Web.Services looks like version 4.7.2556.0 then a link to [schemas.microsoft.com/exchange/services/2006/messages](https://schemas.microsoft.com/exchange/services/2006/messages). &amp;#x200B; Originally I checked Nuget for EWS but I guess this is a different way of referencing the API? I just know there are EWS classes that it can't find in the regular EWS API but does find the classes from the proxy API. &amp;#x200B; &amp;#x200B;
It looks like the EOL for EWS is 2020 as far as features go, they are moving to Graph. I wonder if Graph can be used for non Office 365 users.
Google jsfuck, it‚Äôs really annoying to decipher.
I'm on phone so can't check or tell exactly where it is, I thought it was somewhere under debugging 
Exactly this. I let a Senior Developer go after two weeks last year, it just wasn't working out. I was polite and professional and he just didn't accept it because I was 20 years younger than him and no where near his level of genius. So he totally goes off on me and says I don't know WTF I'm talking about and that's clear because he's been arguing against using EF for two weeks and I haven't listened. He stepped into an already established project where he knew from the outset EF was being used. So when he said *You have no idea what you're doing, EF just isn't the right option if you care about performance.* &amp;#x200B; So I stopped being polite and did a live code review with him on his latest piece of work. His first line was this; var mything = db.OurBiggestTable.ToList().Where(x=&gt; x.SomeProperty == "y").FirstOrDefault(); If you're going to give EF shit for it's performance, please don't read millions of rows into memory on the web server to get one record. Thanks! &amp;#x200B;
I have no idea what your problems might have been, but the biggest problem we've had is that we didn't specify primary or foreign keys in the right order. The where clauses would get generated in the wrong order (or something) and trigger a table scan. Once we patched up the Fluent API, everything has been smooth, even with the janky Oracle db we have to work with.
Saved. I tried picking up ASP.NET core 2 back about a year ago and had to divert my efforts to my actual job. Seeing some good examples of how to do things is going to be a big help when I get back into it. Thanks! Also, I never thought NCoC would ever need to be a thing, but it‚Äôs 2018 and here we are haha.
Right click your www project -&gt; Settings -&gt; Web -&gt; "Start Action" I usually have as "Don't open a page".
Just have to go into the launch.config file and look for the option for opening automatically in the browser, and remove it. Then when you start debugging, VS Code won't launch the new browser tab.
You can set the project startup option to do nothing: 1. Right-click the project, click Properties. 2. On the left side, select Web 3. Under Start Action select "Don't open a page. Wait for a request from an external application." 4. Save Now when you start in debug, it won't open the browser. You have to manually navigate to the localhost address (you can always open it by right-clicking IIS at the bottom right next to the clock and selecting View Sites -&gt; "You site" -&gt; Browse Applications -&gt; localhost http/s url. 
I misread and thought you meant new window rather than tab. Sorry.
Just to be clear: you do a build instead of debugging so a tab doesn't pop up? You can configure default browser in visual studio, setting it to "none" if you wish.
It'll probably still be lots easier moving the existing code over - a lot of it will probably be the same.
I use and love this method, plus attach to process for .NET stuff, but has anyone got this working with a .NET Core site? My understanding is that I have to have a config somewhere that tells IIS to use the Core hosting module somewhere, but I haven't figured it out.
[removed]
That‚Äôs not the only reason. At my old job, it was very useful to have a running instance of our software running on my machine, even with Visual Studio closed. Among other reasons, I did a lot of work outside accessing our REST API using Postman, node, or other tools. Having my own persistent instance/database I could wipe at anytime was extremely useful. 
This. I pretty much set up every project on local IIS at the beginning of every project. 
not sure, I normally use nodemon or dotnet watch to run my asp.net core applications. When I need to debug, I just close that and run a debug task in VSCode or VS. Most of the time though I can get away with just Console.Writeline though.
[removed]
At some point, you may want to do yourself a favor and go through all the menu options to try them out. Also, try all of the right-click context menu options on the various folders in the Project Explorer and the various other views in VS. There are many buried gems in there. OTOH - Learning how to get along with the dotnet command line, Angular's ng cli, and other command line tools for .NET Core is an even better use of time these days. Either way, they are both worth a Pro's time.
Seriously, this ought to be automated by now. Sure, it's easy, but how hard would it be to have the tool simply attach to all w3wp.exe processes for you from a menu option titled "Attach to IIS process(es)"?! Answer: Not hard.
&gt; The where clauses would get generated in the wrong order I don't think that matters. Any is generated wrongly, it should use `select count(1) where ... and rownum =1`, this is enough to stop using it. Then there is this crazy thing that you have to select first and update in the next step and Save on the third step. Wut? I prefer to do in one go. There is no `contains` operator. May be EF is good for a small startup or for the first stage of prototype development 
Iis on servers you control?
If OP uses packages that are updated and sticks to new csproj, it should not be a problem. 
There is also this GH organization [https://github.com/DotNetAnalyzers](https://github.com/DotNetAnalyzers) which aggregates some nice analyzers. Besides the many great already mentioned, I'd like to draw your attention to [https://github.com/DotNetAnalyzers/PublicApiAnalyzer](https://github.com/DotNetAnalyzers/PublicApiAnalyzer) (MS Roslyn team uses sth similiar). IMO vital for library/component writers. In short: it requires your publicly exposed API classes/methods etc signatures be stored in a text file (a separate one for shipped and unshipped API), otherwise an error is reported. Its code actions help you automatically append an API signature into the text file. Added value: code reviews where it sums up all changes to public API.
There is an extension called "Attach to all the things" that lets you do just that!
Very good points.
one thing though I am very interested - how can I feed EF an SQL query and make it cast to a complex object with nested lists. 
It might seem messy at first in XAML, but once you've got the style configured the way you want you can move it to a resource dictionary and then use the style implicitly throughout your app, or name it and use it explicitly with a binding. You're right, changing some styles is WPF is difficult. The button style in Windows 7 is a huge mess to unwind, whereas the Windows 10 style is clean and very easy to navigate. &amp;#x200B; What you're looking for is in the ItemContainerStyle. Right-Click the combobox -&gt; Edit Additional Templates -&gt; Edit Generated Item (ItemContainerStyle) -&gt; Edit a copy Give it a name and "Define in" your Window. Above the generated style with default name "ComboBoxItemStyle1" add a new `&lt;SolidColorBrush x:Key="ComboBoxItemHighlightBackgroundBrush" Color="#F00" /&gt;` Let's just keep it red for now, easy to spot the change. In the style's ControlTemplate.Triggers, find the Trigger Property="IsHighlighted" and change the Setter Property="Background" value to `Value="{DynamicResource ComboBoxItemHighlightBackgroundBrush}"` &amp;#x200B; &amp;#x200B; &amp;#x200B;
Alternate solution to going into the specific style itself, you could consider doing some "kinda-theming" instead by changing the SystemColors. Make a new ResourceDictionary and within it you can start overriding them by going `&lt;SolidColorBrush x:Key="{x:Static SystemColors.HighlightBrushKey}" Value="Red" /&gt;` And now all controls using this highlightbrush will change accordingly, which can simplify the amount of work and make your application skin more uniform.
I was so used to doing it with keyboard shortcuts but for a while I've been using ReAttach https://marketplace.visualstudio.com/items?itemName=ErlandR.ReAttach
Now if only there was a python module that would do this for me.
I'm assuming this isn't a laptop, so coffee shops are out? 
[removed]
I went from [VB.NET](https://VB.NET) to C#. It took *forever* for me to learn the C syntax. But if you're already familiar with VB6 and C#, I can't imagine you'd have much trouble grasping it.
[https://www.harding.edu/fmccown/vbnet\_csharp\_comparison.html](https://www.harding.edu/fmccown/vbnet_csharp_comparison.html)
It really isn't good practice to allow a phone or client application to connect directly to a backend database. The connection credentials are too easily intercepted and may allow a malicious user to perform whatever queries they like. A web api is a good idea. 
Yes, use a web API.
[removed]
Are you using azure? Or any database using ssl certification? If so, theres a gapping whole in mon there with Entity Framework so that could be your issue. I dont have the link on hand but i remember there being a bugzilla case for it. But yeah, as others have said you should be using a web api anyway.
Alive and well, but still doesn't have any plans to support .Net Core?
Unless I'm missing something, using `Expression&lt;Func&lt;T, bool&gt;&gt;` accomplishes the same thing and without manually constructing expressions. 
Blah blah blah. VB.net is 99% C# without the semicolons and {}‚Äôs. It should take about one afternoon for any competent C# programmer to get up to speed with the syntax.
Maybe I missed it in the article, but does Blazor run with .NET v4 or just CORE?
Very nice. I will try that tomorrow. Thanks!
I'll try it and compare to the suggestion from sander1095. Thanks!
In a simple cases - sure, it's enough. Although, in a case when you need to filter out items, which, for example, occurs in a sets larger than average when grouped by a value which is a product of a regex match the LINQ is more preferable.
Yes this is one way but there's an easier way: building out a text query that EF will interpret. There's a small cost but building the query with text is much easier to work than expression trees. It's not generating raw SQL, EF will interpret it and generate an expression but the syntax is SQL-like.
&gt;Install the [.NET **Core** 2.1 SDK](https://go.microsoft.com/fwlink/?linkid=873092) (2.1.300 or later) Core-only it would seem. &amp;#x200B;
[removed]
It is, I had to convert the problems back to .NET 4.7.2 from Standard, but I will do all the binding redirects when I get around to it
Agreed, and that was the long term plan. This was just a test project and I was just trying to do a quick db connection to test it out
I don‚Äôt know if it‚Äôs changed recently but OneDrive would not sync files/folders that begin with a period. The only major cloud drive providers that work with dot files/folders seems to be DropBox and gDrive. 
It's synced, as I said it works fine on my Surface.
There isn't really many things I can see as a benefit using it but it's useful if you have an admin app where the users can build their own queries on some kind of UI be it specifying some tables by a column filter from a text input on the App. Although I do think it's better that a DBA be the one checking the tables using SQL directly, but overall I think it's more on dynamic creation of expression trees post compile time where a user can dictate somewhat how the expression should be created. Although instead of having to do all that work MS already supports that using the [`System.Linq.Dynamic.Core`](https://www.nuget.org/packages/System.Linq.Dynamic.Core/) where you can build queries like this var query = db.Customers .Where("City == @0 and Orders.Count &gt;= @1", "Some user provided value", 10) .OrderBy("User provided") .Select("new(CompanyName as Name, Phone)"); I made one for a business requirement using a bit of Reflection for property names and Dynamic Linq where non-tech savy business admins could query specific dbs for data and exporting.
[removed]
Actually you can use it against LINQ to objects, even LINQ to XML! I may not have been clear enough. I'm not talking about generating SQL, I'm talking about Dynamic LINQ which as a SQL-like text synthax: [https://weblogs.asp.net/scottgu/dynamic-linq-part-1-using-the-linq-dynamic-query-library](https://weblogs.asp.net/scottgu/dynamic-linq-part-1-using-the-linq-dynamic-query-library)
It's almost like using the right tool for the job would be the way to go. Glad it's working for now, though!
Box doesn't either as I found out the hard way.
Because by convention, filenames that begin with period are often config/settings files. Also, in unix-based environments, .. is a symbolic link to the parent directory, so possibly it's an attempt to avoid unintended recursion? *(Pretty sure I got at least some of this wrong, so plz correct this "talking out of my ass" statement reddit...)*
This looks like a very useful API - congrats on putting something out there. I dive too deep into the code, but at a glance looks clean and organized. -Cheers
It takes like 2 seconds to make a git repo, not sure how you‚Äôre saving time by using OneDrive. 
Dunno- but that's not to say a supported OS couldn't have a drive shared to it from a unix-based system. Meh, I do still think it's dumb to not have this as a configurable setting even if the default is to exclude those files... 
you can make symlinks and hardlinks on windows via mklink, ships since win8, available since NT
Thanks. Though that's true, I've not worked with VB6 since 2004/05. But, I'll keep that in mind.
Since Win7 at least, actually.
&gt; https://www.harding.edu/fmccown/vbnet_csharp_comparison.html Not exactly an article, but probably even more helpful than what I was looking for! Thank you!
Did you try the installers before you messed with the registry and removed them? Undo what you did to the registry and try one of the installers again. You may have fucked it and need to reset windows to fix it.
Go [here](https://superuser.com/) and ask your question there. You'll get much more help from that site. It's hard to solve problems like yours through Reddit.
like i said, since nt, but not as part of the os, optional download, later bundled by default üòÄ
It's mainly just for convenience and lazyness tbh. Github and VS can be a pain in the ass, hopefully VS will get better with it now that MS owns Github, but as it stands I've had way too many problems with it to use it for anything other than when I'm doing group projects.
Your post has been removed. Please read the rules in the sidebar.
Azure DevOps is like Octopus + TeamCity in one (plus more). We just switched over to it in my shop and it's a god send. I would recommend checking this out for your needs OP.
i don‚Äôt think it‚Äôs as hard as all that. Task is still the right thing to use in almost all cases, just not for a ‚Äúpermanent‚Äù background task. also, you can use cancellationtokens in a bare Thread, they aren‚Äôt related to Task at all.
Just Git (not GitHub) I think they meant. You can use a terminal (Linux/Mac) or CMD (Windows) and use Git commands there. Or download / use a Git client which provides a GUI instead of having to use commands.
I've got Win7 Pro and never had to DL anything to get mklink. It's part of cmd.exe like other DOS commands like call, arp, etc.
In what way? Two minutes of setup and I can have a new repo ready to go with no issues. The only problems I've had with VS and git has been their weird stance on rebase, which I don't feel the need for with solo development. Worst case I can use the command line or a different tool for the git work while VS only needs to handle the code 
Yes. Sorry. It's all on prem. 
stop using shady antivirus software; i have no idea why people still chooses to install random software from internet instead of using windows defender (which is insanely great and very performant); stop messing with registry; just reinstal dotnet runtimes (but please, use official site)
you didn‚Äôt fixed anything; you need to reinstall net frameworks and stop putting random strings of text into system registry
I don't know, is MSDN free now?
You can still download Windows without a key I think.
You can get a lot of software free with MSDN Dev Essentials, see https://visualstudio.microsoft.com/dev-essentials/. 
So I'm trying to get access to all versions of windows atm. The reason is for creating a home lab to learn more about domain security topics, as well as personal security research.
They seem to have canned Bizspark :( Is the Microsoft Action Pack still a thing?
Only windows 10 right? I'm also looking for the older versions, and server variants as well. 
Unfortunately it doesn't seem to include older software. 
What specifically are you looking for?
180 day free trials ;)
You most probably gonna hit a throughput bottleneck very early on if you persist, query and try to be real time simultaneously. I think a better approach would be if you stored the state in a fast cache, like in memory (like session) or a distributable Redis. Remember, the basic SignalR architecture is monolithic, that is, the connected clients are stored in memory, so you can only notify the clients connected to the current server. Thus, storing state in memory (along with the connection data stored by SignalR itself) is perfectly valid. Until the point you want to scale out. You can scale by making the clients connect to a given server though, akin to how sticky sessions and server selection works in many multiplayer games. If the state is sharded, and all clients should receive the same data on updates, you certainly shouldn't let them query one-by-one. As soon as your update completes, you can send all relevant clients all the info they need. This wqy you query your state exactly once, as opposed to *at least once* when you only notify the clients of the fact there was *some* change (then they need to query manually). 
What if I need older versions? 
How old? Server 2008 r2 180 day evaluation is publicly downloadable.
Its only about $550 a year now, much cheaper than it used to be. 
All versions. 
I think this approach would scale best. I had a large signalr app once and I kept a large of th e state in memory but made sure that I could reproduce it to a stable snapshot on a appool restart. 
You might want to look into MAP. If you are a small business this might work just as well. Microsoft Action Pack. They have different tiers of the subscription. https://partner.microsoft.com/en-us/membership/action-pack
Thank you. This makes far more sense than what I was originally thinking. I still need to do a lot more research.
Thanks, I'll check it out. 
Through azure you can set up your own lab as they have machine images which you can deploy. For example of you They don‚Äôt have old historical versions ‚Äî 2008 r2 is as old as they go, but they have the supported relevant images. Y Also, there are a number of Microsoft programs that give you free azure credit. For example, if you you pass some of the certification exams like MCSD or whatever it‚Äôs called now. They give you $150 a month in credit. I think they give you an MSDN subscription but I don‚Äôt think it gets you the one with all the downloadable products. For learning, They also unveiled a new learning site with a lot of hands on labs which spin up virtualized hands on environments. 
The other answers here offer some good advice. Additionally, another thing you need to be aware of is that SignalR is not a reliable message protocol, there is no guarantee that clients will receive all your messages, and no guarantee that massages will arrive in the "correct" order. You should build some kind of resilience in your client app to account for missed messages and messages arriving out of order.
Great answer. 
A slightly less legitimate way to do it. the-eye.eu maintains a msdn download mirror (you should be able to find it with a quick web search). You can validate these after downloading by checking they match the checksum/hash on the original mdsn site. These downloads still require a key to be activated, however most (I believe) should run in trial mode / un-activated. You should be able to re-arm them a number of times before blowing them away and rebuilding them. If you're only using the os's for a couple of days/weeks at a time and less than 3 months (or 4 x 3 months), they might work. As they are only being used for lab work and not production that might get you by.
Both LINQ method and query syntax is very similar, with some spacing and capitalization changes. Method syntax isn't quite as clear though as VB.net doesn't use semicolons, requiring underscores to continue on a new line. 
Be careful with this. He said he is a security researcher and I know at least AWS forbids pen testing from or against EC2 images without contacting them first. 
[removed]
Could try asking over at /r/DataHoarder pretty sure someone has these "archived"
As I said, I couldn't reinstall it in any way. Do you know a way that can work?
Sounds interesting. It really sounds fun to make. Will everyone using the application have the same canvas or will there be different canvasses? How many figures will you generally have on a canvas and how many clients will be active in one canvas?
It might help to read how [other systems do it](https://wiki.unrealengine.com/Replication)
Check with your local university to see if there are faculty doing similar research, offer to co author with them with a MSDN as compensation.
[removed]
I like to use Entityframework myself, I've also used dapper and a couple other OSS tools, all have there strengths and weaknesses. Just for the love of your sanity try to avoid hard coding string query's whatever you do. 
The way I read the docs you don't get \`slugify\` out of the box. I think the docs are just using \`slugify\` as an example of how to use a route parameter transformer. &amp;#x200B; [https://docs.microsoft.com/en-us/aspnet/core/fundamentals/routing?view=aspnetcore-2.2#parameter-transformer-reference](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/routing?view=aspnetcore-2.2#parameter-transformer-reference) &amp;#x200B; \&gt; For example, a custom \`slugify\` parameter transformer in route pattern \`blog\\{article:slugify}\` with \`Url.Action(new { article = "MyTestArticle" })\` generates blog\\my-test-article.
Ilmerge? 
Yes I know, I also know I could get somebody else to buy MSDN for me, but the reason I asked the question is because I wanted to see what the best or cheapest way an individual can obtain MSDN on their own.
Try out PanoramicData.SheetMagic for simple loading/saving data from/to XLSX spreadsheets using generics.
A while ago I remembered thinking it looked like the cheapest route was to sign up for a single community college course. If that isn't still an option or doesn't work for you, it might help to know which products specifically you think you'll need. I write a lot of integrations with Microsoft products and might have a good idea specific to multiple products.
LINQ and EF core! If you need something lighter than EF core for data access, use dapper. These tools can be used in the dotnet/aspnet core ecosystem.
Yeah, I'm considering just signing up for a super cheap college course to get the EDU email. But do you know if an EDU email gives you MSDN access? If so which one?
When I had an edu address, it was a different program than Microsoft uses now, and back then the specific school had to be coordinating with Microsoft to verify that you were enrolled that semester. That was called the DreamSpark program or something like that. It no longer exists. Imagine might be the replacement. You get Azure credit. You'd need to look around https://imagine.microsoft.com/ for more details and what it offers and how.
\&gt; management's fear of open source. This doesn't make sense but I ignore it for now. &amp;#x200B; If you you have to do data wrangling I suggest using Excel. For a pre-preparation/analysis (I found [this video](https://www.youtube.com/watch?v=kwt6XEh7U3g) very helpful). If you do not want to use python, you can use C#, too. You don't need special libraries. For-loops, casting, string handling,... Try out LINQ, too! Also, program and store your methods in a way that you can easily reuse them in another project. MS had a real cool tool called [Azure Machine Learning Workbench](https://youtu.be/iyCSZ86s5J0?t=200) but it seems they killed it last month for some reason. :-(
So it looks like you create a class, add it to your object, and then pass in arguments to parse, and get the class instance in return. Probably better for heavy-weight programs that would take a lot of arguments or complex arguments. I made my own lightweight argument solution which works great for just adding a flag and mapping it immediately into my code. Maybe this idea will be useful for you or someone else? I am sure both approaches will have their own best use cases. My approach was to make a CommandLineAttribute into which I could provide an argument name and then tag various fields, properties, and methods with these attributes. At runtime my code would call a Parse function and pass in an instance of this object (or for the most common case being the static Program class, the type Program). The command line arguments would get parsed out and matched to fields, properties, and methods. Each command line argument would have 0 or 1 values (--arg=value or just --arg). The type of the field, property, or method parameter would be determined and the value converted to the appropriate type (if no value, then it's assumed to be bool true). Then it's passed in or assigned as appropriate. Right now I am allowing a method to hijack the main program execution by having it call Environment.Exit when it is done to avoid executing the rest of main(). There are probably better ways to do that though; I could probably add in a return value enumeration or something. Works really good for my uses. I could even extend it for things like different syntaxes, short option (-a), automatic help generation, and so forth, but I haven't needed that so far. It is very nice to be able to add an additional argument by declaring a property and decorating it with a short attribute. Then I can just go in my code and use it.
For .NET Core this is controlled by launchSettings.json I believe (expand the Properties node in Solution Explorer to find it).
\+ you get $50/month for Azure stuff
You'd be surprised what you find on some networks. 
Oh. Bizspark is the answer then.
That's great news. My experience with Json.NET has been okay but it really is confusing sometimes. Hopefully Microsoft can focus on intuitiveness and ease-of-use when they are building this API 
Please just don't make life worse. If I find myself in a situation where I always have to use two libraries, you've failed.
That sounds cool.
[removed]
Thank God. JSON.Net is a great library, but a gigantic pain to manage specifically because it's required by ASP.NET but developed a a breakneck speed. I don't even want to know what the current major version is, but I've written more runtime assembly bindings for that one package than anything else combined. For such a ubiquitous format it's a little bizarre there isn't a stdlib option.
I'm curious what features you use in Json.Net that you're worried won't appear in the stdlib version. I know there's always a new major version of the package, but I have only ever used 2 or 3 methods.
This is important stuff. Thanks for sharing that Ben!
I'm curious how Span will help performance considering that JSON at its core is a string based serialization protocol. Perhaps converting the token keywords to primitive types as Kestral does? I don't know, I'm conjecturing.
[removed]
Not happy with dropping support for running on Framework. That's a serious problem for me.
Nice article. How does a Fluent API compare to extension methods? They seem similar, but different in their implementation. Is there much practical difference?
Why? (Just curious)
.NET Core is pretty much "move fast and break things". I am fine with this.
[removed]
It's pretty horrible, works on simple HTML but anything fancy just breaks it completely.
Yep newtonsoft's API has grown out of control and the author's refusal to refactor of deprecate anything has really started to hurt it. I had a big debate with them over a year back proposing a major version release to clean up an issue, and their response was just "you don't understand how important backward compatibility is" That's why we have semantic versioning. It's okay to break things if it lets your library survive many more years!
[removed]
Still I am not touching it until it reaches feature parity with EF 6. If it is to loose features, then I rather use Dapper instead.
Not the OP, but there are still plenty of .NET commercial libraries that either don't run on Core, or have just a subset of their capabilities available.
It's about time....
Current? It's newtonsoft. I'm pretty sure a few major versions came up while you were typing that. 
Can you post the whole error message? I have no idea which line is causing this error and I'm not trawling through you're entire repo for it.
So with the 3.0 release we are dropping .NET Framework support, but adding support for Windows only WinForms and WPF. Kind of looks like they are tying hard to kill traditional .NET Framework for Core in 3.0.
Yes there is a difference - extension methods do not have access to the private members of the class. USing extension methods in the example given in the article wouldn't work - unless you expose the private members, which is not a good practice lol üëç
EF team isn't the datateam tho. The datateam is really small, just a couple of people. They mainly do the sqlclient. IsDBNull() is really slow at times, but it takes a hit which you'd otherwise get with a read of the value anyway, but it could indeed be faster. DataTable has an enumerable rows collection if you use the DataSetExtensions. They're really handy, I use them a lot with schema data retrieval :) Not sure why you'd want to start a transaction asynchronously, as most of the time it's a write of a transaction start command and that's it, there's no back/forth going on what has to be awaited: the command is sent, that's it. So async doesn't really make sense (same way async doesn't make sense when calling Read() on a datareader most of the time: the row is already there, read will be instantly and you are actually hurt by the async machinery)
Fewer string allocations.
of course, I see this as I try to build this repo : 1&gt;------ Build started: Project: BethanysPieShop, Configuration: Debug Any CPU ------ 1&gt;Program.cs(27,40,27,47): error CS1503: Argument 1: cannot convert from 'BethanysPieShop.Models.AppDbContext' to 'Microsoft.AspNetCore.Builder.IApplicationBuilder' 1&gt;Done building project "BethanysPieShop.csproj" -- FAILED. ========== Build: 0 succeeded, 1 failed, 0 up-to-date, 0 skipped ==========
I have a multi million dollar app that uses COM, remoting, app domains, Crystal Reports, and dozens of closed source. Net components. I've been slowly adopting ASP.net core in parts for new pieces. But those new pieces call into the old.
Part of the idea behind .NET Core 3.0 is to allow using windows specific APIs through .NET Core. Right now, most of the .NET Framework's libraries are available through .NET Core, even if they were compiled in .NET Framework 1.1 - I am guessing that once .NET Core 3 arrives there will be virtually no library that isn't capable of running on .NET Core. 
Good to see they're bold to shed JSON.NET to keep a focus on performance in Kestrel. :)
If you're using shared hosting, you won't have access to RDP. You can try to see if they offer WebDeploy as an option. In my experience, it seems to be hit or miss as to whether I can get it working. Usually I just publish the project locally,.zip it up, and upload it using the file manager. Once it's uploaded, I extract the .zip file, and I'm good to go.
The .Seed function does not accept an AppDbContext. And it looks like the first thing the function does is find the AppDbContext so it does not look like you need to pass it in. You need to find the IApplicationBuilder instead. I THINK that is the host variable.
&gt; &gt; &gt; Not sure why you'd want to start a transaction asynchronously, If you don't like that, how about asynchronously sending the Commit to the database? 
&gt; &gt; DataTable has an enumerable rows collection if you use the DataSetExtensions. &gt; But why? Why do we need to pull in a bunch of extension methods for something that is otherwise supported by every strongly named collection class? I think because they didn't want to alter the code. the classes are really big, and adding a bunch of extension methods really is all it took. But I honestly don't know. perhaps they thought adding it would break an interface (it would) and therefore it was unacceptable. Frankly I'm really puzzled why they're so afraid of breaking changes on one hand while they toss overboard support for .net 4.5.1 and earlier like it's nothing. Like they want to keep the amount of platforms to support to a bare minimum and not touch anything as the amount of people who have to do the support work is really small. &gt; If you don't like that, how about asynchronously sending the Commit to the database? Why would that need to be async if the call doesn't block? There's no waiting, you call it, it sends the commit command, the end :) it doesn't wait for an ack as far as I know (if commit fails it will result in an exception, as there's no result value to check).
As a new dev I'm curious what you mean by EF dependency? 
/u/Elllmira a telerik employee .. I hope telerik dies a death now that there are many open source frontend alternatives.
Why's telerik so bad?
I do love XAML and ironically more than HTML even though most of my time involves the web these days. It's very verbose yet quite easy to grasp on a overview level though it gets a bit hairy at times when it comes to binding and nested styles. Also I love how you could theoretically override and bind to anything with it as well. But I do hope they continue to improve on reducing verbosity for it, it's been a while since I'ved done XAML but is it less verbose now, do you still need a ton of converters and nested repeating markup? Also I do wonder if it's possible to create a component style architecture like how the web does it on XAML / UWP. Last time I tried using UserControls didn't turn out very well, I guess I'm missing some stuff or maybe it isn't that easy yet.
In my experience, I've been relatively pleased with Telerik when I've had occasion to use their tools. That said, they have had anything but a monopoly. Most of the time, the projects I've been on have had to do without them, and we got by; though we sometimes would have been better off with them. All that said, I really think XAML Standard is where XAML could really shine. UIs are well understood at this point, and the conventions for users even in multiple cultures are well understood, so forming a coherent standard around that is quite feasible and one would not need to become prescriptive to do so. Then, the contest is between the various implementations that use XAML Standard. This is where Telerik would really shine. Having a standard would be a boon to FOSS implementations as well and would allow them to participate in a UI component ecosystem that can be used across multiple implementations, and by extension, multiple platforms.
[removed]
Yeah undo that. It may be what is confusing the installers.
Haven't been back to desktop programming since we've focused more on web apps from where I work. Thanks for the heads up I'll check it on my free time. Have only tried WPF so far, they say UWP has improved a bit on binding using `x:Bind` vs `Binding` but haven't tried any yet.
[removed]
This is the first thing I thought! BUT Ilmerge can merge managed DLL &amp; managed DLL or unmanaged DLL &amp; unmanaged DLL
My previous company we had a bad joke:"When is a bug not a bug? When its Telerik"
You can deploy straight to an App Service in Azure. Add an app service in Azure, then in VS just right click your project and "Publish..." and put in your credentials, select the app service you created. 
This
Never has incrementing major version solved any problem regarding huge breaking changes. Adapting to the change is still necessary and a potentially expensive task - unless you choose to stay on a soon deprecated fossil version, which will give you all kind of compatibility problems with other libraries and what not. So.. I don‚Äôt have any opinion on json.net and breaking changes there, but believing semantic versioning will solve anything is quite naive. 
hmm... but then it would be hosted on azure?
ASP.Net Core depends on Entity Framework Core.. Kind of, at least. ASP.Net Core references Entity Framework Core, even though it isn't strictly needed. So even though my ASP.Net Core app might never use or touch any EF bits - even within the ASP.Net Framework - it's still referenced. This isn't really a problem in and of itself. The real problem, imo, is that the reference is strongly tied to a specific version of EF. So, if I'm using ASP.Net Core 1.1 I can use EF Core but *only* v1.1 of EF Core. If I use ASP.Net Core 2.0 then I'm locked to version 2.0 of EF Core. It is not possible to use assembly binding redirection to use differing versions of these two components. I'm forced to update my web framework and ORM in lock step, which is not always feasible or reasonable.
If you can just simply swap out EF for Dapper you didn't need EF in the first place.
That is disappointing. I can understand the reasoning, but it feels a bit like a bait and switch at this point. We're going to end up stuck on v2.1 for who know how long because of that.
If you wrote regular [asp.net](https://asp.net) mvc web app, you would need .NET hosting to host it. Those are running on Windows boxes. Most likely your current hosting is Linux based.
New projects aren't the concern. I think its the large number of LOB and enterprise applications that were originally written in .NET Framework.
Ahh, I gotcha.
Ive Just found out about Azure DevOps. Think that's a complete solution.
Oh ok, I understand now. I've only worked in a regular .net project but I plan on venturing into .net core soon in my spare time. The web app I work in uses some homebrew ORM system that's about 200k lines of code long in one file now. I think it would be great to move toward EF. &amp;#x200B;
&gt; The web app I work in uses some homebrew ORM system that's about 200k lines of code long in one file Ouch. Good luck.
Welcome to the world of consulting where each project is a different animal. Nowhere in my comment have I stated that I only work in a single code base.
Right. Agreed. I probably would have never started using it had I know that. I'd have picked something else like Nancy.
I think you're being downvoted for saying SOLID is BS, but I agree with the point that making something public that should be private is not a violation of open/closed. That's exactly what I thought when I read the post. 
I'd personally still rather work with ASP Core 2.1 than Nancy..
Probably. People treat SOLID as a religion; never to be questioned or even thought about.
Well, I think most people just kinda agree and move on, but yeah there's a lot to question about it and many instances where it doesn't apply. It's a useful starting point but it should be used to make every decision. 
Resource intensive: yeah. It's Chrome. So it's probably ok if you have a server with 2gb ram. Probably best to test for your purpose. With Puppeteer you can control the page size, so i assume you can with Puppeteer sharp as well (I've not used it yet)
Yes, well, if I'm going to adopt technology that might last 10 years, I'm not going to pick something that has no useful development plan beyond the next one.
I am sorry about that, my bad
&gt; no useful development plan beyond the next one Are we even talking about the same Nancy? https://www.nuget.org/packages/Nancy/ https://github.com/NancyFx/Nancy/issues/2872 I'm not sure how you could consider that a better bet for 10 year support than ASP.Net Core 2.1.
Seconded. I just discovered it yesterday (even though it's just a rebranding of VSTS or something..), and have already set it up for my CI build. Not too difficult to get going
Xaml is still verbose and infleixble. I don't use converters (I prefer a UI getter), but I still behaviors a bunch. You can't make a I don't think you can implement a [responsive layout grid](https://material.io/design/layout/responsive-layout-grid.html) - well you can, but it'll just be a very shallow hierarchy. It's not only verbose, but I also don't think it's all that re-usable. I doubt I can transfer my Xamarin xaml files to a WPF/UWP/Avalonia project. 
Your question is rather unclear. Do you have a solution that has a webforms project, and a then an API project, too? Or do you want your webforms project to be able to call some separate API and get data back?
I have a webform project that seems to have a some reference in a Web References folder under references.vb to some EWS classes. But when I check Nuget there is no import for the EWS API. I wasn't sure how those references worked in relation to an API library I could download and import using Nuget. &amp;#x200B;
Yep, Azure DevOps (fka Visual Studio Team Services, [https://azure.microsoft.com/en-us/solutions/devops/](https://azure.microsoft.com/en-us/solutions/devops/), and Azure Pipelines,[https://azure.microsoft.com/en-us/services/devops/pipelines](https://azure.microsoft.com/en-us/services/devops/pipelines), should be a good fit. It has great integration with Bitbucket Cloud and you can try it for free (for up to five people). While my team doesn't use BitBucket, we do do all the things you mention. You'll want to use a private agent for your builds and releases (i.e. the Azure DevOps agent running on a machine on your network).
&gt; if commit fails it will result in an exception, as there's no result value to check How would you accomplish that if, as you say, the call is non-blocking? i think you're not thinking it through... :)
How good is the `NET Standard 2.0` support?
WebDeploy becomes pretty easy to use when you read the docs. What kind of problems do you experience?
.NET Standard basically means the code only uses APIs that are common between .NET Core and .NET Framework at particular versions. The most problematic cases will be if you are using Windows-only APIs or third-party libraries which are not compatible with .NET Standard.
If it's a webAPI project, you probably shouldn't be importing it and calling it locally like a standard DLL or referenced project. It's designed to be run as a Web API So it should be added as a separate WebAPI project in your solution, and your code should call it's controllers over an HttpClient instance (or similar) When you run your solution, it will launch your main project, and also fire up a local Web server to host the WebAPI that will react to your calls to, for example : http://localhost:4030/myWebApi/myController/Get 
Thanks!
It's not a WebAPI project, just a traditional asp dot net webform project using vb dot net in the code behind. I'm trying to learn how they have it set up and doing some of the things it does. For instance in the references.vb there is a class for exchange service builder which is from the exchange ews api. But they don't actually import the ews API they just reference the classes from the references.vb. 
Doesn't matter. If you're loading a Web Api package (as in your post) then that package has been set-up to run as a hosted API Feel free to use it, but you have to host it as an API, you can't just load it as a DLL
Web api probably isn't the correct terminology. I used that I think because it was in the web references folder but I think they've sort of imported what they needed somehow(not nuget) and compile it all together. &amp;#x200B;
+1 agreed!
Ok. Suggest you try and either find the correct terminology or clarify the question to include what package(s) you're trying to import. Hard to help from the information given if not accurate. Nobody is going to get this far into the conversation to find that information. These things are confusing, no biggie. 
JObject and JArray will be sorrily missed, I hope they have a replacement in the works for that. Json schema validation is actually the one place where I found Json.NETs limitations. They want you to purchase a license for high usage scenarios, where as JsonValidator4 (I think) is entirely free and works on top of Json.NETs serializers.
AFAIK, .NET Standard 2.0 is supported (i.e. fully implemented) since .NET Framework 4.6.2. What do you mean exactly?
[removed]
\+1 for Azure DevOps
AFAIK, .NET 4.7.1 fixed **nearly** all the integration headaches that came out of decisions that were made during the .NET Standard 1.x series (binding redirects, extra packages with forward-only assemblies that you have to deploy). IIRC, .NET 4.7.2 fixed one or two more, but the situations would only have come up when you're targeting .NET Standard 1.x (I'm going from memory here, and my memory on this one is hazy). AFAIK, .NET Standard 2.0 libraries should work the way that you and I expect them to as of .NET 4.7.1, and .NET Standard 1.x libraries should work the way that you and I expect them to as of .NET 4.7.2, perhaps with [this one issue](https://github.com/Microsoft/dotnet/blob/2ab884e04a0a40c84dcb8782033b2191b7a94fd4/releases/net472/KnownIssues/613745%20-%20Single-name%20references%20are%20removed%20by%20the%20SDK%20when%20targeting%204.7.2.md) that looks like it has to do with MSBuild itself and not a particular version of .NET.
[removed]
fun fact is that Newtonsoft Json has an aggressive change of major version with non-noticeable changes from one version to another. &amp;#x200B; Less fun fact when library authors (NEST, I'm looking at you) have strong locks on major versions of Newtonsoft.Json...
This is really cool. I work on a machine learning platform for embedded devices, and seeing something capable of doing C# in that world is great. 
While this is cool I don't see the point, a pi zero w does the same job and at a fraction of the price the only downside is that you have to install mono. 
For personal projects it's fine. For enterprise projects it quickly becomes a minefield of who owns what data and it's MUCH more preferable to just use internal storage. Plus, articles like this are more useful when they show the entire process. Just saying "now here setup auth0" isn't very beginner friendly. 
Mono lacks support for few things here and there.
[removed]
I'll have to go through an implementation of self hosted authentication / authorization to learn more. It's just that authentication is such a complex subject that you could pretty much spend weeks and months learning the different flavors and proper practices. The big reason why I went down the route of using Auth0 was because otherwise its yet another thing to learn/manage. I'm relatively new to dev work so I wanted to learn more of the fundamentals first before going into authentication.
What's the use case for this?
Yes. Unless you have an identity team/specialist (as some enterprises do), don't roll your own. 
Auth0 can get REALLY expensive if you have thousands of users
I spun up a default project and tried it and it worked perfectly. [https://i.imgur.com/N4dapRE.png](https://i.imgur.com/N4dapRE.png)
&gt;How many Assembly binding redirects and additional package references will you need to make it build, and how many run-time edge cases? yeah seriously, I've had issues with system.data.sqlclient, binding redirect hell with system.net.http... I've had to indeed switch all my netstandard2.0 nugets to have target netstandard2.0 and net461 
The diagram on the kickstarter page shows .Net standard on Mono Runtime 
On the topic of "Things smaller than Full-Sized Raspberry Pi that run Standard/Core" ... &amp;#x200B; Anyone have any insight/experience with the [Banana Pi Zero](http://www.banana-pi.org/bpi-zero.html) ? Raspberry Pi Zero won't run Core, as it's only ARMv6. Seems like the Banana-clone should run Core, but my google-fu fails to find any others experimenting with this. It's not terribly expensive but i figure there will eventually be a BCM2836/7 variant of the RPi Zero (or a more-affordable "Meadow" sort of thing) so will skip guinea-pigging the clone. &amp;#x200B; (FWIW i am not mono-averse, i just luv me some Core/dotnet cli &amp; looking forward to Core on tinier things) &amp;#x200B;
Some cultures (most notably Japan) use the fiber in the banana plant to make fabric and sometimes even paper. *** ^^I'm&amp;#32;a&amp;#32;Bot&amp;#32;*bleep*&amp;#32;*bloop*&amp;#32;|&amp;#32;[&amp;#32;**Unsubscribe**](https://np.reddit.com/message/compose?to=BananaFactBot&amp;subject=I%20hate%20potassium&amp;message=If%20you%20would%20like%20to%20unsubscribe%20from%20banana%20facts%2C%20send%20this%20private%20message%20with%20the%20subject%20%27I%20hate%20potassium%27.%20)&amp;#32;|&amp;#32;[**üçå**](https://np.reddit.com/r/BananaFactBot/comments/8acmq6/banana/?st=jfof9k8d&amp;sh=acd80944)
[removed]
Brings NETMF memories.
Good deal - thanks for the response. I'm not using JST's but the same can be achieved with cookie claims. So what I'll do create a claim with an "expiration date" and then set up an auth policy that only allows the user access the app if the expiry date is still valid. And with every ping from stripe for successful payment, I'll just update that claim.
&gt;Brings NETMF memories. It sure does.
Still somewhat alive... I think they continued to work on it when NETMF was abandoned... https://www.ghielectronics.com/tinyclr/features 
The quality of the various tools and libraries differ greatly. - Kendo is actually great, for the most part, but some features appear to be built purely for demo purposes but are actually quite limiting when used in production. Luckily it is Javascript, so there is almost always a workaround or solution. Extending Kendo is very hard, probably even unsupported. - Telerik ASP.NET Web Forms controls are often a complete mess and quite buggy (ComboBox and DropDownTree). - Debugging Telerik ASP.NET controls is very hard, and code-wise they appear to be messy built (based on decompiled/minified code) - Kendo MVC controls make it easy to emit non-working HTML/JS. - Fiddler is a complete mess since all the ads were added, but there is no (free) alternative. In all these cases actually styling these controls is hard, but Kendo is easier then the Web Forms controls. The Web forms controls are really horrible to style, often needing to resort to !important. On the other hand: - The license is royalty free, you pay per seat, not per deployment. - Support has quite small response time.
Most amazon services, including cognito, have a lovely free tier that is pretty robust and should allow you to stay on it for at least the first year if not longer. After that it is pay for what you use so its remains affordable 
Disclaimer: I work for Microsoft/Azure, but not on the IoT team. Azure Sphere is something really awesome. The dev kit is kinda expensive but the individual units are supposed to be rather cheap. Remote code deployment and debugging is all included. I haven‚Äôt had a chance to play with it myself, but if it works, it‚Äôll be amazing.
In all honesty, services like AuthO are pretty good. However, setting up proper auth that scales is pretty easy with Identity.
What is the value of the incoming accept header?
[removed]
In general 4XX errors are errors with the request, not the response. HttpNotAcceptable (406) generally means the server isn't equipped to return a response-type the request specifies. You're returning "application/soap+xml" meaning your request must indicate the MIME-type "application/soap+xml" is acceptable. To test this, changing the response MIME-type to something generic "text/xml", "text/html", etc would probably lead to the browser displaying the response (although likely not handling it in the way you expected). If that does work, then it's likely you'll need to form a request that has an accept of "application/soap+xml". Assuming that is indeed what you want the browser to believe it has. I don't recall a browser ever handling SOAP, I had thought that was a server-side exclusive, but it's been quite some time since I've dealt with SOAP, so I may be completely incorrect there.
Aaah, i see one can set defaults: `@page "{Id=1}"` So thats okay then. Still. Runtime error would have been useful. &amp;#x200B;
In this case I'm using a basic HTTP client tool (Insomina) and I have the exact same request going to the existing (legacy) SOAP service end-point. A few things to note about this. &amp;#x200B; 1.) The legacy SOAP service end-point that I'm hoping to emulate with .NET Core is responding as normal and as expected. 2.) The HTTP request (headers and payload) between the legacy SOAP service end-point and the new .NET Core end-point are identical except for the end-point URI 3.) I have a break-point set inside my .NET Core service controller right before it returns the response and everything looks good. I see a well formed XML payload in expected SOAP format about to be returned. It never makes its way back So if it's a case of "4XX - You fucked up" that either means .NET Core 2 service are incapable of giving us as developers the level of control needed to get to the metal and have complete control of the the request and response without some level of inference. This is what I suspect the problem is. &amp;#x200B; I know this is a Microsoft focused reddit and I greatly appropriate the help, but I have a small rant: Although the ugly days of WCF seem mostly behind us, Microsoft's engineers can't seem help themselves when it comes to layering abstraction on top of abstraction. The mindset seems to be that as a developer you should invest time learning their abstraction layers and writing a half pages of code to accommodate those abstraction layers, all in the name of "good structure" and for what benefit? Having a boat load of mostly poorly documented configuration and serialization options that we'll never use? Of course all of this additional effort means more billable time and makes for a good paragraphs in the project proposal hailing .NET tech over it's competitors, but for the most part it's just a load of crock. A half day of scratching my head and trying to find good documentation on creating my own OutputFormatter (assuming that is the problem here) and meanwhile programmers in languages like Go could have written 20 lines of code and have been done. I hear you say "Why don't you just use Go then". I would if I could.. I would if I could. I don't control the tech stack on this one just trying to make due. Up until this point I was starting to get along with .NET Core, but sadly I knew the attraction would eventually hit a wall over something stupid like this. It seems to always be about Microsoft taking away our power as developers or making us jump through hoops... It's odd some developers seem to enjoy that or think it's a good trade off for some other benefits (perhaps marketability of skills is the primary one). Digression done. &amp;#x200B;
In the original request being sent by our SOAP clients there is no incoming Accept header value. Just Host: ... Content-Type: text/xml; charset=utf-8 SOAPAction: ... Because I need for the .NET Core based Service controller to accept the same header and responses as the legacy SOAP asmx service does, I should be able to make the .NET Core service end-point successful return a response without requiring an Accept header parameter... As mentioned in my other post, it seems to be a case of Microsoft's abstraction layers not providing us a developers the necessarily level of to-the-metal power to control the HTTP request/response to accommodate this, but I'll be delighted if I turn out to be wrong about that. &amp;#x200B;
[removed]
Aha so does that effectively make it 'nullable'?
Well look at that. Apparently we even have docs on pen testing on Azure. Might be a great way to get a few resources running for cheap if it matches your needs. https://docs.microsoft.com/en-us/azure/security/azure-security-pen-testing
Try adding `options.FormatterMappings.SetMediaTypeMappingForFormat("xml", "application/soap+xml");` to map the SOAP content type to the XML format. Apologies if formatting is botched - I‚Äôm on mobile at the moment.
Ok, so interesting... Adding this and adding back the xml output formatter public void ConfigureServices(IServiceCollection services) { // services.AddMvc(); //(o =&gt; o.InputFormatters.Insert(0, new RawRequestBodyFormatter())); services.AddMvc(options =&gt; { options.ReturnHttpNotAcceptable = false; // If you need to add support for XML options.OutputFormatters.Add(new XmlSerializerOutputFormatter()); options.FormatterMappings.SetMediaTypeMappingForFormat("xml", "application/soap+xml"); }); } Lead to this response. &lt;string&gt;&amp;lt;?xml version="1.0" encoding="utf-8"?&amp;gt; &amp;lt;soap:Envelope xmlns:soap="http://www.w3.org/2003/05/soap-envelope" xmlns:xsi="http://www.w3.org/2001/XMLSchema-instance" xmlns:xsd="http://www.w3.org/2001/XMLSchema"&amp;gt; &amp;lt;soap:Body&amp;gt; &amp;lt;AddTheseNumbersResponse xmlns="http://tempuri.org/"&amp;gt; &amp;lt;AddTheseNumbersResult&amp;gt;22&amp;lt;/AddTheseNumbersResult&amp;gt; &amp;lt;/AddTheseNumbersResponse&amp;gt; &amp;lt;/soap:Body&amp;gt; &amp;lt;/soap:Envelope&amp;gt; &lt;/string&gt; Not exactly what I was looking for, but the 406 is gone. According to this article https://www.codeproject.com/Articles/1204319/Formatters-in-ASP-NET-Core-Web-API It sounds as if there has been a lot of good advice given in this thread, pointing to a possible outcome. However be design .NET Core will not allow a custom formatter to be applied without the Accept header on the on the incoming request... Narrow minded design on Microsoft's part that's only evaluating current best practices with no regard for developers needing to provide legacy support or need to accommodate scenarios outside the box. &amp;#x200B; Thanks all for the advice. It would be nice if there was a solution, but I've wasted enough time jumping though Microsoft's hoops on this one. Going to revert back to .NET Framework 4.6 and just build out a SOAP end-points without .NET Core, it's simply incapable of doing what I need it to. Pity. &amp;#x200B; &amp;#x200B; &amp;#x200B;
Technically it's not an error. It just can't find a matching route - thus "not found". It has no way of knowing if you only want it to match with numbers, or match with numbers or nothing - that changes on case by case basis.
If you are this disillusioned, I suggest you switch platforms. What you described can be solved, quite easily actually with ASP.NET Core, even if you try to force it onto MVC. Even the "legacy" MVC was incapable to send SOAP responses in a uniform way, but the new ASP.NET Core can. You want to use a legacy technology? Go on, no one is stopping you. You want to use a newer technology to support the legacy solutions? Go on, implement it yourself. Don't bog the framework down. In [this post](https://stackify.com/soap-net-core/) you can see a solution to use SOAP requests and responses with ASP.NET Core. Just so you know, it is possible to implement it with middlewares and in MVC's pipeline too, I was tasked to do so last year. Keep in mind that this is SOAP, not WCF. Sorry for being rude, but I don't like when people complain about something and blame it on other then themselves when they are the ones incapable of coming up with a solution. This is a form of toxic behavior which you should try avoiding. Cheers, and good luck!
Write it up on GitHub and someone will give you the correct solution or it'll get fed into a fix.
Why do you need this? Could be a good application for a HTPC setup. Can't think of anything else
Afaik, there is no way to do this. The same as you won't be able to know whether `Foo`'s constructor was called, you won't know whether any of the methods you mentioned was being called. You have to modify the dependency to use an abstraction rather than the actual implementations.
Span will help with ***sane*** passing of byte-slices, aswell as string allocations. Most of the performance would come from native UTF-8 string handling, instead of prior change to UTF-16
If you think this "breaks things", you've never worked with JavaScript.
You've nearly solved it; all you need to do now is remove the XmlSerializerOutputFormatter and perhaps others with OutputFormatters.RemoveType&lt;T&gt;, forcing your raw string to be returned without further manipulation. The response you are getting now is a string serialized to XML. The root of your problem is that out of the box ASP.NET does 'auto-magic' content negotiation, allowing you to return unformatted objects from controllers while allowing clients to choose to receive responses in json, xml, or other serialized formats based on the Accept header. This has been an annoying task for you because your Accept header does not match the Content-Type header of your response, and because you are building your SOAP by hand. Your use case is rather esoteric, and the benefits the rest of us get from content negotiation far outweigh the impact to edge cases (imo). 
&gt;Azure Sphere This is the first I've seen this. Looks interesting. We used Azure IoT services with an STM-based device this year. We are a MS shop for the most part and wanted to leverage Azure knowledge. If I had any complaint to the IoT team it's the lack of updated documentation and code samples on the device end, especially anything targeted at non-hobbyists. 
I agree and think you should submit this to the feedback hub in Visual Studio.
You can pass in an initialized predicate, and so autocomplete is perfectly valid right there. You just need to keep cancelling autocomplete before hitting that space. :)
This might be a dumb question, but do you have a `using System.Linq` statement? This happens to me all the time in files that don't have one yet.
&gt;initialized predicate TIL! This is almost never what the developer is doing though and Intellisense(?) should be able to only hint initialized predicates that start with what I have typed (or leave me alone!)
I was going to say that. That, or just `using System;` because that seems to be required to get lambdas to work right.
&gt; If you are this disillusioned, I suggest you switch platforms. You want to use a legacy technology? Go on, no one is stopping you. At times as developers we are placed on projects where the technology stack is fixed by our employer. I've made clear that I would be using a different technology for this scenario if that were an option. After reasonable exhausting the options here with .NET Core (thank you everyone for the discussion) I did mention that I'm pursuing the one alternative choice available to me, going back to the full .NET Framework and it's robust support for SOAP. Gears have already been shifted so no need for further responses on this thread unless some kind folks here want to help follow through so it's recorded for future reference. Prior to beginning this thread, I had already followed the solution in the post you provided. Unfortunately that's not compatible with SOAP 1.2. The point you seem to be missing is that I'm not complaining about people here, I'm complaining about a framework does not allow us as developers to have complete control over the HTTP request/response. I've agreed that the automatic contract negotiations are good for most when I said "... For most projects that's probably fine and a not such a big deal. For many of mine it wouldn't be a big deal wither. Everything we do these days is REST based APIs and .NET Core does REST very well.". Perhaps you missed that, there are so tall walls of text in this thread. I could also go on about how SOAP (Simple Object Access Protocol) was heavily backed by Microsoft and designed to be future proof. "you can boil it down to XML over HTTP" I recall one enthusiastic presenter from a Microsoft hosted developer session in the early 2000s. In the end there is no one technology that best accommodates every scenario. Anyone who gets defensive and evangelistic about a certain platform needs to break the tribe mentality and get a reality check. I don't expect .NET Core to behave like other languages and do see the value in it's paradigm. That said all I'm trying to do is have complete control over how my service handles the incoming response headers and payload and how it returns a response. This isn't rock science and in order to help make .NET Core future proof this should be something we can do if not in a direct way, then by writing our own output formatters, etc.. It's yet to be resolved if that is even possible for my scenario. It's really the most basic of operations that any framework should allow the developer to do and here we are a few pages deep in responses and there is no solution, just partial solutions that Microsoft's baked in contract negotiations enforce and take away our power as developers. That's not about legacy support, that's about their blocking general low-level protocol access. If you think that will level of control and access will never be necessary, then you are either inexperienced or your development scenarios are very limited. Regardless, for most cases as you've pointed out there's other tech to turn to. It just gets old hitting a wall with Microsoft's technology stack time and time again. &amp;#x200B;
&gt; or just using System; because that seems to be required to get lambdas to work right. Uhh... no.
Since you agree, you could submit the feature request on behalf of yourself. It only takes a minute.
For what it's worth, it doesn't spaz out if you declare your type first. I like having that anyway, but that might just be because i'm terribly forgetful.
Maybe I'm remembering Rx and not Linq, then? I know Intellisense would always balk if I didn't include it. --Actually, it is Rx: `IObservable` is declared in `System`.
This is why I love ReSharper. Its autocomplete engine is so much more intelligent than ***Intelli***sense.
*No availability outside the US.* 
The XmlSerializer is taking your output, escaping it, and adding the &lt;string&gt; around it. So you don't want that. Maybe remove the OutputFormatter line.
Thanks, yes I figured. I've cleared all OutputFormatters. No luck. 
The standard structure is to create a directory for each namespace in your code at the root project level, and set the Root namespace in Properties for the root namespace these folders will build on. Then when you add a new class the namespace will be constructed properly.
If you mean store the password in memory , there is [securestring](https://docs.microsoft.com/en-us/dotnet/api/system.security.securestring?view=netframework-4.7.2). 
Jetbrains' Rider is also a pretty nice lightweight replacement for Visual Studio and has most (all?) of the ReSharper stuff baked in. I was at the point where I couldn't have more than 3 Visual Studios open or they'd be so slow as to be unusable. I can have a dozen solutions open in Rider and I've not encountered issues. Doesn't quite replace everything that Visual Studio has yet, though.
[removed]
[removed]
[removed]
I've tried a few times over the years and felt the same. People keep saying most of R#s functionality can be replaced with newer free/OSS extensions, but there's a ton of hidden functionality in R# that just isn't available in any extension or doesn't work as well. Not to mention the convenience of just installing one add-in over multiple extensions.
[https://visualstudiomagazine.com/articles/2016/12/01/hashing-passwords.aspx](https://visualstudiomagazine.com/articles/2016/12/01/hashing-passwords.aspx) Store the hash with the salt as base64. You would never know password itself - when someone inputs a password you just get the salt, repeat the hash on the input and compare that with the stored hash.
[removed]
I don‚Äôt know if it‚Äôs the ‚Äú.net way,‚Äù but I‚Äôll say this : If you‚Äôre just trying to protect the password from a casual tinkerer , encrypt the password using an embedded key and write to a file. If you‚Äôre looking for better security , you might be better off going to a security forum , because with anything I can think of , someone determined with a decompiler and/or debugger will be able to intercept either the password itself or the key used to encrypt it .
[removed]
Maybe for presentations or something
We all have jobs.
So you would say the demand for this position is high in today's market?
Has demand overtaken supply? Maybe. Maybe the headhunting site's algorithms aren't working? Offer an insane salary and you'll probably see lots of resumes come out of the woodwork.
I'm from the Midwest but will comment. I am happy at the company I am at and don't even entertain other offers. Decent pay, awesome benefits, great coworkers, and I like what I'm working on. I agree the demand is higher than the available workers. You could try lowering your experience/educational requirements, maybe even an entry level, look at first time job employees. It's always hard coming out of school trying to find a job. They may lack experience but you can mold them. And if you pick the right one, they will gain the experience and quickly at your company. 
If you're looking for fresh apples, go to the tree... I would suggest you take a look at colleges and universities. I know my company regularly does recruiting at state universities.
As root54 said, we all have jobs (even those outside US, remember that reddit have plenty of non-american users).
o{escape}=&gt;o Maybe {escape}{escape}
Also some refuse to talk to recruiters.
Low turn-over in some cities coupled with refusal to deal with recruiters and head-hunters probably. You could offer me the sun and moon to leave my job but if you're with a recruitment firm or head-hunting agency I won't even give you the time of day. You may have better luck approaching new grads, like others have mentioned.
I'm in the DC area, there seem to be a lot of .NET jobs and developers here, probably because of government work.
I work from home in Phoenix for a company in Boston. I've been doing this for the past 6 years. I also have 30 days of PTO each year. Stop harassing me with shitty jobs with 1 hour commutes for 20k less and less benefits than I make already. That's why you can't find anyone.
[removed]
i'm a junior but .net devs in my experience stick around in jobs a lot longer than the norm. also they don't really teach .net/c# in colleges or at bootcamps so there are less of us. job security yo!
... which is not wise, at least in NYC. Lots of well-paid .NET positions (finance mostly, but not exclusively) are filled through the agencies and never announced publicly.
We have had a chronic shortage of (decent) developers in our company too. A client of ours has the same problem. I dunno, I'd say that many people find developing generally very hard. I mean, it's not the coding itself, it's the talking to often times clueless clients who haven't got an idea what they actually need to all the planning and documentation that is involved. Plus, if you're working for corporate guys like banks, there is the stress that any mistake could potentially cost millions. That's how I perceive it anyway and it's been hard to hold on lately.
Based on what I've observed coming through candidate wise, none of the good devs are looking for work.
Companies have learned how to hang on to good talent. For a while devs would jump job to job every 1-2 years. They would seek better salary, better environment, better benefits, more training, yadda yadda... The companies starting asking "How can we hang on to our talent?". Now they have studies they rely on that tells them how to keep talent in house. So basically, dev's are jumping around less often which makes them seem more scarce.
Well sure but if you need a visa good luck with recruiters...
Your role is diminishing, that is why. 
As a .NET dev in the literal middle of Illinos, I'd jump on a 130k salary in a heart beat if i could work remote. I imagine with Cost of living it would be about the same as what i make now.
I love the recruiters i work with and always enjoy helping out when i can. We all need to make a living and being helpful, polite and thoughtful goes a LONG way. 
Lack of .NET usage in school has always been a big obstacle. For whatever reason schools favor other platforms so graduates often do not even consider it as a platform when entering the job market.
We're all switching to AWS, React and Node. üòÅ
I'm happily employed. As the saying goes I'm always looking for work, but 99% of .NET postings just don't appeal to be because they are intermediate level and too corporate for my tastes. If you want to grab my attention with a .NET posting, focus on what you're doing in addition to .NET (cloud computing, devops, frontend that doesn't involve using MVC, that sort of thing).
I've had the great fortune to not need a linked in account or use job sites. That may change one day, but that's my story. 
I won't ever return to an office as long as the market is strong enough that I can choose not to.
Most colleges/universities don't teach the .NET Stack, so trying to grab experienced .NET devs can't really happen out of college unless they're self-taught. Not saying that's what OP is trying to do, but if they are having problems getting devs they're probably already looking for Senior devs or at least a few years of exp.
There‚Äôs more roles less talent. I‚Äôm in UK as a contractor. Is see tens of new perm roles every week and the same ones hang around. Also perm roles pay here isn‚Äôt good. 
I'm not saying all recruiters are bad but some of them are very insistent and most of the interactions I have had with then were unwanted. But I understand that some people prefer to use a recruiter to find a new job. I've also had some good experiences with recruiters when searching for people to fill up positions. 
In Chicago, I am getting a ton recruiters that are looking for .NET developers but the highest salary they are willing to pay is $10k to $20k lower than what I make now and worse benefits. Why would I leave?
May I ask if you're trying to recruit frontend or backend developers? I have a feeling there are more back end developers than front end for .Net
[removed]
[removed]
I often pass in a method name, which is probably more common than an initialised predicate l
NYC has an ungodly expensive cost of living as I‚Äôm sure you know, and the dev jobs there don‚Äôt pay all that much more than ones in other large cities(Denver for example) that aren‚Äôt quite as outrageously expensive as NYC. What experience level are you looking for? And how much money are you offering them? Knowing this would at least eliminate an easy reason why you aren‚Äôt having much success filling roles. Best of luck finding candidates. 
San Diego / Orange County. Market is strong here. I've been working as a contractor for the last 13 years. I've never been unemployed. In fact I tried to take a couple months off and I kept getting calls and I wound up taking the gig where I am now (finance). I only do .net - WPF, WCF, Web, Web API, and javascript with the latter as little as possible. 
not! :)
The body shop cold calls are the worst for this. I‚Äôm not interested in leaving my cushy permanent position where I have underlings to be a code monkey in Nowhere, USA for a three month contract.
2007 called and they want their tech back.
It seems that you recruiters are always looking for full time employees, but in this market, who wants a job? I'm freelancing, and I don't want an employer. Even though I try to offer my consultancy services, it's like you are never open to anything but full time. Makes me look for customers through other channels.
I‚Äôm in NYC. The market is very hot now. A few years back, the .Net ecosystem was not as sexy. With a lot of the stuff Microsoft is doing with .Net Core, and Azure/Cloud stuff, it‚Äôs seeing a renaissance. A lot of financial services and fin-tech companies are modernizing and looking for people. It‚Äôs very much a developers market at the moment, especially in NYC. 
Yeah I hate the short term contract thing. The company I work for got acquired a few years ago and we went from 15 people (4 of which were devs) to 400 people so the salary limitations have gone away for me and I don't see a financial reason to get a different job (yet).
I guess I was thinking more along the lines of how picky I'd be. If I were to take the first thing offered I bet I'd land something within a week, at least get the offer. 
Ahh ok, I gotcha. Yea, finding a job is easy. Finding a good job might take some time.
The article does say 2014, but I get your point that it is a little old. Do you have a better approach? I typically do things like this in PowerShell to create a RESTful API service, as I like to keep things uncompiled. Is there a more modern and simple approach for something with code behinds, or is that the part you find comical?
I would run an email service on the backend, therefore it doesn't matter what the frontend is. Submit your data through a post request and let the service handle the rest.
I worked in an office for 5 years (for different employers) before going remote full-time.
Visual Studio Community, SQL Server Developer - both free. 
Agreed. I feel like I hit the jackpot with mine. We're employee owned and we all work from home. Solid company with good growth and great benefits. 
[removed]
I personally pay for the full JetBrains suite (got it cheap on friendship day) and use Rider, but before that I was just using .net core, vscode and the terminal - learnt a lot that way.
Good devs make their bosses highly motivated to retain them. 
You can also further your other technology understandings. Is your goal just to be better in your current role? In that case, I'd ask about training/educational courses or conferences or using your work pc for home projects (which may get into a gray area of software ownership that some may be uncomfortable with). 
&gt; Is it that less people are training to become .Net Developers? there's your problem, unless you absolutely need .NET expertise a skilled senior developer can hop from language to language without much difficulty. I work in at least three programing languages daily, often many more doing both front and back-end work. Just because someone says they do Java doesnt mean they cant learn C#. 
Not as many as you'd think I'm looking for something in the $140-160k range and am having trouble finding much for .NET 
I'd say 3-5 years would be a reasonable amount, more if you can land a high profile job such as something at one of the big 5 or a trendy startup.
On site only, no C2C, Skype interview I will never again put my phone number or primary email on my resume.
SecureString isn't as useful as you think. Here's a discussion/review by the .NET design team: https://www.youtube.com/watch?v=28xZ7Xb5MhE
Come up to Chicago. Wasn't hard to get competing offers over 120k for .NET work 
I got hired full time through the co-op program at my school. I know in the Midwest, there are tons of .NET job openings and not enough devs to fill the jobs. Horizontal job switches usy result in a substantial pay increase up to the market max. 
[removed]
The economy hasn't experienced much in the way of downturns recently; most folks good enough and driven enough to have and want development jobs probably have them and haven't been squeezed out by layoffs. You might not be paying enough to attract people away from their jobs and if you're not looking for remote workers, you're further cutting down on your chances.
Or vice-versa.
I'm glad I was exposed to it in school. They just taught webforms but it was enough to let me jump into Core in no time at all. 
[removed]
Yep, I agree and would do side work remotely as well.
&gt;IT Executive Recruiter What does that even mean? I dug this email out of the trash, clearly they didn't really look at my CV when I dealt with them a few years ago. I repeatedly told his predecessor that I don't do front end stuff. After my previous reply that I was not interested, he still sent me this. I didn't feel like it justified a response, so I simply deleted it. &gt;I was calling as I thought I have something relevant, and you‚Äôve been in your current position so I was curious to hear if you would consider other opportunities. &gt;I‚Äôm looking for a Senior Full Stack Web Engineer for a fantastic product company in &lt;my city&gt;. A background in C# is really advantageous, and you would also be working with Node/JavaScript/Angular/HTML5 on a daily basis. The real 'nice to have' for this role is mobile experience (Android), or Cloud experience (Azure) &gt;This is a family-feel company in an exciting period, and the project is a real-time communications platform. They offer can be very competitive with salaries etc, but more importantly it‚Äôs a company offering flexible working hours, generous vacation, bonus, RSP, fully paid benefits etc. 
1. Don't make your ad so generic. I see things like "Great pay, benefits, and company." Yeah, you haven't distinguished yourself in anyway that makes YOU better than most any other company we can go to. Tell us what makes your work environment better than the one I have. Meals at work, latest badass laptops, tickets to sporting events, things that we can do with our families outside of the normal "benefits" most speak of. Someone mentioned that if companies were willing to hire part-time remote help, they'd consider the work. I am one of those people. I currently work as a penetration tester (GWAPT certified) and consult with developers to tighten their code. Anything in those realms of part-time work, I'd be interested to hear. :) 
[removed]
I'm actually looking to leave.... to start my own business that I'm launching at the beginning of the year :) But no, my teams isn't hiring at the moment.
So they want .net experience with angular, but really want you to write Java for android apps. And this is why people think recruiters are idiots.
Yeah , I‚Äôll watch the video in a bit; but from my understanding securestring just reduces the footprint of when the plain text is accessible in a memory dump; but at some point the string has to be used at which point you‚Äôll have exposure .
Thanks dude, I'll share on here when it's ready. Maybe even /u/teeheeMcweewee will sign up for it (my SAAS is for recruiters).
Exactly. I didn‚Äôt know what I was doing. Why be so snide? I had several projects I was working on for different people today, and this was an unexpected one, so I did what I knew, got stuck, posted a question, and realized I could get around it a different way for now. If you don‚Äôt know how you shouldn‚Äôt have replied.
Offer remote work. Additionally hire good people and not just look at their skills. Too many times companies focus too much on skills and miss great candidates. 
Lol, ok. Whatever you say man. You asked a question on how to do something and I gave you a better solution on how to do it. If you don‚Äôt like that, then you‚Äôre in the wrong field because you should always be striving for better solutions. Never run with shit.
Putting aside Mono, in the past, .NET Framework was essentially a windows-only affair. The next closest thing from a lot of school's perspectives was Java, since you could teach students OOP concepts and what not while retaining platform independence for student computers (look at how many students in universities/colleges have a macbook open in the lecture hall). &amp;#x200B; Of course now, thanks to .NET Core, everything has changed. However I don't expect things to change overnight...since schools are often very slow to adopt new tech.
Out of curiosity, u/teeheeMcweewee, is your firm doing anything to recruit devs from outside NYC? 
Currently studying in Sweden.
I would say so. Our company is having a hard time finding candidates and I went to a conference last month in my city where there were plenty of companies looking.
Absolutely, stay in touch I would love to hear more. 
Sorry, but you misundestand me. I'm saying the scenario you outlined is perfectly valid and doable (I did something extremely similar last year), you just can't do it elegantly with MVC, but I feel you are a little confused as to the terms used by the framework (ASP.NET and MVC are not the same thing). You can do it with ASP.NET Core middlewares, but it seems you are opinionated as to not like the framework. No tribe mentality here, you should just not use a framework you don't like and feel you don't have full control over what you're trying to achieve. Also, .NET is not a language.
A lot of that is completely understandable, the only thing is that when a recruiter doesn‚Äôt give you a company name that has to do with legality, it‚Äôs not voluntary. Trust me it would be easier to do my job if I could go shouting out which companies are looking for positions through me but that‚Äôs not something companies want.
I‚Äôm new to the recruiting game. It‚Äôs great to hear some of these complaints so I know habits to avoid in my future career so thank you!
It‚Äôs hard to figure if the problem is in the market or in your ad without reading it. Maybe you are using and old version of .Net that deters job seekers away. Maybe the company is in a not easy accessible area. Maybe the ad looks very demanding in terms of frameworks/languages. I‚Äôd tone down the ad. Look for a junior and offer training. Will save you money and time if you find a developer with potential and let them learn. 
I just got a job offer for a senior data scientist position listing sololearn c++, Java and c# certificates as references they are looking for. Sometimes it feels insulting how delusional these people are that use these headhunter services. If your regular job offering is so bad that you need headhunters listing you meat to overpay, then you really deserve a college grad with 0 social skills in your senior engineering roles.
Eh, some bosses don't know what they have untill it's gone.
Then those are bad bosses. Good workers don't work for bad bosses if they can help it. 
Pity it doesn‚Äôt support mono.
Back up your files and reinstall/recover windows. 
Oh really? Interesting. I didn't know that. 
Hopefully you're still watching this thread. I'll tell you my frustration with recruiters nationwide, and caveat, I just took a new job, and I did it through a recruiter, so it isn't like I won't work with one. First of all, I'm an english speaker in an english speaking city in an english speaking state. I am *so tired* of getting phone calls from people who cannot pronounce my very normal name and cannot pronounce Charlotte or North Carolina. I know recruiting companies are using offshore to do their cold calling and those people are frustrating. When I did answer calls from this particular group of people, they'd be friendly until I asked about location, they'd say some other city that I don't want to move to. I'd tell them so and they'd straight up hang up on me, no "we'll keep you in mind" or "Thanks for your time". Occasionally, I will get an "Oh" and click. Not even "goodbye"... So I've stopped answering and if you aren't speaking at least halfway decent English, I will not call you back. Second, At least talk about money before spending a bunch of my time. I have more than 20 years experience. My area pays well. Why would they call me and spend 30 minutes of my time talking about a job, and then say "They're paying 40k". How about no. It takes minutes to at least look up average salaries for a city you're recruiting for. Start there. Tell me briefly about the company, gauge my interest, let me tell you what I'm looking for, then move on. Third, some recruiters have this "pressure sales" tactic that they want to spin. I realize these positions are time sensitive but don't cold call me and ask me to be at an interview in 2 hours. I had one guy who simply could not understand why I couldn't have a skype interview with him yet that day -- Sorry dude, I have a job, and if I'm skyping on the job, they're going to be pretty annoyed at me, minimum. forth, ghosting works both ways. If I talk to you about a position and what I'm looking for, that means I'm willing to work with you and I'm ok with talking about other positions that might come up. I don't understand why some recruiting companies ghost. I talked to a Robert Half recruiter who told me all about this other position with a company that seemed interesting. He called me back a few days later to say the position had opened up and was it ok to submit my info. I said sure, and then nothing. I followed up a few times, and nothing. I would like to hear that "Hey, they went with another candidate" or "they decided not to fill the position" or even "They aren't interested in you because you don't have X on your resume" but this guy didn't even bother returning my phone calls and after so long I gave up. THEN after I updated my LinkedIn to show I had a new position, THEN he calls me and complains that he still had that position in the pipeline. There are so many things that can be improved about this process.
Sure thing! The gist of it is that it‚Äôs built around candidate sourcing where you create job postings and have the option to create 100% custom screening questions that are scored. So the flow is you enter in a potential candidate‚Äôs email and it fires off a no thrills/no bullshit email that gives the candidate everything they need to know about the job. If they are interested, they click the job link and apply - leading them to answer the screening questions on submission. Once their resume is submitted, you get an email with their screening question answers and resume link. The goal here is to screen out candidates that are obviously not qualified before you look at their resume. That‚Äôs the primary feature with a bunch of other stuff (you‚Äôll have a profile page with open jobs you‚Äôre hiring for, etc) - send me a PM with your email and I‚Äôll create an account for you (once I launch) to use for free for a few months, if you‚Äôre interested.
True, but in many companies whose main product is not software, managers often don't care about old/new way. It it fits the ecosystem of the firm and they can deliver changes/new code quickly, everyone is happy
Fair point, again! Perhaps the problem is too difficult for Intellisense to get right? Either way, it's a daily annoyance. I know I want **something** done, though I must confess, I don't know what!
I still have an active subscription, but it was a HUGE resource hog, so I dumped it and won't be renewing. Roslynator + some other free plugins do pretty much everything that R# was doing.
There are the same number of developers (and growing), you recruiters are not offering NEARLY enough or sufficient benefits for our skills. **This is not a brag posting**. Supply and demand. the .NET ecosystem is VERY strong and senior developers on this platform are worth a LOT. Raise your game. We are here, but happily and gainfully employed (personally, from home). No we won't commute to work. No, not even if you lie to the employer that we will. This is 2018.
There‚Äôs a lot of talent in the southeast.
If you want to look further afield, here's a tip for you (and any other US recruiters readying this): .NET is very widespread in Australia; Australians speak the same language as you; E-3 visas are very cheap and easy to get; and the Australian dollar is weak against the US dollar at the moment. If you're willing to hire remote, or sponsor a visa, you can pick up some high quality .NET devs very easily.
I don't pay for anything. I use VS code, .Net Core and a DB of my choice per project. 
If you're good enough, I'd employ you to work from where you are. I don't even care where you are providing you have a **very** good (16Mbps+) Internet connection. So would any decent development manager with an ability to recruit and retain. Remote developers are SOOOO much more productive.
[removed]
Glasgow, Scotland here. Personally, I‚Äôve gravitated towards the companies that treat you well from the interview stage. I‚Äôve been lucky enough to have been several of these places. As a junior you tend to jump on the first offer you get, but the job hunt is a two way street. If a company wants a raft of candidates to trip over themselves for a chance to work for them with no sense of mutual respect for the people they interview, they‚Äôre probably shit. The best Employers recognise this and take steps to retain talent. And Company or Recruiter, if a candidate goes for interview. Full feedback is required, if a candidate puts in the time you have to do the same.
Sent you a PM
[removed]
This may get buried, but I'll post this anyway. It's hard to find .Net developers for many of the reasons that are here, but I want to add some things that aren't mentioned so far here. First, if you don't assume that the people that you're looking to hire are already gainfully employed, then you're already starting on the right foot. Even mediocre .Net devs aren't on the market long, so if you want to attract top talent, then you need to make a concerted effort to do so. There's no way I'm looking at a position that doesn't have a salary listing. It's a waste of my time to talk to you if you're only looking to hire someone at $90k a year. Ultimately give me as much relevant information as possible when reaching out, and don't make me jump through hoops. If you do, then I'll either never bite or drop out quickly because it's not worth my time. Second, different .Net devs are looking for different things. If you want my time, then have some idea of what I'm looking for. I'm not expecting a recruiter to read my mind, but don't contact me about a WPF position when I barely have it on my resume. Going back to the first point, if I'm gainfully employed at a job I like, then I don't want to work on updating your legacy VB6 app or deal with Web Forms. Some devs might want to be working with the latest and greatest, others may want to work with a more stable stack. You're not going to get candidates if there's a mismatch there. Third, good devs aren't desperate. The know what they want and they're smart enough to get it. Quite simply, if a company isn't offering something that devs want, even throwing money at the problem will only help to a point. From your perspective, it's a tough conversation to have with your client (the employer), but with a lot of times, the answer is that companies need to make the position more attractive for candidates. In the short term that may be money (which hurts your bottom line), but in the longer term, that means making changes that will attract talent. 
The fact that your new and asking questions is good. I'm convinced that 99% of recruiters simply search for resumes, then blast the ones they find with emails and calls 24/7 until something sticks. They expect candidates to be interested with every position they bring to them (even if it's shit/unrelated tech/crap commute/in another state). The expect candidates to fill out ridiculous questionnaires or the first question they ask is their expected salary. While I can't imagine that those recruiters get far, it seems to be the majority of what I've dealt with, so I guess for some recruiters/companies it's working. Some advice is to realize that while you're being paid by the company to fill the position, it's me who's going to have to live with that position. Realize that you're dealing with a VERY significant decision from my end. I don't care about you filling your position, I care about finding the next step in my career. If you don't realize what's at stake on my end, then you're only going to get candidates who are working with you because they're all out of options.
Cincinnati, working as a Java developer because of salary.
Will look into those seeing as how my performance has gone to shit lately with it myself. 
Good riddance.
Sorry, I didn't mean to be so rude. I wish you well. 
Robert Half is awful. They would submit me without my permission to anyone but sent me mostly jobs not relevant to my career. They are the only recruiters I won't even talk to.
In Mumbai, India and happily employed. I won't consider a company outside India unless they offer remote job
[removed]
[removed]
Web API is the only one that I know of, although people tend to do it with MVC too. https://www.asp.net/web-api
Someone correct me if I‚Äôm wrong but I believe .NET Standard specifies a set of APIs that make up the .NET runtime. It says nothing about the web framework ASP.NET. In other words, .NET Standard is the language spec and ASP.NET is a framework built on the language. 
I thought asp.net core also was part of that specification? The iis module loading and stuff? Might be me that is wrong.
I think Web API and MVC are basically the same thing now. MVC was built on Web API since the final Framework version, at least. I'm pretty sure Razor Pages are something you can use within a Web API project. Web API is your foundation.
[removed]
[removed]
Nowadays you'd use ASP.NET Core with MVC instead.
\&gt; support for WinForms &amp;#x200B; Wow, thats a big surprise to me. I thought they were doing everything they could to get rid of WinForms in favour of WPF. Suits me perfectly, i love WinForms.
I don't know if I'd call it the language spec, but it is a set of shared base libraries. Used mainly so you can target a new library at a version of .NET Standard to ensure that it can be used by various .NET Framework, .NET Core, and other Microsoft stack projects. I always reference back to this table to see the relationships - https://docs.microsoft.com/en-us/dotnet/standard/net-standard
I really love [Rider](https://www.jetbrains.com/rider/), which is basically IDEA for C# (ReSharper without being crippled by VS - no, it isn't the other way around). The only thing it's currently missing is a Xamarin UI previewer. PostgreSQL is my go-to for both personal and professional projects.
The investment is mainly to allow existing apps to be ported, same applies to WPF. Major investment on desktop APIs keeps being UWP. Check BUILD 2018 sessions.
There are tons of application written in WinForms. This effort continues to affirm that investing in Microsoft technology, for the most part, continues to be a safe choice.
I think this is sort of correct. .NET Standard has no implementations at all. It's just a common API surface that those supporting the standard needs to implement. It doesn't say anything about Microsoft's development efforts and what they should support. Even if ASP .NET Core 3 implements some .NET Standard version, nothing says they must also implement the counterpart on .NET Framework.
I Must admit, Core 2.1 is my default now. Docker and Azure cloud computing services with Core. Microservice pattern projects lately with Cognitive Services. I'm indifferent towards the microservices approach but it was a perfect fit in the last project. Front end stack of React/Redux + SignalR + TypeScript made this project fun. Cognitive Services and Custom Cognitive Services (true machine learning) + asynchronous processing of images made this a kickass project plus stocking stuffing for my resume. 
God Microsoft need to work on their naming conventions.
There's NancyFX but I seem to remember a long time ago /u/AngularBeginner said something was wrong with it.
Oh damn.
What do you think of Razor Pages? That was popular in 2014/2015, but died with WebMatrix, and now it looks like they brought it back for .NET Core.
I can give you an example: I was contacted by IBM just a few days ago to jump on a new dept. building some new cloud platform stuff. Sounds like super interesting work. But, considering the commute would be 1.5 hrs (all highway driving non-stop) and I already work remote - remote work is a necessity for me. Like others have said, you cannot pay me enough to move away from working remotely. So that's that. Be willing to offer remote work with (really) competitive wages. "Competitive wages" usually means nothing on a job description. I think most of us are wary of those lies... When someone comes to me saying they are in need of someone who can build "C# modules" as a primary skill... even that "incorrect" language tips me off. Job postings need to be written 100% technically correct. Otherwise, we won't care either. Show you us you know your tech and care about it. Hopefully, that helps :)
It really didn't though. They've had .NET Core publicly available for over two years, possibly three. Before then, who knows how long they've been working on it internally.
You got all the buzzwords for your resume. But your client / users have no idea what tools / frameworks you used. They only care that it works.
Echoing ThereKanBOnly1, it is very important to form a relationship with the people you place. The junior to mid level dev you place today is the hiring manager you will be dealing with tomorrow. I've had a good relationship with a recruiter in my area for a while now and when I found myself in a position where I was making hiring decisions and needed people, he was the first person I called. Not surprisingly, his candidates tended to get hired since he knew me, knew what I generally looked for in people, and didn't waste my time with BS resumes. "Oh, you're looking for a web designer to help with the look and feel of your website? This guy would be perfect! He has a degree in robotics and is looking to focus more on Machine Learning. Bet he'd love to figure out what color your website should be!" \*sigh\* happens more often than you would think.
I work for the leading custom software provider in the southeastern United States. I'm not going anywhere anytime soon. 
Oh, good for you. I‚Äôm glad you like your job.
yes its nothing to do with the language
If I may ask, how did you go about applying? Taking my last exam for the MCSD: app builder next week, so I look good on paper, but I've never spent much time on a well stocked portfolio of side projects and github contributions.
I think it fell in line with the development of bash on windows. 5-7yrs+ probably 
I only answer calls/emails from recruiters in my state (Minnesota) that I have at least a little of a rapport with unless I'm starting to look for something new. There has been an uptick in calls/emails in the last couple months.
When you are given an hour to make something quickly just to get it to work, you use what you know, and can always refactor or remake later. Microsoft is apparently even bringing back Razor for [ASP.NET](https://ASP.NET) Core, as a preference over MVC for many situations. I deleted this thread because I wasn't looking for an argument, and it looks like you were.
Working full remote in the Caribbean here with a great salary and benefit package. Whenever I hear from a recruiter, it's for some job in like... Indianapolis with a $25k paycut. I'm good, thanks.
The main issue will actually be security. You will just materialize any DotNet object which means malicious payloads can run arbitrary code or get the server down. These are the reasons why it's recommended to not use BinaryFormatter ... as it's doing what you are describing.
&gt; No we won't commute to work. No, not even if you lie to the employer that we will. This is 2018. I had an interview a few weeks ago for a "100% remote job" that's like 50 miles from my house (I'm full-time remote now). I get on the phone with the company and they ask why I'm interested in interviewing with them and I reply with "I always make an effort to check out every remote position that comes my way." They then respond by saying the position is not 100% remote, only 2-3 days a week. In response, I told them the recruiter lied to me about it not being 100% remote and that this was a waste of time. I then ended the call.
&gt; I work for the leading custom software provider in the southeastern United States Lol, what does this even mean?
I'm in the Kansas City area. Recruiters I've talked to here have echoed your sentiment. The reasons why seem pretty obvious to me; .NET is winning plenty of mindshare within shops, and thus businesses are soaking up everyone they can find. 
Does this mean immigration is less difficult? 
They employ the machine gun tactic instead of the sniper tactic. Blast as many people as you can with a job regardless of if it fits their skill set. I like your dating site analogy, it fits perfectly in this scenario. 
Hey fun fact there's a ton of people in the south eastern united states. A lot of them work for companies that need custom software to meet their needs. A lot of those people are not hillbillies. Seriously they just mean they work for a software consulting company... in the south eastern united sates. It's pretty straight forward.
I don't understand what it is that you're getting at.
Most Rider from JetBrains
I don't have any issues but I use "x" not "o"
&gt; Not to sound rude, but... By all means, continue assuming that a large chunk of the US is populated by hillbillies banging on keyboards. That's not rude at all.
[removed]
Honestly, saying you're a "boutique" tech recruiter in 2018 just reminds me of what travel agents were saying in the mid 2000s. 
There are certainly some who do, or at least mislead. Some recruiters are honest, some are not.
wow - that's really bad for us (still a lot of .net framework only dependencies needed) - might actually mean ditching asp.net core for us
If you are at a director or senior level position, you should not be talking with recruiters that work for clients who only offers entry level jobs, recruiters can be an asset for you though in the event you contact a recruiter that works in the same caliber of recruiting that you do in IT. Upper level recruiters have the increased respect and opportunities to offer that upper level IT is looking for. 
They announced like 2 years ago that ASP.NET Core wouldn't support .NET Framework. They've been moving in this direction for a while.
Connections from co-workers over the years. Also worked with a recruiter that found me the type of jobs I was looking for with the salary I wanted. 
Ok.. Active imagination and a bit of group and tag. All white people can't play basketball and all people of Jewish dissent are cheap too? 
It doesn‚Äôt have to mean ditching ASP.NET Core altogether - that‚Äôs an extreme reaction. You can stay on 2.x which is a really decent version.
Is swedish language mandatory in dev companies or you use english? Does swedish companies mostly do outsourcing or develop their own products? What is average salary of senior .net developer?
This article points to Core MVC6 being a successor to Web API https://stackify.com/asp-net-core-web-api-guide/ But then mentions Nancy, which as referenced by someone else below, is now deprecated. So which should be the focus? https://www.asp.net/web-api https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.1 I spend most of my time in PowerShell and JavaScript (including PnP and PnP-PS for SharePoint), and have now been getting into node.js, but really want to get good at .NET as well and create RESTful services. Is there a .NET starter and packager similar to MS made like SharePoint PnP with Yoman and Gulp? Perhaps something like webpack? https://github.com/SharePoint/PnP Microsoft has made amazing strides with PnP and modern web dev, so if I focus on .NET I‚Äôd like to make sure it compliments that and won‚Äôt be obsolete methodology in a year. Thanks! 
Yea I am always open to new opportunities. Decade worth of experience in .NET. &amp;#x200B; The problem is typically pay and location. The fact that so many employers can't allow an IT employee to work remotely is just baffling. I'll take a New York job. I'm in the same time zone but in a state that is far away. &amp;#x200B; You can send me a message if you have any positions that would meet that criteria.
THANK YOU! So difficult to find remote work. If your company happens to have any .NET openings let me know ;)
because HTML/CSS/JS is garbage haha
i had some side remote work for about a year, but it is so difficult to find clients
Bootcamps are such garbage. Just use a tutorial online and learn at your own pace
In my experience, they tell you the name of the company when you ask for it. Some still deny that request which is a red flag for me. Means they are afraid of you doing a direct application.
* Visual Studio Community * Visual Studio Code * Azure Data Studio * Fiddler The tools I use most. Tools I need for editting some pictures for websites or stuff. * GIMP * Paint.Net
I don't know anything about SharePoint, but Web API is very flexible in creating modern and restful services, so I think that's what you want. Things have changed since the Framework versions, but most of what you would learn about the Framework versions is still relevant today. MVC and Web API are basically the same thing. I have a Web API .NET Framework project that includes MVC controllers, routing and pages alongside the Web API stuff. The main difference was that MVC is supposed to work with a front-end website, e.g. HTML pages, whereas Web API is supposed to be called programmatically e.g. from JavaScript or your client applications, but there are very many overlapping concepts and features. I haven't used it past the .NET Core 1 version, but I wouldn't get too caught up in whether they're calling it MVC or Web API these days. They're the same, really. The [asp.net](https://asp.net) link you posted is referring to the Framework version, which is a bit older but may still support some things that the new [ASP.NET](https://ASP.NET) Core doesn't. I had to stay on that because SignalR wasn't working with the Core version. Just watch out for things like that. Google the techs that you need and see which framework they are compatible with. The [Microsoft.com](https://Microsoft.com) link is the newer [A](https://asp.net)SP.NET Core version, which it does seem like they are calling MVC, which they are now saying is the platform the Web API. If you're going to learn something new, you should go with that, because the Framework version is probably going to be classed as legacy within a few years; though it's still going to be working for a long time to come.
Thank you for the suggestion! The fix was apparently I needed to put in my versions in the nuspec file, when I did that it worked with a 2.0 core application. I wonder if I did continue to have that issue if I could move my nuget to core 2.0 and it would work on 2.1 applications, since the 2.1 applications may have backward support.
WCF source code is up on Reference Source, we can use it to begin building the server side, as discussed in the WCF github repo. The only thing is it‚Äôs a lot of work. So the petition is a bit bunk what they want is: ¬¥please port server side to .net core.¬¥ I would love WCF on core, I use it in my projects. 
Have you looked into a [format standard such as ASN.1](https://en.m.wikipedia.org/wiki/Abstract_Syntax_Notation_One) ? I don‚Äôt know if there‚Äôs a library for dotnet that implements asn.1 fully, but if you need something completely generic, asn.1 will most probably be able to support it. 
System.Web will stay on the full framework though.
It is an API spec.
ASP.NET Core will use features not available in .NET standard.
[removed]
They're the same thing really. MVC contributes the routing and webapi is bundled in it. If you do dotnet new webapi it's just a stripped down MVC app that returns whatever instead of actionresuls
Is this: &amp;#x200B; \* Web Forms? \* MVC? \* MVC Core? &amp;#x200B; The advice will depend which.
Web Forms
Assuming MVC here, Core or full framework should be the same... Architecturally, if the response parameter is passed by reference (I think it will by default but you should check) it should be fine to do and thread safe. Generally though, most like to keep any changes to the response object in the controller. For the file, ops, I am guessing each request is hitting a different file since it is deleted when it is done, so file locks shouldn't be a concern unless, for some weird reason, this op could happen on the same file, then you would have to check for file locks regardless of where that code lives. However, it sounds like this could be created into 4 steps of: * File operations * Cookie creation * Database operations * Redirection The first and third most likely would be best served in a class/file outside of the controller. The cookie creation and redirection are generally things you see done in the controller. If there is any logic in operations 1 and 3 that control the values in steps 2 and 4, make them the output of those functions. Hope this helps!
I'm so sorry. 
If you don't use any \`static\` variables, and \`Response\` is passed as a parameter, then the only risk for problems will be outside your code. Most likely in the file system. But if you're only doing reads, and not locking files, then that won't happen either.
Haha no worries. I didn't build it, but I don't mind it too much. Hoping to replace it in a few years.
Web Forms. Sorry, should have specified.
Without seeing your code, I'm not going to say there's *no* way, but unless you're doing some weird fancy stuff, yes. Weird fancy stuff is like (mis)using a memory cache or something.
Thank you. Really appreciate the help!
Why not both? Offer selective packages; the use case here would be: A user wants to only use PostgreSQL, so he wants basic framework and the PostgreSQL implementations. Thus he would reference *.PostgreSQL, which has a dependency on *.Core. Then you could offer a meta-package that references all of them as dependencies. The programming effort to provide this kind of functionality is negligible.
Thats not exactly the situation, but I am taking it you would prefer 2 smaller packages instead of 1 larger one. 
Thanks that was it. New Navigation was the item that needed to be enabled. 
If you have a single class (or grouping of classes if you're trying to write clean, single responsibility classes) and assuming you're not using static classes or properties, then you will need to create a new instance of the class and pass the response as a parameter to the constructor. This class will have its own allocation of memory so therefore it will not mix users response data. Also it doesn't matter if you're using web forms or MVC.
To keep up to date, I usually check here, because new versions of the frameworks get posted here. You can also check Scott Hanselman's blog: [https://www.hanselman.com/blog/](https://www.hanselman.com/blog/) and the .NET blog: [https://blogs.msdn.microsoft.com/dotnet/](https://blogs.msdn.microsoft.com/dotnet/) For an API reference, the .NET API Browser is what you want: [https://docs.microsoft.com/en-us/dotnet/api/](https://docs.microsoft.com/en-us/dotnet/api/) We are still on .NET Core 2, .NET Core 3 is in the future.
In my region I'd say absolutely, if you are competent. As others mentioned good devs tend to have a lot of opportunity in the market right now versus 5 years ago.
wanting that dark theme? so good!
Better to have the core logic and implementation (if more than one) separate. 1. If the dependencies are correct then the user can just install Project.Implementation and Project.Core will be pulled in automatically. 2. Having them separate allows the core project to utilize .Net Core or .Net Standard and make it multi platform even if one or more of the implementations requires the full .Net stack. 3. Updating / Maintaining nuget packages on a project is stupid simple these days compared to crashing hell with VS 2015 when you installed or upgraded packages. Some of the stuff I work on has 20-40 nuget packages from internal libraries and dependencies and things generally just work now.
Datagrip is a badass tool and I miss it. 
If they could add a xamarin UI viewer that's actually good Rider would probably be an instant buy for me.
This is kind of the opposite of what I was told [above](https://www.reddit.com/r/dotnet/comments/9to04r/aspnet_questions_about_using_shared_methods/e8xuwj6/). Can you provide any more info on how the data would get mixed up?
For Cross-DB design it is really cool, although I never tried using it for more than simple work. (i.e. I've never tried to optimize a query like I would in SQL developer.)
Such a huge improvement. The last one was unmanagable
Let's say you're trying to decrypt a file using a key from a user's request. // YourForm.ascx.cs init method var userKey = Request.Headers.Get("DecryptionKey"); var filePath = "C:\\temp\\encrypted.file" var fileDecryptor = new FileDecryptor(); var decryptedContents = fileDecryptor.Decrypt(filePath, userKey); // FileDecryptor.cs public class FileDecryptor { public string Decrypt( string filePath, string userKey) { // Load file and decrypt it } } All of these objects will be in their own memory space, and even the secret key is passed by value, so a new memory allocation is made. If you were to do the following, there is potential for issues: // FileDecryptor.cs public class FileDecryptor { public static string UserKey; public string Decrypt( string filePath, string userKey) { if(!string.IsNullOrEmpty(userKey) UserKey = userKey; // Load file and decrypt it using FileDecryptor.UserKey static prop } } The reason this is dangerous is because the static property is shared across instances. So if someone successfully decrypts the file, the next user can simply pass an empty key in the request and they will then use the last person's key.
That's the situation exactly as you described it but yes. So long as all the database libraries are just adapters and the core implementation doesn't depend on anything else.
I would offer each as a nuget. So Core has the interfaces etc. to create an adapter. Then each nuget would implement it for a certain database and depend on Core.
[removed]
Sadly you can't always spot a shit boss when applying for a job.
[removed]
I‚Äôm not using any static properties, only local vars.
Yep. 
That's gonna be tough. Senior .NET positions tend to max out around $120k or so. That's why guys like me have no choice but to just stay where we're at and enjoy the 3% yearly raise.
This 
No surprises, but also no new developments. I may be wrong, but it seems to me that .NET Core is the future and .NET Framework will become either a niche (Xamarin) or an afterthought. I mean, they‚Äôre bringing WPF to .NET Core so that‚Äôs telling.
Well I ask this question to early, I found the piece of software that powers reference source [SourceBrowser](https://github.com/KirillOsenkov/SourceBrowser).
"People don't quit companies, people quit bosses" Don't remember who made the saying famous but it's so true.
you are not wrong - but right now core is not where full framework is (there are a few things that just don't work on core and yes some get fixed but not all) btw: for what I'm concerned they don't bring WPF to core as it will not run on Linux/MacOS but only on Windows All that tells me is that they are going to drop full framework faster (which is a good thing because I think 3rd parties and MS will be forced to close the caps faster) I'm just saying that I gonna wait till the dust has settled - why should I start to bring/upgrade more things to ASP.net core now when I won't be able to support the next version and then have to wait for 4.x (or whatever)? I'd rather stick with full framework and wait for that 4.x
Yeah, that‚Äôs fair and I know that in some spaces (healthcare, some banking) there is quite a difficult process to approve new versions of frameworks and an the speed .NET Core is moving it‚Äôs not helping it. On the other hand, I‚Äôve done quite a lot of ASP.NET MVC and coming into ASP.NET Core wasn‚Äôt as smooth of a transition as I expected. The speed and breadth of changes make it difficult to keep track and as a technologist I worry about staying on top of it. I guess that‚Äôs what spare time is for.
[removed]
If your APIs are designed correctly, it's the same thing.
[removed]
[removed]
Are you looking for cross-plat UI specifically? I've heard good things about Avalonia, waiting for a project to try it out on. I've never used QT though.
Yup, cross platform, we build for linux, osx and windows. Avalonia looks very interesting, but I have not had much luck with the examples, mainly it never works right on linux and I had very little luck working with it on OSX and visual studio. Currently we live in the GTK world, which does the trick but it feels dated. 
[removed]
[removed]
This has nothing to do with Razor Pages really. It's the way browsers work. HTTP requests are either sent blocking (also called a full postback) or asynchronously (via XHR, aka AJAX). So no, not really, you have to use JavaScript to send asynchronous requests. 
Yeah, sadly C# is lacking in desktop development. WinForms is ancient, WPF is abandoned by Ms (I don't really like it too). Modern apps look terrible imo and are Win only. I really like Qt, but sadly either you use C++ directly or Python. No other mature binding available i think. 
I thought it was mostly for C++ ??? How good is it for C++ ? can it compete with C# ui ? or portability across devices ? (like xamarin or react-native) Ive heard only good things about QT and its only growing, nothing beat C++ power/speed when well done
Got mocks? 
Congratulations! What kind of code coverage have you got with so many tests? Also what was the most complex part for MySQL?
Very, very few. Most of the bugs are going to be in the interaction between the ORM and the database so marks are going to be very useful. do you have to admit that's a pretty impressive performance number. That's majority of those tests hit the database at least once and many of them hit 2 or 3 times.
DB integration tests are great. But mocking your DB/ORM tests with something like Moq get you into sub second proper unit tests you can include in your CI gates. 
I think the most complex part for MySQL was the database reflection. It was certainly the most time consuming. In theory, there's this thing called information schema that all databases implement. Unfortunately, the values in columns, they have in it or not actually standardized. Especially when you consider each database has its own special features that know others have. So there's very little code reuse between different reflection engines. But that's what makes this ORM project so interesting to me. You can use it to build pretty much any kind of code generator, at build or run time, to suit your needs. Unfortunately, it also means that each database adapter has to be hand built. depper works for all databases because it only understands the net extraction layer.
MySQL is averaging 7.6 milliseconds per test. Or in other words, 2 orders of magnitude better than just "sub second". 
Thank you so much for all these wonderful and insightful replies. Having built an abstraction layer to target three DBs for one of my projects, I totally see the lack of standards on the information schema. The code I‚Äôm using still hasn‚Äôt enough intergtation tests and it was very insightful to hear about how you go about layering this testing, from micro feature input - output, to transaction, to object and so on. I wonder if you have compiled some of the wisdom and battle scars you got from Tortuga somewhere? 
May I ask which databases you targeted?
If you ever need proofreading or someone to ping off of / tel, you when you are rambling, my inbox is open. I would read such a post. 
And it tests the actual system under test. For an application using your library? Sure, mock away. For a library for talking to the DB? First I'd need to do the actual test to find the actual behavior, which may be surprising, then I'd need to come back and replace the test, and I don't see why I'd want to. I maintain an in-house library that talks to SQL server, postgresql, mySql, and progress over odbc through common top level functions. I hit the DB for the tests too. 
I had talked [about it here a little bit](https://www.reddit.com/r/csharp/comments/9n80g0/can_any_orm_perform_bulk_operations_like_bulk/) on a thread you were also involved in. Mssql, Postgres were added to a application that was originally developed on top of Oracle. 
Oracle... that's gonna be a fun one. Lots of weird edge cases like empty strings are treated as null strings.
Sigh, another article on my long list of one to write. My suggestion is to start with CRUD tests. That is to say, one test that performs a CREATE-READ-UPDATE-READ-DELETE-READ cycle. These are simple to write and maintain because they make no assumptions about what is already in the database. 
Yeah, and we were returning a lot of auto generated Ids, using cursors returned from DB for certain queries, some light dynamic queries from stored procedures. Reads across DB schemas, because the authorization, logging, users and user rights were in a separate schema from the data for auditing / compliance purposes. Things like vector inserts were also a big topic. So it took some time to do the migration. I have an internal document that tried to express some of the story of our migration as an experience to share with the other units of the company. 
Of course, I don‚Äôt think anyone ever read that document.... never got any feedback -_-
Here's a slightly longer example. https://github.com/Grauenwolf/RepositoryTimings/blob/master/RepositoryTimings/RepositoryTimings/ComparisonTests.cs
&gt; cursors returned from DB for certain queries Oh man, I remember implementing that for PostgreSQL. I think its the only way to return multiple result sets from one stored procedure.
Yes, and we avoided that case by modifying the calling code. One stored procedure, one set. :) On my list of todos for that code is to add SQLite as a quick and easy replacement for the binary serialization that we do on the client side of the application. We write to binary files in a folder using a struct format (because the app has a fortran component that reads the structure), but I would like to store projects in a sqlite dB, for easier management. I hope to have time after we finishe the intraday trading module and dashboard by the end of the year. 
Thanks for the good chat, I‚Äôll catch some shut eye and check tomorrow not the thread. I really appreciated our conversation, thank you and have a good day / night. 
Ah, it looked at first like you had some running ~50 seconds.
In my experience Xamarin is the worst...
Why would you? Seperatre concerns. I prefer iqueryable against dbsets same with cosmos Db. No hassles like with all these overengineered repo patterens
AHH you need 5 more MySQL tests ! 3306 üòÑ
Funny you should say that. I still need a few more for stored procedures and functions.
[removed]
Qt was originally for C++ back in the early 90's, it's written in C++ but has bindings for an immense array of languages. Portability is a first-class citizen, it's Qt's raison d'√™tre, I mean it works on QNX and VxWorks (when was the last time you heard someone using VxWorks!?). I don't believe, unless you went web, C# has anything native that can compare to that level of portability. That said, it is a complex project, that level of power and portability does lend itself to a learning curve. But there are a fantastic array of tools out there to help you get the most out of Qt. QtSharp is the C# binding you'll probably want.
Linq2Db faster than EF (core), almost as fast (or probably as fast) as Dapper, but with Linq support.
Genuinely curious here, how did it only take you a day? You must have an insane workflow to write it plus that many tests.
No, it actually took several days to figure out the database reflection code. The way our ORM works, it has to be able to ask the database about its table/view structure before it can generate any SQL. I did this over a year ago. Then I was swamped with projects at my day job, moved houses, and other general life issues. *** Coming back today, I mostly had to copy and modify the SQL generation code used by our other ORMs. Pretty minor stuff like no OUTPUT/RETURNING clauses. On the plus side, MySQL has an upsert that actually makes sense. Then I had to create the database and test connection strings. Your usual new-project stuff that you always forget because you only do it once a year. As for the tests, they already existed. I use the exact same tests for every database from Access to SQL Server. Sure some are turned off if the database doesn't support a feature, but as much as possible I want the ORM to behave the same way no matter which database you are using. (Also see my other comments about multiplexing tests.) This means that if we can use SQL to pretend that a database has a feature that it really doesn't (e.g. SQL Server and upserts), we'll do it. *** Could I really do a whole ORM adapter in a day? No, I don't think that'll ever happen. But with each database I add to Chain, the amount of new custom code I have to write goes down. In part because the newer databases are getting better at supporting ANSI SQL. But mostly because I'm just running out of weird edge cases that I haven't seen before.
I noticed you are not running them parallel. xD
I don't need a proof reader, but here's my notes thus far in case you are curious: https://www.dropbox.com/s/abw7fxsiybpopww/Things%20I%20learned%20implementing%20an%20ORM%20for%20MySQL.docx After I add some more tests for stored procs/functions, I'm going to look at bulk inserts. Having to run everything through a CSV file is going to be interesting. 
Some of the tests aren't independent. For example, it will insert a record take a count. Delete the record take another count. Then I'll check to see that accounts differ by one. ( It would really suck if it deleted more than it was supposed to.) In theory, I could run parallel across different databases, well being single threaded for a given database. But having all those database servers fighting for resources would probably just slow it down.
Python...for desktop applications? Are you serious?
[removed]
https://github.com/qmlnet/qmlnet
You are right - I'm just having multiple small custom services that is below 100 users, so I'm really on small but many containers. Sometimes only 1 or 2 users need a custom service and I must find a way to use a small vm to contain them. Any changes or fixes will directly to production stage. I do understand they are not best practices, but even the amount of users are small, they pay me monthly. Some people may say then Azure is not for me. Azure has a lot of management features that helps is separation and management which is great for a company that having multiple kind of clients, big or small. As a small solution provider it helps me in infrastructure side which I don't need to care about network, firewall or electricity. And that's why I'm asking for kind-of-weird question with these requirements: speed of deployment and cost.
This isn't "high performance" or "feature rich", but I'm glad it exists because it's exactly what I need to port some .NET code to .NET Core. 
`TextFieldParser` wasn‚Äôt bad by any means and certainly does the job. If feels a bit awkward in use, particularly if you deal with fixed-width and both parsers (CSV and fixed-Edith) have the limitation of not being able to support differently-shaped multi-sets in the file, which as I learned recently are quite common in the mainframe world. Also no support for async. A similar library which I‚Äôve heard good things about is FileHelpers: https://www.filehelpers.net/quickstart/
I don‚Äôt think it‚Äôs a bad machine by any stretch. If you have other tools that require macOS, it‚Äôs quite a great lightweight dev laptop. If you don‚Äôt have anything tying you to the OS, there are a few more economical choices out there. To /
Some portable Thinkpad would be better. Believe it or not, .NET Core development is still far superior on Windows, than any other OS.
3300 lines of: Assert.IsTrue(true); ? Just kidding OP, nice work!
[removed]
That's a bad sign. I feel your pain. It's not a good plan for security though, or technical debt. :-/
VS2017 can be a better more integrated experience in some ways, but if you use Vs code it's moot, and OmniSharp is perfectly good
I personally just enable net core in my project configuration every here and then and see what breaks. Enabling net core in project configurations is negligible effort. I then take an hour or two to try to fix the easiest things until I get to the meat where decisions have to be made.i then stop and give myself some week or two to think about the issue and repeat the procedure. Migration really isnt that bad. Try to move from the old to the sdk-based csprojs first and enable multitargeting. In visual studio 2017 you get warning icons for APIs unavailable for of the targeted frameworks. You then use ifdefs to throw not implemented exceptions in case of framework x and move the implementation work into another work item. You run your test suites against both frameworks until both full framework and .net core pass the same suites. Read the docs for multitargeting - this will help greatly.
Yeah I am. I've seen some desktop apps made with Python. Though I admit, Python is not really suitable for big codebases. 
Ha. Just for fun I will change a few of the 50 or so projects in our solution and see how many build errors appear... I‚Äôll let you know.
General advice on this sort of thing: What sort of case are you presenting to business that you need to spend the time to move? Do you really work on the webform parts much? Can you make an objective case that it is slower to work on, is insecure, etc? It very well may not be worth moving apps or pages that don't change often. Your question assumes you really need to move, but you don't really state why. If it is tough to shift your JQuery/Kendo stuff to Angular or React, then why would you? I certainly can come up with some reasons developers come up with for this, but they may or may not be terribly valid for you situation. 
What did you write the ORM in! Can you post what a sample test looks like? Are they select only or write functionality too? How did you know what the data needed to look like to be able to test a stored procedure?
We started by moving our libraries to .net standard. Once we had that, we moved some small projects, and then finally we are working on the bigger projects. Note that your web forms stuff isn't moving.
It will only really be practical to use .NET Core for greenfield work. You are correct that your existing code will never be ported. You probably want to look at taking narrow vertical slices of your stack and reworking it into microservices.
I've been in charge of roughly 950 csprojs at my shop - so you could say I'm quite good at migration now.
Porting is actually one of a few things that might make sense to outsource. Retain one or two remote developers to do the porting for your projects while your team can concentrate on the new features/projects.
Source code https://github.com/docevaad/Chain 
[removed]
Honestly, I don't think there is a good answer to your question. I work in a small company and we're basically in the same exact scenario as you've described. We're 95% building on top of existing decade long projects. The 5% where we're not, we're able to utilize some of the newer tech. For example we're working on exposing an API, so we're going with .NET Core there. Our internal services are one large WCF project. Personally I've lost a little of my love for software development in the last 5 or so years. The rate of change on the .NET side of things (that's all I really know) has been unreasonable. It brings me nothing but anxiety. I understand those that work for consulting firms that specialize in software development love this. They hop on a project, hop off, learn something new, hop on another, etc. I work in a small financial firm, with a WPF desktop application, MVC5 + Webforms married website, WCF services and SQL Server. This is our past, present, and future. No one is going to take a few years to rewrite any of this using the latest and greatest. There is no money for it, no time, no staff, and it doesn't even make sense. All of these technologies are still perfectly functional and probably will be so for many years to come. I know I haven't answered your question, but I'm here to say that I share the frustration.
They are super slow(more than Java or Electron) although.
Intermediate dev here, sole .NET programmer in a company that has a legacy .NET/ASP classic system. It‚Äôs tough, but what I‚Äôve been doing over the last few months is moving everything that can be moved and porting it to .NET standard. Things like the common database library, email lib, reporting lib, etc etc. Also converting all MSTest projects to xUnit and setting it up for CI/CD in Gitlab (but that‚Äôs an optional bonus). Then I rip out the old NuGet libs from the Web Forms apps and replace them with the ported versions. Works perfectly. I‚Äôm exploring the possibility of doing some soft rewrites of the ASP classic code in Razor Pages as well, but we shall see what management has to say about that when I give them my report. 
To help you get an idea of where you stand, Microsoft has made a pretty good tool called the ".NET Portability Analyzer". You can choose which projects and which targets you'd like to analyze and it produces a report.
Thanks a lot. Felt good to read that. I agree the rate of change does cause anxiety for developers and the new tech is just reinventing the wheel. .Net Core doesn‚Äôt really make development faster or easier...
Because .Net Framework won‚Äôt be being worked on by Microsoft.
I know, not enough benefits to port the code. We will only deploy to our own windows servers or Azure.
950 is insane.
me_irl
You are using it for desktop or just mobile?
[removed]
Agreed. OP, that tool helped us quite a bit.
I like that it‚Äôs cross platform. Means I can deploy to Linux servers instead of having to pay extra for Windows licenses plus I have more experience maintaining Linux servers than Windows ones. 
Don't do just for the sake of moving to latest frameworks. Better option is to look for new Business ideas and Projects to start in .Net core. Business don't easily agree to migrate code just for the sake of it. I have web forms projects mostly and even one classic ASP project and Business is happy as long as it works. StackExchange moved to .net core, you can read their case study. Also, may be if you're looking for platform Independence and containers on Linux for deployments like kubernetes for cost savings instead of Windows servers then it might make sense as a business proposition. 
Moving projects onto .NET standard is a good start as someone else said. For the bits of your projects that are too difficult to upgrade, seriously consider redevelopment e.g. your webforms projects. You can't really do anything with those so now. Your webform stuff probably has your jQuery and Kendo stuff tightly integrated too right? For a large code base, it would take far, far longer to port than to redevelop as there is no obvious path. Which means slow, confusing, difficult work. Might be time to scope scrapping that and moving to something like a .NET Core API with a js framework front end for ex. Another approach is, if you have a monolith app, see which parts can be broken out into new projects and deprecate the old code, e.g. Parts of the front end or maybe auth is tightly coupled. You could create a new, separate auth app e.g with IdentityServer and migrate your app to use that instead. Incremental improvement whilst also moving towards a more decoupled, microservices'esc architect. You need to also start tracking your tech debt and pushint back with your boss for house cleaning e.g. after X releases, we need to take some debt and do a house cleaning release. Tldr; look at the bits that can be upgraded and consider redevelopment of bits that can't/are of high complexity.
[removed]
That is a benefit but doesn‚Äôt help me since we already have windows servers.
We recently moved from web forms to MVC. I'd think that's the first step to moving web forms to .net core. We made the web forms stuff available in IFrames and over the next year or so we'll move everything over. This was about a years project but it was a total rewrite of a huge application. We just prioritized what got upgraded and what didn't based on usage. 
It will, just not as much as .Net Core. And will still be supported, so bugfixes and security updated are guaranteed. Are there specific features of .Net Core that you want or need? If not, I don't think that's good enough reason to upgrade.
What you describe is pretty normal. Large architectural changes like porting to a new platform (which .NET Core really is) require motivation and justification. Is it important to the business to maintain its codebase on an evolving platform? If so, it is up to the decision makers to align the company's efforts with business needs. Moving to .NET Core is not a technical decision, it is a business decision and it needs to have business impact. If the decision makers wish to make the move, they'll need to back it up by ensuring that there is sufficient effort available to allocate on this. It could mean charging customers more, it could mean hiring more people, it could mean decreasing ambitions when it comes to new features.
Yeah definitely. I think that‚Äôs the big one for MS though, helps their dev story if .NET stops being a Windows only tech. 
Yeah, good analysis.
[removed]
Cheers, that will be handy!
This is pretty much what we are doing and we are 80% of the way there.
Oh I think .net Core helps Microsoft more than existing .net developers.
Well, moving to GIT wasn‚Äôt that bad. I watched some videos on how to use it. The team met together and we reviewed what the workflow would be and we just cut over. The tooling for GIT in Visual Studio is so good, that it is super easy. Instead of checking in, you commit and push. As for TypeScript, we watched a video or two and we all started using TypeScript for all new client side dev. I converted our main .js files to TypeScript. It wasn‚Äôt that bad. We still have some .js files left, we just don‚Äôt update them. 
Yes. I agree. We aren‚Äôt stuck, we can make new apps in .Net Core. I have a plan to move part of our Monolith to a new .Net Core website. I‚Äôll try to move stuff to Standard Library projects. Personally, I still enjoy coding and I have been at it almost 20 years.
https://discoverdot.net
It was a rhetorical question ;)
Gotcha 
This! a million times.. I'm soo tired of auto-magic ORM's that wind up being terrible state machines causing endless issues in production. Dapper takes care of the boring stuff (mapping objects with the terrible Ado.Net api) and lets me get back to the stuff that matters.
[removed]
[removed]
Based on what? I use vs code on my 2017 MacBook pro for core work and run windows 10 in a VM if I ever really need VS, which has happened about twice in the past 18 months. I also use vs code on my windows workstation at work. The experiences are almost identical, but I prefer macOs, so for me using my MacBook is far superior. 
&gt; .Net Core doesn‚Äôt really make development faster or easier... All that hacky stuff we had to do in MVC and WebForms though.. and now we have this nice simple consistent web pipeline. I'm the CTO and lead developer in a ~30 person org with 6 developers working with me and our codebase is over a decade old - I've been working on it for almost a decade myself. We started transitioning a bit too early, in retrospect, with v1.1 but we were rewriting our public facing website and our main internal admin website and there was no way I wasn't going to move to ASP.Net core for those. Our last admin site ran for 10 years and our public facing website was.. maybe 5-ish and about the same for the public site version before that. Our new public site is ASP.Net Core MVC with Vue and our admin site is Angular 6. Both use the same, new ASP.Net Core API back end. So we started there, with the new web apps, and just left everything targeting full .Net 4.7.x. ASP Core v3 dropping support for full framework throws a bit of a wrench in our migration plans.. We had a few smaller common libraries that were easy to switch to .Net Standard, but a lot of stuff we had to wait on. When v2 came out with the compatibility shim for full framework targeting nuget packages, we were able to switch most of our common libraries to Standard. Our executables still target 4.7.x and we have one main dependency that requires it now broken out into a separate library. Some of our smaller utility apps we've updated from MVC5 to Core, some we've decommissioned and moved into our new API app. I did run into a ton of issues with assembly binding until `&lt;PackageReference&gt;` became available for older .csproj project files. Libraries and console apps were all simple to switch to the new .csproj format, but MVC 3-5 apps have to stay in the old format. We still need better test coverage on the shimmed parts before I'd feel comfortable targeting Core runtime, and we need a solution for our one full framework dependency that may be tough to replace - it does some black magic with font rendering. We also have plenty of performance critical code we might be able to find gains in with things like `Span&lt;&gt;`. It is tough to make time - there's always far more to do than we can accomplish - but we know our software is going to run for years and it is a bad business decision to get too far behind or corner ourselves into "the big rewrite." And maybe a year from now or so I'll probably start pushing to move our main data service from MVC5 to Core. It serves about a billion requests per month and makes a few hundred million external api requests to do so. At that point the only thing we'd have left that might not be Core would be our target runtime, but with v3 dropping full runtime support I think I'll want to hold off on updating our main data service until I can get us able to target Core and v3 anyway.
‚ÄúHacky stuff‚Äù? Sure, not all of it is ideal, but its pretty good. I really want the tag helpers in the new MVC, but I‚Äôm not super excited about anything else. I am going to definitely start moving code to .Net Standard Libraries and get at least once .Net Core application out this year. Thanks for the comment.
Can you please test my extension PrestoCoverage with your tests. I wonder if there would be any curious issues or if it would just work. Great work by the way. Sounds like a great experience 
Depends on how the project is structured. For mine, it's mostly a matter of migrating the DAL to .NET Standard. After which there's only a very thin WebAPI layer to rewrite.
One project per controller, no more than four methods per controller. -- Crazy stuff my client wanted
Don't. Write all of your new features in Core. Also do this for significant enhancements to existing functionality where you can use an excuse for a rewrite, but don't try and reinvent the technology for everything that you already have and is working sufficiently. Better to spend your valuable time on new features that will add value to the product.
[removed]
[removed]
Lol, I know right.
1) Yes. If nothing else, you save about 50% on hosting fees by running on Linux. 2) Anything. It's performant, easy to write, and general. 3) If you've ever written a medium sized site in Node, you'll be begging to move back to C#. JS not only doesn't scale in performance, but the lack of static typing and analysis means it doesn't scale in development either. Things like TypeScript help to an extent, but it's not the same.
I guess I'm thinking I'd use Windows because that's where the best support is, sort of like I'd encourage anyone learning Python to try using Linux if they're comfortable with it. Would you say it's *just as easy* to get started with .NET in Linux with VS Code? I have the idea the Visual Studio proper is the more powerful tool.
We are also in the process of upgrading web form projects from framework 3.5 to 4.6 . CLR 2.0 to 4.0 We are facing difficulty in terms of element ID as JavaScript is not able to find the elements. I know that VS adds clientIdMode=AutoId in the config file . What is the best clientIdMode to solve all the ID problems . We uses iframes and controls are added dynamically . Some ascx/ user controls are reused in the same page . This make it harder to use Static mode . Any suggestions from the migration experts..
https://github.com/graphql-dotnet/parser
Well, if you must use webforms, static is the best. That way it has the same id on server and client.
[removed]
If you‚Äôre just looking to get a taste of .NET, stay in Linux and VS Code. I don‚Äôt see a good reason to make the jump all he way to Windows. If you haven‚Äôt figured it out, you can run .NET Core on Linux. 
[removed]
I didn't find that to be particularly useful as-is. But maybe it can be made into something reasonable. Or at the very least, some bloody documentation can be added. *** Which brings up my problem with the parent project, which is an outright mess. Basically they just tried to hammer some JavaScript library into C# and the overall result is, in my opinion, unworkable. I tried to help out awhile back when I noticed that none of the API was documented. But they got offended by the idea of following basic engineering practices such as not making everything public or turning on static analysis to catch obvious bugs. 
https://up-for-grabs.net/#/tags/C%23
Lack of decent libraries is one of the biggest problems with dotnet, imho. Sorry I know that doesn‚Äôt help
And lack of free opensource libraries I found it shocking coming back to Dotnet from nodejs for a few years and holy crap where‚Äôs all the libraries?
That was basically my plan at my last company. We started moving our core stuff to .NET Standard, and we had a monolith server that handled message queues and web and API traffic, and we split it into two separate servers. The MQ server was pretty easy to make into a DNC console app, and I'm not sure how far they got with the web server, as it had a bunch of Owin handlers.
1) Yes. While Microsoft may not outright say it, their actions speak louder than ever - .NET Core receives far more updates than .NET Framework. It's modular and self-contained making it far easier to maintain for both microsoft and devs without having to worry about both backwards and future compatibility issues. .NET Framework is plagued with backwards compatibility issues which really hinders development. 2) It's a general purpose language. It works for desktop, web, cloud, and micro services. The only thing it's really lacking at the moment is native UI which is mostly due to the fact that it's still very early in it's development compared to mature languages. .NET Core 3.0 aims to solve this by bringing WPF support to Windows. 3) You're comparing two different things really. There is Javascript for the web/client-side of things which has nothing to do with C# and .NET Core and NodeJS. If you are indeed referring to NodeJS, yes, it IS a very viable alternative, and in fact probably preferred for performance. It really comes down to preference on your choice of language, infrastructure, etc. 4) Yes, in fact .NET Core will very likely outperform almost any NodeJS app given you develop correctly. The .NET Core has insanely good performance compared to most other stacks. You can check the benchmarks here: https://www.techempower.com/benchmarks/#section=data-r17&amp;hw=ph&amp;test=fortune **Personal Opinion** I think .NET Core is definitely the way to go if you want to develop a web application. It is actively developed, high performance, cross platform, excellent IDE support (VS Code, Visual Studio), and packaging system is amazing (nuget). I've been actively using .NET for about 8-10 years (came from Java) and I have also worked with the majority of other languages out there, but I have to say that .NET Core is by far my favorite. 
if a control is used more than once in a same page, shouldn‚Äôt we run into issues? 
if a control is used more than once in a same page, shouldn‚Äôt we run into issues? 
Yea, those techempower benchmarks are pretty impressive... but can you imagine what will happen when they [rewrite json parsing using Span&lt;T&gt;](https://github.com/dotnet/announcements/issues/90)?
So you can drop 1 dll in prod and not have to touch ( read - test) the other 949? But that's not how it worSHUTUPANDDoIT
I know, I keep hoping for a straight forward way to migrate web forms to razer pages, but so far no luck
LOL
It's good that they are finally upgrading it to use spans. It should provide a decent boost to JSON serialization. I don't think it'll be that big of a boost (maybe 10-20%?) but it will definitely help. On a side note (not trying to diminish their work, I absolutely love that they go back and improve old code), but at the end of the day, most applications that bottleneck aren't going to do so on micro-optimizations, but rather poor implementation of the framework 
4.8 will be the last version of the framework
Can you please give an example where you have found JS limited in scaling?
I think you responded to the wrong user. I‚Äôm not the Op. Seems you can have a look at the code here for the [current MySQL development](https://github.com/docevaad/Chain/tree/MySQL/Tortuga.Chain)
[removed]
&gt; I'd say 10-20% is probably a reasonable ballpark for overall improvement That's kind of a silly guess to make, given how much web apps vary. One might spend no time whatsoever parsing incoming JSON, while another may do little else but parse incoming JSON. There's already at least one fast, straight to and from UTF8 bytes JSON parser for .Net: https://github.com/neuecc/Utf8Json
&gt; ‚ÄúHacky stuff‚Äù Modules, handlers, filters, HttpApplication lifecycle events.. lots of inconsistency when it came to extending behavior. No async at all. Properly handling 404's and 500's in all the various ways they can pop up in older MVC was a laughable mess (e.g. https://stackoverflow.com/questions/619895/how-can-i-properly-handle-404-in-asp-net-mvc/2577095#2577095). OWIN middleware is much easier to deal with.
On my GitHub. Fix my shit, yo. wasabii
[removed]
Yes and No Yes - - Simplification of project files - Performance improvements - Crossplatform - Better tooling No - - Packaging sucks - No GUI support (yet, will be available in 3.0) - Still feel heavy I think they should have went full native, Go came and ate both java and c#
I recently got a Macbook pro and it's fine, .net development will be superior on windows for some time to come though. I use rider as my main driver so the only difference is lack of built in test coverage for me, VS code will be the same too. I can say the exact same about Linux too (fedora in my case). I went with one because i want to try ios development and I've had a few bad experiences with Dell in regards to build quality (fun fact, my parents 2009 iMac is still going strong thanks to the RAM from an XPS that fell apart). I also like the Mac OS workflow over windows. I'm hoping mine will be one of those macbooks that's trucking along no problem in 5 years(or i sell it). Have you had a chance to try out Mac OS? .net core shouldn't be the only factor in the decision. If your computer will do it maybe try setting up hackintosh(perhaps in a VM), it's a lot of money to sink if you don't know if Mac OS will 'click' for you.
Yes and No Yes - - Simplification of project files - Performance improvements - Crossplatform - Better tooling No - - Packaging sucks - No GUI support (yet, will be available in 3.0) - Still feel heavy I think they should have went full native, Go came and ate both java and c#
You can lookup my username on GitHub.
He doesn‚Äôt understand modern modern node development (stateless micro services). Node scales as well as anything with this strategy. Nodes real strength (IMO) is websockets, but they do not scale well in any environment since they require a persistent server connection. 
[removed]
Reading all of this I think my perspective really has changed on net core, could someone please answer my newbie question.. I always thought asp.net and c# was used more for the back end and then you would use react / redux on the front? 
Blazor doesn't even pretend to be a viable alternative, they're not production ready. You can't have an ~8MB download any time someone visits your site.
What was the reasoning behind this? Sounds silly.
TL/DR: Use an expression when creating LINQ queries that are to be translated to SQL. Using a `Func` with EF causes the data to be filtered in your application instead of being filtered by the SQL server. This may cause: - increased bandwidth (and therefore slowdowns) - may enable a sniffer to see data that's not expected for him to see (even though the security is already compromised if you don't already filter on the server side) 
I‚Äôll definitely look into a hackintosh but I can‚Äôt decide on which Mac to get. The MacBook Pro 2018 is out of my budget but there is also the possibility of a 2017 MacBook Pro refurb? Also is 8 gigs or ram enough? How about HD space?
I have used gql. Net for 2 different projects without a problem, they released a new version a couple of months ago and improved the quality of the project. Sure it is not nodejs and its 2329344 extensions to the gql standard but it gets shit done
2017 should be perfectly fine. Unless you have lots of movies, games, music or photos that can't live on an external device it doesn't matter too much. 128GB is really pushing it but otherwise you should be fine. Once again it depends on need. I just checked my install and it's just under 50 gb, that's with everything set up and pretty much all the programs i want. RAM it's hard to say, My Mac is currently sitting on 12gb but the stats meaningless as most operating systems only start cutting down when they need to. 8gb should do the job fine unless you want to write huge projects or run lots electron based programs or chrome tabs.
Yep. Bits don't rot, and .net full won't go away, it's part of windows and will stay there forever. The main question likely is: will your software need to move to linux? If not, e.g. you're perfectly fine with hosting the stuff on windows, then there's nothing to worry about. Winforms will be supported, as part of .NET full, for the length of time of .NET full. Libraries that aren't tied to the webstuff, can be ported to .netstandard, which might help moving some of the code to .net core for newer projects (so you can reuse that code). Sometimes I feel like our industry is more focused on rebuilding existing working programs into new stuff just for the sake of it and less focused on actually solving problems for their clients. 
If you're paid by the hour, why question these nice job guarantees? ;)
I already wondered how you wrote all those tests! could you give an example for one of these tests which expands to multiple tests? I have over 3700 hand written unique tests and I really want to expand to multiple situations and the like but dread the thought of handwriting a lot of them. (a link to a github source page is enough, thanks!)
I was under the impression that if I If you just use lambdas directly I was under the impression it used the IQueryable interface which makes it an expression by default.
A lambda of type `Func&lt;...&gt;` instead of `Expression&lt;Func&lt;...&gt;&gt;` (an expression resembling a lambda function) will always be evaluated on the client side and will (cannot) be translated to SQL. The trap here is that `IQueryable&lt;T&gt;` also implements `IEnumerable&lt;T&gt;` thus causing the switch to LINQ for `IEnumerable&lt;T&gt;` instead of using the LINQ for `IQueryable&lt;T&gt;`.
&gt; Are you afraid of JS, with the rise of Javascript in the backend and all the innovations in the open source stack, like React, Es6+, Async, Node, Vscode... Do you think that C# will still be a viable alternative to do Web development ? People have been fear mongering/hype blasting this for a few years. I'm unconvinced that Node will push out anything permanently. Java was the death of C++, wait there's PHP, hold the phone there's Ruby, Node is gonna eat everyone's lunch, now Go and Rust are the latest darlings (though they're at the level of Node right before it took off). Next it'll be Crystal, or Nim, or something weird like OCaml. Meanwhile, people are still using C++, Java, Ruby, PHP, Python, etc and those communities and environments aren't going anywhere. 
Definitely try this. Qml.Net acts like a bridge between .NET Core and Qt.
[removed]
[removed]
The [Pro 6](https://www.microsoft.com/en-us/surface/devices/surface-pro-6/tech-specs) has one USB-C: &gt; 1 x full-size USB 3.0 And so does [the Laptop 2](https://www.techradar.com/reviews/microsoft-surface-laptop-2-review) &gt; Ports: 1x USB 3.0, mini DisplayPort
[removed]
No, they have standard USB-A 3.0 ports. Only the Surface Book 2 has a USB-C &gt; 2 x USB type-A (version 3.1 Gen 1) 1 x USB type-C (version 3.1 Gen 1 with USB Power Delivery revision 3.0)
&gt; Eventually Microsoft will stop supporting .Net framework They will not. .Net Framework is part of Windows, so they are pretty much forced to support it forever, at least when it comes to security updates.
&gt;1) Yes. If nothing else, you save about 50% on hosting fees by running on Linux. This was one of the big reasons we made the switch. 
Yeah, there's a best match logic in the compiler which prefers expressions over delegates.
Go is not full native though. It still has a runtime, it's just packed in to the executable. It's why Go executables are so huge. You can achieve the same result with some tools in .net core. Go hasn't eaten anything yet. It's a good language, but it hasn't achieved anywhere close to the mindshare of Java or C#.