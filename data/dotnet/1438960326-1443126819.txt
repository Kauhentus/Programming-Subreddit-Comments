The web site is down, when is it?
Consuming Web API in C# is painful; it's RESTful design and JSON/XML format make it much more comfortably consumed in data-driven web clients over http. As you've found, moving to WebAPI &amp; a JS Client often removes the need for MVC. &gt; do the Api calls through the controller/repository allowing C# to do additional processing on the data before sending it to the front end For many problems, this *additional processing* can be moved behind the Web API. If you do want to write a service to be used in C#, use WCF - you can then use it just like any other class library (and over many transports). Ultimately; Web API is designed for building RESTful APIs over http. For RPC/SOAP/etc services, and for .Net clients, look to WCF and it's peers. 
I had the same problem. Here's how I solved it: When the delete button is clicked, save record ID to an itemToDelete variable using a function. When the confirmation button is clicked, get the itemToDelete value to determine which record you want to delete.
So the solution to fix `NullReferenceException`s is to not have null.
You can have an onclientclick and onclick on the same button. Onclientclick runs first opening the modal, set the confirm button's href in the modal to "this" so when they confirm it just continues and will run the onclick server side code, you can get the command argument of the button from there and do your deleting. 
Thanks. I can't try it yet but will do as soon as possible. 
You could try something like **Lightswitch** unless you want to learn asp.net mvc. If you want something simple and you don't have the knowledge try Lightswitch, don't expect the maintenance to be easy. If some other guy has to maintain your code he will probably throw it away and create it again. If the project is very small and the team knowledge is low then I would recommend Lightswitch. &gt; Server processes the data (this part can get mathematically intensive) Does this need to happen within the request? Is it something that's constantly running? How long does it take to complete?
Hey antiduh, thanks for all your comments, I really appreciate it. I suggest you open issues on github, so we can go trough them one by one. Reddit is not really a good place for this sort of thing.
Concerning hardcoded sizes, well there are 7 base SI units. They are represented in by BaseUnit enum. And each position in array is reserved for a single base unit
I was thinking of using that exact approach. Since I already have all the SQL connection stuff done on the C# program would it be possible to run the web app as follows: 1) Web Application Receives user input 2) Web App sends user input to C# program in same solution 3) C# program generates query and gets info from MySql 4) C# program does the processing and sends the relevant data back to the Web App 5) Web app plots the charts 
I am very much interested in learning MVC, this is for my masters thesis which is due in a year so time is not an issue - I already picked up a book and spent a week on tutorials. I feel like everything is moving to the web anyways and its a great asset to have prior to graduating, thanks for the suggestion though. Also, about the data processing part, it happens within the request, the time it takes completely depends on the user generated query, there are 44 sensors, and the time frame request can range from 30 seconds to 5 months - so if they choose data for 20 sensors over 5 months it can get quite heavy (I am implementing filters though) - especially since it is also processed prior to being charted. Just sending the query and receiving it back takes about 5 seconds regardless of the query. The software is for a Cubesat test Satellite (tiny satellite thats launched alongside large satellites).
Right. In that case you'd want to create a Windows service that will keep all those things in memory. This is a bit more complex to create as the service is another layer. But it would give you the possibility to reuse some code. The service will run always, and the ASP.net server side code communicates with the service. I'm not up to date on .Net modern ways of communicating, but I assume WCF is still the way to go. Alternatively if it's just for learning purposes, there's no problem with doing all the processing on every web request. And maybe you'll find better ways of storing data and structuring queries that makes the whole thing more efficient. And even more alternatively you could use [Memcached](http://memcached.org/) to store in-memory information. That way you avoid creating the service, but still having a good way of storing states in memory.
That's pretty much spot on, but the terminology is a little off. MVC can be a bit difficult to learn, so knowing the terminology and logical separation of the moving parts can really speed up the learning process. Here are some terms to know and a high level overview of them (sorry if I repeat basic things you may know already) View: this is the cshtml page with html+razor. There should be little to no logic here Controller: this is where the logic happens. Based on the request you can choose the best view to return and what data should be sent to the view. Data sent to the view should always be sent as a ViewModel. ViewModel: a class object defined in the Web project that maps specifically to a view. It may seem like an extra step bit this is important for decoupling the data layer from the Web layer, as well as writing extra read only properties that help display information for the page. Data layer: separate class library containing all your sql (or other data source) accessing logic. This is where your C# code would live. Just reference the methods for read/write from your controller and create a view model from this data Models class library: many developers like to create a new project in their solution specifically for models. Models are similar to viewmodels, but instead of mapping to views they map to data. So an example would be a bookstore database would have a books table, you would make a model called BookModel that maps to the table. Your data layer would generate a list of books to send back to the controller, the controller converts that list to a list of BookViewModel, and passes that to the Books view. 
*There is just one more thing we need to do, which is install a sweet IDE that will give us all the awesome functionality we get from Visual Studio, but now on a Mac.* This is so wrong. Code is not an IDE, Microsoft have said so them self, and it does not have half of the functionality that Visual Studio does, by choice.
I'd second what others said before me. Go the (harder) stateless API way. You can learn the most from that and as far as i see that is your goal. Divide up your existing app to Data Access, Business Logic, Representation. Make a WebAPI server app. Than extend it with an MVC client which is quite straightforward. For the fun of it, you can even modify that forms app to use the API after that. ASP.NET WebAPI and ASP.NET MVC are siblings. WebAPI is basically the same thing without the UI part.(html and stuff) They're so alike, that in the next version (ASP.NET 5) they aren't separated but one and the same thing. Because of that, dependent on how fast you are expected to complete the rewrite you should consider starting out with ASP.NET 5. Its about a month away from the last Beta release which should be the end of adding features. From there only stability concerns and bug fixes are addressed. Nov is the marked release of RC1. (You said you wanna learn the stuff for your thesis which is a year away, well get ahead of the curve)
&gt;The logic should only be in regards to generating html I was implying business logic, which is a common mistake new developers make. I should have elaborated on that i guess &gt;Logic does not go [in the controller] Again, I was not referring to business logic since that is where his original code is going on. But the controller does have logic. It needs to handle what view to return, what data to pass to the view, what service/repository/etc it should call for the data, and how to map to the view models. &gt;ViewModels should be infrequently used. This is new to me. Can you provide references to why this is no longer best practice, and why ViewBag should be used instead of ViewModels? I have only ever heard of ViewBag being used for random pieces of data, but even then it always seemed that you should try incorporating that into your ViewModel. It also seems like you would be wasting a lot of the razor HTML helpers such as HTML.DisplayFor, unless I am missing something about ViewBag.
Looks like you've gotten some feedback to include the library that has the existing tool's features. Here's what I'd suggest, piggy backing on what others have suggested. Keep going with the ASP.Net MVC approach however, just use the Web API aspects of ASP.net MVC. These ReSTful endpoints will be the bridge from your client to the api on your tool's library. Use the endpoints to capture the user's inputs to the tool and return the result sets back you need to display the information to the user. On the client side, I"d suggest using a rich client side framework that supports binding, Angular, Knockout, Ember, React. Build up your UI using any framework you want for layout, add your user controls and bind input fields/buttons/controls to JS objects on the client side. In summary: * Use your existing library that has your DB connection information and logic for building data for your charts. * Use ReSTful endpoints to act as your API between clients and your library * Use rich client side framework to interact with your service, posting data and getting return results. MVVM or some variant. * Model - POJO that are just stupid DTOs * View - Your HTML with bindings * ViewModel - If using angular this would be what angular calls a controller. Thsi is the bridge between your Models and Views. Neither of which should have explicit knowledge of either. Here is also where you might add properties that are view specific and not cared about by the Model. e.g. This is a bit more complicated, but this is the current trend where web development is going. This allows for a much richer, responsive UX to include asyncronous interaction with your web services. Side note: If you're going to go down this route, which will require a fair bit of JS to run the client side, I would suggest investing some time in TypeScript. This will allow you to write code that will compile to JS and allows you a language that has some similarities to that of C#, and not so heavy on the JS side. There are several other gains to be had by using TS to include strong typing, compile time build errors (catches type errors before they can be encountered client side at run time), Easy implementation of some of basic OOPs (sans polymorphism). Edit: Fixed formatting
That may work, and is good to think about for specific scenarios, but when talking about generic MVC you want to create viewmodels. It is also better to learn the basics of a framework, so that you can understand the issue that new design patterns are attempting to solve (and if that issue even exists for your task). Can you provide resources to refute any of that? Remember, we are talking about a new student to MVC, not a real world client. If/when the project gets to the point that sensitive data even exists then we would be commenting on an entirely different post without the need to explain terminology 
Do you want to be a C# web developer? Keep plugging away at MVC until it makes sense. It is the way forward (for now). Do you just want to get this done and move on? Don't feel guilty about using WebForms in that case. It will be A LOT easier for you coming from the client/server WinForm world that the app is already written in. EDIT: Gilded? For this? :) With instructions to do something nice...?! Sure, how can I help? :)
So you should have a tightly coupled database to the front end? What if you want to update the db? You would have to update the data layer and application layer. It would break your entire system... Are you trolling me now?
No, you've lost context of my previous comments. 1 HTTP request to a MVC controller should result in exactly 1 call to a in-process service, 1 call to a service bus/message queue, or 1 call to an orchestrator/mediator if you won't build in physical isolation. That single call in to "the service" should in almost all situtations be satisified by exactly 1 database get/query.
&gt; Don't you think that's a bit wasteful? Every time you allocate some simple unit, it's going to allocate 7 times as much memory as you need. Valid point, I'll have to think about that. I was thinking of using ImmutableArrays but I think I read somewhere, they are much slower then ordinary arrays 
Controls are dead, long live Views!
This, plus switch to vs 2015 and the compile happens as you change your code and you get edit and continue during debug.
That doesn't sound like someone "coming back" to asp.net. What kind of programming did you do "back in the day"?
What programming have you done since you left?
The MVC Music store is a good tutorial but maybe a bit basic depending upon what you've done in the past.
This is the exact same solution that had to be implemented in log4net for logical thread context to survive await. They had to switch to immutable stack and immutable dictionary. This guy has done a special build of log4net 1.2.13 with the two patches applied since log4net isn't going to be released again this century: https://www.nuget.org/packages/log4net-await/1.2.13.16 The patches in question are: LOG4NET-455 and LOG4NET-462
Php And javascript mainly. 
I am. 😃
This anecdote is useless because it omits any information about the configuration of those MacBooks. They could be 2010 MacBooks (not Pros) with platters and 4GB of RAM for all we know.
You don't need to use ImmutableArrays to make your class objects immutable - if you just don't provide any way to modify a live object once it is constructed, then it is immutable. Furthermore, ImmutableArrays don't make your objects immutable, because you can still use them in a mutable way - if I store an ImmutableArray (as a reference), and then have a method to concatenate a second immutable array to the stored immutable array, and overwrite the old stored immutable array with the result of concatenation, then since the state of your object is still changing, it is not immutable. For example: public class StillMutable { private ImmutableArray data; ... public void Concatenate( ImmutableArray tail ) { // Concatenate doesn't modify `data` or `tail`, but it allocates a new array // and this statement stores the result in there. this.data = this.data.Concatenate( tail ); } } `string` objects in .Net are immutable, but because they can be used in this exact manner, you can still have mutable objects based on immutable members.
I haven't gotten into MVC yet... Views I think of as the end page client sees, which could have many form fields, how would Views replace individual controls, or small collections of controls/fields?
Because I come here for discussion and to help people. By ferreting the discussion away on your github tracker, it helps *only you*, whereas folks who frequent this sub could also participate in the discussion and learn themselves or teach themselves. By suggesting that we take this discussion off to your github tracker, you're being *incredibly selfish*. Whether I'm doing the work already isn't the problem, it's whether you, or you and everybody else in this sub benefit from the discussion - like I said, that's the entire reason this sub exists, is to have the discussion, and suggestions like yours subvert that. So, yes, I'll happily continue to engage you here out in the open where others could benefit from the discussion, but I take offense to the suggestion that we go off to your personal github tracker to have the discussion. 
Thank you for sharing that. I use Windows primarily so I think I was leaning towards Python for its ease of getting started (installer). That said, I'm not against spinning up a Linux VM and getting started that way. Thank you again.
I think ROR is better aligned with my goals. Definitely will be keeping my eye on GO and Aurelia.
Yeah - no. There's no performance loss by using Windows on "Apple hardware" - it's all the same RAM, CPU, etc. 
They are called "partial views": http://www.c-sharpcorner.com/UploadFile/ff2f08/partial-view-in-mvc/ Must easier to work with an user controls. You don't have to register them in the web.config or on the page like you do Web Forms. You can strongly type them as well.
Yea, I dragged my feet on MVC, but once I was forced to use it I saw how much better it is. Just tell them once you use MVC you can't go back to Web Forms (also Web Forms is a dying architecture). There is a bit of a learning curve though, which puts people off.
Form development is 10X easier with MVC. You just create your model, pass it into your form views and create strongly typed form fields. Then in your controller, you get your model back with all of the values populated (not more 'string firstName = txtFirstname.Text' stuff). Then you can pass that model to your ORM (if you're using one). In addition, MVC will handle all the form validation for you, you just need to put the appropriate attributes on your model (required, regex for email address, etc). I've only created 1 or 2 MVC sites with forms, and I've gotten a little confused on how/when to use ViewModels, but other than that it's really nice and easy.
Absolutely, and this is where I struggle with my jr devs. It's not a competition. If I tell you your solution won't work it's not because I just don't like it. It's because the 16 years of experience I have gave me the foresight to see the big picture. Unfortunately a lot of the time they get very defensive and argue and argue their point which I've already determined moot. I do it very nicely, mind you. And I explain why. Seems like the more you know makes you humble because you've failed so many times to gain that knowledge. We know what it's like to make mistakes. I'll completely and gladly skip over that "drop table" statement I ran on a prod environment (thinking it was my local environment) once. 
Join Pluralsight, get the free 2 weeks, search for "MVC", and work from newest to oldest. THey walk you through full projects in most their tuts.
Alternatively, say fuck it, download VirtualBox, run windows in that, and go on your way...
It's October 25-27. Try dotnotunboxed.net, sorry!
Mithriljs is alright for a minimal concept 
You can work with Ruby and Rails without using a VM. I installed Ruby without too much effort. If you're an experienced developer you shouldn't have too many issues - the main issue with Ruby (and to some extent you'll have this with Python) is when using third party libraries that use extensions written in C. Here you may find Python easier - there's this well known site that has a lot of extensions built for Windows: http://www.lfd.uci.edu/~gohlke/pythonlibs/ I've also built some of the Python libraries myself using a compiler on Windows but I've not tried it with Ruby.
F# is obviously good for learning functional programming but if you want to try something new it's too easy to stay in the comfort zone of Windows / Visual Studio with an MS based language.
just a warning about using that nuget.server - it grinds to a halt with as few as a couple 100 nuget packages. We've been using Klondike which uses lucene on the backend to do searches and has some other features that make it a much easier and more powerful option https://github.com/themotleyfool/Klondike That being said, with so many projects sharing them and it looks like the potential to introduce breaking changes frequently into these packages I'd definitely want some sort of continuous integration set up. Testing against a new nuget package might get tricky. I know teamcity has a nuget package trigger, but short of a script that tries to update projects programatically to use the new project and execute a build I think you'll have to fall back to good ol' best practices on making sure you don't break existing code.
Creating a shared library (or even shared source i.e. links) introduces indirect coupling between the web projects, and comes with a cost. As you mention, when the shared library changes, how do you ensure you are not breaking any of the web sites that use it? Right now, you have the least coupling, because you can change on implementation of the "shared" code without affecting any of the other sites. And that may be appropriate depending on where in the software lifecycle the site is. If it's in maintenance, then refactoring it to use a shared library and pick up the latest features would not provide a good return on the time spent. On the other side, if you want your shared code to use some new feature of the latest .NET release, then you can update the "living" web sites without worrying about upgrading the old sites (which may also involve updating the software or OS on the servers that run those sites). So, the answer depends on your business needs. Here are some options to consider: * Have one true copy of the shared code, and for projects that need to use the code, use Add As Link to include the source in each project w/o duplicating the file on disk. This enables you to build the shared code inside the web application dll so your build output folder does not change (i.e. no new "shared" dll appears in the build). Creating a shared library is better than this approach, though, in nearly every way. * Create a giant solution containing all projects, refactor shared code into library, add Project Reference to new library. you can still use individual solutions for each site, though this introduces a bit of dual maintenance since you have to add missing project references to both solutions. The cost of the dual maintenance depends on how many solutions there are and how often it would need to be modified. * Extract the shared code into its own project and solution, build once, and add DLL dependency to it in each web project. Based on how your source control system is laid out, you could create a separate repository for the shared code, and branch it for each web project, allowing you to move bug fixes between branches as needed (or as not needed). * To distribute the binary, consider using nuget with a private nuget repository. this makes it easier to change what version of the shared dll each site uses and avoids cluttering up the repository with big binaries that aren't needed until build time. Also consider the training cost and the effort it may take to get people to buy into this approach. For these kinds of process changes, there's the cost of implementing them, and the cost of getting people to buy into them, and I'd say the latter has much more of an effect on how successful it is. If no one wants to go the shared library route, then you doing the work to refactor all the projects will go to waste. So, don't forget to come up with a strategy to get your coworkers (and people who have to support the web sites i.e. ops and support) behind your plan.
I have a macbook pro that I use for asp.net development. Get the 16GB of ram, it's completely worth it. I've worked for almost two years on my macbook pro. It was expensive, but i maxed out the specs. No issues whatsoever. 
We use git @ work. I have one solution that has a lot of the background logic in it, plus a few core executables. For new solutions I create a lib/&lt;Solution&gt; submodule that points to my logic solution. I have created a shell script in another submodule that can recursively go through lib/ and find itself (another copy in a submodule in the dependency solution) that will recursively build my dependencies (using MSBuild). Then i just reference the DLLs in lib/&lt;Solution&gt;/Release/. Ends up looking like this: /Solution/ /BuildScripts/ /buildLib.sh /lib/ /&lt;DependencySolution&gt; /BuildScripts/ /buildLib.sh [/lib/] /&lt;PROJECTS&gt;/ /DependencySolution.sln /Release/ /All/&lt;DLLS&gt; /&lt;EXE&gt;/&lt;EXE&gt;.exe /&lt;PROJECTS&gt;/ /Solution.sln /Release/ /All/&lt;DLLS&gt; /&lt;EXE&gt;/&lt;EXE&gt;.exe looks like this in git: /Solution/ /[SUBMODULE: BuildScripts] /lib/[SUBMODULE: DependencySolution] /&lt;PROJECTS&gt;/ /Solution.sln /Release/ 
&gt; you're being incredibly selfish. Funny, this whole time I was thinking this entire endeavour was quite selfless... &gt; I'll happily continue to engage you here out in the open where others could benefit from the discussion Github is as open as reddit, even more so. Your claim that others wouldn't benefit is false. I mean, this is how open source works. Anyway, I see that you have made up your mind, so fine, I'll engage you here.
As others have stated, maxing out the memory to 16GB is crucial, especially since it's not possible to upgrade later on. I use Bootcamp 95% of the time, and it's been a pretty great experience in my opinion. Performance is great, and we have quite a few large projects on our team. 
No there isn't but I don't think that makes Microsoft 'superior'. And you missed the point - being dependent on a big IDE isn't necessarily a good thing if you want to become a rounded software engineer. In my experience too many MS devs struggle when you take their tools away in a way *nix devs don't as they're comfortable working closer to the metal.
I can totally see how all this NullReferenceException jazz seems trivial to a lot of people, but I also constantly see other people struggling with same problems over and over again - both offline and online, hence the article. But there are people out there who can benefit from this sort of simple article - see here for instance: http://forums.asp.net/t/2061090.aspx?Problem+with+examining+values+sent+from+SQLDatasource
You will be surprised how many people don't actually do that because, well, they just don't know how to use a debugger.
&gt;No there isn't but I don't think that makes Microsoft 'superior'. And you missed the point - being dependent on a big IDE isn't necessarily a good thing if you want to become a rounded software engineer. I don't want to be a rounded software engineer. I am a phenomenal software engineer. I build software to do either what humans can't or at a rate humans can't. It's absolutely imperative i apply that to myself. It's absurd to even consider using a dumb text editor. It's laughable to believe that's a positive when i operate on orders of magnitude above because of tools. Why use a hammer when i have a chain fed nail gun? 
Self praise is no praise.
You will probably decide on a commen library with a nuget package for it. However I recommend taking a look at Micro Services and see if that can be a better fit. Pick whichever seems like a more fitting solution. Some people get dazzled with the idea of micro services and forget KISS. 
Let me convey some more information for you. First, nuget is NOT a solution to your problem. Nuget is a mechanism for distributing your shared dll. First you build the common library then any product that *needs* that library can retrieve it via Nuget. This is a way of handling version and distribution of the common code. Second, the shared dll + nuget pattern will work but it *will not fix dependency issues* in fact it sometimes can convoluted the problem which is something my company is dealing with. Third, RESTful services are nice and have some value. I wont debate the SOAP vs Rest but there is a correct time for each. However, I wanted to be clear and say that the MicroServices architectural pattern is *not* specific to REST. It's a pattern where you put your BL objects behind API's (as services) and allow access to it from other projects. It has its ups and downs as well but it *does* reduce coupling to dependencies since the consumer project doesn't inherit all the dependencies of the API's. *few* I really needed to clear that up or else it would have driven me nuts! 
This is a great article, thanks for putting it out there. 
I would as well, but I've never actually run out of memory with huge builds of 500 projects (not in a single solution, though) and MSSQL etc. also running. I have 8GB (Windows 7).
I don't it's well defined when it becomes an IDE. It's a sliding windows from line-based text editors to fully immersive systems.
Fair point. I think the "crucial" usage referred more to the fact that you are stuck with what you have out of the gate.
As you can see from the gist, I have added the "_public/" folder to my project.json as webroot as well as to the ViewLocationConventions. I'm not sure why it can't find the index, especially because the error says it is explicitly looking for "_public/index". Any help troubleshooting this issue would be great; here is my relevant system information: dnvm: .NET Version Manager - Version 1.0.0-beta7-10408 dnu: Microsoft .NET Development Utility Mono-x64-1.0.0-beta6-12256 dnx: Microsoft .NET Execution environment Mono-x64-1.0.0-beta6-12256 uname -a: Linux sloth 4.1.3-201.fc22.x86_64 #1 SMP Wed Jul 29 19:50:22 UTC 2015 x86_64 x86_64 x86_64 GNU/Linux Fedora release 22 (Twenty Two)
SOLVED: I had to implement a CustomRootPathProvider that pointed to _public
Nice article! I've tried ASP.NET 5 on the new Kali Linux 2.0 yesterday and it just worked instantly. What I'm looking for is SignalR 3 and EF 7 full cross-platform support. It would be awesome if we could use .NET Core to create cross-platform desktop apps with rich UI, too. 
&gt; Is this the best way to do this? The PS part is is unnecessary, anything you can do from PS you can do from code (PS calls standard .net objects). If you really really really want to call PS scripts then as well as turning on impersonation (and turning on windows auth &amp; disabling anon) then you need to add this to the runtime section of your web.config &lt;alwaysFlowImpersonationPolicy enabled="true"/&gt; By default asp.net doesn't continue to impersonate in new threads created, this tells it to do so. &gt; From my understanding of the following XML in Web.config using this guide[2] , the commands will still be sent as the configured user, not as the authenticated user... identity impersonate will execute as the authenticated user unless you configure it with a user, you don't have to do anything with your code for this to work, it simply will. Keep in mind *anything* your code does will run in the context of that user.
Are you expecting the console app to run as soon as it launches? Because you could just wait for user input?
On Monday a monk was sent to master Kaimu to inquire, “What is the greatest peril of caching?” Kaimu answered, “Monday is my busiest day. Ask again tomorrow and I will teach you all I know.” On Tuesday the monk returned and asked the same question. Kaimu answered, “Monday is my busiest day. Ask again tomorrow and I will teach you all I know.” &lt;edit&gt;Found it: http://thecodelesscode.com/topics/caching&lt;/edit&gt;
You can build your console app so it's fault-tolerant, i.e. when it starts , tries to connect to the server and fails it just attempts to do that again after a short pause. You can also make this pause dynamic, so the console app waits a bit longer every next time.
Is it possible you have an older venison installed on your Dev server? 
Do you have a hard reference to the .dll in one of your projects? Do any of your *other* nuget packages have a dependency on the *old* version of that dll? Sometimes nuget packages will have a strict dependency on a dll. This means that they will always pull in where version == x instead of version &gt;= x. 
Did you actually check the dll in the bin folder or might you be inferring this via an error? I ask because this reference in particular is in the GAC on my build systems but not on my servers, so it doesn't actually get deployed to the bin folder.
So, locally, when I build my project, the correct version gets copied to the bin folder. I publish via VS publish dialog, so the somehow, the publish process (Method-&gt;File System). The solution itself has 4 projects, one project (WCF with WebAPI installed via NuGet) depends on 3 other ones (DAL and BLL). Just checked the references, and I have the latest version for System.Web.Http.WebHost (5.2.3), copy local is set to true. However, packages folder for Nuget containes those two versions, 5.2.0 and 5.2.3 (see imgur link - http://imgur.com/ya3KzWK). Adding this to main web.config did not help. &lt;dependentAssembly&gt; &lt;assemblyIdentity name="System.Web.Http.WebHost" publicKeyToken="31bf3856ad364e35" /&gt; &lt;bindingRedirect oldVersion="0.0.0.0-5.2.0.0" newVersion="5.2.3.0" /&gt; &lt;/dependentAssembly&gt; Something is using older version and I have no idea what it is
Nope, all relies on NuGet packages.
Hard to tell, it looks like the WebAPI depends on that library.
Have you tried turning on your fusion logs on your Dev machine? It should at least tell you what assembly is attempting to use the older one. 
You're right that would make a terrible user experience. Yeah something similar to what Telerik have where you can load n at a time. Thanks kr0m
Cleaning did not help, but found the offender! OBJ folder where VS publishes from, had old DLL over there. When you clean solution, it does not clean the OBJ folder for some reason (at least for me). I've cleared all the contents and republished again. Thank you for the clue!
Try setting copy local to false, then change back to true, then check for changes in your project file. If the assembly is NOT in your GAC, copy local will display as TRUE in the Visual Studio GUI but will not be saved in the proj file. So then when you publish from a build machine where the assembly is in the GAC, it will not publish the assembly.
Are you using the obj folder as the source for your publish process? If so you might have other similar issues because VS stores temp files there prior to building the final package. I went through a process of fixing some of these issues at my work by creating VS publish profiles and changing our publish process to use those instead.
Please post the content of all your packages.config. Somewhere you have a version mis-match.
Do you have the actual DLLs in the bin directory on the deployed server.
It was never missing, just wrong version got published. Anyway, it is solved now.
We have to look into that issue. Something similar happens when code gets deployed by build controller in TFS. Not sure if we have to consider pre/post build events to do the clean-up.
Wasn't the issue. That was the first thing I checked, turns out packages.config had the right version.
&gt; Anyway, it is solved now. Don't leave us hanging...
I've had good training sessions from https://www.accelebrate.com/ Offers on site and webinar training on a variety of topics. You can even customize courses to focus on different topics.
Replied earlier: obj folder contained some old files.
Older venison how about younger beef or sumtin. Tss Tss. 
I had this same EXACT issue last week, if you're using the publish feature from VS, try deleting the publish profile (in the project under Properties-&gt;PublishProfiles, was TEST.pubxml in my case) and then recreate it. That fixed it for me, not sure what caused it though.... 
Nope, they are not. 
The theme in VS 2015 really is to run many things in many places. :p Almost all major new features relate to that, even the Windows 10 ones since they are mostly about Universal Apps, a concept cool by itself. Then you also have the iOS and Android support via Cordova and maybe something like [Ionic](http://ionicframework.com/) or [Onsen UI](https://onsen.io/). Hell you can probably stick with VS 2015 alone on Windows and get an app all the way to the App Store thanks to online services that help you with that final step without having to own a Mac. That's pretty neat. (Android, of course, has far less hoops)
That is weird, publish profile doesn't contain any entries related to nuget packages and versions.
Ok thanks. Ill give it a try. 
That's what UWP is sort of for but cross-platform meaning cross-windows devices (phone, desktop and xbox). But it could slowly evolve to work on different OSes or mono can make something up?
i know, i'm not sure what caused it for me, but i banged my head against my desk for hours on it... I finally gave up and tried to publish locally and was more confused when the correct DLL showed up in the local publish folder, so out of desperation i deleted the pubxml file and recreated it (even with the exact same settings) and it magically worked. It could be some rare, odd bug with vs2013sp5 or vs2015 (i have both installed but was using 2013sp5 at the time)
What if you just bypass the SyndicationClient and use the SyndicationContent directly: var con = new Windows.Web.Syndication.SyndicationContent("RSS", Windows.Web.Syndication.SyndicationTextType.Xhtml);
Thank you! The dozen or so parents would know where to register, but I know all of them and can pre-populate the db for them. My biggest concern is limiting the new registrations only for school staff and if the filtering by email seems acceptable I'll go with this until I can build a more elegant solution. 
The end to end samples might be helpful: http://microsoft.github.io/windows/
Why not just create a launcher application that checks the architecture and then shells the correct executable based on the architecture it finds. Then your instructions to users are just to run the launcher.exe and it will do everything else.
Yep. I saw this [blog](http://devblog.avdi.org/2015/08/11/what-its-like-to-come-back-to-a-ruby-project-after-6-months/) post today that shows some issues with Ruby and I fear .net is heading in that same direction.
Any proprietary software you utilize will most likely come pre-compiled. If you want something where you can modify the source you will most likely need to go the open source route. Is it common? I would say yes.
If you have multiple executables anyway, why not just build two separate x86 and x64 builds and distribute them accordingly? Otherwise, you can check the architecture of a .NET library with `System.Reflection.AssemblyName.GetAssemblyName("...").ProcessorArchitecture`. You could also use `AppDomain.AssemblyResolve` to dynamically load the right assembly.
Good. I missed these. I only saw the main samples
Gotta be talent that lives in placed like India, Ukraine, etc. In the US, I'm not sure I could compete with that with the bills I have to pay. I liked the article, but the problem I had with it was they said "you get the existing C# code. Just port it to mobile." Well of course every Xamarin dev is going to jump out of the woodwork on that. My first thought was "shit, its already done. A couple of tweaks in Xamarin and BAM, finished product." Here's an idea - do the same experiment but say, "the app is html5 and already works. I'll give you all html5, css, js files and all graphics." See how many Phone Gap guys start waving their hands around. Do it again and say, "its already in Java. We'll give you all .java files." See how many Android Native devs jump up. 
&gt; See how many Phone Gap guys start waving their hands around. Agree. Although I don't think I'd using [DevExtreme](http://js.devexpress.com/mobiledevelopment/). I'd more consider UWP/WinJS or newer. &gt; I'm not sure I could compete Knowing that Xamarin only gives you 20% commons, reducing your platform specific work to 80%. Is it worth the price? One plus with U.S. coders is our execution and delivery has been optimized over the years, giving more bang for the buck... including foreseeing the 12 iterations we have nicely refactored into a product for the projects, perhaps as DDD.
It is beyond common. And they aren't wrong on the divergence end. If they ship you the source for v1.1 and you rip it apart and customize the hell out of it, what are you going to do when they ship you v1.2 or hell v2.0? Are you going to merge the codebases yourself and reapply any customizations? Or are you just going to stay on v1.1 forever? And when your customizations break something, what is support going to do for you? How will they know of their app is the problem or your customizations? For most apps (proprietary or open source) it is far easier to color inside the lines and write plugins where available instead of doing what is functionally the same as completely forking the project.
I believe a discussion about NuGet is a valid topic for /r/dotnet, yet it is down voted. This is why I don't like reddit anymore. In the old days people would have posted disagreeing comments instead of burying the post. 
Do you have any conditional breakpoints set in the solution? I've spent hours debugging weird behaviors such as the one you mentioned just to find out it was caused by a bad conditional breakpoint, such as accidentally using assignment instead of equality operator, i.e. myVariable = 1234 instead of the correct way myVariable == 1234
Yeah, all of my dll references (that aren't from other projects in a solution) come from nuget, so perhaps I just haven't run into any of the issues you have. My only complaints about nuget is that it is a little bit worse with transitive dependencies than bundler and a lot worse than npm. [Paket](http://fsprojects.github.io/Paket/) seems to solve some of those problems, but I haven't used it enough to speak too authoritatively to it.
It depends on the business model: * If it's an application that is not custom ordered, most of the times it comes without source code or with possibility of adding source code for extra price. * If it's an application written just for you, it's more common to include source code, but it really depends on initial contract. Most developers will try to keep the source, so you are bound to contract them to support your app without option to change to different developer.
For testing, Amazon offers a free tier for 12 months. https://aws.amazon.com/free/ Edit: Now that I'm not on mobile I can add more detail. For AWS hosting on the free tier you would use: * An EC2 virtual server instance for Windows/IIS to host your Web Api/AngularJS front end. The free tier gives you a T2.micro instance. You can read up on what the [T2.micro means](https://aws.amazon.com/ec2/instance-types/). * An [RDB virtual database instance](https://aws.amazon.com/rds/) for MSSQL to host your database. The free tier gives you an instance with up to 20GB of storage. Deployment of the instance is all done point-and-click via Amazon's management website.
You're setting Background in both places, the style and the button itself. So the Bg on the button takes precedence. Remove the BG on the button itself and add the appropriate setters to the style to first set the default, then overrides inside your trigger.
You should put yourself together with that guy, he has the same issue as you: https://www.reddit.com/r/csharp/comments/3h6fas/dunno_where_else_to_post_trying_to_style_wpf/
&gt; The main issue is ambiguity between the dll references in the csproj file and packages.config file. There can only be am ambiguity if you fiddle yourself with the references. The tooling is not really at fault there.
Gear host is also good
&gt; Visual Studio does not restore NuGet packages during a build by default. It does.
&gt;that's more a wrapper around API stuff that adds authentication Does that mean the authentication/user management built into my project won't work unless I have it, or will that stuff work just fine with the App Service?
I would say focus on ASP.NET because the majority of roles I come across are all web focused. If you get a handle on Web API and MVC, along with Entity Framework, you should be solid. Would be a great plus to be faniliar with a unit test framework and a DI framework, I personnally use VS Test Tools for unit tests and Unity for DI because my company is pretty big on sticking to MS technologies. In the front end, most things will still be the same. If you are not too strong with CSS or JS, I would recommend learbing those well because a lot of devs seem to only know the bare minimum in those areas.
Interesting. So Visual Studio Code is an important feature of Visual Studio 2015.
Standard reporter trick. If they have news that isn't quite important enough to stand on its own, but still worth talking about, they'll just tack it onto a vaguely related article.
Quite frankly, your code is a mess. - Lack of documentation. - So much static. - No parameter validation at all. - So many mutable static public fields/properties. - A public mutable field of type `ConcurrentDictionary&lt;Tuple&lt;Type, Type&gt;, Tuple&lt;object, bool&gt;&gt;` - are you serious? - Public extension methods of common types like `string` and `object`, especially extension methods that have nothing to do with the purpose of this library. 
Documentation is present? Where? https://github.com/omuleanu/ValueInjecter/blob/master/ValueInjecter/Mapper.cs Not a single comment in this file. Not a single XML doc in this file. Same here: https://github.com/omuleanu/ValueInjecter/blob/master/ValueInjecter/MapperInstance.cs Instead you just have **awful** code like this: Maps.AddOrUpdate(new Tuple&lt;Type, Type&gt;(typeof(TSource), typeof(TResult)), new Tuple&lt;object, bool&gt;(func, false), (key, oldValue) =&gt; new Tuple&lt;object, bool&gt;(func, false)); And static has uses. And you're misusing it. Instead of properly structuring your code and dependencies you just put a static in front of everything.
that would be xml docs/comments, documentation is present, on github readme.md is shown below the source code files, scroll down; I think the static is used ok, I'm not sure what that line does, but you should say why it looks "awful", and why the static is misused
It might also help getting accustomed to VB.NET, which (from my personal experience) still seems to be fairly widespread. There's a lot of old projects that got migrated to .NET from Visual Basic and need maintaining. While the language syntax is quite different and you don't have some of the fancier C# features, you still get to use the same .NET-Toolchain with all it entails. For the most part, if you could write it in C#, you could also write it in VB.NET. The same goes for Windows Forms vs WPF. Knowing the "older" .NET technologies also opens up possible migration projects for you. I frequently see companies looking for developers to help them migrate old code to C# (often even from VB6 or VB.NET). Of course, that all depends on whether you actually want any of these options. Having the options available means little when you don't *want* to work with the older technologies. For instance, I'm currently in a project that's stuck at .NET 2.0 . I can cope, but it can be quite a stretch on my patience sometimes (especially missing LINQ here). If you'd rather stick to the modern technologies, I got nothing to add that /u/joelving didn't already say.
That was it! Thank you so much.
if your code is switch(status) case 123 then the first step is to give the constants names in some shared file: public static class Constants { pubic const int Active = 123; } or create an enum which gives you better type safety public enum Statuses { Active = 123, Closed = 456, } This would let you write: switch(status) { case Statuses.Active In SQL, you can create lookup/reference tables which store the value and the human-readable form. CREATE TABLE StatusLookup(StatusCode INT NOT NULL, DisplayName NVARCHAR(256)) Finally, you could write a small program or shell script to read in the .sql file and do a find and replace on the guide with your own constant. The sql script wouldn't be runnable anymore, but it would be easier to read. That might help and be the easiest solution if you just need help following the business logic of the script.
Thanks for the feedback. I guess my comment about it being common was a little incorrect. I realize most software is delivered compiled like that. My hangup is with the web app being delivered pre-compiled. The software doesn't have a plugin system really and the documentation is pretty minimal. We wouldn't have a problem paying for the source licensing if that were worked out with the company. I was mostly curious if we did this would it really be a pain to keep the code from diverging. From the comments it sounds like this would be the case. I think I'll approach this from the plugin model and just ask for better clarification on how to hook into the certain parts of the app I need access to.
So every time the program runs, it generates a collection of static GUIDs? That's bizarre on way too many levels. I agree with /u/reznet, this should be replaced with an enum system. Enums are an ideal form of syntactic sugar since the underlying base type is int. You can easily convert between numeric bases, you can easily make use of the enum keys, and it makes for a very lean utilization if you are dealing with any unmanaged code and want to declare a const in your code to pass values.
Sorry, didn't have a chance to check until today. You're suggestion led me to the right answer! Turns out the SyndicationFeed class lets you load from a string. Simple solution! Thanks!
Their use cases overlap. I prefer ValueInjector because I find AutoMapper a pain in the ass to setup for dependency injection. It's all that static crap that needs to be wrapped. 
I prefer simplicity and flexibility, so I roll my own mapping implementations. Especially over undocumented libraries.
Enums.
I had a requirement like this for an application I'm working on, only we wanted to save the entire state of an object when saved so there was an audit trail of who changed what and when. The application was using the repository pattern, so I wrote a generic repository class, AuditedRepository&lt;Entity, AuditEntity&gt;, that took two types as type parameters from entity framework. The class then used some reflection to map properties with the same name to a new AuditedEntity, and then saved to the AuditedEntities table. You may be able to do something similarly. My previous employer had this kind of logic strewn about the database in triggers and it was hard to maintain and track. I took the generic repo route because I could see this being required functionality in the future for other tables, and it's easier to inherit AuditedRepository&lt;&gt; instead of Repository&lt;&gt;, than create the trigger (in my opinion). In code first I would assume you could define your model by doing something like public class AuditedEntity : Entity. My project was using database first, so I had to create the table and add it to the edmx file, so updates required updating both tables in the edmx file. With code first I'd think updating the Entity would take care of updating AuditedEntity as well since AuditedEntity inherits Entity. This ended up being way longer than I expected it to be. Good luck!
I wrote and maintain a library which implements a set of events for EntityFramework. I designed it as a drop-in way to do .NET-side triggers. It sounds like your project is a good fit for it. https://github.com/NickStrupat/EntityFramework.Triggers
I can pretty confidently say that .net is not skipping code when under load and that the problem is in your app. How are you handling exceptions? Is there anywhere that continues execution after an exception (that might come up under load)? The application swallowing exceptions would be my number one bet. Is there logging in place? If not then add some at various choke points. Is there any sort of caching? Have you load tested the app with anything to find out this or are you just guessing based on what seems to happen?
It sounds like you might have another problem of too many independent states sharing the same status field. It might help if you show a list of what these statuses are? A recent project I worked with had statuses of active, lost, decommissioned etc. They were all sharing the one field and it wasn't natural. We separated out the active status to it's own property for instance. Then a product could be both lost and inactive. It's pretty common to have a lookup table for these values though. The code can use the real value but there are times when you need the status value in sql.
It sounds to me like OP may be running some non thread-safe code, or something to the effect. OP - I recommend reviewing how you're using your controllers and how your DAL is built. Often thread safety issues don't become issues until higher load as it's not until then that stuff is getting thrown around and paused etc more.
I would have a separate static class (or a singleton) with a property for the start time. When the service starts up, set that StartTime property. Then have your SecondsSinceStart method read the static StartTime property. It's basically a global variable that is available to any instance of TheTimerService. This assumes you only have 1 long running task. If you have multiple, then you will need some sort of identifier for each one.
Ah, I don't think I was actually checking for empty responses in one part... that should help with at least one of the issues. Thanks!
Yes, I've done some load testing. These issues only occur when under load. For example, one of my controllers works perfectly fine when under light load, but suddenly ModelState.IsValid will return false and complain about data not being required (when it is being passed in the http headers). This replicated 100% under load and 0% of the time under no load. Sadly, I don't have any logging in place, and we aren't caching anything (unless it's happening silently in the background). There's nowhere that continues execution after an exception that might come up under load that I know of... everywhere it's failing I'm not catching anything (though the exception catching I've got in is admittedly scarce...)
Are you using the default model binder? Are there any custom bindings you are using? Are there any static variables or singletons that could have the wrong scope? Are you using an IOC container?
I was using a custom model binder, but it's now calling base.BindProperty. Haven't removed it yet, but it's just passing everything to the default model binder: protected override void BindProperty(ControllerContext controllerContext, ModelBindingContext bindingContext, PropertyDescriptor propertyDescriptor) { switch (propertyDescriptor.Name) { //case "mOccurred": // OccurredTimeBinder(controllerContext, bindingContext, propertyDescriptor); // break; default: base.BindProperty(controllerContext, bindingContext, propertyDescriptor); return; } } There aren't any static variables or singletons. I'm also not using any IOC containers. Not using EF, either.
Yes, this is a direction you can go but not one anyone should strive for. Vb. Net and anything older then 3.5 should be avoided unless you absolutely must. It's really easy to pick up the old stuff if you must after you've learned the new because it's mostly the same just more limited. 
This all sounds normal honestly. It's how we do it. And we would have the same concerns as them when it comes to updates. Best I would give you is shared git access and you would lose any changes you didn't check in on the next update. But that is even very rare and would cost extra. 
I am not sure exactly how you are using these values but in general there are two strategies here: 1. Enums - Covered quite well by other posters here 2. Types - Depending on how these values are used and what they are meant to represent during runtime. You may want a simple class with some decorators that store the data. This way you can use the type system for look-ups and cross reference when needed. You can even bake in some of the validations that are likely littered throughout your code into these types for better encapsulation and improved testablility of the validators. Note that you can also mix Enums and decorators as well, you can have an enum type map to a Guid in a decorator and have an extension method to get the guid out from the enum so you can clean up the way the code looks by making it more meaningful without killing the use of the GUIDs outright which may make the code unstable.
&gt;How are you handling exceptions? Also, relating to this: How is the OP handling logging of exceptions if any?... I've seen situations were logging is put in place, but exceptions themselves are not logged properly :D http://stackoverflow.com/questions/15167927/how-do-i-log-all-exceptions-globally-for-a-c-sharp-mvc4-webapi-app
So just getting the nuget package doesn't work?
SQLite is an extension SDK, since WP8 you have to install it into Visual Studio itself. Kind of like XAML behaviors. Not sure if is because nugget doesn't play well with C++ code or what.
Ok.. Ill give it another try
I think a lot people forget that IIS calls you'r controllers in a multi-threaded fashion. Everything lower in the stack then a controller needs to still be thread safe even if you don't spin your own threads. In most cases I see people who inject their EF Context incorrectly and that Context is very much NOT thread safe.
It is running under IIS, I'm not too familiar with it, though. I'm going to add Elmah (as suggested below) and see what gets caught. Static will turn up things, but only static functions, not static variables. I'll do a search anyway just to make sure I'm not lying, as it is a large codebase at this point.
If you find out that your Entity Framework Context (I assume you use EF) is closing connections then you have a multi threaded issue around the Context because it is NOT thread safe. If you are using dependency injection check the following: (1) The correct lifespan for you context is used during DI registration. (2) The context is *NEVER* injected into a static class. If you find that it is injected... don't. Instead new it up inside the static class. (3) The context is *NEVER* injected into a class with a Application level lifespan. This will cause the context to never close a connection and that will hold onto resources you may need. (4) If you inject the context into an attribute and you use the FilterProvider to buildup the context DI you may have just caused #3! [This happened to me and was a real bummer to figure out].
Ohhh, love that you used Gradle for this - that's definitely been my favorite part of the JVM tooling.
Their other post on high throughput ASP.NET in Azure is also super interesting: http://www.ageofascent.com/azure-cloud-high-speed-networking/
Well ya man, if you have 100 people on your website IIS doesn't call a controller and retirn the response one at a time. It has to be done in parallel or any more then 5 users would cause the whole site crawl! Also a tip for iis. It has a thread limit per application pool. So if you run too many apps under the same app pool you might be hurting performance. 
WPF Developer here. Don't bother with WPF as far as it being in demand. Its not dead by any means, but its not a major tech anymore. ASP.NET is your single best choice, its the most in demand tech right now and perhaps through 2016.
Yep, I run a .Net development house and would echo this.
Ugh, just JQuery really. Angular is cool but it's pretty handicapped. It takes a bit more code to do it in JQuery but it's soo much more flexible
You've got it the wrong way around. It's 80% reusable, 20% unique to the platform. 
I read the opposite from another post. I'll try to dig it up.
Thankfully, we only have the one app running on the app pool, so there's no worry there. This app will only have up to 200 people attempting to access it at one time, so I think we're fine in terms of the number of concurrent threads.
What are your reasons for thinking it's handicapped? I've built some apps insanely fast in angular that even thinking about the pure JQuery implementation would give me a headache. 
ASP.NET will continue to be the bulk of .NET related work for the next year or two at least. WPF/UWP is promising but not nearly as deeply entrenched. And even when it is, connected apps still need some server side functionality ripe to be provided via ASP.NET Web API OData.
Thinking about picking up a xamarin license. Is it viable for both android and iOS development? 
Amy help would be appreciated; I'm in central California.
Overall answer is asp.net is the winner in all .net tech. Thanks you all.
There is a license for each
When I started using templates. You can't write any JS in using Angular
I can see that, that's where JQuerys promises come in damned handy
Want a boner killer? Visual basic. 
I find the process of rewriting vb in c# pretty calming. :)
What do you mean by analyzer
Oh man I know how you feel, I had a project where we basically had to port a Forms app to the web and it was painful. All because our solutions architect still expect it to work in the same way a desktop application would. He even asked for double-click! 
I am a .net developer. Started in desktop apps. Now I do a lot of everything. Wpf for desktop, Angular/java script for web, d3 for visualizations, wcf for web services, Azure for cloud platform, R for data analytics.
Most applications at some point will want to start performing actions on the client to prevent an unnecessary round trip to the server. Validations, complex object configuration, etc starts to require a lot of javascript. Frameworks like Angular and Knockout provide a way to minimize the amount of javascript you need to write by handling a lot of the model binding. Knockout is actually the brainchild of a Microsoft employee (Sanderson), although it is not a Microsoft product. One team within my company was able to reduce the amount of js they had written in their ASP Web Api project from 80k lines to 5k after moving to Angular. It can be a powerful tool when used correctly.
What I'm noticing about angular is that it kind of tricks you into following good JavaScript practices - even of you don't know them. By defining everything in the angular namespace, you are protecting your app from the pitfalls of JavaScript global scope. You'll also start to notice how little needs to change to extend functionality after you get over that learning curve.
I would advice caution when choosing to use Angular or not. Angular is a tool and as a tool it should not be used in all situations. When using traditional ASP.NET MVC, the MVC portion of your application will typically translate like this: * Model: Your data model * View: The generated HTML + JavaScript + CSS sent to the client * Controller: Coordinates the generation of the view with loading data into the data model This means that the logic of rendering views is placed (mostly) on your server-side. What Angular and other such frameworks (e.g. Ember.js) are doing is actually to introduce the MVC-pattern on the client-side of the application, so that in reality your know have two MVC-applications i.e. your backend server and the client. This has few notable consequences for your application: 1. The *View* of your backend is no longer mainly serving HTML. Instead it is usually some REST API serving JSON, XML, etc. 2. The client takes over much of the responsibility of rendering the *View* 3. Your client uses the View of your backend (i.e. your API) as its backend when loading its *Model*, i.e. the backend server is used as a data source in a similar way as an SQL database might be used as the data source on your backend server. 4. Your client application can coordinate complex interactions in its *Controllers* in the same way as your backend server can. When deciding whether to use Angular simply ask yourself this: are your client interactions complex enough to warrant introducing a layered architecture (i.e. MVC) on the client-side? For some operations and applications introducing a layered architecture will help reduce complexity and improve your code, while in other cases it may only add unnecessary complexity: * If all you want to do is have a contact form so that customers can send a message to support, for god's sake **DO NOT** use Angular! A standard form-post is way more portable and easy to maintain. Even with validation requirements (e.g. user must enter a "valid" e-mail address) using some smaller validation library (e.g. jQuery Validation) is better than throwing Angular into the mix. * If your application provide lots interactions with business rules limiting the possible interactions based on the current state of the application, e.g. adding access to a service to a customer should only be possible if the customer is active, then Angular might be the right tool for the job. Performing business rule validation on the client-side **ALSO** (remember to never trust your clients and always validate all state changes server-side as well) can be a great help to the user experience of your application. I fear that many developers these days choose Angular or React.js just because they are "cool" and "the latest great thing" (and I myself am not exempt from such folly). Try to remember that not every web page needs to be as complex as Facebook or Gmail. A simpler and traditional Request-Response web application (i.e. vanilla ASP.NET MVC) might actually provide a favorable user experience in many cases: * On mobile devices which do not have the same rendering power Angular rendering slows down the responsiveness of applications greatly. * When a HTTP-request fails in a traditional web application, I get a page error (or an empty page) and I simply reload the page. With AJAX-requests errors are not as obvious and the developers of the application must manually implement error notifications, and even when they do it is no always obvious how to retry the operation (i.e. an operation analogous reloading the page). As an MVC-framework for the browser I think Angular is great. You just need to consider the cases where you use it. **PS.** A simple heuristic for when to use Angular: If you implement your application for mobile devices, would it make more sense to implement it as a native-app? **DS.**
I have, it was kind of cool. I did, I was writing something and I started using angular and it was pretty simple once you learn the directives but it wasn't flexible enough for what I needed and just ended up writing it in JQuery
I use angular because I host a lot of applications on one server and angular let's me get all of my application functionality into JavaScript and templates which cache on the client machines. So instead of constantly serving up entire webpages, a user will only load the entire page once and then it just makes api calls for data. Making all the applications on my server faster and more responsive. Past that, I did a morphic interface in MVC early in my career, a basic form that swapped out partial views based on user selections. It took a couple of weeks of debugging, tweaking how viewmodels interacted with each other and getting/parsing types from posts. I can do the same thing with angular and an api in a day or so, since I don't have to worry about mating up the view models. It makes morphic(?) Models and interfaces much easier to write.
Solid advice. There's also a middle-ground between SPA and plain old postbacks. ASP.NET MVC's Ajax.XXX HTML helpers allow to do some pretty cool stuff without much JS code. This way if you want want to, for example, submit a form and update a list next to it without refreshing the whole page it can be done with very little JS. Once things get really complicated, a good client-side MVC framework is way better than JQuery hell.
I just took over a project that is MVC and angular based. I'm getting more familiar with it, but it was new for me as well. I have been heavy into client side dev for many years, but angular seems to just be coming more prominent in my area in the last year or so. My feelings so far... I like it for the spa, I despise returning to the server when I don't need to. But there are other solutions for accomplishing this, and you have to weigh the benefit/risk (and security) of having so much logic up front spread across numerous js files. When the PMs start asking for changes, or adding in new paths you didn't foresee, it can get complicated quickly. And if you have fields being populated by web api calls, you're page may come up right away, but those fields won't. There are a lot of pitfalls, it's on you to understand and architect for spa. MVC is usually data intensive, if you were working on a simple site most of this wouldn't be so much of a concern. I think it *can* be a good tool, in the right hands. My biggest daily complaint is I find it cumbersome for customizing events, and integrating with other libraries (my own and standards like bootstrap). It definitely wasn't designed for integrating with a .NET project, so the project itself seems ugly to me. But if I had designed it from the ground up, maybe I could have organized it better. And if the whole idea was to not rely on so many libraries to add client side functionality, then why do you have to go download so many modules to add client side functionality? If you're already a js ninja, I don't really see what functionality it's adding beyond making it a spa. Also, the testing suites were designed for node.js apps, you can get chutzpah to integrate with VS but I've spent days trying to figure out how to test all the aspects I need and I haven't come close. I'm not even sure it's possible, as there's almost zero help out there on how to do anything but setup chutzpah.
I have been at my internship for 1 year. I learned ASP.NET MVC and now they have me converting vb6 applications to c#. This is the worst experience I have had in my computing education so far. Major boner killer.
Hey, I use ractive.js and jQuery together. Doesn't lock you into a framework and uses two-way binding with templates. Really awesome for smaller SPA apps. I think you would like it.
I mostly do new app/feature development, which means dealing with product owners and customers that don't know what they actually want and constantly evolving requirements. If i get the chance to do something like rewriting (the requirements are literally in the code!) then I jump at it. :P I understand it would suck if that's all you get to do though.
Probably better than having to actually write new vb6 code
How relevant is Apache Cordova going to be you think?
WPF Developer here. Customers still require desktop apps. And while the customers might be a bit more boring than the hip and upcoming startups that are aiming to be the new Facebook, they might be a bit more stable. From what I have experienced, everybody and their cat is a web developer, but only a few are desktop developers. I, at least, have had no problems in the job market. Pay is also good, and stable. Also, while WPF is not a "major" tech, it's still the de facto standard for new Windows applications in .net right now. (and will be for some time, until everybody switches to Windows 10 and Universal Apps, which... won't be for some time) Another thing is that you don't need to learn a new and hip framework every two month. WPF is a mature framework. (although lacking in some parts)
Keep up on ASP.NET and start learning Akka.NET (which is now stable).
How about a right click menu? 
One thing I have noticed is that Angular is really easy to understand for random off-the-street developers who might still have a PHP mindset. Compared to ASP.NET MVC, the barrier of entry is lower and you can find suitable developers far easier.
Right. I meant to say I get knockout. I don't get angular that had controllers in js.
I find knockout + jquery.validate a more natural fit with MVC. Angular provides both data binding and data validation as well as the obvious client side MVC pattern. In addition there are a whole host of other things Angular does like templating. I think Angular has way to much overlap with MVC so I prefer to pick simpler more specific technologies for solving problems instead of importing a massive framework that *can* solve all my problems but also solves problems I don't have.
As relevant as it is now. It makes sense for a full JavaScript shop. Otherwise it may or may not be a good choice dependent on a load of factors. Seems like big shops experiment with it to find out
"I don't know how much work it is to get a basic app running with Linux + Python but I am guessing it is not as easy as with Windows 10 + VS 2015 ?" This is a slashdot type belief. It's just you switched linux and windows around. 
I didn't say WPF is dead, I said its not really in demand. We are in the context of what .NET skills will be in demand in the future. WPF has its niche but only a small percentage of the .NET jobs out there call for it. UWP is for Win 10 (there is no plus). WPF would be the choice for desktop apps for all Windows platforms. However if you want a marketable skill with plenty of jobs calling for it WPF is not it, ASP.NET is.
I know it was dickish lol. So pro tip for google foo since I lambasted ya. Always include [Library/Framework] and [Language] when googling. It's the keenest way to get hits on the question. 
Oh ya definitely. Well I'm glad you got your answer non the less :)
I thought it would do less than it does.. I am writing work apps and putting them on the raspberry pi and think that is amazing... having all the UI and all 
But it is interesting how it opens up creating single purpose Raspberry Pi machines and put them around the office... no need for a $1000 Dell.. just need a $35 rp I have not transferred me app over yet.. It uses web services so I wonder if there will be any issue with that.. besides that it is basic
Ok. Well that is why I asked if anyone has done both? My only experience with non windows and a designer I worked with using sublime .. And from my point of view it seemed like he was doing things the hard way vs. what I could do in VS
For the sake of my career I hope .NET/Azure becomes cool again
Ok so maybe it is easier. But getting the Win10 image is just 1. Download installer 2. Run installer 3. Run Image writer 4. Insert micro SD and select IMAGE 5. Burn 
I will definitely post back when I get it working. I've got ELMAH in, and I'm making the program more thread-safe. It's a big project, gonna take a bit to fix.
Not really sure it's what you are looking for, but Microsoft frequently updates their samples for universal apps [here](https://github.com/Microsoft/Windows-universal-samples).
Looks good, the repository layer should go into its own separate project, or in the same project as your POCO's/DBContext depending on your needs. Imagine if you were to create a web API for your data, rather than having to refactor your controller code, you would simply modify your repositories to interact with the web API instead of EF. Miscrosoft actual recommends NOT using the UOW pattern with EF, except for the rare case where you may have a complex transactional event that spans two or more different DBContext's.
Well I need to get a job in one of those cities to actually move there. 
But you left out steps that the IoT list above has... When you add 6) Eject the DVD and 7) Boot the DVD... They have exactly the same number of steps.
The `BundleTransformer` is a bad way. Instead of having LESS transpilation happening at compile time you put it to runtime. That's just silly and wastes resources on productive servers.
Why is this still stickied?
here's what I have: http://prodinner.codeplex.com (uses DI, Owin.Auth, lots of CRUD, image upload/crop) https://www.youtube.com/watch?v=fsfOFL4bXXA (tutorial some mvc basics and very basic CRUD at the end)
What hatred? I have not seen any.
Sorry, it wasn't clear, I am not awaiting. It's just a call-and-forget scenario. I'm curious as to what will happen if the calling stack finishes, before this un-awaited Task has yet to complete. As to what I think could happen, my fantasy is it will still continue until it's done; but I suspect, it will end when the calling stack completes... :-/ 
Hey, you could have a look around at /r/windows10iot It's a subreddit I created about everything in regards to this. It's still pretty empty, but feel free to ask questions and stuff. There are already some of MS IOT devs hanging around there as well!
Looking for vangular 2
That's not universal or 5. Good sample though
As I mentioned in the post, the result is cached in memory after each bundle is requested for the first time. The performance impact is negligible.
You are receiving mixed answers because opinions are like butt wholes, we all have them! So this is a really a complicated topic and I don't know how to simplify it any. I spent many weeks investigating this exact same problem with EF and eventually I made a decision and implemented it. I will try and take you through what I chose, why I chose it and what grievances I have found. Please stick with me. First I should describe my general architecture. My product is layered as such. [MVC-Controller] -&gt; (DTO) -&gt; [BusinessLayer] -&gt; [DataLayer]. My controller takes a ViewModel it maps that into a DTO. The controller then calls my BusinessDomainClass and passes in the DTO. The BDC then does work a unit of work and maps data into an Entity (EF object). The BDC then calls Context.Entity.Add(Entity) and will return any necessary DTO's back to the Controller. I chose to NOT implement a Repository pattern for my Data Access Layer. Instead, I put EF into its own assembly, I add repository like functionality to the Entities Models. In the BDC I get end up with code like below. It took a few iterations to get patterns that worked for our solution so what you see is more of a final result. public AccountDomain(IContextFactory icf, IEmailDomain _emd) { public AccountDto CreateAccount(AccountDto accountDto){ using(var context = _contextFactory.GetContext()) { var accountEntity = Mapper.Map&lt;AccountEntity&gt;(accountDto); Context.Accounts.Add(AccountEntity); _emailDomain.SendNewAccountEmail(accontEntity); } return Mapper.Map&lt;AccountDto&gt;(accountEntity); } (1)-P So the first thing I noticed was that when I had a BDC class like EmailDomain it would sometimes need data from an Account that was not passed into the method. One thing was that EmailDomain need all *active accounts*. So what do you do? Do you add GetActiveAccounts to your AccountDomain or do you add a private method to your EmailDomain? What about re-usability? Obviously a REPO pattern would be a perfect place to add GetActiveAccounts. (1)-A People tried both solutions and both ended up causing all sorts of headaches. They had a basic misunderstanding of the BDC-&gt;EF relationship. To fix this we added GetActiveAccounts to the Account entity object. This gives you code like Context.Accounts.GetActiveAccounts(); This way both AccountDomain and EmailDomain have access to this *repository* like functionality. (2)-P The next thing I noticed was that originally we had injected our Context directly into the AccountDomain. This caused problems for Unit Testing as well as we lost a lot of control over the Context lifespan. A Context lifecycle was per-request. This meant that every context would stay alive for the duration of a single web request. The connection would be open. This caused some performance issues under super heavy load (read 1000 concurrent requests). With a repository pattern you would inject the Repo and mock the return data. (2)-A To solve this we used a ContextFactory. The factory returns a new instance of the Context, very simple. This allowed us to mock the contextFactory returned result AND control its life cycle in a very strict way. Helping to fix our performance. issues. (3)-P We have a problem with Mocking the Context. In order to Mock the results of a Context you have to implement a Facade pattern. This is a big 1 time setup cost but after that you need to *remind* every developer that if they add a new Table and new Entity to the Context that they need to *remember* to add that entity to the Facade for Unit Testing. I am personally and intrinsically opposed to telling developers to *just remember* anything. (4)-A We use a database first EF setup, (I recommend code first as there may be an easier solution to mocking then the Facade pattern but I don't know). So Because we use DB first we have a .tt file that *builds* the Context Entities. I went in and changed the .tt file to *also* add that entity to my ContextFacade. So that is my experience with *not using the Repo Pattern*. I do not regret my choice one bit but it has some technical problems that had to be overcome in various ways. I imagine that using the Repo pattern may cause other types of challenges. But that's what we do right... jump technical hurdles! 
Like view resolution, I believe that only happens if you've left debug="true" in production, [which is something you should never do for a variety of reasons](http://encosia.com/a-harsh-reminder-about-the-importance-of-debug-false/). It shouldn't re-check or re-create anything in production unless the app pool recycles.
I read a bunch of articles lately how bad Windows 10 IoT is but when I read it I did not understand what the problem was
I was curious exactly how much overhead there is in going through the MVC pipeline vs letting IIS serve the file directly, so I just ran a simple benchmark here. I created a File -&gt; New Project with all the defaults, changed the default CSS bundle to be just `bootstrap.css`, changed the debug attribute to false, and ran 10,000 requests against both the bundle URL and the direct URL to the CSS file on the file system with ab.exe. On my local machine, requests to the bundle averaged 0.2 milliseconds slower than direct filesystem access. That's a price I'm happy to pay for the amount of complexity it reduces in my development workflow and deployment process.
When I tinkered around with VS 2015 and Windows 10 IoT. The project template that Microsoft gives you is a WPF app and it is very restricted, it will not run under administrator rights. When you deploy, the username and password option does not work so you cant run with elevated privileges. You can only write to a specific directory, I tried writing a text file to "C:\temp" which failed. The only database connectivity built in is the default DbConnection object. There is not any OLE, SQL or anything else. I was thinking about making API calls to figure out whats within the registry and seeing if I couldn't hack the system, but..., the call to read from the registry is within the advapi32.dll. Which within Windows 10 IoT is called advapi32legacy.dll and only has the older registry calls. Not the ones that end with "Ex". After getting that far, I threw on RetroPie and made it a gaming machine for the kids...
- don't make the BO layer methods static - move those into a separate assembly (the edmx/entities stuff should also be a separate project). -i wrote a utility to generate BusinessObjects based on EF schema if you're interested https://github.com/mariusmg/efbog2
Correct, keep your dbcontext usage inside of your repositories. You should never allow references to your dbcontext to leak into your controller code. 
I forgot to mention that this is the way I solve the problem for enterprise level applications that usually end up requiring complex interactions between Controlls and BusinessDomain which result in the DTO's being *more complex then the Entities* and this the mapping isn't a 1:1. Sometimes my DTO will map into 2-3 entities for the BusinessDomain to execute several different logics/persists against. If I am writing a much simpler application where the DTO to Entity is a 1:1 mapping then I *don't use a mapper*. I know crazy right? What does he do they ask? Well let me asnwer that as well. I put all the Models inside the Layer projects (they sit right next to the layer they belong to). Then I have a single Abs.Models.Interfaces project. All the layers reference this project and all the objects implement the *same interface*. Then instead of passing concrete objects around I pass Interfaces. and since all the models adhere to the same interface bada-bing-bada boom. But this really only works if you have a very tight mapping of 1:1. 
Thank you for this, it's very helpful having another person give such a detailed answer - thank you!
Seconding Hangfire. It's worked really well for us. 
You should check out Automapper, it wouldmake your life a lot easier.
Even if you understand that, it is still really frustrating to work with. There are still a lot of issues on the Pi, like lack of any drivers for the GPU. The kernel uses the only UART on the Pi for debugging purposes, so that really cripples your ability to hook up to sensor modules. I also am not impressed with UWP. A lot of functionality you would want in an IOT device is not there, like good communications libraries. In a year or so, Win 10 IOT might be pretty awesome. But right now, I would much rather work with Windows Embedded.
If I go with a library it's value injector. But honestly I don't think either maps are as straightforward as simply doing the mapping. Once you have a perfectly good mapper of your own you can make things more explicite and therefore more straightforward. I do see why people like this libs those. I certainly have projects with either when my mappings where as simple as my example.
I'm drinking at the moment but will come back to this in the morning. In either MVC or WebAPI, there's a task/async behavior property you have to set away from default. By default, ASP.NET will throw if your task isn't completed by the time the web request completes. I've faced this firsthand while developing a commercial product where some of our message log functionality is fire-and-forget. To be continued tomorrow. Maybe this is way better documented now than it was when I ran into it...
The web is cool until you need a real data grid...
Good article and seems like a pretty good solution in most cases. I should clarify that by windows service I'm not meaning a web service. I mean an app on the server reading from a queue. The warnings at the end are the kinds of the things that turned us to using messaging and the windows services that consume those messages and know what to do with them. We had database operations that were taking 5 to 10 minutes after our database grew over the years. The web is simply just not built to handle jobs like that.
I can understand where you are coming from but please keep in mind that building something complex without having done it previously will take a long time. Probably longer than the client will be willing to accept. Few things come to mind: - Parallel computing and distributed systems - Integration with complex business systems like SAP and Dynamics CRM - controlling hardware from .NET - DirectX (although that's more C++ than .NET) - Authentication, SSO systems - Game programming (Even using Unity I don't believe you can just sit down and build a game quickly without having done it before) - Building plugins for other systems and targetting proprietry APIs There's probably more, but the point being that stating you can build everything is a risky thing to say.
I have built a Unity game but only short casual game http://www.kongregate.com/games/oktopusprime/lonewolf and a software for school registration before but I have to read on SAP and Dynamics CRM and code some for practice.. so yeah you're right. It's boastful to say i can build anything. thanks!
Must be nice.
The flipboard I manually curate to collect articles from the world of web development. This board is focused on the expert developer, architect, manager, product owner using the Microsoft platform. It has 125+articles and growing everyday Thanks to /u/BurkDiggler and /u/JakDrako for pointing out the missed link.
They moved LESS compilation and everything to a plugin called Web Compiler.
There's a link to that new extension in the post. That didn't exist when I started writing the post, and wasn't going to exist at all until popular demand sprung up for a gulp/grunt-less solution when people noticed that it was removed from WE2015.
How would I go about adding the product to each one of the reviewable products? Make product an interface? Edit: or would a better way to add a variable in the product linking to the product class? So it would be Review &gt; Product &gt; Movie
Correct. You wouldn't want to cast it. As a general rule, objects should only have as much access as they need to other objects, and nothing more. Since the fact that a given product is "movie" vs "food" is inconsequential to a review, a review shouldn't have access to that info, but rather to the more generic form (product) where it applies. Remember too that when you go to write the code that actually ties all this together, you won't necessarily be dealing with raw "product" objects. You very well might have food objects, movie objects, but since these are all subclasses of Product, they'll all already have an AddReview method that you can pass reviews into. The reviews themselves don't care that it's food or movie or whatever, as long as it's also a product.
Yes. Refactoring by Martin Fowler.
Yes it doesn't show in solution explorer who I add a new one, but if I close and re-open the solution it does (without doing anything else). I'll try using the cmd way to install a package.
Hi, saw your Stack Overflow question so posted a response there. http://stackoverflow.com/questions/32143845/dragablz-components-and-using-a-different-window-as-the-host/32156360#32156360
The raspberrypi subreddit seems just fine with it. Also don't forget about the .net micro framework for the netduino for when a pi is too much.
Microsoft .NET: Architecting Applications for the Enterprise, Second Edition by Andrea Saltarello, Dino Esposito will probably fit the bill quite nicely for you. Doesn't focus on MVC but does introduce how to use some of the concept presented in the book in an MVC app. I'd get a second book on MVC to compliment it once you get the DDD side of things down. I've never looked at any of these books so I can't help there. I know some I work with liked "Pro ASP.NET MVC 5"
What you suggested sounds like a perfect solution. If you want to get rid of query time, then what I would make sure that calculating which reviews needs to be shown is done before hand and persist the result somewhere, like a different table. You could also look into having the "most recent reviews" in a partial action and caching the result of that action. If possible, maybe both? 
How would I go about benchmarking asp.net to see which would be a faster more efficient method?
http://www.amazon.com/Domain-Driven-Design-Tackling-Complexity-Software/dp/0321125215 and http://www.amazon.com/Applying-Domain-Driven-Design-Patterns-Examples/dp/0321268202/ref=pd_sim_14_22?ie=UTF8&amp;refRID=1BJ3FM4DQ009GKAZ9Z4A
NDoc (http://ndoc.sourceforge.net/) used to be the thing a while back. Now a days for API Docs I use the built in XML docs and then for the textual narrative I use https://readthedocs.com/
Gridview is part of webforms. This is seen as a bad way to write web applications and nearly all new .net web developments use the MVC framework. http://www.asp.net/mvc It may seem a bit more work than binding a control that does a lot for you, but it means you understand what is going on when you want to do things differently than the control will let you. 
I disagree. I only use MVC when a web site is going to be rather large. Otherwise I find the time investment not worth it for view changes and what not when I can just do jquery to show/hide divs.
Stack Overflow's MiniProfiler is very good, and lets you profile in production. I think newer versions of Visual Studio have a profiler built-in as well.
Classic ASP.NET? ASP.NET Web Forms? ASP.NET MVC?
Another recommendation for MiniProfiler: http://miniprofiler.com/
Add something like efcache and you could apply a second level cache to specific queries. I like output cache here though. Seems like a simple solution for their problem 
Microsoft is still investing a lot of time into Webforms as a lot of enterprises have investments in that tech as well. You also have the benefit of almost 13 years of examples on the internet. However it does facilitate poor coding practices. You can easily write bad code and the code itself isn't very easy to test. That being said I'd continue going down that route, when you feel that you've hit a roadblock using webforms there is always MVC for you to use and will have most of the shortcomings of webforms solved for you.
My suggestions: * Stay away from large lists of business areas he worked in. My eyes just glaze over. Stick to technical bullet points. &gt; Enterprise Resource Planning, Enterprise Application Integration, Finance, Accounting, Customer Relations, Manufacturing, Human Resources, Advertising, Profitability/Overhead allocation, Inventory Control, Purchasing/Receiving and Order Processing. * Include more quantitative detail about what he did. What impact did he have? Are there numbers to support it? &gt; introducing an N-Tier/Layer methodology which made applications highly scalable, secure and efficient. How was it more secure &amp; efficient? If this is true, then there should be #'s that he can speak to. Transactions/users per hour? Increased data through put? * Give some technical detail about the solutions developed, not just 'designed mission critical applications using .NET'. What do the applications do? Are there any unique architectural problems that he solved? Honestly, it's hard to tell what level developer this person is from the resume. The technologies, for the most part, are pretty bland, standard core stuff. C#, .NET, MVC, SQL Server... Was there any ORM? Caching technologies? JavaScript libraries?
Way too many words. If I can't read it and have a good idea of what you've done in 2-3 minutes, I'm moving on. 
It would be much easier to help if you posted your code. Post your entities, configurations, and DbContext. When you say you "tried extending each one of them with a 'product' class ", what exactly do you mean? It sounds like you should probably have a Product base class with a list of reviews, then extend the Product class for each of your product types. That should get you a Product table with an id, a Review table with a foreign key to the Product table, then a table for each type that extends Product with its own id and a foreign key back to the Product table. To find a Review for a Movie you have to join to the Product table to get the Product id, then query the Review table using that id. EF will do that joining for you, though. But you should probably be thinking more generically. What happens when you want to add a new product type? Will you needed to update the code (bad) or just insert some data into the db (good)?
It would seem that your model is a bit whack in this case... All movies, tv shows and food etc. should be a product item. Then in the product item, have a column for which product-type it is, then you can make a new table or just have an enum for the product-type. This way, you would not get a movie and a tv-show with the same id in the review table's productId-column.
Having written mobile apps on every platform (semi-professionally in my spare time) and being a relatively experience developer. C#/VS was best, the Obj-C/XCode, then a massive jump down to Java/Eclipse/Android (it really makes you homicidal). Xamarin is pretty good not perfect, but alot better, alot quicker and alot more fun. I find for relatively simple apps. It takes in a purely native sense, about 1/month per app. When I use Xamarin this drops down to 1/month for the first app (generally WP) then a week each for iOS and Android. This goes down even further if I use Xamarin Forms. I have never used phonegap or any of the other 'web' based frameworks. I try to avoid web development as much as possible. 3) C# is a really good choice IF you can justify the code of Xamarin. If you can justify the cost for the time saving, go for it, if you cannot, then don't. For me knocking 50% off the time for a project enables me to be twice as productive and most of my work doesn't pay / is for fun. Plus saves me a lot of stress. 4) I have used Xamarin forms a bit for some of the LOB apps I have worked on, and its good and quick to turn out apps, but the performance isn't 100% there yet, and its not massively flexible. But you can still write the UI in the native way. I haven't found this to be an issue, and in some cases I prefer it as I can optimise the UI to the device and OS. 5) I only have an indie license. So what I do is create the Projects in Xamarin Studio, do all of my Windows Phone coding in Visual Studio, then dip back into Xamarin Studio for doing any android / iOS bits. Doing it all in VS would raise productivity but its not a massive issue to justify the 3-4x cost increase for me. 6) Yes this is possible, I still prefer using Xamarin. 
Why not just keep using 2015 if you have it. My understanding is that Visual Studio Code is just a stripped down version of 2015. There is also Visual Studio Community, which is the same as the fully featured BS 2015, but is free for non enterprise. Why all these different versions Microsoft...you are just confusing people.
My understanding was that code allowed development _on other platforms_ ... not specifically cross platform development (not any more or less cross platform than VS already is).
I think you should try them both out. They will both do the job just fine, so it's ultimately a very subjective preference. One of the good things about JS development, compared to .NET, is that there are plenty of free tools to choose from and you don't lock your self in to a specific editor. You can open your project in VSCode one day, and Atom or WebStorm the next day. There's [Node.js Tools for Visual Studio](https://github.com/Microsoft/nodejstools/releases) which is excellent for Node development/debugging. But if you do try VSCode out I think you might start appreciating how lightweight and fast it is.
Agreed he seems to be hitting on the business area's he has worked in an awful lot to just get a development only position. I find the politics is more of a issue with the environment not always the position. But I also see it hard to find an architectural role that is also pure development. I usually see either a person who is in the same position as your dad; small shop pure development and lead dev position. Or at a bigger company that requires someone who is specifically doing architecture, which I think requires a large enough application to warrant someone hired just for this task vs a general technical lead, that he will be doing lots of team management and communicating his architecture ideas to a larger team. Also &gt; Give some technical detail about the solutions developed, not just 'designed mission critical applications using .NET'. What do the applications do? Are there any unique architectural problems that he solved? I don't think it's impossible to find a position like this; I just see lots of architects spend more time doing diagrams and leading a larger political team when they move into the type of position you described. 
Is there a better way to go about this? I'm just trying to make it as generic as possible, but it seems like making it generic is harder than not
Ah I see. I'm a fan of Sublime so I guess I will check it out. Just never thought I had a need for it with VS pro.
This is how I would do it: Create a Product class with a ProductType enum that can be Movie, Tv Show, Food, etc. Then I would give the Product class a collection of Reviews. Your issue with not seeing the list of reviews is likely having to do with Lazy vs. Eager loading in EF. Checkout this article for an explanation: https://msdn.microsoft.com/en-us/data/jj574232.aspx. In your case, I'm guessing you'll need to add an .Include('Reviews') (or something like that) to your LINQ query. Let me know if any of that doesn't make sense or you still have questions!
If I post my code would you be able to review it? If so where is the best place to upload it? 
Yeah, no problem. If your repo is on github or similar that would be ideal. If that's not an option, you could throw snippets in a gist.
Right click the Dependencies node in Solution Explorer and select Restore Packages. This will force the new packages to download. This should happen automatically when you save any change to the bower.json file, but the Visual Studio tooling for MVC 6 is still in beta. There are definitely still some bugs they need to work out here.
You can of course use both, Code is more of an editor, where Studio is an ide. For Angular etc I would go for Code since it allows me to get to my code faster and I get the debug features I need. Studio has a lot of extra stuff that I would not need. I also like learning new stuff so I have an excuse for doing so.
Hello, I've made a GitHub. Here is the [link](https://github.com/VolvoxCompany/VolvoxReviews). Thanks
That's the article's TL;DR. I still recommend the reading though, as the reasoning behind it is pretty informative.
They are essentially the same, at least, they get compiled the same way and are translated the same. I happen to prefer the lambda syntax (x =&gt; x.someKey == value) as I think it's cleaner and more strongly reflects object-oriented-ness of C#, but that's just my opinion.
I use the method syntax for short queries, and the queries syntax for complexer queries. Especially joins, the `let` keyword and multiple conditions are **much** nicer in query syntax. Also, your title is somewhat off. Both options are using LINQ to query the database. LINQ-to-entities to be specific. There's just two different syntaxes.
It's mostly a matter of taste. Firstly: Both syntaxes are LINQ. What the 'method based query syntax' (.Where()) can't do is defining variables as you can do with 'let' in the 'query expression syntax'. You can get around that with some .Select() constructs, but let is - in my view - much more concise. On the other hand, the method based syntax is much more readable for short Wheres or Firsts - again in my opinion. So use whichever you think fits the situation.
Yes, and "generate documentation file" path is pointing to the same file 
Both are LINQ. I use the lambda style, but that's just my personal preference. I think it's cleaner and easier to read. Either one works, just use whatever you are more comfortable with.
Yeah, not fun! And when you start adding things like multiple groupings and sub queries things can get really hairy.
Curve ball, but for static sites I now use node.js, with a few modifications on the Express template which is quite popular. I can bake in a little Rest API for the few jobs that require it. I deploy straight to Azure from GitHub. I use Gulp to run a few build tasks, and I develop in Visual Studio Code. It all feels a hell of a lot more lightweight and quicker than big brother Visual Studio (which I still use a lot for WPF). Plus, all this tech now means I can develop on Windows or Linux, and could deploy wo AWS if I so desired. 
wait, fuck I just realized I should have used a right outer join that two nested linq queries. 
Start from here Learn MVC step by step in 16 hours flat http://www.codeproject.com/Articles/866143/Learn-MVC-step-by-step-in-days-Day 
I use Microsoft Expression Web 4 to create static HTML pages. This is when I am primarily creating content, like documentation, and need spell checking. I also fall back to Microsoft Expression Web 2 when I need spell checking in foreign languages since it still supports Office Language Packs.
Are you keeping cookies and passing them to the frame's URI? ASP.NET maintains its security session though a hash set in a cookie. If you do not pass that when requesting the IFrame it will likely fail. That said the page logic may do other things to make the frame content happy as well. You will be jumping through some hoops to make this work as very often the author of such an IFrame has a requirement to prevent you from doing exactly what you are trying to do.
This resume says - "I don't write code anymore and as such will fail the technical interview". When I was looking for a senior, I wanted to know what technologies that they had worked with and whether they understood the implications of the code that they were writing. I saw a lot of resumes like this and none of them could pass the technical interview because they no longer actually wrote code. Please keep in mind though that the definition of a senior developer and the role that they play differs from company to company. I was looking for someone who could actually write code using modern standards and could dig in and resolve those 'i have no idea what's wrong' bugs. I would also like to point something out: if he doesn't want to be a lead / manager, then make sure that he doesn't do lead or management things otherwise he's going to end up right back where he was.
This. VS2015 node projects are awesome for this kind of thing and configuring node to host your static files for development is easy.
Corrupt installer? Re-download the installation package? It's supported on Windows 7 according to the following link. [.NET Framework System Requirements](https://msdn.microsoft.com/en-us/library/8z6watww%28v=vs.110%29.aspx) Notes: The .NET Framework 4.5 is supported on the Windows Preinstallation Environment (Windows PE). Not all features are supported on Windows PE. The .NET Framework 4 also supports the IA64 platform. For all platforms, we recommend that you upgrade to the latest Windows Service Pack and install critical updates available from the Windows Update website to ensure the best compatibility and security. On 64-bit operating systems, the .NET Framework supports both WOW64 (32-bit processing on a 64-bit machine) and native 64-bit processing. 
Thanks buddy! I did a quick look see into Dapper and came out with (ORM). But yes, looking back on the articles I realize now I misinterpreted the examples. Thanks for the heads up!
Make sure you have SP1 installed - that's the base requirement, not just "Windows 7".
Believe it or not, I was unaware you could monitor the post requests from the browser; seems logical in hindsight. I was figuring them out from the Javascript in the source; that sounds much easier!
If I'm understanding your question correctly, you can specify a different type when doing a select instead of leaving it anonymous. // Table is DbSet&lt;MyDatabaseType&gt; var query = db.Table.Select(t =&gt; new MyLocalType { X = t.x, Y = t.y, Z = t.z });
An alternative approach if you don't want to use inheritance with a generic Product base class is to move the foreign key pointing to the "thing being reviewed" out of the review table and create a junction table between each reviewable item and the review itself. For example: Movie MovieId ...other Movie fields... MovieReview MovieId ReviewId ...other fields that are specific to Movie Reviews... Food FoodId ...other Food fields... FoodReview FoodId ReviewId ...other fields that are specific to Food Reviews... Review ReviewId ...fields that are generic to all Reviews...
&gt; There is an object that takes a 'query type' string and a tokenized string as parameters to its sole method. So everything is "stringly typed" rather than represented by actual objects? Hvae they created there own ORM? That sounds like a really, really backwards architecture. &gt;The new architectural impact is that for just one of these concrete workers, the tables it works with are now remotely located and only accessible through methods on a web service. Obviously, this is performance-critical and it doesn't have any scale issues. A remotely hosted service is always going to have a performance impact. Could you save/cache the data locally and upload it from a service process?
They call Dapper a "micro ORM" because it gets them past pin-headed bosses and micro-managing customers that demand you use an ORM even when it can't afford the performance hit.
Well, it wouldn't be necessary if you are just processing the results in the same scope since you can just use the dynamic anonymous type and the compiler will check it for you, but if you want to cast and pass the result after a First/OrDefault() -&gt; MyLocalType or ToList() -&gt; ICollection&lt;MyLocalType&gt; or as the unexecuted IEnumerable/IQueryable&lt;MyLocalType&gt; into another function you're going to need a defined type. Maybe I misinterpreted your question, since I thought you wanted to cast to an AnonObject type already defined in code. I suppose you could just pass the anonymous result set as type "dynamic" to another function, but that is terrible practice. The reason to create a simple one-off data manipulation structure is so the compiler can tell you when you are being a moron, which is the entire point of using a typed language like C#.
A webservice **will** have a significant performance impact on data retrieval. Oddly enough, rewriting the data calls to actually pull data from an ORM or even a dedicated DAL with specific methods will give you the greatest maintainability, readability and performance. Even if it's a hand-rolled ORM. If possible, implement an IQueryable interface to select your data objects, this will allow you to build your query in a standardized form. Otherwise, if you're *forced* to parse a string to select your data, parsing early rather than late is better. No point going all the way through to generating SQL, only to rip it apart and re-parse it!
tldr: use dynamic or javascript 
I'd say the most critical aspect for him would be to have a clear objective at the top stating his interest into returning to a technical role from management. Otherwise, he might get passed over or pushed towards management roles. On the skill list, I'd recommend cleaning that up a bit. "Microsoft.NET" is better than ".NET Development Suite". C# is generally just "C#" not "C#.NET". SOAP implies WSDL so I'd remove the latter. I wouldn't bother including XPATH and XSLT. There's no mention of javascript or jQuery. If he's interested in web development those are important. I'd also drop "Crystal Reports and Visual Fox Pro". Unless he feels those are important to the kind of job he's looking for. "SQL Server" is a bit vague. Does that mean writing queries, data modeling, administration or all three? In general, I wouldn't stress the resume that much. Different people expect different things in them. Some expect them to be long and detailed other managers like them really short. They mostly just get skimmed anyway. FWIW... The way I would read this is I would look at the skills, skip achievements, then skim job experience for the last 10 years to see if that somewhat fits the role. 
Check out MiniBlog on GitHub. Super lightweight open source asp.net blog engine. It's very lean and hardly anything to it so it's easy to understand unlike some of the more popular engines. 
Can't go better than Wordpress for a blog.
You should go with what comes with the least amount of work. I used Wordpress years ago and was happy with it. I imagine it only got better since then. Now I have [Ghost](https://ghost.org/) running cos I was curious.
Wow, that looks interesting. So I read on a link it says it doesn't need a database.. So how do you keep your content then? Do i need to have a big space on my HD for this then? EDIT: just read it uses xml and json for storing
Right, so the reason why I wanted something that can integrate with mvc is that so I can have my url like domain/blog/article-title etc. If I can do that with wordpress then that would be awesome! But Idk how to..
I went in the opposite direction and chose to use `blog.domain.com` for my blog URL. It lets you have the best of both worlds: point the blog subdomain to your site too and you have have MVC handle rendering the blog posts, or point it somewhere else (github pages?) with a link back to your original site.
As the article's author, thanks for the feedback :) 
Actually, what I've found and tried to describe in the post is that as long as the versions on project.json are fixed (not 1.0.2.3-*), then you will always get the same versions of dependencies because it resolves to the lowest version that satisfies all deps. 
Need to? No. Should you? Yes.
Why should they?
DbContext is essentially a Unit of Work and DbSet are Repositories. Abstracting these with your own implementation allows for testing without executing DbContext and you're not coupled to a single ORM.
You can test with DbSet and DbContext. Check out Julie Lerman's posts about Unit tests with EF. Not tying yourself to an ORM is not something to worry about in testing IMO. Seems more like an overall architectural decision.
Disclaimer: The license for Bootstrap 3 related helpers isn't free. I'm the author of this library, so if you have any questions, go ahead and ask!
To double down on this EF 7 will support new data providers. This in large parts removes the benefit gain from data access abstraction. 
If you are working with Web API apps, have a look at Swashbuckle, which is a nice library for producing APIs to the Swagger specification and will produce a nice self-documenting UI for your API with very little effort. 
Despite the bitterness in this thread, I've used ValueInjector and in some instances it's been really trivial to use. Good job! I still use AutoMapper in some situations, mostly because of familiarity in some of the more complex mapping situations. 
You're welcome. Thanks for the insightful post.
&gt; In the first case, entity framework obviously takes care of that, but for the second case, if you've got complex statements of what you're looking get from your data, then that's going to be repeated everywhere you need it. You can solve that without a repository, IQueryable is an object that can be passed around. Extensions methods are great for this, it solves code duplication and makes the code a lot clearer.
&gt; you're not coupled to a single ORM. There are patterns that solve this that are not the repository pattern.
+1 with this, I still dont see all the fuss about decoupling everything when 99.99% of the time applications don't switch components. If you're really replacing something as core as the ORM for your data, you'll put in the time to rewrite the code that matters anyway.
Yes, if you like redundancy.
It depends, an extension method on an IQueryable will usually just be an action/func and return an IQueryable, which is fairly easy to mock. Testing that the method is called is the hard part and potentially skippable.
Dude, that is pretty slick! Did you write this on your own?
Very similar to an approach I use frequently; I have about 4 methods like &lt;T&gt; Get&lt;T&gt;(Guid id), create, update, delete; for crud operations with a few type constraints. The entities all inherit from this base entity which provides me with that constraint since T is always this base type. I also have shifted ID's and auditing properties into this base entity. Now when I call the save method I have a customized it to handle auto populating ID's and auditing information like what the creating and editing user ids are along with the time stamps; I did this by overriding the savechanges() method implementation and not doing it in the repos method. Also using DI to mock out the DAL beyond the generic repo makes it easy to do integration testing. I only had to work with DbContext or DbSet when I wrote the generic repo which all objects pass through and it actually uses EF; at any point the implementation of the generic repo could be redone for any other ORM. I agree with Thornsten's comments and think this makes a bit more reusable. The bonus is the repo returns an IQueryable&lt;T&gt; so I have a base method in the DAL to start an IQueryable and return it and in the BL/SL I can start adding filters with the where extension methods. Now I can reuse all of these queries from the SL in multiple places of the application. 
&gt; but I have never in 20 years seen an ORM swapped out for another. It's a good idea but in practice never happens One of those cases where we have started doing this unnecessary work to keep the ability do something we will never need to. I have seen one ORM change out but we also reworked the entire service and DAL layer at the same time as it wasn't generic enough to do what we had planned. I do feel the abstraction if done correctly can help keep methods and logic very simple which I view as a huge boon for bringing in new team members.
Agreed with everything Jammycakes has said; as I have had a hard time describing how I separate this type of logic. I find it common that controllers on mvc projects are bloated with queries and contexts that should be in the business logic/service layer. But struggle from time to time figure out how to explain to another developer why I have refactored this one special get method into the DAL and not the service layer like the rest. It's common that these business logic queries will be used in multiple places of the application so refactoring these methods back a layer makes it easier to reuse them and I find also follow OOP better. You can also think of the BL having the same job as sprocs; its a bunch of specific queries to return the data you want. The DAL layer below that really just calls the right ORM methods for you or builds queries for you; and will *usually* have the lowest level and most technical level of code. DAL methods are like the building blocks of Service layer methods.
Agreed unit testing these types of applications is very hard; I like to unit test the logic pieces inside of service/business layer methods; some controllers (more so than I should most likely). ORM &amp; CRUD methods don't fit the unit testing pattern well.
Pretty awesome!
You've done great work here; I like the use of extension methods to apply to controls like .Id(), .Class(), .HtmlAttributes(), .Data(), .Tooltip() I've been looking for something exactly like this and its great!
X gon' give it to ya.
Thank you kindly for the positive feedback!
Ever thought about making an example project?
Well...yes, in a way. Mainly because there's a lot of cargo cult thinking goes on around it. Thing is, people didn't generally explicitly say that they were doing it out of a fear of open source or non-Microsoft solutions, but the attitude was very much there, and as far as I can tell this subconscious attitude was very much the driver behind making your ORM swappable. But because it was more a subconscious thing, it just became entrenched as a "Best Practice," so when EF finally came up to snuff, people carried on purely because That Is How You Are Supposed To Do Things. In the meantime, nobody ever bothered to ask whether it even delivered the benefits that it claimed to offer -- no doubt because they were scared in case that would make them look ignorant in the eyes of people who have the authority to hire, fire or promote them. I remember reading [Ayende's blog post where he pointed out that it didn't](http://ayende.com/blog/4567/the-false-myth-of-encapsulating-data-access-in-the-dal) -- it was like being in the crowd where the little kid stood up and called out "The emperor has no clothes!"
I asked this question to a senior dev when I was interning in college and never felt like I got an answer and this helps that situation make more sense now. Thanks!
Do you actually use dependency injection to implement the interface at runtime? Our DAL is aware of our implementation of the repo but we have to inject the context at run time; its a multi-tenant system with a shared web server. Just curious on how others have done it thanks for the feedback!
I would be interested, certainly. There are a lot of EF examples out there, but not a lot of abstraction and you end up seeing a lot single-tier apps. 
No idea. Didn't someone make a remindme bot?
 I deerrrppped it lol. I made an edit and changed the method name to UpdateClasses.
During my dives into the REST api world I fought terribly with these types of things too. It seems all the REST blogs are fraught with discussions about "If you are a purist you should do X". For your case a "purist" would probably have a StudentClass controller that accepts a PUT method. But I just can't get behind having 20 million controllers in my API. I HAVE to fall back to KISS. What is the *easiest* methodology for my consumers to understand and use. REST purism can lead you to a dark place lol. Good Luck!
Warnings are generated for a reason. Don't just ignore them, or it will bite you in the ass.
That isn't true at all. That's why it's a warning, otherwise it would be an error. Warnings should be evaluated by the programmer and handle according to their intentions. If you designed it to be fire and forget then the warning means nothing. If not, you are going to have a bad time. I have several of this exact warning in an app I work on now and it performs flawlessly, every time. You should be careful making generalizations like that as they are almost never true and lead to misinformation and THAT causes errors.
In scenarios like this I take advantage of the fact that JSON can be hierarchical. In other words, have a collection of classes on the student object. Then if you want to remove a class you PUT the whole student object to the update student end point but don't include the class you are deleting. It also works well the other way (a collection of students on the class object) if that happens to jive better with your workflow. To keep the collection from being a bunch of extra overhead all the time handle a null collection as "we're ignoring the collection" and an empty collection as "there is nothing related". Then only populate the collection in the get endpoints when it is specifically requested via query string parameter. Hope that helps.
It literally doesn't matter. Thanks to attribute based routing, the layout of your controllers has no relationship at all to the URLs being exposed. And for that matter, the URLs usually are meaningless too. Thanks to various code generators, the UI developers aren't going to be seeing the URLs either, they just see the JavaScript based functions that encapsulate them. 
It seems like a lot of answers are confusing good MVC practice with good REST practice, when in fact the two have little to do with one another. From an MVC perspective, the "purist" would implement a StudentClass controller that handles the relationship between Student and Class. There would also ostensibly be a StudentClass model. I'm not sure if that helps you get at what you were really after, but that's the "Good MVC" answer. The "Good REST" answer would probably be to hang a collection of classes on Student and/or a collection of Students on the Class model, and manage your resources using relevant combinations of URI and HTTP method.
I use this method with good results. I've also extended it to have a ParentId field for nesting in trees etc. 
&gt;Now say the user is on the Student detail page that lists all the classes, and deletes a class from the students profile. Which controller would contain the DeleteClassFromStudentProfile method? Which controller contains the method for "getting the classes for a student"? That would be the same controller where you put the "delete class for a student" method. I would put these methods on the Student controller. Or to keep it symmetrical you can put these under the Class controller.
Thanks for sharing this article ! It may come in handy !
Think quite many people are looking at this experimentally. Common theme seems to be that you'd like to be able to deploy containerized .NET applications and do it in a way that doesn't tie you into Azure. I've only seen proofs of concept at this point, but the showstopper preventing further work is the lack of ecosystem support. For example, if you need to talk to a database that isn't SQL Server it's just a showstopper. The open source Postgres connector is still work in progress as is the SE.Redis connector, but connectors for Oracle/MySQL are who knows how long away if they are even working on them, and the same goes for NoSQL clients like Mongo. This kind of issue is really problematic if you are creating software which has to fit in a customer environment. 
Would this methodology still work in VS2015? http://www.aspsnippets.com/Articles/Use-and-connect-to-MySQL-Database-in-ASPNet-Application-using-MySQLConnector.aspx 
Not on .NET Core, MySQL Connector doesn't support the platform yet. However, if you're just working in VS2015 targeting .NET 4.5 on Windows or Mono, should work fine. They'll likely need to #ifdef their codebase to reference different ADO.NET assemblies for .NET Core and .NET 4.5/4.6 and release an additional cross-platform NuGet package. How big a job is that? How much of a priority is it for whoever is maintaining that software? Good questions, and nobody seems to know, which is the concern for people starting up new projects and evaluating the technology. 
I've been very happy with all of the components from DevExpress, including the calendar / scheduling controls. 
Does it handle the database stuff though? I'm building an application of which, when I was planning it initially, the whole calendar system was an afterthought (because it's just DateTime's, *right guys? right? nervous laugh*). I'm looking for something which I can add calendar events to, with a duration, and then query to see if those events have happened yet/are happening now. It's not horribly complicated, and already have a fair idea of how to roll my own, but it struck me that this must be a fairly common use case for applications, and there is surely a decent alternative out there. Also what's the deal with cost/licensing etc on the DevExpress stuff?
I use telerik, and sometimes c1.
What part is giving you difficulty? The standard C# date and time classes are actually pretty good. If you want something a little more Javay, you can take a look at [Noda](http://www.nodatime.org/). The C# port of Joda.
how do I change the service to a network service? if it's at the IDE config level, how do I do it in monodevelop? I'm experimenting with networking as a way to retrieve byte arrays and other variables instead of hardcoding them.
Uhhhh bit out of my realm honestly, but I don't think you do. Like I said, it depends on who the service is running as, so when you install the service it's part of the registration with the Windows service. When running from within an IDE (Not even sure you can do that an actually test the "service", I think you'd just be running the command line version of the app?), it would be running as whoever your IDE is running as.
I'm looking around on MSDN right now for more info, I think it *may* be something in the assembly info. and indeed you are correct in that it runs the command line version of the app as the user who invoked it (modified it to call whoami from the main function and a writeline added to the service start function). you also need to use a special mono runtime to run windows .NET services on linux, it's called mono-service EDIT: farting around on MSDN told me that all 3 security levels can access the internet, so it looks as if I don't need to change the permissions level for this. (local system is "root," local service is a daemon user and network service is a daemon user that can use the standard user account's credentials for LAN access)
Do yourself a favour, and use something like [TopShelf](http://topshelf-project.com/) which lets you debug and test the service like a normal console app, and then install it as a service by specifying a few command line args, rather making an installer or service manager voodoo. It has an option for specifying the user the service runs as- see [Service Identity](http://docs.topshelf-project.com/en/latest/configuration/config_api.html#service-identity) in the docs.
It's more trouble than it's worth.
Hey there. I didn't know you were a developer! I see you in /r/UkraineConflict all the time.
Small reddit huh? I've just come back to EF after many years of doing other stuff, and once again I remember how irritating it is. I used to use the repository pattern with it, but tbh looking back at things there was a lot of YAGNI that came out of it. 
Search for "windows service user" or something. This is not related to .NET; there is no such thing as a ".NET service".
to add a windows service, use the command "sc create", it has a param obj= where you specify the service user, you can use that to change it from LocalService to NetworkService, or LocalSystem, or an actual username The service user isnt set in the .NET executable itself, unless in the case of [TopShelf](http://docs.topshelf-project.com/en/latest/configuration/config_api.html#service-identity) you tell it to run as LocalSystem, since TopShelf has command line commands to install the application as a Windows service. http://docs.topshelf-project.com/en/latest/overview/commandline.html You can also install your service with a [WiX installer](http://wixtoolset.org/documentation/manual/v3/xsd/wix/serviceinstall.html) I think what you're getting confused is setting the requested execution level in the application manifest, which is different than the user the service runs as. http://stackoverflow.com/a/2818776/28659 http://stackoverflow.com/a/1781743/28659 
I recommend "Patterns, Principles, and Practices of Domain-Driven Design" (DDD) by Scott Millett w/Nick Tune, published by Wiley (WROX). ISBN: 978-1-118-71470-6. You can easily find it on Amazon.com. Note, DDD is a development philosophy, designed to manage the creation and maintenance of software complexity. It is the collaboration and construction of ubiquitous language (UL) that makes DDD so powerful.
yes, but if you can reuse good work that other people have done, why not? TopShelf is released under the [Apache 2.0 license](https://github.com/Topshelf/Topshelf/blob/develop/LICENSE)
Also, now is a great time to evaluate the controls you are using in WinForms to see how they will translate to HTML components. If you don't plan on rolling your own components in-house, start taking a look at 3rd party collections now. You'll want to have a good understanding of what features you'll lose or gain in the port, and be prepared to either backfill missing features or propose alternatives to your stakeholders.
There are many ways to skin the cat, but I personally like to use OWIN to host the web API and a static files server (Microsoft.Owin.StaticFiles). When using Angular, I implement IFileSystem and IFileInfo to virtualize the Angular app itself.
ASP MVC doesn't have anything to check whether the user is the creator, since that's application specific code. You'll have to write that yourself. Your code looks correct. Edit: If you do this often enough, you may want to consider putting the code into an Action Filter.
On my phone but that looks good to me, also I would use !recommendation.UserId.Equals(...GetUserId()) as opposed to !=, even though both would work in this particular case, it's just good practice to use the string comparator
And depending on how you wrote it you might actually want equals instead of not-equals? 
Great idea I didn't even think of using Action Filters thank you. Do you recommend any tutorials on how to do that or should I just go with the one on the asp.net website?
I like to use custom attributes. That way, if you want to lock down the entire controller or just a single method you can do so without having to rewrite the same logic inside of each controller - so instead of the if statement you'd have something that looks like this: [CustomAuthorize("Administrator") public ActionResult AddRecommendation() { return View(); } Then in your CustomAuthorize class you can specify what to return if they're not allowed to do what you want them to do. It also prevents you from having to write the same if statement in each method. Unless of course the logic is different in each statement then nevermind! :D Anyway, here's a quick blog post you can look at to see if this might work for you! [http://www.c-sharpcorner.com/UploadFile/56fb14/custom-authorization-in-mvc/](http://www.c-sharpcorner.com/UploadFile/56fb14/custom-authorization-in-mvc/)
How would I get data into the custom authorization to check if the user is the one who created it?
You can get the User from the HttpContext.
But, how would I get the user id that created the recommendation?
Never, ever share the same controller for admin actions with regular users. Your admin controller should use [Authorize(Role="Admin")] applied to class itself, not actions. For the regular user you should likely have a custom actionfilter or base controller action that verifies the current user is the userId they are claiming to be. Also you find security for personal actions like this substantially easier to deal with if you use routes like Profile/{userId}/other_stuff/etc This will let you write an authorization aspect the ensures the current user is {userId} without having to issue a database query.
How would I go about passing the recommendation object to the custom action filter? Also, could you go in more depth about the user routing idea? How would it make it easier? Thanks
In general always try to write positive logic statements. The more negations, the more error prone it becomes. Using != is a positive logic statement. Using !allowed, is a negative. 
You could get the raw parameters from the HttpContext... Not sure whether that's considered good practice though. EDIT: To expand a bit on that, presumably there's a recommendation ID being passed into the Action. You could get that from the HttpContext and use that to grab the full Recommendation from your DB or repository. 
Didn't even see that link thanks for pointing it out
&gt; to add a windows service, use the command "sc create", it has a param obj= where you specify the service user, you can use that to change it from LocalService to NetworkService, or LocalSystem, or an actual username This. The entire thread can be replaced with this paragraph. It's the sc program you need to be googling.
A repository is not the only way to avoid this coupling.
Inspect the route value dictionary on the request for the user id then compare with current user
I watched a few of the videos on PluralSight which seemed to help a lot although it was a bit confusing trying to figured out the DDD stuff. Pay site but could use 10 day trial to watch a few of them I assume.
Use roles for such behavior. Apply roles to users and then use Authorize attribute on actions or the whole controller. [Check this out](http://www.codeproject.com/Articles/682113/Extending-Identity-Accounts-and-Implementing-Rol).
Why about setting a break point and inspecting the call stack? Also, I'd recommend against storing passwords in plain-text. I don't think youre actually authenticating. I believe you should do something similar to the below. FormsAuthenticationTicket ticket = new FormsAuthenticationTicket(1, userId, DateTime.Now, DateTime.Now.AddMinutes(30), true, roles); string hashed = FormsAuthentication.Encrypt(ticket); HttpCookie userCookie = new HttpCookie(FormsAuthentication.FormsCookieName, hashed); Context.Response.Cookies.Add(userCookie);
On the other hand if someone wants to get the license, they'll follow the instructions/links to obtain one and find the page with all that info.
Disk. 
This... Storing the blob in the database will just lead to problems down the road. Filesystems are made for storing files. They're generally pretty decent at it.
What types of problems down the road? This is not a rhetorical question, genuinely curious. 
Database. Look at Microsoft SharePoint.
And Sitecore
I agree that files should be stored in the file system, however, there is a third alternative no one has mentioned (assuming you are using MS SQL) and that is the [FILESTREAM column type](https://msdn.microsoft.com/en-us/library/gg471497%28v=sql.110%29.aspx). Basically, you "store" the data in the database, but it really resides as a file on the system (ELI5 edition). You may find this option fulfills all of your requirements.
Looking for *[storing files in SQL Server](http://lmgtfy.com/?q=storing+files+in+SQL+Server)* quickly gets you to a really good article from MS [To BLOB or Not To BLOB](http://research.microsoft.com/apps/pubs/default.aspx?id=64525) which may shed some light for you. Essentially the answer is *it depends*. IIRC, the tipping point is that above 256k of storage it's more efficient to store in the filesystem, otherwise it's more efficient to store in BLOB types.
I've been using azure blob storage. Url is in the db
Which has a max DB size per site collection. I forget what it is.
Yes, we do have the correct indexes.
You could try Naked Objects if it's a simple CRUD application
Context is UoW, DbSet is your repo pattern, I believe.
Thanks, this looks great, I will look into it further tomorrow. If anything else comes to mind, please write to me. Thanks again. 
It's not a framework, just a small library to help you implement MVVM in an easy way. The distinction being that a framework gives you a "right way" to do things, whereas a library just gives you a set of tools to use. MVVM Light is the latter - there are many ways to use it. Just thought I would point this out since many people seem to assume it is a framework. You generally do not need a special framework to develop WPF apps, unless you are doing something of significant complexity. To implement MVVM, you need to learn specific patterns of thinking and concepts, you do not need a lot of code that a framework provides.
I work with systems that do both (one stores them as files in the cloud, the other as binary blobs). Blobs are evil, don't do it. It makes backup and/or replication a nightmare.
Well, "RAD" is a big area with lots of snake oil, but if you want to keep the conversation to code generation, I can recommend a couple options for that. Probably the most comprehensive option you could find for .NET would be CodeSmith: http://www.codesmithtools.com/product/generator#overview There are many templates available for it too. I personally have used it for a customer and they used it to generate their entire data access layer in a way compliant to their architecture. As it was used for primarily data driven applications, they would do this basically every time the database schema changed. Yes, they could have just used Entity Framework, but this pre-dated EF and really did a lot more than EF could because it played nicely with their in-house architecture. The other option I've used a fair bit is MyGeneration (later renamed to EntitySpaces). It's very similar to CodeSmith in its capabilities, but it is no longer maintained AFAIK. It is open sourced now, or you can go get the desktop product for free: For the older, now open sourced, but very flexible MyGeneration: http://sourceforge.net/projects/mygeneration/ For the newer, My2ndGeneration, which now has more template options, but seems to support less data sources: https://www.my2ndgeneration.com/default.aspx Oh, I almost forgot, the previously commercial version of Mike's work in the form on EntitySpaces: Download the binaries here: http://download.cnet.com/EntitySpaces-Studio/3000-10250_4-10590953.html?tag=mncol;1 Source here: https://github.com/EntitySpaces/EntitySpaces-CompleteSource Now, all that aside, if you want something which is much more DIY, then you have another option available: use Python with Cheetah templates to generate code. I have also used this for a past client where I needed to (on a JSF v1 project) to deliver a number of admin pages for CRUD style database maintenance. The application needed to be maintained in Java, so I just wrote a generic template that used a metadata file that informed the code generator of what to generate. Obviously, this can get tremendously complicated, but a little code generation can go a LONG ways towards saving labor, so it's worth the investment to learn how to do in my opinion.
Last time I used MVVM Light it was so full of memory leaks that I was forced to rip it out with extreme prejudice. That was several year ago and I've since created my old library that does the same thing, just more efficiently than what was available at the time.
I think RelayCommand is good enough reason to not use this framework. If you have any decent amount of commands that have any sort of complicated "CanExecute" logic, have fun with the implementation using CommandManager forcing all commands to requery their "CanExecute" logic. It can really cause performance problems.
Amazon S3 or Azure Blob Storage. Both are solid solutions.
If you know windows forms. But more importantly if you need to develop a web app and don't particularly want to learn all the little gotchas with the web stack. Web forms abstracts a lot away. 
(I was a web developer before I got pulled into a web forms CMS) I think it actually makes doing things more complicated where i can simply whip up a bunch of HTML to do the same thing a lot easier. Then again that could just be a me thing. 
It was meant to hide all the intricacies and annoyances of working with stateless HTTP for people who are coming from non-web backgrounds and don't want to deal with all that. But it never really got there, has a lot of shortcomings itself and produces really ugly code, so I wouldn't use it for anything new, especially if you're used to web dev anyway.
I completely agree that things get complicated very quickly for anything more than a simple website. I hated how insanely complicated it is to do anything more than just standard forms and table views. I found that when I switched from web forms to mvc, I did less dragging and dropping of controls and using event generation (by double clicking on the control) to needing to learn html and the whole web stack.
as much as razor is loved, i wish MVC would support straight up handlebars or mustache templating. 
You can use other view engines like handlebars with mvc. 
Yup, no problem. I've even rolled my own template engine for ASP.NET MVC, works great. But if I started a new project today I would choose Razor because it has become the standard template engine i MVC land.
&gt; learn all the little gotchas with the web stack Web Forms has a large host of other gotchas. You need to learn the lifecycle of web forms page. Since Web Forms keep state on the client machine you can very easily encounter odd behavior that is hard to debug.
I do a lot of developing in Kentico and we use web forms.
Mostly scanned documents and means big pdf files. And some word documents.
I am currently using prism, but only because of their implementation of DelegateCommand
For running your service (daemon) I'd recommend using Topshelf (topshelf-project.com). I'd use the System.Data.OleDb (In the base class library) to read data out of your local MSAccess database. For making your REST calls I'd recommend RestSharp (http://restsharp.org/). Because ADO.Net (System.Data.*) API isn't always the best thing in the world I'd recommend adding in the micro-ORM Dapper (https://github.com/StackExchange/dapper-dot-net). I assume you've heard of NuGet (our PIP / easy_install) you will want to use that to get Topshelf, Dapper, and RestSharp. From there, you could get it all done in one Console Application Project. Good Luck! -d
Thank you very much for the comprehensive answer and for your time. I will look into these and see what is best for me. Thanks again, you are great!
Generate oauth tokens using owin middleware and send them with your headers while making a request to the server. Revoking and refreshing the tokens is a pain though but you can wrote custom middleware to check for token expiry based on time and reject them. Have done this for backbone with a web API backend and working happily in production for over a year.
You missed my point. All client side front end is redundant. The front end is all client side. Even if you do server side binding. The server renders all that fancy binding into client side code. 
Oh right, my apologies. I misread your comment. So where's it supposed to go anyway?
Yeah, but if you do all of the binding and api calls client -side, your credentials and requests are readable and manipulable by the client. If you do it server side, the client only ever gets the result. That's the distinction I was trying to make.
Your credentials are ALWAYS readable and manipulable by the client. &gt;If you do it server side, the client only ever gets the result. The only way to do it server side, is if the user is connected directly to the server. If, at any point, the user is entering credentials in a web browser, then they are doing it client side. Anytime you make a request, data is sent from the client to the server. There are just different ways to authenticate and encrypt the data. Using binding provides built in functionality, but you can achieve oAuth level security with an API using a combination of private/public keys and request tokens.
Dude, it's in the title of the thread. It's literally the only question being asked. Anyway, this conversation has gone full retard. Have a nice day.
Out of curiosity, does the app need to be running all the time? Or is it just something that sends data at a specific time each day? Because if it's just something that needs to run once and send data, you can forget about Topshelf and Hangfire. Just create a console app or windows app and use the task scheduler built into Windows. Or if you're doing this on Linux, just set up a cron job. Much easier than any other approach.
It would just send data at the end of the day, everyday. It's going to be running in windows machines, so noted on the task scheduler 
Octopus will encrypt it in it's store. We've been quite happy with that. I'd much rather go integrated security but we have one system that requires this. Our process right now is 1) Apply password from Octopus 2) Use Octopus to encrypt web.config I think the best solution would be for us to simply pull the connection string from an environmental variable rather than stored in the config file. We'll move to that with vNext but I'm not sure how easy it would be for us to rip out the current ASP.NET configuration to behave with that situation and our process is solid enough for me
Does oauth with owin 2 work seamlessly with Asp.Net Identity? 
Connectors for other databases are fine with Mono though, the author didn't state they are looking at .NET Core specifically. I've been using Mono for a while and it works really well on Linux.
I'm pretty sure that Umbraco is Web Forms. Downloaded it for research the other day and was shocked when I didn't see a model and controllers folder. Take a look.
&gt;In my situation the db and the web server are on the same machine. Whenever I move the db out to it's own box, Please make "whenever" into "as soon as possible". You're compromising performance (both web and database) and potentially security. &gt; as long as all machines are on the same domain, I can continue using integrated security Assuming the account your web app runs under is a domain account (or you use impersonation w/ the user account that authenticates to the web app) with the appropriate permissions on the database, etc., yes.
we'd remove it from the web.config. in vnext you'd initialize your configuration pipeline somewhat like this var config = new Configuration() .AddJsonFile("config.json") .AddEnvironmentVariables(); Maybe config.json defines a connection string for local development. Then on the production servers part of our deployment would be ensuring the proper environmental variable is set. This is how Azure works if I'm not mistaken.
&gt; Please make "whenever" into "as soon as possible". You're compromising performance (both web and database) and potentially security. It's a financial constraint more than anything else. I understand the performance trade offs, not sure how this could be a security issue though. 
reading through other comment, i think you're a bit confused about this. What are you trying to achieve? Case1: You're building a public api. Other developers will build clients against it. This is the case where you need API key and API secret hard coded in those clients. In case this client is a javascript client, embedded in a webpage, hosted publicly then yes the keys are accessible by anyone. (JS obfuscations help to weed out weaker minded "attackers") That's just not secure and not something anyone does. (hopefully) Case2: You're building a private API, that you're building a client for. You wanna authorize individual users who user your JS client. In this case you dont need no hard coded api keys. User will receive a temporary (or permanent if thats desired) token. Its stored in cookies or the browser's webstorage. Case3: Something else, but i dont get what you wanna do.
To use integrated security all you need is for your Application to run under the network user/ iis user/ local user of the machine that the application is on. Then on your database server you need to provide permissions to the $machinename of your application's server. I find that this is a pain in the ass for Development/Debugging but is best practice for Production. Our Dev/Debug/Test runs under a provided username/pw because our dev/local/test environments are all internal domains and well protected. Production is another beast!
its mvc since a while back
Thank you for confirming this. While the last part of your comment goes over my head currently, it still helps me as a beginner who keeps reading conflicting opinions on EF.
MonoGame seems to be Linux orientated rather than Windows. I'm very familiar with OpenGL so that seems like a logical choice but how well supported is it on Windows? 
&gt; MonoGame seems to be Linux orientated rather than Windows. Windows is a supported platform. I don't see why you would think that was somehow degraded. &gt; I'm very familiar with OpenGL so that seems like a logical choice but how well supported is it on Windows? OpenGL support is entirely dependent on the video driver so the capabilities (and version supported) will vary. But you would probably be hard pressed to find a system that doesn't support OpenGL in some form. 
You could potentially use environmental variables now, then set your connectionString to `$(env:SOMETHING)` then pre-parse it before using it.
AFAIK, Windows is still MonoGame's primary (first) target... when their new content pipeline tool was made available, it was for Windows; Linux followed somewhat later. The fact that you had to use an XNA content pipeline for a long time meant that developing on Linux was not an ideal situation; to compile, you had to use Visual Studio on Windows. If your interest is primarily 2D graphics, you could check out [Win2D](http://microsoft.github.io/Win2D/html/Introduction.htm) from the guys who used to work on XNA.
Seems a bit heavy weight if you are only going to use their command implementation...
I know, and they are fairly trivial to wire up in Razor with jQuery.
I am currently building an MVC site in sitecore 8 with Web API happy to help you convert across if you want? I just did the training and unfortunately yes it is still Web Forms despite having support for MVC in their newest version. If you are on an earlier version it is more effort to get MVC going and it is definitely worth investigating an upgrade. Sitecore isn't a shitty CMS, developing in a CMS is generally a poor experience there is always some constraint that bugs you/forces you to do something you dont like. Sitecore is a good CMS but being a good CMS still makes you an overall unideal development scenario. 
I'll check it out, thanks.
[Have you seen this?](http://j.tlns.be/2014/11/21/running-asp-net-on-a-raspberry-pi-with-mono-and-owin/)
Yes. Not sure how much more clear I can be.
It looks like it's not supported for .NET Micro. Here is someone that tried it. It's an older article so if you can find something newer that has better information feel free to correct me. http://blogs.msdn.com/b/laurelle/archive/2013/06/21/net-microframework-on-raspberrypi-part-1.aspx
I'd add that you should look at using the https://msdn.microsoft.com/en-us/library/system.security.cryptography.rfc2898derivebytes(v=vs.110).aspx hashing if possible rather than SHA 256. Also, this is a fantastic read on the subject. https://crackstation.net/hashing-security.htm
Well that was my last guess. Good luck finding an answer.
Win2d is a new Hardware Accelerated Drawing Library that is easy to integrate into WPF. It's open source and developed by microsoft. https://github.com/Microsoft/Win2D
That still requires more work than plonking a data controller and a grid view on a form with barely any coding. It also requires a higher skill level and knowledge of JavaScript. I don't know why you wish to argue and can't concede this obvious point.
Adding some instructions for ASP.net 5 (package) projects... ;) You can use the new project system included in Visual Studio 2015 or used by Visual Studio code already on the Pi, too. Follow the [Getting started with ASP.net 5 and Linux instructions](https://github.com/aspnet/Home/blob/dev/GettingStartedDeb.md) to get dnx up and running. Copy your source code with the project.json file on to your pi, cd into the directory and run: * **dnu restore** (to download required NuGet packages etc). This has to be done only the first time or when the package versions change. * **dnx . run** (notice the "."). This starts your app.
Apprently [Windows IoT runs on Raspberry Pi 2](http://ms-iot.github.io/content/en-US/GetStarted.htm)
Do you do hardcore unit testing and/or use dependency injection for more than just trivial cases? If yes you need MVC, otherwise you'd just use what you know best
I use ads in one of my apps... They really don't pay all that well if you're a small time app developer. Technically, my app operates at a loss. I suspect that the money doesn't start rolling in until you spread it across multiple apps with many, many impressions.
Maybe "collision"? Sometimes when you hash a key, depending on the algorithm you can have a higher probability of a collision, where two different pieces of data result in the same hash.
Cold fusion?
I hope it's not Cold Fusion, for your sake.
Cold Fusion was hot shit in '99. 
Wouldn't the possibility of two pieces of data colliding in a hashtable be the result of one piece having a bad GetHashcode() function? 
am I the only person who doesn't worry about the GAC anymore? I feel like that was a problem we had a decade ago with .NET. maybe I just haven't had issues with it in a while.
Now you mention angular did the mean clojure? What kind of company is it because they could've meant GPS. 
Hmm this seems really cool! Anybody else have experience with this? Might have to check it out myself.
You're right, now that I think about it, they actually might've said clojure. HR who didn't know the software might've stuttered and said 'Do you know about co-clojure'. It's a software development company which develops phone applications which automate specific tasks. I doubt they said GPS though, unless there is a programming software called GPS.
Yes, that is possible. As it is not clear in what context the interviewer wanted to know about collisions (if that is really what was being asked) there are a lot of possible answers.
Did they mean GIS? https://www.google.co.uk/url?sa=t&amp;source=web&amp;rct=j&amp;url=https://en.m.wikipedia.org/wiki/Geographic_information_system&amp;ved=0CCkQFjACahUKEwjIy9OhkNrHAhVMKtsKHfPTBeU&amp;usg=AFQjCNHLGKA9pU63n-Epo5blfCXf3Uqmmg
Too expensive. 0.15 US$ per host hour is (given at least two instances) already 7.20 US$ per day. Meaning over 200 US$ per month.
Do you mind updateing us when you have your second interview.
Gulp and Grunt (and also NPM) are used as task runners. You set up specific jobs that are either started manually, as part of the your regular build or automatically on file changes (a watcher task). What kind of tasks you use is mainly up to you, but very common ones are: - Compile SASS/LESS to CSS. - Compile CoffeeScript/TypeScript to JavaScript. - Merge multiple CSS/JS files to one. - Minify CSS/JS files. The merging and minifying is **very** important to speed up your webpage. By merging you reduce the amount of HTTP requests for your resources, by minifying you reduce the size that has to be transferred. Especially the first point improves speed a lot. ASP.NET has the "Optimization" package for this, but frankly the "Node-World" alternative is better. The optimization package runs at runtime. It merges at runtime, it minifies at runtime. In development it's acceptable, but when deployed this is a no-go. These are compilation steps which should happen at build time. And frankly, the node tooling has so much more options to offer. There's much more options to do. A common option is to merge SVG icon graphics into a webfont. That way you just have to download one font and can use many icons - this again reduces the amount of requests (only one font to download, instead of many images). Or a sprite sheet (multiple images rendered into one, then parts of it are used using CSS). Again this reduces the amount of requests. We once used a task for localization. We required localized text snippets within our JavaScript, so we automatically created a JavaScript version for each language - automatically replacing placeholders within the JavaScript, all as part of the build (or automatically on file changes).
Ahh ok, sorry; slightly misunderstood the question. Not familiar with Grunt/Gulp myself, I've just made-do with NuGet. I agree re. the issues it creates though.
Like the rest of the world, I lost sight of Cold Fusion in '99 or so, so I can't answer that with complete confidence in the technical details. At any rate, it was developed by a small shop, got bought out by Macromedia (who Adobe then bought) and all the while, it was its own weird beast - a language that mixed and mashed itself with web pages, like classic ASP, but not implemented in ASP. Also, it was Windows-only for a good while.
I think you answered your question. Now, you are doing MVC. Now imagine you have an AngularJS site with a webapi in the frontend. Suddenly you are updating your frontend libraries as much as the backend. So as you said, frontend packages not available on nuget? That's bower and npm for ya. Hate that there is no way to tell it how to handle the files? that's grunt / gulp. Don't have the ASP.NET minification and bundling on a static server hosting your SLA (or don't like the way you have to rely on it running at runtime on your prod servers)? Use gulp/grunt. That's it. That's why you'd care. The fact that you all don't care about out of date jquery client libraries and handling them is kind of a problem they are trying to solve here. 3 or 4 years ago people said the same thing about dependencies - just throw them in a lib folder and check that into source control. Why would I need a package manager for that?
[removed]
NPM is a package manager exactly like NuGet except the registry (number of packages) is significantly larger. IIRC it is the largest package manager in the world right now. Bower is an alternative focused mainly on client-side/front-end sort of libraries. Almost anything that is on Bower can be found on NPM. Gulp/Grunt are task runners. They do the nasty things you don't want to have to do like concat, uglify, and minify JS and CSS. They can do a ton of stuff, too much to really list. I have used both. Gulp seems to be on the upward trend, but they both do the same things, the syntax is just a little different. Use whichever one makes most sense to you. You don't have to use them of course, but it does make life easier. It is hard to see it, but if you start using it regularly I think you'll understand a little better what they do and why they are helpful.
I don't have any books for you just some advice. When picking a book for learning .Net I would either pick an ADO.net or and ASP.net. They represent the two main categories of .Net development. With ADO being a focus on the backed/business/data/file io/server side and with ASP being a focused on Web/PresentationLayer/MVC/Session/Web Forms. I personally focus on ADO because I love performance and business tier architecture but I am so well versed that I don't need a book (because I know what to google). Because I know ADO so well I do have an ASP.Net MVC(4) by Jess Chadwick, Todd Snyder &amp; Hrusikesh Panda [O'Reilly] book. It does a good job with ASP as a whole but focuses on MVC specifically. I find ASP to be a little more challenging then ADO because ASP is a a confluence of technologies, patterns and libraries, such as MVC, WebApi, WCF, MVVM and so on and so forth.
When you're done with that, you can read more about the author [here](http://meta.stackexchange.com/questions/9134/jon-skeet-facts/9182#9182)
It can also occur if the hash was to be placed in a bucket that is already full. If buckets are evenly distributed arrays of hash data and the table is attempting to insert a new hash into an array that is already full then a collision can occur and the hash table will run its resolve algorithm to re-organize its tree.
For nitty gritty I would add CLR via C# (http://www.amazon.com/CLR-via-Edition-Developer-Reference/dp/0735667454) 
It will happen one day and it will be a pain in the ass to figure out. You'll learn far more about .dlls, references, nugets, build routine locally vs build routine on your build server and the GAC then you ever thought possible. Then you will find the issue, feel like a hero, and never get to use that knowledge again.... until you do. =)
MAX_PATH is never going to change, as it would cause buffer overflows in every program compiled for older versions of windows.
What issues are you running into with max path? Viewing the files within visual studio? What I've seen is when I include bower or npm folder in my visual studio project, the proj file gets gigantic because it needs to account for every single file.
Dependencies get downloaded into their own subfolder. Many times they would not download due to the path they tried to download into being too long. 
Npm is actually moving to using a flat install structure for modules rather than using nested folders like before. So the MAX_PATH issues should start going away. See: http://www.felixrieseberg.com/npm-v3-is-out-and-its-a-really-big-deal-for-windows/
Could've been Git because it was a software development company with lots of developers and on the job posting it did say Team Foundation Server experience and on other similar job postings from the same company, it did say Git experience.
I'll definitely update after the second interview (on Tuesday).
I have a second interview on Tuesday so I'll find out at that time... hopefully. I'll update the post when I find out.
The biggest change is the open sourcing of .NET Core (along with a whole host of other related projects) which is a cross-platform implementation of .NET. The next major version of ASP.NET will be based on .NET Core and will give you the ability to run your applications on Windows, Linux and Mac. MVC and WebAPI are still the preferred way to do things currently but once ASP.NET 5 is released, they are going to be merged into one unified framework. NuGet, SignalR and OWIN all play a huge role going forward. The web development model is going to follow more of a Node-style of modular development than the monolithic framework approach of the past. As far as the front-end goes, I don't think there is a single framework that has emerged as the winner. The JS ecosystem has too much movement to settle on a framework. That being said, Angular and React seem to be more popular than others. I prefer React over Angular myself (along with RxJS, CycleJS, Mithril, etc.) but you can't really go wrong with anything you select. TypeScript is also huge now-a-days. 
Cool, thanks!
There are Windows APIs that have no problem with paths longer than 260 characters. Those APIs should just be used.
I'd start by checking my application logs. If nothing there then time to Google Fu. First search for MySQL support in Entity Framework {Version Number}" to verify that it exists. Then I'd probably hit up *Mysql Provider Configuration "Entity Framework {Version Number}"* (note the quotes). That finds a very nice page from [MySql EF6 Config](http://dev.mysql.com/doc/connector-net/en/connector-net-entityframework60.html), which also has instructions for how to set up Code First Migrations. Then I'd verify that my configurations were correct. Once correct, run the application locally while targeting the MySQL database instead of localdb. Set break points and step through from the app entry point. Constantly check the Output. By this point you're either working or you are starting to get enough information to know where the problem is. 
Oh thank god. If I have to robocopy over one more undeletable directory in windows, I'm going to flip.
A lot of people swear by this series, but I did not care for my Head First SQL book. Might have already had a predisposition towards it as I hate SQL, but I don't know.
Haha to each their own I guess. Their design patterns book is amazing in my opinion. 
Nobody pays new relics sticker price. I opened two accounts with them in the last month, two salesmen contacted me and immediately offered to lower the rate before I even asked for it. You can easily get 30% knocked off without even negotiating, they will offer it up.
Does anyone have experience with [this plugin](http://www.hanselman.com/blog/IntroducingGulpGruntBowerAndNpmSupportForVisualStudio.aspx)?
There are alternatives that many folk will already have installed (such as Web Essentials) that minify on-save rather than at run time and compile SASS etc. I personally don't agree with webfonts. They're a bad design practice, bad for SEO , bad for accessibility, bad for semantics.... I cant see any use for these "trendy" packages in a .NET workflow.
Ha interesting that you linked that article. I commented on that 4 months ago saying that they should have kept the feature in. 
Your reply here is similar to ones you've made further up. Just because something is different/not how you've done things doesn't mean they're not useful to others. &gt; We are taking everything we love about NET and visual studio and stripping it out , having to duplicate lots of our code to make JS duplicates of our view models etc, removing the awesome assistive tools that VS gives us to use with a truly object-oriented language and the great workflows we have built up with the strong data types inherent in c#..... This is wrong; and if that's the impression you get from Angular or Knockout, you're using those tools wrong. Using Angular doesn't stop you from using a "truly object-oriented language and great workflows". It builds on top of it. We don't use Angular at our shop because we haven't found a good fit for it; but we definitely use tooling such as Knockout to build our sites. I think the main issue (what /u/TapedeckNinja was saying) is that you're relying on VS to do all these magical things for you to build your app-- and it shouldn't work this way. You should be able to (from a command line/build server) pull down your code and build it 100% without having to install VS on your build server. You shouldn't be checking in your minified files. Your build server should be doing that for you
&gt; Gulp and Grunt (and also NPM) are used as task runners. So they replace nant/msbuild/psake and not the optimization package?
&gt; We are taking everything we love about NET and visual studio and stripping it out , having to duplicate lots of our code to make JS duplicates of our view models etc I don't understand why you'd have a view model on the server at all. Honestly, it just doesn't sound like this stuff is a good fit for you. Server-side technologies like MVC/Razor aren't best suited to the same use cases as client-side frameworks like Angular or React. If you're building RESTful services on WebAPI along with JavaScript-driven front-end applications, then tools like Grunt/Gulp and package managers like NPM/Bower are invaluable, even to the nominally ".NET developer." I wouldn't use any of it for a standard LOB application or a pages or forms-driven site, but it's close to unavoidable if you're building interactive, cross-platform web applications.
Sounds good :) just need to research js frameworks again 
Those folders are not meant to be part of your project/solution. Just like nuget's package folder isn't. When you get the source, you run npm install. Windows itself has no problems with crazy long paths. Explorer and cmd, do. Rimraf to the rescue here.
&gt; There are alternatives that many folk will already have installed (such as Web Essentials) that minify on-save rather than at run time and compile SASS etc. I know. But when you use these tools you have to commit these files to the source control. I don't think that is good practice. Those are build artifacts, they are nothing different than *.dll* files. Do you commit those too? They are build related files and should be created with the build pipeline. &gt; I personally don't agree with webfonts. They're a bad design practice, bad for SEO , bad for accessibility, bad for semantics.... That is fine, but that doesn't change that they improve the speed of the website immensely. The less request your browser has to send, the faster the website is accessible. This is especially true for mobile devices and mobile connections. &gt; I cant see any use for these "trendy" packages in a .NET workflow. If you don't have a use case: That's perfectly fine! Everyone has a custom workflow. But a lot of people have, and these tools are by far not "trendy" anymore. Don't be a dinosaur. ;-) We often work with frontend developers who are not very common with Windows. Forcing Windows and Visual Studio upon them is silly. Instead they just run a Windows machine in a virtual box where the application is built and hosted with simple shell scripts, completely without Visual Studio. They work locally on their machine (Mac or Linux) and just sync their files to the Windows machine. Stuff like Web Essentials would not work in a workflow like this.
Yes, you need to install npm. Then it's simply "npm install" and you have all packages installed and working. Then you can just run the build script or the watcher script and let it running. This tooling is free and does not require a huge IDE to work.
You are grossly oversimplifying the process, and it does you no credit. Both approaches require you to install, set up and learn the tools. Using Compass, Grunt and Bower requires you to manage *three* different package managers and *two* wildly different programming languages and their associated frameworks, just to get up and running.
Frankly, the MySQL connector is horrible and utterly broken. You're better off completely removing EF and using ADO.NET directly instead of trying to fix your issues.
ASP.NET MVC 5 no longer has Bundler. See this article, among others you can google: http://www.jeffreyfritz.com/2015/05/where-did-my-asp-net-bundles-go-in-asp-net-5/ 
I'm struggling with this now. I work in a ASP.net MVC shop. We were all good with MVC 4. Then a couple of new devs appeared and began re-architecting a good chunk of our application in AngularJS, using grunt and bower to manage it. I don't mind learning the new stuff. It is what it is. I just struggle mightily trying to figure out what the point of this exercise is. We're spending all this effort re-architecting in AngularJS, and we're just going to have to do it again when the next flavor-of-the-month JS framework comes along.
Nevertheless: as I said ... Ruxit is below New Relic's price point ;-) But to be honest, if you need an APM tool, it should be the feature set which convinces you, not the price.
Move your dev stuff to something like c:\dev or something short.
Collections I usually handle by making sure I always instantiate them before handing them off to something else that would use it. If it's a model's property, then *new* it up in the constructor. If it's the returned type of a method, return a new empty list instead of returning null. If the collection is empty, a foreach loop will not do anything and will certainly not throw an exception.
Similarly, on the project I'm on currently, someone wrote an IEnumerable extension called "Ensure", which returns an empty collection if the collection is null or returns the existing collection if the collection is not null. That way, we don't have to worry about a null collection. Then you call it like this: foreach (var item in items.Ensure()) { ... } 
It's not cheaper. Both are expensive so yes the price point matters. 
Indeed, this is also a good way of ensuring that your loop won't throw a null ref exception.
Can you do null conditional (the new ?. operator) in MVC? If so, go for that!
You may want to check into the Null Object Pattern. 
That is horrible practice. Is null a valid and expected value? Then just don't iterate it. Is it not accepted by the method? Throw an exception.
This whole "flavor-of-the-month" or "trendy" JS nonsense has got to stop. Angular was released in 2009; so was Node. Grunt has been around for at least three years. Can you do the same things on the client with MVC that you can with Angular or React? If not, then that's the point of the exercise. I think the problem is that a lot of .NET developers are doing LOB development and simply *don't need* the features these JavaScript frameworks were built to support. But it's naive to dismiss it all as a script-kiddie trend. MS has made the JavaScript application development workflow a first-class citizen in VS2015 and Azure. It's here to stay.
People said the same thing about backbone and knockout. Fool me once, etc.
Backbone and Knockout are both actively developed and used by companies like Stripe, Belly, WordPress, Sony, Nokia, Baidu, Microsoft, DNN, and many more. We use Backbone in some of our APIs where I work. Nonetheless, this thread was about JS development *tools*, not frameworks. You can (and probably should) use Grunt/Gulp with Backbone or Ember or Meteor or Angular or React or any other framework you choose. You're going to manage those dependencies with Bower or NPM, no matter what they are. You're going to use Git and probably Git-flow and enforce linting and test coverage and documentation using Git hooks enabled by Grunt/Gulp. But, if WebForms or MVC/Razor, TFS, WebEssentials and the rest of that workflow works for you and your team, then stick with it. But a lot of teams are building applications that need more than that.
Sounds like you need a Content Management System like Orchard, DNN, Umbraco, etc. The text box will only allow for content updates, not layout and UI.
I've been applying the jetbrains annotations liberally to document this on our objects return values ESPECIALLY if they return a collection. We also enforce the [Brad Wilson bazooka rule](https://twitter.com/bradwilson/status/432235119969959936)
Anytime! This is one I have used in numerous projects and it seems to have a good balance of features and not overly complex.
CKEditor is another good JS based editor to look into. 
Gotta second this, TinyMCE is spot on
1. Is a cross-platform WPF / UWP planned that can target GNU/Linux? Will it get OSS? 2. Is buying Xamarin an option since you get the Android/IOS as a platform too? 3. Do you know when EF7 adapters will work on GNU/Linux? 4. https://github.com/dotnet/llilc AoT compilation of MSIL against LLVM supported platforms. Can you tell us more about this? 5. I guess a lot of people in the MS realm were not that into OSS. Where can we start and how can we help? 6. Is a minimal, high performance (GNU/Linux-based) OS planned for ASP.NET 5? 7. What do you think about [firefly](https://github.com/FireflyServer/firefly) and [mio](https://github.com/carllerche/mio) as additional web server? 8. This is slightly offtopic: Do you plan to open dev offices in Europe?
Different Phil, methinks.
Any updates on your twisted testicle? Any long term consequences of that or is everything A-OK?
Will anything SQL Server related be OSS? I guess a second question would be, how has bringing .NET into the world of open source benefited the platform as a whole thus far?
Do not give people the ability to create html. They will fuck everything up horrifically. Give them a markdown editor. 
That doesn't help, I've seen npm try to create 100+ directories deep with 2k long path names just endlessly filled with redundant libraries up the wazoo - gigs of crap... it's complete madness really.
Bing!
Thanks for all the great questions - will update here when we publish the interview.
With the open sourcing of Asp.Net and Roslyn, why do we still need Mono? Why not just make the plunge and officially make it cross-platform? Now I'm not saying throw out Mono completely. But instead take some of their awesome cross-platform tools, mkbundle, monodevelop, etc and add them to the official build, while replacing Mono's mcs with an official cross platform Roslyn (I know Roslyn "works" with mono with several patches, but why not make it official? Being independent, Mono of course has some limitations. And limited people who can work on it there is only so much they can do and so fast they can do things like upgrade to C# 6. Since Roslyn is written in C# and can build itself, whats stopping it from being cross-platform officially? That way precious resource don't have to be wasted reimplementing something that has already be done, and the Mono team can focus more on awesome tools.
I disabled my firewall and my antivirus. I didn't worked for me :(
Have you enabled TCP as a protocol? It's not enabled by default. If you haven't done this before, that's in SQL Server Configuration Manager. Not sure if you need to enable it under SQL Native Client Configuration or SQL Server Network Configuration, or both.
Assuming you're writing a public function that other people might be using: I'm of the opinion that no matter what, you should always define what acceptable input values are for your function. Additionally, it's much more readable to throw the exception instead of hitting the null pointer. By this I mean "Parameter x cannot be null" is a lot nicer than "Object reference not set to an instance of an object" which doesn't really tell the developer anything about where the problem occurred.
I was in the middle of doing this exact same thing when I refreshed reddit and saw your comment. You're absolutely right, this whole time it was column type conversions that were giving me these hair-pulling errors. For anybody reading this in the future, if you want (have) to use MySql with EF: Be careful with your column types!!! Like Jonathan notes, timestamp is out. Also, EF will default un-annotated strings to nvarchar(max), which MySql can't handle.
He does. But he is also still on the .NET Foundation team.
[Important PSA](https://www.youtube.com/watch?v=92u08Wmtxwk)
&gt; Assuming you're writing a public function that other people might be using: I'm of the opinion that no matter what, you should always define what acceptable input values are for your function. Additionally, it's much more readable to throw the exception instead of hitting the null pointer. By this I mean "Parameter x cannot be null" is a lot nicer than "Object reference not set to an instance of an object" which doesn't really tell the developer anything about where the problem occurred. You would throw that kind of exception in an MVC app ? Or you would try to solve the problem by yourself without warning the user?
Never tried it. I will check ;) 
ah gotcha, i thought he had completely left MS when he went to github 
Thank you very much. That seems to be the problem. Now I have a successful connection with the database! Thanks a lot!!
I hope that's a temporary username and password. Seems like it.
From my perspective, .NET is pretty well positioned now. I feel like Microsoft has a clear, or more clear at least, roadmap. Stagnation? Sounds a little harsh. It can't be all things to all people, just like javascript isn't always the answer.
Indeed. It was a temporary database/username/password. This database did not have any critical information on it. Thanks for the concern.
Shawn Jackson, a name to avoid.
Honestly, I can't bring myself to even consider looking at the article. .NET is currently having a golden era in language design, platform support, and (aside from EF) API improvements. 
You're welcome. (And don't post your...ah, you get the point).
I've come to find that there's not much info out there on identity. Does anyone have any recommended tutorials that they learned from?
Interesting. I hold a similar view that access to objects should be controlled from the resource access component (data access, or something equivalent), but it has been hard for me to convince fellow developers. Do you have any writing or link to a resource that goes deeper into this?
Just to be clear i don't handle authorization at the DAL/RA, i build my system's reads that a user can only access their own data. I ensure the user is who they claim to be authorizing at the end point, i would never allow a malicious request to touch my system it will always be blocked by the endpoint. In regards to sources to cite, i can't think of any off hand. The main way to sell this design is simplicity. It lets you write the least amount of code. Your endpoint protects you from bad users (malicious impersonation). The system itself just works to read only the user's data. The system just does the right thing. It not longer needs special cases, if(user is good) checks litered throughout the code. This is why all admin/staff/empowered users go through isolated endpoints. They talk to DAL/RA code that can read across multiple users. The individual user endpoints have no code path at all that can lead to inadvertent data exposure.
&gt; Just to be clear i don't handle authorization at the DAL/RA Of course, this is a given :) Thanks for replying. I do something similar, except that I determine the user id to pass to the DAL from the principal whereas you get it from the route data. I think I will give the routing method, as it the URLs then carry semantics. 
You might check out asp.net scaffolding and save yourself much more time than that. :)
I can use a database designer and still be database first right? Edit: the reason that I ask is because I've been having a couple issues when migrating in production if I've done significant changes to the models
We use code-first because we try to stay out of the database as much as possible. I don't (really) care what the database looks like as long as my entites are tied together as I like. Now, this doesn't mean we *ignore* the database, but 80-90% of our time in migrations is spent ensuring our entities have the right data in the right places. If that's good, I don't really care what the tables are.
I have built a few small sample applications in Mono using PG, it takes significantly more code and the context is not as easy to deal with because EF doesn't play as nicely with the PG adapter. It is making leaps even in the last few months. I'm excited for this combination. 
PreferFairness, LongRunning etc.
Like the others said, its a matter of preference. My vote goes to code first though
Either approach is fine but you should look into migrations rather it be Entity Framework Migrations or FluentMigrator. If you use FluentMigrator to persist your database changes with your code/model changes things become WAY easier to manage and keep in sync.
Thank you. Corrected. As you can probably tell, I wrote it from memory.
There is no such thing as a `app.settings` file. There is a `app.config` file. The `ConfigurationManager.AppSettings` are read from this file. When hosting a web application on IIS you don't have an `app.config` either. In IIS you have a `web.config`. It's supposed to be located in the root directory of your web application (that is the web project).
Oh! Thanks, yes I know about stackoverflow, I just thought it was some kind of subreddit-specific tag.
Awesome, I put the settings in web.config and the issue has been fixed. Everything works. Thanks! Now I wonder where that App.settings file came from and why every internet website talks about it... just for general knowledge.
In London the .NET golden era is most definitely a thing. The notion that it's in decline is most definitely not true of London.
You want : https://msdn.microsoft.com/en-us/library/ms733932.aspx Web.config is for IIS hosted solutions. App.config is for everything else, like console apps
He probably referred to app.config because services get created with the app.config by default. It could just be my personal environment, but I always have to change them to Web.config when I deploy. 
We have a showcase system for various projects, which is open-source and using the latest versions of ASP.NET Web API, AngularJS, Entity Framework, AutoMapper, Ninject and more. I dare to say the code is written in a high quality manner, following the best practices. Here is the project: https://github.com/TelerikAcademy/ShowcaseSystem
Nope. The MVC team leverages scaffolding extensively but it is it's own framework that can be used for just about anything.
Also can have mini ones in folders, for different finite settings, e.g. file cache settings. 
Hi, Ruxit is not yet on Azure, but on AWS activate Ruxit is 10$/month. We are still working on Azure support. Are you interested in a short notification when our Azure support is available (pinging you here personally, i mean by that). 
Much like .htaccess counterpart, web.config can also be in any subdirectory of root, and will override the parent directory's web.config settings.
I prefer to use code-first from database. This way I can first focus on building a good database structure in SQL Studio and then automatically let Visual Studio generate the classes in my MVC solution.
This seems like one of those things which sounds simple, but will end up being a total nightmare to implement and maintain! Good luck!
Yes, you can use a designer and still be database first (my preference). If you already have a build in production, make sure you script out your changes to ease updates. SQL Management Studio allows you to use the designers, but export those changes as SQL scripts. You can also use SQL Compare by Red Gate to get the differences between two databases.
http://i.imgur.com/uksT9UP.png the irony
How do DB backups work with this? Are they pushed into the .bak file? If a DB is restored do you know if it checks the files? I remember reading some issues on that front.
Might be some archaic settings file for windows forms applications, something that might have been present during development at some point. But I only remember web.config and app.config.
I second that and there are plenty of .NET libraries to turn markdown into HTML. I haven't used it but StackOverflow's own [MarkDown](https://github.com/Kiri-rin/markdownsharp) may fit OP's needs.
You should try RedactorJS. It is extremely light weight, with a good JavaScript API. 
You can create a presenter, an interactor or something else. Here's a video about some concepts you can use. This video describes some decoupling for RoR but it can be applied to .net mvc. [October CincyRb - Jim Weirich on Decoupling from Rails](https://www.youtube.com/watch?v=tg5RFeSfBM4)
MVC is a design pattern and Angular is a framework/product. I think you should solely use a framework and stick to it. It will make sure everyone on the team is using the same thing so that they're familiar with it. If you have multiple frameworks for the same thing, you'll run into issues where only a certain number of people can efficiently create new features or fix bugs with that framework. I'm not advocating that you should use Angular but you should pick one and stick to it. Even with Angular you'll need a WebApi behind it and if you need real-time updates, SignalR.
Go Code first because, in EF7 Code first is the only supported way: From the [EF7 blog](http://blogs.msdn.com/b/adonet/archive/2014/10/21/ef7-what-does-code-first-only-really-mean.aspx): * *In EF7 all models will be represented in code* * *Another way to sum this up is that rather than a third alternative to Database &amp; Model First, Code First is really an alternative to the EDMX file format. Conceptually, Code First supports both the Database First and Model First workflows.*
I like it! Several people suggest using other technologies: scaffolding, T4, etc. I prefer exactly what you're doing, keeping it simple. Need something new? Just *add* it, instead of jumping through hoops to get the chosen technology to do what you want. KISS.
Can you give an example of display logic that should be in the view model? I'm new to MVC and was under the impression that anything affecting presentation should be in the view itself.
^ This. This is a great article. I'm currently using this setup in a production app with about 100 concurrent users at peak daily traffic without issue.
The quickest I can think of would be a calculated property on the model (I think that is what it is called). My formatting skills are better on Stackoverflow, but here is a quick example: public class Rectangle{ public int Width {get;set;} public int Height {get;set;} //calculated properties public int Area{ get{ return Width * Height;}} public int Perimeter { get{ return Width + Width + Height + Height;}} } These come in handy when you have to check multiple properties to determine whether or not to display something in the view. Another Example... public bool CanEditRecord { get{return IsAdmin || (IsOwner &amp;&amp; IsActive);}} And in razor -&gt; @{if(Model.CanEditRecord){&lt;input type="submit"&gt;Edit&lt;/input&gt;}}
I would argue that it is in fact no premature optimization, but that the added benefits of view models outweighs duplicating a few properties on a class as well as is possibly a direct result of TDD (implement only what you need, nothing more). First, using domain models as view models is perfectly fine in most very small applications. However, as soon as you have a view that needs data from more than one table, your domain model is going to cause you problems. Let's look at how we could resolve this: 1. Partials. Sure, we can create a partial of the domain model, but, we are now managing multiple files (same as with using view models), but with the added fun of if I change the base model, how many other items have I actually impacted. 2. I will use lazy loading -&gt; the data is all related anyways. Sure, this will work, but if you are lazy loading data in your view, I can gaurentee you are not disposing of your data context correctly as using a 'using' statement, the context is disposed before the view is rendered. 3. View Models -&gt; add the property(ies) that you need. Populate appropriately. Second, I think domain models can pose a security risk that you have to deal with in the sense that you could possibly be exposing more data from your table than your user should really be messing with. Even if you are not displaying or outputting a property, if a malicious user can deduce your table column names, he could alter the POST collection to change a value you didn't even have output. The model binder won't know or care.... Again, you have options... 1. Specify the [Bind] parameter on the action method. To me, this was always a lot of extra work, is done using "magic strings" (no IDE goodness or validation -&gt; yea runtime errors) and is prone to user error. 2. View Models -&gt; You are only binding data that you explicitly have set. Also, since you are not using a domain model, you can get away from the temptation of updating a DB record directly from the returned model on POST. Anyways, my two cents. Yes, view models are a little extra work. However, in any application bigger than two DB tables, I would wager the pain saved is better than the work to start it the proper way to begin with. 
^ This. When you SPA, 99.999% of your logic ends up in the front end. The backend basically is a secured CRUD Machine. If done correctly, ASP.NET MVC isn't even tied to your front end app. It could be NodeJS for all it matters so long as it answers the HTTP calls the same way.
I suppose that's a fair enough assesment. I personally start off with the security of the new system before designing the rest. "Security First" seems to me the only sensible way to build an API in 2015.
Well currently the property doesn't have the `[Required]` attribute so it's possible for it to be `null`
I am also curious about this. To me it seems like null could be caused by more than just someone not answering, so you'd almost want more information. Having two fields for every integer seems a bit clunky, though.
From a design perspective storing a relative value (i.e. the age of something) isn't a great idea because it's only correct when calculated. Storing the birth date, or creation date is always the better option. 
Is this a computed value (based off of, say a date of birth and today's date)? If so, it shouldn't be stored in the database. If the field's not required by users, do any external class users ever need to set the value? If not, make it a method. Speaking in general, if your data's going to be at rest in a DB, it's preferable to storing unknown values as null rather than as default/sentinel values.
Ints are value types and can't be null.
No, it's a specific age. How old were you when... I don't want to know a users DoB or anything. I'll change it to be nullable. After reading around a bit more, this seems to be the most sensible thing to do. Thanks
You can use int? Age {get;set;}, "?" being the nullable symbol for a value type. 
I could never go back to the pain of fiddling with EDMX files in DB first. Code first all the way and that's the direction EF7 is heading.
How are they being untrusted? If it's just because they don't trust the issuer I'd tell them to f**k off as long as they are not expired and encryption levels are appropriate 
Love using octopus deploy so I was looking forward to this post. Then I opened it up and had flashbacks to "security experts" blindly running scripts and demanding to know why I could be so careless not to do everything to confirm to their cookie cutter applications. We got lucky and were able to provide documentation as to why we were didn't line up, but lord did it take some convincing. God speed.
I understand, unfortunately it's a non issue that you'll probably have to stand your ground on and explain that the rules for certs for a public facing site should not be the same as the rules you should enforce in your internal network. If you use a load balancer for web apps with your certs on the LB device, you use an internal issued cert similar to octopus between the LB and your web servers. This is not a new thing exclusive to octopus.
DNX + multi-platform console
You have lots of options. SSIS is certainly valid, and probably usually the right answer, especially if you have dedicated DBAs or a team of good full stack people. The one thing I'll point out with this, is use it sparingly. This is a real easy way to couple data models together and can make DB changes harder later. A semi-successful practice we've had with this is to not tie directly to the tables, but to expose VIEWS that you base your ETL process on instead which can present a more stable and specific interface to the SSIS / ETL process. Or you can write a small app to do it. We do that sometimes when we want to isolate a vertical stack (E.g., don't want cross database dependencies, so we move this operation up a level into code. Lots more infrastructure this way, but we find it easier to manage the cross application relationships at the code level with VCS, etc., than at the database level).
When I sat down with security I asked them for an exclusion since the certificate was valid on the f5. They didn't like that answer. I'm going to do the import cert thing for now to pass the scan but hopefully my protest will be noted
No it isn't, that is just the excuse they are using to overreach. Ask them to show you the PCI standard you are violating. I guarantee it will be some vaguely worded section they are clearly stretching.
I'd love to attend (and possibly even speak), but it's too far away, and the jetlag is quite horrendous. I'm looking forward to seeing the speaker videos, though :)
Could always require the poster to add the flair then remove the post, just like you do now, if they don't.
Jobs, more than conferences, localize the subreddit though. Also there are dedicated job seeking/offering subs, IMO they fit better into those.
* Yay * Yay * Yay * Nay For 2 and 3, maybe allow it for a time period and see. If they flood the sub and clutter everything, then stop them too. 
1. Yes 2. As long as it's an informative post and not just spam 3. No, they can link to an interesting article on their website already. That's advertisement 4. No
That's all great - as in, it's a pretty reasonable 'base' - but my personal approach is to strive for simplicitly, so I more often than not ask *why* (and *how*, to an extent)... 1. *Why* have a dedicated repository pattern if EF already *is* a repository and unit of work in one? 2. Are the view models going to be actually different than domain objects? If the answer is 'no' and the view models are going to be a glue-layer, *why* would you separate the domain logic into another assembly, unless you really have a lot of it? Logically separating components inside several namespaces would do just fine - if/when your application grows, you can break it out to a separate assembly.
You shouldn't need the repository pattern if you're using EF, that already separates your db calls in a centralized fashion. You have a typo on the identity pane 'vode first'. Are you using a DDD style for BL or was this your plan for repositories? I've found it to be easier to use CQRS to split apart reading and writing, since they follow different standards. If that interests you, this library may help https://github.com/jbogard/MediatR but the downside is it can be hard to track how a command goes from the controller to the handler without good convention. 
For job postings, maybe we can follow hacker new's model: a periodical posting is made by the mods titled 'Who's Hiring [Date]' and all of the comments are the job postings. For Ads, I'm OK with letting the reddit voting system do the filtering. If it's spammy it will get downvoted. If it's relevant then it will get upvoted. There is no need for mods to make the determination of what I want to see. The hivemind does that. 
Doesn't really matter whether it's an overreach or not. QSAs send compliance reports to the banks. If we ask for to many exclusions, the banks will stop allowing us to use them. I can convince my security team it's not an issue,I may be able to convince my QSA, convincing the banks is another story altogether. What it comes down to is that software vendors have a duty to make sure thier product passes compliancy testing for enterprise environments that they are used in. Even if we all know it's stupid. 
I know that EF implements repository and unit of work, I think is advisable to create an abstraction on top of that so if a change in data store is needed it will be painless to do so. But this is arguable and may be considered needless complexity. Are you suggesting to include the business logic that I am planning to put into BO into the view models themselves? 
No, please don't. Reddit is not an advertising platform. It's one of the few places I visit on a daily base to keep myself up to date. I need clear and distinct information and news, which my peers have voted for and commented using their expertise. That's what makes this place so precious. Please, no spam.
Lightswitch can do some UI generation. Only issue I have with Lightswitch is that it's very opinionated and sometimes edge case needs are way more difficult than they need to be.
Thanks for the suggestion! Is that all that you know of?
I normally do not allow my Presentation Layer to communicate with my Data Layer (even via a repo). Instead all Data Layer access is from the Business Layer. This ends up with the complexity of how do my PL and BL communicate? What objects are passed in to the BL if not the EF entities. There are a few different solutions that add complexity. My one suggestion is that if you are not going to push the PL -&gt; BL -&gt; DL access pattern then I would at least suggest only doing Mappings from View Modals to EF objects in the PL layer then pass the EF objects into the BL. In other words, don't do CRUD from the PL -&gt; DL. Instead go through the BL. 
Of course it's possible to find a .NET job without a recruiter. What makes you think it wouldn't be? *Most* recruiters just take public available positions anyway. And have you ever thought of an unsolicited application? That works too.
&gt; Do you know where to look for job postings by businesses only? No. You will have to wade through the shit to find gold. &gt; I had already thought about unsolicited applications but It seems like it might be tricky to find a tech company that needs an employee and that works in the .net space. Who cares about need. Make them **want** you. &gt; I suppose I would just have to call every tech company I could find a listing for on google maps. Call? Then better forget it. Send applications directly, just as you'd do with an open position. &gt; How would I go about identifying what companies in my town are even tech companies? ... Internet? Research? Show some initiative!
It is not just stupid. It is, as they point out in the article, potentially less secure to use a CA cert in this case. It is not an exception to any rule. There is no PCI compliance rule that applies to this case.
LinkedIn may be a bit of a cesspool of recruiters but if you ignore them, complete your profile there are actual companies using it to hire.
If you do go the boostrap route have a read of [this](http://www.helloerik.com/the-subtle-magic-behind-why-the-bootstrap-3-grid-works); really good visual explanation of the grid system. 
I have no problems with negotiations. In fact some people might consider me a little too aggressive. But what can you do when your one of the few type As in a type B field.
Ya I've been on LinkedIn for about 7 years. I keep it updated regularly but I keep it hidden until I'm ready to get a hundred million calls from recruitment. 
What you want is called WYSIWYG and has been more or less universally recognized as a Bad Idea^TM for like 15 years.
I have better luck with indeed.com I found my current job, which is .net in indeed. There is even a filter to exclude postings from recruiters.
First of all, stop using Monster. That place is a shit hole now. Dice is OK, but still not great. Here's my suggestion on how to find a job that you'll like. First of all, commuting has been scientifically shown to reduce happiness. So figure out how far you would feel happy (not just willing, but happy) to commute (for me that's less than a mile, but I live on the edge of a metropolitan city center, so I have options). Then do a business search and compare their offices to a map to see what is in your commute range. Then go to the website for those companies. They will almost always have a careers section. Put in an application. Most businesses which are not primarily an IT services business will be .NET shops. If you don't find some good prospects that way, then search instead for some local recruitment companies in that same commute range and set up an appointment to come talk with them. They generally have a lot more contacts in the area and most are happy to try to find you a position if they think you are marketable.
I did not know stackoverflow had a careers tab. Awesome man thanks!
I live in Denver so I have a good amount of options and I purchased my house equal distance between Down Town and Denver Tech District precisely because I knew the jobs would be in one or the other. What exactly is a "business search"? Is that a google maps option I don't know about or are you saying just type "business" and see what pops up? I think this sounds like a promising way to find a new position as I am very comfortable communicating. I've used a few recruiters and I find them to be lack luster in their job. They always call and say "I saw your resume and thought I had the perfect job for you! So.... do you have any of this dot nat experience? How long would you say you've done dot nat?" Listen here fucker, its on my god damn resume if you read the fucking thing instead of just cold called me from your database you ass hat! Sorry, little bit of rage there ;) 
Hey, I just searched through indeed.com and this was EXACTLY what I was looking for. Its going to be a huge help in finding the perfect job for myself. Thanks buddy I really appreciate it.
So I got, Monster, Indeed, StackOverflow Jobs, Dice. Any job hunting sites you guys post to that I am missing?
I know that rage man. I get emailed and called by recruiters all the time and they never seem to read my resume. The worst offenders seem to come from India primarily. Here's the thing about recruiters, they're trying to fill positions for companies that have not had luck filling them. So that generally means positions which have strange requirements and the recruiters aren't having luck finding people with those skills on their resume. So they start digging and hoping that they hit pay dirt with someone who didn't list something on their resume. The longer the position remains open the larger the payment is if they find someone. So after a while they can get pretty desperate. The reason I suggest local recruiters is because as opposed to the random call or email types they tend to have close ties to the local businesses and are as much interested in getting the business a good candidate as they are about getting paid, because they're investing in future relations. The random email and call types are usually going to just sell you off to a staffing company anyway once they find out that you meet the requirements. I work for a staffing/recruitment company that has an office literally 3 blocks away from where I work for the client. Both the staffing/recruiter and the client benefit from having good relations, and they both benefit along with me when we make a good match. The account manager for the client I work for is over at the client's office talking with HR usually once or twice a week. So, if you sit down with a local recruiter and you get a good vibe from them, it can be a boon to work with them. Of course there are also bad recruiters too, so be careful. Now, as for "business search" it depends on how you want to approach it. You can sign up for glass door or some industry groups and get emails about companies who are looking (the thing you get at Monster and to a lesser or greater degree at Dice is listings that do not say the company name. While glass door and industry mailing lists are specific about the company that is looking. You don't need to follow the links from there though, just search for the business name in google maps and see where they fall inside or outside your commute line. If they fall within then go to their website and fill out an application. Alternately a business search could be looking for businesses in a specific industry. For example, if you have prior experience working for a manufacturing or shipping company then you could search google maps for "manufacturing" or "shipping" and see what pops up. If you see something interesting, go to their website and check their careers section and see if they have an opening for a developer. Sometimes it's the quality of the job leads that you get over the quantity.
What I do is find the the job on dice/monster/etc and then apply directly to the company. 
Also, use BIMLScript if you choose to go the SSIS/SQL Agent route.
Have you considered going to local tech events? They are usually free, you'll learn new skills, meet people from potential employers and it speaks well of you to potential employers if you are taking your own time to improve your skills.
A partial view will do the exact same thing without all the fuss of a HTML helper. Create a partial view with the snippet of HTML that you gave above (remember to declare the model type in the top line) and save it to your Views/Shared folder (I called mine SpecFilter). Any place you want to render this HTML, call the line below (I will need to double check the syntax). @Html.RenderPartial("SpecFilter", model)
Some of us are still looking after legacy systems. :(
I'm a senior developer. Thanks though.
Have you ever put a resume with 5+ years of .net out there? The recruiters swarm like flies. If you are on this forum I imagine you've had the same issue. Its a bunch of recruiter companies that just have screen scrape scripts that look for any new resume's out there. They then parse the text of the resume stick it into a DB and you get stuck on their phone tree list for months.
thank you for your responses, I changed the SpecFilter method to accept this &gt; @Html.SpecFilter(Model.Select(m =&gt; m.proizvodac).Distinct(), m =&gt; m.proizvodac) I need it this way because I need it for this model several more times and also for other models. Thank you for your responses and time invested.
Nicely written
I'm not really sure why you would avoid recruiters. Sure, you might have to tell them to back off a bit, but it's not like they charge you for their services, and I don't think a recruiter is likely to negatively affect your chances in any given interview... The only reason to bypass a recruiter I've ever come across is if you have a friend at the company who could recommend you and claim the bounty for themselves.
&gt; Does anyone know if it is even possible these days to find a job without a recruiter? Just thought I'd add my experience, I'm testing the waters of the job market and all the non-recruiter postings I've applied to have not received any response back. Whereas recruiters have maybe a 20% response rate. My impression is that in-house hiring personnel have little incentive to spend time sifting through candidates. Third-party recruiters are more gung-ho and as you've noticed will not hesitate to message prospects on LinkedIn. Try emailing former coworkers, chances are better that way, however it can be slow. Recruiters typically can find a suitable vacancy immediately.
As some others have said, it's a really, really dumb idea to start thinking of ASP like it's winforms. Web pages are more dynamic and scalable than that. It's 2015, unless you have a damn good reason not to, there's not many reasons to not use MVC and Bootstrap if you've got a new ASP project (actually there are good reasons, but if you are asking this question then you aren't in a place where you would know when it was a bad idea).
If we put in that extra work item status that you want, would you stay?
Every now and then, one of those LinkedIn messages will be from a direct recruiter. You have absolutely nothing to lose from putting yourself out there. Source: Starting my new gig on Monday as a result of doing just this. It's my dream job.
No. You'll need to debug the problem :-) At the very least sprinkle some logging statements and you'll be able to see where it got to before failing.
(UK specific). I really wish people would find jobs directly. Currently, we're struggling to find good candidates, and we have to use recruitment agents. We really wish we didn't. Unfortunately for us, it's a candidate market and candidates can afford to be "lazy", where they can let recruitment agents do a big chunk of the legwork to get put in front of clients. We think we are not getting as many candidates in as we can because our vetting procedures are more thorough then other companies, and our recruitment agents are putting those candidates in front of more lucrative positions with a bigger guarantee of commission. It's a real shame because we believe we have a very valuable offering and a great environment and we always get candidates excited about the role. To me personally, it holds more weight if you come to us direct then instead of a recruiter. As already mentioned in this thread a lot of recruiters use a scatter approach, throwing enough shit at the wall so that ultimately something sticks.
Wait. Sorry, I may have phrased that wrong. I haven't found the reason of the problem. Its just that, because the modal pops up whenever I press enter on any textbox, any event attached to them doesn't fire.
I'm actually using ASP.Net Web forms. Yep, inside a form. That's what I'm thinking also but I checked and there is no event existing. I won't be able to update the code since it is weekend where I'm from and I don't have any copy of the code on my work pc.
He's not saying he's a senior developer at Mastercard 
Is there a company you want to work for? Go check their site and look for where you give resumes. Are they active in the open source community? Contribute to their repos. Are you blogging or speaking? Get on that. That will get you noticed. You start doing some of these things and companies come to you.
They don't "take" a % of your salary, they get paid a commission that is based on your negotiated salary as well as some conditions (like that you work there at least 90 days/1 year). It doesn't come out of your salary in any way, shape, or form. It's a one-time bounty that is paid based on your negotiated value (salary), usually around 10%. How does that logic even work? Whether on your own, or through a recruiter, your salary is negotiated and agreed to by you. A company is not going to agree to pay you any meaningfully higher amount in perpetuity based upon saving a once-off payment. I know this because I've been responsible for hiring. The only time I'd prefer a direct hire vs. a recruiter is if, say, two twins with exactly the same life experiences and education interviewed at the same time. I'd hire the direct hire then, I suppose. If the one through the recruiter were even a smidgeon better, or arrived a week earlier, I'd go with him. Finding qualified and competent candidates in this field is the hard part. The best-case I could imagine for a direct hire is that *maybe* they could negotiate a one-time bonus in lieu of having to pay a recruitment bounty. But, for the most part, the budget I'm given is for a given percentile of the average compensation. Like, we'll pay up to the 75th or 90th percentile of compensation in this area, although, obviously many places target the 50th percentile. I get frustrated about this because I know there are people like yourself who have this aversion, but then they do a terrible job of actually putting themselves out there on their own. And, those people are people I can't hire, because I don't know about them. This is *why* companies are willing to pay a bounty on top of your salary. It's worth the money to find somebody.
"btn-primary" is just used to select the correct rendering for the button, it has no meaning outside of how the button looks.
I think its visually identifying the action though rather than having any real technical meaning. Its still just a visual style. I think the new version of the documentation helps clarify this a little. http://getbootstrap.com/css/#buttons-options 
btn-primary is only the bootstrap css class. there is no functionality associated with it.
Submit on Enter is normal behavior so depending on what your goal is, I think you could try two things: * Set the tabindex property for the buttons so that the submit button is the lowest value. Also, check the order in which your buttons appear in the HTML. I believe that in IE, the first button is automatically treated as the default. * (Optional) Prevent the default action for your text inputs to allow returns (if that's what you desire). See http://stackoverflow.com/a/9671753/19487 for an example using jQuery to allow returns in TextArea elements. 
I'm in the UK so practises might be different (my company is US owned though and I've not heard of any differences in hiring policy from them) but the X-Y logic doesn't happen. Recruiters take a one off fee which means your logic would mean after a year everyone gets a pay rise, surely? This doesn't happen. Instead salary ranges are agreed first, then an agent is approached (their second question after "is my fee OK" is always "what is the salary band for this role"). Recruiters cost money, yes, but they do work for it. A recruiter talks to candidates, they check their backstory, they tell the candidate about the commute, they check their qualifications (the good ones do anyway), they handle all your rejections (the absolute worst part of recruiting), they arrange two way availability, they call candidates out of hours, they often meet candidates to check their personal manner, they handle "off the books requests", they coach candidates, and most importantly - they filter out bad candidates. This costs around ~ $8,000 for an average developer which is really nothing in the grand scheme. It's also usually guaranteed for 3 months if the candidate leaves. Direct applicants are 90% of the time just chancing it and I can get 100 applicants in a week for a C# role. With a recruiter, THEY get the applicants and I get 10 carefully chosen people I can get excited about. Definitely worth it. But if you're careful, and one of the 10%, go for it - but don't be surprised if you are forced to go via an agency. 
I'm in the UK too (and a hiring manager). Get a better agency! Seriously, if they are withholding candidates or more interested in money than service go to someone else. Plenty of IT recruiters who aren't as bad as that. 
As I've said elsewhere. I've gone through recruiters twice so I won't cry a river if I have to do it once again. I just wanted to make sure I understood all my options. This thread has been extremely helpful though!
Post the html for your form tag, textbox, and submit button 
I'm new to the recruitment role and so far I've been handed a PSL of recruiters to work with. We're based in Yorkshire. If you have any agencies you would recommend, I'd love to hear more.
On a slow day - sure.
Yep they are. The form is in a master page. Since i'm using webforms, the default format of the project is like that. 
I work with Excel a lot, and fwiw, here is the code I use to detect the type of cell content. It's for use on a single cell. Also, it uses a trick commonly seen in VBA with .Value and .Value2 to detect whether it's a Date or Number. public static CellType GetCellType(Excel.Range cell) { CellType cellType; if (Convert.ToBoolean(cell.HasFormula)) cellType = CellType.Formula; else if (cell.Value2 == null) cellType = CellType.Blank; else if (cell.Value is double || cell.Value is decimal) cellType = CellType.Number; else if (cell.Value2 is double) cellType = CellType.Date; else cellType = CellType.Text; return cellType; } // related enum public enum CellType { Blank, Date, Formula, Number, Text } &gt; Microsoft needs to get their shit together for interop I develop COM add-ins for Excel, so I have to jump through all the hoops. But, if you're accessing Excel files externally, I've heard good things about the NPOI tools: https://github.com/tonyqus/npoi 
Agreed. And you have functions built into the library to convert raw cell values to whatever format you need.
I used interop quite a bit for a project a few years back. After messing around with that unstable piece of shit, I came to the conclusion that if you just read everything into a DT and then populate internal class models, that's the easiest way to manipulate your data. And don't forget to kill the app 5 different ways for it to be removed from your task manager.
If you talk shit about your last company, odds are you will talk shit about your next company too. That's something that recruiter (or anyone interviewing you) knows.
Yeah, I chose NPOI for our large production app. It's free/open source and did everything we need and more for spreadsheet generation and spreadsheet processing.
I am just learning .net and saw that question on SO and was interested to know if it was possible. I will play around and try your method tomorrow. TY!
http://stackoverflow.com/questions/12010511/get-the-key-for-a-strongly-typed-model-in-the-controller/12011305#12011305 ?
FYI there's nothing worse than saying "it doesn't work" when reporting an issue. Is there an error message displayed and can you post it *exactly*? That would help immensely to track where the error is occurring (especially if the dev doesn't have .Net 4.5). Edit: the last commit was 3 years ago, so you may not get much of a response.
Recommend getting in touch with /u/ayematey (original coder who's still active)
I will work on porting it. I will put a github if I can get it to work.
Just FYI: for /u/ayematey, the offending line is in Reddit.Client.cs, line 111: System.Net.Http.Formatting.MediaTypeFormatter.SkipStreamLimitChecks = true; for some reason throws an exception when targeted to .Net 4.5 or above.
&gt; SkipStreamLimitChecks Maybe I'm missing something, but I don't see that property in the API Reference: https://msdn.microsoft.com/en-us/library/system.net.http.formatting.mediatypeformatter%28v=VS.118%29.aspx 
I believe it was coming from a System.Net.Http.Formatting nuget package: &lt;?xml version="1.0" encoding="utf-8"?&gt; &lt;packages&gt; &lt;package id="System.Json" version="4.0.20126.16343" /&gt; &lt;package id="System.Net.Http" version="2.0.20126.16343" /&gt; &lt;package id="System.Net.Http.Formatting" version="4.0.20126.16343" /&gt; &lt;/packages&gt;
Ok, try this one: https://github.com/celluj34/CleanModQueue/releases/tag/v0.1
You just ported over something for a random person? You're awesome :)
I mean, it was already in C#, and the fix was ultimately a single line. Granted, there's no guarantee it will continue to work, but I never said I would do that much ;)
Why not just use an item template? I also believe that you can have conditional templates based on object type. I dont think adding this programmatically is going the be the easiest path. 
Usually, yes, but in this case he has adequately identified that it seems to be an issue with NET 4.5 , there is no more detail really needed. Presumably they are using a deprecated call. The dev would HAVE to install 4.5 in order to recompile and debug it, something that they should have done anyway. If website devs are expected to retest against new waves of browsers, Software/app devs should also test against the basics like new OS versions/framework versions.
1) javascript is a shit language in it's current form with no stable frameworks, everything breaks every year. 2) currently mostly no, in the neear future yes. 3) only if you are masochist 4) phonegap is a wrapper for js devs to use html to build "native" apps , xamarin is a company that enables you to write C# on mac/ios/android/linux 5) there is a right tool for the job, and these days most programming languages can do most things. C# apps don't requre iis, asp.net apps can run on IIS and as self hosted (no iis) azure is just an enviorment wher eyou put your app. dosktops won't die for developers, that's the most productive place to write software untill we get to the point where you can hook up your phone/tablet to an external monitor an have the same horsepower (~5-10 years from now) 6) you can learn either and you will be good for the future. it's not about the cost of the platform but the tools it provides you with and the productivity you get out of it. Companies (medium-large) don't care if they pay extra 100k for licenses. 100k for licenses is equal for 1 developer year ( if in the us), if this saves your 100 developers 10% time &amp; effort overall, it's money well spent. Mostly individuals and smallish companies have troubles with licenses for windows server/sql server. However if youa re using a cloud service, those prices are included in the price you pay. 
I agree, create an item template and bind your combo box to a collection rather than doing this through code. WPF was built to follow MVC
I agree completely. I've been using Mono on Linux for well over a year and have no problems whatsoever. It's not even much effort to install. My only concern is the lack of an eco system but that doesn't invalidate the answer - you can currently successfully run ASP.NET applications on Linux easily.
Community contributions are important as long as they are not spam. This would be my suggestion: * Yes * Yes, but only if it's informative too! * In a weekly thread + you can ask for feedback * In a sticked thread? Are there that many job postings?
&gt; 1) Can C# compete well againt all the framework out there because everything seem to go Javascript theses days for backend and frontend why is that ? is JS really better or faster ? stuffs like node.js etc One reason for this would be shared codebase between the frontend &amp; backend. Doing view stuff on the server kind of sucks, whatever platform/framework you choose. Whether or not "isomorphic/universal" JS turns out to be better for this I'm not sure, I haven't tried it myself yet. For the short term, I see more view code being moved to the client-side, with the server side being trimmed down to a webservice API wherever possible. Anyway, .NET is used a lot in corporations and isn't going away anytime soon. Most likely startups are the companies that chase the latest/greatest thing, so I suspect Ruby &amp; Python are the ones losing out to Node/JS.
still doesn't work I'm afraid :( All I get is: http://i.imgur.com/HQ4MSjX.png whether I run "normally" or as administrator. I've checked with 2 confirmed working Reddit IDs. The registry says I have this .Net installed: http://i.imgur.com/sffD6GH.png (from https://msdn.microsoft.com/en-us/library/hh925567(v=vs.110).aspx) I don't know what else to add, but I KNOW from experience that if I install 4.5 in windows 7, I immediately get this same login error, &amp; as soon as I uninstall 4.5, the program immediately works again
&gt; Also in this case. It's fine that he identified (or believes so) .NET 4.5 as the culprit, but that's all. Why doesn't it work as intended? What happens, what is expected to happen? Does the program just crash at start? I don't know what else to add? All I get is: http://i.imgur.com/HQ4MSjX.png whether I run "normally" or as administrator. I've checked with 2 confirmed working Reddit IDs. The registry says I have this .Net installed: http://i.imgur.com/sffD6GH.png (from https://msdn.microsoft.com/en-us/library/hh925567(v=vs.110).aspx) but I KNOW from experience that if I install 4.5 in windows 7, I immediately get this same login error, &amp; as soon as I uninstall 4.5, the program immediately works again (as in logs into my reddit account &amp; starts processing the modqueue of the subreddits I moderate in) &gt;Also he can look at the event log. Most likely this is an uncaught exception - this will appear in the event log. Tada, already much more information than "doesn't work, probably .NET 4.5". You'll have to excuse me, but I'm not a coder. Do you mean Windows Event Viewer? I don't know where to look for that info
1) Depends on where you live. Where I am, Node is a footnote at best and no one has even heard of IO. C# and Java are really the only games in town. 2) Yes, for the most part, currently. Mono has some caveats but works well. CoreCLR, .Net Core, etc. is going to be 1.0 released some time early next year by the sounds of it. That said, you can use it now without too much trouble. It will be Windows, Linux, and Mac compatible. 3) Possible, yes. The reason people complain about JS for big projects is because of things like the lack of decent modularization, etc. The new additions to JS are supposed to fix this issue but will take time for browsers, frameworks, etc. to support them. 4) It depends on what you want to do with your app as to which framework is best for you. If you're doing a CRUD style app then Phone Gap works well. Want to build a game? Probably not the best choice then. 5) Short answer: use what you want. Languages and frameworks today are pretty much interchangeable for the most part. 6) Java is a viable platform/language to learn. The reason it is popular is due to a number of reasons. First, many large companies settled on it as their standard language in the late 90s and early 00s. Changing to another language is difficult when you have thousands of devs and millions of lines of code. On top of this, many universities picked this as the language to teach and use it in their curriculum. On top of this you have companies like Google who brought it back from its slow death spiral into the limelight with the Android OS. So we have tons of companies using it, tons of new devs coming out of school that know it, and on top of that you have various projects that picked it as the base programming language for their systems. So that's some of the reasons that it's popular. There are more but that's a couple of them. As far as your other question of will Java die: yep. All languages die. Java will die, C# will die, JavaScript will die. In the cases of Java and C#, it will be a slow death but it will happen at some point. As far as costs and opening up of C#/.Net, I can develop .Net apps now for about $0 using Mono. I can do the same for Java. Going to .Net Core just changes what I'm targeting. Doesn't really change much in terms of cost.
**1) Libuv** Node.js uses libuv. Kestrel (an ASP.NET 5 dev server) uses libuv. **2) Taskrunner** ASP.NET 5 uses grunt/gulp from node as it's main task runner. You can use bower, too. **3) Modularization** Only take what you need. Node.js you have npm. ASP.NET 5 you have NuGet (and npm). ASP.NET 5 won't target a specific .NET framework anymore but instead packages (NuGets). The .NET framework is currently translated into small packages that you can grab. (see: .NET Core) **4) Host agnostic** It's not bound to a specific server or OS and is self hosted. **5) Middlewares** Similiar to express.js middlewares you have middlewares in ASP.NET 5. 
At this point, I would say it's probably time for a rewrite, but I don't know how it works otherwise I would gladly. I'll probably defer to the original dev to see if he can figure it out. I'll add, I did try logging in but gave me the same error. I chalked it up to me putting in the wrong password and went on my way.
Hello. I believe I have fixed the issue, it was simply missing a reference. Please try this: https://github.com/neoKushan/CleanModQueue/releases/tag/2012.7.31.0_Logon_Fix (I forked /u/celluj34's code on Github, he probably deserves credit as well, if nothing else for putting the code on github but he also made tweaks to the code).
No it's one of the draw backs of c#. Sorry
It's not really a "vs", both are different things :) Libuv is for highly concurrent **IO-bound workloads** while async await is **syntax sugar** for asynchronous task based operations that are not limited to a single thread. Great combination tbh. If you didn't know but node.js is **single-threaded** which makes it not that great for CPU-intensive tasks. If you don't circumvent this, it will block your other connections. However most websites don't have such big tasks and V8 is really good at making JavaScript fast. I'm not sure what libuv uses under *nix or Windows, sorry. 
Could you provide an example of how someone would go about this?
I'm so glad to see more and more responses like this. My last job kept insisting that putting libraries in the GAC was the way to go.
Did you click on his example link? :P
Yeah it's pretty straight forward, you can map your sql query result to an object, using something like dapper for the SQL access. Then you can add which ever fields you wish to the drop-down. Go research dapper and linq. You will start doing some amazing things when you get in the flow. 
That's awesome to know.
I haven't really used it, but some quick reading indicates that it's good at supporting multi-threaded asynchronous event-based processing models. It's not great at distributing load, so anything CPU bound is still gonna melt the server, but it is good at solving IO bound problems. So... I guess it has a place in the world of web servers. That said, I fail to see how it will really make anything better for anyone except the "Javascript everywhere" crowd. Throw some NoSQL on there and it will be barely usable in any OLTP environment typical in a normal enterprise. Better hope your problem domain fits the social network model I guess. I guess that reveals my biases though... ;)
Hey OP - I know this is the worst kind of advice because you didn't ask for it, but I think you're going down a dangerous path here. It looks like you're implementing your own cookie based authentication system and storing sensitive information in plain text in the cookie. This is dangerous because it's trivial for a user to manipulate the cookie and do nasty things like potentially escalate their privileges in the application. I'd recommend you take a look at [ASP.NET Identity](http://www.asp.net/identity) or [Forms Authentication](https://msdn.microsoft.com/en-us/library/ff398049(v=vs.100\).aspx) if you're looking to implement authentication. Security is worth doing right the first time. edit: fix URL
WTF dude. A correctly working app that I contributed freely to the community, which has worked for 3 years. Which you were able to modify because the code was released and actually builds? god-awful? What are you talking about? Are you the kind of person who, when his daddy gives him a 4 year old BMW, says "But it doesn't have a satellite radio subscription, Dad!" ? 
Okay, I'll bite. I'm not trying to downplay your contribution to the community. You wrote an app that people obviously use and find useful and you were kind enough to open-source it - make no mistake, that's a great thing and you should be proud of that. However, when I say that the code is "God-awful", I mean that the code is bad and I stand by that. It's bad code. I shouldn't have been so harsh but this thread had been open for nearly 24hours and I didn't notice you had replied to it, so for that I apologise. However, I'll give you some examples of why the code is bad: The first thing to mention is really prudent, as it's the reason OP couldn't give a more meaningful error and why the true issue with the tool not running on .net 4.5 was hidden: try { var task = client.PostAsync(redditLoginAddr, msg); task.Wait(); var t2 = task.Result.Content.ReadAsAsync&lt;Dino.Reddit.Data.LoginResponse&gt;(); t2.Wait(); result = t2.Result; if (result != null &amp;&amp; result.json != null &amp;&amp; result.json.errors.Length == 0) userHash = result.json.data.modhash; else userHash = null; } catch { userHash = null; } You caught all exceptions and then did nothing with them. Had you at least displayed the exception, or logged it, or *something* then anyone using the tool would have seen that the issue was a missing assembly (JSON.net). They might have even been able to fix it by downloading the necessary .dll. It would have actually been better to not catch anything here and let the normal .net exception window display something. You could have just added "throw;" and it would have set the userHash to null and still displayed the exception window. This is a huge, huge flaw and a really bad practice. When your app starts up, it hangs for...ages. Like 30s on my machine and I suspect it's because you do this a lot: var task = client.PostAsync(addr, msg); task.Wait(); It looks like you're trying to write asynchronous code here, but this isn't async. It's things like this that cause your application to hang for unspecified amounts of time. If you'd just used the await keyword (And marked the method async), then it would have been nice and asynchronous and a much better user experience. Perhaps this was down to only supporting .net 4, but using the BCL library from Microsoft, you can still write async code. Some of your method names leave a lot to be desired. MaybeLoginAndGo()? Or even just the name of your Main form? Application.Run(new Form1()); In fact, the fact that you only have a single monolithic "main" form is also not great. There's a lot of functionality that could be split into user controls, there's a lot of utility methods that could do with being in a separate static class and there's a lot of code in the event handlers that really should be in their own classes. But please, understand that I'm not trying to be mean or harsh here, I'm simply trying to give constructive feedback to you. Your code reeks very much of something that was written as someone was trying to learn C# - and that's ok! There's nothing wrong with that and we all have to start somewhere, but if 3 years later you can still look at that and not see any flaws, well, that's worrisome. I'm a manager for a team of developers for a smallish company. We have bad code, too. We have a lot of bad code, some of it not dissimilar to your code, some that I even wrote myself. It happens. As long as you can look objectively at your own code and see ways it could be better, then you'll be a good developer. If you can't, well.... Anyway, sorry if I caused you offence, it was not intentional.
It's going to sound silly but have you tried "var _cookie = new HttpCookie ("cookiename") { Expires = DateTime.Now.AddDays( - 1 ) } ; Response.Cookies.Add(_cookie); RedirectToAction(Index);" This is what works for me in my controller. 
It's a plain ol form *facepalm*. 
Oh, OK! Thanks! To answer your questions, I think so, yes, no. This is the first time I've seriously worked with OOP, aside from a brief lesson in Java I had at university.
* Yes * No, I'm paranoid about upvote bots trying to keep their advertisements on top.. * No * While this would be nice, I'd prefer a separate subreddit for it. 
&gt; How do the "parts" get their configuration? Does the tool save config updates or is it read only? The tool does everything, it's essentially a huge GUI for making changes to these configs (then later on it processes data based off of the config). The configuration file could be described as a document, you open it in the tool, make your changes and save it. &gt; One idea can you create a tool to convert the configuration to/from something more file diff friendly? a flat text file (e.g. /xml/part1/settings@attribute=value ) Possibly, I never considered the XPATH style. I might have a tinker. &gt; Could you move the configuration to a database (such as sqllite) - I'd probably user triggers to record changes made in an audit table. Hmm. We could move the configuration to anything really, we don't mind reworking the tool as most of the effort is in maintaining the config files. I'm not too familliar with SQLite though, I wouldn't have thought that is version control friendly? Can you elaborate a bit more?
Dapper is an object relational mapper (ORM), it just maps your sql data set back into an object or a list of objects. It's not the only one, but it's the most popular lightweight one, and its made by Stack Exchange (stack overflow) so it has a decently large company backing it. It's not the only way, In my other post i mentioned doing it via *for-loop* which is close to the same thing. ORM's just cut out that step for you. 
In my experience, XML is already one of the better formats when it comes to merging, as long as it's pretty printed and stably sorted. Popular alternatives tend to rely on seas of braces (JSON) or meaningful whitespace (YAML), neither of which is fun to work with in my opinion. At least when looking at a fragment of XML you can get an idea of the context without counting braces (assuming a decent schema). Splitting the files sounds like a good plan to me, that makes the diffed files smaller and multiple changes easier to separate. Is there no way to do it automatically (one file per control or data section or whatever)?
Oh OK, thank you very much. So, just to see if I'm understanding you correctly, I need to: 1. Create a class 2. Somehow populate the class using a for-loop 3. Link it to the dropdown Then it should only be showing the first column but using the second?
Yup! Using the method linked by /u/AStrangeStranger above, you can define what fields from the class you want to use as the value and display.
I missed the fact that there were links. I'm ridiculous. Thank you very much for your help :)
tbh I don't use either SqlLite (but seems better than full dbfor task) or Entity Framework so don't know - but a quick google returns - [link](http://erikej.blogspot.co.uk/2014/11/using-sqlite-with-entity-framework-6.html)
By the sound of it, XML is one of the problems but so is the size, and I am inclined to suggest that you can look into breaking the file into several config files, where settings are logically grouped (say control's configuration in one, static dictionaries in another etc). You may find afterwards that some files tend to change more frequently than others. Also, what do you use for source control?
This doesn't answer the question you asked, but I've had to deal with these issues before, and here is how I solved it. XML is **highly** compressible. Your 20mb xml file will compress down to a few kilobytes. Since you already have a tool that edits the XML and your production application already preprocess the XML and turn it into binary. I would suggest the best course of action is to modify your configuration utility to unzip the file before ingesting it, and rezip the file after making a change. Then modify your production app to unzip the file before doing it's preprocessing work. Since the zipped file is so small you can just indefinitely retain every version of the configuration. Granted, this does nothing to solve your problem of doing diffs in source control, but maybe it's not important anymore because you can save literally every edit ever made and compare them in a diff tool manually if there is ever a need. 
I have found that beyond compare does a pretty good job of digging xml. Also do whatever you can in your tool to always write the nodes in the same sequence. Ie, your data should not be stored in a sorted sequence, if new elements are added they should be at the end. Sorting should be applied at the UI level if needed. If you find deleting elements causes your diff to go bad, perhaps you should just introduce a "deleted" attribute which will keep that element around until a given cleanup check-in. If you have large scale schema changes happening, well that's another beast. Ymmv in this case.
It doesn't sound like the problem is xml or the size of the file. It sounds like the problem is that when you output a dictionary into xml the keys aren't in stable order. So a single new key could result in drastic order changes. It may be that all you need to do is ensure that the order of elements in the xml tree is stable.
Can you explain what you mean by data tier application? Normally, we think of tiers as in display-tier, business-tier, data-tier. So the term "data-tier" means something in an architectural sense. The data tier may consist of a database, but does not have to; a data tier could be something as simple as a text file.
This sounds like an interview question.
&gt; Why does he have "data dictionaries" in a config file? Without giving too much away, the tool is essentially a generic message processor. Messages from different specs and protocols can be fed into it and it'll generate a response that has things like valid cryptographical calculations and such. The messages can contain hundreds of unique "tags" of various lengths and formats so we need a dictionary to look their properties up, but the tags aren't the same between protocols so we can't just have a single flat dictionary across all configurations. &gt; Also "thousands of controls" shouldn't be 20+ megs. That would depend on the size of the control. I don't mean form control, I mean configuration control that dictates how it handles an incoming message and how it responds to that message. &gt; Break it up so it make sense and easy to work with in development. I think this is where I'm heading at the moment and it should be easy enough to break up the configuration into logical components.
[removed]
If I understand you correctly: Data Tier Application (DAC): * Contains database schema * Contains DAC specific objects (pre and post deployment scripts, for example) * **Does Not** contain data Database: * Contains data * Contains schmea * **Does Not** contain DACPAC specific objects Thanks for your description.
A data tier application is basically a database catalog with some metadata attached that contains the version number. Personally, I will not make a database any other way. It makes things really easy and you can do everything in visual studio instead of using ssms, which is basically vs anyway.
So I naturally wonder what sort of issues you have when merging files with Git? XML should be fine as far as the readability goes (unless you're storing heap load of stuff in Base64 encoded blobs or something similar). Given, if it's a huge file and there's many people changing it chances of conflicts are increasing, so might be worth splitting it into several files, as suggested above.
You're spot on. Can you recommend any good differ engines that can do this?
Actually, if you get the data from the database in form of a DataTable or DataSet you should be able to databind those directly to the ComboBox via its DataSource property. You'd then just set the DisplayMember and ValueMember to the column with the display data (what the user sees as items in the ComboBox) and the value data (the *actual* value for each item in the ComboBox). Assuming you read from a table with the columns "id" and "name" it would look something like: ComboBox1.DataSource = dataTable.DefaultView; ComboBox1.DisplayMember = "name"; ComboBox1.ValueMember = "id"; That way the user will see the data from "name" as items in the ComboBox and when a selection is made you can extract the appropriate "id" value with ComboBox1.SelectedValue The way you intend to do it will absolutely work as well, but this way you save yourself the additional step of iterating over the whole dataset and don't need to create the extra wrapper class.
Wow, the number of completely unhelpful people responding here is pretty insane. Basically, you have various tiers of applications User Interface, Business Logic, Data, are the common ones. Therefore I believe in this case they mean when creating a solution in Visual Studio you would have a different application within the solution for each tier. The data application would be the one which encompases talkint to the database so your business logic layer does not need to know how. It should simplify maintenance and support in the future if you don't have to change business logic functions to reference a new database if you need to change it.
One is an application The other is a database They're totally different in every conceivable way ....apples and oranges. A data-tier application , presuming I understand your terminology correctly, is an application that contains a data tier. This would be a library that is called by, for example, the business logic tier of the application in order to perform data operations. For example, it would contain methods to read or write to a database , service, etc. The business logic would call, for example, myAppDAL.GetCustomer(12); And the data access layer would supply the customer data record. A database is a data store of all of your data, possibly including some basic programming (stored procedures etc) but is essentially just the place that your data is held and some rudimentary associated functionality. Your application will get it's data-tier to get data from the database.
We're just starting on that road. Except we're looking to migrate from a bunch of Winform apps to a nice, solid MVC application.
can you render inside some kind of wysywig editor? like http://getuikit.com/docs/htmleditor.html just disable the toolbar. the basic is you assign the htmlbody into a textbox and link the textbox to the htmleditor via javascript. there are instructions for that specific editor that I linked to above. regarding security, .net will automatically encode strings if you assign it to a textbox.
This is a dangerous thing to attempt by yourself. The problem of safely and securely sanitizing email is much harder than I think you realize. I'd look for a library or a standard way of doing this. I'll have a look around and report back if I do happen to find something.
in ASP.net MVC 4.5 I just right click on the Models folder and then add in Entity framework. All that has gone in the new version, with no links that I can find to add it in. (Link is just a placeholder as it wanted one)
I am using EF6. Its usually an option off the Add New Item menu. How are you adding it to the project now? Just reread your post, I see how you did it now :-)
Thanks for that :-)
What are you using to render the HTML? A WebBrowser object should do that. Email HTML rendering is very tricky to do safely. There is a reason its such a pain in the ass to do. To send web emails to be readable in Outlook you still have to use tables!
If this is a Web project render the HTML in an iframe, css is allowed and the last thing you want is for an email to interfere with your web design Attachments are attachments and should be fetched as such I.e. when the end users wants to download them. I belive if you get embedded image of type CID it comes in as an attachment. Most clients display them both as attachment and inline Most email servers strips out embeded objects like flash. It also strips out javascript. You can run some sanitizer ion process to remove them if they exists images come in as either a http link, base64 embedded image or an embedded CID image. To display the CID embedded image you will have to get base64 string and put it in the src property of the associated img tag just like how base64 encoded images are put in. if Security is an issue you can ask user to allow display images and then display it. These are just the few things I learned when parsing incoming email through postmark service
The option didn't appear for me, I don't know why. So I thought this was a sub where you can only post links, some are like that. 
Actually, I'm glad you posted the link...I enjoyed it.
There's no Visual Studio on Linux though. That's pretty much what keeps me Windows-bound. 
https://www.microsoftvirtualacademy.com/en-US/training-courses/introduction-to-asp-net-5-13786?l=dbzfk6pXB_7901937557 had to hack that link up, because i couldnt get the training course to link directly to the EF part Heres a hanselmann post on the course: http://www.hanselman.com/blog/FreeTrainingAtMicrosoftVirtualAcademyIntroductionToASPNET5.aspx 
&gt; Should we allow job postings? Since subreddits can now have two sticky posts, you could use one for a monthly "who's hiring" thread.
My [MimeKit](https://github.com/jstedfast/MimeKit) library includes an HTML tokenizer and HTML-&gt;HTML converter that allows you to strip tags and their content. To "render" a message as HTML, you can use the following code snippet as a starting point: /// &lt;summary&gt; /// Visits a MimeMessage and generates HTML suitable to be /// rendered by a browser control. /// &lt;/summary&gt; class HtmlPreviewVisitor : MimeVisitor { List&lt;MultipartRelated&gt; stack = new List&lt;MultipartRelated&gt; (); List&lt;MimeEntity&gt; attachments = new List&lt;MimeEntity&gt; (); readonly string tempDir; string body; /// &lt;summary&gt; /// Creates a new HtmlPreviewVisitor. /// &lt;/summary&gt; /// &lt;param name="tempDirectory"&gt;A temporary directory /// used for storing image files.&lt;/param&gt; public HtmlPreviewVisitor (string tempDirectory) { tempDir = tempDirectory; } /// &lt;summary&gt; /// The list of attachments that were in the MimeMessage. /// &lt;/summary&gt; public IList&lt;MimeEntity&gt; Attachments { get { return attachments; } } /// &lt;summary&gt; /// The HTML string that can be set on the BrowserControl. /// &lt;/summary&gt; public string HtmlBody { get { return body ?? string.Empty; } } protected override void VisitMultipartAlternative (MultipartAlternative alternative) { // walk the multipart/alternative children backwards // from greatest level of faithfulness to the least // faithful for (int i = alternative.Count - 1; i &gt;= 0 &amp;&amp; body == null; i--) alternative[i].Accept (this); } protected override void VisitMultipartRelated (MultipartRelated related) { var root = related.Root; // push this multipart/related onto our stack stack.Add (related); // visit the root document root.Accept (this); // pop this multipart/related off our stack stack.RemoveAt (stack.Count - 1); } // look up the image based on the img src url within our // multipart/related stack bool TryGetImage (string url, out MimePart image) { UriKind kind; int index; Uri uri; if (Uri.IsWellFormedUriString (url, UriKind.Absolute)) kind = UriKind.Absolute; else if (Uri.IsWellFormedUriString (url, UriKind.Relative)) kind = UriKind.Relative; else kind = UriKind.RelativeOrAbsolute; try { uri = new Uri (url, kind); } catch { image = null; return false; } for (int i = stack.Count - 1; i &gt;= 0; i--) { if ((index = stack[i].IndexOf (uri)) == -1) continue; image = stack[i][index] as MimePart; return image != null; } image = null; return false; } // Save the image to our temp directory and return a // "file://" url suitable for the browser control to load. // Note: if you'd rather embed the image data into the // HTML, you can construct a "data:" url instead. string SaveImage (MimePart image, string url) { string fileName = url.Replace (':', '_').Replace ('\\', '_').Replace ('/', '_'); string path = Path.Combine (tempDir, fileName); if (!File.Exists (path)) { using (var output = File.Create (path)) image.ContentObject.DecodeTo (output); } return "file://" + path.Replace ('\\', '/'); } // Replaces &lt;img src=...&gt; urls that refer to images // embedded within the message with "file://" urls that // the browser control will actually be able to load. void HtmlTagCallback (HtmlTagContext ctx, HtmlWriter htmlWriter) { if (ctx.TagId == HtmlTagId.Image &amp;&amp; !ctx.IsEndTag &amp;&amp; stack.Count &gt; 0) { ctx.WriteTag (htmlWriter, false); // replace the src attribute with a file:// URL foreach (var attribute in ctx.Attributes) { if (attribute.Id == HtmlAttributeId.Src) { MimePart image; string url; if (!TryGetImage (attribute.Value, out image)) { htmlWriter.WriteAttribute (attribute); continue; } url = SaveImage (image, attribute.Value); htmlWriter.WriteAttributeName (attribute.Name); htmlWriter.WriteAttributeValue (url); } else { htmlWriter.WriteAttribute (attribute); } } } else if (ctx.TagId == HtmlTagId.Body &amp;&amp; !ctx.IsEndTag) { ctx.WriteTag (htmlWriter, false); // add and/or replace oncontextmenu="return false;" foreach (var attribute in ctx.Attributes) { if (attribute.Name.ToLowerInvariant () == "oncontextmenu") continue; htmlWriter.WriteAttribute (attribute); } htmlWriter.WriteAttribute ("oncontextmenu", "return false;"); } else { // pass the tag through to the output ctx.WriteTag (htmlWriter, true); } } protected override void VisitTextPart (TextPart entity) { TextConverter converter; if (body != null) { // since we've already found the body, treat this as an // attachment attachments.Add (entity); return; } if (entity.IsHtml) { converter = new HtmlToHtml { HtmlTagCallback = HtmlTagCallback, FilterHTML = true // this will strip any script tags and their content }; } else if (entity.IsFlowed) { var flowed = new FlowedToHtml (); string delsp; if (entity.ContentType.Parameters.TryGetValue ("delsp", out delsp)) flowed.DeleteSpace = delsp.ToLowerInvariant () == "yes"; converter = flowed; } else { converter = new TextToHtml (); } string text = entity.Text; body = converter.Convert (entity.Text); } protected override void VisitTnefPart (TnefPart entity) { // extract any attachments in the MS-TNEF part attachments.AddRange (entity.ExtractAttachments ()); } protected override void VisitMessagePart (MessagePart entity) { // treat message/rfc822 parts as attachments attachments.Add (entity); } protected override void VisitMimePart (MimePart entity) { // realistically, if we've gotten this far, then we // can treat this as an attachment even if the // IsAttachment property is false. attachments.Add (entity); } } This is the same snippet found on http://www.mimekit.net/docs/html/WorkingWithMessages.htm#TraversingMessages except that it also sets the `FilterHTML` option on the `HtmlConverter` to `true` in order to strip any script tags from the input, making it safer to render. 
The next time you find yourself having to do this, consider using my [MimeKit](https://github.com/jstedfast/MimeKit) library - it will make your life incredibly easy.
http://ef.readthedocs.org/en/latest/getting-started/aspnet5.html The Ef7 docs have a great step by step getting started guide
So far I have been really impressed with all the work done on readthedocs for EF/Asp.net. Can't wait until the final releases
Perhaps if we can figure out what's it's supposed to do we can make a better one :)
No prob!
Perhaps! I suspect the issue is just how it's parsing JSON at the moment, but you're right, if there's no alternative to this, then perhaps one should be made.
I would recommend trying to pickup Bootstrap as it's widely supported and has pretty decent documentation. Aside from that you really should learn HTML and CSS as they are very basic and will benefit you greatly. If you don't understand those you're going to have a bad time most the time unfortunately.
What exactly about HTML/CSS are you having trouble with? I don't know every single detail about how stuff moves around in HTML/CSS, but I understand enough to do what I need to do.
Try code academy for some quality, basic, hands-on learning. The focus some time on just creating pluasing UI with HTML and CSS only, leave MVC and .net out of it. Once you have your hands around it, come back to MVC and use what you've learned.
Cool, glad to help. There are also more advanced ways of using the grid system, when you get into the different column sizes and media queries and stuff. To be honest, I don't really understand that stuff very much and never use it. I always use the medium column size like in my example above (see "col-md-6", that "md" is the medium I'm talking about). I write Xamarin apps for mobile users, so I'm not overly concerned with having my Bootstrap optimized for mobile.
Pluralsight has some good tutorials on asp.net MVC and Bootstrap. It's a subscription service $$. But you can sign up for free trial and this might be enough time to help you. You get access to tutorial files. The one with Jesse Liberty (sp?) Really tears a part a Bootstrap based template. There are newer tutorials that combine EF for crud sites. The channel 9 / ms virtual academy hanselman videos have some good demos that cover it too. And as others have said, the official Bootstrap site is a great resource too.
Create an empty solution. Add an MVC project and a class library project to the empty solution. Build your database classes in the class library. In the MVC project, add a project reference to the class library project. 
You may want to try using the chrome dev tools, any browser will work but I think the chrome tools are best for what I'm about to suggest. Fire up a default project in visual studio or go to any website you like. In chrome hit f12 or right click on anything on the page and choose inspect element. This will open the dev tools panel. You will immediately see the hierarchical structure of the html. Another section shows all the css rules that apply to the currently selected html element. Any of these values can be changed right in your browser, though they are temporary and only affect your view. Have fun experimenting with changing styles to see what happens. I use this technique all the time in my web projects. Once I have it the way I like it, I add it to my code. Huge time saver over experimenting and refreshing constantly. I would highly recommend checking out Microsoft virtual academy also. They have tons of 100 level courses on html css and javascript and its all free. Good luck!
This. You might be trying to take in too much at once. Learn html and css first then learn how it fits with mvc.
Powershell, or any CLI shouldn't be creating windows.
Another cool regex reference for visualization: http://regexper.com/
but this not a ".net regex" :)
I use regular html for the most part now. Too many elements have custom attributes that are a pain to inject into the html helper. Moreover, it will make the move over to angular or some other front end data binding framework much easier.
&gt; Single developer and PCI compliance Can't be done, sorry. Outsource your fucking credit card processing. You don't want to be responsible for that shit in the first place.
I use the helpers based on habit, but I think MVC6 is moving towards HTML. 
You don't have one. Your view has stolen it's job. Move that handling that the view does into its own class. Views have one job and one job only: to display things.
I agree I don't want to be responsible for that shit, and I am pushing to have it moved offsite, but for now I need to know if Re-Sharper appeases this requirement or if not, is there something else that does.
Not sure if serious, or trying to get me sent to prison.
I usually use some framework like angular/aurelius/ember. I guess that would be html
I don't believe Re-Sharper is going to apply here, as they are specifically looking for vulnerability checks. Are you doing a PA-DSS compliance validation? If so your assessor should be able to provide guidance on what they expect your answer to be before they will pass you. 
We are moving away from the helpers as we've started using Angular. However if I was making a really simple CRUD page with no client interaction I would indeed use helpers to get it done.
The PCI requirement I'm wrestling with is in my post, which says "or automated processes" and I have bing'ed (and googled) "automated code review" with no real success. 
So I'd had a Download class, and QueueItem control to display things, and a class to have them interact? I don't know, I guess I understand why it would be good, but for smaller applications I feel like following this pattern seems excessive.
Fakes is the MS version of a mocking framework. I second the use of Moq, very solid completely free mocking framework.
&gt;Does anyone have any suggestions for alternative tools or approaches to writing clean, effective unit tests that utilized 3rd party libraries which are not exposed as interfaces and can't be refactored? You should be able to include a shim layer to introduce an interface between your code and this 3rd party library 
Most applications in the professional world are not that small. Most Microsoft APIs are designed to support fairly large scale code bases. If you are only doing a small app that never needs regular maintaince then you can pretty much break all the rules. Once your applications grow in size these concepts make managing large and complex code bases much more realisitc.
Either thinly wrap the 3rd party libraries and then mock that interface, or structure your code in a way that all the imperative stuff happens in one method and functional stuff happens in other methods. For example, instead of something like public int CalculateSomeValue(string someArg) { var someValue = SomeThirdPartyLibrary.DoSomething(someArg); ... some more logic manipulating someValue here return someCalculatedValue; } Do it like this: public int CalculateSomeValue(string someArg) { var someValue = SomeThirdPartyLibrary.DoSomething(someArg); return new ValueCalculator().CalculateValue(someValue); // logic manipulating someValue is in this method } Now you can easily write a unit test for the ValueCalculator.Calculate method since it's a pure function. It has all the conditionals that need to be tested. You can easily write an integration test for the CalculateSomeValue method because it has no conditionals. This is a simplified example. In a real system I would inject a ValueCalculator as a dependency instead of newing it up.
There are also some grammar issues - your instead of you're, possessives missing apostrophes ... may want to have a proofreader give it a once-over.
thanks @overslacked. :) I fixed it...it was on the "your not a JSON..." appreciated it!
Wise words @overslacked, makes perfect sense what you are saying! That's my next demo for sure. I will post it here afterwards. Thanks for the feedback man! :) 
PCI compliance is not a joke. Anyone arguing that it is doesn't really understand what PCI compliance is, and what it means. In order to get PCI compliance, you need to be audited by a professional auditor. If he doesn't find your screw ups, then you're right that nobody from PCI will come and check (you are responsible for hiring the auditor). However, if you are compromised, and they find out that you are the source of that compromise, then you can be held fiscally and legally responsible. So, unless you want a 500 million dollar judgement against you, I suggest not intentionally lying to them. PCI is all about covering asses. And you don't want to be the one that has yours swinging in the breeze. Those big companies have waivers and special dispensations that allow them to continue with their big nasty practice, and that doesn't make them liable. Lying to them does. This is why you want to outsource this, preferably with a payment processor that hosts their own tokenization system so you only keep tokens in your system. Then, you are only responsible for the protected information.
I did not say anything about "fixing" anything with jQuery. I said, that you don't understand how helpers work, and are using them incorrectly. They generate correct html when you use them correctly, and there is no need to "fix" anything if you know what you're doing when you use them. It is unfortunate that it's very easy to use them incorrectly (such as in a foreach) and they will not generate correct markup when you do. But it's a poor craftsman that blames his tool for his lack of understanding.
Why the fuck do you care? It may not be c, but it's still code. 
&gt; Just answer yes. No one from PCI will go down to your office to verify. And when something goes wrong, you will be liable. Good job! You screwed your life!
Instead of twicely telling him he's doing it wrong, work with him and show him how to do it right. Just an idea.
&gt;I feel like following this pattern seems excessive It's this whole "When you hold a hammer everything becomes a nail" thing again. If it works without the pattern, then that's absolutely fine too, especially in smaller applications. It's also fine to mix and match patterns as required. Just because you want your application to roughly follow the MVVM pattern doesn't mean you have to forcibly shoehorn every little thing into it. If you application is small and stays small, just ditch MVVM and stick to doing what you know how to do. Sticking to the MVVM pattern is only going to be useful if you expect the application to grow. In that case sticking to the pattern early will make development and maintenance much easier in the long run. And just for the record, the point of the ViewModel is to be a "bridge" between the Model and the View. For instance, if you Model has the properties "FirstName" and "LastName" but your View needs the full name, instead of putting the logic of combining them into the view you give the ViewModel a "FullName" property, combining the two from the Model, that your View can then access without having to know where it came from or how it's put together. It's as the name implies an extra Model made specifically for the View. But if your View and Model are both really simple and require no additional logic, you can just skip the ViewModel in between. In that case, unless you expect the complexity to grow later on, it'd just be a useless additional layer that mirrors the Model.
I use pretty much 100% HTML, never been a fan of the helper methods personally.
Isn't this a feature of resharper, not visual studio?
No, in 2013 it was a vanilla feature.
Calm down. I guess you could loosely define it as code. It is absolutely not a programming language. 
I haven't found one better than [Regexr](http://www.regexr.com/) for it's speed, flexibility, and reference material included in the app.
I haven't used it but is the fakes you speak of the same as fake it easy? If not the latter its freely available on github and nuget
I thought it was resharper
It's not in VS Community, only Enterprise and Pro
I like [regex101.com](https://regex101.com/), personally.
Well, here is a [screen shot](http://lh6.ggpht.com/_0j4bzarlOBg/TV5Cetw5A5I/AAAAAAAAB0c/47R_12h3oLo/image%5B27%5D.png?imgmax=1200) of the dialog in VS2013 
You can create a facade/wrapper between your code and the third party library, for example, if the third party library call is: library.Method(param1); you can create an interface like so: public interface ILibraryWrapper { public void Method(string param1); } and then have your implemented wrapper class for use in production code: public class LibraryWrapper : ILibraryWrapper { public void Method(string param1) { library.Method(param1); } } and then either use a mocking framework like Moq, or write your own implementation of ILibraryWrapper (e.g. MyFakeWrapper) to use for your testing. This will require you to do dependency injection, that is, the class that is currently using the third-party library will need to have the correct ILibraryWrapper provided to it, depending on whether it's being called from testing code or production code.
&gt; Storing passwords (in any manner) is just plain stupid though. Not even as a one-way hash (what I currently do)?
I figured out why no one thinks this feature exists. This is a feature that ONLY existed in Visual Basic project. And it is indeed gone in VS2015 with the VB project type it looks like.
OK, long description here: https://www.reddit.com/r/modtools/comments/t8u0u/cleanmodqueue_a_tool_to_help_moderators_of_busy/ it basically automates moderator actions on spam in the spam-queue for 1 or multiple subreddits by applying "rules" to each entry. Note: another bug is that you are supposed to be able to apply rules to specific subreddits (assuming you moderate more than 1), but that doesn't work, the rules act globally on all subreddits you moderate.
I already started questioning myself. Thanks for helping me reassuring my sanity ;-)
Hmm, must be something else then.
I've never had that problem. But then again I haven't used VB in about 5 years so maybe it got worse.
That's storing a hash, not a password, and is what you should be doing.
Thank you everyone! After reading the responses as well as some additional material elsewhere on the internet, I'm beginning to understand MVVM more and more. For some reason, I was under the impression if you're building an application in WPF than you *should* be using the MVVM pattern but now I know that's not necessarily the case.
Thanks. I've found a workaround, turns out there was a 3rd control involved in the SQL query that I had forgotten about. By moving the other two controls before the one that wasn't correctly databinding it is rendering correctly. It seems that there should be a relatively easy way to either set the order that controls are databound or to trigger a refresh when needed, I'm sure I'm going to run in to this again someday and won't be able to fix just by rearranging the controls.
I fail to see what your second solution improves on writing a wrapper over the whole library. You won't be able to assert SomeThirdPartyLibrary was called and you won't be able to test CalculateSomeValue.
I best way to analyse this stuff is with a kernal debugger (win32dbg). When your program is running in the task manager right click and "Create Dump File". This basicly dumps all the memory your program is using to disk (like the memory scanner you mentioned). You can then take a peek at that memory win win23dbg (found in the windows SDK (https://www.microsoft.com/en-ca/download/details.aspx?id=8279)) To drill into this stuff I sugesst following these awesome labs at the bottom of this page: http://blogs.msdn.com/b/tess/archive/2008/02/04/net-debugging-demos-information-and-setup-instructions.aspx This teaches you how to look at raw memory dumps and debug problems and will give you an idea of how memory is layed out including how to look at the stack/heap/program space. If your weird like me and havn't lost interest after doing that read this book: http://www.amazon.com/CLR-via-Edition-Developer-Reference/dp/0735667454 Its how the .NET CLR works under the hood including all the nitty gritty details on how memory is used.
When I've done this in the past, I set up a post build event in the class library to transfer the dll into the bin folder of the MVC project - makes things faster when developing both in parallel.
It's matter of finding better matching colors then. Glad you could the the site alright. Will take your opinion into much consideration. Thanks @alkrun. :)
http://learn.shayhowe.com/ Shay Howe has a great free tutorial on html and css.
This talk explains it very well. It's Ruby but the concepts are the same. https://www.destroyallsoftware.com/talks/boundaries
But the post is about unit testing, not integration testing. Anyway, even for integration, you cannot treat CalculateSomeValue as a black box if what it does is create a file or send an email: you should check if the file is there or if the email went out and this depends on a lot of external factors (configuration, infrastructure,....). On the other hand, if you're unit testing, a simple assert to verify that the library was called with the correct parameters in a way that validates *your* code is very valuable.
So just because he asked specifically about unit testing I shouldn't mention integration tests even when they result in a much better solution? That's an odd mindset to have. I don't know if you saw my example code or not but it definitely doesn't create any files or send any emails. Obviously those are cases where a thin wrapper is better, which is why I offered up both options as solutions. There are many, many more code units that don't create files or send emails than there are those that do. Black box testing, when possible, is objectively better than white box testing. Do you disagree? 
If the code that is being mocked doesn't cross any application boundaries (filesystem, network,...) I prefer black box testing. But then I wouldn't even mock it and that makes your example a bit redundant.
I'm convinced you're just arguing to argue. It was pretty obvious from the moment you said "you won't be able to test CalculateSomeValue" that you aren't familiar enough with automated testing to add anything to the discussion. That's a pretty trivial test to write. Get some practice and experience the test maintenance nightmare for yourself and then come back.
From within your view/partial view: bool hideIt = User.Identity.IsAuthenticated; 
Thanks! I tend to always overthink or focus to narrow on what the solution is. That makes total sense. This is pretty normal UX practice is it not? You login to Twitter, Vimeo, Slack, etc. you're inside the application vs. outside the application. Why you need about, or pricing, etc. if you're already a user? 
MS-LPL seems open source enough for this project. i'm not sure I see the value of running software that dumps out the PInvoke signatures for Win32 methods on Linux. Regardless, based on OP deleting their account I think this was just a dumb question
Yep this is the correct way
Yay, yay, yay, nay
My company uses Telerik's Kendo MVC UI components.
AFAIK this is the only way if you intend to use free mocking frameworks.
As in, a gulpfile written in TS?
Personally, and I don't think I'm alone in this, I prefer gulp over grunt. Gulp is "just javascript" while grunt involves config files. As for 100+ javascript modules and external libraries, surely you can organize some of them into larger bundles and divide that way. This is normally how migrating out of a "legacy" situation happens, pieces at a time. How else do you eat an elephant?
I am concerned about initial load times with a huge javascript bundle. As i indicated in my reply to another comment - We have some huge external libraries and could possibly end up with a 3 MB javascript bundle. Good tip on the folder structure. That could work for us. Thanks!
I am calm. I'm not the one throwing around insults. Everything I have said is absolutely true. I don't need to resort to ad homeniem to make my point. Html serves a purpose and does a decent job of it. Nobody can argue successfully that it is code. Code is a turing complete programming language. 
What's the advantage?
You should be aware that the tooling support and the documentation for Grunt is vastly superior than for Gulp. There are so much more plugins. Also Gulp seems pretty much dead. Last year in December the publicly announced that the version 4.0 will be "soon" on NPM, official release is planned for January. Now, 9 months later, they're still on version 3.9. There is no announcement about 4.0 anymore.
You're asking what the advantages of TypeScript are? Type safety and code completion.
Type safety and code completion.
After experimenting with it: No, it's not worth it. It easily takes 4-5 seconds longer to start gulp. Setup however is straight forward. Install typescript-node, rename your gulpfile.js to gulpfile.ts and it works.
True. I am doing this, and it really helps keeping the code clean. Not saying it couldn't be done with JS + HTML in a similarly clean fashion, but it's easier this way. 
I think getting the external libraries from a CDN is fine, but it makes it harder to debug them if something is wrong under development. Grunt/Gulp can help with that, by using a local file under development and swapping it out for a CDN one in production. They can also do many other tasks, since they are task runner, this includes but are not limited to minification of your javascript. One gulp plugin I love is an AngularJS injection one that automatically injects my modules and controllers in the correct order on my index page, and when I add new dependencies it automatically figures out the new order. Since frontend work is not limited to .NET people these tools need to be crossplatform so they where build on Node, and these are the tools the rest of the world uses. So using gulp/grunt gives you more options, you will get experience with tools that other developers are using and it looks like MS is going in this direction too.
For what it's worth, most shops do agile/scrum, and that generally means that teams are responsible for entire features, frontend to backend to infrastructure. Separating frontend and backend over teams just leads to a lot of waiting around.
At least .net can be threaded. I know there are plans to multi thread node.
It will be interesting to know how many times someone will swap .NET with other technologies... In my experience it usually remains same for a long time... However Gulp/Grunt can separate things from .NET for front-end devs (may be even to backend devs if you can think of ways) and can also make certain tasks seem trivial if node/bower plugins are available. And using Gulp/Grunt can be smooth only if you have a pre-defined system for all devs to follow and concerned devs know of node/bower. It also makes me wonder why PowerShell is not hit in this area...
Gulp and grunt depend on npm. Npm packages all dependencies into sub folders. These sub folders end up being longer than Windows MAX_PATH and cause all kinds of issues, failed builds, directories that cannot be deleted, etc. They are working on a fix for this in npm, but until that happens I consider anything that relies on npm in Windows broken. Until it's fixed, msbuild and bundles files are what you get.
http://getcassette.net
this approach isn't bad, but using node/gulp/grunt &lt;nounjs&gt; is hip and new... and all the cool kids do it ... so it must be good, right ?
Partial Views, Html Helpers or Display/Editor templates.
There are also helper methods, similar to html helper methods but basically in the cshtml files. Good if you need it different on reach page. 
we had luck with BootstrapDialog in place of the modals - http://nakupanda.github.io/bootstrap3-dialog/ edit: should add it doesn't replace the modals. just uses javascript to make them happen rather than relying on the markup
Bootbox is another alternative, [Bootbox](http://bootboxjs.com)
Pulling external libraries from a CDN without a fallback is bad because if the CDN is down (yes it does happen) or if that CDN is unreachable by the client your web application doesn't work. Also a key component of your web application isn't in source control, with is just a no-no. Whether you should use Gulp/Grunt etc is another issue entirely.
Thanks for the link, I'll have a read through. My team are still using HTML Helpers, but I have found it to be incomplete (for example, there is no standard way to handle multiple checkboxes). If the consensus is shifting towards HTML, it might become easier to convince them to change.
Did you know that you can write your own taghelpers? You can do this purely in C# or via a razor view that simply define your custom helpers. I think the basic HTML helpers are just meant as a common start point for all developers. 
I just read through this article and the next one explaining how to write custom taghelpers. With some knowledge of JSP, I found the implementation familiar, though simpler than JSP Tags. I like it.
If it works for you then great. As others have mentioned, the idea is to separate .NET dependencies from the front end. Another important reason to be aware of is gulp and grunt have ecosystems catered for front end development and the JavaScript libraries are more up to date than the corresponding NuGet packages. Matz cited this as a reason for incorporating these tools into Visual Studio.
It depends what your build and deploy process is. I normally have bower pull in all the dependences as part of build process and only check in the relevant bower files. At work I either set up a git repo that mirrors the github repo or have a separate vendors library and check them into souce control and they are statically linked which requires more effort to deal with the dependencies. It depends on your companies policies on how things should be kept in source control.
I'd say there's two main reasons. One there are tons of libraries and tools that support it. Two you have a compile time build pipeline which I'd say is worth it's weight in gold.
Its just running within windows (7), running as a simple .net project that I will compile into an executable. Currently using Access as my database.
Hmm, I don't know if there is a built in control you could use that would fit your requirements. You can always make your own user control though. Maybe a grid would work if you put it inside a scrollable panel. 
Mock up would be something like: Table: ProjectName | DueDate | Status | User ---|---|----|---- Project 1 | 17-02-2015 | Completed | Bob Project 2 | 24-03-2015 | Overdue | Mary Project 3 | 10-07-2015 | InProgress | Bob I would like to populate on a from ProjectName ________________ DueDate for as many items as the query returned. (I.e - Where User = 'Bob') Then I want to be able to click on a selection. Like 'Project 1' on the form and it open up another form showing results from: ProjectTable: ProjectName | Objective | Status | DueDate | User | Notes ---|---|----|----|----|---- Project 1 | Objective1 | Completed | 10-01-2015 |Bob | Custom info on objective progress Project 1 | Objective2 | In Progress | 22-01-2015 |Bob | Other info on project Project 2 | Objective1 | Completed | 10-01-2015 |Bob | This is just Data So the new form would pick up [User][ProjectName] and deliver to the form [Objective] [Status] [DueDate] [Notes] But this would only populate based on what was clicked (i.e. - Where user = 'Bob' and ProjectName = 'Project 1')
Any reason not to try a web (intranet) based approach using ASP.net? Not that I know much about ASP.net but I presume it would be easy to distribute, just send a link and login details?
Honestly I just don't know anything about web, everything I know is goggled and self taught from visual basic and VB6 with a little .net info. I'm also trying to keep it out of any other platforms like web as I want it to maintain its own system tray position. 
Thanks for the suggestion, I'll look into them.
I'd recommend forgetting specific technology here. You may actually want to stick with spreadsheets, rather than some poorly written winform/wpf/asp.net mvc app from a beginner, however I'd find what's horrible about the current solution and spend some thinking time about the ways to resolve them without thinking about low level implementation. Take a look at google apps too, the spreadsheets are highly extensible with AppScript, combined with Google Forms etc.. 
You mentioned ViewModels and Views so I assume you're talking about MVC controllers and not WebAPI controllers. If the controllers are thin wrappers on top of other service/manager classes, then I tend to not have unit tests for the controllers. In that scenario, 90% of the problems I see happen as part of parameters and binding and it's tough to cover that with unit tests. I'd prefer to cover that with integration tests where I'm running the full stack somewhere and making legit HTTP requests for each action.
That's why you define a browser matrix which lists all required browsers, and test with each required one.
It does, a bit. If we're talking about MVC controllers it would be possible/reasonable to test the full UI with something like selenium. WebAPI controllers tend to not render a navigable UI, so something more like fitnesse might make more sense. It's definitely not a key factor but it does affect the decision making. Also, WebAPI is easier to self-host which makes it marginally easier to set up integration testing environments.
I would definitely allow people to post conferences. These are a huge part of the dotnet community. The other stuff can get too spamilicious
Ohhh ok. Yeah I'd like to know a plugin that would allow this as well. I've had users ask for this feature. 
Request.IsAuthenticated works to. 
I see this argument often here when somebody asks a question about testing. With skinny controllers and fat domain models writing unit tests for controller actions doesn't make sense. I think saying, "no, I use integration or UI tests for controller actions" is a perfectly valid answer to the question, "do you unit test your controller actions". Simply answering "no" doesn't really add anything to the discussion.
In practice 2 line controller actions are only possible for a small number of actions. Most of the time you need to handle invalid input and/or make decisions about where to redirect to based on the response from the service call.
As promised: http://sillycodevalley.net/how-to-profile-your-net-application-without-modifying-its-code/ Thanks for the inspiration @overslacked 
&gt; What I have are skinny controllers that basically call on to the business layer for logic and data and then populate a local ViewModel to pass to the view. If the controllers really are that skinny, do you really need a lot of controllers then? I mean, I'd assume if they are that skinny, they are very much alike. Can't you go for a more generic solution? As in "One controller to rule them all"? If your proxy like controllers are pretty unnecessary, then yes, your tests are too.
Basic validation occurs in the ASP.NET pipeline before your controller is even called. The rest of the validation can usually be handled in the service. Aside from tricky things like file uploads, the *only* thing my controller does is determine the user's identity and pass that along with the incoming data to the service call.
Google "unit testing model binders", Hanselmans got a blog entry. Why would you need to involve a browser? You're testing input and output of data, not rendering. https://gist.github.com/adamchester/5606734 What about if your controller method returns a created status code? Where is the assertion of this being returned?
The whole point of the model binder is to handle communication with the UI. If you aren't testing that, then you are just hoping that there is no mismatch between the front and back end. If you are testing it, then unit testing the model binding separately is just duplicating work.
No, it's to test whether data is bindable. I use model binding in web api, there is no UI.
Its a good idea, but you are looking at hundreds of hours of dev time. I would allow users to move components and use an orderby to build the page and store the raw html in a blob. Retrieve it by url in the onactionexecuting. Good luck! 
So do I. The term "UI" is a placeholder for whatever calls the server. &gt; No, it's to test whether data is bindable. You don't need to test the controller for that. You can run the JSON serializer directly. That said, you have to be doing something really weird for the data binding to fail. 
What filters would you use to validate against, say, an invalid email?
&gt; What filters would you use to validate against, say, an invalid email? Are you familiar with Data Annotations? If so, use the EmailAddressAttribute on the appropriate property in your model. https://msdn.microsoft.com/en-us/library/system.componentmodel.dataannotations.emailaddressattribute(v=vs.110).aspx For the filter... public class ValidateModelAttribute : ActionFilterAttribute { public override void OnActionExecuting(HttpActionContext actionContext) { if (actionContext.ModelState.IsValid == false) { actionContext.Response = actionContext.Request.CreateErrorResponse( HttpStatusCode.BadRequest, actionContext.ModelState); } } } This filter can be applied to a single controller method or globally using this line: config.Filters.Add(new ValidateModelAttribute());
If you are just passing through to a service or business logic layer then no. At that point you are testing .net and that is just silly. I would recommend testing your JavaScript that calls the controller actions instead. I have been using saucelabs for this but there are others. You could always do it yourself but I found that it was a pain because we didn't have the hardware to host all the different environments I wanted to test in.
Does this use virtual method interception or do the type names get modified, for example would a stack trace look the same? 
Thanks @overslacked :)
HTML with CSS can do dynamic things.
CodeCop looks really slick! I'll be trying it out in the next few weeks to see how it compares to JetBrain's dotTrace. Thanks for the breakdown.
Excellent! I was just in need of something like this!
I specifically said html on its own. 
That's pretty much what I'm doing now. The view is agnostic as the model is just IEnumerable&lt;myview&gt; and in the controller I check to see if the user is in one of various roles and if it is I select all otherwise I select with a .where(m=&gt;m.requestoruser == &lt;logged in GUID&gt;) 
Definitely need an open source version of this..
Very interesting, thanks.
WHY R NO USE IMAP?
Essentially, you can follow this article: http://www.asp.net/web-api/overview/formats-and-model-binding/parameter-binding-in-aspnet-web-api I've distilled a simple example in this gist https://gist.github.com/nemec/df3f1e49b92ae4bff40a, pulling the X-Api-Key header into an additional parameter on the controller. public class MainController : ApiController { [Route("people")] [HttpPostAttribute] public HttpResponseMessage CreatePerson([FromBody]Person p, [FromApiKey]ApiKey key) { key.Dump("API Key"); p.Dump("Person"); return Request.CreateResponse(HttpStatusCode.OK, key); } } This is actually not what I was referring to above, which used an `ActionFilterAttribute` to do basically the same thing, but ParameterBinding is the preferred way to do it in WebApi.
Thanks!
I found this [source code](https://km.zebra.com/kb/index?page=answeropen&amp;type=open&amp;searchid=1442959250672&amp;answerid=16777222&amp;iqaction=5&amp;url=https%3A%2F%2Fkm.zebra.com%2Fkb%2Findex%3Fpage%3Dcontent%26id%3DSA301%26actp%3Dsearch%26viewlocale%3Den_US&amp;highlightinfo=4194307,10,19#), but would love to have more examples. It also just moves the labels but doesn't print hello world. So not exactly working as intended with the ZD500R. I wonder if it is the hardware rather than code in this instance. 
Agreed... MSDN is where I go as a last resort. A nice stack overflow example always does the job for me.
So you don't know how to read T-SQL command reference syntax and don't like reading the rest of the doc that gives lots of examples and definitions of every term. Got it. Programming requires work and thought, if you are not down for that this may not be the kind of work you want to do. [Actual link for reference](https://msdn.microsoft.com/en-us/library/ms177523.aspx)
You can build a html table from the results of SQL query and continue as in the Html (DOM) example. Or you can use javascript example and build the javascript table in text when rendering the page from the SQL query results.
Well as far as I know, there is indeed no official library/sdk to print to Zebra printers that's provided by Zebra. What I always did in my applications was just send raw strings of a [ZPL/EPL script](https://www.zebra.com/content/dam/zebra/manuals/en-us/software/zpl-zbi2-pm-en.pdf) to the necessary port (usually the LPT1 port when working with older models that didn't support TCP/IP network ports). The link you posted also does this. So you'll probably need to do some testing and tweak your label script in order to get your final result. Most use cases for these printers is to just print one kind of label for their whole life. I don't want to just send you random links from things I found on Google, so I'll just give you what I would probably have given a look at. Closest open-source thing I could find on GitHub was [this project](https://github.com/danielemarino/csharp-zpl-tools). You could also check out [this page](https://km.zebra.com/kb/index?page=content&amp;channel=SAMPLE_CODE&amp;cat=C_SHARP) from the Zebra KB with all the C# related topics.
While I agree MSDN can be so unhelpful that it would have been better for me not to even go there, the T-SQL documentation is not that: it's one of the, if not the best comprehensive documentation Microsoft has ever made. Very little is undocumented and examples are given for every option of every statement. Yes, it is complex if you don't know what you are looking at, but T-SQL is complex. Skip right to the bottom and look at the examples, and you'll be well on your way.
Minor note: in English, "duplicity" means "dishonesty"; you may want to use "duplication" instead.
I completely agree, however I'm usually looking for a rather simple example. In all my years of coding, I've rarely looked at MSDN for C# or SQL documentation. On the other hand, MSDN C++ documentation has been very helpful.
Which I find to be a better way to navigate MSDN sometimes anyway.
After looking at the site a bit I would recommend to use the object data source option. On the server side execute your query using executereader() then read the results into a strongly typed object (you need to create a simple class with properties for each of the database fields you want to show). Return this to the JavaScript as your data source. The datatable tool should handle the rest. If you need actual code I will provide but I'm about to go to bed and on my phone.
I don't see the problem here?
The top rated answer from the SO post you linked is how we do them at work. It's a decent implementation that works at least through Windows 7. The only real improvement I've done or felt the need to do is throw an interface on the given code so I can test processes, and I started an API for labels so I don't have massive, nasty ZPL strings in my code.
HTML is a markup language, CSS is a styling language. There is no scripting in either of them, yet together they create dynamic behavior. 
&gt;Also to avoid further complications, I have separate classes to represent email entity and data contract for WCF. It is good way, or should I merge them together? (they are basically identical) Separate is good. It seems wasteful but it is really useful to have them separated. How many address are in the CC and BCC fields typically? If it's not many then you can just the data type to string and separate entries with ';'. AFAIK the will be sent to the email server this way in any case.
I am actually using IMap to access Gmail. But the mails that I am going to process will have such attachments.
I thought about this, but I would like to also store name associated with the email, hence I have EmailAddress class containing address itself + name. Unfortunately I have no idea how often will email have CC/BCC field and/or how many. 
Thanks, edited. 
Why not normalize it? Have a table for the Emai, one for the Email Addresses and one to match Email and Addresses?
It's like you didn't even read my post. I've been making web sites/apps since before css existed. I know it inside and out.
I don't have much experience with Java so I can't answer your speed questions. However, as far as features of the languages are concerned, it appears to me that Java is imitating C# as opposed to making there own innovations. My primary reason for saying that is C# has had lambda functions since version 3 (2008) and Java added them in version 8 (2014). Furthermore, C# has excellent async task handling with the new async and await keywords. To my knowledge Java has nothing to compare with this. I don't know about you, but even if it is a little slower I'd rather use the language that is creating new features instead of the one that is 6 years behind the curve. It's also worth noting that if your primary concern is speed using a language that is closer to the metal will gain you the most speed, but do you really want to program in Assembly?
Which OS are you targeting .. if Windows then C# .. if Linux , MAC and Windows then Java. Note Java by design is slower and from experience C# is less hectic when in comes to development. Also C# is going soon to be on MAC and Linux , talking about .Net and not Mono. Also with Win10 you should be able to create modern apps which run on both the mobile, tablet and desktops. One code, one project runs on all. Another advantage would be Visual Studio CE, it is the best development tool I have came across and it is free. Sorry that I didn't answer your questions .. Java and C# are not that different, for open source community it is mostly Python and PHP. Database engines are almost the same for both. C# is kind of new to the open source community, it will need time to grow..
&gt; 1) on Database and backend are they on equal footing ? which is bigger between oracle or sql ? can they do the same thing ? are they as fast as each others I mean in scaling large project ? I believe you can use almost any database while using c# or java &gt; 2) on UI can java compete with WPF with JavaFX and the others framework ? If you are targeting only windows, no. &gt; 3) on mobile dev if you count xamarin can Java do well too even if its just android ? I think yes, but it's not my field, so it's just a hunch.. &gt; 4) modernity of the language itself which is less verbose or more modern if we cound the latest versions of each ... what's the main differences between the 2 C# is ahead of Java on this one and probably will be in foreseeable future. &gt; 5) on the open source scene which is bigger in term of framework librairies... are companies bigger on java because its older and they invested a lot of code in it or C# is starting to grow because they are open sourcing it ? Both languages have very large communities around them and tons of libraries, however Java is bigger. Companies often go for Java because it's multiplatform. &gt; 7) which is faster ? is it possible to do in java the same things you can do with C# and call some C++ interop dll and combine both C++ C# or C++ Java etc I don't believe there is a noticeable difference in overall speed between these two - it really depends on the task. C# probably has an edge thanks to .NET Native on some platforms or new JIT compiler, but for usual tasks really don't think you can go wrong.. &gt; 8) which is more open or more future proof then the other ? C# who's getting open sourced or the jvm who's developping many different languages like scala etc This is really hard to say, but C# is on the rise right now and is being developed faster than Java. There is already discussion about features of C# 7 ( https://github.com/dotnet/roslyn/issues/2136 ) which is going to be pretty sick if nullability tracking will become a thing ( https://github.com/dotnet/roslyn/issues/227 ).
Thanks. Is there any reason why I can deliver this to any of my devices (android, PC, Mac), except for my Paperwhite?
The paperwhite isn't compatible with a whole bunch of graphical things android, PC and Mac are able to display - basically any e-ink display craps out and dies on dynamic content, they're designed for static, preferably black and white content.
Yes, this is something I would like to achieve. But I don't know how to configure EF properly for this kind of relations. Each email would then have associated email address for: sender, recipient and possibly multiple addresses for CC/BCC. But how avoid duplication? Because after some time, Email address table will be full of multiple rows with the same address/name combination.
Thank you for this explanation! My eBook contains photos and graphics so I'm sure that's why it's not available on Paperwhite. You can also download a free PDF version here: http://hoffstech.com/free-ebook I hope you find the information that I provide helpful! Have a great day!
Moq only works with virtual methods. Interfaces are virtual in C#.
Thank you for your response and advice! I will look more into the DOM example. I really don't remember all that much about HTML or any of the data sourcing options, really. It's been a while.
Did you configure this to be a n:m relation rather than a 1:n relation? I don't see this to be a problem if you use n:m. Edit: aka many-to-many relation
Use a profiler.
Thanks for posting this!
Yes. 
I have feet in both worlds, and I see your XPost in /r/dotnet and /r/java. I'm answering here and not there just because it was first on my front page. 1) Isn't really a comparison of .NET and Java. You can talk to SQL Server from Java code and to Oracle from .NET. I find SQL Server more friendly than Oracle though. Oracle is a royal PITA to install on some platforms. Both Hibernate and Entity Framework are annoying at times, although you can write raw ADO.Net or JDBC on individual systems. 2) Java on the desktop doesn't compete. It's ugly and users hate it. If you need to invest in something customer facing WPF is the way to go, if you need to throw up something quick and dirty that gets the job done WinForms is still alive and kicking. When we need cross-platform our shop turns to Qt. 3) Don't know the mobile world. 4) C# has the advantage here. They were later to the party than Java, so they learned a bit from Java's mistakes, and at one point they were willing to make changes that broke backward compatibility to go forward. Java is trying to catch up with Java8 Streams matching some of the functionality as LINQ, but it's still very primitive and klunky. Java is completely unwilling to break backwards compatibility. That's important for those who demand that code they wrote a decade ago run without changes on the JVM coming out next month. Unfortunately that also means that progress in language development is limited by poor design decisions like type erasure and checked exceptions that are too deeply ingrained to change without breaking backward compatibility. 5) This isn't even a comparison. The Java open source ecosystem is vibrant and full of mature solutions to very challenging problems. In contrast the C# open source ecosystem is quite bare and it's very common to have a need that can't be filled except by some expensive proprietary library that doesn't even do half of what it says it is capable of or by some open source project that was abandoned in 2010. 6) Yes, those still exist. The backbone underneath quite a few Java MVC frameworks is still the humble Servlet. JSF, Spring MVC, Play, and Asp.NET MVC seem to be the big players on server side rendering. I don't really have a preference. Javascript single page applications look really smooth and sell very nicely to customers, but honestly I'm dreading the long term maintenance on some of this code as it ages and the strictness of development tapers off in maintenance mode. Also, the Javascript ecosystem is royally fucked. Who knows if some of these dependencies will even exist in 36 months, all the package managers are packed with poorly written garbage, and there's a new framework out every Wednesday. 7) Probably depends on what you are doing, but my gut feeling is that the JVM is going to be faster for quite many things. 8) Both are future proof. Server side applications are growing in importance, not going away. Both Java and C# will be growing for the foreseeable future. Wouldn't count on other languages on either platform. Too niche to be portable across the job market with any security.
I don't think VS-proper is entirely written in .NET, and significant parts of it (especially debugging and performance analysis) are likely extremely OS specific.
The shell is WFP (since VS 2010 IIRC), so it would have to be rewritten completely into something OSX capable. 
I'm using the RTM and devenv will easily climb to over 1gb and eventually reach 2gb if I don't restart it. I don't really care how much it is using, but when deleting whitespace from a .xaml file causes it to become completely unresponsive. I lose it. Where would you recommend I report this? Also where do I try turning off code lens? It also hangs the first time I hit a break point in either of my two apps I work on. Also after a build completes locally.
VS Code is more of a front end JS editor than a full blown IDE, but from what I've read there are ways to get it pretty close that require some manual effort. EDIT: Apparently it's a Microsoft-built version of GitHub's Electron (formerly known as Atom Shell).
For ideas, I wrote a ZebraLabel class that let's me do them like this: zpl = ZebraLabel.NewLabel(480, True, True) _ .AddBarcode(610, 30, "EC00001234") _ .AddText(535, 115, 8, "EC00001234") _ .AddText(455, 30, 8, "2013.11.28") _ .AddText(355, 30, 10, "CA1207-1234") _ .AddText(305, 30, 7, "SUPPLIER") _ .AddText(265, 30, 5, "PRODUCT") _ .AddText(220, 30, 3, "Echantillon compartiment wagon") _ .AddText(135, 30, 10, "NCIX0000123456") _ .AddText(35, 242, 10, "G20") _ .AddBox(35, 30, 105, 105, 5, "box 1") _ .AddBox(35, 130, 105, 105, 5, "box 2") _ .AddBox(35, 230, 105, 105, 5, "box 3") _ .AddBox(35, 330, 105, 105, 5, "box 4") _ .SetTextRatio(8, 8) _ .AddText(0, 65, 4, "#1", "comp 1") _ .AddText(0, 165, 4, "#2", "comp 2") _ .AddText(0, 265, 4, "#3", "comp 3") _ .AddText(0, 365, 4, "#4", "comp 4") _ .GetZPL() 
TLDR: You should not be teaching this to anybody anymore, unless specifically asked, in which case you will need more in depth information
I would qualify that with run away from TFS using VCS. If it's TFS using Git then it's fine.
"SO developer" alert!!! 😊 
Thanks, this looks good. How would you handle the inevitable duplication? I could either always try to find email address in the DB and if successful assign it to new mail or run some script that will remove duplicated addresses. Which would be better? 
Well, I did not exactly know how to structure relations in my model and configure EF... 
The actual Email Address will only be in the DB once. You just reassign it's ID to multiple emails. So instead of dragging a whole nvarchar around with you, you only carry an Int field. As a whole though, on this level, I wouldn't worry so much about duplication, unless you deal with millions of emails/email addresses. For example you might need to track changes in peoples email addresses. (If a person moves from company a to b or the person that you're talking to changes for example) In that case you don't want to change the address for emails you already send, things like that.
I didnt mean it in a mean way. Just asking, wasnt to sure reading your description of the problem :)
My implementation actually just concatenates a string as it goes along - except for stuff like SetTextRatio that sets internal properties - and returns it on .GetZPL()
I've done quite a lot of programs that print labels using Intermec and Zebra printers. As it's a hassle to change a label roll in the printer all implementations so far have called for a single label design with 2 to 20 variable fields and barcodes. My approach now days is first to design the label using software available on Zebras site (sorry, forgot the name, but you should easily find it there) then print the finished design to a file to get it in ZPL which is by far a faster print method than using GDI. Once you have the ZPL code you can just turn it into a template for your program and either build it line by line or use it as a resource and replace template markers with data. Afterwards just send the string to the printer. If you're dealing with a complicated design and need fast printing there's also a way to upload a template to the printer and pretty much just send the variables each time you want a label printed. There's also a lot of info in the ZPL reference guide you can download from Zebra.
This pretty much covers 80% of my junior developer questions (including your "senior level questions") from 2+ years ago. I made 7000$/year with that knowledge (10000$ most recently while being told that I don't deserve that). Not sure if all those are too basic-level or I just allowed myself to get F-ed in the A for way too long. My guess would be "both"... P.S. SQL Server / PostgreSQL / Oracle indices should also be in this document, I get this question a lot now :) And I can confirm, those listed in the document are indeed amongst the most common ones :)
I'll work from home here in the states ;)
Agreed on just about everything. I think java still outperforms c#, but I don't work on many cpu intensive things so I don't keep up that much.
Thanks for the additional detail! I'm glad you found the study guide helpful :)
Reference?
It's been all but abandoned in favor of UWA. MS never admits things are deprecated.
Yes.
Exactly. The right tool for the job is one with a bright future. An outdated tool will add all kinds of costs in the long run. It would be impossible to find someone with half a brain to work on a webforms app full time, for instance. At least without paying a premium rate. The right tool for the job needs to be chosen with things like that in mind.
Never say never. How many people would have predicted .NET core even just 5 years ago? Especially with their "Any developer, any time, any where" mantra now. I don't think it will be super soon, but I could see it happening longer term.
&gt; The right tool for the job is one with a bright future. How can you say that without knowing what "the job" is? The right tool for the job depends entirely on the job. There are many reasons to choose a particular tool. Having a "bright future" is only relevant if the job requires such a tool. Many jobs don't.
Sorry about that! You can also download a PDF copy at http://hoffstech.com/level-up.
Reference? 
Scroll down on the page to see examples... http://i.imgur.com/59ExUX3.png What's not to like about it? It is as complete as it gets.
I don't think I've seen this expressly stated, but it looks like .net core is, at least for now, more about web development and ASP.NET, not cross platform gui apps. It looks like that want to make sure that ASP.NET can run on windows, osx, and linux natively. I'm not sure there is a plan for GUIs with .net core. Mono probably is still your best bet.
I'd suspect the UWP apps might have OSX make more use of that in the future but it's pure speculation.
If you want cross platform UI in C# you need to look at Xamarin. Alternatively, there is also Unity3d which uses sprite based rendering (more uniform across devices, better animations), but, of course runs very hot (about in line with the Facebook app, lol)
The aim of the [Perspex](https://github.com/Perspex/Perspex) project to create a multi platform UI framework. It is working on Windows, OS X and Linux. It's still alpha, but very promising.
We write our own mappers. I've had perf concerns around auto mapper and it takes all of 2 minutes to put together a custom mapping class.
Can xamirin do OSX? Or only ios?
Windows Universal, Android, iOS, OSX
I don't think the core of .NET includes GUI stuff... Core would be like the key pieces of the framework; objects, collections, etc.
I write wrappers manually. AutoMapper hides the mapping details, and it can be a pain (depending of the application of course) to actually figure out what is going on. A project I worked on used AutoMapper, and it contained this hideous "AutoMapper.cs" which was just a huge file full of automapper configurations for every single model class in a big application. It also spelled out every field regardless of there being any special mapping associated. So when you at that point encounter Map&lt;Foo, Bar&gt; actually figuring out how that was mapped took some time, and being automapper you couldn't step into the mapping code. My opinion is generally don't use automapper. Especially if you don't actually automap. Just write the mapping code by hand. It doesn't take much time anyway, but is very useful later on.
It's used a lot, as a consultant I bopped around from client to client, and more of them used it than didn't. Personally, I feel like it gets the job done, but has some quirks. I also don't know how useful it really is these days with WebAPI being such a thing. I think it made more sense to me when dealing with WCF contracts.
GTK sharp for mono, no idea if it will work with .NET core, likely not though. 
Yes, Xamarin has full Mac Cocoa bindings: https://developer.xamarin.com/guides/mac/