its funny how .net core is open source and everything is happening on GitHub but everybody has no idea on what is going on (release dates, etc.) I'm just waiting for the day when the Wpf repository on GitHub becomes public. I saw mentions of it but it gave me 404 so it's likely private. 
No, the higher versions will have zero impact on your deployed app (intentionally so for 100% backward compat). 
In my experience Solution Architects just make cool Vizio diagrams, talk about clouds, and schmooze with the customers, and don't go anywhere near code... 
You're not even my real dad
Same. In my experience solution architects are commonly professional services/implementation roles that have to do with how a specific customer can make the best use of their vendor's products and services. So not writing code, but making recommendations about which products/services a customer should use and how they should be configured to best address their needs.
Yes 
&gt; Net Core is production ready for the things it is production ready for, but I have an arms-length-list of constant breakage, broken libs, half-baked libraries, major renovations, and deep breaks in the framework that are "soon to be fixed" for far too many quarters now. This is all server side, microservice, stuff too, all of which works just fine on the normal framework, all past RTM. You have a reasonably fair assessment, though I do feel like you're aggrandizing or exaggerating it a tad (e.g., what language support is missing), but perhaps you've just run into a few more rough edges than I have. Transitions are often painful, and with one this significant it's expected. Ultimately I think it's a great and necessary move, but transitioning legacy software has to be carefully evaluated. We're able to simply target the full .Net framework, which side-steps a lot of the problems, but I personally burned a lot of time dealing with issues in mixed solutions when we started rolling in .Net Core dependencies when it was at v1.1. It's a decade old, few hundred thousand lines of code, with ~20-ish separately deployed apps so we cover a lot of surface area - but no desktop GUI, just web and console apps.
I think he means to take advantage of inherent bug fixes and performance optimizations localized to the Framework and not your code. For example, simply re-targeting from 4.5 to 4.7 gets you a bunch of free optimizations and bug fixes.
&gt; I do feel like you're aggrandizing or exaggerating it a tad (e.g., what language support is missing) F#: major code generators, service mappers, compatibility fixes, and core language features for type generation and interactive development. Not just MIA years after RTM, but often dropped, impossibly broken, or reliant on hacks to environment and project files. Project files which then undergo multiple revsisions, so the hacks start needing hacks to get back to functionality from 2006. You think I'm aggrandising? Those bloody yahoos broke *relative paths* in interactive scripts in more recent versions on OSX... Here's the thing, though: I've been doing cross-platform .Net on linux for a dogs age. I should be dead-center for .Net Core's targeting, but the reality has been far different. I cannot justify the time waste of even the last month against the disk savings on our docker images for the last two years. Like I said, .Net Core is production ready for what it's production ready for... But there's a stupendous amount of edges still unaccounted for. This is coming from someone juggling k8s clusters and pure open source cross platform, where .Net Core should be stronger than not. 
Thank you so much 😊
That's right. It can be a bit of a dead-end job and your actual tangible skills (coding) will diminish.
It's an easy mistake to make, no harm done 😊. I already use Auphonic for this show and my two others, and would definitely recommend it to anyone. I'm moving away from Audacity as doesn't seem very stable on Mac OS (I use a Macbook Air for recording). The following tweet should explain the straw that broke the donkeys back: https://twitter.com/dotNetCoreBlog/status/1041415025200689152?
What do you propose? Using a framework from the future? .NET Core 3 isn't even here yet.
"Abandoned" is too strong of a word. It's not like Silverlight; they are still actively fixing bugs and adding minor enhancements to both WinForms and WPF.
No.
I recommend a project that pings an API that is read by a [Particle Photon MicroController](http://a.co/d/4Mny3b5). It's super easy to setup and you could have it blink an LED or something. This way you can have something tangible the kids can see. They'll be able to make a real world connection with what the code does. &amp;#x200B; This could also segue into the Internet of Things.
no u
No
The question is which user interface are people going to use. ASP.net requires knowledge about HTTP apart from the framework itself. Doing a chat app in XAML seems like fun, but it requires an API as well. Perhaps if you provide the API people could start talking to each other through all of their own implementations of the chat. Or doing a Battleship implementation. But the same can be done with a console application writing strings to output like it's 1984! Perhaps that's a great starting point.
Yup, it's in line with your other comments.
I would recommend a project like a mosaic game ( https://images-na.ssl-images-amazon.com/images/I/91senVmXoOL.png ) It introduces arrays, random, images, counters, etc. It’s small enough to be manageable and it has all the building blocks to make literally any tile based game thereafter. 
Upgrading from CLR 2 to 4 is trivial. I have no sympathy for a company that refuses to invest in basic maintenance.
There's details of the incoming http request in the controller that won't be set properly if you just new one up. You'd be much better off moving the code to a shared service of some kind. Then it can be referenced by both without needing to have a controller that's in an invalid state.
Because of questions like yours. You don't know if you should dispose it or not without understanding the implementation when all you want to do is access your own helper method that (presumably) isn't dependent on anything specific to the controller class it's currently in. I'm also going to guess you have just a single project in your solution - just your web app. That's not very usual. Most apps beyond toys will have shared code in a separate library project. Your web app will depend on that library project, as might other executable projects. With your helper method in a web controller, you are unable to share it with other projects in your solution.
Because it's a controller class. Controllers exist for the sole purpose of handling incoming requests. It doesn't belong there, for the same reason you wouldn't put a Walk() method in your Car class. You can do it, but it makes no sense.
I would rather learn *why* to avoid something instead of just blindly taking someone's advice when they tell you not to. Its not stupid to ask a question, that's part of why this sub exists in the first place. As I said in the OP, I understand that the question wouldn't exist if it was in its own class, I just wanted to understand the implications of not doing so.
I was looking on internet on various php/net core comparison and stumbled upon this thread. When i read this: &amp;#x200B; " s "If &lt;senior&gt; ever leaves, it's going to be hard to replace him as Symfony developers are hard to find, whereas there's a booming market for .net developers". " &amp;#x200B; Most stupid thing I ever read. PHP developers are much CHEAPER than .NET and there are issues with availability. You wrote it, like PHP is COBOL or C++. Thousands of websites still use php and will keep using it, new one as well. &amp;#x200B;
I didn't say *PHP developers* are hard to find, I said _Symfony_ developers are harder to find. 
Ya actually a ton of interesting stuff with both including better High-DPI support coming in the future.
That's a solid idea!
It may have a positive (or negative) performance impact though.
Why are you using micro services? Are you aware of the trade offs? I never trust any architect who can't explain the reason "why not". If you are using Microservices are you going to do Docker? What is the plan for caching? All you using REST API's with your micro services or some sort of queuing event driven system? How are you going to share models across micro services? What's the plan for orchestration? I presume you will have an independent database for each Microservice (as per spec) but what is your plan for reporting across the database? What is your designs for production support? Will all services write to a log service and a log database or will each service write to it's own database for issues? What are you using for integration testing? Are you installing dotnet core on Windows under IIS? Why? With a docker image you could use any os. Anyway, these questions are meant to make your mind start working on Architecture. Microservices are the hot new thing but they are also a BITCH and virtually impossible to 'back into'. You have to start from the ground up planning every inch of the way. You better be dang sure of the benefits before you go that route. 
I need to agree on that one. If a company depends on an ancient library where no source is available and the third party won't provide any more support then the company should make a move. ( Even if it means to put an excessive amount of money on the table, using unsupported stuff should be ***expensive*** )
I don't know if kids would be too excited about a to-do list. :) How about a pick-a-path style story game. Each screen can have a couple of actions that take you to another screen, change game state, etc. Students can be creative coming up with the story and the logic. Advanced students can try to do some more fancy graphics or increase the complexity. Add sound for certain actions to increase the hilarity.
I work at a pretty large software company. We rolled our own with identity server. You might look into Azure Active Directory. 
This &gt; Oracle is charging updates for old Java SE versions that have &gt; reached end of public updates stage. was what i meant. &gt;So if you keep your Java SE up to date you won't be charged. Thank you for clearing that up. open source My question / comment did not say anything about closing any source
The primary benefits would be RyuJIT and security hotfuxes. Being sure to not just update the target framework but runtime in whatever .config too. 4.5 is EOL by Microsoft. https://blogs.msdn.microsoft.com/dotnet/2015/12/09/support-ending-for-the-net-framework-4-4-5-and-4-5-1/ It doesn't mean you are 100% vulnerable but possibly out of certified compliance in a PCI or PII capacity.
Take article with grain of salt and it's also 9 years old. Also, one could run out of physical memory too.
I fear you've missed the point. Oh well.
I didn't miss any point, your post was just incredibly condescending in tone and did nothing to answer my question. All you did was criticize my methodology and desire to understand how something ticks. Then you called my app a "toy". Remind me what I'm missing again? /u/markfl12 and /u/throwaway_lunchtime were infinitely more helpful and didn't feel the need to look down on me.
I believe you misspoke RyuJit is used for both .Net and NetCore. Can you clarify?
/u/turdfurg any good?
I could be wrong but my understanding is with .net 4.x it is an in place upgrade so apps will run on whatever version is installed.
Sounds like you're too busy feigning offense to catch the point. The first big clue as to why it's generally a bad idea to new up constructors is exactly the fact that it raised this question in your mind, because the class is designed for a specific purpose and you stuck unrelated code in it that you need to use for different and disparate purposes. Teach a person to fish and all that.. you can learn to discern for yourself why something might be a bad idea. But keep whining about hurt feelings, it's really helping you.
Yes it's 9 years old but actually the way to allocate memory doesn't change so much in Windows. I found interesting to read it in order to keep in mind all those mechanisms...
But your question has everything to do with closed vs open source and you seem to be ignoring everyone telling you that. I'll be stopping answering as well to this thread, because it feels like you are just trolling.
Yeah, that's the core of the question. What needs to be done in order to get those benefits? 
The question isn't whether it runs, but whether it will take advantage of the performance improvements in the newer versions. 
For the most part you can just use a .NET 2.0 library in .NET 4. 
Wow, cheers Scott!
Agreed :)
&gt; I'm just wondering if not using VS makes it appear as if I don't value productivity or something. Yes it does.
Not using an IDE I think will say more about your personality than anything. I don't think anyone wouldn't hire you simply because you don't use VS, it isn't difficult to pick up, but it might indicate you might not fit the environment. If you aren't interested in picking up VS on your own, I might suggest picking up VSCode instead. It is highly popular for a reason, and might reflect better than Vim within the .NET community. While I do understand the appeal of just using a text editor, outside of web development an IDE really is the better choice. There is a lot of quality of life in an IDE. VS by default is rather noisy, but there is a decent amount of customization you can do to reduce most of it. I would strongly suggest picking up an IDE.
Exactly. 1. Compile a c++ lib using C# as source 2. Include it in your x code or Android studio project. 3. Develop your native app. I'm just exploring the possibilities and what would be the flow. I'll probably try something this weekend. I know the idea is stretched but it seems a cool idea at the same time lol
There is much more to an IDE than text editing. I would at least recommend trying VS or VS Code with one of the Vim key binding extensions - ViEmu or VsVim. Then you can better gauge for yourself.
What about a chat app using SignalR? You can also introduce channels, topics and private messages. 
Sorry if I wasn't clear above. For x64, RyuJit is used for both .Net Core (all versions) and .Net Framework (4.6+). For x86, Jit32 is used for .Net Core (1.1, 2.0) and .Net Framework (all versions). .Net Core also supports (to varying degrees in different releases) Arm32 and Arm64 and these use RyuJit. For x64 on older .Net Frameworks (pre 4.6), Jit64 is used. This is an entirely different jit than either RyuJit or Jit32. It is also available to be used in newer .Net Frameworks by enabling the legacy jit, though doing this is not recommended unless you absolutely need it. See this [.Net Blog Post](https://blogs.msdn.microsoft.com/dotnet/2018/06/19/the-ryujit-transition-is-complete/) for a historical look at RyuJit. There is a rough correspondence between the RyuJit versions in .Net Framework and .Net Core: * .Net Core 1.0 ~ .Net Framework 4.6.2 * .Net Core 1.1 ~ .Net Framework 4.7 * .Net Core 2.0 ~ .Net Framework 4.7.1 * CoreCLR master as of 10/2017 ~ .Net Framework 4.7.2 * .Net Core 2.1 ~ .Net Framework 4.8 (forthcoming) 
Build a web API for the business logic and then any language can consume the API.
That's not the point of my question. I've got several alternatives. I'm just digging this one. And for a web server, it's cool, but if you want to manage everything via data (data-driven ui) I'll have to recode everything and build an engine that render from Json (or any other model). I could probably even use unity and receive packages via network in real time. 
Also anything else that may be using client dependency (I had a couple) 
Nothing, you get those optimizations (or degradations if they’ve done something wrong) for free when you upgrade the runtime
Yeah, I've played around with this before. It's possible, but probably not yet ready for production apps. The main thing holding it back is the marshaling. Basically your problem reduces down to two sides: exposing c# as native code, and calling native code from ios/android. Here's a decent walkthrough for the first part, exposing native code using C# and CoreRT: https://medium.com/@chyyran/calling-c-natively-from-rust-1f92c506289d 
No, I have not tried VS. I'm not trying to be one of those evangelical types but I can understand if I come off as one. I'm looking for my first job, so I'm not currently doing .Net development per se. I do development in other languages too (mostly Python/Javascript/Go) and I'm overall happy with my current setup. I use Linux with i3/tmux, so I'm used to a certain type of workflow that doesn't work well with Gui applications. My preference is .Net too which is maybe odd given my development environment. I do recognize some shortcomings of my workflow for .Net specifically but fiddling around with my development environment just hasn't been my priority. My plan is to use VS if I were to be working with .Net professionally, or at the very least try it.
Do some Raspberry Pi projects. I just did a talk that might give you some ideas. [Channel 9](https://channel9.msdn.com/Events/dotnetConf/2018/S314) and [GitHub](https://github.com/CamSoper/have-your-pi).
That's great news and looks very promising. This is the biggest missing piece in .NET IMHO. 
There is a way to call C++ code from Java in Android, this may help you: https://developer.android.com/ndk/ I've never used it, I heard that it has its own problems so it may be as problematic as xamarin. If you try it, feel free to update this thread with your experience, I'm sure people will appreciate it.
Depends on where you work. I'm a solution architect and I code at work, I don't code as much as devs but I get my fair share of "in the trenches" work, around 16 hours each week. 
As a solution architect I would say, understand the domain problem and see if they really need a microservices solution or if they can get away with already in house solutions for much cheeper. Take a look at the staff as well, do they have enough man power to monitor and maintain the proposed micro services solution? As a solution architect you have to keep in mind that whatever is beeing done has to be maintained for a long time. I turn down a whole lot of micro services solutions because of that. Very, very, very few solutions do require micro services architecture. As a closing note, one thing to always keep in mind is that someone has to maintain whatever you are proposing, very important to make judgements based on that. At the end you want to come up with something that will save money and not something that will require a team of 5 devops engineers that client dont have.
Curious/unhelpful - what are the annoying issues you've had with it? I have very little experience in mobile development but may have to start soon and Xamarin was/is a front-runner. 
If it runs on a framework it will use its features. It's only compile time optimizations it would miss out on and I'm not sure off the top of my head how compiler versions works.
Windows Communication Foundation (WCF)
3.5 is old and lacks security, ever thought of putting in the time to pull this guy up to 4.5+?
I'm a heavy user of VsVim myself. My only complaint is when you enter command/search mode, the cursor isn't moved to the command line, so you can't just hit paste, but rather have to click the mouse button.
We're referencing a Microsoft SharePoint 2010 client library that targets 3.5 and will never be upgraded by Microsoft.
Damn
Never heard of that. I've tried to reference the 3.5 library from a 4.x project and I can't remember if it either didn't compile or it threw an exception at runtime when my code tried to call a method from that library. 
Nope. The Microsoft SharePoint client library is the only way to get low level API access to certain functions in SharePoint.
In 3.5, I'm not sure. Does OWIN work on 3.5? I've used that in the past to self-host web services.
What happens when you try to call it from a 4.5 project? It shouldn't matter what version your new project is as long as it's at least 3.5 because DNFX is backwards compatible from the latest version down to 2.0, IIRC.
Use Owin. https://codeopinion.com/self-host-asp-net-web-api/
Specifically: using System; using System.ServiceModel; using System.ServiceModel.Web; namespace WCFApi { class Program { static void Main(string[] args) { var url = "http://localhost:80"; var host = new WebServiceHost(typeof(Service), new Uri(url)); var endpoint = host.AddServiceEndpoint(typeof(IService), new WebHttpBinding(), ""); host.Open(); Console.WriteLine($"Api hosted at {url}. Press any key to exit."); Console.ReadKey(); } } [ServiceContract] public interface IService { [OperationContract] [WebGet(ResponseFormat = WebMessageFormat.Json)] string HelloWorld(); } public class Service : IService { public string HelloWorld() { return "Hello World!"; } } } Requires references to `System.ServiceModel` and `System.ServiceModel.Web`.
You know, I was just arguing with Reddit yesterday, people just didn't understand the concept that legacy is a struggle, that we can't always just update everything trivially.
I would say it depends on what you want to do. But for big projects, it's slow (compile time, debugging). We often have to restart visual studio when debugging. We have to wait for new os features to be implemented. Before it was really unstable with each new versions. In the last years I would say it's a lot more stable. 3rd party bindings are a nightmare sometimes. And to be truly multiplatform (1 codebase for all) , you have to create your own framework (or find an open source one) You can probably find good articles about that. But despite all that, I still find it a good multiplatform solution.
.net 3.5 is well supported as it falls under windows server 2012 r2 support, until October 10 2023. Can you back your claim that it is insecure?
Just deploy the webservice to IIS with .net 3.5 installed. I recommend server 2012 r2 as it's the latest OS with support for 3.5, with end of life being on Oct. 23, 2023.
Hot patches are required to use TLS 1.2 and higher (and does not ship with this support) meaning that if you are making connections via TLS on 3.5 then it most likely is insecure if you are not up to date wit your patches. That’s what I meant by not secure. And we all know Microsoft’s 10 year support is BS, just look at Silver light.
Most of the benefits are on the garbage collection or other low level framework things so test it out with the new framework. Usually apps run faster with more recent versions specially if you happen to use/push specific cases they have improved.
Have you considered just using a microservice to interface your old library? Connect them via some form of IPC and then proceed in the modern world with everything else?
It's JIT so the compilation is just turning your C# code into IL and the lion's share of optimization happens on the target. So the runtime version on the server is very important.
&gt; I can't remember if it either didn't compile or it threw an exception at runtime This post isn't very helpful for anybody without specifics. I am 100% confident you can use your 3.5 assembly in a 4.7 project with the correct binding redirects. Visual Studio will probably do it for you. Use VS 2010 and create a new 3.5 website, reference your sharepoint assembly and get it working. Then open the project in VS 2017 and let it migrate the project to 4.7. Once you have a 4.7 project you can use owin self hosting. 
Could you be more specific about what errors or behavior you're seeing? It's possible you need a binding redirect to make it work. Have you taken a look at its assembly references and dependencies? What happens if you call it from a 3.5 targeting project that is running in a 4.7 clr?
Suicide
This is the exception I get when I target 4.5: System.PlatformNotSupportedException: Microsoft SharePoint is not supported with version 54.0.30319.1026 of the Microsoft .Net Runtime
Ah. They're hardcoding the version. That sucks.
This is the exception I get when I target 4.5: System.PlatformNotSupportedException: Microsoft SharePoint is not supported with version 4.0.30319.1026 of the Microsoft .Net Runtime
This is the exception I get when I target 4.5: System.PlatformNotSupportedException: Microsoft SharePoint is not supported with version 4.0.30319.1026 of the Microsoft .Net Runtime
How is it better than quartz or hangfire 
Would it suffice if you use the newer Core pipeline to host, and locally proxy your calls to your 3.5 host, which will only provide internal APIs? This way you are less prone to the security vulnerabilities in the 3.5 Framework and the 2.0 runtime. 
That's what I thought.
Why would they do that and why even care? I mean if a newer framework can work with their outdated library why not let it happen?
A Microsoft shop will 100% want you to use Visual Studio. 
You could separate code that uses that sharepoint client library to a separare service or console app that you communicate with console input and output. This way you could run your main software with ASP.NET Core.
solid principle may be a bit too advanced for them
Is msmq usually an enabled feature on a SharePoint box? I'm trying to minimize the install impact.
Ah yea fair enough
Find a new library that isn't outdated
Exactly what I was thinking. 
&gt;SharePoint Oh boy. Sounds like it's time for a reevaluation of infrastructure
This what I would do.
If the concern that 3.5 is insecure because you have to patch and cast an enumerable and set an environment variable, you are vastly overthinking it. It's not difficult to add TLS 1.2 to .net 3.5, an afternoon at most. I did exactly this when paypal enforced TLS 1.2 a couple years ago, and we had an old (but supported) commerce application. On that note, Silverlight 5 (released in 2013) is supported until October 2021, not sure where you are getting your "BS" info from.
I think you need to chill a little.
Maybe i do.
I'm pretty sure that's 4.5 or newer.
You could always wait for .net core 3.5 abd hope the version check gets fooled by this... Sorry, -&gt; [] 
oh, even better! 
I love GitVersion, but it is not without its foibles. If you are using TeamCity it will take some tinkering to make it work nicely. 
CSOM has a subset of the features of the server side SSOM library, so CSOM is not an option here.
Not sure why you were downvoted. I was gonna say the same. 
Wish it was that simple. Microsoft is not updating the SharePoint 2010 library.
Broadly speaking, yes. How long have you been a .NET dev? Would this be your first job as one?
Go ahead and start learning VS. It's honestly not that hard to use. There are some great use cases for using command line tools, but if you want a job as a professional .NET developer, you will be expected to be proficient in VS and/or VS Code.
Give VS with the VsVim extensión a chance. It might not support VimScript, but all the modes and commands are supported.
Hehehe
We use it with tfs. It works mostly for what we are trying to do. We are using mainline, but just some instances it calculates some screwed up version. 
You shouldn't. What he probably means is that you have to await the return of one method before calling another on the same context, so you can't parallellize calls for a single request. On the web, this isn't a concern. 
I think I ran into that. In your config file, there's a place where you mark a legacy support flag as true and this problem goes away.
Tangental to to this [When to use Dispose and when not to on a DbContext](https://blog.jongallant.com/2012/10/do-i-have-to-call-dispose-on-dbcontext/) I found it interesting, especially the bit about the enumerator auto closing the connection.
Do you inject the same instance (bad) or a new one each time (good)? They're designed to last for one unit of work.
Here’s a great list of ideas to pilfer from https://medium.freecodecamp.org/every-time-you-build-a-to-do-list-app-a-puppy-dies-505b54637a5d
Oh I guess I was thinking injection into a page model in ASP.NET Core. So, effectively one unit of work I guess. 
Ok, but make sure it's a new instance rather than the same instance. 
Very interesting. Could be useful for situations where you need small JS functionality on a page, but don't feel its necessary to write a whole React component to support an onclick() event. Side note: is it just me or did his comment about "running .NET code in the client which will be more performant" rub anyone else wrong? I mean, isn't the whole point of server side rendering aimed at performance? Surely it's much more performant to build the DOM server side and send it over than it is to force your clients' browsers to do the same work.
The following is a little self promotiony, but it is relevant. I interviewed Ed Charbeneau of Progress Telerik (and the Eat, sleep, Code podcast) for The .NET Core podcast and he went into some of the details behind this. The episode isn't out UNTIL Sept 28th, but the gist is: The client runs a minimal amount of HTML, CSS, and JS. The client creates a connection to the server, and the server does ALL of the work. When the user interacts with the client, the changes that they make (filling in a field, clicking a button, checking a check box, etc.) are sent over the wire as a binary blob, to the server. The server processes the change, does a diff on the DOM and sends _only the changes required to update the DOM at the client side_. The client uses the information it receives to only update the particular parts of the DOM that are relevant (rather than doing a full page repaint). Its exciting stuff, for sure. 
I was in .Net Developers Day in Warsow. Scott Hunter announce there that Blazor Server Side' ll be a part of [Asp.Net](https://Asp.Net) Core 3.0. As I understood this is first easy step to going with Blazor to production. Webassembly seams to be not ready to support whole .Net Standard, probably Microsoft must also do some changes there. Scott highlight that Blazor Client Side and Server Side shared the same code and change from Server side to client side' ll be very easy.
&gt; but don't feel its necessary to write a whole React component to support an onclick() event. In what world is this not possible with 3 lines of JavaScript?
[removed]
Sounds like a remake of ASP.NET Ajax
I loled at his comment and thought the same thing.
Super interested in this. IMO, all the various client side frameworks were developed to avoid the laborious server-side processing of web events, along with the persistence of the client's state. Unfortunately, the client-side language available was JavaScript. Urg. Blazor *replaces* Angular, Vue, React, etc. You write everything in C# / Razor syntax. Considering my shop is using a mix of WebForms, AngularJS and Angular, imagine my optimism! Yes, the initial release is *technically* server-side, but it doesn't make any difference to the programming model. 
Be careful saying this, the last time I brought this up everyone lost their minds. But, yes, this was the promise of Asp.Net's Ajax, and while some of the issues with that were due to how it worked, many of the issues were the result of having no separation between client and server code, and when the client magic had an issue it was very difficult to resolve (except "Let's just wait for Microsoft to patch this!" or "Let's just alter the built in Asp.Net library ourselves"). I think WebAssembly is the future, I think mixing client and server code in one place is always going to get messy. I learned my lesson from Asp.net. At least with Razor you're only generating HTML, so moving it to another web framework would be fairly trivial if you needed to (including just going raw HTML with a template library like Handlebars.js). 
I'm excited about blazor, when released I'll use it in all my projects! I dislike javaacript.
Even though it's still running on the server it's a big improvement to Razor. Razor allows you to write C# on an html page, but that code is only run once, before the compiled html is sent to the client. To create a SPA, the developer needs to separately write Ajax calls (in javascript) to reach server code. This uses signalR behind the scenes to bridge the gap between client and server. The dev wouldn't need to worry about scaffolding out Ajax calls or writing javascript at all. 
&gt; What happens if you just really on dependency injection to provide your DbContext? Trying to rely solely on Dependency Injection to manage your DbContext lifetimes will paint you into a corner sooner or later.
[removed]
Possibly https://docs.microsoft.com/en-us/dotnet/framework/configure-apps/file-schema/startup/startup-element
I don’t know. I feel like the hatred for JavaScript is because people aren’t using modern ES6 or Typescript. React is quite pleasant to work in. I’m worried that Blazor will give our senior devs an excuse to ban React / Angular / Vue when they haven’t even tried to learn them.
Obviously this is possible, but as an example i'm using ReactJS.NET, and utilizing server side rendering for a lot of components. I've got babel, linting, and typescript running against our JS directory. I often weigh the choice of writing vanilla JS directly in my views, defeating the purpose of all my JS tooling, over creating an entire React component to handle a click event.
Server Side Rendering on steroids. Interesting.
It certainly seems that way. 
I would wait for UI frameworks for it to catch up.
&gt;the whole point of server side rendering The point of SSR is that it was the first and simplest way to content to a browser. First it was static content, than basically running code on the server to produce a string and spit that to a browser. This was before even client-side scripting existed.
A few of the frontend components tend to keep a virtual DOM and diff+patch the real DOM. Interesting they would do all this server-side. I'm just afraid it would add latency (networking). But SSR just for the first page would be neat and closer to what others are doing.
&gt; I feel like the hatred for JavaScript is because people aren’t using modern ES6 or Typescript I agree. I think an appropriate analogy is people claiming that working in the back end is too hard because "coding in assembly is just too awful". Of course it is, that's why we use higher level tools like ASP.NET and C# and compile down to machine code. The front end world now has these higher level tools too in the form of frameworks like Angular and React, and languages that are more pleasant to work with like TypeScript. We compile our front end code down to the browser's machine code equivalent. And when people get familiar with this modern workflow, they realize it isn't as bad as it used to be.
And it will be dog slow over anything that isn't a local connection.
[removed]
Thank you so very much 😊
For sure. I _think_ the idea is for local stuff only, rather than over the web. But we'll have to wait and see what Dan Roth, Steve Sanderson, and the rest of the team cook up. 
It's definitely not the only technology to be using a virtual DOM and diffing changes, for sure. I'll be interested to see benchmarks when it gets to that stage. 
&gt; I don’t know. I feel like the hatred for JavaScript is because people aren’t using modern ES6 or Typescript. The hatred for JS is because it's forced upon us. When you're writing server-side code you can choose between Python, Java, .NET, etc. depending on what fits better (or even mash them together) but on the web you have no choice - so you're forced to use JS not only in the places it works well, but in those it doesn't, and that taints you view of the language. IMO if WebAssembly catches on, you'll see an improved outlook on Javascript simply because it's easier to avoid the "bad parts".
Vim is a text editor. Typing text is only a very small portion of the job of a developer. 
The problem with that analogy is that Javascript is not a low-level, high-performance language that's hard to use. It's an easy-to-use, high-level language that's impossible to use for anything practical without layering transpilers and frameworks over the top. Everything that makes JS practical is a hack or a workaround. 
You can run many websites on a single server but will need a proxy of some sort. Nginx is a popular solution.
You can run two (or more) web services on a single host just fine, but they can't listen to the same port at the same time. So if you have a web server that's serving php pages bound to port 80, you have to bind your dotnet core app running a kestrel server to some other port. And as you said, your app binds to port 5000. Now, if you do want both your web services to be browsable on the default http port 80, you'll need a reverse proxy. Nginx is so far as I know the most common and relatively easy to set up. In short you will probably want to configure your server like this: Set up your dns with CNAME's for your host. If your host is accessed by my-server.com you could have appA.my-server.com and appB.my-server.com both pointing to my-server.com. Let your dotnet core app listen to port 5000. Let your php server listen to port 5005. Now configure nginx to listen to port 80 and set up forwarders so that requests for appA.my-server.com are forwarded to port 5000 and requests for appB.my-server.com are forwarded to port 5005. 
Yeah, but all of them would have to be made in ASPNET - correct?
The RMQ transport for NServiceBus just sits on top of the RMQ client, so you get the same connection type as you would if you were doing it on your own. It is a persistent TCP connection and the broker uses a push API. No polling.
Agreed, I'm totally getting a webforms/ajax panel vibe from this and it scares me.
I don't see how, if I'll be redirecting all trafic to a specific port.
And in both cases, writing the compiled code is impractical, so we use higher level languages and tools. I understand that there is a big difference between assembly and JavaScript, but the core issue here and the solutions follow the same pattern.
You will setup rules in the proxy to redirect the domain to its respective port. They can't run on the same port on the webserver. You can use host headers and rules to differentiate traffic. 
This does indeed look interesting. My concern is how it functions in an enterprise-level environment. How would you break everything up into smaller components and deal with microservices? I haven't seen anything in Microsoft's demos about how Blazor will act in the real world.
Thanks for the info. Would you mind providing a source for this information for my own edification?
Lol "without Google" because that matters. You interview with me, prove you know your stuff ... even if that means you use references on Google, as long as you're looking for one right references and understanding them quickly that's all that really matters. You'll have Google in your job, why test you without it in the interview? Clearly he needed Google too based on his "correction" to what you did ...
I ran into this same problem with core. Made me think what's the point? Anyway, my final solution was to run php site normally and use websockets via JavaScript to access an iis server to run .net code and inject the result into the page. had to configure cross domain access for websockets portion. If you find a different solution I'd be interested to hear it!
Upvote as it's good to remind people StringBuilder exists. Bad performance test comparison on concatenation vs. append. The string builder code needs to include additional code i.e .ToString() call to get the same functional object at the end. Also should be looking at objects in memory, not just speed. 
It might be binding to localhost; rather than the ip address so could access them both from the same domain and port by adding ngnix in front as a reverse proxy: https://docs.microsoft.com/en-us/aspnet/core/host-and-deploy/linux-nginx?view=aspnetcore-2.1&amp;tabs=aspnetcore2x For direct external access you can bind to all ip addresses via a varity of different methods such as config, conde, enviroment var or command line param `--urls` https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel?view=aspnetcore-2.1#endpoint-configuration e.g. for http on 5000 and https on 5001 `dotnet run -c Release --urls "http://*:5000;https://*:5001"` 
Do you have a good netcore 2.x getting configured guide? Sorry to bother.
I think there is only 1 thing missing from that time comparison. The final string needs to be allocated on the string builder. It shouldn't really add much at all to the time, but we do need to call ToString() on the string builder and save it to a variable in order to get the actionable time. String builder is also a great thing to bring up in interviews. You can show that the O is better on string builder but just mentioning that you would use it even when short handing to concatenated strings is important given the situation. It shows the interviewer that you understand hidden costs.
&gt; The string builder code needs to include additional code i.e .ToString() call to get the same functional object at the end. Does it? I was under the impression that calling `ToString` gives you 'copy-on-write' semantics. Which is to say, you get a string wrapped around the current array and the next time you modify the StringBuilder it creates a new array that copies from the now-frozen array. But I could be mistaken.
Compete for building products? Sure. Users of apps dont care what it's built with, and if this tech allows teams to create faster and better with less work, then everyone wins. Will it overtake the current frameworks? That's unlikely, due to the sheer momentum and vast scale of deployment of javascript. It's not just in browsers but also server-side and everything in between like serverless/functions platforms. .NET is still facing plenty of competition with Java, Go, Rust, etc, so it's not like it's already an overwhelming winner, so it'll be a long time, if ever, that we see a frontend framework compete with the majors today. That being said, WebAssembly will start getting better rapidly and we'll probably start seeing all kinds of languages targeting it as a platform, leading to many more frameworks as choices.
I didn’t know stringbuilder existed before last week, but knew that strings are immutable! So upvote from me as well! Easy to use, and gave my app an overall good performance boost!
.NET manages its own chunks of memory and has been using Windows' `VirtualAlloc` function since more than a decade. But how it manages the chunks of memory has improved a lot and I think an app is more likely to run out of physical memory than a sufficiently sized section in virtual memory. But a lot has changed since then in .NET itself: [2GB object limit gone](https://github.com/dotnet/coreclr/pull/8853), [GC and Memory Allocation got better](https://www.infoq.com/news/2011/10/loh-net-gc )
There's no "current array". It's a rope.
&gt; You got a better alternative? Yes, and I explained it.
Up to a point. See my other post on this thread.
That is the intended effect in the normal case.
I'm guessing it'll be fantastic for targeting low powered mobile devices. But that's one very specific use case.
It also is a pain on syncing server side to client since you're forced to do JS these days so a lot duplication is done on both ends which effectively increases the chances for errors and also violating DRY. The fact that people use JS these days like assembly where people compile to rather than a High level language really makes you wonder why wasm wasn't done earlier than this. Like that's how we do stuff on the desktop world where we abstract assembly and compile to that. But the problem of compiling to JS is that it isn't as performant at all which creates this weird rift between devs who swear to use vanilla JS and another side where Transpilers and won't touch vanilla with a 10 feet pole. WASM can't get near enough as it is, and hopefully we could upgrade HTML as well in the future.
10.0 feet ≈ 3.0 metres ^(1 foot ≈ 0.3m) ^(I'm a bot. Downvote to remove.) _____ ^| ^[Info](https://www.reddit.com/user/Bot_Metric/comments/8lt7af/i_am_a_bot/) ^| ^[PM](https://www.reddit.com/message/compose?to=Ttime5) ^| ^[Stats](https://www.reddit.com/message/compose?to=Bot_Metric&amp;subject=stats&amp;message=Send%20this%20message%20to%20get%20some%20stats!) ^| ^[Opt-out](https://www.reddit.com/message/compose?to=Bot_Metric&amp;subject=Don't%20reply%20to%20me&amp;message=If%20you%20send%20this%20message,%20I%20will%20no%20longer%20reply%20to%20your%20comments%20and%20posts.) ^| ^[Patreon](https://www.patreon.com/MetricBot) ^| ^[v.4.4.5](https://www.reddit.com/user/Bot_Metric/comments/8o9vgz/updates/) ^|
This is exciting since this also entails that Blazor client side is semi-commited since the whole programming model is the same. Even though it's currently experimental, the whole tooling for VS (intellisense, refactoring, C# goodness) alone makes it very nice to work with. Right now remade a small part of our internal Angular app to Blazor, and could easily switch to client side or server side by exchanging which implementation the interface was using, either consuming it directly on server-side or using HttpClient on client side. Our .Net team would love this to mature quickly as sharing models and validation methods on both ends would cut a lot of duplication we do at the moment. Server-side would do fine with our internal apps since latency isn't a problem and I'm quite excited for this a properly decoupled server-side blazor project should be easily switched to client side if needed to scale, so I can start using Server-side once it's mature enough while also learning client side of it automatically.
Yet another incomplete article that doesn't follow basic performance evaluation guidelines like using a benchmarking framework. If you want to evaluate the memory/execution time impact of these two approaches then you need to do a whole lot more including testing it out with different length strings and the number of strings (concatenating up to 4 strings at once results in a different method call to string.Concat) as well as making sure you aren't actually testing a scenario where concatenation is a compile-time constant. All things considered this article adds mostly confusion and serves as a really bad basis to learn about the subject.
Ok sounds you already are on the ball. I subscribed to your show!
You subscribe with your consumers to RabbitMQ queue. RabbitMQ passes messages to consumers in round robin schedule
Plenty of good points here already, but it's worth reiterating that golden rule that applies at all times: **Do not optimise early.** Yes, stringbuilder is "faster" but if you're making a point of using it on an operating that takes 1/1000th of a second to run and happens once a day, you're not really saving anything valuable. If you've got a tight loop that runs on some hefty processing, then you're talking. 
My friend set it up on his server using nginx, he just had different subdomains for each and different ports for other things. He had like: \- [app.domain.com](https://app.domain.com) for aspnet other service \- [domain.com](https://domain.com) for his portfolio \- [domain.com:4333](https://domain.com:4333) for aspnet cloud service I tried doing the same on apache - seems rather tedious, but I think it's possible.
Thank you a lot, I'll definitely try that solution.
Do all events get sent or just the required events? If I have a single C# onclick event for a particular DOM element then I’d assume other onclick events for different DOM events wouldn’t also go from the client to server. Also, can I push changes from server to client? Lets say I create a TPL Dataflow ActionBlock in Blazor and that links to a background service’s Broadcast Block. Could the Blazor ActionBlock then update the page? I currently use SignalR Core to do the same thing, except Javascript does all the DOM updates. I probably wouldn’t use this to replace client-side only JavaScript logic, but I see this as extremely useful when the only thing Javascript does is make HTTP calls / process DOM updates from the server.
that guy is such a moron that he didn't know /u/kiksen1987 is the correct way to tag people on reddit. What a scrub.
Exactly. IMO, Blazor is to client-side apps what WebForms was to web apps. WebForms was a crutch for people who didn't understand what HTTP verbs are/meant. And UpdatePanel? Suddenly, everybody knew "AJAX". Microsoft is well-known for keeping their developers complacent. All this being said though, I'm a big fan of .NET/Microsoft, but not Blazor.
Blazor is for complacent .NET developers.
Actually agree partially. The "real" upcoming Blazor, that will run client side (using web assembly) looks great. But running DOM manipulations server side has a very negative performance impact as someone else pointed out in the comments. 
Blazor is to client-side development what WebForms/UpdatePanel was to web app development. It's a massive crutch for complacent developers.
Sound a lot like WebForms with update panels
If you don't do .Net, then not using VisualStudio is not that unusual. If you are going to work in a place that does mostly .Net, you will need to learn how to use it. Being your first job, it may not be important that you already know how to use it, but you may be expected to learn. If its a place that does non-MS stuff and is starting to use .Net Core, there will probably be less expectation that you use Visual Studio. Where I work, the people who are used to working on other tech stacks have switched to VSCode for almost everything (front and back). 
I've used pull-up at work. It ties into our source control pretty well (BitBucket), and leaves comments on the PRs indicating what some of the issues are, along with links back to the PU tool to see the full details. The Devs have been pretty responsive with the issues I've submitted to them as well. There are certainly a lot of options for tools like this, and if you're looking for something to analyze your code prior to check in, this definitely isn't the tool. But if you're working with a team, or if you want to have some passive analysis going on in the background to help find issues prior to merging into master, I think Pull-Up would work well for you. &amp;#x200B; (Note, I have not used SonarQube, so I cannot compare between the two.
I'm now finishing up a project where StringBuilder became a major problem. The client is a massive US corporation trying to get off their mainframe. They hired a third party to convert all of their cobol to C#. This created a mess. The resulting system was huge, hard to maintain, and really slow. In attempt to improve performance, I did a thorough analysis of their converted code as well as their framework. And I discovered that all string values across the entire system were implemented as StringBuilders. Initially I was mystified as to why they would do this. Then I discovered what I think is the reason. The programmers were mainly C++ programmers. And I believe their plumbing code had originally been ported from C++ to C#. In C++, string manipulation is usually done with a simple for or while loop iterating over pointers to characters. It turns out that the array index operator for strings in C# is read-only. But for the StringBuilder, it's read-write. So they used StringBuilders instead of strings, because it made porting the code easier, and after all, StringBuilder is faster and more efficient using memory, right? Any time an if statement happened in the code that compared two strings, both strings had to be passed through the ToString function. It turns out that the ToString function on the StringBuilder is exceedingly slow. If you're using StringBuilder for its intended purpose... doing lots of concatenations, then it's not a big problem because you're only doing one ToString at the end. But if you find yourself doing a lot of ToStrings in situations where performance is critical, find another way. If you absolutely need fast string manipulation, there are ways to access string memory using the unsafe keyword with BlockCopy. I did benchmarks, and this approach is significantly faster. Have a look a the source code for StringBuilder. It's available on the internet. A major part of what makes it fast is avoiding the creation of string objects.
[It allocates a new string and writes the chunks into that result and returns it](https://referencesource.microsoft.com/#mscorlib/system/text/stringbuilder.cs,330).
StringBuilder is a linked list of string chunks. When you call ToString it concatenates the chunks together into a new string. Source: https://github.com/dotnet/corefx/blob/master/src/Common/src/CoreLib/System/Text/StringBuilder.cs
Interesting - thanks for the warning!
Nice work! For those who want to develop high performance applications to Create, Edit, Convert or Print Excel spreadsheet file formats without requiring Microsoft Excel… have a look at this website: [ZetExcel - Excel library for .NET, Windows Forms, ASP.NET, Mono, WPF, Silverlight](http://zetexcel.com/)
&gt; initial and final id is 1-means new instance is not created for these operation since it does not change the value of str. You may wonder about how compiler shows this much intelligence. Compiler has nothing to do with it. .Replace and .Trim likely check to see if there's anything to change on the string before making a copy... if not, they just return the same instance. Since strings are immutable they can safely do this without risk of the caller expecting a different instance.
&gt; If you absolutely need fast string manipulation, there are ways to access string memory using the unsafe keyword with BlockCopy. I'd suggest looking into `Span&lt;T&gt;` instead. Though it is well supported only on .Net Core.
That was my initial thought as well. Using stopwatch for timing execution is just plain wrong, even more so for a micro benchmark. He is not wrong about the gist of the topic, but as an industry we really need to take pride in doing things the “best practice” way for articles as they can have more impact than we think.
I've managed to set it up on nginx, but what I've read is that IIS is Windows-only, hence why it was a viable solution for me. Apache was just too strict to set it up how I wanted.
Your question is really vague. There are thousands of ways you could structure a data model in XML. You should work backwards. How do you want the PDF to look? What XML structure does Aspose want? Once you know that you can figure out how to map the JSON to that structure. Like the other guy said if possible make data model classes for the JSON and XML which will make it a lot easier to manipulate from code.
I thought this was kinda what MVC areas were trying to be. I like the DDD nature. I could see this fitting well with teams. Breaking conventional layout and the "new project wizard" mold is most of the battle I think here. Routing, while acheivable in this DDD, seems less trivial than co-locating the assets with their type. &amp;#x200B; The rhetorical "could you figure out where to start?" fits OPs narrative, but well organized "infrastructural code" isn't that hard to figure out. Also, raw design-time code isn't necessarily the best place to start anyway. Tests, docs, or even decompiling/rendered source/sniffing can help figuring out where to start.
Oh so server-side doesn't requires WebAssembly? I was having trouble understanding why one would use server-side vs. client-side Blazor except some edge cases.
3-Tier architecture is fine. What many dotnet developers miss I think is the value of small, single responsibility components and applications. We tend to be so focused on DRY and re-usability that we over architect and tightly couple. I have found developing self contained features to be much more maintainable and easier to work on in general. 
This is exactly what people said when WebForms will come out. History will judge.
&gt; That's like saying Javascript is for wannabe programmers who don't understand real programming What? Using the language native to your platform is the smart thing to do. I never implied otherwise. &gt; .NET programmers, like all other kinds of programmers I've met, like to use the tools that make them the most productive. This is exactly my point. *Complacency*. Most developers are comfortable learning *at least two* languages/eco-systems. Again, look at WebForms. Developers made that same argument you are making. When you don't use the native primitives your platform provides, your plagued with issues. Ignorance is bliss? Anybody remember Page.IsPostBack? Viewstate? The developer community eventually moved to MVC, thank God. The same thing will happen to Blazor.
It immediately made me think of webforms, when I first read about it. 
This is great to see. The last month was pretty bumpy, but still, good too see this finally hit GA.
It's also found in games dev alot (the MS C++ toolkit is pretty advanced, and given DirectX, it only makes sense).
https://github.com/dotnet/BenchmarkDotNet
Above I said that Blazor doesn't hide you from HTML or CSS. No one I know was saying that about WebForms at any point since I started with .NET 13 years ago. Back then, abstraction was preferred because the web wasn't very standardized and because Microsoft was the worst offender at the time (early WebForms liked to make UIs that didn't display properly in other browsers). Blazor is much more like Razor and MVC than it is like WebForms.
You're conflating productivity with complacency and assuming that developers who would use a solution that makes them the most productive automatically aren't well versed with at least two languages/ecosystems. That's a very limited view of the community, and not a necessary part of the technology at all. In this case the "native primitives" the platform provides is the DOM, not Javascript. Blazor emits WASM to work with that directly. Not only that but the .cshtml files are HTML (presumably v5), and will need to reference CSS. THOSE are the native languages of the web: the DOM, HTML, and CSS. Javascript has just been a convenient controller for all of them. Even in the early days, it wasn't the only choice and we've been able to run VBScript and many other languages in the browser with the aid of plugins. There's nothing essential about it though. WASM simply replaces that with a much more efficient option. We may even see a day when Javascript itself compiles to WASM and Javascript would not even be a "native" language in the browser anymore. That day is coming I think, and why not? Now, I think we can agree that SSR a step removed in the stack, and potential abominations like ViewState could creep in again, but we'll see. I hope not. Or, if that does become part of the implementation of SSR, then I'm hoping that SSR isn't the only possible configuration. Personally, I'm only interested in using Blazor to replace Angular, but a LOT will have to happen before I would put any trust in that. It would be a shame to revert back to having essentially a client-server architecture again a la ASP.NET without open REST APIs. But see one of the primary Blazor examples, and you can see that none of that kind of thing is a part of the mix: https://github.com/aspnet/samples/tree/master/samples/aspnetcore/blazor/FlightFinder 
Try it and find out. It's really the only way to measure the size of a string. It probably maps to a GDI function that is used everywhere for that purpose, I'd imagine.
DbContext is an IDisposable. Encapsulating it in a using block should be sufficient 99% of the time.
Have you added a reference to System.Runtime.Serialization ? It's a standard .net under references-&gt;add reference-&gt;assemblies. Unles youre using .net core in which case it's nuget System.Runtime.Serialization.Primatives. Not used that one, so might be wrong for .net core
&gt; Above I said that Blazor doesn't hide you from HTML or CSS. That hardly represents the entire client-side tech stack. &gt; No one I know was saying that about WebForms at any point since I started with .NET 13 years ago. But you agree that more people *should* of, yeah? Let's learn from our mistakes. This... &gt; Back then, abstraction was preferred because the web ...and... &gt; early WebForms liked to make UIs that didn't display properly in other browsers ...indicates you don't get what the issue with WebForms was to begin with. Rendering issues has nothing to do with the issues of WebForms. Also, HTTP verbs were standardized. You are confusing html/css with WebForms. Page.IsPostBack? View state? UpdatePanel? These were all massive crutches to keep people in .NET.
&gt; Rendering issues has nothing to do with the issues of WebForms. I beg to differ. Early WebForms rendered terrible in other browsers. WebForms has other issues, some of which you have mentioned. The one I heard most back then was ViewState, and how it was turned on naively by default. &gt; Also, HTTP verbs were standardized. You are confusing html/css with WebForms. HTTP verbs were standardized, but they weren't used back then for anything but getting pages and submitting forms. Early requests were AJAX and that wasn't standardized across browsers. I also didn't say HTTP, I said web. I mostly meant the browser, JavaScript, their rendering engines and the things they couldn't do that they can today. &gt; These were all massive crutches to keep people in .NET. Yes, and they are all things that don't exist in [ASP.NET](https://ASP.NET) MVC or Razor templates. Blazor uses a virtual dom to patch in changes, but so do all the other JS based frontend frameworks and libraries (Angular, React, Vuejs). &amp;#x200B;
Absolutely.
I think I did these and they didn't work :( 
Do note server side blazor is similar to how SSR works also on most js frameworks these days to speed up page loads and mobile pages since spas runner terribly on mobile js engines. The only difference is that nothing is handed off to the client since server blazor works entirely on the server. But the hybrid server side render then to hand off to client side is on blazor's roadmap. The most similar I can compare server side blazor would be WiseJS and it isn't really that bad using it either.
It's not about disposing it, it's about creating it and when you'll need to retain explicit control over that - which IoC will box you out of in a hurry. You don't always want a new DbContext, and you don't always want to share an existing one. In all but the simplest of applications, you want to retain control of DbContext object lifetime, and unless you're a masochist, you probably don't want to manually pass instances all across your call stack either.
It uses the same code to generate HTML in the client model as it does in the server model. In both cases it is C# code doing a render from a template and a model and then doing diffs on a graph of elements during events.
Your post has been removed. Self promotion posts are not allowed.
Are you generating images on the server? There are a few imaging libraries that have similar functionality..
Yeap It does the same. The only difference is that the controller isn't running locally on the client but on the Server. It isn't really comparable that much to WebFroms imo and I agree with your assessment, it's more like an SSR built modern JS Framework (React, Angular, Vue) but purely server-side with .Net core in exchange from Node.js. Server-side isn't built for a lot of users in mind, but rather for specific cases like all tools we do. Although I properly decoupled project could easily switch to client side as well if they wanted to scale. All I do to switch on my PoC right now with blazor is change the script to ```_framework/blazor.webassembly.js``` from ```_framework/blazor.server.js``` and switch the DI implementation registered for ```IServices``` contracts to use one with ```HttpClient``` instead of directly consuming the server-side Services.
&gt; Learning paths consist of step-by-step tutorials with interactive coding environments that provide free fixed-time access to Azure resources - without requiring a credit card. That sounds promising. 
I see quite some usage for in on internal LOB apps since latency isn't really a problem since the server is in house or in the cloud on the same/nearest region. So one can create interactive websites without having two different language stacks e.g. JS / .Net in our case. It also cuts off the need to validate stuff twice since you shouldn't really trust data coming from Client side that much, so you'd have to validate as well on server-side. Aside from that, the main reason server-side was made was because the architecture is necessary for future targets for Blazor which needed the server side model. One of the PoCs built by Steve Anderson (e.g. the creator of Blazor) was using the server-side model to create an Electron app using Blazor communicating through Kestrel, wherein Electron only did the UI presentation but most of the hardwork was being made through a more performant runtime (e.g. .Net core) instead of node.js which also had full access to .Net APIs (e.g. IO, Network, etc...). It was also needed for running the .Net wasm runtime on a web-worker instead on the main UI thread as well as they have plans to experiment on that model.
Can you get angular though nuget, or do you still need to install npm? I've avoided getting into angular because the whole setup seems excessively bloated and unnecessary
This is what we're using in the office right now. https://github.com/MarkPieszak/aspnetcore-angular2-universal
Not sure, we use NPM. Yes it is awfully bloated but that's just the state of the webdev world right now.
Read logs?
Bonus points for the first developer that manages to run a production workload on learn by swapping between as many accounts as possible.
I did not think about Electron apps!
Generating a SVG. But due to specific text placement I need to measure my strings word by word
It's specifically bitching about not being able to find that time in that assembly, and looking at it more carefully now, it looks like it is the .NET 4.X version. Can you try it again and just make sure? If you get a different error then post that. It may well require more than one assembly referenced. To help you hack through it yourself, the bit after "Could not load type" tells you which type it wants, which assembly and which version. All the framework versions are 4.0.0.0. What's also concerning is the red wiggly line under Fsharp. If you hover the mouse over that it should tell you an error (or not, sometimes there are false positives).
That's neat, what I have been looking for before when looking for examples.
I am trying to do this exact thing in Windows, but stuck on step 4: c:\MyApp&gt;dotnet sln add **/*.csproj Could not find project or directory `**/*.csproj`. Usage: dotnet sln &lt;SLN_FILE&gt; add [options] &lt;PROJECT_PATH&gt; Arguments: &lt;SLN_FILE&gt; The solution file to operate on. If not specified, the command will search the current directory for one. &lt;PROJECT_PATH&gt; The paths to the projects to add to the solution. Options: -h, --help Show command line help. c:\MyApp&gt; Any ideas? Thanks
It's really easy to build lightweight applications in asp dotnet core, so don't be put off. You can easily generate minimal boilerplate projects for a web API or MVC application from the command line.
I would think Razor Pages would be perfect for a basic blog. https://docs.microsoft.com/en-us/aspnet/core/tutorials/razor-pages-vsc/?view=aspnetcore-2.1
[removed]
Learning the dotnet CLI is easy as pie, and to clarify: you do not under any circumstance need visual studio for dotnet core. Use notepad if you want! I would, however suggest the dandy Visual Studio Code (not to be confused with Visual Studio). It's cross-platform, lightweight (as electron gets), fast, open source, hackable and extensible (builds on extensions) and currently very mature. You can use it for pretty much any language you want, be it C, C#, Java, PHP or Python, there is good support for both debugging and editing for almost all imaginable languages (because of extensions) It's personally my favourite editor (and IDE) of all time.
Even though I do dislike making Electron apps, it can probably be a gateway for MS to make a true x-plat desktop UI programming model. The fact that MS now owns GitHub makes it very tempting to imagine, say you'd have a choice between an HTML UI model via Blazor and maybe if they'd hopefully have a XAML renderer UI model as well running on maybe a canvas layer on Electron. This would not be as performant as native obviously but if they could try and isolate the Electron to UI tasks only, maybe strip some un needed stuff on chromium to the minimum required to bootstrap Blazor / XAML and do most of the heavy lifting through .Net core. That could really be a tempting programming model for those Electron devs at the moment. More so if they can make the XAML / UWP model work without any code changes since you could theoretically compile a Windows app in pure .Net while the x-plat ones compiles to the Electron UI wrapper.
How is everyone deploying related infrastructure with this? I've been on AWS Lambda for a while now using the Serverless Framework and have enjoyed using CloudFormation to setup related things alongside my function. Is that something natively supported or would I have to script out separately with Azure Resource Manager? Also, is there a more "serverless" alternative to CosmosDB, yet? I look into this for every few months and it seems like it's still a $20 minimum for a single collection. That'd add up pretty quickly for the few integrations I write for my org.
The biggest problem I could see on scaling is the memory it'd eat by maintaining the App States per connection. This could probably be mitigated if the SignalR connection disconnects after X idle time and some how have a way to restore the App States when it reconnects the moment the user tries to interact using maybe a encrypted session cookie / storage passed to the client browser. They're still experimenting on the reconnection strategy as far as I know on SSB (server side blazor), but it'll be interesting to see never the less. I do agree AzureSignalR could alleviate this to a point (+ points for their service too) and depending on how big your App state is, you could go for 10k+ users I think.
&gt; lightweight (as electron gets) VS Code is nice, but I don't think electron and lightweight fit in the same sentence (cause electron takes up all the space, haha). &gt; you do not under any circumstance need visual studio for dotnet core I think the OP understood that. He said "moving towards using the Microsoft tech stack permanently" so I mentioned VS. VS Code might a staple for every dev machine, but the C# support is not good as VS. And VS Community is free, so I don't see a reason to not use it over VS Code (unless OP's dev machine is macOS or *nix) 
Haha, yeah... electron is quite memory intensive, but let's compare it to the full VS; this is in the context of C# after all. With a few editors windows open (21) on my workstation at work it's consuming about 750 MB of ram, VS Enterprise is consuming about 830 MB (3 windows open), highly dependent on circumstances, I'm aware, but short of VS Code being a full blown IDE, I think that's perfectly fine. To add: I've never seen a loading bar in Code, but I frequently see "waiting for background task to complete" in full VS, and other nonsensical things, sometimes I get a loading bar when simply creating a new file, and it likes to stick around for a while. Bare in mind, this is on a Xenon workstation with 128 GB of ram. VS can frustrate me to absolute insanity, but I've not been frustrated with Code for as long as I have used it. Some features were lacking/lackluster a while ago, but it has quickly been improved. I don't agree with "VS Code not being as good as VS for C#", what features are you missing in particular? For one, VS Code has "code lense" (`3 references` etc... over class members), VS Community does not. It feels crippling. Debugging in full VS has *some* decent features, but not something I can't live without. I'm super biased here, but I don't believe it's entirely unfounded.
Yeah I currently use VSCode for PHP at work. Its definitely the best editor I've used. I'm aware that .NET Core can be developed on any OS now but I am using a windows machine at the moment and doing things like referencing projects and the .sln structures are probably easier on VS as it acts like a GUI for managing all of that. Although I wonder if I should actually get used to using the CLI to do all of those things anyway. &amp;#x200B; Anyway thanks for the tips guys, I'm definitely more convinced about the .NET Core stack now
At the moment it's very basic, they do have plans on a more sophisticated routing model in the future at least. Though it's not prioritized now over other more important features they have in plan at the moment.
Thanks I'll check it out. Quick question though, are Razor pages popular in the industry though? I had heard its quite a new technology, I wonder how many companies are using it? &amp;#x200B; If it's rarely used, is it worth spending time to learn and use it?
Thanks, I guess I'll focus my time on .Net core then. Much appreciated
Vs code is just fine for .net core 
&gt; VS Community does not. I used VS Community until I got Enterprise via MS Imagine/DreamSpark a few months ago. It's an "Ah, nice" feature, but not essential for C# development IMO. &gt; I've never seen a loading bar in Code, but I frequently see "waiting for background task to complete" in full VS VS had that problem but I think the performance has improved quite a lot with VS 2017. As for VS Code, I think OmniSharp's repositories have a summary of issues that exist on VS Code but not VS. [1](https://github.com/OmniSharp/omnisharp-vscode/issues?q=is%3Aissue+is%3Aopen+sort%3Acomments-desc) [2](https://github.com/OmniSharp/omnisharp-roslyn/issues?q=is%3Aissue+is%3Aopen+sort%3Acomments-desc)
Razor views are a staple in .NET MVC development. They are very widely used (in my experience) for layouts in .NET web apps, both large and small.
More popular than you think. 
Using visual studio 2017 enterprise, still loading bars everywhere.
&gt; Bad performance test comparison on concatenation vs. append. I think it even misses the real performance test when it comes to strings: Allocations. In any application large enough where the difference in time would actually matter, chances are that Allocations and GC Pressure are the real performance bottlenecks - even worse if you got strings on the LOH. And any project small enough not having to worry about your GC running haywire is a project small enough not having to worry about miniscule time differences even at an order of magnitude.
If you use Visual Studio there is a wizard to configure the Core template, e.g. WebAPI, Angular, Razor. I'd imagine you can do it from command line too.
How are the cold start times in 2.0? &amp;#x200B; No on wants to wait 2.5 - 3 seconds for the first hit of their API (which is what I ended up with in testing on my 1.x AzureFunction that literally started and returned the count of reccords from a SQL database.
The situation might be different now, as VSCode is fast moving, but last I looked handling multi-project solutions in it was a messy hack fest at best. Personally, I still prefer full VS tooling - I use it for front end only projects even - but a lot of that is simply 20 years of momentum.
Going forward you should only focus on .Net Core. .Net Framework is going to be going the way of the dodo in the not too distant future in favor of Core. Its been unofficially said the next release (4.8) will be the final .Net Framework release.
Razor Pages are quite new, but they have some definite appeal and as a main Microsoft web view tech they'll likely see a good amount of use. The Razor template language is also used in ASP.Net MVC, so you'll have some cross-applicable knowledge regardless of which you use. Currently, there's no doubt MVC is in far wider use than Razor Pages.
To be clear, the above comment was about Razor Pages, which while uses Razor for rendering, is slightly different from using the Razor View Engine an ASP.NET MVC application (core or .net framework 4.x) A Razor page is much more lightweight compared to a Razor View in asp.net mvc. Take a look at https://docs.microsoft.com/en-us/aspnet/core/tutorials/razor-pages-vsc/page?view=aspnetcore-2.1 
Cheers for that, I completely missed the announcement it was out :D
Is that new? I don't remember having to enter card details the last time I signed up for Azure free credits as part of MSDN and developer essentials. I could be wrong though, it was a while back :)
Bit Azure focused. Why isn't this just a part of MVA?
So we are all in agreement that a credit card is required, even though the initial advert states that no credit card is required.
I would recommend getting into serverless development, and .NET Core 2.0 has some cool options for that. [https://aws.amazon.com/blogs/developer/serverless-asp-net-core-2-0-applications/](https://aws.amazon.com/blogs/developer/serverless-asp-net-core-2-0-applications/)
I did a small project in core, and while it's really interesting, I'm not entirely convinced that it's better than writing in C or C++ and recompiling for the desired platforms. The language is so limited that it's really not offering much that can't be had in existing stable tools, and OTOH, is much more convoluted to use than, say a C compiler and "make" 
I use C# and ASP.NET at work, and I tried going down the path of ASP.NET Core in a hobby project at home, and I thought it would be fun to try using Docker, since it's an option; big mistake. Don't make your project in docker unless you are familiar with the workflow, it can make it a hassle to deal with. If you are only familiar with C# .NET and not .NET Core or ASP.NET core, you might have a bit of a learning curve to getting to the final project because the ASP.NET Core way of doing things might be a tiny different. I suggest sticking to C# and ASP.Net Core along with standard deployment. It's a good learning experience!
To add onto One X ... after learning C# Core... go back and learn the Fun times of State management with old net framework RAD webforms. There is so many custom web apps built with [Asp.net](https://Asp.net) WebForms and framework 1.1 thru 4 that you might be able to make some money just being able to convert/patch these old web apps. [Asp.net](https://Asp.net) Framework will be to the web what COBOL was to the old server systems.
MS has some fragmentation when it comes to their learning. They have Dynamics Learning Portal, Microsoft Learning, MVA, and probably some other things. They really need to consolidate some of that stuff.
I don't think there's an announcement yet? I saw a twitter post of a MS Ignite attendee and then realized that 3.0 SDK builds have been out for a while.. 
Nothing particularly wrong with Docker, but it makes certain actions take a bit of thought to do correctly, for instance, making your ASP.NET core site https requires the certificate be available inside the visual studio project, at least the way I did it. There might be easier means of setting up HTTPS, but as a learning opportunity, it was more frustrating than I thought it would be.
What is causing you to think it's not better than writing C++? 
I find .NET Core (2) an absolute pleasure to work with. It feels light, the types really help, Linq is great, F# is da bomb if you like fp. I cannot see myself using anything else soon. I have to support several Node and Rails projects and it is annoying to do so after using .NET Core. So yes, you should. 
We ported all our asp.net code (and we had a lot of it) to .net core in less than 2 weeks, including testing and deployment. Granted, I was a MS products hater (I still think Windows stinks) so our company has always written all C# code in a way that would make it potentially portable which I would recommend to anyone and asp.net core really makes that easy. 
COBOL is very much still around though.
From what I am reading, it's still quite new, and MVC is still the way to go. The reason is because many people are moving towards the WebAPI with a frontend framework model. But if you are doing a basic blog, then Razor Pages might be simpler.
Hey where did you hear this? I watch a fair bit of the asp community stand up and ms released vids and they said they want to move away from the current versioning model (which may explain your point) but they are still going to be releasing updates to both the full .net framework and .net core libraries?
It's not just enterprise. Iot devices. Simple apps, you favorite video games (assuming you like stardew valkey or terraria or starbound or fez or bastion. I coukd go on. 
I'm not sure that it's outright said anywhere, but &amp;#x200B; **You can study the API here:** r/https://www.squaremobius.net/amqp.node/channel_api.html &amp;#x200B; **And in the transport source code:** r/https://github.com/Particular/NServiceBus.RabbitMQ/blob/5800c36c8a32a5dfc94abdc95aa73eeabfdd1fbb/src/NServiceBus.Transport.RabbitMQ/Receiving/MessagePump.cs#L111 &amp;#x200B; **And as the AMQP 0-9-1 spec:** "The AMQP 0-9-1 Model has the following view of the world: messages are published to *exchanges*, which are often compared to post offices or mailboxes. Exchanges then distribute message copies to *queues* using rules called *bindings*. Then AMQP brokers either deliver messages ***to consumers subscribed to queues***, or consumers fetch/pull messages from queues on demand. " &amp;#x200B; I'm not 100% sure (I'd have to look at the source code), but I think the way it actually works logically, is that the broker delivers the message to the queue and then immediately tells the client (via the persistent TCP connection) that there's a message available, at which time a 'get' is performed and then delivered to the registered handler via event. That's it guarantees the delivery to the queue while also being proactive about the delivery. So it's not a direct push per say, but it is a push in that it is not a poll. You can see in the transport source code that the message is received via event (registered before starting the 'consume'. You could easily verify the behavior by looking at the RMQ C# client source code. Just look for where the 'Received' event gets invoked and trace backwards from there. If you wanna test this, set up a test that drops messages on the bus at staggered intervals. You'll notice that the receiver will get messages instantly. If you do the same test using something like Azure Service Bus, you'll notice that the receiver gets messages in bursts on an even interval despite your staggered publishing. At least that was the behavior the last time I ran this test a little over a year ago. &amp;#x200B; RMQ suports both push and pull. Just by reading through the docs, you'll see that the "pull" is done by calling "get" (or "BasicGet" on some clients), and a subscription (the push api) is done by calling "consume" (or "BasicConsume" on some clients). To do the poll (not advised, I believe you'd have to write the loop it yourself and call 'gets'.
That sounds like a best case scenario. Kudos to you guys for the foresight. 
Gimme a static site built with Elm backed by F# web api. 
Got modules
I think you should build all of your projects in .NET Core.
&gt; Microsoft is also working to implement Razor Components, or server-side Blazor, in version 3.0, which integrates Blazor into ASP.NETCore and allows it to run on the server with .NET Core. This is interesting. Hope blazor catches up.
Kind of , it’s mean for smaller applications that just need a page and some code . Kind of like old school .asp pages but with a decent language and view engine . 
I think he means by the community. .net core is a hell of a lot nicer to program in so we will be seeing a lot more of it.
Ive been porting for three months and stilk have at least 2 months to go. We have been moving each side project to .net standard with the eventual goal of moving the api to core. Before that I was working on core for a year. I have learned to hate .net 4.7.... its so kludgy in comparison.
I really love C, but it isnt a golden hammer.
I wasn't even aware they'd got that far, although in my brain it's still March :)
Yes, I find it a bit confusing. Does Channel 9 still exist? I can't remember if that was training or news.
I think they dropped the Web Assembly client-side version of Blazor for this server-side version instead.
You will find so many examples of micro apps here https://github.com/dodyg/practical-aspnetcore
This is not even close to true and has been mentioned repeatedly. I’m currently at Ignite, They demoed Blazor with Web Assemblies yesterday. They stated that the current limitation is the Mono .net implementation and it will take time to fully bake. In the mean time you can use server side Blazor and flip to client at a late time with a few configurations. In my opinion, this is the most exciting project since the announcement of .net core.
[removed]
Dumb question, what are fortunes? The article mentions benchmarks for plain text, json and fortunes.
https://frameworkbenchmarks.readthedocs.io/en/latest/Project-Information/Framework-Tests/#fortunes
Try retargeting your project to the .NET Framework version Infer.net depends on (looks like you are using .NET Core). My guess is infer.net isn’t updated to work for .NET Core yet.
For Date of Birth, .net already gives you the `DateTime` struct, which Json.Net already recognizes and converts to a unix timestamp when serializing to JSON. So instead of having 3 properties, you'll only have one.
Sure, but you can do that in .net code, which avoids the joins in SQL. Something like this: public class Person { [JsonIgnore] public int Id {get; set;} [JsonIgnore] public string Url {get; set;} [JsonIgnore] public DateTime DateOfBirth {get; set;} public object Avatar =&gt; new { Id = Id, Url = Url }; public object Dob =&gt; new { Month = DateOfBirth.Month, Day = DateOfBirth.Day, Year = DateOfBirth.Year }; } The first three properties can be stored in SQL. The last two properties get serialized to JSON, creating the structure you need without having to declare bespoke domain objects. (Apologies if some of the property and attribute names are incorrect. But you get the general idea.)
Great! Thank you. This type of anonymous object creation was exactly what I was looking for. It spares me a lot of joins and .cs files.
The obvious problem with this is that it only works for serialization to JSON. If you also need deserialization, then you probably will need to create concrete `Avatar` and `Dob` classes for Json.net to deserialize into. But you can still use them to basically just set the first three properties, so your SQL schema doesn't have to grow more complex.
Yeah the [C# Discord](http://aka.ms/csharp-discord)
What is the difference to an ajax calls calls an webservice which returns an html-string which is then added to the webpage using javascript `element.appendChild(aChild);`? Why do you think it would be dead slow?
Your posts are amazing. Congrats!
You have two tabs, one built with a dynamic set of json (around 10k on average) which gets transformed into 10 megs of HTML on the client side and one with the contents of an encylopedia which get downloaded from a static server and shown on the tab. You rapidly click the two tabs to flip between them causing the browser to set the display:none attribute on the tab you're not looking at. Angular does this with 2 ajax calls, one for 10k (non-cacheable) which uses a previously retrieved template to render into the DOM and another for a cached bit of data which another template would render into the DOM. Switching between the tabs would just flip some DOM elements (ngIf* or whatever). Blazor, presumably, does this by doing a call on every tab click, rendering huge amounts of DOM on the server side, building massive (let's say 40MB) blobs of HTML to pump down from your server's memory into your browser, and does this every single time you click a tab since it has to go back to the server every time, rebuild the DOM (since we lost it when we diplay:none'd it) and send it back down the wire... Granted, this is a bit contrived, but even spending like 5 seconds on this seems to reveal some massive deficiencies. Client-side Blazor made some kind of sense, this just sounds like UpdatePanels all over again.
Yeah, if you aren't customizing the output at all it really won't matter which tool you use.
Thank you [whitebearphantom](https://www.reddit.com/user/whitebearphantom) ! :) 
When reading code I like to substitute "StringBuilder" with "List&lt;char&gt;" in my head for easier understanding.
Well written!
It's an incredible work.
yo dawg
And the last page of the source code is all right closing parentheses.
Link to source?
Appreciate the feedback. We are more so in a research phase as to what the best approach is and this was one idea. Not sure if we will persist with it or not. Thanks for the resources!
Hmmm, Azure AD B2C looks like it fits the bill. Similar pricing to AWS Cognito, and easy to get started with an [Asp.Net](https://Asp.Net) 5 application (which we are stuck on for now). The management of it is kind of odd, as you can't manage it from your azure sub, you have to 'switch' to a new directory, which is kind of clunky... but I may fool around it. 
Thank's a lot [AlphaDeveloperZA](https://www.reddit.com/user/AlphaDeveloperZA)!
It really is. I have a lot of programmer friends that used to avoid .NET now looking into it.
That site is cancer
I don't know enough to tell if you guys are joking...
I think platt’s joke refers to Python which dies not use brackets. The LINQ Statement could have been true for the old Compiler (again insider joke) I am a .net professional and the new Microsoft is blowing my mind every week. 
Im porting everthing I get my hands on... I find it so much better.
Your post has been removed. Self promotion posts are not allowed.
Don’t exaggerate man. They are there.
Where? How many are in the world? 100? 
You did a project with F* (Star not Sharp?) ... wow - can we hear about this? You would probably find a lot of people interested in you if you just go public with that information - maybe you don't get F* programmers but you might find some coming from Haskell, Agda, Coq, Idris, or people interested in those, as well!
Nah dude, I really don’t know anyone who knows that. Sometimes I think it’s just a myth :)
Must be some.. No reason not to.
It’s true! It’s true! Dude they get around 400-500$ per hour. No joke. But maybe they get it because they’re hard to find.
Why is that? is it much harder or just not as popular as the other languages?
If you’re reading this, send me a private message!
The legend of the f* programmer.. Came here to save the day 
Probably looking for some project in f*, or a tutor
Nah, they prefer to lurk in the shadows :)
He’s a busy guy. I won’t bother him
Maybe they’ll change their mind, just this time - I’m discreet :)
Why not go for the Zen Protocol guys? 
Who knows, you’ll do the next best thing
who are those?
Dude if you actually knew a busy guy’s schedule, you wouldn’t be so annoying, I won’t bother him for something he doesn’t want
It’s a financial platform based on crypto and blockchain, it’s a pretty big project. I think they’re the biggest project to use f*
Pfft. Whatever man. Your loss
Go for the chief scientist of France :)
It’s his loss if he doesn’t fucking update what he wants
Sure, he just waits for people at reddit
I don't tbh, Asher is the main programmer and he’s pretty damn talented. I think that adam is also a programmer.
Guys stop arguing! Whatever happens is great
F# helps?
Superstars! That’s quite fascinating.
I’m not arguing, he’s just nitpicking
Tbh, it’s not that far fetched.. I liked your pov
Yeah, tbh they’re the superstars of crypto
Who knows, maybe he retired after this!
But they sound the same..
 I find it odd that he’s the one behind it but w/e, it’s a great project!
Sure that what confuses everyone.. But it’s still not the same
ah, f* is hard, but it’s a great programming language. 
Heh, learned something new. Go go C and C#!
Totally different programming languages my friend. And it’s regular C, not C*
If you find one, tell me. I’m looking for them over a month now
Oh ok I get you, guess I need to improve my knowledge in programming 
That’s always a good choice :)
I want to learn Zen Protocol! And use it for my ICO project.
You have to know f* to do so?
Not really, but it’s good to learn things in depth.
I only program [MF\*](http://programming-motherfucker.com)
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](http://programming-motherfucker.com) - Previous text "MF*" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
If you sign up for my recruiting package I can guarantee 400$ an hour if you have 3 months of F# experience, but seats are limited so I require an up front fee of \*$999. Also, I can guarantee you will be able to work remote and get two months of vacation time a year and a company car. /s *^(\*$499 for states with a $500 felony fraud limit)*
Interface class? I always thought interfaces were... interfaces, not classes.
I don't know what will happen in the future, but today C# is more mature, and is utilized more often than F# and the same is true for OOP vs Functional Programming as well. There are fewer people learning F#, so there are fewer people who know it and are using it. There are fewer people learning it, because there are fewer jobs in it. If companies though there was a significant advantage in using it today, they would anyways, and F# adoption and learning will increase with the number of jobs available. Some of that has occurred, but it is very slow.
I’ve used them for one off things like design projects before, but I’m incredibly dubious about the quality you’d get from anyone doing programming on Upwork... And seriously, Fiverr? I’m trying very hard to think of anything I’d care so little about that I’d be ok with hiring a programmer there... I just can’t. 
First thing that comes to mind is using 2 hidden input fields. One has the source columns in user selected order and the other input has the target columns. They could just be comma delimited... Input1: Col23, Col21 Input2: FirstName, FavoriteColor This should be easy to consume and work by using the string split to create arrays and do what you need
Agreed brah
Wait, so that was sarcasm? I absolutely didn’t get that, even in *this* thread, and now I feel like an idiot. 
How can I handle the file between these two steps? Right now the file is uploaded, the ui is generated based on the file, then the new view is rendered (the two hidden fields will be used to store column data here); but how would I get the file back to the server to run against the column data?
Only for the fiverr part mate... I really didn't know the quality you need... BUT I can assure you that I found some high quality devs for a big named blockchain project (well it is pretty Big today) and he was picked from up work. Russian guy
Maybe OP is really in to [languages whose goal is program verification](https://www.fstar-lang.org/).
Thanks for the explanation! I'll give it a go and see what I can come up with. 
Forewarning this method only works if you have a static database table and are not creating new tables every insert. The simplest and fastest way I believe to do this would be to read your csv directly into a datatable. Once you have the data, use the mappings specified from your UI frontend to replace the column names current in the position in your datatable. Finally, once you have replaced your current columns on the datatable with what the user specified, you can use a bulk insert method to the database.
I am using a static table :)
Perfect so you can just iterate over your columns, altering each datatable column with what the user specified, and after they are finished, bulk insert! If you are not storing what columns they picked previously (i.e. user picked username twice) you will get some funky columns. Cheers
You are correct. This article was confusing.
Plus the content doesn't sound that useful. There is already an abstraction for reading files or embedded resources. It's called Stream and it works for a lot of other things too. I don't see this as being too useful except in a very occasional niche. Even then it would be easy to write wrapper classes with a common base to enumerate through files OR embedded resources and return a Stream for each which is the only possible useful functionality I can imagine this has.
Well you can directly JSON serialize your database record classes, and there are attributes to control the output (such as overriding key strings). But if that doesn't produce the desired structure you will have to make separate classes to represent it, and I think that is fine. I've done something like this, where Person would be my database record class. [DataContract] public class PersonJson { public PersonJson(Person data) { this.avatar = new AvatarJson(data); this.dob = new DobJson (data); } public AvatarJson avatar { get; private set; } public DobJson dob { get; private set; } } [DataContract] public class AvatarJson { public AvatarJson(Person data) =&gt; this.data = data; private Person data; public int id =&gt; this.data.Id; public string url =&gt; this.data.PhotoUrl; } [DataContract] public class DobJson { public DobJson(Person data) =&gt; this.data = data; private Person data; public int month =&gt; this.data.DateOfBirth.Month; public int day=&gt; this.data.DateOfBirth.Day; public int year =&gt; this.data.DateOfBirth.Year; } 
I no rite? My boss is a long time Ruby + Rails diehard who had about the same opinion of .NET as he did for Java. Occasionally, though, he glimpses what I'm developing and says "I didn't know you could do that in C#" or "I didn't realize that you could run SQL Server on Linux." He's mentioned in passing that he'd like to look into it maybe for his own future dev, and that's a big 180 for him.
The term "mature" seems odd to me. C# and .NET are clearly mature, but the connotation of "mature" in the product world is "this is as good as it's gonna get." With this open source Renaissance, though, C# is adopting a syntax that competes with Scala and JS as far as functional expressiveness, while still being a best-in-class OOP language. It's, like, it prestiged in Call of Duty, and now it's leveling up all over again while still retaining all the perks from its first run.
Garbage.
I agree, but I will add some reasons why. First, there is no "Dot Net language". There are languages that target .NET but .NET itself is not a language. Second, .NET does not mandate a certain type of programming paradigm: &gt;The training program in the Dot Net framework is designed so as to instil the aspiring programmer with essential programming concepts such as SQL querying, exception handling, error handling controls, and Object Oriented Programming. There are functional languages that target .NET, such as F#. This article is misinformed but is written for the sole purpose of selling the class. I question the merits of the class that is being sold if the article that is trying to sell this class has so much misinformation.
Actually, it's an old LISP joke. I stole this version from https://www.reddit.com/r/Jokes/comments/2cbyut/programming_during_the_cold_war/. It doesn't actually reference LISP, but when I originally heard it, it did. LINQ is .... not so different sometimes. In the 1960's the KGB was very interested in learning everything possible about the American space program, sending all sorts of spies to find every possible piece of information. One afternoon, a breathless spy returned to headquarters with a page of paper in his hand, excitedly shouting to his superior, "Comrade! Comrade! The Americans are using Lisp to write their rocket launching software!" The commander was skeptical. "How do you know?" "I broke into their research lab and stole a page from the teletype machine! It's not the whole program, but it's the final page and contains the concluding logic of the program! See for yourself!!!!" The commander looked at the page and smiled: )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) ))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))))))))))))))))))) ))))))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))))) )))))))))))))))))))))))))))))))))))) ))))))))))))))))))))))))))) ))))))))))))))))))))))))) )))))))))))))))))))))) )))))))))))))))))))) )))))))))))))))) ))))))))))))))) ))))))))))) )))) ))) )) )) )
thats true. i am learning to manage the server on my own
Where does it drop the xml file? If you can get the path, you can run custom code to process the contents with XmlReader XmlWriter You just need to implement the task class and add it to a .target file (or inline it in your csproj) for after build or clean or whatever target you want it to execute. https://docs.microsoft.com/en-us/visualstudio/msbuild/msbuild-tasks?view=vs-2017 https://docs.microsoft.com/en-us/visualstudio/msbuild/msbuild-inline-tasks?view=vs-2017
Comparing two objects in C# is comparing the pointers, not individual properties. So you can't use it to tell whether two instances of the same object have the same values. Everyone should probably be avoiding structs unless you have a very good specific reason, like you're having to pass a struct to a C++ library, or you absolutely need to memory map the individual fields.
.Net Core IS .Net I will even go so far as to say that .Net Core is gonna replace .Net for good in the near future. As for your role, you'll pretty much be the middleman between your customers and programmers. You'll translate their business requirements into technical requirements the programmers can use. You'd need a rough understanding of the many features of the .Net framework and how you can use those features to solve your clients' problems. 
.NET does not have a preprocessor; there are other ways to accomplish the same things. One thing you can do is simply include the glade XML file as a project file, make the content type embedded resource, and have your code parse out the values you want. If you want something closer to a preprocessor, you can simply use a resource string, and write a pre-build script to modify the resource file in Resources.resx before building.
You can go into Build Events in properties and run a script or program from there to make the fix. But I would try and figure out if there's a proper way to fix this. I am not familiar with Glade so I can't help with that. How is the filename specified in the gui designer? Does it think your project is in the PhotoApp folder? Are you actually specifying a file not in PhotoApp but moving the file afterwards?
If your backend depends on spring dot net, then it isn’t really [well] designed to be reusable. I’m guessing you want to share a common code base for the desktop and web, then the common layer should just expose classes/services that get assembled at the application entry (the differing UI projects). If you can’t change the backend, then maybe using spring mvc in the web project will solve your problem, but it would still be a fairly bad architecture for the backend to have a hard dependence on spring. But still not as bad as having two DI frameworks stacked on top of each other. 
Wish I could help you, but all my experience is with Kestrel directly or behind IIS or Azure App Service. I'm not sure about the best practices for deploying to an instance reverse proxied by nginx. Good luck.
That's pretty much why deployment automation is a thing, and depending on your acceptable downtime, why very complicated A/B processes, etc. are a thing. In a normal deploy you'd stop the kestrel process, copy the new version of things over, and restart it automatically by a script of some sort. That would be minimal downtime of a few seconds usually (depending on app size, how long it takes to copy, etc.). If you can't take even that short downtime, then you get into much more involved setups, like having multiple copies of the app running at once, and during a deployment you take it out of the nginx proxy temporarily, update it, and put it back, and take off the other, update it, and put it back. That gives you minimal downtime and is the common practice in 100% operations... but it can get WAY more complicated, thats just the general idea. In a lot of places I've been, instead of going through all that they accept a small downtime window on deploys and just schedule them after hours or similar. Really risk adverse places will STILL do that, but also do the A/B deployment strategy above as well.
I think that OP meant they were going into a new role with .NET Framework.
If you want to write code in the Microsoft world, C# is your best bet.
Ask your new team lead or manager, TBH.
The language is the same. The base classes are different but not that much. The tooling is much more complete.
As other have stated, .Net Core is still .Net. From a programming standpoint, you wouldn't notice anything different from writing code in .Net 4.7.1 and .Net Core. What's more import is what type of projects you will be working on. Desktop? Web? From there, WinForms\Wpf\UWP? MVC 4, 5, or 6? 
Ah, here is the issue i was aware of but could not see. Thanks for pointing this out :)
Yes. Otherwise, you're going to have to look up how to do things in .NET and then also translate them into your language of choice.
I made the switch (though a good few years ago now) and it really was not that bad... a few extra brackets, and semi-colons but it does not take too long to get in the groove. 
I have been through this. Moved to VB.net and then c#. If I could do it again, I would have just learned c#.
Yes, c# ftw
I think it might be able to. It probably depends on the library. I've seen a demo where they took a library from 12 years ago and had it running cross platform in .net core.
Project files changed. Some libraries you like using won't be available. That's it. Everything else you know is directly transferable. You'll have a harder time going from WinForms to WPF or WebForms to MVC/WebAPI. Picking up .NET core is just a matter of asking "Ok, how the f- do I do this obscure thing?" 
Yes, and you'll never look back.
Yes, of course you can. The language is still the same and so are many, many libraries. The overall architecture of a web app is different, so there is some learning curve there. And dotnetcore embraces modern patterns like IOC more readily with it's built in container. At this point, though I'm not sure you would need to consider migrating your code base unless cross platform features are required. 
It's different enough to annoy the hell out of you for a few weeks... But ultimately it's mostly the same in your day to day as a developer.
VBA is a completely different language to VB anyway. They share only superficial similarities. 
Another approach would be to deploy the site within a Docker Swarm. It would guarantee up time since there one only be one container down at a time. 
Docker, load balancer, bring up new one, stop old one, no mess no fuss
100% - C# and focus on .NET Core.
Not just confusing, almost every answer is wrong or not an answer to the question. If a candidate told me these things it would be a big fat no. Garbage article.
Yes. VBA has its place but c# is much more versatile. Best way for me to learn a new language is to exclusively use the new one for two weeks. I have only had two out of a dozen I haven't liked, Ruby and coffee script. 
I didn't even think you could reference anything other than .NET Standard from another .NET Standard library. 
If you can simply target full .Net framework you can do that no problem (with some exception, like some Sharepoint libraries were hard locked to v3.5). Have your library and your ASP application both target the full framework (like v4.7.x). If you have to target .Net Core, you can still do it, but your application will fail at runtime if it uses any unsupported APIs.
Framework will still be supported for years to come.. but objectively speaking, the sooner you switch - the better.
None of WCF was. It's annoyed a lot of .net core people.
You would be dim* to continue using VB unless you have business maintaining a large legacy VB code base. All resources around Microsoft are pushing C#. I would start with language basics and then push into the ASP.NET space as the web introduces a fair amount of code and architecture that will just add to the pain of jumping languages. *Programming puns ftw
I learned a bit of .NET Framework ASP.NET before learning ASP.NET and it feels really similar to me. The configuration and startup stuff is much simpler. The rest of it, like views and controllers and working with the ORM feel almost exactly the same.
OData on webapi became more popular and most of the effort was moved away from wcf data services https://blogs.msdn.microsoft.com/odatateam/2014/03/27/discussion-future-direction-of-wcf-data-services/ They ported OData to dotnet core https://blogs.msdn.microsoft.com/odatateam/2018/07/03/asp-net-core-odata-now-available/
Yes. Asp.net dev for the last 3 or so years and I couldn't even imagine asking most of this in an interview. I would walk out of an interview if the words "code behind" or "repeater control" came up.
Yes.
No, VB is far superior. LOL, only joking. c# is definitely the best way ... I resisted for a long time in the early days and regretted not switching sooner. 
Yes, I think OP will be pleasantly surprised. VS 2019 will offer much more for dotnet core but for now .NET has really matured and is nice to work with. 
C# is a fantastic language, and I highly recommend it. No bias. (Actually, tons of bias)
It is basically such a scenario. Library is not complicated 
I was digging and.. what about that? http://gigi.nullneuron.net/gigilabs/net-core-2-0-referencing-net-framework-libraries-topshelf-experiment/
I have a decent background in JavaScript and just picked up C# recently. I'm amazed at how similar they are. So bonus, if you're looking to do web stuff, JavaScript will be really easy for you to pick up upon learning C#. 
Yeeeeeeeeah, seeing lots of stuff that I'd be asked from a place that's still doing WebForms. The moment any question about WebForms comes up seriously, I'm mentally noping out of the interview.
Deploy two copies of your site (code only) that use the same static data. Use nginx to route to one of them. Update the passive copy, start it, then make nginx route requests to it and shut down the other one. Rinse and repeat.
Yes. VB, in all ways, shapes and forms, is a sub-par language.
For a long time I believed the "VB.net will be fully supported" thing and tried to stick with vb.net but eventually I realised that while Microsoft may support VB, the .net community as t large is 99% C#. Articles on new features, examples and demos will all be C#, the rock stars of the industry will make tutorials using C# and the most interesting blogs will be C#. Eventually I just jumped in and switched entirely to C# and have no regrets - at this point unless your job is actively supporting another language I couldn't see any reason to use anything else.
This is about using .NET Framework libraries from an application running .NET Core. It's completely unrelated to what you asked. There is no way to use ASP.NET Core from .NET 3.5 and there never will be.
I actually wanted to run .net 3.5 under .net core... I probably was misunderstood
Pretty strange. We have tens of dotnet core + nginx sites deployed and we \*never\* restart nginx. Just rsync the new files and restart the dotnet process. Maximum downtime is 2 or 3 secs.
But the bullet? LOL. Learning C# is like biting into bacon.
I switched from PHP to C# for web, best thing I ever did. Just be aware of postbacks 😂 days of my life wasted...
I don’t think this is entirely true. They are syntactically identical. But I’ve not (thankfully) written any VBA for about 10 years so my mind may be remembering it wrong. 
what advantage you have gained after switching from php to c#?
Was it ever anything else?
Looks like some WCF Client Code is in Core. https://github.com/dotnet/wcf/blob/master/README.md
Same here. I think this is the case for most of us that made the move from VB6 / VBA.
I put together a super simple sample application for authorisation ... [https://github.com/matthewblott/simple\_aspnet\_auth](https://github.com/matthewblott/simple_aspnet_auth) &amp;#x200B; More details here ... [https://coderscoffeehouse.com/tech/2018/07/30/simple-aspnet-auth-update.html](https://coderscoffeehouse.com/tech/2018/07/30/simple-aspnet-auth-update.html)
Yes. Forget any VB* for ever. 
This is the correct answer. If you target a .NET Framework version that supports the required .NET Standard for ASP.NET Core and your 3.5 Library then you won’t have an issue. Assuming you can target the framework this would likely be the simplest option.
Yeah there was a push a little while ago to get it in because a bunch of people rely heavily on it and can't migrate without it. I use about 15% of everything WCF offers in our current .net 4.x solution, but I really miss it in Core. Give a channelfactory an interface and a couple of lines about the endpoint and binding and instant communication. It's less of a problem for us now as we use a bunch of other technologies more closely aligned with specific communication needs, but I've used WCF for years and it's practically muscle memory :) Thank you for linking to the repo, I wasn't aware it was so far advanced. Last I heard it was just a consideration.
Yes, you should hang up your keyboard and reskill as a farmer.
The syntax is mostly similar, mostly, but the language underneath is really different. 
VB.NET is .NET.
One of the major features of .NET Standard 2.0 is support for .NET Framework libraries without recompilation. It will seamlessly work, but if the library uses Windows specific APIs, it will fail at runtime.
Pretty much. Sure, don't use Structs where it isn't appropriate, but you can compare them. 
If you tell someone you are a .net developer, they'll assume you know c#. It's not a tough learning curve if you have any OO experience. Check out Lynda.com or pluralsite or something like that for some .net core beginner and/or design pattern courses. Should also take a look at MVC and Web API.
Is this a serious question?
&gt;I'm amazed at how similar they are. What are the similarities?
It's the same language just a couple of different libraries. Most of it is the same.
Some of the WCF RIA stuff was. https://github.com/OpenRIAServices/OpenRiaServices 
I've used both, and while I don't mind [vb.net](https://vb.net), c# is definitely better.
Hopefully this sheds some light. It can be done via comparability shim. https://espressocoder.com/2018/09/28/building-a-shim-with-net-standard-2-0/
Why not make a .NET Core REST API that returns JSON to the UI? Then you can just make a call to the endpoint and get back whatever data you need. 
Yes. C# will be easy to pick up, imo.
Why not use asp.net mvc with razor? It would function almost identical with your scenario.
I've added why I don't want to use ASPNET.
I have Code Lens in Visual Studio, Enterprise
Yeah, but it would also run in the browser - the app I'm making is meant to be a simple, small-windowed application where you can write stuff.
Gotcha, well you could look at a solution like [this](https://github.com/ElectronNET/Electron.NET). Only came across it recently and haven't had a chance to really dive into it but seems like it might be worth checking out. It combines Electron (HTML, CSS, JS) with .NET Core 2.0. 
Well, the description says: 'Build cross platform desktop apps with ASP.NET NET Core. ' I appreciate the help, but I would hate to bloat my simple app with ASP.NET.
Yes.
shortest answer, yes
I switched from PHP to C# for web backends because of .net core. To name a few things off the top of my head: - It's cross platform, and works great in a docker container. Not saying PHP isn't, but rather that .NET/C# is now. - It uses static typing - Being compiled, I can catch a decent number of errors upfront. - The utility of the .net standard, threading, async/await, nuget, etc. - I like how asp.net core works, the fact that it uses Kestrel, and that Kestrel is pretty fast. - It's all just C# and .NET. I can carry my knowledge over to a webapp, desktop app, console utility, windows service, something I just fire off with cron in Linux. 
CefSharp somehow had bindings done perfectly. I could have any type of an app (including Console App), as long as it includes the CefSharp library. The whole point of using HTML &amp; CSS for UI so for how easy it is to create a decent, portable and responsive UI, how easy it is to use web-hosted resources and how easy it is to later port to other mediums like - web or android. Javascript is just the neccessary connector between HTML and C#.
Yes. 100% worth it. 
It depends on your set up. The best practice for minimal downtime would be to provision a new server with the new version of your software, and then point your old domain / loadbalancer / gateway to the new version. When the traffic is directed to the new server, deprovision the old server. That way you have zero down time
That is awesome. We have some legacy crap reliant in RIA. Hang on...
I believe what they're getting at might be that C# would be better long term for hiring, better for finding good examples. There's also some speculation that MS may end up killing off VB, but i think that's a misunderstanding of what they mean by this. VB is at the end of the innovation and won't get much more - but C# continues to innovate and grow the language. &amp;#x200B; Being on the hiring side of VB though, i can tell you a pro/con for being a VB shop: It lowers your pool of candidates. We generally only have to review about 5-10 resumes each time we go to hire. It can be a pain because sometimes we can't find anyone and we start the process over :).
I prefer free IDEs.
Yes.
This post is borderline troll sounding, but I'll give you the benefit of the doubt... you should not be so quick to reject the advice given thus far. * First thing - .net core (and asp.net core) is extremely fast and getting faster. [Here's](https://www.ageofascent.com/2016/02/18/asp-net-core-exeeds-1-15-million-requests-12-6-gbps/) and old post; performance keeps getting better. * You should focus on your goals to define the methods rather than the methods themselves. If your goal is a desktop app written in C#, you want to focus on WinForms, WPF, UWP or Xamarin. If your goal is future mobile device compatibility, you want to look at Xamarin or React (react native &amp; react desktop). * If you want to ignore all the advice given and continue trying to shoehorn js+c#, you should rephrase your question to look for alternatives to CefSharp. You're not likely to find many.
Syntax mostly. I was able to complete FizzBuzz in an online compiler (dotnetfiddle.net) in C# with zero knowledge. The only difference was Console.WriteLine vs console.log. (also implied that the compiler already included the namespace and main function). Wasn't the case for me with Python. 
He modified his post. His inital question was about using ASP.NET Core in .NET Framework 3.5.
&gt;Syntax mostly. This is exactly what I said, but you're disagreed with that?
There are quite a few languages that will compile down to the Common Intermediate Language (CIL) that is used by the various flavors of .NET - it never was/will be "just c#" https://en.wikipedia.org/wiki/List_of_CLI_languages
You won't find many (any?) people who have used both PHP and C# who would say PHP is the better language. C# is always near the top of StackOverflow's "Most Loved Programming Languages" survey.
This is going to be for marketing sites, with only a few pages each. I don't want to have to host a totally new .net core application for each small marketing site. So once a client's site is built, it's usually not really touched much afterwards so I don't think it would be much of a issue. I just need a clear way to choose which website to show based on the domain names. This seems to be the easiest way for me to do it, but i'm open to any suggestion on good ways to do this type of things. Action filters to my knowledge don't work with razor pages. You have to use https://docs.microsoft.com/en-us/aspnet/core/razor-pages/filter?view=aspnetcore-2.1 However, the part I'm having trouble with is how to make it default to a specific area based on doamin name without actually using that area name in the route. Like I explained in the original question.
This would mean you would have to re-deploy the whole application to add a new client's site? What if there is an error in your new code? It would take down all other clients sites? If this is indeed the model you plan to use have you looked into using a light CMS, most of them will handle routing like this for you. You could indeed use filters simply by checking the host part of the URL from the context and then redirecting based on your rules.
Exactly this. We had a project at work that was set up like this using MVC and it was brutal. We finally split them up and converted them into separate client projects. In my opinion the headaches this causes are not worth it. Just create a boiler plate project and copy paste that for new sites to get started.
Thanks, i'll look into filters, I just can't find a example of you choose to have razor pages default to a specific area, without showing the area in the route.
I don't understand what won't work about the good example you posted. In theory you should be able to register a new route per domain, using a constraint (like in the answer) so that only that domain is handled by that route, and then specify an area so that all requests go to controllers in that area. As for the razor pages using different layout pages, in "full" .NET MVC each View folder inside each area has a _ViewStart.cshtml file, and that's where you specify the Layout page. To implement themes, or in your case different websites, I just have that layout page pulled from a static class in a helper file, you could inspect the domain at that point and return a different layout file accordingly. 
That's what I'm doing now, this gives me something to think about though. All our sites have a blogging engine and admin section, I'm finding it annoying when I want to update that or bug fix something, I have to go into 7 different projects and edit the same files everywhere.
I think you can't do what you're trying. The only way you can do it is using areas. You can have: * www.domain1.com/Area1 * www.domain1.com/Area2 * www.domain1.com/Area3 ... And so on.
Maybe I'm misunderstanding something, but the example I shows doesn't work for razor pages. the MapRoute only works for Vanilla MVC, I also can't find any documentation on if you can specify Areas as attributes on razor pages, or if it's just by folder structure convention.
In vanilla MVC you can do it. I just can't figure out how you accomplish something like this using razor pages. In the stackoverflow I linked it shows you how to do it in MVC.
I'd want it to now show the Area, right now i'm envisioning the areas folder to just be the name of the clients. so I wouldn't want www.abc.com/aboutus to redirect to www.abc.com/abc/aboutus.
I don't understand what you mean here. &gt; Areas as attributes on razor pages If I guess correctly the answer is generally it's by folder structure. Incoming request -&gt; Router decides what controller and action to call -&gt; Action returns View which, unless a specific path is given, the corresponding view (by name and folder, including area) is returned. 
Why do you want to have all of the domains hosted from the same app? It might be possible to do it but I'm not sure it's worth the hassle. 
Yes it's currently by folder structure, So if you have Areas/Products/Pages/Information It would be at www.domain.com/Products/Information. What i'm trying to do is constraint the AREA by the Domain name. So www.domain1.com/Information would need to pull the information page from a specific area, ie "domain1" area. where www.domain2.com/Information would need to pull from the domain2 area information page.
How are you managing source control? If each site is a separate branch, then merging a universal change should be as simple as a click of a few buttons.
I would only need to update the code in one place, but wouldn't I still need to manually go through every client project to make then use the updated class library? I've never actually done this before and this could be another great way to do this. I'll have to try to look into it.
Currently each site is a different github repo.
Razor Pages are routed by folder structure by default. Simply create Site1, Site2 etc. in the Pages folder and create the individual pages there. After that, you can use the @page directive to route the requests, but it is not based on the domain. You can branch the request middleware pipeline, add a custom routing logic or configure routes to pages directly. 
**It seems like the ASP Core `UrlRewriteMiddleware` addresses your use case.** This is similar to what /u/yugabe suggested, but you can do a URL rewrite within the ASP pipeline (no dependency on IIS): https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/kestrel?view=aspnetcore-2.1 Among their suggested use cases, they state: &gt; Splitting request processing across different apps or across areas of one app. That sounds like your use case. So, in your `Startup.cs`you're gonna put something like this somewhere before `app.UseMvc()`: app.UseRewriter(new RewriteOptions() .AddRewrite("{regex_old}", "{rewrite_to_new}", true)); This essentially rewrites the URL so that the rest of the pipeline behaves as if the request came in at the rewritten URL without actually redirecting the client. You'd figure out a regex pattern that captures the domain and path, then rewrites it to the matching area and path, and Pages behaves accordingly. I tested this just now in a new pages template, and I got it so that `/about` returns `/contact`without a redirect, so it seems to work with Pages. I'll leave it up to you to figure out the details, but I think this is the tool for the job.
You are really misunderstanding the role of the router here. The controller will pick the view files by folder, but what is returned when a particular URL is hit, is determined by routes. 
Sure! Good point. Now that you mention it, the vanilla `.AddRewrite()` extension method may not address the host part (it may only look at the path). **However, you can definitely handle it with your own rewrite method.** The `.Add()` method accepts a method with signature `RewriteContext`, which gives you full access to the HttpContext instance. var rewriteOptions = new RewriteOptions() .Add((context) =&gt; /* Figure it out. */); If you need something more heavyweight, consider making a class that implements `IRule`, and at that point the sky is the limit as far as what you can accomplish.
I'm confused why you're making it sound like learning C# is a bid thing?
Thank you. I'll go through the example today to review. One thing I did notice is that you are not storing the access and refresh token anywhere (other than the refresh token in a file). What is the recommended practice for storing both of these? Can you store them both in a secure cookie or only store a refresh token in a cookie? Not sure how to handle storage. 
Put a reverse proxy in front of your application
Might not exactly be what you're after, but if you like Umbraco, sign up for the Umbraco Headless beta and build the website in ASP.Net Core and query the CMS running on Umbraco Cloud. 
There is a trail, but otherwise it is 25€ per month. However since the Headless is in beta, it is free of charge until an actual product release. 
**Quick questions** * Are these projects all in the same solution, or are is each project its own solution? * Do you care about redundancy/fault tolerance at all in this application?
I haven't had to do that with numerous .NET docker images being proxied through nginx, or some node.js sites, etc. The only proxy I've had to restart is when proxying HLS video streams, but that's a whole 'nother animal. Not saying there couldn't be some unique setup that requires that, but the basic setup I don't think its necessary.
I did think about pre-processing the XML at runtime (before the Gtk object is constructed), but I wasn't sure if this was the best route to go.
The solutions above would be at build/compile time. 
I am NOT an nginx expert, so take this with a grain of salt, its just my understanding. As long as you don't have stateful connections involved (websockets maybe) then I think that nginx just forwards requests to another address it can access. It shouldn't matter if its up or not, or if it blinks, etc. I haven't tried it to verify, but I'm PRETTY sure of that.
https://github.com/iolevel/peachpie-wordpress 
I see F# more of a complement to C# rather than one being legacy/experimental. 
I'm not sure Docker is all that useful if you're going to put all clients in one place, eliminating any of the isolation between them. If you're very resource constrained, maybe consider just one droplet with one dotnet runtime executing all the sites. Also, only worry about resident memory. That's the only count that is actually being used. 100 could be about right for resident memory, so maybe this paragraph isn't useful.
Personally, if I was going to be managing so many sites, I'd automate the deployment of the library using the nuget core libraries and pulling updates from your command and control application which would host your nuget server. You could protect it via API key, but DO also has virtual networks and firewalls, so you could just have your nuget server exposed internally. All this might be more than you have time for, but it would certainly be the most fun. :)
I work on Cofoundry, an open source .NET Core CMS. We've put a lot of work into creating [docs and samples](https://github.com/cofoundry-cms/cofoundry/wiki). If there's anything missing that you're particularly looking for we'd appreciate the feedback. 
I recorded some videos that you should find helpful if you want to try Orchard Core. Creating a theme: https://www.youtube.com/watch?v=wtAIgn4gYXc And Decoupled CMS which is about using plain Razor Pages in Orchard for maximum flexibility: https://www.youtube.com/watch?v=yWpz8p-oaKg There are other ones on the same channel, and more to come.
&gt; I think this is the tool for the job I agree. This is the most straight forward way to get this done.
The OData based versions of it are open sourced. The [OData.NET repository](https://github.com/OData/odata.net) has the maintenance-* branches which contain the source code for the `Microsoft.Data.Services` and related namespaces. The [Microsoft Reference Source repository](https://github.com/Microsoft/referencesource) also has the source code for a rest of the WCF namespaces. 
That’s a pretty shitty explanation of rather outdated stuff. 
Ah that might be the difference then. I only use it in the context of Docker networks. So the host representing my web app technically didn't exist until it's container was created. That might be what made Nginx complain. The host name would have resolved to nothing.
Why can't you use virtual domains? Apache handles this quite nicely.
Checkout Squidex on GitHub, I am starting to build a project using both Orchard2 and Squidex. Basically using Orchard as the proxy to Squidex.
I'm curious what you hated about umbraco. I use it at work and really enjoy it! I have some issues especially around the mismatched documentation in some instances.
yeah
Yes it's definitely faster. You can't even compare the two versions. Everyone who has tried it will confirm.
Anyone else getting a type of click-bait popup prize on this link? Looked interesting until then.
Don't forget to set the location header... This link is just wrong...
Although I have no idea about the latest Java framework and IDEs, I can tell you .NET Core is definitely worth it. 1. Rapid development - It's very fast to come up with a proto-type for any application 2. Amazing IDE in Visual Studio makes many things much easier 3. .NET Core technologies make it very easy to integrate with popular UI/UX Frameworks to make beautiful applications. 4. Entity Framework Core makes it very easy to integrate your app with the backend DB 5. .NET Identity gets your authentication working in no time, literally. And there's more to explore and learn.
.NET/C# was actually originally implemented to be strikingly similar to Java. A lot of developers would go so far as to say it was built to be "Have but better." But the fundamentals of Java and C# are nearly identical. Primarily focused on operating on classes, highly OOP, .net Core shares the cross platform capabilities that Java was built with.
Well at least these * No more Oracle * Unsigned value types * User defined value types * Low level optimizations with value types * Tuple support https://docs.microsoft.com/en-us/dotnet/csharp/tuples * LINQ * No checked exceptions * Better asynchronous model with async &amp; await * C# is better designed language overall than Java * Visual Studio is extremely good IDE * .NET Core is open source with MIT licence and much more... You should try Visual Studio extension Roslynator 2017 it adds lot of new refactorings and analyzers for C#. Default visual studio shortcuts Ctrl+T / Ctrl+, (Navigate To) and Ctrl+. (Quick actions) are really powerful. http://visualstudioshortcuts.com/2017/
LINQ and no more Oracle should be bolded and made enormous.
Learning C# will be pretty easy, but learning the stack will likely take awhile. FYI.
Any suggestions on where to start with .net Core for a asp/vbnet webform dev? I'd like to do some side projects so that if/when my company decides to move that direction I'll be prepared.
C# as a language is much more pleasant to use than Java, and Visual Studio is hands down one of the best IDEs I've ever used. That's all I can say, otherwise my opinion would be biased since ASP.NET Core was the first web framework I learnt, before it was even released as 1.0. I have not used the latest Java technologies so any opinion will be even more biased but Java folks also have biased opinions. ASP.NET Core and Spring Boot are not that hard to set up - I suggest that you install everything and try out the frameworks yourselves (with a very small demo project) and see which one you like more. 
PluralSight is an excellent investment for your career. Choose a beginner level tutorial for ASP .NET Core and off you go. I would recommend learning C# too. I started with VB.NET and moved over to C# early in my career and never looked back.
Microsoft Documentation and Google has everything you need to build a web application, because we have prior experience in other development so for me no books needed. I'd suggest creating a new solution with VS which includes Identity and uses Razor Pages (MVVM, I love it a lot), then use EF Core for your database needs. Maybe a simple CRUD for your favorite subject e.g. database of movie stars. You might want to get a nice HTML5/CSS template from e.g. Envato Marketplace and wire it up as the overall layout of the application. (σ･з･)σ It'll be fun and satisfying.
I thought Microsoft fixed those problems maybe 10 years ago by introducing `DateTimeOffset`?
&gt; replacing it with something better. DateTimeOffset has been suggest for quite some time now, people just don't care and still use DateTime 
It's more of alleviated a fair amount of the pain. Microsoft still doesn't naively support the tz database which is what a variety of timestamp and timezone data uses. Noda Time fixes that, but it's surprising they didn't fix it in .NET Core or standard
I started my current job as a .net developer but have been doing a lot of Python and Java in it. I love Python and think Java is a little more verbose than C# but they are basically the same. What makes me want to stick with Java/Python is the pay and opertunities for cool programming. Machine Learning is so much fun. Kafka and Spark are so cool. And, at least in the Seattle area, a 20k pay bump is not too bad either.
Thanks!
Pluralsight. I’m sure people here are getting tired of me saying it but my company gives all coders pluralsight subscriptions and I have learned and stepped up my knowledge of .net and c# by leaps and bounds. 
Worked in both and I think each has their advantages. I think C# and .Net are superior from a language and basic setup standpoint. I loved LINQ and the async await patterns that can make your .Net app very performant. I also love Visual Studio (especially if you add Resharper). IMO Java/Spring beats out .Net in terms of available packages and plugins, mostly due to the walled garden approach that Microsoft has traditionally used for the .Net ecosystem. Using Maven is a much better experience, with much more useful additions to find, compared to Nuget. I never found myself completely lacking a tool that I needed from Nuget, but with Java you can often find high end implementations of the exact thing you were looking for. As for the learning curve, it’s probably one of the smallest between any two mature languages. The syntax and paradigms are extremely close. In my experience I really enjoyed leading C# coming from Java because it felt like they took Java and polished it up a bit (just my experience, still a huge fan of Java).
W00t! Are perhaps coding for Unity or MonoGame? Because using LINQ inside game loop might not be a good idea. But otherwise LINQ is awesome and leads to better and more stable code by making programmer go towards using code blocks without side effects.
Although they are very similar now, as both languages borrowed from one another, [C# was based on C++](https://en.m.wikipedia.org/wiki/C_Sharp_(programming_language)#History), as Hejlsberg himself declared.
**C Sharp (programming language** From a modification: This is a redirect from a modification of the target's title or a closely related title. For example, the words may be rearranged, or punctuation may be different. In cases of modification from distinctly longer or shorter names, please use {{R from long name}} or {{R from short name}}, respectively. Use this rcat instead of {{R from other capitalisation}} and {{R from plural}} in namespaces other than mainspace for those types of modification. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
Huh. I swear I heard on multiple occasions that it was based on Java and not C++, but apparently my sources were wrong or i missed it. Thanks for the fact check! ^_^
You can store it anywhere you like but probably in some sort of data store would be preferable. I used the file system because I wanted a simple example - too many example solutions rely on setting up a database and don't work out the box.
Can't speak so much for the reasons but as for the learning curve: I stepped into a junior c# dev job without any training in c#, only Java. I found the languages unbelievably similar and that I could pretty much just write Java code and it would compile correctly. It was pretty easy to pick up the specifics of c# from there so I doubt you'll have any trouble with it. You just gotta decide whether it's right for your project.
I've worked both with Spring Boot and ASP.NET Core. While I like them both and don't have any special preferences, I must say that I really miss async await in Java.
Direct file access is prevented by using a handler which redirects the user to the login page if they are not logged in. The handler can also check to see if the target folder is the one to be secured as you may have other folders with pdf docs which do not restrict access.
I haven't done much Java, but I don't think you will have a lot of trouble getting used to C#. The thing I like most about .net is the Visual Studio IDE compared to NetBeans, Eclipse or other Java IDE's. It always seemed I had to configure a lot to get them set up the way I wanted. Visual Studio out of the box felt very intuitive and with ReSharper I feel like a wizard sometimes. Also get used to LINQ... It makes code so much cleaner in my opinion, however some people think otherwise. Another benefit is that you don't have to wear glasses anymore... 
LINQ is not miracle solution for bad code, it just makes it less likely. General solution for bad code is having code reviews, pointing these mistakes to programmers and have them fix their mistakes.
Tuple is rather a code smell than an advantage.
It's very useful for things like LINQ, local functions and private methods. But I wouldn't use it for public methods. Better to create struct or class instead.
in linq anonymous types work just fine instead of tuple, and look more elegant; maybe for private methods it's ok indeed, but once it goes public that's where the mess begins.
You could also just return a stream via webapi and make that endpoint authenticated. See https://stackoverflow.com/questions/11125535/how-to-return-a-file-using-web-api
I'd go with csharp instead of vb.net if I was you. Best place to start is he Microsoft docs. They have lots of tutorials on there. If you want videos then it pluralsight all the way.
Just to make sure that we are talking about the same thing. I'm talking about quite new tuple feature added in C# 7 that uses ValueTuple struct internally and not about old Tuple class that been in .NET Framework for a long time.
In my experience LINQ code is worse than average for quality.
Anonymous types also cannot pass from one assembly to another (due to the way they work internally); so you're left with ExpandoObject (which has its own limitations) or Tuples. While I think regular Tuples might be an anti-pattern, ValueTuples largely mitigate that. Particularly for a small number of items e.g.: public (string name, int gradeLevel) GetStudent(string studentId) { ... } If anything thinks *that* is an anti-pattern I'd love to know why? The above code wouldn't be improved one iota by having a tiny Dto. 
Absolutely love .net core. It's my primary Framework at work. That said, learning a new language and stack for a side project is a quick way to make sure said side project doesn't get off the ground. Imo, sick to what your used to, unless your actual goal is to learn a new language. 
I think the reason people think things are missing from .NET is because the libraries aren't necessarily named after the problem you're trying to solve. Microsoft have a tendency to go overboard and create entire frameworks, or as they like to call them 'foundations' that sets out to solve any issue you could possibly have, so you're left to sift through to find the code that does what you want. However, those libraries more often than not end up using some sort of common infrastructure interfaces, so you can then combine these classes with completely unrelated code and it'll just mesh well. WPF, Entity Framework and componentmodel interfaces with data validation, at the top of my head.
What's does LINQ has to do with datasets? Are you actually talking about LINQ to SQL and not plain LINQ?
&gt; DateTimeOffset Is fine for an instance in time in the past, as long as you always store as UTC. For anything future or for calculating +/- days/months or figuring out what time it is in the user's timezone there is NodaTime (plus IANA timezone strings).
If you're used to IntelliJ, use Rider. It's got 90% of what VS has, plus Resharper built in. I'm on Windows and actually prefer Rider.
If you put your code to a libraru and someone else uses it then you can't just add new field to a tuple without breaking someones code. But there are methods that are unlikely to return anything more in the future then it's probably ok. Using tuples in public methods that are used inside a single solution where it makes sense sound good to me.
I'm a .NET platform architect working for Pivotal - company behind spring. I've done .net since it was invented, so here is my take. .net is a better language then java, it has better constructs especially around async programming. However, where .net is lacking are frameworks that abstract out complexities needed to tackle business problems. Spring is a framework on java that offers high level of abstraction increasing productivity. Think of it as having a much larger box of Lego pieces. For example I can create a repository pattern and expose it as HATEOS api with just a few lines of code. There are things to tackle batch processing, data streams that spring will build up as a collection of microservices, etc. My point is language isn't everything. Also, if you use Java buy JetBrains IntelliJ. It's as good if not better as far as ide as visual studio but for Java. Good luck
Yeah that's what I plan on doing. I only use VB because of work. I've done a fair bit of Java in school so I'm just going to jump right into it with C#.
&gt;JCP, JSR, JEP and all that jazz That made my day.
You're mixing together a lot of different things with different use cases. I haven't checked out EF+SQLite for a long time, but when I did, it seemed poorly supported, if at all. It may be a viable option now. Dapper is a different kind of thing, in that you'll still be writing your own SQL, but the tedious shit involved in "mapping" your result data to some appropriate model class is now handled for you. It is also a lot more lightweight and a lot faster than EF and other major ORMs. ADO.NET is just... your run of the mill database API.
You can license stuff built on the platform however you want. You only need to include MIT if you included source code from the platform. 
You can licence your code as whatever you like. The MIT licence is an extremely permissive licence and a tool licenced as MIT has no effect on work produced by that tool. https://tldrlegal.com/license/mit-license
With the tuple labels and deconstructing it's not so much anymore.
I like the standard TryGet pattern too much to use tuple for things like that :)
Is Rider free?
Lol yes Without question Java pales in comparison to .net in every aspect.
Not sure if they have a free version. I get it through a subscription at work.
And if you're really concerned about performance, there are LINQ optimizations you can perform. If it can be done, you can run it in parallel.
C# has properties and syntactic sugar for short hand property implementation!
It is not
As long as you don't intend to sue Microsoft over the product (.Net Core), you can do whatever you wish, and nothing can revoke your license to use .Net Core as you please ...
Has anyone out there made a really good chart highlighting just how awesome C# is compared to Java? I'm tempted to make one.
If you use .net Core there is SQLLite integrated. (Microsoft.EntityFrameworkCore.Sqlite). There are other commerical providers for SQLite. One option would SQL Server Express LocalDB, which works without a server running. The advantage here is that it works perfectly with Entity Framework and SQL Server Management Studio. I a bigger installtion though.
I call this the `200 Everything's Fine` pattern. 
EF can now alter SQLite table structures (SQLite doesn't support this directly do EF couldn't before; you had to create a new table and copy the data over by hand. Looks like EF does this for you now). So I'd say it's got better support now.
Blogifier uses SQLite as the default backend. Look through the code on it. https://github.com/blogifierdotnet/Blogifier 
Even if he is, unless you're doing something stupid, LINQ to SQL is also glorious. Chances are good that .NET knows how to write better SQL than you do.
Ef core and sqlite work well together 
Just wait till null is a valid value and you have to differentiate between the value null and null because there was an error.
https://github.com/mbdavid/LiteDB/ 
No, but I got it with Resharper license for 1 year (the license lasts forever and Rider does do, but upgrades only last until end of year) for almost nothing. Rider has been a dream on my Mac workstation. 
You lost me, what do you mean exactly? If Try method returns false you handle that error right there not somewhere else.
If it returns false, it may not be an error condition, it could just be that the variable you're checking was explicitly set to null because that's the value you need.
Is async different in Java? Because .NET has had it for years.
Java doesn't have async/await, so I'm sure they meant that in the sense that they miss async/await _when they're using_ Java.
You certainly don't have to _like_ the philosophy behind the GPL, but just because it's not a permissive license doesn't mean it's not an open-source license. 
Java doesn't have async await at all. It has some ways to achieve async programming but imo those are overly complicated. Async await in .NET is so much easier to use and read
It really depends if you have time to learn a new framework and how much experience you have with Java. If using Java won’t cost you any extra money, I might not switch if I was you. ASP.Net Core and Visual Studio are awesome, but not simple. Asp.Net core usually requires you to not just understand C# and SQL, but now you need to learn Dependency Injection, Entity Framework, LINQ, Asynchronous via Async Await and more. All these great new features of .Net Core require some additional learning. And you will need to learn GIT for source control and that can be a challenge if you don’t know it already. Your users / customers will not care how your application works, only that it does. After a few months, you will probably love coding ASP.Net. But you will need time to learn it before making a production application. If you do learn C#, that could be great for your career. If you find an IT department or company that is trying to transition from Java to .Net you might be able to get really good pay helping them. Good luck.
Your post has been removed. Self promotion posts are not allowed.
Your post has been removed. Self promotion posts are not allowed.
https://en.wikipedia.org/wiki/Comparison_of_the_Java_and_.NET_platforms?wprov=sfti1
We do it by storing the files outside of the application dir (that iis has access to) and expose the download as a parameter to an api endpoint. If the user has access we return a result with the file content otherwise they get a 404. We have done this in both mvc and webapi. 
Dapper is faster at executing and materializing queries. Entity Framework makes it easier to deal with relationships - both querying and modifying. It comes with some rudimentary caching. Also with LINQ and Expressions in EF you can also share query logic between in-memory objects and the database.
I think that approach is quite different. &amp;#x200B; EF maps the entire (or most of part) database and their relationship into "memory", and reflecting changes after commiting into database. &amp;#x200B; Dapper in the other side doesn't map the relationships and uses native query to get records and perform updates. &amp;#x200B; If you think in terms of portability to different databases, you can use EF since the SQL dialect and databases diferences are abstracted in EF engine. &amp;#x200B; If database portability isn't important but performance you should use Dapper. &amp;#x200B; ;)
LINQ is independent from the code people write with it. People using LINQ to write bad code doesn't make LINQ bad.
LINQ is independent from the code written using it. People using LINQ to write bad code doesn't make LINQ bad.
Advantages of C#: It's not Java.
Java cannot consume other DBs, say SQL Server? Surely, there must be Java libraries available?
I can think of one counterpoint.....there have been a handful of times in the last 15 years that I have been envious of Java's enumerations.
Oracle owns Java, it's not about the db.
This. And it has data types which will be more familiar and useful.
Tortuga Chain compared to Dapper https://github.com/docevaad/Chain/wiki/A-Chain-comparison-to-Dapper 
What? No you write your Try method code so that when you return false there was an error.
[removed]
These ORMs can be easily used together in big projects when CQRS is taken in place. Dapper is good for the read cycle, where relationships and LINQ are not so important as speed (the only query that needs to be written is SELECT). And EF as well as other complex ORM (like NHibernate) perfectly fits the write cycle with complex insertions, validations and so on.
It seems B2C doesn't support custom domains yet. I would prefer authentication was done at login.myapp.com, not some Microsoft URL.
Personally I'd go with Dapper though that's just my personal preference. I find EF can be overwhelming and you can hit performance bottlenecks. The downside (depending on your point of view) is you'll spend a lot more time writing SQL statements with Dapper (as I say, this depends on your view, some see this as a positive). Since you state you're a new developer I think Dapper is a better choice anyway as it better allows you to learn the fundamentals - EF provides a lot of 'magic' abstracting away a lot of the work which has its benefits but at this point is probably something you could do without.
&gt;https://github.com/docevaad/Chain/wiki/A-Chain-comparison-to-Dapper Not updated since last year and 163 Github stars to Dapper's almost 10k which also has a big company behind it. Chain might be more powerful but sadly I wouldn't choose it for the reasons I just expressed.
[removed]
Interesting. I'd not really thought of using a seperate ORM for the reads in CQRS. I'd be pretty skeptical of the real world read performance benefits of Dapper over EF though. My feeling is that if there are indeed any benefits, they'll be imperceivable/negligible and wouldn't justify the added complexity of having two ORMs in a solution and taking the time to write and maintain many manual SQL select statements.
I use both in my projects. Dapper for reads and EF for complex inserts/updates/deletes
If your database model is simple and your table joins are easier, then EF might be better. EF makes maintenance a lot easier. The tradeoff, however, is speed. EF is just going to be a ton slower than Dapper, but then you have to maintain the SQL queries by hand. I personally like SQL, so I don't mind this part. Plus, you have access to full TSQL. EF can only use what is in common to all DBs, so db specific calls aren't allowed (when using EF via linq).
It's super common knowledge that EF is magnitudes slower than pure Ado.Net or micro-ORMs like Dapper. https://exceptionnotfound.net/dapper-vs-entity-framework-vs-ado-net-performance-benchmarking/
Thanks this helps 😀👍
Handwritten queries can be run with EF Core so that's also an option now.
Still slower than you hitting a well written stored proc. That's the thing. All these solutions sit on top of basic SQL technology. Therefore the more you add, the slower it will be. EF is a great tool, but I realized I only used it because I wasnt great at SQL. I wouldn't get better without doing more TSQL in my case.
Small problem with this is possible file corruption if computer shuts down during write. I would keep some older files as backups when using this.
The problem of EF is that you need to create a property in DbContext for the type you want to map data to (in EF Core at least). With a lot of reading Model classes this list can become very big. Of course the need of direct query approach strongly depands on your domain. But, as for me, I cannot imagine complex advanced search without converting its filters into the select query, for example. So that two ORMs approach sometimes is worth the price in my opinion. 
Ah, thank you.
But that's diminishing returns. The query EF is producing is not performing like you would like? Once it's a handwritten query it'll cost marginally the same (plus or minus ORM overhead). So if that slight overhead is acceptable in this case, I'll take the simplest/easiest to deploy/not adding extra stuff. But I 100% agree with you, EF and ORMs in general are not an excuse to not to learn SQL. It's a tool to help increase developer productivity and code quality. I've been doing old school hand-written SQL for a long time and keep an eye to how things translate from EF/LINQ to SQL. I'm quite happy it handles +95% of the boring stuff and I have options for the special cases.
But that's diminishing returns. The query EF is producing is not performing like you would like? Once it's a handwritten query it'll cost marginally the same (plus or minus ORM overhead). So if that slight overhead is acceptable in this case, I'll take the simplest/easiest to deploy/not adding extra stuff. But I 100% agree with you, EF and ORMs in general are not an excuse to not to learn SQL. It's a tool to help increase developer productivity and code quality. I've been doing old school hand-written SQL for a long time and keep an eye to how things translate from EF/LINQ to SQL. I'm quite happy it handles +95% of the boring stuff and I have options for the special cases.
If you create a new .net core web app you should see a simple implementation of .net core.
No, I mean like the source for a simplified version of asp.net core. Controllers, routing etc. I know I can view the source for asp.net core itself, but this was stripped down to the basics.
I honestly have no idea what you're asking for. Do you want the .net core source code or a project that implements .net core?
Trying to refind a project which was basically an alternate implementation of asp.net core. 
That' even more confusing :) I'm not sure what you want. I don't know what an alternate implementation is. But if you create a new .net core webapp you'll get a startup.cs, you'll get a configuration file, you'll get controllers, routes, views, and models. From there you can tweak away and experiment. 
Unless someone happens across this thread that saw, remembers, and bookmarked it, you're gonna be SoL - that's going to be practically impossible to Google with all the irrelevant matches any set of keywords is going to get you.
Maybe [Nancy](http://nancyfx.org/)? This is really vague.
Apologies, I didn't realise you were the author and I'd have been more diplomatic if I'd known. But yes, I take into consideration the last commit date when considering a project. It might be better than what I am using already but what if I hit problems? How quickly will this get looked at? These are things I have to consider. &amp;#x200B; You might want to do a website for the project, things like that make a difference too when I'm evaluating. It's often not enough just to be 'better' for adoption to take off. Good luck :-)
151 samples of striped down to the basics ASP.NET Core https://github.com/dodyg/practical-aspnetcore
Yeah, that's why I'm asking here as my google searching was fruitless.
Not Nancy, but certainly along those lines.
Just run \`dotnet new mvc\`. It's a basic MVC in Dotnet Core. 
OP is looking for a simplified example of the framework itself, not of a project that uses the framework.
Yes, exactly. A simplified asp.net core style framework.
Can't help with your question, but I find it odd that most people don't seem to understand what it is you are asking. It seems fairly obvious to me what you are looking for here.
Should work. Here is the Nuget package https://www.nuget.org/packages/Microsoft.Build.Tasks.Core/
the dotnet cli provides you with this. `dotnet new mvc` If you're looking for something more production like, I find this to be pretty useful: https://github.com/dotnet-architecture/eShopOnWeb It also comes with a free book / reference website that tells you about why it was designed this way https://docs.microsoft.com/en-us/dotnet/standard/modern-web-apps-azure-architecture/ I've also found this guy's project useful for some perspective outside of microsoft: https://github.com/bradymholt/aspnet-core-react-template
No apologies needed. As I said, I understand why you feel that way. What I should do is start adding the minor features from the back log so that at least it looks like it wasn't abandoned. *** There is a website, though it could always use some expanding. https://docevaad.github.io/Chain/Introduction.htm Or were you thinking of something else?
Speed alone isn't enough to make a proper comparison. But when EF is CPU bound, rather than I/O bound, that give one pause.
He's looking for a homebrew MVC framework modelled after .NET Core MVC
What I think we need is something that will let you right-click on the class and select "Create [SELECT | INSERT | UPDATE] statement". I know enough about database schema reflection to do half of this, but unfortunately my Rosyln skills aren't up to tackling the other half. 
&gt; .NET had an open source implementation before Java and MS never sued them, Not only that, the Mono team added features to .NET/C# that Microsoft didn't have. When Microsoft tried the same in with Java, they were sued.
C# borrowed heavily from Java, VB, C++, Pascal, and just Hejlsberg's general knowledge of language design.
DateTimeOffset isn't a direct replacement for DateTime, though I do use it when I can.
Are you talking about the original, slightly broken version of DateTime or the completely broken version that was introduced in .NET 2.0?
Not really because you can only use DateTimeOffset when you actually have an offset. The rest of the time you need to use DateTime with all it quirks. 
You're right, it is super common knowledge; that's exactly why I said real world use. I'm aware of the db benchmarks. What I'd like to see is a practical use case with comparisons for both EF6/7 and Dapper, in an end to end transaction. i.e. total response time in an actually real world solution with IoC, transaction handling, logging etc. for calling an API endpoint that hits the Db and returns data using the different ORMs. In my experience (over 10 years with .NET) the differences in these types of benchmarks become less pronounced when used in practice. Some times there's a clear winner, sometimes the differences aren't really perceivable.
No, OP remembers a particular GitHub repo they found which created a web framework similar to ASP.NET, presumably from C# primitives, and is asking if anyone else recalled seeing it.
I'm curious, is there anything like the Spring cloud project within the dotnet ecosystem?
This is a very over-engineered solution. Just generate a Guid. If your password repo requires special chars, capital letters, chuck 'A!' on the end. Nobody's cracking that anytime soon.
Your post has been removed. Self promotion posts are not allowed.
https://docs.microsoft.com/en-us/dotnet/framework/whats-new/
I can see your point, but that requires pretty much the same level of validation regarding character requirements. 
Thanks for the input! It should work better now.
Unfortunately I have one program that uses it. I wish they'd to something else, but unfortunately they don't. 
&gt; Native applications may use SQL CE via OLE DB. The latest, and last, release is the SQL Server Compact 4.0. As of February 2013 SQL Server Compact Edition had been deprecated; no new versions or updates are planned, although Microsoft will continue to support until July 2021. AFAIK Microsoft recommended switching to SqLite
Geez, that styling is annoying on mobile. I shouldn't have to horizontal scroll normal text. 
Sure, I'm not saying that wouldn't work. At the same time, you could also just dump all the character types in there without even checking the requirements and there wouldn't be any problem. It also depends on what you want to achieve with this. If you are simply generating it until it's reset by the user, then it's all fine. If you plan on having it be somewhat readable, then it might not be the best approach.
Here's how I do it... `AllCharacters` is just a string of all the default characters allowed. public static string Generate(int size = 15, string allowedCharacters = AllCharacters) { char[] chars = allowedCharacters.ToCharArray(); byte[] data = new byte[1]; var crypto = RandomNumberGenerator.Create(); data = new byte[size]; crypto.GetBytes(data); var result = new StringBuilder(size); foreach (byte b in data) { result.Append(chars[b % (chars.Length - 1)]); } return result.ToString(); } 
Can you completely stay away from PHP with this solution? I know you are able to build plugins in C#, but do you need to write any PHP to bridge the languages/core?
Thank you very much, I will check them out
Other's advice on not using GUIDs as passwords: https://blogs.msdn.microsoft.com/oldnewthing/20150701-00/?p=45241 
This entire article is based on using the first 8 characters of a Guid as a password. This is a terrible idea. My suggestion is to use a full Guid as a temporary password.
Thanks for the feedback. Would a postgres option suit you? It's not in scope for the near term, but it's something we're mindful of and have put abstractions in place to facilitate. Whether we do it will depend on demand and the cost of supporting it.
Was it definitely dotnet core? Are you thinking of one of the alternative .net mvc frameworks like FubuMVC? [https://github.com/darthfubumvc/fubumvc/tree/master](https://github.com/darthfubumvc/fubumvc/tree/master) 
Absolutely. Any open source RDBMS would work, although I do prefer postgres
Imagine you change from using a serverless function to some other mechanism (or add another trigger whilst still keeping your function) - If you had a Mediatr handler, you could just wire it up to your new trigger and it would still be the same already tested (hopefully you are testing the handlers) code, while otherwise you would have to refactor
me too.. legacy project with slq ce 3.5 and clickone i regret so much
I constantly toggle on/off Resharper so I can compare features but I still go back to Resharper as the navigation, code refactorings, code analysis, test runner etc. are still quite a far bit ahead of Visual Studio in many areas. Some features are nearly identical but Resharper is just that little bit better in some areas. I should compile a comprehensive list sometime. There's still a lot of worth to Resharper if you can bear the performance blips. 
Sorry to see the discouragement. I didn't downvote, but it can be used for a lot of things. Some people vote to mean "yes" or "no" in a purely factual response. Some mean it for other reasons such as not liking tone or perhaps they don't like a person, but by far the first reason is most common in technical forums--it's simply a way to reply to give input to an answer on accuracy without needing to type what is already being typed. Don't let it bother you.
Hah, good catch! I just used a constant, but obviously you can build it however you want. `public const string AllCharacters = "abcdefghijklmnopqrstuvwxyzABCDEFGHIJKLMNOPQRSTUVWXYZ1234567890";`
I think it wasn't written anywhere here, but you could try to follow some of the instructions from [https://www.jetbrains.com/help/resharper/Speeding\_Up\_ReSharper.html](https://www.jetbrains.com/help/resharper/Speeding_Up_ReSharper.html) &amp;#x200B; Disabling anti virus programs for your source code folders is one of the must do's :)
I got to sunset mine last year. Holy crap what utterly half-assed products. Good riddance.
Op is looking for an alternative MVC framework, simpler than Asp.Net MVC Core. 
If this password is used for sensitive material, you should probably add some method for scaling the 'byte' rather than modding over (unless your alphabet divides evenly into 255). To give an example, if your alphabet is 170 characters long, i.e. 2/3 the range of each byte, there are 85 positions above 170 that are going to "spill over" with mod, making the first half of your alphabet twice as likely to be "randomly" picked as the second half.
Yeah. It's called a web app. 
Isn’t this Azure Web Apps?
Yep absolutely, good shout
https://azure.microsoft.com/en-us/services/app-service/
I would hate to have to be the dev responsible for reviewing all of those shit pull requests.
Interesting... I'll definitely dig into that. I created this for token usage, not passwords, but the point is still valid.
Definitely do change the Random, it's not safe to use for passwords. Also I'd remove the bit at the bottom about sending the password through an email, that's a really bad thing to even suggest. Only thing you should be emailing is a timed token for reset use.
Yeah and it's alright for some things, but any WinForms UI gets a little off when displayed. WPF isn't possible. If it's a console app or the like, you're better off running it on Mono than Wine. The ONLY reason to use wine is of a dev decided to statically call the windows API or file locations.
That is correct. 
Same here. It was supposed to be our replacement for Access when it came to embedded databases, but instead it was nothing but trouble. 
You can run it in a container on a windows docker host. Net core is more flexible if you just want asp.net core
Thanks! I didn't know it could be run locally.
They call them Azure App Services now, same thing though.
Azure app service as others have pointed out. We migrated all of our VMS to app services and it was awesome. You just need to be aware of the differences and/or limitations and realize that file I/O is very very very slow so make sure your apps don't need to touch the file system. 
&gt; Wine in production Not a good idea. If you absolutely cannot rewrite, use Mono. Wine is not supported/recommended for production use. Having said that, have you checked out the https://docs.microsoft.com/en-us/dotnet/standard/analyzers/portability-analyzer linked in the other thread? Have you tried compiling under netcore 2.1 and seeing what breaks? Converting to netcore 2.1 is _considerably_ easier than anything in the 1.x line. Most business logic code will just work, as-is.
Sheesh. Before that it was Azure Web Sites. I have to think that if MSFT had stuck with the original name OP wouldn’t have been confused by the branding as “App.”
Having a hard-coded constant (although I'd recommend `static readonly` rather than `const` if it needs to be public) is the way to go. It's exactly the right mix of short, understandable, and verifiable, and it simplifies the code considerably. It also makes it very easy if (when) your application needs modified character selection criteria. For example, maybe you need a "omit ambiguous characters" option where the choices exclude (among other things) O and 0. This is trivial to do if you are using strings like this.
You can run it in a container on an app service too and then you get all the perks like autorecovery and scaling etc.
We moved from CE to SQLite a few years ago at my current job. Much easier to deal with
And app plans are really webfarms, but I guess that's less fancy then a "plan". And I think they're still Web Apps btw, App Services is an umbrella term for many of the managed thing they're offering, such as functions, bot services, web apps, etc.
That's a great attitude. What a wonderful way to help get people into contributing to open source.
That's so wrong. SQL is so painful to write that a simple query looks so long and hard to read which makes it very unmaintainable. That's why ORMs exist. SQL is just disgusting to write.
So now its not open source in general, but just a celebration of open source Microsoft projects..?
No, I just ported to .NET Core and ran it that way.
Nice example of clean architecture. But, people... please, please, please don't do shit like this: public async Task&lt;(bool success, string id, IEnumerable&lt;(string code, string description)&gt; errors)&gt; Create(User user, string password) 
If your employer pay for MSDN, you get some credits each month.
Explain to a newbie?
We had to retool a few things because of it. 
If it's going to return all that stuff, then you should make a type.
Using (nested) tuples like this could be seen as code smell I guess, as they warrant a new data structure.
Thanks for explaining!
Was looking fine up until you hid logic behind the repository. Your business layer isn‘t a plug-in, while repositories are.
I've gone back and forth on this a lot because I always see this sentiment but very little explanation. Is the issue the tuple? Should it be a class? Is it that it returns objects and results? Should it be try/catching exceptions? Real, actual question: what's the best practice here?
[removed]
do you have any string concatenation to create SQL statements in your codebase? 
No, this is just stock asp.net core 2 with Identity. 
Came here just to say this is code smell.
You're right, it shouldn't take long but I was thinking in the interim while we try to rewrite if we can run it all under wine for potential scaling benefits now. Then once we finish rewriting, then run it directly via mono. That way we get the best of both worlds. Although, it does seem like uncharted territory and for that I realize that this - running under wine - may not be the best option even in the short term.
&gt;the ability to define nested classes &gt; &gt;within &gt; &gt; an interface. &amp;#x200B; What reason would you do this as opposed to class per file?
&gt;Automapper I laughed out loud reading this...
I tried okta, and hated it. 
Before .net core, it wasn’t possible to not use VS. If I was interviewing, I’d not that you’re relatively new (I’ve been doing .NET since 2003, so it’s subjective). If you did well on the other questions, it wouldn’t bother me — actually, it’d let me know you didn’t rely on the IDE, which shows understanding. Getting preachy about how much IDEs cripple developers’ brains or something like that would disqualify you, but it doesn’t sound like that’s an issue. My job is actually an IT architect, so I’d say that I really don’t care what tool you use, so long as your stuff works and you don’t cause issues with the other developers (including them getting frustrated when pair programming or helping you set up your environment). You will be issued VS 2017 and/or VS Code, though. I wouldn’t approve Vim, just because of consistency of tooling is beneficial to an organization.
What have you got against automapper? I wouldn't use it blindly, but writing one syntax to convert from one entity to another without having to write out every single property when they're named the same can be a nice time save.
Agreed. Enforce domain rules in a service layer or the like, only that layer is allowed to talk directly to the repo, and the repo is "dumb" 
Yeah. I moved from Lead Dev to Solution Architect about three years ago. Unfortunately, I don’t code anymore and my organization recently made the move from mixed shop to pure Java (over my strong objection). I also don’t code, anymore, which makes the change even harder. Most of my time is spent doing design reviews, reviewing tool requests, and punching holes in developer ideas. What I thought I was getting into was helping set technology direction and working with teams to establish standards and improve code quality. As others have said, an “architect” job can vary from company to company — anywhere from being the title given to lead developers to guys that never get closer to code than a Visio diagram. Make darn sure you know what you’re walking into during the interview. I’m currently trying to run away from this position before all my tech skills atrophy.
Wat 
#ON THE ONE HAND THIS IS COOL AND USEFUL, HAVE AN UPVOTE. ON THE OTHER HAND, WTF HAS HAPPENED TO FULL STACK DEVELOPMENT. CIRCA. 2005 YOU COULD MAKE A CRUD WEB APPLICATION WITH LIKE ONE LINE OF CODE. 
You can do that?!? Ugh...
Been a developer since 2000, please share some info about the one line crud app. I'm curious.
I am missing discriminated unions so much!
He must be a cult member from Ruby. 
You will want to store the data in a database, look into setting up an SQL server then look into entity framework or any database orm. That would be your best solution. If you want something a bit more quick and dirty could look at importing the data from a csv.
Probably not. 
No not at all, and identity doesn't have a default admin account 
Enable query logging on your database engine and change login just to be sure. Update database to latest version, do antivirus scan.
Has anyone used this? I've never heard of it before and I love the name for personal geographical reasons. also, when they release updates, we can be like, "Y'all got that new Orleans?". I need to go to sleep.. 
I always feel that the use of tuples in this way is simply because people are either too lazy to make another type, or they think another type for just a single method is overkill or simply that just have no idea how to name it(I’m sort of a victim of the naming part)
For those wondering as I was, Orleans is a &gt; framework that provides a straight-forward approach to building distributed high-scale computing applications, without the need to learn and apply complex concurrency or other scaling patterns. https://github.com/dotnet/orleans/blob/master/README.md I have no idea what it's useful for so I guess YAGNI for me :)
They sure have enough shallow blog posts on FOTM technologies, all with a section dedicated to setting up authentication with Okta :)
It's [similar to an actor pattern like akka.net](https://github.com/akka/akka-meta/blob/master/ComparisonWithOrleans.md) (via akka, via Erlang) implements.
I haven't used it in a production project - I went with [akka.net](http://getakka.net) instead.
When you create an use case with well-defined boundary (poco request in, poco response out) several objects start to populate the folder/namespace UseCases. This happens especially if you use pseudo-discriminated unions (see for example “OneOf” on github). They’re a good tool - you get to use strongly-typed classes instead of flags and status codes. When you declare an interface for your UseCase (its usefulness is debatable, but still) you could wrap everything into a single logical unit, as opposed to having Request or Response folders that would be just big POCO bins at that point. I understand most people here are used to throwing exceptions for pretty much anything, but there are (and could be) better ways to manage the program flow, and how the various parts fall in place. Being able to define boundaries and ownership is not revolutionary, but I guess it’s controversial nowadays. 
[removed]
Maybe Orleans 3.0 can be code named Po' Boy
I'm with you on #2 and #3, which are some of the reasons why I also love F#. But I disagree that #1 is really a benefit - defining the class within the interface just gives it the same scope as the interface, there's no gain over putting the definition next to the interface instead of inside it, and it hurts code readability 
Gotcha, thanks for the reply..
FFS didn't know it was an ad until [halfway down the page](https://developer.okta.com/blog/2018/09/07/build-simple-crud-with-aspnet-webapi-vue#add-authentication-to-your-vue-application). Thanks for wasting my time.
this example is way nicer and cleaner imho: https://github.com/EduardoPires/EquinoxProject
I'm curious if anybody here has chosen this over libraries such as Akka.NET or Proto.actor. Orleans seems much more opiniated as well as heavy compared to the others.
I don’t think you answered the question. That still doesn’t answer why you’d embed a class within an interface as opposed to a namespace and one class per file. I’m not sure what status codes and flags have anything to do with it either. And no I’m not used to throwing exceptions for anything. I’m used to exceptions when it’s exceptional and no other time. You can define boundaries and ownership through assemblies, not through jamming a bunch of classes inside an interface. For example to separate business logic and business contracts from the web implementation and contracts. 
Where is your website running?
Although I think Entity Framework Core has some performance improvements.. It really depends on your project - for a service with the load of say Facebook I'd say definitely not EF but for small to mid level projects EF will work fine and your users won't notice a difference. EF is a good solution to get something up and running really quickly and it's easier to maintain - I'd advise anyone not knowing what they're doing to stick with EF first for practise on setting up data repo's. Learn from it and make the jump to [ado.net](https://ado.net) if you felt comfortable enough.
If you're a new developer my suggestion would be to use Entity Framework. Look at some basic examples and learn how to use it properly - don't skimp. Create some simple Hello World apps and when you're comfortable apply it to your project. Understand what it does and why. You'll hear a lot of people on this thread talking about Performance. EF will be slower in performance but it's a trade off with how easy it is to setup and maintain. Think of it like learning to drive. Progress to a faster car when you get comfortable on the road. As you're a beginner Performance shouldn't be a factor for you unless you're writing applications serving thousands of users a minute. TL;DR - Start small with EF and progress to something closer to the metal as you get more confident
Is it really causing you a problem at the presentation level as a user using your application running with EF? If your application is serving hundreds/thousands of people a minute I'd probably expect to see a slow down but for most applications EF should be fine.
I was thinking something that would allow me to do like: "Hey, label - figure out what text from the DB you are supposed to display based on *something*". That "something" is what I am looking for, to make it so that each control autonomously decides what to display.
I would love to switch to .net core, unfortunately our CMS platform uses full-fat .NET ...someday
AFAIK it's stateless, however it does log a lot to the file system. Maybe I should configure it to log to the DB (though DB access is generally far slower than hard drive) 
I really like Orleans. It is easy to use and has a wide range of uses. If any of you have e used the Halo live services (played Halo 4+ or used the app) you have used it. In essence it creates a simple scalable stateful service. Most services are stateless. For example, a Web API endpoint or ASP.NET MVC website by default. You submit a request with arguments and the service queries a database and then returns a result. Nothing on the service is saved. It does not have a state. It is essentially a relay for information in the database. A stateful service, on the other hand, maintains state in memory. This means that faster lookups are possible with the caveat that a client needs to connect to the same endpoint and not be continuously load ballanced between servers. The model for development is also different. Inheritance is not something that should be done. For example, if you have an employee grain (actor) in Orleans, you do not have a manager grain that inherits from employee. Instead you have an employee grain as a property of your manager grain. They can use the same ID since IDs also use grain type. Everything is also Task based with a lot of use of async / await. In the end you get a system that feels like it is synchronous code but can be clustered with little effort. 
Object mapping done by hand or generated is easy to understand, easy to test, easy to modify, mantains your object references so refactor tools work, doesn't introduce runtime bugs because you named something wrong. Autofac solves an easy problem with magic creating other problems. Auto
That’s two lines on mobile, can you please refactor?
One problem is that in VB.NET if you end up with an object type, you are allowed to call functions on it that are specific to, say, string. As long as it ends up being a string at runtime, you're good. But this prevents things like intellisense from working properly, and turns easy to fix compiler errors into hard to fix runtime errors. It's likely "my_column" was a string type column at some point. So Item() returned a string. But now it is an integer type column so now it returns an integer.
Not sure if Unity should count as its own entry. It uses Mono internally (though when building for UWP and probably other platforms it uses .NET Core).
Depends on exactly what you want. Is relational a requirement? If not, [LiteDB](http://www.litedb.org/) seems to have a pretty good set of features. I haven't really taken it for a spin, yet, but I was considering trying it for the project I'm currently working on. For me, one of the big niceties of EF is the fluent mapping, which LiteDB looks to have. I hate have display or persistence-specific decorators on my domain entities because of tight coupling (I actually do share entities between persistence options just enough that I want them clean). Also, only needing the NuGet package, rather than any sort of service looks nice.
"Grain"? Java's ubiquitous use of the term "Bean" is ridiculous. Can we keep that crap out of the .NET world please and use meaningful names? Sorry, I know you [probably] didn't coin the term so this is more of a general rant at the projects creators.
You could call them Actors, but they're significantly different to actors in the Alka/Erlang sense because they have managed lifecycles, no supervisor trees, and hence aren't explicitly created or destroyed. The reason for that is reliability in a distributed system - the runtime handles it for you. The research paper eventually coined the term Virtual Actors for them. Carl Hewitt (the person who coined the term actor in the 70s) said that "Orleans is an important step in furthering the goal of the Actor Model". So he considers them a kind of actor, too. You could call them objects, because they're similar to objects in the true sense, but that would again be confusing because the term already has a commonly understood definition. Maybe "serverless objects", since the model is a serverless one (the concept of individual servers is abstracted away), but it might be a bit on the nose. Maybe distributed objects? They're called Grains because it's a short and easy word and doesn't have any common existing meanings in software, plus the idea is that each one is relatively small and there are an uncountable number of them. There's also the idea of dehydrating/rehydrating them when they're moved in and out of long term storage, but that wording isn't often used. I'm not one of the creators, but that's my reasoning nonetheless.
A `Grain` is an abstraction made within Orleans, specific to that library. What's wrong with that?
Akka has a managed lifecycle for actors, it just puts control of this lifecycle in the developers' hands, supervised by parent actors.
I wasn't aware Mono is that old! Thanks, Matt. 
Love the timeline. Looks amazing. Nice work. 
https://stackoverflow.com/a/1019349/196319
The Unity Mono has been heavily modified. It may or may not have needed a separate entry at the time it was originally adopted, but it's definitely a separate entry now.
I've worked briefly with akka net but felt it was very rough around the edges when it came to documentation. I could do tons with it, but the learning curve was challenging. Orleans looked far too alpha when I was comparing it at the time, but if it has become a mature product and has documentation similar to other Microsoft projects I would at least take a look.
Ah, thanks. I wasn't aware of that.
This is literally the use case for OOP. Create a new class that inherits from the top-level control representing an employee. Have that class accept your Employee object in the constructor and construct itself appropriately using that data. Then have your form class instantiate these controls as needed.
Of course, this means Yet Another Visual Studio 2017 Update, 15.8.6 this time.
Yeah, although I can't take any credit for that, it's all https://time.graphics/
Thanks, I *suspected* that was the case, but didn't know for sure. Do you know if Unity has ever published the code or any info about the modifications they made to Mono?
Thank you for giving a text summary for those of us that don’t have time/opportunity to watch it yet
Do you mean something like this? [Stackoverflow link](https://stackoverflow.com/questions/60683/checkbox-in-listview-control)
Also IL2CPP https://docs.unity3d.com/Manual/IL2CPP.html &gt; IL2CPP (Intermediate Language To C++) is a Unity-developed scripting backend which you can use as an alternative to Mono when building projects for various platforms. When building a project using IL2CPP, Unity converts IL code from scripts and assemblies to C++, before creating a native binary file (.exe, apk, .xap, for example) for your chosen platform. Some of the uses for IL2CPP include increasing the performance, security, and platform compatibility of your Unity projects.
Just write your front end in vue and consume APIs from your C# back end. There is a template that Microsoft has that serves a Vue front end from a sort of mvc back end. It's not overly bloated. If you don't have any experience with Vue I'd check out the docs. They're straightforward and very well done. 
Templated and Generic components are finally out. Also creating render fragments of HTML and store them on variables or templates is quite neat. It's kinda like React and Angular together.
We recently went live with service fabric \[on premises\]. It's serving our needs very well so far. The internal process orchestrator, fault failover, domain discovery and service resiliency work as advertised. The real deal is the "stateful" programming model and "Actor" patterns. No other framework offers this and for handling burst loads/grid computing and low latency writes and reads with stateful services are god-sent.
I wouldn't consider that a managed lifecycle. A managed lifecycle means that the lifecycle is managed for you, just like how memory is managed for you in a managed language. The biggest issue with shifting the burden of instantiation to the caller is that in a distributed system, you don't know if the caller is alive at any given time. So you might send a one-way "add item to cart" message, followed by another, and you don't know if there's any actor listening at the other end unless you wait for a timeout. If you were to get an error (eg, you used an 'ask' instead and the runtime tells you when an actor is no longer instantiated), the caller now has to determine what to do about that (for starters, why isn't the actor available?). Grain's don't work that way: they are uniquely identified by the tuple of `(type, key)` and the runtime will ensure that the grain is always alive and able to receive your calls, propagating any transient availability errors back to the caller. So the user never explicitly says "go create grain X", they just start messaging grain X and it will be activated when needed and eventually deactivated when not. It's similar to virtual memory being paged to/from disk. Does that make the distinction a little clearer? Downvoter wasn't me, btw.
[removed]
Can you debug yet? 
There's nothing stopping you from having a table with a large text field where you take an object, serialize it in JSON and save it there. You'll be storing a text document with the limitation of making querying that data in the JSON impossible or harder to query depending on your SQL Server version. &amp;#x200B;
Yes, debugging was added in 0.5.0 but it's very limited. **You can currently only: ** Single-step through the current method (F10) or resume (F8). In the Locals display, observe the values of any local variables of type int, string, and bool. See the call stack, including call chains that go from JavaScript into .NET and from .NET to JavaScript. You can't: Note that the debugger capabilities are very limited. You can currently only: Single-step through the current method (F10) or resume (F8). In the Locals display, observe the values of any local variables of type int, string, and bool. See the call stack, including call chains that go from JavaScript into .NET and from .NET to JavaScript. You can't: Note that the debugger capabilities are very limited. You can currently only: Single-step through the current method (F10) or resume (F8). In the Locals display, observe the values of any local variables of type int, string, and bool. See the call stack, including call chains that go from JavaScript into .NET and from .NET to JavaScript. **You can't** Step into child methods (F11). Observe the values of any locals that aren't an int, string, or bool. Observe the values of any class properties or fields. Hover over variables to see their values Evaluate expressions in the console. Step across async calls. Perform most other ordinary debugging scenarios. Step into child methods (F11). Observe the values of any locals that aren't an int, string, or bool. Observe the values of any class properties or fields. Hover over variables to see their values Evaluate expressions in the console. Step across async calls. Perform most other ordinary debugging scenarios. Step into child methods (F11). Observe the values of any locals that aren't an int, string, or bool. Observe the values of any class properties or fields. Hover over variables to see their values Evaluate expressions in the console. Step across async calls. Perform most other ordinary debugging scenarios. 
Thank you, seems like they are making great progress.
I'm so excited for the first non-experimental build of Blazor it's unreal
I'd do this by having the following two tables to begin with. Forms -- FormId - PK, int Name - nvarchar Fields -- FieldId - PK, int FormId - FK, int Name - nvarchar Order - int DataType - int (corresponding to an enum) Constraints - JSON, possibly (list of allowed enums for varchar types, min and max for numeric types) Each form gets its record in the Forms table. And each field in a form gets its own record in the Fields table. It would be easy to assemble most simple forms out of this much information dynamically.
Have you compared the Postgres and Sql azure paas prices? I recommend determining your needs then compare costs then make the decision. 
Wow, that's really interesting. Never thought of it this way! Thank you.
no, i presumed postgres will be cheaper, but perhaps it isn't!
https://azure.microsoft.com/en-gb/pricing/details/postgresql/ If you can make sense of the mystery of azure pricing
SQL Server 2016 and up even allow you to query JSON but I imagine that won't be super efficient. Depends on what your goal is it could be enough. Or maybe at the end of the form survey campaign you aggregate the data or something like that.
Look into the Identity documentation for this. simply said, you use the UserManager class for creating new users and asigning them to roles. I.E. var User = new ApplicationUser(); await UserManager.AddToRoleAsync(user, "Admin" ); Hope that helps you
Okay thanks this was helpful 👍🏻
You can turn OwnerDraw on and use VisualStyles and/or ControlPaint classes to draw the checkbox in the cell.
Client side debugging is very very limited at the moment, /u/orisfunk gives a very good detail on what you can do with Client side debugging. But you can actually use Server-side with full .Net debugging and it's quite easy to switch modes since if you decouple your API usage you can swap out the API services easily. It's what I currently do right now when playing with Blazor, make a server-side app first then from time to time swap to client side if everything still works. And good news since Server-side is commited you can start making them on that mode when the Blazor model matures and swap back to Client when client side gets full commitment from MS.
&gt; Hangfire Interesting. I'll take a look
Quite a few large companies use SQL Server.
&gt; First demo is WPF then is AvaloniaUI that starts at 1m14s. Rendering performance of AvaloniaUI+SkiaSharp+OpenGL vs. WPF (rendering of 5600 strings). https://github.com/wieslawsoltes/Core2D https://github.com/AvaloniaUI/Avalonia
&gt;classic ASP page Oh, my deepest condolences. I haven’t had to touch that stuff in over a decade now.
Hmm, that's interesting. SQL Server on Azure maxes out at 80 cores. And PostgreSQL a measly 32 cores. Compare that to SQL Server 2008, which supported up to 256 cores.
Can you share the project file that you showcase with Core2D in your video? I'd like to see the performance on my own system.
You're right - I'll switch to WPF. What topics would you recommend I read up on?
I'm afraid I have only dabbled a bit in WPF myself, so I don't really have any recommendations, sorry! I'm not even certain WPF can let you manipulate XAML at runtime to do templating with it like that. I don't really know enough about it.
Remembering back 20 years.... just use (javascript) in asp pages, it will save your brain from exploding, you can then use a lot of older javascript libs to do things like json2.js ([https://gist.github.com/atheken/654510](https://gist.github.com/atheken/654510)) for parsing json etc &lt;%@ Language= "Javascript" %&gt; &lt;% var message = 'This is my message: '; for (var i = 0, endI = 10 ; i &lt; endI ; i++){ Response.Write( message + ' ' + i + '&lt;br&gt;' ) ; }; %&gt; 
&gt; * Should I use EF Core? Yeah, probably. You could consider Dapper as a micro orm instead, but you probably don't really need the performance and managing relationships and changes is easier with EF. &gt; * What about Ninject? No. It doesn't really have any features you can't find in a more performant IoC library. I recommend SimpleInjector or just using the built in IoC with ASP.Net Core. https://simpleinjector.readthedocs.io/en/latest/index.html &gt; * Do I need to design it differently if I want to put it in the cloud? Not much really. Avoid using the local file system. Keep your web sessions stateless. Don't use P/Invoke and native code.
https://files.gitter.im/AvaloniaUI/Avalonia/Gpqp/lines.project https://files.gitter.im/AvaloniaUI/Avalonia/rCwe/texts.project
That was my perception also :)
Are you the guy from the thumbnail?
Consider not using ASP.NET MVC and instead use ASP.NET Core.
If you want to go super cheap, user a linux docker container with postgres, host on vultr - $5/month.
It's good to hear from the Blazor team! I was wondering when we would hear from you again. Keep the updates coming!
I'm a little confused by this. I don't see how passing a view model to the view, and translating between View models and domain models is any different to standard MVC? That's what the M is for... I've always had a view model per view, and the controller translates between the view model to the domain (hence controlling everything). What is the M in MVC for in your instance? Do you have 2 different models? 
I like the separation of concerns and testabilty, but don't think I could take this and run with it. 1) By hybrid MVC-VM approach do you mean hybrid MVC-MVVM? 2) Do you have any recommended resources for further reading/tutorial for this approach? 3) I am planning on eventually moving over all my current WinForms apps. I don't want to use an approach that would make doing that prohibitive. I'm concerned about the downside you mention in regards to that. Thoughts?
Thanks. I'm being lazy and simply saying .NET instead of .NET Core. From what I have read, Core has what I need. I know not all features are in Core yet, but I don't need to use features that are specific to regular (straight/plain?) .NET.
.net framework vs .net core Framework is being sort of discontinued or at least all of the new development focused on core.
The service layer (which creates the viewmodel in this scenario) would be considered part of the model. 
&lt;slaps forehead&gt; Yeah, framework. Geez, come on brain!
I found it this year. This amazing, especially if you want to use decorators. 
Parquet.NET has actually changed since v3.0 and is faster than C++ lib, especially around complex types. It's also more memory and CPU efficient than parquetcpp (we're using native array pooling and try to keep everything in GC gen1). Low level details are exposed since v3.0 when the core was rewritten, and this lib has a strong attribute of implementing anything new low level fast as it's a fully self-contained package. It also provides optional row-based access missing in ParquetSharp or java libs (unless you're using wrappers like Spark). It has native C# POCO serializer to parquet files that works by generating IL on the fly. Linux, Windows and Mac support is first-class, but it runs on Android, iOS, Xbox, Samsung TVs (some real world scenarios) etc. There is no marshalling or serialization overhead anywhere, it's a single zero dependency nuget package targeting all platforms and architectures. 
Not only does it suck, but is a clear security hole. Too easy to inject, or protect against injection in a non-pragmatic way.
1) Yes, Model-View-Controller-ViewModel 2) None offhand, however it's a widely enough discussed topic that your Google results will match mine. I would put search emphasis on differentiating between the patterns of MVC/MVVM and the actual ways they are implemented. A quick search turns up [this post](https://stackoverflow.com/a/3540895) and [this post](https://stackoverflow.com/questions/24588838/entities-vs-domain-models-vs-view-models/24591599#24591599). The second post would probably help you envision it better. 3) As far as the downside, that really won't matter unless you're talking about an application that's getting millions of hits per second. Anything less than that and you're in the clear. Most of the time, this practice is not put into use for pages that get that volume, it's used in complex business applications that see far fewer hits.
Thats not the source. That is an opinion article, with several crossed out statements probably from the assertion that .net is no longer supported. This could not be further from the truth, as "there is no end in sight for support." This is the real source (for the author's article and my quote, both from the dustin metzgar): https://player.fm/series/the-net-core-podcast/corewf-with-dustin-metzgar
WPF + DataBinding + ListView + Templates
these may be a big complex, but the target nowadays is microservices. i think the biggest pitfall made if someone would start a new app from scratch now is doing a monolithic web app over service oriented web app. the point being you want your front end entirely decoupled from your back end services/apis. this gives you better flexibility, maintainability, and scalability. https://github.com/EduardoPires/EquinoxProject https://github.com/dotnet-architecture/eShopOnContainers
Learn how to do dependency injection with constructor injection, you'll love how easy refactoring is. Try very hard to only use new() for Poco classes.
You can do something similar in Winforms if you want, it is not as easy as Xaml, but it is feasible. 
We have a few paths depending on the application type and where its hosted: On-Premise Database in SQL Server deployed using DACPAC: TFS Release Manager invokes custom Powershell which uses SQL command line to pre-DACPAC SQL Script and then runs DACPAC command line to deploy database .NET Framework 4.6 apps deployed to on-prem app and web servers: TFS Release Manager invokes custom Powershell to stop service or website, copies files, and starts service or website .NET Core apps deployed to DCOS using Docker: TFS Release Manager invokes custom Docker container that has Python script that deploys app to DC/OS using DC/OS API .NET Framework apps deployed to AWS ECS using Docker for Windows: TFS Release Manager invokes Docker container that has Python script that deploys app to ECS using DC/OS API AWS CloudFormation TFS Release Manager invokes command line script (that uses AWS tools) to deploy CloudFormation templates Non-DACPAC databases (Generally MySQL or Postgres on AWS RDS, generally Aurora): TFS Release Manager invokes custom Docker that runs Flyway migrations against target database But it all starts with TFSRM. It's flexible enough for our needs. 
Which version of TFS are you using? Do you have a deployment pipeline set up with a dev, integration, prod environment? Is it easy to set up deployments?
Honestly, I've found that SQL server on Azure is one of the cheapest database solutions around. The lowest tier is $5/mon for 2gb. What did you see for postgres pricing?
DO - NET CORE - DEPENDENCY INJECTION - USE AZURE AD FOR PERMISSION MANAGEMENT - USE AZURE BLOBS FOR FILE STORAGE - USE ASP NET BOILERPLATE DO NOT - CREATE YOUR OWN MANAGEMENT - PERMISSION SYSTEM - STORE FILES IN DB OR FILE SYSTEM - USE EF6 - CREATE A CRUD MONSTER, CONSIDER USING MICROSERVICES
TFS 2018, though most of the pipeline was set up on 2015 and 2017 Yes, we have a pipeline set up, generally 2 sets with shared task groups: Dev/QA: Teams manage their own paths Prod Path: ALPHA is set to deploy automatically upon a new build created from the "release" branch on the relevant git repo PROD is deployed once a week on a schedule, with manual oversight to determine if we should roll back, but the actual deployments are automated (human clicks the button, TFS does the work, human verifies that the release isn't broken) All other "prod-like" environments (Demo/Training and Patch Verification) are deployed automatically after PROD deployment. They can be deployed to manually during the week otherwise (i.e., to verify a patch on release-1 when release has already been cut for the weekly deployment, or to fix a Demo-environment specific issue, etc...) 
I'm a fan of this architecture https://www.youtube.com/watch?v=wTd-VcJCs_M Also it depends what you mean for the cloud, if you just want to spin up a VM and shove the file on their then probably not. If you want to take advantage of cloud native tools then I recommend you look at the 12 Factor App. https://12factor.net/ 
Yes. I work for one.
Nice. That sounds great. We also use TFS and Git, but aren't using the release management module. Are there built in mechanisms that do the roll back for you, or do you have to push a fix forward? Or script the rollback? Any gotchas with using TFS that you have encountered?
We're also looking for a .Net Core CMS, but we couldn't find any good one that supports an open source db, so we landed on building a CMS on our own.
Use thin controllers. Ideally, in all your controller methods you’ll call some other class to give you a view model with all needed data, and pass that to your view. The only logic in your controller besides that should be built in asp.net stuff like user.IsAuthenticated or ModelState.IsValid. Reason: ASP.Net classes like HttpContext, and the Request object are hard to mock. The better you separate that from your other classes that return viewmodels, the easier unit testing will be.
STAHP YELLING!
SORRY MY KEYBOARD BROKE HOWEVER UPPERCASE IS UNDERRATED SORRY
One big mistake I made was returning entity models from my controllers. You can end up serialising whole relationships. Create a view model with the exact data the page needs.
I̺̰̙̣͈̙͔͡T͓͕̻̦ ̖̖C͖͎̰̩E̷͔̩͎̥̦R̳̺̗̤͎T͘A̹̼̩̮̲̹̟͡Í͍̼̫N͇̥̣̮̥͍ͅLY̲̟̰͕̖̭̪͘ ̝̞̙̪͔̠I̺̰̖̲͕̹S̴͍̪͓ ̺̙͓̟̙̩Ǹ͉͖̙̗͇O͡T̼̟̹̱̮ͅ. ̣̜ ͏̤T̸̘̩̘̤ͅR͕̪͖̘̬̝E͎̼̯͉͚̱͝M̖̯̫B͓̟L͈E͙̣͡ ̴̼̺̙I̤͓ͅN͞ ̵̞͍̭͎Y͉̞̤̩͞O̯͖̣̳UR͏̹̯̝̭ ̻̗̖̳̞U̘͚̞̻͝N̫̯̖̺̗͓̦W̸̯̫O͇̜̺̘̩͟R̳T̟͖̩̲̪H̬̖͙̙͚̖͈I̭N̕E͍̻̫ͅS̙͡S̘͚̼̣͖!̬̹̭̱̜͔͞ ͚͔̝͇̲ ͔̱̟̣ͅͅK̴͍͚ͅN̯̞̜̠͇͇O̩W̧͔̮̹̹̼̻̺ ̯͕ͅT̺͘H̯͓̮̩͔̗̥Y͇̬̜̼͓̕ ̥B͈A̫̼S̠̱̻̯̤̘̦͜E͉̙̭͎͡N̩͈̬̳̲E̱̗̣̭S̴͖̳S̲͙̫͙̤̘͔͜,̛̗ ̻̮̙̭̟̹̗ B͓͙O̗̦͖̰̮̞̕W̮ ̤̦̺͉̘̞B̞̘̲͝E͎͎̣̥͙̺͟F͈̟̳̱O̖R̭̩̘̗̯̮E̵̯ ̭Y̝͎̙̖̳͖̟O̗̦͎̙̥U̟̠͈̼̺̞͕R̨ ̰P͍̲̦̱͎̭̗͡R̫͎̯̮̩͈Ơ̭P̻̞̝̀E̘̮̜̦͇̘͕͢R̳̖̥ ̘̣̰̰͍̝̦͟G̯̮O̙̞̟D̙͙͓͖͖̰! ̡͔(̗̘̦̦͙͚̘A̤̘͙̩̖͎̳n͕̻d̳ ͇̳̦̳̭̳͓͟b̠̠̺͈̥̜̞u̝̲͖͡y̶͉̳͈̪ ̶̝̙̺a͖̦̳̝̠̹ ̜̮̪͕n͇̮̙͈͖͎̯e̫̬͕̖̯̜͎w̵̟ ̶̟͉̼̘̣̬k͎̝͈̤e̛͈̯͈͕̣y͏̦͇̯̤͕b̥̯̙̺̞̦̕o̫͍̻̱a̹̘̭r̗̣̤͎̪͔͓d̙͙ ͚y̫͡o͇̼͖̺̰̯̞u̺ ̢͇f̱͕̞̪̤͖uc̞̣̟̘̣͍̤k̞̭͖i͉̠͍͚̗̘͡n̝g̭̤̥̯͕͜ ͖͍̝̝͎c̸̞͍̹͎̯̟͍h͙̪̞̻̠͍͢ͅe̶̗̩͇̫͉͎͕a͉̪͇p͖͇͙̺s͏͓̞̦̘̩ka̗͓͈̼͕ͅt̲̥̳̫̭e̩̰!̝̤̣̝͜)͔͟
I was going to write exactly this, but most likely not as good. Great post! 
Powershell
For our netcore app we are using jenkins with docker on unix machines works like a charm. For our net framework legacy app we are using jenkins and octopus on windows servers. 
No I've always used the M in MVC to be the view model. MVC doesn't promote separation of concerns of the domain, but the view. Its about keeping logic out of the views. I did specify in my comment using a domain model (I. E. An entity, person) and a view model (I. E. CreatePersonViewModel) together, so I'm not quite sure how that came across as me using the same entity everywhere, but thanks for your reply non the less. I'm sure it will help someone else! My question to the OP was, if the M in MVC is for the CreatePersonViewModel (which it is), what does their VM stand for in MVC VM. (this would be different to MVVM which doesn't use a controller) 
VSTS for our cloud based stuff, annoyingly clunky Jenkins scripts for on-prem.
thanks!
In the company I work for, Jenkins because of legacy projects and consistency reasons. Personal, Azure DevOps. 
Just use VSTS (Azure DevOps).
I use MSBuild to deploy. 
Octopus. VSTS builds and packages, Octopus deploys to development and testing automatically. With the push of a button we can later push to production. &amp;#x200B;
Thanks for the feedback. I've referenced this from our [GitHub issue](https://github.com/cofoundry-cms/cofoundry/issues/171) that tracks this feature.
What's a CRUD monster? 
I really loved the virtual light trilogy by William Gibson, even though it was written in the 90’s, it seems even more relevant to the current day. 
is this real? LOL
Jenkins to run various powershell scripts that deploy, validate, smoke test, etc.. to various environments in turn with different sign off points running off AD groups as gate keepers.
For the easiest path I'd use Octopus Deploy as it's designed with ASP.NET and IIS in mind. Out of the CM tools you've mentioned I've set up a few .NET environments with Chef, Puppet and Ansible. Ansible was the best for ease of use, setup and customisation. But these environments also included MySQL, Hadoop, Nginx and Kylin.
Go out and build something :)
I hate bamboo too...so happy to have left a place where I couldn't pull them away from it.
Care to explain what's the problem with storing files in the database?
Octopus
Octopus deploy kicked off from TFS. Octopus is awesome! Just check it out, you'll love it. Previously I used Jenkins + web deploy and I hated my life. 
Appveyor you mean?
Team city + Octopus
build things
Buings. *** ^(Bleep-bloop, I'm a bot. This )^[portmanteau](https://en.wikipedia.org/wiki/Portmanteau) ^( was created from the phrase 'build things'. To learn more about me, check out this )^[FAQ](https://www.reddit.com/78ilq0).
Chocolatey for days. We have a couple different types of environments we need to apply to (AWS/on-prem/locked-down customer site), so we use choco packages for everything that gets deployed, including things like dacpacs, static files, and reports. Easy to tell at a glance what version of anything a server has and keeps the install logic with the code. Our actual release pipeline ends up being pretty light aside from a boatload of testing. Moving to a system where we use chef to get the base configuration of servers down, packer to create images with the cookbooks, and terraform to create environments with the images. Haven't seen how much we're going to need super fast auto-scaling, so still deciding between images that use userdata to grab the latest package or completely new pre-baked, though. We use ~~VSTS~~ **Azure DevOps** for build/release/issue tracking and it works pretty well for us, aside from a few annoying things *couchnoyamlreleasedefinitionscough* of course. 
Before going full VSTS, we were using TeamCity for build and running unit tests. Our ASP.Net projects would include the OctoPack NuGet package which adds a MSBuild task to create another NuGet package for deployment. This NuGet deployment package gets published to the TeamCity artifact repository. We then uses OctopusDeploy to consume the NuGet package for deployment to the servers. It worked well. But VSTS is definitely nicer. We can track a deployment back to a release, back to a build artifact, back to a commit in Git, and find its related work items, etc.
Most certainly. It features large multinational corporations, mixed reality headsets, human like AI and big data data analysis. What will YOU create with Azure and .NET Core 3.0?
Docker and AWS Elastic Beanstalk (for ASP.NET Core).
Octopus and teamcity. Used it for years and still happy! 
Thanks was a phone deal and has been corrected
Cake Build .Net. Fully customisable and very well supported with addons for everything from Sonar / Slack / Jenkins etc. We run enterprise deployments in CD using our Cake setup combined with BitBucket / JIRA / CloudFoundry. 20,000 users per day so our deployments need to be reliable and we've found Cake fantastic. [https://cakebuild.net/](https://cakebuild.net/) If you are currently using MSBuild / PowerShell etc then you'll immediately see the benefit of Cake after playing with it for 5 mins.
VSTS
We use TFS for on-prem build and deployment. 
WHEN YOU CREATE A HUGE SYSTEM THAT HAS MANY COMPONENTS OR AREAS AND WHEN YOU WANT TO UPDATE A SINGLE LITTLE THING, YOU HAVE TO UPDATE AND REDEPLOY THE WHOLE SYSTEM
VSTS -&gt; Azure container registry then Helm upgrade in AKS to upversion Kubernetes deployments. 
Yes. They are the same thing. In my environment I start with a smoke test environment where we deploy and then do a simple login to ensure the system is at least accessible. No sense deploying a busted build beyond the one environment and halting testing work. Once that passes, the same build artifact is passed on to 5 other environments for parallel deployment. It is all pretty nice. On the pluralsight stuff, I would encourage you to sign up for the ten day trial and then cancel if you don't think you can keep up with it. Will at least allow you to watch this one course. Personally I pay for my own yearly subscription. In the grand scheme of things it isn't much and having easy access to the information is invaluable. 
Odd bot
More complex queries are really a pain in the ass. EF is good for really basic CRUD operations but you'll approach a point where it just doesn't scale anymore and it's hard to get rid of it or convert to stored procedures. \&gt; The app is going to be small at first, but expand over time. You might consider using EF but only for the detail/edit entity screens and deleting. &amp;#x200B;
Ha, can you elaborate? I thought the atlassian stack looked pretty nicely integrated.
My company has Pluralsight licenses, so I'll have to dig up my old account. Haven't used it in years. Thanks for the info! What would you say the deployment failure rate is? What kinds of issues do you run into with the TFS deploy?
Nice. The things I've seen about octopus make it very appealing. Do you know anything about their licensing?
It's pretty cut and dry on their website, they now license on a target (server) base instead of a project base. We have mutli-tenant and single-tenant deployments and both work flawlesly. 
Docker Compose. I make a YAML file to describe the app and any backing services it needs (like PostgreSQL) and use the "restart: always" for each container. Then, I can deploy to any VPS provider like DigitalOcean and not have to worry about the app ever stopping.
Kind of off-topic but I started playing around with it yesterday and love that you can do this: &lt;button onclick="@(e =&gt; Console.WriteLine("Hello, world!"))"&gt;Say hello&lt;/button&gt; Using Lambda expressions in an onclick event. Pretty sweet.
What's wrong EF6?
Bad bot.
&gt; complex queries are really a pain in the ass Just use `FromSql`. How is that a pain in the ass? It's no different from how you'd make the query in any micro orm.
It's always good to start building things, even crappy little things, once you know enough to get started, but if you want to continue reading in depth, I'd suggest a few books from Manning I've finished: &amp;#x200B; * [https://www.manning.com/books/dotnet-core-in-action](https://www.manning.com/books/dotnet-core-in-action) (If you want to learn more about the .NET Core platform itself. This one also features some unit testing.) * [https://www.manning.com/books/asp-net-core-in-action](https://www.manning.com/books/asp-net-core-in-action)
It does cover on prem, but unless you are on an older version like TFS 2015 or below, the functionality is effectively the same. The UI is radically different in the cloud and coming to on prem with TFS 2019, but the steps you follow for putting together a release pipeline are pretty much identical if you are on TFS 2017+. Your pain point will be if you are not closer to the new versions and you have to fight your way through bureaucracy to get it updated. I wish you well in that endeavor. &amp;#x200B; If you're using older stuff, look for course from Ben Day or scour through his [blog](https://www.benday.com/blog/) for some of the older posts. He has a few that cover TFS 2013 and 2015, but last I spoke with him he was saying he needed to go through and update his latest course to reflect the Azure DevOps rebranding so at some point his stuff will look like what you have been seeing as well. &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B; &amp;#x200B;
Why's that?
You'd be designing UI tables by executing SQL scripts/editing the database directly. While your suhhested method is quick to *generate* the forms, it will be incredibly cumbersome and ugly to maintain. My previous job did exactly what you are suggesting and it was absolutely horrible to make changes.
Welcome. The failure rate is actually pretty low. Where I tend to see problems is with database upgrades and that is purely because of the manner being used to perform the updates and therefore very specific to my situation. Other than that it all runs smoothly. &amp;#x200B; Prior to setting this all up the idea of having half a dozen environments set up for different scenarios was a virtual impossibility. Things were done manually and the idea of one guy sitting there waiting for the build to complete followed by trying to deploy to all of those environments in a timely manner was just absurd. We kept running into situations where developers would get bugs sent to them because one QA person had configured the single test environment to work in a way that caused the functionality to not work without telling the other QA people. Now we can say "Well of course it didn't work on the 'free' environment. That's a paid feature and the button only shows if they pay for it. Check it on the 'paid' environment". With the environments split out it is pretty easy to differentiate what is happening and not worry about what someone else may have done to things to get their particular use case tested.
For one client, I'm using TFS -&gt; MSBuild -&gt; Octopus and it works well. We're grandfathered into the Free license that Octopus no longer offers. I really like Octopus because it's very easy to configure and kick off scripts to run db scripts, update SSRS, etc. Deploying to multiple environments is also seamless. For our other projects, I'm using GitLab CI/CD to MSBuild, then using PowerShell scripts to do the actual deployments. Handling multiple environments is kind of clunky but I've got it working well enough while keeping the .gitlab-ci.yml file static. I may purchase Octopus in the future to streamline the deployment side.
Learn by practice, not by only reading. Reading programming books should only serve as a reference, it's always best to get your hands dirty as much as possible. You'll end up a professor, not a programmer with what you're doing. :)
We publish from Visual Studio to a local folder. Then we run a sql script and use Beyond Compare to copy the files to the website folder.
USE CAPITALS FOR EVERYTHING
Would you still use ASP MVC to create the APIs? I have not read about CQRS, so I'll look into that. However, I have read some about DDD. What I have read (can't find the source), is that DDD is really over-engineering unless there is a strong need. Thoughts?
good share, thanks!
You are saying use `new()` instead of `new(id, name)` for example, correct? If so, why? Where/when would you set the properties of the object you just created?
I will check this out. Thanks. Will likely have some followup questions. :)
Thanks for the tip. Do you happen to have any example of what that looks like? Both good and bad examples?
Makes sense. Thanks.
I'll have to dig in and try to digest this more. Thanks for the explanation.
Eh? No. This is just the storage mechanism. You could create a pretty graphical interface to generate the forms and their fields. Directly executing SQL from your application is a one-way ticket to security holes.
You like Core? Why? Probably because it's cross platform right? Well, everyone is telling you to build things... That's cool, but my recommendation is to go install a simple small dotnet Core app on a Linux distro in a docker container. This is WHY you chose dotnet Core. Go experience it!
I too recommend learning Docker with ASP.NET Core
Why do you need to update the existing JSON objects in the database when the fields of a form change? Also, why do the forms keep changing?
I am not familiar with the Html.Grid(), but I have done a lot of raw HTML. The way I would do this is to make a second row below each row that has a single cell that spans across the whole table. This cell would be hidden or shown by the expand button, and would itself contain a second embedded grid/table. Hopefully that will be enough to get you going.
I only end up using the Jetbrains memory profiler once or twice a year- but it has paid for itself each time I've had to pull it out. 
No, he or she is advocating leveraging constructor injection (IOC) to resolve dependencies (think services, repositories, whatever that have their own dependencies) vs new-ing them up yourself manually. You can create new POCOs with `new(id, name, ...whatever)` or use a factory.
Ok. Thanks for the clarification.
Genuine question, I get the benefit of CI and hooks, but what other problem does this solve for you? This is not a critique of VSTS/Azure but I just haven't come across something yet where I need a system for builds. We have a release manager, who decides when one happens, they build and deploy to azure. Using deployment slots and environment configurations, we move that build around to test as needed. This isn't being snarky, I am sure I am missing some aspect to this since it has become so mainstream, but I haven't seen a situation where a build pipeline would solve an issue yet. All of our problems occur before the build, or only found in testing after; everything in between seems fairly standard and tedious.
Today we pay on average 2124$ each month for our RDS MS SQL instance on AWS, if we used Aurora (with Postgresql compatability) the price would be around 442$, to increase storage space and IOPS is also cheaper with Aurora and it has a ton more features in the AWS ecosystem.
&gt;With .NET Core, you can ship the framework as part of your application. This enables you to take advantage of the latest version, features, and APIs without having to wait for the framework to be installed. Who even wrote that part. Referring .Net Core as a framework while you have something such as .Net Framework. 
Hey, thanks for reading! (I'm the author of the book) The book should give you just enough to "be dangerous" and go build things. There is plenty that isn't covered, but googling or referring to larger books (like the Manning ones mentioned below) should help you learn more. I'd recommend picking a small problem that annoys you, and trying to build an app that solves it. For example, I built [OpenID Connect Debugger](https://oidcdebugger.com) because I got frustrated trying to hook up social login in something else I was building. Next I want to try using ASP.NET Core and SignalR to build an easy text sharing app because I'm often working on two different machines. Shameless plug: If you have access to Lynda or LinkedIn Learning, I have a few video courses available - https://www.linkedin.com/learning/instructors/nate-barbettini If you don't have access, DM me and I can send you a 3 month coupon code. I also wrote a long-form tutorial (almost its own Little Book) on ASP.NET Core + Vue.js featuring my day job (Okta): https://scotch.io/tutorials/build-a-secure-to-do-app-with-vuejs-aspnet-core-and-okta Good luck! :)
POCO is plain old c# object, or a class with only value properties, not method or logic.
HAHA WHY AM I GETTING DOWNVOTED?? SRRY IM NEW
HOW COMPLEX CAN A QUERY BE LOL? 
Also, our pipeline mission statement was that we had to be able to completely run the pipeline locally before committing. That includes IIIS setup, uni tests, integration tests, e2e tests, code quality checks via Resharper CLi, OpenCover reports etc. Cake catered for all of this giving us full confidence by treating each developers machine as a mirror of the destination deployment. 
It's a pain because you now have a bunch of queries written in linq (that can thusly benefit from other refactoring tools, various types of static analysis) and then some Normal SQL. Besides, the bigger fear for many when it comes to EF and complex queries is that it IS a complex query, someone DOES write it in LINQ, and the result is something that causes a DBA to slash your tires. You can absolutely write decent SQL with LINQ. And you can absolutely write terrible raw SQL. But IME it's easier for a developer to write a bad performing LINQ query than a bad performing SQL query. 
It's just really geared toward having builds, then creating a release from those builds before ultimately creating a deployment. There wasn't a good way to share variables (that I know of) between builds and deployments. There are some things that just don't fit into the build/create release/deploy model. I prefer teamcity by far if I'm having to pay for a CI tool. Also, there really wasn't a good/easy way to tag branches with build version numbers in git. It's really not one single thing...just a lot of little paper cuts.
It's faster, it's cross platform and it's the future.
Amazing! Thanks for the great library and example!
\&gt; Besides, the bigger fear for many when it comes to EF and complex queries is that it IS a complex query, someone DOES write it in LINQ, and the result is something that causes a DBA to slash your tires. \&gt; But IME it's easier for a developer to write a bad performing LINQ query than a bad performing SQL query. &amp;#x200B; This. Thank you
.Net is legacy software. Long live .Net Core.
usually i prefer to reserve HTTP 404 - Not Found for invalid URL or API Service is not available. but in case of PUT, i prefer to return 400 - Bad Request used for validation error message ( like invalid data, any business rule failed resource is not available for update etcs)
LOL SIX PAGES? SQL IS OVERRATED USE LINQ 
Well, you just need Jetbrains Rider to do all the jobs: Vue, .Net Core in one place. If it's about azure deployment and services, then you're right to stick with Visual Studio. However, it's always an option to do deployment and azure services through cli.
Ooo... Good luck for you. But, if you need more experience to manage your own server. I personally dont want any headache and use shared hosting is enough. :)
Your book is amazing, and I love the "Learn by example" method. Would you consider writing a more complex one? Like a more complex task manager with a lot of different fields and options? I would gladly pay for such a course. I found your method of teaching much more effective than other books I bought, like the Manning's ones.
lovely bot
Because .NET Framework doesn't own word framework that's why.
I would be very interested to read the nitty gritty on where they use dapper vs where they use ef core, though.
OT, but I find this banner great: https://i.imgur.com/ibJjkGN.png
Linked twitter thread about SO going offline: https://twitter.com/Nick_Craver/status/1047925037007884288 tl;dr: &gt; Instead of pulling back dozens of posts from the databases (filtered remotely), the StackExchange app pulled back 142 million posts per user profile load (then filtered locally). They replaced it with a dapper query as a quick fix while investigating ;)
It's very cool that part of Blazor is going to production. I still want WASM Blazor on the client side to progress and hope Blazor being included as Razor Components will keep things going for Blazor in general.
That's a funny one. I've seen that kind of issue when an IQueryable gets cast down to an IEnumerable with other ORMs, wondering if it's something similar here.
The expense of using EF has usually been in converting your LINQ query (either query syntax or method syntax) into a SQL statement and in object materialization and entity change tracking. Dapper is excellent at materializing a result set into an IEnumerable&lt;T&gt; and it doesn't have to deal with query generation since it accepts SQL statements directly. We've converted our simple (select * from SomeTable) queries to Dapper for performance too but kept EF when doing inserts since we get unit-of-work transaction support from the DbContext. I suspect they've encountered areas where Linq2Sql was overkill and switched to Dapper. 
We use dapper for reads, EF core for writes.
Can we mark it as "duplicate" and scorn them for not using Google first?
So why did EF Core turn that Where into a client side filter? Was it the use of the answers local variable?
TIL StackOverflow was running on .NET 🤔
Because: \- you should be choosing the simplest, primitive solution where you can help it \- db storage is expensive
I’m not sure I get your question? .Net Framework is the name of the existing framework. .Net Core is a newish, open source C# framework. Why are you questioning dotnet core as a framework? 
I've never used Dapper before, or worked with two different ORM frameworks in the same project for that matter. Do you use the same entity classes for both Dapper and EF, or do you need to make one for each framework?
You should be able to use the entity class. IEnumerable&lt;MyEntityClass&gt; x = conn.Query&lt;MyEntityClass&gt;("select * from sometable"); Dapper adds the Query() extension method to IDbConnection.
It is possible to create arbitrary links to any point in the document but I don't know about highlighting. I am also not personally familiar with how to set up links like that. IIRC link properties are just key/value pairs of strings so you can try searching for how to set up what you want with ANY PDF library and it will probably work in iTextSharp too.
For a long time they were the premier .NET application on the web. They even created a popular ORM called Dapper.
Have you heard of vertical slice architecture? https://jimmybogard.com/vertical-slice-architecture/ It effectively allows you to use the right tool for the job depending on what feature you are working on and it a great way to move away from BBOM architecture.
Just curious. Do you mean just PowerShell scripts or Desired State Configuration?
My guess is a group by call. Not sure about the latest version but they were local before.
My (limited) understanding is that overrides in IL are largely implicit: any method with the `virtual` flag automatically overrides a `virtual` method of the base type with the same name (and signature?), unless it also has the `newslot` flag. The `override` directive (which I assume your `Overrides` property represents) can optionally be used for explicit overrides. In the case of C# this is used for explicit interface implementations, but the IL be used for methods as well.
I think the bigger news is they are going to use EF Core. Very interested to see how they perceive it after it being deployed for a bit.
My guess would be because they called to list on the first query.
Yeah, first time I saw that was a few jobs ago. Suddenly showed up, and while the site would load naturally anything that depended on JS wouldn't work properly. Turns out some exec directed the support guy to block a bunch of shit, including various CDNs like Google's, which is where SO pulls their jQuery library from. Told them this was 100% unnecessary and made a site critical to developers almost completely unusable. Fortunately the architects managed to get them to reverse it, among other stupid blocks they put in place. They even went so far as to block all banking sites other than the one the company used, "To prevent people with access to financials from doing something they shouldn't with their personal and company accounts." Right, because there's no way they could do that from *anywhere else in the world?*
They were using LinqtoSQL for crud operations until now. 
Also https://stackexchange.github.io/StackExchange.Redis/ https://nickcraver.com/StackExchange.Exceptional/ and https://miniprofiler.com 
They were one of the first on ASP.NET MVC.
In my case it was because I forgot to backup my umatrix config when reinstalling windows ;)
Somewhat strange that they wouldn't use AsNoTracking() for that query. Just looking at it I would guess it is just to retrieve data.
There are a few things, primarily it gives you a pipeline where you can make sure everyone's changes are merged and build, you can run tests, and do code analysis and things like that if you want. If you're only doing that stuff when it's time to deploy, you're delaying the discovery of problems until then. By having all that run automatically every time anyone on your team pushes a commit, you can catch and fix any issues immediately. Ideally, your CI build should be deployable at any point, and you would have a release definition (in Azure DevOps or some other product) that lets you deploy to an environment and promote it through them until production. All of this enables you to release smaller changes safer and quicker which leads to better software delivery outcomes.
Does it ship with the necessary native libs yet?
ouch that was awkward
we're using their redis implementation at work, with ~8000 reads/s without a problem. A really great library when working with redis
Fantastic news! Props to all