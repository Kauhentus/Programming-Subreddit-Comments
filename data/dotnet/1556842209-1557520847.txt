Both times I used signalR was to do notification about some processing updates
I don't. I push to my personal branch, then I tell my lead my code is ready. He checks it, and if he approves, he merges it to Master himself. I have created personal projects which I have merged to master however, but those are just for fun, not work.
&gt;Only the technology that powers the most popular websites I did say they do have proper niches. Most web applications don't serve millions. Most internal web apps I work on only serve a few thousand or less. What's best for Netflix is often not the best approach for the internal bathroom supply tracker system at Joe's Company. Don't buy jumbo jets when Lear jets will do. The blunt truth is most of us work at ordinary projects at ordinary companies. Plus, we'd have to change our organizational structure to make service-oriented division of tech labor viable. It may be a good change, but does require top management buy-in, which is something I have no control over. Other orgs I've worked for are in a similar bind. Conway's Law.
Oh so they are a fad and will fail because _you_ don't use them for your projects. Got it.
When you work with Razor Pages you don't use annotations to specify the action type, instead you write them like this: HttpGet: OnGetAction(), HttpPost: OnPostAction() So in your example you would have to name your action "OnPostUploadAsync()". Keep in mind that when you try to interact with the action the "OnPost" part gets omitted so you would simply make a http post request to "UploadAsync" like you would do in MVC.
&gt; i call the static method that "Gets" a instance of the service class This sounds like an abomination of the Locator pattern and is generally considered an anti-pattern when it's done "properly". If you're using an IoC container, why are you calling `Container.Get` and not just letting the container handle it?
I can't really speak to the thoughts of the developers working on EF Core, but to my limited understanding, it's supposed to be a system that abstracts away the implementation and just lets you focus on things at a conceptual level, in a way that your application needs, rather than a way that your database needs. Usernames, passwords, lengthy text data, dates, timestamps, etc... Depending on the database you choose, which may change at any point, the types that these are actually stored as in the table can be quite different, and have different limitations, but your application will have a really clear idea of what you're aiming for (with annotations/fluent API), and be able to compensate appropriately moving from one paradigm to another. By coming at it from the other side, a concrete implementation first, and then telling EF Core "create whatever POCO technically works for this", it feels like there's a lot more room for error, and many more details that need to be worked out after the conversion is actually done, even in the best of circumstances. For instance, a data type might be limited to 4bytes within MySQL, but is it limited because you placed the limitation there yourself, or because that was simply the max size for that built-in type? Is that type going to exist in other databases if you need to move later, and should the same assumptions be made as to its limits? Is it varchar(255) or varchar(MAX), and is there always a way to actually tell one from another at the application level? Either way, if it's a password, you're going to need to place further validation on the property that's generated, if it's a string, you're likely going to have a max length (remember not all databases have "text" types- it's not in the SQL standard I don't think), etc... The conversion that occurs in the latter case (DB-first) I feel can only ever tell a part of the story, because of the various limitations of the specific implementation (database type) you start with, so it's much more "incomplete". That's just my impression though, and I'm hardly an expert at EF Core, so take it with a grain of salt. =)
Ok I'll try that
The App has launched as MSFT Events this year. Seems to just be going live.
I dont know the answer to your question, but I know how I would answer it for myself. I would use ILSpy or a similar disassembler to look at what underlying code actually does.
We do; they suck. There is a time and place for them, but it's not that common of occurrence. The idea has been around in various incarnations for 25+ years in the listed technologies. It always sounds great on paper, but runs into problems in practice. I learn from history and invite you to do the same.
My hunch is that when execution leaves the \`using\` block, it will dispose the stream. However, the \`await\` should keep it in place until the save finishes. Could you link to documentation on \`imageStore.SaveImage\`? I couldn't find the reference for that method.
Try adding .ConfigureAwait(true) to the end of SaveImage
'imageStore.SaveImage' is an extension method where I handle all the azure blob configuration, but it's not even making it to this method so it's happening in the using block
No your engineering team sucks. Micro services aren’t new aren’t a failure and aren’t all sucky. What you hate is the architecture created and people not understanding micro services. If you jump into having hundreds of services then of course you’ll have issues. But if you for example follow domain driven design you can easily create services along bounded contexts. The term was only coined because a bunch of architects have been working on similar designs for awhile. So it’s obviously not obscure and a failure.
This causes the same error. I'm starting to lean towards the 'CanWrite=false' being the source of the issue, but I could be just chasing a ghost there.
Have you tried simply using image.OpenReadStream() as the parameter for SaveImage? Edit: or if you have access to the SaveImage method, why not simply accept an image as parameter?
How about `.ConfigureAwait(false)`? It lines up with the StackOverflow post you linked, and also [this other post](https://stackoverflow.com/questions/43069026/stream-readtimeout-threw-an-exception-of-type-system-invalidoperationexceptio).
It's a failure as a *mainstream* technology. If it takes brilliant geniuses to "do it right" in regular-sized orgs, then it has a problem, or at least **too many prerequisites,** including possibly a structural re-org.
Will azure accept IFormFile as a type to save and image to a blob? Edit: The azure method UploadFromStreamAsync() won't take the type IFormFile, and it seems like this OpenReadStream() is a very common way of uploading to azure. I think I'm probably just doing something stupid
It gives the same error...
Seeing as how .ConfigureAwait doesn't help, I would suspect an issue with the async wrappings around your extension method. Maybe check your `SaveImage` function to make sure it's correct? Try calling it in console? Try calling outside a using block? Have you gotten the underlying functionality to work in a proof of concept?
I have not gotten the functionality working yet. This is my SaveImage function public async Task&lt;string&gt; SaveImage(Stream imageStream) { var imageId = Guid.NewGuid().ToString(); var container = blobClient.GetContainerReference("furnitureimages"); var blob = container.GetBlockBlobReference(imageId); await blob.UploadFromStreamAsync(imageStream); return imageId; }
I think your idea of the generic host and the web host is practical but you might want to look into something like hangfire which allows you to schedule/fire background tasks from within a web application. That should probably make it easier for your web app to communicate with the long running tasks without a timeout issue. From there, viewing the results of the task is as simple as reading from the database the background task is writing to. You might even decide you don’t need to build out your UI very much because the hangfire interface already suits your needs (shows tasks scheduled to be run in the future/running now etc). You may also want to look at IHostedService. You can do similar things to what hangfire offers with that in .net core
Also, you may want to try an approach like this one which uses WCF as a windows service to process the tasks and can be called via simple Ajax requests https://interworks.com/blog/banderton/2009/10/30/long-running-tasks-aspnet/
Thank you. I’m reading a lot through jobs/hosted services now. Maybe I’ll ping you once I push my code.
I don't see anything wrong :( If I were in your shoes, I would mess around in the C# interactive shell until I was able to successfully upload any file, and then I would write a separate script and validate that it can upload stuff, and then move back to the original problem with what I've learned. Sorry I couldn't be more help
Is it throwing the exception on the call to the async method call, or image.OpenReadStream()?
Errors that show up like that in in the object viewer can be misleading, and don't always match the actual cause of the problem. Can you paste the actual error message and stack trace that is being thrown?
Genius :) And thank you for sharing the solution, it's really appreciated :)
Your welcome
Based on his description, I think Hangfire is a good call. The crux of his test runners is that he needs a way to kick off long running background tasks. Hangfire with a different work type per "widget" or "type of test" would fit his use case well, and it'd give him queuing , retry, and a number of other useful things for his needs... Have they released a Core version yet? I haven't used it in a while and last I checked they were holding off because they didn't want to work with the GenericHost stuff and wanted native core Windows Service support. If not, it probably wouldn't be TOO hard to spin up a IHostedService worker in process with a web site that could spin off background worker processes... but those projects tend to get more complicated than you thought pretty quickly :-)
Hangfire came out with a core version a while back. I've used it and its really easy to configure and use in core
Does anybody know how equality is handled for expressions? Are two identical expression trees equal?
At least when writing infrastructure code you often have to access your dependency provider directly.
I might be reading this wrong, but I'd say no. If you think about how most sites compose their urls to support many countries it would probably look like: www.Weeee.com/en-gb/page.html for England and www.Weeee.com/en-us/page.html for America. What's happening here is the route changes for each locale. The server can then use the same page.html template, and only amend the region specific information.
This. You're looking at the error the debugger is causing trying to access a property when viewing the object in this little interface. It doesn't tell you anything here. What's the actual exception?
Same.
They don't have equality -- each expression tree is a distinct object. They're not even serializable. I guess you could write an expression tree visitor which would recurse over one expression tree and compare it to another.
Declare imageid outside of the using statement, see if that fixes it.
Just use the normal ASP.NET Core 2.2 docker image?
I explained very well what I'm complaining about. What they offer now has no real use cases for anyone. What they will offer is in preview and we have no idea how long this will be for. Aka this is not production-ready technology. Unless you're working at a web agency and write pretty much whatever you want no employer will accept a non-proven technology. Enterprise projects are expected to last decades, and they're not the type you start with a framework that's just a gateway to another preview framework, both of which will require years to prove themselves on the market.
How would a standard image know what your dll entry point was, or what ports it needs or how volumes are set? If you create the project and select "docker support" it will add a dockerfile for you which is mostly set up. Volume stuff isn't really something you can default. FYI, this is the default dockerfile : FROM mcr.microsoft.com/dotnet/core/aspnet:2.1-stretch-slim AS base WORKDIR /app EXPOSE 80 EXPOSE 443 FROM mcr.microsoft.com/dotnet/core/sdk:2.1-stretch AS build WORKDIR /src COPY ["WebApplication1/WebApplication1.csproj", "WebApplication1/"] RUN dotnet restore "WebApplication1/WebApplication1.csproj" COPY . . WORKDIR "/src/WebApplication1" RUN dotnet build "WebApplication1.csproj" -c Release -o /app FROM build AS publish RUN dotnet publish "WebApplication1.csproj" -c Release -o /app FROM base AS final WORKDIR /app COPY --from=publish /app . ENTRYPOINT ["dotnet", "WebApplication1.dll"]
That's what I expected. I just find it a little bit odd, because that means that doing DSL stuff like MVC must be pretty expensive.
The author of the article is a contributor to the CoreRT project right? Great article, hope CoreRT gets more love, it's an amazing project!
`ConfigureAwait` is irrelevant here.
This is the only useful advice in the thread. OP, are you sure that's actually an exception that's being thrown? I'm guessing not.
What's the database you're actually connecting to? Is it a local instance of SQL Server developer edition, or is it a cheap hosted database, for example?
We host an asp.net core application as a virtual application in IIS under the parent webforms app that we are migrating away from and that is allowing us to do both with legacy maintenance happening in the webforms code base while we port pieces over to asp.net core.
In this example I'm connected to an instance of SQL Server 12.0.5207.0 locally, however the app that's encountering this problem is hosted in Azure, also using SQL Server
The gods of programming have snapped their fingers it seems, somehow this just started working. Copypasta from stackoverflow: For some unknown reason, it's just started working correctly again - the only thing I did was switch to another branch to continue work, and open another copy of the project to test things as I thought of them. As soon as I ran the sample code it just blasted through all 10,000 iterations with no issue. This doesn't explain what caused the issue and how to reproduce it but it makes me feel like there's some caching/buffering of requests somewhere that filled up possibly?
If you want to dive into other frontend tech, combinating with ASP .NET Core, look for API design, DI, async, Entity Framework, LINQ, how MVC works .. filters...middleware, binding, requests..responses, authorization.. may also razor...and so on.. for MVC .. Design some example application and just start to code.
Great scenario, they pay, you learn.
XmlWriter and XmlReader use XmlWriterSettings and XmlReaderSettings objects so that they don't need tons of parameters. Check those out.
Never heard of pragemtech. I started on Microsoft Learning. Bob Tabors courses. If you want to learn Microsoft, I wouldn’t stray far from Microsoft. They have a lot of tools...and it’s theirs.
I only use it to host websites too. I find it as cheap, if not cheaper, and a lot more reliable than other hosts I've tried.
Thanks for that advice, I really don't know what to start learning after c# because there's SQL, linq, asp.net core ,asp.net mvc and me being a dumass barely know what to do
What you are after is called [internationalization and localization](https://en.wikipedia.org/wiki/Internationalization_and_localization). &amp;#x200B; Most of the docs I see about how to do this in [ASP.NET](https://ASP.NET) Core use MVC in the examples, but I found a Stackoverflow page that looks relevant: [https://stackoverflow.com/questions/52280911/localization-in-asp-net-core-2-0-razor-web-application-without-mvc](https://stackoverflow.com/questions/52280911/localization-in-asp-net-core-2-0-razor-web-application-without-mvc)
You are reading correctly :) So you'd control this from routing configuration based on some value that determines where the user is visiting from (maybe something in startup/middleware)? I guess you could have separate pages if you wanted to also? &amp;#x200B; Many thanks
Yes exactly, and sure you can have multiple pages too and combine both approaches :)
Doesn't this defeat the purpose of using Docker?
No worries...there is a ton to learn. The stronger you are in C#, the better. The Microsoft classes get into LINQ fairly quickly and they will help you out learning SQL. Core is the future so it’s good to learn, but MVC will also give you good principles. My greatest advice is going to be even if you don’t understand things just accept them, they will click later on with repetition,
Your database probably cached a bad query plan or a table lost its indexing. TOP(1) usually requires some type of OrderBy that may not be indexed at the time of execution.
Thank you soo much for your valuable advice
Try looking here: [https://www.reddit.com/r/learnprogramming/wiki/faq#wiki\_getting\_started](https://www.reddit.com/r/learnprogramming/wiki/faq#wiki_getting_started) &amp;#x200B; Personally I learn the best doing projects instead of going through courses, perhaps you can start a project so you know what need to learn, then go through the specific topics. Also serves as a good addition to your portfolio.
This looks like exactly what I need - thanks!
&gt; Ask yourself, are a few of the parameters related? Good point. I wrote below "if there are multiple methods with the same parameters list" but this is also true if there are multiple methods with _similar_ parameters lists. You could find common subsets that logically go together and make an object out of that. e.g. turn pairs of `startDate, endDate` into `DateRange` objects.
The screen shot above is when I step into the using block, but ultimately the app breaks when it goes to call the async method
It’s a System.NullException being thrown. When inspecting the ‘image’ parameter under headers ‘contentlength’ is null. Could this be causing it? I will paste in the stack trace shortly.
I dipped my toes into SignalR last week. My use case is to upload and process pdf images on the server and feed back progress to the client via SignalR. It took me a while to get my head around the different parts and how they all work but I think I've got it now. The Microsoft Samples did help but I feel there's a gap for a sample for my use case. Maybe that's something you can add? \- File uploaded asynchronously \- Server processes file (image manipulation, extraction etc) \- Server sends a message for each step in the process \- Client displays messages I have starred your repo
The stack trace will show you exactly where the problem is occurring. Without seeing your code it's difficult to say what the problem is, other than something is `null` that's not supposed to be.
Your first pre-req will be a desire to never stop learning. The second will be the basics: html, css, js.
Thank you for the reply! I rarely get any useful responses on here when i have questions so thanks, this will help a lot.
The less you have the less you will struggle to understand why stuff are not working "as usual"
One tip is that you should get used to being confused and working with concepts you either don’t understand or barely get. There’s a lot to know and you will be outside of your comfort zone a lot. Things will begin to click as you progress, just remember to always smile and nod. I would take advantage of Microsoft learning center before they change it. Bob Tabors courses are great
You absolutely need to know javascript. It's fine to want to focus on the back end but you'll not be very employable if all you know is c#. It really is a great time to be in web development though. The number of great tools we have to work with now is awesome. I'd also suggest you get into .net core, not just [asp.net](https://asp.net). It's true the best way to learn is to actually build something, so start with something small and work your way up into more complicated things. To be really proficient at web development you need to know how to write good javascript, c#, AND CSS. You need to really understand OOP principles so you can write a clean, fast, and lean back end. You need to understand asynchronous programming, authentication/authorization, caching, database design/interaction with DB, how to serialize/deserialize JSON (or any other portable data format)...the list really is endless.
Thank you so much! Would you recommend to first "master" the .NET Core, OOP concepts and then go to JS and CSS?
I've only found the basic C# course from Bob Tabor and went through that. It was a good course. Haven't found any relating to ASP.NET in detail tho. Thank you for the good information!
Focus on learning oop concepts first. You must have a solid foundation or you'll end up creating more problems for yourself.
Correct. Calling \`.ConfigureAwait\` is important when writing library code that might be used on both .NET Core and .NET Framework, but OP is using [ASP.NET](https://ASP.NET) Core (this can be inferred from their screenshot), and it makes no difference there: [http://blog.stephencleary.com/2017/03/aspnetcore-synchronization-context.html](http://blog.stephencleary.com/2017/03/aspnetcore-synchronization-context.html)
After that I have done all my online learning through pluralsight.
Semi off topic but, what are you using to load test? I'm about to start load testing my api and am wondering what err body is using.
I like Mosh a lot. He provides thorough information and a lots of real world advice, often suggesting strategies that aren't "by the book" but save a lot of time and headaches later. He's also got a friendly upbeat personality which helps me stay focused.
The stack trace is not very helpful either. NullReferenceException: Object reference not set to an instance of an object. As far as I can tell nothing being sent is null. Postman is passing 'Temporary Headers' where the contentlength is null, but is this something that should NOT be null?
I know right?! It all looks good, but something is askew. I'll let you know if I ever do find it. Thanks for the discussion, it was helpful!
So there are a couple of things you can try here. One is to unwrap the using statement and use a try/catch try { stream = image.OpenReadStream(); var imageId = await imageStore.SaveImage(stream); } catch(Exception e) { // Put a break point in here. You should be able to get a stack track if an exception is thrown } finally { stream?.Close(); stream?.Dispose(); } Or you can try copying the file to a memory stream before trying to upload the stream to azure file storage using (MemoryStream stream = new MemoryStream()) { image.CopyTo(stream); stream.Position = 0; var imageId = await imageStore.SaveImage(stream); }
I would highly recommend just creating an mvc project and looking at the code generated by default. Try to add new functionally and change stuff around in the project. This can give you lots of insights and increase your comfort writing code.
So i Bind all the services at the start of the app, and I call the Container.Get in the constructor of the view model and set it to a private field, and then I reuse the service through the view model without having to re create the object. I've read about the anti-pattern, but if a instance is created once, what is so bad about calling the Container.Get when you need to get the service?
Hi, this is just the error message, not the stack trace. You should rewrite your code to put a `try..catch` block around the code that is failing and then write the error to a log file (if you're injecting a .NET Core `ILogger` into your API controller, you'll notice that you can pass an exception object there when you write a log message), or put a breakpoint in the `catch` block and examine the exception object that you're catching. For example, based on the code you provided in the original post: ​try { using (Stream stream = image.OpenReadStream()) { var imageId = await imageStore.SaveImage(stream); } } catch (Exception e) { // Put a breakpoint here and examine e }
I use this https://github.com/codesenberg/bombardier
Check out JMeter my team is currently impelementing an extensive load test to check the performance of our system.
I get the exact same error/stacktrace in both instances. The only difference I noticed is that the MemoryStream was allowing the CanWrite property to be true
I've hears good things about Plurasight. Would you recommend it? Also any particular courses from there that you like?
I did this and the exception message and stack trace are the exact same as what is being output in Postman for the stacktrace and exception error. It gives me no more or less details.
I really recommend ASP.NET Core in Action, as well as either Programming with Mosh or Tim Corey’s (or both!) content
On the C# side, the exception has a StackTrace property. Can you copy/paste what it says?
I do not see what you mean by stacktrace property. I posted a screenshot above of what I am seeing.
I always call .CreateIfNotExists() on the container before uploading or downloading from storage. Maybe try something like this: public async Task&lt;string&gt; SaveImage(Stream imageStream) { var imageId = Guid.NewGuid().ToString(); var container = blobClient.GetContainerReference("furnitureimages"); container.CreateIfNotExists(); //&lt;--- make sure the folder reference exists var blob = container.GetBlockBlobReference(imageId); await blob.UploadFromStreamAsync(imageStream); return imageId; }
You have highlighted the StackTrace property in your screenshot. The value of that property tells you exactly where the error is being thrown. Click on the magnifying glass icon next to the value and it will display it in a more friendly way.
I would certainly recommend pluralsight. There are too many courses to recommend any, but a good route for you would be to search the tech you’re interested in and then sort by recent and watch the newest ones geared to your skill level. From there you will start learning which instructors fit your learning style better. Most of the instructors are Microsoft mvps and supreme experts in their field. It has helped me tremendously
Thank you very much!
No problem, happy coding
Thank you!
I know where it's being thrown, I just do not understand WHY it's being thrown. There is nothing NULL in the image parameter, and nothing NULL in the stream. So why is it throwing a NULL reference. The stack trace gives me NO other information other than where and what the error is. It does not point to what specifically is causing the error.
Yes, this is for sure good practice, however the issue I'm having is happening before this code is executed.
I would recommend Udemy over Pluralsight. I have both and I see better quality videos cheaper on Udemy. Pluralsight is a hit or miss, I tend to really enjoy the Scott Allen videos there. But with Udemy you can find very detailed tutorials that you can do step by step. I'm a C# developer but need to learn angular. https://www.udemy.com/share/1000awAkcddVhTQH4=/ This video is really good. He starts with the API backend, with core and helps explain entity framework/security with jwt tokens/database. Then jumps to help you test the api before even getting to the Angular part with bootstrap and css. Good starter video to show fullstack development.
If you can post the actual stack trace, and the line of code that is throwing the error, I might be able to help you. If you don't want to do that, that's no problem; my advice to you in that case would be to put a breakpoint on the line of code that the stack trace says is causing the error, call your API controller via Postman again, and examine every variable and object reference used in that line of code to see if any of them are null when they shouldn't be.
Thank you! I'll try both probably but its good to hear some advice.
Alright so it sounds like it is not the file that is being uploaded that is causing the issue and I do not think the async method call is prematurely disposing of the stream. Your Azure Storage may be configured incorrectly? it is hard to say though.
This was aimed at reddit in general. Not this particular sub. Just for clarification. Thr comment on this post have been amazing and am very thankful for all replies. You have all helped me a lot.
It breaks before being able to step into that method. System.NullReferenceException: Object reference not set to an instance of an object. at FHIStorage.API.Controllers.FurnitureController.UploadFile(IFormFile image) in C:\FHIStorageAPI\FHIStorage.API\FHIStorage.API\Controllers\FurnitureController.cs:line 217 at Microsoft.AspNetCore.Mvc.Internal.ActionMethodExecutor.TaskOfIActionResultExecutor.Execute(IActionResultTypeMapper mapper, ObjectMethodExecutor executor, Object controller, Object[] arguments) at System.Threading.Tasks.ValueTask`1.get_Result() at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeActionMethodAsync() at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeNextActionFilterAsync() at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Rethrow(ActionExecutedContext context) at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Internal.ControllerActionInvoker.InvokeInnerFilterAsync() at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeNextResourceFilter() at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.Rethrow(ResourceExecutedContext context) at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.Next(State&amp; next, Scope&amp; scope, Object&amp; state, Boolean&amp; isCompleted) at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeFilterPipelineAsync() at Microsoft.AspNetCore.Mvc.Internal.ResourceInvoker.InvokeAsync() at Microsoft.AspNetCore.Builder.RouterMiddleware.Invoke(HttpContext httpContext) at Microsoft.AspNetCore.Diagnostics.StatusCodePagesMiddleware.Invoke(HttpContext context) at Microsoft.AspNetCore.Diagnostics.DeveloperExceptionPageMiddleware.Invoke(HttpContext context)
Async / Await exists in JS &amp; i'm familiar with the concept of DI roughly because of Magento, so it sounds like this shouldn't be too much of a bridge to cross. Neat.
It doesn't even make it to the method where my azure storage is configured.
Okay. What are the values of `imageStore` and `stream`?
Try it with non async methods and see if there's a difference. Ef core has always had weird issues with async queries in some cases
My implementation of it was incorrect. I moved the SaveImage method out of it's interface and into one I have working properly and it will get me into the method without breaking. However I still get the same exception error on `var container = blobClient.GetContainerReference("furnitureimages");` But this seems like a different can of worms. This I can try to work out without bothering kind folks. Thank you for your help!!
Just jump in, build a simple site, then do another. Don't worry as much about RESTful services and HTTP method concepts just yet. With .net it can be easier to build things before understand them. Then you can go back and lean how it works. There are some .net developers that never even make it to the understanding part, they can code but don't really know much about how things work. &amp;#x200B; Also with .net there are usually 2 or 3 ways to do the same thing.
Okay, great. Good luck!
How are you throwing your exceptions?
The fuck? No if it requires a competent (not brilliant just understands their job) architect that doesn’t mean it’s a failure. Loads of thinks take architects do “do it right” have you never worked on something harder than a rails app or something?
With programming in general there are usually 2 or 3 ways to do something. Also, it's pretty bad advice to a newcomer to tell them to just do something and don't worry about understanding why it works. Understanding why and how is critically important or else they'll never gain independence as a developer. They'll get stuck copy/pasting from StackOverflow and never understand their codebase.
Make sure to add the nuget packages for logging to file: Serilog.Extensions.Logging.File Then in `Startup.cs` and `Configure()`, add `ILoggerFactory loggerFactory` to the method parameters, then `loggerFactory.AddFile("Logs/{Date}.txt");` When you want to log something, just inject the logger into the constructor as per usual: ILogger&lt;ClassName&gt; logger _logger = logger; private readonly ILogger&lt;ClassName&gt; _logger; and then log exceptions like this ` _logger.LogError(ex.Message);` or `_logger.LogError(ex);`
&gt; How would a standard image know what your dll entry point was, or what ports it needs or how volumes are set? By telling Docker so. You don't need a custom Docker image.
I graduated CS from a state Uni, and used c# in one AI class, most of the time I used Java in school. &amp;#x200B; I got an internship that paid reasonably well before graduation. I did well and ended up being the first developer on staff. There was a need for a internal web application. It seemed like MVC 5 was a good choice so I went for it. I had little knowledge of C#, 0 knowledge of dynamic websites, little knowledge in databases and servers. Now, when I have to go back to that application I can see how much I grew just in a year. I went from a total rookie, to improving architecture, finally understanding why I should use inheritance, using dependency injection, using async/await, understanding how EF framework works, writing unit tests, LINQ and more. &amp;#x200B; So, just create a .Net Core or .Net MVC 5 project and check out the scaffolded code. Then, try to add your own stuff. Sometimes if you are getting stuck, read a book. I have been working with the framework for over 2 years now, but sometimes still learn something I didn't know that may seem trivial or basic. Then, at some point when you read online tutorials, watch videos or books everything that was cloudy will start clicking together.
If you are doing IaaS, you can drive the price down by using reserved instances.
Thats inspiring to hear. Thank you! Will try and learn by doing.
web services are just HTTP responsive server endpoints. Think of it as a web page with no UI. 1. Develop a code library that calls the two web services and concatenates, does whatever marrying of data that is needed, and presents it in a logical way via it's methods. This library should present REST service A and B as if they were one service/interface. You can re-use a lot of your existing CLI code in this library. 2. Modify your CLI so it is just a UI to calling that library 3. Wrap that library inside your own webservice. You now have 2 interfaces to your data combiner(or whatever you'd like to call it) and you can re-use the core functionality in any other interface/software you can think of. &amp;#x200B; Just my 2 cents.
 I'm doing the same thing using @Html.Action. Pitfalls might be the multiple DB hits might slow things down, however now you can secure the elements and enclose this in an if Statement if someone shouldn't be able to see it. @Html.Action("Index", "Things", new { AccountNumber = Model.AccountNumber, isPartialView = 1 })
Why would you want to build a C#/Access application rather than C#/SQL Server Dev application?
If its an Azure Instance, the SQL instance has limits. I know that Brent Ozar ran into an issue where the SQL Log file was limited to 1-10mb/s throughput, which will cause issues for any inserts/deletes. Also the size of the Azure SQL instance as EF has built in retry policies to keep you from catching the Azure SQL Busy exception. You could also have a Garbage Collection issue on the app itself. If its low on memory, the pause could be attempting to clean up memory, then allocate memory if you hold onto a context for a long time. There is also the ".AsNoTracking()" option which you can use. If you don't want to edit the data, this also should free up more memory.
I’d guess this part is clear to him. He wants to have an exception logger middleware that only logs real exceptions and not those trusted=true exception.
I have never seen these exceptions so it’s some addition you made. Hence it would be helpful if you were showing some code.
That's exactly what this does. If he's trying to log JS errors or something else, he needs to be a little more clear on what logging method already doing and what types of exceptions are being thrown. If he's using this method and still seeing trusted=true, then it's probably an exception with one of his scripts.
Because not every application which needs to store data should also need a Server instance running somewhere. Single user applications (where the application doesn't need network interactions between multiple users) use this, so you don't have to install a DB-Server on your local PC. However, I think many apps use their custom schema or XML/NoSQL instead of MS Access.
There are several SQL solutions that don't require a server somewhere else.
Kill it with fire!!
Yes, that's my point. OP was upset they had to create a dockerfile and for some reason assumed it was an image thing.
&gt;n talk to the DO It's been two months but how would you rate the book?
I am not the only one with the advice of not worrying about some of the details on how things work. Much of the time when you build it you figure out how it works along the way. I have mentored plenty of jr developers into amazing programmers, but I have also worked with a ton of Copy/Pasters that will never learn or change.
Just POST (Ajax or not) to the other controllers. Use your home controller for your index GET request.
Venkat's videos (the guy from pragim tech) are all over YouTube, if you search about a c# topic he has probably covered it. I owe him a lot from what he taught me so far.
* 1. Separate the data access from the business logic (if you didn't already do this, please tell me the name of your company so I can never hire you) * 2. Alter the database to use proper FKs * 3. Change the internals of the data access layer without modifying its api or facade * 4. Done
Honestly I think this defeats the purpose of using docker, however one solution might be to create just a runtime custom image that links to your DLL name and then simply use bind volume mapping. However with this solution you will build your image just once. Docker file might be as simple as this FROM mcr.microsoft.com/dotnet/core/aspnet:2.2 WORKDIR /app EXPOSE 80 EXPOSE 443 ENTRYPOINT ["dotnet", "WebApplication1.dll"] Build image docker build -t &lt;yourrepository&gt;/webapplication1-wrapper:latest . Publish your application to where on system you want dotnet publish "WebApplication1.csproj" -c Release -o /prod/WebApplication1 Run image and link it to your app docker run -v /prod/WebApplication1:/app -p 80:80 -p 443:443 &lt;yourrepository&gt;/webapplication1wrapper:latest This is just from top of my head as I am not near any machine with docker so it might need a slight modifications, however the idea should be clear enough.
Were a reseller for a erp system targeted at small businesses. Were prepetually understaffed. The only focus is get it out the door and get in billable hours. Nothing is done the right way. My primary job is reports, although I am looking for jobs as a junior dev since I hate reports. While I'm stuck at this job for the time being here's the situation....the erp system we implement has no api. I dont have the time nor the experience to write one myself. I also can't alter the erp database tables without possibly blowing up a huge number of things. I was just wondering if theres any way to specify relationships without FKs and without altering the existing tables.
First question, why would foreign keys blow up the app? Second question, why not use stored procedures? You can still make an easily maintainable awesome application with price. It’s a little more work, but doesn’t have to be a mess. Using EF Core on an existing database may not be the best plan. We use stores procedures at work successfully. We have a single class with a property for each proc. E.G public static readonly string procName =“dbo.procName”. Then we write code that returns poco classes from the datareader async. We write test methods to validate the data access code works before coding the rest of the app. It takes slightly longer but we get better performance and sometimes we can make quick fixes just by updating a proc. Not really an answer to your question though...
1) I know it wouldn't blow my app up. Im more afraid that altering tables created by the ERP could screw the the ERP system up. Trying to avoid that if at all possible. 2) Stored procedures would definitely work, I may have just been over engineering a solution. I don't really have anyone around me I can ask about design choices so I'm kind of on my own. Could you possibly show me a bit more of an in depth example of what you were talking about?
Use Database First . Or disable code migrations and do database migrations yourself or sql scripts. But I would strongly advise you to simply do it the right way, and create a proper database and write out a big migration from the old to the new database. Your current solution is going to crash and burn sooner or later, OR you're going to burn through massive amounts of billable hours keeping this thing afloat.
Ive used linq to sql for like the last 9 years and you actually can create your own relationships in their designer for cases like this. https://docs.microsoft.com/en-us/visualstudio/data-tools/how-to-create-an-association-relationship-between-linq-to-sql-classes-o-r-designer?view=vs-2019
Your post has been removed. Self promotion posts are not allowed.
AJAX get will work but you have to be sure you don't exceed the maximum amount of socket connections in the browser. It will probably be fine as long as the calls are pretty quick to complete. I was working on a project where this approach was being used to make multiple calls and it consumed all of the socket connections which would prevent the user from being able to navigate to any other links until another socket connection was available. We ended up moving it into a single action result that just relied on various services to populate a single view model and that worked out better for our use case.
[https://1drv.ms/f/s!Ahh6OzIki1IngegU68OMN88fqT5P1w](https://1drv.ms/f/s!Ahh6OzIki1IngegU68OMN88fqT5P1w) Here is a sample data access layer and how to use it.
why not just do your joins using method syntax, if you know the keys then your joins will be efficient. ideally you want FKs defined with navigational properties. If you are using sql server, check out EFcore power tools, you can generate the dbcontext, relationships and validation in one hit. i do a mix of fluent and data annotations. I'm not a fan of convention approach e.g. Id is assumed to be the PK and ForeignTablePk is presumed to be the nevigation property on the principal. if anyone can suggest something better than EF power tools id like that. one problem with ef core power tools is that it doesnt always bring it all the relationships. So i keep a separate project with EFCore power tools and just copy across what i need.
It's a stupid question. A website that allows offline access, da fuck?
Move access DB to SQL server for reliability and scalability. If it's only a two page app with simple functionality, re-write it using something vaguely modern, doesn't really matter what, but write some tests and write it so that it's scalable (this is a big topic, too detailed to answer properly here). Depending on data size, you could use browser HTML5 local storage for offline access. To be honest it doesn't sound like an interview question... it sounds like they are looking for an answer to one of their own problems :)
Ha! Companies pretending to have an original interview and instead hiding their real infrastructure problems behind a quiz. Very very easy way to gather free consultancy from candidates xD Btw, whatever web app + entity Framework database first approach should solve it. Offline access? What da...
Your post has been removed. Self promotion posts are not allowed.
If you can swing it, do a $30 subscription to pluralsight and take all of Scott Allen’s courses. They’re the best intro to asp.net mvc, IMO.
Its a question meant to show the depth of your experience, since there are many ways to answer the question. I would migrate the data to a traditional database for it to be maintained by staff. From there, it depends on how many products they have. If they have less than 4mb of product data, then you could store the product data in local storage for a web site and make a PWA that supports offline usage. If it is more than 4mb of product data, then you could suggest a mobile application instead. You could also make a traditional web application with client side caching that would support temporary offline usage, but it would have to detect when it was offline or online and the browser may balk at starting the web application when the user is offline. With the product data prepared periodically and cached in the background (which is appropriate because they expect to only get fresh data on login, according to your supplied description) and a client side framework performing the searching, paging, and rendering...they should easily be able to support well over 500 concurrent users on a single, relatively small, server...though quite a bit of that depends on the other functions of the web application. &amp;#x200B; That answer doesn't work for everyone. I can use it with confidence because I have converted multiple Access databases in the past and I could talk loquatiously for half an hour about the kinds of challenges that arise from that and how to overcome them. I am a team lead, and I often ask similar (though usually not so detailed) questions during interviews. I don't think of interviews as a challenge to the interviewee, more like a controlled forum for the interviewee to show off their knowledge and experience and where the questions are meant primarily to prompt them into an area (I hope) they are passionate or knowledgable about.
They probably were looking for an answer about progressive web applications, which typically can allow offline access if they are designed for it.
Thank you for the response. I am only a mid-level developer, and I did feel this question was beyond my experience and expertise. That apart, I did try answering it, and said I would use .NET MVC with Entity Framework, and a SQL server database. The interviewer was not satisfied, so she asked me if my approach would be the same if she swapped the database with Oracle. I replied that it is still possible by using a different data provider, specific to Oracle. Her next question was 'What if it was DynamoDB, which is a NoSQL database? Does Entity framework support that?' I was stumped, because I have never worked with NOSQL databases before. About the offline access thing, I frankly admitted I have no idea about it. To that, she asked me if it would help by moving having the database in the cloud. I responded by saying that it still may not help because an internet connection is required to access data on the cloud. She then went on a different trajectory, asking me if I would have the entire application on the cloud, or just the database on the cloud. Again, this stumped me. Do you have any thoughts on these? But yes, I do realise that it is not possible to come up with an answer like yours, unless one has actually worked on something similar.
Your not going to get hired by saying "looks rubbish I'm out" or "too many red flags". Neither are you going to get hired by just saying move to SQL server and forget that you don't just magically get reliability and scalability for free. &amp;#x200B; The question misses out a lot of the system detail, but this is a good starting point for asking probing questions. How many products are on offer? How often are the product listings updated, if ever? How often are products added/removed? Is there a linked stock inventory or product review system? Based on the system detail outlined, you could assume there are few products listed, which have not changed, don't need updated, and are not tied to any stock inventory or product review system. If that's the case there would be nothing stopping you from extracting the data from Access and shipping that data as on offline file to your web app or mobile app. This will easily provide 500 users with read access and will scale well beyond that. If you need simultaneous reads/writes, then you need to ask how often are your writes compared to your reads and how important is data consistency. Are the business happy with a time delay between updating the product system and the web application displaying that updated information? A further design would look towards a CQRS approach whereby you separate your reads &amp; writes, allowing you to maximise read performance without negatively affecting write performance and vice versa. You will need to consider making the data consistent at some point, this can be achieved with event publishing. There are many technologies which perform this function (Akka.NET, Kafka, SignalR, MQ message bus, Web sockets, etc). There are many designs which could achive offline login. I would probe and ask what sort of security is required. It's not clear from the outline where this web application is running. If it was only running in a corporate network the answer might be different to one running exposed to the public internet. You would need to consider how to properly secure user credentials and ship that offline to your offline web/mobile app. That is not a trivial operation and requires careful consideration.
It sounds like they're hoping the interviewee will ask a lot of questions
&gt; To be honest it doesn't sound like an interview question... it sounds like they are looking for an answer to one of their own problems :) “The original developer of the application is no longer available.” Dead giveaway. Lol
SQL Server, Oracle, or a No-Sql solution would all be viable solutions, just each with its own advantages and disadvantages. Entity framework's code first obviously doesn't support dynamodb or no sql, but that's not a big deal. You just wouldn't use entity framework if you went the nosql route then. For sure I would move both the web application and the databases to the cloud environment, which would make scaling much easier. You would want to learn about "scaling up" vs "scaling out". For offline access, I would have said the same answer as the other poster, using the browser's Local Storage to store all the products and if connection to the internet is lost, fall back to that. But quite a discussion would be had, because if the db has 500 products, that's probably no issue, but if they had 100,000 products, there would be other considerations with that.
Haha yes for sure!! Not actually relevant to the question asked at all. Why volunteer that tidbit of information? It doesn't make sense... unless it's actually a problem that's happening to them right now.
Isn't Cosmos DB a NoSql db and you can use it with EF Core? I mean it's not the best use of a NoSql db but I guess you can.
Weird but this is what I would throw out. You can migrate the access tables and data to another more robust one. Sql Server would be the easiest one. I would have asked if it requires offline access, I would ask who is the target audience. Because a website that goes offline and they require the ability to use it means that stale data is ok. If it is then caching the data client side could potentially work short term, until they need to process something. Using Windows Auth might allow offline access. Maybe a desktop app so that you can cache locally, save data to a local database or queue and process when they go back online. This one is tricky. Scaling question is more of an architecture one. Do you use MicroServices and queues. Using Domain Driven Design might help with this as well. What hardware are you going to use, I mean self hosting or cloud hosting. Depends on what is available to the company or which ones they are ok with purchasing or using. It's a broad question that is supposed to make you ask more questions while coming up with ideas.
The only [database provider](https://docs.microsoft.com/en-us/ef/core/providers/) I see that is NoSQL for EF Core is Cosmos.
Well entity framework is an ORM, or "Object *Relational* Mapper". NoSQL is not relational, so conceptually to me, it doesn't make sense that entity framework is designed for NoSQL. I could be wrong and maybe there is a special case for Cosmos DB, but Cosmos is also a catch-all for a bunch of nosql services that are offered by azure. There is a difference between an ORM and just a straight up driver. Like there are libraries and drivers for C# to work with mongodb and all sorts of other NoSQL databases to make it easy to use, but they are not ORMs so to speak (because they don't need to be).
I agree with you on this. It would treat a NoSql as a relational db. But it can be used, which depending on requirements it might or might not be a good idea. I think it's not using the power of NoSql, I'm kinda trying to figure out what is the net gain of it, but it can be used.
Yeah I was just pointing out that EF can use a NoSql db. Not that is the best approach to using one.
Scaling and DDD are two different things entirely. Drawing your aggregate boundaries (which are concurrency and consistency boundaries) properly helps avoid deadlock and performance issues. But in general, DDD is for mature, complex problem domains, not an architectural solution to a scaling problem. This is not a complex problem domain - it's t-shirt complexity size is XS. So I would throw out DDD as an option. &amp;#x200B; Also, if you suggest a microservices architecture for a 2 page app, I might cut the interview short and wish you good luck. A person that suggests that is very into RDD (resume driven development) and is going to promise delivery of the app in a week and take 3 months. :) &amp;#x200B; Since it's 2 pages, the login could be scaled to it's own auth server if need be to reduce load on the data server. The product data sounds like it's pretty static or in a read-model, so all that would be needed is no-lock read access in SQL which should easily be able to scale to 500 concurrent users without much of a hardware commitment. Use of a stored procedure would be preferable because they are compiled (depending on how you write them, don't use dynamic SQL) vs how LINQ would interact with the database. &amp;#x200B; MVC or Razor would be very adequate for the UI for such a simple app. Angular or React is overkill, imo. I'm imaging that users would have the ability to sort, filter and page the products so those actions should go back to the server anyway, depending on the number of products. If there are some rich user experience features that are desired, by all means, Angular/React is in play. &amp;#x200B; For offline viewing, I'd maybe suggest a button on the list screen to download the product data as a simple JSON object (depending on if there are embedded pictures or not, even then, those could be downloaded a stored locally as individual files). The persistence should derive from an interface - one implementation for going to SQL and one for going to the local JSON store. &amp;#x200B; Hopefully some of that helps with your knowledge.
I wouldn't try to answer the question directly, I would ask and answer questions like I was trying to build the system they are describing. I would ask why they need to have offline access to a system with products. Find out if it is an ordering system, or a service system (warranty and repair, RMAs, that kind of thing) or if its just a contrived example for the interview. With 500 concurrent users and a login it would make me suspect that they are building a B2B portal or a LOB applications (that is, internal use for managing their business workflows). Systems like those usually have pretty complicated business rules and need to be accessed around the clock from many locations. I would tend towards cloud hosting in those cases, because its usually pretty easy to run your web app behind a load balancer in multiple data centers without a lot of sysops interaction, in those cases (like with an Azure App Service, or some equivilent in another cloud host). Those kind of systems can be hard to run offline, since then you need to distribute the business logic code and the records that back them, but ensure that users can't see the records of other users (even by inspecting the local file/db cache). You really have to deeply understand what they are trying to accomplish before you can really recommend an approach with that kind of problem. The distributor I work at has a product catalog of 3 million products, so even talking about client side caching them in a web application is somewhat laughable, but I think most manufacturers and online retailers have a much smaller number of accessible parts.
Or they are asking about a pretty normal scenario in most work scenarios and how the interviewee would handle it.
Yeah, I think this is actually a good interview question.
Because most legacy applications no longer have the developer/teams available. All they have is documentation and business users. It's implying you have to familiarize yourself with the code base and you won't have help in this scenario. This is a good question and does not imply they are looking for an answer to their own scenario, because by the sounds of it the application is piddly and any developer worth their salt can pick tools to do it.
Just have a look at this keynote https://www.infoq.com/presentations/8-lines-code-refactoring It has some good insights .
Will definitely check this out thanks!
What was your answer?
Moving from Access to MS SQL is the first step. Next step would be determining the infrastructure requirements: Either they support MS SQL on-premise and all of the hardware / networking that is involved with on-premise, or you pick a cloud provider (Azure, AWS, GCP) and host the SQL from there. For a 2 page app it seems like overkill to convert to Oracle, or No-SQL, or \[Insert buzzword hyped new DB Technology here\]. You would also need to define exactly what "Offline access" means. Does the company admins want offline access, or is the offline for the customers? Perhaps a daily export to Excel is enough to satisfy the requirement. Sometimes these interview questions are just about seeing how you think, and sometimes they are picking your brain for free answers to their problems, who knows. Good luck with the job search!
Good information, thank you.
Honestly if was interviewer would be far more interested in questions (how who kind/much data, reason for off line, does need to be available outside network) you asked rather than "solution" you proposed. Your respinse sounded more like code monkey/programmers than a developer if you know what i mean. Anyone can say something like "Database X/mobile or web front end" (especially if that's their "area of expertise"..though remind you of the old hammer and everything looking like a nail saying). Simple fact is not enough detail in that "spec", a developer should be asking more questions if the description of the "problem" if not good enough. The only "tricky" part of the spec is the offline and for that you need more info (MS access bit would say is red herring to freak out younger devs who might have no real experience of it, really has little bearing on any proposed solution)
I feel like this is one of those job postings that goes like "Urgent opening for .net developer".
At first, I thought this was a reasonable interview question and at least they aren't asking you how to balance a binary tree or something. But, after hearing the follow up questions, it seems like their goal is to stump the interviewee and ask questions that in my opinion, don't make sense for such a small project. How would "moving to the cloud" help or hinder? You're still dealing with the same crappy code just running it somewhere else. I would agree with another commenter, you dodged a bullet.
I'd ask for clarification on "offline access". Does that mean access when there is no network connectivity for the client, or no network to the outside? Does this data need to be updated frequently, or does it need to be held simply for archival purposes? Offline access will cause issues if they're also expecting users to have updated product detail.
Just to make you feel better, I have asked a question very similar to this before in interviews (not quite the same but big similarities). I exclusively asked it to people coming to interview for senior positions. In my situation, I didn't actually care what technology people chose because the technology changes. I wanted to see how people approached the problem. The key things I was looking for: - What questions do you ask? - How do you maintain uptime during the transition? - How do you make sure that what you are doing is correct? - How do you make sure this problem doesn't happen in the future? Because I'm a nerd for automated testing, my ideal candidate uses that as the answer to all questions. They talk about using unit tests to understand and document the current behaviour. They talk about integration tests, automated smoke tests and deployment tests to maintain uptime They talk about integration and approval tests to make sure that what they have built continues to provide the functions of the original As far as technology goes, someone can blag me so long as they show they're considering technology limitations. Like I said... The details don't matter as much as the approach.
Hitting DTU limits and actually getting throttled by the database? https://docs.microsoft.com/en-us/azure/sql-database/sql-database-dtu-resource-limits-single-databases vCore might be a better model as (I think) that just constrains your resources rather than throttling https://docs.microsoft.com/en-us/azure/sql-database/sql-database-vcore-resource-limits-single-databases
we have probably close to a thousand microservices where i work. The company is heavily involved in the spring framework so they used Zuul gateway to do basically this same thing. The problem I have with these service registrations, api gateways is that over time you still run into the same problems without having one, but worse is you now add the complexity of multiple network hops/calls all the while the company and management, and people who have been there for a while think that they do have a good api gateway system. oh, just go hit the url at this one location and it will determine where to reverse proxy to. Except now I moved a few services to kubernetes in the cloud. I don't want my on prem api gateway to handle the reverse proxying/knowing where to send api calls to the cloud, this is just unnecessary distance a call needs to make. I'll just add another api gateway in my kubernetes cloud environment, and use big ip to now proxy requests to my kube cluster, but i haven't converted everything, so maybe some things will have to go back to on prem or visa versa. Oh wait, kubernetes has the concept of services already, do i really need another instance of this api gateway? Well it has all our authz, so lets just use the api gateway instead, and now suddenly you are having hundreds of web services constantly registering itself because kube horizontal scaling can happen a lot in a short amount of time, especially if you have unhealthy pods. Can this product handle that? Maybe this one other team is getting huge, and it needs its own instance of this api gateway to manage all its routes, (I know this is a problem we have at our current place, not sure if its really necessary or not, maybe even if you think its a bad idea, they are the main revenue generator in the company so they get what they want). so now the original api gateway still needs to be the initial source, but it needs to reverse proxy to this large teams api gateway. It's maybe a bit more manageable, but I've heard stories of an api gateway calling an api gateway calling the a service, which then had several dependencies to other services, so they all still needed to go through the api gateay which ended up being 10+ hops total.
Regarding most of your questions, Microsoft has an article about similar architecture with having multiple API Gateways that exposes different parts of the system, furthermore, they are exposed through ingress controller (https://docs.microsoft.com/en-us/dotnet/standard/microservices-architecture/multi-container-microservice-net-applications/implement-api-gateways-with-ocelot).
Jimmy Bogard has presented several talks on this subject. [https://www.youtube.com/watch?v=gfh-VCTwMw8](https://www.youtube.com/watch?v=gfh-VCTwMw8) A definite watch before you go off and architect your next project if you must jump on the microservice bandwagon.
I'm pretty excited about this, I have ideas, man.
Well it does make sense either way. If the original developer was available, a good starting point would be to start there and gain insight into nuances, logs, documentation, or notes that maybe he/she had maintained throughout the project lifecycle. This may separate the experienced developers who see the big picture from a less experienced dev coming in saying how he is going to re-write this thing from scratch using all the cutting edge technologies. Having said that, it's probably just there existing issue :)
You think so? I've worked for a few years without really studying a JS framework and pretty much only done back-end stuff in that time. I know how to do basic things in JQuery but that's it. However I am learning it now. It's definitely extremely useful to know.
It's always confusing. Just start out by learning a tutorial that will let you build a ASP.NET MVC project and don't worry about the details. Don't worry about Core or front-end stuff or becoming a master of it yet. Just pick a tutorial and work all the way through, trying not to get overwhelmed. Later you'll learn the difference between all the different nuances, technologies, and software versions. But you'll get there. Just start anywhere.
Trying to learn C# without .NET Core (or .NET Framework) is akin to trying to learn Javascript without the DOM (or objects that come from any other host, such as Node.js or WSH). You can't really hope to learn C# on its own. &amp;#x200B; Having said that, don't worry about learning C#. Since the surface area of the language is relatively small (only 100 keywords), and is very clearly documented at the Microsoft docs site ([https://docs.microsoft.com/en-us/dotnet/csharp/index](https://docs.microsoft.com/en-us/dotnet/csharp/index)) you should be able to pick it up as you go along.
\- Switch to sql server and EF core \- Dockerize the app and set up load balancing \- Re-architect the database wherever necessary to fix performance issues \-- Sql server should significantly speed up performance over an access db \-- Sql server is more secure than access db \- I'd check the security of the logins and hopefully find that all of the password info is hashed with a good algorithm. \- For offline access it's a little bit more complicated.... \-- I'd start by asking what specific functions need to be available offline and then make a determination from there \-- For obvious reasons you can't really do payments / ordering offline or anything like that. \-- If the app is offline you can still use a PWA (progressive web app) to make it function offline on desktop and mobile. &amp;#x200B; &amp;#x200B; Honestly I'd propose a rewrite with more fleshed out requirements in a better web framework and database that can handle more requests. As they grow they'll really want that extra security. You'd have to write a database conversion script but it would probably not be horrifically difficult if most of the requirements are the same / can be derived? &amp;#x200B; If you aren't doing any ordering at all then listing products should be a legitimately simple task using Angular or something else with a template for a single product and then populate that template using metadata about the product. Assuming there isn't a billion products your company sells you could probably re-create all the data by hand.... &amp;#x200B; TLDR: re-write and migrate the old data to the new platform using a PWA or something similar. (Docker is your friend here too)
Did you check out visual studio templates? I think you get to a good place by googling.
This is awesome thanks for sharing. I wish the guy that designed our systems at my job had watched this instead of making a giant microservice mess and then getting fired.
I think the way to go is to create an API backend and a js front-end that displays data from the backend
I know them, I’m asking for opinions on which one is better, I used both. Maybe someone also had some good or bad experiences and I can decide which way to go. Currently I’m on Razor side, but maybe there is a point to switch to JS side.
The new microsoft way, they have been doing that with windows itself for a while now. It sucks :(
I love how they've actually taken the time to develop an error which says "We updated our program without your saying and inadvertently f\*\*\*ed up your file". Brilliant. :D
The thing is, it happened with Visual Studio on the project which I haven't backed up, yet. So this could really hurt if something went wrong. Bonus points for doing it while I was coding.
Thank you, this gives me a lot of insight into the minds of interviewers. I still think maybe they were expecting too much from me, since I applied for a mid-level position (I don't have enough skills or experience for a senior role). And you too mention that you exclusively ask these types of questions to senior-level candidates. I breezed through the phone screen, but I struggled with the onsite interview. Apart from the main question (which you provided your views on), the interviewer also asked me a bunch of questions about stuff I didn't know well at all, like these: 1) Explain GAC (Global Assembly Cache) 2) Describe .NET garbage collection process (I answered this) and the generations (didn't know this part). 3) What happens if you wrongly call the 'Dispose' method? (I attempted to answer this, but she wasn't satisfied). 4) What are the pros and cons of using GUID instead of identity as the primary key in a SQL server table? (I had no idea) &amp;#x200B; So from whatever I have described, do you think their expectations from a mid-level candidate was perhaps a bit too high? Or is a mid-level developer supposed to know this stuff?
The "offline access" requirement is a "Version 1.1 feature". Well do that once we've got the first bit migrated. Users just have to be online for version 1.0. The implementation is trivial without it. Sync is HARD, and the percentage of time people are offline is typically very low. HOWEVER, as this is an interview question, you should ask about the requirement. WHY, WHEN and WHERE does it need to be used offline? There may be a very good reason (e.g. medical records for flying doctors), or a bad reason (e.g. "We thought it might be useful for er.. dunno"), so be cautious here.
Why no good in EF? I'm using EF Core and am doing similar things. Any particular reason I shouldn't?
Great answer.
Just don't use Identity.
There’s no indication that the file is fucked up.
Security for what exactly? If you're just talking about the login security for the user, then you can look into oauth written out yourself, or store your own users (make sure you read up on pbkdf2). If you're talking about security of the system, make sure you use stored procedures instead of dynamic SQL, and sanitize your inputs, there are some good regex options out there.
The lines defining low, mid and senior developer are more about the economic needs of the job poster. Often a senior level job is posted as mid level to save $20,000 per year. That is what was happening with that interview.
Someone know, how integrate ocelot with swagger/openapi3.0?
As has been said elsewhere, the lines are blurry sometimes between the roles. For us, a senior role was someone who could at any moment pick up and lead the project if the lead was not available. That said, I also sometimes play interviews by ear. If a candidate struggles with the mid level questions for a mid level role, I might drop down to the graduate questions. If you were interviewing for the mid level role and I asked this question, it would be because you'd aced the rest of the interview and I wanted to see how far you were for a senior role (I don't know if that's what's going on here, it's just the levels that I was interviewing at. Obviously the janitor at Google can write assembly. 🙂) As far as your other questions go... 1) The GAC is something that I used to expect mid levels to know, but I don't expect any more because in my experience it's fallen way out of favour... And with good reason. I found it to be a pain the bumhole whenever I tried to use it. 2) The GC process is something I expect of mid levels (who have Dotnet experience or java experience). Generations is something I would definitely expect a senior to know and would not be surprised if the mid levels knew. 3) Kind of a weird question... Do they mean "What if you forgot to call it?", "What if you call it on a null object?", "What if you don't follow the Dispose/Finalizer pattern?". Not sure what they mean. I would expect a mid level dot net developer to be comfortable with Dispose and it's quirks but maybe not with the Dispose/Finalizer pattern since if you haven't worked at a place where they used it, it's easy to not know about it. 4) For the pros and cons, I guess I shrug a little at that. I don't know where it sits. You'd have to think about the role. If you still don't know the answers to any of these let me know and I'll hook you up, but I'd like to give a little more interview thoughts to go along with this... I'm sure you know this already, but depending on where you are geographically, the expectations would be different. I gave you an insight into someone who interviews in the Midlands in the UK. In Silicon Valley, there's more people available looking for tech jobs and more jobs available. This has an impact on the market. I tried to slip a phrase in there occasionally about "when interviewing a Dotnet developer". When I interviewed for a small company, we needed people who could get up to speed quickly, so we asked the questions that we needed people to know straight away. When I interviewed for a global company, we once hired a senior with no Dotnet experience so I wouldn't have expected him to answer any of those questions. The larger company had less turnover and a higher level of engineers because the main thing we looked for was passion. If someone only had Ruby experience, I'd go away and try to translate some of our questions into Ruby Speak and I'd try to learn the basics of Ruby and give the engineer an open question to let them tell me about Ruby to see if they were passionate about it and had an in depth knowledge about something they'd been using for years. The final point I'd like to make is my biggest one. Never forget that you're interviewing the company. They think they're interviewing you and to begin with in your career, they are. But when you get better at interviews, the interviews stop worrying you so much. It's more about you interviewing the company to see if you want to work there. You're not allowed to quiz them like they quiz you though, so you have to be more subtle. Think about how they interviewed you. Were you interviewed by two tech leads who seemed really interested in your answers or a HR person who was checking for keywords off a list? Personally I want to work for the one where it's clear they understand the importance of the role and I get an insight into the passion of the people I'm working with. Some people might be put off because it might mean that you'll be expected to do interviews later in your career there too. What questions did they ask? This gives you a great insight into how their lives work. I asked the legacy question partly because it was something we occasionally had to deal with (particularly around acquisitions) but also because it was vaguely open so it didn't bother me too much. The GAC question bothered me a little more because I don't see it being used much anymore. That would have been a red flag to me for when it got to the questions at the end for me I would ask something similar to: "You asked that question about working with a large legacy code base... Is that the kind of thing you do a lot? Is it the kind of thing I'd be doing a lot?" If they answer yes, I might follow up with something like "any plans to migrate it to some newer technology?". Them answering no here isn't a deal breaker, but the way they answer is important. Personally I love working on legacy code bases so long as I have some leeway to improve them. I don't like it when I'm applying sticky plasters to a turd for a year. I don't know if all the questions they asked were provided, but all except the legacy one were deeply technical. I think this again gives you an insight into the company. Maybe it means that they write a compiler. 😁. More likely they either don't have a lot of experience interviewing (because these questions are crap in my opinion for hiring someone today) or they have to deal with these problems on a daily basis. Remember that you have value to the company, not just the other way around. Sorry if this was unhelpful rambling crap, but I got the impression you hadn't done a lot of interviews and I wanted to give a little more insight into my brain on either side of the table. 🙂
https://docs.microsoft.com/en-us/aspnet/core/security/authentication/identity-custom-storage-providers Would be quite a bit of work to write a fully featured storage provider from scratch, though. Dunno if anyone has already done that for ADO.NET.
Wow, this was like an amazing post regarding interviews! Thanks a ton! This job interview was in Sydney, Australia. The software engineering job market in Australia, from what I know, is quite nascent and immature. And it is pretty small as well. So employers often have unrealistic expectations from potential candidates. I often see some jobs being posted over and over again, which means they would rather keep the position vacant till they find the perfect candidate, instead of reducing their expectations. The pay is uneven as well. Of course, this doesn't mean I am making excuses for myself, but getting a programming job in Australia can take over 6 months, and several failed interviews. Oh, and I do know the answers to those questions now! After every failed interview, I make it a point to note down the questions I couldn't answer, and look them up online. The design question I originally asked is quite complex, so I posted it here to get ideas and perspectives from more experienced developers. I have around 5 years of software development experience, but I was made redundant (along with the entire IT team) from my previous job because they decided to outsource IT to the Philippines. It was only then that I realised how hard it was to find a job. I was supposedly 'overqualified' for junior roles, and not skilled enough for mid-level positions. Also, in Australia, most developer jobs are 'full-stack'. One needs to know at least one back-end framework (like .NET), a database, JavaScript (with at least one framework or Library like Angular or React), basic Devops (CI/CD), and familiarity with at least one cloud platform like Azure or AWS. I spent several months trying to upskill myself (managed to learn some Angular 6, and some CI/CD tools), but I eventually realised that it was still not enough (after several failed interviews). I thought I was struggling because I am a self-taught developer (my basics aren't too strong), so I decided to drop my job search efforts temporarily and went back to university to get a degree in Computer Science. I just started my course earlier this year, so I have a long way to go before I graduate. But I still love writing code, so I am continuing to work on small personal projects as a hobby. I just completed building a web application with .NET Core 2 and Angular 6. I am even tempted to seek developer jobs again, and if I succeed, work full time and change my university workload to part time. Maybe I will give it a try again later this year. Once again, your views and insights were extremely helpful to me. It gave me a better understanding of my current skill level, and an idea of what I need to improve on, if I intend to seek a developer role again.
I hate these dialogs. You get the same thing in Office if Excel crashes or is killed. &amp;#x200B; WTF does "Recover" mean? What's the delta? Show me what I'm recovering so I can make an informed decision.
I had similar issues, in my case these were caused by a bad query plan. You can fix it by forcing the fast query plan: https://docs.microsoft.com/en-us/sql/relational-databases/performance/monitoring-performance-by-using-the-query-store?view=sql-server-2017
&gt; sanitize your inputs This is vague advice that means something different to everyone. Do you mean prevent XSS? Do you mean block special characters?
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/latexandloaf] [API Gateway using .NET Core, Ocelot and Consul](https://www.reddit.com/r/LatexAndLoaf/comments/bkvyvb/api_gateway_using_net_core_ocelot_and_consul/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
I don’t know if it’s been ported to core, but .NET framework has a built-in forms authentication provider (if that’s the sort of security you mean) I actually do a lot of ADO only software. I work with datasets that don’t map well in EF or cases where object types can not be determined until runtime (or later). It’s not “hard” but it does take a significant amount of planning to avoid spaghetti
Well I'm confused.
After moving towards Web API with JSON, there's a part of me that wonders why anyone would want to work with SOAP and XML. WCF just seemed cumbersome after building a straight up RESTful API.
You get ObjectDisposedException if it was exposed. So that is probably not the issue. You look like you're getting a NullReferenceException in your own code which means some variable is null and you're trying to call methods or properties or otherwise do something with it. Check the line referenced in the stack trace. Assuming it's from the code block you posted, imageStore is probably null.
About the recovery dialog ... This just means the file was unsaved when VS closed. Rather than save it directly to the existing file, VS temporarily saved it to another location because you might not have wanted the changes to be saved. Now it's asking if you want the changes back It didn't f'up your file.
It was vague advice for a vague question. Without more info about what they're actually looking for it seems pointless to go into too great detail, doesn't it? Regardless, I make a comment about regex right after it, so I think its pretty clear I meant the latter
Security for users and different principals/roles across a web app that is quite extensive and will have many different authorization scenarios
I saw this, and some blogs pointing to this, but it would be some work (and a lot of research to avoid leaving any security holes).
If your intent is only to call SP's, I'm struggling to see any reason to use EF. All you're really getting is the deserialization into a model, and Dapper can do that for you.
Thanks for your input. I agree, but I want to add Identity. So...dapper and identity is what you are saying?
It's just the .csproj file that had some changes since the last save lost, and it saves whenever you compile. No big deal.
I'm working in Smart Metering Company. Recently I Integrated our system with Oracle MDM (Metering Data Management System), so I had no other choice instead of writing soap services because Oracle MDM can only consume Soap Web Services using WSDL. Last year we moved our System from .Net Framework to .Net Core &amp; minimised 7 servers from 10 for handling the same number of Smart Meters Requests. That's one of the reason I wrote Soap services for MDM Integration using .Net Core as well.
Which makes sense I guess, but if anything I feel it's yet another reason to not use Oracle products.
[removed]
I would agree with Merad. EF comes with a lot of overhead and a lot of potential for misconfiguration and lack of performance. If you need statefulness and local caching then it might be a good choice. If you are working statelessly then Dapper gives you all you need.
Do you have a strategy for migrations? If that's also out of scope then EF sounds like overkill.
EF is overkill, so then what are some feasible authentication/authorization options?
I second this. EF temps people to do things badly to easily. If you're intent is to stick with SPs for access, definitely skip it and just use Dapper. It gives you the projection of results into strong types that EF gives you with very little of the overhead.
Check out IdentityServer4, you can configure it without using EF.
MVC 5 isn't dead. It's just not the latest, people can really over exagerate some times
watch aspnet core tutorials then you shpuld be fine
Can you please elaborate more please? I'm really worried I've wasted my time learning c#
Mosh hamedani's course on udemy says you must have experience with mvc to engage in his courses is this true?
Maybe start with a general c# tutorial first and then move to webdev.
I'm learning c# right now through udemy (mosh hamedani's courses) for the hope of becoming a mvc dev but I'm hearing some stuff recently about mvc being dead or c# is pointless and stuff which gets me worried
if you understand old stuff then you can easily transition to new stuff. But mvc is not dead. Watch asp.net core videos and you are fine
Thanks alot for the advice. It's a relief to me as I got really worried hearing mvc is dead, hopefully that isn't true and I'll try to master asp.net by my 15th birthday
Plan more time lol. This will take years
C# isn’t going anywhere .NET Core uses C#.
:(
Don’t worry. You haven’t wasted time at all. Most of what you have learned about C# will be very similar in any other object-oriented programming language. Most of what you have learned about .net will stay the same for many years to come, and even for successors to .net. And the core concepts of asp.net, asp.net core, asp.net web api etc are all the same and will stay the same. Learning new stuff is never a waste. Just keep at it and enjoy it.
Those courses are probably geared for people already familiar with .NET MVC.
C# is the language you write the code in. The framework you use changes depending on what you need and that's what moves a bit quicker. C# is not going anywhere and IMO probably going to grow quite a bit more with the advent of .NET core and cross platform capabilities. You've chosen a good language that will set you up with many options and a good base to learn other languages if you chose
I agree with you completely and specifically this part &gt;Learning new stuff is never a waste I'm really happy I'm busy learning programming instead of wasting my teenage life and thanks to you I'm motivated to continue my journey
ASP.Net MVC is a broad label used to describe a web framework that exists in both .Net Framework in several forms (one of which includes MVC 5), and Asp.Net Core. You can look at MVC 5 as an older version of the general MVC Framework, where the Asp.Net Core MVC represents the newest version of MVC. The reason it’s so confusing is that MS reinvented the Framework that powers a bunch of these technologies, thus the strange division between .Net Framework &amp; MVC 5 and the .Net Core stuff. There is a _ton_ of crossover between MVC 5 and MVC on .Net Core. You are not wasting your time learning MVC 5. However the articles you are reading about MVC 5 being dead are “correct” in that that version of the Framework will remain stagnant while .Net Core MVC will continue to gain new upgrades and features. So, if you’re able, learn the Asp.Net Core version of MVC. The latest version is 2.2, with 3.0 on its way in the next few months. There are a ton of great resources to learning Core MVC, and if you ever need to use MVC 5, like when you become employed, it will feel very familiar to MVC Core.
so their are chances of soon to be 15 year old me to be a good programmer soon and maybe prove useful to other people and fellow programmers with c#?
I don't know about what your skills will be like I'm afraid. However C# will continue to be useful for years to come
Don't stick to much to technology. Everything you learn today will be outdated in 2 years anyways. Its about concepts and understanding them: MVC is a good base, but for WebDevelopment I actually would rather recommend going the JS-Client / REST approach (for C# this means dotnet core web api and a JS framework of the week ;) ): its simply a cleaner cut between UI and services which helps in any microservice or even microapplication approach.
Authentication and authorization have no correlation to EF or any other ORM. They are unrelated. You could be authenticating against Azure AD, Identity Server 4, Azure B2C or Auth0 for example.
If EF is overkill IDSvr4 is a mass slaughter....
You don’t need EF for identity, that’s just the default out-the-box implementation. You can implement your own or there are existing implementations out there for various back ends already. Have a look on github for what’s out there. I can’t recommend one as I haven’t used any of them before.
In my project I expose a set of DTO classes which are separate from my EF Entities. They are exposed via a CRUD webapi. For the many to many relationships I map them into the DTO without the join table. So I would expose a StudentDTO with a list of CourseDTOs, or on the other side I would expose a CourseDTO with a list of StudentDTOs. In the case of the api consumer, they wouldn’t even know the join table existed. If I was creating an ER diagram for the api consumer, I would leave them out. In the case of my backend code, I of course use the join table. So if I was creating an ER diagram in the context of the backend I would include the join table. So I think it depends on how you are exposing it, and who the audience is.
Great, this is actually just for a college project but the ERD is in the context of my backend so I will show the joins. Thanks alot for the answer, appreciated.
Same thing i believe too. In the coding Bootcamp i am those many to many tables required for the StudentsPerCourse.
It is like drinking from a fire hose. Prepare to be overwhelmed! Spend some time figuring out what your goals are, and target the sessions you want to attend before you get started or the whole day goes to pot. Prepare to wait in the queue for the keynotes. It gets crowded and they pack people in before opening the doors. I've enjoyed the two I attended, wish I could have gone this year. Looking forward to the live stream...
Highly recommend against EF for a sproc based implementation. I dont think you will like the chunky way it handles those return types.
EF is over kill because he already has stored procedures for his queries. Identity Server is completely unrelated, and if he already has his login sprocs, its as simple as calling them and returning an oauth token for the rest of the application, he's not adding an unneeded layer by doing this like he would be by using EF.
For some small projects, I use asp.net membership for authentication. You can install it on a database using the tool in the framework folder. It creates tables and stored procedures and doesn't need EF. I don't know your other project specs though.
Maybe I'm misunderstanding what you mean... If you create a model from the database, the joining table does not become an entity in the model. In other words you would never have the StudentCourses entity.
&gt; IdentityServer4, you can configure it without using EF am currently doing this....all in-memory lol
Even though I’m a fan of EF, it sounds like you don’t even need it if you’ve already got sprocs for everything. I’ll add my voice to those recommending against it for this project.
Yessir, same here for some of our small API's. Works great.
It seems the [Nuget package](https://www.nuget.org/packages/Consul/) is still available to use. As for the read-only state of the repo, the most likely explanation is that the repo owner is not able to do maintenance on the library anymore, so they made it read-only. It is not ideal, but at least now people know not to expect updates. If this is a crucial piece of software to you, and you're willing to put in the time to maintain it, perhaps you can approach the owner of the repo and see whether you can take over ownership? I see their email address is on their [alternate GH profile](https://github.com/anwright-ms).
This is a must for anyone doing any "architect" work. Figure out who has solved your problem before, which solutions worked long-term, and the biggest pitfalls that people hit. There are a lot of architects that like to cleverly invent new architectures in a vacuum and it rarely goes well.
The inbuilt templates are quite bad esp for angular. I've done various implementations with core api serving both the api and angular. Imo it's just pain that bites you. Have two separate projects one for fe one for api. Use the angular cli to create projects for angular e.g ng new app. The cookie cutter templates that Ms gives are out dated to what angular is up to and the project layout / architecture is wrong
FYI - Membership is deprecated and should not be recommended for new stuff (as far as i know it is still supported so it's fine to keep it on legacy stuff). Identity is the replacement for it. As for the OP, if you are on Core, I would suggest taking a look at ASOS. I personally don't find Identity to be very useful compared to rolling our own implementation (our project uses the password harsher from identity, that's it lol).
And the time/effort spend writing an identity provider would still be worth it, compared to bringing in EF Core as a dependency. &amp;#x200B; Maybe we can get someone to open-source an implementation? I hate to see people use EF Core for this reason.
If you add EF for Identity, do you need to change your existing database connection method? Why not keep them separate? Depends if you need to cross query the databases or if you can rely on the user id from the user's identity token.
You are correct. The client is disconnecting before the request is complete. This sometimes happens and is normal, the client should retry. There is nothing for you to "fix" as far as the exception goes; ASP.NET is letting you know the client disconnected before you sent the response and an exception works well for this since you can catch it to do any cleanup you need to do. Though in this case none of your code was in the call stack so none of your code has yet been invoked. This is happening entirely inside ASP.NET.
In EF core you do
Thank you very much for your reply :) I figured that when I saw the stack trace which didn't have my code in there that it was something that wasn't under my direct control.
How are you sending the token?
I'm sending the token with postman , as Header with a HttpGet. And about "useAuthentication()", I already did, still the same.
And the header looks like 'Authorization: Bearer eyxzyourtoken'?
Also, you have requireHttpsMetadata set to true. That will fail.
Ummm 'Authorization : Bearer ey(token)' I don't see an eyxz prefix.
Changed it to false...
Okay. I would have expected logs for an invalid token, but do you have a resource in IdServer named Swap? And does the token have a scope within the Swap resource?
I'm currently at work and don't have access to the code above. Will to be okay to talk about it later today? I've sent you a chat message :) thanks a lot!
This happens frequently if you’re missing an await somewhere in the call stack.
In my action filter Attribute code there is one place where I am doing the following: `var content = currentActionContext.Request.Content.ReadAsStringAsync().Result` Could that contribute to the problem? In this particular instance that whole action filter function completed normally so I don't think that was specifically the issue in this case.
This is usually just a dumb exception that is thrown when a request is cancelled. For instance, when someone clicks something too fast before the data returns, or switches pages before data loads, etc... You can usually just suppress the error in your WebApiConfig class (pardon the VB, it shouldn't be hard to translate to C#): &amp;nbsp; Public Module WebApiConfig Public Sub Register(config As HttpConfiguration) config.Routes.MapHttpRoute( _ name:="DefaultApi", _ routeTemplate:="{controller}/{action}/{id}", _ defaults:=New With {.id = RouteParameter.Optional, .action = RouteParameter.Optional} ) config.MessageHandlers.Add(New CancelledTaskBugWorkaroundMessageHandler()) End Sub End Module '--Avoid throwing errors on cancellation request Class CancelledTaskBugWorkaroundMessageHandler Inherits DelegatingHandler Protected Overrides Async Function SendAsync(request As HttpRequestMessage, cancellationToken As CancellationToken) As Task(Of HttpResponseMessage) Dim response As HttpResponseMessage = Await MyBase.SendAsync(request, cancellationToken) If cancellationToken.IsCancellationRequested Then Return New HttpResponseMessage(HttpStatusCode.InternalServerError) Return response End Function End Class
Thanks - so this looks like it will effectively continue processing on the server side. Is that correct? I can't seem to reproduce the error locally as yet...
It tries to return the response as it normally would, but captures any cancellations and returns them as HTTP/500 instead of just throwing an unhandled exceptions. Normal responses aren't fudged with at all. I forgot where I read it, but I heard this has been a bug of MVC/WebAPI for a while. This fix has been working well on my live servers for a couple months.
Ah ok I see. In my specific use case I am triggering server side processing when a client performs the request, so the return (and even the exception) are really secondary to the controller continuing on and completing. I'll see if I can rig up some tests and work out how to catch/ignore the error but continue on, although I'm not sure if this is a good idea as if the client has cancelled the request or timed out I guess I can't guarantee that the POST data (the most important part of this request) is whole. &amp;#x200B; Thanks!
Two things: 1. See if you can implement an `async` filter and `await` it instead. 2. If you can't, use `.GetAwaiter().GetResult()` instead of `.Result`.
It sounds like you are doing something like "fire and forget" if I'm not mistaken. So the user clicks a button that POSTs to your server saying "hey start doing work", then you immediately respond back saying "okay I'll start now"... and then your WebAPI continues on processing? If that is the case, are you positive these background threads are actually running to completion and not getting murdered or timing out?
Ok great, thanks for the advice!
While the return code is good to send back, it's not as important as doing the work. The workflow is actually something like: 1. Client script runs, making a POST to &lt;my-api-url&gt;/DoWork with a whole bunch of data (application/x-www-form-urlencoded ) 2. Controller code for the DoWork runs to completion (no asynchronous code in this) 3. Controller code returns HttpStatusCode.Ok It's very "synchronous" in its nature in that I don't use background threads, tasks, etc and I don't need to return straight away. I also think if it was a thread/task it would throw an "AggregateException" or a "TaskCanceledException" but I could be wrong on this. Ideally, regardless of whether or not the client script closes the connection, if I receive a valid request to &lt;url&gt;/DoWork then I want to continue doing the work, since the client script really doesn't care about the return code. It would be nice to catch and log the exception in my original post, but the controller code must continue on. Normally this works perfectly fine - this is the first time I've seen this error and it is also the first time there was a large delay between the client script making the POST and IIS logging the request. Not sure if the two are related, but I think they would be.
Does this support 500 concurrent users?
“They don’t even go here.”
You can consider [Asphostportal.com](https://Asphostportal.com). They fully support .net and they have reliable service.
Yeap.... Previously, I also used Azure, but they are expensive. I can't afford it. The deployment is very easy and quick. We can't compare it with shared hosting. For shared hosting, asphostportal is good consideration, they are cost effective and very reliable.
Someone should notify the authors of the official .NET Microservices pdf/book, as they mention Consul a couple of times but clearly it's a gonner now so...
I sort of assumed the link would go to a blog post about 4 things, rather than a registration page. It's an immediate turn off when I have to give you something so you can market to me.
Speaking for the React MS template, the frontend part is a standard React app, created using CRA (Create React App). In that sense there's nothing non standard about it, it just happens to be housed in the same project as the asp.net web API. It would be easy enough to start with that, then move the frontend React app out into its own project. Communication with the API is done using standard fetch requests etc.
Yes, there’s another repo now: https://github.com/hashicorp/consul (Went to the one you linked, then went to the Consul website linked from there, then followed their link back to GitHub. That led to the above repo.)
Official web-page links to https://github.com/hashicorp/consul
Thank you!!
you are welcome :)
It will show you if you tell it to. But yeah it should work like VS Code does and just save it to a separate temporary file and reload it when you rerun VS.
\&gt; Database access was an afterthought This is just not relevant. There is no need for a UI platform to reimplement database access. Any platform supporting .Net Standard 2.0 (and probably earlier) can do database access just fine.
I agree - refuse to register to read a 'free' article.
Some of this has already been stated: * Move to SQL database * If you have a .Net Core web application you could always scale it up if needed. I would develop the app then do stress testing to see if more work needs to be done. * You simply cannot perform read/writes offline, this is equivalent of "Hiring fresh grads doctors, must be able to cure cancer", however, if by offline they mean on their internal network but without an internet connection, the application could be hosted on a local server accessible when user is on the domain. * I would use layered architecture, EF core, .NET Core and hosted either on azure/AWS or locally depending on what the company currently has as far a servers and infrastructure goes.
Personally, I don't like Razor pages and mixing BE with FE in one project\\solution. So, my personal preference is having two separate projects\\technologies for BE and FE. For FE just choose whatever you comfortable with, while BE is just an API. &amp;#x200B; Currently, I have a .NET Core Web API as BE and Angular as FE.
&gt; ASP.NET is becoming very popular for developing web applications and many of these applications are high traffic in nature and serving millions of users. WHAT YEAR IS IT? I don't think ASP.NET is popular for any new web application.
Btw, I think it would be better if you create a new post on StackOverflow and answer it at the same time. With that said, more people would be exposed to your solution. I doubt that anyone will browse reddit for that matter (only if Google indexed it correctly).
You're right. Reddit threads have come up in my search results in the past but StackOverflow is certainly the best place for this information. I'll try to find time this week to put it up there.
Wow, this is getting really interesting... What a great time to be a C# developer! :)
&gt; Today, we’re announcing that the next release after .NET Core 3.0 will be .NET 5. This will be the next big release in the .NET family. &gt; &gt; There will be just one .NET going forward, and you will be able to use it to target Windows, Linux, macOS, iOS, Android, tvOS, watchOS and WebAssembly and more.
Ah shit. Just when I \*thought\* I figured out the difference between .net framework, .net core, .net standard, netcoreapp and other target framework monikers, and meta-packages, there's some kind of new thing.
Please release it fast! And make it build inside Visual Studio. Not like .NET Core 3! Why can't building apps become as easy as 5y back when only VB and C# were there in VisualStudio? Think about it MS. Make .NET 5 great.
It's not a new thing. It's just .net core. The announcement is really that they are killing .net framework. With no "framework" they are just dropping the "core" from the name.
.NET 5 is on the same roadmap as .NET Core 3.0 so I would just consider it as a continuation of that project. They are skipping .NET Core 4.0 as a name for obvious reasons with confusion with all of the various .NET Framework 4.x versions. With the introduction of .NET 5 it sounds like they plan on having all of the current functionality of .NET 4.7 and .NET Core reimplemented in the patterns used by .NET Core today so I imagine that this will be viewed as the complete replacement of .NET Framework on Windows going forward in 2020 and beyond. So Framework and Standard will disappear and we will just be left with .NET 5 This works alongside the previous announcement that .NET Framework 4.8 will be the last framework release.
This should in theory unify things. Especially the Core/Framework confusion
* WPF and Windows Forms Update * Publishing Single EXEs * Introducing the JSON Serializer (and an update to the writer) * Index and Range * New Japanese Era (Reiwa) * Hardware Intrinsic API changes * .NET Core runtime roll-forward policy update * Making.NET Core runtime docker images for Linux smaller * Docker Updates * AssemblyLoadContext Updates * COM-callable managed components * GC Large page support
If you can't build .NET Core projects in VS then you're obviously doing something wrong. Works perfectly fine out of the box for me and everyone I know.
🤯
COM-callable managed components Does that mean I can use .NET Core 3 for making Visual Studio extensions with custom (WPF-based) editors now?
It seems that .NET core can target every platform and service on earth, except MS own's .NET Framework. I work with \- MS own's Exchange APIs (no API for .NET core and GraphQL is for Office 365 online only) \- MS own's Dynamics 365 SDK (.NET core is not even on their radar) \- Various corporate software that have good legacy .NET plug-ins but poor Web APIs. I barely even have a single project I can plan on .NET Core in a corporate environment. And even if I could, the risk is too great that I need to interact with some unexpected .NET framework stuff, and I don't to build a wrapper service every time it happens.
What happens with .net 4.7 and onward is something I don't understand. Are they saying everything in .net 4.7 will work in. Net 5? Or is it more that .net 4.x is the end of the line and .net 5 is what people should be using. Specifically things like SOAP, WCF and aspx pages. This are often mentioned when people say they can't move to core. Surely they don't mean .net 5 will support everything?
Added more information, Please help me :\]
What isn’t easy about it now? It’s even easier. And .NET Core 3 hasn’t been released. You can’t assume how it will work before it’s actually released.
That confirms the death of the old Framework.
And even explorer.exe extensions I believe. (Whether you actually want that from a technical perspective is still questionable though)
There is likely not going to be any 100% compatible path forward from .net framework 4.7 and onward to .net 5. .NET 4.8 is the end of the line for that support and .net core based systems are the only ones going to be directly compatible. &gt;Specifically things like SOAP, WCF and aspx pages. This are often mentioned when people say they can't move to core. Surely they don't mean .net 5 will support everything? It may not support everything but WPF which is currently not supported in .NET Core 2.x will be supported starting in v3. From the passage below it sounds like they are going to try to close all the major gaps between .net Core and .net framework 4.8 inside the .NET 5 release but personally I would count on legacy features being unsupported if they are not implemented at all in .NET Core 3. &gt;&gt;From the inception of the .NET Core project, we’ve added around fifty thousand .NET Framework APIs to the platform. **.NET Core 3.0 closes much of the remaining capability gap with .NET Framework 4.8, enabling Windows Forms, WPF and Entity Framework 6.** .NET 5 builds on this work, taking .NET Core and the best of Mono to create a single platform that you can use for all your modern .NET code. They say later on that they are going to try to consolidate the best of .NET Core, .NET Framework, Xamarin and Mono and combine it into a single framework that can be run on all platforms supported by those right now. If you rely on legacy features in WCF, ASPX pages, or other older technologies then they likely don't have any path forward after framework 4.8.
.NET 5 is MS's... *wait for it*... 2020 vision. 😎
Many architects are not very good. I didn't make them that way, I'm merely stuck with them, and they ignore my advice for unstated reasons.
He's probably referring to certain project types that are in the process of being added during Core 3's development. Initially making WPF and WinForms apps required the use of the command line to create the project files.
absolutely!
I mean, if you're using a preview then it should be obvious that it's a work in progress. Complaining about it just makes it obvious how little he or she knows about .NET
They hinted at that with the 4.8 announcement. Basically 4.8 is a bunch of maintenance fixes and then is going to be mothballed.
&gt; and then we intend to ship a major version of .NET once a year Can anyone help me understand why that is a good thing? As a production user since .NET Core 1 and considering .NET Core history, that scares me. Virtually every new major version came with breaking API changes, performance issues and runtime bugs. For example our microservices get frequently killed for cgroup memory limit violation: https://github.com/dotnet/coreclr/issues/16906 To me this urge to spit out major versions every year sounds like their will to "sell" .NET Core whatever it takes is greater than the will to turn it into a reliable runtime.
You just stick to the LTS releases?
You don't have to immediately migrate to the new version. Versions can be installed side by side.
Java interop? In what way?
&gt; Virtually every new major version came with breaking API changes Exactly because of that. They can progress and advance the framework much faster. If you need long-time reliability, then you stick to the LTS version.
Of course. It can C#
.NET Core 1.x LTS ends on June 27 2019. Not helpful.
Is it possible to use Preview 5 with Visual Studio for Mac? Preview 4 doesn't work with it
some kinda ffi most likely, I guess
True but adopting .NET Core 1, 2 or 3 is a known risk you took with it being new and their release models back then/now. If you weren't okay with support ending this July you wouldn't have adopted it after all. If you aren't okay with .NET 5s release and support plan you'll have to switch languages / frameworks. But, the grass isn't necessarily greener elsewhere.
Take your damn upvote.
That was last year's announcement. The current announcement is that they are killing Mono.
It really depends on what language/server you are using. &amp;#x200B; /r/webhosting will be your friend.
For example, .NET MVC and SQL Server. Do you keep both a local version and a live version of the site? What's the standard here?
I think earlier versions of .net core had lot of bugs because it was new and they brought in lot of breaking changes. However, it seems like the framework is maturing and going forward it will not be the case. Given the fact that .net framework is essentially dead now.
you should always keep a production (live) and a developper environnement. In some case you will also want to have a staging environnement for testing.
Now that you mention it, in the visual studio 2019 keynote they said something about two separate projects in .net Core 3 I think I'm not sure one that acts like a backend service, the other like the front and they had shared codebase or something like that, but I'm not sure don't take my word for it was after the big stuff and I wasn't paying to much attention because they said that .net Core 3 was still at preview, so I thought I'll check it once it's out
Half the blog post is about the investments they are making to the mono runtime.
The author mentions using the IEnumerable IoC pattern a lot. &gt; I’ve done this in a tonne of different ways with huge success. I would be really interested in hearing some practical real world examples of it.
.Net FX won't be getting more than critical fixes and security updates going forwards. There are stand ins for some of the frameworks you mention and some hints that other ones like WCF or something similar might be making a reappearance
If you are running on Windows the drop in compatibility story is actually pretty good. They did a lot of work to get popular Nuget packages to work even without a recompile. Obviously if you do something the Runtime or Core BCL doesn't support you can have problems but with the Windows compat pack and the preview release of the .Net FX reference assemblies on Nuget the story is a bit brighter for older FX projects.
In the most basic sense, you copy the published project files to your production (live) server after testing locally and verifying everything is working. Then when adding new features you work only on your local environment until the code is ready to be deployed to production. This can be a manual process, or you can use build tools and continuous integration tools to automatically deploy code changes to a test or production server. It is also common to have a staging server, which allows other people to test/review the changes before they go live. If this is a personal project then you should be fine with just local and live environments. But if you need a 3rd party to review or verify work before it goes live then you would want Local &gt; Staging &gt; Live as your three environments.
Hallelujah 🙌🏼
I also had this doubt, what does that even mean and swift interop too? No clue here... Can someone help ???? ❓
the exam is about Universal Windows Platoform Development (Applications running on Windows 10). Not Windows Phone.
Have a look at SoapCore on github :)
I really wish google was equipped to handle these sort of name changes. It sucked big time when I was searching for relevant answers during the core 1.0-1.1 change, or the Windows Phone-WinRT-UWP scandal.
So glad I chose .NET almost ten years ago and kept with it until now. I hope now with .NET 5 we will better support for AOT compile for game consoles. Ps4, Switch, etc.
4.8 does contain several new features, for example in WCF.
something something "C with glasses"
Yes, but you'll need Visual Studio for Mac 8.1 Preview.
Try Bing, you might get better success.
I don't think "major" today means the same thing as back then. Anymore a major release is is much less major than it used to be.
Really glad they finally said this, I have been arguing this point and people have repeatedly said it wasn't confirmed by Microsoft. Now if they would just put out official statement on the future of Desktop or the lack thereof.
No, .NET 4.x applications still need the appropriate version of .NET installed to work just like always. It will be the same with 5, but each version of the runtime is separate now, including patches, so developers have better control over which version of the runtime their app is run with if needed, or they can just specify their app should use the closest version the user has available within some range of versions.
That’s interesting. I recall that VS warned me before starting the update and I had the opportunity to stop it. Either you found a bug or MS changed the flow.
I love the Blazor (wasm) notes there, and finally merging the somewhat redundant runtimes. Really looks like they're serious with wasm being a compilation target for .NET. What a great time to be a .Net developer these days.
I just want someone from MSFT to comment on whether or not there's an intention to add UWP support to .NET Core 3.0 (or .NET 5.0, even).
r/brandnewsentences
.NET Framework, .NET Core, Xamarin and Mono all will be unified in **.NET 5**. Finally, the pain of fragmentation will go away!!
I think the interoperability of Java, Swift, Objective-C are supported because of Xamarin framework, for cross platform mobile app development.
Blazor could be their downfall.
Why?
I feel better about having to work with c# for now. That’s pretty nice to see.
So will Web Forms come in .NET 5?
Man, I wish Visual Studio had real-time saves like Rider or any other Jetbrains IDE has. I can just pull the plug on my PC and when I boot it back up, I haven't lost any work.
&gt; Introducing the JSON Serializer So, an end to Newtonsoft Json.NET?
Web Forms will not come in .NET 5 since .NET 5 is the vNext of .NET Core and Web Forms is not being ported to Core.
Without basic support for industry standards like SOAP and WS-* via WCF, no way.
Definetly a cool framework. But I am still missing a real (and good) documentation for it.
I think they said they will add uwp to .net core in one of the main talks yesterday. Either in the one by the lesser Scotts or in "All developer things" by Hanselman.
Yes - why?
But they also said to merge Mono, and Mono support WebForms.
They're taking the VM portion of Mono (basically the Mono-equivalent of the CoreCLR repository) and using CoreFX as the framework layer. It's also important to note that the Mono implementation of Web Forms doesn't work with IIS, only with Apache, FastCGI, and XSP. Additionally, I don't know (and don't think) that Mono's WebForms support works on Windows. It also doesn't have all of the features of Web Forms. So it's not a drop-in replacement that could be built into .NET 5 easily or really at all without a ton of work and a massive bug tail.
Soon to be a horrible time to be googling or asking SO questions related to .net!
Not really... Google constitutes 1/2 or so of my searches now. It's extremely hard to find information on anything relatively niche or specific that also contains keywords that mommy blogs, clickbait sites, blogs, or how-to's have latched onto sometime in the last 5-10 years... What Google needs is a "more of this", "less of this" filter that you can apply on individual results to narrow down the search... Results get more and more polluted/diluted with the common denominator. Just like how popular subreddits become polluted with images and memes, as that is the common Reddit denominator. It's a problem that will only get worse.
Is James Newton-King involved with Microsoft in writing this feature in .NET Core?
When you use collection. AsQueryable() and ise Linq - it automatically generates Aggregation query.
SOAP may be a standard, but it's dead. Give it up.
It is dead for script kiddies but not for enterprise :-)
enterprises are moving away from it thanks to us script kiddies
Not really, fortunately.
If it takes you a month to interface a REST client, you aren’t productive anywhere anyway :-)
If it has 100+ methods and 1000+ complex types, the REST "string composing" try-and-fail approach is not very effective. Again, I am talking about enterprise.
If you have 100+ methods on a single service, you are breaking so many patterns I don't know what to tell you.
You are definetly thinking about REST services in a wrong way. Enterprise architecture has evolved a lot in the last decade. I am not saying you should migrate everything you have in your enterprise apps, no way. But when it comes to developing new apps for those companies, SOAP should be buried 6 feet under.
&gt; SOAP should be buried 6 feet under If the new technology provided at least the same set of features. No, nobody use WADL, it is not even a W3C standard yet. Without metadata description to build strongly typed client in one second it is useless toy only.
When I'm trying to download preview version for Mac site starts to download exe for Windows. I don't understand how does it work...
Why not use Swagger, now [OpenAPI](https://en.wikipedia.org/wiki/OpenAPI_Specification) , i believe that is most common for REST development
Swagger is useless. As long as there is no widely accepted WSDL alternative, the technology is still a toy only.
This is for merging into dot net core. Mono disappears and is subsumed into the next version of .Net Core which is then called .Net 5. Same strategy they took with .Net Framework. Integrate into .Net Core, then depreciate. It's the right strategy.
Another problem: after updating to preview channel Visual Studio shows main screen for few seconds and crashing.
Duplicate of [this][1]? [1]: https://www.reddit.com/r/dotnet/comments/ble2lw/introducing_net_5/
What documentation are you missing for it?
[removed]
The point of an SPA is that it handles the routing and the like. As for setting it up, there’s not much you have to do. When I get home I can link you a good tutorial for using JWT and CORS, but really, Vue just needs to consume from your API controllers in MVC.
Microsoft had made a mistake when they haven't made .NET open source, but the company was different back then. When they introduced .NET Core I was impressed they drove the open source ride and finally realized it's crucial in order to compete in every standard, but was skeptic about the reliability of it. When .NET Standard was introduced, I was confused. So many different .NET versions, so many APIs and so much synchronization needed to be done by one who wants to target .NET Standard. Today, I am confident Microsoft is going to use the benefits of all different mishmash of .NET frameworks to create an amazing, easy to deal with and truly cross platform framework. Bravo!
It is just amazing. Should be embraced
I love web forms due to RAD but it creates lazy programmers, so I can't say seeing them go goodbye is a bad thing, reminds me of the days when everyone was a Access Application Developer when Button1's action was onclickButton1 , etc. taking all the default xyz naming. Unfortunately I see some worse results when you include a power RAD component set like Telerik the fresh/junior don't understand what/when/where/how. So calls specifically database calls get called multiple times just on page rendering. Always great to watch SQL Profiler on Application hit mark 10s and 10s of calls before actual user interaction. Now opposing view is , alot of code is created for you in the MVC methodology but once you need to go outside that you need to track it down or adversely code every little single thing yourself.
This is 2019 my friend and [ASP.NET](https://ASP.NET) is still very popular choice of web developers. At MSBuild conference .NET 5 is going to be game changer framework from Microsoft. .NET still has Having 6X more speed than NodeJS and also angular can only handle front-end.
.NET Core was the game changer already, .NET 5 won't change anything about that. ASP.NET Core is a popular choice, not ASP.NET.
that's why I m using c# and I told them to do the same but they didn't.
There is a lot of systems running on SOAP.
There are tools for accessing WCF services, you just can't make new ones.
I thought it was obvious as soon as they announced support for WinForms and WPF on .NET Core. There is only one reason they would make that investment, and that was so that they could deprecate .NET Framework.
Even if they can't make it attractive on WASM, its server side model is still infinitely better than traditional WebForms.
[JSON.NET](https://JSON.NET) will be entrenched in legacy applications for the next decade, but probably greatly reduce its usage in new systems.
and they have cemented that understanding by... removing 'core' from the branding of .NET 5!
I was hoping for better performance out of System.Text.Json. Its great to have a quality serializer as part of corefx, but I thought taking advantage of new performance primitives and making a UFT8 specific variant would give it more of a boost than 15-20%. I think the planning issues said that they just built an minimal viable product for the 3.0 release, I wonder if they have more work to do on it for performance?
Like dead how? You mean no one creates enterprise level SOAP services anymore? I don't know for a fact as I work in a small shop now, but as of say 5 years ago one of the largest brokerages in the US was completely SOAP services (in Java). It may not be sexy anymore, it may not even be widely used for new development, but to call it dead? It's going to be used for decades to come.
SO: "Why is **X** not working in 5, i was worked in 4.0, we needings XP support" *Closed as duplicate of 'Why do i still have to breath'*
A SQL parser is as simple as it gets. some really *really* ***really*** simple SQL can even be "parsed" using Regex. (seriously, don't) &amp;#x200B; what do you need it for?
I have been shouting from the rooftops that desktop software is dying. Enterprise is starting to embrace the web and the deployment situation for Microsoft has been deteriorating over the last several years. MSIX shows promise but only for delivering thought the store.
&gt;what do you need it for? Users can write SQLs to perform tests on their tables and they save these SQLs for each test. I want to find out what tables and columns are covered in these tests.
Why use MVC instead of a web api ?
This is a pretty terrible way to to this. You'll get all sorts of warnings when trying to open it in Excel. WAY better to use EPPlus (free as in beer) to just create a \*real\* .xlsx file. [https://github.com/JanKallman/EPPlus](https://github.com/JanKallman/EPPlus)
Good riddance tbh
Hi! &amp;#x200B; I want to handle things like authentication, authorization and SEO with MVC, so I dont want to go "full SPA". Although data will be server to frontend by api-controllers(same as MVC in .net core).
Yeah, I just did authentication/authorization through a WebApi. No clue how SEO works tho. I honestly believe if you use a front end framework/library, there's not much point to have .net MVC structure behind it but I am not that experienced.
At some point someone's going to make a third-party library. Consider that .NET can't even natively handle JSON.
I've tried that route as well, but Its very common to mix the two. The big sites I've worked on have always been some form of MVC underneath. If you want to optimize SEO then you need to render stuff server side, and NUXT is not an option in my case.
While I agree EPP is a better solution I'm not sure what errors you are referring to. I have used the above method several times with zero issues. Granted you can't create an xlsx file using the above method only xls files but it works.
Does that mean UWP will be truly cross-platform or still specific to Windows only?
Is that VS for Windows, or for Mac?
Windows only, similar to winforms and wpf being added in .net core 3. It would be nice to have a good cross platform UI library though. I'm not such a fan of Xamarin Forms. Perhaps a good blazor UI framework would be the way to go.
Simplest way? Use a Datatable and execute the statement which precludes actually getting results. It's \*super difficult\* to parse a SQL statement perfectly. Example, this code does just that. public virtual QueryResult ValidateAndGetColumns(string sqlExpression) { sqlExpression = $"SELECT * from ({sqlExpression}) as __TEST__ WHERE 1 =0"; var colProperties = new List&lt;ColumnProperties&gt;(); using (var conn = GetConnection()) { try { conn.Open(); var cmd = (DbCommand) GetCommand(sqlExpression, conn); var reader = cmd.ExecuteReader(); for (var col = 0; col &lt; reader.FieldCount; col++) { var colName = reader.GetName(col); // Gets the column name var typeName = reader.GetFieldType(col); //This is almost certainly because the DB uses a custom type... if (typeName == null) continue; ; var type = typeName.ToString(); colProperties.Add(new ColumnProperties { ColumnName = colName, DataType = type, OrdinalPosition = col, TableName = string.Empty }); } } catch (Exception ex) { return new QueryResult {ExceptionMessage = ex.Message}; } } return new QueryResult {Columns = colProperties}; }
A couple new articles on MSDN Magazine: https://msdn.microsoft.com/en-us/magazine/mt149362?author=julie+lerman
Specifically this : https://excel.uservoice.com/forums/304921-excel-for-windows-desktop-application/suggestions/15385080-html-formatted-files-with-an-xls-extension-no-lo
thank you! i hve tried the old Julie post. did not works maybe you luck and it will works for u.
Is it still worth writing new things in WCF? I am intrigued but I don't want to go down that rabbit hole if WebAPI is the way forward. What makes WCF great?
VS for Mac
&gt; Unfortunately I see some worse results when you include a power RAD component set like Telerik the fresh/junior don't understand what/when/where/how. So calls specifically database calls get called multiple times just on page rendering. I deal with this on a daily basis in code reviews because pretty much everyone outside of me and one or two other senior level guys don't know what's actually going on when you use their controls. While it's easy to blame the devs, I think it's just a result of web forms being a super dated technology. You shouldn't have to have 5+ years of experience to understand how the data is getting bound to any given object. I've always said web forms wasn't bad itself, it just enabled bad programming practices because they made it easy for people who don't really understand the framework and how it works, to be able to write applications.
I really hated having to smart
Nice framework but still lacking the GPU support.
I understand from experience that it’s very unlikely to happen, but I would take this opportunity to convince your management team to replace whatever WebForms project you have with a .Net Core project.
.NET is the Future of .NET
I understand that, but porting to Web Forms is not always possible when you have X projects that use Web Forms and always on a tight budget. &gt; a lack of security updates in the future .NET Framework will keep receiving security updates. Especially because it is a Windows component.
I would maybe use the React template from the dotnet sdk. That will give you an MVC backend (Templated as an API but still uses MVC) also set up to serve a SPA from the same kestrel host process. Then just delete the contents of the `ClientApp` folder, which in the template is a Create React App sample. You can then put whatever front-end app you want inside `ClientApp`. Just `npm init` and go nuts. You will want to know that `Startup` runs your SPA using `npm start` but you can change that to run any npm script. Also in your .csproj it is configured to run webpack using `npm run build` as per Create React App, when you do a `dotnet publish`. You can also change that.
I'm following up internally to see what info would help. I know for VS for Windows, but I'm less familiar with VS for Mac.
I agree that ASP.NET Core is the choice of the day. And yes thats what I was pointing to that .NET as framework is growing in right direction now. .NET is going to become .NET Core and ultimately cross platform and compatible to Target any device.
Can you share your IDE logs with me (either DM or email to [kevinpi@microsoft.com](mailto:kevinpi@microsoft.com))? From a member of the VS for Mac team: &gt; The Ide log will have information about the crash. The file is located here in `~/Library/Logs/VisualStudio/8.0`. We’d need the latest `Ide.*.log` file after the crash.
&gt; is a known risk Clearly MS didn't bother reducing that risk for .NET 1.x users. Compare it to how the Java platform has evolved.
What? :)
The Exchange "APIs" are either Powershell, which you can call through PS remoting, **as you should**, or EWS, which is a REST API that you can call with just about any language under the sun. Or, if you want to call it in C# natively, you can always use the managed API, which is literally an [OSS project on github](https://github.com/OfficeDev/ews-managed-api). What part of Exchange can't you communicate with via .NET core? Because last I checked, you could literally communicate with all of it.
You mean Microsoft should charge a license fee for every user of the NET Runtime?
 Hanselman\*
Thought it was official that net framework would never go beyond 4 almost as soon as netcore was announced? We switched almost immediately for new services
Ever heard of OpenJDK?
I'm pretty sure you get an error if you try to compare a generic type with null and haven't used a where clause to limit it to reference types. Is this something new that comes with non-nullable reference types?
&gt;I have been shouting from the rooftops that desktop software is dying. and nothing in the post confirms this. Desktop cannot even rationally die. Browsers run on desktop OS in the enterprise. Market share and models have and are changing but the death of the desktop is mythical.
&gt; Why am I down voted? &amp;#x200B; because you didn't read the post this thread is about. Thats directly addressed in it.
My enterprise defines our APIs in Swagger (OAS). You can use Swagger generator to scaffold strongly typed servers and clients in many languages. There are enterprise platforms like MuleSoft that raise the level of abstraction even higher using out-of-the-box connectors.
So I read an article about .Net 5 being the future yesterday, and now I'm reading that .Net Core is the future. What gives?
So is everyone with .NET framework apps effectively screwed or will there be a migration path?
Did you not read the rules in the sidebar?
I agree with the other reply. It's pretty simple to get the column names from However the query result is not considered a "table" and in fact with complex queries which mutate the data it doesn't make sense. For example if I do this query: SELECT COUNT(*) FROM [MyTable]; I get a single column called "COUNT(*)" with a single record. But that result query is not from a table. There is no actual column called "COUNT(*) " in MyTable. Though if you know in advance the queries will not be too complex you can use regex to parse the table name out, and assume the column names won't be messed with (eg if there is an AS clause in a SELECT that renames the output column to anything) you can get what you need pretty easily. However it sounds like to me what you really want to do is trace a query. Run it and then see exactly what the database does with it by parsing a log file or something. In theory you could then see exactly what tables and columns are pulled even before any operations are performed on the data from the query. I assume the big database engines can do something like this but I have not needed to do anything like this before. This seems like the place to start for SQL Server but it sounds like it is keyed more toward troubleshooting the server itself and not for individual queries so I'm not 100% sure. https://docs.microsoft.com/en-us/sql/relational-databases/extended-events/extended-events?view=sql-server-2017
Why? I personally find it extremely verbose and painful to work with.
.NET 5 is .NET Core
Salary range?
Comparing to `null` has always been legal unless `T` is specifically constrained to be a value type. You can't *assign* `null` to an unconstrained `T `, though.
Chrome OS is an entire operating system ( I know not technically) but theoretically built in a browser. With the introduction of Visual Studio Online and the existing Office 365, Microsoft is probably going to move in that direction. Azure and the cloud is the future.
https://developercommunity.visualstudio.com/content/problem/559920/shutdown-on-startup-vs-2019-for-mac-preview-1.html I have made report with all logs on forum
So what? Again on what does a browser run in the enterprise? You are late. Azure and the cloud are already present tense and past tense. They have been around for years. like I said, Market share and models have and are changing but the death of the desktop is mythical. due to screen size business and enterprise still run on desktops. They are NOT dying
Agreed. It's incredibly important to point out that this isn't even creating an Excel file. It's just a text file with some html in it that Excel can open. Also, this method only works with static files as they aren't actually rendering the view with any sorta data model, they're just copying the .cshtml file.
Of course, Mono would also still be free. Too bad it only runs a limited subset of the available software.
I've been porting a Web Application running on .NET Framework 4.5.x project over to .NET Core over the last 2 days. Aside from the whole move to Dependency Injection everywhere, a few API changes, and no more EDMX support (EF Core), the migration has been fairly easy. Can't speak for Desktop applications, but I can't see anything holding back Web Applications migrations to .NET Core / .NET 5 and up.
This optimization was also the fastest way I could find to [check if a generic type parameter is a value type](https://sharplab.io/#v2:C4LghgzgtgPgAgBgARwIwG4CwAoRLUAsWuyaAdADICWAdgI7F5oCsjyAygBZgBOADhTAAjMgCUArjWBUoAU2I4A2gCkqwAOKyasnlQDGACmABPPrID2AMwO1gASjsBdHHADM+AGwoATEgCSEABqYAA24rIAKqayADwRAHw4AN44SGko7mheQubmIUgAggYRSABuoeF2SAC88WUVsmSawFFmBnZkAcFhkdEK2OkZnkg5eUgAQu01dSZmVsUdXQ2t8jip6W7Do/kAwsX1PVW1B+FIVBBI3eEr/YObWSO5+QAiU8cAJrKWYOIhwAtnC5XXpmW4bTKobJPJAAUTedU+31+/wiVQAhNUkDRfiEwWl7pDHmMAGLwpBogyIn5/AHVTHYkIhOx4oYPbZIdRktHqbztFl8XTlYCyLbQnlkqnI2n0nEsglQsYACS5it5zLWA3SinIEikMkaO3MUD4VBCOnYOlK+lkEDIAFlZMBOOZ3n5jSEDDrJNI5GRDcbTebLdbbQ6nS63XwQgB5PjScw0W0FADmyZ4NogVFKsj8NBCtFoyac6zSAqzYGFoqVaumSElNNRNRljOIAF8gA===). Strangely the x86 Legacy JIT only optimizes `T == null` but not `T != null`. The Core JIT also optimizes the `T is ValueType` checks.
Desktop **software** is dying, not the desktop. Web apps and services are the future.
yeah, about that.. https://github.com/dotnet/corefx/blob/master/src/System.Text.Json/docs/SerializerProgrammingModel.md
browsers, operating systems and utilities are all desktop **softwar**e and that will be the case for many years to come. The problem with many of you is you don't know the difference between dying and market share changes. Does your smartphone have just a browser or do you install other things? As long as desktops exist people and companies will want to add functionality in other software. As much as in the past? no - market change. Dead? No. Meanwhile a whole host of things make no sense to run only in browsers - graphic editing, PC gaming, home entertainment - anything that take serious computing power. There are 800 million devices using windows 10 of which the majority are some form of desktop/laptop. There will always be a market of people that want to do more than open a browser on those devices. Desktop software dying IS mythical.
&gt;Yes they've now got round to porting WinForms and WPF to Core, but it's an afterthought If you think MS is abandoning PC Windows anytime soon you are drunk.
Ah, maybe that's what I was thinking of. Thanks.
/u/p3tch is pointing out that we don't know what you're referring to in your title when you say "you have to." What is it you don't have to do? Don't have to worry about generics, structs, and nulls? Don't have to be smart? Don't have to do something else?
The key here is that there is finally something akin to an official document from MS describing the state of affairs. The key points which have not been stated previously in a manner that us peons can provide to our phbs are: &gt; After .NET Core 3.0 we will not port any more features from .NET Framework. AKA "if you have libraries that don't work against .NET Core after 3.0, they are your problem to fix if you want to sell them." &gt; .NET Core is where future investments in .NET will happen. AKA there will be no new features added to .NET Framework (will not be getting http2 push, TLS 1.3, utf8 strings, SSE intrinsics, interface implementations and so on). &gt; Existing applications that want to take advantage of the new features in .NET should consider moving to .NET Core.
Thanks - I've let the team know about the report.
"You dont have to be"*
I would like to point out that this code block: class Program { static void Main(string[] args) { var path = "c:\\temp\\notfound.txt"; try { File.Delete(path); } catch (UnauthorizedAccessException) { FileAttributes attributes = File.GetAttributes(path); if ((attributes &amp; FileAttributes.ReadOnly) == FileAttributes.ReadOnly) { attributes &amp;= ~FileAttributes.ReadOnly; File.SetAttributes(path, attributes); File.Delete(path); } } } } will ignore any UnauthorizedAccessException that is NOT caused by a read only file. I would suggest this code block be used as an example of how to unlock a read only file and only that. If you're catching exceptions and run into a condition you can't handle in your exception handler, I recommend `throw`ing the exception again instead of quietly eating it. This will help you detect bugs and other problems. So the code sample becomes: class Program { static void Main(string[] args) { var path = "c:\\temp\\notfound.txt"; try { File.Delete(path); } catch (UnauthorizedAccessException) { FileAttributes attributes = File.GetAttributes(path); if ((attributes &amp; FileAttributes.ReadOnly) == FileAttributes.ReadOnly) { attributes &amp;= ~FileAttributes.ReadOnly; File.SetAttributes(path, attributes); File.Delete(path); } else { throw; // No idea what to do, let some other exception handler have a try. } } } }
Good point! Will play around with the sample again and update the post. Thanks.
How was this not obvious as soon as you heard about .NET core?
I added more stuff because I am terrible at reading whole articles before I comment. :) Good article, though you don't touch much on access control lists which are usually the cause in my experience, but to be fair those tend to be complex and newcomers to .NET probably aren't going to be doing things that require messing with filesystem permissions.
Love the input! I don't see the post as a static resource. Would make a lot of sense to extend it with the issues you mention. Thanks again, really appreciate the feedback.
Thank you for your detailed reply. I am not really trying to trace the query. I just want to know the tables it interacts with (updates, deletes, selects, and so on) and the columns involved. This way I can tell the user their tests cover x tables out of total n tables. And calculate some metrics for coverage. Nevertheless, appreciate your answer.
Hi guys, I can't seem to create a Global.asax file. I'm trying to add it manually (Add-&gt;New Item-&gt;Global Application Class), but there is no option for this file type. Please advise, thank you
This would work okayish for most select statements in most databases. But it Updates, Inserts, and Deletes. Also, you can't extract the table names this way. You wouldn't know what table this column belongs to unless you query some schema information table (which doesn't work since I want to support a long list of databases). Nevertheless, thanks for the effort. It seems parser is the way to go by hunting down the grammar files for several databases. I haven't been able to come up with something else.
Hahaha. Good one.
&gt;Global.asax Because .net uses Startup.cs no Global.asax
Oh okay, thanks. How are the Application\_Start, Application\_End, Session\_Start, Session\_End, etc events handled? I don't see them in this file
Thank you!
Engineers and confusing/bad naming schemes, name a better duo.
WCF != WebAPI, if you're going to go that route, look into something such as grpc. And no, I highly recommend not writing in WCF. Your app will become incredibly reliant on a technology that is basically "dead" now, and it's a pain in the butt to work with.
Isn't it obvious from the context? As a non-native speaker I might be seeing/expecting what others don't. I might just add "be" and correct the post's title, if you think it's not clear.
i 'member using sqlite the first time. I could be dumb as shit. nginx too, can almost sleepwalk the devops of that. I hate having to smart too.
Well, WCF is good if you’re connecting to something which uses SOAP and WS-Security or similar. Interop with foreign systems is not something you can always control.
I called that one when they announced the very first alpha's of .NET core.
I think you would do something like a .net Web API backend (can't really use MVC with frameworks like Vue can you?) And use node/spa services + vue's serverside rendering. I know you can do something like that with react, should be similar with.
Remote work possible?
As something to keep in mind, I once used a utility that converted LINQ query strings to actual link queries that could be run. I forgot what library it was, though. Something to consider.
Whoops - thanks!
it's clear. but op is just making a joke.
If you do some expr \`if (typeof(T) == typeof(AnyValueType)\`, the JIT deads the branch if it is false when the generic is instantiated (and deads the other branches if it is true, etc)
Put your Application_Start code in the Startup.cs constructor or Configure method, then register a shutdown method as shown here: https://thinkrethink.net/2017/03/09/application-shutdown-in-asp-net-core/ Session state is not so common in MVC but again there might be a way to register start/end methods while adding session to the pipeline in Configure --&gt; app.UseSession.
But said it was perfectly fine to keep calling it core. That'll make things less confusing! :P
That same article you read said it was fine to keep calling .NET 5, DNC, if you really wanted to.
Sort results by date, or only show last year.
Wondered who this new Scott was, and how many Scotts does MS really need!? Then notice the spelling mistake, and newer mind...
Webforms...
I haven't found one I really like...
What? You mean editing a table of data on the front end?
That sucks. Sounds like it started life as one of the thick clients from circa 2003-2004, where all the features were supposed to be independent and update via the observable pattern and delegates. I wrote a couple of those. Sounds like over time it evolved into a spaghetti mess with no real clear cut vision for the architecture. And of course scrapping it and doing a full rearchitecture is out of the question... I wish I could suggest something, but it sounds like it is at the point where your best move is to just start scaling down the number of projects by either pulling out core functionality into separate classes or combining the user controls into their own project...
I mean...yea, but particularly regarding, in-line, in-a-grid
Agreed. Client-side/WASM will be a bonus, but the development model in general is what i'm more enthusiastic about. And as i understand it- with the prerendering bits out there, lack of SEO is no longer a disadvantage of using it server side.
Yea, that's where I am at
The long-term game plan is to migrate it to a web interface and probably rewrite the spaghetti code while we're at it. We currently have one staff member working on this, it's not me, and the actual update is going to take years to complete. In the meantime, everyone else is working on the same spaghetti code, clients still need updates and custom work. And I'm not a decision-maker, I'm just the person trying to get it all to compile easily if we do 3rd party framework updates.
You guys could use wisej to port it to the web. I would still want to pair down the 1300 projects.
Project A shows a form from project B. Project C,D,E reference A for that low level functionality (im assuming) Can you not split project A in two. So that the part that is used for showing the form is separate from all the core functionality used by all the other projects
I know this isn't exactly what you're looking for, but if your use case is to allow some editing a collection, then I found [this project](https://github.com/danludwig/BeginCollectionItem) useful. It's good for editing existing records but if you want to insert or delete your own records, you'll have extend the functionality as I have.
The templates and scaffolding that ships with the out-of-the-box version often influences what organizations use and how they use it, for good or bad.
[Kendo](https://demos.telerik.com/kendo-ui/grid/editing-inline), if you're willing to pay for it.
Sencha Ext
Web-Forms :-)
Normally I have an action link in the far right column called ‘edit’ and when you click it it takes you to a new view where you can edit the data and save it. When you hit save it can return you back to the master table with the new updated data. The next thing you could do is make some jquery/JavaScript/Ajax voodoo to do all of that on the same view by just popping up a modal when the user clicks edit.
I built some js craziness to do it... it works really well but I don't recommend this approach
Yup, Telerik controls are excellent.
I’m sorry this happened to you. God speed.
Make sure you’re using some sort of concurrency check when you save. Without it, you won’t know if another user changed that data while you were looking at it.
Vue + Vuetify data table is super easy.
A good site is still usable even if JavaScript is disabled. There are a lot of factors outside your control that can cause JavaScript to either fail to load or to stop working once loaded, including network latency, browser extensions, varying levels of browser support for different APIs, user disk space, issues with CDN or DNS resolution, et cetera. &amp;#x200B; So a wise development team will first build the site to work without any JavaScript at all, then use a library to enhance the user experience for those who have it enabled. Vue in particular is very good at this kind of incremental, selective adoption. &amp;#x200B; This happens naturally to any site that cares about search engine ranking as web spiders don't execute JavaScript. It also happens naturally on bigger sites because they have important clients who aren't running evergreen browsers on modern machines.
I have had good luck with [Datatables](https://editor.datatables.net/manual/net/mvc).
That's all true. But even if you want to use any bootstrap beyond what's in the new project template, you still have to write it yourself. For whatever it's worth, I think I have seen some angular and react project templates as well.
For server side MVC this isn't bad: http://mvc6-grid.azurewebsites.net/ But usually if I need an editable grid I'm in client side JS land.
https://www.datatables.net/
\^\^\^ This &amp;#x200B; The team that decided that 1300 projects was a good idea really needs to have it highlighted at the top of their linked in profiles...
Darthavg sounds smarter than your decision maker :)
Are you running software that targets 4.6.2 or do you need the exact version 4.6.2 installed on your OS?
Ok, I made the regex parser, now how do I make it read HTML too?
I’ve worked on projects where I legitimately wanted to LinkedIn message the people that worked on it before me and tell them to crawl in a hole and die. It’s beyond frustrating that people basically come in and wreck shit then leave. I’m in a similar spot with a semi decent corporate website I’ve been hired to add features to and maintain. It’s a 12 year old webform app and it makes my eyes bleed every now and then.
[Domain Driven Design](https://en.wikipedia.org/wiki/Domain-driven_design) A great example exists on [Stack Overflow](https://stackoverflow.com/questions/1222392/can-someone-explain-domain-driven-design-ddd-in-plain-english-please/1222488#1222488). A simplified example. You have 3 projects. A, B, C. A needs to talk to B and B needs to relate the complex models or objects to A. Basically you relate A to B then both A and B to C. C basically just has objects with properties. No real code. Adding more projects farther down the road will be similar. Let's add D and E. B needs to talk to both D and E. Therefore you add references from B to D and E. D and E both reference C so they can communicate. Notice that in both examples C never references anything, therefore you are not circular.
**Domain-driven design** Domain-driven design (DDD) is an approach to software development for complex needs by connecting the implementation to an evolving model. The premise of domain-driven design is the following: placing the project's primary focus on the core domain and domain logic; basing complex designs on a model of the domain; initiating a creative collaboration between technical and domain experts to iteratively refine a conceptual model that addresses particular domain problems.The term was coined by Eric Evans in his book of the same title. *** ^[ [^PM](https://www.reddit.com/message/compose?to=kittens_from_space) ^| [^Exclude ^me](https://reddit.com/message/compose?to=WikiTextBot&amp;message=Excludeme&amp;subject=Excludeme) ^| [^Exclude ^from ^subreddit](https://np.reddit.com/r/dotnet/about/banned) ^| [^FAQ ^/ ^Information](https://np.reddit.com/r/WikiTextBot/wiki/index) ^| [^Source](https://github.com/kittenswolf/WikiTextBot) ^] ^Downvote ^to ^remove ^| ^v0.28
I used knockoutjs and created a javascript viewmodel class to handle interactivity with the grid and a data class to save the edited rows to database. Here's an example of editable grids using knockout: https://knockoutjs.com/examples/gridEditor.html Here's an example of paging grid: https://knockoutjs.com/examples/grid.html Here's another more detailed implementation: https://www.dotnetcurry.com/aspnet/1006/edit-html-table-crud-knockoutjs-aspnet-webapi
afaik its never illegal to compare a value type against null. it does generate a compiler warning, since value types are by definition never null.
I would recommend you read the book Legacy Code if you haven’t already. It gives you some good advice on breaking dependencies in dirty code bases.
&gt;After .NET Core 3.0 we will not port any more features from .NET Framework. sort of. wf, wcf, and some other big names won't be, but general windows support will be and ongoing effort, especially as they are comitting to core being the wholesale replacement. they will be prioritizing breaking stuff that real enterprises encounter. imo wcf and wf are a pain in the ass, but i don't see why they couldnt be ported (they call out wf already has been). hopefully appdomains die for good. hopefully the gac dies for good. hopefully framework references die for good. etc.
It is illegal in the specific case I mentioned: a generic type parameter with a `struct` constraint.
agree a million percent with regards to how this nonsense applies to mobile. nobody wants an "app" that is just a website. even electron apps have native capbilities. people want native experiences because *they work better*.
framework isn't going anywhere. you're fine. the migration path is: dont use wf or wcf or appdomains. for the vast majority it will just work (or so they advertise)
Theirs is actually the best strategy. And probably they make more money than you, and will have a job after you do.
What?
You need to figure out an equivalent to C# string.IndexOf(string) that can handle surrogate pairs in Unicode characters, with the unicode character you are using in your example. Here are a couple of resources on the subject if IndexOf urrogate pair Unicode: [source 1](https://stackoverflow.com/questions/50182335/what-is-a-unicode-safe-replica-of-string-indexofstring-input-that-can-handle-s) [source 2](https://stackoverflow.com/questions/4859023/find-an-array-byte-inside-another-array/26880541#26880541) [source 3](https://dogmamix.com/cms/blog/Finding-substrings) With this example code, you can see the Unicode character you are using as a surrogate pair since the length of the string comes back as 6 instead of 5. Console app code: &gt; internal class Program &gt; { &gt; private static void Main(string[] args) &gt; { &gt; string test = "♪Mary"; &gt; int indexUnicode = test.UnicodeIndexOf("ary"); &gt; Console.WriteLine(test.Length); &gt; Console.WriteLine(indexUnicode); &gt; &gt; } &gt; } &gt; public static class Extensions &gt; { &gt; public static int UnicodeIndexOf(this string input, string find, StringComparison comparison = StringComparison.CurrentCulture) &gt; { &gt; return IndexOf( &gt; // split input by code points &gt; input.ToTextElements().ToArray(), &gt; // split searched value by code points &gt; find.ToTextElements().ToArray(),comparison); &gt; } &gt; // code from another answer &gt; private static int IndexOf(string[] haystack, string[] needle, StringComparison comparision) &gt; { &gt; var len = needle.Length; &gt; var limit = haystack.Length - len; &gt; for (var i = 0; i &lt;= limit; i++) &gt; { &gt; var k = 0; &gt; for (; k &lt; len; k++) &gt; { &gt; if (!String.Equals(needle[k], haystack[i + k], comparision)) break; &gt; } &gt; &gt; if (k == len) return i; &gt; } &gt; &gt; return -1; &gt; } &gt; &gt; public static IEnumerable&lt;string&gt; ToTextElements(this string input) &gt; { &gt; var e = StringInfo.GetTextElementEnumerator(input); &gt; while (e.MoveNext()) &gt; { &gt; yield return e.GetTextElement(); &gt; } &gt; } &gt; } Hope this helps.
anytime scott guthrie's red shirt is referenced, [scotty](https://i.chzbgr.com/full/6311660800/hF80C9E42/) memes [come to mind](https://i.imgflip.com/1mnwik.jpg)...
and they always will because any increase of internet speed will be outpaced by bus and other architectural increases in PC tech.
And I thought my 500+ projects solution was a nightmare... I am in a similar situation (with a 15+ years old codebase) and one of the "smart" solution they thought of was to create a lot of interfaces and load the by name instead of referencing the dlls (in other words a kind of bad implementation of dependency injection). I have no advise except good luck. And know you are not alone in that kind of mess.
All I seem to get is legacy projects. I update them so they are consistent, using modern tech. Often huge sweeping wholesale changes which is astoundingly scary but the other option is worse... Then I get bored and change jobs. Rinse and repeat. &amp;#x200B; That is to say, work out an upgrade path for your webform app without saying 'rewrite from scratch!'.
Tell a bit more... which authentication method is the app using? What form are these IDs?
suffering from the same probleme
If the app requires network connectivity and it doesn't make use of any hardware specific to the phone, then consider not writing a mobile app. Instead, refactor the existing web application to be mobile friendly. Start with a toolkit like [https://getbootstrap.com/](https://getbootstrap.com/) (there are others).
With .net and frontend frameworks you still unfortunately need the initial default route (and controller) that renders your front end app to exist. The templates usually set you up with a controller that only has one action to load the index. You would probably still want a web api to serve up data though.
[Slickgrid](https://github.com/6pac/SlickGrid/wiki). It's javascript but I use it alongside MVC controllers via Ajax and bind its Dataview to .Net model classes via json. &amp;#x200B; There's a bootstrap version out there too.
You can get the list of users using your UserManager or EF. Code var users = context.Users.ToList(); public List&lt;SelectListItem&gt; UserList =&gt; users.Select(x =&gt; new SelectListItem { Text = x.UserId, Value = x.UserId }).ToList(); Razor &lt;select asp-for="Input.selectedUser" asp-items="Input.UserList" class="form-control"&gt;&lt;/select&gt;
Check Capacitor from the ionic team. They have a good get started guide. I'm on my phone and can't go into detail. The framework is beta but we use it in prod without any major issues.
What do you mean, what? Come in, work for a year or two, be super arrogant, leave a stinky brown pile, get a new job with a big raise, rinse, repeat. Soon you will be a SVP, director or CIO ... stop worrying about code quality or good architecture, only losers worry about that kind of stuff.
I used a custom Signal-R interface to HandsOnTable (with TypeScript bindings). Been meaning to open source it but our open source projects don't seem to get much traction making the effort rather unappealing.
Remove the first ToList.
Ok. It’s not meant to be followed directly, but hopefully start him in the right direction based on the little information provided.
You were looking for: https://www.redditinc.com/advertising
Only web devs seem to think desktop is dying. At workplaces people absolutely despise enterprise web apps and always want the desktop version if it exists.
What is the alternative to WCF? Over the course of the last years learning .NET I've been given the impression that people just ignore completed frameworks that offer solutions for 90% of use-cases, write their own code that handles a single use-case, and then spend lots of time adding more features that the framework already provided out of the box. At first glance many of these modern solutions look like someone thought take a tiny bit of functionality from established libraries, make them easy to use, it gets popular because apparently learning framework APIs takes effort. Then people forget about the more advanced use-cases and how much work it would take to implement in the new library. Am I wrong?
Considering how long the maintenance/support phase lasts for most Microsoft products, .NET framework apps should be safe for at least the next 5 years.
.NET 5 is actually clarifying the current .NET/.NET Standard/.NET Core confusion.
Would be cool to see some comparisons with [Utf8Json](https://github.com/neuecc/Utf8Json)
Timing, I reckon
You can take a look at this template as an example or starting point. GitHub: [https://github.com/danijelh/aspnetcore-vue-typescript-template](https://github.com/danijelh/aspnetcore-vue-typescript-template) Medium: [https://medium.com/@danijelhdev/multi-page-net-core-with-vue-js-typescript-vuex-vue-router-bulma-sass-and-webpack-4-efc7de83fea4](https://medium.com/@danijelhdev/multi-page-net-core-with-vue-js-typescript-vuex-vue-router-bulma-sass-and-webpack-4-efc7de83fea4)
This guy codes
DevExpress
Might be a better idea to take a course on .NET Core and not just assume you know it because you know .NET. You'll save a ton of time by not wasting it on these little differences.
Really? Long ago I had to use Telerik controls for WinForms in the past and they're were nothing more than a massive dumpster fire. Slow and riddled with bugs, everytime they released an update to fix some of the bufs, many new bugs were introduced. Their product simply didn't work in the real world.
In similar situation. Have used a lot of the flexibility of WCF. Have a large micro service stack on wcf that has lived longer than the term microservice was being used. There is no way in hell we are getting the approval or funding to ever replace it. On the periphery we also have a soap service that is used by a few hundred major clients that implements WS-\* and a few other of the WS bells and whistles from the olden times. Abandoning SOAP and WCF is expected though as the attitude from Microsoft has been "Fuck the customer's needs" for quite some time now.
What's vuetify about? Why do I keep hearing about it, whats so great?
Accidentally?
I agree, I had to use Kendo in two projects and it’s only good if you have to display simple table with data, nothing more. Anything else is a pain in the ass and duck tape hacks to make it work.
Can you elaborate more please
Please don't pay for Telerik controls. Telerik is a cancer on the .NET ecosystem.
There is none. Basically WCF users are screwed.
Well, first you do \\s\*&lt;\\s\*(.+)\\s\*&gt; then you go to ~~hell~~ heaven
Service Fabric came first. It was MS’s way to build their own cloud. I think Russinovich ran it. Google was ahead of them, and built K8s, then released it open source. It pretty much ate all of Service Fabric’s lunch.
Service Fabric came first. It was MS’s way to build their own cloud. I think Russinovich ran it. Google was ahead of them, and built K8s, then released it open source. It pretty much ate all of Service Fabric’s lunch.
literally every blog or video that talks about deploying dockerized [ASP.NET](https://ASP.NET) Core application to Heroku uses default mvc template and never talks about the database. In real world if you are going to deploy a [ASP.NET](https://ASP.NET) Core app you will have a database with it.
If you want something that is javascript/ajax driven (i.e. has no postbacks), I've done nice things with [ag-grid](https://www.ag-grid.com/). If you want to expose large datasets, their server-side data source can save you a lot of time with built-in lazy loading for the data.
I used Telerik controls in an MVC app I wrote 10 years ago. Saved me probably a month's worth of work. Was worth it in my opinion.
Hmm... Interesting. I used Telerik controls in an ASP.NET MVC app I wrote 10 years ago. Seemed fine then. Maybe they've changed since then...
They aren't screwed if they can just continue using WCF. If there's no alternative then WCF still has a purpose in the world, but no one seem to be able to tell me exactly what that is. What does it solve if on one hand people say I shouldn't use it on a new application, yet at the same time there is no equivalent framework I should be using? Has the problem it solves gone away?
Service fabric integrates with your applications to give you features like [reliable collections](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-services-reliable-collections) and an [acotor framework](https://docs.microsoft.com/en-us/azure/service-fabric/service-fabric-reliable-actors-introduction). There's some more stuff like that too.
I think pretty much everybody was thinking that too even though Microsoft was repeating `noooo don't worry .NET Framework will ALWAYS get the latest features too`
If you don't want containers, SF is for you.
Might have saved you time back then, but now the app is dependent on Telerik licensing and compatibility updates. There are so many free alternatives out there. It's worth it to look for them.
Haha A+ trolling.
Here is s list of reasons cited by people who use WCF https://www.infoq.com/articles/WCF-Net-Core-Debate
I think the idea is to actually rewrite it to write away all the awful design pattern. It's just going to take a very long time and we need more than one staff member working on it. Okay, I pseudo lied, we also have the boss's son working on it over the summer while he's a student. Go go gadget nepotism!
As little as possible, in my opinion, and as high up in your code as possible. If you're referencing a container everywhere in your code, you've tightly bound yourself to that dependency injection framework. Ideally you'd do constructor injection wherever your can, and then you can just let your DI framework do the work of satisfying those dependencies for you.
SF can be used with and without containers.
At the same time, use constructor injection everywhere you can, in all classes that you can get away with it in.
There are too many databases and ways to deploy them to even briefly go through in an article that focuses on essentially something else.
Our decision maker has been coding for a long time at the same company and hasn't done ANY studying on modern design patterns.
It sounds like your first step is to get Project A to not reference other projects directly, since it has the low level logic. One approach is to replace direct references to other projects with events. Those projects should then reference Project A to subscribe those events and launch their own forms or whatever. The best thing to do overall is probably to get a general sense of the program functionality, which bits depend on which other bits, which bits each part NEEDS to depend on, and then how they are distributed between projects. You may find some pieces make more sense in different projects.
Typically just apply it on Controller creation and fill out the dependency graph, though there are some situations where infecting the service locator into a factory can help with complex construction scenarios. But maintain a strict separation between your business logic and resolution root classes (such as factories).
I avoid inline grid edits. I always do a modal window or link to another page. I have had too many instances in the past where a simple edit row eventually evolved into a complicated form. Programming complexity aside, often the lack of screen real estate becomes a problem too. Good luck.
The only thing this method for is return a complete task. It is non blocking.
Task.FromResult creates a Task that is 1. Complete 2. Contains a value *** a= await TaskFromResult(x) is just an inefficient way of writing a = x.
That's a good point. There are plenty of critical business applications made with Webforms, and porting them won't be a quick or easy job. Fortunately, I think Webforms has been pretty much feature-complete for quite a while now. Companies that depend on Webforms apps can probably plan to transition away gradually over the next decade or so if they need to.
I understood it is blocking from this article: https://blog.stephencleary.com/2012/07/dont-block-on-async-code.html
You are thinking about task.Result.
Silly code a = Task.FromResult(x).Result;
Ah, yes. In article Task.Result. Sorry for confusion :(
No worries, we all make that kind of mistake
Honestly, Project A references very little besides a few other config projects. Project B's form is one of the FEW exceptions. The forms in Project B are called from a right click menu generated in Project A and I just don't know how to generate it without just extending the loop by adding a project inbetween. I feel like this MIGHT work, Project A A.iUcB Project B frmB:iUcB ProjectMain MainForm.ProjectA.A.iUcB = new frmB(stuff) but then I think about Project X, Y, Z that decided they needed their own Project A instead of taking the instance being passed around by ProjectMain, and I balk at the idea of hunting through 1300 projects for the 10 that do this.
If you're talking "Dependency Injection" in general, you should use it, as a principle, as much as possible. Try to use interfaces and avoid instantiating one class inside of another, dependent class, but rather pass it in via the constructor. If you're talking, specifically, about using the IoC container to directly resolve dependencies (ie. container.Resolve&lt;IMyService&gt;()), then you should do that as little as possible. The container should only be used directly when you're registering your dependencies (bootstrapping) and in rare cases where you're building some advanced resolution logic, such as if you're developing a framework or something.
It's an ERP, so I sort of get it, but I feel like at LEAST, the layered approach probably would have worked better. WHY did they not decide on a data access layer? At least, that's the design pattern they taught us when I did school....
Root Composition is the only place you should be using/setting up an IoC container (DI)
Project A only needs Project B to show a form. Project B needs Project A so it can pass an instance to every child usercontrol.
I would say in an application that uses a hot loaded plugin architecture and an IoC container to control dynamically registered services, the classes responsible for managing the plugins should also use the IoC directly...but that's about the only exception I can think of.
Why do you care? Your app targeting 4.6.2 will run on 4.7.2 when it’s being run on newer windows machines
 a =await Task.Run(() =&gt; Task.FromResult(x).Result);
TLDR; GraphQL gains popularity I see so many words but it’s only a bunch of graphs wrapped with filler words. Had hoped for more.
Really nice "minimalistic and easy to use" WPF MVVM example, but at the same time containing advanced concepts. Should be plenty of use for students trying to learn. Ideas: 0) imo, a simple CRUD app is best example. Maybe add code that shows how to CUD your records? 1) somehow lacks examples of `DelegateCommands`. Questions: 2) why didn't you use a MVVM framework (like Prism) ? 3) why no Dependency Injection?
`Task.FromResult` is what you use when the method needs to return a `Task` (e.g. you are implementing an interface or abstract class), but this specific implementation doesn't need to be async. `Task.CompletedTask` accomplishes the same purpose when the return type would otherwise be `void`. Unit test mocks are where I find myself using these structures the most because I am simulating what would otherwise be network calls.
https://www.youtube.com/watch?v=7uW47jWLMiY
lol pdf
It's a UI Component collection for the Vue.js framework. Its kinda like Bootstrap, but more modern looking and has more features.
pdf is good for printing. what you need LaTeX? Word? i can check it in.
But Kubernetes cannot.
I think it might depend if you are already in an async method. awaits can still return synchronously if the task is completed, so there wouldn’t be a context switch. Difference would be that using await creates the state machine for the method, and that does add overhead if you aren’t otherwise in an async method, but that’s compile time rather than runtime Slowest step is allocating the task through, Task.CompletedTask or a cached task would be preferable if you can
Put it in the README....
ok
I've been hosting my .NET Core / Angular App on Heroku for about a year now using this [dotnetcore-buildpack](https://github.com/jincod/dotnetcore-buildpack) (well, a private fork so that the created slug is smaller, but it's the same idea) and it's working fine. Why go with a custom Dockerfile? What's the benefit?
Pretty sure “a = x” still wins this one :)
You got nullable the wrong way around. If you declare it as you did in the example, it will not give a compiler error, but allow assignment of null. If you use nullable as compiler flag, and don't make it nullable and then either don't assign it or assign null, you get a compiler error.
i have tested before few months. it was giving a warrnig. i will test it again and give you a feedback.
This is great, precisely what I'm looking for!
Nice, thanks!
thank you :)
[removed]
Also used if the method is sometimes async. Say it checks a cache and uses FromResult or a TaskCompletionSource as appropriate.
The point is that it’s not always an option. You may need to satisfy an interface that requires a task
How about deploy a db to a docker columned and call it a day?
How about deploy a db attached to a docker volume and call it a day?
You are missing a couple of `.ConfigureAwait(false)` and `ContinueWith` /s On a serious note, this is not even funny, I've seen variations of this too many times :( &gt; But I want my async function to yield immediately. No, you don't. In the extremely rare case you do, use `await Task.Yield();`
Man, that sucks. Tbh, if it were me, I’d just get a new job and let those clowns deal with their own mess.
Totally unnecessary Task.Runs are quite frequent in a lot of async code I've seen. That starts a new thread -- if you're waiting on an external dependency you don't need the overhead of an entirely new thread. That's why the await keyword is there -- it's just a callback.
Well, Task.Run doesn't usually create a new thread, unless paired with TaskCreationOptions.LongRunning (and even then, I don't think a new thread is guaranteed). What it does is it schedules the callback on the thread pool queue. Still completely unnecessary if code inside is actually async, except for some very rare corner cases.
The question was specifically about "a = await Task.FromResult(x)" not about implementing a method in an interface that's defined as returning Task&lt;T&gt;. In that case you'd return Task.FromResult() directly - NOT "await Task.FromResult()".
Now I'm curious: I thought that it actually scheduled the task to run on another thread (not start a new thread sorry). Meaning you get more overhead than a simple callback, but it's useful if you have a big computation to chew through. Basically, you should parallelize with Task.Run if you actually need to parallelize, and you use await as syntax sugar to hide the fact that you're doing a callback method. Let the CPU do something else and come back later. How correct am I?
The JIT is smart so you don't have to finish sentences.
I've been trying to move towards using the MVVM pattern, but even for a relatively small project, the traditional project structure became quite overwhelming. I can't believe I haven't stumbled upon the feature based structure before! Seems like it'll make it much easier, so thanks for that. Will watch for more examples :)
No, question was about the difference between them “a = await Task.FromResult(x)” This is a contrived example with obviously no use. But if you have a method that returns Task.FromResult, then the consumer will have to await that call to get the results. The main reason for a synchronous function to return FromResult is an interface
He initially asks: &amp;#x200B; "in async method await can be put in front of Task.FromResult" &amp;#x200B; He does not ask about awaiting the return of a method. &amp;#x200B; But anyway, you are correct in the point that you are making as well. So all good :)
Task.FromResult is typically a way (at least for me) to implement a synchronous function that returns a Task. Normally this is not useful but if you have a base class or interface that defines an abstract function that returns a Task (because it is meant to be async) but your implementation does not actually need to do any async work, it's useful.
Yes, that's correct, it runs on another thread, which is already created, or it can potentially start a new thread if it is a cold start, depending on the parameters of the thread pool. Wrapping a CPU-bound code in `Task.Run` is usually a good idea. From the flow perspective you will not see the difference between `await Task.Run(() =&gt; callback());` and just `callback();`, but you will free up the caller of your function to do other stuff. I like to illustrate this with a socket server main loop example (pseudo code) while (listener.Active) { var socket = await listener.AcceptAsync(); HandleConnectionAsync(socket); // do not await } Assuming that all the logic for the error handling is in HandleConnectionAsync(), this implementation can handle multiple parrallel requests perfectly well, but if the function is completely synchronous, it will have to wait until the connection is closed untill it can start handling a new one. So, wrapping your heavy computation in Task.Run makes sense, since then the handler will yield and a new connection can be accepted. But if all the synchronous parts are very fast, the overhead of yielding to the thread pool, context switches and GC pressure can add up. On the other hand, it is still pretty cheap from performance perspective. For me, superfluous `Task.Run`s smell because I consider them a signal of intent that there is heavy computation happening inside or something else that requires more careful review.
The way you do this is completely different. All the .as?x files are gone and replaced with pure C# in some form or another (except .aspx are now .cshtml). It might be best to look up some sample projects and look through the code.
Hmmm... yeah. you're probably right. It *was* MVC 1.0 that I developed for. :)
Usually not, actually. I typically focus on algorithm questions rather than technology specific question. There just isn't time to deep dive into WPF minutia (for example). Google "top .net interview questions" and read the trivia, but mostly brush up on recursion, loops, OOP, data structures (SQL). Be ready for whiteboard questions. &amp;#x200B; Also, be cool. Nothing worse than an applicant knowing all the answers but you can't work with them because they're super weird / lazy / awkward. &amp;#x200B; And speak clearly, the more you own the room the less "stump the chump" trivia you'll encounter.
Be well-groomed and smartly dressed, be 10 minutes early, be enthusiastic, be agreeable, be humble, be informed (google their company + their products/services + their business market). They want to know: can you do the job, do you want the job, do they want you on their team. Source: interviewed many many candidates for large orgs.
What if inside one of nested async functions I make synchronous call to DB. Does it make all of this calls synchronous down the line? Or blocked thread would be the one from which this call to DB was made?
Don’t be afraid of “I don’t know”. Don’t BS... your resume explains it all, just ensure you’re able to speak to it and you’ll be fine.
As a fresh grad, demonstrating enthusiasm, aptitude, and knowledge of core concepts are going to be most important. As entry level dev, most people interviewing you are looking to see how much hand holding you'll need and how eagerly you'll be learning on your own.
So what's the catch? No spatial data types? No SqlDependency? Or is this really going to be a 100% drop-in replacement?
I usually ask devs to start talking about their work experience and I'll start drilling down whatever path they present me. It's not hard to smell bullshit, and I'm uninterested in playing kind games or getting someone to give me an exact key word. That said, interview styles are aplenty. Best thing you can do is be comfortable talking about what you know and honest about what you don't.
[removed]
Null coalescing assignment is more realistically shortening variable = variable ?? expression; to variable ??= expression;
I really don't have any good advice for you. I'm gonna ask you about your current projects and the problems you had with them. Then I'd ask you about scaling then up and how much money you think it would cost. Then how much you could reduce that by using a different solution. I'm gonna ask you about automating the process so you can focus on more features and what features you wanted in your projects. Then I'm gonna ask you to show me the project we've been talking about. 9/10 people can't show me the project. I haven't hired a single one of those.
This feels like it has nothing to do with stores but you're using that as a cover story to find your solution. Further you think you know what reliable services, stateful and stateless and actors mean but you're mistaken and don't know it.
Typically you don't want to do any long-running synchronous calls. If you have an API that does not have an async function, then you can wrap JUST that call in a Task.Run and await it, as a quick and dirty way to async it by throwing it on a new thread. However be careful none of those objects you're using are not going to be mutated by other tasks or threads since now you're dealing with multithreading. I am not sure if that is the best solution or even a good idea but it has worked the places I've tried it. But in generel think of an async function is a bunch of synchronous stuff in between all the await calls. All an await call does is tell the Task system that it should go and do something else until the call completes, then come back and run more of your code. So until you hit an await, it can't go and do other things. So in a WinForms app "others things" is handling user UI interactions, for example. It also helps keep CPU usage down since you don't have to explicitly poll or wait for something to finish, you have a one-liner that you understand to mean it's going to wait for you.
They claim they are just moving the code base outside of .NET so that they can release it more often, but the timing coincides with splitting off EF, removing [JSON.NET](https://JSON.NET) and removing support (in [ASP.NET](https://ASP.NET) CORE) for .NET Framework proper. Its kind of stretch, but I wonder if they are trying to slim things down in preparation for AOT being part of the tooling in .NET 5.
I doubt that AOT is relevant for this, but it may cause problems for EF.
If this is all you’re trying to do, ef would be quite overkill.
Learn the MERGE command in SQL. It is very useful for this situation.
You are an MVC OG.
While I don’t disagree I’m modifying existing code that has been ok up till recently. Just trying to optimize the best I know how to.
Thanks I’ll check this out!
Oh no.. I mean to use this as Learning path. I will commit to GitHub if all goes well. No gimmicks. I am at crossroads of changing career and looking at cloud dev or operations as next step. Thanks Though!!!
About Exchange yes I was mostly referring the Managed API, which is indeed OOS but without official support for .net Core. Many issues about this on the github page, including a fork that fixes most problems. However, using some unsupported fork is not exactly a great option for an enterprise solution - MS obviously abandonned that use case. I've never interacted with Exchange using powershell so that's intriguing to me (I'm no Exchange expert). Calling powershell scripts from a .NET core project doesn't really appeal to me at first sight, but I will keep it in mind! All that said, I do respect MS for pushing forward in general even at the cost of the holy grail of compatibility. It's great in the developer space, but not so much for enterprise applications unless you go all-in on cloud as they obviously want you to.
The managed API is just a wrapper around the REST calls which are just plain HTTP calls. .NET core can totally do that.
We run Exchange 2013, and it seems the REST API was added in [2016 CU3](https://blogs.technet.microsoft.com/exchange/2016/09/26/on-premises-architectural-requirements-for-the-rest-api/). This is actually TIL for me, thanks!
No, the API has existed since the 2007 era. Refer to the XML sections here for an example: [https://docs.microsoft.com/en-us/previous-versions/office/developer/exchange-server-2010/hh532558(v%3Dexchg.80)](https://docs.microsoft.com/en-us/previous-versions/office/developer/exchange-server-2010/hh532558(v%3Dexchg.80))
Those samples are using the EWS managed api however - which is presumably calling the SOAP backend and isn't supported/compatible with .NET core. No?
We use SF heavily and found out at build that they are reallocating resources away for SF development. Yeah proprietary systems!
Corert can play nice with some reflection (if you want it to), but it can't handle runtime code compilation. I was just thinking they might be slimming down as a way to reduce compile times, but now that I think of it, I don't see how unused libraries would have much appreciable impact on AOT. Maybe I was thinking about the output file sizes of the single file bundler that just released in 3.0 preview 5
We use it for both soap and non soap distributed micro services. Its bullet proof and takes a steaming dump on any of the current .net core offerings that require an epic shit ton of infrastructure code compared to a web.config file and 2 lines of code. Im not talking about soap either. Been using protobuf on it for years. But because the cult of "its too hard" seems to have won over at Microsoft are now legacy.
The bandwagon is actually a short bus when it comes to enterprise needs and .net core with the WCF attitude. In hindsight this is going to be looked at as the time when Microsoft dev leadership smoked too much of the Seattle weed.
WCF allows you to basicly plug in any transport you want along with a pretty wide range of built in ones. Out of the box it provides soap for message exchange and metadata. Protobuf and json have been available for a long time. It doest have a learning curve because it abstracts a lot from you in terms of configuration and code. That is the strong point. You are not writing piles of infrastructure code. Most of the .net core examples I've seen of half assed distributed clients have you building all of this stuff from scratch. But its the new shortbus Microsoft mentality these days. Guess I need to get with the program and embrace the reinventing of the wheel.
Its officially dead. They took it out back behind the shed and shot it after giving it a good rogering two days ago.
No WCF = its a short bus
Until the WCF debacle is addressed for enterprise customers its a shortbus.
There’s no forcing to upgrade, but it is the future. As of Monday .NET 5 is what’s next which will be the next version of core.
Hahahaha. Indeed I am. :) I still have my original Pro ASP.NET MVC 1 book on my bookshelf: https://www.amazon.com/Pro-ASP-NET-Framework-Steven-Sanderson/dp/1430210079 What was remarkable about this book was it covered: * MVC * Dependency Injection (IoC containers) * Unit Testing and TDD * n-tier Architecture * ORMs All in 1 book in a current and relevant topic. It's one of the best books in software engineering that I've ever read. And the irony is that it wasn't trying to be a software engineering book, but the author did a really great job of covering all the bases well.
This. There are a lot of reasons why WCF is employed out there. Because its cool is not one of them (anymore). The current cult of reinvent the wheel and disregard 13+ years of a successful distributed communications and extensibility framework is dumbfounding.
Very interesting. I should have picked that up back in the day.
Well if he has implemented self hosted WCF services using anything other than basic http binding he has no options or has to pretty much rewrite everything that WCF is currently doing. If that is going to cost anything other than free then yes that is actually absurd.
Got WCF yet? Nope? Hell the last time I tried to get Spatial/geometry types from Sql to work it was a god damn CF [https://github.com/dotnet/corefx/issues/31775](https://github.com/dotnet/corefx/issues/31775). Wake me when its working for enterprise customers.
The current version of the Pro ASP.NET MVC book is still very good. I think I have the latest copy on my shelf. I haven't written an ASP.NET MVC app in a long time, but I still like keeping up on ASP.NET MVC.
What do you development wise these days?
Does IL2CPP play nice with reflection?
Didn't they plan on having a hybrid AOT wherein there's a light weight JIT still running on the side to handle Reflection and Dynamic compilation. Though this model most probably won't work on platforms that doesn't allow JIT at all (IOS comes to mind).
I don't have any experience in Unity, but a quick look at the [documentation](https://docs.unity3d.com/Manual/IL2CPP-BytecodeStripping.html) implies you need to give some hints to the bytecode stripper for it to play nice with assemblies that contain types you might reflect over.
Reflection seems to be mostly controlled by flags put as properties in the project file, but dynamic IL generation is unsupported today. It looks like there are some [issues discussing strategies to implement it](https://github.com/dotnet/corert/issues/5011), but I don't see any milestones or design docs.
Its just about making stuff be able to update on an independent cadence.
Python/Django, sadly. It's not nearly as powerful or flexible or as easy to use as C# / ASP.NET MVC. :(
There are XML examples of the requests that the managed API would send to perform the same functions. It's just the managed API wrapper around the SOAP calls that isn't officially ported to core, which... is really just a wrapper around the SOAP calls. &amp;#x200B; Do you need something special to call a SOAP API? Isn't it... just XML?
what is AOT?
Ahead of time. It means compiling to machine code without an IL / JIT step in beweeen.
Hi, and thank you for your awesome feedback! I will definetly add this to my Todo! Posting issues is always welcome as well! :) I will start on the CRUD and Dependency Injection examples immediately.
is your hiring pratcice basically just "do you work outside of work hours?". It seems so lol
The “IN” keyword executes as many “OR” statements which can be inefficient for long lists; it is usually faster to put the values in a temp table and join. If you are getting timeouts, also check your indexing and lock behaviour; setting WITH (NOLOCK) on the table you are reading from may help. It’s difficult to offer advice on EF without seeing your code but I will say I find it easier to manage SQL code of any complexity in stored procedures and just call the procs from EF. It’s also easier to maintain the SQL code that way.
Good to hear. Is there a blog that shows-off the differences between the 2 binaries inside in the package?
Did not use Prism because I think it is to large of a dependency for no value (yet). So far I can mange without it. In fact, in most of my projects at work I can mange without it. The idea with this open source prooject is to keep dependencies low, as they can tend to hide the magic stuff that actually does the work.
Anyone knows the limitation of the Core binaries inside that package?
Added Dependency Injection now. &amp;#x200B; [https://github.com/haavamoa/xaml-code-experiences/tree/master/xaml.experiences/architecture/designpatterns/dependencyinjection](https://github.com/haavamoa/xaml-code-experiences/tree/master/xaml.experiences/architecture/designpatterns/dependencyinjection)
I've found it totally valid to use stored procedures in cases like this. EF gives a lot of benefits but doesn't always pick the best/ most efficient SQL and sometimes you just need to get closer to the metal.
Yeah, in the blog post they mentioned a hybrid AOT and a full AOT for cases like iOS.
That is CoreRT, they will be using the Mono runtime that has an interpreter and JIT already for use in AOT scenarios.
That was one of the reasons that they went with Mono instead of CoreRT.
This sounds great. Appreciate your help!
Thanks, that's a nice writeup. It has convinced me that WCF is still relevant for future development and that people are simply ignoring more advanced and complex problems with communication, and only learn the very basics.
So if there's already a nicely consolidated communications API, why are people calling it dead because of ONE new easy-to-use single-protocol (http) API? That's ridiculous -- is this a leftover mentality of ignoring MS libraries because it was popular to dislike them a decade ago? It feels like all these modern solutions boils down to just doing surface-level problem-solving and saying it's good enough because it's so easy to use. Yeah, easy because it's surface-level and solves one very specific thing. Then it becomes a mess as when they have to implement more advanced use-cases, if they bother at that point. I'm still very confused why so many APIs are being ignored.
If I can use this in a .NET Core project to just do [ADO.NET](https://ADO.NET) natively - I'm gonna be super psyched. Been waiting for this for a long time.
`Task.FromResult` is not async. It is always called synchronously and hence never blocks.
Prism makes a lot of stuff easier, but only in big apps (100+ views, etc.) But I agree, it is probably better to keep a small, demonstration app like this.
What does this mean for those of us that use Entity Framework?
Your post has been removed. Self promotion posts are not allowed.
Who said that? Have they released plans for how AOT will work in .NET 5? I wasn't able to watch every minute of the build stream. The article I linked says they should use the Mono interpreter, but the first response from someone from Microsoft is that they should build their own because the Mono interpreter won't play well with other runtimes.
Could be worthwhile to just cache the task itself and then just return that instead of creating a new one.
The .Net 5 announcement covers that there will be two supported runtimes CoreCLR and Mono on top of a single BCL (CoreFX). Mono will be used for AOT scenarios. In Build there was a question on one of the .Net q&amp;a panels specifically on CoreRT and Scott Hunter said that they would have an AOT solution and that Mono is it. Furthermore on the CoreRT repo one of the maintainers said that he will continue to support on his own time with community support but MS wasn't putting any weight behind it anymore.
You meen like the way the Oslo wave and crApp Fabric was the future? Or how WinFs would change the world? Look man been in this game a long time. Microsoft pulls this shit every few years. It doesnt always pan out. There is no way this is going to get serious enterprise traction or even within Microsoft's own products without addressing the huge gaping holes that have intentionally not been filled in. Dismissing customer's needs and asks is not a way forward.
&gt;Or is this really going to be a 100% drop-in replacement? Not a "100% drop-in replacement", the way I'd use that term, because you have to adjust all namespaces at least.
Its not a replacement for WCF. Not even close. It handles one single use case and is more like .net remoting. Especially in implementation. No thanks.
My example isbased on this example: [https://msdn.microsoft.com/en-us/magazine/mt829270.aspx](https://msdn.microsoft.com/en-us/magazine/mt829270.aspx) &amp;#x200B; I have test it. it still give a warnning. the text is changed, but is still works fine. Maybe I will change the example with otehr one,
If that's all its close enough
True. Maybe store it directly in the cache.
&gt; Is this a case of people making it complex or convoluted by trying to do too much in one place, or is the very baseline configuration a lot to understand? I blame the documentation, which focuses on the overly complex XML configuration and doesn't describe key points well enough. Once I learned to ditch the XML config and do things in code it was a lot easier.
Ahead Of Time
Probably nothing as EF barely scratches the surface of SQL Server's capabilities. But they could change the dependency without affecting your code.
I'm not sure that this is the best way but if you're starting with a list of values couldn't you take that list and query the table for the values you want to compare and then do a LINQ Intersect to find what matches?
Likely nothing, the existing provider will work for quite some time. This is a brand new announcement, EF is prolific as is Dapper. No one is recommending you start dropping this into prod now.
using System; using System.Linq; using System.Collections.Generic; public class Program { public static void Main() { List&lt;string&gt; sourceValues = new List&lt;string&gt;{"Apple", "Orange", "Pear", "Banana"}; List&lt;string&gt; fromDbValues = new List&lt;string&gt;{"Apple","Pear","Banana","Cherry"}; var intersectedValues = sourceValues.Intersect(fromDbValues); foreach(var val in intersectedValues) { Console.WriteLine(val); } //Results //Apple //Pear //Banana } }
This has already been posted. Discussion can be found here: [https://www.reddit.com/r/dotnet/comments/ble2lw/introducing\_net\_5/](https://www.reddit.com/r/dotnet/comments/ble2lw/introducing_net_5/)
Ooops, sorry and thanks for the notice
I put them in readme. just copy paste. I will format them texyst later. [https://github.com/alugili/CSharp8CheatSheet/blob/master/README.md](https://github.com/alugili/CSharp8CheatSheet/blob/master/README.md)
This is super cool!! I’ll play around with this
Ok, so they are merging the corefx implementations so that running on Mono or .NET makes little difference, and using AOT compilation with the Mono runtime when AOT is needed because the Mono LLVM backend gives them access to many more types of devices and LLVM is powerful in its own rights. I found the comment you mentioned in github. They seem confused about Microsoft's stance on corert. I hope Microsoft reaches out to them. Its sad that they weren't contacted before the conference.
It seems like the MS guys involved with RT were informed and so only did RT work out of hours or on things that would make sharing code between the runtimes easier. Sucks a bit for the community that they didn't know, but several of them still seem happy to keep pushing RT forward as a community project.
Thanks!
Thanks!
They claim they are lucky that they get the bulk of the work by being in lockstep with other projects, so it isn't difficult to maintain, and it appears there are some substantial benefits to corert if you don't need to target WASM or currently unsupported devices/platforms. There is a lot of time between now and .NET 5. I'm not convinced they won't make any changes to their plans between now and then.
The catch... "There was no magic code merge behind the scenes: we still have divergent code bases from .NET Framework and .NET Core (for now). "
Mono is already shipping and is mostly feature complete. CoreRT seemed like a cleaner more performant initiative but it never really made it past experimental. I do think it is good Microsoft picked one technology to invest into. I just hope that even though the implementations are quite different some of the CoreRT goodness makes it over to Mono. Lastly, it is possible the community do enough to make CoreRT another drop-in runtime. I suspect getting the toolchain working seamlessly might be a challenge even if all the runtime pieces come together.
I deal with hundreds of our enterprise customers and I can tell you people aren’t just moving, they’ve already moved. The amount of non-core .NET conversations I have is less than 10% and never about new development, mainly about porting or maintaining legacy apps. It already has traction everywhere.
That's like saying "trains could be the downfall of railway lines".
How are you appending the ' #tabs-3 ' anchor?
I was under impression that synchronous code is blocking because execution happens in the same thread. Correct me if I am wrong.
Thanks, so does this just mean faster builds?
Hi and thanks for the reply, it made me search on another directions as well, but no better results :( It is created with this, in the same .ascx-file: &lt;% var id = Model.Product_Id + "#tabs-3"; %&gt; I just tried to change that, build the string with HTML.Raw, HtmlDecode, Encode.. Nothing.. Always the same result.
We have a few hundred enterprise customers still on soap that would disagree with you. Not saying we don't create restful interfaces too. Wcf is not just about soap. If you were only ever using it for soap or http calls it was already too heavy of a tool for that. We use it for that along with protobuf some integration scenarios and a lot more. Its an important tool for folks that arent just throwing up a web api.
No, it means way slower builds but faster app startups and maybe some better optimizations here and there. It also means a larger binary.
No offense but writing wcf off as old and soap as its only use just exposes your lack of understanding the problems that wcf solved not only for your employer but the entire echo system.
Can't stress this enough. With most junior positions I'm looking generally for whether they have some technical ability but otherwise I want them to been keen to learn and personable. You can teach technical skills with .NET, but you can't stop people being arseholes (generally)
"blocking" means that the calling thread is waiting for another thread to complete. If the execution happens on the same thread, there is no blocking. It just follows the same execution flow as a usual method call.
.NET isn’t being discontinued, just none of that stuff is in the new version because there’s no need. Nobody should be using soap for new development, if you are you’re about 10 years behind the times and making poor decisions. Nobody is saying you have to move existing projects off of .NET 4 - but for anything new you should be using modern patterns and practices which .NET Core/5 greatly enables.
The binary would be much larger compared to a framework dependent application, but (potentially) much smaller than a self contained or single file bundled executable.
I think handling runtime code compilation was the most important difference. There are quite a few existing libraries and a lot of legacy code out there today that already depends on runtime code generation / compilation and corert can't support that.
Joining against a table valued parameter is a lot faster than an IN clause. You can do it through EF using FromSql.
Yep that would be a big part of being feature complete. The CoreRT community are working on an interpreter, but it is only a prototype so far. So it was less can't, but more hadn't in time.
Grpc does not address why people are asking for still use wcf. https://www.infoq.com/articles/WCF-Net-Core-Debate
You seem to be drinking the “if we didnt shit out the beta 2 years ago its legacy” coolaid. You guys only just added transactionscope to core ffs. This just shows how out of touch dev div has become these days.
Throttling, behaviors, ability to control the message headers, and about two pages of features built into a framework that keeps that shit far from the code none of which have equivalent features in core. Grpc does not address this stuff. The next person that says grpc replaces wcf is getting kicked in the balls.
Not part of dev div. Just someone working directly with customers every day. I think you’re pretty close minded compared to where most people are and that’s unfortunate.
Things wcf can let you do in 2 lines of code and a few config entries. None of this has an equivalent in core and we only just got transactionscope. A transactional queuing programming model Behaviors Bindings Context Contract based programming model Contract Behaviors Contract-based Coding Model Discovery Durable services Endpoint Behaviors Extensibility Extensibility model Headers Instance Management Interception-based Pipeline Message inspectors for instrumentation and access to SOAP headers Metadata Exchange MEX endpoint and MEX framework Named pipes Net.Pipe Binding Net.TCP Binding NetTcp (half-duplex) Operation Behaviors OperationContext Ordered Messages Queued Services Reliability Security Self-hosting using ServiceModel.ServiceHost Service Behaviors System.Transactions Throttling
This. Microsoft has a long sordid history of halfassing while touting products that don't pan out and are killed off with lots of carnage abandoned customers. The suck level in core is mostly w existing code and has been about on par w the hmm this is cool but management doesnt give a shit w core. It took them 3 releases to realize out of process proxying to kestrel blows goats compared to current iis asp.net model. No shit. There is a lot of astroturfing and arrogance going on. Reminds me a lot of the windows 8 days. That didnt work out to well did it?
.NET or ASP.NET version differences? Given it's a server side generated link, it seems weird that it would be different on different client machines.
People use unstable releases in production?
The entire issue is, nobody knows. It’s a preview, which may contain crucial errors nobody has found yet. Yes, all code contains errors, but previews could contain significantly more. If you release, then you may have to (and probably will have to) issue an update with a fix. If the code is a simple process, then the risks may be relatively low. If it’s complex, then you’d have to judge for yourself.
I saw a job posting which said they were developing with .NET Core 3 right now. That's why I'm asking, I always considered it unsafe to do so.
Developing with something doesn't mean it's in production. They could be developing future projects that they know will be released post .net release.
ActionLink generates a link to trigger an action. Fragments are out of scope since they do not influence what action is triggered. Easiest thing to do is concatenate the fragment onto the URL AFTER it's generated by ActionLink.
Hi I have few suggesions With all framework and helper classes you made, a simple application with just a login screen would be awesome to show. If you explain each steps, it would help beginners. &amp;#x200B; I felt MVVM framework to be bit tough, if you can explain MVVM pattern it would help. Thanks,
It is likely buggier than a stable release. If you do hit a bug, you will probably be unable to do anything about it, except roll back to a stable .NET and recode anything that is not compatible. If something did go wrong with a stable release, you'd be far more likely to get help from the community or Microsoft. Microsoft will probably offer no support at all since their official stance will likely be you should not be using it for production yet.
I suppose one can even optimize for size (vs performance) as can be done in C or C++ builds.
I used .NET Core 1 Beta. Though it went to 1.0 final (and I knew it would) before we finished the project using 1.0 final The scenario went something like this: Project Manager: Hey we need to make this thing, maybe you could code it in Java Server Pages? Me: Um, how about ASP.NET, which I actually know how to code. Project Manager: It'll be Windows only, but that's fine. **MONTHS PASS** Project Manager: Hey I want this running on Linux. Me: -.- Whelp, guess we're using that new .NET Core beta that came out. I'm not recoding this from scratch especially in Java which I don't even know.
Taking your feedback into account :) thank you!
Dapper is such a thin layer that it shouldn't care so long as this new one still implements the System.Data base classes and interfaces.
In most cases hiring specs shouldn't be taken as gospel.
Have you looked at any static analysis tools for quick wins? Sonarlint, roslynator, codecracker, sharpen among others will give you plenty of advice for making your code prettier and nag you into making positive changes directly in visual studio.
What really helped me is Youtube. I went into C# development completely blind to the language, with a background in javascript and C++ during college. Watch youtube videos on the SOLID principles, DRY, and dependency Injection. If you attempt to adhere to all of that, you have some pretty damn near good code, and when you have experience under your belt, you will be able to discern when to get away from those principles. Also, remember that bad code that works is better than pretty code that doesn't.
[Read this](https://www.amazon.com/Code-Complete-Practical-Handbook-Construction/dp/0735619670), its 10years experience rolled into one book. &gt; *code by for optimizations* * 1 - Never optimize things unless there is a definite need. * 2 - Run the slow code through a profiler, then improve only the code it identifies as slow. * 3 - Measure things before and after optimizing
What I am doing currently is as follows: `query = "UPDATE Vehicles SET Visibility = 0, Archived = 1, ArchiveDate = GetDate() " +` `"WHERE " +` `"((ISNULL(VIN, '') &lt;&gt; '' AND VIN NOT IN (" + vins + ")) " +` `"AND " +` `"(ISNULL(Stock, '') &lt;&gt; '' AND (Stock not in (" + stocks + "))))" +` `"AND (Archived IS NULL OR Archived = 0) " +` `"AND (Stock NOT LIKE '%TAC' AND Stock NOT LIKE '%CON' AND Stock NOT LIKE '%SIL') " +` `"AND SubscriptionId = '" + subscriptionId + "'";` `dbContext.ExecuteCommand(query)`
What I am doing currently is as follows: What I am doing currently is as follows: query = "UPDATE Vehicles SET Visibility = 0, Archived = 1, ArchiveDate = GetDate() " + "WHERE " + "((ISNULL(VIN, '') &lt;&gt; '' AND VIN NOT IN (" + vins + ")) " + "AND " + "(ISNULL(Stock, '') &lt;&gt; '' AND (Stock not in (" + stocks + "))))" + "AND (Archived IS NULL OR Archived = 0) " + "AND (Stock NOT LIKE '%TAC' AND Stock NOT LIKE '%CON' AND Stock NOT LIKE '%SIL') " + "AND SubscriptionId = '" + subscriptionId + "'"; dbContext.ExecuteCommand(query)
Here's what I need to convert to a stored proc. But I am confused on how to pass in the lists of vin and stock as a variable. &amp;#x200B; query = "UPDATE Vehicles SET Visibility = 0, Archived = 1, ArchiveDate = GetDate() " + "WHERE " + "((ISNULL(VIN, '') &lt;&gt; '' AND VIN NOT IN (" + vins + ")) " + "AND " + "(ISNULL(Stock, '') &lt;&gt; '' AND (Stock not in (" + stocks + "))))" + "AND (Archived IS NULL OR Archived = 0) " + "AND (Stock NOT LIKE '%TAC' AND Stock NOT LIKE '%CON' AND Stock NOT LIKE '%SIL') " + "AND SubscriptionId = '" + subscriptionId + "'"; dbContext.ExecuteCommand(query)
FYI, codereview.stackexchange.com focuses on this specific thing. It's helpful.
If you have a specific challenge ask about that when it comes up. You're smart and experienced, which means you'll also pick up a lot by helping others in the community, especially if you have to do a little research to get the answer :)
The feature that you using in the newest version of .net for may change its interface or not even ship with it. It may also contain critical bugs that need to be fixed. This leaves you with live system that you need to update which usually harder or riskier to fix. The question you should ask yourself is why do I want to use a preview version?
Ill be that person if you will for me. In the same position
What level of experience with netcore and docker do you have? Do you have a personal project you're working on? If so, or if you have an idea, I'd be down to help you get an asp.net mvc core app running in docker and helping with code reviews. Some technologies I want to get more casual hands on with are gRPC, Redis, Hadoop, Spark. Or if you want to start with something existing rather than make the app from scratch you can check out the pizza app they were using to demo at build.
Same, is there a subreddit for this?
I'm always happy to look at any code you are willing to share, and give feedback.
Zero experience
Yes I will
Let’s make a discord or another flavor of group chat
https://join.slack.com/t/dotnethelpworkspace/shared_invite/enQtNjMxNDEwODY0Nzg5LThmM2JlZmYxN2FlM2IyZGE5MDNiNTY3YjRjNzhiMzYyNTU5MTMyMTRiYmRkOGMwNWVlMjc2MDZhMTVlZWNlOWY
https://join.slack.com/t/dotnethelpworkspace/shared_invite/enQtNjMxNDEwODY0Nzg5LThmM2JlZmYxN2FlM2IyZGE5MDNiNTY3YjRjNzhiMzYyNTU5MTMyMTRiYmRkOGMwNWVlMjc2MDZhMTVlZWNlOWY
That book has helped me so much in my career. That should be required reading.
Nope. WinForms and WPF are still Windows-specific technologies. .NET still lacks an officially blessed framework for cross-platform desktop apps. There are some unofficial ways though. Avalonia UI is based on WPF and Qml.Net another one someone recently pointed out to me.
Made a slack to chat a little bit easier https://join.slack.com/t/dotnethelpworkspace/shared_invite/enQtNjMxNDEwODY0Nzg5LThmM2JlZmYxN2FlM2IyZGE5MDNiNTY3YjRjNzhiMzYyNTU5MTMyMTRiYmRkOGMwNWVlMjc2MDZhMTVlZWNlOWY
What’s the likelihood of a port tho... It must be an immense undertaking, but could basic controls and features be emulated? I have no idea how WPF works internally, but with maybe Vulkan instead of DX?
I'd guess something based on web assembly would be a likely successor to WPF in the future. I've no idea what their internal thinking is, how it would work with MS store for example, but I'd buy into a better Silverlight over Blazor tomorrow.
Nice. I'll join tomorrow morning.
Yes, but someone has to do it. Lots of work
Does avalonia let you have a single assembly, and separate build artifacts for different OS?
WebAssembly is just a runtime Avalonia is a ok path to go, but it needs major support.
No. The whole point is to move WPF and WinForms to be able to target .Net Core, that's it. Just because something targets .Net Core doesn't necessarily mean it is cross platform. There is just too much existing software using WPF and WinForms and the point is to have a migration path to newer technologies. .Net framework is not getting any more new features so if MS wants WPF and WinForms to live on, they need to make it work for core. Maybe one day they will be cross platform, but right now they are just too reliant on Windows specific features. At this time they have explicitly said they do not want PRs adding cross platform capability. Maybe sometime in the future they will work on cross platform capability, or maybe a group forks it, who knows. I'd love to see WPF being cross platform. While it has a steep learning curve, you can do some great things with it.
doesn't it always end up like a piece of shit though? Historically the platform changes of several different implementations masquerading as one gives you that old: &gt; weird flickering when you press a five pixel high button on OSX on Wednesday afternoons. kinda thing. Or am I just being old and cynical? I'd still suggest the best cross platform is html + javascript although then you're just switching the platform issue into a browser one (although we've improved over the past decade).
No need to read the book now....
&gt; doesn't it always end up like a piece of shit though? For games? No. Because nobody expects games to be consistent with the OS UI. For everything else? Yes. There is fundamentally no way better than HTML to do cross-platform UIs that still look native. And HTML only gets a pass because people have lowered expectations.
It just seems odd to me because the point of core, I felt, was for cross platform support. But now core will have windows specific. And with that precedence, why not being WCF in to net 5?
&gt; For games? No. Pretty sure Linux owners have suffered a long time on that front due to driver support, right? That would include the bindings into stuff like OpenGL or am I talking nads?
I released a product on .net 1.0 Beta... Holy shit I am old.
Kind of a grey area. It's driver support, which used to be a common issue on Windows, too (bleh S3 Virge days). Basically, WinForms and WPF are tightly coupled to the underlying Win32 API. Linux/UNIX/MacOS/Android/etc. have completely different low-level drawing APIs, and so there is no way to make a 100% drop-in implementation of WinForms and WPF without punting back to generic 2D drawing APIs which would make performance absolute shit. Games use APIs like OpenGL and DirectX, which themselves are low-level, and so can be consistent across all platforms that support those APIs. However, the open/closed source driver issues between AMD and nVidia on Linux mean that sometimes you get some funkiness.
Microsoft owns Electron now so there is technically a Microsoft cross-platform framework...just saying ;)
While I agree that one of the primary goals of core was cross platform, you're still going to have platform specific packages. Just think about Xamarin. There are certain features that only work on Android, or only work on iOS. That's just how it is. Just because the platform is cross platform doesn't mean everything has to be. It just seems they have decided they want WPF and WinForms to still be useful so the only path forward is for them to be supported on the new platform.
No core is cross platform but wpf is a feature that utilizes core it’s not actually core it’s just going to be a feature built on top of core. While core will be cross platform not all features implementing core will be cross platform from day one
I hope that WPF will be available on Linux. I think Mac OS would be targeted first, but once that's done - Linux support is a smaller step.
What about java?
But they could build a framework on top of it. Possibly something like Electron
I saw a talk given by someone on the .net core team and he mentioned that when they were developing blazor someone actually got it working with electron, and he mentioned this could be a way to move forward with porting desktop apps across platforms.
But it's the same amount of work
Maybe, maybe not. Chromium is already cross platform and anything built on top of it would benefit from that. I could see MS trying to build an Electron analog that uses WebASM and c#. That way they only need to build a framework on top of chromium instead of retooling all of their code for cross platform use They already have some of the groundwork - they’re porting edge to Chromium and they’re porting parts of .NET to WebASM packages
Looks and runs like crap on every platform (except Android, where it's the native UI toolkit, not cross-platform Java UI toolkits). That isn't to say that there aren't examples of Java-based apps that look and perform OK, but their authors spent a lot of work tweaking to get there. Which is kind of the point. Microsoft could make WPF into a cross-platform UI toolkit like Java, but what would it provide over Java Swing/Whatever? Instead, Microsoft seems to be leaving it up to 3rd parties to come up with "runs anywhere .NET core runs" UI toolkits. The design patterns have long ago moved to Model-View-Controller, and you can share 100% of your Model and Controller code in .NET Core already. Having a UI-specific View layer for each native platform isn't that much more work than tweaking a generic layer for an app of any significant complexity.
F# bro
I've seen your query in the other replies; how adhoc is this - how many times does it run a day? Is it triggered by users based on selections? Some context on how it's triggered and how often would be helpful. A couple of side things in the meantime; you're using isnulls - is there actually a chance you have empty strings in those fields instead of null? Could you change your input / save so empty strings are always saved as null instead of ''?
If you just want to convert this to a stored procedure, look at table-valued parameters. Build the tables of vins and stocks and push them into a stored procedure. Then left join to the tables keeping rows where the joins both result in a null.
It's definitely not happening... https://github.com/dotnet/wpf/blob/master/Documentation/contributing.md “We also do not intend to accept contributions that provide cross-platform implementations for Windows Forms or WPF.”
This is not WPF. Blazor has already been demonstrated to work in Electron. https://github.com/aspnet/AspLabs/tree/master/src/ComponentsElectron/sample/SampleApp
the point of core IS xplat. to that end core is a massive success. but it is certainly not the case that everything that USES core is xplat. Wpf and winforms can now host themselves on top of core, that is all. They are, however, factoring the ui stuffs to be detatched from windows proper so that they can ship stuff on different cadences and even support older versions of windows. so maybe ports would work some day. and wcf isnt in .net 5 because wcf sucks. there, i said it. it's a terrible abstraction. it's so abstract that it is impossible to use, and also so abstract that it is bad at doing common things (you literally can't set the "host" header). framework isn't going anywhere if you can't avoid wcf, but if you can avoid it, do.
You will die
But Microsoft would build a UI library using WebAssembly at the core in an Electron host I guess.
I highly doubt MS will make a UI library for Blazor. Have a look at: https://github.com/chanan/BlazorStrap https://www.matblazor.com/
merge is sql server specific. mysql has an "on conflict" clause, and pg has the same clause since later versions (2016).
I've written a few Java cross-platform desktop apps using JavaFX and the default look is not bad, but you can actually style in Metro / Material Design / etc using some third party stuff. Performance is fine as well. Why I would like cross platform WPF/UWP and XAML is the binding system. JavaFX is a pain with nested bindings, if the parent object changes you have to keep a references to every binding, unbind and the rebind to the new properties, whereas WPF etc just works. The other thing is DataTemplate, it is great. But maybe I should be looking at cross-platform using .NET Core and some HTML thing in electron? Is that the only serious alternative?
I understand that. My point wasn’t about wpf, it was about a universal desktop framework.
This runs twice a day. Vin will either have a value or be null. Never empty.
That’s exactly what I’m working on :)
Oh no. Still years of learning to be had in c# land. I’ve been at it for 5 years and still feel new some times.
This isn't even technically possible without packaging up the entire Windows shell and drawing subsystems, which, obviously, isn't on Microsoft's to-do list. Winforms is a very thin abstraction over GDI+, the graphics device interface. And I mean very thin, so much so that you can alter how your applications UI is drawn directly. WPF extends and replaces this abstraction with a compositor approach and a new markup language to take advantage of that composition engine. It also provides access to the 3D capabilities of the graphics device subsystem (via DirectX and DirectDraw), which allows WPF to do all the fancy things WinForms cannot (without a ton of effort, anyway). All that to say, no. Not now, not ever actually. Neither of those technologies even make sense outside of the Windows context. You'd need to recreate both abstractions over Quartz, Weyland, XOrg, whatever the native graphics engine of the target platform is. Again, not many people interested in doing so since those platforms already have equivalent tooling of their own.
It runs automatically / scheduled? Based on what inputs, how are the two lists of items provided? If vins will never = '' then don't do isnull(Vin,'') &lt;&gt; '' just do Vin is not null
Mac OS wouldn't not be targeted first honestly. Not enough enterprises use a Mac as a workstation.
My 18 years of .NET development tells me Mac OS would be targeted for WPF before Linux. We're talking about end users and developers here. More business desktops (not talking about servers) run Mac OS than run Linux. WPF is not targeted for headless servers.
Can you post those lines you are seeing on the comman prompt?
&gt; Electron Just no
I don’t like Electron, but maybe they can figure out how to make it faster if it uses WebASM instead of node
Nevermind I found the issue, it wasn’t working on my laptop for whatever reason. I tried it on my pc and it worked though. Thanks anyways
I joined. I've wanted a group like this for a while. I'd even like to have a weekly "meeting" for general review, discussion, cool new things we've learned, etc.
You're talking to someone who has been a .NET developer professionally for over a decade and used it since .NET 2.0 in 2005 and also has been in Linux since the 90s. .NET 1.0 was released in 2002 not counting for a beta that wasn't exactly popular. Barely 17 years ago. Now I'm not going to call you out on that exactly... You're only off by a year, but it does put the point in place that you're already trying to prove a point using unrelated nonsense. Your "18 years" of .NET qualifies you to know facts about business workstations and Apple products. What's your correlation here? Linux isn't a headless server. I truly hope you know better than that, especially since I said "Linux workstations". Now, Linux is actually quite popular in businesses. In office settings not relating to design occupations, Windows is absolutely the most widely used. However, a large second place world wide, used in governments, schools, and corporate giants is Linux as a server and a desktop. Some of this is RedHat. Linux is also the most popular OS for things like Kiosks and mobile devices (I'm going to group Android and ChromeOS into this). This makes Linux a massive massive target audience of cheap custom hardware devices, especially in my industry. Now outside of that, Microsoft is also on a recent "Microsoft Loves Linux" campaign. Outside of the recent Visual Studio for Mac, there hasn't been a lot of Mac attention from Microsoft. Microsoft is also including Linux into Windows 10 and has an entire subsystem dedicated to it. But you're probably right, your 18 years of .NET experience probably tells you Microsoft wants WPF on Mac.
Welcome! A meeting of the minds so to speak
MERGE is part of the 2003 version of the SQL Standard. https://wiki.postgresql.org/wiki/SQL_MERGE And while MERGE can be used for an upsert, it's more generic than that. It can also do things like performing an update when there isn't a matching row `WHEN NOT MATCHED BY SOURCE [UPDATE | DELETE] `.
You also can't teach people to be interested in improvement.
I feel like you missed the part where he's entry level developer.
Is there any reason why Microsoft don’t want to do brand new cross platform UI Framework?
Lucky me! I have this book!
Ugh redis...
Are you using the shared model? Then you probably have the wrong version installed.
Slack is so resource hungry, it'll kill my machine next to the open VS instance.
I think it's just return on investment. There's a lot of effort involved and not a lot for them to gain by doing it. Porting WPF would pretty much mean rewriting WPF so they would probably be better starting from scratch. The cross platform support so far has been limited to the "core" functionality and even that has taken years. That's enough to use Linux to host microservices though, which is what a large amount of Azure is based on, so as a company focusing on cloud and not the desktop (and certainly not other desktops), doing that makes much more sense.
&gt;job posting That's the problem right there. It also probably required 10+ years of .NET Core experience. Job postings are mostly garbage in the software world.
As others have said, if you're not using containers then there is a whole framework built in to do microservices there with a whole bunch of features built in you don't get with things like AKS. Also, with Service Fabric Mesh coming, if you didn't want to manage nodes and the health of clusters etc. then that's going to be a huge win for you.
True. Thanks!
Of course, but that's the point. .NET compiles to IL, the IL could transpile to run on web assembly. Obviously you'd need to do all the plumbing to make it use Web GL etc, but it's all technically possible. I'm not knocking Avalonia, I'm thinking quite far into the future. MS have committed to delivering Blazor now, but I'd still rather work in WPF or a WPF alike.
I'm sure MS will deliver some kind of I -house cross platform UI solution though... WebAssembly seems like a fine option for that since getting the same elements building across all platforms is trivial. Unless they wanna go a route similar to Qt but they don't have any products remotely similar at the moment.
&gt; I’ve started a slack channel for group talk, code reviews, q and a. [You could make a Stack Exchange site out of this.](https://codereview.stackexchange.com/)
&gt; It just seems odd to me because the point of core, I felt, was for cross platform support. It's **a** point, but not **the** point. Some other points are faster iteration by allowing more frequent breaking changes, as well as allowing independent installations.
The trouble with this query is that every time it runs it will scan the entire table; it is not [sargable](https://www.sqlshack.com/how-to-use-sargable-expressions-in-t-sql-queries-performance-advantages-and-examples/). One solution that may be relatively easy to implement is to create a [filtered index](https://docs.microsoft.com/en-us/sql/relational-databases/indexes/create-filtered-indexes?view=sql-server-2017). In general using IS NULL and IS NOT NULL always creates non-sargable query plans, but you can work around that by using the EXISTS clause where possible or using a filtered index if you take into account: [A filtered index that you create together with the IS NULL predicate is not used in SQL Server](https://support.microsoft.com/en-za/help/3051225/a-filtered-index-that-you-create-together-with-the-is-null-predicate-i) (the article includes a workaround). Hope that helps :)
That would be a sad future. Very sad.
Although I think development is a little more stable these days, I once developed using the preview version of MVC back in the day. I knew there would be a final release before the project went live so I ran with it. That was a whole host of fun when the final version was released. There were so many breaking changes that I spent about a week sorting them all out. Not to mention that I released it on IIS6 which was a minefield of other issues with MVC.
Hi, so first of all, thank you for your suggestions and tips. I tested nearly every method you all suggested but it seems that IIS is always encoding the url when using Html.ActionLink(). Normaly this should not be a problem. I think that the main Problem I have is, that this website was build on old Frameworks and plugins. As there are NO comments in the code and no gitrepo I can only see the old copyright from 2010 and some sites added in 2014 that this site is clearly out of date with the technology used. I think I could be glad that the creator updated to .net 3.5... &amp;#x200B; My solution is now: &lt;% var id = Model.Product\_Id + "#tabs-3"; %&gt; the Link is now generated in Html directly: &lt;a href="/Product/Edit/&lt;%= Html.Encode(id) %&gt;"&gt;Back to Transactions&lt;/a&gt; &amp;#x200B; So this is the solution in the Frontend, I have similar issues on the Backend as well when other actions are triggered, but there are more possibilities for me to solve that Problem. So Thank you guys again, the suggestions did lead to the solution :) &amp;#x200B; BR van
Microsoft has no interest in enabling people to create desktop apps on anything other than Windows. They've conceded server software on other platforms because that might still mean they can make money off of you from Azure.
The slow part is embedding an entire independent browser on every electron app. If only they could figure out a way to embed the browser control into the OS so every app can count on sharing it... oh wait, they tried that in 1998 and got royally screwed over.
I’m not against it. Would be good since it supports code formatting
This topic is discussed with Scott Hunter from Microsoft on the latest episode of Dot Net Rocks. Hear the answers from the man himself. https://dotnetrocks.com
I need to interop with a java app and a big payload,bxash lookup data from both, so I think that'll work. Any reason you dislike it?
The best way to make a cross platform UI is to create web application. The desktop is dead.
It’s been causing a lot of headache for us in production due to it timing out trying to retrieve data. We’ve yet to figure out why
The answer was pretty much no. Use web based technologies in combination with electron instead.
Shouldn't make any difference. The web server (IIS in the most cases) authenticates the user against the active directory.
I think if you hire devs that cant tell you about their projects, you’ve made a mistake. Even before i went to college, i can tell you about some things i was working on. How does that relate to entey level?
You should look into using SAML in your application. There are libraries that you can use to implement it like Component One. Your application would redirect the user to the AD server for authentication, and then if successful you get an encrypted token back to tell you information about the user (like their ID). ADFS supports SAML but it assumes some work on their side also to setup your app as a service provider.
Yes, you can authenticate against AD from a website. All that's needed is the website has to be able to communicate with the AD service. If the IIS server is outside of the domain you will have to provide a secure link to it. Azure offers AD capabilities to mirror your AD and has a lot of reference material on how to do this type of setup.
This is what ADFS is for.
Definitely. It’s a type of forms-based authentication. Like others have said, as long as your IIS service has access to AD it’ll be a breeze. Otherwise it gets slightly more complicated if it’s outside the network.
Apologies for the delay, but I have a rough draft on how to approach this that I am still working on... but a getting started with vue-cli and dotnet core [post I made]([https://blog.robjam.dev/posts/vue-multi-page-dotnet-core/](https://blog.robjam.dev/posts/vue-multi-page-dotnet-core/)). It is still pretty rough so if you have some feedback let me know on twitter or reddit dm. I will hopefully have a sample repo up tomorrow to show as it might be easier to understand with the whole picture!
So what's the query here? Are you asking someone to write the program for you fully or offer concept suggestions?
What is your definition of a Sing Page Application? For me (and probably others) a SPA is something that handles page routing in a single html/js/css document. Vue (and react AFAIK) have the option to add client-side routing (in the browser). Point being that data/interation-heavy portions of your site can utilize the benefits of a client-side framework while other portions (admin CRUD pages, etc) can still leverage MVC/Razor. This also makes things simpler when doing Authentication/Authorization as that is handled by MVC without having to worry about SPA authentication schemes (api + jwt). I would dislike having to implement a dashboard in razor/jquery when I could make use of a framework like Vue/React.
In the general world, I would agree. But, there are still plenty of scenarios where people need to deploy applications to people who are disconnected from network resources, or applications that do not need to be on a network.
There is no “my definition of an SPA”, there’s just the definition of an SPA. Angular, React, and Vue are the big 3 in that field. MVC has nothing to do with Razor, so the “MVC/Razor” is incorrect. MVC is a server architecture pattern, Razor is a server side templating engine. Authentication and authorization are two very different things. You should look up the difference. There’s nothing more complex about creating a JWT token and sticking it in the header. It’s just a cookie basically that you send with every request to verify. It’s not difficult in the slightest. Mixing authorization schemes however is a bad idea. There’s no reason to really be using Razor Pages at all, as even Microsoft’s documentation encourages users to not. It’s simply there to replace the legacy webforms that some poor devs refuse to move away from.
I would be happy if someone could point me to right direction. Right now I am trying to host ActiveX inside my wpf app but without any luck.
It is guaranteed that there will be trusted connection. Each company that wishes to have this feature for it's users will need their admin to establish the connection. The problem is that there are thousands of companies. How does it work in that case? Does the user select from like a dropdown which organization he wishes to log into, so I can Make a request their Domain controller? I have no previous experience in ADFS integration so it all just sounds kind of fishy to me. It does seem like the best thing security wise, but still, it's a requirement.
This thread has documentation in it for a windows form: [https://social.msdn.microsoft.com/Forums/office/en-US/83d47c8c-90f3-4ad7-8ae4-e44de910de82/is-it-possible-to-run-a-powerpoint-presentation-only-the-content-in-a-windows-forms-project?forum=winforms](https://social.msdn.microsoft.com/Forums/office/en-US/83d47c8c-90f3-4ad7-8ae4-e44de910de82/is-it-possible-to-run-a-powerpoint-presentation-only-the-content-in-a-windows-forms-project?forum=winforms) &amp;#x200B; I would try to get it running in a windows form and then look at porting it to a WPF via importing the right controls.
Your post/github resources helped me so much! Vue-cli (recently-ish?) added an option for [multi-page (naming is hard)](https://cli.vuejs.org/config/#pages) so the custom webpack configuration can be integrated into `vue.config.js` to get a lot of the boilerplate down.
It would be possible with an OpenID connect solution, the AD is the identity provider and for example IdentityServer4 can integrate with it. ID4 is open source and certified. Would be like when you sign in with your Google account on a website
I tried to use webbrowser inside winform control and then display it in winformhost. problem is that when I open the pptx browser wants to download the pptx instead of displaying it :(
I'm at work, I'll try to put something together when I'm home
If they do this, my assumption would be that it will be done by Xamarin team.
Either they'd need to know their active directory domain name, or you'd want to do something like give each organization their own subdomain on the app. It really depends on your own use cases and preferences for data partitioning. That's really more of an architecture question though.
&gt; give each organization their own subdomain on the app This exactly. OP, from a UX standpoint this should be preferred over knowing their AD domain name but like Mecha said it just really depends on lots of things outside the scope of the question.
Why is that?
The UI framework of choice in the Microsoft eco-system should be a **web browser**? What a colossal performance waste.
Try setting a `Content-Disposition: inline;filename=foo` header
Perhaps, but it has been demonstrated to work pretty well as a solution to cross platform development.
Perhaps, but still it would be a sad future if everyone would start adopting such incredible resource hungry technologies for everything.
This is actually very interesting. Thanks! Will take a look if it can be implemented easily
Why are you sending via an Outlook account? Azure provides SMTP servers for this purpose; use them.
Yes, I just found SendGrid free tier with 25k emails/month. Thanks
What are you trying to do? the description souds nonsensical.
PMs
Simple segregation of Commands and request along with general repositories all this in IOC containers. this way you can unit test commands,request and repositories.
Hey, there are a lot of technologies you can use:[MSAL.NET](https://MSAL.NET) is Microsofts C# library for authenticating against Azure AD over OpenID Connect (OAuth 2.0)[https://github.com/AzureAD/microsoft-authentication-library-for-dotnet](https://github.com/AzureAD/microsoft-authentication-library-for-dotnet) ADFS is the old school library to connect to on premise AD[https://github.com/microsoft/adfsOpenSource](https://github.com/microsoft/adfsOpenSource) A lot of federation gateway providers also let you use Active Directory. Check out these * IdentityServer - [https://identityserver.io/](https://identityserver.io/) * Auth0 - [https://auth0.com/](https://auth0.com/) * Keycloak - [https://www.keycloak.org](https://www.keycloak.org/) * Okta - [https://www.okta.com/](https://www.okta.com/)
If the default embedded browser gives you problems, I recommend switching it out with cefsharp instead. [https://github.com/cefsharp/CefSharp](https://github.com/cefsharp/CefSharp)
IT managers often make decisions based on how much MS will support a tool in the future. This is expected because they want support and relevant upgrades in the future. If core is presented as the next generation *rather* than a "type of" product (expansion of product lines), they will be compelled to move away from the older tool.
Firstly, just to clarify what CQRS (Command Query Responsibility Segregation) actually is. It is not method or a pattern to be used in the situation of needint to call stored procedures. CQRS is a large undertaking and really is only useful in certain use cases. It deals with separation of command and queries, as both are often separate databases and possibly database types (SQL/NO-SQL), along with event sourcing and other things. &amp;#x200B; What I expect you probably mean is CQS (Command Query Separation), which is a lot more suited to what you are trying to do and can be fairly simple to implement. It is just separating queries from commands in a clean way. &amp;#x200B; Since you have a lot of stored procedures, I would recommend using Dapper as your way of accessing the database. Dapper is a nice lightweight Micro ORM. &amp;#x200B; You can then implement the CQS pattern in such a way that is testable, most definitely using dependency injection. There are plenty of tutorials around about CQS, Dapper and unit/integration testing all of this.
I used to do vb.net .... switched to C#. I would recommend switching to c#. More jobs out there for c# vs. vb.net.
I second this - unless you are required to learn it for a specific job that you want to keep, there is little reason to choose [vb.net](https://vb.net) over c# these days.
Even in those scenario's you could run local web servers or just self host a web application. Added benefit is that customers can use any type of device to use your applications.
If you're going anything complicated with SendGrid other than sending emails, I'd really recommend using [StrongGrid](https://github.com/Jericho/StrongGrid)
Isn’t C# much harder? I have a lot of spare time maybe I can learn both? I am 14 so I have a lot of time before thinking about jobs
Yes. We'll go with that. As /u/Mechakoopa suggested, I think the subdomain for each organization approach will satisfy our needs.
It's not harder, just different...in many cases you might find it easier, although it depends on the individual programmer. C# is by far the more popular language and the one that I would choose 100% of the time over VB.
Alright cool, any books or sources that can help begin the language
Not really. I did VB and [VB.NET](https://VB.NET) for decades and it took me some time to switch to C# but I managed. Also, you'll have StackOverflow to help. By the time you're 17 or 18, you'll be an expert and you could probably get a great paying job doing programming. I've seen good intro books on c# and it helps to build something and practice at the same time. In my opinion.
The most definitive source is Microsoft Docs: - [C#](https://docs.microsoft.com/en-us/dotnet/csharp/tutorials/intro-to-csharp/) - [ASP.NET Core](https://docs.microsoft.com/en-us/aspnet/core/getting-started/?view=aspnetcore-2.2&amp;tabs=windows) There's no need to spend money on books, especially if you are a beginner...most of the material will probably be a little too advanced (no offence!). Also worth just searching up tutorials on YouTube. Web and mobile are kind of the "big things" these days so it would be smart to try your hand at that side of programming, unless you have specific projects in mind like desktop, etc.
Many books have a lot of garbage or fluff in them. I like to see the meat. I saw one a few years ago at my library but don't remember the name. If you have access to a library or a bookstore, have a look there.
You'll be fine, come over to C#. [VB.NET](https://VB.NET) exists for historical reasons, I wouldn't recommend it to anyone now. &amp;#x200B; Usual boilerplate, google Dev Essentials, it's a Microsoft programme which is free and includes lots of training resources including PluralSight, and come back here if you hit any issues :)
I don't think it will be harder. I'm curious what your reasons for wanting to learn [vb.net](https://vb.net) were?
There is kind of a market in instagram where people build apps that go for rare usernames and I have an old source code and was doing some minor development but I would like to get more experienced and sell these apps
Thank you for the reply! That's all very good to know, unicode strings can be tricky. The team has responded to my bug here if you want more info: [https://github.com/dotnet/corefx/issues/37526](https://github.com/dotnet/corefx/issues/37526)
You can also use Microsoft Graph to send emails from a Microsoft account using OAuth, and if you need to generate any kind of MIME data, use MimeKit.
I opened a bug with the team: [https://github.com/dotnet/corefx/issues/37526](https://github.com/dotnet/corefx/issues/37526) Essentially, CoreClr delegates the task to the machine to solve. Linux uses ICU as the tool, which is different from what Windows uses. This appears to be a bug in the ICU library.
I'm so confused as to why anyone would want to do this.
What entry level new grad has any realistic knowledge of scaling and the *price* of infrastructure on a business scale? That's a totally ridiculous question in this case and shouldn't even be something that they should be concerned with on the job.
Both Entity Framework and Dapper have stored procedure support. Why not use one of them?
[Does this help? ](https://docs.sonarqube.org/latest/instance-administration/notifications/)
Unfortunately not, as those are all based on conditions, such as the quality gate going from green &gt; red or the opposite It’s really got me scratching my head, it feels like such an obvious thing to want! But thanks for replying :)
SPROCs don't really change your options here, so I'm just gonna recommend the generic, most common answer: A Repository class with a method per projection / SPROC, and a POCO that it maps the result to. As for testing the integration point, I usually just wouldn't. I'd mock the Repo in all internal unit tests, and would ignore tests on the repository. Repos should be pretty damn thin consisting of mostly glue code between libraries which doesn't really benefit much from it. If you are asking how to test the business logic embedded in the SPROC... I can't help you there unfortunately. Tooling around that just really isn't as good, and your tests end up needing data set up a certain way for repeatability, etc. so it gets involved. Thats enough weight of complexity against me writing tests around it that I usually advise against it unless the cost of NOT testing it is high enough to outweigh.
I don’t think they should have their own, separate tables as users considering all users belong in the aspnetusers table. However, you could add roles for each user such as “student” or “teacher.” Also, you could create two separate tables for teachers and students. This could include the aspnetuser id so you have two different tables with teachers and students separated.
Yes the Staff members will have different roles such as "admin" "staff" etc and I have previously achieved this so I'm pretty confident in that. If all users should appear in the aspnetusers table that's fine I wasn't 100% on that so thanks for that. Also the creating 2 separate tables using the aspnetusers Id sounds like what I want to achieve that's great. 1 further question, how do I create the separate tables for Staff &amp; Students as both my Student &amp; Staff currently do not create their own table since they are in the aspnetusers table.
Depends on what you are asking as in “how.” Do you mean how to actually create those tables in the database or how to insert the users into their associated tables, such as staff and students? I would assume the former since you mentioned how, but I wasn’t sure since you said students or staff do not create their own table.
Beware that EF Core doesn’t support ExecuteScalar type stored procedures. As in those that return a single value. You’ll need to go back to ADO for that.
customers are using powerpoint o show how to make certain things. we would like to use this presentation with sensors so they would show the current step.
can I use cefsharp to display powerpoint presentation? I'm worried it would become too compilicated.
I meant how to create the actual tables in the DB. But I found a resource online to help with this. As my Students &amp; Staff have alot of different fields this means there will be alot of null values in the aspnetusers table, is this unavoidable? Or is their something I can do to minimise this.
I come from a strong background in VBA. I completely skipped VB .NET for C# even though the former was more familiar. They're very similar languages, but C# is much better designed and there are better books out there for learning C# vs VB .NET. If you don't have a strong background in either language, learn C# 100%. A few books I would recommend are C# Step by Step and C# in Depth. Both are on Amazon and other book publishers. And they've both been recently updated.
Oh that's obnoxious..
TBH I'd just carry one with the established pattern. It's not cool or clever, but following established patterns is much of what a developer does. &amp;#x200B; If the company and the veteran developers are telling you not to do something, but your going to do it anyway, how will that look if it causes a catastrophic failure in live?
Not sure, does Dapper work with .net core? https://github.com/StackExchange/Dapper
Is this your first programming language? VB is much easier to learn with zero experience. But if you already know some programming then C# basics are not any harder.
First programming language and definitely seems easy so I think I’ll get more experienced and then move it C# since the code looks really similar
Something to ask is whether or not this is for a job. Hobbyists generally find VB to be more forgiving. Muggles do not understand things like 'for' and 'For' being completely different words. And the use of semicolons and braces can seem like arbitrary madness. But yea, if he wants to turn pro C# is where it's at.
Books... anything on Amazon for VB 8/.NET 2.0 or later. You can often find them for practically nothing and they are perfectly acceptable for learning the basics. (Avoid books before 2005.) Also get a cheap book on SQL. Again, the basics haven't changed in decades. A book from the 90's would still be appropriate. *** For Javascript you'll need a modern book. Ditto for advanced features in C#.
Xamarin.Forms? I think there's bindings for most everything out there?
A stored procedure is just a function call. The function happens to live somewhere else, so you need a thin wrapper around it, but at the end of the day think of it as an encapsulated function.
Don't, just don't.
&gt; how can I test that? The same way you test any other code that contacts a database or web service: 1. Write a bunch of mock tests 2. Realize that the mock tests are less than worthless 3. Write integration tests 4. Realize that your integration environment is broken 5. Fix 4 or return to 1
I do both at my Job (some current and previous coworkers use it). I've found that you can find a lot of VB.net examples when looking up stuff for National Instruments devices as VB.net tends to be used in a lot of the same places as Labview (think manufacturing and some automation). But like a lot of other people have said, you should learn C# instead because there are way more resources for it and they both compile down to almost the same code.
What fields? You aren’t adding any to aspnetusers are you? Most of the time whatever fields are there are all that’s needed per user and usually there isn’t more than a couple that are null. That table should only include user information really, not business/school information. Someone correct me or give a better approach than me if you see one or if I am approaching this wrong. I also cannot speak on behalf of Entity or approaches using that as I only use Entity for identity (authentication/authorization). But I think your best bet is to create two tables, teacher and student. You add any columns you need for those specific entities, such as student id or teacher id. These tables should not be dependent on anything related to your website, as in a real world there shouldn’t be a dependency there. Forget how I mentioned earlier about adding the aspnetuser Id to these tables. Now, as far as your site goes, an admin should be creating user accounts/managing them. Upon account creation, the admin assigns a user role (teacher, student) and a user claim, either teacher/employee ID or student ID. This id can be used to retrieve the associated information from the teacher or student table. This isn’t the only approach, however, it’s one that to me would be ideal/practical.
VB.NET is a near death language, just start with C#. If you program in VB.NET you would find way less useful stackoverflow posts to help you solve problems, and the existing resources and blogposts about VB.NET are either antique or of people who are stuck in 1997. C# and VB.NET have mostly the same capabilities, but different syntax. The syntax of VB.NET is maybe more readable for absolute beginners, but after a few days of learning this won't matter anymore after you got the basics. The only reason VB.NET exists is because MS wanted to lure VB6 programmers to .NET.
I recommend Udemy. I am using them to learn React/Node/Java and Python. &amp;#x200B; All of them are videos, but they usually come with ebooks too. &amp;#x200B; When you first sign up, everything is like 90% off, then once a week or so they have sales for like 80% off
you need to learn dependency injection (for services), the Model-View-Controller pattern (including ViewModel as well) and Razor Pages. you can find tutorials for all of these on the MSDN
If you are using EF Core: https://docs.microsoft.com/en-us/ef/core/providers/ Just install the nuget package for the relevant database and follow the docs linked with it, these usually also tell you how to structure the connection string.
Thanks!
I made a lot of Mocking classes and then wonder, Does this worth the time invested? Then realize it really doesn't, so maybe I'm doing it the wrong way.
 It means you take a pen and paper and ask your dad's friend what the site does and what he expects it needs to do. Then you start **a complete new** project in ASP Core, not a single line of code and not a single html tag should be used of the classic asp site. The difference in technology is just too big, meaning you'll have to start from scratch. Classic asp today, is like a spitfighter, it did its job at the time, but it's totally useless in today's world and you can't use a single part of it create an F35 out of it. And since you don't know anything about .NET, you'll have to go through a lot of tutorials first. [Here is an official video tuturial from Microsoft](https://mva.microsoft.com/en-us/training-courses/asp-net-core-beginner-18153?l=VM5gy36dE_6611787171) [And here the official tutorial in text](https://docs.microsoft.com/en-us/aspnet/core/?view=aspnetcore-2.2)
The fundamental problem with unit testing is that we don't teach people other types of tests. Most developers can't write even a basic smoke test because they don't even know what it is. It's like learning addition and never moving onto multiplication. Yes you need to learn unit testing first, but you should not stop there.
[C# in Depth](https://www.manning.com/books/c-sharp-in-depth-fourth-edition) is worth every penny, you can easily find 30-50 percent off coupons for Manning. I got it for like 25 bucks.
Using SQLite as an example, you would need to add a reference to a nuget package such as System.Data.SQLite. The connection strings look a bit different for SQLite: `Data Source=c:\mydatabase.db;Version=3;Password=hunter2` &amp;#x200B; Where `c:\mydatabase.db` would be the path to your database file.