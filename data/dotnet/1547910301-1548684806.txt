You are wrong üòÇ WPF is (partially?) In the newest dotnet core. It naturally had a ton of windows specific code in it, so I can see why they did web services first.
Haha yes I meant the future of the Microsoft camp! 
Link? I still use VS for c#, but I use code for everything else. I'd imagine Rider would support this
As an MS employee I‚Äôll say this: It‚Äôs not a bandwagon, it‚Äôs the future of .NET. Sure the .NET Framework will be around for a long time and continue to get support and updates, but I‚Äôd expect them to be mostly just patches and fixes. Core is the focus and the future. It‚Äôs way more performant, has better community support, and runs everywhere.
I cringe when I see classic applied to asp.net. We still have actual classic asp to support.
There are now features coming to dotnet core which MS stated will never come to dotnet framework, like Span&lt;T&gt;. But there are still features in framework you won't find in core. It pisses me off because it destroys the concept of standard
So far, I have been able to create the quiz: multiple choice answers, fill in the Black answers, and a block for writing. I have yet to determine how to create a clock that moves on to the next page after a certain amount of time, which will help me calculate the WPM manually. I am almost ‚Äúthere‚Äù but still missing some crucial aspects and really don‚Äôt want to use the google docs stuff for surveys
Well, some of us do. God bless you poor souls who've decided to bite that bullet. But let's be real, the sort of businesses looking to support their archaic classic asp app aren't the same sort of businesses looking to stay ahead of the curve with .net core.
Features like WCF services; Apparently it's not on the roadmap and it pisses me off too. In a B2B scenario where data is exchanged between partners using SOAP / WSDL's / WS-Security, this should have been an essential use case.
Take a look at https://aspnetboilerplate.com will give you a great launching off project.
Why would it not apply to the ecosystems as well? I help maintain some Django 1.x applications and would love to upgrade them to Django 2.x but that requires moving them to Python 3 which is hard due to some bad architectural decisions made early in their life cycles that rely on Python 2's Unicode handling. 
Wow
We're still on platform. But we use the dotnet CLI in our build processes. So much nicer and cleaner to have just "dotnet build foo" instead of "FindMsBuild(); CallMsBuild();" and all the rest. And the VS 2017/dotnet sdk csproj format is just so much nicer. We never have any stupid "cannot find assembly" problems anymore. And it makes updating libraries across the code base so much easier. We had to use stupid complicated regexes before to find the reference in the csproj, in the web config, and in the packages config.
What are people's experiences with performance monitoring? Is there any apm integration (new relic, application Dynamics, dynatrace)? How do you look at memory dumps from a problematic service without DebugDiag and windbg? What are the altrernatives?
Are you just talking about the new csproj format and the dotnet CLI? You can use those for platform (mostly). 
I'm talking about the startup.cs file, the fact that you can use json files for your configuration and all those small things that make it so easier to work with ASP :)
I had more issues with System.Net.Http than System.ValueTuple.
Which part of what I said was wrong? .NET Core 3 ports over Windows specific frameworks. When ASP.NET was ported over to .NET Core it was from the start made to support cross-platform (the biggest part was breaking off the IIS dependency in favor of self-hosting, similar to the OWIN libraries for .NET Framework). They have also, and this is the first time they've ever done this for .NET Core, said they have no plans for cross-platform support for Desktop, something that was part of the original .NET Core initiative.
Thank you for this. 
You can use the DPAPI so it is accessible by the app pool service account only.
&gt;To make a net core app that has a UI on all desktop platforms, you could give users a console app that hosts a blazor app on localhost, and then opens the browser. I was thinking the same thing. Seems like that approach could be a good replacement for Electron apps don't you think?
In my team we used .net standard and for a new application we decided to use .net core and I can say that configuring the build process on TeamCity is way easier and I am yet to encounter any .csproj and nuget issues on the core. Whereas, I used to see the assembly issues frequently on dotnet standard. For OP perhaps it doesn't matter but we are saving some money on server by moving from windows to linux also docker works like a charm on dotnet core. This might be a bit unrelated but I think after MS have open sourced dotnet (and its available on mac and linux) C# has a better chance against Java. I have developed in both and personally I find C# and Linq to be amazingly productive.
I started .net core about 2 months back because we're building out all of our new services using .net core...and man I love it. 10/10 would recommend. 
Ran into valuetuple because it's required by EF Core 2.0 which is in 4.7.2 but prior to that needed a binding redirect off a bad version number. Got around that by updating the IIS server to 4.7.2.
Badwagon!? People give me shit for working with c# and dotnetcore :(
Can you elaborate on the GAC issues? At my job we are using the asp.net framework, and have moved our common routines like auth into a framework DLL that we store in GAC on each web server. Can we continue to use these DLL's with core? Or would we need to rewrite and compile them in core? And how does "no more GAC issues" affect what we're doing?
You can get the bare-bones SOAP web clients to work with Core. If you want to support more of the advanced features you will have to write some extra code to override behavior. I had to integrate SOAP services into .NET Core at my previous job.
That would be me. Our contractor built a classic ASP application that forms the heart of our product. If that wasn‚Äôt enough, he built it in the worst possible manner. There‚Äôs a single class that contains everything the app ever does. 15,000 lines without comments and white spaces. Nobody is allowed to ever touch it without going through 4 layers of paperwork.
You could build a query that does only the joins without the filtering, then tack a Where and the Select on the end. 
If you abstract out the users filtering then all your queries look like: var filteredUsers = ... // users, or users.Where(...), etc. UserPlacements = ( from p in _plaContext.Placements join u in filteredUsers on p.User_id equals u.Id.ToString() join c in _plaContext.Companies on p.Company_id equals c.Id select new UserPlacementVM { Id = p.Id, UserId = u.Id, ... } ).OrderBy(vm =&gt; vm.UserName).ToList();
Razor is significantly easier to handle. It was a real improvement: both more intuitive and more compact than the previous system.
Thank you! Creating seperate queries for filtered users and other stuff to be used in single LINQ will be just the thing, i'll go with that.
Yes, it's the future. As someone who works in both daily (we're migrating) after you get past the initial hurt of learning a new framework, you'll love it. We're building a new API with .net core and graphql and it's freaking amazing. 
Does it still have all the intellisense and such when you do it on vs code?
I think it depends largely on what is offered. I think [ASP.NET](https://ASP.NET) Core is a direct replacement for most use cases, but not all. For example, if you use SignalR, [ASP.NET](https://ASP.NET) Core SignalR does not support HubPipeline modules, which are basically filters that can run in the SignalR request pipeline. So with .NET Core, you would have to manually copy some code into each method, which is not a great solution. [ASP.NET](https://ASP.NET) Core always seems to perform better though. Even with blank sites, I've noticed that pages load faster. Any console app that I've done in .NET Core has always been faster. That's great stuff, and they've got framework integration for the new Span and Memory types. Good stuff. Ultimately, I think it's feature sets that determine what we can and can't use. With SignalR in particular, I hope they will re-implement HubPipeline modules because they are pretty important to me.
If you have OLTP (on-line transaction processing) database where you have users data for normal operation. Then you have OLAP (on-line analytical processing) database (like elastic search), so you have to transfer data from the first one to it. You write small piece of software to move data from one to another which is data pump.
WCF is a showstopper for us. We aren't the only system in our ecosystem and moving off of an *extremely* stable SOAP communications stack is a nonstarter.
not very respectful
[https://visualstudio.microsoft.com/vs/features/ssdt/](https://visualstudio.microsoft.com/vs/features/ssdt/) or juste Google dacpac and dbproj.
Thank you for the response. This is very helpful, I broke the upload out into an extension method and controller for uploading the image. The link you posted I just what I had in mind, thank you.
While you can still feasibly build applications using .net framework, MVC5, and WebAPI2, it probably isn't a good idea long-term for new projects. Microsoft has essentially crowned Core as the future of .net and if they decide to add a new feature to ASP.NET, it will only be available in core and will not be backported to MVC5/WebAPI2. For existing projects however, there isn't really much benefit to porting them unless you need Linux support.
You probably want to change [FromForm] HttpRequestMessage request to [FromForm] IFormFile image Your request is recognised as a POST, otherwise it wouldn't get to your action method. 
Check your ‚Äòthis.Request‚Äô . Is the method POST there too?
[Versioning documentation](https://github.com/chucknorris/roundhouse/wiki/Versioning) Generally they recommend you version your database in the same way as your code, but you can tell it to use whatever version identifier you want.
If you are using EF, you need to switch to EF core, since EF is basically feature complete, and all future development will be EF core exclusive. However, you can use EF core in a framework project. Since you mention APIs, the performance gains for in process hosting with core 2.2 are crazy, so I'd definitely give it a try.
I tried to jump on the bandwagon with a new library I'm writing, but had some performance issues. After lots of Googling, the bug apparently wasn't in my code but in the core implementation (https://github.com/dotnet/corefx/issues/24457). The issue has been open for more than a year, but no fix scheduled. Thankfully, converting back to framework was relatively painless, but I'm pretty bummed that my first shot at core had me crawling right back to framework.
and when will you be finished with new and final solution? maybe you at ms don't know but there are people who have to do real work in real time.
I‚Äôm not sure what you mean. There is no final solution for anything in tech ever. It‚Äôs an ever-changing ecosystem and always will be. And we‚Äôre also made up of engineers doing work in real time. Almost 100k of them in fact. That being said .NET Core 2.1 is a Long Term Support (LTS) release, meaning we will provide 3 years of updates for it.
The packaging mechanism that you would use is nuget. Your build / publish would contain all necessary libraries. This is good, since it lets you containerize easily.
There‚Äôs no GAC in Core at all. Apps are meant to be independent and include their dependencies with each deployment. For a GAC-like environment check out the runtime package store, but it‚Äôs not something used by default. You should move your libraries shared between .NET and Core to target .NET Standard. You will have to at least rebuild and possible rewrite some of it to leverage in core. Also to target standard you should be using 4.7.2 or higher for a reliable experience.
As a golang developer / devops , for the last few years, I am heavily considering going back to C# .NET I like go's simplicity, but they still havent addressed linq / collections / generics / exceptions etc. I know Rob Pike said "he hasnt found anything that cant be done in a for loop, however, I have the right to disagree. &amp;#x200B; So is my next big thing going to be .NET? thats the question I am trying to answer. &amp;#x200B;
GAC is horrible, glad it is no longer an issue.
&gt; Also no more GAC issues Yeah, but I haven't experienced dll hell like these last couple years since the days of COM. Assembly versioning and binding during the transition from full framework to core has been a clusterfuck.
the request isn't being converted correctly from whatever you're sending in, so you're getting the equivalent of \`new HttpRequestMessage()\` which defaults to GET.
Our main service components are still stuck targeting full framework, but our new public website is targeting Core and New Relic appears to work just as well on it as it does on full framework apps. I'm curious about dump debugging as well. Haven't caught much wind about it in the blogosphere, and haven't had the need to go there myself yet.
Really? I thought new relic used ETW. So it's pretty cool if they figured out an alternative for Linux. Thanks
Oh, sorry, I'm only speaking about Windows based hosting. I do not know off hand if they support Linux .Net Core deployments.
Why not? I still have to occasionally go into asp, but I'd also like to use dotNet core to make docker images easily. It's like with old cities, new stuff built on top of old stuff, which was built on top of even older stuff. You will cringe... We expose a lot of our dotnet libraries to classic asp via a Com+ project. Logging, database calls, etc. Easier to update the shared scripts in asp to call that than rewrite thousands of pages
Thanks, I was unsure in particular if the built in primitive types might be implemented as value types.
Fuck. I'm ded ‚ò†Ô∏è
I work at SAP Concur. We use a lot of Microsoft stack. SAP has a love affair with Microsoft. They're running on azure, and Microsoft is implementing SAP. 
I wouldn't call ElasticSearch olap. But I get you. I thought maybe there was an ElasticSearch river or plugin called data pump.
Hear hear. Love c#
https://blogs.msdn.microsoft.com/dotnet/2018/05/07/net-core-3-and-support-for-windows-desktop-applications/ "The highlight of .NET Core 3 is support for Windows desktop applications, specifically Windows Forms, Windows Presentation Framework (WPF), and UWP XAML. You will be able to run new and existing Windows desktop applications on .NET Core and enjoy all the benefits that .NET Core has to offer."
Oh, you want _cross platform_ windows desktop apps? 
&gt; It pisses me off because it destroys the concept of standard How come? In no context I know of does "standard" mean "has *all* the features".
You do, but there‚Äôs also visual studio for mac : https://visualstudio.microsoft.com/fr/vs/mac/ It‚Äôs not as complete as visual studio on windows but it does the job quite well.
What features is it missing? I ask because I work on windows desktop and considered getting a Mac but wanted to be able to work on it.
The debugger and profiling is a bit inferior imho. But it‚Äôs good enough. I still mostly use visual studio code. Visual studio for Mac is actually a rebrand of Xamarin Studio. If you use dotnet core exclusively, developing on OS X is totally fine. There‚Äôs also https://www.jetbrains.com/rider/ if you use resharper with visual studio. It‚Äôs the only way to get resharper running on OS X afaik.
I don‚Äôt. I support old web forms sites in conjunction with .net core sites. And I work through vpn a lot too
Platform can be manageable with mono depending on your use case. You would still probably need a windows partition. Bootcamp the OS X dual boot utility is very good.
Yeah... probably not worth it for me. 
I love core, fun to use, easy to write but such a bitch to get uploaded to my host. Been at it a week now on one site. 
I think you'll find VB6 has the stability you are searching for
Ok guys, we have a winner
While .NET Core is the future, SOAP - I'm sorry to say - is definitely not.
Sounds like you want an HSM appliance. 
Why not just encrypt a flat file with your key or encrypt values in a sqlite db or something?
Seems a bit overkill when I could just do an aes encryption and just store a private key within an app
I'm curious what the problem is you're having? .NET Core is stupid easy to deploy on the big hosts like Azure and AWS.
Surely you mean loser.
This is what I'd be doing if I were to take a custom approach
You can configure using json files now with barely any code needed to set it up. .ConfigureServices ( configureDelegate: ( context, services ) =&gt; { services.Configure &lt;AppConfig&gt; ( context.Configuration.GetSection ( "Logging" ) ) ; }
I agree host it on azure or other big providers and it's easy, but also expensive. There is no free lunch. On a small provider I get errors which seem be related to bugs, Because it's new, being unable to unpack, or versioning. Not to me tothe hassle of google + going away soon for the login. 
Basic CRUD has been templated into [ASP.NET](https://ASP.NET) for years. You don't have to do much to set that up - just create a controller with entity framework. Obviously if you don't have any specific requirements, you can pretty much just use the templates. It seems like you're saying there's no reason to develop software anymore, and if that's indeed what you're saying, it would seem you need to broaden your perspective to see the new problems.
Well you know someone is writing the code for all those tools you are using... Besides you shouldn‚Äôt need to be writing crud by hand anyway. Use EF or some ORM to do it for you.
Yeah, this is where I would be filling out applications to GTFO ASAP.
&gt; It‚Äôs not exactly that simple. CIL was designed to be language agnostic Sort of, but its object model is dictated by CLI and C#.
Dot "." Net is redundant. It's dotnet (especially in the Core context) or .Net
&gt; Hell, the _mov_ instruction on an x86 computer is Turing complete. . That doesn‚Äôt mean it‚Äôs useful. Well, it can calculate any computable function so... kinda useful?
&gt; What if _condition_ is _false_? Then you never enter the loop and the variable won‚Äôt ever have a value assigned. (Although the CLR initializes variables to 0, to make runtime safety easier to verify; but C# has stricter rules.)
&gt; Literal zero can already be assigned to any enum type. Yes, unfortunately. Actually, enums are just plain too weak (type wise), in my opinion. &gt; Furthermore, it‚Äôs the _default_ value for every enum, regardless whether or not it‚Äôs an explicitly named member. Yes, 0 is default for all fields and variables, in fact. 
Maybe ask /u/AngularBeginner? :p
&gt; and it just happens that .NET uses double hashing. It doesn‚Äôt, though. At least .NET framework doesn‚Äôt. 
I can‚Äôt count the number of hours I‚Äôve spent over my career dealing with GAC issues. 
Ouch. Please tell me it‚Äôs also not in VSS. 
EF Core is currently very bad. I am quite happy with all other parts of the .NET Core stack but EF Core is just tragic. I really regret migrating one of my active projects to it and I stopped migration on the other due to EF Core. I will migrate with .NET Core 3 when EF6 is supported. I cannot recommend migration from EF6 to EF Core to anyone and I am not even sure I would recommend it for greenfield projects.
If you want to go in the middle, write your business logic assemblies to netstandard. It will ensure you can migrate more easily in the future, or let teams who might be in a better position to use Core now to reuse instead of rewrite.
If you are using Entity Framework 6 wait for .NET Core 3. If you are not start migrating now.
I'll add my two cents. .net core is a slightly different framework. Not enough to give yo many issues but some things like ASP.net middle ware game me a bit of trouble wrapping my head around. I have made a move to a company that uses core and its not as different as I thought. Its like Java script and different front end frameworks, the syntax is the same, a bubble sort is a bubble sort and logic flows the same, but the old easiest pipelines are different and take some getting used to.
By cross platform I mean linux and OS X.
Interesting! Just preparing a presentation/demo about my initial thoughts as a. Net developer being exposed to Go recently. Apart from the lack of the features in Go you mentioned, is there any other competitive advantage .Net core has against Go? Especially when it comes to Web servers, Web apis? 
And they're still using Visual InterDev. &amp;#x200B; I joke - but yesterday we had to reinstall VB6 on our build server thanks to the Office 2019 upgrade.
I guess you'll have to be content with windows, Android, and iOs. Not meaning to be snarky, but can't figure out a way to write that which doesn't sound snarky. But that's about 90% of all screens in the world, so I can understand Microsoft not doing huge amounts of work for that last 10%. I wonder if you could just run the windows desktop apps under Wine? 
You could always write a version for core... if it is that valuable to the community as you expect it to be, you won't have to maintain it alone..
Could you fix the issue? If you found the problem and know a way around it consider writing a fix and creating a PR
Nope üòÅ Lots of it is still in a monolithic subversion repo, but some of it is ported into github enterprise. And defined as a role in our provisioning framework, so the owning teams can do DevOps deployments. Onto windows server 2016 datacenter. Of classic asp. It's still much better than depending on the cm team for deployments and the service management team for server management. There's a nice plugin for visual studio code for syntax highlighting. And there's a nice plugin that does "run this code of language x" which let's you test running vbscript snippets.
Why specifically EF 6? Is there something particular about EF Core in .net Core 3?
We have compounded our technical debt in such interesting ways over the years. We expose lots of our core dotnet functions to asp via a Com object. So classic asp can call SQL server 2016 and specify Application Intent=ReadOnly to be directed to the read replicas, using TLS 1.2. And it can call our Couchbase Memcached buckets for cached data (depends on another com object). ADO recordsets can be serialized and cached there. DotNet and asp can share the simple key-value caches. The only thing we can't get is new relic visibility. But... We could... Extend our original asp tracing functions to post to new relic API... There's always the temptation.
https://blog.couchbase.com/leveraging-the-power-of-couchbase-in-classic-asp-applications/ Enjoy üòÅüòÇü§£üòõüòúüòù
Not talking about SOAP web clients, talking about building the SOAP service itself in dotnet core, which is what the full framework does with WCF.
Ahhhhh. I did not have to build SOAP services myself. No idea what kind of work goes into that
It's not a wagon. It's a freight train to the future.
MVC core is a complete rewrite and one of the things they changed is that MVC Web API and their OWIN extensions are all integrated into one pipeline. That means rather than having to set up your CORS, Oauth and everything else up to three times with all sorts of horrible conflicts and mess you do it once. Integrating an identity server is much cleaner. Hosting your service in a container is dramatically easier and smaller. Load balancing is easier. You can still use IIS to do all the complex bits Kestrel can't do, but you can also use nginx or anything else you want. Core **already** has features full framework doesn't. Unless you have a dependency that isn't core compatible new work should be in core today. 
That looks confusing as heck to me üò∞
An assignment means the variable is initialized. Do you know what initialization is?
HostBuilder tends to look a little weird at first yeah. I'm still feeling my way through it personally.
In my original explanation I gave the reason why Microsoft doesn't support cross platform and never disagreed with it or said it was unreasonable. I'm asking why what I said was wrong. 
Here is my current error it doesn't match up with any packages I have ... &gt;FileLoadException: Could not load file or assembly 'System.Diagnostics.DiagnosticSource, Version=4.0.3.1, Culture=neutral, PublicKeyToken=cc7b13ffcd2ddd51'. The located assembly's manifest definition does not match the assembly reference. (Exception from HRESULT: 0x80131040) &gt;Microsoft.EntityFrameworkCore.Infrastructure.EntityFrameworkServicesBuilder.TryAddCoreServices()
Man that sounds like a fun project to fix up. [https://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052/ref=sr\_1\_1?ie=UTF8&amp;qid=1547954349&amp;sr=8-1&amp;keywords=working+effectively+with+legacy+code](https://www.amazon.com/Working-Effectively-Legacy-Michael-Feathers/dp/0131177052/ref=sr_1_1?ie=UTF8&amp;qid=1547954349&amp;sr=8-1&amp;keywords=working+effectively+with+legacy+code)
EF6 will be ported to .NET Core as part of the .NET Core 3 wave. EF Core sucks. If you have a project already on EF6 it is a severe downgrade to move to EF Core but with EF6 available on .NET Core it will be fine.
Examples?
Tools matter. Bad tools get in the way and should be dumped in the trash.
This already exists in IIS, https://www.aspsnippets.com/Articles/Encrypt-decrypt-WebConfig-section-using-aspnetregiisexe.aspx
Do you have a .Net Core ORM you prefer over EF Core?
It is optional, and it is not as hatd as it looks. 
aren't the attributes only for resharper? c# 8 non-nullable uses the "?" just like nullable structs. 
This isn't supported for .net core and it's json configs
I reread the article and I think attributes aren't used for c# 8 non-nullable types, only the "?" or Nullable&lt;T&gt;. 
Android and iOs are other platforms ?
No but some people prefer no ORM (or micro ORM). I think EF6 is the best ORM
You seem to be saying MS shops are stuck with it because MS is pushing it. If it sucks too much, people will *still* go elsewhere. Remember, you couldn't force people to buy Zunes (although you sure the heck tried). I find that a bit arrogant to be frank.
I specifically said Desktop.
Yep, for .net core I'd think you use Microsoft.AspNetCore.DataProtection; but I've never personally used it. 
Good article, but it‚Äôs Blazor from here on out. 
I haven't used it, but Entity Framework Classic looks pretty good. It's a fork of EF6 that runs on .Net Core. https://entityframework-classic.net/
Nobody is stuck with anything - everyone is welcome to stay on the .NET Framework if it works for them, but it‚Äôs not going to get the same focus and frankly isn‚Äôt even capable of receiving the same sets of features and progressing at the same rate. Because of this our main focus is on Core and that‚Äôs what we recommend using for new projects. It‚Äôs even open source so you can propose your own changes too. If you have a large .NET Framework deployment there‚Äôs no pressure to convert it, just be aware that you shouldn‚Äôt expect the same cadence of new features that there‚Äôs been with core or been in the past. Microsoft puts in a lot of support to a number of languages, frameworks, and tools. We honestly don‚Äôt care what tools you use; we only care that you pick the best tools for your own productivity. We offer a great set of first-party options that many people prefer and we‚Äôll continue to do that, but use what works best for your own situation.
We have several projects running on EF core, and have no issues. You have to verify what the query generator does, and sometimes have to rewrite queries compared to EF6, but you had to check that with EF6 initially as well. Can't confirm "very bad" or "tragic" at all.
[removed]
It won't even take much of your time. Basically it is the same as ASP.NET. If you ever used IOC containers, Memory Cache, Middlewares etc. you'll have easy time going through it. ASP.NET CORE is based on common patterns so it will be easy to jump in. You will get into the advantages of it as you use it.
`netstandard2.0` isn't the only option. If needed, you can multi-target very easily, so you produce both a `net4xx` and `netcoreapp2.x` version of your library (and any other platforms you need). There are advantages to both strategies, so don't just assume .NET Standard is always the "best" option.
For enterprise projects this just does not work. You always have to depend onother projects over which you have no control that uses SOAP contracts. This can be an actual service but in most cases it's an enterprise service bus which does not support anything but SOAP. This forced us in my previous project to use a self written java api gateway that translated the incomming SOAP messages to REST so we could process them in .NET core, which can run on Linux and therefore is easier to scale out using technologies like kubernetes and dcos. I believe .NET core is definitely the future and we should embrace it but the reality is enterprises are not there yet.
What I mean is that it‚Äôs hard to add it into a language in the optimal way, as opposed to if you had designed the language around it, such as with Swift. Some features you would like are missing. I didn‚Äôt mean it is hard to use. 
Does system.diagnostics require the SDK installed? You might just have the core runtime installed on the server. Do you even need it? Might just be able to resolve the reference?
Are you by any chance using multiple projects? If so I would recommend looking at solution package consolidation as we get this a lot when one project is ahead of another and then the projects are referenced to each other. The dll gets overwritten on publish and subsequently can‚Äôt be found by one of the projects.
Well, nullable types are basically optional types (Nullable&lt;T&gt; exists since c# 2.0). Languages like F# works with non-nullable reference types and with nullable types. 
It sounds like you have just styled a webpage. This is quite different from implementing authentication and processing the results on the server. You're also going to need some JavaScript to calculate the number of words per minute that someone is typing. From your post, it sounds like you have no server-side experience, and perhaps even no programming experience at all; and it also sounds like that's what you need. It also sounds like you do not yet comprehend the requirements of such a task. It sounds to me like you're going to need to learn some client and server-side programming in order to complete this. Since you asked on r/dotnet, that you would be C# with an [ASP.NET](https://ASP.NET) MVC website that persists results to a permanent backing store, e.g. SQL Server, using [ASP.NE](https://ASP.NEt)T Identity for user accounts. You can then process the collected data as required. I see that in one of your other comments here, you've been assigned this task on the grounds that you can learn how to complete it, and I wouldn't put you off learning; however if you're starting from the beginning, this will take you some time to learn all of the required skills to a good standard.
It will lower the overall complexity because you are separating by concerns. That however doesn't mean that you can't layer services on top of that to do more useful things with your collection of microservices.
Thanks. That's odd. I've heard nothing but praise about EF Core. I have used it myself on side projects - admittedly not extensively. It's a complete rewrite, therefore they have had the chance to correct some design mistakes they made with EF. 
Isn't 4.6.1 Standard compatible? What makes 4.7.2 more of a reliable experience? 
ya you are right .. I misread it.
A couple of years ago I started a new job as the lone IT tech at a manufacturing plant. I found out that one of their central applications was built in classic asp, running on a Windows 2000 server... About once a day the web site stopped responding and someone had to go to the machine and physically power cycle it. I actually had a great time porting it to ASP.NET Razor WebSite. Soo satisfying when I deleted the last .asp page from the (new) production server. 
Yes, but they keep adding new functionality sort of orthogonal to what EF6 has. Inheritance is a pain in EF Core, and TPT/TPC are not coming event with EF Core 3.0 
Gradual migration is what I found to bring the most pain regarding CI/CD. Having a mixture of old and new projects targeting .NET Framework, NetStandard and .NET Core in one solution - was a real nightmare. YMMV
That idea briefly crossed my mind, but if I'm understanding the github discussion rightly it involves an entirely new API, so it would be a significant effort in a domain I'm completely unfamiliar with. 
Razor pages. I didn‚Äôt get it at first, and it reminded me of web forms so I just dismissed it as a gimmick. I started using it on a recent project just to test it and I love it, it makes so much more sense. Also the example you gave of a downside isn‚Äôt even true, you can convert it easily or just use an MVC controller if you like. Though, you probably shouldn‚Äôt be trying to do that anyway üòâ
I just remembered a project a couple of years ago where we went from mvc pages to an angular app and it was really easy to just change what was returned. Have you been unit testing pages? I assume it is just as easy as testing a page on a controller. Any gotchas there? &amp;#x200B;
I'll admit to not having played with them much, and seeing them as webforms v2018. That said, they seem a lot better than webforms since they don't have tons technical baggage, and if I was making a really simple site I'd probably reach for them. But for a 'major' application I'd stick to MVC Core.
It's all about flexibility. Lots of apps have controllers that consist of nothing more than `return View()`, which is a sure sign the controller doesn't need to exist. When a controller is needed, use MVC, when you just need a page, use Razor Pages.
No, it will of course increase complexity of the system. The more microservices you have the more complex the system is. That is the trade off you make for it and I think anyone who has actually designed such a system would know that. You can as easily "separate by concerns" without having a http boundary between your services. OP: I can see such granularity in some cases. Usually when you have 100+ developers working on the project but even then you should think of creating to granular services. Distributed transactions are really tough and you will end up with them and many more problems to a much greater degree.
Yep, that is pretty much how my recent project has been going. We have both. MVC for web api and pages anywhere a view is served.
It‚Äôs kind of funny how the world goes. First we had ASP and PHP etc which mixed everything on the page, code and presentationeverywhere. Then we get WebForms with separation. Then we get MVC and all with even more separation. Then we go back to Razor Pages. I usually go for RP if the controller would basically be ‚Äúreturn View()‚Äù type of thing, or not a lot of code. It can still be separated from the presentation and works fine. Anything bigger I go for a controller to keep the separation better. 
Can you use RP and MVC at the same time? Also RP looks like winforms with designer partial classes.
Yes you certainly can use RP and MVC at the same time. Razor pages are more like having a class which just deals with a single verb of an mvc controller. So say for Edit you have OnGetAsync() and OnPostAsync().
I'm heading in the direction of going fully service based and leaving the UI to JS developers. Lets all move on from .net MVC and skip Razor pages entirely.
Yeah, but Nullable&lt;T&gt; is internally quite different from nullable reference types, which are a compiler feature. This makes it a bit inelegant. 
Our management doesn't feel like it's worth the risk to take on a redevelopment project yet. Maybe it'll be a cause for concern when Windows Server 2008 finally goes out of support. Even then, I am guessing that they will continue to keep it as is until the day somebody actually breaks in due to a Windows vulnerability.
Didn't know about that project. That's what the .NET team should have done from the start.
Yeah sometimes I have to rewrite queries that were perfectly fine in EF6 to raw SQL. Also I had already checked the queries with EF6. I didn't ask for a migration to something that I have to check and also generates worse SQL. And client evaluation makes lazy loading look like a good idea.
I make my service classes as small as possible within a larger web service project. Using a variation of the "vertical slice" approach, I can readily break up my web service into smaller micro services as needed, but I didn't want to have to manage that up front. 
Yeah... I don't know about that. The supposed fixes to design will allow them to support non-relational databases. Why would I use an ORM for non-relational databases, I can already describe objects in their client APIs because they are non-relational. The R in ORM stands for relational. And for that I get worse queries across the board, unsupported operations, ugly APIs and terrible decisions (client evaluation)
Yeah, they removed TPT inheritance officially because it can lead to bad performance if you have a lot of derived classes which you would knowingly and explicitly create. However they decided that silently pulling the whole database and evaluating queries client side was just fine.
Lazy loading is never ever a good idea
Yes, but client evaluation is requested to be off by default, and they are considering to change it. However, I am curious why they decided to enable it in the first place. It‚Äôs so radical and not explicit change in behavior compared to EF6 that it‚Äôs evident they will be hated for that decision by many developers. I hope, in couple of years EF Core will become mature enough. 
I‚Äôve been doing a good amount of this in my current project. Instead of MVC, I‚Äôm writing a lot of Web API controllers and passing that along for output via JS.
As a Microsoft employee, are you qualified to make this claim? I‚Äôve listened to probably a dozen interviews and podcasts from people from Microsoft who were delegated to speak on the matter and have stated the opposite: the Framework isn‚Äôt going anywhere and is going to receive updates and continued development.
Great! I think it is wise to use RP or MVC depending on the situation.
I'm holding out hope in the future for Blazor, but we moved on from MVC views and Razor Pages more than a year ago and our web applications have been substantially higher quality since we moved to Angular.
&gt;...will most likely ever only use Windows Servers and Win 10 in work situations &amp;#x200B; I think the bigger question should be why you think this is going to hold true? &amp;#x200B; It's one thing if you never want to always stick with what you know and have used. It's a completely different problem if you think every future employer you have is going to share the same perspective or decisions as you. &amp;#x200B; Though I am not a user of dotnet core, I look at it as an evolution of the platform, and not a fad, or bandwagon as you have so nicely put it.
Generally it is one of two issues. You probably either built your project for a version of [ASP.NET](https://ASP.NET) Core that is not on the server, or you are explicitly referencing a part of [ASP.NET](https://ASP.NET) Core (or .NET Core) with a version that is different than the version of [ASP.NET](https://ASP.NET) Core you are targeting. If you are referencing a DLL directly and copied it manually to your debug folder, then that could also cause an issue, as it might not be found at Publish time (though you should have an error in that case). &amp;#x200B; Assuming you installed the .NET core runtime on the server using an installer with the default paths...what is in `C:\Program Files\dotnet\shared\`[`Microsoft.AspNetCore.App`](https://Microsoft.AspNetCore.App) ? Is there a 2.1.0 folder in there?
This may slow down development considerably. Needing multiple developers to add a new field to an application seems like a bad idea.
Depends on context. For personal projects: Razor pages all the way. The ability to have dependencies specific to the action instead of the controller is awesome. For work, the way we inherit controllers/views across multiple solutions means Razor pages probably won‚Äôt work for us. But I‚Äôm looking forward to seeing what the new ‚Äúembed the Razor in the DLL‚Äù stuff will do for simplifying our builds.
I am wrong. I'd thought initially wpf and winforms in dotnet core meant support for that. Sorry about that
Yeah it is requested. Also it is requested that query generation becomes better. I have no doubt that EF Core 6 will be better than EF6. We just have to wait a decade for them to achieve it the same way we waited for EF to become usable. The thing is now we have working EF and didn't need to go through this pain to get at the same place I am pretty sure they enabled it because they couldn't make a presentation of the new tool you should migrate to at a conference that didn't support Max
It‚Äôs just buggy. Something that work in Core will throw exceptions from .NET. Even recently someone from the .net team tweeted about how it was a premature to push for compatibility so soon and 4.6.1 should be avoided for standard. There‚Äôs a bunch of issues on GitHub about it. 
There was a Microsoft product called Web Pages, or Web Pages with WebMatrix (it was very hard to search for, including WebMatrix helped). It's this basically. And IMHO, this is what _should_ have been the product which followed classic asp. Same thing, different tags. My shop evaluated whether we should go to asp.net MVC or to Web Pages. We went with MVC, largely because whoever named it Web Pages, destroying your ability to search for it, should have been fired.
Your comment is pure whataboutism. I say that client evaluation is bad and EF Core sucks and you go "yeah but what about the lazy loading"
You say that, but this is the direction many people are taking now. It will become more and more common. It very much depends how you're setup to function, where I work we're production teams and within teams we have .net devs, JS devs, and some full stack devs.
You can have very well structured monolith which doesn't equate big ball of mud. Stop doing noun driven microservices. Instead focus on composition architecture instead of layers which is easy to pull apart to match physical manifestations of your teams, business unit capabilities and external systems. Most places doing microservices are doing it as a form of premature optimization
I am the lead architect at a company with six devs including myself. We have a code base that started 15+ years ago. I don‚Äôt think having front and back end developers would work for us. I think that pattern is too complicated, we strive for the simplest code. 
It was not meant to be whataboutism, I was simply talking about lazy loading. You're saying client evaluation is bad. Well, EF core fully agrees with you and even logs a warning by default when it takes place, and theres a config entry to throw an exception instead. Yes, EF core acts differently from EF6 im some cases. Noone ever said that the transition will be two clicks. But without changes there's no improvement. And if client evaluation is your reasoning behind "EF core sucks", the problem might be a level 8 one
Microservices are not idea for *small* applications - all you will see is complexity. The goal of microservices was best described to me as "simplistic divide &amp; conquer": divide each separate component or domain context into its own little project that conquers its own separate little task. Now when you, or someone else touches the system, they only have to touch this one small little context and they don't have to know *anything* about how other aspects interact with it (other than following best practices). &amp;nbsp So on a small project, you're adding a complexity layer that doesn't make sense, right? I mean, you don't need a microservice just to give your *Hello, World!* application CRUD features. &amp;nbsp Now imagine you were tasked with making a large company dashboard application for up to 50,000 concurrent users (and I'm making this ugly intentionally): - They want a responsive SPA (with 2FA) that authenticates against their global SSO/permission source (call it ADFS). - You must be able to view/update your personnel profile with the company (ex: Oracle PeopleSoft) - You must be able to view/update the internal issue tracking board (ex: Bugzilla) - You must be able to view/update data in the CRM software (ex: SalesForce) - You must be able to view/update requests/approval/purchasing via a 3rd party website's API (ex: CDW) - You must be able to view/update some ancient internal software - for sake of pain and making it *slow*, let's say it's a desktop-only software and a robotic process handles inserting and retrieving data from this application - There will be no local persistence storage. - A year down the line, they want a mobile app that offers similar features, same SSO, no 2FA, but now they need it to also interact with the custom built internal inventory/sales system. At a server level, you have 6+ data sources or other systems you're communicating with, each totally different from the other one, and a few aren't even locally controlled. You have two separate presentation layers to support. That's a *LOT* of crap to bake into one application, and even more crap that can break when you make small changes. &amp;nbsp What happens when you need to scale up one part of the application because maybe it gets used the most? What happens if the VP of HR approves upgrading from HRSoftware v2.7.1 to v4.0.1 and breaks functionality in your application? Imagine you, as a newly hired developer, inherited this monstrosity as a single combined MVC/WebAPI application with a handful of libraries and were told to fix a bug that keeps happening or implement a major code change like adding API support for the mobile app. How hard would that to be trace the flow of the application? Debug the code? Create/Run code tests? *This is where microservices come into play most commonly:* each part within that application can be split into a microservice that exposes a simplified interface that provides other applications only what they need, nothing else, and can also offer the ability for multiple independent applications to utilize them. 
I was apprehensive at first, but after using it a bit I actually prefer it. Putting the controller logic in the view model for each view feels more natural than large controllers with many routes with separate model classes for each view.
I think that's amazing. However, it sound like you are seeking a challange. Try something new if the task is too mundane. Some tasks are ment to be templates to a certain degree since they are commonly occurring in projects. 
Thank you very much for such a good answer
While I completely agree with the above, A 'project' of that scope won't fit inside anyone person or teams head. So I would ask *(playing devils advocate for a moment)* for this kind of scenario, is the advantage more about splitting up the work into separate teams, rather than just the technology aspect? 
it absolutely depends on context. but for anything larger than a simple site (and will forever remain simple) go with SOLID principles. I guess I'm in the minority here, but I cringe any time I see any sort of logic in a view or viewmodel. I only put loops or simple if statements (on a viewmodel bool) in my views. viewmodels only have getters and setters. I also keep my controllers as thin as possible. use Automapper for converting domain models to viewmodels. separate concerns. abstract away complex logic. because you are of course writing unit tests for all the logic, right? I know this probably sounds like over engineering, but I have been bitten too many times by coupling between views and logic, and of course, PTSD from webforms. that being said, we have recently been moving more towards client side and Web API anyway, and that creates a nice, natural separation of concerns. 
The performance is better in ASP.NET Core.
Not sure how this benefits you
Are we listening to the same interviews and podcasts? Everything I've heard confirms the employee's statement. There are 2 billion installs of . NET Framework, and they can't ruin those. So, there will only be security fixes and minor enhancements (such as Win10 API). So, sure, it will see "continued development", but it is in maintenance mode.
I've tagged your site as it looks interesting, but yes CLR via C# is relevant. Remember that each iteration builds on the foundations. Even the new "Memory" are will make sense after you've read it. It's not obligatory, but if you have the time at least dip a toe in it.
CLR via C# is still largely relevant. I don't know how far the latest edition goes, but it may be missing Async state machines and Span and Memory types.
it makes your code easily debuggable and code coverage can be seen as quality indicator 
You can use Gmail aliases and some sort of filtering e.g. if your email is user@gmail.com you can setup user+alias1@ and user+alias2@ and they would hit the same inbox. 
From what I've seen (which is pretty limited for Razor pages, to be honest), I think they're about the same honestly. I'm abstract most of my logic out of Controllers and into a different layer of the application, so the Controller/Page is mostly wiring to the same things anyway. The logic inside the page/view is going to be pretty much the same either way - only presentations stuff. Conceptually, I like the idea of the logic for a given page being tied to its code directly in a Razor page more than a Controller handling several pages, that part seems a lot neater. 
grpc is a replacement for WCF, web api not as much
Then have devs learn c# and JavaScript? I don't understand why there seems to be an aversion to.
It is slower, unless you have full stack developers who know the front end and backend. But it‚Äôs also more extensible. Good to separate the two, especially if you‚Äôre supporting multiple clients from an API.
The sourcelink part is one I get and understand. But I am not sure how code coverage data in the nuget package is beneficial. (That is the way I understood that.)
Also, if the pattern isn‚Äôt helping you in some way (support for multiple clients, needing microservies to solve bottlenecks) it would be a very hard sell to upper management...
Oh that is the smart option. Well done! Thank you :)
The controller is there for separation of concerns. Just because it isn't needed now, does it mean it won't be needed in the future. If it is a super simplistic we application with no need for security, logging, or other possible complications ever that razor pages is fine. Otherwise the flex of MVC is definitely a life saver when real world projects start getting more complicated. 
The kind of devs who would like C# would hate JavaScript
the coverage data is published to the azure devops portal, not to nuget.org
Seriously we should adopt csharps rules: Rule 1: No job postings (For Hire and Hiring) Rule 2: No malicious, intentionally harmful software Rule 3: Posts should be directly relevant to C# Rule 4: Request-for-help posts should be made with effort Rule 5: No hostility towards users for any reason Rule 6: No spam of tools/companies/advertisements for financial gain Rule 7: Submitted links to be made with effort and quality 
Read the file as a string and deserialize it into a obj of your choose. 
Both have pretty different programming styles so it's daunting to some devs. Plus both are growing/changing at breakneck speeds so it can be exhausting to keep up with both.
Use System.IO's File static class to read the file to string format, then Newtonsoft.Json's JsonConvert static class to deserialize the string to a type of your choosing.
Hah funny... Our VFP app is source controlled in VSS üòÇü§£üò•üò´üò≠
I played around with some razor stuff and it reminded me of shitty php spaghetti code I used to write when I was learning how to program
Okay thanks its works 
.NET Core 3.0 will bring support for EF6 https://blogs.msdn.microsoft.com/dotnet/2018/10/04/update-on-net-core-3-0-and-net-framework-4-8/
I never said it was going anywhere, in fact I said: &gt; the .NET Framework will be around for a long time and continue to get support and updates The focus of the .NET Framework going forward is stability, security, and compatibility. Support and updates will absolutely continue - we've committed to perpetual support for it in both Windows and VS - but it's development is not going to be focused on innovation. On the other hand the focus of Core is Innovation. Core was an opportunity to rewrite things from the ground up without worrying about breaking changes. This has allowed for many changes that would never have been possible before. Core is where you'll see more language features, new standards, runtime improvements, etc. And these aren't my personal thoughts, I'm just reiterating what's been communicated both internally and externally from the .NET and VS team. 
&gt; (it was very hard to search for, including WebMatrix helped). I dislike this trend in naming things. It makes googling for documentation so much harder. I run a small-medium (leaning small) forum on the Invision Community platform and it's the same way. "Commerce," "Pages," "Downloads," etc. Even worse even including their company abbreviation ("IP") is included. Loooots of "site:" usage when searching lol.
Yes, what are you waiting for?
It really depends on the scope of the work. Sometimes it's a decision for future maintenance, sometimes it's a decision for future expansion, sometimes it's just to make it easier for initial development. I'm currently on a project of similar scope using .NET Core &amp; Docker, and there are only 4 developers on the team of 9 people: a UI/UX engineer who also serves as the Agile coach, a mobile dev, an Angular/.NET dev, and a straight back-end .NET dev (me). Basically the timeline is to build out the individual microservices, build the facade service that supplies the MVC/WebSPI, then build out the MVC/WebAPI at the same time as the mobile app. Timeline is about 6 months for the development with continuous testing. But, the advantage is that anyone can come along and work on this project and should be in good shape. If something changes and small adjustments need to be made, it's not a wholescale recompile. 
I think both MVC and Razor Pages can be used together, so controllers could be added later if you need one.
If you're server rendering html, Razor Pages is a better model than MVC.
&gt; I am the lead architect at a company with six devs including myself. We have a code base that started 15+ years ago. So am I, same number of devs, same age of code base. It used to be just 2 or 3 of us, and we used to be more full stack. Now we're much more distinctly front and back end, though all of us back enders are more than capable enough to add some fields end to end. We've all done significant front end work, and we've only had one or two truly front end only devs, our other primarily front end devs have been capable enough in the back end as well. It's much smoother for us to focus where we prefer and where we're stronger, and it definitely helps to reduce major context switching.
CLR via C#, C# In Depth, Writing High Performance .NET Code and Pro .NET Memory Management are my big four books for C# .NET Devs. Read all four and you'll know more than 95% of .NET devs IMHO. 
We use Azure Devops. Do you break apart your user stories into tasks for both devs?
&gt; it can be exhausting to keep up with both word.
Then have them use Typescript. 
Great read for a starting road map for a migration. I would (will) make one change to the migration with regards to deleting the code. Copying the code and deleting the code is a traceability nightmare in the future. It's better to maintain the traceability and move the files using your source control functionality.
&gt; Do you break apart your user stories into tasks for both devs? It depends. We built a new public website (Core/Razor + Vue + Core API) and main internal admin site (Angular 2-6 + Core API) last year and during main development yes, stories were almost always split. Now, changes and additions is maybe 50/50 if it's split between front and back end developers or if the back end developer does it end to end. We have a lot of HTML animation work that our front end devs specialize in and that can push simpler front end work to back end devs. There is a specific section of our public site that we almost always have a front-end dev take. Front end devs almost never implement a feature end to end at this point. We also have a number of developer-oriented system and operations tools that back end tends to just own, though we will ask for front end dev help at times.
Huh... Interesting. My team makes the applications that the business, approx 75 users, and clients, about 2000 users, use during the workday. We don‚Äôt have any fancy pants animations or anything. The developers tend to stay in one area of the business so they can gain domain knowledge. Do you run into issues where a front end developer is waiting on a back end dev or vice versa? 
I am been developing professionally for about 5 years mostly in C# and Unity. I change companies recently and I was thrown into a task of creating a dashboard and database with [ASP.Net](https://ASP.Net). I have never done web work before so I did not really know what to do so I started off with Razor pages. As my dashboard grew I found razor pages a pain to get done what I wanted. For example sorting a grid of data without reloading the page. I started to learn about AJAX and now I am doing full front end web development with ReactJS. I honestly much prefer my workflow now then I did with Razor pages. I know this is not ideal for everyone but it worked for me. I am in a position where I am creating tools that support a very large studio but I am also given the time to learn new skills to apply to the job. If you have the time I would suggest just skipping razor pages because the web front end skills can also be applied else where. &amp;#x200B; All that being said I am on my first project with [ASP.Net](https://ASP.Net) and have only been working on it for 3.5 months. &amp;#x200B; &amp;#x200B; &amp;#x200B;
We run a content service that provides things like news, weather, traffic, flight times, trivia, sports scores, stock prices, edu/entertainment in image, video, and html form to about a quarter million public displays around the world. Over a billion requests per month. Waiting on other people isn't too much of a problem, but we do spent a fair amount of time managing that. We plan mostly around weeks and quarters - what are we doing this week and maybe next, and what larger goals do we intend to complete in the quarter. In general, we don't have externally set deadlines, but they do come up roughly a handful of times a year where a client needs custom work or a new product ready by a certain date.
Lots of official examples at https://www.newtonsoft.com/json/help/html/DeserializeWithJsonSerializerFromFile.htm
Neither, I prefer SPA's with a REST API.
Our environments are night and day...
Thanks for your suggestions :-) After clearing all warnings, in my desperate attempt to do something., and removing the packagereference it finally loaded. Goodness knows why it was misbehaving, but its wasted a ton of time I could have spent more productively. 
But client evaluation is objectively worse :) As with everything else in EF Core they made things worse compared to EF6. My main objection to EF Core is that it generates significantly worse queries. This alone would be enough but I have more - Missing APIs like a query API to read a Guid, DateTime, string, etc from raw sql query. The suggested replacement API is worse because it requires declaring a wrapper class. (I have other examples but this one annoyed me the most) - client evaluation. True they removed lazy loading but client evaluation is worse - No TPT inheritance (or TPCT for that matter)
Yes, I know. EF Core shouldn't have existed. It was a giant waste of everyone's time. They should have gone with EF6 port from the start.
That's really neat. Good work
Here's some example code! ``JsonConvert.DeserializeObject&lt;{type}&gt;(File.ReadAllText("{path}");`` You'll have to put ``using Newtonsoft.JSON;`` and ``using System.IO;`` at the top of your file too. Replace ``{type}`` with the type of class you'd like to deserialize into. Replace ``{path}`` with the filename of your JSON file. Let me know if you need any help!
After 15 years in .net and the last 4 years in go I really do not miss exceptions at all TBH. Both are fully valid choices. I love both. My opinion is that this is a good opportunity to matter in the open source space where .net is a lot less present than go. 
God speed
.net core is not a Microsoft product per se. It is supervised by the dotnet foundation in which Microsoft is a majority member (in term of number of contributors). So saying that .net core is Microsoft "camp" is a bit disingenuous. I expect to see more and more non-Microsoft contributions to core. And while most decisions are at the moment taken by Microsoft's teams, I also expect more collegial decisions in the future ;)
Unfortunately there is a big difference between being able to conceptualise how something will function and actually implementing it. The first is easy, the latter requires specific skills acquired with a lot of practise and study. The problem is that ‚Äúnot knowing what you don‚Äôt know‚Äù (1st stage of competency https://en.m.wikipedia.org/wiki/Four_stages_of_competence) leads to over expectations of how easy a task will be and under expectations of how long it will take to complete. The is a lot to do here: user interface, log in, database, a way for you to see the results, measurement of typing speed, checks that what is typed matches was is required, generation of content for testing, site hosting etc. If I was to estimate how long it would take me (skilled in desktop dev and c#, medium in web page design, low in asp.net) I would guess two months minimum. This is not to discourage, but just to help reassess how long it will take. Especially if your boss is expecting something relatively quickly. 
Yes!
I feel that Razor Pages adheres to the Single Responsibility Principle better than using a controller. We don‚Äôt put logic in the RP, we are using the CQRS pattern with Mediatr so the View Model just sends off the request.
That is probably why we have TypeScript.
That is possibly webpages instead of razor pages. They should have named it something completely unique to avoid confusion
Good grief, read it all! History that is correct is very helpful to what's going on right now. History that's wrong is also useful, after awhile you know it was wrong and why. As a programmer you can't know too much. The only issue is time and prioritizing. If you've got the time for more C# details by all means read it. Learn C++ and you'll see the parallels. Learn Java and you'll see the similarities.
I'm not the OP but thanks for the list! I learn much better from books as well. 
Enterprise code monkey here. What‚Äôs the application of this in the real world?
I guess they can both be used well or misused badly. 
what I mean is say you have a ProductsController, you will likely have action methods of Index, \[Get\]Create, \[Post\]Create, \[Get\]Edit, \[Post\]Edit, \[Get\]Delete, Delete confirmed. that is a lot of different logic in one file. With razor pages in the folder /Pages/Products you would have a file for each verb. So Edit.cshtml.cs has 2 action methods OnGetAsync and OnPostAsync. 
Here‚Äôs a post by Scott Hunter explaining .NET Framework is not in maintenance mode. It is actively being developed on with new features being added: https://blogs.msdn.microsoft.com/dotnet/2018/10/04/update-on-net-core-3-0-and-net-framework-4-8/
They have already announced that ASP.NET Core will stop seeing releases for .NET Framework going forward. I believe they also said we won't see Span&lt;T&gt; support ever. So, yes, Framework will see "continued development", but it will just fall further and further behind. The updates listed in that link are new features but not in the same line of updates that .NET Core sees or will see.
[removed]
We're arguing semantics. I believe we're on the same page. Cool cool. 
Still a lot of switching context... as in, how you code mid tiers and back end, is not at all like doing the front end work.
Not all do. 
Man, I would've loved a video like this when I was starting out. Having to learn a lot of that stuff on your own is a total pain.
Honestly that‚Äôs the reason why I did it, explaining OOP with C# in a game engine is way more fun than learning it with JAVA by drawing circles hehe 
Depends on the team structure. As a backend developer, I can support 4 to 6 UI developers. I get the same specs as them, so I can usually have the REST endpoints ready before they need them. The alternative is having people who don't understand databases mess around with SQL. And no one wants that. 
And database design. Which is the most important because if you screw up your database design all of the other code becomes much, much harder to write. 
Why does it need to be so complicated? Also, if you are doing agile then the requirements often change, right?
As I see it, there's nothing 'complicated' about it. The UI devs focus on what they do best and I focus on what I do best. Having specialists allow us to move a lot faster than having people with a shallow understanding of everything no expertise in anything. 
I get that, makes sense. But why does the application need to be that complicated? Is there a simpler solution that solves the problem? 
&gt; if you are doing agile then the requirements often change, right? Yep. But that's no excuse for not taking the time to write a technical spec. The benefits include: * The ability to show the spec to the stakeholder and ask "is this what you want?". So much rework is caused by not verify the requirement was properly understood. * You can use this time to think through, and document, edge cases. Often this reveals holes in the requirements that need to be addressed. * With a tech spec in hand, you can offer a much more accurate estimate. (Like a real estimate, not "story point" bullshit.) * The tech spec also helps you identify what needs to be changed so you don't get half-way through the UI before you realize the database doesn't support the new design. * Finally, it serves as a starting point for the test plan. Especially if you have a QA team. 
In the type of projects I work on, everything starts with Angular for the UI. Once that decision is made, we don't have a choice about things like REST vs Razor.
Nice. Seems like you work at a good place that is on top of stuff.
I did in the Silverlight era. Now I can't be bothered to learn Angular so I stick with Razor for toy projects.
This seems likely. Check `this.HttpContext.Request` on the controller while debugging, it should be POST in there.
Oh no, it varies a lot from project to project. Right now I'm watching one project (multiple teams) not follow this rule and they are suffering insane amounts of overtime as a result. For another project my "requirements" are so detailed that I often don't need to write technical specs. I just scan down the checklist for possible mistakes and then implement it in presented order. 
Huh... well UI frameworks come and go...
"High DPI improvements" are just bug fixes needed to keep pace with hardware advancements. Definitely a "maintenance" issue. "Modern browser and modern media controls" is likewise a maintenance issue as they decommission IE and WMP. "Access to touch and UWP Controls" is the only real one, but even it is more of a stopgap measure while we wait for .NET Core 3 to be finished. 
Interesting. How do you decide when to use a SPA framework or plain MVC? Modern browsers are so fast it‚Äôs more about what we developers choose than anything else...
Bad analogy. jQuery is losing in popular because its 'unfashionable' not because its a dying technology.
It's not being killed off, just neglected. There are a lot of people who need WCF and there is no technological reason why it cannot be ported; its just an issue of manpower. WebForms, by contrast, is a hot mess. Did you know that WebForms requires at least one WinForms library? Microsoft reports that they repeatedly tried, and failed, to untangle the mess and just gave up trying.
Maybe, maybe not. A lot of companies depend on WCF for scenarios that your basic REST service cannot handle.
Which is why I'm a backend developer. I don't care what the flavor of the week is in JavaScript land so long as it can make REST-like service calls.
I care
Use an SPA if you are building something that feels like an application. Stuff that, 20 years ago, you would download and install. Use MVC if you are building something that feels like a web site. (Reddit, Wikipedia, a front page for a physical store, maybe an online store).
Code lens used to be a feature I missed. But I heard community has this too now.
I‚Äôll try to make a game with it.
In 2019, yeah.
I still don't understand why people are comparing Razor Pages with MVC, I really don't think Razor Pages are meant to replace MVC, rather work alongside MVC. &amp;#x200B; I personally can't think of a situation where I would choose Razor Pages over MVC entirely, but definitely can see a place where it doesn't really make sense to go through the whole MVC hassle.
First off because when you are scaffolding CRUD based on an Entity Framework DbContext you have the option to you have the option to choose either. When you start to look at clean architectural styles then Razor Pages makes sense to combat controller bloat and structurally you can have everything relating to the Use Case in the pages folder
Top 10 reasons I can think of: 1. ASP .NET Core gives you a leaner new project format and config 2. The middleware pipeline in ASP .NET Core is so simple yet powerful 2. The new tooling you get with .NET Core is very mature and super easy to use, i.e. using dotnet commands in the command line 3. You can switch back and forth between full VS20XX and VS Code if you have to, even if it‚Äôs on Windows only 4. There is considerable performance gain in switching to Core 5. As others have mentioned, the Windows-only .NET Framework won‚Äôt get the same feature updates as Core going forward. In fact, some C#8 language features will only be available in .NET Core. Ability to run cross-platform (for you and colleagues/collaborators is a bonus) 6. ASP .NET Core will only run on .NET Core, starting with version 3.0 7. Branching out from your current use of Web API, you should definitely take a look at Razor Pages, a great alternative to MVC for web page applications. 8. Going beyond Razor Pages, you should also take a look at the (still experimental) Blazor for full-Stack C# web app development, thanks to WebAssembly which runs your C# code in any modern web browser. 9. Not to mention, server-side Blazor (now known as Razor Components) will ship with ASP .NET Core 3.0 and will allow your Blazor app to run on the server side (with a few minor changes to configuration) by using SignalR to communicate between the client and server. 10. And speaking of SignalR, we finally got SignalR Core in ASP .NET Core as of v2.1 so it‚Äôs really a very complete and mature framework for all your web app and web api needs :) BONUS: EF Core has also gotten a bunch of new features as of v2.1 so I have started to recommend all of the above as of 2018. Enjoy! 
I've developed two projects recently using core MVC and Razor Pages. The projects are structured slightly differently and of course each page has sort of code behind page. Those are the two big differences. I think for speed of development it could be quicker to develop using Razor Pages if it's a small project. Overall I enjoyed the experience.
That's really rad, and while I can't say I've wrapped my mind around it fully it seems like it'd be a wet-dream for collaboration with less technical artists on games and such. 
`asp-for` only controls for which item you want the select to be. If you want ASP.NET to fill in the options also you need to use `asp-items` tag. 
The way you define `asp-items` isn‚Äôt correct. You can check this answer on Stack Overflow for more info on how to specify the properties etc: https://stackoverflow.com/a/34624217
nice! pls finish this tutorial as there are very less good and complete .net core vids out there.
No worries, we will, probably about 12-15 episodes total.
I wanna say thank you. Very good tutorials and topic to cover. I hope you have success in spreading this so more people can see it. 
Thank you! Once we complete the series (12-15 episodes I think), we'll try to spread the word :).
[removed]
Are you/have you covered how you are handling HTTPS redirects through the gateway?
Not yet, but what do you exactly mean? Gateway simply returns the data from internal services.
Then how are you handling HTTPS?
You can enforce a redirect using e.g. ASP.NET Core middleware or http server such as Nginx.
Okay thanks its works but i make it with Datasets 
Yes. You should. And you know 90% of it already. 
SignalR uses JSON as the message format by default, so you wouldn't have any issues on that side of things, but I don't know if there is a SignalR client for swift, so that might be a hurdle. You could always opt for a combination of SignalR and Web API, so that you can offer a polling API in addition to SignalR push, if that's appropriate for your app.
Google says there are at least two SignalR swift clients out there: * [Swift SignalR Client for Asp.Net Core SignalR server](https://github.com/moozzyk/SignalR-Client-Swift) * [Swift client for SignalR (iOS and Mac) ](https://github.com/adamhartford/SwiftR) The official documentation even links to the first one: [ASP.NET Core SignalR supported platforms](https://docs.microsoft.com/en-us/aspnet/core/signalr/supported-platforms?view=aspnetcore-2.2).
I appreciate the work you are doing so much.
Thanks!
Microsoft published it. Then they pulled it after 1115 downloads. Probably due to breaking changes. Can't you just clear your nuget cache, remove the package add readd it? ü§î 
well, i did use the proposed google'd solution, of going back down to 2.0.0. but why not have *something* on the nuget registry, mentioning what happened and then how to fix it? totally fucks your confidence that maybe *you* did something wrong, and that you cant trust pushing a build. 
Love ‚ù§Ô∏è this. Great point.
Mind blown. I don‚Äôt want to read it because my internal optimiser will overflow. 
Middle-school level article quality.
Completely deleting a package from nuget.org should be a rare occurrence: https://docs.microsoft.com/en-us/nuget/policies/deleting-packages If I was making guesses, I might wonder if 2.0.1 was published accidentally and pulled back quickly.
My first programming job consisted of maintaining a legacy PHP application where the main file was 30,000 lines long with one blank line between each line. It taught me the most important thing - how not to write applications.
So basically make it difficult for the little guys and easy for the big guys? Doesn't make sense.
What the fuck! That would drive me to alcoholism.
Don‚Äôt forget jet JetBrains Rider which can be considered as one of the best if not the best.net IDE.
any suggestions for improvement?
There are lot of available, documentation on GitHub is best to start for beginners. I found below tutorial to work with GIT in Visual Studio, may be this will help https://youtu.be/7_n-LfAAhiM 
Unfortunately, cascading drop-downs on a web page are something you need to implement in JavaScript. .NET Core does not include any pre-built "widget" or "control" for this like you might expect with something like WebForms or Winforms. There are any number of ways to do this, but your options are basically the same as with any other web page. You could use Angular, React, jQuery, vanilla JavaScript, or even find or buy a 3rd party control that does what you want.
I don't know about popper but jQuery, no. I remember this conversion being enough work that I just left those apps with bootstrap 3 and all net new apps got bootstrap 4.
It depends on what versions of jQuery and popper.js you currently have. The Bootstrap package.json list what‚Äôs required, https://github.com/twbs/bootstrap/blob/v4.0.0/package.json. From there, these are the jQuery and popper.js requirements. "jquery": "1.9.1 - 3", "popper.js": "^1.12.9"
In case you haven't seen it, Bootstrap has a migration guide on their site [https://getbootstrap.com/docs/4.0/migration/](https://getbootstrap.com/docs/4.0/migration/). Does not explicitly mention jQuery or Popper versioning though.
Just a side note. "Git" is the source control system, like SVN. "GitHub" is *an* online Git repository. It may be a little pedantic, but it's good to understand the difference.
If you're used to toirtosesvn, TortoiseGit is there obvious place to start. But the git tooling inside visual studio is good. 
Apparently there is some security vulnerability in 3, which is why people are moving to 4...so I‚Äôve heard
I think they were hoping for something more sesquipedalian.
Assuming you're upgrading to Bootstrap 4.2.1 then you should probably grab Popper.js 1.14.6 based on their CDN example. If you're only using the Bootstrap tooltip/popover components, I'd suggest using the bootstrap.bundle.js file and you won't have to worry about Popper version as Bootstrap will handle it for you.
FreeCodeCamp have a great video on understanding Git, also if using visual studio git integration the same principles apply
Or do some due diligence and go post on [/r/dotnetjobs/](DotNetJobs reddit) like everyone else. This is a discussion forum about dotnet. 
Something I started doing when I was last seeking employment was to build an interactive resume site. Include pdf/docx generation for downloading a copy in the user's preferred format. Make the site queryable via api (rest is fine, bonus points for graphql, bonus bonus points if you embed a fronted http client to demo it like some api docs do). Add the ability to contact you via email form, or to request access to references. Obviously include everything else you have in your portfolio with links if applicable. Add auth so you can hide private info and/or restrict editing ability. Keep a version history to allow for comparisons. 
In my opinion, you should showcase something that might help a potential employer to make money. For instance, a shopping cart application. You should show you know: - your security - your DB - a bit of front end 
Username checks out
Interesting. Coming from F# I just tried OCaml as a proof of concept for a production server. Came back to .NET with my tail between my legs. I assume things like an HTTPS server will be much easier and more reliable on .NET Core using `HttpListener`. Am I right?
Checkout Syncfusion [HTML to PDF in C#](https://www.syncfusion.com/pdf-framework/net/html-to-pdf), it uses popular rendering engines such as Internet Explorer (IE), WebKit, and Blink (Google Chrome) and it is reliable, accurate, and high performance .NET library. [C# HTML to PDF example](https://www.syncfusion.com/kb/9143/how-to-convert-html-to-pdf-in-c-and-vb-net)
And "Git Flow" &lt;&gt; "GitHub Flow"
This was true, but a newer version of 3 was recently released which fixes this. I dropped it into my Bootstrap 3.3.7 project, and everything just worked. [https://getbootstrap.com/docs/3.4/](https://getbootstrap.com/docs/3.4/)
Score! I‚Äôm Very familiar with FCC
Super! Thanks 
I've never been able to bring myself to use it. It feels lacking even from jet brains IDEs, sourcetree, or command line. But this is more because these tools didn't exist much when I started,so I had what worked really well for me down already. As for OP: there's always this to learn with : https://try.github.io/ Or codecademy: https://www.codecademy.com/learn/learn-git
Noted thank you
Ty! 
Yeah, this is a good idea - code something in the field of the job you'd like to work in.
I don't see why only having basic CRUD features would be a problem. You can still showcase that you can build a solid architecture with a good test coverage and produce a working application. Not sure about what would that be, maybe a cost tracker with basic user account management and a solid dashboard + crud operations for handling adding / removing etc.
I've put together a list of .NET technology resources for junior devs here, its prolly worth checking out. https://github.com/AdamHess/TrainingMaterials
I can do everything I need to from tortoise git. Been using it for almost 6 years. Jet Brains IDE‚Äôs hurt my head. Source tree is okay. To each their own. 
[removed]
The little guys still have to shell out a min of $100+/hr for the same skills the big guys want and there‚Äôs a 99% chance you want someone to work for min wage. That‚Äôs why we don‚Äôt want these posts here. And if I‚Äôm wrong and you do have a realistic budget for this project, I‚Äôll gladly submit myself at $150/hr.
Yup. I largely use command line. If I'm working on our android app, I'll use jet brains (or forget about it and tab over to command prompt). And source tree I mainly use for the revision visuals and better diff view. I've never actually used tortoisegit, just the svn variant. Best part about all of these, you get to find what you like the most.
+1
I was able to figure out how to do what I needed. My main goal was to be able to turn proxying of certain endpoints on or off at runtime. This should have occurred to be before, but MapWhen is the way to go rather than Map. Then, I can just include whatever condition I care about in the evaluation. &amp;#x200B; Example: { var mapIt = false; // &lt;-- how i can enable/disable this particular proxy attempt at runtime app.MapWhen(ctx =&gt; ctx.Request.Path.StartsWithSegments("/contentService/v2/strings") &amp;&amp; mapIt, builder =&gt; builder.RunProxy(new ProxyOptions { Scheme = "https", Host = "webservices.h5c.co", Port = "443" })); app.UseTestMiddleware(); if (env.IsDevelopment()) { app.UseDeveloperExceptionPage(); } else { // The default HSTS value is 30 days. You may want to change this for production scenarios, see https://aka.ms/aspnetcore-hsts. app.UseHsts(); } app.UseHttpsRedirection(); app.UseMvc(); }```
You do not learn git, you just get used to it
What a pointless article.
I moved our old asp site to windows 2012 before porting it, so it shouldn't be a problem if you need to migrate it later on. 
It learns you!
Thanks 
Can you please elaborate? Was it pointless because you already knew everything the article mentioned or that it didn't have a "central point" or something else?
Has little substance. It just makes a load of random points without any depth, no real comparisons or analysis. I am experienced in .NET but if I wasn‚Äôt, this doesn‚Äôt really help me nor make me want to invest in .NET.
A couple of things I use frequently: * IntelliTrace (historical debugging, e.g. being able to step backward) * Live unit testing * Code coverage analysis Some things I have been meaning to try: * IntelliTest (auto-test methods with a bunch of different inputs checking for exceptions etc.) * Architecture/dependency validation (plus live dep. validation new in VS2017) That's off the top of my head, some of the features listed on the version comparison page I have no idea about Maybe I shouldn't have said "you won't get on any other IDE", I was mainly thinking of comparing to the free VS edition. I'm not too familiar with Rider but I use ReSharper and I know it provides alternatives to some of the stuff above like live unit tests (I do however usually prefer the built-in VS implementations). Going back to the topic of whether people adopting .NET still helps MS: Point is, a lot of this stuff is big for large companies and you're gonna have to pay *someone* for it. A large percentage of new adopters are gonna go with VS and some will want to pay for VSE, even if competitors like Rider are good alternatives (and of course, some things Rider cannot do yet)
want some redundant dotnet dot dotting ? https://try.dot.net/ :)
That's actually kinda neat. Like a minimal https://dotnetfiddle.net
 needs more dots ! dot.net.fiddle.dot.net ?
I recommend being able to demonstrate that you can work with data and relate objects of significant types. 
* If you use social media, aggregate your online activity to a single timeline from multiple API sources - e.g. tweets, instagram posts in a chronological order * ... or if your use is limited, redefine a way of showing the information available - e.g. graphs of information for your github profile page * show a new way of presenting your CV or profile by filtering - e.g. filter / highlight languages important parts e.g. tech, languages, principles 
Thanks for the feedback. This was certainly more of an overview, but I'm planning some more detailed content, especially around async streams and Unity. I hope some of it will align better with your interests. 
What I‚Äôd say is, choose a target audience. Are you trying for the newbie/just getting into coding group, who are at the moment bombarded with 100 technologies from mobile development, to ML/AI? Or are you looking at experienced devs who might be on another platform (ie Java)? That‚Äôll help you decide what content and at what depth you should go into. This overview for example, is still probably too high level/abstract for a beginner, and also too basic for experienced devs.
I believe you should consider to do some 'architect' works, such as import DI in your projects, and maybe separate your project to multiple libraries. A 'clear' structure is a big plus for your project.
Here‚Äôs my take as a senior dev who regularly interviews people. Build a project to completion. Like maybe a website for yourself with an About and a Projects tab. Just complete it and make it look nice. That‚Äôll show you know the gist of routing, html/css, and models. Once you have that. Start implementing some cool patterns or new technologies into anything. It can be your website. It can be a new project. It doesn‚Äôt matter. But if you have a half completed project but can explain to me how you implemented dependency injection and why that is huge! If it‚Äôs finished or not doesn‚Äôt really matter to me. I don‚Äôt work for free so why would I expect you?
I would love if someone made an awesome pdf document creator that wasn‚Äôt crystal reports. That would probably work better as a NuGet package though.
I think people are pushing IdentityServer because they've done a lot of the work for you. It's not difficult to setup JWT with IdentityServer 4. &amp;#x200B; If you're looking for something "built-in" that you can start with there is the Microsoft.AspNetCore.Authentication.JwtBearer library.
Do you know of any sample projects with those specs? I know the official Microsoft page has an mvc music store but it‚Äôs pretty outdated.
Build something u find interesting. My side projects involve data scraping then doing something better with the data then already exists. Which usually involvea building an app to serve that data. Im not a fan of mac so I prefer to use core api rest services and put an angular app to do crud on that
IdentityServer4 is different than Microsoft Identity. Although, you might use it on top of Microsoft Identity. http://docs.identityserver.io/en/latest/ 
I am so so so so glad you have been honest with your employer. Good luck to you. So many people think it's ok to take it toll you make it and it's ruining this profession.
Master the Visual Studio IDE. Keyboard shortcuts &amp; window splitting FTW! Embrace unit testing. Understand unit v. integration tests. Lean on the Test Explorer. Embrace continuous integration and atomic deliverables/checkins. If you go more than two days without checking-in/commiting code to an integration branch you're setting yourself up for problems. Ideally you've got frequent small changes flowing daily. Immerse yourself in the leads POV. Don't be a disingenuous sycophant, but listen &amp; *hear* what they're saying. Grok the business domain and the existing code base. They'll likely have some form of coding standards documented that you should follow. Usually it's easy to follow the patterns laid out in existing code. Don't be afriad to bring your own expertise to the table though. You'll be junior and the FNG, but hopefully, they've recognized your talent and aren't looking for a mindless grunt.
Understanding the basics of ASP.NET is extremely important. I would give a quick run through on the desired tutorial based on their technology: [MVC 5](https://docs.microsoft.com/en-us/aspnet/mvc/overview/getting-started/introduction/getting-started), [Web Forms](https://docs.microsoft.com/en-us/aspnet/web-forms/overview/getting-started/getting-started-with-aspnet-45-web-forms/introduction-and-overview), or possibly using the new [ASP.NET Core MVC or Razor Pages](https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-mvc-app/?view=aspnetcore-2.2) Understanding the basics of C# would be great - not sure if you did Java or C#, but if you did Java, you'll see very familiar items. Once you have the basics of the language, you can start looking into items such as LINQ and Await/async . Best of luck - out of everything I look for in a new developer, it's the desire to learn. Do not be afraid to ask questions, spend some time trying to solve a problem yourself when you get it (not too long) and let your other developer know what you have tried. This should help build a good relationship and expectations. 
&gt;Authentication.JwtBearer Yes, the examples I give have Microsoft.AspNetCore.Authentication.JwtBearer , it's not that hard and the examples given are very good. I'm understand why this isn't #1 in microsoft docs on day 1 of core release. I don't understand why people want to run their own server for Identity, then I might as well use something like firebase, auth0 or azure ad, which is fine, but I always run into some probably where something is in compatible and I have to start writing custom code, so my own token I create on Web API, using a decoded key is much simpler. &amp;#x200B; I just don't get it, isn't it much easier and more scale-able to decode with encryption, get all your claims. Then start you project with Identity server, worry about the deployment of that or your 3rd party token server, then get some requirement that's incompatible with your token server, so you have to go back to your own anyway. Yeah, forgot password and 2 factor can be a pain, I suppose it depends on the project, but it never saves time in my opinion
Thank you for all of the input. I‚Äôm going to look in to everything you mentioned! Is there a good source for keyboard shortcuts? That and code snippets is something I really want to become familiar with but I‚Äôm not sure where to learn. 
Just be honest with what you don't know, own your mistakes, don't be afraid to ask stupid questions. 
[Here's](https://docs.microsoft.com/en-us/visualstudio/ide/default-keyboard-shortcuts-in-visual-studio?view=vs-2017) the default VS Shortcuts. Ctl+Shift+B (Build Solution) is the "Wonderwall" of shortcuts. I wouldn't worry about snippets, they're cool, but more novel than practical. At your level, it's just not it. At advanced levels, T4 templates to generate code are more practical. You'll need to check with the lead/existing code; but as you get into unit testing, [mocking frameworks](https://docs.microsoft.com/en-us/ef/ef6/fundamentals/testing/mocking) are crucial. Especially as it relates to EF contexts. Moq is a prominent library for this.
The package is called ‚ÄúIdentity Server‚Äù but it is not related to Microsoft Identity, and it does not need to be a separate server/application. Its not a Server. It‚Äôs still just a NuGet package with pre-rolled configurations for the various authentication flows. I really dislike how they named it. You can disable everything you aren‚Äôt going to use. You can still do all the claims transformation you want. You can still use any user backing store you want, including Microsoft Identity if you so choose. I‚Äôm not swearing by Identity Server though - I personally prefer to avoid big project-defining packages like that. But it may be a viable solution depending on your use case and I have used it in the past. As for future requirements causing issues, obviously that‚Äôs always potentially a problem and something to consider when making your decision. I think you could benefit from doing a walkthrough of the Identity Server 4 documentation.
Careful with the stupid questions. There's a balance that you can overdraw from here. Try to batch these and schedule one:one time with the lead to ease the burden on team members. Open communication is key, but you can easily get a bad rep among the team if you're continually "googling" other developers.
Sign up for a free 10 day sub to Pluralsight and check out some of Scott Allen and Paul Sheriff‚Äôs videos. Agree with the post above, give respect to those trying to teach you and be eager to learn. That is what they want most. Look into design patterns and again as stated above, learn the kB shortcuts in VS. snippets are your friend. There are loads of podcasts to grow and keep pace with the advances. .Net Rocks, Hanselminutes, Herding Code and Coding Blocks are some of my favs. I look for those who are part of a collaborative project, create apps or manage personal websites. It shows they have passion and will learn on their own. Unit testing and proper OOAD will take you far. Headfirst has a simple book on OOAD and design patterns. Check Humble Bundle often to snag a collection. They change them often so check weekly. Good luck, I hope this helps!
Haha, I didn‚Äôt want to get myself in too deep! Thank you for the well wishes! 
Agree entirely, then there are those who go to a conference and think it counts as knowledge of the domain. Well I watched the presenter write Angular code so I know it right!? No pal, just no.
I would love to use firebase, auth0, or similar, but within my enterprise that's not an option. Yeah, it would definitely save me lots of time and pain. And unfortunately, my enterprise-hosted solutions don't meet user requirements, so I'm stuck implementing my own authentication and authorization stack. That's why solutions like Identity Server exist. Still far better than rolling my own from scratch.
All you need to learn git is ohshitgit.com ü§£
Ah, maybe it's worth it if I need to also add Google logins
Thank you! I‚Äôm going to check out all of those links. My university uses Java to explain most OOP concepts so I‚Äôm very familiar with it! I appreciate you mentioning things that you look for! I‚Äôll try to keep those things in mind! 
What was the Udemy course you took and how was it? Thanks!
It‚Äôs called ‚ÄúThe Complete ASP.NET MVC 5 Course‚Äù by Mosh Hamedani. It covers the basics well and you spend the whole class on one project so it‚Äôs nice building a complete project and seeing it all work together. However, some of the stuff is outdated and you‚Äôll need to be prepared to troubleshoot some frustrating problems because of that! It‚Äôs definitely worth the $10 you can get it for, but you might could find a more up to date course. 
I am going to use identityserver for SAML. if it wasn‚Äôt the case i wouldn‚Äôt use it. 
Both firebase and auth0 were hard to implement with react-native and it was very hard to customize styles for the login for mobile. Firebase was much easier to use than auth0 though, even got it going well in c#. Firebase also will automatically log you in on android devices without having the user type in a code, I really liked it.
Thanks! I‚Äôll check all of that out. Especially the podcasts, I‚Äôm always looking for new ones! 
visualstudioshortcuts.com
Be a sponge and ask a ton of questions. I would rather answer a million questions than have a dev who fucks up because they didnt understand something and didnt speak up. Learn the business. Why are we making this change? How does it help our end user? I can't tell you the amount of times I have been able to save myself work and others headaches by understanding the business case of a request, and either showing them a better solution to the problem, or seeing that the proposed solution did not fix the actual issue. Continue to learn and grow. Find a way to learn from everyone and everything. Next year you should be twice as knowledgeable and twice as good as you are now! Congrats!
Agree mate. There's questions and there's intelligent questions, more refined. It shows that you have taken effort to develop some understanding. Also, look things more in abstract way, implementation bit will become clear as you spend more time. Good luck
Thats actually a pretty good idea.
I am using the same approach in my hobby project. Couldn't handle dealing with error in my free time. ngrx is perfectly fine, it allows me to be as flexible as possible and implement my own caching strategy, where Apollo doesn't have one without cache invalidation. There are also downsides, you can't think of components fetching the data they need anymore, as you can't leverage the batching behavior for requests. I am using `graphql-request` as a dependency. import { Injectable } from '@angular/core'; import { GraphQLClient } from 'graphql-request'; import { Variables } from 'graphql-request/dist/src/types'; import { from, Observable } from 'rxjs'; @Injectable({ providedIn: 'root' }) export class GraphQLClientService { private client = new GraphQLClient('/graphql'); public request&lt;T, TVariables extends Variables = Variables&gt;( query: string, variables?: TVariables ): Observable&lt;T&gt; { return from(this.client.request(query, variables)); } } 
Yes, although I'd use Kestrel instead (ASP.NET Core, especially bare-bones, doesn't have much overhead).
Bonus points for being honest !!! I'd start by looking at the way the other devs work, and following that at first. You dont want you work to be an island of differing standards, so for now just make sure your work "fits in". Once you've been there for a while you can understand the business domain and start to suggest changes 
One tip is to email your new company and ask if there is any other technology they're using or topics you should be aware of, just so know what to expect. Then in the time you have remaining, so a little research or learn about that topic/tech. &amp;#x200B; For example, if the company are using other services or tools such as elasticsearch or Azure functions. You at least have some time to get a little grounding on those tools. &amp;#x200B; Doing this should demonstrate some intiative and enthusiasm. Congratualations on the new job and good luck!
While this is the kind of future for web development I hoped to start seeing it‚Äôs still bizarre....
Listen to the users, read and learn the business requirements, understand the functionality of the part of the app you are working on. Do not worry about knowing the technology. This is an existing app, chances are it already has code, screens, functions, objects, etc. similar to what you need to work on which you can use for reference. 
So it happened. Another 15 years in Windows forms . Now in browser‚Ñ¢
FYI: Google is changing its login system right now as it's shutting down Google+ logins. For the .NET Core built-in stuff, [this Github page](https://github.com/aspnet/AspNetCore/issues/6486) has a workaround.
I wanna see a win forms app hosting a web view with a win forms app inside that running with wasm 
Just as soon as Electron.WASM is ready we can start work on Electron.Net.WASM
If works do not touch
Thanks. I hate it.
Thanks, I'll look into it. Good luck!
Next up - a drag 'n drop RAD IDE for single page apps.
...This is amazing. I need to send this to my coworker who thinks pushing a branch before a feature is 100% complete will mess everything up. 
It's not really working for me...
Good question, also really wish they didn't wreck the out of the box solution you got with mvc/webapi with AccountController. Now it requires you to roll your own in core
Nice effort tho, it needs more work
Reminds me of VB6 ActiveX Documents that could run in IE (hopefully without the security risk).
Just check the official documentation for *self-contained deployments*.
The main reason is that enterprise systems mostly use Java or C#, and Java is still not that fun to work with. .NET has made lots of strides with .NET core. .NET as a web api/a front end javascript framework together seems like it'll be a popular thing for enterprise web apps for years to come.
Sample only loaded in Chrome for me...
That's amazing!
The publish tool allows you to select whether to use self-contained deployment or not.
Not for any practical reason...UNLESS it's part of a distributed / microservices architecture / requires specific settings to run (the benefits of containerisation basically). Check out [https://www.ifesenko.com/blog/2017/01/18/Windows-Containers-or-Dockerize-an-existing-ASP-NET-MVC-5-application/](https://www.ifesenko.com/blog/2017/01/18/Windows-Containers-or-Dockerize-an-existing-ASP-NET-MVC-5-application/) for how to do it if you really want to though. 
Delphi had [IntraWeb](https://www.atozed.com/intraweb/) almost 20 years ago; it used the same visual designer as the desktop apps but converted it to HTML/JS and a backend IIS DLL. It was totally a hack, but it was a pretty neat hack.
compiling a self contained Windows application is as easy as `dotnet publish -c Release -r win-x64` &amp;#x200B;
Perfect! Thank you so much! Glad to see it is that easy. I was using \`dotnet publish -c release\` but only getting the DLL's. This worked perfect.
Thanks all
You need to take a magnet to his machine. Only way some people will learn. Branch, develop, push frequently
One other thing. Even though it does make an EXE and works, it is not self-contained. I ran ````dotnet publish -c release -r win-x64 --self-contained true````, but it is still looking for a slew of DLL's. In my publish directory, there are 217 files for a basic console application.
This is so awful in practice but so amazing in theory. I'm glad it works, though.
It's probably worth it if you're using cloud hosting that supports it, as your production environment is basically the same as your test environment. Other arguments about scalability et cetera obviously depend on your specific needs and may not apply here. &amp;#x200B; Don't bother with Windows containers - they're horrible. Containerisation is pretty much the MVP of dotnet core, and in dotnet core that means linux images.
Well, currently the app is on a shared windows hosting. I have a spare linux VPS, so I thought to dockerize the app and put it on VPS. I'm almost sure that I won't scale the app nor will work on it anymore, since I moved to asp.net core. I just need to have it live for a portfolio. If I decided to dockerize asp.net core apps, I shouldn't use windows containers at all?
Nothing from that. It's just a simple CRUD app. So I guess I will leave it as is.
The official aspdotnet core images are actually Linux images. It‚Äôs just faster and more efficient all round, really.
Do agree!
Worked for me on Firefox and Edge
Working on it :D
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/csharp] [Wasm.Winforms nuget is ready!](https://www.reddit.com/r/csharp/comments/aj20j7/wasmwinforms_nuget_is_ready/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
nice job! how do I host on web.core.windows.net like yours?
&gt; I was hoping it would work like a web packager, where it would only include the libraries that are necessary to run the app, and then package a self-contained exe That is not how it works. You could look into a tool like https://github.com/Fody/Costura and https://github.com/dotnet/corert will be coming eventually
I use azure...so I think thats the default...maybe?!
Amen to that. I've been hammering on him to get a fucking branch pushed he's been working on for 8+ weeks now.. Yes, 8+ weeks.. 
To note, if you sign up for [Microsoft Dev Essentials](https://visualstudio.microsoft.com/dev-essentials/), you can get a 1-month free trial for Pluralsight.
Just wanting to see how it works is a perfectly valid reason...but don't go doing it for a production app until you know more about what works (and what doesn't!)
If you already are doing CI, scripted deployments, scripted environment provisioning, etc., then yes I think its worth it because it simplifies server and dependency management. I prefer my servers to be as minimal as possible and cleaned of necessary dependencies, etc. With Docker my server stays pristine. I don't install frameworks, or languages, or any of that, because each container has its own version of all that. I don't deal with upgrades or any of that, because thats basically moved upstream to the container definition. I don't have to deal with installing those frameworks or dependencies correctly because, again, its moved upstream to my base containers. I don't have to worry about conflicts between apps needing different versions of frameworks because each container has its own copy of its own dependencies. Its not that its COMPLETELY different, it just solves some headaches around dev ops stuff... at least for your use case. If you have to build something out and want to start talking Kubernetes, or cloud host providers, etc., then of course it has other benefits that you probably don't care about. But I totally converted. Hell, a lot of the stuff I might need to develop locally for stuff, like Redis, RabbitMQ, even SQL servers, etc., I sometimes just run in a Docker container locally. Its really cut down on that itch to reload my machines every year or two because the base systems just stay clean.
The problem with Delphi isn't Delphi. It's the tooling. MSBuild 2.0 project files that get overridden just by opening the options, constant crashes, eye-burning UI, insane pricing and a buyout of Borland to literally reap license fees and not produce any meaningful improvements. Delphi developers are literally more interested in a 3rdParty IDE Fix/Hack pack than for the bland release notes of the IDE.
This is equal parts hilarious and terrifying. 
It's important to demonstrate value by critiquing their existing codebase as much as possible when you get there.
Oh, absolutely. I loved Delphi back then and would love a decent RAD tool today, but it totally went off the rails when they decided to chase Microsoft instead of focusing on their own stuff.
You can upgrade your build to 4.7 while still using older libraries. How much trouble a particular upgrade is depends on how your projects are setup and what version jump you are doing. If you have a dev server I would just try bumping to 4.7 on it and doing some testing. 4.6&gt;4.7 is not a problematic one from my experience. 
Right on. After some digging and prodding and planning for maintenance, it seems like the ticket was very poorly worded and only needed to be upgraded on their workstation not the server anyway but still good to know. Thanks!
And if you are *not* doing CI, scripted deployments, scripted environment provisioning, etc., then it's worth it because you currently have a fragile, manually deployed app that is hard to migrate or redeploy, so you may as well bite the bullet. The next dev who has to deal with your legacy-ware (once you've moved on due to your Docker enhanced resume) will thank you.
It is a risk. All the dotNet 4.x platforms are "highly compatible in place upgrades". They replace the earlier version. Having said that, we have had no problems with any of the upgrades.
Been using .Net since the late 1.x years and have never had a framework upgrade break anything
Nope, self-contained refers to the folder you're publishing to. It will only have the needed libraries and bits from the .NET Core runtime. Your application is still a DLL. However the dotnet.exe is renamed to your application EXE so it's easier to run.
You'll be happy to hear .NET Core is going to be flexible in that regard. Each version is installed separately. By default apps will opt into bug fix releases on top of the version they were compiled for, if available. But apps can also specify a range of versions to run under IIRC.
Thank you.
&gt;You'll be happy to hear .NET Core is going to be flexible in that regard. Each version is installed separately. By default apps will opt into bug fix releases on top of the version they were compiled for, if available. But apps can also specify a range of versions to run under IIRC. Honestly, by using the phrasing "Target" I had kinda figured they went this route already. Appreciate the insights!
Thank you for the clarification. Much appreciated.
_triggered_
It's also worth mentioning it only applies to console applications. If you are making an application to run under IIS you still need the AspNetCore module installed into IIS. Obvious in hindsight but somehow I thought it would still work without installing anything. I guess this is why ASP.NET Core projects are not self-contained by default.
Since OP mentioned mvc5 the .net core images won‚Äôt work. MVC5 is .net framework , not core . So that means windows only. With that said windows containers have gotten a lot better , especially using the 1709 build of windows server as a host. We have a full ci/cd pipeline pushing to a swarm, including dynamic routing with traefik. It honestly works pretty well and we have had no major issues . My biggest gripes with Windows container images is the size , they are huge . The windows server core image is still orders of magnitudes bigger than the .net core images or most alpine based images. 
I've had no issues with windows containers. A lot of "horrible" stuff there is mostly related to intercontainer networking. I've tried it with simple .net 4.6 web app + SQL server but ultimately decided against it in favor of azure web apps and azure SQL. 
To back up what you said: [Application Compatibility in the .NET Framework](https://docs.microsoft.com/en-us/dotnet/framework/migration-guide/application-compatibility) Generally going from 4.x to another 4.x is 'ok', but sometimes there will be issues. The bigger the application, the more risk that it won't run on a different version without cleanup. Your average enterprise web application requires changes to upgrade between 4.x versions.
I wait for a point release. So I'd wait for 4.7.1 to come out, not jump on 4.7.0. Risk averse
Never really had to. One consideration nowadays is 4.6.2 is the lowest you can be and consume libraries targeting dotNet standard
[It's happening.](https://www.destroyallsoftware.com/talks/the-birth-and-death-of-javascript)
MVC is a separate thing. It runs on .Net, both Core and the full framework. Essentially the idea of .net is that all major versions are compatible at runtime level - so .net core 2.0, 2.1 and 2.2 shouldn‚Äôt require recompilation if you use MSIL binaries for it (you probably won‚Äôt in core, just on framework) Windows Forms is being added to Core, apparently, which is going to be interesting :)
MVC 5 is from ASP.NET (note: no Core). It was the server framework that ran on the windows only .NET Framework and IIS. ASP.NET Core is similar, but was rewritten to be open source and run on .NET Core.
Hey bud. MVC 5 = ASP.NET MVC 5 which came before ASP.NET Core. If they kept the same versioning Core would be MVC 6, but the nomenclature has changed because the platform has changed - being that ASP.NET Core was built on .NET Core and MVC 5 was built on .NET Framework.
In addition to all the other good comments here. The Core semi-equivalent of MVC 5 is using the MVC pattern in ASP.NET Core. You should probably focus on sticking to stuff with the Core suffix. E.g. Entity Framework Core, .NET Core, ASP.NET Core
I have had issues with references to packages that used a library of .net framework but also existed in nuget as dependencies for other packages. I believe it was the System.Net.Http package; and then other projects in the same solution would have issues because things were not segregated enough were a dependency existed in more than 1 layer and redirect bindings were not getting updated correctly. Eventually I tried to update the dependency in all projects in a solution, where we had went down a path of having some shared libraries where the class library project was brought into the solution which meant all of our solutions required the update if that library was a higher version than the root project in another solution. If you have some shared class libraries that act as wrapper for specific packages it could become problematic; you can most likely remedy this by compiling them and distributing them via a private nuget server. Or making sure your redirect bindings are correct in the root project of the solution. I would definitely run the tool [Application Compatibility in the .NET Framework](https://docs.microsoft.com/en-us/dotnet/framework/migration-guide/application-compatibility) that /u/wllmsaccnt mentioned as it will give you a list of all dependencies and what is compatible with your change. 
Good to know. Thanks.
Just a heads up MVC Core version numbers and other libraries like that do not always match up with the .NET Core version you are running from my experience. 
That would be what WiseJ does :)
It used to be 6 months -&gt; 3 months -&gt; now 1 month :(.
Winception
I don't understand the purpose of this. If win forms is run on a website and you run a long operation e.g. scrape 10000 URLs, parse, commit to Db. Won't requests time out? If not then there needs to be some long polling and a cancellation token on the api doing the work. Not only that but an api is simply not supposed to do batch jobs / long running execution. You would normally create a msg and process it else where e.g. azure app function. Or does it not work like this? If you want to use a console app with core can't you just use a bridge class with. Net standard, eliminating this web hack?
There are many old business apps that with this can be with simple hacks be resurrected and worked in webassembly. I am pretty sure there are way better methods for writing new things or business logics but many companies still have old apps which now they can reuse or repurpose
Sure, but what about my other concerns are they addressed in this library?
It depends on how your environment is setup. If everything else is, absolutely. If this is just a standalone thing in the environment, it can still be convenient to do just to align testing and deployment in an easy portable manner. Certainly nothing bad about it and the effort required isn't significant anyways. As far as container type, you'll have to do windows (unless you use mono) since MVC 5 is on .NET Framework.
I'm a Windows sysad by background. Disabling insecure TLS protocols is a big deal and Windows doesn't make it super straightforward. There is some fucky interaction with reg keys depending on framework version. (Check out SchUseStringCrypto.) My concern is that you make a change and break connectivity to other services in the stack. We had _so many_ hours of failed maintenances because the web later couldn't talk to the data layer any more, etc etc. This won't be a problem on public cloud, but on your own infrastructure, test everything during your outage window.
I have a domain in o365 and I set up a catchall. I give a separate address for every single login. I caught one email harvester just yesterday.
I‚Äôm glad they seem to be finally focusing on performance, but I fear it might be too late. I _really_ like the JetBrains ecosystem - not only do their products run like greased lightning, but the workflow is a lot better than in VS too ü§∑‚Äç‚ôÄÔ∏è
As a huge jetbrains tool fan, you and I have different definitions of greased lightning. 
Haha, maybe! I‚Äôm coming from VS with ReSharper and both my work and home workstations are powerful multi core machines, so for me JetBrains stand-alone IDEs have always run really well, whereas VS (even without resharper) is comparatively glacial. What problems are you having with it?
Resharper is your performance issue right there buddy.
No fair complaining about VS if you are using Resharper. That's like saying your horse is a fault when you enter a race while it's still attached to a beer cart.
Sadly, resharper just makes it unbearable. Running vs without extensions is a lot better, but still way too slow with large C# and C++ code bases :(
That‚Äôs why I said it was still slow without extensions :P It‚Äôs a lot better, yes, but the JetBrains IDEs still seem to handle large code bases much better.
That's quite a nice idea too. I just have to pick a good domain name :)
I agree. Rider is a delight to use. 
I really don't have a lot of performance complaints with VS. Every time I've installed Resharper (which I pay for to get the profilers) I've uninstalled it within an hour because I can't stand how sluggish it makes VS. CodeLens also gets turned off immediately every time some upgrade turns it back on.
Yeah, R# makes VS _wayyyy_ slower, but I've found the base product to be quite slow anyway once your code is large enough. Why do you turn CodeLens off? Is it for performance reasons, or because you don't like the feature?
Performance reasons and I have a small team and don't find the information terribly useful.
Not sure id this helps but I found [OpenIddict](https://github.com/openiddict/openiddict-core) to be far easier to use than IdentiyuServer.
It's an improvement on what I did before but it's not perfect to have a catch-all. Exchange Online gives you only a subset of transport rules of on-prem exchange. I'm contemplating a microservice SMTP filter where I can add an email address by an http call and then hit it in an SMTP transport rule and drop unknown addresses or forward known ones to my real mailbox. Having said that, I have yet to receive any spam to unknown addresses in my domain, so it's working well enough and it's super-low-effort.
https://www.jetbrains.com/help/resharper/Speeding_Up_ReSharper.html May some of the tipps from this article can help. Especially disabling Windows Defender (or similar programs) for the ReSharper cache is a good thing to try.
JetBrains plug-ins are the worst for performance though...
The VS plugins, yes - the standalone IDEs, not so much (in my experience).
Thank you! I tried this before and it didn't seem to help, but it's worth a try for anyone else :)
One creates an empty project, the other a web forms project and the last an MVC project with basic contents. Why not try them out and see?
Except it's not slow without extensions, it's not even slow with extensions. It's slow with Resharper's shitty code in it. 
[https://github.com/astonished12/training](https://github.com/astonished12/training) Check this out. Maybe it will help. Good luck with your project! Cheers!
Thanks!
Appreciate all the info :) 
&gt; --self-contained true per docs this should be unneccessery (https://docs.microsoft.com/de-de/dotnet/core/tools/dotnet-publish?tabs=netcore21) &gt; --self-contained &gt; Publishes the .NET Core runtime with your application so the runtime doesn't need to be installed on the target machine. If a runtime identifier is specified, its default value is true. For more information about the different deployment types, see .NET Core application deployment.
Despite the snarky comments, which totally center around people's opinions of WinForms and not your work, this is an impressive project. I'd be proud of myself if I could pull it off.
I haven't tried doing anything like this using EF, but I've seen the TransactionScope class used to get SQL-transaction like behavior to span multiple connections. That should simplify your error handling code. You may need to modify the DB itself if you want to use snapshot isolation for your transaction scopes - that will depend on your insert, update, and read throughput on these tables to reduce deadlocks.
Appsettings.json is incomparably easier to use than a Web.config. You'll see once you start using it. I realized I hate web/app.config files will all of my being.
jQuery is unfashionable because it's losing relevance. It's inherently bloated in comparison to using specialized libraries. Also, they messed up the Promise implementation.
Oh. There's that. That might work the same way as some ADO .NET projects I've tried. Thanks for the valuable tips. 
I've mapped the "Suspend Resharper" to keyboard keys, I now I only turn it on when I explicitly need it.
Cool, I'll check this out too
I see what you did there 
Original post date: May 22, 2018 Valid point tough.
[removed]
Lots of code or lots of projects?
We use a sweet little utility that unfortunately due to some malware sounds like malware itself but is called "IIS Crypto" that we use. It allows you to save a profile of your TLS and other crypto setting to apply to your other systems and such its pretty sweet for adjusting all those TLS settings. I wouldn't be able to get by in for a dmz domain to do it all with gp so we do it this way. 
This guy (doesn't) OData
Without some way to wire in business logic, this is just an extra hop between you and EF isn‚Äôt it?
If you map every EF property to an equivilent API field, yeah. But you could define expressions that, for example, calculate an age from a date, or convert your DB values based on a the user's preferences (e.g. miles or km). You could override OnCreating to set a CreatedDate or CreatedByUser property that isn't exposed to your API or is read-only. Maybe inject a service bus and raise an event when a new entity is created. Or perform validation rules or data-cleansing before modifying an entity. Or maybe some fields are only available to users with certain roles. Any other ideas are welcome - I'm hoping it can do a lot more that just wrap up a database!
What are the benefits or drawbacks versus OData?
You can use Span&lt;T&gt; on full .NET. There are additional runtime changes to make it even more efficient on core, but it still works beautifully today on full .Net 4.7.2.
It's a struggle isn't it :) I had a .com, .net and .co.uk for one domain name. I didn't want them so let them lapse, but they lapsed at different times, the .com first. Within minutes it had been bought and was on sale at a substantial price, because they assumed I had made a mistake. The internet is a dangerous place :)
Same here, but with the code vision feature in Rider. I‚Äôve just not found it to be useful and not being able to toggle it with a keybind means I just leave it turned off :(
Code, I‚Äôve never worked with an sln with more than 30 or so projects
Major drawbacks would be that it's not as established, not as stable and not as feature-rich. I must admit, I've not used OData in anger, and it's perhaps a lot more customisable than I realised, but I'll give it a go. I find OData's conventional URIs a bit unnatural. I'd rather do `/users/fred` than `/Users('Fred')` for example. And I'd rather not use the `$` in my querystrings. I'm also unsure how I'd do things like raise an event when a field is changed, or perhaps split an API Name field into FirstName and LastName in my DB. This project doesn't aim to define a common API format - rather it allows you to create your own. You chose if you want camelCase or snake\_case fields. You chose if PUT and/or PATCH does partial updates. You chose if pagination uses the Link header or whether you want page info in the response body.
I know iiscrypto well. It is a GUI for schannel config. Schannel is one, and only one, part of the protocol stack. Once you've set schannel, you've done the easy bit. Now tell me: if an app targets 4.6 and is running on a server with 4.7.2 installed and uses ADO.NET to communicate with a SQL 2012 CU2 instance, what else needs to be done before you can disable TLS 1.0?
I am not familiar with JArrau so I am not sure I can help you with your specific problem. I recommend looking up the documentation for ToObject, I suspect it either cannot deserialize arrays as List&lt;&gt; or can't handle complex objects like your CorrespondenceJob. I would recommend looking at using a data model to represent your JSON. You are already doing it with CorrespondenceJob but you can take it one step further and make a couple more classes for the rest of the JSON structure. I think you can then just add the top-level class (I am not sure if you can deserialize an array directly but you can try) to the parameters of your controller function with the name matching the name of the form field and mark it with an attribute (FromForm? Something like that). Though I have not tried this myself; I was not aware you could do this until recently and haven't had the chance to try it. The alternative is to run it the form field value through a deserialization function and you'll get the object out and can just work with it like a normal C# object, AND you get full compile time check support (eg that "ReferenceId" string could contain a typo and the compiler has no way to know. If you have a class with a ReferenceId field the compiler will know if you typo it.
No idea, not my job tbh... =P
Seems like a good idea, but at a glance sounds a lot like ODATA. I thought .NET Core was headed this direction, but ODATA left a little bit to be desired, particularly because the proposed solution to enforce permissions and limitations on particular queries made to a data model was to create an override and "manually" apply the response authorization. I see this has that as well, but the authorize attribute may be handy approach may be handy. I'll have to play around with it. Unlike some of the other responses so far, I see a some potential with this actually. I was not a big fan of ODATA syntax and the complicated nature of setting up the filtering and potentially pulling too much data and filtering it out in-memory. I read in the documentation that it may be possible to hook up this with a repository pattern instead of entity framework, although it was a little unclear. I am curious on the LINQ is set up with the querying, so I may look into that as well (especially if working with a repository pattern), though I'm guessing it simply hooks onto the entity that is requested. Looks like an interesting project!
 Seems like a good idea, but at a glance sounds a lot like ODATA. I thought .NET Core was headed this direction, but ODATA left a little bit to be desired, particularly because the proposed solution to enforce permissions and limitations on particular queries made to a data model was to create an override and "manually" apply the response authorization. I see this has that as well, but the authorize attribute may be handy approach may be handy. I'll have to play around with it. Unlike some of the other responses so far, I see a some potential with this actually. I was not a big fan of ODATA syntax and the complicated nature of setting up the filtering and potentially pulling too much data and filtering it out in-memory. I read in the documentation that it may be possible to hook up this with a repository pattern instead of entity framework, although it was a little unclear. I am curious on the LINQ is set up with the querying, so I may look into that as well (especially if working with a repository pattern), though I'm guessing it simply hooks onto the entity that is requested. Looks like an interesting project!
Thanks for the great feedback! Those frustrations with OData are probably areas I should focus on to make the project more attractive. It's only got simple auth features at the moment, but I wanted something similar to the Authorize attributes we use on MVC controllers or SignalR Hubs. You've touched on the idea for [Root](https://firestorm.readthedocs.io/en/latest/stems/roots/) classes there, where you return the IQueryable that everything else Stems from. I actually didn't think that'd appeal to anyone as I found it created too much boilerplate, so I started using the data source idea instead. Now I want to revise this area. I figured implementing MongoDB would help me abstract data concepts and reduce coupling to EF, then I think Roots should just be another data source implementation. Thanks! Let me know if I can help with anything :)
Interesting read. I didn‚Äôt realise intrinsics were coming to dotnet core
CSS has an outline property that can be used to give outlines to elements. Keep in mind some elements may already be using this property. If you don't want to interfere with the page's contents you'll have to determine the element boundaries relative to the page (a bit complicated when you have to take scrolling and maybe even frames into account) and then add your own element with overlay on top.
Good idea! I‚Äôm pretty inexperienced so I did not even think of editing the actual loaded page itself.
nice, they fixed the ef6 edmx saving bug from preview 1. 
Why emulate taskkill with \`Stop-Process\`? Why not just use it as it is?
So .NET 4.7 and Core are different things. Core runs perfectly on a Mac (with VS for Mac or VS Code for IDE) . Yes the easiest route will certainly either have Windows as a remote desktop (check out Azure for some free / no-cost ways to do this [https://docs.microsoft.com/en-us/azure/virtual-machines/windows/using-visual-studio-vm](https://docs.microsoft.com/en-us/azure/virtual-machines/windows/using-visual-studio-vm)) OR on the Mac run a VM with Windows in it on the Mac . 
You should create both with one call to the API. &amp;#x200B; In the API, you could do an add on both tables and then do db.savechanges() if one fails no changes are made. The problem here though, is that it seems that the bookId get created sql side? In that case that would not work and you would have to do what you described add book, get info, add to history and if fails delete record. However, I would still probably want to do this with one API call and have that logic inside the API.
WCF is always mentioned alongside SOAP, does WCF do other things that still make it relevant? I'm fairly new to development and a quick readup on WCF makes it seem pretty involved.
Empty creates an empty web application. Web forms creates an application that has the web forms folder structure and some basic files, this came before the MVC. MVC creates an application with MVC file structure and some basic files, this came after web forms. You may also see [ASP.NET](https://ASP.NET) core option, which is the newest. &amp;#x200B; A simple search will reveal pros and cons of each. &amp;#x200B; &amp;#x200B; &amp;#x200B;
"using TransactionScope" seems to work. I did a test and it works just like any normal SQL transaction. Anyway, both logic (using transactions and yours) are done in the API, so one call is made. Just feels like the transaction approach would deadlock sometimes but API calls are asynchronous, so a little wait here and there might be ok. In the end, looks like it's just a matter of choice.
I chuckled.
Yep, knew 4.7 didn't run o n mac, that is why I specified. The free VM is a cool option. I'll look into paralells.
Is it a nuget package?
Integrated terminal is very welcome 
So is your project net core or net framework? You‚Äôve still not really made that clear, since your post says both
Yes. System.Memory.
*Hey just noticed..* it's your **7th Cakeday** Evairfairy! ^(hug)
Could you please make sure that .net core has been setup on the server?
Sorry, that was a typo. We are on net framework.
Impressive! I'm amazed you managed to deal with the drawing part if I recall Winforms calls into quite low lvl draw calls to the windows API itself. I presume those calls gets translated to equivalent canvas calls? Impressive work nevertheless. 
Interesting, I love the new `switch` expression overall it makes it more cleaner in my opinion. Also it kinda reminds me if `F#`'s piping with the default case at the end, though the default case would have been better to using the `default` keyword than `_` imo as it's more readable than the `_`. 
In your case the biggest shift in difficulty will be in the MVC aspect of .net core. When you get started it will seem difficult because it's very different, but it is much, much easier. The VB -&gt; C# is not that difficult. once you start working in C# everything that you're used to in VB _is_ there it is just accessed in a 'C' way. I recommend building a simple api that takes json payloads and responds to them. 1. install .net core sdk 2. open a terminal and run `dotnet new webapi`. Don't bother learning dotnet version of MVC until you understand how the backend works (the C). If your company moves to .net core, they likely will want to build a single page app in vue / angular / react. All of these can be fed by a dotnet core backend which all your strength lies in. 3. have a peek through the template. run it locally. Download postman and send a few example calls to it. 4. investigate async / await on these endpoints 5. investigate dependency injection. The way .net core does this is _beautiful_ and easy to use. You essentially setup services then in any method you can simply use it as an argument and it is 'magically' resolved. public Constructor(ISalesRepository repo) { _repo = repo; } public void ConfirmPurchase(Invoice invoiceDetails) { _repo.ProcessOrder(invoiceDetails); } Once you get a handle on all of these things you're golden. All an MVC app does is return a razor HTML page (called a view). I recommend not focusing too hard on that because your front-end is interchangeable; but dotnet core's future is in the backend.
Dunno.. i have not a singe executable that i start in that script anf it annoys me that i cant implement such simple behaviour with a c# type definition or somenthing like that, also maybe just because of sheer interest...
Switch expression is dope
I love anonymous Record types. Great addition to F#.
 foreach (var x in jobs.Skip(1)) { jobList = JsonConvert.DeserializeObject&lt;List&lt;CorrespondenceJob&gt;&gt;(x.ToString()); }
Never mind, found the problem... There's a fluke with the asp.net core version of the project that requires you to close the solution and reopen it or else bower won't download required jquery/etc lib files.
Could you elaborate on what libraries could replace jquery at the moment?
The DOM API is a lot better now. `document.querySelectorAll()` pretty much does what most of us used jQuery for in the past and it's native. For AJAX we now have `fetch()` which displaces the need of jQuery's `ajax/post/get` and also there are a ton of small libraries built solely for this functionality if you need older browser support. Animations with jQuery were always jank because they weren't using the proper approach in some of the methods. `Velocity.js` is a small and amazingly versatile animation library that will give a much smoother experience. Promises were kind of messed up in jQuery in that they weren't up to spec and they couldn't fix them because backwards compatibility is jQuery's biggest sell. Poeple mostly use `bluebird` for that today. The general idea of the web today is that you shouldn't import what you don't use, because in the end with these front-end heavy applications it all ends up being downloaded and parsed by the browser regardless of whether it's used.
Thank you very much, I was not aware of those changes. I'm also of the opinion to use as few libraries as possible
congrats!
That's my main issue with it. The fact that you can make an expression bodied property with switch statements is awesome. Also loving the change in the using pattern!
I love that change as well. As for someone who uses a lot of IO and dbContexts that was a very welcome change as it avoid the weird scoping problems I had with the `using` statement and having to nest. Though I do wonder how the compiler attaches the `Dispose` call to the calling method though since if I recall the using is just syntactic sugar for `try {} finally { // dispose }`.
Thanks for the effort out into the article. I'm not nearly as smart enough to appreciate the need.
WCF is always mentioned alongside SOAP, does WCF do other things that still make it relevant? I'm fairly new to development and a quick readup on WCF makes it seem pretty involved.
I believe there is still effectively a try / finally for the using statement, except the brackets are inferred based on the lifetime of the variable.
Unpopular opinion, but I don‚Äôt really like these improvements. Yes, it does the same thing with less screen space, but it‚Äôs less intuitive. A using statement with brackets- it‚Äôs fairly reasonable to intuit that the object is disposed with the closing brackets. A switch statement is more intuitive with the case keyword. Writing the word default: is more intuitive than an underscore. I suppose I‚Äôll get used to it after resharper suggest the new format for like the 100th time, but call me simple- I prefer the old way, and not having the new way as a language option. This is coming from a guy who always uses expression bodies for one line method bodies, so I‚Äôm not completely crazy. 
If you construct your SQL string in code, and then open it using a SQLDatareader, you solve a lot of problems: 1) Only SELECT statements are processed by a Datareader, i.e. it is inherently read-only. So no arbitrary SQL. 2) The Datareader can also return schema information with GetDataTypeName which makes it easier for your code to handle data types correctly. 3) It's fast! I've written several User Query Designer using this approach and it works well.
How do you handle limiting the user's access to the tables you want them to be able to access?
Precisely! Thank you much, happy cake day!
Thank you for this answer, all good stuff to consider! I especially like you suggestion regarding the "ReferenceId", although this is a pretty standard across the board (inside of this app), here I am just following convention. But I do agree, there is no fail safe if the Gate way ever decided to send back "RefwferenceId"
Ahh that makes sense. The Roslyn compiler can already detect it like how analyzers can detect if a variable is unused so I guess they're using that here. Pretty intuitive as well as it assures you dispose the object instantly when it's unused so overall it's more efficient resource wise.
I do love the way you can use the switch-statement and I'm going to use it. But not the example with the \`Point { X: 0, Y: 0 } p =&gt; "origin",\` it feels so awkward... I would prefer then the \`when\`-clause. For me 'less code' doesn't always mean 'cleaner/readable code'. I also think that the new \`using\` may have certain side-effects. I would prefer the old syntax and decide myself when the instance is disposed (at the end curly-brace). For example, if I read something from a disposable resource (like a db), then I want to dispose that resource as quickly as possible before I start doing something with the result. The example for \`using\` in the post actually illustrates this. There is a \`using var options = ...\` in the method \`static void Main\`. So the variable \`options\` is only disposed at the end of the program (which it does anyway), but not when it isn't needed anymore.
Try to enable failed request tracing and look at those logs. 
The answer to all of your questions are "no" I'm developing with .net core for a year and I can say that most of the libraries for web development is available for .net core. There are still some libraries that require full .net framework. &amp;#x200B; They say .net core 3.0 will support windows forms tho.
Windows forms, wpf and uwp are Windows only. The only thing changing is you can target .net core 3 instead of framework which allows for side-by-side installation of .net core and all the other improvements that come with .net core. It does not mean the UI is cross platform and MS has expressed no interested in porting them for now.
The short answer is no, you cannot use framework on linux. It is too dependent on Windows which is part of the reason why .net core was created. Winforms, wpf, and uwp are not cross platform and probably will not be for years if ever. Yes, .net core 3 will support them but it is similar how .net core right now has an additional library to interact with the windows registry but that doesn't mean the registry is suddenly cross platform. MacOS visual studio is not the real visual studio -- it is a rebranded Mono Develop. You cannot develop windows UI applications on anything other than windows. You mentioned clipboard manipulation -- that is such a small and specific API that you want to interact with and that is purely windows only in framework. Anyone who knows C# will be able to work with that API. I would focus on learning C# in general and not worry about a specific API for a small feature.
These guys are right. If you want to develop with .NET Framework for Windows desktop apps you'll need Windows and Visual Studio. Technically you could use Xamarin Forms on mac but that's not what your employer is looking for. That's the bad news. The good news is that it's worth it. Visual Studio *is* that good.
I don't know how other people do it. My users connect to SQL using Windows authentication and access data as themselves. Permissions are granted based on Active Directory group membership. Literally created groups called InvoiceRead, InvoiceUpdate, InvoiceDelete and assigned those to an Accounting group or whatever.
you don‚Äôt really need to as the garbage collector will take care of this
Setting up the environment for Windows/Visual Studio is a lot cheaper (free) and more straight forward than it used to be. Id suggest running Windows 10 in a VM and choosing the "activate later (skip product key bit)" - this will install windows feature complete (apart from desktop customisation and theme things) making it essentially free forever and then pop Visual Studio Community Edition on and just start coding!
All using does is ensures Dispose is called. https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-statement But maybe I just answered my own question. There may be a chance when File.Create fails with an exception yet has resources that need to be disposed of. Using is preferred for this reason. Sometimes its just a matter of googling the right question :-). 
thank you for this information. I did not know that ‚Äòusing‚Äô calls ‚Äòdispose‚Äô
thank you for this information. I did not know that ‚Äòusing‚Äô calls ‚Äòdispose‚Äô
I imagine that the bracket is effectively, invisibly inserted by the compiler. It shouldn‚Äôt change performance, but it sure as hell makes the using statement less readable, as evidenced by this discussion 
Is it really possible to run win 10 for free (legally and for personal use only) this way you said? No restrictions other than fancy stuff?
Currently just using it for a personal closed source project, so was a bit sad to see them planning a license change. But they also say "We're gonna be cheap, almost painfully so, in order to hopefully not drive away users." and if so, no qualms. Really depends if their version of cheap matches my own.
Most of .net Framework works by calling win32 api procedures under the hood. That's why you can't bypass windows. .net core is a rewrite to be independent, so since they have to rewrite everything, it's missing stuff. Similar thing with Mono. However unlike Mono I hear .net core is almost there. It has entire microsoft team on it unlike mono. So yeah, like others said - running full .net Framework on linux is impossible. Your other options are .net core or mono, which have their own constraints. Also, yes there is a good feature comparison table somewhere on Microsoft's website. I urge you to check out docs.microsoft.com, it's really good and has all this answered there.
Yeah I know VS has a great reputation, it's just that I wondered if I could just avoid adding layers of stuff to learn on top of playing with the language constructs
As one have suggested I think the resource is disposed at the point it detects you're not using it anymore by the compiler, kinda like how Roslyn compiler can detect that a variable is unused or that a section of code is unreachable. Although it does kinda make it hard to see which are disposable as it's now implied, it'd still dispose efficiently unless you're doing some weird reflection to throw the compiler off which in that case it's better you'd use the `using () {}` syntax.
Thanks for your answer, it makes a lot of stuff clearer to me now. Just to be sure, does that mean that I can build against the Xamarin API under linux/bsd then? I just mentioned the Clipboard API because I wanted to give an example to contextualize (and I'm still not sure about how I can circumvent that for now); it's not that important to me for now. 
I've never used Xamarin so my answer would only be guessing regarding the UI parts. For backend code it is best practice to make a library targeting .net standard 2.0 so it can be used with .net framework or .net core. In case you aren't aware, .net standard is a common API between framework and core. If you target standard, you can use either framework or core depending on the platform the code is running on. If you needed to use platform specific features, you'd have to handle those on a case by case basis and use runtime platform checks and/or #ifdef statements.
Yeah this is a web app so that‚Äôs my really an option. I think I‚Äôm going to just go with EasyQuery. I got with their support team and they confirmed that users are only able to access the tables and fields you explicitly define. I‚Äôm pretty sure the SQL the user writes isn‚Äôt the SQL that gets sent to the server, it appears that it has its own middleware SQL interpreter that translates what they write to the actual SQL that hits the server.
I just found that while googling : https://blogs.msdn.microsoft.com/cesardelatorre/2016/06/27/net-core-1-0-net-framework-xamarin-the-whatand-when-to-use-it/ while it seems a little old, it might have the basic information I need. I suppose that I didn't find anything before because I wasn't sure where to look (msdn looks like it only holds a big reference manual) 
The garbage collector will take care of it, but when it feels like it. Up until then, the file handle may be held open a little longer than you expect, especially if that file is needed for something else immediately after. 'using' gives you control over when Dispose is called. 
I mean, if your sole objective is to learn .NET, then you can either just learn .net core on your machine (which will be mostly fine, the apis dont differ much) or you can spin up a vm with windows in it and get visual studio (which you will for sure use in your new job, its simply stupid not to use the best IDE out there if your goal is productivity). Either option is fine, I'd go with 2 considering this will be what your dev enviroment will most likely look like.
Can't you compile .NET Framework code against Mono on Mac/Linux? I know when I use Rider I have the option of creating a .NET 4.7 project and it runs using Mono (obv no UI support). 
can you post a minimal example that gives you the error? All your post is saying is ".net builds my project but theres something wrong how my machine interacts with it" and I don't think I can help you much with that amount of info
MSDN is kind of a big reference manual, and anyway, it's being phased out (if it isn't already - it now contains older stuff, legacy APIs, etc.). Microsoft docs is where it's at. To read about various .NET implementations: https://docs.microsoft.com/en-us/dotnet/standard/components Choosing between .NET Core and .NET Framework: https://docs.microsoft.com/en-us/dotnet/standard/choosing-core-framework-server And finally, here's a neat comparison table: https://docs.microsoft.com/en-us/dotnet/standard/net-standard#net-implementation-support
You can omit the variable assignment if you don't need it. The compiler will introduce a hidden variable under the hood and dispose it. This is what I usually do in these scenarios. using (File.Create(@"c:\tmp\example.txt")) { } &amp;#x200B;
It's not really a "common API". .NET Standard is not an API, per se. It's just a specification. Then there are various implementations which fulfill that specification. That's why targeting .NET Standard gives you higher flexibility, because you can now use any implementation of it - be it Core, Mono, full Framework, etc.
I freaked out a bit when I saw your comment, but dual license isn‚Äôt so bad. I encourage donations from any company I work for that uses OSS code, but I‚Äôm probably in the minority. This forces the issue! 
I'm not sure how I feel about the license change...
Stop-Process will kill the process while taskkill will simply try to close all its windows (allowing the app to remove its tray icon as it closes). taskkill /f is the one that works like Stop-Process
From my (a developer's) perspective its definitely Visual Studio. Its too good and is the number 1 reason I don't just run some linux distro.
No. 
What is it about open source graphics libraries that instills such greed? You don't see Automapper, JSON.NET, etc trying to stop others making money off their tools.
Pity about the license change. Ah well, if you just need to do resizing and whatnot I can recommend https://photosauce.net/ it is _amazing_.
Isn't this only available for IIS? I am running my solution with VS code and HttpSys. Is it possible to use it with this setup?
You are right, but unfortunately I don't have any errors except the generic 503 error. Here is my setup * IDE: VS Code * Project template: [ASP.NET](https://ASP.NET) Core Web App MVC * WebHost &amp;#8203; public static IWebHost BuildWebHost(string[] args) { return WebHost.CreateDefaultBuilder(args) .UseStartup&lt;Startup&gt;() .UseHttpSys(x =&gt; { x.Authentication.AllowAnonymous = true; x.Authentication.Schemes = AuthenticationSchemes.NTLM | AuthenticationSchemes.Negotiate | AuthenticationSchemes.None; x.UrlPrefixes.Add("http://127.0.0.1:54672"); x.UrlPrefixes.Add("http://10.0.2.15:54672"); }) .Build(); } * Log output when I run the project with VS Code &amp;#8203; 2019-01-25 19:30:33.133 +01:00 [WRN] [] Overriding address(es) 'http://localhost:54672/'. Binding to endpoints added to UrlPrefixes instead. 2019-01-25 19:30:33.133 +01:00 [INF] [] Start 2019-01-25 19:30:33.134 +01:00 [INF] [] Listening on prefix: http://127.0.0.1:54672/ 2019-01-25 19:30:33.134 +01:00 [INF] [] Listening on prefix: http://10.0.2.15:54672/ Hosting environment: Development Content root path: C:\Users\ra\Repositories\AIM2.0\backend\src\AIM2.Backend.API Now listening on: http://127.0.0.1:54672/ Now listening on: http://10.0.2.15:54672/ Application started. Press Ctrl+C to shut down. And when I try to open the website I get this error &lt;!DOCTYPE HTML PUBLIC "-//W3C//DTD HTML 4.01//EN""http://www.w3.org/TR/html4/strict.dtd"&gt; &lt;HTML&gt;&lt;HEAD&gt;&lt;TITLE&gt;Service Unavailable&lt;/TITLE&gt; &lt;META HTTP-EQUIV="Content-Type" Content="text/html; charset=us-ascii"&gt;&lt;/HEAD&gt; &lt;BODY&gt;&lt;h2&gt;Service Unavailable&lt;/h2&gt; &lt;hr&gt;&lt;p&gt;HTTP Error 503. The service is unavailable.&lt;/p&gt; &lt;/BODY&gt;&lt;/HTML&gt; What other information would be helpful? 
In this case correct. The FileStream will call Dispose in its finalizer :) 
They have every right to expect money for their efforts. Isn't it greed to build commercial applications on the backs of a few open source maintainers working at their spare time?
Says right in the post: &gt; Donations don't pay the bills If you're so sure it's greed, then go ahead and write your own, free open-source graphics library and release it. You can even fork the ImageSharp codebase and start from there. Nothing is stopping you. Go on. Don't be greedy. 
If you can free yourself of the .NET Framework constraints, and work entirely in .NET Core, JetBrains makes a C# IDE called Rider that works well on Linux. VS Code is another option as well, though it's more of a "code editor" than a full-blown IDE.
Maybe you need to "Preregister URL prefixes on the server." https://docs.microsoft.com/en-us/aspnet/core/fundamentals/servers/httpsys?view=aspnetcore-2.2 Maybe also try specifically setting a MaxConnections. Under IIS at least, 503 usually means the http sys queue is full and can't accept the incoming connection.
Mono provides it's own implementation of winforms, but wpf and uwp are currently windows only. You can build .net framework programs (provided you don't use windows only features) using mono via vscode, however you will need to modify the build tasks to call "msbuild" (provided by mono) instead of the dotnet commands you are currently using.
It would leave the file locked until the GC decides to do a collection. You should dispose of an object asap to avoid unintended side effects.
I don't understand what you're giving me. We had a variety of courgette related crap which stuck the the brief; let some BA learn how to write tests in this super easy to learn Structured ~~Query~~ Story Language. This feels like something a BA still wouldn't do, and offers me nothing over what NUnit, with behaviour driven names and intentions would deliver. 
Absolutely amazing yes, I know the developer and he's brilliant, but Windows only. The license change only affects non open source consumers who, most likely are charging for their product. Is it to much to ask that someone pay for the tools they profit from?
Still working out the costs but the current (subject to change so don't try to hold me on this) plan would be something like this: $365AU per developer per year for max 3 years before the license becomes perpetual. $186 per year for indie developers. Alternatively a perpetual license could be purchased straight off (not worked out cost yet) but that would be more designed for big corporates. Does that match expectations? I reckon most people spend more on coffee.
&gt; Is it to much to ask that someone pay for the tools they profit from? Not at all, just don't expect people to like it. Imagine if the same licencse model was used with https://www.newtonsoft.com/json or https://nunit.org/ et al.
Thank you very much! It was an issue with netsh. I had three entries on the urlacl. [http://10.0.2.15:54672/](http://10.0.2.15:54672/) [http://127.0.0.1:54672/](http://127.0.0.1:54672/) [http://+:54672/](http://+:54672/) The documentation from your link states that you shouldn't use wildcard bindings. So I removed the last entry and it worked again.
My primary use is for making thumbnails in a .net core web app I wrote. That cost is way more than I spend in hosting and is comparable to my Jetbrains subscription for a dozen products (or whatever; it's a bunch). So, no, it's not in my "cheap" category and I'd look into using something else.
It's a way to enforce behaviour driven testing along with best practises (we must have a given, when, and then) in order to run a test. The real benefit is the html output which can be cascaded to whomever and easily make sense to them (granted you have used the attributes such as StepText etc properly) As well as this, a raw JSON/XML data dump is produced, which any data analysis guys can use in your pipeline/metrics. &amp;#x200B; See here for a preview of the HTML / JSON / XML: [https://github.com/thomhurst/BDTest/blob/master/ReportPreview/ReportOutputs.zip](https://github.com/thomhurst/BDTest/blob/master/ReportPreview/ReportOutputs.zip)
This is such a disappointing comment to read; I can assure you changing the license is not driven by greed. ImageSharp and co have taken up nearly 4 years of the evenings and weekends of mine (and the other core team members) lives. From scratch we've written the codecs and algorithms, learning and battling the complexity fraught with. We've put in an extraordinary amount of effort to build something that is easy to use for the uninitiated yet powerful, performant, and flexible enough for imaging experts. None of this is easy and I've come very close to burning out several times. When I first started ImageSharp, there was nothing available for developers who wanted to use 2D graphics with netstandard. I had a dream of democratizing image processing and I was fed up of seeing leaky, poorly written code copy/pasted from blogs proliferating through codebases. I want to be able to work on the libraries full time and continue to build something that realizes my dream. Without the financial support that commercial licenses could provide (as long as people actually choose to think differently from you and support the work) this would be simply impossible. Is that so wrong?
That's disappointing. Why not release just the thumbnail code online and leave the rest of the code closed source?
I hadn't really thought of that; kind of assumed if the app as a whole was closed, the open source option wasn't available. The implementation is more or less what you see in a demo, so it seems a little odd to put into it's own library.
1. Yes. Typically, .Net apps to not compile to native code, but to an intermediary code than is later interpreted and executed by the .Net virtual machine. This way you know your application will run where .Net will run: Windows, Linux, Mac, XBOX and so on. &amp;#x200B; Normally .Net doesn't run on Linux (except through Wine), but Mono does. Mono is another implementation of .Net that started as an independend project but it is currently owned by Microsoft. Mono is more portable than .Net and therefore runs on more platforms than .Net. &amp;#x200B; So, if you make a .Net application on Windows (even a WinForms application), compile it on Windows and the compy the bins to a Linux having Mono installed, that application will most likely run without issues. &amp;#x200B; Of course there are exception, like when you use DllImport to make calls to Windows-specific libraries, which are not available on Linux, or like when you ignore the recommenced best practices for making your appllication run cross platform. &amp;#x200B; 2) Yes. There is a list of implemented features of .Net Core (as .Net Core is newer than .Net Framework, the list contains the .Net Framework features/namespaces/types/members implemented by .Net Core). You can find this list for each .Net Core version (and for .Net Standard versions too). &amp;#x200B; But, to the best of my knowledge, WinForms is not part of .Net Core yet so you won't be able to run WinForms applications with .Net Core. &amp;#x200B; Still, you can run WinForms applications on Linux using Mono. Even more, you can even develop WinForms applications directly on Linux, using an IDE like MonoDevelop. You won't have the visual editor that you have on Visual Sudio, so you will have to position and size controls manually in your code, but it works. &amp;#x200B; 3) Yes. You can compile .Net code to .exe (not to native code) both on MacOs (using Visual Studio, for example) as on Linux (using Mono Develop, for example). If you want to compile to native code
&gt; MacOS visual studio is not the real visual studio -- it is a rebranded Mono Develop This isn‚Äôt as true as it used to be. Visual Studio on Mac now shares a lot of code with the same IDE on Windows - https://adtmag.com/articles/2017/05/10/vs-for-mac.aspx?m=2
[removed]
Odd comparison. Why not compare with Graphics Mill of LeadTools or other graphics SDKs. They charge a lot more.
Put the file in an open source git submodule and you can include it in your normal project without having to create a separate one. 
Perhaps I should have been clearer. My objection is to the bait and switch tactic that I've seen repeated over and over with the AGPL license. I have absolutely no problem with projects starting with dual licensed AGPL/commercial. What I've seen happen over and over (and been personally burnt by twice: Ghostscript and Openclinica) is companies leveraging FOSS licenses to built marketshare, then swapping to AGPL to effectively force the majority of their users to pay up. I work in non-commercial public health research. I can't open source my work due to the extreme sensitivity of the data I work with, and my budget can't cover paying for utility libraries. The research resulting from my project saves lives. However, "non-commercial" licences are never actually non-commercial, but "educational". Research isn't teaching, so my pleas for non-commercial discounts are almost always rejected. \*\*\* Now, you might say "But changing license is no different to me just stopping development", which of course happens to projects all the time. Normally the void is filled by another FOSS project starting up to replace it. The problem is by changing to AGPL/Commercial you've split the market into: 1. Non-commercial, open source projects: These can use your project, so see no need to create a FOSS alternative. 2. Commercial, closed source projects: These can afford to pay you, or pay someone else. 3. Non-commercial, closed source projects: These can't use your project, and can't afford anything else. They form a small proportion of projects, so won't result in a FOSS alternative. I don't use Imagesharp, and I hope this lets you continue to develop what is a valuable library. Nevertheless, I will continue to rage at how unfair these licensing models are to some of the sectors that need open source software the most, charities...
I'm talking about non-commercial, closed source applications.
It's a great answer. What was the motivation? Do you have people who can correlate the metrics into something substantive? I'd be really interested to hear how that works for you. Would you consider a blog post on the wider application; how you see it working, how to interpret the metrics, that sort of thing? 
[removed]
Would you say the same if they had GPLv3'd the code? It would have even worse consequences for closed source applications.
GPL is fine, APGL is far stricter. If I have a website using an AGPL library for some backend serverside purpose, AGPL says I need to opensource my entire application.
If only that was how AGPL worked! [https://softwareengineering.stackexchange.com/a/107931](https://softwareengineering.stackexchange.com/a/107931)
Because it's a standard library. Charging for it will be the death of it. All good, it was a pain in the arse to use anyway.
Which part is greedy? I mean that's really quite an insult, so please do explain - where's the greed?
What's a standard library?
You're right, sorry I mixed up the licenses but what I meant to say was would you still call them "greedy" if they relicensed to AGPL without the option for you to pay them at all?
Hey! Your point is so much clearer with the edits! Why didn't you start with the public health research stuff? :) We have agreed with JamesSouth that we should include a free option for non-commercial users. A possible solution: you email us from your organization's address, we provide you a perpetual commercial license for free. 
No, of course not. The problem with dual AGPL/Commercial is that it makes both extremes happy, but screws the middle (non-commercial, closed source). If they went AGPL only, the demand from the closed-source, commercial, side would eventually result in a new GPL/Apache library. From the responses from the dev it's obviously not deliberate in this case. But often it is, and generally based off cornering the market, hence greed.
You didn't read the comments did you?
&gt; Because it's a standard library. Charging for it will be the death of it. All good, it was a pain in the arse to use anyway. A. What is a standard library B. What made it a pain in the arse to use? You're the first person I've seen comment that anywhere.
Ah, then yea I agree with the guy above me. Net framework will not run on Mac. You‚Äôll need to run a VM/rdc into a Windows machine, or target Core. 
[removed]
As in you want to save the JWT token in a cookie?
No, I wish to use the standard JwtBearerDefaults.AuthenticationScheme and the standard Identity based auth together. Setting services.AddDefaultIdentity&lt;IdentityUser&gt;() makes all auth requests to to the this and ignore JWT. I have had an idea but I can not check it until tomorrow as it is late. I will post it it works. In the mean time any ideas would be great.
[FluentMigrator](https://github.com/fluentmigrator/fluentmigrator) (my preference), [dbup](https://github.com/DbUp/DbUp) and [roundhouse](https://github.com/chucknorris/roundhouse) are the main options I'm aware of. None if them should care what ORM (if any) you use.
Here is the source of it for net core if you are interested. https://github.com/dotnet/corefx/blob/master/src/Common/src/CoreLib/System/Text/StringBuilder.cs
&gt; I also think that the new `using` may have certain side-effects. I would prefer the old syntax and decide myself when the instance is disposed (at the end curly-brace). The C# 8 syntax is basically comparable to RAII in C++ - the object's lifetime is bound to its declaring scope. I'm doubtful that it will be any more or less problematic than current using statements. I know I've seen plenty of massive using statements written that were *far* larger than they should have been.
This SO post points to the following blog post with examples https://stackoverflow.com/a/47946700 https://wildermuth.com/2017/08/19/Two-AuthorizationSchemes-in-ASP-NET-Core-2
Search for "Reference Source" to see the original version. 
[Porting projects in general](https://docs.microsoft.com/en-us/dotnet/core/porting/) [ASP.NET HTTP Modules to Middleware](https://docs.microsoft.com/en-us/aspnet/core/migration/http-modules?view=aspnetcore-2.2) on this page on the left under migration you can find docus on specific version migrations and there are lots of good ones under [ASP.NET](https://ASP.NET) to [ASP.NET](https://ASP.NET) Core I think you would find useful. &amp;#x200B; Making a Middleware that works for both may not be possible, and really is specific the application itself. But abstracting its logic into a class library that takes basic types would be a good option and you can just map the apps values into the method for it. 
If using SQL Server then SSDT should be your first thought. 
For my narrow use case, yes. The app in question doesn't even generate beer money in a "good" month.
https://referencesource.microsoft.com/#mscorlib/system/text/stringbuilder.cs
Core has progressed faster with new apis than Framework
Have you tried Argu? 
First off, congrats! This is a very impressive project and it must feel great to release it. I spent about 20 minutes looking through your documentation, as my company is actually about to start a major API project. I generally like your setup and features, especially compared to some past experience with OData. Unfortunately I don't think it's quite able to meet our (rather complex and convoluted...) needs, but I'll definitely keep an eye on it and I foresee using it in the future. There are a couple things I didn't see mention that you may want to think about adding (or I missed). Is there any ability to perform validation or hook in with a tool like FluentValidation, other than manually calling it from the stem's `OnSaving`, etc. methods? How would I return validation error and a 400 response? What about error handling; what are the response code(s) for exceptions and what does their json look like? Is it configurable? What about general configuration of response codes, say if I needed to return a 202? I'm not expert on marketing, but I would suggest to keep mentioning it here when appropriate, and perhaps do a "Show HN" post on Hacker News and/or post it to /r/programming. Before either of those however I would suggest a complete overhaul of your readme. Your documentation is actually pretty good, but you can't expect people to click through to it. Your readme needs to convey enough info to give someone an understanding of what the library can do, then point them to the documentation for details. At the least I think your [what can it do](https://firestorm.readthedocs.io/en/latest/intro/what-is-firestorm/#what-can-it-do) page needs to be in the readme, along with some description of the more advanced features (adding business logic, ability to do mapping, etc.).
I'm still in the beginner phase of F#, but I don't see any reason why you can't do this. F# lets you define types that implement C# interfaces, and that can then be referenced from any C#/NET Standard project. There is occasional strangeness (e.g. serializing a concrete F# type to JSON via NewtonSoft will add "@" to property names), but so far I haven't seen anything which would preclude you from doing this. I'd say it's a much more sensible approach, compared with writing the same in C#. You also might be able to knock something together super quickly with FParsec ([http://www.quanttec.com/fparsec/](http://www.quanttec.com/fparsec/) \- disclaimer, I haven't got around to using this myself).
The two frameworks do not share the same API.
I've used dapper and flyway for migrations. https://flywaydb.org
FluentMigrator is really good for migrations. Very customizable and user friendly, with many extension methods e.g. Nullable(), Indexed(), WithDefault(something), etc. You can also find a really easy migrator script for your project. Dapper is great for creating queries and executing (async or not), and returning whatever you need from the execution.
Do you need to write code to do this or can you use something like bcp?
From my tests, #4 should have been your best option. I am currently using bulk insert to insert 1.2M rows (11 columns, identity column) and it's taking 5-7 seconds on insert. The columns are small, but mostly text. This is currently to a MS SQL instance though, not SQL Azure. With the datatable creation, it's maybe 20 seconds total.
They do share a common subset but they do not share an entire API. It's the point of .NET Standard. You can be guaranteed that something that is part of the supported .NET Standard will be there in all versions of .NET that support the standard but you cannot guarantee that anything else will be available in all .NET implementations.
Some more examples in the tests [here](https://github.com/twitchax/Sheller/blob/master/src/Test/BasicTests.cs).
To give an idea on the size, the data as a .csv is ~28MB. #2 and #3 seem to possibly implement #4, so yea it seems like it should have been the best. Yea I'm working with MS SQL instance as well, not Azure.
&gt; a SELECT * FROM TableName, when the table is filled with the 78,043 rows of 27 columns, takes 25-30 seconds. That is a lot of data for many clients to parse and may not be the best indicator of DB performance. Perhaps consider importing the whole file into a temp table and using MERGE into the dest table. If the csv or xslx is from a trusted source you may be able to use the SQL BULK INSERT feature on the file directly (after validating and copying to a folder visible to the DB). Or generate a new CSV and pass that to the DB for BULK INSERT.
Ah string builder. The thing that keeps hanging me up on prallel processing workloads that require the manipulation of a lot of strings. Everything boils down to calls to `FastAllocateString()` which can only be executed synchronously it seems, as a whole. So all threads eventually start to wait on `FastAllocateString`, which puts an upper limit to parallelization.
I haven't used bcp before, I was looking into it earlier today though as a possible option. It seems to support .csv perfectly fine. Does it support xlsx? If it doesn't I guess I have a ton of options for converting it to .csv (use what I'm currently doing in C#, use a python script, some JS library that handles it, etc.) I'll maybe test it later and see if it brings any performance improvements.
Also take a look at SSIS - https://docs.microsoft.com/en-us/sql/integration-services/load-data-to-from-excel-with-ssis?view=sql-server-2017
I'm not sure right now if loading the file onto somewhere visible to the DB is a possibility. I'll have to check on that. I'll also try to append directly with the .csv in SSMS and see how long it takes. I looked into creating a temp table and using MERGE, however all the tests above were on an empty table to begin and still ran 35+ seconds. I don't think it would change much unless the unique index is killing performance currently?
I came here to recommend this same type of solution. Inserting into an empty temporary or loading table, and then doing a merge.
Yeah Xamarin works well. I have a WPF XAML project that is Android/Linux/Windows. It's a bit different but not by much.
+1 to this. In my experience, (4) is typically the fastest. On thing to consider here is that indices on the table into which you are inserting _typically make the insert slower_. Indices are great for lookups, but they do [negatively affect insert times](https://use-the-index-luke.com/sql/dml/insert). What kind of hardware is running the instance? How many rows are in the table before you insert? How many do you expect to overlap?
Yeah try manually importing in SSMS using the import wizard, that would be a good benchmark.
I'm trying to find a "quick read" on this right now to get an idea if it'd be suitable. Pretty much looking if it's executable on linux with a command. Do you know if it is? Thanks.
r/lostredditors Seriously though, there's gotta be a better sub for this.
 Just delete it. No one here wants to know about your junk mail. 
I see bullet points for editing, programming, etc. But what about testing? I know that's one reason people tend to switch over to MVC over web forms.
&gt; Another point of reference for the speed is that a SELECT * FROM TableName, when the table is filled with the 78,043 rows of 27 columns, takes 25-30 seconds. Yeah something's wrong there. Unless those 27 columns are huge blobs, that's a tiny amount of data and shouldn't take anywhere near that long to run. What version of SQL Server and what's it running on?
I'm nowhere near an expert on this low level stuff, but this blog post (and linked source) seem to indicate there's actually a "slow" and "fast" allocation available and the speed gets chosen based on available thread-local storage. Maybe that's causing some grief if you're doing a lot of ToString? https://mattwarren.org/2016/05/31/Strings-and-the-CLR-a-Special-Relationship/
Hi test6554, Thanks for your comment! I am not arguing against MVC. I was always a huge fan of MVC even prior to Microsoft building the MVC Framework. I had created a PHP MVC Framework based on a flat file ( and later sqlite ) CMS system that I built from scratch that I released in 2007 ( [https://sourceforge.net/projects/macs-framework/](https://sourceforge.net/projects/macs-framework/) ). And when I initially started thinking about building a ASP .NET CMS system, Microsoft had not yet released version 1 of the MVC framework. While building the CMS I have been able to over come most of the pain points of webforms like viewstate etc. and because of the way the CMS is built you will not need to work with the webform part of the framework, but program everything in cshtml files and use C# which will be compiled at run time using the RazorEngine compiler. Thanks again for your comment!
Yes, you could do that for learning purposes I guess. If it‚Äôs not for learning purposes I suggest to use something thats battle tested like https://github.com/commandlineparser/commandline/blob/master/README.md
&gt; Pretty much looking if it's executable on linux with a command Nah SSIS is Windows only afaik
Thank you for that! 
Since version 6 will be released under the Apache licence, isn't possible to fork version 6 into a new project and continue with Apache etc?
Are they true strings, or would an array of characters work? And if they're guid-ish/base64-ish rather than actual unicode, you could optimize even further by keeping them as shorts. 
Any new features planned? 
The license change is fine. They gotta eat too and we need people to continue to work on amazing libraries otherwise the whole ecosystem will not exit its "library desert" status. Not everybody works for Microsoft and got paid working on OSS. 
They are actual text, like parsing a couple billion line long CSV, or converting a database into a flat file format. Arrays of chars run into the same problems, where eventually as you run this on more and more threads contention around the memory allocation starts to go up and performance drops. Right now it runs optimally on 6 cores, more than that and the performance stays the same and sometimes gets worse. I was thinking of trying to stop the heap from getting thrashed all the time by constantly creating new arrays by just reusing arrays of chars. But not there yet, my attempts have had worse performance since I have a bunch of state management code I had to add in. Plus I really don't know nearly enough about how C# and .Net operate on a lower level.
File an issue, and I'll be sure to take a look. :) I am about to use it for a real scenario, so I would guess that will yield a few features, as well.
This is a bad take. There are countless hours put into open source software, it is totally reasonable and within a community members right to change their license and to be compensated for their work. Moreover, they are very clear that they will work with nonprofits and non-commercial uses of their software. You should reconsider how this lands, as they were real humans out here trying to make .net a great community.
Only asking because I think it could be fun for me and others to help out:)
Totally for that! Feel free to send PRs, as well. I just don't like to respond to feature requests with an immediate, "I accept PRs", haha.
Any plans on porting it to asp.net core? 
Well yes but why don‚Äôt you just cut out the middleman and take the food straight out of my family‚Äôs mouths? 
Sure, I just don't know what it is.
Well you're a bit of a prick aren't you?
Out of curiosity, how does the sensitivity of the data you are working with affect the visibility of your code? There are many security libraries who are open source and benefit as a result. Developers knowing the implementation doesn‚Äôt make it any less secure. What is requiring you to be closed source?
this, please!
Sounds to me like a job for spans and Stackalloc. David fowler and some others did some examples awhile back of a CSV parsing routine using it
And with that response now you are too. Wonderful!
I have found I can get good performance from using [Table-Valued Parameters](https://docs.microsoft.com/en-us/sql/relational-databases/tables/use-table-valued-parameters-database-engine?view=sql-server-2017) - you create a datatable in c# and pass to a sql cmd parameter which does a merge. (one issue - you need column order in datatable same as defined in type as it ignores names). I have hit memory issues so usually I break the table down to approx. 1000 rows at a time
Navigatable site: [https://source.dot.net/](https://source.dot.net/)
Core also has a navigatable site: [https://source.dot.net/](https://source.dot.net/)
There should be a meme where equivalence is appreciated. Seriously though, I only posted here because the phisher feed was .net specific, so there's a chance people here would get hit. Definitely the wrong sub, but if I can't reach out to a community and ask for directions without getting some prosthetic human being a prick, then I'll block the prick and continue to work with the less dickish.
Try TPL Dataflow? Sounds ideal for this.
I have it working. My config: // This method gets called by the runtime. Use this method to add services to the container. public void ConfigureServices(IServiceCollection services) { services.Configure&lt;CookiePolicyOptions&gt;(options =&gt; { // This lambda determines whether user consent for non-essential cookies is needed for a given request. options.CheckConsentNeeded = context =&gt; true; options.MinimumSameSitePolicy = SameSiteMode.None; }); services.AddDbContext&lt;ApplicationDbContext&gt;(options =&gt; options.UseSqlServer( Configuration.GetConnectionString("DefaultConnection"))); services.AddDefaultIdentity&lt;IdentityUser&gt;() .AddDefaultUI(UIFramework.Bootstrap4) .AddEntityFrameworkStores&lt;ApplicationDbContext&gt;(); services.AddAuthentication() .AddJwtBearer(options =&gt; { options.TokenValidationParameters = new TokenValidationParameters { ValidateIssuer = true, ValidateAudience = true, ValidateLifetime = true, ValidateIssuerSigningKey = true, ValidIssuer = Configuration["Jwt:Issuer"], ValidAudience = Configuration["Jwt:Issuer"], IssuerSigningKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(Configuration["Jwt:Key"])) }; }); services.AddMvc().SetCompatibilityVersion(CompatibilityVersion.Version_2_2); } Authorise for multiple schemes like this: const string AuthSchemes = "Identity.Application, " + JwtBearerDefaults.AuthenticationScheme; [Authorize(AuthenticationSchemes = AuthSchemes)] public IActionResult PrivateAction() { return View(); } Is seems as though in previous versions if the first method of authentication failed then the other registered authentication methods were attempted. This now seems much more exact or precise.
Thanks for the link. I have looked at this but unfortunately it did not work as I hoped. I have posted my solution.
Very nice. I was thinking about writing something similar. But I'll try yours out first...
Hey a thought that might help ease some people‚Äôs concerns and also get more people to pay would be to offer a free single developer license with a revenue limit as a way for people prototyping an idea but prototyping in public for an eventually paid idea to not worry about the cost up front. I know if I were exploring starting a startup by writing an app that would be able to use this that would make a huge difference.
Look at using Span, Memory, and now Pipelines. Anyone trying to write a fast parser should be using these new features. 
Thanks! Really grateful you took the time to look through the docs. With validation, I want to make the attributes more extensible and this is a perfect idea to get me started, so I'll have a look into this. But you're correct, currently you'd have to override `OnSaving` etc. There isn't much documentation on errors, so I'll get onto that. Internally, the response is built by iterating through 'modifiers', so for example the [DeveloperExceptionResponseModifier](https://github.com/connellw/Firestorm/blob/master/src/Firestorm.Endpoints.Responses/Modifiers/DeveloperExceptionInfoResponseModifier.cs) is used if `ShowDeveloperExceptions` is true. On my todo list is to allow some way for users to pass in custom modifiers. That way you could configure the exception messages and status codes. I'll start working on a better readme file then! Thanks for your feedback and I hope one day the project meets your company's needs
Fair point. Any of the libraries listed here; https://blogs.msdn.microsoft.com/dotnet/2017/01/19/net-core-image-processing/ You seem to be taking this quite personally. All power to you if you want to charge for it. Everyone is allowed their opinions.
I gave practical advice and information. you're being insulting. Hardly equivalent. You asked for directions, don't be mad that I gave them.
AutoMapper author here - my OSS work is sponsored. If I wasn‚Äôt sponsored, there never would have been an AutoMapper. Major OSS either needs sponsorship or commercial licenses to be viable. I think the greed entitlement falls entirely on the consumer here, greed of time and wanting someone else‚Äôs free work. James is trying to make the project survive. That‚Äôs not greed, that‚Äôs reality. Either he gets compensated, somehow, for his work, or he can‚Äôt work on the project to the level it needs to be successful. We are all humans here, maybe next time just ask if the projects you don‚Äôt want to pay for make exceptions for academia and non-profit? Knowing the authors of many dual licensed projects, licensing is really hard and is almost always an iterative process to make it viable for the author and fair to the consumer.
I recently switched to table-valued parameters for bulk-inserting data with our stuff. I was able to insert ~1.1m rows in under 10 - 11 seconds. I'm not sure how fast that is in the grand scheme, but it was well over good enough for what we needed at the time so I didn't spend time on further optimizations. 
Kestrel didn't get to be one of the fastest web servers by luck - that might a good reference on handling parallel string manipulation effectively.
On a large project that had lots of business logic we had a goal of having a test for every possible outcome. Essentially we had a test that touched every ‚Äòif‚Äô, ‚Äòcase‚Äô , and ‚Äòcatch‚Äô statement. When I left the team there were over 900 unit tests. It may have been overkill but it saved us many times when new features were added. 
&gt; a test for every failure that should happen These are just two tests: Validate the input, and check if the username is already taken. Look up parameterized tests
For me the intent of the API and the usage of the using statement are two separate things. The using statement is needed to clean up native resources since he is using an idisposable. Passing a parameter in the sound constructor doesn't make any sense, and then you wouldn't use that parameter? Regarding intent of the API, wouldn't it make more sense to add some sort of factory method? So you would get something like the following: Sound sound = be.CreateSound();
Windows may be set to left handed mode. See https://answers.microsoft.com/en-us/windows/forum/windows_7-desktop/context-menu-going-left-not-right/a09e42df-fdd0-45fc-a501-7e5e145a22b3
That's more than a visual studio pro license costs. That's not even in the realm of cheap.
I had looked into that previously and (stupidly) concluded that left handed was the correct mode maybe because I thought it had to do with text orientation. Anyway, your comment made me read it properly, think, and solve my issue. Thanks! :)
I totally thought this was a major update to the chat client named Pidgin.
Solved!
I've just been burned so many times. After the third or fourth time you have to spent days rewriting because of a change from GPL/LGPL/Apache to AGPL it's hard not to become cynical. [https://github.com/logary/logary](https://github.com/logary/logary): Apache 2.0 -&gt; No use on IIS without license [https://github.com/ionide/ionide-vscode-fsharp](https://github.com/ionide/ionide-vscode-fsharp): MIT, but removed features and added to a close source subscription extension [https://github.com/itext/itextsharp](https://github.com/itext/itextsharp): LGPL -&gt; AGPL dual license Ghostscript: GPL -&gt; AGPL dual license Openclinica, Community-driven medical study software: LGPL -&gt; Closed source I spend almost all my spare time writing an open source tool with nearly a thousand users. I'm never going to charge users, nor change my license to something less permissive. \&gt; it is totally reasonable and within a community members right to change their license and to be compensated for their work Of course it is, but it's naive to assume AGPL is a safe drop in replacement for non-commercial use. \&gt; Moreover, they are very clear that they will work with nonprofits and non-commercial uses of their software To be fair, unless I've made a huge error, that bit was edited in after my comments. And while I'm sure in this case they will, if the industry as a whole accepts dual AGPL/Commercial as a standard, there will be plenty who don't.
Happy to help!
This is the exact attitude to have. People aren‚Äôt entitled to open source. Participate or pay or die.
\&gt; Major OSS either needs sponsorship or commercial licenses to be viable. Absolutely. But **AGPL** is not the answer without a non-commercial use exception, which wasn't there when I first commented. \&gt; I think the greed entitlement falls entirely on the consumer here, greed of time and wanting someone else‚Äôs free work. I spend almost all my free time on MIT licensed open source projects. I have a fair number of users, but my tool is to do with entertainment, it's nothing important. Then in the day, where I work on things that actually matter, I'm repeatedly hit by an industry moving towards a license that punishes non-commercial work. It hurts that my unimportant (to the world) work can use every project under the sun, but my important work suffers due to what basically come down to legal issues. \&gt; maybe next time just ask if the projects you don‚Äôt want to pay for make exceptions for academia and non-profit? Unfortunately, organisations usually say no, if they reply at all. Six Labors have kindly indicated they'll provide free licenses to non-commercial, but that's not the norm. \&gt; Knowing the authors of many dual licensed projects, licensing is really hard and is almost always an iterative process to make it viable for the author and fair to the consumer. I regret my initial comment because it's clear that in this case it's missed the mark with the author of this project. But the effect of dual AGPL/commercial is to monetize commercial and non-commercial works alike. And I find it hard to describe trying to charge non-commercial projects as a selfless action.
Same here...
I was confused why the Pidgin chat client was being posted to r/dotnet. It's written in C.
Well, this project would not receive any contributions (who contributes to random websites they don't use?). It's also not going to be reused by anyone (nothing novel). So the tradeoff would be: \- Ability to use AGPL licensed libraries vs \- Significantly increased visibility of vulnerabilities in the applications I'm not sure how I'd convince an ethics committee that "maybe someone will review our code for free" balances against "if we ever have an obscure security vulnerability someone could notice and compromise the system". I think the open source argument for security tends to only work if there is at least one developer outside the organisation who has incentive to look :)
Well, GPL wouldn't allow that example. [https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.en.html#MereAggregation](https://www.gnu.org/licenses/old-licenses/gpl-2.0-faq.en.html#MereAggregation) If the .dll ended in the final app, it would be bound by GPL. And AFAIK AGPL doesn't change that part of the definitions, only changing what "distribution" would be. I think the solution would be to have an .exe with the thumbnail code which communicated with the main app through pipes or sockets.
\&gt; I'm also not really happy about this, but we ended up choosing dual-licensing, because we simply could not find any better model that may actually work. Sorry for accusing you and /u/JamesSouth of greed. It was hyperbolic and I'm afraid I've caused this post to become a bit of a mess... Your responses clearly show you aren't, and my comment was more a commentary on the series of other products in the field that refuse (sometimes explicitly) to consider non-commercial use (iText, ghostscript).
How does it compare to Sprache?
My rule of thumb is if it's behaviour the user is going to see in the product, then for the majority of the time it's probably worth testing it. Because \_when\_ I accidentally break it, I want to know about it. Tests become a burden when they are slow to run or impede your efforts to maintain your codebase. If they break when you modify the design of your code but the outward behaviour remains the same, they're less valuable.
Yeah this guy really needs to consider renaming his project. \*sigh\*
Your route is ‚Äúupload‚Äù. Are you sure ‚Äúapi‚Äù is being prefixed as you expect?
Not quite, but stuff is in the works.. we're getting there, ever so slightly :)
Sweet. What's the next big thing for Pidgin? :D
Also, try setting it to raw after choosing the file. Seems weird, but I think it might be the way.
Ya this is the top of my controller [Route("api")] [ApiController] public class FileUploadController : Controller { And setting it to 'raw' still gives me the same error.
This is not Pidgin the chat client from [https://pidgin.im](https://pidgin.im). We (Pidgin the Chat client) have considered asking for this project to be renamed, but have not done so yet as there are multiple other uses: official recognized spoken/writing languages and the BBC Pidgin language service ([https://www.bbc.com/pidgin](https://www.bbc.com/pidgin)). As we have no copyright/trademark on the term there's not much we can do and fighting all of these different fronts doesn't seem very wise either.
Way to much to list here, our ChangeLog is a good place to start, but it needs a good summary. And after just glancing at it.. It's a bit out of date in regards to shutdown protocols. [https://bitbucket.org/pidgin/main/src/default/ChangeLog](https://bitbucket.org/pidgin/main/src/default/ChangeLog) 
Thanks, I'll look it over, but I was more asking along the lines of what are just a couple big ticket items that you're excited to see come to Pidgin.
Behavior Driven languages certainly sell better than they're adopted. However, there is a value when writing acceptance criteria and tests. Gerkin syntax translates well into test automation with more established products like Selenium. OP is a bit audacious though trying to write a new library for which there's already adopted product in the market. 
New languages for plugins, we added webkit, but have to remove it for silly reasons, better password management support, and there's a ton of other stuff in the pipeline
\&gt;Is the demand for forum software shrinking? Is it due to Facebook, Reddit, Discord, etc.? I would say it started shrinking a while back, as social media gained popularity, and not much demand remains.
What makes you feel like they do t care about core? It's getting the most new features now and they've said the future is core, not full framework. They even ported all the winforms and wpf libraries for windows to it...
Cool. Thanks.
Don't know, just don't hear much about it and I can't remember the last time I heard about any serious apps using it. Honestly, I haven't spent that much time with C# lately, so maybe I have a bad perception about this. 
This is exactly what you should be doing - especially for a code path as vital as registration and auth.
I‚Äôm a little allergic to the idea of ‚Äúfull coverage‚Äù. What does it mean in unit tests? Testing getters and setters of POCOs? For unit tests I prefer testing all code paths. In well isolated components that‚Äôs input/output. What you are testing here is a Service I‚Äôm not sure exactly what that means in your domain so this is very general but I guess it interacts with some repository and acts on the results and you can easily mock what the repository returns. Looks like you have a bunch of combinations with expected input/output. If possible you could run that as parameterized tests instead of unique test cases for each. If the expected result is ‚Äúfail‚Äù for a set of inputs your test could look something like this (Xunit example). [Theory] [InlineData(null, ‚Äútest‚Äù)] [InlineData(‚Äútest‚Äù, null‚Äù)] [InlineData(‚Äúalready@taken.com‚Äù, ‚Äútest‚Äù)] RegisterUserShouldFailFor(string email, string password) { var result = myService.DoThing(email, password) result.ShouldBe(‚Äúfail‚Äù) }
This is fairly serious? =&gt; [Bing.com runs on .NET Core 2.1!](https://blogs.msdn.microsoft.com/dotnet/2018/08/20/bing-com-runs-on-net-core-2-1/) Its all about .NET Core; they've gone all in, so much so that WPF, Windows Forms, and WinUI (UWP) have been open sourced for .NET Core 3.0 so it can run Desktop apps (on Windows) https://blogs.msdn.microsoft.com/dotnet/2018/12/04/announcing-net-core-3-preview-1-and-open-sourcing-windows-desktop-frameworks/ 
Yeah but does that really count? I mean Microsoft developed that, it's not like they had to pick something vs NET Core.
Hi James, I had a question regarding memory usage. I actually tried various different libraries (MagicSharp, System.Drawing, PhotoSauce, and of course yours as well). Your performance was really good. But listed here (https://docs.sixlabors.com/articles/ImageSharp/MemoryManagement.html), the docs mention that 300-400mb of memory is retained. I'm planning on deploying my app in the free tier app service on Azure (only has 1 GB ram). My image processing will sporadic, so will configuring imagesharp to release retained resources help alleviate my concern about having this block of memory be unavailable? Wanted to ask because your library is very straightforward to use. I know the recommendation is using a service with &gt; 1GB memory but I can't at the moment unfortunately.
Depends, if you need ODP.NET, WCF or even something like Swing, then not yet.
&gt; However, these days it seems like they don't care that much about net core Can't tell if trolling or not. .Net Core is the stated future of .Net and clearly where all of the R&amp;D effort is going. 
No I'm not trolling. Is it so strange to encounter someone with a different perception around here? 
This may not be the best answer, but I was in the same boat as you...went through MS tutorial after MS tutorial, to keep ending up with DB object conflicts and blah blah blah....Finally, i just created a new web app, from the new web app template, with all the identity "stuff" out of the box, in the template, then copied my existing application code/pages/etc, to the new website, and manually re-added all users via a c# script to register them, using the Identity framework's create new user methods. Such a PITA 
What about mobile development, any chance of that? 
&gt;Maybe I haven't been paying attention or whatever Yep.
In case you didn‚Äôt run [across this.](https://stackoverflow.com/questions/46895523/asp-core-webapi-test-file-upload-using-postman) 
Yes, it is strange to encounter someone with that perception when for the last year or two Microsoft's focus has been so heavily on .Net Core at the expense of almost everything else. 
Yeah, I love the behaviour focus of BDD, but the overly green sausage-fest made me dislike the implied disconnect between BA's and dev. Still, we need audacious people :)
Well I did say I haven't been paying attention to what Microsoft has been doing for a while now. I wasn't aware people would get so defensive about it. 
It doesn't matter, someone reached out.
It's like wandering into the Apple forum and saying that you perceive that they don't care much about the iPhone. Folks aren't being defensive- they are befuddled that you could be aware of the ecosystem but be that much out of the loop on where it is heading.
Honest mistake! Today is actually the first time I‚Äôve heard of the chat app - I probably should have googled before naming the library. I was just casting around for words related to languages and Pidgin seemed cute. I‚Äôm sorry for any confusion or difficulty I‚Äôve caused. That said, the projects are obviously nothing to do with each other (different purposes, different ecosystems, etc) so my feeling is that it‚Äôs probably not too serious of a problem, and any confusion is probably worse for me than it is for you üôÇ. Feel free to email me if I‚Äôm wrong about that, we might be able to figure something out
You could try to explicitly set the request content type on your endpoint. &amp;#x200B; `[HttpPost("upload")]` `[Consumes("multipart/form-data")]` `public async Task&lt;IActionResult&gt; UploadFile(IFormFile image)` &amp;#x200B; [https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.consumesattribute?view=aspnetcore-2.2](https://docs.microsoft.com/en-us/dotnet/api/microsoft.aspnetcore.mvc.consumesattribute?view=aspnetcore-2.2)
Well I already said I had stopped following it. I haven't done any serious development in C# for a while now. My focus has been on Rust and Python for the last few months. "Wandering into the apple forum"? Really, are you all so serious about this. I mean yeah, everyone has their preferences and everything, but this is just a technology. If people in this sub are going to get this offended about it I might as well leave and take my questions with me elsewhere. 
That's not an intended target for Core. They have Mono for that
So I can do it, just not with net core? 
No worries, like I said it's being used all over now, and we used the name in reference to pidgin languages, so \*shrug\* :)
.NET on mobile is possible, yes. Xamarin makes it possible to develop on mobile
it doesn't matter to you because no one insulted you.
But can I do that on linux is my question? 
Thank you for you suggestion but this did not solve it for me. 
I did come across this and followed the same convention but still I get the same error. I've read something about Failing antiforgery validation will short circuit the request and return a 400 immediately. Any ideas on how to work around this, I'm very unfamiliar with this validation
The service I run, built in .Net (in the process of migrating from full framework to Core), handles well over a billion requests per month, makes millions of external api calls every day, and serves almost 2.5PB of bandwidth a year. Serious enough?
It does count since that signals to everyone that Microsoft is all in on dotnet core and not the full framework is just going to maintenance status. However, maybe you worded your original post a little wrong. I'm going to assume your talking about the ability to write portable GUI apps like Java. While it's possible to write a dotnet core GUI app with [Avalonia UI](https://github.com/AvaloniaUI/Avalonia) it's still probably not as portable as using Java. Now, app development isn't just about GUI apps. I personally see dotnet core as an equivalent to something like nodejs. Command line, web apps, web api, or a service app, that's where it really excels and probably would put Java to shame in [performance](https://benchmarksgame-team.pages.debian.net/benchmarksgame/faster/csharp.html). It's really all about right tool for the job you want to perform. I love C#, but I still need to dip into JavaScript, Typescript, Xamarin with mono, and C++..
This would probably go a lot easier if you just told everyone what exactly you have and what you want to accomplish.
I'm thinking it has to do with the validation because the request isn't even hitting my controller. I changed up the routes to see if that was issue and passed it a bad value and got an expected 404, so I don't think it's the route either. This is quite the conundrum.
I have a web API in rust, it runs on linux. I use linux as my development OS. I need to create a moblie app that uses that API. I would prefer to use a multiplatform solution like Xamarin, particularly because I prefer C# to Java and I don't really know swift or ObJ-C. I probably should have clarified that. 
Xamarin only has out of box support for macOS and Windows. It is probably possible to manage something with MonoDevelop and some manual work, but I think it hasn't got much love lately. 
I think you misunderstood what I meant when I asked that. I asked that because I wanted to know if their tech had been adopted by other devs. In my opinion languages and technologies seem to grow more when outside developers from whomever came up with the tech start using it. Take Rust for example, when Mozilla adopted it, it got a lot of attention, or at least I think that's how it went. If they developed it, then forget what I said because I just made an ass out of myself. To me Microsoft switching to net core for bing sounds like self promotion, which is why I believe it doesn't count. Now if you told me RedHat or SUSE started using net core for x or y reason then that's another story. 
Well that is disappointing. I would prefer to do that in C#. Java is boring, I don't want to use javascript unless I have to and I don't and Dart didn't really do it for me with Flutter. 
Well it's a lot better than "Microsoft did bing on it so that means its serious". However, does it run on linux? 
Think you're missing his point completely and no one is offended. That said, your reaction to these answers is really annoying tbh.
Annoying to who? To you? That's not my issue. And I'm not missing his point, I just don't think it's that relevant. 
No, the code base is over 10 years old and the applications themselves still have to target full framework due to various dependencies. Once we can target Core, and eliminate a particular imaging component that's windows-only, that's something we can consider. But it would take a long time for us to ROI on switching from Windows to Linux, so it's not a high priority, whereas fully targeting .Net Core is something we see as necessary to avoid unacceptable levels of technical debt. 
In my image uploader, I had to remove the attribute `[ApiController]` as the convention was blocking something/has incorrect bindings. I don't remember the exact details. Can you try this?
Well I can respect that. I think people are getting the wrong idea here. It doesn't have to run on linux, I would just wish more people adopted it there. I honestly don't know what people see in java and with Oracle's recent "we're going to charge you for java" policy, I don't know why anyone would want to use that thing. I asked this question because I wanted to know if I could consider NET core on linux for future projects. I don't want to use Java, so NET is my first option for this but there other choices as well. 
Yes. Issue? Are you drunk? it's just a helpful comment, since you seemed to misunderstand the other commenters' reaction.
Well maybe you guys oughta sound a little more helpful or something because to be frank it sounds like you are being condescending and passive aggressive about what I asked. I don't even know why someone is going around downvoting some of my other responses. It's like someone didn't like what I asked. I mean, I'm sorry but I'm just not up to date with what's been going on with net core. I asked this because I prefer to find out from the people who use it and not from some site that's only covering the very basics. I didn't think people would be "befuddled" about it. What? Is everyone around here assuming I have my eyes stuck on whatever Microsoft does? 
You could start an open source project for this.
Your key is Image and your controller is expecting image. I've just tested my [asp.net](https://asp.net) core 2.2 api and it's case sensitive.
The contribution of companies and individuals to .NET Core since its open sourcing is probably one of the reasons MS are focusing all of their efforts on .NET Core as the .NET Framework doesn't accept contributions and it therefore has a hard time keeping up with the [16000+ community contributions from 3000 companies outside Microsoft](https://mattwarren.org/2018/12/04/Open-Source-.Net-4-years-later) that have happened since it was open sourced. RedHat, Intel, Samsung and Qualcom are all major contributors The source is also under the independent [.NET Foundation](https://dotnetfoundation.org/) organisation rather than Microsoft.
If you had Enterprise edition of Visual Studio what you would get is automated testing to create these unit tests, and code analysis to tell you exactly what part of your code isn't being touched by a test, down each if statement. So yeah, that is how specific I would be if I had access to that tool, but since I don't I will just have as many as I can be bothered to make. So no, you're not making too many.
I am not commenting on the question. It makes a lot of sense to ask whether to focus on netcore. I think it's asked often and usually gets helpful replies. I could see a lot of people confused about that if they don't follow ms closely. I just commented because you misunderstood some guy above and the whole "sorry for not following dot net, don't take it personal" seems like a defensive reaction which does not reflect what the other commenters are actually writing to you. To chip in on the question - yes, I think netcore has full focus and is the future of dotnet. I work in a SaaS business and we migrated to it. They keep releasing rather huge performance improvements and it will support future c# versions etc.
[removed]
So this route is actually what I've decided to do :/
JetBrains has Rider which works as Linux IDE environment for Xamarin (and .NET Core) https://www.jetbrains.com/rider/ VSCode would probably work also, though I don't know how clean the process would be; Visual Studio (Windows) and Visual Studio (Mac) has fairly honed linkup and debugging experience for mobile.
I see. Those are interesting proposals. I shall look into them.
I actually want to, but that is why I asked questions about demand. It just feels like no one cares about this stuff anymore. Otherwise, someone probably would have stepped up by now.
Is the IEnumerable already in memory? Otherwise your bottleneck might be the read part, you're calling writetoserver on something that isn't ready to be written as it hasn't been read yet. I copied over thousands of tags, each with thousands, some with millions of data points. In a loop for each Tag, I combined it with DbContext.Add to get the tag object primarykey generated by EF, added Datapoints to the tag, then called SaveChanges Immediately after I use DetachUnchanged which looks like this public static void DetachUnchanged(this DbContext context) { foreach(var entry in context.ChangeTracker.Entries().Where(e =&gt; e.State == EntityState.Unchanged)) entry.State = EntityState.Detatch; }
Just FYI, rust was originally developed by Mozilla. And yes, multitudes of companies are adopting it and using it.
Hence, my comment about that. 
I really appreciate this comment, it‚Äôs been a rough 24 hours. 
Not according to this page? https://visualstudio.microsoft.com/vs/pricing/
VS code Xamarin support is really gross right now. The premium experience is full visual studio on windows. However as mentioned Rider does support [Xamarin](https://www.jetbrains.com/help/rider/Xamarin.html), I'm just not sure how much. I think you can do a trial. If you are targeting just Android, then Android studio with [Kotlin](https://developer.android.com/kotlin/) is probably your best bet. If you need to Target both Android and iOS, then look at Xamarin, but good luck. Last time I used it last year for a project it was frustrating. I ended up switching to React native. My web apis are all written in dotnet core and it worked well.
Thank you. This is what I wanted to know. Sprache is really nice to express a parser but if this is a more performant and flexible parser combinator library that makes it worth looking into for my next parsing project. 
Discourse is newer, not crappy, and light years ahead of the options presented in that post
IM has moved on since I was using Pidgin. I would certainly like to stop using WhatsApp for some people, Facebook Messenger for others, Viber for others etc. but I doubt their protocols are open and easy to implement.
Need both. Using js is really something I want to avoid. I do not like that language one bit, having to use it on web is enough. I guess that leaves Flutter. 
I may have said this elsewhere, but yeah you can absolutely use dotnet core for new projects and not worry about it being a third rate technology stack. We are developing a brand new web app that will be used by a metric crap ton of people, and the API is all dotnet core running on Linux. The front end is Angular, so mostly Typescript transpiled down to JS. We couldn't be happier with how well it's working out in Linux. But like I said, it's using the right tool for the job. Right now mobile and desktop UI apps are not good for core. That's more of a Mono/Xamarin thing or other frameworks.
Tests should be validation of expectations, which is short hand for ensuring the code does what the users expect. We add some extra value by creating tests that also assert stability. So a password of "select * from users" will not actually return all the users. I do get what you're saying. Tautological tests are a PITA. "I've proved 1 == 1!!!" so you need to focus on the business requirements first and tech smarts second. Neither are optional :) If I saw your tests I'd be ok with them, but I'd still have to ask you to define what a "bad password" was. In a year someone is going to look at that test because the password requirements have changed and suddenly a bad password is now a good password? Feel free to over comment on tests, it's really helpful down the line. 
We're actually looking at using flutter for our next mobile app.
Yeah, but I wanted C#. Whatever, I'll just learn dart. Hopefully, that language becomes an alternative to javascript, if it isn't already. I would use it in a heartbeat. 
As long as the code is implemented as a replaceable plugin it‚Äôs ok. They main application cannot depend on it. Read the Ghostscript notes on the subject 
I wonder NPM isn't a library desert despite everything in it coming from FOSS devs. And I've never even heard of an NPM library that was licenced.
Well, you might have some fun with Kotlin then. You can make use of Kotlin/Native for the iOS part, just take into account that it is pretty much WIP. https://blog.kotlin-academy.com/multiplatform-native-development-in-kotlin-now-with-ios-a8546f436eec
This is it! This seemed to be chumming up the binding and forcing Postman to spit back a 400 before ever handling the action. The Odd thing in my opinion is that if you removed the parameter from the action you would hit it. 
I did notice and try this, however was not the solution. THank you for the response but u/SatsuTV was able to figure out that the \[ApiController\] was causing some type of binding issue. 
It's been done so many times in other frameworks, that there just is not a lot of demand. For instance, reddit's core is open source and can be forked at will.
I think if you keep the [ApiController] attribute you have denote what part of the request the parameter is coming from for model binding to occur. For instance your method signature would be: Upload ([FromBody] IFormFile image) Or some other of the [FromX] attributes that I can‚Äôt remember off he top of my head.
Like you, my preferred OS is Linux and I use Ubuntu 18 right now. The key drawback I see is the not-as-smooth integration between Core &amp; MS SQL Server on non-Windows OS. I'm using Postges with PGAdmin but much prefer the usual MSSQL with SSMS combo. 
You could just check your settings in the your AccountController equivalent Login‚Äôs POST action. For instance when identity returns a result that indicates that 2FA is required for the user, and your settings indicate that 2FA is disabled at the application level, you could just sign them in and disregard the requirement.
In my case I'd be happier with Postgres. I don't know what mssql is like now, but when I used it before it felt like an overly complicated monstrosity. I'm not much for proprietary databases, quite frankly they're not that great. I have the same line of thought for oracle, except that thing is way worse. 
nice troll
Yes that is what I was doing. Trolling. I guess it is inconceivable for some people in here to imagine that not everyone follows their favorite tool/language. Why don't you go bother someone else? 
nice troll
It's 100 n something when you buy in bulk. No one pays that price, I guarantee you.
That's another thing I'm observing: discussion software is often just thrown together as a small component in a larger system. The whole community-in-a-box approach feels less and less common. I used to bounce between communities that had forums at the heart. Today, most discussion happens in comment threads attached to blog posts. :(
Cool! Feel free to give me some feedback or file issues.
I mentioned Discourse. I agree it's a solid and modern choice, but I weep at the choice to use Ruby as its foundation.
Not unless you know a significant chunk of API without network, I guess that would do. I haven‚Äôt tried coding in an iPad but what‚Äôs the point of using it, much more paying for an app that wouldn‚Äôt reference the platform/framework you wish to write unit tests for? 
ApiController will automatically return bad request if the model state is invalid, so that your code isn‚Äôt littered with `if (!ModelState.IsValid) return BadRequest();`
Is there any way of using raw SQL with FluentMigrator? I don't get it why people do so many abstractions. 
Stick with postgres. We moved away from mssql to postgres and feel like we made the right decision. Also, Microsoft just bought Citus Data, so plan to see much broader support of postgres in the Microsoft world soon.
Just saving space by not packing my laptop. I have coded offline with a laptop by just grabbing the NET core &amp; EF documentation in pdf, so I figure I could do the same thing as long as I'm able to compile and run the code. 
Then don‚Äôt use it? You‚Äôre using someone else‚Äôs free work. I don‚Äôt give away free work for my OSS either. Someone wants a feature that my customers don‚Äôt use? I charge.
Can you give some sample code of its complexity causing problems. I've never had an issue with it. And also think it is way better than the old way.
&gt;Any plans on porting it to asp.net core? Hi neverthy, I have been looking into rebuild the CMS using ASP .NET Core. Thanks!
There is an environment configuration builder https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-2.2#environment-variables-configuration-provider
You can use sql strings or files. 
Sure, those documentations would work. But what if you suddenly need a package to do some more but because you‚Äôre offline, you can‚Äôt even do it? These were the questions I was asking myself then before so I dumped the idea coding in the iPad. While .NET core runs on win/linux/mac, I am not sure if an sdk has been mode optimized for the Axx processors. Either, bring your laptop and be more productive or just enjoy your vacation/travel without coding üòÇ‚úåüèΩ
There is facebook messenger support but no one has written viber support yet. [https://developer.pidgin.im/wiki/ThirdPartyPlugins#AdditionalProtocols](https://developer.pidgin.im/wiki/ThirdPartyPlugins#AdditionalProtocols)
And how many licenses is bulk? In fact don‚Äôt bother commenting because you‚Äôre adding nothing useful to the conversation. You‚Äôre comparing a multi billion dollar company with pockets deep enough to heavily subsidise licenses to encourage further spending in their ecosystem with four guys who are just trying to make a living who are already charging less than existing sdks. You‚Äôre either an idiot or a troll and I‚Äôll wager a dose of both. 
I guess I didn't say it write. Its that there are low code tools all over now that can replace what we used to have to write 14 years ago as a custom website
We use steel toe and piggyback off our Java cloud config server, and get our secrets from the kubernetes secrets. Locally we actually can develop in a docker container, by mounting the files and the container we run dotnet watch so we use .env files passed in!!!! Works amazingly. We can run every service with compose. And we debug any container at any time 
Beautiful. Thank you 
&gt; steel toe You mean this? https://steeltoe.io
Cool, but how do I provide a local version?
Couldn't find anything in the docs. But would this be correct? var sql = @"initial_migration.sql"; Execute.Script(sql);
It's definitely the natural progression that systems become easier to develop. This progress makes it easier for us to focus on developing specific application functionality, rather than building the tools to then build that functionality.
I'm a c# guy who got roped into asp.net core for a project, and I found pluralsight tutorials to be well worth the monthly cost. I learned a ton from them. I had a hell of a time wrapping my head around MVC and it really helped alot. Its a pay service, but worth it since you can do it off and on when you have time or can afford it.
Yup. Works well for us. Spring cloud config is industry standard. Looks good that the dotnet teams are able to use industry standards and fall in line with the Java teams
If you want to buy a few hundred ImageSharp licenses, I'm sure /u/JamesSouth will be happy to cut you a deal. Until then, fuck off with the false equivalences.
 PSA - Signing up at https://visualstudio.microsoft.com/dev-essentials/ gives free access to Pluralsight for a month (and a load of other stuff, like Azure freebies.)
May be below tutorial will be helpful for you to build real application https://studymash.com/our-courses/web-development/build-real-world-web-application-in-asp-net-core-and-mvc/?tab=tab-curriculum 
JavaScript does not have its own standard libraries so everything is on NPM. There are tons of paid NPM library (chart libraries, etc).
Are you guys planning to create a special pricing just for the resize/thumbnail generation features? I think there is a large market for this feature and if it is priced correctly, it will be a best selling product.
Try all the samples here https://github.com/dodyg/practical-aspnetcore 
https://blog.nodeswat.com/what-i-learned-from-analysing-1-65m-versions-of-node-js-modules-in-npm-a0299a614318 &gt; there is actually a surprising amount of placeholder modules in NPM ‚Äî almost 2% of all modules have no content besides a package.json and maybe a licence - &gt; about 40% of modules were not updated [in the] last year [2015] On the other hand, it does seem that &gt; 50% of all modules are MIT licensed. It's a bit hard to read his "code percentage" section, but if I understand it correctly about 50% of modules on NPM are &lt; 10% original code, meaning the 90% of the package is dependency code. Also: &gt; One of the funnier ones I found was on a package called closing-time. What it does is download and execute a shell script, which in turn downloads Semisonic‚Äôs ‚Äî Closing Time and adds a row in crontab that starts playing the song every day at 5pm. I'm glad there are critically important modules like this one keeping NPM from becoming a desert... As a closing anecdote, do a search on NPM for 'pad' and see how many duplicates of the exact same package exist. I know left pad is memed now and probably doesn't represent the same level of duplication across the board, but to extend your desert analogy, NPM might be the equivalent of drowning because there's *too much* water. https://www.npmjs.com/search?q=pad
You can have multiple config providers. I use a settings file locally and environment when deployed.
Thanks. I'll test it out. Great to hear that memory reduction is in the works. As the other person mentioned, having a resize/thumbnail only generator would be nice as I am only using that functionality currently.
I'm on the team that writes the official tutorials. Which tutorial are you having issues with? How can we make it better? 
I wouldn‚Äôt call that ‚Äúkey functionality‚Äù really
But what if you needed to write an application that is compatible with multiple space/time coordinates?
How is that got anything to do with manipulating date/time on the machine?
This sucks. I don't trust the Windows clock so I wrote an application that sits in the background and sleeps for 60000ms then updates the time. ^^^xposted ^^^to ^^^/r/programmingcirclejerk 
Well lets say you drop through a wormhole. You are probably not going to find a compatible NTP server. So instead you are going to have to knock out a quick signal processor in VB to parse whatever is coming over the AM airwaves and translate it into a date/time that your OS understands. Once you've done all that, do you really want to watch a console window while you try to fat-finger in the new date/time? No, you want the application to go the distance and set the time for you automatically.
I can‚Äôt tell if that is sarcasm
I second plural sight. Company purchased it for us and I‚Äôve just been watching everything. The angular videos really helped us transition and learn angular 1.x to 2+
Now, I've never used VS Code personally, but some of my programmer friends code exclusively in it (on their job, professionally), and I hear it's pretty neat. It also has a rich systems of extensions. So it might actually be just what OP needs at this stage, since he mentioned elsewhere he wanted to play with language constructs.
You can wire up multiple configuration sources and then they'll be used in the order in which they are declared. This lets you define the bulk of your config in a json file, and then add in the environment-specific bits either via [user secrets](https://docs.microsoft.com/en-us/aspnet/core/security/app-secrets?view=aspnetcore-2.2) in dev or [environment variables](https://docs.microsoft.com/en-us/aspnet/core/fundamentals/configuration/?view=aspnetcore-2.2#environment-variables-configuration-provider) / azure key vault / etc. in production. 
No, I think that is considered to be 'absurdity' rather than 'sarcasm', at least in my native dialect of English. But think of all the real world breaking changes... https://xkcd.com/1172/
Clicked link thinking it was to do with the IM program and not this. The IM program that's been called Pidgin for a decade now.
I feel like the easy solution for backwards compatability is that when you have this enabled all assemblies with it off return all classes with a ? As you don't know for sure if they're nullable. 
I prefer just getting my hands dirty and learning as i go, the more you do it the more you learn. im not a fan of watching a 4 hour video on pluralsight. I do research but generally i look up the offical docs or a good article that explains what im trying to figure out. the github microsoft has crated with examples is decent but not comprehensive, it is updated quite frequently tho, so its worth a doing a pull and updating it every so often https://github.com/aspnet/Docs there are often references to this github in their official documentation which is quite useful e.g. if u want to figure out how to configure ef core https://docs.microsoft.com/en-us/ef/core/modeling/alternate-keys though sometimes for a more over arching question you have on how to solve a given problem with good architecture, that i find very difficult to find. many examples are overengineered or just crappy. 
What‚Äôs stopping you from using the vue cli? As with all things, there‚Äôs more than one way to do things . The asp.net spa template is one way , but not the only way . Also you can create a docker image from the asp.net spa templates , if you choose. It all depends on your architecture. I‚Äôve built several apps with .net (both core and framework ) with a vue front end . No issues (including running in containers.)
Hello, I‚Äôm not the person you asked but I can tell you it‚Äôs bloody infuriating when I‚Äôm trying to learn how to do something and it tells me to scaffold code without showing the generated code anywhere. It immediately turns an otherwise good tutorial into a useless one unless you have those tools to hand and your project is in a state that you can do that.
I asked myself the same question some months ago, and couldn't find an answer beyond that it may be easier to get something up and running quickly, it's easier to deploy back-end and front and together, and there may be some benefits from server side pre-rendering of components (invoking node.js through asp.net?). I guess there may be some justifications for it explained here https://docs.microsoft.com/en-us/aspnet/core/client-side/spa-services?view=aspnetcore-2.2 But basically it seems cleaner to have a total separation, and use the appropriate tooling for the SPA (npm, gulp, vscode). Besides that, the SpaTemplates package (which contains Vue) was abandoned by Microsoft last year in favor of focusing on the ones included by default in .NET Core (react/angular/blazor), so it is never updated.
For local dev, I'd say the vue-cli is nicer but honestly it comes down to how you want to host the minified css/js that your webpack will produce. The vue-cli works great for local dev but I think the advise against using it to host your production code. As for the c# template, I think in production it turns just off hot module reload and it's good to go. So when you containerise the c# vue template, it'll be good to go straight away. With the vue-cli, you'll probably want to use something simple like node.js just to serve the css/js. 
Thank you I bilive the docemnation explained very well , but i agree with you it is more cleaner to use JS framworks tooling.
I don‚Äôt find them useful as well Developing spa requires different workflow and better suited tools (cli, vscode, etc.) I tend to separate spa &amp; api workspaces and rely on the clis 
The angular template uses the angular cli. Is the vue template not the same?
That's a company that wants to charge me 14000$ a year for you.
I'm assuming the error you mentioned (but didn't mention *which* error) is the reason that the documentation says to never use `asp-route` and `asp-controller` together.
Thank you, I updated the question with error details. I also found this in the documentation, but I wonder *how* to use my route with tag helper? Is it even possible?
Have you tried this: https://loune.net/2017/06/running-shell-bash-commands-in-net-core/ I have had that page open in a tab now for some time, because I was planning on trying it as well, but didn't get around to it yet. 
server side pre-rendering
Okay thanks its works :) 
They rewrote the angular templates at some point to make them more useful (I think in the 2.1 release?), but they stopped maintaining the Vue one. The Angular ones don't really require you to make any sacrifices to work...you get the full power of Angular with the convenience of a one command debug and a one command publish. You can freely do work between the angular cli, your csproj / msbuild, or front end tooling as you see fit.
I think it's partly a relic of traditional .NET web projects (MVC, etc.) where front and back end were mixed together in a single project, and partly due to front end project generation tools only having matured in the last couple years. Around 2015-2016 I remember seeing a lot of blog posts complaining about how setting up a modern SPA app was an absolute nightmare, and it seems like the front end community set out to address that and has done pretty well with vue-cli, create-react-app, etc.
Does this work: &lt;a ~~asp-route="project"~~ asp-area="" asp-controller="Accounts" asp-action="Index" asp-route-projectID="1"&gt;Accounts&lt;/a&gt;
Thats what i also found out, however i want to do the reverse: i want to stop the program gracefully so it hides the notify icon properly, just without using taskkill...
You'd have to use P/Invoke to locate the processes' windows and close them. https://docs.microsoft.com/en-us/windows/desktop/api/winuser/nf-winuser-enumwindows You can use that to enumerate all windows. https://docs.microsoft.com/en-us/windows/desktop/api/winuser/nf-winuser-getwindowthreadprocessid You can use this to determine the process id of each window and match against the process id. https://stackoverflow.com/questions/9519206/give-a-windows-handle-native-how-to-close-the-windows-using-c Here's a couple different ways to close windows (don't use CloseWindow API, that just minimizes them).
It appends `projectID` as query string: `accounts?projectID=1`
I did consider this, it just seems silly to extract something like this: if (\_context.Users.Any(x =&gt; x.Email == [user.Email](https://user.Email))) throw new AppException("Username \\"" + user.Email + "\\" is already taken"); Into it's own method or component.
Create a new project and scaffold and watch it happen? Though valid complaint
You can and should have the api http service separate from the spa http service. That‚Äôs the norm for spas. Asp.net MVC style would be having them together. What using the templates give you is just that, a template or something to start with. What using asp.net over day node is using the same tech you are in the backend, so you can use the same loggers, exception handlers, telemetry, etc. basically utilize features of the framework you‚Äôre already comfortable with .
Gonna give this a shot and see how I like it. Trying to convince business to use BDD and specflow. This might be easier I don't know, but it feels like it's more for integration tests. I like the way you think chief.
Which course in pluralsight do you recommend? 
Let me know what you think :) 
It all depends on what you're looking for. The library itself uses the data to produce the HTML report. Other uses are completely up to you and your business. Automated emailing of percentage pass rates to business stakeholders? Flaky test tracker? Test time tracker? The data is there to do as you please. I'll look up writing a blog post soon, and perhaps look at producing some demo custom reports. Thanks for the interest! 
Are you referring to Gherkin/SpecFlow? I just feel you're slightly locked down as to what you can produce and pass into your tests from the separate feature files. I like the flexibility of a pure code based test, but that also offers you the benefits of an easy to understand gherkin syntax 
ASP NET CORE from Adam Freedman from Apress editorial
:) Do, it'w the bit that interests me. Sending this data to the business hold no interest to me. I spend way too much time telling people that testing is probably harder than writing code, so while I value it, it's in the LOC and Test Coverage category for me. Quality over quantity is probably my mantra :) All that said, I'm in a silo and I get a load of really good information from people outside that silo. It's really helpful to me :) 
We do actually have both a common law trademark (under US law) and a copyright on the name and branding of the Pidgin instant messenger. We simply do not have a registered trademark. As to whether this is "confusingly similar" to Pidgin the IM client or not, most corporate entities would probably say yes and sue, but as a FLOSS project I don't think we would consider it problematic. Whether it is best for this newer project to rename while it is young for the good of it, Pidgin the IM client, and the open source community is an open question. (Cf. Firebird the web browser renaming to Firefox so as not to conflict with the Firebird open source database.) As a Pidgin/libpurple developer, I am inclined to believe that it's not a critical issue. I agree with @benjaminhodgson's assertion that it's probably harder on this project than on the IM client. In the spirit of FLOSS, live and let live. When you're the premiere parsing library in any language and people can't find the Pidgin IM client past all your google hits, I'll applaud your success. ;-)
A completely overkill, but nice quality of life detail with all the Microsoft tutorials would be a walk through of the scaffolding process (what gets scaffolded and how those items come into play) that you could link to everytime a tutorial says "generate scaffold." It's a bit overkill, but there are some people that dive in headfirst or woild benefit from an easy reminder / chest sheet for the generate process. 
Or just a single tutorial on scaffolding would be enough. 
Well, I'd love to see one for each of the "new" generators but I'm sure that would be time consuming. We get great insight in short form with the peaks on visual studio but, for a beginner, having each said written out in a long form would be very nice. 
Yeah that's the stuff. It handles web client testing really well. I understand plugging in RestSharp for WebAPI works well in that too, though I don't have experience there. Abbreviated libraries are nice, until they're not. Firing up a SpecFlow project takes a while and is perhaps heavier than your lib, but it handles quite a lot of use cases. 
I can see that. As .net core grows and more beginners use it as a starting point the demand and need for it can increase as well. So it‚Äôs not out of the question.
Maybe there is another route it hits first? Check (or post here) your routing config.
The angular template is outdated to. Kinda annoying.
I don't know how to do this with the anchor tag helpers. This is one of the reasons I don't even use the anchor tag helper. Another reason is that it just feels more constricting and verbose than string interpolation. I know this isn't what you were asking, but just making sure you considered it. Instead of the helper, you could just use: `&lt;a href="@($"~/{projectID}/Home/Index")"&gt;link&lt;/a&gt;` Or something similar to that depending on what was dynamic and where. Simple, straight forward and concise.
&gt; app.UseMvc(routes =&gt; &gt; &gt;{ &gt; &gt;routes.MapRoute( &gt; &gt;name: "default", &gt; &gt;template: "{controller=Home}/{action=Index}/{id?}"); &gt; &gt;routes.MapRoute( &gt; &gt;name: "project", &gt; &gt;template: "{projectID}/{controller=Home}/{action=Index}/{id?}" &gt; &gt;); &gt; &gt; &gt; &gt;}); &amp;#x200B;
Try switching places.
The reason tag helpers exist is to provide for separation of concerns: route config is disconnected from link and url generation. Tag helpers query your route config and determine the url. The way you do it, by providing such a hardcoded string, you are tight coupling your link generation to concrete routes. Once you decide to change your routing config, your links will be broken.
**Oh, wow, THANK YOU, it works!** I had no idea. I changed order of route mappings as you suggested, so that the `project` route comes first, and now the links generate properly. That's strange. Is the tag helper hardcoded to use the first mapping in the list? I guess I need to do some research :). Thanks again! &amp;#x200B;
As someone has noted in the other comments, depending on your project, 100% coverage could be a chimaera useless to hunt. Also, sometimes our code it's so expressive that covering with one test is not enough (think of all the different outcomes of a Linq query) Finally, in general your team won't have the time to cover every single line of code. So you got to decide what's worth being covered. In my company URL consistency is on of the most important requirements and our URLs are pretty complicated. This is why that section of the platform alone has over 2000 unit tests. (That application has over 30 controllers and at least thrice as much services running local, and we have in total 4000 tests). Another trick, use AutoFixture to generalise your tests and speed up how to write them. 
It will bind to the first route that matches what you specified with your tag helpers. So, since your said your want controller=Accounts, action=Index, it bound you to the first one you mentioned above. It did not look further. You should always define your more specific routes before your more general routes. Your "default" route is actually more general than your "project" route, which has more segments. But since it was listed first, it got bound to first.
But wouldn't they be broken the other way to? Aka... you change route... then your values in your attributes no longer are correct? Aka... I don't think updating your routes will automatically fix your attributes, but I could be wrong.
Agreed, but it's not very hard to update and it's an absolutely vital skill to have. 
Take a look at https://github.com/damianh/ProxyKit for alternative proxy middleware.
For my (personal) projects I separate frontend and backend for two reasons (note, I always run them in a docker container) 1) I want them to be independent of each other. If I want I can swap the backend or frontend 2) I want my apps to be horizontally scalable. Depending on the load I can either increase frontend performance or backend
Sounds unnecessarily complex for just replacing connection details. I've found this dotenv approach: https://github.com/bolorundurowb/dotenv.net
If anyone is interested, found a dotenv alternative for c#: https://github.com/bolorundurowb/dotenv.net
It‚Äôs two lines total. Super easy. Easier than managing files with dotenv from my experience (I‚Äôve used it a ton with ruby).
Yeah, still ironing some things out in using EF Core with it, but we're going with Postgres for a side project because we can use it for free. My primary job since August has been as a Rails developer, where Postgres is pretty much *the* RDBMS of choice and there's plenty to like. I can agree that SQL Server almost certainly integrates better and works "out of the box", but so far I haven't had issues using Postgres with EF Core and code first. Really my only issue at the moment is figuring out how I want to structure the models to have EF then structure the database. At the entity level we have an abstraction, but mirroring that in the models causes one table with "ClassName_ColumnName" to be used for certain fields when migrating, but breaking things out differently feels like overkill. It's one of those fun things about programming, figuring out the best way to do the thing you need to do. :D
Used this recently to port a particle system that was made in C to C#. Living dangerously I guess. This is one of the reasons C# has been my favorite language for the past 9 years. 
&gt;The vue-cli works great for local dev but I think they advise against using it to host your production code. I'm not familiar with SPA's, why would you need to host it in production as anything but static files on a web server of your choice (apart from losing pre-rendered components)? All the transformations will usually be done beforehand by the build script, no?
Funnily, I'm pretty sure all the examples /u/BezierPatch mentioned are heavily sponsored. Newtonsoft didn't replace Microsoft's own serializers for free...
I've been using /u/JamesSouth's stuff since well before six labors, and I was always impressed at how actively he has been developing it. Got a reliable, stable product? Now we're done right? Hells no! C# just introduced 10 new language features which could shave 10ms off processing time of certain images! Let's go! My only regret is that he wasn't picked up by one of the large FOSS foundations, and was forced to take this path to make the project sustainable. It's an amazing set of tools, and a real credit to the team behind it.
No, they won't break in the second scenario. You specify asp-controller and asp-action, and the URL will automatically be translated to your custom route if you have configured one.
How much do you think Newtonsoft Json receives to be Microsoft's defacto JSON serializer of choice? If you want to sponsor /u/JamesSouth, then go right ahead. Until then, guy's got mouths to feed.
No idea. What makes you think Newtonsoft Json receives anything?
I think the OP was going to dockerise and run the vue-cli in production for his front end. I might have misinterpreted what he said. 
Primarily because Microsoft hired him to maintain the library. https://twitter.com/jamesnk/status/978719138347495424
Yes, in 2018. *After* proving how valuable it was to the community. The earliest version being https://www.nuget.org/packages/Newtonsoft.Json/3.5.8. That is seven years. Not to mention, a few Microsoft devs have recently admit that taking Newtonsoft.Json on as a hard dependency was a probably a mistake on Twitter.
&gt; Yes, in 2018. After proving how valuable it was to the community. I'm sorry, but /u/JamesSouth has been developing ImageSharp for years too. You want to talk about it being valuable to the community? Umbraco depends on it, which means there's a few hundred thousand sites out there right now benefiting from it. I know I developed an almost identical implementation for Kentico right as Umbraco released theirs - and it was built on almost an identical technology stack, and for good reason - it's basically the best that's available at the moment, and James has only improved it since then.
I get it, you feel for him. I refer you to my earlier reply:- &gt; You seem to be taking this quite personally. All power to you if you want to charge for it. Everyone is allowed their opinions. And you can spend years developing something doesn't mean squat. It actually needs to be used by the community widely and broadly. JSON is synonymous with JSON.net. Unit Testing with xUnit/nUnit. SFTP with SSH.NET. ORM with nHibernate/EF/Dapper.
You can ignore it for most part. Visual Studio/Microsoft had provided "wizard" for everything out of the box since decades ago, but a lot the "out of the box" stuff are rather entry-level/generic/uninspiring/out of date after a year or two. If you know what you are doing, you can basically ignore most of it. They make a lot of assumptions about * How you want to wire your app * How you want to deploy your app * How you want to maintain/upgrade your app They are basically Yeoman-esque templates provided by Microsoft. 
If you're going to try and include nHibernate and Dapper in there with ORMs, then you're going to have to provide some references for what exactly you think is synonymous with image manipulation. I already pointed out that it's embedded within one of the largest open source .Net CMSs out there. With 400,000 potential installs minimum, what alternative would you suggest has higher market penetration currently?
I appreciate all the comments and feedback everyone has given. Being new, I know persistence is key in becoming a developer. I appreciate the material recommendation, and also encouragement in a way! Thank you!
I didn't save my problem code, unfortunately. But one of the most common patterns is that VS Intellisense will say it's one thing, based on color etc., but execution gives a different result. For example, C# "//..." comments may end in output even though they were green in VS, per typical C# comment. And, Visual Studio often reformats/indents it irregularly, especially if you have C# loops or conditionals in it. With the percent-style (&lt;%...%&gt;), it was almost always clear whether one was in code mode or HTML mode. I rarely had any problem with percent-style mode ambiguity for my both eyes and Intellisense. I would like to ask again for examples of something common Razor does clearly better, not just saving a few characters here and there. &amp;#x200B;
/u/bloodytemplar [ASP.NET Core MVC](https://docs.microsoft.com/en-us/aspnet/core/tutorials/first-mvc-app) is the guide. I understand bits and pieces, but it honestly feels like a tidal wave of information. Maybe because I barely understood what an API was before starting this, but I have zero knowledge in regards to a lot of the material covered in the guide. I think it's just going to take time, and constantly referencing the material. I might bounce around a bit, and possibly review mentioned Pluralsight course. &amp;#x200B; It could also be due to the time in which I review the material. So don't take it as a slight towards your team or yourself! The information is honestly gold, and it's a great guide. I'm just really new. For instance, don't even know what async is and I've seen that crop up a few times in the code. 
I agree. I really dislike the Ms tutorials that rely on using visual studio to scaffold as the foundation of the tutorial. Teach me the long, tedious way first and then show me how I can avoid it with scaffold *after* I know what problem it solves.
adding `[FromBody]` or `[FromForm]` triggers the same error
Hmmm. Have you tried binding to IFormFileCollection instead?
Right now I'm about to write a .net core mvc project with a client folder I made with create react app. Since it was an MVC I was going to make that project also work as the API for the react app (or static files in production). The problem is I want to take advantage of server side rendering. In .net core you get the aspnet-prerender-module tag helper that needs to go in an index.cshtml file. But I can't figure out how to sync that up with the client/build/index.html file to make it one single build... I'm just thinking now to set up a Node.js app (container) to serve the client app and implement SSR and write a separate container in C# to be the API. Any advice about my situation? 
If I had to comment quickly, I'd say that visual studio, project files and solution files are super annoying. There are things abstracted away. Like adding a file to a folder in a .net project updates all this stuff. Like the .csproj. If you want, download software called beyondcompare, generate a project from one of the templates in a directory, and try it yourself in a different directory and compare them with the software. &amp;#x200B; If you want proper tooling that doesn't rely on a Microsoft template, try to disconnect from them as much as possible and keep the javascript world away from that dependency. If you are interested in SSR, I think a Node server for the front end will be super nice. 
[removed]
What's wrong with using Ruby? You're not the one using it, its developers are. These days, you aren't expected to even prepare a system for the software you deploy, you just run a Docker container for the database and a container for the software itself. What language it's programmed in is irrelevant.
What? The language choice significantly impacts performance and others' ability to contribute.
You should be able to run the commands directly without invoking bash, since in Linux all commands are actually executables (unlike Windows where some commands are internal to cmd.exe and only work when run through cmd.exe). Eg for sed you would specify "sed" for the FileName and the arguments for sed in Arguments.
You should be able to use P/Invoke to reproduce the functionality if you want by directly calling the Windows APIs. Or you can call the binaries on your OS to set the date and time for you. Regardless, on Windows (and Linux? not sure) it's not a big deal because you need to be running elevated to change the time, which you usually won't be. And there's typically no legitimate reason to change the time anyway once it is set properly. You risk confusing programs that time themselves and any logged timestamps and fiel modified values will be set wrong until you set the time back.
More info on why it's so important: https://www.youtube.com/watch?v=-CxX8nvLalE
Lots of libraries have been ported over to .NET Standard and you can even use Framework-only libraries if you don't mind your app only running on Windows. So I would say it is mature at this point. However the bulk of the rest of the "missing" APIs Framework has that Core does not is coming with 3.0 soon. Things like Winforms and WPF. Which will still be Windows-only of course. So depending on what you want to do you may want to wait for that.
true because in vue case it is not exist yet there and you need to install some generators before you create the project [https://github.com/MarkPieszak/aspnetcore-Vue-starter](https://github.com/MarkPieszak/aspnetcore-Vue-starter)
I made this template for **.NET Core 2.2** and **Vue.js** as a multi-page application. [https://github.com/danijelh/aspnetcore-vue-typescript-template](https://github.com/danijelh/aspnetcore-vue-typescript-template) Now imagine that you have to set-up all this thins all over again whenever starting a new project. It's just pointless work.
Maybe cause you said not much seems to be happening with .net core. Anyway, conversations on the net between perfectly normal nice people can spiral out like this sometimes simply because text format loses a lot of the emotional and non-verbal communication. 
Yeah I don't have to prove anything. You are the one fighting so hard to change my opinion. If he wants to charge for it, all power to him.
In the same place, you get 3 months if you have Visual Studio Pro MSDN.
I over-reacted, sorry for that.
If consumers of the dependency will use IMyDependency abstraction instead of concrete implementation MyDependency, you make your code more maintainable. Common scenario would be for example swapping MyDependency implementation with some FakeMyDependency to help testing or developing your code in some environments.
You're mixing up several concepts there. Inheritance describes a relationship between two classes. Classes can *implement* an interface, but they do not inherit from it. If a class implements an interface, it is valid to reference that class either directly or through its interface. The page you linked is a reference for dependency injection, which is a technique in which the concrete implementation of an interface is provided at runtime. This concept is independent of the 'link' between a class and an interface it implements. The link created by dependency injection allows for loose coupling between a service and the consumers of that service. The primary benefit of such a loose coupling is that the service implementation can be configurable and changed on the fly. You might provide a mock implementation for testing or swap implementations based on other runtime decisions.
Thank you for sharing after skimming the content I find it may be more useful than MSFT one [https://github.com/dotnet-architecture/eShopOnContainers](https://github.com/dotnet-architecture/eShopOnContainers)
&gt; https://github.com/danijelh/aspnetcore-vue-typescript-template good job looks more cleaner and orgnaized 
So the line services.AddScoped&lt;IMyDependency, MyDependency&gt;(); is saying "whenever you need a concrete class of IMyDependency, use MyDependency", and so if I decide to later on implement a newer version, called MyDependency2, I simply change this 1 line of code?
Yes, exactly. Or you might have logic that chooses an implementation based on environment or customer or whatever. It‚Äôs just about flexibility.
Hi there, yeah - tbh I was surprised too; I don't think its very well publicised but I found this link as an example: https://www.howtogeek.com/244678/you-dont-need-a-product-key-to-install-and-use-windows-10/
Thanks heaps
Yes, The Morning Dew which Morning Bree generally used to be a subset of.... https://www.alvinashcraft.com/
Just here to make sure, that you actually meant what you've asked... 
I've encountered an issue with wss-connections and certificate-cn checking in 2.1: they checked it case-sensitive in linux-systems. Thats the reason I switched to 2.2. Otherwise I would have stuck with 2.1. LTS
2.2 is the way to go.
Introduced me to Saga. Nice touch. Investigated a bit more and foud NServiceBus, very interesting. Thx for the vids.
Also try the [ASP.NET](https://ASP.NET) Weekly: [https://www.getrevue.co/profile/aspnetweekly](https://www.getrevue.co/profile/aspnetweekly)
If logic is embedded in a class that is difficult to setup and/or has lots of dependencies that must be mocked -- then sometimes the best approach is to break that logic out into a `public static` method (either making it an extension method or in a separate static class or even just within the original class). By making it static, you're forced to think about what inputs do we really need to make the decision. And what should the output be based on those inputs. Which lends itself well to a parameterized test. In the case of your tests, it smells more like you're testing a validator. So you should have some sort of validation class that you can test against (passing in an input and getting back an answer of valid/not-valid).
Thanks, we do things a little bit different :).