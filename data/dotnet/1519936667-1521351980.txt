The microsoft side of the process is usually solid. Most of the issues I have seen are related to 3rd party dependencies, so pretty much every project I have ever tried to migrate short of some simple ones needs some hand holding.
My docker compose differs, the context appears to be putting it inside the project folder and not the base folder (which is probably why it can't find the referenced project) version: '3' services: profile.api: image: profile.api build: context: . dockerfile: Profile.Api/Dockerfile depends_on: - rabbitmq - sql.data sql.data: image: microsoft/mssql-server-linux:2017-latest rabbitmq: image: rabbitmq:3-management-alpine Your Dockerfile is also different as well, not sure if it's a problem but this is mine FROM microsoft/aspnetcore:2.0 AS base WORKDIR /app EXPOSE 80 FROM microsoft/aspnetcore-build:2.0 AS build WORKDIR /src COPY . . WORKDIR /src/Profile.Api RUN dotnet build -c Release -o /app FROM build AS publish RUN dotnet publish -c Release -o /app FROM base AS final WORKDIR /app COPY --from=publish /app . ENTRYPOINT ["dotnet", "Profile.Api.dll"]
&gt; The requester sends the ID over TCP socket to the partner client. A MITM could intercept that ID, request the key from the API, make a second request to the API to establish their own ID/key, send the second ID to the other party and then proxy the connection between the two parties.
+1. Have been using it for similar purposes for 3 years with only the occasional issue. 
I think the Dockerfile may be the issue. Thank you for the insight. I will let you know if it works.
Thanks for sharing your files. Tried changing my Dockerfile to match yours. I still have the same problem. 
no the context is the path of the build, you have to change the path to the Dockerfile as well, for example yours is this: build: context: .\src\Services\Bonus.API\ dockerfile: Dockerfile Try changing it to this: build: context: . dockerfile: src/Services/Bonus.API/Dockerfile
When I run docker-compose outside of VS I get a different error: MSBUILD : error MSB1003: Specify a project or solution file. The current working directory does not contain a project or solution file. So the dockerfile workdir is /app then /src then /src/profile.api in your project. does is look like /src/src/profile.api or just /src/profile.api? my directory is C:\dev\NET\IdentityServer\src\Services\Bonus.API Microsoft has a src\src\project instead of just \src\project. 
My favorite .NET Core feature: no more assembly binding redirects! .NET Framework had this aggravating feature that if you had the following set of dependencies: 1) App depends on library X v1.0.0 2) Library X depends on library Y v1.2.3 3) You install newer library Y v.2.3.4 (because you use it in other contexts too) You would need to manually configure .NET Framework in your app.config to accept v2.3.4 in place of v.1.2.3. This caused no end of hassle and I am happy to see it gone! .NET Core will just accept whatever version you package with your app no questions asked.
Maybe its a combination of both Dockerfile and the docker-compose changes that are needed I know you mentioned the eShopOnContainers and these are their docker files, they are very similar to mine. In truth, I'm just guessing because I don't really use Docker that much and this is my first project using it. https://github.com/dotnet-architecture/eShopOnContainers/blob/dev/src/Services/Ordering/Ordering.API/Dockerfile https://github.com/dotnet-architecture/eShopOnContainers/blob/dev/docker-compose.yml
The general problem here is that it doesn't matter how secure your key exchange is if you don't know if you're exchanging keys with the right party. You will need some kind of shared secret (e.g. a PIN) that's confirmed in a secure way. I'm afraid I don't know enough about this to give any specific advice, other than the old "don't roll your own crypto". Maybe look up "EKE".
What about MySQL, stored expressions?
Line 20 ends with "&gt;". It should end with "/&gt;". Otherwise the parser is looking for an end tag, which it isn't finding. And the subsequent tags don't belong inside a MenuItem 
Thanks. I'll look around some more. It'd be nice if there existed a service like Let's Encrypt, except for end-to-end encryption as opposed to HTTPS.
 public class MyDb : DbContext { public DbSet&lt;Person&gt; People { get; set; } public DbSet&lt;Issue&gt; Issues { get; set; } public DbSet&lt;PersonIssue&gt; PersonIssues { get; set; } public DbSet&lt;TreatmentInstance&gt; TreatmentInstances { get; set; } protected override void OnModelCreating(ModelBuilder mb) { base.OnModelCreating(mb); mb.Entity&lt;Person&gt;().HasMany(x =&gt; x.PersonIssues).WithOne(x =&gt; x.Person).HasForeignKey(x =&gt; x.PersonID).OnDelete(DeleteBehavior.Restrict); mb.Entity&lt;Issue&gt;().HasMany(x =&gt; x.PersonIssues).WithOne(x =&gt; x.Issue).HasForeignKey(x =&gt; x.IssueID).OnDelete(DeleteBehavior.Restrict); mb.Entity&lt;TreatmentInstance&gt;().HasOne(x =&gt; x.PersonIssues).WithMany(x =&gt; x.Treatments).HasForeignKey(x =&gt; x.PersonIssueID).OnDelete(DeleteBehavior.Restrict); } } public enum IssueType { Physical, // disability, illness Psychological, // mental disorder Substance // specific substance abuse } // one row per person public class Person { public int ID { get; set; } public string Name { get; set; } public virtual ICollection&lt;PersonIssue&gt; PersonIssues { get; set; } } // Issue // one row for each specific issue such as mental disorder, specific type of addiction, illness, etc public class Issue { public int ID { get; set; } public string Description { get; set; } // Alcoholism public IssueType IssueType { get; set; } // IssueType.Substance public string SuggestedTreatment { get; set; } // "Go to AA meetings..." public virtual ICollection&lt;PersonIssue&gt; PersonIssues { get; set; } } // Maps a person to an issues. Multiple rows can exist mapping one person to various issues. public class PersonIssue { public int ID { get; set; } // technically we can use a composite key of PersonID + IssueID but I think its easier here to just go ahead and crete an ID public int PersonID { get; set; } public int IssueID { get; set; } public virtual Person Person { get; set; } public virtual Issue Issue { get; set; } public virtual ICollection&lt;TreatmentInstance&gt; Treatments { get; set; } } // Maps a specific person and issue to an INSTANCE of a treatment such as one Dr visit, one perscription refill, one counseling session, etc // You may want to make a Treatment table similar to Issue public class TreatmentInstance { public int ID { get; set; } public int PersonIssueID { get; set; } // public int TreatmentID { get; set; } fk to Treatment table if you decide to make it public DateTime TreatmentDate { get; set; } // 3/1/2018 public string Notes { get; set; } // "Bob said he is feeling better...." public virtual PersonIssue PersonIssues{ get; set; } }
Install the target framework migrator extension into your VS2017 and thank me later.
Microsoft has a site where you can select a start and target framework version to get a list of all known issues.
sorry if this is a really noob question, but where would one apply the use of digit separators? Is it a performance thing where you can be specific about your use of the numbers? Or maybe some kind of bit shifting operations? Is there a real world scenario where using a numeric constant could be made better by using this feature?
It’s purely for readability of the code. Hard to count the zeroes in large numbers. It has no effect on the compiled code whatsoever. 
Don't do it. Code first is a poop show
It kinda is but Rider is pretty good, and VS Code is amazing if you don't mind getting your hands a little dirty.
As others have said, just make a copy of the project and open the old solution file in the new version of visual studio. Problems will be slim to none, mostly involving some random dependencies here and there that you might have good luck finding a nuget package for.
Why do you say that? I've been using it very successfully for several years now. I drop+recreate for my integration tests, use migrations. Its great but you have to invest some time to learn it.
How the hell is that helpful?
Don't use EF Core either, it should have never shipped.
http://www.entityframeworktutorial.net/code-first/configure-one-to-many-relationship-in-code-first.aspx I tend to use option 4 of the data annotation route. 
Been a while since I've done WCF work, but since no one's answered I'll take a shot. To start, I strongly advise self hosting rather than hosting in IIS. Even if you're using SSL, you don't have to use IIS. The reasoning behind this is IIS always seems to get in the way and simply makes hosting and configuration more complicated. Also, I strongly advise you to keep as little in the config file as possible and try to move as much of those config details into the code as possible. The reason? When setting up a service to work with complicated security bindings, these are no longer things that can change, they are requirements for your service to be able to run. Keep the address and the cert details (name, store, etc) there, but not any binding details. &gt;every client would have to authenticate itself with a client certificate and username/password Is there a specific reason why the client needs the certificate? If you're already inside your network, then I'm not sure what it adds, and it will complicate the deployment of your client, and lead to a number of support desk tickets due to issues surrounding the certificate on the client. Unless you've got a really strong reason for this, I'd drop it and just stick to username and password. &gt;create a root certificate for this project Make sure to get a full fledged cert, rather than one you've made yourself. Self signed certs can cause issues. Dev with self signed is fine. &gt;deploy root certificate to every client and one client certificate for every client I'm not sure I follow you there. Why is the root cert for the service going on the client? This should only ever be on the server and not shared at all. Also, does one client certificate mean a unique cert per client? No matter what the answer is for those questions, this seems like it will really complicate deployment and IMHO adds a ton of security that potentially provides little value. If these computers are on your network why do the each individually need their own certs? Here's a [post on Code Project](https://www.codeproject.com/Articles/36705/simple-steps-to-enable-HTTPS-on-WCF-WsHttp-bindi) about creating a self hosted WCF service and configuring it to use SSL. Please DO NOT follow step 7 for anything in production. You want to catch those errors an log them because A) an error means you should probably deny the request, and B) because that's the best place to log the error so you can track it down. Other than that, don't use a self signed cert. You also might find [this post](https://www.codeproject.com/Articles/36396/Difference-between-BasicHttpBinding-and-WsHttpBind) helpful. Basically, you'll want to use WsHttpBinding and for security mode you'll want to use Transport with Credentials or Transport. One final note. A big challenge with these services is the dev setup and production setup. The need to be different, referencing different certs, in order to not be a pain in the ass for devs and to be secure in production. If you're not using config transforms for different builds (debug vs release at the least) then you should read up on doing that.
Sure it can be very simple in a few use cases. Primarily being small, up and starting applications, or some product you deliver to a client for minimal cost. Long-term flexibility, production ready, enterprise code? No. Show me one large company using this technology that is used for their primary revenue source? Microsoft has been pushing this since 2008. I can't name one company I have worked with that did this. I met one solution architect that worked at a start-up that was starting to gain a lot of attention and receive a lot of investment. They scrapped the fuck out of code-first mostly related to performance problems, some alters of the database, required dropping the whole database, he mentioned many more. Some of my concerns could probably be alleviated by talking to someone who knows the ins and outs of everything related to code first, it might be some of a gap in knowledge I'll give you that. But you will never see the performance of using an ORM, let alone a code-first solution for bulk inserts match SQLBulkCopy. The list is lengthy. Let me know if my comments may be dated, as this stuff rapidly changes. That being said, I have my team transitioning to using EF 6 and creating a datalayer for a lot of our applications. In this case we would obviously use database first, but given the chance, all discussions I've ever had when starting new applications has been to go database first, because it isn't much overhead to plan our db ahead of time. Going database first also seems like it would make adding versioning, or using scd's a lot easier later on.
see the response to u/the_other_sam
Thanks!
For my part, and as the author of the blog points, it’s about legibility. When I have blocks of hex constants, I now use underscores to pad the number so the lower bytes are right aligned. As to why this feature wasn’t in the original parsers I don’t know. 
I might be way off base here but wouldn't it be a many to many relationship because one person may take many drugs and many people may take the same drug? If this is the case would a bridging table not work?
Wait, you don’t enjoy “potenitally different build outputs for consecutive builds”?
As I write this comment I have in front of me a very large application that seamlessly targets both sql server and MySQL. It polls a data api and downloads data on multiple threads. I cant describe it to you I can only say it is working, tangible proof that ef works great for many different kinds of apps. It is well known that ORM's in general are designed for CRUD operations. I agree that if speed is your ONLY objective you should not be using an orm. In my case and for most other general business casses the ease of use is well worth the speed tradeoff.
I've used dapper and it is little more than a fancy substitute for sqlconnection. I'm not badmouthing dapper just saying it does not compare to EF. The real power of EF is LINQ i.e. the ability to move your business logic out the persistence layer (database) and into managed code. 
Haha! Thanks for the reply! Will try. 
I don't use dapper either we use service stacks ormlite and/or npoco both of which have a nice tradeoff of simplicity to functionality. 
Wow this blew up, I posted at the office and didn't check until I got home! Thank you everyone for your replies and I will try all the solutions posted. Glad to hear that there might be slim to none problems just by opening the project in VS 2017 and changing the targeted framework. Have a great weekend! 
Right on! Thank you! 
&gt;This is a 'high exposure' system for a government in a third world country and from our experience there could be some incentive to 'break' the system - either from our competitors or from our client it self (to circumvent license policy or to perform some actions in our system that shouldn't be allowed). From this viewpoint we would like to tighten up the system as much as possible. The deployment shouldn't be a problem because we set up all PC-s and the Server at our company and then ship them to the client. I figured there was some sort of reason for that approach. If you've got a process to deal with the deployment, then I think you'll be fine. &gt;&gt;Make sure to get a full fledged cert, rather than one you've made yourself. Self signed certs can cause issues. Dev with self signed is fine. &gt;Shouldn't the self signed certificate work equally good as a full fledged certificate for a closed system like this? As long as all the clients have our self signed root certificate in their trusted root store? Or am I misunderstanding things? They should, but sometimes there are components in WCF that do not like them. A number of errors that I've had are due to self signed certs not being trusted (as they shouldn't be). Also, considering what you've outlined with this system, I think self signed certs are also a potential vulnerability and avenue for getting into the system. Anyone can make a cert that looks like the ones you've made, so if someone realizes that a self signed cert will get them in, then what's to stop them for making their own. Self signed certs are also harder to revoke if you ever run into a situation where you need to do that. &gt;With the root certificate I mean one without the private key of course. And as far as I understand, in the case of self signed certificate on the server for TLS connection, the clients should have the appropriate root in their trusted root store. If not, then we would have to suppress HTTPS errors which is a big no-no, as you also stated in your next paragraph. This is circumvented by having a full blown cert rather than a self signed one. &gt;Regarding the unique certificate per client - we were thinking to use this as a simple licensing model. When we prepare PC-s for the client, we generate a unique certificate for each PC and save its thumbprint in our database. When the client makes a request to our server, he should authenticate itself with his client certificate and we would check in the database if the thumbprint is correct and if it is still active. And it is one additional layer in our security model (besides VPN, TLS and username/password). Frankly this is the piece that I just don't know if you can pull off. You can have a cert on the server and one at the client, but I don't know if you can have a single binding accept multiple unique client certs. I assume if you could, it would have to be done by wildcard or something, as I'm not sure how you'd have the service recognize each individual cert and deny the request if the cert wasn't one you recognize. I get that you'd like to be able to identify and authenticate that each request is coming from an actual machine you've deployed. Certs can be moved around too, so an individual machine could've been compromised, a cert could've been moved, and now that cert is being used in a way different than what was intended (across multiple machines or something else) I'd take a different approach and have 3 components for client authenticatation/authorization. The first would be to have a single client cert for all machines. I think this will make the service easier to configure and manage. The second is obviously username and password. You can do basic credentials, but then you'd have to handle the user management yourself. I'd try to tie those to your AD if you can, and WCF supports that. The third component would be to have the client present some machine details to the service and check those details. I'd pull something like the processor ID, hard drive ID, or a mac address. While all three of these can be compromised, you're basically pulling parts out of the computer at that point. During the process of setting up the clients you can have a tool that registers whichever ID or IDs (you should probably use more than one) you're referencing with the server for later. When the client authenticates, they would need to present those IDs and if they haven't been previous registered, then you can deny the request. Slow Cheetah was what I used previously to do the config transforms, so glad you're already using it.
Why, in such a modern language and platform, does the package manager not allow sourcing from a git repository?
[tl;dr](https://docs.microsoft.com/en-us/aspnet/core/tutorials/web-api-help-pages-using-swagger?tabs=visual-studio)
I would take an orm over ado any day of the week these days. Code first is unnecessary abstraction, that's my argument. Let's say now your customer wants relationship changes, or they want their product page to be zippier, or they want everything displayed on one page. How are you handling index fragmentation? You mentioned big application? I don't care about application size. I care about your 3 V's of data. What is your plan for handling large set based logic? What is your data warehouse strategy? And by far the biggest, now your customer wants versioning/scds. What is your plan there?
I don't get it, why would you want that? Is it a front end thing? Some packages do have source code in them. If I want stuff from git, I use git not a package manager.
&gt; sweggar my sides Also, why would you use this poorly written guide when the official docs do a better job? I get people want to blog, but at least make it something valuable not a engrish rehash of something else.
Lol @ your project name.
1. Bootcamp a Windows partition onto your Macbook 2. Install full blown Visual Studio (hopefully with some kind of student account/license) 3. Register a visualstudio.com account and sign into that on the Macbook 4. Repeat steps 1-3 on Windows Desktop but use the same account so your settings are synced across the two computers 5. Either use Dropbox to keep your project files in sync across the two (easy/basic method), or learn how to use a version control platform like TFS or github and sync your projects across those. *If you go with the latter method I would highly recommend TFS as its free and integrated really well into VS (and you'll have a TFS account by making the VS.com account)*
Yup, I have a license from my University! The only problem is that I don't have a lot of disk space on my Macbook, so I can't really do a Bootcamp partition :/ Do you think that Visual Studio for Mac is good enough, or is it better to do everything on a Windows machine?
IIRC you are restricted to the cross-platform parts of ASP.NET like ASP.NET Core and Xamarin. While ASP.NET Core is something you will want to start out learning for web development, you are missing out on everything in .NET that existed prior to Core, like WinForms, WPF, .NET Framework 4.7 and below, legacy ASP.NET, etc. If you're okay with that, then forge ahead. I can't speak much for the actual mac version of the IDE. Looking at screenshots its quite a bit different, so I have no idea if it supports all the same plugins and useful stuff everyone has come to know, love, and support over the years.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/csharp] [I wrote a relational LINQ provider for .NET Standard 1.4+ that supports a ton of stuff including GroupBy, TakeWhile, Zip, TPH\/TPT\/TPC queries, etc.](https://www.reddit.com/r/csharp/comments/81g5hv/i_wrote_a_relational_linq_provider_for_net/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
Notepad. Basic, simple, does the job.
(I honestly once took over a role from someone who used Notepad as his editor.)
Especially as .Net Core moves forward to target OSS, why _wouldn't_ you want that? Barrier to entry is a _huge_ hurdle to contributions to OSS software. Releasing an OSS project as source to the package manager means that anybody who uses the package has the source (and build instructions via msbuild) available. Find a bug? Fix it in your project, push to remote, and submit a PR. Want a new feature? Same thing. If Microsoft is trying to push .Net into the world of open source, I think this is a must. I don't want to fiddle around with checking out a remote project separately, figuring out how build it and linking it into my project separately while I wait for the remote PR to be accepted or not. Furthermore, building from source gives you a verifiable product. X source resulted in Y assembly on Z machine. You don't have to trust blind assemblies pulled from a remote source. Really, the reasons are countless.
Different strokes ;) I don't want any of that in a package manager, I don't want to build the packages, I want compiled assemblies. If I was obliged to compile an OSS project, I would take the output and put in our private nuget feed.
I mean, at the end of the day you can have both. At the base of it, git is about tracking _versions_. There's no reason that assemblies can't be stored alongside source in git, and assemblies distributed to those who want them, and source to those that want source.
Please avoid making everything `public` by default, **especially** when writing a library. `ValueTupleHelper` should not be public. Like this we some day end up where we have 20 times the same method in the public API because every library added it as a public method. Also: Your library is completely undocumented.
FWIW GroupBy should be in the next EF Core, it is in 2.1 preview
I was just curious about why you would want that. You can indeed use source control to hold assemblies. Years ago, I was using a CI server and Visual Source Safe to implement a publish subscribe model so that projects could subscribe to "latest" and their source control would be updated after the build of whatever they subscribed to.
I never got to the point where I would want to pack it up and distribute it so I never went back to restrict the visibility of anything or leave 'proper' documentation. I did leave comments in certain tricky places that I felt especially needed explaining, though it was more for myself than anything. I almost made it to that point. Almost.
Being nosy, what's going on in Add()? :)
Yeah, I'm guessing that I'll be using something in the Visual Studio family instead of Rider, so I'll go with VS Code most probably. I already have the full VS but I wanna see how Code is!
Have to do to the AMA link above --^ to ask the questions
So you think that it's better to learn the basics of C# on Windows? Do you know what kind of stuff I'll miss in a Mac?
&gt; If I use dynamic linking to use the OSS stuff via a dll, I have far fewer things to consider when using it. If I compile the OSS code within my solution But again, you can still compile external dependencies as as DLLs and link dynamically, so I don't feel that is an issue against the notion of git repositories as Nuget packages. In fact, I would expect this to be the default, where the override in your `.csproj` would be to compile the target into the project assembly. &lt;ItemGroup&gt; &lt;PackageReference Include="SomeCompany.Utility.UsefulStuff" Version="3.6.0" Prefer="Source" Compile="Linked" /&gt; &lt;/ItemGroup&gt; This also isn't a new problem. Licensing issues have been prevalent for years (decades?). You always have to read and understand the license for any library you use, but luckily today license are vastly simplified and understood.
Gotcha, thanks :)
Thank you! 
I'm going to disagree, leave things public but keep your top level namespace clean and that only people trying to mess with internals should ever touch anything deeper down. Also make almost everything virtual. 
&gt; an issue against the notion I'm not saying it couldn't be a feature, just why I personally never saw that sort of need, you can go propose it to whoever manages nuget. Package ID Prefix Reservation and Package Signing are what I'd like to see more of Its not me downvoting your replies;Someone downvoted the "Wait, you don’t enjoy " reply so it might be a dowwnvoter but it might be someone who just doesn't like your tone. 
Well, I wouldn't go so far as to say 'useless'. I really like the change tracker in EF Core and only occasionally need to add a call to `.AsNoTracking()` for tuning. I think the problem has been a matter of approach more than anything. 'Legacy' EF had its whole own AST for queries; EF Core uses Relinq which is its own AST but it's kind of a mish-mash in that you still use the `Expression`/`ExpressionVisitor` paradigm intermeshed with it. I opted for a complete embrace of the `Expression`/`ExpressionVisitor` paradigm with the mindset that *all* other features -- model metadata, change tracking, `Include()`, whatever -- should be modular to the core query provider rather than the other way around. Then the `DbContext` would be the mediator that orchestrates gluing together the pieces: take the data model, form `Expression`s that materialize them from `ColumnExpression`s and whatnot, create a `SelectExpression`, stick it into an `IQueryable`, and let the core query provider work entirely in its own language from that point on. It doesn't need to know a damn thing about any of the other components.
Re 'useless' : I am writing from the perspective of a guy who writes web APIs. My dbcontext lives inside a very small using block than its gone for good. For me, tracking really is an unnecessary feature because my context lives for like three lines of code. I realize there are others who keep the dbcontext in memory. For them tracking is much more useful. EF really needs two APIs: One for those who use it statelessly and one for those who use it to maintain state. For the former group, the current "AsNoTracking" feature is a switch that contradicts a cornerstone on which the API is built. Those who use EF statelessly should not need to know about tracking or attaching or detaching. And every API should function as if those concepts do not exist. 
&gt; leave things public That's going to lead either to breaking people when you change some "implementation detail" or to being unable to change it in fear of breaking them. If you're writing a public library, you should think a lot about what's in your API. "Just make everything public" is not good enough. &gt; Also make almost everything virtual. Please don't. Customizing something by inheriting from a base class and overriding its methods has its place, but you shouldn't just blindly sprinkle `virtual` everywhere and call that "extensibility". Especially since a lot of the time, composition is better than inheritance.
I understand that submitting PRs to big projects like EF Core is a lot of work, but I think it's the best way to make sure your code will have impact. There's not much chance anyone will use your library, while thousands will appreciate it if you improve EF Core. So, depending on your goals, you might consider doing that. Also, if you're frustrated with how the repo owners do things, you could try helping with improving that. For example, I believe gitter works well for some communities, maybe you could suggest that one should be created for EF Core? That could help with making communication more real-time.
That's an incredibly heavy price to pay to be able to fix a bug. And even then, it's not certain that you could fix the bug this way, especially since it requires you to be in control of creating instances of the problematic class. And the price I mentioned includes performance: performance matters for many libraries and making everything `virtual` can hurt it a lot.
FFS you don't have performance concerns over virtual. GTFO 
&gt; I realize there are others who keep the dbcontext in memory. For them tracking is much more useful. Wat? I don't think it's changed in EF Core, but in EF4/5/6 DbContext is supposed to be short lived; the object tracking will bloat quickly and depending on how the app is made you can run into stale data issues.
It uses caching for the the compiled delegates, and the generated code is pretty much reader.Next() with some GetValue in a new expression with a member init block. I haven’t profiled it but it’s pretty basic. As for your question about the dynamic Dictionary thing: I would say it’s possible of course, but I don’t think it would be worth the trouble as opposed to using another library geared specifically for generating piecemeal queries from dynamic tables and columns. 
Like I said, no disrespect at all to the team... I respect their process, it’s just that what I wanted to accomplish was too far-reaching and time-consuming *within the boundaries of that process* for me to keep up *as a non-Microsoft employee*. I mean, I made this project last year in two or three months’ worth of free time when it took me longer than that to not only work within the boundaries of Relinq but also to try to get things broken down enough for acceptance — and then there was still a long road ahead. The team was very cool the whole time and I really enjoyed it! I just needed to move on and this project was my way of having some kind of closure, I guess.
From all of our views you're missing everything without source code
Oh! You're right. I used DevExpress to add 3 tabs, a datagrid on 1, a pivotgrid on another, and now this chart. Here's the Form1.VB code I've got: Imports Microsoft.VisualBasic Imports System Imports System.Data Imports System.Windows.Forms Imports DevExpress.XtraCharts Public Class Form1 Public Property DisableCustomQueryValidation As Boolean ' This lets me run queries that use temp tables. Sub New() InitializeComponent() ' This line of code is generated by Data Source Configuration Wizard ' Fill a SqlDataSource SqlDataSource1.DisableCustomQueryValidation = True SqlDataSource1.Fill() End Sub Private Sub ExportToExcelToolStripMenuItem_Click(sender As Object, e As EventArgs) Handles ExportToExcelToolStripMenuItem.Click MsgBox("In development.") End Sub Private Sub ExitToolStripMenuItem_Click(sender As Object, e As EventArgs) Handles ExitToolStripMenuItem.Click End End Sub Private Sub Form1_Load(sender As Object, e As EventArgs) Handles MyBase.Load PivotGridControl1.Refresh() 'Sample code to change everything. Rework to 1 series? 'OTDChart2.SeriesTemplate.ChangeView(ViewType.Line) Dim chart As ChartControl chart = Me.OTDChart2 AddHandler chart.BoundDataChanged, AddressOf chart_BoundDataChanged End Sub Private Sub chart_BoundDataChanged(ByVal sender As Object, ByVal e As EventArgs) Dim chart As ChartControl = CType(sender, ChartControl) Dim OTD As Series = Me.OTDChart2.GetSeriesByName("Series") If OTD IsNot Nothing Then OTD.ChangeView(ViewType.Line) End If End Sub End Class
just this mornign i was wondering what it would take to write the LAG/LEAD operators. this reference might be handy!
I think it's still meant to be short lived, but if you're manipulating state the intended workflow is - Load from db - Make your changes - Save to db And that requires tracking. If it was intended to be long loved it wouldn't shit the bed if you accidentally shared it across threads.
&gt;&gt; If it was intended to be long lived.. No - threading is an entirely different issue unrelated to this discussion. Loads of objects in the .net framework are not thread safe and that has nothing to do with their intended lifetime. &gt;&gt; I think it's still meant to be short lived What specific feature or characteristic of design makes you say this? Workflow for short lived context is: * using(.... load from db...) * Make your changes * using(... save to db...) In above workflow two different instances of the context are created, each independent of the other. Tracking is not required and makes no sense for this pattern.
So what would you consider one long using block where you load the objects, make your changes, and save the objects? Because I use that pattern often. If I have to do something complicated I pass the context along as a parameter into a helper method, but never actually store the thing. It's lifetime is less than a single controller method... but still long-enough to load-update-save an object.
Who?
Are you sure you .NET?
I don't know if there is a legal definition of "short lived" (comments welcome) but I imagine one of the characteristics of the PATTERN will have something to do with "per-request" wherein the entities are retrieved in one instance of the context and modifications saved back using a DIFFERENT instance. In this pattern stateful concepts (like tracking and attaching) make little sense because nothing is persisted across instances. 
Like what? .NET Core 2 has most of what any web dev needs. 
No need for a “full blown license.” If you insist on Windows, get Visual Studio Community at http://VisualStudio.com/free. It is literally Pro Version. Great for students. 
I guess that depends if you're using the raw entity POCOs as your DTOs. If not, there's enough work being done locally in the "post" action that it helps. Either way, I've worked on projects with truly long-lived entity framework context. It's a *disaster*. Every time validation fails, for example, you have to purge your invalid objects before you can continue to use the context because it feels like it was not really meant to live much longer than the first SaveChanges.
That link is awesome, I did my first web app! I'm just wondering, is it better for me to learn front-end web dev if I want to do web dev with ASP.NET? I don't have any experience with web dev so I'm wondering :P
VSCode is awesome, thanks for you work :D
I can't say anything about your code as I would have to see it to judge it. If the method doesn't depend on an instance of the class it belongs to then it should be marked as static.
So before I answer, can you elaborate your development experience? Have you taken any programming classes?
No, I read books and keep MSDN very close while making good use of the API. I used to compete in .NET programming and placed first once for VB and C#. I’m not a pro, but I’m pretty proficient in C#. VB is a whole different story though.
But in my current project it wasn’t giving any issues to development. The console system is just a layer in the project and I thought it made things simpler. This is very fascinating yet hard to learn because everybody has different feelings instead of concrete examples or explanations.
anyone else hate using linq to create sql? I prefer to just write sql. Neat stuff though
Yes it's a little simpler to call a static method. But think about testing some other part of the program that has a call to YourStaticClass.Run() in it. How are you going to test that piece of code and check that it's calling the Run method with the right parameters? You can't, because you can't inject a mock implementation of Run into that other piece of code, and what's worse, during unit testing you can't prevent triggering parts of the system that you're not interested in during the unit test, at least not without jumping through some strange hoops. Judging from the reaction of your colleagues, the thought this trade-off between simplicity on the one hand and rigidity on the other was a bad one. Although it would have been better if they had focused on the code instead of you, the programmer.
Don't do this -- it's slower than sin. Make a context and pass it around, one for each thread.
Virtual methods take a slight performance hit, best to only make things virtual where you intend for an override to be added later. Further reading: v-tables
Dude, encapsulation makes debugging easier, not harder. Do you even code?
Absolutely. If you’re using an IoC framework (Ninject, etc) which you can (and maybe should) on even the smallest of projects, static classes / methods can always be described by instance classes defined in a singleton scope. 
Typical Microsoft to call making things static an optimization...
Makes sense to me what you did. I would use a static class for like a utility class. 
&gt; That means in turn that it will be hard to do unit testing, especially when the static class changes state. No it doesn't. Static fields make unit testing hard, not static functions. No one looked at `Math.Max` and said "oh my god, I don't know how to unit test this". &gt; A thing being static raises a red flag in experienced programmers; they know that more often than not you'll come to regret it. Ha! it's easy to make a static function into a non-static method.
Think of development like mechanical engineering. A mechanical engineer may key something so that it can never be put in the wrong way. They may purposefully add a failure point in a drive shaft so that if a blade gets jammed it doesn't destroy the gears turning the shaft. We do this in software engineering. We limit the code to run in certain manners so we or novice or developer can't break it. By protecting a property or method you prevent someone from setting a variable directly rather than using the appropriate interface designed in the program. By not declaring a class public you prevent one assembly referencing another and creating an odd dependency and creating a project that can't be built. Now, mechanical engineers do what they do but a novice will call them out. "Why DOESN'T this fit?" not realizing it's keyed for the place. "Why did they put this iron pin here it's far too weak to hold this together." They don't realize that it's a shear pin that can withstand far less force than the gear teeth and it's a mechanical fuse. They stupidly replace it with a steel pin and next time disaster happens it's a $2000 fix rather than a $10 fix. Your static main is your entry point. That's expected but a static method off a static class may be just lazy in someone's eyes. I would have to see it. Most novice programmers mess up their first programs here. We've all done it. If it's not hurting anything it's not a big deal. If it could potentially cause performance issues it could be a big deal. If you know it's not then you are the engineer and they are the novice. Lastly, people are petty. If I spell "your" when I mean "you're" people will correct you because they are petty. If you use pascal case as opposed to camelcase people will give you shit. If some is asking for a peer review of their code I'll give them my opinion. If I ask for spelling errors in my comment I'll ask for it. Ya know what... let's just go with people are petty. TLDR 
I don't know, there are many popular development practices in which this would be a bad advice. (Dependency injection to name one) Of course in small-ish programs with no need for long term maintenance or much refactoring, it is often advantageous not to dwell on such practices to speed up the development significantly.
I have used static for the following: * Private methods that don't require this (internal utility functions) * class initialization (Class.Create(TypeEnum type) for instance) * Properties that affect all instances of a class (though usually I use a const) * I'll sometimes create a static class of utility methods that I don't want to associate with a particular class I agree that context is everything... Static is a tool that may or may not be useful in a given scenario. Survey the MSDN for all the cases Microsoft thought static was a good idea for.
Static functions themselves can be tested, that's true. It's when static functions call static functions (call static functions, etc.) that it becomes more difficult to test other components in isolation. The problem arises not when testing the methods themselves, but when testing higher-level components that _use_ those methods. It's generally harder to mock away a piece of the system in a localized manner if it's static or buried in a nest of static calls. You end up having to mock much more of the system for the test. That's the reason many people in this thread are recommending IOC for what would normally be static. It not only makes it easier to test, but it improves the code quality. When to use static: - For short "stitching" code, like fluent APIs - For short logic that doesn't ever need to be mocked or that has only one logical implementation (e.g. Math.Abs) My rules for when to avoid static: - Method contains non-trivial algorithm - Method creates non-trivial objects - Method makes non-trivial decision about what to call - Method uses a ServiceLocator - Method is _passed_ a ServiceLocator - If the logic would make it difficult for a caller to replicate and modify without copy/pasting a lot of code. I.e. if you want to use the logic, but you just need to change one line somewhere deep in the knot of code ... if the code was written as smaller components in an graph of objects rather than static code, you'd be able to replace the exact component you want. If everything's static (or parts are static), this is more difficult, if not impossible. - [Extension Methods](https://github.com/mvonballmo/CSharpHandbook/blob/master/3_usage.md#extension-methods) - [Static Methods](https://github.com/mvonballmo/CSharpHandbook/blob/master/3_usage.md#static-classes)
Thank you! 
If the function is static you would have to inject the objects into the function anyways, so it’s as testable as loading all the crap in the controller. If it’s a static method that access static properties looks worse, but it could be mocked for testing. I get that most people are against anything static, but usually is unfounded. The code ends up much simpler, equally testable or even easier to test I would say. And also usually with better performance. I had a ton of discussions everywhere I work about this. People usually don’t get it, thats why I recommend everyone to learn F#...
I mark functions as static when they don't use (and/or change) any of current class instance properties or functions. If the class itself doesn't have any instance properties, fields or function it is also marked as static
A static method should be pure ideally. For one input, always produce the same output. No need to mock anything. But of course, if you need a logger, which is the typical. In that case you can pass it as a parameter. Is cumbersome but works. I.e: public static int Sum(int x, int y, ILogger logger); That can be mocked or not without problems. But as I said, ideally you would make static methods that are pure. Parsing, mappings, mathematical operations, etc. Which funnily enough, **those are actually the kind of functions that really need to be unit tested. ** My theory is that as soon as you need mocks something is not quite right to be unit tested. (Not always of course)
I usually constrain this simply to if the thing is doing something stateful, it should not be static. I disagree about triviality though: if the algorithm is nontrivial, that doesn't mean it shouldn't be static in my opinion. Sorting methods can all be static, and if I need to support replaceable behavior, I (the consumer) can write an interface adapter. 
Always use the static keyword on a method that does not access any class fields or properties. This indicates that it merely transforms input parameters into outputs. If that method is for use by the class itself only, remember to mark it as private (or possibly protected if it is used by derived internal classes) - this should be most of the time. If you mark a static method public (or even internal), consider what you are doing. You are stating that this method is available for all comers to perform that method. This is generally a very bad idea, as you may want to configure the details of how the method is performed later, requiring the method to be part of a non-static class. There are some reasonable exceptions (factories for example), but you should probably ditch these and use dependency injection instead. Another reason to use static methods is in extension methods. In this case, both the method AND the class should be marked static. For example: internal static string ToPascalCase(this string inputText) {...} ...this would have to be in a static class. In my opinion, avoid static fields and properties like the plague. I have suffered nothing but misery attempting to use these. With multiple object instances accessing them, they never do what you think they do. You've written a value and another thread immediately overwrites it? Debugging hell. 
Hello, Could you give an example of the structure that you have in your static class ? and how do you use it? It may be the way that you are using this piece of code that the static does not fit well. Thanks
I see your reasoning, but I rarely "inject" objects into methods, most of the time I use ninject to initialize majority of my objects - thus injecting into constructors. (Almost) all of the dependencies implement interfaces. Therefore it's very easy to refactor and mock for tests. Using static functions and keeping track of dependencies in the code seems "flimsy" in this regard, but that's no doubt because I use this different style of programming. But I definitely see that it could lead to functional approach. And I definitely accept that there may be a nice way to address my criticisms, but if not taken all the way (near F#), I don't think it's worth it.
For class initialization lately what I have been doing in a project is that I have a private constructor and a public static Create method that returns a Result&lt;T&gt;, that way you can’t even create an object with the wrong parameters and also not throw an exception. I.e: var carResult = Car.Create(1, 2, 3); if (carResult.IsOk) Var var = carResult.Result; Else // handle the error.
For me IOC means that the code is a nightmare to refactor or reuse. Specially refactor. It’s funny how something being loose in theory in reality holds you so tight when wanting to change the code.
Funny, I have exactly the opposite experience. May I ask, what projects do you work on? ( Web, WPF, services, data processing... )
One method calling another with deep nesting doesn’t sound like proper unit testing to me...
It may be the nature of our different projects. I haven't touched web development in the last 7 years. I work mainly on lower levels of video processing applications and services, or backends to some of our management applications. So - many long-running actions, with emphasis on code reusability. Regarding the self-ass-kicking, we avoid service locator approach, thus we use ninject as a nice initializer. I don't even remember when was the last time I encountered an error caused by invalid bindings. (And it is very easy to test for this kind of error, at least as long as you keep your bindings static.)
Not really. Sure you can't DI a static class, but if it's actually stateless you shouldn't really need to. If you're running into a case where you're mocking a static class you're probably in bad architectural territory. Sure, don't stick something that crosses layer boundaries in a static class, but static classes and functions are much faster. 
How do you write unit and integration tests against your static code? You don't, because you can't, at least not without resorting to some horrible tech like ms fakes. Besides testing issues, statics are also frowned upon because they are not OOP. It can't be OOP without an object. Static methods are strictly procedural. Statics become useful when they are complimented by other features in the language, like extension methods. This way the enhance the OOP features instead of break them. 
&gt; Microsoft thought static was a good idea for. Example code should show the relevant case in the simplest way, not best practices.
So static classes should be avoided as much as possible but static methods inside of a static class is fine as long as it’s purpose is to run a single task or calculate a single value?
Static methods inside classes have the same problems as fully static classes. The problem happens when you use the static method inside a non-static method, e.g. private static Context GetDbContext() { ... } public void DoStuff() { var context = GetDbContext(); ... } You will have a hard time testing DoStuff() in isolation without a database. There are a lot of ways you can optimize memory usage and performance without resorting to statics. It's better to change your design towards that (e.g. use the new Span&lt;&gt;, use structs and stackalloc, etc) but even then I wouldn't worry too much. The .net runtime ,ryu jit and framework are all highly optimized for performance first, memory usage second. A typical .net application will use 4x the memory of the equivalent native application, but achieve 95% performance. Don't be afraid to use new(). 
They are most useful when used for their actual purpose - to control variable lifetime. You may need a singleton/lock type variable across all instances of a class. You would make that variable static. Now what if you need to do some operations with that static variable? Those methods would need to be static too, and that's why we need static methods, even classes. To deal with static variables. We need static variables to have different ways to control variable lifetime besides new(). 
I think you should clarify your comment. I took it as don’t use singletons when static will do, but if you mean don’t use IOC frameworks then it changes the whole meaning/intent. 
I think of static classes as stand-alone "utility" classes - like a Swiss army knife that has a number of "blades" (i.e., methods) that perform a fixed function, always doing the same thing every time.
This is awesome! A question, would this be something ready for use in production or should one wait until final release? 
It is absolutely ok to write a static method that does some crunching on the parameters you give it and doesn't need to refer to any instance fields/properties in the rest of the class. The class you decide to put that method in is another question. You should find somewhere sensible for it to live. You might even decide to create a class to group a number of static methods that all relate to each other.
Anytime your class has some object that needs to be accessed by all instances but can't be const, it should be static. However, I'm really struggling to remember the last time I used a static field that wasn't also readonly. For example, almost every class I write (other than POCOs) looks like this: public class Foo { private static readonly ILogger Log = LogManager.GetCurrentClassLogger(); // ... } For methods, anything that's pure (doesn't access the object's state) is usually static. Typically these are things like factory methods, or private helper methods. Classes are marked static when everything they contain is static or const.
Read wiki's design patterns, and SOLID design principles. Also read .net' Framework Design Standards book. The problem you have is you just understand the basics, but need to understand more complex items.
I guess clicking the IAma link is too much to ask? Or Google? Miguel de Icaza has been a prominent figure in the .Net ecosystem for over a decade.
I guess asking reddit is too much, too. 
It is when the answer you seek is one click away.
I agree, adding dependencies to highly referenced classes using DI is so satisfying. Now whenever I see a static I need to refactor to add to, I basically start by converting to non-static abd adding DI first, then add the dependencies. Yesterday I refactored a static class that required a context object as a parameter in each and every method on it by moving the context to the constructor, then changed all references to it's constructor to be injected on the consuming classes constructor and removed the context from each of the method calls. All before doing any of the necessary changes. Once that was done adding a versioning service to the method calls required 0 signature changes.
Your not a bad programmer. You are an an amazing one. Bad programmers do not seek advice, they hide their ignorance, they stick to their bad habits, they do not learn, they do not post paragraphs to reddit asking how to improve and when they look around they see only their brilliant clever code. Amazing programmers often feel stupid and insecure and doubt themselves and when they look around they see the things they want to do better and mistakes and their insufficient barely good enough code. Keep this shit up long enough and you'll find yourself in some amazing place. Take care :)
It's not pure functional that's important, it's avoiding interaction with global state. Mockable parameters are good too. That's why your logger example is okay - it's only interacting with a mockable ilogger and its other parameter.
I'm not talking about sample code, I'm talking about .Net API.
oh god that name..
That's cuz castle is a poorly documented and legacy crap by today's standards. Go to is autofac which makes ioc a joy
I use Visual Studio with ReSharper and definitely recommend both. Now that I've been using ReSharper for awhile I couldn't imagine coding without it. Lots of tools that make development easier and faster. JetBrains makes some good stuff and it's probably worth checking out Rider, I haven't tried it yet so can't say whether or not it's better than VS.
I wouldn't say WPF is dead, especially for Windows development where you may want to target &lt; W10. Heck, there are even still new WinForms applications being made (I know.. :( ). Personally, I would go for WPF. I think it's amazing, allows total control from top to bottom, and every so often I discover a new way of doing things that makes me appreciate it so much more. My only gripe is the documentation, you might spend a few days learning how to do X, you implement it, and then a month or two later while working on a separate component you learn something new and the big "oooooh so that's what we should have done" moment comes (but maybe that's my fault for not spending enough time thoroughly learning the technology before implementation).
IMO, keep the package manager managing packages, and the source code manager managing source code. I guess I just don't see it as a big deal to do a git clone, submit a PR, and in the meantime publish a package to a nuget repo (which can be a network-shared folder if you don't want to set up a server). I've done it quite a few times at my previous job to fix various bugs and integration issues.
Having created applications in both. I can say I enjoyed using UWP a great deal more. This is of course subjective, WPF is still a good choice. For most purposes it was faster and easier to develop in UWP, especially on the front end of the application with Blend. One issue I disliked of UWP was lack of documentation / community around the platform when I first dove in. This was about 1.5 years ago. It has progressed a bit but nothing like a platform like WPF being around for so long would have. There were some snags with libraries not available to UWP (some security measure in a tcp connection werent working properly) but that was a bit ago, may have seen an update. Anything you really need though for the most part should now be available. Worse comes to worse, you can always use a service, connect locally, to do any wpf/net&lt;=4.5 features that are needed as I did with some aspects of the application. Best of luck in your decision. I wouldnt over think it though. Both are very capable of handling the majority of applications. My advice though is UWP. It may have some drawbacks but also has a lot going for it as well. Since WPF will phase for the new kid on the block eventually, I tend to choose the newer development platform to learn, more fun. 
Steep is an overstatement. It’s still just a less optimized method call. Don’t make your inner loops virtual, but don’t worry about the performance of making things virtual where it makes sense. Do worry about the bug impact of making it virtual. Issues like yoyoing, unexpected side effects, called from constructor, etc.
Nonsense. Nonsense. This project isn't Rosyln. It makes SQL text. Text generation is so many orders of magnitude above virtual. You're comparing a flake of dust to a boulder. 
Those things only happen from people abusing virtual. If they abuse it and it blows up in their face. That's their own problem. 
If there is even a slight chance that one of your users are not on Windows 10, you HAVE to use WPF as UWP only supports 10. Hope this helps.
UWP is the direction Microsoft is going in so new projects should target that platform. As others have said, if you need to target older versions of windows then you will have to use WPF
I am sorry to hear that you haven't had a good experience using Cake. I would be happy to spend some time going through it with you if you wanted to? Also, if you could raise some of the concerns that you have as issues on the GitHub repository, we would love to address them.
I've seen that too. It looks so good on paper, but fast forward five tears and it's a nightmare.
If you don't know how to write a test against a static function, then you don't know how to write tests. Period. Stop what you're doing and get some help. Seriously, if you think you need takes to test Math.Max you have been seriously misled.
He's confusing static methods with global variables. Global variables are almost always a bad idea, especially when mutable, but static functions that don't use globals are fine.
Making things public make it hard for people to figure out what they are supposed to use. As for virtual, you can always do that later when you actually have time to design the code for inheritance. See .NET's Collection&lt;T&gt; class and how it carefully supports subclasses.
I think it's a really bad idea, but lots of people keep the context for the life of the request, going so far as to use DI frameworks designed for this purpose.
Connections are pooled at the System.Data level. EF shouldn't need to be handling any other resource.
Same here, but it can be useful for quick and dirty code.
Is poorly documented and in this company they did custom configurations to make even worse. I tried autofac a few years ago and I have to say it was WAY better.
&gt; fast forward five tears awesome typo.
One can make an argument that a properly implemented di project, replacing container should not be a big refactoring job
Instantiating a context and destroying it is slower than reusing it due to the need for repeated heap allocation and deallocation. It's really easy to be inefficient with memory in C# because of all the abstractions. Memory allocation and garbage collection are expensive operations so you should minimise the need.
Yes, but you have to offset that by how slow the EF context gets as it accumulates crud. Even worse with WebAPI, the caching effect can cause you to pick up child objects that you didn't want to send to the client. It took me a long time to understand why EF users were so enamored with AutoMapper and DTOs (which they erroneously call "view-models"). Now I know.
Put your dbcontext in a using() block and perform one unit of work. You should be OK.
&gt;Instantiating a context and destroying it is slower than reusing it There is a lot of room for debate around that. I don't have any hard numbers so I wont dispute it. Its fair to say however that testing for a given implementation is worthwhile. Supposedly [Context pooling]( https://channel9.msdn.com/Series/aspnetmonsters/ASPNET-Monsters-109-DbContext-Pooling-in-Entity-Framework-Core-20) will address this issue. This is another feature that confuses the heck out of me because it implies the context is designed to be used as a short lived object. Yet the EF API is clearly designed as if the context is long lived. I think it would be a good idea to create a new context called something like StatelessDbContext or ShortLivedDbContext that has an API that truly supports stateless operations with semantics that make sense. Ya think?
Extension methods. Or when its all you need.
C#, Linq2DB or Dapper
&gt; Also keep in mind a LINQ query returns an IQueryable, not an actual query - it's an IEnumerable which is guaranteed to be LINQ queryable. You may want to convert your qCustomerID to a List before doing any more work with it. You don't need to convert to list because FirstOrDefault(). 
ToList is not needed, FirstOrDefault() will materialize the query. 
I do a lot of what I do is WPF client development. On the positive side, the lack of sandbox is powerful. The access to graphics hardware and shaders is powerful. It is very mature, but finding libraries to do the difficult stuff can be a challenge, as there isn't much new interest out there in WPF. I use it for dedicated purposes like you, mostly for marketing event software that is heavy on visuals and embedded UI for tge public to interact with. If you have questions, feel free to PM.
&gt; But if the query can return a NULL result If CustomerID property is int and not Nullable, it will return 0 (zero).
I use it with static classes with only static methods. 
when it contains no state, extension methods, perfect example.
By the same retarded logic System.Collections.Generic is dead. That hardly ever needs to change.
&gt;&gt;&gt;&gt; Don't do this -- it's slower than sin in core because there isn't the hidden resource pooling behavior under the covers.. Make a context and pass it around, one for each thread. Dear god. I'm somehow not surprised they managed to add new abhorrent behavior to replace the bad behavior they got rid of going away from EF6. "One for Each Thread" sounds dangerous; I'm being pedantic but with threading it's important to be pedantic; Async scoping is probably more safe for most operations, since Thread locals are not guaranteed to flow when an async call jumps threads. &gt; &gt; Instantiating a context and destroying it is slower than reusing it due to the need for repeated heap allocation and deallocation. It's really easy to be inefficient with memory in C# because of all the abstractions. Memory allocation and garbage collection are expensive operations so you should minimise the need. Agreed that allocations and GC should be minimized, but to the original point this seems like one hell of a design smell; I guess the question boils down to whether EF has changed how retrieving items from the DB when they have changed versus what is in change tracker. *Will I have stale data even if I try to grab from the context again?* (I believe EF6 would indeed return stale data) If Stale data is still the behavior, it's somewhat horrifying that the code isn't written performantly around that scenario. [Even still, the most recent published results from Frans Bouma's Access bencher show it's not terrible on memory.](https://github.com/FransBouma/RawDataAccessBencher/blob/master/Results/2017-11-20_NH5.txt). But it is still a good bit more memory than the more lightweight solutions out there. But if you're running an app where you're worrying about performance and GC I'd start to wonder why you're using EF in the first place. Dapper is fast, proven, and can be hooked up to any DBConnection provider with minimal work. If someone wants LINQ, Linq2DB supports a stupid number of DB Providers out of the box. Note where it shows up on the results provided, and then look at the actual codebase. It's been written very... escoterically in ways that probably make /u/grauenwolf cringe. ;) But all in the name of performance. EF Core is very fast for being so new and probably not yet optimized. However building designs that have questionable data safety in the name of performance are just plain wrong in almost every case. &gt; It took me a long time to understand why EF users were so enamored with AutoMapper and DTOs (which they erroneously call "view-models"). Now I know Because their stuff is hacky as sin? 
Here is the entire Data Grid in-case it is needed. https://pastebin.com/WNn32wdr
Yeah, I can second the winforms thing. My previous job was weird. Anything new for desktop was winforms. They acted like I was insane when I suggested using something new. They didn't even know what uwp or wpf was. :(
All this project does is override the SaveChanges method for you. It does have some nice features but I found it only did 60% of what I needed and decided to write my own.
[This list of changes to the System.Collections.Generic API in .Net Core disagrees.](https://github.com/dotnet/corefx/commits/master/src/System.Collections/ref/System.Collections.cs)
You are nitpicking an argument I made to prove a point
Awwe. &lt;3
Probably because people are too stuck on the concept of perfectionism. If you or it’s not perfect then you’re nothing.
Maybe take a look at [Avalonia](https://github.com/AvaloniaUI/Avalonia) as well. It's still beta, but it looks like there's a lot of potential in there. Very similar to WPF, but Open Source and aimed at cross-platform use.
I'm curious. Why UWP is better? I haven't done anything with it as our main development plattform is still Windows 7. Looking through it, it doesn't look that different from WPF although some parts were missing.
You are operating under the assumption that the EF context should be stateless in implementation. It's key advantage in speed is that it is not stateless in implementation. It is a locally cached state repository.
It's not the same, exactly. The packages are different, obviously, but there's breaking changes that will need work. The entire model for identity and authentication changed not-insignificantly from .net to core. Additionally, if you're using EF for your orm currently, you'll likely have even more work at this later as EF Core is a whole new project with a much more focused feature set. I've never used membership reboot, but I would read through the documentation on the. Net core site about how to migrate from .net to core and see if it looks like it's less work to just rewrite that layer rather than try to use identity as a stepping stone.
Thanks. Yeah it seems that just migrating the entire asp layer at once is the way to go. My service layer will be simple, and my data layer with ef should not be too terrible. 
&gt;You are operating under the assumption that the EF context should be stateless in implementation. Did you just now realize this? LOL :) 
If you just want a wrapper, why use EF? Build a repository layer or use dapper or both.
At least for me, UWP wins when you are talking about perf. P/invoke is more than 200x faster (it can be even 600x faster as far I saw). XAML rendering on UWP is also faster. Use less memory, CPU, GPU and network usage is more efficient too. If you want, you can use Win32 APIs too. If you are targeting on 10, there isn't much reasons to use WPF IMO. 
If you use GroupBy in EF, you'll have to wait for version 2.1. it should be ready in Q2
If you use GroupBy in EF, you'll have to wait for version 2.1. it should be ready in Q2
And if you use Lazy Loading that is also not in 2.0. I'm pretty sure it's in 2.1 as well. Until then you have to explicitly list your Includes.
ASP.NET Core doesn't use OWIN (it has its own, very similar pipeline model), but there's a NuGet package (https://www.nuget.org/packages/Microsoft.AspNetCore.Owin/) that lets you use OWIN middleware in ASP.NET Core, or use ASP.NET Core middleware in an OWIN application. 
I often use params string[] includes Instead, as it can make for more readable code: Cars.Get(x=&gt;x.HasLicensePlate, nameof(Car.Wheels), nameof(Car.Fuel), nameof(Car.Insurances))
Can you clarify your question? If you are already an ASP.NET Core developer, you are already at the most updated version of ASP.NET technologies.
The previous version of HttpClient is tricky to use [#1](https://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/), [#2](http://www.nimaara.com/2016/11/01/beware-of-the-net-httpclient/). 
It seems that your comment contains 1 or more links that are hard to tap for mobile users. I will extend those so they're easier for our sausage fingers to click! [Here is link number 1](https://aspnetmonsters.com/2016/08/2016-08-27-httpclientwrong/) - Previous text "#1" [Here is link number 2](http://www.nimaara.com/2016/11/01/beware-of-the-net-httpclient/) - Previous text "#2" ---- ^Please ^PM ^/u/eganwall ^with ^issues ^or ^feedback! ^| ^[Delete](https://reddit.com/message/compose/?to=FatFingerHelperBot&amp;subject=delete&amp;message=delete%20ID_HERE) 
link 2 was really informative, 10 open tcp connections open for ages and getting socket exceptions on asyc await requests, yikes. i guess this class is an abstration over other ones like webclient, so you could go back to those to resolve the issue. but yeah the answer he provides is there also for the current client.
Nothing can use OWIN. It's simply a standard a product implements or not. Although kestrel and asp.net core are not OWIN compliant as is, there is a standard translation layer you can use to run your code within a OWIN pipeline "Microsoft.AspNetCore.Owin".
perfect, i will try that.
i will try this website.
&gt; why I can't use global variables if I know what I'm doing. You know what you're doing now. But 2 years down the line when your working code needs to change, and that code is using global variables, you need to understand the entire program and how it's interacting with that global data before you can safely make a change, otherwise you risk breaking things in another area of the software. It's basically kicking a can down the road, when you come back to it at a later date, there's a lot more work involved than there needs to be, because you need to think about a lot more code than you would if the data was tightly controlled.
Have you ever actually replaced EF with something else that would necessitate the repository pattern?
It depends on context. For my companies needs, yes, have switched concrete repos out. I’ve gone from EF to documentdb and documentdb to mongodb, and I only had to change the repo registrations in my app container with no surrounding code changes. But that honestly happens rarely. The bigger benefit I see is the generalized abstraction of the repo means that working on one project to the next feels the same, no matter what underlying orm we are using. Sometimes we even mix and match repos on a project! However, were a very agile shop with tons of projects coming in constantly. The pattern made sense for us. If your positive you will only need EF and you are only working on one product for a long time, it might not be necessary.
&gt; this company they did custom configurations to make even worse Oh god this sounds familiar. Why are these decisions made? It's so horrible. In my case we pay for a proprietary database system where we get to use their API, which is complete with any kind of data analysis you could imagine. Yet at some point someone decided that we were to store the data in our own proprietary format which means we can't use any of those automatic data analysis tools. Now we're stuck with a whole lot of data and no one with the expertise to do anything meaningful with it.
Engineering. The very idea of creating a simple CRUD takes longer to get accepted than it probably takes you guys to finish a product.
OK then yeah, make the jump to ASP.NET MVC Core 2.1 Preview 1.
You don't need Owin. ASP.NET user management can be overly complicated. I knocked together a really simple solution [here](https://github.com/matthewblott/simple_aspnet_auth) with an accompanying tutorial [here](https://coderscoffeehouse.com/tech/2017/09/05/simple-aspnet-auth.html).
We finish projects regularly. I implemented our CRUD repos as nuget packages, so we don't spend any additional time to consume them in a new project. Just pull them down and you can start using them. It actually speeds development up... I don't write CRUD anymore, just define data models and write logic that consumes the repos. Since January I've completed a Xamarin.Forms mobile app for Android/iOS, an Angular 5 project w/ WebApi and ef repos, another angular 5 project with web api and mongo repos for customer service site, and a phone service which uses mongo repos and asterisk for automated phone dialing. I'm also currently on sprint 4 of 6 for another angular 5 project that uses these repos. Honestly after the repos were finished, I never spend time writing CRUD in our backend code. I spend most of my time either in the front end, or just writing tests for the backend. Huge benefits, little effort. Whatever compelled you to comment what you did, I bet it was projection. 
&gt; why not just have separate classes for each animal and take care of your methods individually for each class? Because - you will repeat code - if a method need a change, you will need to change on all classed 
Or maybe just jump to WebApi in ASP.NET Core 2 and go for frontend in modern web like SPA (Vue, Angular, React)
You're wrong. Public doesn't make things hard. Bad apis that are not coherent and simple make things hard. I started with keep your top level namespace simple and the entire public api. Version that. Everything else can be internal. You could also literally make everything else MyApp.InternalsOnly.blah blah blah. Don't confuse *implementation* with **contract**, any longer. 
You're arguing that instead of using the built-in `public` and `internal` keywords, it's better to mimic them with naming conventions? What's next, make private methods public but name them with a leading underscore?
That's what most people want: something that generates SQL and otherwise stays out of the way.
You can also do href=“/“ so you can change domain without changing code.
LINQ LINQ LINQ Migrations What grauenwolf said 
Sure buddy
You don't know what encapsulation is if you think that has anything to do with internal. 
&gt;an old project with Web Forms in VB and I'm planning to migrate it to ASP.NET Core MVC with Identity You mean, *rebuild* it in Core? Because trying to *migrate* it is like taking a diesel engine and trying to migrate it into a Thorium reactor. Especially since Core is C#, and [does not use VB](https://github.com/aspnet/Home/issues/2738). It is far easier just to rebuild it from scratch and migrate the data.
ElasticSearch has a nice .net integration story.
Cool, reading their tutorial gitbub repo now
This is the best solution assuming you have your app mapped to the root path
What you are looking for is called Full Text Search. SQL server can do it, but something like Elastic is probably your best choice
Does fulltext search rank results in order of relevancy?
I have no idea. I have never used it myself.
They did that too. 😂 EVERYTHING custom and with layers on top. Even the google maps widget that they use doesn’t let you access more than 3 or 5 of the google maps options...
Lucene if you want OSS and a large community
+1, thats better than what I was doing, thanks (:
Define relevancy
This is my bundleconfig.cs just in case https://pastebin.com/LHh1Seid
Using DBreeze Text Search. Working quite well
Try putting &lt;meta http-equiv="X-UA-Compatible" content="IE=Edge" /&gt; in head section. Put it before anything else.
Have you looked at any documentation on Angular? ng generate is used to create components/services/etc
Yes, it can generate an optional relevancy score. This is probably your best bet for performance if you’re ok being tied to sql server https://technet.microsoft.com/en-us/library/ms142524(v=sql.105).aspx
Have a look at this: https://www.hanselman.com/blog/ASPNETSinglePageApplicationsAngularReleaseCandidate.aspx 
Bro, im a professional full stack developer. Just shut the hell up and take an OOP course. 
What happens if you deploy debug mode to your server?
Can't you politely disagree without resorting to name calling? This isn't r/politics.
Do you think if i should jump to django,node js or even php for better future in web development?
I present the courses 
😂😂😂 I hate Java I give mad credit to kryo I'm jealous there 
Look into Vue.js, or Angular. Really though, what you choose to go with depends on the project and your own preferences. I'm working with vue.js and web apis.
i'm going thru what you're going thru right now, and have exactly the same concerns with WPF and UWP. there are not many choices when it comes to desktop applications, and i say this after casting a wider net to include gui projects using other languages such as go, but those projects are not far along yet. i, too, have Avalonia on my radar (@NotTheBus has a post here mentioning it) and i'm hoping that project succeeds so we'll have another choice
Dude, I know.
Maybe, but I'm talking about built in visual studio functionality. Of course I could look over internet for some scripts for that, but I haven't installed visual studio to use it like simple text editor and cmd, when vs is designed to keep those things away from me.
[removed]
Yeah, exactly. While we haven't even approved of starting yet, which is why I think changing platform later is unlikely.
Try [this](https://github.com/matthewblott/simple_aspnet_auth) for a really simple ASP.NET Core user management solution.
1200 controls on a single page?
I'm a little rusty as far as aspnet webforms go, but it might help you. `FindControl` is the way to go here if you want to programmatically use the inputs. But the Webforms framework has a very specific naming system for the controls it renders. [Here is quite a bit of detail](https://docs.microsoft.com/en-us/aspnet/web-forms/overview/older-versions-getting-started/master-pages/control-id-naming-in-content-pages-cs) on the naming system which might help you further. The gist of it is that aspnet will render its own ID for controls to make them all unique and you need to find the correct containers and drill down into them to find the actual controls (think of it as a tree of objects that make up the entire page). [See this subsection](https://docs.microsoft.com/en-us/aspnet/web-forms/overview/older-versions-getting-started/master-pages/control-id-naming-in-content-pages-cs#drilling-into-the-appropriate-naming-container) 
 foreach (GridViewRow row in GridView1.Rows) { TextBox contentBox = (TextBox)row.Cells[1].FindControl("GridView1_Box-NormSeng_E-AfdID-1"); ... } I think your control id is wrong... it shouldn't include "GridView1_" at the very least. Why not dump out what the control id's actually are: var s = string.Empty; foreach (GridViewRow row in GridView1.Rows) { foreach (var c in row.Cells) foreach (var i in c.Controls) s += i.ID + "\r\n"; } /// examine 's' to see what the control id's are FindControl is pretty picky and it won't check containers for child controls (only immediate descendants). And if I recall correctly it uses ID (i.e. before all the parent container ID's have been prefixed). Here's a routine that checks child controls (but so inefficient... you need to think very carefully about using something like this): public static class ControlFinder { public static Control Find(Control Container, Type ControlType, string ControlId) { object o = Container.FindControl(ControlId); if (o != null &amp;&amp; o.GetType() == ControlType) { return (Control)o; } else { foreach (Control ChildControl in Container.Controls) { var FoundControl = Find(ChildControl, ControlType, ControlId); if (FoundControl != null) { return FoundControl; } } } return null; } }
FindControl uses the concept of naming containers and doesn't really use the control hierarchy like you would expect. What Control.FindControl actually does is find the first ancestor in the control heirarchy that implements INamingContainer, and then search its list of controls that it "owns". For example, if you have a control heirarchy that looks like this: Page (INamingContainer) form TextBox1 Repeater RepeaterItems[0] (INamingContainer) TextBox1 TextBox2 TextBoxA ... RepeaterItems[n] (INamingContainer) TextBox1 TextBox2 TextBoxA If you call Page.FindControl("TextBox1") it returns the control that is a child of form and ignores the repeater items because they are owned by different naming containers. If you call Page.FindControl("TextBoxA") it will return null because it doesn't "own" any controls named TextBoxA. If you want to traverse the control hierarchy, you can write something to do that using Control.Parent and Control.Controls. FindControl doesn't look at hierarchy; it looks at naming containers.
To highlight best practices for the community 
Thank you :) &gt; I think your control id is wrong... it shouldn't include "GridView1_" at the very least. I know. Like I said I've tried all the different permutations, with and without, and I know GridView1_ is from the ClientID. It was just an example. I also know that it's picky, which is why I search the cell - that's the furthest down the hierarchy I can get, right? foreach (var c in row.Cells) foreach (var i in c.Controls) s += i.ID + "\r\n"; That's exactly what I was asking for - a way to output the actual ID. I'll try it and get back to you :) As for the other code you suggested, yeah no, I would never use that in the finished product ;) I've tried something similar for debugging, but I like the design of this one better so I might give it a go if the other line doesn't help, so thanks again!
best option is probably to use javascript. window.history.back()
On a Mac, VS Code or Rider are your best bets there. I'm not a mac user, but the general consensus for VS for Mac is pretty lacking at this point. I can't speak for Rider, but it's gaining popularity for those who are already invested in Resharper.
Yeah I've been using [this page](https://www.telerik.com/blogs/the-difference-between-id-clientid-and-uniqueid) for reference on the different ID types and what they do, but none of the permutations seemed to work. I'm pretty sure I have at least skimmed the page you linked before too (and many, many more), but I'll give it an in-depth read through if /u/rbobby 's suggestion doesn't get me further. The subsection you mention does seem like a very good resource in particular, so thanks :)
What database are you using?
Oooh! That's helpful; for some reason that explanation of FindControl has not cropped up anywhere I've searched (not in a way I could parse anyway). Hmmm. I'll need to mull that over, but that will definitely change my approach. Super helpful - thanks!
I think it's better to add a logo that link to the home page, and an "Go Back" button on the bottom &lt;a href="/Home/Index"&gt;&lt;img src="{LOGO IMAGE}" /&gt;&lt;/a&gt; &lt;a href="#" class="btn btn-primary" onclick="window.history.back();return false;"&gt;Go Back&lt;/a&gt;
SQL Express atm but from what I am reading I think I should move to NoSql
I am able to hit js breakpoints in vs with the template but only up till I make a change that causes hmr to reload and then it breaks
Have you tried ClientIDMode="Static"?
Thanks!
Asp.net MVC is great for job opportunities, and it is a better way and easiest way for being on the cutting edge for you. The less easiest way is to learn front-end with some framework, like AngularJS, and use it with asp.net core WebAPI on the back-end. In my opinion, this is most flexible and beautiful way to use .net on the web for now. I think this is the future of .net in web. And someday SPA will lead the market, and MVC will be deprecated like WebForms nowadays.
The only thing I can think of is [Julie Lerman's courses](http://thedatafarm.com/blog) but they require a subscription to pluralsight.
Thank you. If it comes to that I'll see how much it costs. 
Anything long term you have to figure it all yourselves. No application framework will help you there.
&gt; ClientID I'm pretty sure FindControl() expects Control.ID not ClientId. Usually what I'd do is use the debugger and examine the control tree directly. It's a giant pain... but desperate times call for desperate measures :)
AngularJS, for example, is a framework too. And it can be the good choice for some kind of long-term projects. But I understand what you're talking about. ABP is really pushing you to face some kind of limitations.
Depending on your level of MSDN subscription you can get a decent discount (as well as a free trial).
I am personally not a big fan of framework like ABP. As you mention, we already have to rely on JavaScript framework on top of MVC plus other essential libraries. Adding more layers on top of those are more trouble than they are worth.
A web portal shouldn't really serve as a replacement for an extensive excel document. A few suggestions, but I know sometimes crap like this is the only way to appease business side. 1. Could you not paginate the rows or add some recursion to the controls so that not everything is being executed/updated on the same page? 2. If its just a spreadsheet that needs to be synced up or something, why not just make a site that offers a copy of the spreadsheet and also allows them to upload it. Once uploaded you can process/sync anything that wasn't done adequately by the spreadsheet. 
Oh I'm still a student, so I don't have an account. This is probably a good test to see if I can hack it on my own lol
I'll second this. I had a similar issue and it made son sense since I was using the same browser to view my code locally and remotely. I might not have used IE=Edge but something similar. [here](https://stackoverflow.com/questions/14611264/x-ua-compatible-content-ie-9-ie-8-ie-7-ie-edge) is a stackoverflow related to this.
Also..If you don't need an instance of that method across user sessions. If you wanted to do something like quickly track the number of instantiations of objects, you could use a static method for that.
The boiler plate is a good starting point, for any project that has the potential to grow, I would push back the DataContext, Models, and anything related to direct data access to a separate class library. This is to ensure that there is a clear separation of concerns. The only thing the web api or MVC project should have is the views and controllers. The controllers also shouldnt directly access the DataContext class, I would make use of the repository pattern to minimize the number of places where the data is being manipulated. This will make it easier to change business rules if you're only making changes through one place. So your controllers speak to a repository (in the data class library) that then speaks to the datacontext and manipulates the database.
I'm curious to hear other peoples take on unit testing log calls. On the one hand, yes, you want to test what a method is doing. But I feel like checking for a specific method invocation is usually too coupled of an approach. Ideally, your method has easy-to-verify ins and outs and so you don't need to worry about checking internal work at all. But of course, that's just the happy path and we all live in reality. And if you're writing unit tests that are specifically checking "yes, an error is logged when this known case occurs", then this sort of thing can be useful. But again, it seems like you could be checking for it in a different way (like getting back an error response from the method). Especially since there are multiple ways you could approach the various things you may want to log, not all of which would necessarily be unit testable (think AOP). If you were to migrate your logging from the more traditional approach seen in this post to something done via attributes, for example, these sort of tests would start failing merely because of the test tying itself too closely to the internal behavior of the method. I guess this is just my long-winded way of saying I'm glad that Solution 1 exists, because that solution is closer to "test what it does, not how it does it." Solution 2 seems like a hacky work-around in which you're not only altering code, but also adding MORE code, simply to satisfy testing a method invocation. I may be wrong, but it feels like a smell to me.
Nice. Thank you. I figured out how to add columns, now I'm trying to figure out join tables. Microsofts docs actually make more sense to me than those of python
Solution 3: Use a code coverage tool like dotcover. Make sure all logging statements are covered. You know the logging method was called. Anything more and you're just validating Microsoft's logging implementation.
&gt; the future's bright I hope, I'll have to change my career if the future is JavaScript and blockchains
Hah! Tell me about it. I think this is why everyone I speak to is so interested in Blazor in particular.
If I had to decide for a random unknown team I think I would tell them to use the boilerplate. You will end up with some fat, but they wont go totally off the rails with their own wacky design.
That is a good point. I've been in this place for 4 years and we have a strong foundation of code, strong reference architecture, and a stable of good developers I've helped hire. When a new project spins up we put together this boilerplate ourselves as we need it. But if I was to move into a new company where I didn't hire half the team and write half the reference architecture I suppose I would also recommend this boilerplate. It's as good of a framework as I've written myself, if not maybe a little better given its all inclusiveness. 
Well let me know when Systems.Collections.Generic becomes sentient and gains feelings
Except for a few marginal cases ("this method really should swallow exceptions and log them"), testing logging statements is actively harmful. It's exactly the sort of fragile test code that breaks for no good reason, and on top of that it provides a disincentive to adding more logging ("I don't want to have to write more tests now") and to improve logging ("this message is inaccurate, but I don't know which tests might depend on it", etc.).
That's kind of my thinking on it too, glad to get some affirmation lol
It’s quite capable, but expect weird api‘s
I'm doing pretty well with Typescript, at least. I really have my eye on Blazor, though.
Blazor is awesome, but I'm also interested in C# UI frameworks that bypass HTML and CSS almost entirely. I want XAML in the browser. :P
That was called silverlight
Silverlight was a plug-in. It wasn't natively running in the browser.
please write something for entityframework core Correct me if im wrong on this, but i found some annoying features not available in entityframework core. I dont use generic repository. I directly query on my dbsets with IQuerable. so I build up an expression tree. What i found lacking is that EF core does not support time comparison, if you try to do this with EF, it will be executed in the code! I had to hack around this by creating enums of time spam groups e.g. 0 : &lt;5 mins, 1 : &gt;= 5mins &amp;&amp; &lt; 10mins etc etc
Go Blazor! I've been waiting FOREVER for this. Would be fantastic if they dumped HTML and CSS into the same trash bin that JS is going into. Why cant we have a really truly modern browser that renders XAML or similar? Don't be too quick to say no one would use it. MS has a little cool factor going on right now with .net core. 
I don't necessarily disagree (I don't seem to have an opinion either way), but what makes XAML that much better than HTML/CSS? I use both and I would much rather write HTML/CSS than XAML.
I prefer going from scratch, a lot of useless crap in the boilerplate 
You would use a Windows Service with network privileges. A Windows Service is more or less a console app, with some differences. I would use this http://topshelf-project.com/ which makes it all so much easier to deal with. That service could then be a WCF server, HTTP server, whatever you want.
I'm really confused by the reaponses here. I've always just spun up the empty mvc app from console and thought it saved me some awesome time. Do people *always* use the full blown mvc boilerplate?
Actually abp is not a mvc preset in visual studio, please check the link, think you might be interested. And honestly, I was hope someone will write success story about using abp in the big project, but for now, all of the people in the tread seems to prefer empty project instead of framework/preset.
Can’t most of those upsides be explained by single target platform? Wouldn’t XAML, if it were to ever make it to the web natively, suffer from the same issues that HTML had in its early days?
HTML and CSS are still pretty bad in comparison, even if you're only targeting a single version of a single browser. And XAML in the browser probably wouldn't suffer from the same issues since it's being implement in the browser and not by the browser.
&gt; And XAML in the browser probably wouldn't suffer from the same issues since it's being implemented in the browser and not by the browser so there would only be one implementation. You might underestimate the web community there.
This, the current web was not designed for applications 
You can get a trial through Imagine.
Oh nice. Thank you!
One of my co-workers got really excited then mad that we can't be using this already. 
Progressive Web Apps (PWA) is a principle covering quite a lot of different web requirements, but what they all have in common are that they better the user's experience. In this post, we'll explain what a PWA is and show you how to turn your ASP.NET Core app into a PWA, using only a few lines of code.
1. Oh updating it is not the issue as such. The issue is that in order to update the database I need to know the ID of the source controls :) After that it's just iterating through them. 2. That would be too heavy a workflow, especially since this comes form random people who may or may not be familiar with the system. It has to be as simple as possible. The end user don't even see the finished "spreadsheet", they're just seeing a simple input page for their area of the business. It's just that the data controller needs to be able to make adjustments to everything in one place, daily. In any case, the solution is all but done, so I don't have the time for a major rework. 3. Checking the ID in chrome doesn't help, because it reports the ClientID, not UniqueID or ID - it shows what is rendered to the user, not what the server sees at runtime. That's the crux of the issue. I've gotten some good suggestions/info here though, so we'll see how it works out later today.
&gt; Could I persuade you to tell me where to look in order to examine the control tree? I don't know that feature and I feel like it'd be real handy for this. Step 1: debug the application using visual studio. This can be a challenge sometimes. Make sure you start visual studio as Administrator. Step 2: Set a breakpoint in your code where you're having trouble with the tree Step 3: Hover the cursor over the variable and it will show you its properties. Expand the "Controls" property... examine each entry. Step 4: Keep expanding/looking at controls. This can be a giant pain... but your control is in there somewhere :)
Do you know if Avalonia can build portable applications in the sense of no install required? I have some in-house tooling that needs a GUI and it's somewhat unsatisfactory to have a full install process for each new version instead of "just" replacing the binaries
Ah ok, I just hadn't been digging far enough. I do use the examine option quite a bit, but mostly to see data/collection contents/sql results. Cool :) Not to worry about the minor changes, I'm sure I'll survive losing those 45 sec to find the right objects ;) It was mostly to document it if anyone googles their way to the thread in the future.
I also see it like some others here: OOP is not all there is. Since I wet my feet with some Haskell I started thinking about functional concepts in non-functional contexts a lot. When a function can work with only a hand full of variables without requiring state it has no side effects: it can be static. If a function does require state and has no side effects: see if you can refactor the state-handing in one function and pass it's output into a second, static, function that does the rest. If a class has no real state whatsoever: it can be static as a whole class. In my opinion, most static functions should be pure (in the sense of no side effects, no state and deterministic output for any given input) and pure functions should not cause problems in testing. The only "state" I sometimes have in static classes are settings I load into them upon starting my application, but then always make sure to have all options as optional parameters in any function that uses them. This way you keep your application testable.
Would it still be inverted if your generic repo had something like this? I use a generic repo with methods like this so I don't have to rewrite this code in every repo and that way the BL does not bleed into my repo layer. Then developers could inject the CustomerService into any controllers they need to use it in that way everyone is relying on the same business logic. Would that be a bad thing or am I missing something? public virtual async Task&lt;List&lt;TEntity&gt;&gt; GetMany(Expression&lt;Func&lt;TEntity, bool&gt;&gt; filter = null, Func&lt;IQueryable&lt;TEntity&gt;, IOrderedQueryable&lt;TEntity&gt;&gt; orderBy = null, string includeProperties = "") { IQueryable&lt;TEntity&gt; query = _dbSet; if (filter != null) { query = query.Where(filter); } foreach (var includeProperty in includeProperties.Split(new char[] { ',' }, StringSplitOptions.RemoveEmptyEntries)) { query = query.Include(includeProperty); } if (orderBy != null) { return await orderBy(query).ToListAsync(); } else { return await query.ToListAsync(); } }
thx, I did this but no change
Thanks for the link, I validated all of my css files and there's some warnings but no errors. Could this be due to the warnings?
I deployed two versions, one in release mode and one in debug mode. Here are the links: * Release: https://vidlyrelease.azurewebsites.net/ * Debug: https://vidlyrentals.azurewebsites.net
yeah that makes more sense, thanks
Look at NEventLight. Akka .net is also an option but it goes beyond just event sourcing 
Marten? [Project Marten](https://github.com/JasperFx/marten) Though I’d be a bit careful about being too storage agnostic. The capabilities of each data store is pretty different so you’d care about that at some point. GetEventStore for example supports projections out of the box.
Used ES as a concept in a large(ish) system. EvenStore is a great persistence system for it, however even if you don't want to use it, there is a ton of ES concept discussed here: https://groups.google.com/forum/#!forum/event-store also check out https://groups.google.com/forum/#!forum/dddcqrs ES as a concept makes a ton of things easier.. but there are massive tradeoffs you have to consider. lastly, please consider that you don't have to use ES or CQRS everywhere. some problem spaces make great sense to implement it, some don't. Start with some small sample projects, have a domain model.. implement it as ES.. then make a breaking model change... VersonX to VersionX+1 problems can be difficult. 
I've always found them to be largely pointless. There isn't much to actually frame in an "Event Sourcing framework" or library. What is it you're looking to abstract, if I may ask?
ddd-cqrs-es.slack.com is also very active. 
I am looking for a set of classes and services to help me manage / teach me how to manage out-of-sync states across an architecture. It is not a business requirement yet, I am just curious.
No, the web is still trying to come up with web components, while XAML has native support for controls since day one. I am yet to see something like Blend for HTML/CSS.
Thank you, I will check it out.
Thanks !
&gt; Would that be a bad thing Short answer: probably. I think the rule is that your dbcontext should be internal to your business log layer (a .dll library). You never want to create a hole in your BL that allows direct access to your db. In practice this is a bit more complicated as you need it for tests but you should get the idea. internal MyDbContext : DbContext { } Honestly I find that for larger apps most generic interfaces break down quickly because the entities are so different. For instances for some kinds of entities like many-to-many you don't even want pubic Add() or Edit() methods exposed. Boring and uninventive as it is I just fall back to methods that describe the business intent and try to parameterize as much as possible: public List&lt;Customer&gt; GetPastDueAccounts(int minAge, int salesRegion, string rename, more parms....) { } 
Neat.
I think that if you come out of that course and have some projects under your belt and have a decent grasp of the concepts that they've taught you, you should be in good shape to become a Junior .Net Devloper.
Thanks you, looks promising.
Thanks !
As long as you are near anything resembling a city you should be fine. If you put up a linkedIn profile with any sort of experience, you will have recruiters crawling over themselves to setup interviews. When you do start looking, make sure you setup multiple interviews and don't necessarily take the first offer that comes your way. You should be able to be a little picky, and make sure you are interviewing them as much as they are you.
I'd recommend not storing them in a database for a few reasons. First, depending on how many songs you store, the size of your database will be large. Dealing with this might be cumbersome after a while. Second, any time you want to access a particular song, you need to query a database to get it, and return megabyte worth of data. This is pretty processing intensive. Which brings me to my 3rd point. Storing the audio in Sql Server means there's no physical file on the server, which means you are probably not going to be able to cache it on the server. 
This is an extremely ambitious project so I'm hesitant to tell you to jump right in. That being said, there's lots of moving pieces to a website like Mixcloud and if you are a beginner you could certainly learn a lot about the webdev stack. What's your experience with web development? Are you comfortable working with any frontend technologies? Just basic css/html/js? Streaming the files will require some complex communication between server/client. The alternative is to have users download the entire file and handle playback, track seeking etc. all client side. This has a lot of upfront bandwidth when changing tracks, and requires the entire file to be kept in the client's RAM. Storing files in some kind of sql db should work but EF Core doesn't support things like sql server file streaming. Your server (.net core application) will have to keep the file entirely in memory when it's being transferred / streamed. With many users this quickly becomes an issue, as 1,000 3MB songs will use 3GB of RAM. Notice Mixcloud allows you to play music while you browse the site. This uses javascript to manipulate your browser's URL and fetch content via ajax to update the page. A true page navigation would cause the javascript playing audio to stop. If you've never made something like this before, check out [this mdn page](https://developer.mozilla.org/en-US/docs/Web/API/History_API) on how it's done. There are a lot of really important questions involved in this kind of project. Keep in mind, sites like Mixcloud, pandora, spotify web player etc all have large teams developing them. This includes people with expertise in areas I've outlined as problems for your goal. I would recommend a different project, but if you really want to try this start small. Maybe take a single mp3 file from the .net core app and try streaming that to the client and creating controls to seek, pause and play. Once you have that working maybe use a folder of mp3s and allow the client to skip songs. DB storage quickly gets complex for this kind of app so if you want a simpler project that makes use of a database consider something like a blog that just has small, simple entities.
Eventual consistency. Not something that is solved lightly and, in my experience, requires a very tailored solution.
You should also specify in which location are you looking for a job. In Central/Eastern Europe you would be hired on Junior position easily. 
Is there any shortcut for Visual Studio to open terminal pointing to project folder? How do you use terminal along Visual Studio?
I keep a terminal window open outside of visual studio :/
Agree. We are seeing the web come around to the binding and component model (MVVM) with Angular. But XAML is simply more expressive.
Why would you want to unit test an ILogger extension methods that you didn't implement yourself?
Eventual consistency can be a terrible problem. I once had this problem in an admin app where people had essentially presented eventual consistency as a feature instead of a problem: Admin user does a search, deletes an item, then does the search again, item is still there so admin selects it, ui generates an error because when it tries to get the item it no longer exists. 
I don't know how far into security they will go, but most people coming out of college seem to have little to know understanding on good security practices. I'd highly recommend before working someplace you try to self-teach yourself some, there are millions of resources out there, from how to store passwords safely (hint, you don't) and how to protect from common attacks like SQL Injection (which IIRC compromised sony's PSN a few years ago and its the most basic web attack), XSS, etc. There is no one perfect way to secure everything, but having a security mindset when building code prevents back end developers from blindly trusting anything that comes from the front end, which is the best mindset anyone should have when being a back-end developer. 
make up some shit like Trump on your resume. that seems to work.
Probably much easier to get started with something like this. Looks much more "traditional" from a relational database perspective. Good luck!
I would not store the files in DB really but on CDN. And the CDN is a simple server that supports multi part streaming. The back end can be a SAN like FreeNAS optimised for best read speed. That way can also then two locate servers easily by copying files using something like rsync- or distribute very popular songs to cheap cloud services. Basically your question is Architecture related. The code is so minimal for serving files. 
Oh he can cache it... but really you shouldn’t cache it especially if it’s r adding bytes from drive If IO Becomes a problem time to move to a CRN with a nice SAN backend like FreeNAS or some good cheap fast raid 
Versioning for example. If your domain object has Name in 2018 and in 2019 you split that into FirstName and LastName. Suddenly you have a mismatch that needs to be resolved.
&gt;Could this be due to the warnings? Possible, but IMO highly unlikely. Warnings are typically when you are not doing something to completion or are missing a recommended thing. Warnings do not deal with errors, which is where any bundling problems would creep in. My next recommendation would be to take a bundled CSS and laboriously “unbundle” it by hand in a text editor (such as Notepad++). That way, you can compare what you wrote in your original files with what exists in the bundle. Hopefully the bundled CSS goes sideways at very specific points so that you can clearly see *where* things go wrong. AFAIK bundling CSS just puts CSS files end-to-end and removes the spaces, carriage returns and other text-based features that make CSS files easier for humans to read and edit. That way the files are (slightly) smaller for faster downloading and there is just one file (instead of several) to make the older HTTP/1.1 protocol more efficient. By manually unbundling them, you can compare what exists as a bundled version with what you wrote, and see if anything is missing, corrupted or out of proper order.
It's just a good book of general design &amp; best practices, not in my opinion related to back end.
Ah yup of course. Never had to use one so it didn't come to mind.
awesome! the EF core is quite disapointing that they havent provided more features yet. thank you
Im from Serbia, Novi Sad. There are a LOT of bug companies here..so i hope that i could get hired easily
I see that Azure has a CDN service but sadly I have no idea how would I implement that into the project. I have absolutely 0 experience with Azure.
That might just do it ! Thanks !
Instead of waiting, why not create that technology?
.NET assembly linking and type resolution are kind of finicky about assembly versioning, public keys and embedded platform/culture info. This affects all assemblies loaded, though I'm not sure if it's base on the process or the AppDomain. It's probably one of my major annoyances when I have to deal with 3rd party assemblies. Having some packages reference others by source and compiling them that way would be a bit of a nightmare unless you could enforce it all the way down the chain. There's still the issue with 3rd party assembly licenses. Linking vs compiling are two different scenarios from a licensing standpoint. Optimizing your assemblies can also drastically affect performance and deployment sizes. Yeah, depending on a clean build from someone else has its weaknesses, but it's also significantly easier to inspect a compiled .NET assembly than native assemblies.
I handle this by having short lived tokens ... when they refresh their token the new claims come in. If you don’t want to do this you can always go low tech and add a blurb to the page that tells the admin (or whoever sets roles ) that they should inform the user that they need to log out and log back in .
Using a token version as suggested in the following link may be a solution for you: https://stackoverflow.com/questions/43978021/update-change-roles-claim-or-any-other-claim-in-jwt
It's tempting... I should gather my thoughts. The way you can separate style and structure is really good in HTML/CSS. XAML is usually very verbose there. But my 'real' job already has me in 200%...
Idempotency plays a massive part, as does separating the notion of doing something because of a command to achieving a particular state because of a command. By that I mean when the command to delete an item is received, the goal isn't to actually delete the item, it is to reach the state of "item deleted". If you're already in that state, then it's a success. facetious example code: public void Handle(DeleteItemCommand command) { var user = this.repository.Get&lt;User&gt;(command.UserId); if (!user.HasPermissionToDeleteItems()) throw new YouDoNotHavePermissionToDeleteItemsException(); var item = this.repository.Get&lt;Item&gt;(command.ItemId); if (item != null) { var @event = new ItemDeletedEvent(item); this.repository.Delete(item); this.eventDispatcher.Dispatch(@event); } } So, assuming the repository returns nulls instead of throwing when an entity cannot be located, you can see it doesn't matter if we try to delete an item that doesn't exist - and perhaps it's correct to not care because we were only trying to delete it, after all. :)
Why do I need to await? Are the calculations not fast enough to give a result immediately?
It’s pretty fast. We have an await to prepare for random connection delays. 
Also resolves the problem of if the user is removed from the application. Nothing like having a 30 day JWT hanging around and no way to lock the user out apart from wait for it to expire....
How I have done it in the past is that is that you have two separate tokens - jwt and refresh token (usually a guid that is saved in the db, usually has a lifespan of 2 hours to 30 days - pending if you have a remember me option). Both of these tokens live in the browser, usually local storage. The jwt should have a lifetime of about 10-20 minutes (remember, jwt's are stateless). When it expires, you should send your refresh_token to the server to retrieve a new jwt. This will refresh all the claims. So, what you do is that when the user is updated, you just update the jwt using the refresh token, even though the jwt hasn't expired. However, people (developers) are going to complain about "you should not have your refresh token in the browser!!". My answer to that is that whenever a refresh token is used to renew a jwt, you invalidate the existing refresh token and issue a new one (this is called sliding scale, I believe). Another thing to do is that when you save the refresh token in the db, don't just save it in a table called refresh_tokens. Save it in a user_devices table so when the user logs into their account, they can deactivate any or all other refresh tokens on other devices (use js to get device info and location). You can also make it to where if you manually log out, all refresh tokens are invalidated. You can also have an admin be able to invalidate (deleting from the db) refresh tokens. Also, something cool I like to do with this is that when a user visits your app - have the browser check for a valid refresh token. And if one is found, ping your server for a new jwt and skip the log in screen. Hope this help.
I think you're missing a lot of fundamental units since my first request to convert W to kW failed. 50 different unit types is a dram in the pottle.
Thanks for that! We are catching them as they come in and adding new calculations every chance we get. We have added several thousand different ones and still building. 
&gt; Why do I need to await? It's not local; it hits an HTTP endpoint to do the conversion.
JWT tokens only live for a short time. So every 15 minutes or so it would update their claims when they request a refresh. I feel like that is reasonable. 
&gt; ES as a concept makes a ton of things easier.. but there are massive tradeoffs you have to consider. Would love a summary of your experience with ES. Everything I've read about it is written by someone with an ax to grind one way or another. Would you use it again?
We do pretty much the same, but in a SPA ;)
https://social.msdn.microsoft.com/Forums/sqlserver/en-US/6c91805a-7021-458f-9c5b-13c1c0d25b95/the-semaphore-timeout-period-has-expired-azure-sql-database?forum=ssdsgetstarted You need to make sure the plan you have is sufficient for the number of connections and processes you're doing. 
What? That can't be right.
They want to charge for it, too. [Source](https://unitconvert.io/#pricing). It's kind of insane, really.
Thank you for your reply. in the example Is there way to $expand?
Lol I meant to say if your user has a collection of comments. Are you using entity framework?
Excellent timing of posting this. Was absent mindedly thinking of tackling this. This looks like a big head start from what I feared
https://dev-squared.com/wp-content/uploads/2018/03/uc_output.png &gt; 12g is 12000000 Milligrams What? TBH, it looks like they manually wrote the console output (it doesn't match the program's strings), so it's probably just a copy-past error (?). But still...
Generally access tokens are short-lived (in case of Azure AD one hour by default for example). Tokens are typically not held by the server so you can't revoke them. I think the best thing you can do to adhere to standard practices is either wait for the token to expire, use the browser session to issue a new token when access rights are changed or have the user login again if his access rights have changed. I reckon this shouldn't happen very often anyway, right? Typically a refresh token isn't given to public clients (i.e. clients that can't keep secrets safe). Browsers should be able to use their session to refresh the token anyway.
That sounds awesome. Happy that the post helps!
If talking http anyway wouldn't it be better to host the ASP.NET (Core?) application in an IIS? What benefit would a service grant in that scenario?
For the reasons raised by /u/kukkimonsuta
We ditched IIS because it's an additional dependency, annoying to debug and configure (especially for simple cases like this), the deployment process is more elaborate and it bind you to Windows Server. That said I think it would be completely legitimate. I guess it's a matter of taste.
That's a good point. Especially if only running on the local network. Thanks for clarifying. But how does it bind you to Windows Server? I have an IIS on my development laptop running Win10. Or is it pro only?
https://pasteboard.co/HaMztyV.png Works well.
Not an answer on question, i am noob web dev and i have really dramatic question. can vs code do everything what visual studio does? i am asking that because my pc has only 2gb ram(it is toaster i know) and visual studio is lagging on it. also i wanna ask one more thing, i have 32-bit windows so debugging is not supported from omnisharp in vs code.. and can i debug with any other program? 😂 (btw im poor as well so i can not afford new pc) 
I'm taking about the period when the system is currently inconsistent: the search service still thinks the item exists but the item service says it doesn't
Thanks for clearing things, i wanna know if i should just continue with dotnet mvc or shift to node js or django or something else in case of job opportunities.
Thankfully, I think the overreliance on Javascript for the web is a temporary but painful blip on the radar. I can't see how it will be essential to write swathes of code in JS when WebAssembly is more established.
No it doesn't. Thousands upon thousands of possible unit conversions will still fit comfortably in a small database file. And that's assuming that you don't optimize it for size by running everything through SI units.
Appreciated, and that is solved by the solution I've already described - eventual consistency is a matter of a very short time span. We aren't expecting this consistency to take a week to materialise, more like 300ms at the most. You'll need to consider that mismatch as a real scenario and not a "technical problem". This is what many consider the draw back of eventual consistency, however after time I realised this isn't a technical problem - it's just as it would be in real life. E.g. User "A" opens your app, does a search, and now has a list of items in front of them. They go for a coffee or whatever. In the meantime, User "B" logs in, opens the same list and deletes an item from it (call it "Item X"). User "A" returns from their coffee, sits at their terminal and (without refreshing the list) attempts to delete "Item X". What does your system do then? Why shouldn't your eventual consistency system do the same? What about before computers existed? User A phones (or worse.. writes a letter to) the depot and asks what is in stock; gets told and writes it down. User B phones the depot and instructs them to remove Item X from stock. Is the depot now responsible for phoning User A to let them know they need to update their notes? What happens when User A tries to do something with Item X? Why should software be any different to this?
No one is trying to delete a second time. &gt;Admin user does a search, deletes an item, then does the search again, item is still there so admin selects it, ui generates an error because when it tries to get the item it no longer exists. 
The MSDN blog article on this is longer, better written and has a better version of the exact same diagram.
Thank you for your feedback. This was meant to be concise, not to be deep, but chances are that I will improve it based on the feedback I got so far. In what way do you feel their version is better? I think the diagram is useful to illustrate the concept and I mostly redid it to avoid copyright issues. It should be equal in any relevant way.
Most likely Microsoft's own product: Dynamics CRM. It's a very commonly used product for enterprise companies.
Do you mean crm or cms? 
You basically copied the diagram MS already created but with worse kerning on your fonts and the margins make it hard to read. Concise is OK but add something new to the content. Right now this just feels like a page designed to improve SEO for your site. If that is the case I understand, just know search engine bots are getting smarter than that.
Isn't the whole point of .NET Core that it can target non-Windows environments?
I mean like osx, linux and by extension Docker.
So what's actually wrong with that? Why is it a problem that the UI now says something to the effect of "It appears this item no longer exists."?
I don't understand the goal of this. You took a graphic from the [MSDN Blog](https://blogs.msdn.microsoft.com/dotnet/2016/09/26/introducing-net-standard/), removed a lot of useful information from the [overview section of the official .NET documentation](https://docs.microsoft.com/en-us/dotnet/standard/components), and posted it on your blog. How does this help beginners or add value to what's already available? 
What is the problem with storing the keys in the database? User secrets are not for production configs, its more for local settings.
Well, right now for osx (or macOS again) GUIs you seem to are bound to Xamarin. And there are no (official) desktop GUIs for Linux on Core as well. There seems to be a third party beta state framework for Core desktop GUIs called Avalonia, but I have not yet looked at it in detail. ASP.NET Core and Core cli on the other hand are macOS and Linux ready already.
I am working towards building a body of knowledge on the general topic and this piece is important to me in right this depth. Just to get the 30.000 feet overview. For people who want more details I put the links at the bottom. I want this information to be part of the whole I am creating, even if that means that not every post is original and not everyone likes every post.
Servers though.
I totally agree, that what you say is the right thing for most topics and posts. In this particular case it would defeat the purpose of being a quick fact sheet to get an overview. Probably going in depth on this might be worth another dedicated post on its own later on.
This one looks good, too: https://github.com/angularsen/UnitsNet. Open source, 1600+ commits, very active, "600+ units", the API is actually typed (looks like OP's is just strings), etc.
Oh look, you've ignored what I wrote again. Carry on being the angry guy with his fingers in his ears. Good day.
Oh that's much better. Good find! I just went with the first example that came up via search.
Well, no??? ASP.NET is for web applications, services are for long running processes that have nothing to do with web stuff. It's a little tiring seeing this mentality so often "I will just do some complex logic that could take longer than the connection timeout will allow and just hope it works".
But in that case maybe http should not be the first choice, or am I wrong?
You're not wrong, Walter, you're just an asshole.
In the database. 
&gt; On top of the foundation lies the .NET Standard library `.NET Standard` isn't a library. &gt; It holds all of the code that is not platform or environment specific library like LINQ and collection types and lots of components in the System namespace. It defines a specification; it doesn't really hold much code other than what's necessary to define that specification. &gt; As .NET Standard is open source you can explore it yourself at https://github.com/dotnet/standard/ What are you expecting people to find at the Github link?
Would you store the key as plain text, or would you encrypt the key?
The problem is, is that the service has to been running at all times even if the user is not on the website. The application will be monitoring tweets and retweeting certain ones with the specific criteria.
Ah, in that case, I'd say start with Hangfire, then progress to a separate worker role if needed. 
The c# twitter wrapper has streams that are similar to webhooks. Would it be ideal to run them in hangfire or should I use a worker role? And just to clarify, what do you mean by a worker role? A console app? https://github.com/linvi/tweetinvi/wiki/Streams
Got a link to that?
as a backend guy, arguing about why we need security with the program managers is a never ending struggle. “well no on will find out”. no, this data is sensitive, it has to be locked down. 
It's been a while since I've worked with azure, so I'm not sure if this still holds, but worker roles were the companion to web roles. Web roles responded to http requests, worker roles ran as background processes to do more compute work in the vein of windows services. The streams API that you linked to is meant to be kept running in memory, so a separate console app, background process, or worker role, etc. will be required to keep it up and running so you consistently get the events you are interested in. 
Thank you very much for all of your help.
Your first 3 items, as far as I can tell, are the same thing (or very close) in terms of implementation. But like most of these questions, it depends. A good place to start is this post by /u/matthewblott. It includes a boilerplate project that implements a lot of Core auth paradigms; I copy and pasted a lot of it into my current projects. https://coderscoffeehouse.com/tech/2017/09/05/simple-aspnet-auth.html
Fantastic. The File.IO APIs have always been a bit of a pain point in how restrictive and "thick" they were, to see that this thins them down and lets the underlying operating system handle much more of the behaviour is amazing. ``` We've made matching consistent with legacy behavior on non-Windows platforms (????.txt matches the same on all platforms) Match expressions no longer match 8.3 file names on Windows (*.htm will match only *.htm, not *.html, *.htmz if the volume 8.3 generation on) We've fixed enumeration of unusual Windows files - you can now get *Info classes out successfully and use the methods on files that end in spaces, periods We do very little validation of paths up front as there is very little we can accurately predict (unblocking numerous xplat and some existing Windows scenarios) We only check for embedded nulls, no other chars are rejected, including wildcards (as nulls are never supported and OS APIs almost universally take null terminated strings) We don't check for "proper" colon placement We don't check for segment length or total path length We don't check for "proper" UNCs We still throw for null or empty paths on all platforms or paths of all spaces on Windows (as they throw from the Win32 GetFullPathName) We don't trim leading spaces on any paths on Windows anymore (we did for some, not others) We don't trim whitespace characters from the end of paths on Windows (such as nbsp) GetPathRoot, GetDirectoryName, etc. don't throw for empty anymore, they return null (like they do for null). GetPathRoot now works consistently with various Windows prefixes (e.g. \\?\, \\.\) ``` I'm in heaven.
You would need to sideload a traditional WPF application too. It's just the term for installing software from anywhere but the Store. However that process is more streamlined with UWP. The file extensions (`.appx` and ` .appxbundle`) are automatically associated with the package installer by default, so double-clicking then will give you a simple overview of app metadata and an install button. Alternatively you can also install the application from PowerShell without the GUI "Wizard" or deploy them with GPOs (never tried)
My stack of preference is .net core and angular. For databases I choose sql or mongo or both depending on the size and needs of the project im working on. Sure they both move quickly in versions and features but other than that it's a really performant and robust stack when done with care. To each their own I guess.
&gt; Also having Microsoft ~~having~~ hating? If so, then that would actually be my first guess.
My point was that that's exactly how UWP "setups" behave - except more consistent.
There's a lot of irrational hatred towards anything with a Microsoft stamp. That said, Python / Django is a lot easier to use than ASP.NET MVC which can be a bit verbose.
Yes, thanks!
asp.net core is just a framework. dot net core is the runtime. there are plenty of applications you can make that are non GUI (i.e. "console" apps). a lot of which you use every day: git, nuget, etc.
it is known khaleesi
For begin you can see a course on MVA and late you can see a sample on GitHub.com/Microsoft 😊 
Idk, I stay away from that sub for the most part. Probably because they're a bunch of bootcamp grad hipsters who think JS is the master language 
You should consider this upcoming feature (which you can already implement in .net core 2.0) https://blogs.msdn.microsoft.com/cesardelatorre/2017/11/18/implementing-background-tasks-in-microservices-with-ihostedservice-and-the-backgroundservice-class-net-core-2-x/
&gt; Significantly faster directory enumeration Nice, I always thought directory enumeration was weirdly slow in .NET
[removed]
Very interesting. This is exactly what I’m looking for. The only concern I have is it seems that the tasks only run for 5 seconds by default. Do they continuously loop or is it just a one time action?
But this is a bad excuse! :) Go [Nancy](http://nancyfx.org/) if you dislike verbosity*. * Which I personally think is more about flexibility and being opinionated so that your project will scale. Nancy or that fun ad-hoc Python framework like Flask is perhaps nicer for small projects but you instead need discipline to keep your project together and following known good practices.
Thank you, I'm gonna have to look into this. One thing I forgot to mention is that the server side will need to read/write access to the Windows server that it lives on. However, only to open and run an exe (CAD software) do a few commands inside CAD software (Already finished that part using the CADs API), and print some PDFs back to a shared drive on the network. Is this still possible with WebAPI? 
I didn't get any errors, that's the stupid thing. Sounds unbelievable but output didnt give me any. I also have it working again with a previous VS version so i cant give any more info sadly
Look on StackOverflow.com for industry trends. Django is a CMS written in Python, so we're taking about multiple different things here. I don't code in Python, never learned or used it yet. But you can't go won't even it according to even just trends and stats. Python is heavily used in all areas of tech - datacenters, desktop, web, mobile, embedded. You can't go wrong. Depends on what you like. Personally, I've always gravitated towards the c-syntax languages like C, C++, C#, Java. But those languages, their popular supporting frameworks and ecosystems plus the endless expanse of tech they touch, could fill *many, many* lifetimes of careers. Depends on what you like. Focus on that, then chase the market. 
case in point to this, Square-Enix just issued temp bans to a bunch of accounts where people transferred servers on FFXIV because they used debug tools to edit a server's ID to match one that was locked (certain servers get locked at times for player balance) and were able to transfer to that locked server while it was still locked. That's basic stuff, the backend checked locked servers and only returned the unlocked ones to make the drop down list, but never validated that the information that came back was still valid before performing an action. If SE's web developers had a security mindset this never would have been an issue because when the request was posted it should have been thrown back saying the server is currently locked, you can't transfer there at this time. Instead of just blindly trusting what was still available on the front end.
Sorry for the delay - here's a sandbox example of how I implemented everything. -TokenService.cs public class TokenService : ITokenService { private readonly TokenConfig _tokenConfig; private readonly IAuthRepository _repo; private readonly UserManager&lt;ApplicationUser&gt; _userManager; public TokenService(IOptions&lt;TokenConfig&gt; tokenConfig, IAuthRepository repo, UserManager&lt;ApplicationUser&gt; userManager) { _tokenConfig = tokenConfig.Value; _repo = repo; _userManager = userManager; } // Creates and returns both JWT and Refresh Tokens public async Task&lt;Object&gt; GetTokensAsync(ApplicationUser user, string clientId, string scope, bool rememberMe) { if (true) //verify client exists here { var now = DateTime.UtcNow; var jwtExpiration = TimeSpan.FromMinutes(30); var accessToken = BuildJwtToken(user, clientId, now, jwtExpiration); var response = new TokenResponse { AccessToken = new JwtSecurityTokenHandler().WriteToken(accessToken), TokenType = "Bearer", Expiration = (int)jwtExpiration.TotalSeconds }; if (scope == "offline_access") { var refreshExpiration = rememberMe ? DateTime.UtcNow.AddDays(30) : DateTime.UtcNow.AddMinutes(60); var refreshToken = await BuildRefreshToken(user.Id, clientId, now, refreshExpiration); if (refreshToken != null) { response.RefreshToken = refreshToken.Id; return new { access_token = response.AccessToken, expires_in = response.Expiration, token_type = response.TokenType, refresh_token = response.RefreshToken }; } return null; } return new { access_token = response.AccessToken, expires_in = response.Expiration, token_type = response.TokenType }; } return null; } public async Task&lt;Object&gt; RefreshTokensAsync(string token, string clientId) { var refreshToken = await _repo.FindRefreshToken(token); if (refreshToken != null) { if (refreshToken.ClientId == clientId) { if (refreshToken.ExpiresUtc &gt; DateTime.UtcNow) { var user = await _userManager.FindByIdAsync(refreshToken.Subject); if (user != null) { bool rememberMe = false; if (refreshToken.IssuedUtc.Date.AddDays(30) == refreshToken.ExpiresUtc.Date) { rememberMe = true; } var result = await _repo.RemoveRefreshToken(refreshToken); if (result) { var model = await GetTokensAsync(user, clientId, "offline_access", rememberMe); if (model != null) { return model; } } } } } var removeResult = await _repo.RemoveRefreshToken(refreshToken); } return null; } public async Task&lt;bool&gt; RevokeTokenAsync(string token) { if (token != null) { var result = await _repo.RemoveRefreshToken(token); return result; } return false; } // Create JWT Token private JwtSecurityToken BuildJwtToken(ApplicationUser user, string clientId, DateTime now, TimeSpan expiration) { var key = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(_tokenConfig.Key)); var creds = new SigningCredentials(key, SecurityAlgorithms.HmacSha256); //add claims here var claims = new Claim[] { new Claim(JwtRegisteredClaimNames.Sub, user.Id), new Claim(JwtRegisteredClaimNames.Jti, Guid.NewGuid().ToString()), new Claim(JwtRegisteredClaimNames.Iat, new DateTimeOffset(now).ToUniversalTime().ToUnixTimeSeconds().ToString(), ClaimValueTypes.Integer64), new Claim(JwtRegisteredClaimNames.Exp, new DateTimeOffset(now).ToUniversalTime().Add(expiration).ToUnixTimeSeconds().ToString(), ClaimValueTypes.Integer64), new Claim(JwtRegisteredClaimNames.Email, user.Email), //new Claim(ClaimTypes.Name, user.UserName), new Claim("client_id", clientId), new Claim("email_confirmed", user.EmailConfirmed ? "true" : "false", ClaimValueTypes.Boolean) }; var jwt = new JwtSecurityToken( issuer: _tokenConfig.Issuer, audience: _tokenConfig.Audience, claims: claims, expires: now.Add(expiration), signingCredentials: creds ); return jwt; } // Create Refresh Token private async Task&lt;RefreshToken&gt; BuildRefreshToken(string userId, string clientId, DateTime now, DateTime expiration) { var refreshTokenId = Guid.NewGuid().ToString("n"); var refreshToken = new RefreshToken { Id = GetHash(refreshTokenId), Subject = userId, ClientId = clientId, IssuedUtc = now, ExpiresUtc = expiration }; var result = await _repo.AddRefreshToken(refreshToken); if (result) { return refreshToken; } return null; } // GetHash helper private static string GetHash(string input) { HashAlgorithm hashAlgorithm = new HMACSHA256(); byte[] byteValue = System.Text.Encoding.UTF8.GetBytes(input); byte[] byteHash = hashAlgorithm.ComputeHash(byteValue); return Convert.ToBase64String(byteHash); } } Hopefully that should get you going. Let me know if you have any questions.
I don't think that skipping "unwanted" files by default is right. Who's to say which files are wanted or not. This could cause a lot of confusion. I get that it is configurable, but I think the default is incorrect.
No idea what's going on in /r/webdev, but speaking as someone who recently transitioned off the typical Microsoft stack (used to use .NET Core, SQL Server, Azure; now use Golang, PostgreSQL, AWS), here are some common complaints that people have with Microsoft/.NET Core: - People don't trust Microsoft. This is perhaps a bit unfair, but Microsoft did shady things for a good two decades or so and only just recently embraced open source. Takes time to earn trust back. - Engineers (myself included) are impatient creatures and generally don't want to wait more than a couple seconds for code to compile. I worked with .NET Core 2.0 for roughly 6 months and found the compiler to be incredibly slow (10+ second compilation times on a machine with 8 cores and 32GB RAM) when multiple, medium sized projects were loaded. Golang, Python, Ruby, Node.js are favorites for a lot of people because they either have very short compilation times or no compilation times at all. - Related to the "people don't trust Microsoft" comment, the open source community for .NET Core isn't there yet. Relatively speaking, it's still easier to find open source libraries to accomplish whatever you need in other languages. For example, real time messaging - I count 4-5 different production grade websocket/long-polling libraries for Golang, where we only have an alpha version of SignalR for .NET Core. - Frustrations with various things that haven't been ported to .NET Core yet, especially libraries / services related to Azure. - I think the .csproj/.sln project format puts a lot of people off. It's better with .NET Core, but the reaction most new engineers at my job have when they see these files is still: "why are they needed / what do they accomplish?" I have roughly 5 years of experience with .NET stuff at this point, and I still don't know why we have them either - .NET Core should just have one file for solution dependencies and that's it. No need to have a "project" concept at all; namespaces and folders do just fine. 
Hey @panagiac I am also struggling with CefSharp with another issue, would you mind throwing a look? https://stackoverflow.com/questions/49180900/could-not-load-file-or-assembly-cerfsharp-core-dll-or-one-of-its-dependencies
If .NET Core existed in a vacuum, it would just have a project.json file. It did in pre-release state, when it basically did exist in a vacuum. But .NET Standard libraries had to interop with .NET Framework, meaning it had to work with MSBuild, so back to .sln and .csproj files. The good news is we got a much lighter weight .csproj file out of it.
I agree that it's *better* in .NET Core, but I still find it unnecessary at the end of the day. Also, given that the .csproj format is completely different using the .NET Core build system, I question just how much interop they were able to achieve without rewriting stuff anyway. It smells like internal politics to me rather than a logical choice, but I could be wrong. I don't work at MS after all :)
You could say it's tribalism, but then asking why people don't use your technology instead of their technology is the same kind of tribalism.
&gt; .csproj/.sln The project file says what to do (if anything) with the files that are in the project's folders. Maybe its a mix of the dependencies and a make file. The initial way the VS use the MSBuild file wasn't great, nothing was included by default, every file needed to be explicitly included. My recollection (from many years ago) is that when the switched to proj files to MSBuild they just ported the persistence to xml that would work with MSBuild. I remember seeing something once along the lines of "they were supposed to port sln files to msbuild, but it was too hard" 
I suggest you check out https://github.com/Lokad/AzureEventStore
 var studentToUpdate = await _context.Students.SingleOrDefaultAsync(s =&gt; s.ID == id); if (studentToUpdate != null) { studentToUpdate.phoneNumber = "123-456-7890"; await _context.SaveChangesAsync(); }
Really? Enumerating files from the root has always been a pain, no one wants "System Volume Information" or "$RECYCLE" and having a list that filters them out isn't guaranteed to always get everything. At least this way it's finally fixed.
This is a little older but are you sure you are retrieving the object from the database first? You should make the modifications on the object returned and make sure you aren't modifying a separate object. https://stackoverflow.com/questions/25894587/how-to-update-record-using-entity-framework-6
&gt; People don't trust Microsoft The MSFT "hate" is wholly unjustified: all companies do shady stuff all the time, but somehow MSFT keeps getting the stick because of some irrational cult behavior. I have far more complains of Oracle (pricing), IBM (quality) and SAP (contract hell). &gt; Engineers (myself included) are impatient creatures and generally &gt; don't want to wait more than a couple seconds for code to compile Three comments: * Absolutely. .NET Core is dogslow to compile and is finally getting the corrective treatment in 2.1; * If .NET Core had been developed like a normal product, we would still not have seen the light of 1.0 -- and it would not have shipped as long as it was that slow. Trade-offs were made and (personally, even though it is certainly annoying) it was a good trade-off; * Sure, your Node app starts immediately: except you have no idea if what you wrote is syntactically correct or not. Again, it's a trade off. &gt; I think the .csproj/.sln project format puts a lot of people off. .csproj for .NET Standard/Core projects is perfectly fine: it is exactly what you described. Format for .sln can be cleaned-up next. And yes, I still see the need for .sln files.
That is a pretty amazing example. Your example makes a really good concept for how it works. I have been using IdentityServer4, and have been finally understanding the OAuth2 specifications. Your code looks really good. Thank you so much for taking the time, it helps a lot with some of the ideas I have!! 
There is no such thing as partial updates in Entity Framework. The whole record is replaced with the object, not just the changed fields. **** If you want partial updates, you have to either use raw SQL or a different ORM. Here is an example using Tortuga Chain: dataSource.Update("dbo.Student", new { id = 3, phoneNumber = "numberHere"}.Execute();
I had a go with ID4 (I mean, I didn't spend more than like 2 days looking at it) and I just thought it was way over complicated and robust for apps that have less than say, 50k users and/or have fully "trusted" front-ends, basically a dedicated angular frontend for a .net core api backend. So what I did was read [this article](http://bitoftech.net/2014/07/16/enable-oauth-refresh-tokens-angularjs-app-using-asp-net-web-api-2-owin/) that everyone throws around with refresh tokens, use the ID4 connect api endpoint form inputs (oauth, I believe), took some pointers from Shawn Wildermuth's jwt example and then added some stuff I thought would be necessary. btw - this is how I get Authorize to work. (this is core 2.0) services.Configure&lt;TokenConfig&gt;(Configuration.GetSection("Tokens")); services .AddAuthentication(options =&gt; { options.DefaultAuthenticateScheme = JwtBearerDefaults.AuthenticationScheme; options.DefaultChallengeScheme = JwtBearerDefaults.AuthenticationScheme; }) .AddJwtBearer(options =&gt; { //options.Authority = Configuration["Tokens:Issuer"]; options.RequireHttpsMetadata = true; options.SaveToken = true; options.TokenValidationParameters = new TokenValidationParameters { // The signing key must match! RequireSignedTokens = true, ValidateIssuerSigningKey = true, IssuerSigningKey = new SymmetricSecurityKey(Encoding.UTF8.GetBytes(Configuration["Tokens:Key"])), // Validate the JWT Issuer (iss) claim ValidateIssuer = true, ValidIssuer = Configuration["Tokens:Issuer"], // Validate the JWT Audience (aud) claim ValidateAudience = true, ValidAudience = Configuration["Tokens:Audience"], // Validate the token expiry ValidateLifetime = true, RequireExpirationTime = true, // If you want to allow a certain amount of clock drift, set that here: ClockSkew = TimeSpan.Zero }; }); appsettings.json "Tokens": { "Key": "supersecretkeythatshouldbechangedinproduction", "Issuer": "https://localhost:XXXXX", "Audience": "https://localhost:XXXXX" }
&gt;- I think the .csproj/.sln project format puts a lot of people off. It's better with .NET Core, but the reaction most new engineers at my job have when they see these files is still: "why are they needed / what do they accomplish?" I have roughly 5 years of experience with .NET stuff at this point, and I still don't know why we have them either - .NET Core should just have one file for all of the dependencies and that's it. No need to have a "project" concept at all; namespaces and folders do just fine. &gt; Tooling is the answer to that. This is where VS shines, although I heard in core it's still lacking
it‘s working here. try to delete all bin &amp; obj folders and the package folder, kill all msbuild instances in the task manager. 
I see. A little confused as to where builderToUpdate came from within the scope of that request. What is the contents of the "FromBody"model - have you checked that to make sure all of the values are being parsed appropriately? 
I really don’t understand complaints about build times in general. Maybe if they took 30s+ I could see myself getting annoyed, but it seems like every time I work on a C# project, I just code, and I’ll compile maybe twice total for a complete project? Once after I think I’m code complete to test the feature I’ve just added, and maybe one more time after that after I’ve made some adjustments based on whatever feedback I’ve gathered from the first run? Maybe part of that is just the fantastic feedback Visual Studio gives you as you type, but like you mentioned, that is a strength of static typing and a compiler in general. Yeah, builds are “long,” but because of the strictness of the language, builds are also rare.
No async?
My guess on this is that the “model” variable is coming in via HttpPost in your ASP.NET Controller. That instance of model probably has Name as null. I’ve gotten burned on this one before. +1 to @grauenwolf for saying you need to load your Entity from the DB, then update that instance of the entity with values from the HttpPost’d model, and then save the entity from the db. 
You need to post the entire object. You're setting the name to null if it's not passed in. Which is the expected and desired behavior. 
My apologies I'm just modifying my code to make it simple and easy to grasp. Should be personToUpdate.
After looking over this and into IHostedService this is exactly what I’m looking for. Thank you!
For a long time .NET development meant working with a monolithic framework, in Visual Studio, on Windows. And usually it meant working for a large company, on a legacy codebase. Its going to take a while for people to come back around, at this point .NET Core is than Flask, or NodeJS.
What version of JDK are you running? I have the same problem and was contemplating uninstalling and reinstalling VS this weekend. 
&gt; That instance of model probably has Name as null. I’ve gotten burned on this one before. One way around that is to ignore any fields that are null when you do the copy. Though that does raise the problem of what to do when you actually want to set a field to null. Another option is to use a `Dictionary&lt;string, object&gt;`, `ExpandoObject`, or some other type that distinguishes between a missing field and a null field. *** Now we have to talk about Mass Assignment Vulnerability. If you have some fields that are restricted (e.g. `User.IsAdmin`), you can't just blindly copy whatever is in the model into the database. With EF, you can handle this by manually mapping fields and ignoring the ones that are restricted. With Tortuga Chain, you can setup a restricted field check. DataSource = DataSource.WithRules( new RestrictColumn("Users", "IsAdmin", OperationTypes.Insert | OperationTypes.Update, user =&gt; ((UserToken)user).IsAdmin)); This code means "On the Users table, the IsAdmin column cannot be written to during an Insert or Update operation unless the current user is an administrator.
&gt; _ctx.Entry(personToUpdate).CurrentValues.SetValues(model); No, you have to copy the values one by one.
I am aware of that. It is a very ugly way of doing it so I asked if there is a way without specifying each specific property. My actual tables have way more than 3 columns so it is pretty absurd to do it that way.
So as long as the connection string is kept safe and handled correctly there is no security risk by not separating database access to a separate project?
Utility classes are an antipattern, but static classes can certainly be used to group/organize pure functions with related functionality. This is probably the better default choice. If an object is state + behavior, and there is no state, why would you artificially create some (ie. an instance of a non-static class) when all you have is behavior?
static fields for pure data. static methods for pure functions.
You can still do that, just implement UserStore&lt;&gt; and friends.
I find that any change, any where at any time seems to break Xamarin 
Thanks a lot for the feedback. Built in implementation of UoW good passes for generic scenarios. If you have complex scenarios (like multitenacy, context switch etc) You should have your own UoW to be able extend it, according to your requirements.
Hey I just passed that exam in January and my two main resources for content were MVA and Youtube. Why do you say MVA is outdated? I don't think it is, actually they already have 10+ hours of video content on .NET Core which will come up in the exam, so be prepared. Also, try the exams available online so you can get a sense of what kind of questions you'll be answering (and some are actually the same!). Good luck!
And UoW itself is simple pattern to start and commit transactions. UoW class itself quite small (you can see it inplementation) So why need to introduce additional dependency.
I was looking into this and it seems very involved (I think I'm about 3/4th of the way through) and figured there might have been an easier way. Thanks mate!
Why do you need 4 libs for web socket? MS has a library production ready already if you don't care about signalr...
What do you define as “pure data”. And wouldn’t you be worried that the data can be modified anywhere?
I think yes, it's ready. We have a open source, ASP.NET Core 2.0 based e-commerce software. It's safe and fast. And for sure it can be used in other projects. 
If you base your implementation on the concrete implementations in entity framework, but reimagine it as dapper code, then you can avoid any pitfalls. The EF code is on GitHub, and easy enough to locate.
I really like how you have created your own implementation of the oauth2 specifications. It looks really interessting - I see you're using Password Grant, which I guess you don't use Client Authroization then? I've been looking a lot into it now, and from your examples it makes it a lot clearer again - Something I like with the oauth2 specifications is the "Scope" which I saw also from Slack can be used a ApiResource and Authrization identifications instead of just using pure Claims. Currently I just use the IdentityServer4 - I read somewhere oauth2 implementation wasn't ready yet (from Microsoft side) but I guess you can always create your own Server implementation. I really got going with IdentityServer4 when I looked away from all the OpenId Connect stuff (took a long time to realise why they try and shove it down your throat). Just out of curiosity - do you use single user authentication, like permissions? I have an idea of how to use it with oauth2 Scope, but I was wondering if you "just" use Claims to do that? 
Have a look at https://github.com/aspnet/Identity/blob/dev/src/Identity/SignInManager.cs Follow the rabbit hole from there. Search for the class called UserManager. See what it calls and so in. 
Have a look at https://github.com/aspnet/Identity/blob/dev/src/Identity/SignInManager.cs Follow the rabbit hole from there. Search for the class called UserManager. See what it calls and so in. _userManager.GetUserAsync(User); This is essentially a service. It gets hooked up in you Startup file. On of the things it does, it hooks it up with your DbContext. It creates a few (10?) tables in your db as well. If you are going to use Identity Server 4 in your stack, its best to put it in its own project and host it alone; then all your own services can connect to it (aka assuming you are on the Microservices bandwaggon). I personally do not follow 80% of the default stuff the MS gives us.. If you follow all of their docs and the accepted practices, you end up with monster spagheti code. Their way only works for simple projects..In enterprise development their way quickly gets in the way. 
&gt; I have NEVER once heard a Linux based developer complain that they wished they could have everything .net core has got. There's nothing we can't do with it. This is confusing. Are you for or against .NET Core?
&gt; I would never go back to windows no matter how cool or advanced it got So even if Windows is better, you will always stay on Linux, because it's better?
Dynamics
That's why I created Tortuga Chain. Not just because EF wasn't doing what I wanted, but also because I wanted something where I could go in and tweak the behavior. 
Claims based policies for permissions. If it’s a dedicated client then there’s no need for client authorization, IMO.
You don't. It was just an example to illustrate the fact that the open source community is active for other languages.
&gt; I really don’t understand complaints about build times in general. Seriously, big SPA projects can take like 5 minutes to build.
I don't know if they "hate" .net core so much as they prefer other technology stacks. Most web devs where I'm from use Macs, target linux over AWS/Heroku, prefer server-side javascript (ie. node), use react/flux/webpack/npm, etc... The the place where ASP.NET core fits into this stack is the server-side web application. Superficially, it wouldn't seem too disruptive to swap out Node.js/express for ASP.NET, but really you're exposing yourself to potential risks, particularly: Vendor lock, and Microsoft's reputation for framework churn. When you invite ASP.NET in the door, you're accepting a lot of additional baggage. ASP.NET is a web framework, which makes it heavy-weight in itself, but it also comes with it's own compiler (for razor templates), its own DI mechanism, its own servers (Kestrel and IIS), it's own package manager, cli tool chain, config file format, etc... most of which is brand-spanking-new and produced by Microsoft^TM. Additionally, the ecosystem steers you toward other choices such as, EF (ORM), Azure (PaaS), Visual Studio (IDE), which are also Microsoft projects. Sure, it's possible mix &amp; match ASP.NET with other independent, non-microsoft components, but generally the developer won't be as smooth. The bulk of the documentation/samples/tutorials online are based on MS technology, so they won't help you should you stray from the prescribed stack. Iven in this new day and age of OSS, Microsoft continues to go out of its way to sell heavily-curated software development solutions. They want to own the dotnet developer experience from end-to-end, and this manifests itself as a very strong "orthodoxy" within the dotnet world. If you like the brand of Microsoft's kool-aid, then you won't have any problems. They'll be happy to give you everything you need. You can take comfort in your decision to use products produced, endorsed, and backed by a giant corporation with lots of money. The other thing you should probably accept is that few of these products *earned* their market-share on merit alone. They're in use because Microsoft endorsed them. So there's a good chance that you're ASP.NET project will be forced to depend on some *inferior* companion technologies. I think this is what deters web devs the most. There's strong pressure to go "Full Microsoft" once you introduce ASP.NET into your stack. If you've happen to quit a job at a "Full Microsoft" dotnet shop in the past few years, you'd be wary of going down this road again.
The big appeal of Javascript is the early phase of the software development life cycle. "I went from zero to MVP in 30 mins, and I deployed with a git pull!" It's sort of like sleeping around without using protection. You have no real responsibilities or long-term plans, and god damn it feels amazing. Then your Javascript project catches gonorrhea, and you wish you had at least used typescript.
/r/jsmasterrace
Hehe, nice analogy :-) What exactly do you need? If it is just for testing. Just run/host it locally. F5 in visual studio will run it. If you want to host it locally, look into install IIS. If you want to host it online, just search for an asp.net host Azure is a battleship, but it also integrates really well with visual studio
You might want to look into VSCode/JetBrains Rider and asp.net core. It will allow you to learn c# and web basics with native software for linux.
I'll probably skip that for now. Part of the "learning" part is dealing with VS for the compile/build/deploy process. .Net on Linux is cool, but there are all sorts of jobs for it on Windows. 8-) I took on a really large 4+ year VB.Net project, just finished it up, and discovered that VB.Net seems to be falling out of favor and all the web app work near me is in C#, so I'm tuning up to follow the money. 8-)
I'd say pick a different course. This is way too broad, especially when you are gunning for an entry level job. Being decent at few things trumps having very basic skills in a lot of things. I recommend you first decide for what platform you want to develop and focus on that skillset. E.g. if you want webdev, focus on ASP.NET - MVC, DBs integration (EF and MongoDriver), Razor, general C# best practices (programming and architecture patterns, etc).
weird experiences*, most leading to migraines.
Definitely not. Things have changed in the last 8 years. It would be covering a lot of old techs and missing out on new features. You would have to take a whole other course to catch all the things you missed, so it would be a waste of time. Hopefully you are not learning VB.net by choice.
Vue.js is great! I'd use async/await though, not sure why people insist on using raw promises so often when most of the time async/await is going to make the code far cleaner.
Counter-point: any job requiring VB.net has a high chance of not adopting any new tech in the past 8 years anyways. Might be better off with an old book so you arent learning stuff that you can't use. This assumes it is for a job, of course. If it isn't for a job I'd HIGHLY recommend not learning VB.net
Thank you. I'll have a look into it now 
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/csharp] [\[X-Post from r\/dotnet\] - Visual Studio 2017 - Stable Yet?](https://www.reddit.com/r/csharp/comments/83bl84/xpost_from_rdotnet_visual_studio_2017_stable_yet/) &amp;nbsp;*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger) ^/ ^[Contact](/message/compose?to=/r/TotesMessenger))*
At my workplace VS 2017 has been the most stable version with an even better installer. And it's been that way for almost a year. Your unfortunate experience is likely an outlier. We use GIT, no idea about TFS.
I have been using VS2017 on our C#/WPF/MVC/WEBAPI multi-project solution with about 50k lines (not huge but decent complexity) without issue since about 4 months after release. We migrated from 2015 to 2017 and it was much less pain than 2012 to 2015 was. We use custom project files and build scripts pretty extensively and automate CI through Jenkins without issue. Should work even better with TFS since there are more native plugins.
Would it be possible for you to spin up a new VM and test it?
You don't have to use Windows with .NET Core. That's the whole point of ASP.NET Core.
I will be the happiest man in the world when we can ditch JS permanently with Blazor. That's the dream.
Very stable. Just don't update your projects to versions that won't build on your build server.
It seems like you mean CMS because you mentioned EpiServer. In which case, Umbraco is by far the most popular .NET CMS.
Works great. They patch it fairly regularly. No more having to wait for massive service packs to fix issues 
We use it extensively, as well the Visual Studio Online Team Services integration for source control, Sprint planning, work tracking, time budgeting etc. It's pretty damned good atm
I started using it recently, and for the most part I like it. Maybe somebody here can help me with my one issue. I run my program in debug mode, and it hits an error, the debugger pauses the program and stops at the line with the problem, and it tells me the error. It's absolutely painful to get in and change the code. Before, when this happens, I would click in the code and could immediately start typing. But now, I click somewhere, start typing, and the screen goes back to the error and my typing didn't change anything. I have to then scroll back up and click in the code multiple times to get it to give me a cursor that will allow me to actually type. It's weird and clunky. I don't know if this is a bug in VS, or it's some behavior that I can disable in the preferences. But it never used to do this. It's annoying as hell. Other than that, VS2017 is way faster than 2015. I know they said 2017 has a lot of performance improvements, but it definitely shows. I'm really starting to like it, other than the annoying debugging behavior.
Upgrading tfs isn't an option? Why?
You should be able to install vs2017 without uninstalling previous versions
2017 has been better for me on day 1 than 2015 after year 1.
VS Community is free.
You should have no problem building from VS2017 to a TFS 2015 server. That was our setup for almost a year until we upgraded TFS and then moved on to VSTS. You will just have to ensure you aren't using any language features that aren't supported in VS2015. For us that was C# 6 features. It's more stable than its predecessors, that's for sure. I've found that a lot of problem we've had center more around our managed desktop environment than VS itself.
We use VS 2017, and to be honest I haven't even needed ReSharper. And until somewhat recently, we were using TFS 2015 (we're on 2017 now). Your projects will build just fine provided you don't use C#7 syntax (inline out parameter declaration, etc.). Anything using C#6 and lower (including the null propagating operator) will build just fine. Oh, and you won't be able to use .NET 4.7.
because i don't know yet if that will affect the build and release agents.
Opinions are like assholes. Everybody's got one and everyone thinks everyone else's stinks. Why waste your time commenting when you have concluded that I am a moron?
Maybe I worded my statements in a confusing manner. I am simply asking if you feel confident you can use it with production applications while integrating with TFS 2015 build agents
Yes, i know this. Regardless, I appreciate your feedback
Thank you. You have given the most helpful feedback so far. I don't know why others think this is a strange question. My assumption is that most people here use VS alone and simply don't care about CI/CD integration. Many to most companies host their systems in house for important reasons. I can't simply put everything in the cloud and have it magically work
It probably will but luckily it's just software and you can just fix it.
I just removed it, because I couldn't tolerate its .NET Core support. I'm using VSCode + its C# plugin for .NET Core development now. It's fast and just works. Also you don't need to download a huge packge (Full VS 2017 is ~ 23 GB) to just work with .NET Core.
I had a shit experience with 2017 when I installed it until a few updates, personally. I’m not really sure why you’re being such a fucking dick to OP. 
No. Are you having issues with the emulators? You should follow this: https://developer.xamarin.com/guides/android/getting_started/installation/android-emulator/xamarin-emulator-manager/
We've had enough issues with 2017 that most of my team has moved to Jetbrains Rider IDE. Some annoyances with it but it is hands down better in my opinion. 
I also had a terrible time with 2017 and have been avoiding it until it got patched up enough. Sounds like it's time to give it another try.
My workplace is using 2017 since last autumn and building on TFS. TFS was migrated to 2017 after developer already used VS 2017. We built VS2017 projects in C, C++, C# and VB.NET on TFS 2015 and we're building it now on TFS 2017. For me, VS 2017 is more stable than e.g. 2015, 2012 and 2010, and that was the case **before any upgrades**. (I didn't use 2013.)
Right, just to be sure, you do know. Net core can also run in Windows right? I work at a company that makes software for pretty big companies and govs and we're using. Net core just because it is portable. It allows us to make use of existing infrastructure but also transition to Linux-based stack. 
I do (see my other response else-thread). Agent "generation" ('15 or '17) does not matter. What does matter is what version of build tools you want to use and what .net version you're targeting. You can even use '17 build tools on the '15 agent, but unless you have native code, you don't need to.
The right answer depends on your experience and personality really. If you are completely new to programming in general I would strongly suggest finding some kind of course. A beginners course that is a couple of years old is probably still fairly accurate. It will just be covering the basics, and those will not have changed a whole lot. UWP is just an evolution of WPF so its foundations are well established, and are not likely to change. If you have experience creating UI in other languages, I would say skip the formal route, and just dive in doing a Google/Bing search whenever you run into something you don't know. Microsoft should have a "getting started" page for UWP, that should be enough to get you going in the right direction. Generally, for myself I prefer the latter option. It is how I learn best. It does have some pitfalls though, it is easy to implement a solution that isn't considered best practice. 
It's not, but most people use either babel or typescript, both of which down complie async support. 
&gt; think the .csproj/.sln project format puts a lot of people off....No need to have a "project" concept at all That isn't true. Well, it may be true in many/most projects it is not true with all. If you are working with a cross-platform project you are going to want multiple .csproj for each platform and then another for shared code. This setup makes such a situation much more simple than it would otherwise be. Like I said it probably isn't very useful for most situations, but for me this is a feature that saves me a lot of time and hassle. This is the thing about .Net it crosses every paradigm and every platform. In order to do this it has to introduce something like the .csproj/.sln split in order to accommodate this wide variety spaces it traverses. Personally, I think if someone uses this as an excuse to avoid .Net they are being rather petty, and most likely are just looking for any possible reason to avoid .Net because they have an irrational avoidance of it. 
Depends on the context. If you are asking out of curiosity that isn't tribalism, that is just seeking knowledge. If you are asking out of disgust then yes that would be tribalism.
&gt; This assumes it is for a job, of course. If it isn't for a job I'd HIGHLY recommend not learning VB.net Why is that?? I'm learning it for college, introduction to programming using VB.net 
Thanks, yeah I'm basically completely new to programming. I've tried to start learning a few times over the years, but something always seems to come in the way, but this year it's been going well so far. I've started doing the MVA and Pluralsight courses on the subject, and they seem to be ok so far, the only problem with Pluralsight is that it uses Blend too much. 
Very interesting, is there any stable release for production ready? Definitely gonna test it later 😁
0.17.3 is pretty much stable. you can try it out :)
Great write up! I’ve been meaning to write something up myself. I just got my API running on GraphQL on a branch over the last few days. It’s been mostly great. Only a Few pain points and that seems to be mostly due to lacking documentation for certain topics. My next hurdle is trying to incorporate Relay compliance so I can use it on the front end - have you had any success there? 
Agreed!
As of now I didn't try relay yet. Currently only focusing on the server side now. But will definitely give it a look soon. :)
I use VS Code for React and other front end projects, would love to use it for .NET Core too. I briefly experimented with it, the only minor annoyance was adding new files and having to manually write out the namespace and controller code, though I suppose that could be resolved by a plug-in. Is that still the case?
Awesome. I'm looking forward to the second post. I'm completely ignorant about the server side implementation of GraphQL, but I'd be interested to see if there's some way to map a GraphQL query to IQueryable to integrate with Entity Framework. 
For the people who pointed out flaws in my post: I updated it, like I announced. It should be more accurate and original now.
Everybody with a job opening near me is Microsoft from top to bottom. I have an entire stack of *nix and various "cloud" projects and qualifications but nobody cares. 
Not sure I get your argument. Like you say, it "isn't very useful for most situations," so at the very least, it should not be enabled by default. Also, as far as I know: languages that support multiple platforms such as Go, Python, Ruby, Java, etc do not have this "project" / "solution" concept and I've personally never encountered a situation where I needed a separate project that targeted some other platform. APIs these days (at least with .NET Core, with Go, etc.) are cross platform compatible, so there's no need to do what you're describing because the code doesn't need to change based on the processor architecture or OS.
I've only encountered this issue when using Angular 2/4/5. I have a large Vue.js project with about 15 dependencies that compiles "cold" in less than 10 seconds (slow, but only happens once), and any subsequent changes take ~300 ms to recompile because of caching. Had similar experiences using React.
Sure, if you're just developing code you don't need to compile multiple times per minute. However, if you work in an environment where continuous testing is applied (where compilation happens often), you would understand the need to compile quickly to see the results of your tests immediately. Or, if you use `dotnet watch`, compilation will happen every time you change a file. In any case, you don't need to make this speed for correctness tradeoff if you're willing to consider other languages besides C#. For example, you can have both speed and correctness if you use a statically typed language like Go which has great linting tools and a fast compiler. Hell, even Java code is apparently pretty quick to compile these days.
I'd be really curious to know how many people actually feel the same way. I don't doubt that you have some use case for this, but my point is that I'm all for sane defaults - if most users don't need this concept, put it in a settings menu somewhere (or expose it as a `dotnet new` flag), but don't force everyone to use it. Like I said, it does negatively affect users when merging code, so I'd rather not see it enabled by default. It may not affect you in the same way, but we'll just have to agree to disagree.
It's stable, but I would use JetBrains Rider over it any day of the week and twice on Sundays. The difference in performance and general productivity is just massive if you've been on VS for a while.
That is a far point, but I think the issue here is more with how it is implemented, which I am not a fan of either, than that it exists.
It would be awesome for the project templates that come in VS to use commented-out options that you could use later on.. for example, "uncomment this line if you want to use MemoryCache/Session/ ResponseCaching/etc".
Well that makes me feel better about the whole thing. Thanks for helping out
It's fully supported by all modern browsers, plus the transpiling with Babel or TS.
Thanks for the great article and for bringing attention to GraphQL. I wonder if I am the only one who has always felt that REST is a leaky abstraction of the transport layer and an unnecessarily tight constraint around an API. Now that it's not such a hot buzzword anymore I wonder if anyone will speak out. Or maybe I'll just get beat up.... LOL.
`p = InStr(Ws, sp)` Looks for the first separator character (`sp`) in the string. What do you do if the string starts with a separator character? 
You can try these extensions for that: https://marketplace.visualstudio.com/items?itemName=jchannon.csharpextensions https://marketplace.visualstudio.com/items?itemName=wilderminds.wilderminds-aspnetcore-snippets https://marketplace.visualstudio.com/items?itemName=schneiderpat.aspnet-helper https://marketplace.visualstudio.com/items?itemName=k--kato.docomment 
so `FirstWord("Hello World", " ")` should equal "Hello", correct? Then `p = InStr(Ws, sp)` finds the space but we don't want the output to be "Hello " so `Left` needs to take one less from the position it found. Now, what happens with `FirstWord("HelloWorld", " ")`? There is no "first word" so it should return everything. `p` is 0 and if we just had `p = Len(Ws)` then when we account for the issue above we'd end up with "HelloWorl" which is not correct, hence the `+1` to compensate. --- Aside: correct me if I'm wrong but this is classic VB not VB.net, yes?
I'll be damned, you're right. This must be a newer update because 6 months ago it wasn't supported afaik
You're supposed to spell it with a $ sign, like: "Micro$oft".
hidden lesson: use good names.
You should ask your instructor why they wouldn't just use string.split instead?
&gt; Aside: correct me if I'm wrong but this is classic VB not VB.net, yes? It certainly looks like it, but it turns out that in .NET `Microsoft.VisualBasic.Strings` has `Trim` and `InStr` methods.
I think you'll get beat up because it's easier to resist change. I am looking to learn GraphQL myself. I have written one API in C# and would like to see how GraphQL matches up to it. 
Are you having trouble parsing the value out of the page? Getting your page to load? More info needed including what you’ve tried, what isn’t working, any error messages, and so on. 
https://docs.microsoft.com/en-us/dotnet/framework/network-programming/how-to-request-data-using-the-webrequest-class
I use Visual Studio 2017 Community daily since the initial release and update it at each release. Never had a problem apart some updates that are really slow to process. Paradoxically, waiting too much to update can be the cause of this type of problems. 
Thank you for clearing it up for me! And yes this is VB.net 
You'll find a lot of programming is solving for the good path and then thinking about all the different ways it can fail and trying to account for those. For instance, the things that popped into my head about this function: 1. What if the search string is an empty string? 2. What if the separator is an empty string? 3. What if the separator is the first character? 4. What if the separator is the last character? 5. What if the separator is not in the search string? In more complicated scenarios, you may run into failure scenarios that your particular function can't/shouldn't account for (if a database connect disappears in the middle of execution, there's not much you can do to protect from that) and that's okay but it's good to think defensively. This is also where automated tests can come in handy: For each of the 5 questions above, you can write a test which gives the function a particular input and checks for the appropriate output. If it doesn't get that output the test fails and you adjust the function to account for that scenario until the test then passes. It also double checks that changing the function doesn't re-introduce the problem again, known as a "regression"
404 error...
just fixed, sorry!
That is almost the solution for all xamarin build issues.
Not GraphQL, but oData offers this feature so I don't see why not.
Yes.
&gt;Using only Arrays and the split(). Why? Sounds like a homework question. What have you tried?
I have no idea how to do it without just using the above mentioned. I could just do this: s = Regex.Replace(s, " {2,}", " ")
Is there a reason you can't use normal string operations? Replace is a function on all strings that does a literal match on a substring and replaces it with a given substring. If the question is explicitly about using the split() operation on Array, then I hope you have at least taken a test string or two with excess spaces, called split(' ') on it (with a single space as the character you split on) and looked at the output....
Do you know what split() does? It's perfectly-suited for this task.
I'm assuming you'd like to do this to improve performance? Super simple: public static string RemoveDoubleSpaces(string phrase) { var array = phrase.Split(default(string[]), StringSplitOptions.RemoveEmptyEntries); return String.Join(" ", array); } Voila!
Use VS 2017 at work with Windows 7 and while I use it for day to day coding, it feels like an unpolished product. Intellisense breaks when switching Git branches, have to delete the privateregistry.bin files every couple of days, etc. Frankly I’m surprised how many people are happy with it in this thread.
We have a monitor/dashboard at work and we have a browser with several tabs and a chrome extension that cycles through the tabs. The tabs include: * New Relic APM to show performance data . * Jenkins CI job , specifically showing the last unit test run. * Pending Github pull requests. * Infrastructure metrics on our prod servers (cpu, memory etc) The goal is to provide a HUD for anyone in the area or folks walking by to take notice. While we do have alerts in place, many times we've noticed errors on the dashboard and it has really saved our butts.
Had the same experience on Windows 7 until 15.4 or 15 5 was released. The current version is stable. At least as far as it can be on Win7.. All in all our anti-virus and instable drivers for Windows 7 contribute to a messy experience. I really hate going in to work to be greated by bluescreens... The messy proxy config, SVN and overall Network Reliability make my days rather less productive and enjoyable. I feel like I could get at least double if not more work done on my PC at home..
Really like the idea with cycling tabs. Also the pull requests. 
&gt;My assumption is that most people here use VS alone and simply don't care about CI/CD integration. Well I don't think it's that. It's that VS2017 can target different versions of the .net framework and as long as your build tools on the CI/CD server supports the code you should be fine. We don't use TFS, instead run MSbuild on Jenkins and although we upgraded to VS2017, we still stuck with MSbuild 2015 for a while with no issue. We just had to ensure that developers didn't use any of the new language features and if they did, the CI build would break and they would be reminded. Since then we've updated to msbuild 2017 with no issues and yeah we've been using Visual Studio 2017 for local development for a year and building against msbuild2015 and later 2017 to release production builds.
I'm actually looking at this forum today because I'm trying to solve this problem. I want to learn .net core. I've got the basics of nodejs .. took me a month of work on a online course which is two years old but everything in it was rock solid. It's a lot of fun coding with nodejs. On the other hand, I got offered an interview for an entry level webdev position that uses c# .net. I honestly haven't talked to the tech guy yet so I don't know what their exact stack is like but I assume it's one of the many versions of asp.net. So I've been searching for good learning materials. Unlike nodejs, I can't find any. I've looked at multiple courses, they were all outdated. Which tells me that every time M$ creates a new version, they break everything. In fact, here comes 2.1 .. so even if I do find .net core 2 material, it'll be outdated in a month. I've mostly given up for the time being and I'm just hoping that the stuff I've been studying with the Mean stack is going to be enough to get me the job. (no Mean stack jobs around.. 90% of the web dev ads I read are php) And, like I said, it's fun. Most fun I've had outside of game programming.
This is nice! Wonder how hard it would be to do something like this, but with a paired client dotnet app.. Instant file sharing, or remote shell type apps
I'm really stoked about this. 🙌🏽
We developed it on Windows, because we've used ASP.NET MVC before, but our contributors are developing it also on Linux now, since it's possible to run it on Linux and Mac. You can look at it here: https://github.com/grandnode/grandnode
 WebClient client = new WebClient(); string downloadString = client.DownloadString("https://blockchain.info/tobtc?currency=USD&amp;value=11000"); string n = "nand"; Console.WriteLine(n); This is what im trying.
@{ WebClient client = new WebClient(); string downloadString = client.DownloadString("https://blockchain.info/tobtc?currency=USD&amp;value=11000"); Console.WriteLine(downloadString); } I am getting a parse error atm.
I will give this a shot!
Looks like you’re running that code in a Razor view and probably getting a syntax error. Hard to say without the specific error message. Could it be that you need to add a using statement for the namespace that WebClient lives in?
so what should i use to output the text? I apologize im still learning.
We hugged it to death :(
Thank you!
It's fine, but hold off on major releases until a bugfix release or two. VS2017 15.6 hangs for me on both ending debugging and closing VS. Didn't have many issues with previous versions of VS2017, I assume they'll get the quirks in 15.6 resolved soon. My main PC is still on 15.5.x, and I'll leave it there until they resolve the issues.
so...we're going to blacklist this site now that it's spammed our sub, right?
VB.Net would be fine if its your only option. It's sucks that the college is so out of date, but that's not unexpected. Take a C# class if they have one available instead. Otherwise, python is a great choice too.
It really doesn't matter. I think the only real thing you need is a good readme.md in the root folder. Everything else is up to you. People are simply going to clone down the repo and launch the .sln.
It’s up too you really. As long as it isn’t confusing and makes sense; no structure is a bad structure. If you start toward building larger projects, the separation into different folders help organizes things as your root becomes more of a container to split into say script folders, config folders, etc. 
[removed]
Great thank you! I'll make sure to include a good read.me.
Thank you, I'll evolve the structure as needed then.
Make sure to add the Visual Studio .gitignore file before committing to GIT. https://github.com/github/gitignore/blob/master/VisualStudio.gitignore
I like that the .sln file goes in the src directory, it makes it more visual studio friendly. I'll see what I come up with and we can share notes :)
Good point, thanks :)
Thanks for linking to it, will add.
[This](https://gist.github.com/davidfowl/ed7564297c61fe9ab814) is a common file structure for GitHub projects.
Thanks. I read through this earlier but didn't think a consesus had been reached. I'll definitely be referring to it though.
&gt; default(string[]) That caught my eye. I just double-checked and `default(string[])` evaluates to `null`. But, if you replace that with `null` as the first `Split()` argument, it's a syntax error. What is this magic?
Might take a look at some of the open source Microsoft projects, but they break their own conventions now and then.
I never think about it. VS and the github extension does everything for you. No need for anything manual apart from pushing.
So, we're using the implementation of `String.Split()` that takes these arguments: `String.Split(String[] separator, StringSplitOptions options)` &amp;nbsp; The `separator` parameter tells `String.Split()` to use all of entries in an array to act as delimiters to split on, but if you include no items in the array, you can use a StringSplitOptions enum property to specify more complex split operations. &amp;nbsp; So, as the `options` parameter allows you to pass an enum property from `StringSplitOptions`, we can use something like`StringSplitOptions.RemoveEmptyEntries`, which is responsible for telling `String.Split()` to remove any contiguous spaces--an operation more complex than splitting a phrase based upon an array of delimiters, because you can only pass static values to the array, such as two spaces, three spaces, etc. &amp;nbsp; As far as the code sample from you WPF testing app is concerned, the value is null because you are trying to instantiate a new object, but the default keyword isn't designed for instantiating objects--it's specifically for passing the default value of Type as a parameter without having to instantiate a new object. &amp;nbsp; Whew! That was a little lengthy, but I hope it provides some clarity!
I'm using visual studio only and a local build agent that I setup with 2015. Some people have started to use only 2017 and it doesn't seem to have caused any issues with the build agent. I haven't added any projects that were initially created in VS 2017.
Not the prettiest, but more efficient: private static string JoinWhitespaces(string input) { var result = new char[input.Length]; var isInWhitespaceBlock = false; var length = 0; for (var i = 0; i &lt; input.Length; i++) { var ch = input[i]; if (ch == ' ') { if (isInWhitespaceBlock) { continue; } isInWhitespaceBlock = true; } else { isInWhitespaceBlock = false; } result[length++] = ch; } return new string(result, 0, length); }
&gt; EDIT: Note that default(string[]) should yield an empty string array, not null. You might want to see what's going on there. This is wrong. `default(string[])` returns null because array is a reference type. You must be thinking of `Array.Empty&lt;string&gt;()` 
Mac user, .net developer. I love DNC and being able to build my APIs on my Mac. Before I would host a VM to run Visual Studio on, so my workflow is way better now. I’m using DNC at the office as well but on a PC w/ Win 7. On the Mac I like it better , mainly for having native Bash terminal support and multiple terminals at once. Using DNC has been way better than doing Java on the Mac. I don’t know everything just feels snappier.
Yes, you’re right, I didn’t thank that through. The reason that `null` can’t be used in place of `default(string[])` in the context above is because `String.Split()` requires the type to be known for the `separator` even if it’s `null`. By passing `default(string[])` instead of `null`, you’re explicit declaring a null string array, rather than a completely null value.
Put me down as a 'me too' for everything /u/chuchurocka said.
&gt; mainly for having native Bash terminal support and multiple terminals at once. just use wsl. &gt; win 7 doh, no wsl for you :(
And stuck with corporate IT managing our machines :/
I generally use gitignore.io to supplement the standard ignore file. Also helpful if you know all the tooling you want to use.
WSL is really slow on my work machine and it's no slouch. While I appreciate that it allows me to bring along my Linux knowledge, I don't feel like it's a complete replacement for a native Bash terminal.
https://github.com/bolorundurowb/shortid/blob/2a6542a04b6bd7b3ee19d985ed73e880cf304a9a/shortid/ShortId.cs#L105 Why 20? https://github.com/bolorundurowb/shortid/blob/2a6542a04b6bd7b3ee19d985ed73e880cf304a9a/shortid/ShortId.cs#L54 Building the pool again and again for every id is bad design as it is unlikely that the pool will change during application run. https://github.com/bolorundurowb/shortid/blob/2a6542a04b6bd7b3ee19d985ed73e880cf304a9a/shortid/ShortId.cs#L27 https://github.com/bolorundurowb/shortid/blob/2a6542a04b6bd7b3ee19d985ed73e880cf304a9a/shortid/ShortId.cs#L69 `Random` is not thread safe. ---------------------------- **Now lets look at the API** static string Generate(int length) static string Generate(bool useNumbers = false, bool useSpecial = true) static string Generate(bool useNumbers, bool useSpecial, int length) static void SetCharacters(string characters) static void SetSeed(int seed) static void Reset() First, let's clean up overloads. I've left the default parameters alone, but note that in libraries they have one nasty surprise - the default value is compiled into assemblies that call them, so if you change default value but do not recompile assembly referencing your library it will keep using the old default. static string Generate(bool useNumbers = false, bool useSpecial = true) static string Generate(int length, bool useNumbers = false, bool useSpecial = true) static void SetCharacters(string characters) static void SetSeed(int seed) static void Reset() You can set used characters, but can't get them. You can also add numbers and special characters to the pool by toggle. Personally I see this as a conflict that doesn't really bring user anything extra - if user wants different character set, let him define it as a whole, so let's remove the shenanigans with numbers and specials. static string Generate() static string Generate(int length) static string Characters { get; set; } static void SetSeed(int seed) static void Reset() Now we still suffer from inability to use multiple pools in the same app. We have different options for this, but I'd go with putting the pool as a parameter to `Generate`: static string Generate() static string Generate(int length) static string Generate(string characters, int length) static void SetSeed(int seed) static void Reset() The only state is the `random` instance now. This can produce unexpected behavior when running in multiple threads. Let's do what `Random` does by making this non static and immutable: ShortId() ShortId(int seed) string Generate() string Generate(int length) string Generate(string characters, int length) You could also provide thread safe static methods so that you don't force user to allocate more garbage with tradeoff that they can't choose the seed: ShortId() ShortId(int seed) string Generate() string Generate(int length) string Generate(string characters, int length) static string Generate() static string Generate(int length) static string Generate(string characters, int length) Implementation of the static members should look like this: private static readonly ShortId instance = new ShortId(); public static string Generate() { lock (instance) { return instance.Generate(); } } .... --------------------- Alternatively why not piggyback on the `Random` itself and rename the package to `RandomString` static string NextString(this Random random) static string NextString(this Random, int length) static string NextString(this Random, string characters, int length) As bonus points you could also provide static string GetString(this RandomNumberGenerator random) static string GetString(this RandomNumberGenerator, int length) static string GetString(this RandomNumberGenerator, string characters, int length)
yea it's definitely got perf problems, especially with the filesystem. that being said, though, it's certainly nice to have anyway.
Linux C++ developer. Embedded video processors. We use C# for some of our automation. LINQ Is fucking awesome. The "infrastructure" part of .Net is very well done, IMO. Reflection is stupidly useful. Async/await is powerful, can't wait to get that in C++. There are parts of C# that make no goddamn sense (the design of Stream and lack of multiple inheritance annoy me the most in recent history). Lack of standalone functions bug me a bit as well (static classes to the rescue I guess). As for .Net and Core - it's like they realized that MSBuild was waaaay more complicated than it needed to be, so they swung to the other ditch and his everything behind the `dotnet` command. 
Stream kinda sucks, but the lack of multiple inheritance is a blessing. It causes so many stupid bugs. Look into using interfaces with extension methods.
Just out of curiosity, what don't you like about Stream? 
Or...or...know what you could use? NuGet!
When we upgraded TFS from 2015 to 2017, I kept our 2015 build server. All I had to do was reconfigure the agents to point to the new TFS instance. Once I got everyone over the hurdle of a new version of TFS, I set up new 2017 agents to take full effect of the 2017 features. 
Might be the most important response in this thread. We use some custom agent activities and i wasn't sure if they would still be there for 2017. So basically, I can keep the TFS agents in 2015 and upgrade the main TFS instance to 2017 with no issue. Correct?
I've actually got my eye on Xamarin. Being able to bring my C# knowledge to mobile development and shared code between OS's is really appealing.
&gt; lack of multiple inheritance annoy me the most in recent history Composition over inheritance. 
It can be incredibly frustrating not having interfaces for Stream. That's my only complaint about it, not sure what others complain about. 
&gt; Lack of standalone functions bug me a bit as well Do you know `using static`? It makes calling a static method *look* like calling a standalone function.
I like David Fowler [.NET Project Structure](https://gist.github.com/davidfowl/ed7564297c61fe9ab814) - can be easily built up and it fits almost all project types.
Yes, I know about it. Still feels like a hack. 
Well the big one is that the base class has *everything* and some things throw when the real Stream can't do that. Like it makes no sense for the base class to have a `Seek()` method unless *all* streams can seek. 
For the most part, I agree with this. There are times when it's nice to be able to do MI - sometimes it leads to less duplicated code. 
I believe in our case, we stood up a new 2017 instance and then imported/migrated everything from 2015. All of our build and release definitions were there. The only thing missing were agents in the pools/queues. We have a separate team that manages TFS, so I can't speak specifically about the process there, but from a user perspective, it was painless. Without knowing more about your agent activities, I can't say for sure, but in our case, everything was there. I had standard stuff: nuget restore, msbuild, execute command line (for .Net Core), execute powershell (for creating and replacing environment specific tokens), VSTest, etc. 
Wow, what? What's the full syntax for that? Sounds nifty.
`Microsoft.NETCore.App` is the new `Microsoft.AspNetCore.All` which is introduced with V2.1 SDK. More info: https://github.com/aspnet/Announcements/issues/287
[removed]
[removed]
https://docs.microsoft.com/en-us/dotnet/csharp/language-reference/keywords/using-static
~&gt; ConEmu
&gt; Using a local folder as a feed will not work and copying every version manually is a lot of work. Then use a network share. This isn't a hard problem. 
https://github.com/NuGet/NuGet.Server
I started with .NET on Linux, in the early Mono days. The Mono community was great and C# was fantastic, right from the start. C# is getting better every release. I like F# too but Microsoft hasn't been so good at supporting it. .NET Core has been good to me so far but it is another case of Microsoft hitting a soft reset button and then actively supporting both the new and the old. The whole situation around Core, Framework, UWP and the various projects surrounding it is messy. Last time I checked there was no support for developing for .NET Core on FreeBSD so I haven't used it for some ob my own work. My worry around .NET Core is that once Microsoft decides that they're not into open source and cross platform any more, they'll let it die a slow death.
thank you, i will check it out when i have time.
I don’t understand what do you really want? To learn something without putting any time into it? Sorry but the technology from the movie Matrix where you just download the knowledge to your brain does not exist yet...
Microsoft actually admitted F# is mostly community driven.
It's just like doing #include
Know the feeling. Also struggling with freaking Win7 in 2018. Sucks.
&gt; […] if you also want to allow the use of LINQ, there’s no escape from implementing interfaces. I don’t get it. LINQ is as pattern-typed as `foreach` is. More so, maybe, because it takes into account extension methods. Create `Select`, `Where`, &amp;c. methods, and the keyword syntax works. 
i would argue \(nicely argue\) that stand alone function is a hack. it's a C compatibility thing in my mind. But I also use other languages. So I use C, C\+\+, C# and F#. They all are structured differently but when i use C\+\+ or C# i don't want stand alone functions, they seem too out of place.
You have to host it yourself and pay for the server. The point of the post is to do it for free.
i admit, i am being pedantic but it is native Bash. WSL doesn't run on top of your win32 it is a separate subsystem. There might be performance issue but the reason they call it Ubuntu \(or whichever you use\) is because it is Ubuntu. \(for anyone that cares\)
No, i dont wanna learn it. I just wanna build my application with my basic knowledge. Think like OpenCart. I don't know how to build a website. But thanks to OpenCart, it was easy. I wonder if there is something similar to it for web application. like templates. Since im more familiar with asp.net than others. I asked for it. I thought i was clear. My bad.
Heads up with automapper. Only use it if you are loading a page worth of info. It's much slower then mapping by hand, so if you don't have appropriate paging strategy that is run before automapper kicks in, you will see user experience impacted. Otherwise it's great
Part of the reason is explained by Jon Skeet, see the section 'The Elephant In The Room' in this post http://btburnett.com/2017/12/who-says-c-interfaces-cant-have-implementations.html
It's free. The costs are absolutely no different to your proposed soluton.
Use Braintree (made by PayPal) for PayPal payments
No, I still don’t follow. The claim is that if you want LINQ support, you must implement interfaces. This is simply not true. Try using the keyword syntax on a type that doesn’t support LINQ, and Visual Studio will tell you what shape of method it's looking for.
This site needs banned from reddit for spamming garbage code. The purpose of this article doesn't even make sense. It checks for the existing of an item then manually sets an index. No one should be following this guy's advice because its all sloppy code. 
Maybe I'm missing something here. This project is open source but it's still a web application I have to host myself.
Let's say that I want to build my project on my work PC. I can just clone the repo that I use for the feed. This way it's accessible anywhere. Was that not clear from the post?
Thanks. I can use a foreach loop if I pass the data from the controller but i am looking to fetch the data from the API end point instead. Is it possible to do something like that? I'm trying to do that because i was doing Mosh Hamedani's MVC5 course and he said that it is better to make api calls on the page and let the html mark up be generated on the client side rather then generating the complete mark up on the server and then sending it over to the client. 
I agree. I was stoked when I first learned about `using static`, but then quickly realized that all it did was obscure where the method came from.
Putting binaries into a repo? That's usually a no-no. Just use the nuget server. 
I'm sure it's great and all but no I am not a fan. 
Why wouldn't I just use the other stuff that's already out there that works with Linux. Too many to name (and yes some are cross llike C, C++, Python, Ruby, Java, Scala, Node.js, etc etc. Sure some work with windows, but then I would have to deal with windows. Give me a console in black and white and one that DOESN'T allow spaces, please. 
Because C# is an absolute pleasure to work with. And the tooling is pretty amazing. No one's saying you have to use it. It's just that you can.
You create the UI manually. **Think of everything as URLs.** Your screenshot has these "options" for viewing the list differently. * 3 Listing Types (All, Auction, Buy It Now) * Sort Type * View Mode (Grid, List) * Guaranteed 3 day delivery (boolean true/false) So if you construct the UI based on those attributes (with **default query string** values), it'd be something like this. ~/my-listing ~/my-listing?listingType=1 ~/my-listing?listingType=2&amp;sort=1 ~/my-listing?listingType=1&amp;view=2 Based on the incoming HTTP Query String parameters, your **MVC Controller** class retrieves records from the database accordingly. &amp;nbsp; For user interaction (e.g., changing **Sort** option), you have two options. * old-school way of doing things (i.e., URLs with different query string parameters) * client-side JavaScript framework like ReactJS or AngularJS etc. 
Just use a VPN and a network share.
Can't you just make the API call in a controller, return the results and then use a loop in the razor page to populate the page? 
Wait. Can I use Memory&lt;T&gt; to skip Marshal.Copy(...) if I want to access unmanaged memory?
&gt;the design of Stream could you elaborate on that?
You're right, I mis-understood your question. I don't quite get what the author is saying there.
If you are going down that route, it'll take longer to implement. If you are doing this for a school project, you need to get it working and move on. Otherwise, you won't have time to complete the project. &amp;nbsp; It is not worth spending the extra time implementing it via AJAX if this is just for a school project. You have more important stuff to finish.
It wouldn't be, just using an API rather than a dbcontext. Are you asking how to use the API from inside the view rather than a controller? Because I'm not sure that would be the best way to do things unless you had a very specific reason why. 
VSTS has package management which is for hosting for packages and symbols. They have nuget capabilities and I’m pretty sure it’s included in the free 5 user deal
Awesome!
So to me it looks like you've got the NotifyOfPropertyChange on the ToolData which will notify the View when the value of SelectedTool changes. However, you don't have a NotifyOfPropertyChange on the ToolData.ToolID property so the UI does not get any notification when that value changes.
What about making your ToolData class an observable object?
&gt; public class ToolData &gt; { &gt; public string ToolID { get; set; } &gt; public string ToolDescription { get; set; } &gt; } Based on your code in your original post, I would expect something more like this: public class ToolData { private string _ToolID; public string ToolID { get{return _ToolID;} set{_ToolD = value; NotifyOfPropertyChange(() =&gt; ToolID);}} public string ToolDescription { get; set; } } EDIT: I'm terrible at reddit formatting but my point is that ultimately, the setter of ToolID needs to fire a notify since that's what your changing with this bit: SelectedTool.ToolID = DBDataTable.Rows[0]["id"].ToString(); I haven't done WPF myself so this is coming from my Xamarin experience, but a lot of the MVVM principals are the same.
It's pretty easy to integrate NServiceBus with other systems. I integrate it directly with SQL just by posting JSON messages in the queue table (using SQL transport) but the same is possible by just sending message to RabbitMQ Here are a couple links that might help you: https://docs.particular.net/samples/rabbitmq/native-integration/ https://docs.particular.net/samples/sqltransport/native-integration/
Maybe so, maybe not. It depends on what your code standards demand. If you feel more comfortable, you could create a separate property in your ViewModel called ToolID that fires a notifypropertychanged and then set it's value from your model's ToolID. Following this idea, you would no longer be doing any direct bindings from the view to your models. Honestly, now that I think about it that might be the better practice in terms of stricter separation of View and Model, but it does kind of feel like your just duplicating your data a bit.
Yeah, that would definitely work. I was just hoping to be able to use a class created in the Model so that I can avoid creating 10 properties for this one page. I'm creating a single window application using the TabControl. Having a million properties within the ViewModel may just be the nature of the beast with this type of application though.
You did trigger a thought which seems to be a **solution**. Instead of editing the properties of SelectedTool itself, I create an instance of ToolData, fill the data, then replace SelectedTool's value with the new instance of ToolData. This fires SelectedTools NotifyOfPropertyChange and updates the text box. public void TCOSubmitID(string tcoToolID) { SQLiteCommand DBCommand = new SQLiteCommand("SELECT id, description, manufacturer, model, serial, track_cal FROM inventory WHERE id=@toolid"); SQLiteConnection DBConnection = new SQLiteConnection(Properties.Settings.Default.db_connection_string); SQLiteDataAdapter DBDataAdapter = new SQLiteDataAdapter(DBCommand.CommandText, DBConnection); DBDataAdapter.SelectCommand.Parameters.AddWithValue("@toolid", TCOToolID); DataTable DBDataTable = new DataTable(); DBConnection.Open(); DBDataAdapter.Fill(DBDataTable); DBConnection.Close(); ToolData selectedTool = new ToolData(); selectedTool.ToolID = "Test"; SelectedTool = selectedTool; ViewIndex = 1; }
This would also work and may be appropriate for your use. The only thing to keep in mind is if you want to change the values of any properties of selectedTool and have your view update, you will have to create a new instance every time.
`using static System.Console;` for example. Then you could call any static method within `System.Console` `WriteLn("Foobar");` vs `System.Console.WriteLn("Foobar");`
Generate a correlation id for each task and include it in the log messages. You can then filter on that id when reading the log.
You could always log the ID of the thread which performs specific tasks.
Some logging frameworks make this easier by allowing you to attach information to the logical call context, which supports flowing through async call chains.
Threads are pretty meaningless in async environments. Parts of the same method may run on multiple different threads, multiple different calls may run interleaved on the same thread, etc.
I use AutoMapper a lot. Especially mapping between domain layers.
Wow! I've been looking for something like this to simplify my workflows. The python support looks promising. Is tensorflow supported? Also, is my data protected? How can I transfer it to the model to train it?
Hey there, those are great questions. We've had a lot of interest in tensorflow support and it's coming very soon! For data hosting we're recommending S3, or you can simply upload a gzipped file as part of your application. Of course S3 will be far more performant. We put great focus on security, so you're data is secure. Any of your code is running in an isolated environment protected by a hardened OS, SELinux, seccomp, and containerization technology. Also your code is not co-hosted with anyone else's code. We really wanted to just stick everyone's code in co-hosted containers but the fact is that the kernel is just not secure enough. Take a look at this for example: https://bugzilla.redhat.com/show_bug.cgi?id=CVE-2017-5123 
He wants what every aspiring new dev wants - a sample project with gruntwork done. 
Hey I love .NET Core on my mac. Jetbrains Project Rider is a fantastic tool.
This looks really useful for background tasks in a web service but how can I use it to host my webservice without configuration files?
Another great question, the only thing stopping you from full-blown web deployments at this time is the ability to receive inbound traffic from the network. We had prototyped support for it but don't feel comfortable releasing until the security implications are fully understood. Take a look at this docker bug as an example of this potential issues: https://github.com/brthor/docker-layer2-icc In summary, full-blown hosting (and something even better) are coming very soon.
That article was not written by Jon Skeet, it just uses the same skin as Jon's blog. :-)
Sure, but if you want to use LINQ with a custom type that doesn't implement `IEnumerable&lt;T&gt;`, you would have to reimplement all of LINQ yourself. So it's not really practical in most cases.
That, just like basic HTTPlogs do with request and response.
&gt; Local variables are allocated in the stack. Not always, for example local variables in `async` methods or local variables that are accessed from a lambda are usually allocated on the heap. And that distinction is important when you're talking about `ref struct`s.
I don't think you can slice a list directly, because it is of variable size, and automatically reallocates. You can do `ToArray()` on a list, or have your method take an array, or even better, have your method take a Span. Then instead of `.Skip().Take()`, you just `.Slice()` your span. Your action of course also needs to take a Span.
Yes, but you have to wrap that unmanaged memory in a class that inherits from [`OwnedMemory&lt;T&gt;`](http://dotnetapis.com/pkg/System.Memory/4.5.0-preview1-26216-02/netstandard2.0/doc/System.Buffers.OwnedMemory'1) ([example](https://github.com/dotnet/corefx/blob/9cde05f/src/Common/tests/System/Buffers/NativeOwnedMemory.cs)). This means that you're still allocating a manged object, but only a small one, and you do avoid the copying.
Thanks for taking the time to write that response. I'm familiar with Split() and the options, but if I want to split on spaces, I usually just write: Split(' ', StringSplitOptions.RemoveEmptyEntries); My point was (and despite your best efforts to explain it), I still don't get the how `default(string[])` gets translated into splitting on spaces.
Does the input have to be `List&lt;T&gt;`? If yes, then you won't be able to use `Span&lt;T&gt;`, unless/until [`List&lt;T&gt;` gets support for `Span&lt;T&gt;`](https://github.com/dotnet/corefx/issues/19814) (which won't happen in .Net Core 2.1). If you can change the input to be `Span&lt;T&gt;`, then you can benefit from it: public delegate void SpanAction&lt;T&gt;(Span&lt;T&gt; span); public static void ForEachChunk&lt;T&gt;(this Span&lt;T&gt; span, int chunkSize, SpanAction&lt;T&gt; action) { while (true) { Span&lt;T&gt; chunk = span.Slice(0, Math.Min(chunkSize, span.Length)); action(chunk); if (chunkSize &gt;= span.Length) break; span = span.Slice(chunkSize); } } 
For anyone interested in playing around with this, note the the var itemSize = Marshal.SizeOf&lt;Foo&gt;(); line in the example is a bug. Marshal.SizeOf is not guaranteed to be the same amount of bytes as stored in memory. So for some times, this would result in completely invalid code. Instead, please use Unsafe.SizeOf&lt;T&gt;(); from the System.Runtime.CompilerServices.Unsafe nuget package. Otherwise you will see code using NonPortableCast to byte breaking for some types but not others.
Ah, I totally misunderstood. If you simply pass a specific character, such as a space &amp;nbsp; `Split(' ', StringSplitOptions.RemoveEmptyEntries);` &amp;nbsp; `String.Split()` acts upon only the character you passed. &amp;nbsp; If you pass a null string array &amp;nbsp; `Split(default(string[]), StringSplitOptions.RemoveEmptyEntries);` &amp;nbsp; `String.Split()` assumes the delimiter should be any whitespace character--it's a shortcut built into the method so that you don't have to pass an array of white space characters, especially useful because various text encoding standards contain different numbers of whitespace characters.
ThreadPool.QueueUserWorkItem is probably available
There's lots of other options for dealing with unmanaged memory than the `Marshal` class, for what it's worth.
OK, now everything clicks. Thanks for the explanation. Side note: I finally got off my lazy butt (while magically still sitting on my lazy butt) and looked it up in the MSDN docs [1]. Under the "separator array" section they give the same example you used, as well as two alternatives : `(string[]) null` and `null as string[]`. I always thought that null was null, and it never occurred to me that it could have a data type. So apparently, that's why I got a syntax error when I tried just `null` as a parameter. Interesting. [1] https://msdn.microsoft.com/en-us/library/tabh47cf(v=vs.110).aspx
Sometimes there are functions that act purely on their inputs and require no state and have nothing to do with anything else. Having to come up with *another* name (for the class) to stick that function in is annoying. 
Im guessing (I’m hoping) you mean UnmanagedMemoryStream and associates. Very helpful indeed. However type safety was always a concern. Having a generic class wrapped around that will make my life easier. 
With c# 7: if (anyStream is IO.ISeekable seeker) { // seeker is not null here } You can add an else if you want to know if anyStream not implement IO.ISeekable else { // can not seek, what to do now? } 
I was referring to things like the Unsafe class, which is my go-to for interop stuff. It does have a lot of nice generic functions which make correctly-handling unsafe memory easier.
Well TIL. I have a tendency to reinvent the wheel. But on the other hand I had to implement some of that stuff before NuGet even existed. Then again this is very good to know
How is this different than aws lamda?
Coherence integrates into the programming language, so there's no deployment or configuration. No specific way your code needs to be formatted, pass a lambda and it's getting run immediately. FaaS services are a subset. You could make your own on Coherence. This will become more apparent upon the completion of a couple more features.
Full disclosure these are my projects. They are for .net core 2. https://github.com/codenesium/samples?files=1
Locking that down is tough. Do you allow outbound http requests? Domain access? File access? I'm sure you've thought of these things so I have respect if you got it all working. 
EntityFramework
&gt; functional programming a thing I was trying to make that point with c and f#. I guess a time and a place? 
Great question thanks! Locking it down was surely the most challenging portion of the project and even lead me to find network isolation bugs in docker. We are using seccomp to block a number of potentially dangerous kernel syscalls (more than default docker), including limiting outbound socket types to strictly SOCK_STREAM and SOCK_DGRAM (you can't use ping for example). Our security measures should not affect most legitimate applications however. Ultimately, users are segregated with strict trust boundaries across the application architecture, and that ensures users cannot mingle in each other's data.
We will, in time, Mono as well.
Looks like [33:17](https://www.youtube.com/watch?v=8GrXNE8ehLY) is where the benchmark talks start.
Are you putting each user's code in their own container? I'm not super familiar with docker.
Each time you run an instance of your code as a user (you can run many instances), that gets put in a container. Each user is segregated by the VM and additional trust boundaries like networking policies for example. I'm planning a full write up, after done handling the launch.
I greatly appreciate everyone's questions here. We have a slack community you can join here as well: https://www.coherenceapi.com/slack/
It's Jakarta EE now for EE. Oracle gave it away to the eclipse foundation, but wouldn't release the trademarks so it can't be called Java anymore(the stack not the language)
 That looks perfect. Thanks!
How does this compare with Azure functions? 
It would be great to use this for something like remote uptime checking of your web projects -- at least once you support http reqs. How would one deal with non-response from your server (you are down, I am down, a peer is down, the internet blew up)?
Yup, this was trivial to implement for Serilog.
I'm well aware that it's JakartaEE now, but at the same time I didn't think anyone here would.
Even better, it is Open Source: https://github.com/CoherenceApi/Coherence.NET https://github.com/CoherenceApi/coherence-py This is good feedback though and we will update the docs with an exhaustive list shortly. It's the things you'd typically expect in a deployment of your application, and differs by programming language (and potentially version of that language). Of course we'll work with any companies that reach out as well. 
I used head first with c# but it was starting from scratch, fundamentals, which I'm not sure you need. 
Stephen Hawking died :(
btw why did you define a delegate instead of using Action&lt;Span&lt;T&gt;&gt; 
specially something called "database first". that can generate entity framework stuff for you based on an existing database.
ActiveMQ? Use JSON for serialization.
I was thinking more intermediate 
Close. The major difference is that Parallel.ForEach can send batches of records to each thread rather than one at a time. Which might be better or worse depending on the situation.
Thanks !
That is not LINQ, but your own methods that have the same name. You could argue that there is no difference, but I disagree. LINQ is when your LINQ query is in the form of an expression tree that the underlying provider interprets and return the result. By implementing IEnumerable you get this for essentially free.
C# in a nutshell.
Isn’t that more of a reference book? It’s on my library though, I’ll check it out. Thanks for the recommendation 
Too bad there is **still** no written re-cap of this feed.
Whoops!
LINQ is a collection of extension methods for IEnumerable&lt;T&gt;. Like Reactive Extensions is a collection of extension methods for IObservable&lt;T&gt;. Please check the public methods for Where at https://github.com/dotnet/corefx/blob/master/src/System.Linq/src/System/Linq/Where.cs What collection in .NET doesn't implement IEnumerable&lt;T&gt; so that you can test that? Don't confuse the collection type with its content type. 
You can use MemoryMarshal.GetReference() passing in a Span&lt;T&gt; or a ReadOnlySpan&lt;T&gt;. Their implementation of the square-brackets operator returns a reference, which means you can directly access unmanaged memory with no copies at all. I'm going write about this scenario next.
I knew that getting the size of a type has always been a pain. I just wanted to keep the sample simple but you're right. I've been using the Unsafe class but didn't notice this method. Thanks!
[It's one of the limitations of `ref struct`s that they can't be used as generic arguments](https://github.com/dotnet/csharplang/blob/fcaa659/proposals/csharp-7.2/span-safety.md#language-constraints): &gt; A `ref struct` type may not be used as a type argument, or as an element type in a tuple type.
I changed the sentence to "Local variables in regular methods (not using async, yield or lambdas) are allocated in the stack". 
I was worried seeing this, until I realized it only affects people who are doing what Microsoft has advised against for years now...not running Kestrel behind a reverse proxy.
&gt; LINQ is a collection of extension methods for IEnumerable&lt;T&gt;. No. LINQ is [Language-Integrated Query](https://msdn.microsoft.com/en-us/library/bb308959.aspx). Microsoft supports it out of the box for `IEnumerable&lt;T&gt;`, but any type can opt into it by providing methods of the correct shape. .NET is full of such situations. Types not implementing `IEnumerable` can opt into support for being `foreach`able, types not implementing `ICollection&lt;T&gt;` can opt into support for collection initialization, and types that are not `Task`-adjacent can opt into support for being `await`able. 
&gt; You could argue that there is no difference […] I can and would and will. The `Select` method on `IEnumerable&lt;T&gt;` does not accept an argument of `Expression&lt;Func&lt;TSource, TResult&gt;&gt;`.
If you care enough about performance to go about writing `ref struct`s, you should care enough about performance to provide a few specially-shaped methods. Especially if the type you're creating is not inherently a collection. 
That's only partially true. Even if you're ruining behind a proxy, you're affected if your proxy isn't configured to validate host names. And even if it is, you're still affected if you don't update to v2.0.6 of Microsoft.AspNetCore.All. 
Coming from primarily developing in .NET, we decided to use Xamarin. Honestly, as a .NET fanboy of late, I hate Xamarin. It's such a pain in the ass, you blow at it wrong and it falls on it's face. It almost feels like a dead project. I can't get an android 8 emulator to work on it, I can't get their live player to work, want to do certificate pinning while still utilizing the native HTTP backends? Good luck with that, the docs suck and most of the tutorials are confusing or misleading. We're going to seriously consider switching to Google Flutter after we get the first iteration of the app done. In comparison, so far I've been very happy with the flutter community (or at least what I've seen from it from the outside), a friend of mine has used it and said he loves it (and he's used Xamarin in the past before), plus it compiles to native, has some pretty nice debugging features, and can make some great looking UIs. 
There seems to be conflicting information between the security announcement and the security issue discussion. One implies that using a reverse proxy mitigates the issue, and the other states you need to upgrade for all applications using 2.0, odd. Thanks for pointing that out.
Second. 
Yes, exactly—I mentioned this in a reply to another comment above (I might have been a little, let’s say, ‘Carl Sagan’ed out when I first replied the other night ;). I have to say, as a crazy Apple fangirl for many years, I’m amazed by how much working in the .NET ecosystem for the last 6 years has turned me to the dark side. I’m incredibly impressed by the state of both .NET and C#, and valuable little intricacies like this are seemingly never ending. It’s really reinvigorated my love of coding.
I'm not sure if I ever have had a good use case for automapper. I've never ever felt like it 'saved me code' or 'saved me time'. At best it kept all the mappings in a single configuration file. Which to me didn't add enough value to add another dependency, and one that's slow at that. 
Sorry but the only other way I know to support LINQ is to implement IQueryable&lt;T&gt;. That's what I do at my job. I use relinq to do it but that's way too complicated for this small article.
Interesting. I'll give it a go. Thanks!
You're probably better posting this in a sqlserver or sql subreddit.
Thanks for the suggestion, I’ll do that as well!
&gt; Automapper, where you continually ask yourself is the complexity really worth it to save a few lines of code you will never touch again? Man I relate to this so much. On one hand I love automapper because I don't have to hand-map large models between the DB, gRPC, and anything past that... but at the same time, I look at it and think &gt; I mean, I'm only going to do it once... This is slower, requires some pre-configuration.
I just started doing this using Handlebars.JS to create templates for the 'item' I'm displaying, in your case products. Here's a quick example I pulled together https://jsfiddle.net/nh1df37v/8/ I create each of my 'templates' as a plain cshtml file so they have their own file. Then I include them in my main page as follows: @Html.Partial("~/Views/MustacheTemplates/ProductItem.cshtml") Then the rest of the fiddlecode I provided should be straight forward enough, I'm only using JQuery and Handlebars. Obviously you would replace the hardcoded data array with an AJAX call to fetch your own data from the controller. 
One useful note that I'll post here so people can see it without reading the article: **This only affects ASP.NET Core webapps running through IIS.** IT doesn't affect webapps running through Azure, nginx, Apache, or any other reverse proxy.
Anything related to web development. Maybe asp.net mvc or web api. I am open for offers.
Try searching https://www.firsttimersonly.com or https://www.codetriage.com 
Ill have to take a look into it, sounds promising 
I use the same userid in my db but there is no sql table reference you should always have access to the same id via HttpContext user identity 
I can't speak from experience using it yet, but I love the way it looks so far. 
OK so there might be an element of sucking eggs here, do bear with me. When you take any website that serves up more than just static content and break it down, it has a number of different parts that all do different things. Different things require different tools so we have different technologies/languages for them. For example: Something to store data in- database: so uses SQL, MongoDB etc Something to retrieve data, process it and present processed data to be consumed- an API: so uses WCF, dot net core, MVC etc Something to consume processed data and produce html documents to be consumed by the client (yay actual website!) - a presenter layer: so MVC, angular etc Things to make those html documents functional, pretty (HTML and CSS) and interactive for the user (JavaScript, JQuery, Angular) To build a web app from start to finish you need all of these skills, which means web developers tend to be a jack of all trades. Most devs specialise in one area, and have a passing knowledge in others to get by. If you're looking to start, I'd start with building some basic apps from tutorials and branch out from there. 
They aren't advising against that anymore. They document that with Core 2.x, Kestrel does not have to be behind a proxy.
I think you will find very usefull the Web Developer Roadmap 2018. https://github.com/kamranahmedse/developer-roadmap/blob/master/README.md There you will see all the relevant technologies and how they relate with each other. Hope this helps.
Thanks, got a couple of new subscriptions. 
But Kestrel for .NET Core 2 is now ready for running directly, several people on the .NET team have said this and Scott Hanselman's podcast site also directly uses Kestrel.
I removed the decoration from the `Detail` action, then added logic to it: // get Driver from DB ... // is the User the Driver? var isAuthorized = await _authorizationService.AuthorizeAsync(User, driver, "UserIsDriver"); if ( !isAuthorized.Succeeded ) { if ( User.Identity.IsAuthenticated ) { return new ForbidResult(); } else { return new ChallengeResult(); } } // return the View .... Which works for the User/Driver. Still need to find a way to authorize an Operator.
Not sure why you're struggling to find .NET resources. https://www.asp.net/ has good resources about getting started.
Threading.thread.sleep(3000);
Have you tried: Thread.Sleep(3000); Should work.
You're welcome. Glad I could help!
don't forget to add using System.Threading; or none of that (spot on) advice will work. just an fyi.
 Program.cs(27,5): error CS0103: The name 'Threading' does not exist in the current context [C:\Users\User\reddit-importer\reddit-importer.csproj] The build failed. Please fix the build errors and run again.
It gives me this error. Program.cs(27,5): error CS0103: The name 'Thread' does not exist in the current context [C:\Users\Tetractys\reddit-importer\reddit-importer.csproj] The build failed. Please fix the build errors and run again.
 using System.Threading; up top with the rest of them should sort you out.
Thanks.
Thanks.
This might help: https://blogs.msdn.microsoft.com/webdev/2013/10/20/building-a-simple-todo-application-with-asp-net-identity-and-associating-users-with-todoes/
Just be aware that using Thead.Sleep() will pause a single threaded application for the duration. You wouldn't want to use it in a server application unless you *really* know what you're doing. Another approach is to use a timer: System.Timers.Timer runonce=new System.Timers.Timer(3000); //milliseconds runonce.Elapsed+=(s, e) =&gt; { runMyFunction(); }; runonce.AutoReset=false; runonce.Start();
https://www.asp.net/learn scroll down to getting started. Pick if you want ASP.NET or ASP.NET Core.
I think I just filled up my buzzword BINGO card. Your problem(having the duplicated logic) can be solved, but it feels like more of an architecture problem than a technology problem. &gt; We have a SQL Server project which takes in datafeeds from multiple sources and transforms/converts the data before inserting it into the DB. Not sure what you mean here? Do you mean you have some sprocs someone manually runs pointing @ a file or a web service? &gt;We currently use TSQL to apply this logic which is complex but does the job. CLR could be a place to move this logic to but it will still have to be called from the sql server. &gt;I'm leaning towards creating a microservice (in .NET core) for this feature and create API endpoints to allow the PHP application to interact with it. I'm not sure what this buys you. You could write the api end point in php and call it within the app itself and migrate whatever is happening in the previously mentioned sql project to interact with the database thru this end point. 
That is fantastic! Thank you very much
Thank you for the detailed reply. I appreciate the information. Very helpful
LINQ to XML
Azure on prem is almost impossible nowadays. Back when it was still brand new, there were little restrictions. But now you have to buy Azure specific hardware and the requirements are ridiculously high. Not to mention that you still have to pay for executions and execution times even though you own all the hardware. It feels like MS is forcing you to use their Azure unless you work somewhere like the government, where data can't be stored offfsite.
Woo
Couldn't agree more. I wanted to buy hefty azure stack towers for everyone on my team to be able to develop end to end solutions for their platform. I was seriously disappointed to see them abandon the onebox installation and go with an OEM approach. We do pay for VS subscriptions that come with Azure credits, but that $50 wouldn't last a day with some of the scenarios we would be interested in prototyping. Sure wish I could buy a bunch of 16 core threadripper systems and set up a bunch of little azure cloud environments... maybe some day.
Where i work we mostly do dotnet and we have 2 webapps already running on dotnet core (one 1.0 the other 2.0) we have absolutely no problems with it, both running on Linux on productivos servicing a moderate amount of traffic, what makes you think dotnet +linux is not viable yet?
Is on-prem different from running a local cluster? We have a local Dev cluster at the office running on a NUCs.
Once you move your code into the cloud, you are subject to a myriad of environmental considerations. Some small, some large. A couple we've run into: * SQL Azure has transient fault concerns you need to handle in code, doesn't the same feature set as OnPrem SQL Server, and obscures the details of the underlying infrastructure with their DTU abstraction. Things like CPU, Memory, temp file size are all hidden, and can sometimes result in failed queries without warning. * App Services will transition sites between servers whenever they please (Sometimes several times daily), and frequently runs into Blob Storage latency failures which result in fail requests (and additional host transitions). This was incredibly disruptive to some of our applications. Additionally, there are many situations that can exhibit behavioral differences from traditional OnPrem IIS as well. We ran into hard coded limits such as request timeouts, inverted defaults for 32/64 process modes, etc. My takeaway was that you can't rely on anything they provide having uptime equivalent to OnPrem resources, or exhibiting the same behavior with default settings. Expect network failures, unpredictable response times, and failed requests. TLDR; Azure will totally unplug your servers, and all your assumptions about how their stuff is working are probably wrong. Tailor your code accordingly. 
I'll have to give this episode a (re?) listen, but my guess is that .NET Core 2.1 specifically is what was being referred to. It's in preview right now, so... not quite ready :) Core 2.0 + VS Code is a solid, no-BS combo. Not sure if it's been mentioned, but Jetbrains' Rider is an alternative cross-platform IDE that is also worth a look, although it's not free, so that may be a deal breaker. I've never used it, so I can't speak to it versus VS Code for web development.
I use .NET Core quite a bit for production apps.
You are welcome :)
Sounds really interesting. I'll give it a try. Thanks for the recommendation.
If you need a military-grade ID with all the bells and whistles (like Visual Studio), your only option is going to be [JetBrains Rider](https://www.jetbrains.com/rider/). However, if you are willing to put in a little bit of work customizing VS Code I highly recommend it. I actually have [a repo with a Vue/ASP.NET Core template](https://github.com/phil-harmoniq/vue-template) that includes some VS Code configs if you'd like an example.
I read the article, but couldn't figure out how would not validating the host headers could lead to a security vulnerability, let alone a privilege escalation. Could someone please provide an simple example of how this would be exploited? 
If you had to pick one due to time constraints, I'd highly recommend .NET Rocks! Very informative, very entertaining.
&gt; Not sure what you mean here? Do you mean you have some sprocs someone manually runs pointing @ a file or a web service? Sorry, we receive a feed of data from multiple areas, some via an API, some via csv files. There is a process or function which transforms the data before we insert it into our database. &gt; CLR could be a place to move this logic to but it will still have to be called from the sql server. Thats correct, I want to be able to write the logic in one place and to use it in SQL server as well as the PHP app. I'm familiar with stored procedures but from what I understand using an object oriented language like C# to write business logic would be easier and cleaner. Then with the use of CLR we could import this logic into SQL server to use as well? &gt; I'm not sure what this buys you. You could write the api end point in php and call it within the app itself and migrate whatever is happening in the previously mentioned sql project to interact with the database thru this end point. One reason is to separate the logic from the main application, its quite complex and does a lot of data manipulation. The php app does a lot of other things such as authentication, send emails etc. 
Probably depending on what you are looking for. Developer Tea is more bite sized and also very great. But for news, entertainment and hard skills you surely are right!
I haven't found any details (the advisory is probably intentionally vague), but it sounds like the host header supplied by the client was used to generate URLs, which could be exploited to send password reset emails pointing to a malicious website (which steals the password reset token) or possibly inject HTML into the email.
So really, this vulnerability is only applicable to ASP.NET Core applications that have custom code which makes decisions based on the supplied host header? There's nothing built into ASP.NET Core that automatically cause a privilege escalation regardless of user code? 
I would assume that this affects ASP.NET Identity. But it's not what I would call "escalation of privilege". It doesn't allow you to execute code, just potentially take control of user accounts. I'm just speculating based on that bit of text, mind you, but host header injection is a pretty common vulnerability. 
Thanks! Just trying to understand how I'm affected, if at all. They're not making it easy. 
for enterprise it would still be best to have and be familiar with a windows dev environment with unix deployment. anything running in linux in .net core must be able to run on windows and being an enterprise the computers will be windows is highly highly likely, not to mention you will have to support and work on any non linux components. all that aside you can't beat visual studio, which basically all enterprises would use.
If you're using Windows Identity, this might give you access to a user account on the server, which potentially means escalation.
*Company's Forgive the spelling and grammar. I only had a few hours sleep last night.
Does it actually support password resets in that scenario?
Response to your post.
Hey, thanks for your answer. I haven't had the time to implement all of this in my system yet, but I will write a response when I'm finished. But this caught my eye: &gt;Also, considering what you've outlined with this system, I think self signed certs are also a potential vulnerability and avenue for getting into the system. Anyone can make a cert that looks like the ones you've made, so if someone realizes that a self signed cert will get them in, then what's to stop them for making their own. Why do you think that? If somebody else creates their own client certificates they won't be validated by my system because they don't have my root certificate. If I keep my root certificate (with private key) safe and issue only client certificates and root with public key only, then the security of my system is not compromised at all... Or am I missing something?
I moved from ng to react and was very happy with the move. But, it takes away all of the 'guard rails' that you get with ng so you better know what components it was giving you, why they were there, and what you're going to replace them with. I worked a lot with c# when I was originally doing ng dev and it did seem to line up with concepts I already knew. I guess the advice would be pick a technology you and your team are more comfortable with. If you're hiring for someone to pickup whats there and continue with react make sure they have some experience in large apps, depending where you're based it can be extremely difficult to find these people and they command pretty large rates. In my experience you will find many more devs that do c# and ng, however be very careful about core js skills. Again just in my experience, but they can be gaps in knowledge because of how much typescript can resemble c#, you can get up and running fairly fast without learning what its really doing. They are different languages and in a larger app they will bite you if you don't understand whats going on under the hood. Be particularly weary of devs that cannot explain what a ts class does and why its different to a c# one. 
The only reasonable answer imho is to upgrade, run some tests and then decide if its worth it. If not just roll back.
My preferred stack in general is .net core and react with redux; it sounds like you just inherited a sloppy dependency mess of boiler code I’ve worked with angular and react and the learning curve for angular is way worse. Typescript and react is easy and fun to work in, and you can have a strongly typed redux app relatively easily! I recommend spinning up a “create react app” and separating your UI from your API project entirely; that helped me a ton
Agreed. Since Vue is going to be used on the admin side then I don't see why you wouldn't use it for the front end too. It's awesome.
I can speak for Rider. It's definitely the best tool for .NET Core on Mac/Linux. VS Code mostly works, but I have had issues with the debugger crashing, clunky intellisense, no static analysis, etc. This is probably more of an issue with the C# extension than VS Code, but there doesn't seem to be any alternatives. Rider is basically the ReSharper extension for Visual Studio, but as a standalone IDE. Lots of refactoring options, templates, code style enforcement, a gui nuget package manager, etc. The one thing I don't like is the git/vcs integration, I still find myself going back to VS Code or Terminal to do that. Overall i recommend it if you can afford it.
The best framework is the framework you enjoy to use. So if you know ng and like it more, then sure use it or vue. It’s not like every framework is supposed to be the jack of all trades either, that’s why I like React to be honest though. It’s just the view part of the stack and I get to plop in all the other pieces how I like them... having spent the last year on React I’m really confident so it’s easy to make informed stack choices, whereas a React stack built off a boilerplate just sounds like sadness waiting to happen 
&gt; I am also worried that exposing the swagger documentation to the public is a bit of a security red flag. This would be false. A dedicated attacker records the requests made through your site in normal operation and then probably fuzzes them with an automated tool (like burp suite). All that a good swagger file provides that the scan doesn't is possibly reasonable documentation about what the various endpoints and parameters do. On the other hand a well documented swagger file probably means the dev has put some effort into the api, is performing some input validation, and is likely higher quality code than something which is not documented. --- Obscurity is not Security. 
I feel exactly the same way. Even while learning React, I feel like it's a waste of time since there will be some shinier new framework in a year or two. Let's just assume that Blazor is going to take root and go with that! 😁
Thanks. The repository even has a Dockerfile. Nice!!. 
Are those production apps like some variant of regular monolithic CRUD? Thanks.
You should take a look at Mobx with React. Redux is far too boilerplaty and rigid for me. Mobx uses the notions of observables, observers, and actions. As a .net developer, I felt the learning curve for MobX was very minimal.
THIS! This is wat i was hoping for. Thanks mate Can you show me the template .cshtml file too if possible?
Not really. But they're distributed cloud services.
I will give Rider a try. Thanks.
Create productitem.cshtml as the script block in the fiddle. I.e. starting with &lt;script id="templateProduct"&gt; and going through to the &lt;/script&gt; Then include productitem.cshtml in your main view by using the HTML.partial call
No problem, I keep forgetting how to set up certain things so I made this for a reference.
You definitely don't need a Windows machine - I've been doing .NET on a Mac and deploying to Linux since before .NET Core was released (using Mono).
admittedly, i am NOT an mvc guru however, what exactly is NOT working? Sorry if it is contextual and i may have missed it.
Why WPF?
If you haven't found anything I've got an idea for a new project.
1. we need more detail on what you are doing 2. this is not the best place for this kind of thing, these kinds of concepts are often best found in example solutions from microsoft or some 3rd party blogger/stackoverflow contributor like this article on [csharpcorner](https://www.c-sharpcorner.com/article/upload-files-in-asp-net-mvc-5/) 3. Even if you still want human help after #2 it is much easier to ask "hey im trying to get a file to upload in MVC5 using this example project i found, i am having issue X (explain your specific issue), can you tell me whats wrong?" 4. Post all relevant code, if you are afraid of exposing private info make a generic FooBar sample. If you can't make a FooBar sample work then you will never make it work in your larger app.
right. The problem with that blog link is that they are making a separate controller and using that controller to save the image on disk. What i want is to embed the same functionality in my products controller(code posted above). Is it ok (or even possible) to call the upload controller within my product's save controller? 
i dont have any code that saves the image to gets the path. I need some suggestions to make it happen
From my perspective you seem to be missing important real world questions, little hint, it's about the money (your time is money to company btw) Cost of redevelopment now vs headaches/increased cost of updating tech over x years. Does the redevelopment provide direct or indirect financial benefit to the company?
This is correct and is extremely frustrating because you have 0 visibility into these types of issues. I've had sites go down without warning because the filesystem holding the application suddenly flips to read-only and starts rejecting write operations. Usually this resolves itself within minutes but I've had it take up to 4 hours before.
Is this really a surprise, though? React and Angular are intended for building Single Page Applications (SPAs) and stuffing more than one logical webpage into one is going to quickly lead to headaches.
Yes you can redirect internally or have the client do it. Usually I don't encapsulate functionality in controllers. I put the functionality in pure C# classes that have dependencies only to what they need to get the job done then I call those classes from my controller. This way I dont have to ask the question "how do I get to functionality under another controller" You can do it, its just a pain and really you are breaking the rules to do it. Follow SOLID principals and be a happier developer.
Some thoughts: - The Swagger generated forms sound like an issue, but not because of React. The issue is the auto-generated forms. I use Swagger extensively and auto-generate client libraries but that's it. I think your forms should be decoupled from the API spec. - I am in a similar situation: front-end on angular 1.5 and ready to transition and considering Vue or React. The developer community around me have all moved to React. I too like the look of Vue, but I am worried that this will limit me when hiring or contracting locally. - An advantage of React over Angular+Vue is React Native. If you are doing a mobile app, the skills and perhaps some components translate across between the web front-end and native. - I don't think the fact that the back-end is .net should have any bearing on your front-end choice. I don't really understand why a .net dev should consider angular more "natural" than React. As you scale your team, you are also likely to have front-end and back-end devs and so less developers needing to be experts in both. - An open Swagger spec is not a security issue in my opinion. If it exposes vulnerabilities, those vulnerabilities should be fixed as opposed to hidden. 
Certainly not a review. More so just shit content to fill a blog and hoping for some amazon referral link sales.
what i was saying that angular being designed the way it is and the features it provides, seems like its miles easier to manage large code bases.
I'm fairly certain that you can write a stand-alone executable that does not require installation for Windows 7 without having to use WPF.
Check out how Squirrel installer works. It is a lightweight installer that leverages userland folders for storage, these folders are secured to the logged in user (users of higher access can take ownership). You don't need to use squireel installer just see how they are doing things. In short its data files in X:\Users\&lt;USERNAME&gt;\appdata\roaming\&lt;APPNAME&gt; and app runtime files in X:\Users\&lt;USERNAME&gt;\appdata\local\&lt;APPNAME&gt;
1. You can use app data environment paths to save program specific data. There are several ones (different types and scopes). If you need to protect data .net has a library for that. 2. If you don't have thousands of settings use the Visual Studio settings. You can change it from application to user per setting. When you change the values you can save the config. Next time the app is launched the user specific settings will be loaded. Painless way of doing configuration. Otherwise you could use json.net or sqlite combined with no. 1 above. 3. Have you considered going cross platform with .net core or mono? You wouldn't be able to use WPF outside of Windows but you could either share core code and write different front ends per platform or use a cross platform UI.
You can but if you want a rich, windows UI you have WPF, Winforms or GTK# the options are not great, WPF is still the best when those are the choices.
Your reply doesn't quite make sense because of course you can make a application with or without WPF have it be portable. Why is using WPF an issue? What other UI framework do you suggest that would work with win7 and up? 
Just wanted to throw one last crazy option out there: [Fable](http://fable.io). If you *really* care about a uniform experience between front-end and back-end development on a .NET stack, there's no comparison. You will literally use the same source for your domain model and some business logic on both the front and back end. (Prerequisite: F#)
A word of caution for anyone who inherits an application and then pitches to management for a rewrite, be careful. You will have to hit each deadline to the date or management will get "iffy' about the project. They have something that works, the code is a mess, but you can draw a line and say "All new code is done this way" and slowly kill off all the old features of the old app. That way you can focus on new features and not have a feature drought that puts pressure on management to put pressure on you and your new dev team. 
Others have commented on the tech aspects of this which I have no further to add and I know you asked this from a programming/library perspective - but since you’re the sole developer and are obviously not having technologies dictated to you - what makes sense for the company? If it’s a tiny code base that can be chucked away and rewritten in a few months and that provides benefit to the enterprise and your role - then it’s likely worth it. More often than not though there is a ton of stuff built on top of this - and a change like you’re proposing is a huge task in which case it’s only beneficial to you to rewrite - and better for the company for you to suck it up and become a react pro. Too many projects and startups die because of technology changes that are instigated for no good reason beyond personnel changes. Not trying to be all hail corporate- but if you believe in the startup and are trying to do better for the delivery of your product - then these are the things you need to think about. If you don’t - then whatever. Just keep cashing your checks until they run out.
My reply was out of curiosity and not necessarily meant to be a rebuttal. My understanding of WPF is that it is a little more cumbersome to use but yet has certain advantages. Was hoping to learn the reasons why OP chose WPF over simple WinForms.
If you allow people to upload files into `/uploads`, think about what might happen if they upload `badfile.exe` or `badfile.aspx`. You should either: * Create a whitelist (e.g. jpg and png files only) * Or write files outside of your webroot
 System.Threading.Thread.Sleep(&lt;millisecondsTimeout&gt;); [Thread.Sleep Method (Int32)](https://msdn.microsoft.com/en-us/library/d00bd51t(v=vs.110).aspx)
I agree WinForms is much simpler and if I was making a simple app / tool I would use that instead.
uhhh, i would prefer saving as a BLOB with FileStream enabled. Don't need to worry about file paths which will be unreliable
Send a pm 
It would fail to run. You can't SELECT INTO a table that already exists. The SELECT INTO should be changed to a INSERT @t SELECT... If you wanna do SELECT INTO I don't think you can use table variables anyway you'd need to use a temp table or real table. Either way don't create it first! 
My first question would be “why are you building the admin interface in a different tech stack?” Sure you can, and on a larger team it may not matter, but if the same guys are going to be developing both you’re going to create a mess. The guys you hire who know Vue will want to rewrite everything it, as will the guys who are more familiar with React. Like it or not React seems to be the way things are going. If I were developing something new today, and especially if I had an established codebase (no matter how crappy) with it, I’d seriously consider sticking with it. 
Yes, you are right. But come on, don't use that nasty INSERT without defining columns explicitly ;).
I'm not going to write the code for you..
WPF templates and examples all use MVVM pattern by default. While a bit more cumbersome it is far more flexible in real UI scenarios where you have multiple controls and states. Further due to the use of MVVM as a general standard all the examples you find are easier to grok since you dont have people applying tier own bad patterns in examples or doing hard to break up 1000 line methods in codebehinds. You can still screw up MVVM bad, its just easier to do things right until you want to do something unique with binding, then you want to murder small animals.
This is probably one of the most common questions and thus easiest to Google. Have you bothered to look on stackoverflow or follow a tutorial?
Don't mean this question to be nearly as loaded as it sounds, but with a lot of the progress in Ecma standards and css improvements (especially grid) do you feel that things like Angular and react are more niche things or approachable as the default?
As an interview question for .NET developers? Nonsense.
Angular is a framework while vue and react are libraries
Are there certain use cases or requirements that jump out to use as "Oh I should use Angular/React" might have been a better way for me to ask it. What sort of scenarios are interactive heavy in your opinion? 
I think you should look at what jobs in your area are looking for. There is a ton of potential combinations of stuff you could learn. 
Two possible downsides to consider: - Hidden incompatibility issues - rare. Just try it and see, like kmgr says. Most of the time, there's no issue. - [Platform support](https://docs.microsoft.com/en-us/dotnet/framework/get-started/system-requirements). 4.7+ isn't supported on Vista/Server 2008. If you're on earlier OS versions, you might be even more restricted. But I think XP/Server 2003 is .NET 4.0, so you probably don't have to worry about that. If your clients don't want to upgrade and it's holding back your codebase, check the MS support lifecycle and remind them about the impending doom. There's all sorts of liability issues in using unsupported operating systems. Other than that, upgrading is usually positive. Upgrading to newer versions also means a higher supported .NET Standard implementation, which might be handy if you're interested in porting your projects to that.
This is true. we have some tsx page in there. still don't feel so great.
This is a good point. In the coming months, we are having a redesign done. I would rewrite it at that point as due to the nature of the current code trying to fit a new dashboard will be quite painful.
Definitely. In my experience, almost every developer who inherits a codebase wants to rewrite it. In small companies which don't have much governance, this can be costly. I would definitly leave it to the point of when the redesign will happen.
If Blazor takes off it would be awesome.
I can second squirrel. It also allows you to auto update your application just by pushing files to a server. I was able to securely integrate it with s3 and also sign my updates! Squirrel is an awesome piece of tech.
Ahh Telerik, most problems in software you can hit stack overflow and find an answer somewhere buried there. But not with Telerik, they run their own support site where every single god damn answer wants you to download their demo project. 
I'm not able to work due to a medical problem right now, so I'm trying to learn some new skills when I have chance (between pain breaks). Alas, that's good advice. Thank you
That doesn't help you integrate it with a .NET API though. There are a lot of tasks you would want tied into your build step, and setting up Node, the build tasks, and the script to start your debugging can be a pain for a new small project. If you are doing an entirely Node.js front end, then none of that matters, but then how do you handle authentication for a user based application? Setting up JWT or an open auth based option isn't that hard, but it is extra overhead.
Are you seriously complaining about vendor having their own support site with knowledgebase? I actually really like telerik support, they actually read your question and always reply in 24hr. They also issued private builds for me when I found a bug and needed it to go to prod before their official release
How is react any simpler? What you have highlighted is another reason I want to use vue.js for the admin section. I usually use vscode for frontend and vs for backend. 
Yeah I guess I was. It is interesting to hear another point of view though.
The thing that bothers me the most about Tag Helpers is that they seem to be... inspired... by a 20-year old Java technology called Tag Libraries. 
I don't use react, so I have no comment there. We have used Vue.js with a couple projects now, and its a lot easier to integrate with asp.net mvc (and signalr) than angular.
I had a listen to about 1.5 episodes so far - quite a behemoth in terms of episode length, but it's actually worth it. I started with the "Clean Code" series, which is a very good review of and reflection on the Uncle Bob book of the same name.
I've been doing it for a few months now, and quite frankly, it sucks. You *cannot* mix container technology, anywhere. Maybe this will be fixed soon, but it's the reality today. You cannot have both Linux and Windows containers in Docker. You cannot have both Linux and Windows containers in a single EC2 cluster. It means there is *no* incremental shift. You shift everything. I have about a dozen services that use third party .NET 4.5 libraries with no .NET core version which means they must run in a Windows container. Now how do I develop for that, and for the other 50 or so services that will move to .net core/linux? I can configure Docker on my dev machine for Linux containers or Windows containers, but not both. If I switch between the two, I can never try having my services talk to each other which is the whole point of moving everything to microservices in containers. 
You should at least try using VS Code. The editor itself has quickly become one of the most popular ones over all. The C# tools are not as advanced as in VS2017 or Rider but should suffice for starting out. .NET Core is not yet that mature, but still usable for production and 2.1 with it's improvements for large projects should be out before you are "finished" learning .NET. I'm not sure what you mean by Azure being expensive. Running development environments while learning shouldn't cost much. And AFAIK you get a usable free tier for the first year. 
It depends - it will do perfectly fine scaling and shit, but if you need that feature, that is not yet available your left with tools to build it yourself. 
I mean, I can understand their concern, it's pretty new. That being said, do your managers actually understand what .net core is and/or have they done any research on how viable it would be? Or are they just taking a wild guess? I think as a platform/runtime, .net core is awesome. I love how I have it setup in our CI process at work using gitlab and the gitlab container registry to build and maintain docker containers for our service layer for easy deployment and scaling. I haven't found many features that I needed which didn't already exist in either the API or nuget packages. From a development perspective, it feels far more mature now than it did before. That being said, I don't know how many people here can do proper risk assessment for your situation. I *personally* think it's good enough, but at the same time I'm not in your position, I don't know your specific use case and what kind of regulations you might have to follow, and I haven't had to research .net core from your perspective.
Imo, Windows docker is just a new way to deploy IIS apps, and doesn't have any of the real benefits of Linux docker. I've been focusing my time on full replats to netcore.
I actually switched to Linux as my main OS at work about a month before Christmas. I ended up switching back to windows :/ I love Linux and VS Code, but I just found it got in my way far more than visual studio ever did. IE: I would debug an application, and the interface of VS Code would just lag out and the application would run super slow. Autocomplete kept screwing me up more than actually helping. I really missed the formatting features that VS has and VS Code doesn't seem to have (IE: Type a closing bracket and it fixes indentation on a block of code), and various other things. Maybe it's better now, but I've not tried it since. 
I use .net core in production as well. While our load currently isn't that big, it's been working pretty good. - I have a service layer currently contained in one application which runs as a gRPC server. It sits in front of the DB and handles most of the DB work, and some third party API calls (mostly all of them except in some specific situations.) The way this is setup it would be easy to split all these services up if I needed to, though. - I have several clients using it. Clients ranging from a web API for an app, to notification processing (text, push, and e-mail), various tools, and soon an employee portal. - I have the entire setup going through a CI process which creates docker containers for these individual components, and uses the gitlab container registry to store them. This makes deployment and scaling (if we ever want to scale it out) easier. So far I'm very happy with the direction they're going. 
Short Answer (opionionated) Presentation: Only display data, or do minimal calculations (ex.: percentage from total-current) Buisness: Create display-ready objects from different sources Database: One of the many different sources used to gather information for further transformation in the buisness AndOr Service-layer(hint: Adapter-Pattern)
.net core 2 is faster than 1.x so it should be fine from a performance standpoint .. my only concern would be that you are working around bank information and there are still vulnerabilities cropping up in .net core no matter what version you are using 
We're using in production for an API and Auth server. We haven't found any stability issues and it seems considerably faster than our existing technology. Saying that, we've not rolled out to the masses yet, but I highly doubt there will be platform issues
Were using it right npw for production for web n api. Havent had any issues with it so far.
The easy solution here is don't use Windows containers.
I maxed out a network connection, and a load balancer, load testing a dotnet core web api project. If you want to use enterprise tools, like a APM, or anything that injects HTTP headers into requests for tracing, you may want to stick with full framework until those vendors catch up.
How so?
You want to use the CLI tool lambda to deploy. That is what VS uses. dotnet lambda deploy
Try CoreUI
Why EC2/Docker to serve static files? Maybe your doing something else with the container? My dream scenario: .NET Core Web API in Lambda Front end framework in S3
What exactly do you need help with? You can DM me if you don't want to post here.
I'd rename Database to Infrastructure and do different models for displaying and different models for business logic(domain). Presentation should know how to map domain models to view models, and Domain maps infrastructure models(entites or whatever) to domain models.
That pretty much sums it up. As to what should go where, think about how it would go if you decided to replace one of the layers. If you wanted to switch databases would you have to change anything in the business layer? If so, it belonged in the database layer. If you wanted to change it from a Windows app to a web app, same question, would you have to change anything in the business layer? Yes? then move it out. You'll probably never "swap-out" the business layer, but as a thought experiment it can still be valuable to image what would be involved if you needed to. 
ASP.NET Core 2.0 is just amazing, though if you are using Entity Framework you'll miss the Lazy Loading. It's coming on version 2.1 which will (hopefully) be released in the second quarter of 2018. I also had some problems with Owned Entities (some just didn't work, though they worked fine on ASP.NET 4.x). These are the only issues I've had faced so far. I'd recommend you wait for version 2.1. Until then, go ahead and play with it, perhaps you'll encounter new obstacles or it'll fit just right to your business.
SmartAdmin
I get most of my themes from https://themeforest.net Search for 'bootstrap' They won't be ASP.NET core specific, but I'm guessing that's ok.
I liked this one. [here](https://startbootstrap.com/template-overviews/sb-admin-2/) 
[Look here](https://wrapbootstrap.com/themes/admin)
You... you can have mixed Kubernetes clusters in Azure... it's supported by ACS and will be by AKS if not already...
Yes the product is mature, 2.1 is generally a minor release that adds features. Scaling with docker on Linux images with kubunetes will absolutely get you to reliably handle thousands of requests per second with dotnet core. What is your alternative / what are you using today?
Lazy loading is the source of half the badly coded defects I've seen :)
We have come full circle in an odd way. Xaml is so htmlesque especially with components these days!
This is the way JavaScript ends. This is the way HTML ends. This is the way CSS ends. Not with a bang but a whimper.
Eager loading. Make the call once to the db and be done with.
IMO, tag helpers are not necessary and only cause confusion. Write proper html and simple javascript, along with razor, be done with with.
I asked this question 2+ years ago. I posted my solution in the comments. https://www.reddit.com/r/dotnet/comments/3o2hmg/mvcweb_api_and_images_best_practices/
I'm a little paranoid and toarray almost every linq query as soon as I'm done work this compsoing the query expression. I don't like iQueryables or Expression&lt;&gt;'s being passed into IEnumerables. Even as a preventative measure. Seen way too many issues with deferred execution.
oke, I will try to make the project as I think you all mean and when done with the first step I will ask for feedback here in the forum 
I'm not sure I follow what you are saying? Why would you pass IQueryables/Expressions into IEnumerables? All eager loading is, is adding basically adding a join for the additional data (that you would normally lazy load) on your initial data grab.
This is pretty much where I landed after grappling with Windows/Docker for a while. Seems useful as an alternative to VMs for legacy workloads, but there's nothing to really justify it for new work.
First AvaloniaUI and now this, c# is definitely getting better and better 😁😁
Return a 302 Found status with a Location header pointing to a page that says ‘your download has expired’. Or, depending on your framework of choice, return `Redirect`. 
Except that the domain layer shouldn’t know anything about the infrastructure layer. That way you can plug in a different storage layer when needed. 
Flot or morris charts are dead, I cant remeber which but the other one was useless by itself. if your using this you will want to research your charting libraries.
Yeah, copy and paste coding is the best! Who needs UI components or functions?
Or you could join 2018 and use a proper js framework to handle it all for you.
Good to know. I haven’t used it in a while honestly. 
Iqueyable&lt;t&gt; is convertible to IEnumerables&lt;t&gt; so people who are trying to use nice simple interfaces sometimes fuck up big time.
what are "components"?
I compiled this then used IIS virtual directory. It didn't load (I say spinning loading thing).
My .02, core 2 totally works as advertised. BUT. it is not "tried and true", its still too new for that. i'm using it in production with no problems. but my operations have a higher risk tolerance than something like a fonancial company. downtime would suck, but it would be more of "just fix the root cause" than getting sued. but that may be too much risk for a financial company, which is understandable. if this is greenfield development, just target netstandard2.0 as much as possible, and switching later on will be fairly straightforward. have your entrypoint target .net framework, and have it just be a proxy into the netstandard2.0 code. this is actually what i do too (but i target core 2.0), just in case.
the "full" framework still has bugs too, i wouldnt make that the sticking point. core also has less surface area, so there's that. i think maturity would be more of a problem than security, especially if you put your kestrel stuff behind a reverse proxy (like you should anyway).
&gt; I maxed out a network connection, and a load balancer, load testing a dotnet core web api project. thats good, right? to me that suggests that the .net core parts are very capable.
While this is amazing, oof, the size of the page is huge (13 MB) and the page uses up ~130 MB of ram to render.
https://developer.mozilla.org/en-US/docs/Web/Web_Components
160MB here.
It only knows models that it returns or requires(which should be sperate from database representation I agree, though in most cases that would be an overkill). Whether thats called entity or anything else is your business. 
That's why it's likely to gain more traction imho than these other offerings.
Lazy loading has its merits at times. I'm working on an API call where it does a lot of processing on a huge chunk of the database branching off of one entity. Eager loading everything it needs is a gargantuan task by itself, made even worse without nested Includes. I'd also rather not pass the dbcontext into the lower levels just to do more loading. For the rest of the API surface, I leave lazy loading off though.
The greatest challenge we've faced with core 2 is 3rd party libraries being ready for core 2. For example NServiceBus is only just now in RC. We've been developing an MVP release against their beta packages hoping we'll just happen to line up with their GA lol. Other than that, it's been great. 
React is great for rapid development, but it is a completely different mindset. I am of the mind that you should use frontend technolgies for the front end, but only if it makes sense to do so. What I mean by that is that if you're developing internal tools, then there's probably not much gain by putting too much focus on UI/UX. In those cases, stick to webforms or vanilla js using mvc. That way all of your .net developers can contribute. It's also much easier to find those engineers in the job market. If you're developing a consumer product where UI/UX really matter, then I would invest in frontend developers and a frontend framework like angular or react. These frameworks evolve quickly to adapt trends and there's tons of community support for maintenance and extension of those frameworks. In the end, just don't forget: whatever you choose, you're committed to. For example, if you invest in React and stand up your product in that, now you're stuck trying to keep those engineering spots filled with competent react developers, and depending on where you're located, that could be a challenge. And many that write react well are very young and tend to require more guidance which is another investment in itself. That is my experience anyway.
Found the gopher.
Yeah I agree, it's definitely not "tried and true" status yet. I'm doing pretty much the same thing you are, and I have to believe that's how they intend it to be used. It only makes sense to target most of your code to netstanard if you can, and then the runtime app simply wraps that and targets what it needs. I've not had a case where I *need* to use the framework instead of netcore yet, but everything is setup to work if I do. All the logic for the gRPC backend I've written for work is netstandard library, and the actual gRPC server is simply a netcore app with a main function that implements some logging with Serilog, loads a config, and starts the gRPC server. The database access is done through a library I've written targeting netstandard, and uses Dapper (I work with a guy who insists on putting everything in stored procedures, and we gave him control of the database at the beginning, so I pretty much just write sproc calls in Dapper.) And it all works really nicely with CI and docker.
All solutions need to be architected first. For example. You can build a production ready api, but what is it needed for? What will it be doing? How many inserts/updates/reads/deletes will it need to handle? Is code first an option? Or should it be database first? Who are the end users. Building production ready solutions will always require more insight, since it will affect how you will build it, what design patterns you will use, what your database structures will look like, etc.
From what I unstand this isn't using linking or any sort of optimization so in theory it could get a lot more efficient. 
Here is how to structure your code. Each bullet point represents an app or assembly (visual studio project). Each project references those below it. * MyProject.WPF, MyProject.Web - Presentation. Never put business logic here. Access your data by referencing one or more of your APIs. * MyProject.API.REST, MyProject,API.WCF, etc. These API projects contain thin wrappers around your services (below). Never put business logic here. * MyProject.Services - Almost all your code lives here (!). OrdersService, CustomersService, ProductsService - each service with Add(), Save(), GetByID, GetBySomethingElse, etc. ALL your domain (business) logic lives here. Never put put domain logic in a controller or .svc file. If you are using Entity Framework (it was made for accounting apps) your DbContext lives here. * MyProject.Model - Models for entities only. No code in this layer! Order class, Product class, Customer class, etc * MyProject.Domain - Interfaces live here. No code in this layer! IOrdersService, IProductService, ICustomerService, etc. * MyProject.Core - Application utilities live here. No domain code i.e. nothing that knows about a Product, Customer, Order, etc. This is for extension methods, data conversion, anything that you might use ANY .net app. This is a great utility (IMO because I wrote it :)) that helps you write testable, scalable service layers for applications architected as described above. https://github.com/leaderanalytics/AdaptiveClient https://github.com/leaderanalytics/AdaptiveClient.SimpleConsoleDemo 
Is the adaptiveClient really needed when only using a database 
This is useful. I'd love it for populating EF databases
Try uninstalling the PH toolbar extension?
I use bogus or faker they're both great.
That's a lot of questions lol. But we're glad your here! I can tell you that having the new Microsoft as a main contributor to an open source ecosystem is awesome. Tons of documentation and integrations across the board. So much is in .net. I think you should look into .net core specifically. It's the cross platform open source version and it is seeing the most action. You can easily use command line tools for development, but VS Code is a great option. To be honest I don't really have any negatives for working with the platform, but I'm sure someone else will have some so stay tuned and happy coding!
Is .net core the primary thing I'll be using for web development. Or is .net core also for locally run programs?
So IMO the best web framework for .net is asp.net. It is on .net core. You can make awesome web apps with it. As far as desktop programs, .net core doesn't have any official way to run GUI apps, but CLI support is all there. I'll be right back. I'm going to send you the link you need for learning everything about .net core and asp net core.
Here you go: https://docs.microsoft.com/en-us/aspnet/core/getting-started That's a great resource.
Thanks a ton. I will give this a thorough read.
All of these I'm assuming the language is C#. &gt; What are some of the pros and cons about using .net for both small are large scale projects. Pros: Maintainability due to static typing and performance due to Microsofts recent focus on it. Cons: Not as flexible due to static typing and can take longer to build a working product, unless you're more familiar with .NET. &gt; How does it interact with js frameworks like angular, react &amp; vue.js which are very popular these days? The same as everything else. These days everyone builds their front end as a separate application and it interacts with some APIs exposed by your backend. &gt; how is .net suited to building webapps which seem to be on the rise potentially in future being favored over native apps? .NET is perfect for web apps. Most .NET jobs I've seen are web jobs. &gt; Is .net considered easy to learn, hard to master. If so why? It's not a complicated language but the framework is very large. &gt; Is visual studio the only enviroment to code .net in? With .NET Core there aren't many limits on what you can use to develop in. I use either Visual Studio or VS Code. You could use notepad if you want. Obviously you can't fire up PHPStorm (well, maybe, but I don't recommend it). &gt; What are some good sources to getting started from scratch with .net? And when googling issues do I google .net or asp.net &lt;issue here&gt; ? Microsoft has some pretty good documentation. I mainly work in .NET Core so when I'm googling I use `netcore [problem]`. -- My own personal bias: I love C# and .NET and also come from a PHP background.
In the readme it said it was built on SOLID principles and had never heard of it. So after a quick Google search I found [this](https://www.codeproject.com/Articles/703634/SOLID-architecture-principles-using-simple-Csharp). Really interesting read and eye opening. 
Thanks a ton, these are some really good answers! Edit: I am a little confused about the first part. Is C# also used for web development? I was under the impression that it was only used for applications run locally.
Can you explain what it does?
Gotcha. Doesn't the service container in asp.net do this also?
There are tons of examples on the web just search for .net web api controller using MyProject.Services using MyProject.Model using MyProject.Domain public class OrdersController: Controller { [HttpGet] public Order GetOrderByID(int id) { // Your controller just wraps your service layer like this. // dont put business logic here. // You often just need one line of code just like shown here. return MyProject.OrdersServices.GetOrderByID(id) } }
We're using it in production.
Interesting. Could I just change the lifetime on the service? I'm just trying to see if I should be sold on your lib lol
The fact that we need stuff like this says a lot about EF.
In a sense yes, depending on how you setup the options when registering the DbContext. But, consider the case that you want to implement a repository pattern with data access being handled at a lower level. Say I have a PersonProvider that needs a DbContext, but I don't want my ioc container to create a new PersonProvider on every request. If you register your PersonProvider as a singleton, you'll only ever get one injected DbContext in that provider class. You'd have to match the dbcontext's lifespan in any class that needed it to get a new one on each time its injection. This allows you have have business logic/classes and repository classes created one time per the lifetime of your app but still get a new DbContext everytime it's needed.
I'm not actually crazy about the new implementation. The classes I use to register the context/provider take in a configuration and database name, which then gets the connection string for you. It was driving me crazy that I needed to worry about connection strings in the startup class and really missed being able to specify a connection string name on the DbContext.
You're asking the wrong person. While I agree with the theory behind his solution, my route was to ditch EF entirely.
So what did you do instead of EF?
That's neat
Seems a little unusual to me learning a new syntax to generate code in a syntax most people already know. 
Thanks for saving me some time
I just wanted to drop a couple suggestions for good resources I found when I was learning c#. Good if you don’t like dry material: Http://Wibbit.net Great for understanding the basics and their performance considerations. http://Dotnetpearls.com 
Come on, in fairness: Is a delegate really something you'd expect to have mutable hash? Nope. Do class instances often have pseudounique hashes? Yep. Little gotchas like this are a nice educational moment about the platform, and a good reminder not to assume too much. 
A dictionary with EventHandler as the key sounds quite reasonable to me.