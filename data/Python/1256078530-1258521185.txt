Numpy has nice facilities for operations on arrays. If you are able to fit your data in a nice structure you can avoid for loops most of the time. From what I understand you want to compute the median for each pixel over a given set of images. I would recommend converting your list of arrays into a 3D array and using the axis keyword to operate only in one direction in that 3D array: images_array = array(images) result = median(images_array, axis=0) Depending on the amount and size of your images you might have to watch out for your memory. (BTW what are you computing the median instead of the mean value for? Just curious.) 
&gt; Please show me a citation that shows this convention is necessarily true for all OO languages. I didn't say it's *necessarily* true, or that it was limited to OO languages, or true in all OO languages. Most interfaces I know do behave this way, which means that failed "create" functions don't require you to "destroy" partially created objects. 
Hmm, how is this different from lambda, apart from the extra keyword?
I believe multi-line lambdas are currently taboo. Guido doesn't like them, or so I hear. 
&gt; maybe a fork or an interpreter flag. Go ahead and fork. I'd bet my house that it will never be an interpreter flag, tho, because (a) the python devs hate adding interpreter flags, and (b) the absence of the flag would lead to syntax errors when importing/running any of the statements above. &gt; I like Python's syntax, but would like it to be more flexible. You're barking up the wrong tree, but I suspect you already know that. &gt; I'd have this be valid code on its own, such that it could be used in an expression as a "multi-line lambda" (lambdas wouldn't exist after this). Two things. If you need multi-line lambdas, just write a function. It's not that hard. Second, I would like something similar, and that's "def" to be an expression, e.g., foo = def (x, y): return x + y But I'm not holding my breath. &gt; I'd also make allow implicit returns, but I realize that would break existing programs (perhaps an interpreter flag?). Implicit returns, are you kidding? Fire up python, run `import this` and contemplate. &gt; I think this would be a wonderful amount of flexibility to have. I disagree, as I think it would lead to far too large WTF/LOC ratio. (Trying not to be too negative on you; it's definitely not my intent to be personal, but your ideas seem ill-considered.) 
I deleted the post because I remembered some things I forgot to include, but strongly appreciate your feedback. I realize that what I'm talking about is in line with the Zen of Python. My person preferences differ from those on many ways, but in almost every other way I prefer Python to anything else. I expect I'm not alone, and think it would be great to have us all working on mostly-interoperable code rather than entirely separately.
kodos is great, I've been using it regularly for regexp work in Python. My typical workflow is * Grab text I need to regexp * Come up with a candidate regexp * Curse and swear when it doesn't work * Tweak it * Grab and use the kodos generated sample code
Updating modules is a planned feature of [PyPM](http://www.reddit.com/r/Python/comments/9w36c/pypm_a_package_manager_for_python/), a binary package manager for Python (similar to apt-get). Currently, typing "pypm install lxml" will update existing lxml to the newer version (if available). In future, a new command "pypm update" will be implemented to update all currently installed modules.
k i'm not saying you're the only one. saying "i have errors!" is a stupid way to ask for help. be specific.
&gt; or true in all OO languages. Which is my point. The semantic is different in python. By the way, your semantics for constructors/destructors is incorrect. Objects are neither created nor destroyed by constructors and destructors. Creation and deletion is reserved for new and delete. For every object oriented language I have ever used, the semantics for constructors is to initialize the state of a newly created object. The opposite semantic for destructors would then be to release any state which utilized resources that would not be automatically released by delete. With this semantic, the python method makes more sense. In which case, the gotcha is really in c++.
Wish I knew about this last year when I was writing a pretty elaborate parser.
There is also [http://www.txt2re.com/](http://www.txt2re.com/) that can generate regexp's for other languages
http://www.pythonregex.com/ has been my personal favourite for some time. It says it is inspired by... Oh... Kodos. '^^
I think you forgot to *import telepathy*
It's because I'm stuck with python 2.4 on production servers.
And there's also [this](http://txt2regex.sourceforge.net/) one, which is a single shellscript
Kodos has a place onmy desktop. I hardly ever use it because programming in Python, I check for alternatives to regexps; and when I do use a regexp, I know enough to not need Kodos most of the time. Very rarely, like when electing to use a large regexp to parse the SREC file format: http://en.wikipedia.org/wiki/SREC_%28file_format%29 I then used Kodos to help in producing a neatly commented expression, and it works very nicely for me. - Paddy. 
You are correct, as this is indeed the semantics of constructors and destructors, even in C++. However, I wasn't saying that constructors create and destructors destroy. I was talking about the idiom for paired functions - one does some kind of initialization (the "create" function), and the other releases (the "destroy" function). As I see it, most such function pairings I know do behave this way. The gotcha is expecting `__init__` to be paired with `__del__` when they aren't.
My fav is still the old kregexpeditor, it does not generate sample code, but it visualizes the regex in a nice way.
&gt; The gotcha is expecting \_\_init\_\_ to be paired with \_\_del\_\_ when they aren't. Yeah.. I understand what you're saying. My response is that you're simply wrong. They are paired (one initializes state one releases held resources), they just aren't paired in the same way that c++ does it... bringing me back to my main point. WHO CARES? It's a slightly different semantic... one might even argue python has a better semantic.
Never thought of doing 3d arrays. Must give that a try. I have 4 GB of memory so it should be ok for the file sizes i'm doing. I'm computing the median just for comparison. I'm comparing it to other methods i've done like mean,mode, and addition. The median results aren't that great but the mode algorithm is fairly similar so I'd like to speed it up. Found while loops are marginally quicker, but still glacially slow. I've found addition and mean to be easy to do as you can apply basic maths to an entire array and it's surprisingly quick. Cheers for the pointers. [edit] Just remembered there is no numpy.mode. Damn.
Why? Except for the "name mangling" part, all that is convention. Double underscores on both sides are just a design decision for operators and other "special" methods, like the initializer, __init__. This is sometimes called "magical", but there is nothing magical about it. The name mangling thing though could be considered somewhat awkward. But I've never actually seen it in practice (except by those guys who want some private mechanism, but it is not meant to be used that way).
free(NULL) is defined as a NOP. So when malloc() fails you may call the "destructor function". However, you have to manually call them and they have nothing to do with OO con- and destructors, as these (as arcticfox said) initialize the state of an object.
__init__ is a convention. You may override it with a new Metaclass. Proof: In [14]: class M(type): def __call__(cls, *args, **kwargs): inst = cls.__new__(cls, *args, **kwargs) # Not __init__, but: inst.initialize(*args, **kwargs) return inst ....: ....: In [20]: class A(object): __metaclass__ = M def __init__(self): print "Hello, I got called!" def initialize(self, a, b): self.a = a self.b = b print "Hello, alternate constructor got called!" def println(self): print self.a print self.b print "^_^" ....: ....: In [32]: b = A(4, 2) Hello, alternate constructor got called! In [33]: b.a Out[33]: 4 In [34]: b.println() 4 2 ^_^ In [35]: b.__init__() Hello, I got called! My metaclass does everything the call operator of type does, just with initialize(). __del__ should not be used. It may cause problems and you don't need it, after all. If you need to close resources, you should to do that with the with statement or explicitly in a try-finally.
`worker = (numpy.median(img[y, x] for img in images) for x in range(x_size) for y in range(y_size))` This is a generator expression that you can then feed to numpy array constructor (avoiding intermediate list) and reshape appropriately. I'm not sure about the x-y order though: you really want it to go through memory continuously and I don't remember what numpy does with 2d array layout. And why do you use 'y' as a first index? Numpy array operation would be the fastest of course, but it's not always applicable.
&gt; And why do you use 'y' as a first index? I can't remember the exact reason why but the conversion from PIL image object to numpy array reverses the 'axis'. That expression certainly looks logical to me. I must give that a try. Thanks.
Found the reason. &gt; NumPy indexes 2-dimensional arrays as (row,column) as opposed to familiar coordinate notation of (column,row). This is because matrices written index notation use this order (ie, the element g_{ij} refers to the ith row and jth column of matrix g). So when considering an array representing a picture, one has to use the unfamiliar (y,x) format.
Ah, I see. Then make it `for y in range(y_size) for x in range(x_size) `, with the last index changing fastest. I've checked, the array of size (2, 4) is laid out in memory as [[0, 0, 0, 0], [0, 0, 0, 0]], so iterating in this way means going linearly over the memory.
I'll try that next. I had heard you should put the biggest loop on the outside but that was for C. Didn't know it would apply for Python too.
How exactly would I 'import' the generator expression into a numpy.array? I've tried numpy.array(worker, dtype=object) but that didn't work. I've only been able to get into an array by creating a list which is pointless as it requires more loops.
AFAICT, `__del__` is "properly" paired with `__new__` and not with `__init__`. I would agree that they are "effectively paired", which may mean exactly what you want it to mean, and still requires one to note that they don't behave as some people would expect. Which brings me to &gt;WHO CARES? Not you apparently :) People coming from c++ maybe. I'm pretty sure many of the people that I work with who do use Python will find this useful.
`numpy.fromiter(worker, dtype = int, count = size_x * size_y)` `count` can be omitted. Found it in the second comment on [Stackoverflow](http://stackoverflow.com/questions/367565/how-do-i-build-a-numpy-array-from-a-generator), which in turn was the first result in Google for "numpy generators". Google-fu is a necessary skill for a programmer, train it! About traversal order -- of course it's not limited to C. The idea is that when you read consecutive data, processor sees the pattern and uses the prefetch magic to preload your stuff to caches, so you are limited by memory bandwidth (and the amount of work you need to do with each element, of course). When you jump from place to place prefetch can become confused and anyway has to load and then store the entire cache line (32 or 64 bytes) just for one value you want to set (if your array is bigger than the caches). So now you are limited by the memory latency, which means going like 100-200 times slower, in worst case. Compared to this the overhead from using interpreted language is negligible. Also, in fact the greatest Python's problem in regard to performance is the fact that an array of ints is actually an array of pointers to heap-allocated objects, using numpy arrays solves this problem.
Thanks again. Somehow I missed fromiter. I saw fromfuntion but totally noticed the other.
Sorry to keep bothering you but is the fact that there is a nested generator prevent fromiter working? Also, I was looking for the wrong thing. I was searching "numpy, generator expression" and couldn't find anything obvious. [edit] I've just realised I misread your 1st post. Disregard this. [edit2] No I didn't. The numpy.median(img[y, x] for img in images) results in an Exception TypeError: unsupported operand type(s) for /: 'generator' and 'float' 
Yes, this seems to be the case. Numpy is kinda old and it shows sometimes. Anyway, this works for me: import numpy from pprint import pprint shape = y_size, x_size = 10, 7 images = [numpy.ones(shape, int) * i for i in range(5)] # pprint(images) worker = (numpy.median([img[y, x] for img in images]) for y in range(y_size) for x in range(x_size)) result = numpy.fromiter(worker, int, x_size * y_size).reshape(shape) pprint(result) 
Cheers again. Adding the brackets makes it work now. By using the generator the time for completion ~80% of the original for loop method. Just have to figure out why processing 2 images instead of 4 barely makes any difference in time.
Holy crap. That is fast. What takes about 2m50s using generator expressions takes 8seconds with this. Is it possible to run custom functions on arrays or does it have to be numpy's?
lately I am using this http://re-try.appspot.com/ 
Seems to be auto-banned. :-(
I prefer Ruby to Python myself, but you are trolling here. Go read both implementations - Guido's CPython and MRI - then you tell me which is the "hack". Ruby semantics are great but this is not a battle you should be fighting. Whether Ruby calls the plus method `+` (which is "magic" in Ruby!) or Python calls it `__plus__` is the smallest of difference, I can't imagine why you are going on about it. edit: markdown edit 2: It only looks like a hidden feature if you have never programmed in, or ready *any*, Python before!
Whats the point of lobotomizing some one who is already shown not to have brains ;) 
Kudus to Kodos
strptime(), it doesn't accept anywhere near this many inputs, though. Unless you write a parser for each, I guess...
The function you are looking for is [datetime.strptime](http://docs.python.org/library/datetime.html): &gt; import datetime &gt; datetime.strptime("2009-10-21 16:30", "%Y-%m-%d %H:%M") The format strings for this function and its inverse datetime.strftime conform to the specifications for the analogous functions in C. I like the datetime module because it recognises that there is a difference between absolute times and durations and thus has different types to represent them. Hence you can do arithmetic such as duration_1 = time_2 - time_1 and time_3 = time_2 + duration_1 etc. The module doesn't support 'fuzzy' matching.
Try either timelib: http://pypi.python.org/pypi/timelib Or dateutil's parse(): http://labix.org/python-dateutil#head-c0e81a473b647dfa787dc11e8c69557ec2c3ecd2
You might also be interested in `datetime.timedelta` &gt;&gt;&gt; from datetime import datetime,timedelta &gt;&gt;&gt; d = datetime.utcnow() &gt;&gt;&gt; d - timedelta(days=1) datetime.datetime(2009, 10, 20, 22, 37, 21, 948884)
If you want fuzzy matching and input that is more natural to humans (e.g. "30 minutes from now", "next Wednesday") then check out parsedatetime on Google Code.
^ this
Wow! Thanks, everyone! I'll read through all of your comments thoroughly.
a half ass google produced the two results you're looking for as the first results: [python excel](http://www.google.com/search?hl=en&amp;source=hp&amp;q=python+excel&amp;aq=f&amp;oq=&amp;aqi=g10) [python ms access](http://www.google.com/search?hl=en&amp;q=python+ms+access&amp;aq=f&amp;oq=&amp;aqi=g-sx10)
I use apt-get... I hate it when people write their own niche package management systems (like easy_install or Zero install). These things usually try to be way too clever and get into fights with me and my hand-made setups and of course with dpkg, which does not tolerate any competition. Packages that are stable and I would consider to be worthy dependencies are usually in Debian. I think you should really try to avoid having more than one or two bleeding-edge dependencies that have to be kept up-to-date by hand anyway. You should really think if you trust someone else's code enough to make yours depend on it.
I would do 2.6 first since you'll be able to use more libraries. 3.1 just has a few changes put on top of what you'll learn from 2.6.
Personally, I would go for 2.62. That is also the version built into os x.
Like choosing any language, or even learning anything, you should figure out what you want to do first, and then proceed in the direction which makes the most sense in your context. 
I agree. If you limit yourself to 3.x then you wont be able to play with all the cool stuff like [Django](http://www.djangoproject.com/), [NodeBox](http://nodebox.net/code/index.php/Home), [pygame](http://www.pygame.org/news.html) etc... 
&gt; That is also the version built into os x. Why would that be relevant?
It's relevant if the OP uses OSX
It is a good facility and obviously will simplify lot of things ..
My standard response is to start with [Discover Python](http://www.ibm.com/developerworks/views/opensource/libraryview.jsp?search_by=discover+python). It's a 9 article series that will get you up and hacking in no time. After that, read [Dive Into Python](http://diveintopython3.org/).
And 3.x isn't really different enough to make learning it later on difficult, anyway.
| ^ self FTFY
I thought one of the nice things about OS X was how easy it is to install stuff by drag and dropping them. Python's official website have dmg files for OS X.
Speaking from personal experience, 2.6, definitely. I downloaded 3.1 because I didn't know any better, and it was very disappointing. All the cool libraries are unsupported, and a bunch of MIDI stuff I wanted to use just wouldn't work. Doesn't look like it is time for 3.1 yet. Stick with old versions for now, they're fine.
This.
I am also then, in turn, going to downvote your comment until my finger falls off.
Definitely 2.6. So many libraries, packages, and apps for Python are not 3.0 compatible yet that you will run into unnecessary frustration. Python at v2.6 is already sufficiently kick-ass as a language that there is little marginal advantage for the beginner to deal with the immature state of the 3.0 ecosystem.
Don't post "this". Just upvote.
When I started learning I chose 3.0 thinking it was better to have the last thing but I quickly downgraded to 2.6 when I realized I wasn't able to use all the cool stuff. Think more of 2.6 as the actual version and 3.0 as the upcoming one. 
Another vote for 2.6. It's still a bit early for the 3.x series, so lots of libraries don't support it. It's not like there are a huge amount of incompatible changes between the two, but it's annoying: especially if you're just trying to learn the language.
Older version. Python 3 is basically an OCD release: language developers don't like living with old mistakes. Thankfully, the number of real mistakes made while creating the Python core language over the years has been shockingly small, so using *any* release will be pleasant. Starting out using Python 3.X would currently be about same same experience as using Python 1.5.2 (circa 1999): the two releases probably share about the same amount of library support at the moment.
I personally write everything new in 3.1.
Although it's not stdlib, you might want [dateutil](http://labix.org/python-dateutil) &gt;&gt;&gt; import dateutil.parser &gt;&gt;&gt; dateutil.parser.parse("5:50 A.M. on June 13, 1990") datetime.datetime(1990, 6, 13, 5, 50)
Can you tell why it's auto-banned?
Learn 3.x, write it in 3.x, but run it on a 2.6.x interpreter. If you are not aware, 2.6.x is intended to be both forward and backward compatible. That means all of the 3.x syntax still works, but by having the 2.6.x version installed, you can still use 2.x modules. 
Just learn 3.1. If you find that you need to switch to 2.6 for some library, you can easily do that. There is very little in 3.1 that will not work in 2.6.
How should I know. I always try to reach some moderators to unban my stuff. But now it's getting really annoying. I leave it that way and restrain myself from submitting anything in subreddits that ban me. At the time: programming, pics, geek, worldnews 
Often OSX developers will assume you're using 2.6 because everyone does. Finding help on the internet is also much easier.
As stated, I think these changes are too dramatic to actually be accepted into Python, but would like to know your thoughts if it were plausible.
For the record, there's some documentation now at http://gevent.org
Apple customers are only used to thinking in terms of what Apple will let them do.
"Apple customers are never satisfied, unless Steve Jobs tells them they are." But I doubt this is relevant for the OP, he would have mentioned it in the question. He's likely not on a Mac anyway.
I wrote a simple script in python+gtk a while ago ... http://www.gtk-apps.org/content/show.php/gregex?content=109697
Yea, and [wxPython](http://www.wxpython.org/) and [PythonOCC](http://www.pythonocc.org/) also! So: learn 2.6 so you get exposure to all kinds of great stuff. Then it's an easy progression to 3.1 (especially if you use the \_\_future\_\_ stuff in your own code). edit: formatting edit2: [I have official support of this opinion](http://python-commandments.org/python3.html)
I dunno - if I were you I'd stick to the interpreter you're writing code for - that way, if something weird happens, you know it's your code, not some obscure compatibility issue, and you don't have to jump through any hoops. That said, I've not tried running 3.1 code on a 2.6 interpreter, so it might be a lot smoother than I realize.
Not relevant for the OP, but key to understanding why someone would suggest using the version that ships with OSX.
Does [extended unpacking](http://www.python.org/dev/peps/pep-3132/) work in 2.6? That one of the features in 3.0 that I think would be really handy.
Arghhh! strtotime is maybe the worst example of php's bad date "api". It clearly violates the "Do one thing" principle and tries to be a poor date parser and date calculator at once. The drawbacks are obvious: it only parses english dates and can only do one type of calculation (adding/substracting a period from a date, but e.g. not calulate the difference between 2 dates). Since you only have the possibility to enter the period as a string, you never know if it was the bad string syntax or a wrong period value that caused an error. In the beginning the python approach with 2 separate libraries dealing with date parsing and date calculation might seem pretty odd to you, but you surely will appreciate the flexibility you gain from it.
Yes, even try: 1 / 0 except Exception as e: print(e) works in 2.6 
[Note by GvR](http://mail.python.org/pipermail/python-ideas/2009-October/006305.html) and [submission to /r/programming](http://www.reddit.com/r/programming/comments/9wcaj/python_likely_to_halt_language_grammar_and/).
What a great unanswer. In reality, there's very little that he'd want to do where Python 3 would be more capable than Python 2.6. Conversely, there's quite a bit that can be done in Python 2.6 (due to better libraries, frameworks, tools, etc) that cannot be done in Python 3. Moving from 2.6 to 3.x will be simple once you have the core concepts down, so don't worry about wasted learning time. Pick the version that has the most capabilities so you can learn while doing things that interest you. That'll be the fastest most painless way to learn.
Just install them parallel. On my mac system python goes to 2.6 python3 goes to 3.1 I write most things for 3.1, but if I need some arbitrary lib its easy to just call 2.6
Some gotchas there, ie urllib and urllib2 in 2.6 are in a completely different location in py3k. Though I still am for learning 3.1 on a 2.6 interpreter, just watch out for some of those gotchas.
Hey einsidan, I'm also planning to start learning Python. Care to try and work together (help each other) while learning? Send me a message if you're interested.
Ask your teacher which he would prefer to teach you =)
Hi Chris
that's not quite true, is it? i have a package written on 3 and to get it to work on 2.6 i need to do some ugly hacks with ABCs. also, a few magic underscore methods don't work the same. it's almost ok, but the gotchas can be painful.
Also it is worth noting that many of the people dissuading learners from 3.1 are using the availability of third party modules as an argument, but as a beginner learning to code within the standard library is/should be part of what makes you a better coder...
this what ?
&gt; I want to teach myself Python.... same here buddy. Are you going to be putting it to use ? is it for work or just hobby ? 
Start with v2.6. From the [Python.org download page](http://www.python.org/download/): &gt; If you don't know which version to use, start with Python 2.6.3; more existing third party software is compatible with Python 2 than Python 3 right now. The language hasn't really changed all that much between 2.6 and 3, it's mostly some sensible syntax changes, and a tidied up standard library - nothing that will really impact on your learning of the language, whereas not having access to countless third-party libraries *will* make learning the language less pleasant..
Good news, distilled: currently 50 to 130% faster than CPython (slide 13 of 26), with additional optimizations, GIL improvements, and the start of the merge with CPython planned for 2009Q4 (slide 14 of 26)! :)
I don't think that will work. As a simple example, the print statement exists in Python 2.6, so you can't use the 3.x print function. There are workarounds to this, but it won't look very pretty in some cases. It's also an extra stumbling block when learning a language. 
I think you weren't aware of it as it isn't exactly true. :) 
It depends on what the beginner wants to do. If you want to learn Python to do useful things with it, it's silly to do without third party libraries if you need one. If you want to write a web application for instance you'll need a web framework library (and most haven't been ported yet). And it's still true that only a few third party libraries are available in 3.1. 
I agree with that. Stick with Python 2.6 for now. Python 2.6 has preparations for Python 3.x in it, but I don't think it's true you can write idiomatic Python 3.x code and run it on Python 2.6. It won't work in all cases, and that will only be confusing. Python 3.x will mature as library support increases for it, but it will likely be a few years before it can compete with Python 2.x in that area. 
I certainly agree. PHP is a mess. My main server-side scripting language is PHP, but not by choice.
2.x .. that's what is used right now. You can upgrade later.
I extend [my offer](http://www.reddit.com/r/Python/comments/9wgyc/hey_reddit_i_want_to_teach_myself_python_but_cant/c0esb1d) to you as well.
No no, we use "self".
Python really needs a "using 5.10" like Perl.
&gt; from \_\_future\_\_ import print_function &gt; from \_\_future\_\_ import division
Good answer, I didn't know about print_function (division has been there forever). Looking at the 2.6 "what's new" it looks like indeed one can get quite far. It is still a lot to worry about for a beginner, though. 
Yes, but these two things are not dichotomous. While someone who knows the language may find that they can rapidly deploy code by leaning on third party modules, don't underestimate the value of a beginner reinventing the wheel a few times by starting from scratch. The standard libraries are quite wide in their scope and certainly have enough depth to handle the vast majority of tasks. I do agree however that not all beginners are attempting to learn "the language" but are simply trying to solve a particular problem; in which case having an existing framework of the heavy lifting is certainly a sensible solution. I tend to thing of "teach myself Python" as a task which is self evident in the goal of learning "the language". I suppose we could remove the presumptions/assumptions from the discussion by asking for clarification from the redditor who initially asked. 
I'm not talking about rapidly deploying code. I'm talking about rapidly accomplishing cool stuff. Third-party modules make this a lot more likely. Not everybody's interest is held by text and files and such - perhaps they want to try their hands on, say, game development. Reinventing the wheel is a useful learning experience, agreed. But programmers will reinvent the wheel anyway, no matter whether third party libraries are available, so we don't need to encourage them by their absence. The best way to learn any language is to actually try to accomplish something with that language. That doesn't mean that the more theoretical aspects should be forgotten, but language idioms are in a large part cultural and are best picked up with experience. 
Isn't Guido using 2.x for his daily work in Google?
That's not really how reddit works...
Do you personally not use any 3rd party libraries?
You're right in your domain of assumptions, and for all we *knew* Einsidan only wanted to browse the language a bit to see syntax and stuff. If he didn't plan on building anything why not look at 3.1? And what if he is already highly skilled in programmin' ? Why not start with 3.1 and help port things he is interested in using? You made your assumptions when you answered the q, I made my own. Plus I hope to have provided a little incentive for him to ask more detailed questions in the future, but with this at +2 he'll probably ask "how do I hack" next
It's false. If some Python version past 2.6 was both forward and backward compatible, I'd be using it.. but its fantasy.
sure but I have very little spare time (looong commute) so basically I can only learn on weekends
Either you're *really* nitpicking, or you managed to miss the whole goal of 2.6. See http://docs.python.org/whatsnew/2.6.html: "Python 3.0 adds several new built-in functions and changes the semantics of some existing built-ins. Functions that are new in 3.0 such as bin() have simply been added to Python 2.6, but existing built-ins haven’t been changed; instead, the future _ builtins module has versions with the new 3.0 semantics. Code written to be compatible with 3.0 can do from future _ builtins import hex, map as necessary." Aside from that, I would bet a dollar that if OP read 3.x documentation and ran it on 2.6, it would be a very long time before he even found an incompatibility (which can be made compatible again using 'from future' etc).
And I'll explain myself better.
is that 3to2 (well, sort of) equivalent ? 
yes i am also interested to learn this fantastic language and according to you people which version is most suitable can you please guide me i am just stranger of this language :) .Thanks :) 
The OP would run into the print statement like, right away, right? And that'd necessitate a from future statement right away. 
Do you already know other programming languages? If you do, then just learning the language might be possible, though you won't learn all the idioms unless you do real work in it. If you don't know programming very well yet, you better set yourself some (modest) goals and try to accomplish them. You can't say you learned a natural language if you can't at least understand real sentences spoken or written in it, and you can't say you learned a programming language if you can't at least accomplish some programming tasks in it. A lot of goals can be accomplished with just the standard library available. A lot *more* goals can be accomplished if you use some extensions. It depends on what goals you set yourself. 
See [this post](/r/Python/comments/9wgyc/hey_reddit_i_want_to_teach_myself_python_but_cant/).
That's uhh, pretty stupid strategy.
Hey reddit, I want to teach myself Windows, but can't decide whether to start with 3.1 or a newer version that is more "compatible. What should I do?
python 2.5, ftw
I've seen this article before. I think the author comes across as mainly annoyed that super() doesn't work the way his favorite language does. Though I give him points for taking the time to understand how it _does_ work rather than simply declaring it broken when it does not behave as he expected (as so many other people seem to do).
No, wrong. I recommend trying at least once before claiming expertise. Python 2.6.2 (release26-maint, Apr 19 2009, 01:58:18) [GCC 4.3.3] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; print("orly"); orly &gt;&gt;&gt; print "orly" orly You can print as a function without any "future" all day long.
No, it is nothing to worry about. Everything he will do is built in to 2.6, the from future is not necessary for most things, including using print as a function right out of the box. It is only mutually-exclusive edge cases that one has to disambiguate with a future statement, otherwise both are supported by default...as myself and others have already proven with examples.
Minor correction, the compatibility only exists between 3.0.x and 2.6.x. 3.1 is being mirrored in 2.7, which is not out yet.
I don't understand what you mean?
It doesn't especially matter. For a novice the only important changes are: print "Hello World" # printing in 2.6 print("Hello World") # printing in 3.0 and decimal_num = 5 / 2.0 # division in 2.6 integer_num = int(10 / decimal_num) decimal_num = 5 / 2 # division in 3.0 integer_num = 10 // float_num There's also an under-the-hood revision of objects, but It's seriously no big deal. Python 3.0 is a break in backwards compatibility, not a total revision of the language.
But, you need to import from future if you want the same behavior from print. Examples: Using 'print' by itself (print in 2.6 prints a newline. print in 3.x prints '&lt;built-in function print&gt;') Using the 'sep', 'end', or 'file' keywords args to the 3.x print. 
Am I misreading what you're saying about the print statement? You mean you can't use it in 3.x? Or do you mean you can only use the &lt;3 style in 2.6? $ python2.6 Python 2.6.2 (release26-maint, Apr 19 2009, 01:58:18) [GCC 4.3.3] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; print("Hello world") Hello world &gt;&gt;&gt; print "Hello world" Hello world Edit: I think I get it now. You meant you can't use `sep=` etc. in 2.6. Fair enough then. 
The print("Hello world") doesn't work here because "print" is a function, but because ("Hello world") is equivalent to "Hello world" in this context. Just try ("Hello world") by itself as an expression on the prompt. If you do "from __future__ import print_function" in Python 2.6, print is a function however. 
Only ones which are ported. :)
Man, I don't know how you do it. I'm stuck using 2.4 an 2.5 half the time.
see greenlets/stackless python cant do it on its own, it lacks proper continuations
Thanks! http://codespeak.net/pypy/dist/pypy/doc/stackless.html answers exactly my question. (they even use the same example of consecutive squares.) [Edit] I posted a solution using additional thread.
Here's a crappy half-implementation that needs to consume the entire ' 'generator': def iterate_sq(i): for x in range(i): yield x*x def generate(f): ls = [] def y(arg): ls.append(arg) def inner(*args, **kwargs): f(y, *args, **kwargs) for element in ls: yield element return inner @generate def it2(y, i): for x in range(i): y(x*x) if __name__ == '__main__': print list(iterate_sq(10)) print list(it2(10)) #output: #[0, 1, 4, 9, 16, 25, 36, 49, 64, 81] #[0, 1, 4, 9, 16, 25, 36, 49, 64, 81] I don't think it's possible for this to work with an infinite generator.
Here's a solution that uses additional thread. It seems it's hard to control the flow without threads or continuations. Due to some scoping issues I had to use Python 3's nonlocal. from threading import Thread, Semaphore def generate(f): def result(*args, **kwargs): value = 5 consumer = Semaphore(0) producer = Semaphore(0) def executing_thread(): nonlocal value def yielding(v): nonlocal value producer.acquire() value = v consumer.release() f(yielding, *args, **kwargs) producer.acquire() value = None consumer.release() t = Thread(target=executing_thread) t.start() while True: producer.release() consumer.acquire() n = value if n is None: break else: yield n return result @generate def it_squares(y, x): for i in range(x): y(i*i) for i in it_squares(5): print(i)
I think the Python equivalent to "using 5.10" is "from \_\_future\_\_ import".
Notice that you can't set the recursion limit to an arbitrary size: http://bugs.python.org/issue6356
This isn't what the OP asked for, you're running it2 completely until exhaustion whilst appending to a list, then unpacking using regular python yield. Maybe what OP wants could be supplied if keywords in python were also objects. I don't know what else that would cause though...
Out of curiosity, are continuations needed for this, or just full coroutines (like Lua has)?
wtf is a "GIL" ?
http://lmgtfy.com/?q=python+gil
From the first link Googling for "python gil": http://docs.python.org/c-api/init.html#thread-state-and-the-global-interpreter-lock
no changelog
It is at the usual place, linked rather prominently in the second paragraph of the page. http://www.python.org/download/releases/2.6.4/NEWS.txt
That's not print as a function. That's a print statement printing a string that has been put in parentheses. Counterexample: $ python Python 2.6.2 (release26-maint, Apr 19 2009, 01:58:18) [GCC 4.3.3] on linux2 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import sys &gt;&gt;&gt; print('orly', file=sys.stderr) File "&lt;stdin&gt;", line 1 print('orly', file=sys.stderr) ^ SyntaxError: invalid syntax You're better off just writing it cleanly for 2.6, so you can run it through 2to3 than doing little hacks like faking functions to make it look like 3 code. I believe I also heard about some work on a 3to2 utility, so you can start writing native 3 code, but I don't know how that's going. Edited to add: Another problem with this pseudofunction is that it's not a first class object. &gt;&gt;&gt; write = print SyntaxError... 
Did you know you can send personal messages to users? They won't show up in the thread, and you'll spare yourself a few downvotes. 
Thank you to everybody who is committed to supporting the 2.x generation of the language!
i always mix those 2 up well, what you need is to save and resume execution in some points so full coroutines should fit
in general you don't want to use threads in cpython without a good reason (the GIL makes them ___suck___)
me too
My favourite host is Webfaction, but I have not made use of their Python support for which they are famous, other than through their prepared apps like Trac.
[WebFaction](http://www.webfaction.com/) tends to be the most recommended option and are on top of Python hosting i've been happy with them although I'm moving to the [rackspace cloud](http://www.rackspacecloud.com/) which is like a cross between S3 and [slicehost](http://slicehost.com) because I wanted to play around with some things that require a real VPS (WebFaction is a lot easier and almost as flexible) 
yep, one more vote for webfaction. Easy to setup and more importantly, the people there know what their stuff.
I used to use webfaction, but I never really understood what all their wizards were doing. I eventually just opted instead for a VPS slice on linode.com, where I have control over everything. Their base package starts at 19.95/mo, so it's not as crazy as it sounds.
&gt; crappy half-implementation that needs to consume the entire 'generator' 
&gt; but I never really understood what all their wizards were doing What is there to understand? They are just web app installers.
Linode is the best priced vps if you are looking for your own server. 
Came here to say the same.
I've been using SliceHost, and I have been very happy. However Linode offers more for the same price but I've been too lazy to switch. I just like VPS more than shared hosts. I like setting up my own server.
!
Thanks for posting this five times in a row. Downmodding was much more satisfying.
Anyone know the result of Guido's feature freeze proposal?
still trying to learn 2.6.3
so purpose is to host some Python applications?
Nothing stops you from installing your app/framework yourself. I personally don't understand how anyone could hand over control of their production code environment to a "one click installer," so I just set up a mod_wsgi app and installed Django myself using pip and virtualenv.
epsilon
Only bad part about Linode is the available memory is not a lot. It's basically just enough to barely run the server. Otherwise the service is amazing.
Now as someone who is just getting interested in learning python (so far it's been C and assembly for me and still very much a novice) could someone please explain to me why anyone would be interested in working with 2.6.4 and not 3.x if they're starting from now. Is this a backwards compatibility issue? 
2.6.x releases are just bugfix releases with no new features. However, most of the libraries have not yet transitioned to 3.x series. So if you are starting a project right now, it makes sense to start with 2.6.x if the libraries you are going to use are not going to support 3.x in near future. 
I couldn't figure out how this is any better than [pyopt](http://code.google.com/p/pyopt/) or [argparse](http://code.google.com/p/argparse/)... any comparison bullets?
I had downloaded the first edition and it was awesome. Downloading the second edition right now.
ditto for [WebFaction](http://www.webfaction.com/).
I do all of my python development on [Google appengine](https://appengine.google.com/). Its FREE. You can run Django on it if you want, or just use their system. Only drawback is their database is a key/value store, so doing join queries is hard.
As much as it was a suggestion, it was from Guido; it's pretty safe to say it's frozen ;)
I'm running a large web service on a 256mb slice. What application architecture are you running that this will barely be enough to run the server?
... and memchached is slower than reading files off the disk, and you have to use a frankenstein version of Django, and your app is now locked into a platform so you cannot grow, and ...
I'm loving Slicehost. The API is really easy to use, so having a script that automatically provisions new boxes or scales back is pretty easy to write dependent upon traffic. They are the about the same as Linode service wise. They have a great article repository full of all the things you'll ever need to know about running your own server.
I'm running two Django apps with postgresql, apace and memcached on their smallest package with a bit of memory to spare.
I have a xen instance at work running 4 (low traffic) django apps as fastcgi behind lighthttpd, using sqlite as storage, running on a stripped down Ubuntu 8.04. It has 128 MB RAM and it's running just fine. Mem: 131292k total, 119308k used, 11984k free, 2128k buffers Swap: 524280k total, 212k used, 524068k free, 21936k cached
I agree. WebFaction is really good and their support is outstanding. And I recommend it despite my criticism below. Two things I don't like; don't know if they apply to you: * The only thing that I don't like is that they use Python 2.5 as a standard. If you want to use 2.6 or another version you have to do much work yourself. There is no easy way to "just switch" versions that I know of * Importing large datasets is a pain as all statements cancel after 30 seconds (which isn't nearly enough for 10GB+ data) and one either has to ask support to temporary lift this limitation or split the data
&gt; explain to me why anyone would be interested in working with 2.6.4 and not 3.x if they're starting from now. Need a library (or a set of libraries) which isn't/aren't going to be ported anytime soon. For instance if you want to code with Django, Twisted or Turbogears… 2.x is basically a mandate.
Ya, ya, I know he's Dutch, but I still can't help but imagine this scene... "Yo, izza nice language youz got here. Be a shame if sump'en bad were to happen to it. Maybe youz give up a donation and we won't haffa put it on ice, if youz know what we mean." 
http://djangofriendly.com/hosts/ lists and ranks many python-supporting web hosts. Pretty much everything there would apply to Python hosting in general, not limited to Django.
Also agree - good pricing, plenty of available documentation and has great support for stacks other than python as well.
you used the 1st edition to learn Python ?
I gave the book a quick look and was pleasantly surprised. It reminds me of books I used to learn to program when I was young, simple guessing games on the Commodore Plus-4. (Far-away look in my eyes, a moment of deep nostalgia.) Yeah, it's nice. Teaches some basic concepts, doesn't go too deep into the more complicated Python routines. Looks like it ramps up in complexity at a good pace, too. Really, Python was the perfect language for something like this. I would have eaten it up as a kid. Well done. I'm going to bookmark this so I can pass it around later.
The book looks interesting. But, I am learning 2.6 before I bother with 3.x, would this book be usable with 2.6 (I understand a lot of 3.x features are available in 2.6)? If so, would it be seamless or require code modifications?
Blog link is broken on the book's website.
From what I've seen of the code, it should work in both without any issues. The changes from Python 2 to Python 3 mostly affect more complicated code -- everything here is simple enough that it should work on everything from 2.6 up. Of course, I haven't tested that theory, but at first glance everything looks kosher.
Byte of python and this book helped me grasp python very well.
 Indent with Python
Ok, maybe that's a little underpowered :D
Fixed it. I had messed around with the .htaccess files so that Apache would let you download the .py files, instead of trying to run them as cgi scripts.
Hi, this is the author. I do believe the code should work in 2.6. The only differences I made were 1) the print statement is now a print() function that uses the endswith keyword argument, 2) raw_input() is input() and 3) I have list(range(x)) instead of range(x) when trying to generate lists. I originally shifted the book to Python 3 because the publisher (who has since dropped the book) wanted it that way. But there isn't much of a difference to begin with.
Holy crap, thanks Reddit! This is the author. I was surprised I didn't have to plug my own book on the Python subreddit myself. Thanks to everyone for the nice words (and blunt critiques!) I'll be making minor edits over the next few weeks, and once I get a better desktop publishing solution, I'll print out hard copies over lulu.com or something. Thanks again!
Props for using python3
You should definitely look into the [Beautiful Soup](http://www.crummy.com/software/BeautifulSoup/) library. It is very good at parsing HTML, especially if it is partially mal-formed. **Warning** This will make writing your image crawler significantly less fun! Good Luck!
no option to change fonts/colors? (I couldn't find it, except for messing with the src of course)
Tornado, web framework, also does crawling
I used [scrapy](http://scrapy.org/), I like it quite a bit.
Second for Beautiful Soup. If you want to do more yourself, go with httplib. What do you want to do with the images? If you're just storing them, that may be all you need. If you plan on any image manipulation (to resize them all to one size, transform all the jpgs to png, create thumbnails, or something similar) you'll want PIL, too.
hi, al, what is the difference (for windows) between python.org's python and activestate's python ?
Functionally, there is no difference. Both Python.org and ActiveState have their own implementations of the Python programming language, and your scripts should be able to run on both with no problem. There might be some performance differences, but you'd have to look into that yourself. Python.org's Python interpreter comes with IDLE (not sure if ActiveState's does or not), which is the ide that the book uses. (Because it is simple, not because it is the best.) If you're learning Python, there really is no difference. I'd just default with Python.org's interpreter.
The last crawler I used with Beautiful Soup ended up being 12 or so lines. It's a great library.
[sitescraper](http://code.google.com/p/sitescraper/) was written by someone I know. I've never used it directly, but I have used data scraped by it. It's not a crawler per-se, but it may help with the image extraction. Just something else for you to look into. 
I thought i'd mention [lxml](http://codespeak.net/lxml/). I've tried B'Soup and Lxml, and the latter, whilst harder to work with, was a lot quicker for me. It also has some good docs and ability to use [B'soup as a fallback crawler](http://codespeak.net/lxml/elementsoup.html#using-soupparser-as-a-fallback) if lxml can't figure something out. My use of it is minimal though. Getting "bodyContent" from wikipedia articles, and cover art from Amazon.
For large crawls, Nutch (the crawler that comes with with Lucene) is awesome. It's built on top of Hadoop and is very well-written and easy to extend. Not python but, imho, worth a look.
It might also make it slow.
Second for scrapy. Liked it a lot, has a similar project structure to Django, and it has support for [images](http://doc.scrapy.org/topics/images.html). Also, it uses XPath which makes the job of traversing the HTML much easier IMHO.
[Mechanize](http://wwwsearch.sourceforge.net/mechanize/) is very nice, too. I've found coupling it with BeautifulSoup works wonders.
Nice one, Al. Good to see you incorporated the suggestions about using Pygame from earlier. However, seeing as Python 2.6.4 is freshly released, you should probably link to that one as it is a solid bug fixing release.
If you want speed, go with lxml. If you want a more flexible crawler, go with BeautifulSoup. If you go with BeautifulSoup, you'll want to use an older version (like 3.0.7) to parse ugly and mal-formed code because the newer version has a different HTML Parser in it.
You got a lot of parsing suggestions, so, as a network-level suggestion, I'm gonna posit Twisted. It's good for this sort of thing, as it makes it easy to composite a processing pipeline, and it's remarkably quick. Also, if you're just crawling for images, you can probably avoid a full-on parsing library and take it down to bare-bones - you could probably even implement a regexp solution pretty simply. 
Forget what I said about Scrapy then, that was 10 months ago, and I think it has become better since (for example it uses lxml now). I still don't agree with the design much and if I did something related to scraping I would probably start from scratch. Having said that, you have nothing to lose from trying it, and it may end being what you need. Also, it was mentioned already, but I'm going to say it again anyway: lxml is *WAY FASTER* than BeatifulSoup (and I would like it more even if it wasn't faster)
Have no fear, they are the same.
Use PyQuery: http://pyquery.org/ . It's the beautiful API, but screaming fast (since it's built on top of lxml). Pretty much the hottest thing ever.
I made a spider that downloaded images of at least a certain resolution from a number of sites (the page seeded to the spider served as an index of the images) with Python/Beautiful Soup. &lt; 50 lines, 130-150 images downloaded per minute on average
I just used BeautifulSoup for a project I did over the weekend, I didn't find it very intuitive but with tinkering I got it to work for what I needed. I like the idea of using XPath better. I think I am going to give scrapy a try next time I need to crawl html. 
It will make it slow, you'd like to think you'd be bandwidth limited on this, but I assure you soup will be a huge bottleneck. There are other parsers out there, some which are faster and still maintained. I still really like Beautiful Soup, I just wouldn't write a spider with it (again).
Pyquery is the best. from pyquery import PyQuery as pq d = pq(url="url_you_want_to_scrape") for i in d('img'): #do stuff with images
wget? curl?
Be a man, use regexp.
Also Tidylib to parse malformed HTML, does better job than Beautiful Soup.
Twisted for fast async network communication and html5lib for parsing weird HTML
I haven't done this for a few years, but tidylib + lxml was a very good solution for the large scraping project I was involved in. There may be better ways of doing this now, but the key thing back then was the ability to do xpath queries on html in the wild. Tidylib got things into XML which could be processed by lxml. At the time, the use of Javascript was not as extensive as it is now. If I were doing it now I might also consider using something like selenium, as you may effectively need to emulate the browser environment to get the data you're looking for. Using a real browser may be the best way of reproducing this environment.
Actually, I think lxml.html is better. I've yet to come across anything it doesn't parse, but have run into html that completely broke beautifulsoup. It's also much faster, and shares an API with ElementTree, so there's nothing new to learn if you're already used to processing XML. 
How about using/improving [Harvestman](http://www.harvestmanontheweb.com/)? 
wrote a scraper framework for a previous job: beautifulsoup: clunky, but unicodedammit is fantastic. lxml: this is fantastic. use it and learn xpath avoid urllib2 like the plague, pycurl is pretty good though if a crappy api.
lxml supports html parsing
I found lxml to be more flexible than beautiful soup. you can use xpaths with regular expressions. 
&gt; You should definitely look into the Beautiful Soup library. Definitely not. 1. BS 3.1 tends not to work very well due to swithing from SGMLParser to HTMLParser (or something like that), which makes BS blow up a lot and requires switching to the older BF 3.0.8 instead 2. BS is slow and takes a lot of memory 3. BS doesn't provide xpath or css selectors, which is pretty damn annoying. In general, complex selection query in BS are a no-no I'd strongly suggest `lxml.html` instead: the parser is just as good (as BS 3.0.8's) in my experience (if not better), the library is screaming fast and provides both CSS and (complete) XPath selectors as well as a much nicer ElementTree API to work with elements. The only downside of lxml is that it's not pure python, but I doubt that's an issue for this project.
Why not use lxml out of the box then? lxml.html provides everything you need for screen scraping and you can select nodes using css or xpath selectors (which are much better than BF's selector in any case)
&gt; Python 2.6 is now in bugfix-only mode; no new features are being added According to the linked page
Thanks for this, I have a project that this would make a little simpler, so this is good to know about. (The project is to download the pages that are external link targets in Wikipedia. The pages will be used as examples of disambiguated entity mentions. For instance, if I find the name "Birmingham" in a page linked from Birmingham, Alabama, I'll use it as a positive instance of that entity, and a negative instance of "Birmingham, England". The examples are fed into a machine learner to produce a system to add links to Wikipedia pages.)
More importantly, which adult site are you crawling?
Hey, this is cool. I will use this... for something.
I've had great experiences with [mechanize](http://wwwsearch.sourceforge.net/mechanize/) and [lxml.etree](http://codespeak.net/lxml/tutorial.html) The author of BeautifulSoup seems to have [little interest in continuing development](http://www.crummy.com/software/BeautifulSoup/3.1-problems.html). lxml has modules that mimic the BS api as well. I've no experience with [Scrapy](http://scrapy.org/), but a quick glance at the docs and examples make it appear to have the tools of both lxml and mechanize, I'll have to try it sometime. 
No! str.split, list slicing and string concatenation is much faster.
Can someone explain why you would upvote this comment?
How would you crawl the web? Start at a.com, and go from there? I never really understood how this was supposed to work!
If you were crawling the whole web you'd probably seed the crawl with web sites from a directory such as from the Open Directory project. If you started from just one sight you could end up at a dead end pretty quickly.
Well I was joking a bit about a.com, b.com, c.com, etc., but is that how most crawlers do it, by using a source such as the Open Directory Project?
Yes basically thats how you do it. You would start with a list of 'seed urls' and then from every page extract more links and continue. More advanced crawlers will also execute javascript and get links from there. Some crawlers also 'guess' urls. For example if a.com/?p=1 had content and so did a.com/?p=2, a.com/?p=3 will probably also contain content.
How would I use mechanize on a web wide crawl? It looks as if the only thing that it does that I cant do with lxml + urllib is filling forms. I dont need to fill any forms.
Whats wrong with urllib2?
Thanks for the link. I am doing this mostly for the fun/learning. Thats why most of the code will be written by me. But Im sure that Ill be able to use/contribute to projects like this one and scrapy...
Yes and as for the javascript- Ill probably use python-spidermonkey.
As wikipedia states- web crawling is easy to do on a small scale, but very hard on a large scale.
I also thought about using regular expressions but would that be very hard due to the fact that (probably) most html on the web is malformed?
I couldnt find any information on this.
Yes- Ive seen a couple of benchmarks that show that lxml is faster than beautiful soup.
blah blah blah...what is his point?
I, for one, prefer a 2.6 in bugfix-only mode.
I recommend [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/), but nowadays I would go for [lxml](http://codespeak.net/lxml/). I also recommend debugging with [IPython](http://ipython.scipy.org/), it really helps with navigating the DOM and looking for the correct tags you want to scrape :)
I used QT which had QTScript to evaluate javascript. It worked well enough, and was packaged
// works in 2.6 (even in 2.5, and maybe 2.4).
A very good question, my experience with the tools has been doing a lot of site specific spidering, commonly with login and search forms. Without that, mechanize seems unnecessary. One problem I had with mechanize/urllib was lack of keepalive. A quick search reveals support now via another module: [urlgrabber.keepalive](http://linux.duke.edu/projects/urlgrabber/help/urlgrabber.keepalive.html) Also, another library [urlgrabber](http://linux.duke.edu/projects/urlgrabber/) caught my eye, which could have several advantages for your task of image spidering: * keepalive * byte ranges * resuming * progress reporting * throttling * batched downloads using threads * retries
My elegant comment serves two purposes: (1) discouraging reinventing the wheel, and (2) alerting novice readers interested in image crawlers to alternatives they might not know about.
TLDR: BDFL proposes to stop changing Python syntax for a few years. Most people are okay with it. This will probably happen.
Generally a good thing, but I'm with Jesse in wishing that they'd slip PEP 380 in before the freeze. Oh well.
&gt;Beautiful Soup &gt;BF Er?
Frain Bart, sorry. (and "BS" looks so bad, BS is your Best Friend after all*) *: not really.
It's a pretty funny article at some points, I just don't hope anyone takes it too serious though... Then again, anyone who does, doesn't deserve Python's enlightment ;)
I am really really enjoying my VPS at [http://prgmr.com/](http://prgmr.com/). Great prices and support and no hand holding whatsoever. Great if you're looking for a no BS host.
Tons of nice quotes on there. &gt; While many languages can be used to encrypt data, PERL has something built-in that gives you encryption. Perl calls it "syntax".
If someone were to take seriously something off Uncyclopedia, well, I'd have bad news for them!
I dunno, their article on [Reddit](http://uncyclopedia.wikia.com/wiki/Reddit) seems completely accurate to me. 
The excert here about the GIL is pretty much true from my stand point, python threads are essentially useless from a dealing with blocking IO calls point of view, which is what I commonly have to deal with. Fortunately the multiprocessing module from py3k was made standard in py26 and released for py25 as a seperate download, and it deals with all of the GIL issues I've faced. And it even forces you to correctly share objects (sort of), making it hard to create those really nasty memory sharing race conditions. Unfortunately it doesn't make it easy like Erlang, but thats like saying "my camper van is useless at ploughing fields". Now if only all of the popens would just be killed off so there is just one, and I would be forced to name my first-born Guido.
&gt;Dejected, El Guido almost gave up on the language until a strange, foul smelling Japanese researcher named matz encouraged him to continue. matz' motives were not pure, however, for as soon as Python released a stable version matz stole the code, added a bunch of question marks, and called the new language Ruby. 
Would be funnier if the article actually is sarcastic. But this article is just being opposite to reality.
&gt; python threads are essentially useless from a dealing with blocking IO calls point of view That would be true, except for the part where basically all IO operations in Python release the GIL.
`popen` has been deprecated in favour of the subprocess module, hasn't it? Also, I've no idea how useful it actually is, but have you looked at [Candygram](http://candygram.sourceforge.net/overview.html)? &gt; This package provides an implementation of the following Erlang core functions: &gt; &gt; - spawn() &gt; - send() &gt; - receive &gt; - link() &gt; &gt; These 4 functions form the core of Erlang's concurrency services. The spawn() function creates a new process, the send() function sends a message to another process, the receive statement specifies what to do with received messages, and the link() function allows one process to monitor the status of another process. In addition to these core functions, this package also provides implementations of several supplemental functions such as spawn_link() and exit().
-1, the "post links about python the snake in python the programming language section" joke is pretty tired
re: popen, you are correct, but there are still at least 4 popens left apart from subprocess. It is quite un-pythonic. re: Candygram - awesome, thank you sir.
Except for the *blocking* ones. Have a play with tkinter, and or popen, and or sockets (getting sockets to block is a bit more edge case than the other examples, but is quite doable with relatively simple servers).
Any long-running C operation will release the GIL, *especially* I/O, and *especially* sockets. Otherwise there's no point in having threads at all! From Python 2.6.1, Modules/socketmodule.c line 2310, function `sock_recv_guts`: Py_BEGIN_ALLOW_THREADS timeout = internal_select(s, 0); if (!timeout) outlen = recv(s-&gt;sock_fd, cbuf, len, flags); Py_END_ALLOW_THREADS
The GIL is released for blocking I/O operations: &gt; The lock is also released and reacquired around potentially blocking I/O operations like reading or writing a file, so that other threads can run while the thread that requests the I/O is waiting for the I/O operation to complete. [Thread State and the Global Interpreter Lock](http://docs.python.org/c-api/init.html#thread-state-and-the-global-interpreter-lock)
Beautiful Soup is still excellent even with the speed and memory constraints. The speed at which one can develop algorithms to intelligently crawl the web is greatly increased with the fluent api of Beautiful Soup. *If* you run into a constraint implement portions in lxml. Focusing on the faster tool is bit of painting the bike shed IMO.
&gt; The speed at which one can develop algorithms to intelligently crawl the web is greatly increased with the fluent api of Beautiful Soup. Considering lxml offers css and xpath selector (which are both an order of magnitude simpler, smarter and more efficient than BS's terrible interface which isn't anything even remotely fluent) *and* a better overall interface due to being elementtree's… it's the superior choice by far anytime you don't need a pure python library.
It may not be that much code but I could port my crappy little blog off of App Engine in about an hour. Other than the datastore everything else I use it open and could easy run in a normal Python environment.
You're not allowed to license Perl programs under the GPL, because writing a program in Perl is considered obfuscation.
I have to "metoo" lxml.html. Ian Bicking wrote it, which means its ridiculously well thought out.
Upvoted solely for the comments about using shelx. It's exactly what I've been looking for to parse options in an app I'm writing using Cmd.
I personally use the [real django](http://www.42topics.com/dumps/django/docs.html) and if you really want to grow you can pay them or move your django to a different data store. Personally I don't like ORMs anymore and the bigtable store scales really well. 
bookmarked
Why do you need to keep them up to date? Can't you just install them and use them as-is until you upgrade a program that needs it?
O python, is there no task you cannot be wrapped around?
I love it when people bash something that they don't have a clue about, just because they heard crowds doing this. Especially when it's in the docs.
 db(buyer.id&gt;0).select().find(lambda row:row.name.startswith('C')) Are they just processing the whole dataset client side or is the lambda getting translated into some map function that's executed on the server side? If it's the first option this is kind of dumb. This would only work with really small datasets.
Can the official WordPress release talk to any db other than MySQL? The answer to that question is a pretty good reason to me at least.
It's the first, in fact most of these work by simply moving the operations into Python.
Consider db(query1).select().find(condition) everything in query1 is mapped server side; everything in condition is done clientside. Normally for a RDBS you put everything in query1. If you run on GAE and GAE does not support the operator LIKE, than you have to do it clientside so we provide API for it. GAE limits the max number of records to 1000 anyway.
&gt;People need to get the idea that __init__ is a constructors out of their stupid brains, __init__ is an initializer, it sets up an instance, it doesn't construct anything You're arguing that the standard definition of a constructor (in most object oriented language) is wrong. It has nothing to do with python. What languages have constructors that actually 'construct' the requested object ( in the way that `__new__` does)? 
It amazed me that it's so easy to cause a leak in python...
This won't cause a leak. Python has, since 2.0 I believe, had a 2nd GC that runs in order to clean up cycles. http://docs.python.org/dev/library/gc.html
The article explicitly mentioned that Python leaves alone (leaks) cycles containing objects with a custom `__del__`. 
You're correct that items with ``__del__`` AND a cycle won't be collected, but I don't think that constitutes easy :)
You should look at various accessibility APIs. Accessibility is big on exposing user interfaces in a way that's agnostic as to how exactly the user is interacting.
`__del__`'s a method I could've used without anticipating any danger... Maybe that's my fault.
What operating system? On OS X you can use the accessibility framework. I'm only aware of [how to do this via AppleScript](http://www.macosxautomation.com/applescript/uiscripting/index.html), but there should be a way to do it via Objective-C, and thus via PyObjC (or you could just call the `osascript` command from Python via the `subprocess` module)
Depends on which Python you're using; not all implementations have the same garbage collector.
Really all you have to do is make sure in a child-parent reference cycle to use weakrefs when storing child's ref to the parent. I use the following descriptor... from weakref import ref as make_weakref class weakref_property(object): """descriptor which provides transparent access to stored object via weakref. :param attr: This allows specifying the attribute that will be used to store the weak reference. By default, a random one based on the property's id will be chosen. usage:: class Test(object): x = weakref_property("_x") """ def __init__(self, attr=None): if attr is None: attr = "_weakref_property__%d" % (id(self),) self.attr = attr def __get__(self, instance, owner): if instance is None: return self ref = getattr(instance, self.attr, None) if ref: return ref() else: return None def __set__(self, instance, value): if value is not None: value = make_weakref(value) setattr(instance, self.attr, value) def __delete__(self, instance): delattr(instance, self.attr) 
Reference cycles are incredibly common in many types of software, and proclaiming them as "verboten" is not practical. Using weakrefs to break the chain in a reference cycle is an option, but introduces a performance bottleneck during heavy traversal....and also require care that the cycle is always referenced from the "strong" side else you lose half of it. The best solution, if strong reference cycles can't be efficiently avoided, is to avoid `__del__`... you can't rely upon the object's state within `__del__` anyway. If you need an event to occur when an object is dereferenced, point a weakref with a callback at it. You just have to be careful not to create a strong reference from the callback's local namespace to the object or the weakref never gets triggered (unless the callback itself disappears first, which is similarly useless).
The Expect UNIX tool does exactly what you are looking for. http://en.wikipedia.org/wiki/Expect It runs scripts in Tcl, but there is also a Python version called PExpect http://pexpect.sourceforge.net/
In general, doing this in a GUI is platform- and toolkit-specific. I've pursued trying to achieve the same thing and had some luck with Xext, and a friend has had some joy using WinAPI, but it's a fairly tedious process and the tradeoff between generality and power is sharp. If you know your target app is built using Tk/Qt/Gtk there are better specific ways to handle it; if not you're basically stuck with screen-scraping or recording relative coordinates of events and praying. More info at http://wiki.tcl.tk/15726. For Windows, http://www.autohotkey.com/ is a pretty popular tool for doing expect-like things to GUIs. For console-based apps, Expect is awesome.
I see you getting upvoted. Can you be a bit more specific?
That doesn't work if you don't know in advance if the child will only parent's ref.
Expect doesn't interact with GUIs, which is what OP wants. BTW have you used pexpect? I've found it to be flaky and slow.
Of course, as Spyder is an IDE, "MATLAB-like" means here "MATLAB's IDE-like" or in other words: "Spyder is to Python language what MATLAB's IDE is to MATLAB's language"... but it's quicker to write "Spyder [...] (has) MATLAB-like features [...]". That's all!
[pyWinAuto](http://pywinauto.openqa.org/) for windows GUI automatio. In my experience I've found it to be unintuitive but I thought I might mention it.
You did not mention the operating system, which is critical to give a good answer. Windows has excellent accessibility features, but there's no easy way of enumerating a list of all controls you specifically can interact with. The best you can do is make assumptions. In Windows every control has an optional WindowText and a mandatory Classname. The latter usually spells out the type of control it is; Edit for Edit boxes, Button for Button, etc. But this all depends on the GUI toolkit, the individual control, whether it's using Windows' Common Controls, etc. `EnumWindows` and `EnumChildWindows` are what you'd want if you want to enumerate all controls belonging to a parent window. As for keyboard/mouse input: use `SendInput()`, it only works well when it's used in a thread in the same process as the one you're trying to interact with. 
Building a pokerbot, eh?
Those doc's are for if you are a C program with multiple threads attempting to interact with a Python VM from outside. If however you are a Python program interacting with certain system land things, like for example the modules I listed, then it is not terribly difficult to block the Python VM. 
While programming with Python, I rarely *had* to use cycles. When I did, it was usually easy to keep the 'strong side', as the 'weak side' were usually back-references. Regarding avoiding `__del__`: when acquiring resources, you sometimes *have to* use `__del__`. In that case you can try to just take it out of the cycle.
cycles are common in highly traversible structures like DOM trees and are also necessary for other kinds of rich object interfaces. Such as an object referencing a dictionary-like object that provides a key-value interface to a certain part of the parent's state. edit: also I've yet to see a `__del__` that can't be written using weakref callbacks. usually you're trying to finalize some state which the deleted object references. The callback is passed those references at construction time and takes care of finalizing them independent of the need for the original `self`. `__del__` in my experience is pretty unreliable in general.
That sounds reasonable, next time I write code with cycles, I'll consider your approach. Could you please expand on "`__del__` is unreliable"? I've written (in the blog posts) about some ways in which it is, but it seems you're referring to something else.
There's also [appscript](http://appscript.sourceforge.net/) for Python which allows one to communicate with Mac applications in much the same way that AppleScript does but with less of the soul-sapping AppleScript quirks.
how does one write an efficient and optimized query without intimate knowledge of exactly what conditions evaluation is shifted into in-memory ? do you provide a planner tool ?
web2py does not automatically shift queries into memory. You have to be explicit on where is the query to be performed, in the database engine or locally in memory (see howto in the previous answer). If you use a RDBS you would probably do everything at the database level. 
So, honest question, how is this any different than writing this as: ``filter(some_predicate, some_web2py_query)``
In terminal type: `man python` You'll see you can get Python 2.5 by typing `python2.5` which gets you into the Python 2.5 interpreter. If you want the change to be permanent, type: defaults write com.apple.versioner.python Version 2.5 
You could consider using a virtualenv to create a sandbox for your project: % sudo easy_install virtualenv % virtualenv --no-site-packages --python=/usr/bin/python2.5 &lt;sandbox-name&gt; % cd &lt;sandbox-name&gt; % source bin/activate Your prompt will change to include the sandbox name and when you launch python, you'll see you're using Python 2.5. The additional nice thing is that when you easy_install further packages they'll just be added to the virtualenv rather than the system python. To leave the virtualenv, just type % deactivate
2.6 contains only new features that won't break backwards compatibility. 3.0 contains changes that *will* break backwards compatibility, such as the change of the `print` command to a function. The core modules will work, but as `masklinn` says, external libraries probably won't. My coding has only been for personal projects, and I absolutely love Python. It's like writing pseudo code all the time. Best of luck to you.
Functionally it is not. The difference is only syntactical (acts on a Rows object not a list and returns a Rows object). It makes it easy to do thinks like db(....).select.find(...).sort(...).json() for example. Some of the the other API described in that page are less dumb (like lazy evaluated attributes and virtual fields). Of course, in a sense, everything on this topic is trivial and dumb when compared with Relativistic Quantum Field Theory. ;-)
Congratulations for not reinventing the wheel. Not sure why I'm being downvoted for congratulating them on targeting for LLVM, instead of creating their own JIT compiler.
Thanx a lot that's awesome! And i'm a noob... could you tell me how i could install package without easy_install in this sandbox? Oh and also : i like to run my script via textmate, how can i get texmate to use this sandbox? I know that's a lot of questions but thanx!
You'll notice in the sandbox that there's a bin, include and lib directory that's been created. Packages can go into lib/python2.5. I'm not sure about TextMate however, as I don't use it. You may be able to [set up the search path](http://manual.macromates.com/en/shell_commands#search_path) to additionally source that 'activate' file in bin.
I love this idea but there isn't enough recent material... It's hard to get a critical mass for this sort of thing.
Intriguing article, but doesn't tell us much new. Also needs some fixing. It badly needs more definitions - for example, what exactly is an "AST evaluator"? The correct definition doesn't come up when you Google that phrase, many people reading the article won't know it - I'd say AST parser myself. The language trips over itself. For example, this whole sentence could vanish if the second paragraph were better structured: "Strictly speaking this is an exceptionally broad category which encompasses most virtual machines today, however for the purposes of this article I'm going to exclude any VMs with a Just-In-Time compiler from this section (more on them later)." (later meaning one sentence later!) You could just say: "There are three types of interpreters, Abstract Syntax Tree parsers, and byte-code interpreters with or without a Just-In-Time compiler." then speak a little about each one, and lose most of that paragraph! Still - more is good! Tell us MORE more!
Thanks for the feedback (author here). I'll definitely be blogging more on this topic, I'm doing the "blog every day for a month" thing this month, so tonight I'll have another post up covering some of the optimizations unladen swallow has implemented.
I'm totally psyched! Sorry the feedback came out a little harsher than I intended...
It sounds like you're saying "Unladen Swallow are reinventing the wheel" using sarcasm.
I'm using a VPS from [glesys](http://www.glesys.se), it's a Swedish service though!
I thought you get Abstract Syntax Trees from parsing?
Python has a pretty big libarary of modules, is relatively well documented, easy to read, easy to code in (once you get used to whitespace, which isn't that difficult), and as an interperative language, it's nice to be able to code and test on the fly in IDLE without having to go through the whole build/compile routine each time. I also like that it's an actively developed language (and moving toward stabilization), and mostly, it just takes a few lines of code to do what takes many lines in other languages. All this being said, of course there are tradeoffs, but as a scripting language, I love it.
You could also go a bit more into the LLVM - I vaguely know what it is, but more depth would be nice. Great idea for articles though! I've long wanted to know more about unladen swallow.
I feel like my entry kind of ends a little early in the story. I think I may need to do a follow up on \_\_del\_\_() and breaking cycles as well. Feedback is appreciated.
Who asked you?
&gt; tradeoffs such as ? (imo: job prospect not that great)
His imaginary fans
That's cool then. Feel free to blow off my criticism.
I used pexpect and it wasn't bad. You have to make sure you change buffering for large results and the speed isn't an issue. The only issue I have with pexpect is that it wasn't very 'pythonic' with it's use of .before and .after.
I am about 6-10 times faster developing web apps in Python than in Java. And when I am done my code looks purdy.
Basically, you should almost never implement __del__, just as you should almost never implement __new__. It's analogous to rarely explicitly writing 'new' or 'delete' in modern C++. If you need some form of RAII, consider instead looking into the protocol for with-statements.
Can you explain a bit more which part exactly causes the refcycle? I used to think cycles are really hard to hit if you code semi-intelligently but this seems not to be the case.
"If, however, you’re writing a high performance internet server intended to handle the ever increasing demands of the modern Internet, you just might be screwed." Why would you ever use Python for a high performance internet server??? If high performance is your biggest concern you would get better performance out of C. Of course, your development time would dramatically increase...
It's got almost everything I need for rapid development in the base language. The only basic thing I can't do quickly with the default installation is web development (and no, I don't think they should choose a particular web development framework as something to include as a part of the default install, at least in part because the database interface modules need to remain separate, and in part because in two to three years, someone will do it better\*). The only thing I'd suggest changing in the default install is the widget set, though the best options (GTK+ and Qt) really can't be shipped with the rest of Python without changes in Python's license, while Tkinter doesn't have this problem (despite looking like like ass and not having a means of laying out interfaces graphically). \*For proof, look at the state of Zope three years ago and compare it to where it is now. Pylons and Django will ultimately meet the same fate.
how many fucking people who have read the introduction paragraph to every langauge in the world needs to chime in with their fucking retarded ulta high level performance crap. 
how cynical we have become
I think you're right, a more straight for approach would resolve the circular references. Change AddLF and AddCRLF into functions that return the modified string instead of sending it off to a call back and the cycle is gone. It would also make the code a lot clearer. Though I'm sure that the motivation for using a call back was removed for a simplified example.
Any chance on posting the refactored code? I'm curious what your solution was.
And after one swift s/?/./, all is solved!
That's it. Where having a Visual Basic code off. Meet me at 0x00000005
The last link of the cycle is that a bound method keeps a reference back to the instance it was pulled off. (He mentions the bound reference, but it might not be clear if you haven't played with them.)
&gt; code stability provides more benefit than new syntactical candy and included batteries and obsessive reorganization. That's why COBOL and Fortran are so much better than Python and modern languages.
I'm going to be sticking with python 2.5 for a while, because that's the last version that doesn't require the Visual Studio C++ redistributable files to be installed on Windows in order to run.
What do you mean? 2.6 installs and runs fine for me without any additional files.
You've probably already got them installed. If you're a Visual Studio user, then it's a certainty. [Here's a mention](http://koobmeej.blogspot.com/2009/08/python-26-py2exe-and-vc-runtime-issues.html) of the problem when freezing programs using py2exe.
I'm not, I don't have VC installed on my XP Pro SP3. Thus my previous post. Windows Python is using VC DLL in one form or another, though in the past it was IIRC msvcr.dll, without version. I think this file (and msvcr71.dll used later) are provided by Windows Update at some point.
It's probably installed by the Python installer itself, then. That doesn't help if you ship programs packaged via py2exe, though. Edit: Since VS 2005, redistributable files (*90.dll) haven't been installed by Windows Update, more's the pity. *Last edit, I promise* -- Until python 2.5, you could just plop down the C-runtime files in your directory when packing with py2exe, but starting with python 2.6, the new side-by-side DLL model is used, and , and you can't use side-by-side with DLLs (you need to install the files with vcredist, or use a merge module).
No, I'll accept it. I didn't look well at the linked URL, assumed it was a self post without any accompanying description, just an open question for folks that use python. Queue the egg on my face. Oh well. You live and you reddit.
My pun threads never take off :~(.
Negative things just quickly: * Relatively unkown language. * No static type check, runtime errors. Must write unit tests, asserts try-excepts etc... * Performance. * GIL paralell compute-intensive threads anybody? * No mature library and 3d party support, especially hybernate, MQ, SAP, Oracle, OLAP engines, freeze and other "enterprisey" things. * Problems with distutils and deployment I leave the good things to others. 
How did you notice that there was a problem at all? I had a funny experience with GC not long ago: def generator(N): return ((x,y,z) for z in xrange(1,N+1) for y in xrange(z+1) for x in xrange(y+1)) def benchmark0(N): return set([t for t in generator(N)]) def benchmark1(N): return set(generator(N)) For N=300 this benchmark0 runs in about 20 seconds and benchmark1 - in about 50 (!). If, however, I measure time using testit (which disables gc and almost drove me insane with this!), then it's about 4 and 3.5 seconds. Basically, the idea is that default gc settings are to collect gen0 after 700 uncompensated allocations, gen1 after 10 gen0 collections, gen2 after 10 gen1 collections. Which means that if I allocate ~500Mb of data it spends a lot of time just walking the whole graph repeatedly on gen2 collections -- they happen every 70000 allocations and I did about 18 millions If my calculations are correct. So if you want to allocate a lot of small objects, you better disable gc while you're doing it. Don't know why benchmark1 with is two more times slower though.
Oh, I see now... I didn't realize that a passed method was called "bound", and the gc output shows the instance. Thanks for the clarification.
I'd like to try my hand at porting an existing library to python 3000. Maybe others have this urge too. I'm not sure how I should go about this. Ideally someone who's already part of a development team would come here and say they need a hand. I think I'm a bit scared to just go knocking on the doors of big projects like mercurial or bazaar for example and ask them if they've got plans for porting to py3.
all of them? library availability is probably the biggest stopper for py3k adoption.
pygame
although it would be a huge undertaking... twisted and django
It's not exactly porting since they have Python 3000 support, but from what I've read the Distribute (setuptools replacement) people would love a new programmer to general bugfixing, feature-implementing work. And you'd essentially be working on a project that might get used by thousands of Python libraries.
Really yummy stuff that reveals all sorts of details! In today's Python, if I'm describing a new function and have the choice of def Fn(my_list): # .... or def Fn(*my_list): # ... which is faster? I'm believing now that the second one is, because there is only one list construction...
I'm not sure if there is a difference, but there isn't one as a result of the METH_O stuff I describe, those flags only apply to C functions.
wilberforce is correct. I'll add something to the blog entry to make the description of loop explicit. Edit: Added to blog entry paragraph after the gc output: "This bound method holds a reference back to the Foo instance, completing the cycle." Thanks for the input!
Using things like coroutines or Twisted it is very possible to make massively scalable systems in Python.
We saw a 20% loss in throughput when the feature in question was turned on by a customer handling ISP-level loads. From there it was just profiling and testing to identify that there wasn't anything in the code path we'd written that would cause that level of slowdown. Additionally, our heap was much larger than we'd expect to see; that was the kicker that told us we were "leaking" memory.
I really don't understand what this is about. Is this their pygments?
No, its a library for programmatic analysis and transformation of Python code. You could use it for pygments like stuff, but that only needs the lexer component.
congratulations!
Django, numpy, scipy, matplotlib, Twisted, SQLAlchemy
Mostly because it is good enough. Parts of it are great (love the introspection capabilities) and some parts drive me batty (like how self is used). There's lots of stuff in the libraries, it's popular enough that other people have already solved all the problems that trip me up and a search almost always turns up a solution quickly. There are certain tasks that I end up solving over and over again. For example, I've probably written 10 different programs for search and replacing text in a file and it always takes me longer than it should because regular expressions are a huge PITA. Don't think this is a Python problem though. 
Uninstall the ubuntu package and install the easy_install ipython package?
SQLAlchemy already ported.
Using easy_install makes you a bad person. I assume you meant pip.
haven't noticed a difference or cared enough to change my habits.
Could you explain for the uninitiated? I know that easy_install doesn't have an uninstall...is that why? Is pip going to replace easy_install? Hmm...markdown is eating my underscores and making italics out of it...that's not right...
\\_ to write underscores. Pip doesn't have uninstall either. They're maybe possbily considering possibly in the future, maybe.
This is a [known bug](http://bugs.python.org/issue5833) in Python's readline module. Arch Linux already applies the patch attached to the bug report in their builds and it should be included in Python 2.6.5 and 3.1.2.
You could take a look at http://bpython-interpreter.org Though I am a developer of that and might be biassed.
How dare you self-promo... Ooo, a full curses-based interface w/ popup autocompletion. Nice! Gonna try that out for a while instead of ipython.
I HATE the subprocess module. I want the popen functions: popen2(), popen3(), popen4(). Here they are: # Popen functions for python3 adapted by RVD def _methodist(func, instance, name=None): """Inject a function into a class instance. """ import types setattr(instance, name or func.__name__, types.MethodType(func, instance)) ##def popen(cmd, mode='r', bufsize=0): ## """Open a pipe to or from cmd. ## ## The exit code is attached to stdout.close ## """ ## import subprocess ## if mode == 'r': ## p = subprocess.Popen( ## cmd, ## shell=True, ## bufsize=bufsize, ## stdout=subprocess.PIPE) ## # inject new close function: ## def popen_close(self): ## self._close_orig() ## return self._p.wait() ## p.stdout._p = p ## p.stdout._close_orig = p.stdout.close ## _methodist(popen_close, p.stdout, 'close') ## # ## return p.stdout ## elif mode == 'w': ## p = subprocess.Popen( ## cmd, ## shell=True, ## bufsize=bufsize, ## stdin=subprocess.PIPE) ## # inject new close function: ## def popen_close(self): ## self._close_orig() ## return self._p.wait() ## p.stdin._p = p ## p.stdin._close_orig = p.stdin.close ## _methodist(popen_close, p.stdin, 'close') ## # ## return p.stdin ## else: ## assert False, "invalid mode: %s" % mode ##__all__.append('popen') # Don't reimplement os.popen if you don't have to. import os popen = os.popen try: __all__.append('popen') except: pass def popen2(cmd, bufsize=0): """Execute the shell command 'cmd' in a sub-process. On UNIX, 'cmd' may be a sequence, in which case arguments will be passed directly to the program without shell intervention (as with os.spawnv()). If 'cmd' is a string it will be passed to the shell (as with os.system()). If 'bufsize' is specified, it sets the buffer size for the I/O pipes. The file objects (child_stdin, child_stdout) are returned. The exit code is attached to stdout.close """ import subprocess p = subprocess.Popen( cmd, shell=True, bufsize=bufsize, stdin=subprocess.PIPE, stdout=subprocess.PIPE, close_fds=True) # inject new close function: def popen_close(self): self._close_orig() return self._p.wait() p.stdout._p = p p.stdout._close_orig = p.stdout.close _methodist(popen_close, p.stdout, 'close') # return p.stdin, p.stdout try: __all__.append('popen2') except: pass def popen3(cmd, bufsize=0): """Execute the shell command 'cmd' in a sub-process. On UNIX, 'cmd' may be a sequence, in which case arguments will be passed directly to the program without shell intervention (as with os.spawnv()). If 'cmd' is a string it will be passed to the shell (as with os.system()). If 'bufsize' is specified, it sets the buffer size for the I/O pipes. The file objects (child_stdin, child_stdout, child_stderr) are returned. The exit code is attached to stdout.close """ import subprocess p = subprocess.Popen( cmd, shell=True, bufsize=bufsize, stdin=subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.PIPE, close_fds=True) # inject new close function: def popen_close(self): self._close_orig() return self._p.wait() p.stdout._p = p p.stdout._close_orig = p.stdout.close _methodist(popen_close, p.stdout, 'close') # return p.stdin, p.stdout, p.stderr try: __all__.append('popen3') except: pass def popen4(cmd, bufsize=0): """Execute the shell command 'cmd' in a sub-process. On UNIX, 'cmd' may be a sequence, in which case arguments will be passed directly to the program without shell intervention (as with os.spawnv()). If 'cmd' is a string it will be passed to the shell (as with os.system()). If 'bufsize' is specified, it sets the buffer size for the I/O pipes. The file objects (child_stdin, child_stdout_stderr) are returned. The exit code is attached to stdout.close """ import subprocess p = subprocess.Popen(cmd, shell=True, bufsize=bufsize, stdin =subprocess.PIPE, stdout=subprocess.PIPE, stderr=subprocess.STDOUT, close_fds=True) # inject new close function: def popen_close(self): self._close_orig() return self._p.wait() p.stdout._p = p p.stdout._close_orig = p.stdout.close _methodist(popen_close, p.stdout, 'close') # return p.stdin, p.stdout try: __all__.append('popen4') except: pass 
Seconded, especially for numpy, scipy, and matplotlib. Unfortunately, it's going to be quite awhile for numpy, and therefore the other two, as well. Lots of C. Lots of work.
mysql-python, numpy, scipy, matplotlib
This happens to me with ipython on the mac (through macports).
http://www.b-list.org/weblog/2008/dec/15/pip/ covers the issues nicely.
On a totally unrelated topic, why the _fuck_ does launchpad use https?
Upvote for you just since you made a comment on a year old story.
PyGTK!
Thanks!
&gt;One of the many tools using Python is GroupThink, which lets random people on the web help classify galaxies (more fun than watching porn :-). Don't forget python-based tools to allow random people on the web to classify porn. Like /r/nsfw
**Numpy**, but that's not a one man job. How about PySerial? 
+1 for bpython. The undo feature is particularly nice.
LOL
Yay! Guido acknowledges the existence of the large and disruptive force that Python represents in the vast area of scientific computing. He's come out to SciPy before but it's great to remind him that there is a whole genus of non-web-based applications where Python is playing an absolutely critical and transformative role. Kudos to Fernando, Jarrod, and the whole Berkeley contingent for inviting him to their symposium!
Well said!
yeah, basically, corporate code-monkeys or data "analysis-paralysist"
Its there now in the pip dev branch. You can upgrade to pip dev branch by pip install --upgrade pip#egg=dev I have been using it for a while and its stable. uninstall is important and works well.
And why would that make any difference?
I am a working research scientist who does most of his work in Python and is consequently much more productive than his C/C++/Fortran colleagues. Sadly people, including young researchers, are very closed minded to adopting new languages/technologies in the Scientific world and this inhibits the wide adoption of Python and their own work. These great projects are sadly the exception not the rule.
Any documentation for how to use it with django?
The heck?
Well yes, on the documentation site there is a chapter about django: http://docs.bpython-interpreter.org/django.html
I'd love to use Python instead of MATLAB, but our complicated testing harness is in MATLAB. So I'm building python bindings for MATLAB. I need to throw them up on github one of these days...
Thanks for reply. Fiddling with buffering is indeed necessary. Did you ever encounter a limit (just above 1000 characters for some reason) on the length of strings you can send? We found this recently -- I haven't reported it to the author yet but I will.
If the issue was with ubuntu's ipython package you would replace it with a different build of ipython? Considering my ipython works from easy_install it might be worth a shot. Probably took longer for you to ask the question than try it out. But it looks like it was a bug in 2.6.4 so forget it anyway.
&gt;Maybe uninstallation will get added. (It might get added to easy_install, but I think the chance for pip is higher.) They should update their homepage.
Sorry, I never used it for sending big amounts of data. The stuff I usually send is not bigger then 300 chars. The responses sometimes contain 400K chars though. Also the module is written entirely in Python, which is nice if you need to troubleshoot/tweak it.
Wrong parent to reply to :) Oh, and BTW, easy_install is not being maintained any more; And pip has already added uninstall; but it is right now only in the dev branch.
pyglet, pygame, cocos2d, pygimp, blender python bindings
I would like to invite you to join the subreddit r/scipy ( http://www.reddit.com/r/scipy/ ) a place to tell the Reddit-Python-Science community about your projects and post news about the evolution of Python in science. "A subreddit for everything to do with high performance/numerical/scientific computing using Python. NumPy, SciPy, matplotlib, SAGE, Cython, the Enthought Tool Suite, and many more."
Please do it. Seriously, PM me when you do and I'll definitely help contribute. 
I would go with mysql-python, some of these other projects are too big to be a one man job.
:( *hug*
I met him for the first time just this month. Clearly a great advocate for Open Source scientific software. Makes me recall just how tenuous our existences are. RIP Warren.
.
not even 40 ? what happened ? RIP
RIP :( The company I work for uses PyMol daily.
Alpha quality, but nice promise.
Looks nice, but does it provide the high level approach regarding IO (socket errors) on various platforms? Twisted does that for me you know.
If you already have an iterable, the first is better, since you don't have to un- and repack it.
Sounds very close to [eventlet](http://eventlet.net) which is itself built off of [greenlet](http://pypi.python.org/pypi/greenlet)
I like the io-scheduled coroutine model, and I like that they use get/swapcontext instead of fiddling with the stack directly, but it bothers me that it has forked versions of Python, wsgi server, memcache client and psycopg. Eventlet lets me monkey patch a standard python so that code written using threads and sockets magically performs better and uses less memory.
Oh good, another option parser module for Python! I don't need anything for Christmas now.
That might have been a better title. Only one nitpick is that argparse is an old parser, the news is the new feature.
You can just run.. nosetest --with-xunit --with-coverage ..to output the XML reports and coverage, without having to run your unittests several times
"The effects of Python in the development community" - that's a debating theme not a research paper title IMO. Try something that would be very popular to read nowadays: "Python &amp; Google - serious language used by serious people?"
Why do you guys follow the Django convention of calling controller files "views" when in software engineering textbooks a "view" is what you call a "template"?
This is explained in http://docs.repoze.org/bfg/1.1/narr/introduction.html#similarities-to-other-frameworks
I really like that idea, I'm going to see what I can find on it, and see if anybody else posts an idea. Thanks.
Isn't it amazing that [MVC concept](http://en.wikipedia.org/wiki/Model%E2%80%93view%E2%80%93controller) goes back to 1979? EDIT: I think this is fascinating since the concept of MVC (or MTV or MVP) is still not taught much in schools and alien to many programmers, yet so useful.
and the point is?
what point?
What kind of research, in particular? As in, using Python to do some interesting research? Or writing about how Python has changed the world in some way? Or something else?
While I won't pretend to have all the answers, to me, MVC doesn't match the web very well in general. From the article you reference: Though MVC comes in different flavors, control flow is generally as follows: The user interacts with the user interface in some way (for example, presses a mouse button). The controller handles the input event from the user interface, often via a registered handler or callback and converts the event into appropriate user action, understandable for the model. The controller notifies the model of the user action, possibly resulting in a change in the model's state. (For example, the controller updates the user's shopping cart.)[5] A view queries the model in order to generate an appropriate user interface (for example, the view lists the shopping cart's contents). Note that the view gets its own data from the model. The controller may (in some implementations) issue a general instruction to the view to render itself. In others, the view is automatically notified by the model of changes in state (Observer) which require a screen update. The user interface waits for further user interactions, which restarts the cycle. If you think about this critically: Do your templates ("views") always query your model directly? I dunno about you, but my "controllers" do this, massaging the data for easier use by the "view" (template). Likewise, what do you do when your "controller" returns JSON? Do your controllers use a template to generate JSON? If not, where's the "view" then? We just punt and say basically there are two things: the model, and the view. The templates are really just an implementation detail of any given view (a view doesn't need a template to return a response). To be honest, I don't t think the originators of "MVC" would agree that MVC web frameworks have anything to do with their definition of "MVC". People want to give web apps the same properties as common desktop GUI platforms by using the same terminology as those platforms. But it just doesn't match up very well. I basically agree with this article on the subject: http://www.sitepoint.com/blogs/2005/12/22/mvc-and-web-apps-oil-and-water/ . 
A second article also exists at http://www.reddit.com/r/Python/comments/a2ajm/an_introduction_to_bfg_part_2_of/
Really wish they'd have kept this blog up. :(
the point that mvc goes back to 1979. or rather the implication that it is somehow good or infallible. This is what I'm asking, what the hell's your point?
Portage /pathetic-fanboy.
&gt;•The Hubble Space Telescope team in Baltimore has used Python for 10 years. Win
More like that I guess. Its a paper for english (very general english) and it can be on anything, and i want to use this opportunity to learn more about python, which is why im looking for a decent topic. doesn't have to be super geeky.
This is not to mention that templates are *embarrassingly cache-able* (if on the off chance they do become the bottleneck). Lex, parse, and just re-run the evaluation of the syntax tree with whatever environment the caller passes in.
I explained it above. I edited my post before your reply. I was not making a statement about the naming convention but about the concept in general whether one calls it MVC or MTV (Django, Repoze) or MVP (.NET). Thanks for the good work.
k cool, i thought you were going to be one of those guys that believes everything was invented, there are no new ideas to be had etc. etc. etc..... FWIW, I am not a software engineering purist, but to me using MVC in the strictest sense makes me write a lot of code in controllers. And I don't like it, it's usually a bunch of wiring, boilerplate stuff that clutters up what I'm actually trying to do. Views are clean, models are clean, and the reason is because all the duct tape to make the app actually do things is in that controller. I don't know how django does it, but bfg to me allows for a nice decomposition of what would normally be what I would put in the controller, thus I think my separation of concerns is better. And I'm not even sure whether that is the intent of the framework authors, but hell it works for me. I should probably elaborate on this more in my next article, because it is indeed my favorite part of the framework.
Because Scheme is lacking libraries, availability and a powerful, standard object system and Common Lisp is butt ugly. I'm pleased with Python's dynamic, Lisp-1-y design, cleanliness, object system, libraries and ubiquity. I'm displeased at Python's statements (should be expressions) and Guido's contempt for/trolling against functional programmers.
I'd be interested in learning more about design decisions. Thanks.
How are you interested in it without "actually know"ing it? Is this like when you have a crush on a girl even though you've never talked to her? You think she looks good and you're positive you'll have so many things in common, once you get to know each other.
I only know web scripting languages at this point, and would like to learn at least 1 major language like java / cpp / python and after doing a bunch of reading on all 3, as well as comparisons, python seems to be the one that sounds most appealing to me, that I would want to devote a lot of time into learning. Then, once I actually know how to use it, I can see if I like it as a language.
Anybody else getting a 505 - Server Too Damn Slow on this page?
Now, let's take Cython and improve on that one. No, wait, let's write it in Assembler!
Write about how to remove the GIL
I dunno, I've seen some things done with sed and cat...
How about calculating carbon emissions per page served with django vs. ror? import paper paper.introduction() paper.body("ponies") paper.conclusion(tone="witty")
Maybe.
You forgot a link.
fixed
How does this templating engine stack up against django's?
no
It's faster.
I'd write about the origins of Python. Take the angle that it's a current-day extension of Dutch entrepreneurship and intellectual excellence that was first manifested in the Enlightenment era centuries ago. Bring in a discussion of how Spanish imperialism, Lutheran puritanism, and Catholic crazy-fucking-pope-ism was still stifling scientific and social innovation throughout the rest of Europe, thus concentrating free thinkers like John Locke and Christiaan Huygens into the little subsea country. Finally, draw a ridiculous and unsubstantiated parallel between the influence of John Locke on America's Founding Fathers and the influence of Guido van Rossum on American innovation within the software development field.
By *at least* 0.5%.
Yes, their blog had some potential :(
I love the touch of making every template variable a system global. Speed can also be improved by reducing pattern matching requirements, restricting template variables to a single character. Phillip.
For clowns who down-modded without any comment -- thanks a lot, keep it classy.
so i don't get it. isn't .5% basically nothing?
The title of the blog may give it away ;) He's suggesting that people should spend less time "optimising" their templates and more time optimising the important things like database query times and the actual business logic.
research on: 1) Why Python - w/ all its benefits - is so little used/adopted in the **corporate world**. 2) (Related to #1) If it is, in general, considered (by the corporate world) as a "hobby language", why is it so and how to correct that. Basically, why, in the corporate world, has Python not been able to have the adoption as the following * Cobol * Basic * Java I think these questions are relevent especially to today's economic landscape - jobs, companies looking to save/increase productivity etc. 
If you use a Python install tool such as pip or buildout, then you just need to deploy your own project, and you can automatically pull Django in as a dependency. You could probably just shell out to pip from Capistrano if you wanted to keep the scripting parts of your deployment to within Ruby. Although that might be kinda klunky ... and if your project only has one dependency then not really worth the bother. 
Thanks. It was useful to making [this](http://www.reddit.com/r/Python/comments/a2j3g/beautifulsoup_script_to_convert_almost_any_html/)
Yay I've contributed a patch to that, I've never been happier!
Jim Fulton started [calling the Controller part of MVC Views in 2001](https://mail.zope.org/pipermail/zope3-dev/2001-December/000063.html) during the creation of Zope 3. I don't think anyone at the time was thinking about MVC, or about trying to stuff square pegs into round holes, although the Java people had already started doing this at least a year before. And I'm pretty sure the Django people came up with name Views independant of taking a cue from Zope :P 
You can also download 408 already converted layouts (together, in one zip file) [here](http://web2py.com/layouts) 
this is an extremely handy tool. 
Surely you jest. Ed is full of luxurious features shunned by Real programmers who prefer [TECO](http://en.wikipedia.org/wiki/Text_Editor_and_Corrector). How are you going to compare with the simplicity and elegance of: @^UB#@S/{^EQQ,/#@^UC#@S/,^EQQ}/@-1S/{/#@^UR#.U1ZJQZ\^SC.,.+-^SXQ-^SDQ1J#@^U9/[]-+&lt;&gt;.,/&lt;@:-FD/^N^EG9/;&gt;J30000&lt;0@I//&gt;ZJZUL30000J0U10U20U30U60U7@^U4/[]/@^U5#&lt;@:S/^EG4/U7Q7;-AU3(Q3-91)"=%1|Q1"=.U6ZJ@i/{/Q2\@i/,/Q6\@i/}/Q6J0;'-1%1'&gt;#&lt;@:S/[/UT.U210^T13^TQT;QT"NM5Q2J'&gt;0UP30000J.US.UI&lt;(0A-43)"=QPJ0AUTDQT+1@I//QIJ@O/end/'(0A-45)"=QPJ0AUTDQT-1@I//QIJ@O/end/'(0A-60)"=QP-1UP@O/end/'(0A-62)"=QP+1UP@O/end/'(0A-46)"=-.+QPA^T(-.+QPA-10)"=13^T'@O/end/'(0A-44)"=^TUT8^TQPJDQT@I//QIJ@O/end/'(0A-91)"=-.+QPA"=QI+1UZQLJMRMB\-1J.UI'@O/end/'(0A-93)"=-.+QPA"NQI+1UZQLJMRMC\-1J.UI'@O/end/'!end!QI+1UI(.-Z)"=.=@^a/END/^c^c'C&gt; 
never speak its name lest it take your soul.
&gt;Why Python - w/ all its benefits - is so little used/adopted in the corporate world It's not native to windows. It's pretty popular where there are plenty of 'nix platforms and some windows deployments as well (my old school comes to mind on the last one.) Of course there's Google which really stresses the hell out of python. "hobby language" is an excuse people use to explain why they don't want to be interested in Python (mostly perl diehards and corporate windows guys who want to look good by saying that if they don't know it, it's because it's "crap" with "hobby language" being used because it's hard to repudiate since it's based so heavily on one's opinion.) /misdirected-rant.
there's only so geeky you can get with an english paper since the teacher needs to know what the hell your talking about. Unless you try to make it come off as just _really_ postmodern, anyways.
oh man, I hope that emacs script actually exists.
downmodded for sharing code? When did microsoft get to reddit?
I still have to try harder to use that, but Makefiles do the job for me.
why not use sqlalchemy and forgetaboutit?
[yes another](http://groups.google.com/group/comp.lang.python/browse_thread/thread/6c5f48c8a79063f5?hl=en) parallel ssh library...
Yeah, that's how it "sells" itself so to speak. However, you can do pretty much whatever you want with it. I use it to deploy webapps, but that doesn't prevent me from using it to do trivial sysadminning tasks though. I deploy my app, restart apache and memcached, all with in a matter of minutes. I could extend my fabfile a bit to do that on 10-15 servers without too much pain as well. It's a lot easier than futzing with expect imo.
&gt; Anyone using this as a library? Using it as a tool not a libary. Fundamentally I see it as alternative to one of the many [parallel ssh](http://delicious.com/tag/parallel+ssh) implementations out there - a way to issue commands to multiple servers. By placing those commands in a "fabfile" you think I bit more carefully about what you're doing before issuing potentially destructive commands to you entire server farm. You also have a nice convention that others will immediately understand - if they find fabfile.py in the root of some project you've been working on, they just need to... fab --list ...to get a list of commands to administer that application.
I provided a repro for a bug. Not as cool as a patch, but still nice to know I could help.
I love contributing to open source projects, especially when they're on Github... I feel like an insurmountable barrier has vanished when I see it's on Github.
I **love** Fabric. Usually it takes about an hour to configure Apache for a new django project, virtualenv, etc (mainly because it's so boring I stop doing it), but I wrote a few Fabric commands to do everything for me, so now I just check the project out on the server, run the two commands and Apache is good to go.
just used cpan, it's actually a shell script nowadays, to install some packages use: cpan Modern::Perl Moose This will use your configuration (system-wide or home) to determine ftp mirrors, dependency handling and such.
Ubuntu needs to fit on one CD. They trim off packages that the average user won't need by default to keep it slim. If you install an app that needs it, it will be pulled in automatically. If you want to play with it, you're smart enough to install the tkinter from the repos.
Yeah I get that. I understand not including less popular packages for space restrictions. I don't get breaking up existing pieces of software. I could be wrong but my understanding is that Python 2.6 includes Tkinter by default. So why install a version of Python that technically is broken? It's not like I'm trying to install PyOpenGL or some other 3rd party library. This should be part of the Python 2.6 package. Disclaimer: I normally develop under Mac OS X and Windows, so perhaps I've missed something. Last time I developed seriously on Linux was Slackware 0.8 or 0.9 or something like that.
the last time i checked, the latest version of fabric wouldn't issue commands in parallel. Has that changed? I really like everything else about fabric, but this one point was deal breaker for me. 
No! Dealing with CPAN is one of the things I hate most when I have to install some stupid perl program.
I think people are missreading the "People want CPAN". Its not that they wish CPAN the utility, they wish to have CPAN the content. They wish to know that whatever task that they are going to do they will get a module that is likely cover the problem space.
PyPI is fatally flawed. Python packaging as a WHOLE is fatally flawed. I may have to set up a private local PyPI service to archive and host the packages I use in production. Why? Because one day the Toscawidgets team decided that nobody used version X anymore, so they removed it from PyPI...and *everywhere else* it was hosted on the internet. I had to spend _hours_ tracking down exactly what changed between the version I was using and the latest version just to launch a website that was supposed to be launched way before I started that epic endeavor. Why doesn't easy_install/Distribute/pip/anything have a goddamn "uninstall" command yet!? Why do I have to use "yolk -U" to list my out of date packages and then manually "pip install -U" every package that's listed just to upgrade all of my packages? It's insane!
I think you're misreading it yourself, unless you're talking about some post/article other than the one at the top of the page. &gt;However, since easy_install is not as ready yet as the counterparts in other languages, if the biopython developers add too many dependencies, nobody will be able to install it properly, and nobody will use it. 
FYI: the next release of pip [will have an uninstall command](http://bitbucket.org/ianb/pip/changeset/66a028f84e05/).
A follow-up article: http://www.cafepy.com/article/python_attributes_and_methods/contents.html
Strange. I think the exact opposite. "cpan &lt;package&gt;" is about as easy as you can get.
How is this bad news? Google operates on a massive scale, and Python -- as fantastic as it is -- is a sluggish language. If a process takes 1 second in Python and half a second in C, multiply that across a million users and the difference is profound. Google is still strongly supporting Python. The fact that Google is supporting development of the language so strongly despite their lack of use for it should be taken as a vote of extreme confidence. But I think the simple truth is that projects undertaken by Google need every speed advantage possible.
Pretty sure the people who replied are Google employees currently working on Unaden Swallow. So I'd say it's confirmed.
Me: People want TPAIN :-)
This version finally puts down the laden.
Trolling headline: Employees are being told to use tools appropriate to the job, and one aspect of a programming language as a tool is performance.
Title should be: ,,No news: Google employees are encouraged to use Java or C++ instead of Python for new projects where appropriate.''
&gt; Python will still be slower than C and Java Of course, this is why you prototype in Python, and recode hot spots in C.
The headline is directly quoted from the OP
I haven't tried this latest release but you're right - it executes commands against each server in series. For stuff like deploying though, that can be a good thing e.g. wait after the first server for a manual check of the change.
Awesome, do you know if I can use it instead of the silly {% slow stuff %}?
Horses for courses. I have had experience (late last century) of writing a web application using C++ and suffered greatly as the inflexibility of the language locked in design errors that made it sluggish and difficult to modify. It makes sense for huge systems like Google or Amazon or Yahoo to spend ten or a hundred times the development time on their systems, because in their case it makes the difference between deploying 6000 servers or 12000 servers. It also makes sense to spend immense resources on developing data structures and algorithms for, say, the Linux kernel (or indeed the Python runtime), because it affects the efficiency of everything running on that platform. 
As far as I know, Jython is slower than CPython.
You sure can!
Indeed. At work we use Python mainly for glue between processes which are written usually in Java or erlang. There are times where Python can't handle the bill.
bad news :-( A change of direction due to 'merge' with oracle?
Thanks for pointing out the obvious :-) /edit: why the downvote? I think prider has pointed out that it is not a troll headline, because indeed i lifted the sentence from the discussion thread... 
&gt;Of course, this is why you prototype in Python, and recode hot spots in C. I think it's even better to rewrite the whole thing, once you know what you want to do. Which doesn't mean the flexibility of python isn't great when you don't know what you want yet, ie. when prototyping.
This is called environment friendliness.
FWIW I've had the same disappearing packages problem with CPAN.
Both correct depending on circumstances (ie what your profiling shows up). For instance if you have a logfile analyzer with nice GUI, and profiling shows you are spending 99% of time processing the logfile, it makes sense to keep everything in Python except the hotspot recoded in C. If it's a spreadsheet package and the UI lag is unacceptable, then there may be no choice except to recode the whole thing in C. The first is obviously the ideal choice as it is easier to add new features. Phillip.
&gt; Why doesn't easy_install/Distribute/pip/anything have a goddamn "uninstall" command yet!? [PyPM](http://docs.activestate.com/activepython/2.6/pypm.html) has an `uninstall` command. &gt; Why do I have to use "yolk -U" to list my out of date packages and then manually "pip install -U" every package that's listed just to upgrade all of my packages? PyPM will soon have this feature (automatic update of installed packages).
Yes, and the OP is asking to confirm a rumor, not actually speaking authoritatively.
Once I learned Wave is all written in Java, I knew Google was totally doomed.
&gt; Google operates on a massive scale, and Python -- as fantastic as it is -- is a sluggish language. If python is 'sluggish' then what is java? A drunken braindead gnat on crack? Python is far from perfect, but Java is worse in almost every possible imaginable way, and the least is said about C++ the better. (C is great, and as others have pointed out, it is ideal to implement any perf critical sections.)
Java is slower than python?!? http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=java&amp;lang2=python&amp;box=1 . It does better than C++ in some tests - http://shootout.alioth.debian.org/u64q/benchmark.php?test=all&amp;lang=java&amp;lang2=gpp&amp;box=1
gmail was written in java as well.
I know what the problem is for me: I do not have access to the site-packages directory on my system. I need 2 things: 1. easy_install should make it easy to install into a directory that I choose. 2. pkg_resources should make it easy to use eggs that are in a directory on my PYTHONPATH. I think the entire Python community completely overlooks #2. I cannot add every single egg-file to PYTHONPATH. I want to add just a single directory, where all my eggs will be located. In fact, it should be the *root* directory of my own packages. Python should understand to look into lib/python2.6/site-packages. It should even have an architecture specific default-search-path, like Perl. easy_install developers should not assume that I have access to the system directories.
I just want to package my Python application as a single file. My end users don't want to install a program. They want to double-click the icon for a single file I send them and have the application run. Java has supported this for at least 10 years using executable Jar files. Am I missing something? Is there a python "executable egg" file?
Python in "dynamically typed interpreted language slower than statically typed compiled language" shocker. The conclusion appears to be: if RAD and maintainability is more important, you should use a language designed for RAD and maintainability. If speed of execution is more important, you should use a language designed to give speed of execution. Phillip.
I would like to think that this will be the stimulus that Guido, or someone else at Google, needs to fork Python to allow changes that will actually significantly improve performance. What I am afraid will happen though is that this will just lead to the further marginalization of Python and dynamic languages in general. If Google is going to be a leader within the Java/static space instead of in Python/dynamic space, that's just going to deprive the Python/dynamic space of a LOT of inertia becuase there simply will not be much, if any, perceived force behind Python based solutions. Or, has all that happened already anyway?
Not Javascript?
http://s3.pixane.com/pip_distribute.png
py2exe? There's a py2app for Mac too I believe (which makes a directory, but that looks sufficiently like a file on a Mac).
Use virtualenv
As of now there's a released pip uninstall
I want to wear a t-shirt of this at Pycon :)
And its reliability and performance hugely stinks compared to google search.
I'm the author, free to use according to http://creativecommons.org/licenses/by/3.0. Drop me a line if you want the SVG (inkscape) sources.
Microbenchmarks == totally irrelevant.
Damn straight
You should replace "ministry of propaganda" by "ministry of public enlightenment" (or "ministry of distribution" if you want to remain python-oriented)
cool ! I know someone who does silkscreening - She could probably print a dozain.
py2exe generates many files. I haven't tried py2app yet, but a py2exe that produced a single file would probably work, although with far less flexibility than say an executable jar.
Why?
oh shit.....just when I'm starting to really learn Python. edit: maybe I should switch gear and pick up Java before I hit retirement
Do I really have to explain why? Oh dear...
Nope, you don't really *have* to. Was just curious.
Were you wanting a job at google? Still plenty of other places you can use python.
yeah that too
ummm, every "test-search" on Python jobs I did came up with a *very* short list...
I wonder if Google had to do it over again today what would there programming language stack look like? Personally I would go for Python/C/Erlang or Jython/Java/Erlang.
Not sure why you'd want to throw out working code, if it meets your needs, just because it's Python...
you can be a python programmer or a java drone, it's your choice. if you're programming purely for the money, better get a different job, you'll save yourself a lot of stress.
except ... it doesn't work ... $ `sudo python distribute_setup.py` ... ... ... Traceback (most recent call last): File "distribute_setup.py", line 458, in &lt;module&gt; main(sys.argv[1:]) File "distribute_setup.py", line 454, in main _install(tarball) File "distribute_setup.py", line 82, in _install assert _python_cmd('setup.py', 'install') AssertionError`
every ten cent web startup thinks they will be the next google and chooses their tools using that pretend mindset.
See [BackPAN](http://backpan.cpan.org/).
i'd learn python, ruby, perl, etc. that family of languages is close enough to each other that it takes a lot less to switch between them than it does from python to java. i learned java years ago. i dont enjoy the language much.
"ИЕШ" is new, right? But then what does "ИЕУТ" mean?
- What is your python version and your system ? - can I get the full TB in a paste pls ?
NIET =&gt; no
huh? according to the actual google thread, "Well, simple common sense is going to limit Python's applicability when operating at Google's scale: it's not as fast as Java or C++, threading sucks, memory usage is higher, etc. " Rly? I think Google needs to have more developer training and education on the merits of python
python2.6.4 under a fresh install of "ubuntu karmic 9.10" manatlan@manatlan-laptop:~/Bureau$ python distribute_setup.py Extracting in /tmp/tmpv8eSK3 Now working in /tmp/tmpv8eSK3/distribute-0.6.8 Installing Distribute Traceback (most recent call last): File "setup.py", line 41, in &lt;module&gt; from setuptools import setup, find_packages File "/tmp/tmpv8eSK3/distribute-0.6.8/setuptools/__init__.py", line 2, in &lt;module&gt; from setuptools.extension import Extension, Library File "/tmp/tmpv8eSK3/distribute-0.6.8/setuptools/extension.py", line 2, in &lt;module&gt; from setuptools.dist import _get_unpatched File "/tmp/tmpv8eSK3/distribute-0.6.8/setuptools/dist.py", line 7, in &lt;module&gt; from setuptools.command.sdist import sdist File "/tmp/tmpv8eSK3/distribute-0.6.8/setuptools/command/sdist.py", line 4, in &lt;module&gt; import os, re, sys, pkg_resources File "/tmp/tmpv8eSK3/distribute-0.6.8/pkg_resources.py", line 2656, in &lt;module&gt; add_activation_listener(lambda dist: dist.activate()) File "/tmp/tmpv8eSK3/distribute-0.6.8/pkg_resources.py", line 647, in subscribe callback(dist) File "/tmp/tmpv8eSK3/distribute-0.6.8/pkg_resources.py", line 2656, in &lt;lambda&gt; add_activation_listener(lambda dist: dist.activate()) File "/tmp/tmpv8eSK3/distribute-0.6.8/pkg_resources.py", line 2162, in activate self.insert_on(path) File "/tmp/tmpv8eSK3/distribute-0.6.8/pkg_resources.py", line 2256, in insert_on if '0.7' in self.version: File "/tmp/tmpv8eSK3/distribute-0.6.8/pkg_resources.py", line 2120, in version "Missing 'Version:' header and/or PKG-INFO file", self ValueError: ("Missing 'Version:' header and/or PKG-INFO file", setuptools [unknown version] (/usr/lib/python2.6/dist-packages)) Traceback (most recent call last): File "distribute_setup.py", line 458, in &lt;module&gt; main(sys.argv[1:]) File "distribute_setup.py", line 454, in main _install(tarball) File "distribute_setup.py", line 82, in _install assert _python_cmd('setup.py', 'install') AssertionError manatlan@manatlan-laptop:~/Bureau$ 
Ok Thanks, looks like the installed setuptools on your system is particular. Could you add an issue with these info in our bug tracker please ? Thx
I had removed all setuptools package from dist-packages and now, it works ;-) setuptool don't come with the ubuntu. I had installed setuptools 3 days ago, to be able to easy_install
hey man I'm just being practical here....Not living in parents basement no more, not under 22 no more...i got family to feed, bills to pay...no job no insurance no nothing... this is the greatest country on the planet, get it ?
You use easy_install to install pip?? 
Wow. I've luckily not had to touch Java over the last 5 years. After spending some time writing Java code using 'lovely' app servers that exist to make development 'easier' I was very happy to move to Python. Hopefully Google won't fall down the rabbit hole that is Java for everything!!! (which is not very distant from Python for everything). Java is quite good for backend buses, services and other heavy-duty-need-large-groups-across-the-world projects with various levels of programming ability. Python (IMHO) is great with smaller teams of mediocre or better programmers for web projects, tooling, middleware and cross platform GUI's. Though to be honest, it's 2009. I want to write Python ... or Ruby .... or Falcon ... etc.. I don't want to write Java, C++, etc.. if I can avoid it.
I'm with you, Google couldn't possibly understand the fine details of a programming language.
ah, that's just N written like И... Heh, that's hard to understand. :P
Yeah. I know. That's what I said, too. I still love it, though.
But follows the thread, the rumor is confirmed too. Well, at least it is a bad news to me. I am trying to promote the use of python in my workplace. Google has always been my 'trump card' - a very strong reference, or assurance, to the management that python is a scripting language with serious backing.
It depends. Java's VM takes longer to start up, but once it's running it tends to be pretty efficient compared to Python's VM. If you put pure Python up against pure Jython I *think* Jython will be faster after it compiles to bytecode. Some people find writing Java easier than writing C so writing 'native' modules in Jython is easier for them (and thus they do it more) .. and the Python part of Jython becomes the nice high level glue.
Maybe get a 'distribute-setup.py' variant script going which installs pip as well first, avoiding the 'easy_install pip' step. Then the shirt won't get out-of-date quite so quickly :P
I am following the thread, I've even replied in it. This is not a new Google policy, if it was do you think Youtube would still be entirely Python? This is someone trying to blow out of proportion the fact that at Google's scale performance can be directly equated with expenses.
Are you sure the Python code is compiled to Java bytecode? Is it not compiled to some kind of Python bytecode, that is then interpreted by an interpreter itself compiled to JVM bytecode?
Colin Winter is member of the Unladen Swallow team at Google. I suppose he knows what he is talking about...
Yes that's the right step. I am adding this.
Cyrillic letters used as latin letters make my eyeballs bleed. It's even worse when they're using them to spell Russian words. ИУЕТ is pronounced IUET and DД is only half cyrillic, but is essentially DD. The proper spellings are Неть and Да. I can't see it the way they want me to see it.
Have you tried writing computationally intensive apps in both languages?? I did. Python is MUCH SLOWER than Java. Like an order of magnitude IF you are lucky, factors of 20-30 are not uncommon. Now, please share your experiences. (Just make sure that Java and Python apps were written by similarly competent developers).. Oh, and don't get me wrong I code in Python for living and use Python for computationally intensive stuff a lot (because dev time is more important).
You are wrong. Byte-code compiled python must still preserve python semantics. That is you still don't know at run time whether 'x+y' means integer or string addition. The stats which I have seen so far say that Jython is 2-4x times slower than Cpython http://blog.dhananjaynene.com/2008/07/performance-comparison-c-java-python-ruby-jython-jruby-groovy/ 
&gt; it's not as fast as Java or C++, threading sucks, memory usage is higher, etc. Which of the statements above are wrong? 
If you rewrite it, it's obviously because you have a reason :) I can see three reasons for rewriting a prototype written in python: * Better speed using a language that compiles to native code * Cleaner program, because prototypes tend to become messy after a while * Static typing, because while dynamic typing is great for a prototype, static typing can help when working on a big codebase with multiple people.
Maybe the author is just being self-deprecating in a humorous fashion to point out how so much effort results in so little code, but I am of the opinion that incremental improvements in code is always a good thing, especially if that means less code and same functionality. Trying to use the tools you have in the most efficient way to solve the problem you have in the simplest terms is what coding is all about, when it's done right. This is KISS in situ.
This is no different from trying to write a good 2 page paper on a subject. It is easy to write a good 15 page paper on something. It is hard to write a good 2 page paper. It comes down to efficiency in choices and just elegance. Part of what makes Python great to begin with.
done, issue #90
There is power in names. Most of the complexity in the original algorithm gets shifted to the fortran subroutines that comprise most of SciPy.
Is number 3 really valid? I hear this often but I don't see how static typing would help. I've worked on some pretty large code bases in Python and never once thought "This would be easier if it was statically typed, because of all the people that are going to be working on it." How does static typing make things easier in this case?
You can still promote the use of Python in your workplace. There are very few places like Google in the world; nobody has their level of scalability and few come even close in server deployment size. Python is being used successfully across a wide variety of domains by everyone from small hedge funds to massive multinational oil companies to just about every movie shop. You don't need a trump card if you have a fistful of kings and aces. http://python.org/about/success/
Python and Ruby are different beasts than perl.
&gt;Finally I’m like, hey, how far can I push this? With some more thought and spending a few days trying to get my head around all the powerful scipy libraries, I finally figure out that the core of my entire algorithm can be implemented in an extremely general and yet fast way in just a few lines. It’s really just a matrix with some flexible number of dimensions to which I am applying some kind of n-dimensional filter, followed by an n-dimensional non-linear optimiser on top of an n-dimensional interpolation and finally coordinate mapping back out of the space to produce the end results. uhhh...duh....what a n00b
I guess you're right
A huge organization like that can't possibly understand _anything_. The fact that they are now in the business of hobbling their programmers gives me great joy, because I really do think Google is evil, and anything that hastens their demise can only be received as the very best of news.
It is just that the management wants to look at some external factors such as vendor support. Having Google on the python side is certainly advantageous.
I was sure to get criticism on point 3 :) It's a controversial matter, but I hold by my position. Let's look at your example: &gt;I've worked on some pretty large code bases in Python and never once thought "This would be easier if it was statically typed, because of all the people that are going to be working on it." In my opinion this is not the case where static typing is useful. It's useful when you get to work on code that was written by 5 different people that were there before you and don't even work there anymore. In this case static typing helps because you know that if it compiles, function X gets type Y and returns a Z, no matter what. It helps making the correct assumptions when changing things.
and i'm really giving you practical advice. you're in for a world of hurt if you don't like this job. you can consider a career in IT, but programming is both demanding and thankless.
gmail was first implemented a very long time ago.
Another simpler instruction: wget http://bitbucket.org/ianb/virtualenv/raw/tip/virtualenv.py python virtualenv.py --distribute env/ source env/bin/activate Now you have a nice isolated environment with pip and distribute.
If you want to learn python, I'd suggest [Dive Into Python](http://diveintopython.org/) or perhaps [Dive Into Python 3](http://diveintopython3.org/) depending on which version you'd like to learn. This is a somewhat important question, since some important libraries haven't made the jump yet. Anyway, I know that OpenCV (a computer vision package) has python bindings and has routines for getting data from a webcam. I don't know off-hand how you would take a picture of the desktop (it's a rather platform specific thing).
kind of a misleading title, the order is more "don't start creating more python projects until unladen swallow is complete." it also doesn't preclude jython development.
Thanks. I'm working my way through DIP at the moment, but I thought I'd get stuck in with a proper project. I'll take a look at OpenCV in the meantime.
Talk to Greg, I bet he could make some nice ones (which I would definitely have to purchase).
Yes, I'm aware people do stuff for reasons. They are not always good reasons though :) The key phrase was "if it meets your needs".
I've had the exact same thing happen to me, in Matlab; in one case I discovered, after a week's worth of coding, that I'd almost exactly replicated an signal processing library function. 90 lines down to 3.
If that happens, you have to put them up on the xkcd store or something.
&gt; The proper spellings are Неть and Да. Well yeah but people who don't read cyrillic will completely fail to understand, then.
Also, you forgot to revert the N in "python" on the first line. You should also invert the R's, I think.
That didn't install `pip` for me. $ ls bin/ activate activate_this.py easy_install easy_install-2.6 python python2.6
pip rules. I am the always-late RPM packager of Plone, and pip has made my work possible (not easy, mind you, still a shitload of work to do Plone RPMs, but at least it is possible now).
This is what made grading an introductory applied mathematics class for several years a real headache. Students would turn in 5-6 pages of code when a half could have done the same thing better. Once you start adding more than one (MAYBE two) for loop(s), you're usually doing something wrong. Someone mentioned to me once that in their first semester matlab class at another university they didn't even show the students how to do loops until the very end of the class. That sounded like a great idea to me.
I'm probably your worst nightmare, because I find I understand algorithms much more when I've written my own version, puzzling through all the issues. After I've got it down, I'll be willing to use other implementations.
This is exactly what I go through every single day, even though I've been using scipy religiously for quite a while now... The saddest thing after you finish a project, is how little you have to show for it. Everything's implemented in about 50 lines of python - it's quite depressing, really...
http://s3.pixane.com/lenin_packaging.png This is a much better infographic.
&gt;Неть It should be just 'Нет'.
Most web apps spend there time in IO wait. I would assume they are using non blocking IO for there projects so they can scale. For the little amount of code that does need optimization I have found writing Python allows me to quickly write faster algorithms. It seems to be extremely rare that I need to write any C code but then again I don't write any code that deploys on tens of thousands of servers. The real questions is should developers who don't understand this be deploying code to thousands of servers?
People do stuff for reasons? THIS CHANGES EVERYTHING!
I thoroughly enjoyed everything I understood about that article, ..all 7 words.
perl ? kill me now if I have to
oh, I'm in IT and I do program edit: just wanting to learn new skills, y'know these day.....
Not wrong about everything. Java is probably easier to write 'native' modules in than C. And if x is a string and y is declared as a non-final class you don't know what x+y means in Java either. VM's can learn what x+y is in your code, then compile that with a double check that things have not changed. Python VM's are slower because we have not yet worked out how to speed them up. Which is kind of relevant because that is why Python is still a valid choice for a performance intensive application. You can get the shape of the application done fast, and then invest some time in ways to speed thing up.
voted up for honesty.
This is my first blog post ever. Let me know what you think. :)
Looking at the FAQ I infer compilation to byte code. It is not actually English or anything but the FAQ says: Jython is approximately as fast as CPython, sometimes faster, sometimes slower. Because most JVMs - certainly the fastest ones do - long running, hot code will run faster over time. http://wiki.python.org/jython/JythonFaq/GeneralInfo#HowfastisJython.3F 
The faster part is pretty accurate. The memory part is not accurate. Java needs to be out also, since C is much better than Java on memory usage. For a non-cpu intensive web application, the threading is closer to *ok* than *sucks*. And the assumption that threading is essential is probably bogus, multiple processes work well for many things. 
Totally supports ZoP but this is kinda gay
I very much enjoyed it, it actually made me want to hunt down some more post project experiences. I've only played with Django a bit, but your post on apps kind of confirmed my fears about extensibility. I know the creator of Pinax acknowledged this as well, mentioning that it is a trade off. I'd be interested in hearing if anyone has had a different experience with customizing community apps. Not sure if this will help for the file structure thing, but when I want to figure out standard practice for organizing files, I search out a few projects on github and see how they do it. This method was particularly helpful in learning best practices for Ruby, as it's not something that's typically talked about much.
&gt; It is easy to write a good 15 page paper on something. I would argue that it's not a good 15-page paper if you can write just as effective a paper in 2 pages.
And you would be arguing the same thing... I think it is a different meaning of *good*. Cf: "It will take me a *good* hour to drive home from work with all of the traffic today."
Pretty damn good for a first of anything. [Custom template tags](http://docs.djangoproject.com/en/dev/howto/custom-template-tags/) are your friends. Inclusion tags might be one of the things you're looking for. 
Yeah, that's why I gave three very good reasons. What are you arguing exactly? Let me point out that the comment you're so proud of was one of the worst straw men ever: &gt;Not sure why you'd want to throw out working code, if it meets your needs, just because it's Python... Add what point did I claim you should rewrite code *just because it's python*? Never.
You win! Have a cookie.
I love cookies :)
Im guessing the downvotes are suggesting this should be posted in the django subreddit, and not python. I've heard that submitting ruby code in the python subreddit angers the gods.
The big documentation pages have not been a problem for me. They have listings of the functions and other API stuff that are fairly comprehensive. As for include-with-arguments.. You do know that template inheritance can do something quite like that? Just define blocks where you want custom text. Override blocks if you need them changed. Of course not for things that should materialize out of thin air, but in my experience those can be designed out.
First of all i'd like to say that i'm kinda a noob in matlab and python. I used both language, but i have to say that i have a lot of difficulties to manipulate matrix with scipy. I don't know i need to see matrix to work with. Anybody feels the same? I'm open to any advice (just remember i'm a beginner!).
I did a little more addition to the script you provided, so that it acts like python manage.py shell_plus and imports all models. Here you go: http://gist.github.com/231878 BTW, What background do you use for terminal in which pink, yellow, orange text is all comfortably viewable?
Also you can wrap the [include](http://docs.djangoproject.com/en/dev/ref/templates/builtins/#include) tag in [with](http://docs.djangoproject.com/en/dev/ref/templates/builtins/#with) tags if the context for the included template. I find the docs ok, but mostly I just use the "(item) API" pages or "List of (tags|fields|widgets)"
&gt; In this case static typing helps because you know that if it compiles, function X gets type Y and returns a Z Isn't it called documentation?
Having been using django heavily for a bit (and not being a web-guy), most of the time django apps "just work" - when it comes to extending them, if I have to make heavy changes, I simply treat it as if I would any piece of code, namely, I make a copy and make the changes I need. Django apps come in all flavors and sizes, some big, some small - for the bigger, more complex ones, you can subclass the models, tweak the urls and views.py files on your site's level, or for smaller ones, just make a copy and change away. Ultimately, I don't find just accepting the "this app does x and I won't modify it, and instead jump through hoops to do y" idea to hold much water. If you have an app which does 99% of what you want, hack it to make it do what you want. As for file structure; check out James Bennet's "Practical Django Projects" book, for the most part, it's pretty simple - app-specific code goes in the app dir, use url includes, etc. My personal opinion on where to put apps has evolved - more and more I put all "apps" in a top-level apps directory, and code which may be shared among apps at the top level of the apps directory.
Is it? I always was horrible with the soft signs.
I have found a better Asyncronous IO design is this: http://mattgattis.com/blog/2009/10/18/introducing-magnum/ the design I wrote up a while back (http://blog.hackingthought.com/2008/09/new-web-server-design-for-new-web.html) basically it is a hybrid model. As the volume of small json (growth of AJAX applications) and NoSQL (couchdb, riak) databases getting some decent read IO performance I think we are going to get decent performance. 
Then do `easy_install pip` inside that virtualenv.
Good in the sense that is sufficiently covers the subject matter. Just as the 10 page program covered the task at hand.
In terms of frameworks available and how they're ran? Sure. In terms of language structure? Not so much.
It's not that bad, but is easier to write sloppy and hard-to-maintain code in.
I dunno, every time I use django I feel like the code is really clunky and slow (which very well might be my fault). This is why I've switched over to [webpy](http://webpy.org), which I've been enjoying a lot more than I did with django.
Django's written in python though. It's modelled after ruby on rails though.
I repeated on my computer and got pip. Are you using an older virtualenv? Only as of a couple days ago did it install pip.
[An announcement of the newgil work by Mr. Pitrou](http://www.pubbs.net/python/200910/47531/).
It should be noted that the priority requests idea was removed from the final implementation of the newgil.
I will look at this this week :-)
Featuring creepy-dictator GvR.
 '-._ ___.....___ `.__ ,-' ,-.`-, PYTHON PACKAGING `''-------' ( o ) `._ IS NOT SICP ! `-' \ \ \ .---..,--' ................._ /_--...--, `-.._ _.-' `'-----'' 
If you inverse the R of Republic, you should probably inverse all the Rs in the picture. Just sayin'
Django was in private use (prior to it being Open Sourced) before Rails was announced actually. They are very similar, but it isn't true to say it was "modeled after" Rails. 
Excellent post. Have you tried any other python framework? Are you planning to?
Very cool. Makes me more willing to play with py3k. Can't help but feel jealous since py2 is in freeze :)
&gt; Are you using an older virtualenv? I used the exact sequence of commands given by you. So I used virtualenv.py from bitbucket tip. Python 2.6.4 (32-bit) on Mac OS X 10.6.1. Note: I have setuptools-0.6c11 installed in ~/.local .. but that shouldn't affect the availability of pip (even if --no-site-packages is given), I believe. Bug?
Here's the conclusion (made me think why PyPI choose xmlrpc): &gt; There is no magic. All it takes is a few people that sit down and get first something running, a rough cut. Then iteratively enhance it. Don't try to create a master plan that will get everything right in one fell swoop. The only one that will get swooped is you. &gt; One way to summarize most of the above is the priceless KISS principle-- Keep It Simple, Stupid. Avoid too complex setups. Start simple. &gt; Another important credo is: Avoid bottlenecks and interdependencies. Decentralize. Create and encourage alternatives. For example, the most popular search engine of CPAN isn't actually part of CPAN proper: search.cpan.org just mirrors CPAN and from the data builds the search indices and searching/browsing interfaces. That's way there can be several seach engines of the same CPAN. Similarly, currently we use CPAN.pm + MakeMaker to install modules: but we are not committed to either, and the community is working on replacements. Keep things loosely connected. This allows for different people to work on their own enhancements without disturbing the other parts. &gt; Perhaps the most demanding thing is commitment: someone must keep things running. A slowly decaying and dusty archive is almost worse (and certainly more sad) than no archive at all.
But it's *not* prepared to handle exit unless it's evaluated, because "exit" alone isn't proper Python code. &gt;&gt;&gt; exit.__class__ &lt;class 'site.Quitter'&gt; &gt;&gt;&gt; repr(exit) 'Use exit() or Ctrl-D (i.e. EOF) to exit' Knowing that people would try to type it, they prepopulate them with objects that `__str__` to helpful strings, but that when called actually exit the shell. Otherwise they'd need to make `exit` and `quit` into reserved words
see this guy ever time I pee
If they're pre-populating these with objects that have proper `__str__` methods, why not pre-populate them with objects that have an initialization method that exits? s/in/an/
&gt; There is power in names. A great quote which I'll be stealing :) It seems to be all over the internet in many contexts. Do you know the source or did you invent it independently?
Presumably they're initialised as soon as the shell starts, so you obviously don't want it to exit then. If you mean exiting from `__str__`, then you wouldn't be able to `print exit` or do those sorts of introspection without killing your shell
&gt; Presumably they're initialised as soon as the shell starts Yep: &gt;&gt;&gt; dir(__builtins__) […, 'exit', …, 'quit', …] In fact, they're not shell-specific, they're also present when you run a script. edit: here's the whole thing, from site.py (which is automatically run during initialization) def setquit(): """Define new built-ins 'quit' and 'exit'. These are simply strings that display a hint on how to exit. """ if os.sep == ':': eof = 'Cmd-Q' elif os.sep == '\\': eof = 'Ctrl-Z plus Return' else: eof = 'Ctrl-D (i.e. EOF)' class Quitter(object): def __init__(self, name): self.name = name def __repr__(self): return 'Use %s() or %s to exit' % (self.name, eof) def __call__(self, code=None): # Shells like IDLE catch the SystemExit, but listen when their # stdin wrapper is closed. try: sys.stdin.close() except: pass raise SystemExit(code) __builtin__.quit = Quitter('quit') __builtin__.exit = Quitter('exit') … and it turns out you don't have to import sys to call `exit()`, there's a builtin for that. Thanks for this Python Discovery of the Day, raging actionscript guy.
I hate faux Cyrillic. 'Яepublic' makes no sense to a native speaker, since 'Я' is pronounced as 'ya'. Likewise with 'pдckдaging': Cyrillic 'д' == Latin 'd'. Etc, etc.
Toys Ya Us?
should be "ministry of pypaganda"
pls consider making one featuring Gumby
your picked nits are duly noted.
ddayummm 
Luckily, there are many people who don't speak Russian. Personally, I know that the 'Я' is 'wrong', but I just like the aesthetic.
This reminds me of the python graphic about the 'bracist imperialists'...
&gt; I hate faux Cyrillic. Yes, but using correct cyrillic characters make it unreadable for anybody who doesn't know the alphabet, and faux-cyrillic is a pretty common (and good) way to evoke the Soviet Union.
Toys'R Us actually uses a reverse R, not the cyrillic Я (and so does Korn by the way), the goal being to evoke a child's handwriting. Likewise, in the NIИ mark the second N is just reversed, not the cyrillic I.
This is dumb.
"Don't use Perl; it's counter-revolutionary." "Python is dope!" "KAN I GET IT ON TEH LUN1X?!?"
Pretty sweet. It's about time, too. The GIL really had some bad behaviors on multicore machines.
well that was worth a downmod. It was also intended more to come off as less of an a-hole online. Thanks for the history though.
This isn't a change to the core language; it's a change to the internal implementation of the primary interpreter. What does the moratorium have to do with it?
A link to a tweet? Gee, thanks.
Thanks! :-) Unfortunately, I can't attribute it to myself. In this case, the inspiration came from watching the SICP videos. Download and watch the [first few lectures](http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/), and you'll see what I mean.
eweek spawned a lightbox popup taller than my firefox viewport and wouldn't scroll
Inaccurate at best. Coöccurance does not necessitate correlation. I've just started with Python, but it has nothing to do with wanting to program anything Google-related or with cloud computing. Google using Python may have sparked the interest for some or provided the final nudge for others (for me it possibly did, but I've been wanting to learn Python for quite some time), but concluding that the only reason Python gained interest is GWT is nonsense. Also consider this as an indicator of interest: http://google.com/trends?q=python+language%2C+gwt&amp;ctab=0&amp;geo=all&amp;date=all&amp;sort=0 (results are obviously different for "python programming language" or "google web toolkit" but the terms are sufficiently unambigious and common enough to prove a point) Needless to say, the statistics are already pretty meaningless because it's the result of a survey among "North American developers". Not every field lends itself to using Python equally well. Not every field lends itself to cloud computing either. And not every field would be inspired by something Google does -- once something gains momentum, it picks up followers regardless of its initial cause anyway.
You studying for the GRE writing section? :-D
The moratorium applies to Python 3 as well.
root@mycomputer:~# pip install --upgrade genshi Downloading/unpacking genshi Downloading Genshi-0.5.1.tar.bz2 (303Kb): 303Kb downloaded Running setup.py egg_info for package genshi warning: no previously-included files found matching 'doc/2000ft.graffle' warning: no previously-included files matching '*' found under directory 'doc/logo.lineform' Installing collected packages: genshi Found existing installation: Genshi 0.5.1 Exception: Traceback (most recent call last): File "/usr/lib/python2.5/site-packages/pip-0.6-py2.5.egg/pip.py", line 482, in main self.run(options, args) File "/usr/lib/python2.5/site-packages/pip-0.6-py2.5.egg/pip.py", line 677, in run requirement_set.install(install_options) File "/usr/lib/python2.5/site-packages/pip-0.6-py2.5.egg/pip.py", line 2744, in install requirement.uninstall(auto_confirm=True) File "/usr/lib/python2.5/site-packages/pip-0.6-py2.5.egg/pip.py", line 2059, in uninstall for name, value in config.items('console_scripts'): File "/usr/lib/python2.5/ConfigParser.py", line 544, in items raise NoSectionError(section) NoSectionError: No section: 'console_scripts' Storing complete log in ./pip-log.txt Great. Broken eggs and no frying pan to see. Any help here?
I have to admit is is really annoying. Typing exit or quit is pretty much standard on everything afaik except Python and sqlite3 (which are exit() and .quit respectively). Python should be able to detect when it is in a shell and provide preferably both to leave. Phillip.
their bourgeois curlies really turn my stomache, you know that?
Isn't it called unit tests?
&gt; faux-cyrillic is a pretty common (and good) way to evoke the Soviet Union. It certainly doesn't do this for me, I just perceive faux Cyrillic as idiotic. Besides, the subj pic is not even a good stylization. Just compare it with original [Soviet Constructivist posters](http://kaipersons.files.wordpress.com/2009/04/constructivism-1.jpg). edit: [Another example.](http://news-service.stanford.edu/news/2005/november30/gifs/poster_lenin.jpg)
&gt; using correct cyrillic characters make it unreadable for anybody who doesn't know the alphabet Using Latin alphabet and a stylized 1920's font would make it even more readable and much less camp. [Example.](http://designhistoryinpopularculture.blogspot.com/2008/10/franz-ferdinands-this-fffire-cover-2004.html)
I like the Constructivist aesthetic too, that's why I'm reacting.
for those of us at work where twitter et al are blocked, what's the tweet in question?
could you have mixed a little more disdain into your comment?
similarly, the only big problem I've been having with django is moving it from happily working on the built in development server to working properly on apache. I haven't found the documentation to be particularly useful (though I probably have myself to blame for running everything on windows, trying to learn how to set up linux as a server at the same time as learning django seemed foolish).
Python is awesome! It only took me three hours to write a script to do the genetic work that the previous research experiment spent 4 months on.
Great, now I have to go out and by a new shirt: "I programmed in Python when programming Python wasn't cool"
What do you mean by "language structure"? Perl's treatment of namespaces, prolific use of sigils, are all quite different from Python. The metaprogramming facilities and first-class type system in Python guide you towards writing vastly different types of code that what would be done in Perl.
&gt; Antoine Pitrou's "newgil" work lands in py3k branch. Huge! http://bit.ly/LKnoz #py3k @dabeaz (who started this) &gt; &gt; gvanrossum &gt; Guido van Rossum
Unit tests don't necessarily check data types whereas documentation should clarify them always. Mind you unit tests and good docs surely are a good idea :)
Too many pop-ups; didn’t read.
 &gt;&gt; while not exit: null@vm-karmic:~$ That's why. Exit is not a reserved word.
s-s-s-superb
No.
Definitely. In fact, I almost did, but decided &lt;del&gt;you&lt;/del&gt; pudquick might be referencing something other than the moratorium, even though I hadn't heard of anything, and that &lt;del&gt;you&lt;/del&gt; pudquick might not be trying to spread FUD. Then I went back and tried to edit all the disdain out. Sorry if I did an inadequate job. Update: changed you to pudquick, since joeldavis and pudquick are obviously not the same person.
The link in the tweet just went directly to the changeset. This way there was at least a little explanation of the changeset, and more people are likely to know who GvR is than Mr. Pitrou.
Would you be in favour of words like "GR∑∑K" as well?
Depends what you're trying to express. And you could probably just as well go with grεεκ instead.
&gt; Depends what you're trying to express. It is usually used to provide a sense of 'greekness'. Along with plastic pillars and statues. Think restaurants or in movies. As if appearance is more important than content or any degree of correctness. I hate that. &gt; And you could probably just as well go with grεεκ instead. You can't. It doesn't look 'Greek' enough. That's the problem :/ 
Then you go with GR∑∑K, that's the kind of stuff Goscinny and Uderzo used to do in Asterix
wow. Can you be more specific?
I get why, and I now get the reason for it, but as mentioned elsewhere in here it's common in most languages to handle "quit" or "exit" from a shell without explicit function calls like "quit()" or "exit()".
I had to [redacted out of privacy]. Because of this, the previous non-computer-savvy people went through it by hand not knowing there was a better way. I exported the data as text files and then combed through them using python and voila! Four months of work saved. I don't get paid for those 4 months though :/
ah yes, I see this sort of stuff all the time. The funny thing is: I will show people how fast I can do it. Then I will tell them that they could do it just as fast if they spent some time learning basically any programming language and they don't even try.
Could someone port this to do the same thing for Django? Given my limited experience with Linux and scripting I'm sure I could probably figure it out myself with a few hours of head-against-desk-bashing (no pun intended), but maybe someone out there could whip it up with minimal effort and save my head the abuse.
Yeah, I have one of these for fabric. Maybe I'll put it up on Github for you... EDIT: I am currently struggling internally with whether to release something with hardcoded paths or not... I hate to release ad-hoc code. EDIT2: [Here you are](http://github.com/Poromenos/apache-config). Additions/etc welcome (specifically, if someone could separate the paths/servers config in a file it would be great).
Well, I look at PERL, Python, Ruby, PHP and see lots of similarities. I see a "family tree" if you will. Perhaps it starts at shell scripting, perhaps earlier. And like a family, things change from generation to generation. Ruby and Python both introduce some pretty neat things that you won't find in PERL, but you should be able to see where they are still similar and why they're in the same family tree.
very cool (both the multitouch and the ctypes usage). 
For your third bullet, are you planning on letting people send gifts to already assigned recipients? For the name associations, you will not need more than a single table to store who gives to whom and that can just be two columns (sender and recipient) with each being a foreign key for your user table's primary key. The logic to populate the table is: select &lt;pk&gt; from &lt;user table&gt; where &lt;user is willing to ship internationally&gt; if (list.size == 1) list.getUser(0).setWillingToShipInternationally(false) else matchUsers(list) foreach country in &lt;country&gt; select &lt;pk&gt; from &lt;user table&gt; where &lt;user is not willing to ship internationally&gt; and &lt;country&gt; = country if (list.size == 1) list.getUser(0).setOutOfLuck(true) else matchUsers(list) function matchUsers(list) randomize(list) make list.getUser(list.size - 1) sender for list.getUser(0) for i &lt; list.size - 1 make list.getUser(i) sender for list.getUser(i+1) This pseudo-pseudo code does not take multiple gifting into account. I can write the actual code for you in perl or java and all I need is your table schema. You do have my [email address](http://scr.im/sunkid). Use it! ;) EDIT: matchUsers actually should take care to minimize matching folks in the same countries. The randomize function could possibly take care of that. In any case, there will likely be more US senders willing to ship internationally than there are international users with the same inclination. It might be easiest to have the latter ship to the US only. So randomize could probably work like this: * split user list up by US and non-US * take the each sublist and randomize randomly * alternating between the two randomized lists, fill the final list * the tail of the final list will likely be US users that have to mail to other US users to randomize randomly: returnList = new list(oldList.size()) foreach user in oldList do i = random int &lt; oldList.size() while (returnList.getUser(i) != null) returnList.setUser(i, user) probably not the world's most efficient code, but I am pretty sure it'll do for a list of a few thousand users.
[direct link to the awesome deployment spreadsheet](http://spreadsheets.google.com/pub?key=tZ42hjaRunvkObFq0bKxVdg&amp;output=html)
You could look into buildout (and recipes) to help one do things like that.
you do realize I'm not pudquick, right?
You'll probably want to use buildout: http://jacobian.org/writing/django-apps-with-buildout/
This script makes use of apt to get the packages it needs, then handles the configuration as well. Even ports doesn't configure your packages for your specific use for you.
i was impressed enough with how much 'sudo apt-get install mysql-server phpmyadmin' will do for you :D
You're right, my bad; I'll update my reply. Also, I was serious—I wasn't trying to be disdainful. I guess I should have started over instead of editing my initial comment. Also, I apologize for generally sounding like an ass.
This might be a question for Randall Munroe...
I wonder how many sites out there now have their default admin password set to web2py. 
Oh crud, I meant 'its' with no apostrophe.
[http://wiki.python.org/moin/PyPIComments](http://wiki.python.org/moin/PyPIComments) for details, pros and cons.
Another aspect of memory to keep in mind is Python is refcount based and uses a less-advanced generational garbage collector than say Java and .NET do. 
Thanks, Ian. Didn't know that. :-)
While impressive and commendable, this is more an issue of non-computer-savvy reserchers than of Python. I'm sure that if someone there was a C programmer he'd do it ages ago - perhaps it would take not 3 hours but 5 hours, but it would've been done. It's amazing some scientists and researchers still have no clue of the automation that's possible with computers, in 2009.
This script does not exposes the admin interface. It runs two copies of web2py. One public and one on localhost only. Even if the default password is web2py you still need to ssh tunnel to the machine to login. This is a production environment. EDIT: In any case, it would be idea to change the script so that it makes a random password and prints it after installation. I will do so.
Headline seems a bit slanted, especially since in the original implementation MvL explicitly locked package authors out of the process. At any rate, I'm on record as being against comments and "meh" on ratings. And, increasingly, worried that an important resource for the Python community is essentially under the absolute control of a single person who's not really answerable for how he chooses to run it.
So Ubuntu users are being encouraged to run scripts taken directly from the internet as root?
You're trolling ? The script is human readable and it is doing mainly apt-get. No offense but your comment smells of fallacy. ( This is far more secure than downloading any windows exe from the net. )
&gt; This is far more secure than downloading any windows exe from the net. Doesn't change the fact that training people to download, make scripts executable, and run them as root is not a good idea. I don't see how what people do on Windows is relevant. A deb|rpm containing dependencies, instead of apt-get calls and the remaining logic coming from a signed repository would be a better practice.
Not a bad idea.. now how do you convince a distro to make it happen.
Guido's indeed a dictator.
Oh and the "slantedness" really was just trying to show how absurd this poll is. User contributed data for deciding on user contributed data is exactly what this poll is.
Off topic: How much do grammar errors really reveal about the typist? What can we infer from your little slip-up? I think that you are educated enough to know the grammar, but this offering to our community wasn't worth enough of your time for a double checking. Does that mean anything here? Your one second of extra work would have been seen by hundreds of eyeballs. In the past, I didn't understand why people would get angry about grammar corrections. Now I see they interrupt and sidetrack a discussion. But if you aren't educated or considerate enough to catch your own errors, should people listen to you talk? Sometimes, on a technical matter. But when a person rants about their political bugbear or a complicated abstract concept, or anything that can't be immediately verified I feel it is our duty to point out their flawed language. It says, "If you're going to ask for our attention, refine your presentation." I see anything less as disrespect.
We like him that way.
 my_func.original_function = func ... and you can access the original function again even when using closure and @wrap.
Won't this lead to memory leaks, as the callback keeps a reference to the function and vice versa?
I should have added that I had little experience with python beforehand. I have three years of experience with Java, and it would have taken a lot longer. 
Python does have a cycle-detecting garbage collector, so in theory, no. In practice, I have no idea how well it actually works, so maybe.
The GC only gets run in intervals, so if you make these faster than it can collect them, there will be fun.
That's an interesting thought you have there. I will try harder next time though some lenience would be appreciated (I'm asking this from the omnipresent Mr. Anonymousgrammarfailhunter if he's listening). From my experience I'm more prone to these silly slip-ups than others even in my native language. Presentation means a lot indeed.
You don't have to convince them. Just create the package and submit it for inclusion.
I would take some help in getting this done. I do not much about the process.
I don't either, but I'm assuming that your distro of choice has some junior packager support system, I know Fedora does. So send someone an email, or hit them up on IRC and find out what the difficulty level is like.
the argument=None is one of the first things I picked up actually. 
That's very interesting, but I would disagree with that taxonomy quite a bit. Ruby is directly influenced by Perl, and Python to a much lesser extent, but PHP is a different beast altogether. Python and Ruby are both interpreted, but that does not mean they were designed to be scripting languages. 
The solution from the article: def append(value, l=None): if not l: l = [] Is wrong. Use: if l is None: .... Empty lists will equate to False. Notting an empty list will be true, so anyone who *wants* to append to a given, empty list, can't. I don't think the article illustrates the first issue well. The 'default_append' example *should* be the expected behavior: you're appending to a given mutable object. What's not expected is if you take the returned object from a call without specifying the list... &gt;&gt;&gt; def append(value, l=[]): ... l.append(value) ... return l ... &gt;&gt;&gt; a = append('1234') &gt;&gt;&gt; a ['1234'] &gt;&gt;&gt; b = append('5678') &gt;&gt;&gt; b ['1234', '5678'] &gt;&gt;&gt; a ['1234', '5678'] ...which usually isn't expected behavior. (Edit: formatting)
Well, for some reason, my mind sees the $variable distinction as a clear indicator of the lineage. I see $variables in MIPS assembly, shell scripting, PERL, and Ruby. I think they're also in Python. In Java, C, C++, etc... variables are like "int name = 9;". What do you think about that?
Wow, that is so meta...
standard white english is overrated
Nope, $variables are not valid Python, and Ruby doesn't use them either. Variable names are just like how you would do it in C (except, of course, you don't explicitly declare them apart from initializing them with a value.) The fact that you bring up MIPS assembly would seem to actually contradict your original point, actually. Any assembly language is so far removed from a modern dynamically typed, interpreted language like Ruby and Python that even if "$var" was a superficial similarity between all of them, then that similarity is pretty much meaningless.
Fair enough. You win. :) Thanks for the lesson!
If you don't have some serious credentials you might look like a fool making that assertion.
&gt; The 'default_append' example should be the expected behavior: you're appending to a given mutable object. No. I expect default argument to be what I get when I don't supply that parameter *on each call*. It's the default I should get.
What I was saying is when you *do* give an argument (which the example using the 'default_append' variable did), such behavior should be expected: it appends to the given argument and returns the given argument.
Good. I got tired of having to add -Wignore to paster every time I ran setup.py. :)
&gt;**The first step is to bundle the CPython interpreter with your application.** That’s fairly straightforward if you know what you’re doing. You simply include the Python interpreter with your code. Could anyone elaborate on this? I think I know what he means but I have no idea how this could be done. I'm most likely entering the wrong search terms but Google isn't turning up anything useful. edit: thanks both
Personally I tried SQLAlchemy and it felt a bit clunky compared to the django ORM. It's really awkward that there's more than one way to do it: There's the django-ish OOP syntax and there's the functional table() syntax. To make things worse, not everything works on both syntaxes. So I would vote for django if it was easy to disentangle the ORM or if you don't mind carrying a 15 MB weight with you.
I'm kinda -0.1 about this, it's a tradeoff. This change makes it easier on the app developers but hides information from the casual interpreter user.
I'm pretty sure he's saying to add a path within your application directory structure and put the python executable and any libraries under there. So, you'd have something like: /myapp/bin, /myapp/lib, /myapp/python, /myapp/python/bin, /myapp/python/lib... whatever. Then you'd write a batch(?) script or exe that calls "/myapp/python/bin/python.exe /myapp/bin/main_app.pyc" which has library load paths correctly set to look to /myapp/python/lib. That batch script or exe would be the main app that the user would click on. This is pretty common with non-compiled languages. A lot of vendors do similar stuff with java-based apps. Tools like rubyscript2exe and probably py2exe are often doing something like that for you.
I am overjoyed. This broke all kinds of ipc with pipes and the like not to mention 3rd party modules filling up my logs with oh so useful warnings about md5/sha/sets. 
I like Elixir(a declarative layer on top of the SQLAlchemy library) and the [Diving In Toturial](http://elixir.ematia.de/trac/wiki/TutorialDivingIn). Just fell it's not very active developed and I think I need more documents.
I tried SA as well and am of the same opinion as you. However, I liked SQLObject more and actually used it. SA feels too heavy and requires quite a bit of boilerplate (or used to).
same here, the django ORM gets some flak, however i find it intuitive to a point that I've rarely felt with software
SQLAlchemy is pretty cool, but remember it's an ORM and introduces the ORM mismatch with your relational model. Be comfortable with that if you're going to use it. If you don't care about relational, I'd suggest ZODB over SA. SA also feels pretty heavy, and sometimes not the best documented: usually you can find what you need pretty easily but there are points where the voluminous documentation doesn't help you find out "how do I do X", and occasionally it lags behind the interfaces somewhat. Frankly, SQLAlchemy is not my favourite thing. It's very useful and very complete but even having used it for several projects it still feels rather magic. There are layers and interfaces in there whose purpose I don't understand and just have to trust. It feels a lot more like Building Enterprise Software than programming in python.
No damn it, I know SQLAlchemy and want web2py to use it.
Difficult to read, no explanatory text, a good number of "No equivalent" entries with no explanation. Basically a waste of time.
Also, when did "web2py" become "w2p"? Seems to me to be sometime after I successfully learned to ignore articles mentioning the former?
the django orm, while catching up, pales in comparison to the power of sqlachemy.
I completely understand and love sqlalchemy above all other options. 
Why? SQLAlchemy does not run on NODB. web2py runs on GAE and we plan to support MongoDB in the near future. EDIT: you can use SQLAchmey with web2py although you will lose some interaction with forms, for example web2py cannot generate forms from sqlalchemy models. You can also define web2py models using the SQLAlchemy syntax and/or the Django syntax (and mix and match web2py/sqlachemy/sayngo syntax), there is a partial and poorly tested compatibility mode, although it would still be using web2py DAL to generate sql/gql. We provide the functionality so that you ran SQLAlchemy models on GAE.
I prefer Django's ORM as well but SQLAlchemy matched with Elixir provides a pretty adequate substitute when needed.
Check [Embedding Python](http://docs.python.org/extending/embedding.html).
Of course, the question is how much of that power the average developer really needs, and how much is "good enough" :)
btw why isn't elixir in the trunk? I mean, that's just a 3rd way to do it in SQLAlchemy, sounds superfluous.
Note that I'm not saying everyone should use SQLAlchemy, but take a day to learn it. There are a lot of *interesting concepts in this library.
I used Django and SQLObject. With both I started to hit walls pretty soon. In the case of SQLObject in 3 hours. I still have to find something which SQLAlchemy does not handle. If you can query against properties represented by an SQL select, you won't use anything else ever again. 
So I can't bundle this once and run it on every OS it seems? I need to make a specific bundle for each OS with it's own interpreter? I still have to read grudolf's link so maybe the answer is in there.
Is there any benchmarks available about the WSGI or HTTP server like [Tornado did](http://www.tornadoweb.org/documentation#performance)?
Not really. I run "ab -n 100000 -c 25 http://x/" just now against example/wsgiserver.py and got about 3800 req/s. I plan to do proper benchmark later to put that in context. Given that HTTP handling is done in C by libevent-http I think that raw request/second speed should be on a par with Tornado and others. It'll be even more faster once libevent-2 matured: http://www.provos.org/index.php?/archives/61-Small-Libevent-2.0-Performance-Test.html I think it'll be more interesting to benchmark other stuff, like how much memory an open connection consumes. 
Deleted reply from OP, which I found in my inbox but missing from the thread: &gt; Since reddit filters "web2py" as spam. We are still officially web2py. .. I have nothing to say.
Sehr, sehr interessant!
wow, libevent2 seems very promising. One question if I may, how do you handle code reloading?
Brian, it's funny this comes up just now. I just the other day decided to go and try out SQLAlchemy on a project. I found that although I had access to way more ability with SQLAlchemy, I never once stepped outside the ability of the Django ORM, nor can I foresee any reason why I would need to. Maybe I just subconsciously design projects with the limits of the Django ORM in my mind, maybe that's a good thing. I for one prefer the simplicity to having extended abilities.
I don't, I reload the process instead. I think it's the best you can do with Python.
You're close :) Actually, it would be more like "très, très intéressant" :)
Ok, I'm confused. He writes perfectly acceptable German and you correct him with French. Is there something I'm missing?
He wrote "interessant" in his post, which I assume was a slip from his native language, French, but which I mistook for German since there was no accent on it, so he corrects me saying that it's actually French. Just a weird conversation overall :P
Have you used the [SQLAlchemy Expression Language](http://www.sqlalchemy.org/docs/05/sqlexpression.html)? It's just a nice pythonic way of building SQL queries so it's more directly SQL-y.
I hope Elixir can be merge to trunk too. maybe it's still not mature enough?
Since reddit filters "web2py" as spam. We are still officially web2py.
There has been some confusion. The message was for you. Anyway, it is not a secret, they told me. Other users may have been prevented from posting about web2py because of this spam block.
Thank you Graham. Excellent work. Very important for the community.
Okay that's fair enough. I like what you guys are doing with web2py I'm just lazy and sick of learning new ORM API's.
It includes an ORM, but is more than an ORM.
Thanks. I appreciate it and I understand. Anyway, all you really need to know is: db.tablename.insert(field=value) db(query).delete() db(query).update(field=value) db(query).select(orderby=field,groupby=field,limitby=(0,10)) query=db.tablename.fieldname==3 query1=query2&amp;query3 The rest is details.
this: db(User.id==Address.id).select(User.ALL,Address.id.count(),groupby=Address.user) renders: SELECT users.*, anon_1.address_count FROM users LEFT OUTER JOIN (SELECT addresses.user_id AS user_id, count('*') AS address_count FROM addresses GROUP BY addresses.user_id) AS anon_1 ON users.id = anon_1.user_id and not: SELECT users.*, count(addresses.id) FROM users, addresses where users.id=addresses.user_id group by users.* ? They are quite different, in query optimization characteristics as well as actual result. If the former, a LEFT OUTER JOIN seems pretty surprising behavior based on what the code says.
I heard some fud about ruby having a better framework abstraction layer than wsgi, does anybody here know the details?
I agree with his general point but: &gt; nor can I foresee any reason why I would need to. seems strange. Just on a base level, you *never* could see yourself wanting multiple primary key support, or multiple db's, or wanting full Oracle support, or using a union in your sql, or an in memory database engine to test things, or introspection of a database on the fly instead of dumping the schema into a models file etc. etc.? Never? I mean, the Django ORM does what you want most of the time, has a very nice API, and you don't always need sqlalchemy, but I don't see how it's better to change your design to your tool instead of having functionality available that you don't happen to use.
Exactly. But in truth, once you learn the ORM stuff it is hard to resist using it!
&gt;&gt; I still have to find something which SQLAlchemy does not handle. Same here. Whats more, is that even though I have years of experience writing raw SQL statements and only 6-8 months using SA, it is a rare that I bust out old schools SQL in the several apps I use SA in. It is usually less typing and simpler syntax using SA.
Yeah I have never really seen the upside of Elixir, perhaps I don't get it
What about take ten minutes to learn how to use a file system?
Many developer would never see the need for lots of what SQLAlchemy provides because they did not start with SQL. They don't see the need of being able to query the whole report in a single query instead of in a nested loop. They don't see the need of having DBMS constraining single item in a one to many relation. Or the need of being able to issue and SQL query on a single table and making sense of it without having to join to ten more table for status codes or parents' name because every primary key is auto generated integer.
SQLAlchemy has built in declarative layer now. It's not exactly like Elixir but I don't know what's missing.
Nope. It renders SELECT users.name, users.fullname, users.password, count(addresses.id) FROM users, addresses WHERE users.id=addresses.user GROUP BY addresses.user; If you want to do a left join the syntax is different.
the GROUP BY there is invalid, for starters. It will only work on MySQL. Real GROUP BY requires that all non-aggregated column expressions appear in the GROUP BY. Then as far as "GROUP BY users.*", which is what databases like PG would accept here, go and read http://weblogs.sqlteam.com/jeffs/archive/2005/12/14/8546.aspx for information on why SQLA goes through the trouble it does to stress explicitness. its basically inefficient and relationally awkward to be grouping on a large number of columns.
you can do groupby=User.id|User.fullname|User.password you can also do groupby='users.*' 
Ruby is a programming language. WSGI is a Python API specification. You can't exactly compare them in the way you are describing. If you want to compare specific web framework implementations for Ruby and Python then that is a different matter. FWIW, whether the Python web framework can be hosted via the WSGI API is irrelevant to the discussion.
Correct, with Apache and mod_python "code reloading" is done by periodically throwing away the interpreter that's been used for N thousand requests and starting up another one. Having tried to implement module reloading myself in long-running Python servers, it's not worth even trying. Python's import system and caching in `sys.modules` makes it quite difficult. (What we effectively went for further down the line was to whitelist a certain set of modules for code reloads, everything else would persist)
Two things that I've come across: * Letting the RDBMS handle "Upsert". Need to drop down to raw SQL for this * an OrderingList association proxy without putting an artificial key on the ordered-list table 
Specifically you may look at 'http://plone.org/products/collective.hostout' which effectively allows automated remote deployment of buildout managed systems.
Yeah, but sometimes I want less than an ORM. And the sheer volume of stuff in SQLAlchemy makes me wonder at times what happened to the Unix philosophy and to `import this`.
I forgot I had an account for a long time. Then I couldn't remember the password and hadn't stuck an email address against account so couldn't reclaim password.
Thanks! I never enable the line numbering because I'm really not sure how to share the OS's clipboard when I yank text. So, if I just highlight and copy-paste into another document, it brings my numbers with me. Any ideas how to eliminate this problem? Other than that, good stuff in here!
"upsert" is a MySQL-specific feature. Its a little tedious when people keep mistaking MySQL's hacks as things which should be first-class implementation-agnostic features. Its why we added the [compiler](http://www.sqlalchemy.org/docs/05/reference/ext/compiler.html) extension so people can begin implementing their pet non-SQL features themselves. Also orderinglist has no artifical key requirement.
Select what you want to copy __in vim__ using visual mode and hit _"+y_. "+y Copies to the clipboard "+p Pastes from the clipboard 
This does not work for me. When I try this, and then paste into another application (gedit, for example), it just pastes the last thing i copied outside of vim.
If you're using ubuntu, you have to install either vim-gnome or vim-gtk to get the X clipboard stuff to work. Yes, this is stupid.
I don't understand why you would use those functions as opposed to just mapping a command like ":w&lt;cr&gt; :!pylint %&lt;cr&gt;" or something.
Err, no. "Upsert" is a term describing an operation which can be written in most dialects. It's also a very common operation for some classes of DB-backed applications. FWIW, I don't mind dropping down to `.execute()` for this (the compiler extension looks like total overkill), but it's a counterexample to luckystarr's claim. As for orderinglist, the schema it choked on was `(owner foreign key, ordering unsigned int, .., primary key (owner, ordering))`. The mailing list advised me I needed a different primary key to handle insertions.
It worked! Thanks.
Add this to your vimrc: " Toggle numbers on/off for easy copying using &lt;F2&gt; nnoremap &lt;F2&gt; :set nonumber!&lt;CR&gt;:set foldcolumn=0&lt;CR&gt; As shown, you just press F2 to toggle line numbers on and off.
Sorry, I have no idea what you're talking about, I just wanted to clarify that sqlalchemy was not just an ORM. You should use whatever makes you happy.
I should have mentioned that.
Excellent idea. I'll update it.
Good tips thanks. I've been wanting to have these in my vim for python. Will try them out plus the pointed vim scripts.
I heard a rumor that Rack's better than wsgi, that's all.
noob question: Do I just copy this to my vimrc file?
While this is a cute quote, the original quote was, I think, made in the context of a discussion that included Zope 2, a web application framework in Python that is more than 10 years old now, but still actively maintained and improved. Legacy code is frequently unpleasant. Grok is a friendly packaged Zope Toolkit, which is based on the Zope 3 project, a complete rewrite of the above. Now the Zope Toolkit can be considered to bite too, but for entirely different reasons. :) 
Actually, that's my python.vim file, which is located at ~/.vim/ftplugin/python.vim. VIM can apply specific configurations to specific types of files, but you have to enable that feature in your .vimrc. I'm at work right now, so I can't copy and paste mine, but it looks something like this: " global settings I want applied to ALL files I edit in VIM filetype plugin on "this enables file type based configuration. set number setlocal tabstop=2 setlocal shiftwidth=2 setlocal expandtab setlocal autoindent setlocal smarttab ... So the way vim loads these is kind of a trip. It'll go into all the directories in your .vim directory and look for &lt;filetype&gt;.vim.
&gt; "Upsert" is a term describing an operation which can be written in most dialects. it can be written as: SELECT * FROM table where id=&lt;x&gt; if not exists: INSERT else UPDATE We provide SELECT, INSERT, and UPDATE. It's trivial to write yourself a def that calls these in the manner you prefer. Or you can write a stored procedure to do it. You can call those too using `func`. only MySQL has "REPLACE", a single SQL-like statement that does the whole thing, generically, in one execution. If we supported this it would be a `replace()` construct in the MySQL dialect, or as I said you can use the compiler extension to write your own construct. If we were to provide it, one surprise is that python-side defaults/onupdates wouldn't be able to function since those must be determined ahead of time. If you're looking for "upsert" with the ORM in one step, Session.merge() accomplishes that. For volume its usually more efficient to load the entire field of records you're dealing with first and put them in a dictionary. This is why we don't try too hard to make automatic "upsert" constructs - its really better for the developer to decide how (s)he wants to handle checking the existence of lots of records before inserting/updating, rather than using an overly genericized feature that runs like crap. edit: seems like Firebird and SQLite have MERGE as well. not quite the same as MySQL's REPLACE. I'd be +1 on supporting a merge() construct though it would see very little usage thus far.
&gt; As for orderinglist, the schema it choked on was (owner foreign key, ordering unsigned int, .., primary key (owner, ordering)). The mailing list advised me I needed a different primary key to handle insertions. a constraint on the key would mean that you can't reorder the items, since it involves trading keys which requires a blank space for one item temporarily. If you can find a tool that handles this I'd love to see a generic way to address that. inserts should have no restrictions.
What happened to who?
What do you mean "now"? The initial release of Grin was July 14th, 2008. It is really awesome.
Is it a standalone script that you can put in your ~/bin. Because ack is and that's why I'm using it. Convenient to install on all your machines with the bunch of script that follows me everywhere.
... or you could just let Emacs do grepping for you, if that's your thing. It'll exclude directories and files you don't care about automagically. And it'll give you the results in a hyperlinked buffer for your benefit. `M-x rgrep` for recursive grep. `M-x customize-group RET grep RET` for grep config.
From the PyPI page: &gt; grin uses setuptools to find and install its dependency on argparse So it needs the argparse library. Other than that it's just one self contained file, grin.py.
&gt; The main problem I had with GNU grep is that I had no way to exclude certain directories that I knew had nothing of interest for me, like .svn/, CVS/ and build/. [Since 2.5.3](http://savannah.gnu.org/patch/?3521), grep has had --exclude-dir for this.
Ack is fantastic, and as the author mentioned, suffers from none of the stated deficiencies anymore. But the more tools like this the merrier.
Can I use it to parse HTML tags?
RACK is an API specification akin to WSGI and was actually inspired by WSGI. See the definition at 'http://rack.rubyforge.org/doc/SPEC.html'. If you compare that to WSGI specification at 'http://www.python.org/dev/peps/pep-0333/' you will see that they are more or less doing the same thing. I still think you are confusing an API specification with a particular web framework implementation which just so happens to be able to interface with a web server using the RACK or WSGI specification. Both RACK and WSGI are very low level, they are not frameworks in themselves. So, compare the WSGI and RACK API specifications with each other if you want, but you shouldn't be comparing either of these to high level frameworks such as Ruby on Rails or Django respectively. In other words, compare framework to framework, not framework to web server interface specification, it just doesn't make sense to do that.
It it better than ack?
Try ack and you will never go back.
...and we have a winner
Jesus Tap-dancing Christ what the fuck is the matter with you people? Do you just go into articles looking for nits to pick? And post as soon as you find one without finishing? I swear being unable to see the forest for the trees is a requirement to be signed up here. Not more than four sentences later in the *same fucking paragraph* he says: &gt;Recent development has added these features, but I had already released grin by the time I found out.
Until `argparse` is included in the standard library. See [PEP 389](http://www.python.org/dev/peps/pep-0389/).
I'm by no means a pro programmer but maybe try pyqt4?
Forgive me if this is an annoying question: What advantages does web2py have over, say, Django or Pylons? I only ask because I've been seeing quite a lot about web2py lately and not much of it is good, though...
 for i in `find . -name "*.py"`; do grep "searchtext" $i &amp;&amp; echo $i; done; Various arguments to 'find' and 'grep' and maybe some pipe filters would allow for capability much greater than grin, and it is language-agnostic.
seconded, it just rocks. As an aside, ruby had glark (http://www.incava.org/projects/glark/) for about ten years. 
[**EDIT EDIT See below**] I have to disagree with the general positive tone of the article -- I hate my Python Essential Reference. Perhaps it's better for libs, but I find for core things it's *horridly* organized, with things like the functions for dictionaries scattered across three different places. The index is also one of the worst I have ever seen -- completely and absolutely useless. I find myself getting angry every time I try to use it. Perhaps the 4th edition is better, but I'm not going to take the chance. **EDIT: Oops, big apologies, the book I hate is "Python in a Nutshell", 2nd edition, from Alex Martelli. Apologies for slandering the Essential Reference!!**
The biggest advantage is that it has a smoother learning curve for those coming from PHP, as it tries to mimic the bloated namespace, the horrendously ugly apis and the overall absence of design. It is intentionally non-pythonic because otherwise it could scary developers not familiar with Python or that consider the language awkward. Have I mentioned that it has hundreds of superglobals, all in CAPS? In short words: lovely collection of anti-best practices in programming.
What about improving the Python documentation?
I'm a fan of wxWidgets myself. I would recommend that if you're gonna do cross-platform stuff.
I checked out both docs, thanks for the links. All I wanted was a comparison between rack and wsgi. Comparing the docs will take me a bit longer to do than someone who's used them both. So if anyone with answers is out there - I'd like to hear 'em.
Goodness gracious, that's disgusting. I'll take `ack --py "searchtext with fucking PCRE bitch"` instead of that shit any day of the week. Plus I get pretty colors everywhere.
Does the book comes w/ its PDF version ?
does this book come with its PDF version ?
When I posted this...2 points for wxPython and 3 points for PyQT4. So, let me bring up the rear and suggest Tkinter. 
Turtles all the way down.
Why does it have to be divvied up by language? Why not use the tool that suits your needs best, regardless of language? That's why I want http://betterthangrep.com/ to have links for ALL the grep improvements, not just ack. The source for the website is in the ack repo on github, if anyone wants to add links: http://github.com/petdance/ack/tree/master/btg/
No, not PCRE. Perl regular expressions. PCRE is not Perl regular expressions, no matter how C they claim it is.
Sure, you could do that, but you're typing about three times the same amount of text. Ack is designed to get you doing your most common searching as fast as possible.
I wish SA doc would be better organised and its API was actually clearer. There are so many instances where you're left wondering "what should I be using? How? When?" Also there are so much abstraction debugging SA can be a tedious task. Finally using SA in a threaded application is like voodoo. I would probably look at alternatives like the database template of Spring Python remining me of Hibatis.
If I'm understanding this correctly, there's an error here... &gt;" Pydiction script &gt;" http://www.vim.org/scripts/script.php?script_id=850 &gt;" ~/.vim/after/ftplugin/python_pydiction.vim &gt;" ~/.vim/after/ftplugin/pydiction.py &gt;" ~/.vim/after/ftplugin/complete-dict &gt;let g:pydiction_location = '~/.vim/after/ftplugin/pydiction/complete-dict' Shouldn't 'pydiction_location' be set to '~/.vim/after/ftplugin/complete-dict' since that's where your comment indicates it's installed?
someone once said, "those who don't know zope are doomed to repeat it..." or something to that effect. 
I don't see what the problem would be for Matlab and Python coexisting. I think both languages are pretty easy to read. But then, asking a whole organization to be literate in both is probably too much. However, I also don't see any reason why a company would ever prefer dealing with licensing(Mathworks) when there is a free service with better development(Google) and vastly more flexibility. I would start with resources like: http://www.scipy.org/NumPy_for_Matlab_Users Showing that everything in Matlab can be done in python. Then I would move to some references documenting how much faster it is for engineers to develop in Python. I am not providing one because there are many, but they are for specific industries and I don't see any video camera examples. Take your pick. I would then reference the licensing benefits. The cost of Matlab licenses is not insignificant. If there are any special considerations for your industry, like the fact that Python can also be used for this, that, and the other thing, don't forget to mention those. Just always remember to tie it back in to the time, resources, sustainability equation.
http://wxglade.sourceforge.net/ don't worry about writing it all from scratch (unless that's a project requirement of course) the first time through. There's plenty of time ahead of you to memorize method signatures.
Python is awesome and I prefer it to Matlab, but there are still some areas in which it doesn't compete with Matlab. But depending on what your company does, Matlab's superiorities may be moot. Start by compiling a list of what Matlab and Python do well for the company, and then do the same for their limitations. Talk about your personal experience with Python, cite ways in which using Python has saved you time or eased development/maintenance. Then talk about the benefits of open source versus relying on proprietary languages. For example, if The Mathworks decided to increase their licensing fees or create a backwards-incompatible version of Matlab, how much of an issue would that be for your company? If possible, try to turn everything into numbers. How much would your company save by switching to Python and reducing the licensing fees paid to The Mathworks? With that money, could they hire more developers to take on more projects?
Thanks for the insightful post! I wasn't aware of that resource before and it helped with a project I am working on.
Can you explain "a free service with better development(Google)" please?
&gt; Finally using SA in a threaded application is like voodoo. that's a silly thing to say. There's no threads spawned off or anything like that in SQLA and not much mutexing either. So using SA in a threaded application is no more difficult than using a bunch of objects and DBAPI connections in a threaded application. You're free to have many threads change your objects as much as you'd like with or without SQLA, and you'd have the same amount of synchronization-based headaches as a result, and the golden rule of "don't share data between threads" holds as much without SQLA as it does with it. If you don't know how to write thread-safe/thread-localized code in general, then yes someone advising you "don't share data between threads unless you synchronize access" probably seems like voodoo; but that has nothing at all to do with SQLA. Except that we're nice enough to give you a helper object called "scoped_session", which is just, a thread local object. You should probably read up on the docs for Python's "threadlocal" object until it no longer seems like "voodoo".
web2py is designed to have coherent APIs while some of the other frameworks are just a collection of modules written by different people. It has minimalist set of [API](http://web2py.com/examples/default/api) that are very easy to learn. It has an Database Abstraction Layer that is comparable to [SQL alchemy](http://web2py.com/examples/static/sqla2.html) but it is the only DAL/ORM that also support Google App Engine out the box. We support a total of 10 different database engines. Like Django/Pylons it has a Model View Controller architecture. Although unlike them it executes your app, it is not your app that imports the framework. This means you never need to restart the server when you edit your apps. This + the integrated web based development environment make web development very easy and smooth.
Actually web2py came out from an academic environment as an attempt to merge some of the best features of Django and Rails in a consistent and coherent manner suitable for teaching the inner framework design to undergraduate students. At DePaul University we have thought 4 courses using web2py covering both internal design and exposed APIs. People who use web2py do it because of its design. web2py is designed to follow and enforce the best Software Engineering practices out there including proper MVC, postbacks, form validation, escape all html/xml output, role based access control. Just to name a few. There is a convention about the API. All global variables and functions in web2py are lower case (there is only 4 of them). Classes defines at the framework level are upper case (html helpers and validators) while classes defines at the app level are capitalized. [Here](http://www.web2py.com/examples/default/api) is a complete list of the exposes API. 
&gt; Showing that everything in Matlab can be done in python. I love Python to bits and hate MATLAB as much as the next guy, but this is so far from the truth that it came up behind it again. MATLAB has function libraries for *anything* you might want, all conveniently packaged in one easy namespace (bleh). There's a very good chance the OP will have to duplicate quite a lot of the MATLAB code, so, unless he uses almost none of the MATLAB math libraries, the switch is going to be very painful.
We're not using Simulink or any of the extra toolkits, which is where Matlab would be superior. Matlab's graphics might be a bit better.
I'm sure there would still be people using Matlab, especially for prototyping. I guess the question for management is whether they should invest in getting some of the other developers up to speed with Python.
&gt;Yes, this is all very useful. Especially that part about having to refer to a Unix man page. I'm sure the Windows programmers find that especially useful. If you type 'man something' into google, you almost invariably get a copy of the unix man page as its first result. Try the case in point, `man recv(2)` for an example.
Start blogging, posting examples - make using/adopting cheetah frictionless and easy. Post examples using them with common, popular web frameworks. 
This is not going to help answer your question, but...when you finish putting this proposal together, would you mind sharing it? I'd be very interested in seeing how it works out. Good luck!
 I'm no matlab expert. I thought everything was already replicated in python in some of those scipy libraries. Either way showing if things are replicable is the business case! My answer outlines that exactly. He has to enumerate any differences between them and prove python is still effective. If its not then his research will show his business case isn't strong and convince him to suck it up and code with matlab.
Google helps fund the development of Python (by employing Guido van Rossum etc.). The documentation and compilers for python and the associated math and statistical libraries (scipy, numpy, R) are all free. Not saying that R is part of python, but bindings exist and it helps show the breadth and portability of python.
&gt; Post examples using them with common, popular web frameworks. I second that. 
I personally had no problem just randomly picking up Python and running with it. The idea of investing time to get up to speed seems odd to me. I would just add 20% time to the first project they try maybe. This is highly dependent on the field of course. Once a strong programming foundation is established I have had little difficulty moving between languages. This is largely because libraries are so well documented on the internet with Python, Java, PHP, etc.... I imagine this isn't the case with proprietary languages. Also, this certainly wasn't the case back when alot of current developers were in college.
I will probably recommend using the [python(x,y)](http://www.pythonxy.com) distribution. It looks like it really can do most of what Matlab can, all in one package, except for Simulink and some of the toolkits.
I personally don't really like how Numpy syntax works compared to either Matlab *or* R. I love Python to bits, but for this array processing stuff, prototyping in Matlab might make sense.
Yeah, I picked up Python on my own, too. Two out of our ten developers could do that without much trouble. But the others just won't unless they are told to. They are 9 to 5 programmers without much real interest in learning new things. Although they do complain about the status quo a lot.
Here is another resource showing Python and Matlab playing nice. Doesn't look that mature though. http://claymore.engineer.gvsu.edu/~steriana/Python/pymat.html Also, My wife says one things that Matlab has that other systems are really lacking is signal processing. Since you work with video that might be high on your needs list. I haven't heard of anything python related for signal processing.
Pick the top Matlab developer that's open to change, and help that person learn as much Python as possible. If that person can't articulate the benefits of Python over Matlab, you probably shouldn't be pushing for the change. haiku version: try before you buy; help the best developer make your case for you
I definitely dig the "make X frictionless to use"; suppose I'll have to start digging into how various web frameworks use templates (Django, Pylons and TurboGears come to mind, any others?) In years gone by, I remember projects comparing themselves to each other "X is faster than Y", etc, do you think these comparisons are useful to anybody? Given the popularity of Django over other options, I'm operating under the assuming that ease of use is tantamount to speed or technical superiority
That's sort of what I thought, too. Our top Matlab person jumped right in when I mentioned it and said, "A new programming language? Yay! How do I get started?" So she had a test that kept getting memory errors and she was going to rewrite it in Python. That would be great, but I think she got side-tracked, and I helped her find a work-around. So that may or may not happen.
That would be nice, because MATLAB's syntax drives me up the wall, but from a cursory glance it doesn't look like it has a significant number of math libraries... E.g. I didn't find a telecommunications toolkit or any signal processing or anything like that...
In that respect, everything in MATLAB can be done in Brainfuck (or, even worse, Perl).
Well for one there is [SciPy.Signal](http://docs.scipy.org/doc/scipy/reference/signal.html).
&gt; ...I remember projects comparing themselves to each other "X is faster than Y", etc, do you think these comparisons are useful to anybody? This is really a marketing gimmick. It probably does generate interest in blogs/slashdot/reddit etc. especially if the other template engine writers post their version of the benchmark in response. However I would imagine for almost all but a tiny fraction of cases, template generation is dwarfed by database access times and as a result is largely irrelevant.
IMHO the point here is that (1) the manual is not even trying to be comprehensive, (2) since in Windows Python sockets are based on WinSock it's not really cool to tell me to look at the Unix man page. When I'm not using IDLE/Eclipse interactive console (meaning I'm working from my linux box) and unless I need to work with something cryptic (no docstrings, obj.members faked by \_\_getattr\_\_) all I need is dir() + help() + google. I only read docs when I'm doing the conceptual part of coding and most of the time it's faster to try something out, rather than looking it up in the docs anyway.
Does anyone else feel that MATLAB takes an inordinate amount of time to debug compared to other programming languages? If so, coding/debugging time could be an argument. I know MATLAB much better than python, but I just find python so much more productive, intuitive, and idiot-proof. It usually takes me at least 3 hours to debug a MATLAB program I wrote for an hour of writing whereas an hour of python programing usually just means 15 mins of debugging.
she? o_O edit: judging from the downvotes, reddit didn't get that I was asking whether she was hot or not :p woman + matlab + hot = goddess :) 
Been there, done that -- in a couple organizations. Having tried for quite a while, I personally don't think it's possible to work this through a "business case" presentation. It'll look pretty, I'm sure, but will be just as successful as all other business case presentations you've seen. The problem is developers who are using Matlab often aren't "real" developers in the sense that they don't enjoy programming and the relative elegance that comes with moving to a real programming language. They simply see Matlab as a tool for their image or signal processing work and are not going to put forth the effort to move towards a different solution since the tool they have usually works, all their previous work (and the the previous work of all their colleagues) is in Matlab, the software has paid support and is financed by the organization for them. There is very little incentive for them to move even if they agree with your logical arguments pointing out they have to pay some organization in Massachusetts in order to convey their intellectual thoughts. Numerous presentations showing the Matlab and Python syntax are often similar enough for the majority of things they're used to from Matlab will be seen as intellectual curiosities unless you have signal processing folks who actually think about languages and would choose to be programming in anything other than Fortran or C if Matlab wasn't around. At any rate, I've found the finance point is the best one to push, but it's not easy. I almost convinced a manager to provide 1/2 the price of a yearly Matlab license with all the add-ons we used directly to the salary of any person who would switch to Python. That would have saved ~$500 per person to the organization and placed ~$500 bucks in the paycheck of everyone that moved. I didn't see how that wasn't anything but a win-win and still the organization balked. Don't get me started ... (... too late.) I haven't tried convincing my current manager that I should get the Matlab license kickback since I'm using Python and Octave for my Matlab related activities (Octave so I can run the Matlab scripts of my colleagues when I have to). Some day I'll build up the courage. Don't mean to be a pessimist here, but I've stopped trying.
Sorry to be negative, but why are you so sure your company should switch in the first place? If there are serious risks in continuing to use Matlab, and you can do the necessary work more safely with Python without incurring any other risks, then great, that's your argument to management too, business case and all. On the other hand, if I were your boss and you tried to sell me on a technology where you were the only guy in the office who knew it and I had an established team using an established product otherwise, I would take a lot of convincing about a lot of things... starting with the fact that you weren't trying to make yourself indispensable, in which case I would see a huge red flag and start taking steps to isolate you prior to letting you go. In the grand scheme of things, factors like having a readily available pool of developers, having an established code base, and using an industry standard tool that is tried and tested are way, way, *way* more important than dropping a few hundred bucks on licensing fees or spending a bit of time to work around an occasional glitch.
Well one nice feature is that Python can interact with MATLAB format matrices using SciPY, as well as being able to interact with MATLAB itself! This means that the transition period will be quite easy, as any business critical development can still continue while the switch happens. I guess your best bet is to focus on the numbers, Python and all the required packages is free, where as MATLAB has quite expensive licenses. Also it might be possible to implement the same function in both approaches to show that it is equal in power and just as concise. The main problem as far as I can tell will be justifying the re-training of other developers and the performance of the language (although PSYCO and SciPy can technically outperform or rival MATLAB). I guess the best thing is to show that MATLAB is easier to write in-efficient code in, and takes longer than the Python equivalent. Also have you thought about looking into Octave instead of MATLAB. It's still free, and has quite good interop.
I'm not really that sure that we should switch. They surprised me by asking me to make a business case, so they must have been thinking about alternatives. So I'll put together the best case I can and they can decide. I really do think it would be better. Also, they are trying to move me from the low-level C stuff to Matlab, and I am resisting, and they want to keep me happy. I would look for another job if it came down to that.
LOLOL, just because there arent as many women in software engineering doesn't mean that the ones that are have any less talent on average
check out OMPC - open matlab to python compiler: http://ompc.juricap.com/
I'm a business owner that has used python extensively for 10 years for almost all of my work. You have not provided the information necessary to make a business case. The first question to ask is: how does your company make money? Developing digital video cameras doesn't make money. Selling something makes money. What does your company sell? Camera designs? Cameras? Your time spent consulting? The second question to ask is: what gets in the way of your company making more money, now and in the future? You have a business case for switching to python IF and ONLY IF your company makes more money by doing so. (Assuming of course that the goal of the business is to make money.) Two big costs from their perspective is going to be time lost to the learning curve, plus the *risk* of time lost to projects running late due to rework (of code you already have in matlab or just mistakes introduced by developers as they're still learning, etc.) Perhaps what you should do is give a couple talks on how to do things in python at a lunch seminar. Be an evangelist to the other developers so they get interested in learning on their own. Get a couple people who seem interested, and see if you can form a team to do one part of the next project. Here are some ways to minimize those costs. Either do a small project skunkworks style as an experiment, *or*, if it's possible, try to replace one component of your matlab system (perhaps the one that's triggering that error). If you can work out a way for python to talk to the other parts of the system and you can replace just the one piece, then it won't be such a huge investment. How would python actually make more money for your company? You have to figure this out, and you have to be honest about it. By that I mean that when you really think through how money flows through your company, there is a very good chance that switching languages doesn't make one bit of difference, because it won't affect the constraint on that flow. Just because a technology is more advanced or nicer to work with doesn't mean it's right for your company. Robots are better technology for building things than people, but there are six sigma factories in China that use nothing but manual labor, because manual labor is so cheap there. *Maybe* in your company, the Matlab codebase is good enough that it just wouldn't be worth the costs of switching. I've rambled enough here. If this helped at all, I wrote a blog post a couple years ago that includes three stories of changes I made that I felt actually had an impact on the companies I worked for, that you might want to take a look at: http://sabren.com/?p=74 By all means, keep looking for an answer. There are probably plenty of non-bottom-line reasons that python could make life easier. And maybe you don't really need a true business case, but just a case for making things work better in your department, and getting rid of some of the headaches for your manager. 
What do you mean by "building a community around" Cheetah? A templating system doesn't really seem like something that you build a community around. The way I imagine it is that people just drop it into their project if they like it and start using it. On the other hand, if you are trying attract more developers, then I guess the question would be why? If you can answer that, then you can probable attract more developers to work on Cheetah. For example, are you planning to do something with Cheetah that will make it much better for programmers to use than the other templating systems? If you just want more people to use it, then I guess I can offer a few suggestions: * compare the syntax and features to the other template systems * make sure that it is trivially easy to use them with any of the frameworks (that you have everything in place that a few seconds installation/setup would allow someone to use Cheetah in any web framework). * show what makes it different, better, etc... than others like Genshi, Mako, and all the others out there. Of course, you can always get lots of users when it is the default templating system for a popular web framework. :) ------ Anyways, I do have two questions. What do you really mean by you want to build up a community? What are you trying to accomplish? Also, why would I personally want to use Cheetah over something like Mako or Genshi? Does it offer something that would really be nice to have in a templating system? I'll probably end up needing a templating system eventually, so I thought I'd ask (although I'm already leaning towards a different one). :)
I would have thought that just by showing them the [pricelist](http://www.mathworks.com/store/priceListLink.do) would have been enough to convince my company. But they seem content to shell out over $5k for the base license and all the necessary toolboxes for each engineer. Then they pay another $1k for annual maintenance fees. The costs jumps to over $10k for those who need simulink.
Thanks for the thoughtful post. That's the kind of business insight I was looking for.
Yeah, I was just putting that out there in case anyone didn't know. Google *understands* you.
&gt; What do you really mean by you want to build up a community? What are you trying to accomplish? Good question; a larger user-base whole view the project as a necessary part of their stack. When I first started using Cheetah, the project was languishing and my colleagues and I used it more out of momentum than desire. Having an enthusiastic group of people using a project helps a *lot* with motivation to continue to improve it (at least for me) &gt; Also, why would I personally want to use Cheetah over something like Mako or Genshi? Does it offer something that would really be nice to have in a templating system? I'll probably end up needing a templating system eventually, so I thought I'd ask (although I'm already leaning towards a different one). :) I personally find Mako's syntax to be quirky and odd, although of the two other options you mentioned it's conceptually closest to Cheetah. The ability to dynamically (i.e. at runtime) compile any string to a template class, or compile templates ahead-of-time is a good feature for either one. Genshi is overly complex IMHO which results in major speed hits. I kind of wanted to shy away from focusing on things about Cheetah specifically and more on refining a some points that might be applicable to any Python-based project in terms of getting it in front of users and increasing adoption/development.
&gt; Although unlike them it executes your app, it is not your app that imports &gt; the framework. This is, together with the polluted namespace, probably the hugest point of criticism. The justification seems to be to not let errors appear in the surface of the app, and log them in the admin. You don't need to exec all code for that, of course... you can just wrap the app process and catch possible exceptions. Loading and exec'ing all the app code is the job of the server. This is unreasonably weird. &gt; This means you never need to restart the server when you edit your apps. Development servers (from django, pylons, app engine etc) normally reload modules so that you can see the effects of code changes without restarting the server. You don't need to exec all code to have this feature.
&gt; They surprised me by asking me to make a business case, so they must have been thinking about alternatives. FWIW, that doesn't really follow. If someone on my team asked to make such a radical move, I'd certainly want to know the business benefits it would bring and the implications for finances, timescales and the like! &gt; I really do think it would be better. Well, OK, you mentioned that you could come up with a list of technical advantages. Can you explain to us what those are? You mentioned "memory fragmentation errors on 32 bit windows"; is there no way to work around those in Matlab, where Python provides one? &gt; Also, they are trying to move me from the low-level C stuff to Matlab, and I am resisting, and they want to keep me happy. Respectfully, don't count on it. As I said before, having someone who is the only guy in the business doing things differently is a liability: it creates a single point of failure, and the potential damage caused by such a failure grows the longer the situation continues. It may well be that if you're not happy working with the same tools as your colleagues, the correct thing for the business to do is to accept that the two of you are no longer a good match, offer you a good reference, but let you go. And that may be the best thing for you as well.
There is some good stuff in [scipy](http://docs.scipy.org/doc/scipy/reference/), which is included. Probably not as much as in the Matlab toolkits, but more than what we need. Also, it is easy to wrap any old Fortran or C libraries.
If you were clearly pushing self-serving ideas I think silhouette could have a point about red flags. However, I don't think enthusiasm about new solutions or even evangelizing a language you know well should be threatening. Counter intuitively, I think that if you adopted an attitude where you actively kept your head low to avoid any dangerous politics, you would not have fostered the trust that it sounds like you have at your company.
edited for clarity :) 
Guido van Rossum posted on a startling number of scientific projects in which Python plays a major role. "It looks like Python (with extensions like numpy) is becoming a standard tool for many sciences that need to process large amounts of data, from neuroimaging to astronomy." My favorite is the 8-camera, 100 fps tracking of a firefly in real time. http://neopythonic.blogspot.com/2009/11/python-in-scientific-world.html
I had a hard time choosing between Ook! and Python.
I don't know, I just got my copy in the mail since it was a review copy.
Yes, that is the main criticism. The fact is, reloading modules is not a safe thing to do. Executing the code has advantages: we can catch and log every exception; everything is cleanly garbage collected so no memory leaks; we can build a standard context in which apps are executed so that user does not need to import required API like "request"; "response", "redirect"; it allows us to manage bytecode compilation instead of leaving that to Python (that allows us to collapse the rendered template hierarchy in one pyc file per action and cache it for speed). The ability to do exec is the only feature that is truly unique of an interpreted language. I do not think that is weird for us to use it. I think it is weird not to take advantage of it. I grant two things to you: 1) web2py handles differently than every other Python framework (but not because we did not know better, it was a design decision after having evaluated pros and cons) 2) everything has pros and cons. I think people should give Django a try, Pylons a try, and also web2py a try and they can make up their mind. There is no solution fit for all. EDIT: BTW. This thread is about the web2py DAL. That is a normal module. If you do not need the entire framework, you can just use that module as you would use any other python module. There is no exec involved.