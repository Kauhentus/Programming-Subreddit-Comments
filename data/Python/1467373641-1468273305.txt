I am on Community Edition, why sould I pay for professional? [Serious]
But how do I get those 100 clicks per second? That is my question. Thank you for your reply. 
Blynk is easy to use to read sensor data, if you can use a mobile application.
Who needs tab or backspace anyway if we’ve got \^I and \^H?
If you learn by example, for example from checking out Github posts, then I think you will find a lot more python 2 than python 3 applications there. When there is a lot of code, changing all the print statements, Tkinter to tkinter, adding UTF, etc.. gets old fast. It's good to know both.
Plotly's JavaScript library and Python API are open source. If you have a server to run the JavaScript on, I believe you could still use plot.ly without having to deal with their hosting restrictions. 
Could also mean JavaScript/CSS features like syntax highlighting, code completion, etc. Anyway..../u/OvisPresley, most things you're looking for are probably found in PyCharm's professional version. Yes, it's non-free but you're really getting what you pay for. **However**, you have three options to either cut the cost or get it for free: * Get 30% off - https://www.reddit.com/r/Python/comments/4qnfwd/get_pycharm_at_30_off_and_support_django_all/ (currently the #1 thread on /r/Python) * https://www.jetbrains.com/student/ * https://www.jetbrains.com/buy/opensource/
Sure, just takes some getting used to. The good thing is that ctrl is where capslock normally is, and esc is right above it. None of which, of course, are a coincidence.
(I'm the PyCharm Developer Advocate.) Web frameworks, remote, web development, and a couple of other things. https://www.jetbrains.com/pycharm/features/editions_comparison_matrix.html
(I'm the PyCharm Developer Advocate.) This is the right answer. Also, when you google for a question, the answer generally is in PyCharm, and the UI is different for that feature in IntelliJ. So it's easier to follow the help. 
Thanks! I want to give it a try.
With the new model, they can still do that. It has perpetual fallback.
no, originally it was like Adobe CC. They then changed the model because people like us lynched them. https://blog.jetbrains.com/blog/2015/09/04/we-are-listening/
I for one was fine with that pricing model. People think they are entitled to things.
Myst was originally made in Hypercard.
&gt; use their old outdated version for eternity Outdated != not working. &gt; Personally, I think $10/mo for full access to Photoshop is a fucking steal. 120$ per Year. So after 5-6 years you pay more.
Agreed. Lynching was extreme, but It would have priced itself out of my range. I haven't bought sublime either because $70 is a lot for an editor for me. (which is also their right)
Ah, I see - this is not so much commentary about the user experience of using Anaconda &amp; the conda-forge community, as much as it is about the difficulties of navigating the Windows &amp; Visual Studio compiler toolchain. Thanks for the clarification!
I'm glad that works for you. As a consultant, that doesn't work for me. I'm sure I'm not alone. Regardless....paying $600 every 5 years whether through a subscription model, or through flat cost, is not an unacceptable amount in a business environment. Hell, it's not an unacceptable amount in a hobbyist or enthusiast environment. The subscription pricing is just fine, and gives people with less income an opportunity to use the software legally. As someone who doesn't really use Photoshop that much, dropping $600 didn't sit very well. But $10/mo is meh. Three less coffees a month.
Interesting name, [this mobile game](https://play.google.com/store/apps/details?id=com.gameloft.android.ANMP.GloftA8HM&amp;hl=en_GB) came to mind. 
Thanks for the kind words. The subscription, feedback, change cycle happened just as I joined JetBrains. It was neat to see a company still human enough to listen.
They're the same thing, PyCharm is just cheaper and only supports Python. There's no reason to get it if you already have the full IntelliJ.
Yes, but not the only way it is done though. During my apprenticeship (pharmaceutical/chemistry) i was looking for interesting stuff on the network drive during some downtime and i found the company guidelines on rounding. - .5 is rounded up/down - .5 is rounded towards/away from zero - .5 is rounded towards the next even/odd number - .5 is rounded depending on the next smaller decimal (odd/even ; up/down). e.g. .52 could be rounded up and .53 down - just cut off digits for every process one of the ways is standardized. My highlight of the text that came with the explanation of the ways (translated): "At best, measurements are random numbers with an expectancy value that correlates with a measurement parameter"
I still don't like it. I just can't complain that "Ruby syntax is bad cause I don't like this and Python is definitely better".
I see. Seems like culturally dependent thing. Where I'm from, this is not common and I'm not exactly mathematically illiterate. Banker's rounding sounds like a good system to not accumulate errors. I like the concept, I just never heard of it.
no java? :|
&gt; ... I got more that I wanted and for free. :) But are you angry about it? ;)
It's actually much cheaper if you use more than one product. I regularly use PHPStorm, PyCharm, and DataGrip, with occasional use of IntelliJ and RubyMine. So paying for perpetual licenses for all of those every year would be damn expensive, but it's not bad with the subscription. I also got a really nice discount being a previous perpetual license holder. I don't know why people get so bent over things like this. As I say, there are plenty of alternative (much shittier) free IDE's available.
Why would you want to advertise you are a Java dev? Also, look at the subreddit.
At this point there are no specific PyLadies events running. We don't have an active chapter in Columbus. Last year some of the PyLadies attendees from other cities hosted a small get together, but nobody has stepped up yet this year. That may change, so keep an eye on the web site. The only beginner class is the Over the Bumps, which is a 2-hour tutorial.
To build on /u/tdammers advice: As an intern, whenever you receive your answers to the security acceptability of your script, you should ask how they came to those answers and why. Answers to those decision making questions are of far more value to your internship experience than whatever script you wrote.
If you need to interop with a bunch of C++ code that uses Qt, you have to use the idioms that exist in C++ and are accessible in Python. If you don't need to touch the C++ side of things, you can use whatever you are most familiar/comfortable with and it doesn't make a big difference. Sounds like @property solves all the problems that you have, so there's probably no value in trying to find new problems to justify some other solution. :)
Yeah of course you could. In my opinion the jetbrains products are worth the cost. Honestly I pirated them at first and then bought a pro license because of how much it impacted my daily work. They are developers making development easier, and I support that all day
Wow, great job! I'll definitely check this out 
&gt; Can I completely trust ... no matter what follows, the answer is always "no"
If you install lxml you can just render the python plot in your browser with plotly. Otherwise, bokeh or seaborn are decent options. I also believe there is a library called Vincent. There's also matplotlib, doesn't look so nice but it gets the job done. 
PyCharm community edition is great
This 
Works on mobile 
Learn what you want. 3 is better and has more cool shit, but you won't be using it as a beginner, and when you're ready to use it, you won't have any trouble switching gears between 2 and 3.
But you can not use it for any commercial purpose. Even accepting donations for your open sourced code is violating their license agreement! 
Not extensively, but a coworker in another department switched from plotly after trying it out. He said it was way easier to implement!
I mean, I get it. I know why it's this way. I still consider it a weird little wart in the syntax, though.
It's not less unsecure than when you wrote it. In fact, with the optional built in encryption, it's probably more secure than most compiled programs. Working with some colleagues at another company, we caught a major company in a flat out lie about their software supporting 64-bit output. They sent a compiled executable to read some data, which they claimed proved it supported 64-bit. It was 32-bit. We then decomplied it and saw that it really was 32-bit as expected. Then again, you're making your code for your coworkers. Why do you care about internal security that much? Put a proprietary stamp on it and be done.
Thank you :)
Did some p2p for school. Definitely checking this out, thanks!
Thank you !
No problem! After all, what's the point of a library if it's less usable? 
No problem! If you want, I'd appreciate see feedback/review. 
I think that's a little harsh. Knowing which functions are used most and least could guide future development.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I am the author, can you specify what are you missing? Personally, I found a few useful functions I wasn't aware of. Also it would be very interesting to use this in sorting code completion.
Good job man. It takes a good coder to write good code, but it takes a great coder to get shit on when you show your work and actually get back to it and address all the issues people brought up.
True. And unfortunately, since I'm trying to support python 2.6, I can't use SSL in the best possible way. I'm thinking about dropping that for 2.7+, but I don't know the actual implications of using default settings vs a context. 
I'm not going to pretend to know how hard the grading task is. So I'll just ask. Could you require that the source passes some lint tests? What about complexity metrics tied to a share of the grade? These can be automated. Require all submissions to cleanly pass pycodestyle with default settings. - https://github.com/PyCQA/pycodestyle - https://github.com/PyCQA/mccabe I should clarify. The idea behind these requirements is that then you may write other scripts to detect things like monkey patching.
Do you have a good reason for keeping support with 2.6? The only reason I can see for people still supporting 2.6 is because of CENTOS 6, which is not a great reason anymore. 2.6 is 8 years old now. Personally, I wouldn't bother unless I had a very good reason. The latest long-term support Ubuntu release doesn't even install 2.x by default. People are finally migrating to 3.x now. If 2.6 is keeping you from using SSL well, I would highly consider ditching it unless you had some very strong requirement for 2.6 compatibility. More people are going to be annoyed if it's not compatible with 3.x than 2.6, for sure.
Doesn't handle modules. Scipy.stats, scipy.io, etc are not functions
Alternatives for this are: - Just use postgres with pytest-django's --reuse-db flag (and --nomigrations) - Use the pretend module instead of mock - Use factory-boy for creating objects (and use factory_cls.build() where possible) Forgot to say: please don't use sqlite to run tests against if you deploy against postgresql or something else. You are not correctly testing your codebase that way (sqlite is not as strict as other db's)
Thanks, I'll take a look. I was primarily looking at pandas when writing queries and it wasn't affected as much. 
Oh yeah, jetbrains are going to steal your hello world.
Yeah. That's going to be coming next release. I would have done it for this one, but I'm skipping out of town for a while, and I wanted to get this out before that. I'm not terribly great at writing these things though (as I'm sure you noticed), so I'll probably need to come back for feedback. 
When I first learned python, i just skimmed the docs and picked up the basic syntax. Going over some books to learn the whys of the language 
This is sound advice.
[OpenCV](http://opencv.org/)
To add to this, SDL2 can be accessed in Python through the [PySDL2](https://pypi.python.org/pypi/PySDL2) library. So /u/iwhitt567, I would skip pygame due to its poor performance and it being somewhat outdated, but Python with other libraries might still work. Still, I would probably try [Godot](https://godotengine.org/) first.
Is there already a postgres FDW that connects to Wikipedia? :D
OpenCV is the answer, but even with that, I'm not sure I would call it simple or easy. This is highly relevant: http://xkcd.com/1425/
[Image](http://imgs.xkcd.com/comics/tasks.png) [Mobile](https://m.xkcd.com/1425/) **Title:** Tasks **Title-text:** In the 60s, Marvin Minsky assigned a couple of undergrads to spend the summer programming a computer to use a camera to identify objects in a scene\. He figured they'd have the problem solved by the end of the summer\. Half a century later, we're still working on it\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/1425#Explanation) **Stats:** This comic has been referenced 775 times, representing 0.6641% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d4wj1lx)
About half the time. 
Yeah, when I looked it seemed like nginx had the capability to buffer chunked requests and present them as a simple content-length and body, but apache doesn't. Some apache *modules* do, but mod_wsgi isn't one of them. It has an option to allow chunked requests and do no special handling, making the next layer up the stack have to deal with it and accept that it doesn't know the length of the request (technically breaking the WSGI spec), but I wasn't able to find anything that did anything useful with that option
There's commercially released steam games using Python. [This one for example](http://store.steampowered.com/app/312970/). I remember him doing a [Pycon talk](https://us.pycon.org/2014/schedule/presentation/159/) on the non-programming side of game dev such as distribution. As far as I am aware, he's also open sourced the code for the engine. 
i have no idea
Great!
Agreed. Simple would be an object that never changes size or "brightness" against a uniform background and looks the same in every frame. As you add clutter, brightness variations, even camera noise, and object scale and other degrees of freedom. The level of difficulty will increase.
Get this blogspam outta here!
/u/ldelossa, please listen to this guy. Please please, _please_ do not write this yourself if it's going to be for anything besides a learning experience (and even then, writing it yourself does not make you an expert or secure enough in the face of an attacker). Rolling this yourself is not safe and it's very easy to miss something crucial in the implementation that will lead to a vulnerability. For example to name a few: * Does the network this is deployed on to MITM SSL decryption? * How are you protecting the files on disk? * What do the applications do if your microservice is down? * How do you handle revocation? * Do you audit access? * How do you make sure the application can only access secrets for itself and no other application? * How do you verify that the application making the request is actually the real application without sharing private information? Any one of the above can be potential areas where whatever scheme you've designed is a security risk and not a security enhancement. Now one thing I will suggest is to go out and research KMSs, Key Management Services and pick one that suits your needs. https://www.vaultproject.io/ for example would be a good place to start looking. Cloud service providers like AWS also have their own solutions usually too.
[Image](http://imgs.xkcd.com/comics/standards.png) [Mobile](https://m.xkcd.com/927/) **Title:** Standards **Title-text:** Fortunately, the charging one has been solved now that we've all standardized on mini\-USB\. Or is it micro\-USB? Shit\. [Comic Explanation](https://www.explainxkcd.com/wiki/index.php/927#Explanation) **Stats:** This comic has been referenced 3135 times, representing 2.6858% of referenced xkcds. --- ^[xkcd.com](https://www.xkcd.com) ^| ^[xkcd sub](https://www.reddit.com/r/xkcd/) ^| ^[Problems/Bugs?](https://www.reddit.com/r/xkcd_transcriber/) ^| ^[Statistics](http://xkcdref.info/statistics/) ^| ^[Stop Replying](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=ignore%20me&amp;message=ignore%20me) ^| ^[Delete](https://reddit.com/message/compose/?to=xkcd_transcriber&amp;subject=delete&amp;message=delete%20t1_d4wnf8u)
Interesting! It seems very easy to use, but I wouldn't say it's minimalistic. It looks like it has every feature one might need IMO.
I quit at the first question. AFAIK python uses reference counting AND mark and sweep. There was no AND answer, so I don't trust the test.
Writing C# without Visual Studio, (or MonoDevelop if you're unlucky), is like sucking farts out of someone's ass to find out what they had for dinner the night before. Sure it might work, but it's slower, difficult, creepy, and you could just ask them.
You didn't answer my question though. 
Why not just len([c for c in input_string if c.lower() in 'aeiou'])
I broke it apart so that it was easier to read. I would probably do it your way in code that I wrote.
I would definitely recommend the JavaScript library Highcharts, [demos](http://www.highcharts.com/demo). Here's an [edited](http://jsfiddle.net/dcswLptc/) version of their example (all I did was change the chart type from a simple line to a scatter plot).
&gt; I got tired of learning (and forgetting and relearning) a new argument-parsing library every time I switched languages the [docopt](http://docopt.org/) command line parser works in multiple languages and has the advantage of fitting well with the --help option you would have to create anyway. It's good to have some choice though.
Ya wtf a tuple can be appended to and fully overwritten, but existing elements cannot be modified without overwriting the whole thing 
The time limit is damned short when one oft he questions have bloody essays as alternatives. 
I use pyinstaller to make my scripts into .exe files for my friends and colleagues. http://pythoncentral.io/pyinstaller-package-python-applications-windows-mac-linux/ this is the exact tutorial I followed to make it happen. I've found this to be the best solution so far
Python itself doesn't specify how GC is done, but the reference implementation does indeed combine those 2 approaches. If you're using a different interpreter like pypy or something, the GC may well differ.
docopt is great, except you need gcc 4.9 or newer for c++. 
It opens fine for me when I block it from connecting to the Internet. 
It probably looks complex because it's an inherently complex problem! I'm not familiar with matplotlib, but the two successful approaches I've seen are: 1. Extract the non-GUI portion into a reusable library, and then write separate (but similar) applications that all happen to use this same core library. Transmission does something like this, for example. 2. Define your own GUI library, and write the application against that, and then implement this GUI library on each GUI toolkit you want to target. Firefox does something like this, for example. I personally think that #1 is less work, and gives better results. But if you're going to be needing a lot of custom controls and supporting a lot of different platforms, #2 can have advantages. If you're looking for a simple way to keep the overall structure of a PyGTK program, and then just set a flag at build-time and get a PyQt4 program, I think you're going to be disappointed. GUI toolkits don't tend to be that similar in structure. You can't just do a find/replace to port from one to another.
4.8 when I find the time to update my PR replacing std::regex with Boost.regex !
That's really disingenuous with respect to the docopt example. Give me a break. If you can't decipher the docopt example *even without knowing anything about docopt* I wouldn't trust you to write a CLI library.
I'd pick the Java-based one. Better performance, more mainstream (= better support?), and there's some great JVM-based languages these days so you don't actually have to use Java. 
You are a god sir. Thank you
Yes, please. A boost dependency is less than ideal, but better than no support for 4.8 at all. 
Huh? I don't want your real world example; sure, it's nice to have, but I'm looking for something to quickly compare how your tool would fit into my work flow. The "naval" example is pretty much the "Hello, world!" of CLI libraries. It has all the features of a medium-complexity interface: sub-commands, common and differentiated options and arguments, etc. I know how to implement it in half a dozen different Python or other libraries - partially because they all provide examples. What I want to know is how do I implement it with **your** toolkit. Because that's how I'll figure out if I want to keep an eye on your library and consider adopting it in the future.
This is so much help! Thanks so much I need a little time to review and attempt a few things. I will post back! Also someone posted vault by hashi Corp, which may accomplish some what of what I need 
Use flask and host a site. Password protect it if you don't want others to view it 
Great, no problem!
Sounds like you have to make it app-specific, unless you tee output and try to match on `(\d+(?:\.\d+)%)`
I'm guessing he is probably concerned about memory corruption vulnerabilities as that is typically the problem with binaries vs scripts. 
To add another suggestion: spyder.
Yeah, we rounded up to 100%.
I'm not exactly sure what you mean by your formatting or your question... But there's no ambiguity here. You're updating the slice 2...4, which modifies the original list. It also means that since your updating a list, your iterable value is unpacked into the list. 
It's not ambiguous. You just don't know what's *actually* happening. When you write list3[3] = [3] What you're *really* doing is calling list3.__setitem__(3, [3]) It sets the item at index 3 to the object passed in as the second parameter. A list is just an object, so [3] is just an object, like any other. However, when you call this: list[2:3]=[1,2,3] What you're *really* doing is this: list.__setitem__(slice(2,3,None), [1,2,3] The list class' implementation of \_\_setitem\_\_ checks to see if the first argument is a slice. If it is, then the second argument must be an iterable (it checks), and it expands the contents of that iterable into its own, at the location specified by the slice.
Okay I downgraded to setuptools 19.2, and ran with the -d flag and commented out those lines, but where should I be setting `debug=True`? I put it in the spec file but it didn't seem to change anything. There is a warning log in the build folder though that shows a SHITLOAD of missing dependencies, I put it on [pastebin](http://pastebin.com/DVtHhbKz), definitely seems like that's an issue. Thanks for your time!
Click is super easy to use. Maybe there's just something wrong with you. 
Looks interesting. Ruby support?
Ok thanks for the info :)
{\**major flashback to coding my 90's Maximus BBS*\*} #AAAAAAAAAAAAGGGGHHH!!!!1one
Why not just dump the gtk part? 
You want /r/learnpython
Very cool. However &gt; it's possible to write programs that make use of ANSI escape codes, and at least will work on common Unix systems like Ubuntu or OS-X (**though not Windows, which I won't cover here and is its own adventure!**). :'( Can someone point me in the right direction for how to do this on the windows 7 console? Is it even possible?
For those that don't want to use unicode escapes and have something work with python2/3 just use standard octal codes: print("\033[30m A \033[31m B \033[32m C \033[33m D \033[0m")
We honestly don't need a standard one. It's not a crazy problem that is hurt by splintering of implementations, like argparse optparse docopt click, hell even one I wrote, argvee. They're all pretty thorough and there's different reasons to use each. They don't all necessarily solve the same problem. argparse has really thorough logic for really common unix interfaces, even more complex ones. It's actually very succinct and flexible, but it forces you to write a unix like command line interface - which of course is usually a good thing. docopt is a common api that works across different programming languages, and it's really easy to read. I'm sorry though, in typed C/C++/Rust it can be a pain in the ass to implement. If you just want two arguments input file output file, I'm going to check argv and be done with it. Sometimes it's even pretty heavy compared to what your program does and increases the footprint of your program. It's great, it's a common api, it's self-documenting by nature, but this isn't always necessary. And honestly, the cross-language thing isn't that helpful. It's not like I copy and paste a python script docopt and reimplement in C++. And there's still a ton to add from python to C++. It's just easier to remember the start, but there's also tons of boilerplate to add in C/C++/Rust. click is great, and attacks the problem in a completely different way. It uses decorators and lets you associate functions with commands. This should definitely exist in addition to docopt and argparse. It solves somewhat a similar problem in a way that is more useful for certain programs. I'm not going to only want one of docopt or click. click might be more succinct for a specific script. And then there's my unpopular little library: http://pythonhosted.org/argvee/ That solves the problem in a way similar to click, but I tried to make it much more succinct. By nature of declaring positional arguments and keyword arguments, you're defining an interface to that function. I don't see why you can't just wrap that function in `@app.cmd` and have the command-line parser library just infer what arguments you're going to want. You set a keyword `debug=False`, why the hell not just see that and automatically add `-d/--debug action='store_true'`? It might not be a popular library but I tried to solve it in a way that just infers what arguments should be created so you don't have to type anything out except the function. I think it's completely valid to have tons of different libraries, as long as each solves the problem in a unique way and well. But yeah, clio doesn't seem to solve it in a unique way that we really need right now.
https://pypi.python.org/pypi/colorama
Great tutorial! Thank you
https://stackoverflow.com/questions/16755142/how-to-make-win32-console-recognize-ansi-vt100-escape-sequences and you may want to upgrade - http://www.nivot.org/blog/post/2016/02/04/Windows-10-TH2-(v1511)-Console-Host-Enhancements but that article also makes good points about ConEmu.
# Abusing ANSI escape codes for fun and profit ~$ cat test.sh #!/bin/bash echo "Hidden code would run if you execute this." ~$ ./test.sh This could have been bad! ~$ hexdump -C test.sh 00000000 23 21 2f 62 69 6e 2f 62 61 73 68 0a 65 63 68 6f |#!/bin/bash.echo| 00000010 20 22 54 68 69 73 20 63 6f 75 6c 64 20 68 61 76 | "This could hav| 00000020 65 20 62 65 65 6e 20 62 61 64 21 22 20 23 1b 5b |e been bad!" #.[| 00000030 39 39 44 65 63 68 6f 20 22 48 69 64 64 65 6e 20 |99Decho "Hidden | 00000040 63 6f 64 65 20 77 6f 75 6c 64 20 72 75 6e 20 69 |code would run i| 00000050 66 20 79 6f 75 20 65 78 65 63 75 74 65 20 74 68 |f you execute th| 00000060 69 73 2e 22 0a |is.".| 00000065
&gt; The way that most programs interact with the Unix terminal is through ANSI escape codes. No. Because not every terminal connected to a UNIX server is the same.
When you can remember the 1990s you should know that every terminal had other codes and capabilities. You won't to much with "ANSI escape codes" on a VT52. 
*Not an expert.* Try to create a tool/site/bot that is usefull to you. I started out on python by creating apps for GAE. First the guest book example. Then an http torrent tracker redirector. You should try Heroku though. If you're only starting out try to do some exercises from the sites you find here: https://gist.github.com/medecau/790976 Try to get paid by writing scripts for others to use. This is where I learned the most. Really learned about Regular Expressions. Wrote a few scripts for file conversion and web scraping. PDFs, log files, CSVs with weird encodings and varying number of collumns. Learned about writing code for different environments. Windows vs linux or Mac. py2 vs py3. And even py2.7 vs py2.6. Writing scripts that are really CLI tools for users that cannot edit the code. I've teached too. It's awesome. When writing your own modules try to mimic the libs with the best APIs - see requests and tortilla modules for examples. Visit the standard lib module list, pick an interesting module and try it out. Helps you keep up with the language and learn about what's available. Definitely check out [built in functions](https://docs.python.org/3.5/library/functions.html), [data structures](https://docs.python.org/3.5/tutorial/datastructures.html)(https://docs.python.org/3.5/tutorial/datastructures.html), and [wrangling text] (https://docs.python.org/3.5/library/stdtypes.html#text-sequence-type-str). Also [collections](https://docs.python.org/3.5/library/collections.html) and [itertools](https://docs.python.org/3.5/library/itertools.html). Just realised I need to spend sometime there. Search for awesome python on google, pick an interesting module and try it out. 
Yep
The curses library is meant for this. * [Library](https://docs.python.org/3/library/curses.html) * [Curses Programming with Python](https://docs.python.org/3/howto/curses.html#curses-howto) * [Example program](https://hg.python.org/cpython/file/3.5/Tools/demo/life.py) 
You could make this clearer by changing it to `if self.right is not None:`
[removed]
Short answer: Spend 10,000 hours writing Python. That's about 5 years working full time.
Where did you find people to pay you. How much did they pay 
Have you talked to patients/doctors about this? Is the hardware on the person it is measuring?
How is this different from other services already in the market?
Actually you can't. That would have a different outcome since `False` is not `None`, but the code shouldn't be executed if `self.right` is `False`. Consider the following: Python 3.5.1 (default, Mar 3 2016, 09:29:07) [GCC 5.3.0] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; a = True &gt;&gt;&gt; b = False &gt;&gt;&gt; c = None &gt;&gt;&gt; d = 0 &gt;&gt;&gt; if a: ... print('a is truthy') ... a is truthy &gt;&gt;&gt; if b: ... print('b is truthy') ... &gt;&gt;&gt; if c: ... print('c is truthy') ... &gt;&gt;&gt; if d: ... print('d is truthy') ... &gt;&gt;&gt; if a is not None: ... print('a is not None') ... a is not None &gt;&gt;&gt; if b is not None: ... print('b is not None') ... b is not None &gt;&gt;&gt; if c is not None: ... print('c is not None') ... &gt;&gt;&gt; if d is not None: ... print('d is not None') ... d is not None As you can see, both `b` and `d` are not `None`, but are also not truthy.
Hey cool. That was a fun read about named tuple. Mmm syntax sugar *and* performance? I'm definitely going to try and use it everywhere for a while...
And it inherits from tuple so it has the same behavior &gt;&gt;&gt; from collections import namedtuple &gt;&gt;&gt; PointCls = namedtuple("PointCls", "x,y") &gt;&gt;&gt; my_point = PointCls(5,34) &gt;&gt;&gt; my_point[0] == 5 True &gt;&gt;&gt; my_point.x == 5 True &gt;&gt;&gt; my_point[1] == my_point.y True
Been there. The only solution I found is to pkill all the browser processes. When you do close/quit, sometimes some "phantom" browser processes stay there chilling. After some scraping, I do a "os.system('pkill firefox')" and it works neat-o. Have fun! PS: would you mind explaining what you're doing? I'm curious :)
It depends on everything
lol. go away
Why not just dump the PyQt4 part?
The expression Python is slow, has to be made with a condition. In general I don't like such blogs with such a generalization. There is on youtube a lecture from a guy who accelerated a Python code 114000 times and in the end the IO memory speed was bottleneck. Python is slow, when someone is direct comparing a Fortran or C code with plain written Python code. But this is a problem for very small group of users. Python is slow when used as a base for games. But one of the largest single shared online games was written in Python (eve-online). For most projects project management and maintenance is more important than pure raw number crunching power. The focus on number crunching is just wrong. Instead of giving starters of programming wrong ideas, they should learn how to develop a descent mindset how to use the right tool for a problem. 
I like this write up. It connects a lot of dots between c, Python, numpy, and performance. Everyone always *says* that you can speed up Python with numpy, but never explains *why*. This article handles the *why* fairly well.
&gt; But one of the largest single shared online games was written in Python (eve-online). Wow, I didn't know that. I was curious so I googled it and apparently they used a different Python interpreter called Stackless. I read the wiki and it seems like it optimizes thread use (or something, I'm dumb). If it's more optimized than the regular interpreter why doesn't everybody use it?
It's not necessary though - the ANSI escape code isn't Unicode. It's, well, ANSI: \033 is suffice. 
My understanding is that Stackless Python is most similar to the greenlet module of today. I was about to put a lot more detail into this post until I realized that it was mostly speculation mixed with what I remember reading a long time ago. I hope someone adds some clarification.
&gt; you can launch a bunch of new instances quickly, but it takes too long for them to be ready to serve. Was dealing with this on my current project. Super heavyweight "enterprise" Java application. My team has worked on containerizing it, but even with containers that launch in seconds you're still waiting several minutes before its ready to serve traffic.
 clc; clear all; meu=0.0121504;h=0.0001;i=0; for tau=0:h:25 i=i+1; if (tau==0) x(i)=0;y(i)=-0.4487;xp(i)=1.0402;yp(i)=0.6079; else % calculating x and y f=y(i-1)-2*xp(i-1)-(((1-meu)*y(i-1))/((x(i-1)+meu)^2+y(i-1)^2)^1.5)-((meu*y(i-1))/((x(i-1)-1+meu)^2+y(i-1)^2)^1.5); g=2*yp(i-1)+x(i-1)-(((1-meu)*(x(i-1)+meu))/((x(i-1)+meu)^2+y(i-1)^2)^1.5)-((meu*(x(i-1)-1+meu))/((x(i-1)-1+meu)^2+y(i-1)^2)^1.5); x1(i)=x(i-1)+h*xp(i-1); y1(i)=y(i-1)+h*yp(i-1); xp1(i)=xp(i-1)+h*g; yp1(i)=yp(i-1)+h*f; fp=y1(i)-2*xp1(i)-(((1-meu)*y1(i))/((x1(i)+meu)^2+y1(i)^2)^1.5)-(meu*y1(i))/(((x1(i)-1+meu)^2+y1(i)^2)^1.5); gp=2*yp1(i)+x1(i)-((1-meu)*(x1(i)+meu)/((x1(i)+meu)^2+y1(i)^2)^1.5)-((meu*(x1(i)-1+meu))/((x1(i)-1+meu)^2+y1(i)^2)^1.5); y(i)=y(i-1)+(h/2)*(yp(i-1)+yp1(i)); x(i)=x(i-1)+(h/2)*(xp(i-1)+xp1(i)); yp(i)=yp(i-1)+(h/2)*(f+fp); xp(i)=xp(i-1)+(h/2)*(g+gp); end end plot(x,y) 
And pandas has a read HTML function. 
Let me guess, you tried to `sudo pip install libxml2` or something. Never ever do that ever. If it's in the repos, use your package manager to install it. If it's not (or is too old), use `virtualenv` and install it into your virtual environment. If you think a solution to your problem starts with `sudo pip`, stop - you're actually creating an even bigger problem.
how would you do it with pandas? Would it be a combination of pandas and beautiful soup?
Lol. PEBKAC error. You should never sudo pip install
"Makes me love Windows and Visual Studio all the more." My condolences
Yes. On my Debian server. For my Ubuntu desktop I used virtualenv. But setup the environment with pyhton2.7 as the default. So now I need to figure our virtualenv to understand the situation. I'm a windows developer for 25 years. Dll hell was never this bad (or perhaps it's the frustration talking). 
Ignore all the dependency errors for things you don't need (e.g. distutils) or things that are obviously not an issue (e.g. builtins like os). The other ones, you should add to the top of your main program (spacegame.py). These three in particular `numpy`, `pygame.Rect` and `pygame.rect.Rect` should be imported. Get it working and then remove extra junk. The `hiddenimports` thing is supposed to make that work in a way that doesn't clutter your main program, but it's not as easy to use or robust. Not 100% on how the debug options work. I just turn them all on. Set `debug=True` in your EXE from your spec file. 
It is frustration talking. If I may, I suggest you look at the [Anaconda](https://www.continuum.io/downloads) Python distribution. It doesn't overwrite your system version of Python, and it has virtual environments etc., and it comes with a whole bunch of stuff pre-installed (if you so wish, that is). Once I started using it, my life became a whole lot simpler. As for virtual environments, initially I was also super confused about them. But they're really damn simple - They just replace one folder with another in your $PATH and/or $PYTHONPATH. Meaning, if you have 2 virtual environments, one called `default` and the other called `mahogany`, running `source activate mahogany` will remove `default` from your $PATH and put in `mahogany`. Basically this makes sure different versions of Python and other packages can all coexist in harmony. Like world peace on your computer.
You are missing fundamental knowledge on how to use Linux for Python development. Sadly, if you are expecting some crutch like VS, you won't find it. 
&gt; Dll hell was never this bad (or perhaps it's the frustration talking). It's the frustration talking. You created linux version of dll hell by spewing random libraries all over your filesystem and breaking the system install. Small consolation but at least you needed to be root do do it.
Exactly. Look at projects like [MyPaint](https://github.com/mypaint/mypaint). The project is mostly in python, except the part that renders brush strokes, as that needed a higher performance and was written in C. It's like some people don't understand they can use more than one programming language in a program.
Why do you want to use Linux when you're more comfortable with Windows?
&gt; I simply do not have time to deal with Linux+Python. Then don't. &gt; What am I missing? No idea, I've never heard the complaint you had. Python comes preinstalled on almost all Linux distributions. Beyond that, you should probably be using pip
I don't like the look of those errors.
Upwork, previously known as Odesk. I bet there are other avenues. I'd love to lose the dependency on their platform.
nope, 2.7.9. http://stackless.readthedocs.io/en/latest/stackless-python.html It is still actively maintained.
I always wonder how these statements stack up when using Numba or the intel python interpreters. Anybody have any insight on whether 'python is slow' still bears out there?
You have two small problems that are annoying. DLL hell wasn't solved for what? 20 years? Yea, frustration talking :P
Can you recommend a Spring alternative for REST APIs &amp; OAauth2 Server that loads instantly and which can embed a server so one can just run a .jar file to start it?
At work I only do Spring, and personally I don't really do any Java (pretty much 100% python). That said, I have heard good things about Spark (not the big data related apache spark, bad naming), Play, and Grizzly. I haven't had to package them up, but most of the newer ones provide some way to do über jars since it's almost a necessity these days to compete with Spring boot. As far as oauth2, not sure if you are looking for a provider or resource server - but in either case I am not aware of one that just "comes out of the box" like Spring's... Consumers of oauth2 are simple enough to implement though.
Take a look at [Spark](http://sparkjava.com/documentation.html) with [Pac4J](https://github.com/pac4j/pac4j). I've only done some quick prototyping with the combination, but it would be easy to build an executable jar with these two. Spark is a great lightweight tool to use for a rest api. Startup isn't instant, but takes a couple seconds for me. I can't believe that Spring continues to be recommended/used with the frequency it is. It's a big bloated mess, and building a framework (Boot) on top of a bloated mess is not really a solution in my mind. Admittedly, I probably don't work in the types of industries/products that Spring would make sense in, so take my opinion with a grain of salt.
Pandas only has like 20 functions. And it has such limited functionality knowing which ones are most popular really doesn't have much value as a way to evaluate the module.
Noob here: install Anaconda, works better. All you need to do is, conda install libxml2
That's why they came out with the VT100. :)
Are you threading the functions so they run in parallel? The IRC part may be blocking. 
Multiprocessing will spawn a separate process with its own memory and to return values to the origin process you have to use a queue which spawns its own process. This can be a memory hassle of you create a lot of processes. You may just want to just use threading for async functions. It's much simpler cuz threads share the same memory allowing variables in one thread to be accessed by another thread. 
Flask + Flask-SocketIO. 
I probably wouldn't call myself an expert, but I just wrote a lot of python :P Pick some projects to implement, read the docs for the surrounding areas of python. Also research 3rd party libraries (for example, use Requests rather than python's built in http clients).
To whoever overwrote a bunch of proper styling based on made up style guides, thanks for wasting the time of those who are trying to help beginners not make styling mistakes.
Correct, it lets you write I/O code that feel threaded but is actually using one OS thread.
 Ooo... So it doesn't just make things faster you have to actually write additional or different code? I was thinking I could just download it and my scripts would run better.
AFAIK, the Intel distribution just adds optimised libraries; it doesn't fundamentally change the core language.
Correct. 
That's hilarious. Just today I was using that tutorial, going through the process. I have to say that everything written has been correct and worked for me thus far! Big thanks to whoever wrote that.
Another thing I forgot to ask about is if anyone knows of any good resources for best practices in Python. At what stage do you start worrying about the GUI? Would you start the GUI before working on the functionality? 
If the GUI is the primary way the user will interact with the app, then I would design (not necessarily implement) the GUI first. Kind of a "start with the end in mind" approach. 
You might want to have a more comprehensive README.md. I had to go to the link to find out what you are doing, would be much better to include a description of what you do, how it works, and a README.md file on your Github repo.
Gotcha thanks!
bottle.py + gevent
Keep things simple by using the supply TK suite. 
 &gt;It's like some people don't understand they can use more than one programming language in a program. Or they do understand, and they wonder why you would bother. Why not just write everything in the faster, more processor and memory efficient language? That's what you have to answer to those people. They don't care that you can write a program in more than one language. They want to know why you would put up with a slow language. (and there *are* good answers, for sure.)
You can see huge speed ups just by running a program with pypy instead of cpython. I've seen more than 2x speed improvements before, but usually it helps a lot with long running scripts that have repetitive slow code that is looped over a lot. Speedups are thanks to JIT compilation.
Try downloading Pypy and running your scripts with it. It almost always just works, and with long running scripts you can see huge performance improvements. I've seen more than 2x speed with it.
CPython is slow. Python is just a language. There's nothing about Python that forces you to use one core. It's unfortunate that the reference implementation is slow, but maybe one day we'll see a GIL-less high-performance python implementation. Personally, I have used pypy quite a few times to improve performance where it actually mattered, and the increase was impressive, sometimes more than twice as fast. Whether it's used often or not, it has worked completely fine in my experience, and it was as simple as either using a virtualenv or just invoking it directly with pypy.
By TK you mean TKinter?
I looked up general information on qt5 and they have changed a lot of stuff so that qt4 doesn't translate directly into qt5.
no problem! Yeah, one thing you might do as well is [run cprofile](https://julien.danjou.info/blog/2015/guide-to-python-profiling-cprofile-concrete-case-carbonara) if you haven't. It's found spots in slow code that I had no idea were an issue, like csv dictwriter double checking that every key exists before writing a row, definitely the kind of thing to check for, pypy or not.
What? I updated 2 virtual machines: Linux and Windows. Windows was basically automatic. I was banging out python and C# code in no time. That was not the case with Linux. What's the 99% that's easier on Linux? 
I like the idea that Python is optimized for developer time not run time. Sometimes raw performance will be more important but nowadays, computers are fast enough that for a majority of tasks it's more important that the programmer be able to spend less time writing the code. Hell, even Matlab is like this. I hate using Matlab but it's great at doing what it's aimed at doing: letting engineers and scientists who don't really know programming do numeric computations. (Although it does let you overwrite the imaginary unit without so much as a warning, which seems counterproductive for the audience it's aimed at.) 
Okay, but isn't because of the GIL, effectively only one thread runs at a time in python? Also, I have found that if it is IO-intensive, we should threads and when it is CPU-intensive, we should use processes. Isn't it like this? 
For my Ubuntu development machine I just did that. Unfortunately, following the apt-get instructions for my Debian server means I must reload the OS. Too much corruption to even purge and reinstall python 3 and tools. I appreciate you and a couple others pointing me in that direction.
Thanks this worked great for my Ubuntu development machine!
Except that the semantics of the problem *probably* mean that the `left` and `right` attributes will either be references to other nodes or `None`, so in this particular case `if self.right is not None` might be both equivalent and more maintainable (as it makes the design intent clearer). So while you are right in a literal sense about the general semantics of that one logical test, you may be missing the forest for the trees (pun intended).
Check the selenium changelog to make sure your version of selenium is compatible with the version of Firefox you have installed. A selenium release typically is only tested to work with a few versions of Firefox active around its release. It is very finicky. 
Unfortunately Pypy breaks linking to C libraries doesn't it?
Is the code open, and if so could you post it? I'm working on a flask project and I would love to see how you're searching and displaying results.
Haven't had to myself, but [it should be fine](http://doc.pypy.org/en/latest/extending.html). But I have heard issues regarding C, but that's due to lots of C code that is meant to interface with CPython using the CPython C API: http://pypy.org/compat.html C code that includes "Python.h" is probably written with the CPython API. From that last link it looks like they're trying to implement the same API but it's alpha/beta. It makes sense though that C code that is written for CPython won't work. Still, you should be able to use ctypes and import functions from shared libraries all the same. It's not that it can't call C code, but it probably won't work with C libraries that are built using the CPython API specifically.
last time I tried this was july last year: it's poorly supported by new frontend frameworks, outdated protocol, and only python2.
Both Flask and Flask-SocketIO now support Python 3. Flask-SocketIO had a [major version increase recently](https://flask-socketio.readthedocs.io/en/latest/#differences-with-flask-socketio-versions-0-x) that may address your previous issues. [`flask.jsonify`](http://flask.pocoo.org/docs/0.11/api/#flask.json.jsonify) can be used to easily return JSON to a calling front-end library or [`flask-restful`](http://flask-restful-cn.readthedocs.io/en/0.3.5/) if something more structure is desired.
I was thinking specifically numpy and scipy, the former of which is kind a support in pypy but not really. The later appears to still be completely non functional in pypy.
*Not an expert* But I've [written about my techniques for improving my coding skills](http://www.pydanny.com/code-code-code.html).
Where'd you get that code from? It's missing a call to `app.exec_()` at the end. edit: I'll expand a bit. The QWidget `show()` method just tells the widget that it should be visible and returns. So your program was running through each line of code and just exiting after executing the last line. With an old computer, you might've seen the window flash up on the screen briefly. QApplication's `exec_()` is a blocking method that runs the main event loop. It is what keeps the program alive until you close the window. The main thing I've learned about PyQt is that most of the time, the [plain Qt docs](https://doc.qt.io/) are sufficient (and they're quite good). In fact, the PyQt class reference docs just link to the C++ docs. For differences, such as signals and slots, you can refer to the PyQt documentation specifically. Once that clicked for me, I was no longer dealing with poorly-written tutorial code and was able to reason about how I should implement things.
Actually I'm new to reddit. My friend told me to share the knowledge. Its my first link shared it reddit.
Thank you, do you have all of the c&amp;h comic transcripts downloaded? btw site is awesome, and suprisingly fast
Yes, they are threaded
Put `display: block` on the &lt;a&gt; tag. If you temporarily put `background-color: red` on the &lt;a&gt; and toggle display: block on and off, you'll see how the "hit target" changes.
Realistically, that first year is going to give you the first 4000 hours when you're inevitably abused by a supervisor that tricks you into thinking 80 hours a week is standard.
https://github.com/andrewgodwin/channels
In Python, assignment and mutation are very different things. Assignment works on *variables* (names that refer to objects), while mutation works on *objects* (the things that variables refer to). Here the variables are temporary (a parameter becomes a new local variable each time the function is called), but the object is permanent (the default argument is the same object each time, the one specified when the function was defined). When you write `to = []`, you are making the temporary local variable refer to a new object. The variable is changed, but the object `None` that it used to refer to is unaffected. On the other hand, `to.append(element)` mutates the object itself (the list created by `[]` in the function definition). Since there is just one copy of the default argument object, future function calls that use the default will have new local variables that refer to that same, now-modified, object. (Subscript assignment complicates things: an assignment like `x[0] = 1` *is* a mutation to the list object that `x` refers to, but is *not* a mutation to the object that `x[0]` used to refer to.) **Edit**: also, /r/learnpython
I do, haven't uploaded it, for my bandwidth sucks. Will do when I am on a better connection. It is fast because the images are in dropbox and most of the work is done client side except the search. The app is pretty lightweight.
Agreed, but it's not that hard to convert the code. PyQt5 is more pythonic, because they got rid of the need to manually jump between Python objects and Qt objects. Now they're converted on the fly. When coupled with Python 3 it's even better due to greatly improved Unicode support.
short answer: architecture matters 1000x more. and is more likely your actual bottleneck algorithms matter 100x more time to market matters much more getting revenue from customers matters much more
Make sure that you have the updated version. Use sudo pip install --upgrade socli to update to the latest version 
If you use it for work only, and use it on desktop computers, I would do it simple - using `tkinter`. It will be the easiest path. If you are not selling and it makes you job easier, make it as simple as possible.
Yeah, I was wondering why you'd link directly to a stream, which will be completely after the relevant stream is over.
The "500 Lines or Less" book doesn't seem to be available yet, but there is a good rundown of each chapter on the The Architecture of Open Source Applications (AOSA) [Blog](http://aosabook.org/blog/). Some great content in there!
&gt; But... it actually proves that Python is still slow. Compared to what? Even C is slow if you can use VHDL and a FPGA. That's not the point. As long as the execution speed is sufficient any complains about a slow language is stupid. 
Still an xyproblem. What do you want to achieve?
Well, it's always the same for a language/development environment: what are the pro's and con's for this specific type of work. It all comes down to: what is the best tool for the job, and what are you most comfortable with. You just have to be aware of the limitations of each language, and not blind to the advantages/disadvantages of other languages than &lt;fill in your favorite&gt; - which happens way too much. I like quite a few languages (and dislike quite a few others) for various reasons - but I'm always open to new experiences, which I think is a healthy approach. I'll never blindly say "this must be done in language X" without evaluating the pro's and cons. That's doesn't mean you have to learn a new language when a new problem pops up where this would objectively be the best option. Learning also has an overhead - only do this if you think it'll be useful for you in the future, and don't judge the tool by your first attempt at writing something useful in it when it doesn't work out terribly well.
I'd also like to point out that using a web framework can be a decent alternative to QT/GTK/TK, of course, it should be used for the simplest of interfaces, otherwise it can be a bit slow. My current work project uses Flask (with Flask-Script, Flask-SQLAlchemy and Flask-WTF), I even included keyboard shortcuts in some pages.
Yeah, a guy at work was pushing for using something else (I think grizzly) but I didn't want to push on people too many changes at once as we are moving toward a pseudo microservice approach. Spring can be a lot faster too, the main reason for the slowness is the component scanning and auto configuration. If you manually tell spring what to import it can significantly speed up boot. It's a really powerful framework when you understand it.
I did as soon as I fell in love with asyncio about 2 years ago, I use Python 2.7 at work but personally I do everything in 3.5. And for those who keeps with the "until my distribution ships it" argument, there's always pythonbrew to help with that.
Yeah I like that method as well, I prefer it when I know what I'm doing. But doesn't that bring a lot of extra time in planing out the interface for your code?
Serious Q, can watching these help as a beginner or should you have the basics first for this to have impact?
It's the then do something part where things can get a bit sticky
It depends on what you mean by beginner. If you are beginning python programming, then this will likely be too much. The first episode [YouTube](https://www.youtube.com/watch?v=xQTFmIRTWmM) will give you a good idea of how advanced it is, and goes a lot more into the ideas behind emulation and hardware :) If you know python but know not much about emulators, this is probably for you!
You're missing several subtleties here. The first is the distinction between a name and an object. Names refer to objects, but not all objects have names. `to` is a name, and a list is an object. Inside the body of the function, if you write `to = []`, you are instructing Python to create a new list object and make the name `to` refer to that object. The lifetime of names and objects work differently. When the function returns, all names of local variables go out of scope and their lifetime ends. So the name `to` ceases to exist when the function returns. There is no way for the name `to` to maintain any kind of knowledge across function calls. Every time you call a function, the names of local variables start fresh, and they die when the function returns. They don't carry over. Objects work differently. An object has a lifetime that lasts as long as necessary; an object continues to live as long as it's reachable by something. For example: def some_func(obj): obj.append(42) foo = [] some_func(foo) There is only one list object in this entire example. It is created on line 4, and the name `foo` is made to refer to it. Then when the function is called on line 5, inside the body of the function the name `obj` also refers to that same list object. When the function returns, the name `obj` goes out of scope, but the list object continues to exist because it is still reachable from the name `foo` at the global scope. So even though `obj` is the name of a local variable, and even though that name was created and destroyed as part of the function call, the object it referred to outlasted the function call. The same thing applies in your examples. In the first example, when the function is called, the name `to` is created. It is initialized to either refer to the second argument provided by the caller; or if the caller did not provide a second argument, then it refers to the default value object, which in this case is a list object. That object is what outlives the function call, not the name `to`. The name `to` comes into existence and dies every time the function is called. That is why if you execute `to = []` in the body of the function, a new list object is created and `to` is made to refer to it. That is what happens any time that line is executed. In the first example, if you let `to` be initialized to refer to the default value object, then it will be the same across every function call, as that object's lifetime outlives the function. It will be the same list object every time. In the second example, if the line `to = []` is executed, then a new list is created. 
Tests means your library is most likely to be adopted by the "right kind of users" which will report more bugs correctly and even send PRs for them. AKA your project benefiting from its open source status. Plus, with the tests cutting down on potentially hard to chase bugs, you cut down on those reports that may make you waste a lot of time for no good reason.
&gt; he presence of tests also makes it easier for someone else to contribute to your library, but honestly basic self-preservation provides 90% of my own motivation. Oh I completely agree with you, I would have test for every important line if I could but that doesn't change the fact that it for me is boring to write them! I do believe a lot of these emotions against writing the tests dwelves in the fact that I'm not doing it on regular basis, I just need a boot in my behind to actually get started!
Indeed, as I've stated I'm not against testing, on the contrary. But I do find it very hard to keep the same level of interest in my code when I know I need to write tests for it. It might be worth mentioning that I have severe attention disorder so any tedious task becomes really heavy, writing tests and documentation being two of the most tedious ones in my world. The library I'm working on is a Python implementation of the UPnP Device Architecture 2.0 based on the asyncio library. I do enough UPnP related hackery now and then to find a need to make this library, plus I haven't contributed properly to the OS community in a very long time. On a side note in implementing tests; As this library is heavily network driven and there's a few interfaces that are platform dependent. Should I mock the data from the specific platforms or skip them depending on the platform the tests are running on?
Thanks. I used virtualenv on my Debian server. Had an issue with the first setup, no problem setup a second and all is well! Definitely, learned it's value.
I wrote [a blog post](http://takluyver.github.io/posts/so-you-want-to-write-a-desktop-app-in-python.html) on the different options for building GUIs. It's a couple of years old, but the landscape hasn't changed much. In short, I reckon that Qt is the best option for standard desktop applications (windows with menubars and buttons and so on). Depending on the priorities for the application, though, it might be best to use Kivy, or to run a local web server with an HTML and Javascript frontend. There's also some interesting new work around mobile interfaces under the [BeeWare](http://pybee.org/) umbrella (see Toga, VOC and Briefcase, for instance). That looks pretty new at the moment, though.
Dear FXCKY0U, you should be able to easily achieve this using filename globbing in the shell - no need for python. Assuming the ROMs you're talking about contain the text `(J)`, then you just need to do something like: `rm -f *\(J\)*` Please have a look at the sidebar of this subreddit, where you'll find, "if you are about to ask a question, please consider r/learnpython" and other useful links. 
Just checked using dis, and python does *some* optimisation. Constants (2 + 2) *are* folded into 4, but x + x is still x + x (Because python *can't* assume that x + x is always equal to 2 * x). Would be nice if you could give types to allow python to do these optimisations.
I start with the tests first, it's part of the design stage for me, and I make sure I docstring those methods. For me the motivation comes from pretending like I'm creating a puzzle that later I'll solve by implementing the code. Code that would otherwise be mundane and unrewarding will instead feel like a stage cleared in a game, or a piece of the puzzle found. Later I craft the documentation from a lot of the test docstrings, so it doesn't feel like too much of a burden.
Great advice.
Unit tests are not a debugging tool, they are a verification tool. They are used to convince yourself that the code does work and to highlight the specific cases where it does not. The REPL is also of limited use in debugging. You can play around with things but if something isn't working it's not going to let you quickly walk through the execution to understand exactly what's going on. Some components may have requirements and dependencies which are difficult to replicate in a REPL. PDB is a debugger. It lets you examine the behavior of your code as it's running and so allows you to understand exactly what the root cause of a problem is. These are three different tools for three very different tasks.
I guess my definition of debugging is different/wrong. There are of course similarities between the methods: they all try to make sure the code you will run on your next attempt will be successful. Is there a better term?
1. A virtualenv would probably do it?
I believe PyInstaller can be used to bundle things like numpy or pandas. You get the added benefit of having everything in a one-folder bundle with a single executable.
Put a CI badge for your current code coverage if you use Github. It keeps you honest.
I had the same issue when I used selenium for some scraping. Traced the problem to a reference cycle. Broke it with a weakref proxy using this monkeypatch: def __init__(self, driver): from weakref import proxy self._driver = proxy(driver) from selenium.webdriver.remote.mobile import Mobile from selenium.webdriver.remote.switch_to import SwitchTo Mobile.__init__ = __init__ SwitchTo.__init__ = __init__ This should obviously go to the upstream project but I was too lazy.
Which branch dev or master on your github repo?
Check this [hackaday article](http://hackaday.com/2015/12/02/amazon-dash-button-pwn3d/) as well as[ this one](http://hackaday.com/2015/08/12/amazon-dash-hack-it-to-run-your-own-code/) out. I stopped halfway through but I believe you have to set up some sort of javascript listener to listen to the MAC address on the wifi network. From there you can have it send a REST API call to somewhere to perform an action (I think the easiest might be [IFTTT \[If This Then That](https://ifttt.com/) - great agnostic automation connector]). 
What interests you? You will get more out of reading code that does something that you find interesting. It's also helpful to run the program or use the library before you read it, so you know what the behavior is. If you're reading code that belongs to a library, pick a function or a class from the library that you have used, find where it is defined, and start reading there. Try to follow the thread of execution starting with a function or a class method. Well written code is broken down into smaller parts which call each other. This can make things confusing when you first start reading, because it will feel like you are constantly jumping from function to function and getting lost in a maze of code. You may want to keep a piece of paper nearby to jot down notes and draw a picture of the relationships within the code. You can also use a debugger to help you step through the code.
~~I can't find the exact article that's why I posted a few.~~ [Found the exact article with steps.](https://medium.com/@edwardbenson/how-i-hacked-amazon-s-5-wifi-button-to-track-baby-data-794214b0bdd8#.1ugndbl89) You have to follow one of the Hackaday posts. In the setup I read, you go through the app, it asks you for your wifi password, then the next screen it asks you to select an Amazon product to order with your dash. This is where you end the setup of the button, as it is connected to your network. You should get an IP listener (Angry IP or others) and start scanning your network for devices. Look for the one that you don't recognize (won't necessarily say THIS IS AN AMAZON DASH BUTTON LOOK AT ME) and copy that MAC address. The end result in this article is a simple timestamp form, but the results are limitless. 
You are right, that was a weak argument.
In the future you should direct questions to more appropriate subreddits, such as /r/learnpython. See the sidebar.
Nice tutorial. Pandas is a godsend to anyone working with labeled tables. If you're currently storing your data in a numpy ndarray and keeping row and column labels in separate lists, look into using Pandas for a better way! One thing I noticed, HTML rendering may have messed up the "less than" sign in your comparison examples.
In your first example, you're saying "the default value for `to` is this empty list: `[]`." The "this empty list" part gets executed when the function is defined, and is therefore in the same scope your function is defined in. In your second example, you're "the default value for `to` is the value `None`. Within the function you're saying "If the value of `to` is `None`, set the value of `to` to a new empty list. Because you're within the function, that empty list gets created in the function's scope - and that scope is created once each function call. This is more confusing because of the concept of mutability, but the problem is really one of scope. The problem is that in the first case you're modifying an object that's defined in the outer scope (and is therefore shared across all function calls), while in the second case you're modifying an object that's defined in the inner scope (which is NOT shared across function calls).
What /u/_ntnn and /u/Meefims said, but adding [pdb++](https://bitbucket.org/antocuni/pdb/src) as an option: From the docs: &gt; pdb++ features include: &gt; &gt; colorful TAB completion of Python expressions (through fancycompleter) &gt; optional syntax highlighting of code listings (through pygments) &gt; sticky mode &gt; several new commands to be used from the interactive (Pdb++) prompt &gt; smart command parsing (hint: have you ever typed r or c at the prompt to print the value of some variable?) &gt; additional convenience functions in the pdb module, to be used from your program Not life-changing, but very **very** helpful
I've spent some time trying to write wrappers to make errors more explicit/verbose/explicit and I'd be quite interested in seeing yours if it is available somehow...
Is it kosher to include code developed using the student version in a commercial product as long as you buy a full license before making your commercial product available for purchase? 
Doesn't Jetbrains revert you back to the version that was available at the start of your yearlong subscription? (It's entirely possible I'm mixing them up with someone else.) 
Exactly, stuff like keeping track of autocomplete for class methods from imported modules doesn't come for free. If you find Pycharm too heavyweight you can always use Sublime or another text editor (as opposed to an IDE like Pycharm). 
&gt; Octave is an open source re-implementation of MATLAB, and **it is insanely slow** compared to the real thing, but it is great for educational use. Can you prove this (bold-faced) claim with a link or something? 
Try updating your installation of aiohttp... not sure if this library supports TLS 1.2 - it should do, but you might have an outdated version that doesn't or has bugs... I had a similar issue with Requests on py2.7 recently
http://stackoverflow.com/questions/22703796/time-comparison-of-for-loop-in-matlab-and-octave some slightly naive code is partially to blame here, but I've seen this kind of performance difference first hand. MATLAB optimizes it and gets good performance, where Octave does not.
XLSX files are zipped xml (MS open xml standard) unzip grab the xml and parse it.
Parsing the files isn't a huge concern (pandas does this rather easily), it is validating the form, content, and such before pushing the data into a database.
try this http://aiohttp.readthedocs.io/en/stable/client.html#ssl-control-for-tcp-sockets
If you test them. There are differences, but once you learn the rules, it's really not bad. If you haven't done it before, it's not gonna work. pyInstaller isn't going to make a windows-linux-mac-solaris executable though. You can make a multi-platform compatible package/egg/wheel though. &gt; How can we get it working for people with other accounts without them installing anaconda? Give them a prebuilt exe from pyinstaller for their platform.
I use PyQt for scientific applications dealing data analysis for certain types of electron microscopes. I dabbled with Tk first but PyQt in the end seemed easier. MY software works on OS X, Windows and Linux. I have little to no need to support android/iOS thus have never really given Kivy a shot.
I played around with that a bit, but it seemed somewhat limited. Basically, it lets you embed restrictions into specific columns/cells on things like valid choices and number ranges. However, I want to actually perform some more complex validation logic and be able to use reference data already in the database to verify certain things. Also, the offline nature means that people can still override things like header names, add or delete columns, mess with sheets, etc. I also want to be able to provide feedback to correct issues. That said, I'll take another look at Xlsxwriter or even consider forking it to add some functionality. In the end though, it will be up to Django to not allow anything into the database that isn't valid. 
I think the best way is to lock out everything in these files except the cells that may receive user input. From what I see Excel has [extensive locking options](https://support.office.com/en-us/article/Lock-cells-in-a-worksheet-b2f833bd-9db5-48a4-9ec0-8e451ac27c3a). If you can do this, then the only thing you need to verify is that all data are in place and look sensible and this is much simpler.
Tell me more about the protocol being old please. I thought websockets were a standardized protocol
Reading code without the goal of a specific fix or change seems weird to me. It's like going to a hardware store looking closely at hammers but not using them. 
I just imagine myself going through the steamung shit pile that is my untested code 6 months later trying to add a feature and running into 15 different bugs. Grab a beer or two some night and write the docs and the tests. I usually write docstrings before my code to describe my ideas and tests just after my code to verify them. DDD or TDD?
aiohttp uses your system certificate store, via https://docs.python.org/3/library/ssl.html#ssl.create_default_context . Depending on your OS, other software also uses this (e.g. wget, curl), so you might want to test whether those can retrieve the contents.
As long as you ignore the first suggestion given there, that is. Passing your own cafile or pinning a certificate is fine, not verifying the ssl connection is not.
That's actually not a bad idea, I should start seeing the testing as an individual challenge and as a part of my codebase rather than some side task. I do experience some tough to crack stuff with doing asyncio testing, need to mock the transport unless I want to spin up an actual client implementation of UPnP and test that. The up side is that I am a member of the Open Connectivity Foundation which has inherited the UPnP Forum assets, so I have access to their UPnP test tools where I can validate my implementation as well. It provides a lot of test cases I could just reimplement in Python. On the mocking part, it's not quite that easy. Let me explain a bit further; The UPnP specification requires a reconfiguration when a network interface has gone down or has been changed, to allow hooking on this I had to implement an interface in Linux to listen for RTNETLINK events, and in OS X I had to implement a Kernel Event listener to do the same. So the tricky part is to emulate reconfiguration of a network interface. Also as far as I remember, I'm not allowed to have OS X running in docker unless it's hosted on an OS X Server machine.
That was incredibly satisfying to watch, I'm amazed how just does things right away without hesitation. Not sure if I'm the only one but I can go think about a possibly solution to a problem for hours without writing the code for it, I think I might be more into solving problems theoretically than practically.
I like that! I don't think it will motivate me enough though, but it's definitely a good way of looking at things. How about if you already wrote the code but not the tests, how would you go about getting the tests written for code that's already done?
Do you also outline your workflow for the project? I recognise myself in that method as well, although without the testing for most parts. Continuing my example with the project I'm working on, there's multiple individual procedures involved in UPnP; addressing, discovery, description, control, events. I know discovery requires addressing being implemented, so i know I need to start with that. But here's where things go bad for me; I don't necessarily know what discovery requires from addressing so I start outlining discovery before, and I don't yet know what discovery will be doing so I do a short implementation of that and realise I need to implement descriptions as well. And before I know it I'm implementing it backwards. I do docstrings for any public methods, but I feel like I should do it for internal methods as well since I'm prone to forget stuff...
Way ahead of ya! :)
I always found the term domain logic a bit to abstract to be honest, it's clear when you're doing web development but for a library without any UI I would say most of that code is the domain layer. Or have I got that all wrong?
Where is that option hidden in PyCharm? I use the same IDE as well, and that would be really handy! About testing, I recognise myself in that all to well. Recently we've been required to fulfil a full test suite because we use that to validate the specification of requirements for a project though. I do devops stuff at work as well, and many times doing Ansible modules and these I tend to skip writing tests for because they're most of the time very short and does one single thing. That in itself is probably a bad reason to not write tests, but point is that writing that module takes about 1 hour and that's all the time I have on my hands, so no time for tests...
Yeah you're going to get lynched for this! Just kidding man, but I do believe there are situations where tests are more of a burden. But the aggregated experience of developers over a decade says that tests are a good practice, and I don't thinks there's many that disagrees because there is truth to it. I myself find that a good test suite can really help me out more than once in a project, if not it's good for validating specifications of requirements. I do like your take on documentation, as it is right now I'll be the only one using this library and if I see it's getting a userbase I could do the documentation at that point instead.
I usually work in places for 1/2 years (never been a contractor) so that happens quite a lot :) I also think that the code I leave is gonna be read by some psyco who knows where I live xD 
&gt; Also as far as I remember, I'm not allowed to have OS X running in docker unless it's hosted on an OS X Server machine. It's even more limited in that regard, on OS X docker basically boots a linux kernel in a vm and uses that to provide containers, so it's always running linux. Great if all you need is linux. In your case it won't fit the bill, but maybe you can look in to using virtualbox # simulate unplugging the cable for interface 1: vboxmanage controlvm 10927416-b305-4667-a0fd-d5d218e9971f setlinkstate1 off And with vbox you have the ability to snapshot a running VM and restore it. That way you could have a fresh machine in a known state by just resuming the snapshot. Anyway, there are tradeoffs to each approach, so whichever route you take, try to find the fun in doing it.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
To check the certificate presented by a website, your computer needs to have a set of trusted certificate authorities (CAs). These CAs 'stamp' the certificate from the website, indicating that it is, indeed, valid. It seems aiohttp is unable to load the trusted CAs, which means the certificate presented by the website is seen as invalid. You can work around this issue by manually providing a list of trusted CAs to aiohttp: sslcontext = ssl.create_default_context(cafile='/path/to/ca-bundle.crt') conn = aiohttp.TCPConnector(ssl_context=sslcontext) session = aiohttp.ClientSession(connector=conn) r = await session.get('https://example.com') If you don't pass the cafile parameter, create_default_context should load CAs from the system certificate store. You can try passing the CA list from e.g. python-requests (https://github.com/kennethreitz/requests/blob/master/requests/cacert.pem) to see if that solves the issue. If that solves the issue, you should try to figure out why the system certificate store is not working correctly. Maintaining your own cacert.pem also means that you have to manually add new CAs, or otherwise sites may become impossible to reach in the future.
He could have added this package: [expcontrol](https://pypi.python.org/pypi/expcontrol/0.2.3) . I have not used it myself, though, but I read about it. 
You should look at the library BeautifulSoup which is a robust HTML scraper and parser. Much better and less error prone than regex when dealing with HTML.
Ah, tuntap is a great idea. Can't say I have any other tricks up my sleeve, but I'm always looking to learn :)
I use super-strict checks in my IDEs, so every function, module and class requires a docstring specifying all parameters' types and meaning, it's super easy to generate some documentation with sphinx and write the rest by hand after that. Overall, it's a simple thing - I can either spend 5 minutes writing docs and tests at the time I write the function, or many hours writing docs and tests for a large amount of code.
I have it says: -bash: pip: command not found
I'm not really sure how python is set up on OSX, but I believe pip comes pre-installed with Python 3.4, so the problem you're having is that bash can't relate the command "pip" to the actual file that designates what pip should do (I don't know what that file is on OSX, but on windows it's C:\Python34\Lib\site-packages\pip) [This stackoverflow post](http://stackoverflow.com/questions/9780717/bash-pip-command-not-found) may help you out. I'm fairly certain you can install pygame without the use of pip, but it's easier with pip, and having pip running will help you out a lot in future installs.
requests*
Sounds like a job interview... and sounds like you won't pass.
ooops the code is all messed up with no newlines. let me try to improve on that import random rng=random.Random() lol=[0,0,0,0] x=[9,1,3,6] lol.append([1,1,1,1]) lol.append(x) print(lol) rng.shuffle(x) #x=[1,3,6,9] print(x) print(lol)
How much value added is Pandas over Numpy? I see the official tutorial spends time on things like computing the `mean` of a data frame, which replicates Numpy functionality. I understand the value of conveniently labeling columns in large Numpy matrices, what else am I missing? My impression from a couple of years ago was that Pandas is mostly an "answer" to R, making it easier for statisticians to use Python more conveniently. It seemed that the value for an expert Python coder was minimal over the vanilla Numpy/Scipy stack. 
&gt; I always found the term domain logic a bit to abstract to be honest As it determines a concept it is of course quite abstract 😉 &gt; but for a library without any UI I would say most of that code is the domain layer. It depends! If you write a lib that deals almost only with IO (db access or something) the *domain* part of it might be extremly small. I would recommend you the excellent book from Eric Evans: Domain Driven Design. Imho a bit difficult to read for a none native speaker, but very interesting and enlightening 😊
Thanks very much
I am not sure, but here is the [license](https://www.jetbrains.com/student/license_educational.html) I think doing what you said still violates the license. &gt; 3. GRANT OF LICENSE &gt; (B) You may not: &gt; (iv) use Products for any commercial purposes. Because the product would be used for commercial purposes still.
Strip the data from the XML, run it through your business lair for validation, and add the data directly to database. You probably have a validation rule set that can be used to create the class that checks the document for inconsistencies.
You're welcome, and welcome to Reddit. A couple things that might help along the way: when fixing your content you can click the "edit" link to modify in place instead of commenting on your own thing and hoping people pick up on it. Second, when replying to a comment it's better to use the "reply" link after it rather than creating a new top level comment
That's because the repo has one watcher and one star (the author) and its link is broken on pypi
I find that pandas makes it much easier for me to work with experimental data or large data sets. It's really nice to be able to do things like df['work'] = df['force'] * df['distance']. It also makes working with timeseries data much more enjoyable. Pandas has ways of merging time series of different sample rates. It also has simple methods for resampling your data.
Oh, did not notice that. Thanks for pointing it out!
Pendulum is a new library for Python to ease datetimes, timedeltas and timezones manipulation. It is heavily inspired by [Carbon](http://carbon.nesbot.com) for PHP. Basically, the Pendulum class is a replacement for the native datetime one with some (I hope) useful and intuitive methods and the PendulumInterval class is intended to be a better timedelta class. An important note about the Pendulum instances is that, unlike the native datetime ones, they are mutable via the appropriate methods. To those wondering: yes I know [Arrow](http://arrow.readthedocs.io) exists but its flaws and strange API (you can throw almost anything at get() and it will do its best to determine what you wanted, for instance) motivated me to start this project. It’s still fresh so any feedback is appreciated :-). Link to the official documentation: http://pendulum.eustace.io Link to the github project: https://github.com/sdispater/pendulum
The version of socketio for flask was outdated. That's what I meant.
Oh, thanks for the clarification. I see your concerns have been addressed in the new version. &gt; Releases 0.x required an old version of the Socket.IO Javascript &gt; client. Starting with release 1.0, the current releases of &gt; Socket.IO and Engine.IO are supported. 
I see what you mean. Even though all the features are detailed in the documentation it may help to showcase the main features of Pendulum. I tried to make it concise by displaying a piece of code on the homepage but it may not be enough. But basically: * It enforces UTC when possible * It can create datetimes from strings, timestamps or the normal way * It can manipulate timezones with ease * It can make comparisons of different timezones datetimes * It supports localization natively (to display datetimes in a more friendly way) * It adds a bunch of methods to add/substract durations in a more natural way * It provides new properties to access basic information more easily * Improves timedeltas with new attributes and methods and by providing a way to display them in a friendly way.
That would be good to list on the homepage. My point was even simpler, although I hate the trend of badges everywhere, you should also write 'extensively tested, full coverage, bla bla'
This looks so clean! Very nice.
Enterprise Architect can generate code from state machines. You can modify the code generation templates too. See [here](http://www.sparxsystems.com/enterprise_architect_user_guide/9.3/software_engineering/code_generation_from_behaviora.html)
Some details on reliability, coverage, production readiness and how it is implemented etc would be good since datetime is hard and important (/u/ilikebigsandwiches noted similar).
This is true, but I've found that it only works for certain languages. For example, if I select Java as the language I want to generate, it works just fine, however Python doesn't seem to be one of them. I've only been able to generate abstract class structures - no deeper level logic. Maybe I don't have something configured correctly?
How is kivy for desktop applications as opposed to tablet and touch apps they've been highlighting?
Translation: Aiee! It's escaped from Java! Kill it before it breeds!
A good question :) Hopefully would act as a common mode of communication between a variety of engineering disciplines and would introduce a level of commonality within the team developing software. 
use vagrant. at first it may take you some time to get it up and running than, say, installing ubuntu on virtualbox, but for me, after trying different VMs and distros, vagrant is the only viable long-term solution
What do you mean "Pythonic manner"? You may be spot on since this really is more of an architecture issue... 
There are lots of standard libraries available, that (almost) every python implementation will have. Read up on [builtins and standard libraries here](https://docs.python.org/3/library/). There are plenty more you can get, but those should be available with pretty much every installation of python.
Just and Update: There is a bug in [JetBrains](https://youtrack.jetbrains.com/issue/IDEA-117946) tracker for this. 
https://www.youtube.com/watch?v=ogMNV33AhCY
I think you are right. I have to admit -- I am having a terrible brain-fart today. See screen shot: http://imgur.com/jMyfUt9 What line of code am I missing? How do I get that 'apple' data frame snippet to get into .csv with the new encoding? Been working on this too long.... 
WSGI doesn't support websockets so it will be hard to do it completely with Nginx, gunicorn and a WSGI framework like Flask. Armin Ronacher(the author of Flask) suggests using something like Redis that supports Pub-Sub to handle the sever push - http://lucumr.pocoo.org/2012/8/5/stateless-and-proud/
I've used Arrow a lot and am happy with it. I am not intending to discourage you on this project, but have you written down anywhere your motivations in more detail, so I could understand better why you created a new project? After a very quick pass, I'm not actually seeing huge differences in functionality or API surface area between Arrow and your project, so I'd like to hear more. 
It's good to hear that.
Regarding the mutability, I hesitated too but only specific methods mutate the instance. The native methods behave the same, ie. returns a new copy. But it's not set in stone, so it might change if this too much of a hassle for the users. The add()/sub() methods are here to allow a fluent interface and call chain. It's easier to do pendulum.now().sub_day().offset than (pendulum.now() - delta(days=1)).offset Both Pendulum and PendulumInterval classes inherits from the sdtlib classes so they can replace them. However, for libraries that relies on the type() function to determine the class (sqlite3 for instance) it will not work.
Between Arrow, Delorean and this, i wonder... why dont we agree on a stdlib replacement like we did with requests?
I don't want to be too cynical here, but this library is quite literally a baby. And while the API looks nice, I've been burned too many times by new libraries with decent APIs just losing support. So for me, I'll happily keep an eye out on this and would like to be wrong. But until then, I'm pretty happy with [arrow](https://github.com/crsmithdev/arrow) any time I don't just use the stdlib. 
"Which reported stuff like:" What a cliff hanger! Or broken article
How precisely does this differ from [Delorean](http://delorean.readthedocs.io/en/latest/)?
To save you from writing Getter and Setter methods? Oh wait...
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
The site loads Javascript-code for Pages (http://pages.revox.io/). I assume this is what was used.
offset is the number of seconds since epoch, it's just there to show that accessing attributes is easier with the method. Regarding the change of name for the sub() methods, it might be a good idea. I just wanted a concise name so I thought sub was appropriate.
Well, if you don't specify a timezone, it defaults to the UTC "now" so it does not exactly rely on a global state. Regarding the inconsistency you point out, it's so that the Pendulum class behaves like the standard datetime, if you don't pass hour, minute, second those default to 0:00:00 while create() is here to circumvent this limitation.
Yes, I use Pages, I just changed the color theme. The documentation is made with Sphinx and a custom template that fits with the rest of the website. 
Arrow behaves strangely and is not always reliable. An example: dt_timezone = datetime.datetime(2016, 7, 5, 8, 0, tzinfo=pytz.timezone('Europe/Paris')) arrow.get(dt_timezone).isoformat() '2016-07-05T08:00:00+00:09' pendulum.instance(dt_timezone).isoformat() '2016-07-05T08:00:00+02:00' Pendulum also has improved timedeltas (named PendulumInterval) and a bunch of helpers for common cases. 
UTC "now" is the definition of global state, and it's not made obvious (directly contradicting EIBTI), _and_ I honestly can't find any cases where that behavior is actually desirable. If you want to be able to create objects that are partially current time, you can use a sentinel magic value like `pendulum.FILL_NOW` or something. Edit: another cool API design could be a `replace()` method taking the same kwargs, so you can do `Pendulum.now().replace(year=2016, month=1, day=1)`.
&gt;To those wondering: yes I know Arrow exists but its flaws and strange API (you can throw almost anything at get() and it will do its best to determine what you wanted, for instance) motivated me to start this project. Would be good to put that on the front page because most people who visit it will probably also be wondering "why not arrow?"
Actually, you can do tomorrow = pendulum.now() + timedelta(days=1) I added the add()/sub() methods to allow chaining methods, so you can have pendulum.now().add_day().to_rfc3339_string() rather than (pendulum.now + timedelta(days=1)).to_rfc3339_string() that is, I think, less readable. Anyway, the choice is left to the user.
IMO invoking the word "timedelta" is kind of ugly when the fact you're using a timedelta is implicit anyhow. Hence the idea of using "Days" / "Weeks", etc. &gt;I added the add()/sub() methods to allow chaining methods, so you can have In which case why not this: pendulum.now().add(days=1).to_rfc3339_string() &gt;that is, I think, less readable. *shrug* I think this is pretty readable: (now() + Days(1)).to_rfc3339_string() But the choice is good I suppose.
I would second all the voices here telling you to install [Anaconda](http://continuum.io/downloads). I'm biased because I am one of the people that help make it. :-) Basically, the problem you're running into is that a lot of Linux distribution internals are relying on the "system python" to do things. But you also want to use Python as a development tool. If you're not careful, you will install development and/or incompatible versions of libraries that will clobber the proper functioning of your Linux system. That's where a python distribution like Anaconda comes in. There are a few others out there, but Anaconda is designed from the ground-up to be non-intrusive to your existing system python, requiring only a $PATH change, and cleanly installing into a single directory, that doesn't have to be owned by root. Additionally, Anaconda's packaging system is designed to support all sorts of additional metadata that ensures C compiler and runtime library compatibility across even gnarly 3rd party dependencies. Furthermore, Anaconda is cross platform, so you can create "environments" of interdependent packages on Linux, Windows, or Mac, and have them be portable across OSes and machines. Think of it as a lightweight Docker. Anaconda is fully open source (BSD licensed), and supports languages beyond just Python, including R, C, C++, Node, Java. FWIW, Windows and Visual Studio work great with Anaconda on Windows, including non-Local-Admin installs. Anaconda is actually the default Python runtime on Azure ML, because it includes so much of the data science/scientific computing stack. 
Isn't https://wtforms.readthedocs.io/en/latest/ can do the same? Also, interesting stuff, but a bit another field https://marshmallow.readthedocs.io/en/latest/ .
Concise is a lot less important than clarity though. So for offset I think seconds_since_epoch would be way better. And if the epoch is 1900, then seconds_since_1900!
Well done :) I will consider it myself for a next project `^_^`. Also thanks straita, for the first reply :)
The last line sounds like you can't even get it to work in your local development server?
diff_for_humans() defaults to now in the timezone of the instance making the call for the comparison. And diff_for_humans() is not the same thing as diff().for_humans() past = pendulum.now().diff_for_humans(past) pendulum.now().diff_for_humans(past) '2 days after' pendulum.now().diff(past).for_humans() '2 days 19 hours 44 minutes 4 seconds'
HOW?
What have you tried so far?
I agree that it might be confusing. I will look into it. Thanks for your useful advice. It points out some flaws that I never considered while developing pendulum.
Oh yeah, and I hope you get them. I just am not the type that does that anymore - and voiced the concern. A lot of people get inspired for a project and it fizzles (I have been guilty of this too) - so it's hard to buy in early.
Looks great! Good luck and I hope you will make it better and more stable with time! (not that is not amazing right now)
The desire was to add attributes and some class-like functionlity to tuples, which could be done by just plain inheriting from tuple. But a general-purpose class which stores the name of elements as an attribute ends up being slower than a regular tuple. So as a performance optimisation, the namedtuple implementation generates a string containing the definition of a class which hard-codes the number of element and their names, and evals it to create a class.
And then there is Egypt... =D
if there're 2 things i've learned from programming, it's that datetimes are never easy
There's the [`webagg` backend](https://github.com/matplotlib/matplotlib/blob/master/examples/user_interfaces/embedding_webagg.py) in matplotlib. I can't tell if it's reasonable to use in non-local contexts. Plotly became [open-source](https://github.com/plotly) some time ago under the MIT license. I haven't used it, but [mpld3](http://mpld3.github.io/) seems interesting. Strictly on the browser side, I used [jqPlot](http://www.jqplot.com/) (MIT) some years ago. 
yes, requests the stdlib replacement /s.
Why wouldn't you use a state machine if it maps well onto the problem at hand?
Thanks for the advice. It actually makes a lot of sense. I just wanted it to be more readable for newcomers but maybe it's not worth the hassle.
I'm a really big fan of comparisons between libraries. As you say, your most direct comparison is Arrow. I think it'd be nice to have a section in your docs called "Pendulum vs. Arrow" (or something to that effect), where you lay out the differences with examples showing why Pendulum is better. I find those kinds of direct comparisons really useful when deciding between two similar libraries.
Literally my first question when seeing this post was, "okay, cool, why not arrow?" I'm glad someone beat me to posting this!
Is it possible to share the pages URL?
The sidebar recommends asking questions in /r/learnpython. Also, you may want to include any code that you have tried.
OP, you must be feeling golden right now. Every time someone suggests something in this thread you say it already works like that.
What took you so long?
We sort of did. Guido approved a change to Python to add DST awareness to Python's datetimes so that eventually arrow-like features could all be rolled into the standard library. I think for the last (two?) releases now no one's had the time to actually do it. :-( Ok, wait - it looks like the original proposal was met with some "it's not a bug, it's a feature" objections and the PEP was withdrawn, and now there's a weird new one with something called "fold" thanks to Guido... on second thought, arrow is the best bet. :-( https://www.python.org/dev/peps/pep-0431/ https://www.python.org/dev/peps/pep-0495/ 
So basically I just need to import all the things it can't find? And I should import them in my main script? Problem is, I never use numpy and don't even have it installed as well as most of these other modules that it's saying are missing. Anyway if I were to just use the hidden imports list, could I just put all the supposed "missing dependencies" in there, or should I just do the ones that don't throw an error when I try to import them?
You will need to built it from the sources for the newer version (and I'm not sure it's even available on PyPi so pip wouldn't work anyway, except to build it.). I skimmed your post and it looks like mercurial isn't installing properly because it can't locate the python program because of some sort of an environment path issue. Did you install python3 with brew as most of these tutorials seem pretty adamant about using brew to install python first so this may help with the pathing issue. Also, maybe try linking pip directly to the source for pygame instead of the repo and avoid needing 'hg+' altogether? pip3 install http://www.pygame.org/ftp/pygame-1.9.1release.tar.gz From there hopefully you should just need the right stuff installed to compile pygame on your system.
[pygame isn't on pypi.](https://bitbucket.org/pygame/pygame/issues/59/pygame-has-no-pypi-page-and-cant-be)
Your code is nearly impossible to read here; reddit mangled it good. Please post the whole thing in a [gist](http://gist.github.com) and link to it, otherwise nobody's going to be able to help. (No guarantees they'll be able to help after you do that, but at least there's a chance :)
I am surprised at some of the player ratings. Did you analyse tweets only in English?
I wish someone would set this to music.
Thanks, I'll switch over the zip and try it again. I have 30 variations of zip and join that I've tried. I'll also post a few lines of data to the gist. I have posted one, someone else suggested it. I'll post the data there too.
Looks very clean. Perhaps I'm in the minority but I've never had much difficulty with the datetime package. Why should we switch?
The way to understand it: zip(ABC, 123) -&gt; A1, B2, C3 "@".join(ABC) -&gt; A@B@C Of course zip and join take iterables (lists) so a = [1, 2, 3] b = [4, 5, 6] zip (a, b) -&gt; [[1, 4], [2, 5], [6, 3]] A string is an iterable so "hello" is treated as ["h", "e", "l", "l", "o"] by zip.
Upvote for absence of the term "for humans".
What you're requesting is called a "spam bot" and there are plenty of templates for spamming bots readily available. In fact check the sticky over at /r/RequestABot . Just don't look at their rules though, since the first one asks you not to make a spam bot.
Hrm looks like there's some bugs … http://i.imgur.com/nPcy7uS.png
Ah, what you need here is a metaclass that parses your UML diagram. That would totally work. If you make it, you deserve to have made it.
Firstly, the standard library (stdlib) is the collection of native modules included with Python. I'm going to assume you mean 3rd-party ones, like those found on PyPI. Secondly, I'll also assume that this is meant to some way inform a decision about which version to use. Unless there is a *specific* library you want to use that supports py2 **only**, you should be developing firstly in py3. If necessary, spin up a container / venv (Docker / Anaconda are handy for this) to support older versions as a secondary measure. In answer to your question, checking [pypi.python.org](https://pypi.python.org/pypi) lists 83,808 total packages. A [Google Trends search](https://www.google.com/trends/explore#q=python%202%2C%20python%203&amp;geo=US&amp;cmpt=q&amp;tz=Etc%2FGMT-10) seems to suggest that py3 is gaining pace. I would approximate that 60-65% of all actively developed projects are py3, though take that with a heap of salt.
I imagine. But I started it because I've been hurt too. Pendulum is still in its early stages but I trully hope I will make good on this promise :-)
Yeah Its a job interview, but I am looking for the solution of problem. I know some python did some work on django also now looking in the project known as quokka, its very cool. Here are the files https://goo.gl/yRhqaf. Please tell me what I can try, One friend told tensor flow library
I have no Idea how to go about it, that is why I posted here. Please tell me what I can try. Here are the files. https://goo.gl/yRhqaf
Wot
You don't have to import pygame twice. Delete from pygame import * and try again.
Could you elaborate on why you felt inclined to just post 'wot' instead of actually criticizing my post?
Okay, I got it fixed, the problem was that pygame needs a window open in order to respond, thanks for the help though :)
Well, judging by his username I think we can conclude he is of a 'simple mind'- to put it nicely. 
Yeah i know, but there could be any Maya programmer around
Nice verbosity.
I've used a pretty similar project recently : https://github.com/rhiever/reddit-twitter-bot . Not sure what are the pros/cons of each project.
Many thanks, I'll have a look at this.
I was in this same position last week. I learned Flask in just one night sitting at my computer. I can definitely help you when I get home from work later today
Thanks heaps for the help. I must confess to still being a bit lost. The function I'm using to generate the plot is below: plt.plot(ls_x,ls_y, linewidth = var_plotlinewidth, c = var_plotlinecolour) When I try and mangle this into your solution above (and this is all completely user error, I must stress!), I get the following error: Traceback (most recent call last): File "&lt;pyshell#1&gt;", line 1, in &lt;module&gt; ax.spine['top'].set(color = '0.75') AttributeError: 'list' object has no attribute 'spine' Any thoughts?
There is no difference as such. My frustration is none of them are perfect, and require a lot of hack to get what you want. For me, for JS scripting, I use [Google charts](https://developers.google.com/chart/), as it's the only one that worked out of the box. Highcharts- I could never get it to work. Bokeh has terrible and out of date documentation. Matplotlib- while not perfect, gets the job done, usually with a lot of Googling. Like I said, none are perfect :(
Thanks for the reply. Unfortunately, I think my question may not have been clear enough. As I understand it, some X% of the standard library is written in Python itself (in order to help with portability, etc.) - the remainder being written in C. I'm wondering what percentage that is for the most recent releases of Python 2/3. I'm not trying to decide which version to use, just curious about this implementation detail.
I once read a quote that was something like: &gt; Always write code in a way as if the person that has to maintain your code is a violent psychopath that knows where you live.
the entrenched status of psych toolbox (and matlab, for they matter) is frustrating.
Success! You're a bloody genius, thank you VERY much.
Would probably be better to round robin them so the same one doesn't play twice in a row. You can randomly select the audio to start with each time it's run so the first doesn't get played too often.
Yours looks more powerful. Mine ist realy just a basic implementation.
GIANT ANACONDA - WORLD'S BIGGEST PYTHON SNAKE FOUND IN AMAZON RIVER - Longest Python 
I think there are more stdlib modules written in Python than in C - I'd estimate it's maybe 2/3 Python. You can see the files in the Python source: * [Standard library modules in Python in the Lib/ directory](https://hg.python.org/cpython/file/tip/Lib) * [Standard library modules in C in the Modules/ directory](https://hg.python.org/cpython/file/tip/Modules)
All iterables support iteration (by definition), but not all iterables support indexing. A sequence is an iterable that supports indexing, so another way of saying this is that not all iterables are sequences, but all sequences are iterables. This really shouldn't be surprising if you think about it. The ability to iterate over something is a subset of the ability to access an element by numerical index. Obviously if you can support indexing you can support iteration. But there are lots of situations where you can only iterate, but not index, because you don't know how many items the iterable contains, or where they start and end. That's kind of the whole point of iterables, that they abstract away those details. For example a file object is iterable and yields each line of the file when iterated over. But you cannot access lines of a file by index because there is no way to know what offset in the file a specific line begins at, since each line can have a different length. The only way to access lines of a file is by reading them sequentially; random access is impossible. And this can be generalized to the concept of lazy computation, where each item of some iterable is only calculated on demand, rather than creating the whole iterable up front. 
No, there isn't.
Haha, thanks for sharing this. It got some good laughs at the office! ;-) Fits right in with https://github.com/NARKOZ/hacker-scripts
Then rewrite it, from scratch, in Python. Just make sure they validate back to back. The reason it's that entrenched is because it works and it's been validated. Repeat for COBOL, FORTRAN, etc in other industries. 
Timezone aware dates, for a state?
I hadn't been working with python for many years (since 2.5 I think) before that. 
D'oh! Of course that's much better, thank you.
That's an overly-broad topic, worthy of a book in itself. Try this one: what exactly is it that you want to know? What are you trying to accomplish?
Hi Peter, I'm not /u/pysk00l, but I do have some feedback I hope is helpful! First off, though, bokeh has matured into a *fantastic* library and visualization toolkit. With each new release, increasingly-complex applets/visualizations are becoming easier and easier. For instance, I was recently struggling to visualize a very high dimensional analyzed dataset; I had my "high level", publication-quality summary figure ready to go for this analysis, but in order to really dig into what that figure said, I was having to make hundreds and thousands of companion figures that dug into the data in different combinations of variables and over different facets. I really just wanted a quick and easy tool to pull up the figure I wanted on the fly, so I made an interactive viewer in ipywidgets. It... worked... but it was slow an clunky. However, [it was incredibly easy to build the viewer in the latest iteration of bokeh](http://i.imgur.com/FfVfgDp.png), and it's *fast*. Im my tool, the "Hue" tool actually controls what factors are available in the two dropdowns below it; the regressions are computed on the fly using statsmodels, and their summaries are displayed in the table below. The "hue" variable is dynamic; some factors have far more terms than others, but that is reflected in the figure and companion table. The only issue I had with this plot was figuring out a way to do legends. But that was easy enough to fix - the diamonds are the centroids of each faceted part of hte data, and they have a hover element which is colored to indicate what they refer to. I may also go back in to colorize the companion table, too! Re: feedback on the bokeh docs, I think there could be more examples and information how to layout elements using the various containers. I spent quite a while trying to fine-tune the layout on my viewer so that the main canvas would expand yet the controls would remain small, but I just gave up - it was too difficult to try to let one part of the layout grid expand responsively yet others be fixed, but maybe that's not in the current feature set. The actual documents are difficult to use right now for two reasons. First, the "search" tool is useless because it links against old versions of the library and often fishes up deprecated or out-of-date functionality. I think that the "search" should only reference the current release's docs. Second, it would be great to offer an online version of the docs with static examples. The current version takes a really long time to load. And honestly, a gif of the interactive functionality would be totally fine for me - if someone wants to see in detail how the different bokeh elements work, maybe you could offer a link to a separate page where its rendered? Finally, I'd encourage you all to continue to seek out examples from the community, to compile a sort of "cookbook." I'd offer my viewer as an example, if that would help! 
iterator[i:j] could have meant islice(iterator, i, j) or even list(islice(iterator, i, j)) though. I guess they decided that would have been confusing enough.
I don't have one that I've developed, but I've been messing around with [this example activity](http://imgur.com/iWQId9l) that was provided by Enterprise Architect as an example. Do note that this is a Java example, but I was able to generate C++ &amp; C# code from this without a problem. Python still wouldn't generate logic from this while the others would. 
Here's what I did https://github.com/Sayan98/EarthView
THIS IS AWESOME.
I will take another look. I was thinking that all I needed was the zip. Thank you! 
Thanks for the reply uhm I did install Python3 but I do not get it as I already have 3.4 so why do I need python3? But anyways I have both. When doing the above this error occurs: " src/pygame.h:106:10: fatal error: 'SDL.h' file not found" - Pastebin:http://pastebin.com/xNKFyqi0
&gt; dt_timezone = datetime.datetime(2016, 7, 5, 8, 0, tzinfo=pytz.timezone('Europe/Paris')) never ever use `datetime(x, tzinfo=timezone)`, always use `timezone.localize(datetime)` dt_timezone = pytz.timezone('Europe/Paris').localize(datetime.datetime(2016, 7, 5, 8, 0)) arrow.get(dt_timezone).isoformat() '2016-07-05T08:00:00+02:00' This is not a problem with arrow, [but with pytz](https://pypi.python.org/pypi/pytz?) Quote: &gt; Unfortunately using the tzinfo argument of the standard datetime constructors ''does not work'' with pytz for many timezones. &gt; datetime(2002, 10, 27, 12, 0, 0, tzinfo=amsterdam).strftime(fmt) '2002-10-27 12:00:00 LMT+0020' What you get to see when you use the constructor as above, is the very first transition from the Olson DB for that timezone.
Python's socket wrapper is relatively thin, so the performance there will not be a problem. I suggest its a problem in your code and how it scales, or more likely in shitty USB stuff - although to know more would require more testing. Your colleague is almost certainly wrong however, Python socket performance will be sufficient for what you want to do here[1]. [1] I assume this is also true on windows, it certainly is on Linux
Maybe but arrow could fix it since it's misleading and you don't always know how the datetime was constructed when using arrow so you'd expect it to behave correctly.
The last time I tried Bokeh (which was a long time ago), I went to the Quickstart example, (as well as other intro examples), and they *did not work*. Hours of Googling later, I found out that the Bokeh library had moved on, while the docs hadn't. This should never happen- if the library is updated, so should the docs! And something as important as the quickstart, which is the 1st thing newcomers try, should **never** be left out of date. I did eventually get it working, and liked what I saw, but since all the docs were out of date, accomplishing anything was painful. I just gave up. Like /u/counters says, a cookbook would be nice. Don't force me to look in the source code to see how a library works! BTW, this goes for all Continuum Analytic products (was trying Numba, same problems).
Thanks for the input, I appreciate it.
Are you going to cover sound emulation as well? 
Very interested in trying this out! I've been using a rather heavily customized version of Pyglet to do my own gaming (lots of hand-optimized things, modules selectively compiled using Cython, etc.) but I'm curious to try this out and see how it performs. Has this been tested with PyInstaller yet?
Someone should create a package which stores operational data and transforms it into a mock api. Reading these things sounds like you're just setting up another API. Tons of DRY.
I haven't tried it out with PyInstaller. I should give that a go. Thanks for the idea.
If the last time you tried Bokeh was "a long time ago" then why would you make assumptions about the current status? Worse, why would you make public proclamations based on your admittedly out-of-date information? I don't mean to put too fine a point on it, but that is committing *exactly the same sin* that you are complaining about in the first place. To wit, currently: * 100% of the 100% complete reference guide is automatically generated directly from source code * All of the ~200 live plot examples in the users guide, reference guide, gallery, or quickstart that have accompanying source code are generated automatically from the accompanying source code --- if you see a plot at all, it is a *guarantee* that the accompanying code must function We've put a huge effort into automating our docs, build, and test efforts. There's plenty of room for improvement, but I will say this: in 25 years of using open source software, I've seen few projects as comprehensively and thoroughly and automatically documented as Bokeh is *currently*. ~90% of mailing list and stack overflow questions I can answer with a link straight to the docs. Maybe you could try to find things like that out first *before* disparaging the truly long hours and hard work people have made with casual offhand remarks. It's easy to make proclamations about what "should never" happened but the reality is that we are all fallible human beings with all too human limitations. Being an OSS dev on the receiving end of thousands of users' input can be grueling and grinding work. But here's the thing, the value, the true value of OSS is that it *can be a collaboration*. User's don't have to be static actors. Indeed as long as we are bandying should and shouldn'ts --- they *shouldn't* be static actors. If you see a problem, *help make it better*. That is within your power to do. I promise you, your efforts will be appreciated. By me, and every other user as well. 
Hi counters, thanks for the kind words. Can you let us know which pages are most problematic with slow loads? There are two reasons we embed live plots: * it's still difficult to programmatically generate image (long standing issue) But more importantly * making real plots is a valuable check on the documentation validity and consistency. Given that, what might make the best sense would to split up some of the larger pages. Your input would be valuable in guiding that effort. 
I almost like this idea except `iter[i:j]` would mean something different everytime you called it, since iterators aren't rewindable. I suppose you could make it mean: islice(tee(iterator, 1), i, j)) But that's still problematic. 
/r/django
All - This thread has been immensely helpful. I'm in a similar situation where I'm having to use Django with MSSQL. I was able to get the database connection working (Thanks /u/fenoronha !) but now when I try to log in to the admin page I get the following error: &amp;nbsp; &amp;nbsp; 'unicode' object has no attribute 'utcoffset' &amp;nbsp; I've tried the suggestion [here](http://stackoverflow.com/questions/16492031/how-to-fix-this-error-unicode-object-has-no-attribute-tzinfo) but it didn't seem to help. Any suggestions? 
Oh. Well. That answers why some of this seems weird. Thanks. Just allow me to bugger off and get an in depth refresher.
Is is possible to modify the exe and add logging? Log an item once you receive a request from the socket and then again when the exe returns the response. If the duration between the two stays constant while you add devices, it's a problem with the network, but if the exe takes longer to send the response over time, it's a problem with the program. That said, I highly doubt you're saturating the throughput of your network and it's probably a performance issue in the exe.
lol. more useful than most stuff that shows up on this sub. :/ 
I wasn't talking python3 the version but python itself. As most computers come pre-installed or download it from a package manager or python website itself. Thats a pretty standard install but it may not instill in the same path for the environments so when the brew application was trying to run a python command to install stuff it couldn't locate the path it was expecting. So installing 'brew python3' would install python 3.x (I assume the latest) with the appropriate development paths that brew needed for mercurial and other stuff. Anyway, onto your current error. Congrats, you almost had pygame installed! Pip was trying to compile pygame for you but it's missing a required third party dependency. [It's called SDL and can be acquired here](http://www.libsdl.org). You can try running brew to install it, brew install sdl sdl_image sdl_mixer sdl_ttf portmidi If brew gives you that same error as before when trying to install mercurial ("sh: Python not found" something like that) try running brew python3 To have brew install python how it wants to. 
Oh I get it! You're a bot! A really bad one, at that!
Interesting, but could you add a table comparing it to some of the similar libraries out there? I'm thinking Arrow, Delorean, Moment, etc.
I've never used Pythoni, but Pythonista is an amazingly well designed IDE with a lot of cool features: * a UI library and visual design tool * ctypes support for native iOS libraries * tabs * NumPy and Matplotlib support * lots of other useful third-party libraries * an active community forum Pythoni might still be good for a beginner though, so I don't think it's a huge deal what you use at this point. 
Thanks for explaining the python3 thing - I already have installed the SDL libraries. It also says that I have Mercurial 3.8.3 installed. Doing the above "pip3 install http://www.pygame.org/ftp/pygame-1.9.1release.tar.gz" still gives me the error about SDL..
This might be symlink shenanigans. Or, you might have `sudo pip install` in the past and forgotten. After you activate the virtual environment, go through a few of the python aliases: blake@desktop:~$ workon ignis (ignis)blake@desktop:~$ which python /home/blake/.virtualenvs/ignis/bin/python (ignis)blake@desktop:~$ which -a python /home/blake/.virtualenvs/ignis/bin/python /usr/bin/python (ignis)blake@desktop:~$ which -a python2.7 /home/blake/.virtualenvs/ignis/bin/python2.7 /usr/local/bin/python2.7 /usr/bin/python2.7 ^---- resolves to /usr/bin/python
In BlogPostSerializer, you don't want to use TagSerializer to represent tags: tags = TagSerializer(many=True) That gives you a list (with many=True) of *objects*, which get serialized to dicts. What you want is something like a custom PrimaryKeyRelatedField that gives names instead of PKs. For example: class NamedRelatedField(serializers.PrimaryKeyRelatedField): def use_pk_only_optimization(self): return False def to_representation(self, value): return value.name Use this in place of TagSerializer (keeping many=True) and that should be what you're looking for. Alternatively, DRF already provides StringRelatedField, which will do the same thing as the class above since your Tag model's \_\_str__ representation is the name. This kind of question is really better suited to Stack Overflow, to be honest.
[removed]
Make sure your using driver.quit() instead of driver.close() Driver.quit() should kill the session and delete the /tmp files, however driver.close() will not delete the /tmp files. 
From the command line just type python setup.py install I don't know if Mac's still use sudo for privilege escalation (admin) but if so use sudo python setup.py install and it should compile and install it for you if all goes well.
Strange, it seems to be working now and it should have never been down... Thanks for commenting this, although I didn't see it until now because I had no idea this was posted (I run the site)
Odd, it still redirects and refuses to load. When I click [this](http://www.datadependence.com/2016/05/scientific-python-pandas/), it redirects to [this](http://www.datadependence.com/wp-content/cache/page_enhanced/www.datadependence.com/2016/05/scientific-python-pandas/_index). [Proof.](http://puu.sh/pSGDn/5c6066ee75.png)
I think you were right with the USB guess. See Edit
It's a black box for me and prohibitive as a result. But, check my edit.
Short version: self is always the first parameter for a function inside a class. That way the function knows on which instance it should act. [This post explains it in detail](https://pythontips.com/2013/08/07/the-self-variable-in-python-explained/)
Then, in my example, it is obligatory "self.age = 25" instead "age = 25" ? Sorry for the questions, but I'm a completely begginer and I'm learning English too XD.
This probably isn't the best place to have the discussion but out of interest have you used MongoDB and struggled to implement a solution vs. PostgreSQL? If so I'd genuinely be interested to hear. I've used MongoDB for appox. 4 years now on quite a few projects and whilst I've not used PostgreSQL (other than to play around with briefly) I've used MySQL on projects for around 10 years. For both MongoDB and MySQL/MariaDB I have websites with between 500k and 1.5m page requests a month (so nothing too busy) and to date for projects up to this size I've not had any real difficulty in using either. My preference at the moment (I'm fickle) is for MongoDB on most of my projects and if I push myself to answer why (which I have to because I really don't have a very strong preference) I think it's purely because I like thinking about data structures in flexible dictionaries rather than typed flat tables (PostgreSQL JSON fields excluded - which I believe MariaDB also supports now), it just feels closer to the Python structures I'll use to interact with the data - but I'm not saying that's a great reason just my 2 cents. At the end of the day I guess I'm a slave for whatever I enjoy using the most (or dislike the least) and so unless a particular option is going to bite me in the butt somewhere down the line (hence if you have knowledge of this please share) I just don't see the issue with using one or the other for most projects.
hey josh
Wow. /r/learnpython. Just like the sidebar says. Or use Google. Or pick up a book. Jeez.
Counters that example looks fantastic, would you have any interest in writing something up in our new project blog? 
Hmmm bizarre. It loads fine for me on two laptops a phone and a tablet and there is a steady stream of traffic to it... Have you maybe got something cached? I'll clear my sites cache for good measure too.
That's pretty damn cool! I'm currently working on finding duplicates in real estate posts =&gt; http://nemutam.com/duplicate/21058-apartament-de-inchiriat-2-camere-in-cluj-napoca-cartierul-plopilor and I've been experimenting with http://blockhash.io/ and https://github.com/polachok/py-phash/tree/python3. I will have to run some tests using your implementation as well.
Except that it has been. [Psychopy](http://www.psychopy.org/). The folks over there work hard at trying to displace psych toolbox. The reason it's slow going is not just because it works and is validated (albeit that is very central to it). It's because change and turnover don't happen unless people unfamiliar with the entrenched tech have a choice and get to choose the better one (ref. [The homogenization of scientific computing, or why Python is steadily eating other languages’ lunch](http://www.talyarkoni.org/blog/2013/11/18/the-homogenization-of-scientific-computing-or-why-python-is-steadily-eating-other-languages-lunch/)), or the new option is so much better than people are forced to change in order to stay relevant (ref. deep learning). It'll happen. Eventually. There's no way I'm going to be the one to instigate it. I'm a 5th year phd. I barely have enough emotional energy to answer the phone. 
Wow what a naive way of looking at it. a repo with stars and forks shows maturity. More bugs are found, more features are being added. But go whine some more you hack
&gt; import schadenfreude 
Thanks for sharing, seems pretty useful.
It has and will continue to be released under the MIT License. The question is how much the API might change. At this point only about ten people have developed with it. I'd like a wider audience to give feedback before locking in the API.
That's why I'm confused. I found the same documentation but it doesn't seem to fully describe the situation.
If your search engine is broken you can use mine - https://duckduckgo.com 
Did you manage to glue your shift key down in the process?
4.4 is not "4.4". It's 4.400000000000000000000000000000000000000001. You can't represent some numbers using exponents of two like we try to do with binary computers. So, 44 / (4.4+epsilon) == something slightly less than 10, which rounds down to 9.
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
But you see double precision errors &gt;&gt;&gt; 0.1 + 0.2 0.30000000000000004 However in this case: &gt;&gt;&gt; 44.0 / 4.4 4.4 It appears exact. So how is the second different from the first?
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Yes, I've clicked the original link and it works. Also with or without slashes works. Are you still having problems?
What's happening here? &gt;&gt;&gt; 0.1 + 0.2 == 0.3 False &gt;&gt;&gt; 2.2 + 2.2 == 4.4 True &gt; 44 / 10 == 4.4 True It's clearly not just print lying. I know doubles have limited precision but at what point is the error introduced?
But why does `math.floor(44/4.4) == 10` but `44//4.4 == 9`?
Rounding is not what integer division does. Try math.floor() .
That doesn't explain why, if 4.4 cannot be represented exactly, that 44/10 compares equal to 4.4 and 0.1+0.2 doesn't compare equal to 0.3.
 &gt;&gt;&gt; 0.1+0.2 == 0.3 + 0.00000000000000003
You shouldn't use == or the equivalent to check equality of floats, in any language. "less broken" code: &gt;&gt;&gt; import sys &gt;&gt;&gt; e = sys.float_info.epsilon &gt;&gt;&gt; diff = abs((0.1 + 0.2) - 0.3) &gt;&gt;&gt; diff &lt; e True (genuinely correct code would pick a tailored error margin rather than going with the minimum error margin, though. And do a few other things explained in the first link below.) Explanatory links: * [relatively simple summary](http://floating-point-gui.de/errors/comparison/) * [detail](http://docs.oracle.com/cd/E19957-01/806-3568/ncg_goldberg.html) EDIT: as you point out in your later reply, `math.isclose` does the generally correct thing here. EDIT2: .. people should still take the time to read it's documentation, because floating point comparison just plain isn't as straightforward as integer comparison.
It was a typo; i fixed it almost immediately.
I thought it did. When you evaluated 44/10, you got a value that has one approximation error in it. When you evaluated 0.3, you got an value with one approx error in it. When you evaled 0.1, you got one approx err. When you evaled 0.2, you got one approx err. When you added those last two, you got an error added to an error, which does not equal one error.
I learned the hard way. In pulling a number out of a database and comparing it to an expected value, it was not the same. 0.1 != 0.1 because 0.999999999999999999999999 != 0.100000000000000000000000001 . I went crazy for a few hours debugging.
In python, there is `math.isclose()` for this
By that logic adding a third number should fix it ... I don't think the hardware works quite in this manner. Anyway I worked out why the thing's not working. it's because the docs are wrong or ambiguous or we can't read them properly. See the other post.
The `4.4` is actually very slightly larger than `4.4` because of the limitations of limited-precision floating point representation: &gt;&gt;&gt; '%.50f' % (4.4) '4.40000000000000035527136788005009293556213378906250' `4.5` is exactly represented, and `4.6` is slightly under, which is why their corresponding versions of your test calculation both return `10.0`: &gt;&gt;&gt; '%.50f' % (4.5) '4.50000000000000000000000000000000000000000000000000' &gt;&gt;&gt; 45 // 4.5 10.0 &gt;&gt;&gt; '%.50f' % (4.6) '4.59999999999999964472863211994990706443786621093750' &gt;&gt;&gt; 46 // 4.6 10.0 The next one, `4.7`, is again slightly *over*, resulting in a `9.0`: &gt;&gt;&gt; '%.50f' % (4.7) '4.70000000000000017763568394002504646778106689453125' &gt;&gt;&gt; 47 // 4.7 9.0 One way to avoid this problem is with the `decimal` standard library module: &gt;&gt;&gt; from decimal import Decimal &gt;&gt;&gt; 44 // Decimal('4.4') Decimal('10') 
This doesn't really answer the 'Why' or the 'How' in your title. It really just addresses things you didn't like in Python while trying to build a website. &gt;how Erlang is able to solve those specific problems for me It never really answered this either. It's not much more than just complaining in my opinion, but I am a programming newbro, so what do I know? Also, it might be beneficial to have someone read over your writing to check for errors in the future.
Yes, that makes sense. What doesn't make sense is why `math.floor(44/4.4)` is any different than `44//4.4`. I was expecting them to be the same and I'd like the rationale for why they should be different.
I... don't know what this is. 
## STORY TIME When I was maybe 8, my dad picked up a Pascal (this was in the early 90s) compiler for a programming class he was taking. I asked him what it did, and he told me that it let you make your own programs. Eightyear old me was like "games are programs, right? **I'm gonna learn how to write my own games!!!** Now as you can imagine I had very little success in learning how to write the beautiful platformers that I envisioned using vanilla Pascal in a pre-internet world. If simple, well documented libraries like yours had been around, things would have gone differently! I read through some of the examples and I think you've made a really excellent tool to get kids into programming. Well done! I'd be remiss not to suggest an improvement. Some of the examples use trigonometry. Obviously this is essential, but I wonder if adding some geometry helper functions might make the library more accessible to people who aren't comfortable with that kind of math? For example, instead of the cryptic `atan2`, you could have a function like `angle_from_horizontal(point_a, point_b)`
Well that I'm not sure of; the name of the file is pyHook-1.5.1-cp27-none-win32_amd64.whl and I've tried Python 2.7 and Python 3, but maybe it's different compiler versions or something? Sorry for the dumb questions, I'm coming from a java/c# background so this is all new to me.
Just to clarify I am not the author, I found this article on HN and shared it here 
Looks to me like `pip` can't find pyHook. Try installing the correct wheel from here: http://www.lfd.uci.edu/~gohlke/pythonlibs/#pyhook Oops, should also be clear, which OS are you running?
Ceci n'est pas une pipe.
The internal representation is none of our business. You can depend on nothing, except that an value will be within some margin of the hoped-for number. Every time you see "actual == expected" with relation to floating-point, it should be "abs(expected-actual) &lt;= margin" or you're doing it wrong.
Nothing I do reproduces the error. I've tried on vpns, on a different network on a different PC that has never accessed my site and it works every time. I'll keep looking into it but it appears t be working.
&gt; When you added those last two, you got an error added to an error, which does not equal one error. There are two possible cases : you get either zero or two errors. The former case occurs when the errors are equal and opposite. (of course, a single error may be added in either case, when storing the result) Example: lo = 1 - sys.float_info.epsilon hi = 1 + sys.float_info.epsilon '%.20f' % (lo + hi) '2.00000000000000000000'
This is very interesting, and I can't wait to check it out. I would love to see an easy-to-use Python framework for teaching gamedev (I teach Python and gamedev to 11-14 year olds). I recently checked out Love 2D after hearing so many good things about it, and I was really impressed. It has a great community, wide 3rd party library support, ease of distribution (.love files are brilliant), supports desktop &amp; mobile... If only it were Python! I've been using Pygame, but while it's easy to use, it's a bummer to install, distribution is nigh impossible, and it's getting pretty long in the tooth (SDL). Not to mention its embarrassment of a website. Do you have a roadmap? What's the ultimate goal of the project? Are you interested in feedback from an educational perspective?
&gt; Your "print" function lies to you when it can, to make you happier. And to make you sad, when you try to understand what's really going on.
You need to see the problem in base 10. `1/3=0.3333 repeating`. `0.3333 repeating * 3 = 0.99999 repeating`. Is ``1/3 *3 = 1`? Depends on if I have infinite precision. On paper, I do. There are numbers in base 10, you can represent perfectly and there are numbers you have to truncate. Same is true for base 2, but it's much worse.
The *binary float* 0.1 is not quite the same as the decimal number 1/10, but as close as you can possibly get in the limited precision of a float. Likewise the *binary float* 0.2 is not quite the same as the decimal number 2/10, and 0.3 is not quite the same as 3/10. Add 0.1 and 0.2 together, and you get something not quite the same as 3/10, because the error in 0.1 and the error in 0.2 reinforce, so you get something *even more wrong* than 0.3: py&gt; 0.1 + 0.2 0.30000000000000004 So 0.1+0.2 != 0.3. 44 and 10 can both be represented *exactly* as binary floats. (Floats can represent all integers exactly up to about 2**53 or so.) When you divide them, you get a binary float which is *not quite* the decimal number 44/10, but *just so happens* to equal the binary float 4.4. That's just the way floats work: sometimes errors add to give you a bigger error, sometimes they cancel to give you a smaller error. The fractions module is good for seeing the exact difference between a float and the float display: py&gt; from fractions import Fraction as F py&gt; F(0.1) - F(1, 10) Fraction(1, 180143985094819840) py&gt; F(0.2) - F(2, 10) Fraction(1, 90071992547409920) 
&gt; You shouldn't use == or the equivalent to check equality of floats, in any language. That's superstition. If you start adding arbitrary fuzz to your comparisons just because some cargo-cult developer told you never to use `==`, you're going to run into problems. Just because some floating point calculations are inexact doesn't mean that they all are, and it certainly doesn't mean that using an inexact test is *always* the right solution. Sometimes you need an inexact test with a "fuzz factor", sometimes you need an exact comparison. And no, using `math.isclose` doesn't help, because you still need to decide *when* to use `isclose`, whether to use an absolute or relative comparison, and how big a fuzz factor you should use.
What makes you think that they *should* be compared as equal? To me, I would say that they clearly are not equal: the errors are in the opposite direction. One is big than 0.1, the other is smaller than 0.1, I'd be very reluctant to say they equaled each other. If I ran a calculation that was supposed to give an answer *strictly no less* than 0.1 and got `0.09999...` I wouldn't say "oh that's close enough". It's clearly an error, and unless I understood the error, I 'd be doing the wrong thing by accepting this as "close enough". I assume that you meant `0.0999...` rather than `0.9999...` since what you typed is almost 1, not 0.1. 
Right. I thought they were equal because printing the value said "0.1" in both cases. It's only hindsight and a debugger that let me type the two long numbers above. At the time, they sure looked equal. --- edit: More specifically and simplified, it looked something like &gt;&gt;&gt; val, = sql_odbc_to_oracle_server("select 0.1") &gt;&gt;&gt; print val 0.1 &gt;&gt;&gt; val == 0.1 False
Ah. *floor division* gives you the `divmod` quotient: &gt;&gt;&gt; q, r = divmod(44, 4.4) &gt;&gt;&gt; q 9.0 &gt;&gt;&gt; r 4.399999999999997 The `9` is what you get from the floor division operator. `math.floor()` has nothing to with it. Using true division, you already have a perfect `10.0` before even calling `floor()`: &gt;&gt;&gt; '%.50f' % (44 / 4.4) '10.00000000000000000000000000000000000000000000000000' The answer for the true division can be calculated from the `divmod()` results, as a check. You have to add the quotient and the fractional remainder: &gt;&gt;&gt; '%.50f' % (q + r / 4.4) '10.00000000000000000000000000000000000000000000000000' It turns out that the most accurate representable number for this operation is exactly 10. This is what you get from `44 / 4.4`. 
did you even read the article ? P.S. there is not a single line of erlang code in the article.
In my opinion Solarized dark is a perfect colorscheme for python.
The only 'quickfix' that I can think of would be to tune the IDE JVM settings.
Disable inspections and plugins you don't use
Personally I find a fully featured IDE a bit 'too complicated for beginners'. Especially since I firmly believe that failing (the compiler/interpreter telling you 'no') helps you understand better what your fault was, than the error messages in IDEs. For beginners I would say that IDLE/Geany/Notepad++/SublimeText/Atom or whatever editor you prefer is fully sufficient for beginners.
For Python I used to use neovim with a shitload of plugins (like jedi etc), and now I switched to emacs with spacemacs and the python layer. The Python layer in spacemacs has a lot of features that makes it 'IDE-esque' and I find it really comfortable to navigate my code in emacs. Although generally whatever commenters will say here will boil down to 'check out the IDEs and check what feels most comfortable for you'
As specified: you can turn things off. But that negates the point of having PyCharm to some extent. "Turn off the things you don't need" implies that you know what you need, which of course you don't!
Search before posting. There's another thread posted today about the exact same thing! That being said: use PyCharm. It will help you learn faster and make fewer mistakes when you are experienced. 
Gruvbox
Nice article. However, I discourage use of Lena. If you've ever seen the full age, it's from a porn magazine. I don't like the message it sends. 
doesn't yaml already have support for custom objects? %TAG !neon! tag:ne-on.org,2010:neon/ an_object: !neon!entity {type: int, nulls: yes}
[Molokai](https://github.com/tomasr/molokai/blob/master/README.md)
I'm a big fan of [seoul256](https://github.com/junegunn/seoul256.vim ).
Or just adapt an off the shelf one https://github.com/mesosphere/marathon-autoscale
Also my choice.
I agree, but I do think PyCharm is a little too 'busy' for a total beginner. Also, having to set everything you do up as a project is a nuisance when you're just doing basic stuff. I would recommend the free version of Wing IDE as a nice middle ground. It still warns you of syntax errors etc (though autocomplete is not available) and you can run scripts directly, but it has a much less daunting interface, and you can just start writing a script and name/save it when you're ready to run it. That said, PyCharm is certainly superior for anyone who has a reasonable footing and wants to get serious. And if you are determined not to be put off by things which may seem unnecessary/messy/fussy at first on faith that its best practice in the long run, you may as well start with PyCharm.
[Apprentice](https://github.com/romainl/Apprentice)
That's not entirely true. Jetbrains tools usually come with things like SVN support enabled by default, or in the 2016 pycharm series, warnings for python2-3 incompatibility. You can't know everything that you don't need but you can certainly know *some* of what you don't need.
I like the [kooten-theme](https://github.com/kootenpv/emacs-kooten-theme) (high contrast between soft colors). Oops, that is Emacs :-)
I think you misspelled Emacs
Gruvbox dark or darkblue.
Get outta here, you heathen!
(small enough) Integers are exactly represented. So 44 is 44, and 10 is 10, exactly with no loss of precision. "4.4" is just a string, and the intepretation of that string is 44/10, and so 4.4 == 44.0/10.0 exactly. The inexactness is that the decimal representation of 4.4 is not 4.4... not that 4.4 is not 44/10. When the CPU attempts to compute 44/10, it takes two exact quantities (44 and 10) and divides them. It ends up with an expression 4 + 1/4 + 1/8 + 1/64 + ... + some really small stuff that cannot be represented as a power of two. So in binary 4.4 is 10.011001... which gets rounded to the closest value, but printed as 4.4. 0.1, 0.2, 0.3 are respectively 1/10, 2/10, 3/10. None of which can be represented exactly. All three have rounding errors. What is awkward is that 0.1 and 0.2 both round up when you attempt to compute 1/10 and 2/10 in base 2. That means that 0.1+0.2 has a rounding error and ends up that 0.1+0.2 &gt; 0.3 In other words its not any different than when a you add up a pie chart and see that the total is greater than 100%. In essence 0.1 and 0.2 are 34% and 67% respectively of 0.3.
+1 Use molokai for just about everything
Thanks, I ended up using the StringRelatedField which worked but I'll look into PrimaryKeyRelatedField for next time I run into a data representation issue. Thanks!!
&gt; Metaclasses are deeper magic than 99% of users should ever worry about. If you wonder whether you need them, you don’t (the people who actually need them know with certainty that they need them, and don’t need an explanation about why). -Tim Peters 
I use it occasionally. I like it a lot but it is quite unusable after ~30 minutes (on a Mac). It eats up so much memory that it brings everything to a halt. I really really want to use it (I love R Studio) but the memory keeps me from it. Edit: spelling
Yes. Though I prefer the light versions. I never liked dark background work. I also like that I use Solarized on my work machines (where I do 99% of all coding, even at home for personal stuff) and regular white at home. It reminds me of the distinction
Hey now...I see a version 2.0 from Rodeo. I will be giving it a try. The review above is for v 1.2 and previous.
Highly reccomend WingIDE. Its debugging functionality is at least as powerful as PyCharm - and it's many many times faster. The pro version costs money, but they have a 30 day demo (that can usually be extended forever - I bought it anyway). Wing is much cleaner and focused on just Python debugging - for an introductory course I would think that PyCharm's "Everything and the kitchen sink" approach could be a bit overwhelming
I tend to stay away from Desktop apps built on Electron.
I could not figure out how it would be better for me than jupyter notebooks, so I spent little time with Rodeo.
solarized dark!
That's pretty dope. Deep Neural Networks are something I have been eyeing for a while, and this provides a gentle introduction. Now to come up with an awesome project to do with them.... 
I like railscasts.
&gt; That doesn't explain why, if 4.4 cannot be represented exactly, that 44/10 compares equal to 4.4 and 0.1+0.2 doesn't compare equal to 0.3. Argh, so many misguided answers! Here, look at this: In [48]: def bf(f): ....: return '{:064b}'.format(ctypes.c_ulonglong.from_buffer(ctypes.c_double(f)).value) In [54]: for i in [-0.1, 0.1, 0.2, 0.4]: print('{:&lt;4}: {}'.format(i, bf(i))) -0.1: 0b1011111110111001100110011001100110011001100110011001100110011010 0.1 : 0b0011111110111001100110011001100110011001100110011001100110011010 0.2 : 0b0011111111001001100110011001100110011001100110011001100110011010 0.4 : 0b0011111111011001100110011001100110011001100110011001100110011010 The function takes a float and returns its binary representation (Python uses 64bit floats). The first bit is sign, then 11 exponent bits (in a biased-by-1023 representation (i.e. you have to subtract 1023 from it to get the actual exponent), then goes the mantissa with implicit 1. The important thing is that as you can see, mantissa stays the same. In fact, I did some experiments and it seems that it is always so: adding a number to itself is always the same as multiplying it by two, and that does not introduce any further rounding errors because it just increments the mantissa by 1. Obviously I can't be bothered to trawl through the IEEE 754 standard to see if it's actually mandated, and nobody seems to have asked the question on SO already (that I could find).
I ended up posting on Stack Overflow and got an answer that helped out. Here's the solution for anyone else that looks at this thread: http://stackoverflow.com/questions/38230267/django-unicode-object-has-no-attribute-tzinfo-error-using-django-pyodbc-azu
Check out spf13 it comes with a bunch of plugins including solarized color scheme and is easy to uninstall if you don't like it 
Apparently not
I'm very interested in feedback from an educational perspective. I manage http://ProgramArcadeGames.com which is a first-semester course using Python and Pygame. I love Pygame, but like you said, it has issues and there's no progress towards taking care of those issues.
I've tried to make the interface more consistent and easier to use. The drawing primitives are better and don't have those weird bugs Pygame has with thick arcs and circles. It has a physics engine for platformers. Animated sprite support is built in. Oh, and a turn-based example would be a great idea. I'll add it to the list. Thanks.
Thanks for the reply. I was considering using pyparsing or ply (which we've used at work in a different project). In the end I decided not to use any pre-existing library mainly because I thought it would be more fun and maybe teach me more I guess.
base16-eighties
Any benchmarks/references baking these information ? Or this is pure evidence ? 
That would be a great place to list out issues that you run into. Thanks!
Darcula https://github.com/blueshirts/darcula Edit: wrong link and a letter
PyCharm is MUCH more intelligent than vim is: def foo(a): return a.b foo(5) # &lt;- error! Int does not have a member b There are VI key bindings for PyCharm if that's your thing. 
Just spent a few hours playing around with v2.0. I don't see myself using it much....its even more unstable for me than previous versions.
PEBKAC...
hey michael, when i first started learning python i watched a lot of your tutorials. Heres an API/service mocking tool i built recently. id love to hear some feedback on it from you. https://github.com/ThriceGood/Mimic/ 
It's essentially a fork of Chromium, using node.js for scripting purposes. So the benefit is you have a very mature desktop app as your foundation, and you can build desktop apps with reasonably fast performance that are Windows/Mac/Linux cross-platform from day one. The downside is, Chromium has a non-trivial memory footprint. If you're the type of dev to work with lower-end hardware, you may find it sluggish. If you're the type to buy a laptop with a Core i7 and 16GB RAM and say fuck it, then it'll probably run just fine.
Thank you! I know this is a VIM thread, but added this color scheme to PyCharm and loving it!
Honestly `-Xms 512m -Xmx 1024m` is generally the sweet spot for most setups regardless of specs, a larger heap may reduce the total number of GC runs but it will also make them take substantially longer. If I have lots of plugins installed (like I do with my full IntelliJ setup) I may increase the max heap size further to accommodate the increased classpath + long-lived plugin data size, but it's not something that MOST PyCharm users would need to worry about.
It's a variable that is None
oh please, just install app and launch Activity Monitor or Task Manager
Average! It's free and open source that's plus!
I like this layout more than the Jupyter layout. Mainly, I like having dedicated panes for a console and for documentation (otherwise, I find myself google things that are in docstrings because its actually faster). You can also find this type of layout in Spyder. However, with a Jupyter Notebook, I like the ability to have outputs in the same document as the code. Great for reporting an analysis and the results. I wonder if the ideal would be to have a jupyter notebook in the left half of a screen, with the upper-right corner holding a pane for documentation (and current variables? though I never use those), and a lower pane holding a terminal with the same backend kernel as the notebook.
The only thing I don't understand about the expression support is, why not just support Python functions? i.e., why not make this, &gt; aes(x='np.log(B - A)') into &gt; aes(x=lambda A,B: np.log(B-A)) i mean, i assume that string is eventually eval'ed anyways, so why not just take a function as the argument? ok, i can see that handling selection of arguments to that function might get a little complicated.. but surely there's a more pythonic solution than string passing.
&gt; food_pinching_effeciency oooooh... a field name is a bad place to have a typo... XD hope it's just the website
It seems like matplotlib has more of a modular/ object-oriented interface. However, it also has a lot of redundancy which is not very pythonic. Also, it's shit. (disclaimer: personal opinion)
That is correct. There have been a few different attempts; toyplot is pretty nice although not very powerful.
So how do I utilize the libraries so I could run it on Windows, even though I'm writing it on Linux? 
Isn't it just: bs = [i for i in range(256) if i &amp; 128 == 0] 
if goes after the for. In a comprehension the variables are defined left right, with the sole exception being the value recorded in the comprehension itself. So your example won't parse. What makes things confusing is the construction: `[1 if x else 0 for x in list]` which is really `[TERNARY for x in list]`. `1 if x else 0` is treated as a single expression. So `[x for sublist in list for x in sublist if test(x)]` is valid and first extracts sublist from list, and then x from sublist and then tests x, and then constructs a list from only those x that pass. `[x if test(x) for x in sublist for sublist in list]` would not parse for two reasons. 1. The incomplete ternery `x if test(x) ????` needs an `else something` 2. The `x in sublist` would fail because sublist doesn't exist until `for sublist in list`.
What about bokeh?
Hey thanks for replying. So the web socets provide the connection between the server end and the client or user's end. How would the graphics and actual movements in the game be done? would that be a browser language?
Flask is great and there's a 'flask-restless' framework that makes this kinda thing super easy. I've no experience with falcon though so I can't really comment on that.
I'm looking right now and it appears to be very well documented. Can you post a link to the page you're talking about? 
Because that would be evaluated before `aes` is called.
What drove me to abandon matplotlib was that changing one part of the layout would screw up another. Like, change the label font and the margins move. I ended up making a thin wrapper library that piped to gnuplot.
You mileage may vary ;)
Here's a very informal account of how the main [User Guide](http://bokeh.pydata.org/en/latest/docs/user_guide.html) pages load on my (old) workhorse MBP using Chrome (Version 51.0.2704.103) - [Quickstart](http://bokeh.pydata.org/en/latest/docs/user_guide/quickstart.html#userguide-quickstart) - pretty fast; functional after about 2 seconds - [Getting Set up](http://bokeh.pydata.org/en/latest/docs/user_guide/setup.html) - no interactive elements to delay loading - [Defining Key Concepts](http://bokeh.pydata.org/en/latest/docs/user_guide/concepts.html) - ~6 seconds - [Plotting with Basic Glyphs](http://bokeh.pydata.org/en/latest/docs/user_guide/plotting.html) - this is one of the problem pages; it took about 12 seconds to load, the entire time which my browser was frozen (couldn't scroll or change tabs) - [Making High-level Charts](http://bokeh.pydata.org/en/latest/docs/user_guide/charts.html) - also a bit slow, about 11 seconds to load - [Leveraging Other Libraries](http://bokeh.pydata.org/en/latest/docs/user_guide/compat.html) - no problems - [Styling Visual Attributes](http://bokeh.pydata.org/en/latest/docs/user_guide/styling.html) - ~10 seconds -[Configuring Tools](http://bokeh.pydata.org/en/latest/docs/user_guide/tools.html) - ~3 seconds - [Laying out Plots and Widgets](http://bokeh.pydata.org/en/latest/docs/user_guide/layout.html) - ~4 seconds - [Working in the notebook](http://bokeh.pydata.org/en/latest/docs/user_guide/notebook.html) - No problems - [Adding Interactions](http://bokeh.pydata.org/en/latest/docs/user_guide/interaction.html)- ~5 seconds The rest of the pages don't really load interactive plots, so they're fine. Breaking up pages is a good idea. The real issue to address is that the pages that load the slowest are the most important ones - the ones that show examples of all the various styling options and whatnot. These are what I want to constantly refer to when I'm flipping through the docs (moreso than the API/Reference), but I don't necessarily want to have all of them pre-loaded in a separate browser window (that's my go-to solution right now). Hope this helps!
Coming from R, I love it... but I don't have much reason to code, so I haven't spent a lot of time in it and don't really have anything I like better. I don't really have any issues in Windows.
There's a "power save mode" but it turns most of the useful stuff off. Honestly, having tried a few Python IDE's, I'd live with a bit of sluggishness if I were you. Komodo (second place) is much slower. Do you know about PyCharm Edu?
thanks!
Did you miss-spell "Dracula" or use the wrong link? I'm off to hunt for a Darkula VIM theme now. 
Could you give me some pointers/directions to making somethign like this? I would love to scrape certain stuff to add to my google calendar.
The direct route is to make a folder called 'colors', inside your vim user folder ( which you'll have to locate if you have not yet. ) Then you put colorscheme files in there and they'll be available. Or, leave that up to your package-manager and just add the necessary lines to install the colorschemes you want. As for reference, reading the comments in the actual file is often the best way to go. Often there will be global configuration vars you can set and the instructions on that tend to be in the comments.
 i &amp; 128 == 0 is the pass case, so what you really want is: bs = [i for i in range(256) if i &amp; 128 != 0]
Hey All, we just pushed 2.0.5 (just for Mac / Linux; Windows folks we're real close to a 2.0 release), better doc-strings and some data-type viewing. You can get it [here](https://www.yhat.com/products/rodeo/). 
Restless is hamfisted and believes you want to map your database tables straight to API endpoints. Which, if you want to do that, then that's your best bet. Restful is my poison of choice since it's more of a small toolkit for building APIs. 
We have limiter experience but we built a small project in Flask first and found that we need security and we needed this and that and then realised we were replicating the functionality that django had so we went with that. 
Hey tea-drinker, Im brazilian and not even close to be a fluent english speaker :-D Oh and by the way, thanks a lot for helping me, i dont know why I was using "//" :/ 
I too have longed for such a solution to no avail. AFAIK, no such solution exists. Matplotlib does have a OO interface that I tried using exclusively for a while, but it's ultimately not so good.
What OS are you running it on? On Linux I found that the UI style it used drastically changed the performance. I don't know how much choice you have on Windows or OS X though. Other than that, as suggested you can look into jvm config changes to increase the amount of memory it can use and that may help a little. What are the specs of the system you're running it on?
What you want is something that let you do your jobs most naturally, most intuitively without headaches of having to look up something. 
$89 per year with the discount if you were wondering
What's wrong with matplotlib?
Seaborn serves those that want/use matplotlib but want it to look prettier. Ggplot serves r users of Ggplot or those that think the grammar of graphics style is cool. 
Wow, this has got to be one of the most practical machine-learning and data-analysis guides I've seen put on here. 10/10, I learned about the 'cut' function in pandas, and several modules in sklearn that can make my life easier.
yes, it comes to my mind that vim is so powerful,but it is a little bit for vim to do as an IDE,its code complete from the Youcompleteme plugin just using some buffer thing.i do love it ,but i realize that it is time for me to change ,so i switch to educational PyCharm 
Okay, thanks. I was thinking in terms of generating figures to illustrate data and models in general.
[Spacegray](https://github.com/ajh17/Spacegray.vim)
&gt; but that's too hackish. and extracting the information from the outer frame when parsing a string is less hackish?
&gt; Writing an API that depends on correctly naming a function argument what has that got to do with anything? This is how the evaluation environment is built up https://github.com/pydata/patsy/blob/master/patsy/eval.py#L195 plenty of people have done this over and over, but it always fails on one issue, non-local variables, which means that some programs will behave unexpectedly swapping `'pd.yaddayadda(B)'` to `lambda: pd.yaddayadda(B)` will pull from non-locals as expected, but be harder (but less hacky) to make use of
base16 default, simplicity and consistency at the tty. 16 colors give me enough lexical/syntactical hints. Much more than that tends to distract me. I use vim because I want a more or less zen experience.
The problem is just that there are too many things that you might want to customize in a plot. And to do specific things like "rotate the x axis labels", you'll always need to learn some specific syntax.
Do you support Linux or just Ubuntu? I only see a `.deb` for download.
No thank you, sorry for not being able to do anything...
That's why the new fake static typing in 3.5 is awesome.
Badwolf or Papercolor
You take that back.
what have you done
There are 3 APIs, 2 of which are sort of documented (one is very much like Matlab, the other is Python-esque). One is good (the largely undocumented one). I say sort of because the arguments are wrappers around `*args and **kwargs`. That's not helpful. The fast one is just horrific.
["No", "Yes"][True]
The Lenna and Barbara images are kind of industry standard for testing images. I have no idea how it happened :)
Try constructing a minimal code example demonstrating your problem and posting it here. You will likely find your bug in the process.
It's actually not too bad if you approach it in its object oriented manner. Here is a good link : http://nbviewer.jupyter.org/github/jrjohansson/scientific-python-lectures/blob/master/Lecture-4-Matplotlib.ipynb
If you're developing only for Windows you should be developing on Windows. If you're trying to develop for multiple platforms you should be prepared to put in some code that distinguishes between platforms.
They also seem to have signed the [Python 3 Statement](http://python3statement.github.io/). 
I don't think the library would pass A and B in. Instead the library would pass the dataframe into the function. That's how I did it when I wrote an implementation of ggplot in JavaScript and it worked rather well. Allowing a function to be passed in allows for much more flexibility.
Is it weird that the syntax highlighting and line-wise movements *really* excite me?
Yes... too lazy for that. Also, at home I'm a Windows user. It's a little more complicated to install things here. You know, downloading the installer, double clicking, clicking on "next", "next", "next"... "install"... "finish"... 
Is anybody else getting NameError: name 'unicode' is not defined It seems to be broken for me.
The problem is it was built to copy the shitty Matlab API. Just use the OO API and ditch pyplot.
What a load of crap &gt; 0.10.0 also marks a shift in project goals for python-ggplot. While the initial &gt; intention was to mimic the R-ggplot API, it's now clear that this isn't 100% &gt; neccessary (and can make for some really strange looking code). Congratulations, you didn't learn the easiest lesson to learn from matplotlib - that copying the API from a foreign language is a bad idea. And then you call Matplotlib a bastard. yhat are not serious developers. I wonder how long before they abandon python-ggplot again. I guess it depends how much free press this gets them. &gt; ggplot 0.10.0 introduces the ability to customize your own themes. yay, now you are adding features that matplotlib already has. &gt; aes(x='np.log(B - A)') yay you learned about exec. this should be fun &gt; The faceting system has been rebuilt from the ground up congratulations your faceting system is now worse than seaborn &gt; I still strongly believe that there's a place for ggplot in the python data ecosystem OK.
I was hoping to see Jupyter Notebook UI redesign. Great release though!
It depends on how complicated the website is. The "right" way to do it, would be through BeautifulSoup and the Google Python API (both easy to find on Google). If it's more simple, you could replace BeautifulSoup with regex or just a simple string search for the things you need. There's really not much to it. I think my (horribly unreadable) code ended up as about 100 lines.
In LabView I've written myself at the moment, just to prove it works.
I just updated to the 5.0 release. Multi-line editing is fantastic. The old behaviour was one of the main reasons it didn't use the console-based iPython very much.
Yes, its actually with a "C", Darcula. :) and Wrong link as well https://github.com/blueshirts/darcula http://imgur.com/a/yQmmO
As far as I understand the post, IPython 6 requires python3 to run, but you can use it to interact with a python2 kernel, and thus continue to write and run python2 code.
That's a different project, with a different release schedule. I hope they release easy skinning, I'd love to utilize the entire width of my window, as I often try to squeeze in two side-by-side windows on my 13" and the notebook still draws a lot of margin.
Did anybody just as impatient as me, manage to install ipython 5 in an Anaconda virtual environment? I get the following error: Installing collected packages: setuptools, wcwidth, prompt-toolkit, pexpect, ipython Found existing installation: setuptools 23.0.0 Cannot remove entries from nonexistent file /Users/user_name/anaconda3/envs/py27/lib/python2.7/site-packages/easy-install.pth *Edit* I hate being that guy writing "never mind i fixed it" and then not post a solution, but I reinstalled and uninstalled everything ipython and jupyter and deleted a bunch of files by hand and reinstalled and uninstalled a few more times and then it worked.
Hi, Excellent post. 2 problems though (not sure if it's my installation or a general problem...) 1. tf_clf_dnn = skflow.TensorFlowDNNClassifier(hidden_units=[20, 40, 20], n_classes=2, batch_size=256, steps=1000, learning_rate=0.05) tf_clf_dnn.fit(X_train, y_train) tf_clf_dnn.score(X_test, y_test) WARNING:tensorflow:TensorFlowDNNClassifier class is deprecated. Please consider using DNNClassifier as an alternative. /home/name01/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1197: VisibleDeprecationWarning: converting an array with ndim &gt; 0 to an index will result in an error in the future result_shape.insert(dim, 1) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-25-665e9fced04a&gt; in &lt;module&gt;() 1 tf_clf_dnn = skflow.TensorFlowDNNClassifier(hidden_units=[20, 40, 20], n_classes=2, batch_size=256, steps=1000, learning_rate=0.05) 2 tf_clf_dnn.fit(X_train, y_train) ----&gt; 3 tf_clf_dnn.score(X_test, y_test) AttributeError: 'TensorFlowDNNClassifier' object has no attribute 'score' 2. tf_clf_dnn.fit (X_train, y_train) tf_clf_dnn.score (X_test, y_test) /home/name01/anaconda3/lib/python3.5/site-packages/tensorflow/python/ops/array_ops.py:1197: VisibleDeprecationWarning: converting an array with ndim &gt; 0 to an index will result in an error in the future result_shape.insert(dim, 1) --------------------------------------------------------------------------- AttributeError Traceback (most recent call last) &lt;ipython-input-31-0e3059fc39d8&gt; in &lt;module&gt;() 1 tf_clf_dnn.fit (X_train, y_train) ----&gt; 2 tf_clf_dnn.score (X_test, y_test) AttributeError: 'TensorFlowDNNClassifier' object has no attribute 'score'
What a time to be alive
I laughed. But I hope my original comment didn't come across as snarky. Ipython copy paste bug is ~~the bane of my existence~~ a minor but annoying inconvenience. 
Really a nice edition addition to fuel our addiction.
This is *great*. Muliline editing, completion menu, syntax highlighting. The best part personally is that all these changes are in Jupyter_console too. This means that I can run Matlab code (faster I install Matlab Jupyter kernel) in a Jupyter console *with these same features*
I know Lena is a standard, I'm also involved in image processing. I made no claims against the Barabara image. &gt;&gt; was hurriedly searching the lab for a good image to scan for a colleague's conference paper. They had tired of their stock of usual test images, dull stuff dating back to television standards work in the early 1960s. They wanted something glossy to ensure good output dynamic range, and they wanted a human face. Just then, somebody happened to walk in with a recent issue of Playboy. http://stevehanov.ca/blog/index.php?id=63 A good description of some of the criticism can be found on Wikipedia. https://en.m.wikipedia.org/wiki/Lenna &gt; I first saw a picture of Playboy magazine’s Miss November 1972 a year ago as a junior at TJ. My artificial intelligence teacher told our class to search Google for Lena Soderberg (not the full image, though!) and use her picture to test our latest coding assignment. &gt; At the time I was 16 and struggling to believe that I belonged in a male-dominated computer science class. I tried to tune out the boys’ sexual comments. Why is an advanced science, technology, engineering and mathematics school using a Playboy centerfold in its classrooms?... As a result of TJ’s culture issue, some young women are deciding not to pursue upper-level computer science courses.[17] Papers have been published with other images in protest. http://arxiv.org/abs/1202.6429
Well, you could pass a named function, or, presumably, a callable class. Don't really see your point.
I think that's a little harsh dude. Personally I strongly welcome more plotting libraries. And the idea of porting an API from another language is far from an inherently bad idea. Why don't you go work on something for months so someone can trash it in a forum after you make a release post?
The shortcut is ^ R. On OSX ^ means control. So press ctrl+r to run. The function keys on OSX default to the controls (brightness, volume, etc). Hold the 'Fn' key and press a function key to use the non-control version. But F5 is not the run shortcut for PyCharm OSX default.
Do we owe bad engineering good feedback?
I agree with you. But when I started working with images I didn't notice the sexual context of the image. I realized that only a couple weeks back when worked on the blogpost and found the wikipage that you pointed in (the link in the post).
IPython is the kernel. Jupyter is the notebook UI.
From the very great book Fluent Python: &gt; the Python data model [...] describes the API that you can use to make your own objects play well with the most idiomatic language features. From an exemplary card deck object from the same book: &gt; By implementing the special methods __len__ and __getitem__, our FrenchDeck behaves like a standard Python sequence, allowing it to benefit from core language features (e.g., iteration and slicing) and from the standard library So the Python Data Model as I understand describes the implementation and handling of objects. Inheritance and/or implementation of (magic) methods allows your object to be used "pythonic", regardless how freakish your data and data handling might be. For example, you implement an object that represents some kind of list-data. By implementing __len__ and __getitem__ you can index it, slice it, iterate over it... in any way or any other module/package/API be it standard python or not. Usage is simple like any other list. However, under the hood, there might be the most complicated things going on to provide the actual data in that list-object.
there's a difference between "giving feedback" and what you wrote. 
I love this! The only thing I miss from BPython is inline docstrings... Otherwise, I prefer IPython in all respects now.
Seconding this, have done a number of applications with Falcon, find it very straight-forward with a clean API.
Thanks for the explanation. I was trying to copy paste from the stack exchange answers, but I wasn't understanding how the comprehension is parsed.
Excellent. Thanks for the help.
if you understood my feedback you would see the value in it (and the snark is for free)
So.. any API that does keyword arguments is hackish? Wow, you have a radically different idea of what python is than I do.
Tornado, because I like async stuff. For quick'n'dirty rest services flask and bottle are fine.
Python doesn't work like that.
ok, conversation over then.
You've got a python 2 vs 3 mismatch?
I'm pretty sure this problem is the subject of a tutorial on datacamp.
&gt;old the 'Fn' key and press a function key to use the non-control version TIL
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
I would be happier with a ground up implementation of the Grammar of Graphics without pounding it into an unnecessary functional style (the original GoG is OO, and a nice fit for Python). This is the approach Bokeh took (for it's lower level API, as opposed to the charting API) and I think it works well. Perhaps one could make use of the fabulous work on matplotlib backends, rendering, Artists, and Conatiners and build a GoG API out of that and get something very nice.
For the "lazy", who don't know what this is about: http://python3statement.github.io/
This is exactly what you are searching for https://github.com/dddomodossola/remi
Mostly correct. The Notebook is one of the available Jupyter UI, but you got the gist right. We know it's still confusing. 
It's requiring you to *define* functions with the right argument names that is hackish, not calling them.
Happy to make you happy. 
See https://github.com/jupyter/jupyterlab you can try it today if you like. Brian will do a talk at SciPy that should be recorded.
Love the improvements.
We have been working closely with with Jonathan (the author of promt_toolkit and PtPython/PtIPython). We are bringing part of PtPython to IPython slowly. IPython is not up PtIPython UI, but PtIpython have some kernel feature that don't (yet) work great.
[removed]
Same here -- I used Lena until I learned about the controversy. Once I saw that and the paper (published by Rachel Ward) I quickly stopped using Lena. 
There is a fork that's trying to do just that.
That the error I'm getting from pip
No. Python is the kernel.
I've been playing with this for ~10 minutes and I can't figure out how to have multiple "pages", and why dialogs go to their own page? Also, one of the examples (`desktop_app.py`) has an error: (test-py35)blake@desktop:~/code/github/remi/examples$ python desktop_app.py Traceback (most recent call last): File "desktop_app.py", line 6, in &lt;module&gt; s = server.StandaloneServer(MyApp, start=True) File "/home/blake/.virtualenvs/test-py35/lib/python3.5/site-packages/remi-0.1-py3.5.egg/remi/server.py", line 1007, in __init__ self.serve_forever() File "/home/blake/.virtualenvs/test-py35/lib/python3.5/site-packages/remi-0.1-py3.5.egg/remi/server.py", line 1010, in serve_forever import webview ImportError: No module named 'webview'
I love how newer Mac keyboards have totally dropped the ⌥ ^ ⌫ symbols (but ⌘ persists?) while the UI still uses them... `:\`
That's excellent news. Any idea where I can find it in case I can contribute?
Okay a noob question: is there a way to autocomplete braces, strings inside ipython?(the feature exists in jupyter notebooks)
This, you can customize the sh!t out of jupyter notebooks through CSS, which is one of the reasons I love the platform, among many.
it's harder to use and arguably not more pythonic than a string
The easiest way to do this, if you're going to make the `Year` objects in advance is to store them in a dictionary. Dictionaries allow you to do a "lookup" by matching a key (your input string) to a value (your `Year` instances). There's more information about [`Dictionary` in the Python Docs](https://docs.python.org/2/tutorial/datastructures.html#dictionaries). Here's some additional information about [why to use `dict.get`](http://www.tutorialspoint.com/python/dictionary_get.htm) instead of direct lookup (`years[year_selected`) in this case. It would look something like this: years = { 'y2016': Year(2016), 'y2017': Year(2017), } year_selected = years.get(year_selected_raw_input, None) if not year_selected: print "Sorry, you can't select that year!" For future reference, these kinds of questions should be posted in /r/learnpython 
It's not an error but a missing dependency. In order to go like standard desktop app you have to install pywebview. ;-)
If you want multiple pages, just overload GenericDialog class. Or simply change the root widget.
Thanks for the suggestion, will be done. ;-)
Well, what's the error?
Awesome. Thank you very much! And sorry for the misplaced post.
That'd be awesome. This has definitely been a challenge as I'm not a python pro, and I'm really learning what's in the guts of a packet at the same time, lol
I hit this using pip too. I went back, did conda install setuptools to get to the latest version, ran pip install ipython again, and it reported everything was already up to date. So, likely, it installed the first time in my case and the error was a red herring.
Wow. It's *exactly* what I had in mind.
You can use semicolons in Python :)
Perhaps I'm not understanding correctly, but in chrome you can highlight **whatever text you want**, then right-click (on windows) and there will be a pop-up for *Search Google for 'whatever text you want'*
Pythontutor looks pretty ace. This code doesn't use sys at all, so you can drop that line and try it there. Also /r/learnpython is always happy to pick up newbie questions.
I'm just looking through the code, I didn't run it -- and if it works really good job! I'm just going to offer some code style critique. From top to bottom... 1) Canonically class names are CamelCase and descriptive, `fb_bot` -&gt; `FacebookBirthdayBot` 2) `pwd` as an parameter is ambiguous since it has a meaning (Print Working Directory) in linux. There's no shame in just calling it `password`. 3) `pg_url` and `pg_url_notify` are also unnecessarily ambiguous. 4) logging configuration for the whole script makes more sense outside the class. 5) Docstrings should be triple double quotes. `'''` -&gt; `"""` 6) What are `em` and `pw`? ...oh e-mail and password. 7) Birthday messages could be defined in the `FacebookBirthdayBot` class, or in the global namespace .. instead of in the `if __main__` block.
Thanks! Very helpful.
Hopefully you guys can get some parity in terms of history, vi mode, and custom keybinds. I'd love to go back to IPython if those features were up to the standard of ptpython. 
Having Python code is "not more pythonic" than having a string with code in it? Wtf?
It seems to work now at pythontutorm thanks for that helpful hint! Cross posted to r/learnpython as well. 
If you need to get around paywalls there are browsers extension to do so: [this](https://chrome.google.com/webstore/detail/bypass/ekfnpmbmfmlnbphalelfmiodjmbbjlmp?hl=en) for chrome or [this](https://chrome.google.com/webstore/detail/bypass/ekfnpmbmfmlnbphalelfmiodjmbbjlmp?hl=en) for firefox. If you want to make a python script for that you should make a shortcut on your os that launches a script. That script captures your clipboard or your mouse selection and launches the webbrowser or a keyevent (that simulates the keystrokes for opening a tab and searching) 
It's $40 USD. 
I dont know how much you know about jquery but creating a jquery script in this would be pretty easy depending on the source code of the site but you can do something like find all h1 tags (assuming the title is in h1) and use the wrap() function in jquery to wrap it in a Google search call. You can do a lot with Python but when it comes to this I don't know if it's possible with Python. When it comes to automatically doing this on every page visit, look into things like grease monkey which automatically runs custom scripts on whatever website you want
Maybe post here also. I'd also be interested. 
I don't think we're on the same page here. What I'm complaining about is against a hypothetical API that would go like this def apply_function_to_columns(df, func): """ df: some DataFrame func: function where the arguments have the same name as columns of the dataframe """ nargs = func.__code__.co_argcount cols = func.__code__.co_varnames[:nargs] return func(*[df[c] for c in cols]) 
Try this: You defined a function called random_phrase. Then a little bit down you say random_phrase = "" and then try to make the function equal to a string. You can't redefine a string the name of a function. Does that make sense? 
Try renaming the variable random_phrase in the function generate_and_score. It has the same name as your function random_phrase, so you're effectively erasing that function when you call generate_and_score. I don't know if that makes the whole program work, but it does get it running...
Thought you were trolling for a second. But this is pretty much what you want to do from what I can tell. http://www.reddit.com/r/netsec/comments/4ric34/why_mac_address_randomization_is_not_enough_an/d51psk0
To run MATLAB code do you use calysto? Could you ever get it to reload functions you've run and changed without having to restart the kernel?
Yep - sounds like a driver with a limited ability to deal with context.
Sorry for that line with the empty string. That was originally removed but I tried adding a lot of stuff to break the program in different ways. 
Definitely, I suffered from those moments in which you feel like dumb haha. You're totally right. Renaming issues. Now is up and running. 
Are you kidding? Syntax-highlighted REPL?? Yes, please!
Shift-enter has worked for me
it just adds a new blank line for me :(
I would try not to do it. It is easier to understand the action of // with ints. floats, remember, have more devious edge cases where even when others describe what is happening, the edge cases don't seem worth the cost of using // with floats. if you have floats and want to do something specific then it ight be better to explicitely use fllor, ceil and whatever so it is easier to reason about what happens in edge cases from the expression. It will probably make it more maintainable too.
No it's actually IPython. There's a limited Python kernel as well.
Lack of multiline edit was what kept me away from commandline ipython all these years.
I once thought that it would be cool if it was possible to rewrite code during debug in python. I thought it might be possible because its "interpreted".
Is this anything like "dbstop if error" in Matlab? When i was using matlab many, many years ago that little statement saved me A LOT of time. I dont see the point of tracing back in the stack since figuring out the bug from current state (stop if error) was always sufficient for me. 
You basically want to create a chrome (or other browser) extension. You can do that with javascript.
IPython is the reference implementation of a Jupyter kernel. Or to make vagues comparison, IPython 5.0 is to Jupyter what Android Froyo is to Smarphones. You can Also install Andoid JellyBean (IPython 4.0), or you can install WindowMobile (Perl Kernel), install iOS (haskell Kernel). You are allowed to use a Nexus 5 (the Notebook), or a Motorol RAZR (Jupyter console). You can use Multiboot, (JupyterHub) ...etc. Does that make (some) sens ?
&gt; In the near future, I'll be running an introductory Python course and would like to recommend that the students install Pycharm as it seems to be the friendliest IDE out there. Hmm, for an introductionary I would recommend you some more simpler editors than a full blown IDE. Let's be real, your students won't need 90% of the stuff pycharm offers. A good way is a editor that can be improved with plugins. Atom or Sublime Text are good and slick editors, but you need to install some plugins to have a solid starting place (auto completion and maybe a linter). Or forget about the whole Editor and IDE aproach. The recent ipython update to version 5.0 LTS made ipython a hell of an interpreter, with multiline editing, nice autocompletion and live syntax highlighter in a normal terminal! And this across the three main platforms (Linux, Mac and Win)!!! And why stop there, ipython notebook or jupyter is an even more interesting playground for playing around, testing and discover code. Write your code in the browser, divided in useful cells, syntax highlighting, autocompletion, powerful magic in a shareable html page. Spice it up with readable documentation and you have an awesome enivroment! And this system offers alot more. Create a jupyter hub, so that your students can connect to it and nobody needs to install anything, all of it runs through your own server! The thing is, most of the avalable IDEs are created with professionals in mind so you will find alot of functionality the coding noob would never use and have a long time to even understand why he need some of it in the future. "Keep it simple, stupid!" ;)
https://autohotkey.com/board/topic/13404-google-search-on-highlighted-text/
ok
RemindMe! 24 hours
I will be messaging you on [**2016-07-10 00:40:39 UTC**](http://www.wolframalpha.com/input/?i=2016-07-10 00:40:39 UTC To Local Time) to remind you of [**this link.**](https://www.reddit.com/r/Python/comments/4rvced/wifi_distance_is_it_really_possible/d5505ou) [**CLICK THIS LINK**](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[https://www.reddit.com/r/Python/comments/4rvced/wifi_distance_is_it_really_possible/d5505ou]%0A%0ARemindMe! 24 hours) to send a PM to also be reminded and to reduce spam. ^(Parent commenter can ) [^(delete this message to hide from others.)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Delete Comment&amp;message=Delete! d5506nd) _____ |[^(FAQs)](http://np.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/)|[^(Custom)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!)|[^(Your Reminders)](http://np.reddit.com/message/compose/?to=RemindMeBot&amp;subject=List Of Reminders&amp;message=MyReminders!)|[^(Feedback)](http://np.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback)|[^(Code)](https://github.com/SIlver--/remindmebot-reddit)|[^(Browser Extensions)](https://np.reddit.com/r/RemindMeBot/comments/4kldad/remindmebot_extensions/) |-|-|-|-|-|-|
The major breaking change between python versions is between python2 and python3 - if the distribution has recently changed what /usr/bin/python points to, then scripts that are using that as the `#!` line might start failing. (You can check the version by typing `python -v` - if it reports 3, then try changing the script to use: #!/usr/bin/env python2 instead and see if that resolves it. Point versions between 2.x and 3.x should rarely break anything, at least not unless there was a major jump in version (potentially breaking changes have a deprecation period of a couple of releases where they'll warn, but not cause an error). The other possibility is that it's a library dependency that's got removed (or potentially one that broke something by changing the API). You'll need to take a look at the error message to diagnose this - if you see an import error, try installing the relevant package.
They're for more complex than regular debuggers, and as such are a harder project. At least that's what my gut tells me. You either have to store historical state (either fully or as some sort of delta) or be capable of undoing instructions (easy for `a += 4` when a is a fairly normal number, impossible for `a = 4` for a randomly defined `a`). Realistically, there will probably be some combination of the two, as many of the most common operations (iterate in a loop, perform arithmetic, etc) are easy to undo, whilst others are potentially impossible (overwrite a value).
So... bugging.
calling eval() on string that contains python code is somehow the more pythonic way? what...
yes, the elif would be completely ignored if the 'if' statement is true.
[removed]
 if A: do thing 1 elif B: do thing 2 A|B|does thing 1 happen?|does thing 2 happen? -|-|-|- True | True | yes | no True | False | yes | no False | True | no | yes False | False | no | no If A is true, it does thing 1 and skips every `elif` or `else` block attached. Otherwise, it goes to the next `elif` and treats it like another `if`. If it gets to an `else` without doing any of the things, then it does whatever is in the `else` block.
Thanks!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Hi there, from the /r/Python mods. We have removed this post as it is not suited to the /r/Python subreddit proper, however it should be very appropriate for our sister subreddit /r/LearnPython. We **highly encourage** you to re-submit your post over on there. The reason for the removal is that /r/Python is more-so dedicated to discussion of Python news, projects, uses and debates. It is not designed to act as Q&amp;A or FAQ board. The regular community can get disenchanted with seeing the 'same, repetitive newbie' questions repeated on the sub, so you may not get the best responses over here. However, on /r/LearnPython the community is actively expecting questions from new members, and are looking to help. You can expect far more understanding, encouraging and insightful responses over there. Whatever your question happens to be getting help with Python, you should get good answers. If you have a question to do with homework or an assignment of any kind, please make sure to read their sidebar rules **before** submitting your post. If you have any questions or doubts, feel free to reply or send a modmail to us with your concerns. Warm regards, and best of luck with your Pythoneering!
Thanks for the input 👍. I'll make some changes today.
How about reverse debugging of multithreading processes? Feels like it could help find bugs that usually appear due to thread synchronization issues. However, this is one of the cases where the debugger might have direct influence on the bug. Like in quantum mechanics where measuring one property influences the other and vice versa, making it impossible to measure both properties at once (oversimplified). That's why these bugs are often called Heisenbugs. Can I kill Heisenbugs with reverse debugging?
Anyone knows will it break Spyder3 ipython console?
If you can't even take the time to *personally* message a friend for their birthday, but have a bot do it for you, they aren't really your friend.
[pyjs](http://pyjs.org/) perhaps?
Hmmm, there's something funny going on there. It would be Bad if two floats that are different print the same. Using Python 2.7, here is the float closest but less than 1: py&gt; for i in range(100, 0, -1): ... x = 1 - 2.0**(-i) ... if x != 1: ... break ... py&gt; x 0.9999999999999999 And sure enough, print tries to make the number look good rather than be exact: py&gt; print x 1.0 Note to self: always print the repr of floats when in doubt. 
In your example, you can't select specific columns, it will always pass all of them to `func`, which is problematic specially for large datasets. I still think that that ggplot devs decision of using strings à la `func='np.sin(col_name)'` is the best solution for this problem, the only other alternative I can think of that uses lambdas is something like ggplot(df, aes(x=lambda a, b: np.sin(a-b), y=lambda a: np.cos(a), argx=['col1', 'col2'], argy=['col3'])) which is terrible.
the firefox link is chrome link
Format it properly first, it's a mess. Or paste it on pastebin or one of the other similar sites.
because it's all on one line.
My guess is that he meant SSL/TLS encrypted traffic, but to answer your question, yes. SSH is Secure SHell, an encrypted replacement for telnet (and in the even older days, rsh and rlogin). It's generally only used for remote access to a system rather than web app stuff though.
Nice reference, this could take the place of many stack overflow tabs. Pandas is so complicated, but it is a useful tool.
Before you get too proud of Apple, Safari is the only browser where I couldn't "Inspect Element".
Additionally: won't work if the app cert-pins the "real" cert. But you could probably then find the memory address of the pinned hash and try overwriting it with some sudo hax.
&gt; that's standard behavior in all debuggers. Nope. For example, in a for loop you will hit the break every iteration. That is standard behavior, break if error is not.
Seems like a great idea. Could you give an example of the json config file? If I understand correctly, you develop your python application like normal, then when you're ready to deploy you run debpackager and this generates the init script/systemd service file, then builds a .deb like fpm? If so, this is awesome and I'll be trying it out. 
you are right, i'll get on that, just for the record its a binary only right now. But source packages creation can be implemented easily enough. Also i do not really follow Debian packaging policy or all the packaging guidelines. it just creates a binary deb that can be deployed on Linux right now. so this tool is not mature enough for creating packages for PPA's and other official repositories. just for your private debian repo :)
Maybe some minor cosmetic changes. I was just a bit to eager to release, and didn't test it on python 3 Edit: python 3 supported aswell 
Good work!
Well, you could do it like that, but that's not what I meant. The SO-Post describes a pretty accurate formula to calculate the distance from the signal strength and the channel used. 
&gt; 'await' and 'yield from' represent transfers of control that the code doesn't care about and can't even see You're 100% wrong here, sorry. Can't blame you really, since there's a lot of confusion around the subject (some of it seems almost intentional), very few clear explanations, and you gotta get yourself quite a few lumps trying all the different approaches before you even begin to suspect that there's something weird is going on. Basically, there are two orthogonal purposes to various kinds of "not-thread-based concurrency": performance for IO-bound applications and making synchronization easier. And for some reason it's the former that is used for marketing almost exclusively, while it's the latter that most people who use this stuff actually end up finding the most useful. Threads are hard, so hard that you pretty much can't reason about the way your code executes concurrently unless every shared resource is protected with synchronization primitives. So you use synchronization primitives, but it's too easy to forget to protect something or to protect too much. With callbacks or futures or explicit coroutines suddenly you don't use synchronization primitives because now you _can_ reason about concurrency. What was so hard in case of threads that you might not even realize that using mutexes and such is a _choice_ (until you remember about lockfree algorithms, but they are black magic and limited in scope) -- here you just go and do like it's no big deal. Because you know for sure that between two `awaits` your code can't be interrupted and the state of the world change under your feet. But if you get an idea that it would be neat if you can make the compiler insert awaits automatically, you're back to square one you where at with threads. Because now every function call might secretly be a context switch and someone might remove $100 from an account as you log that you've checked that it has enough funds and before you actually debit it yourself. Making the compiler implicitly insert awaits is trivial. It is a choice to have a dedicated keyword that stands out in the code like a sore thumb. It's a danger sign, here the context switch may occur and the state change. Further reading: https://glyph.twistedmatrix.com/2014/02/unyielding.html
sweet stuff way over my head
Thanks a lot for this, especially that last link. I had always thought the new async stuff was unnecessary syntax but this explains really nicely why it's needed -- explicit is better than implicit.
&gt;Python 2.7 ಠ_ಠ
Awesome! I wonder if mypy have any plans to develop a tool to infer some function types automatically to help with such migrations? (I prototyped such a tool once and it seems to me that 50-60% of the annotation work can be easily automated because most real python code isn't insanely dynamic [hatlog](https://github.com/alehander42/hatlog)
I've come to the same conclusion, however I have no idea how to do it. The docs aren't making sense to me.
Ah, in your title you said "a tool for making debian packages and daemons out of any project" and I thought you meant it would handle those tests that turn "manually executed command line program" into "daemon". Also, I've never used maven, so what does your tool give you over fpm? 
Have you seen tox? It makes it really easy to run tests against different Python versions you pick. You still have to write tests, but it's a damn useful tool.
ye im actually planning to use that, tnx for the advice
Im on mobile, so I can't really run the code, but the way you have two booleans: onGround and falling seems like a really bad way to implement the checks. They are the same thing with opposite values. 
Scaling is the least of your worries right now, get your product off the ground and worry about size later. And flask is perfectly suitable for "big" (whatever that means) apps.
&gt; Only 50% though because many of us aren't using it for that, and would consider the statement true. If you're sure enough about your ability to not have any shared state at all, or to protect the shared state you do have with `gevent.Mutex`, sure, use gevent and do that. In fact it is way better done at the interpreter-OS boundary anyways, so you can catch _all_ blocking calls. And that's what gevent does as far as I understand, so if you want that, use gevent. `asyncio` has a different purpose. You're still 100% wrong when saying that asyncio can be made better with such and such changes, because those changes would make asyncio _worse_ for its stated purpose. Like, there seems to be a _mathematical tier_ impossibility in making a thing that gives you the best of gevent and asyncio worlds. So you have to choose one for the task at hand and don't blame the other. &gt; If we consider what the minimum needed to implement this is, we find it isn't conversion of our function-based code into a perfectly isomorphic but perfectly incompatible stack of generators. All it is is.... a flag. A keyword which lets us carry context switch permission across a function call. I'm not sure I understand your point here, but if I understand it correctly it was addressed in the linked article starting from _"Oh well. Since I’m still a fan of explicit concurrency management, let’s do the clearly unnecessary busy-work of updating the ledger code."_ 
Things that are easy to explain are not always good tools to build good software on. Threads and processes are good to start people out learning about parallelism, but to argue that because event loops are complex they should be removed is bizarre. Millions of new programmers learn how to use event loops every year because they write iOS or Android apps. The concepts are not beyond your students. 
fixed :)
Indeed, avoid solving problems you don't yet have. There are many ways to scale flask. You should think about those solutions later.
I did not meant to imply event loops should be removed. But the current implementation is IMO beyond salvaging. I have a nagging feeling it could have been achieved without new language syntax.
Great comment. I mostly agree. However, I would take issue with the whole "threads are hard" point. This a crutch/trope that the python community has been using for far too long. Threads/concurrent processing are an important part of modern programming and python's aversion to them reflects an archaic, head-in-the-sand view that is really holding the language back. The proliferation of attempts at asynchronous programming (remember concurrent.futures?) is the community's attempt to play catch up without the fixing the real problem which is that the GIL is now very outdated. It was fine when Python was just trying to be better than perl, but having easily cleared that bar, Python has trouble going further because of its starting to feel a little dated in the way described. That being said, I love Python and think it has a bright future of if they can fix these things. 
&gt; However, I would take issue with the whole "threads are hard" point. Threads ARE hard. My personal itch that turned to be more of an open wound about that was boost::asio, which is a C++ thing. It's, like, things are all nice and warm until you try to run dispatchers from multiple threads and suddenly all those nice promises of easy concurrency fucking disappear unless you do stuff in a very particular way. I'm totally OK with the GIL, the thing with the Python community is that they are concerned about it, unlike Ruby, Perl, PHP, Lua, Javascript, &lt;generic scripting language&gt;, they all have their equivalent or just don't have free threading at all. Like, it's retarded. It's no coincidence that all those other similar languages have the GIL or don't allow free threading at all. Why is that the Python community in particular stands out being butthurt about GIL? It's OK to have a GIL, really. That's not a problem.
Ah, not on a Mac, I should have been more specific. On a Mac, only using explicitly `esc-Enter` works. Matthias and I tried *a lot* to find an alternative for OSX, but failed.
http://i.imgur.com/wREbYv1.png
+/u/ImgurLinkingBot http://imgur.com/gallery/O1z109s 
The middle argument, `(8 + adcnum) &lt;&lt; 4`, is toggling bits. I assume this is what you want help with. I can't help you with the `xfer2` API itself because I don't know it. Let's go with the bit-toggling. You can switch things on and off in a data parameter (integer) just by toggling the various bits inside it. This *seems* complicated because you can't see what's happening, but it is actually easy to visualize. The first thing is that `adcnum` will not be greater than 7. So let's see what adding `8` does to an int smaller than that: &gt;&gt;&gt; '{:016b}'.format(0 + 8) '0000000000001000' &gt;&gt;&gt; '{:016b}'.format(1 + 8) '0000000000001001' &gt;&gt;&gt; '{:016b}'.format(2 + 8) '0000000000001010' &gt;&gt;&gt; '{:016b}'.format(3 + 8) '0000000000001011' &gt;&gt;&gt; '{:016b}'.format(4 + 8) '0000000000001100' &gt;&gt;&gt; '{:016b}'.format(5 + 8) '0000000000001101' &gt;&gt;&gt; '{:016b}'.format(6 + 8) '0000000000001110' &gt;&gt;&gt; '{:016b}'.format(7 + 8) '0000000000001111' I'm using a binary formatter to show you the bits. So if you look carefully, you can see that *adding 8* actually toggles the *fourth bit* for that number. We're counting from the right here. Next, the `&lt;&lt; 4` is going to shift your bits over to the left by four positions. I'll do it with the last one from above: &gt;&gt;&gt; '{:016b}'.format((7+8) &lt;&lt; 4) '0000000011110000' So, I'm guessing---but you should verify---that your RPi API looks at 8 bits for this value, and in our example here, we have toggled the last four. Each of those switches (0 or 1) will "mean something" in your API. Does this make sense?
http://i.imgur.com/vU16FEz.png
http://i.imgur.com/nB0aZSG.png
http://i.imgur.com/yRsjJEo.png
/r/learnpython. Take this rubbish there.
http://i.imgur.com/7zA6i79.png
+/u/ImgurLinkingBot https://gyazo.com/c688e50e7fb83441f27e12e34cf23e00
&gt; A keyword which lets us carry context switch permission across a function call. that is *exactly* the whole point of explicit async. An irrational and misguided fear of "concurrency", for which explicit async is not even a real solution. Using an implicit system like gevent, the gevent runtime automatically context switches whenever we do network IO. Using regular threads, the operating system automatically context switches (faster than gevent and vastly faster than asyncio) when it is most optimal. The GIL is also released during IO. So unless you have many hundreds of arbitrarily slow and/or sleepy/idle connections, asyncio is significantly less performant than traditional threading, even in Python, even with the GIL. 
&gt; The response time for small requests "drops off a cliff" due to a single large request, apparently due to "the implementation of the GIL"? No technicalities, just repeating what dbeaz said, assuming I understood it correctly: GIL prioritizes tasks that are computationally heavy. In case of 3x fib(1) their relative cost was the same, so they got 1/3 of the cpu time each. Once fib(40) with much higher individual computational cost entered the picture, it hogged the vast majority of the available CPU time courtesy of the internal python scheduler, leaving only scraps for the others.
Think about where this stack object stores its elements. You have access to that data structure, so it's just a matter of returning the length of it.
This sounds a little like homework but since you asked have you tried len(self._contents) 
Well actually I just chose a basic example. I don't know how to call on self._contents outside the class? How do I do this outside the class is my question. 
Have you done any testing/ benchmarks around this? How much of a performance difference are you talking about? I find coroutines easier to reason about.
Just wanted to know how to call on Stack outside the class, im good now though. 
&gt; The language is split in two, not because the things we might use/async use have different functionality, but because they have different implementations. No. It's because it was too complicated and they went and made it easier after Python 3.4's first attempt at a solution. Having two ways to solve the same problem? Can we just remove lambdas? Should we remove list comprehensions too?
How is it different from checkinstall? More control on the output config?
You should share more context about your application if you want good feedback on how to configure it. What kind of environment are you running this in? What bottleneck are you encountering? What are the performance characteristics of your service? QPS, cpu bound, io bound, memory bound, etc. Nginx is a reverse proxy, web server, load balancer, etc. etc. Whatever you want to call it and however you're using it, the important thing to understand is that it's independent of python concurrency. All it does is forward requests. If you suspect that nginx is misconfigured or the source of your bottleneck, I can go into a little more detail (I have the least experience working with this layer), but it's unlikely to be your problem. uWSGI works by creating an instance of the python interpreter and importing the python files related to your application. If you configure it with more than one process, it will fork that instance of the interpreter until there are the required number of processes. This is roughly equivalent to just starting that number of python interpreter instances by hand, except that uWSGI will handle incoming HTTP requests and forward them to your application. This also means that each process has memory isolation—no state is shared, so **each process gets its own GIL**. Thus, using only processes for workers will give you the best performance if your aim is just to optimize throughput. However, processes come with tradeoffs. The main problem is that if your application benefits from sharing state and resources within the process, pre-forking makes this untenable. If you want an in-process cache for something, for example, your cache hit ratio would be much greater if all of your workers were housed in one process and could share the same cache. An important implication of this is that processes are very memory inefficient—memory isolation often requires that a lot of data is duplicated. (As a sidenote, there are ways to take advantage of [copy on write semantics](https://en.wikipedia.org/wiki/Copy-on-write) by loading things at import time, but that's a story for another day.) For this reason, uWSGI also allows your workers to live within threads in the same process. These threads solve the problems mentioned above regarding shared state—now your workers can share the same cache, for example. However, it also means they share the same GIL. When more than one thread needs CPU time, it will not be possible for them to make progress concurrently. In fact, GIL contention and context switching will make your application run slower, on net. For IO-bound applications where workers spend so much time waiting for IO that GIL contention is rare, this *sounds* like it shouldn't be a problem. And if your application is like most web applications that spend a large part of its time talking to other services or a database, it's probably IO bound. So all good right? In reality, thread based uWSGI workers almost never work flawlessly for any python web application of even moderate complexity. The reason for this is primarily the ecosystem and the assumptions that people make writing python code—many libraries and internal code are flagrantly, unapologetically, and inconsolably NOT threadsafe. Even if your application is running smoothly today with thread based workers, you'll likely run into some hard-to-debug problem involving thread safety sooner than later. Moreover, so called "IO bound" applications spend way more time on CPU than most developers realize, especially in python. Python code executes very slowly compared to most runtimes, and it's not uncommon for simple CRUD apps to spend ~20% of its time running python code as opposed to blocking on IO. Even with two threads, that's a lot of opportunity for GIL contention and further slowdowns. My main point is this: Whatever bottleneck you're running into likely has to do with the fact that you're running 2 threads for each process. So unless shared state or memory utilization is very important to you, consider replacing that configuration with 4x processes, 1x threads instead and see what effect it has. Citation: Nearly 2 years debugging and tuning performance of python applications of many flavors at Uber justtrustmei'veseensomeshit.
i wanted to have more control over the stages of the packaging process, so in future debpackage can do more custom/advance things and when i did my research i understood that checkinstall is more limited in that sense. but i may be wrong.
There is some type inferencing done by `mypy` (nothing OCaml-class, though). Google [is also trying to do this](https://github.com/google/pytype) but in my quick tests `pytype` crashed with the codebase that I wanted to annotate.
I wanted annotations inline, not in .pyi files - IMHO you want them in your codebase, not "outside" it, since the arguments' types act as excellent documentation as well; you navigate to a function's code, and you instantly see what the arguments are about. The only case where I'd use .pyi files is for python2 codebases - that is, where syntax prohibits from having inline type annotations (and no, comments don't quite cut it - at least not for me).
Indeed! Forgot about that. Then again, in this case that was the least of my problems :-)
You don't need a nagging feeling: it's literally true. If you check the PEP for the `yield from` keyword you'll find it is literally syntactic sugar over about 80 lines of code. The reason there is a keyword there, rather than having coroutines *magically* end up running in a coroutine runner, is for generality. Coroutines are bigger than event loops and bigger than asyncio: asyncio represents a specialised deployment of the idea. To see the advantages of this model you should look at curio, which uses the same syntax but a thoroughly different threading model. Languages shouldn't make too many decisions for you: instead, they should give you tools to build good solutions. 
"Performant" here is a word that hides a multitude of sins. Performs better along what axes, under what workloads? For example, your threaded model is not more performant in the fact of 10k concurrent connections where having a per-thread stack of 8MB means that you need to allocate 80GB of memory just for stacks alone! My asyncio code base can handle this: your threaded one cannot even execute. I'd say asyncio is performing better there! If your only metric of performance is "how fast can I context switch", you are prioritising specific small set of problems over the wider design goal. Designing for performance is just not as easy as saying "asyncio slow, threads fast".
Please be aware that this is considered bad code style in Python. Since Python has no `private` keyword it's generally accepted that anything that starts with a underscore *is* private and should only be used inside the class. 
You'll probably encounter people trying to add malicious code to your bot.
What an awesome reply. Excellent insight. Thank you. 
PyCharm is great and if you like the vim way then ideavim will probably cover most of what you're used to. I use that for most serious development work. For simple scripts I use vim (or sublime text with Vintageous). For data work and prototyping I also often use a Jupyter notebook.
Awesome explanation! Only thing I'd add is that the multiple processes can share state via an external in memory cache. Qn - how well would the op's setup run on pypy
How so?
Think of SQL injection but with your bot. Just make sure it's safe.
Try flexx Ita on github
Patreon used(uses?) flask and they're fine. Instagram uses django and they're also fine. It doesn't matter, you can use flask and switch to django later, or stick with flask, there's no exclusivity in actual features i.e. what you can achieve with it, the only difference is design patterns. Use the framework that fits you the programmer, the program you're thinking of can be done these 2 frameworks or even others. I've made a flask app that went from quick prototype to production real quick, the features crept up and the code got kinda messy to handle, decided to google up on flask best practices for big projects, turned my hacked up prototype into a better organized flask app in 2-3 hours (including research).
You are the man!! What a response. I can give a little more detail about the application (as far as I know). . The characteristics as far as I see is 50/50 cpu bound and i/o bound. I see a lot of kernel time usage from the process along with user time (assuming kernel time spent at i/o, and user time spent turning on-cpu). What I did notice tho is under load, uWSGI is just slamming 2 cores, out of a 4 core machine. I'm assuming that my throughput is bound to the depth of the run queues on these two cores (The kernel doesn't seem to be load balancing the thread to other cores, which makes sense for memory locality and cpu cache considerations). . I COULD go back to the Dev break your python code into a multi-process architecture, so that your i/o and serialization functions utilize multiple cores and return a response on a FIFO queue, and synchronizes. BUT isn't uWSGI essentially doing just this ? The service could be completely bound to 1 core, and starting 4 uWSGI processes essentially allows 4 'instances' of the service to run, utilizing cores in parallel. Also about Nginx, it sits on the same server and it's being used as an HTTP front end for the application, no form of load balancing is happening. It does have it's own worker process pool, but all workers are pointed to the same unix socket which is the uWSGI gateway. 
Always an interesting suggestion to move to pypy, we will have to look at that option also. 
But spec'n the machine correctly and adjusting several tcp queue params should be comparable, no? 
I created an account just to answer your question. Check this talk by Miguel Grinberg - Flask at Scale - PyCon 2016 https://www.youtube.com/watch?v=tdIIJuPh3SI
&gt; For example, your threaded model is not more performant in the fact of 10k concurrent connections that's why I said above, and in my post, "unless you have many hundreds of arbitrarily slow and/or sleepy/idle connections". 10000 concurrent connections in one process *is* the use case for async. Though I use gevent for this case. Suits the use case + no need to rewrite the whole Python ecosystem is a plus. &gt; Designing for performance is just not as easy as saying "asyncio slow, threads fast". It's a good thing then that's not at all what I said. Though I would possibly say that "asyncio slow, gevent fast", because they both target the same concurrency model, gevent just does it with less Python overhead. 
`# generate requirements.txt always using the latest certifi` `pip freeze | sed 's/^certifi==/certifi&gt;=/' &gt; requirements.txt` Combine with the rest of your release-tagging script.
Very solid point. 
Only thing that has ever worked for me is starting a project and then keep going until the bitter end.
If you can't think of anything specific you want to do, you can always make a clone of some other site you like/use. There's almost always an interesting problem involved in any moderately sized website. Regarding the motivation a lot of that is just up to forcing yourself through the cruft. It's not always fun and you may get blocked but it's good practice for professional applications too, given the motivations there must also often be internal.
If you're serving requests to public internet clients, Nginx is a smart choice because it's a much better-tested and more secure codebase. Not that uwsgi is bad, it's just that nginx is that much better. So it'll insulate you somewhat from any security issues or bugs in uwsgi. Also as mentioned since Nginx buffers the entire request before passing it on, and can optionally buffer the response on the way back out, it protects uwsgi from slow clients -- malicious or otherwise. Assuming you're using the uwsgi module in nginx (as opposed to passing plain HTTP requests) you're not adding much overhead by doing it this way compared to a naked uwsgi server.
One thing which stops from completing what I start is when there is no gratification for prolonged periods of time. This gets me to jump from one interesting technology to other with just a basic understanding of the technology until I get fed up with myself(Since I am good at none).
Yeah I assumed that and that's why I initially gave the first response but he seemed to want to know how to do it outside the class, so I figured why not..
Yeah, I use `pip freeze` to get those. Before you freeze you can check the diff to validate (on a UNIX box): diff requirements.txt &lt;(pip freeze) From there I decide if I manually add something or just do the normal file dump.
Cool! Spotify used to have something like this, but it appears they removed it from the client. I still get some mails every once in a while, but they come with a huge delay and are not covering all the artists I follow. So this is a really good thing, thanks :) Edit: Just noticed that you wrote "tweets", but I suppose I can simply modify it to do something else for notifications, since I don't use twitter.
Thanks! Of course you can. Here https://github.com/michael-123/SpotifyNotificationTweeter/blob/master/new_releases_tweeter.py you only have to get the result from result = s.getAllNewReleases() and then you can go on your way. In other words: Change lines 11 to 16 to the way you wish to publish the releases. I think Spotify has a real problem with their notifications for new releases. They work on a playlist which updates every friday with new releases. But I don't know when it is going live and if it is really working that well. And it is nice for me to see new releaeses on my Twitter timeline :)
It's a pretty common format for templating. 
okay Thanks for your support
Your notification bar is giving me serious issues.
Thanks, that's what I thought too (about it being a security issue).
You an accidental exerciser ? 
No, you misunderstood. It will always get the latest version on your PaaS. At least, with `pip install --upgrade -r requirements.txt`.
Getting better at *favorite language* is missing the point I think. do stuff, add value and you will inevitably get better at *favorite language* along the way. 
I add only direct dependency by hand. `pip freeze` can add `B` to `requirements` list. When A is updated, update `requirements` by running `pip freeze`. 
Wow, this one looks quite deep. Is this just aimed for medium-to-intermediate javascript programmers or is also beginner friendly? 
They might just re-run `pip install` on a clean image every time, which would also get the latest version. Anyway, if you want `certifi` up-to-date, put `pip install -U certifi` before your `pip freeze` command.
As long time python programmer i had trouble adjusting to javascript mess. So instead of Javacript I learned Dart which can compile to Javascript. Works nice.
Try not to equivocate python and java. They're vastly different. If I were you I'd learn about - the base types in javascript - functions and function scoping - prototypal inheritance - keywords and asynchronous behavior THEN I'd try looking for the syntax to do the equivalent python stuff: loops over objects decorators 
I had a great deal of luck with the book "Javascript: The Good Parts". It's a quick read and is aimed at people who are not new to programming. O'Reilly Publishing: http://shop.oreilly.com/product/9780596517748.do Amazon: https://www.amazon.com/JavaScript-Good-Parts-Douglas-Crockford/dp/0596517742 
I don't think that will happen. But what could happen is someone merging a virus with a picture, and having multiple pictures on a page so they're downloaded but not sent
&gt; Again, you're always passing all of the columns to the function. You shouldn't be doing that, specially if you're working with a dataset with hundreds of columns, even with iteritems not copying data. Why not? I mean, let's say it's not iteritems but a dict view so there truly is zero copying, why not? &gt; Besides, what do you think is more legible, this [....] or this [...] The first example isn't even what I suggested! It's x=lambda col1, col2, __*: np.sin(col1 - col2) or x='np.sin(col1 - col2)' And I would vastly prefer the first one. Why? Because: - the tooling would work, I could search for usages, I could click on np.sin and go to the function etc - it would be just normal python And besides, how do you think the stringy thing is implemented anyway? How does it get those columns? By magic? It probably does something very similar to what I suggested anyway.
&gt; What I did notice tho is under load, uWSGI is just slamming 2 cores, out of a 4 core machine. If you want to be able to fully utilize your CPU, you'll need to spawn more processes. Since you're saying that your requests spend about half of its time on CPU, you probably want about cores * 2 number of processes to fully utilize your cores, keeping in mind memory constraints. &gt; BUT isn't uWSGI essentially doing just this ? This is exactly what uWSGI solves. If you're interested in a source walkthrough (and because I've got some time to burn today :)) [1. This does all of the uWSGI initialization. It's a masterpiece of code cruft, but let's try to walk through it...](https://github.com/unbit/uwsgi/blob/master/core/uwsgi.c#L2104) [2. This initializes the python interpreters—creates and initializes the data structures for the interpreter, including one GIL for each worker.](https://github.com/unbit/uwsgi/blob/master/core/uwsgi.c#L2895) [3. By calling Python's API directly, not by shelling out!](https://github.com/unbit/uwsgi/blob/master/plugins/python/python_plugin.c#L296) [You may also be interested to see when uWSGI does all the python environment setup, which includes importing files, creating the "uwsgi" module, etc. Note again that it does this by calling the python API directly, making the python interpreter part of its process](https://github.com/unbit/uwsgi/blob/master/core/uwsgi.c#L3187) [Here is the code that actually does the importing.](https://github.com/unbit/uwsgi/blob/master/plugins/python/python_plugin.c#L1080) [4. Finally, uWSGI spawns the workers.]( https://github.com/unbit/uwsgi/blob/master/core/uwsgi.c#L3346) If you follow uwsgi_respawn_worker, you see that it's essentially just fork() ing. There's a separate interpreter instance for each worker. [5. But what about threads?](https://github.com/unbit/uwsgi/blob/3dc786f2c8843151612aebdfc479eb41ee7a004f/core/loop.c#L101) [Threads are created as a new ThreadState within an existing interpreter, meaning they contend with GIL.](https://github.com/unbit/uwsgi/blob/master/plugins/python/python_plugin.c#L1348)
Great thanks!
I'm in the same boat. A mentor at work is helping me build a simple dashboard at work and mentioned I should focus on nodejs over JavaScript, but I'm confused as to the overlap. I really want to learn the technologies correctly and not become focused on a subtech like how some Ruby on Rails devs don't know core ruby. 
Do you know where these modules are located (pygame, tkinter, cython, etc.)? It would help to know. Then check PYTHONPATH. Simply type "echo $PYTHONPATH" from the command line. Also, fire up python, then: &gt;&gt;&gt;import sys &gt;&gt;&gt;sys.path Did you find the path to your modules in either of these? If not, that would be the problem. Check it out and let us know what you find.
If you know basics the do some research on specific object their method n all on mozilla docs
both. 
&gt; In particular, Python does a terrible, confusing job at handling closures (i.e. they work when you treat them as read only, but magically stop working as soon as you write to a closed variable; thank you for the Heisenbugs, Python), so it'll probably be pretty unfamiliar. You can use the keyword `nonlocal` if you want to reassign values in a closure. 
An internal error occured, your image couldn't be uploaded.
An internal error occured, your image couldn't be uploaded.
http://i.imgur.com/bxEoXIB.gif
But without a shared cache DB you can't scale horizontally.
Pypy.js docs?
Neither a Linux issue or a python. Your distro probably already has a python version installed. So you're accessing a different install than the one you are piping into. Check your /usr/bin
I have used the ArgumentParser module in scripts I wrote for our company. I think this stack-overflow might be what you're looking for. http://stackoverflow.com/a/9031331 Let me know if that helps! :)
**[Javascript for Python Programmers.](http://jfine.bitbucket.org/docs/js4py/)**
OK, I appreciate the help! Thanks! Chris 
Thanks - this fixed the issue.
There are multiple projects today that will translate Python into Javascript as well. There's also rapydscript and coffeescript which were influenced by Python.
+/u/ImgurLinkingBot https://gyazo.com/-1;'"
An internal error occured, your image couldn't be uploaded.
i was a beginner with codecademy under my belt, and was understanding this. I prefer simpson to crockford, and his frontend masters courses are gold. just make sure to get the examples and work through and think about this stuff.
&gt;scrape ftfy
I made a python script to extend the pass features, it may be a good idea integrate this features natively in passpy, check it out, https://github.com/individuo7/passx anyway any comment will be appreciated
&gt; You can use the keyword nonlocal Not in production Python code... that's Python3000 only. My go-to solution is the first-element-of-a-list hack: &gt;&gt;&gt; def foo(x): ... a[0] += x ... print a[0] ... &gt;&gt;&gt; a = [5] &gt;&gt;&gt; foo(4) 9 Regardless, the point still stands that Python so heavily discourages closure use in both 2.x and 3.x (by not making `nonlocal` the default) that Python doesn't prepare you for the extremely heavy use JS makes of closures. I'd say that closures are used as frequently and are as important to understand in JS as iterables are for Python, whereas in Python closures are almost never used and could arguably be considered a [PEP-20 violation](https://www.python.org/dev/peps/pep-0020/). 
should we assume that's a typo and you mean "javascript" instead of "java?"
good reminder, nonlocal required for closures
I highly recommend using [Eloquent JavaScript: The Annotated Version](http://watchandcode.com/courses/eloquent-javascript-the-annotated-version). Eloquent JavaScript is a great resource but has a well-known history of people hitting a wall around chapters 4 &amp; 5 and not knowing how to proceed.
I think nonlocal is a keyword rather than the default for optimization reasons. I wouldn't say closures are discouraged; actually nonlocal is an accommodation for them, it's just awkward because the default behavior is more performant.
I'd recommend learning http://www.typescriptlang.org/
Speaking JavaScript: http://speakingjs.com/es5/index.html (Axel Rauschmayer is a great blogger on various JavaScripty things as well.) I like You Don't Know JS but it's not very efficient for beginners, IMO. His pluralsight course seem better, but I haven't taken them. The Good Parts was good, but a lot of practices have changed since. 
It depends. When I am writing code or doing continuous-integration-like testing, no. I only stick to what my project directly depends on. This way, my list of dependencies are almost always up to date (save for that one or two odd packages that depend on a specific version of another package). It has the benefit that newly-introduced bugs in dependencies will crop up sooner. When I am deploying to a server, once all dependencies are installed based on the requirements.txt file in my project, I update the requirements.txt file with the list of all installed packages, so that this deployment may be reproduced "as-is", whether on another machine or at another time. This way, I can test a deployment on the long term and know that my app is much more unlikely to break if I reinstall it at a later date or if I ever update my dependencies. It's a double-edged sword, really. As a general rule, I freeze the version of dependencies that are less "trusted", or more likely to break. There are however some libraries I trust more re. stability. For instance, I would be surprised that an update to pytz, or Django (within the same major branch) could introduce more problems than they correct.
Please take the time to watch this lecture - Javascript - the Good Parts. This gives a great background. https://www.youtube.com/watch?v=hQVTIJBZook
For frontend, avoid javascript ? I love Livescript http://livescript.net and its prelude functional library, there's also Rapydscript (very pythonic but less tools) http://www.rapydscript.com/ or Coffeescript.
It took me a while to parse that url; my brain kept telling me nyminutes was short for New York minutes.
 Well, yes and no. As the article you linked points out, once you have threads (which in this context includes coroutines), the problem of needing to maintain separate sync and async domains just goes away. The horror of asyncio is, that having solved the problem, the implementors then *deliberately added it back*, by giving the coroutine system a notion of what constituted code which was so different from the one used in the rest of python that any ordinary piece of code from outside the coroutine system just wouldn't run. 
Using the console to manipulate and then write mods for web games is how I learned. I think the main benefit of this is having to work with a range of coding styles, and digging a little into meta-programming. 
YUUUUUUUUUUUP. My bad. I program I promise.
+/u/ImgurLinkingBot https://gyazo.com/adf957fbcb19a5196e9c0be979916001
http://i.imgur.com/sSa3xON.gif
Hmm, as for me front-end JS is a "not good part" of the language. The problem is that browsers has a lot of limitation due SOP (and by browsers "design") and developers console in browsers is a crap (IMHO). Edit: funny Tumblr for understanding JS specificity http://jswtf.tumblr.com/
Good point. A correctly configured load balancer offers many of the benefits of a full web server.
Though your super() calls are still Python 2 style e.g. super(Python, self).__init__(**kwargs) can just be super().__init__(**kwargs)
As someone who's more comfortable with JS, What would you say is the Python equivalent of this?
Can you take a step back and try to explain what you're trying to accomplish? What is going on in this directory you're watching? There seems to be a few things wrong with your code which make it hard to understand what you're doing. Some of the basic stuff I can mention without delving into it: * Having an else clause after a while loop where you can't break from that while loop is useless. * Why bother allowing the specification of whether multiple files are wanted. It seems unnatural. If the user is passing in a pattern, they probably want to match against all of the files. * waitForFiles doesn't explicitly return anything, which means it'll return None. I then doesn't really make sense for verifyFiles to return that. * You have a fairly common race condition here. You look for the files existence, and then if it's not there, set up a watch for it. What if the file is created between the time you check for it and the watch is created? You need to set up a watch for it and then check for it's existence before (optionally) waiting for events. I think the waitForFiles not returning False, but returning None might what's messing you up here. What I don't understand is how is this function supposed to wait for files to be downloaded? If a file exists when it's called, but isn't done downloading, it'll return None right away.
Markov-Chains and Convolutional Deep Neural Networks fit this task. 
The goal of this function is make sure files are present. If the file is not there it needs to wait. I also need to make sure that the file is done downloading that way I don't pull a partial file. The multiple files flag is there because we want to make sure there are not multiple files (eg files left over from a previous day, or user dropped multiple files by mistake) I will take a look at the other suggestions listed
this is great, thanks for sharing it. one question, what's the difference between "DB.connect(['Cars'])" and "DB.Cars"?
&gt;actually scoping in JS makes more sense than in Python I am very curious what makes you say this. I work heavily with both and I almost never trip up scope in Python, but continue to in JavaScript. 
Pretty outdated TBH. I would recommend Secrets of the JavaScript Ninja by Jason Resig (created of jquery) or You Don't Know JS (which is available for free on github https://github.com/getify/You-Dont-Know-JS) for something more current.
I am using a tutorial right now that taught me how to make my own "Hello World" file. I changed some bits around, but it worked.
&gt; scrape :D didn't notice
Most likely people will just say use Swift in about two more years when it stabilizes. This approach just seems extremely complicated for what you get. 
Isn't Swift not cross-platform? Are people even using Swift for data science?
What kind of hello world would need requirements.txt?
I guess it's simpler in JS because you have to declare (`var`/`let`/`const`) variables before you can use them. So it's always clear which variables are local and which aren't and for those that aren't the rule "go up the scope chain until you find it" is pretty easy to follow. Compare that to Python, where you can also have nested functions but when you want to assign to an outer variables you have to mess around with `global` and `nonlocal` statements which can't even be used directly in an assignment. But you can still read from outer variables without those additional statements. So when you assign to a variable and forget the `global`/`nonlocal` statement it behaves differently, and if you then try to read from the variable before you assign to it there's an error. That has tripped me more than once.
I do, will definitely switch it up and see if that helps. Thanks for the info. 
The Oreilly rhino book or "The Good Parts"
Very cool, but what is the difference to numba?
I would check the length of trigger and if it's shorter than nine characters I would terminate the execution showing an error message to the user. But everything depends on your use-case. Generally it is a good idea to have exceptions shown to the user only when there is an unexpected error in the program's execution. Users do not like strange pythonic error messages coming from your program, because they might not know what they mean. If you expect an error to happen, check first or catch it (if checking first is not possible) and terminate the program controlled telling the user what happened.
&gt; IMO they're one of the main attractions of the language Why is that? I'm kinda confused as to the usefulness of closures vs classes, for example? Is it just concern about scope?
Numba is for actual use, this blog post is for teaching purposes. It is kept short and explained well, so you can actually understand what happens. With the stuff you learn there you could write numba-like stuff for special cases that numba itself doesn't cover. Just like when you take a class on building compilers, you won't build a full-featured C++ compiler as an exercise, but some small compiler for a simple language. 
Yeah because `let` &amp; `const` have always been a part of JS and are extensively used in the wild :P
I heard about this resource but I've never tried it. Looks pretty neat! 
I tend to like videotutorials and after them I always complement my learning with some books. What's your opinion on this one from udemy? https://www.udemy.com/understand-nodejs/
No one seems to point this out as far as I can read; async def is not just a new syntax for the "old" yield from syntax used in asyncio, async def comes with actual coroutines implemented natively which is not the same as generators. Currently there's a bridge in place in the implementation that allows us to use async def and yield from interchangeably but hopefully that will eventually end up being deprecated. More on topic; I find asyncio to be rather nice to work with, but it's far from perfect. The lack of documentation and examples being one example, the rather large code base of different implementations such as Streams, Protocols, Signals and low-level socket functions is inconsistent (why isn't DatagramProtocol.datagram_received a coroutine!?). It's a mess to properly cleanup your event loop once gracefully shutting down, and the list goes on. So yes, it needs some work and had a rather bad introduction into the standard library but it's still quite magnificent to work with if you give it an honest chance and don't expect it to solve every concurrency issue you ever experienced magically.
Reminds me of finish my compiler we build in class :) Anyway, a really nice tutorial. However i would still recommend using llvmlite instead of llvmpy.
There are some nice curated Python Doc lists. Not exactly equivalent but sporting great resources for Python beginners as well as masters: https://github.com/vinta/awesome-python If you're more into (paid) courses, i found this in my bookmarks: http://bafflednerd.com/learn-python-online/
`var` has always been, so that doesn't change what I wrote. In fact, `let` introduced a way to explicitly declare variables in block scope which is a feature Python is still lacking entirely. So there's yet another reason why scoping in (modern) JS is superior to that of Python. I'm not saying that JS is The Shit™ but in this aspect they nailed it, imho. Also `let` and `const` *are* getting used, but since your typical web application is targeted at every shitty browser in the wild you still need a [transpiler](https://babeljs.io/) before you can serve your code. Imagine every bit of Python you write needs to be able to run on something like Python 2.0. I think it's actually quite impressive that JS (or ECMAScript) manages to evolve into a usable language at the pace it does.
Yeah, I never got it to work. After 3 complete reformattings and reinstalling, buying books, scouring the internet, and losing an insane amount of sleep, I decided to throw in the towel. lol But thanks for the help guys! It was still fun! 
Just a demonstration
Sure thing, let me get right on that!
More generally, you should try to avoid writing numerical code in pure python. Any time you have loops with numerical calculation, you should vectorise using numpy.
Before you take this further, do you have a replacement for a proper whatsapp API?
Seems good! As for book, I can recommend Node.js in action (https://www.amazon.com/Node-js-Action-Mike-Cantelon/dp/1617290572) - not the new one but good at all. 
Not sure what you mean by JS pop up blockers. I was running my selenium on firefox and was not using any pop up blockers on that browser. Automation like this one is a lot of trial and error. It took me a good number of attempts to get it right. Sometimes having to switch between using an ID attribute or class or name. In a general aspect the only advice is to keep trying different things.
I'll probably have to go with some hacky solution like using Selenium to control the Whatsapp web interface.
Pendulum is a library to make Python date times more easy to deal with. Following the several feedbacks I received for Pendulum, I’m releasing the 0.3 version which brings a lot of improvements and changes. It’s important to note that this version causes major breaking changes, so if you’ve experimented a bit with the previous version just take a look at the changelog to make appropriate modifications. Those are essentially to simplify the API and making it more intuitive.
What's the deal with all the "we want more girls" and "free mentoring" in Python community - isn't it defeating the purpose of gender equality? 
To some "equality" means "we have to make the stats the same for both genders", but they tend to leave out the years of learning, work, dedication, and selflessness that someone like guido has put in; afaik there is not a female equivalent to him, and if there was an equivalent to the other core devs you know for sure that she would be invited in very quickly.
Whatever it means, I would welcome more women in computer science.
Plot twist: the website is made with Python 2.7
Got to double the supply in order to keep the price down.
I already have the ebooks so it's perfect!
At some point it might be easier to ask people politely to not spam the group?
Hahaha
Constructurs are the `__init__` functions. These are the `__init__` functions for the ops.
Well it will not be maintained by the PSF. However since the acceptance of py 3 is totally laughable I'm pretty sure somebody else will step up and the PSF and their failed py 3 experiment will be of no relevance. Meanwhile py 2.7 is and will stay the most stable interpreted language ever conceived. 
I think py2 will be around for a long time, too (perhaps with someone else maintaining it). But that doesn't mean py3 has failed. Both can both be popular and many people using them.
Swift is already running on Linux though it is under heavy development. It is under heavy development on Apples systems too for that matter. This is why I mentioned a future date as things need to gel and stabilize. The fact of the matter here though is that Swift has a lot of good features that make it a good candidate for a Python replacement. As for data science, development of libraries and support code has been so rapid I wouldn't even want to guess at what people are using it for or more importantly projected incorporation times. You need to remember though that this is a compiled language and as such some of the odd approaches to improve the performance of Python aren't needed. Basically Python for scientific processing has become a huge Kludge. Too much has been tacked on in the hopes of making Python competitive with compiled languages. This article is a prime example of a kludge. Swift on the other hand presents us with some of the same niceties with respect to syntax and readability in a more flexible language. I really see a future where Swift becomes the go to language that displaces Python and frankly a lot of other languages for this type of computing. It is a very balanced language. In any event you seemed to missed completely the point about two years or so from now. 
I don't know if it's fair to call it failed, however, I would certainly not call it a success. It's hard to find exact statistics, but with a quick google I found [this](https://blog.josephscott.org/2015/05/15/python-version-usage/) from last year, indicating just 17% adoption of Python 3 after 5 years. That's pretty terrible. Here's [another](https://w3techs.com/technologies/details/pl-python/all/all) indicating only 3.5% adoption for python webapps. Breaking backwards compatibility was a huge mistake. I know it's messier, and not as "pythonic", but they should have left support for legacy syntax, functions, etc. alongside the new stuff. Allow 2.7 code to work instantly, but get the linters, IDEs, and other tools to start warning for deprecated code. Or, perhaps find some way of allowing old syntax using some kind of directive, so that you can integrate old libraries and code, while using Python 3 in new code.
Little did I know that "Guido" is pronounced "Gee-doh".
Just to be clear my old library usage accounts for less than 5% of the code I'm writing. If ti was any more we'd put in the effort to port it to py3.
Did you try https://pypi.python.org/pypi/sharepoint? It supports custom urllib2 openers for which you might wanna try https://pypi.python.org/pypi/python-ntlm
&gt;If there are two people who are close and one is male and one is female, then choose the female since she's underrepresented in the field. Simple as that. That's horribly sexist and I hope you're joking. Equality means equality, not inequality when it serves your purpose. You have to be retarded not to realize that you can't 'give' someone a position they're less suited for without taking it away from someone more deserving. 
That article is ridiculous and this entire train of thought that acts as its premise is getting out of hand. "Something bad happened to me and I happen to be a women, therefore it happened because I'm a woman" 
I did something like this several years ago using pcap data stored in MongoDB. The following looks like it might be appropriate: http://stackoverflow.com/questions/33165212/reading-pcap-file-from-stdin-in-python-scapy
Yeah, encourage more girls to spend time with their computer in school and to choose college major. It's unfair that women already in tech get preferential treatment compared to their make colleagues. Personally I don't mind that much as there is enough work in tech and everyone can find something well paying if they are competent. I just think it creates a toxic environment. Sticking to meritocracy or at least striving for it is a fundamental part of tech culture. I wouldn't want to work for a project in which quotas based on gender are used to determine who does what.
Outside of certain fields that's no concern at all. E.g. we mostly use matplotlib, seaborn, numpy, pandas, scipy, and scikit-learn. They've all worked with current versions of Python for years
Deciding ties according to gender is discrimination based on gender. Even if you're not sued you will see people leave over it. 
Because website loses its purpose after countdown just like py 2.7. Sounds perfect tbh.
If one house is on fire and another isn't, and you have a firehose, does using it on the burning house "defeat the purpose of house equality"?
What's "debatable" about it? If half the population have been historically excluded from a profession, why is it not a case of "oh wow, probably a lot of really good people we could hire if only we get them in the industry"?
I think it probably is debatable whether there should be exactly a 50/50 split, but at the moment Python is developed by a core team with a 0/100 split, and the programming world at large has gaps ranging between 30/70, 20/80, and 15/85. Those aren't healthy numbers by any means.
I can do that too, though. [Here's one saying python 3 is more supported, now.](https://blogs.msdn.microsoft.com/pythonengineering/2016/03/08/python-3-is-winning/) [Here's one from anecdotal evidence](https://www.quora.com/Is-it-better-to-use-Python-2-or-3-in-2016) [Here's one saying either should be fine, but 3 is better to start with](https://www.fullstackpython.com/python-2-or-3.html) [An opinion that has changed in 3 years to support Python 3](https://jakevdp.github.io/blog/2013/01/03/will-scientists-ever-move-to-python-3/) If you want to use Python 2 then do it, but realize that you are part of a dying crowd. I dare suspect no significant new tools will be produced for 2.7 ever again.
Do you have a link to this change? [Dialect.delimiter](https://docs.python.org/3/library/csv.html#csv.Dialect.delimiter) still says that it accepts only a one-character string, or are you referring to something else?
Jesus man, use the API
Wow, thanks! Didn't notice it, was looking only at the string inside the tags.
That's not pretty terrible; Guido said there were similar lengthy upgrade cycles for older Python 2.x versions too. It actually means that Python is so popular that it's entrenched in long-term enterprise applications.
Not in Italy where the name comes from, but in some northern European countries.
I've never heard of any of those, but it left out [Haxe](https://haxe.org/), a somewhat better-known language that compiles to... almost everything. Between the superglue powers of Python and the compile-to-everything of Haxe, they might be all a developer ever needs.
If there's someone who's measurably worse, don't go with them. If there are two people who are mostly the same, you can either flip a coin or aim for diversity. Why is random chance *better* than actively seeking out diversity in any kind of context? I say this as an upper-middle class white guy who would always "lose" if diversity comes into play. I'm still for it. I'd rather see a community of people who bring different things to the table.
“string” meaning “bytes” and “character” meaning “byte” in legacy Python, but actually real Unicode strings and characters in current versions
Let's not rehash the static/dynamic fight *again*. You probably are talking about type errors appearing when something gets changed. That's usually because terms are too broadly scoped. *Well written* Python is either functional or well encapsulated if oo so the effect of changing something is much less due to tighter scope. Also, Python is highly expressive and has superb libs so there's less LoC to change to begin with. As to lack of quality control... Depends where you work, really.
Can you elaborate? I don't see anywhere in the article where she describes something that might have just happened to anyone male or female. I mean, as a guy I can't speak to the experiences women face in the tech world. If you have had different experiences I'd love to hear it. I don't think I know personally any women in the tech world that haven't encountered one form of bullshit or another just because of their gender.
Obvious but not obvious. 
If you have that kind of control over your codebase, then I can see Python working quite well for you. Indeed, in the few instances (very few) where I've had full control over my Python codebase it turned out ok. But even then, I'm way more productive with the help of a compiler. Personally, it's no competition. I'm fully willing to accept it could be different for other people in different circumstances. But for my own, C# has been undeniably superior.
&gt; That's horribly sexist and I hope you're joking. Equality means equality, not inequality when it serves your purpose. You have to be retarded not to realize that you can't 'give' someone a position they're less suited for without taking it away from someone more deserving. Did you read the part where I said "close"? Often it's difficult to make a judgement purely on numbers. There are all kinds of variables that can't be measured. Given that, and given you can't be certain which contributor will eventually be better, if you have two people who are more-or-less equal in ability, you may as well go for diversity. And again, close. If it's clear that one of them is obviously better, go for the obviously better one. But if it isn't, there are other factors you might subconsciously use — culture, for example, or even a desire to not appear "reverse sexist" or whatever — that might lead you to choose the man when actually the woman *was* the better candidate. Do you see what I'm getting? If it's close between two candidates, choosing a woman might be the better choice just because with all of the various barriers and issues in the coding community, going for inclusiveness is a positive decision in the long run anyway. 
OP -- you find anything?
The closest thing I've seen to that is a "use as a tiebreaker in event of equally-qualified people". But then I don't interpret "make efforts to help women get into the industry" as an automatic "lower your standards", because I don't see women as inherently less-qualified the way you do (and let's be clear: the only logical way to get from "help women get into the industry" to "prefer less-qualified people" *is* to assume women are less qualified by default, so you need to own that assumption sooner or later).
You can use a StringIO() object: from cStringIO import StringIO fd = StringIO('\xd4\xc3\xb2\xa1\x02\x00\x04\x00\x00\x00\x00\x00\x00\x00\x00\x00\xff\xff\x00\x00\x01\x00\x00\x00\xe3\t\x84W\xc0\xb5\x01\x00"\x00\x00\x00"\x00\x00\x00\xff\xff\xff\xff\xff\xff\x00\x00\x00\x00\x00\x00\x08\x00E\x00\x00\x14\x00\x01\x00\x00@\x00|\xe7\x7f\x00\x00\x01\x7f\x00\x00\x01\xe6\t\x84W\xbd\x86\x00\x00*\x00\x00\x00*\x00\x00\x00\xff\xff\xff\xff\xff\xff\x00\x00\x00\x00\x00\x00\x08\x00E\x00\x00\x1c\x00\x01\x00\x00@\x11|\xce\x7f\x00\x00\x01\x7f\x00\x00\x01\x005\x005\x00\x08\x01r\xe8\t\x84W\xcb\xc3\x0e\x006\x00\x00\x006\x00\x00\x00\xff\xff\xff\xff\xff\xff\x00\x00\x00\x00\x00\x00\x08\x00E\x00\x00(\x00\x01\x00\x00@\x06|\xcd\x7f\x00\x00\x01\x7f\x00\x00\x01\x00\x14\x00P\x00\x00\x00\x00\x00\x00\x00\x00P\x02 \x00\x91|\x00\x00') rdpcap(fd).show() # 0000 Ether / 127.0.0.1 &gt; 127.0.0.1 hopopt # 0001 Ether / IP / UDP 127.0.0.1:domain &gt; 127.0.0.1:domain # 0002 Ether / IP / TCP 127.0.0.1:ftp_data &gt; 127.0.0.1:www S 
You should be able to pass the result of the `urlopen` call directly to `rdpcap`. Although this doesn't seem to be a documented feature, Python libraries are generally designed to accept "file-like" objects. It's a bit buried in metaclass magic, but Scapy's `RawPcapReader` will [accept either a filename, or a file-like object](https://github.com/secdev/scapy/blob/4fc399a985614956337805492c851b2aaacf267b/scapy/utils.py#L601). Note that `rdpcap` is basically just a [wrapper around RawPcapReader](https://github.com/secdev/scapy/blob/4fc399a985614956337805492c851b2aaacf267b/scapy/utils.py#L553).
An appropriate user name
It's not that hard to keep quality up if you set standards and do reviews based on those standards. Sometimes you see people doing reviews based on what this senior or the other feels is best, resulting in the devs being pulled this way and that. A concise written standards doc is a bit of an up-front cost but are well worth it. Another good aspect of Python is that it's actually pretty easy to concoct universal standards. The /r/programming threads about C scares the shit out of me, there are so many rival schools of thought. You can also specify a subset of pep-8 to run before push is allowed. We do have some nasty legacy code, methods with hundreds of lines of code... but those responsible have all learned their lessons and are much better now, lol.
Hi chief Dan Do you think you can help