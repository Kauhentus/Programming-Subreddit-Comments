Ha, you're welcome. 
Seems like people are pretty sick of it this year, what gives?
Hey, I updated the script significantly. Here's a link to the new one http://www.mediafire.com/?wcj2732299gy7ov. I'm working on moving it to github.
yeah, i have been seriously considering this approach
Great advice, thank you. I'll try this out now.
Well, it's the first time I hear of this program. I am rather glad that someone posted it again. Also, it seems interesting to talk about the inner workings or "design" of Python programs. 
It sounds like maybe you have it installed for Python 2.7, but not 3.3?
It's Turkish. Even though I can read it most people can't hence the downvotes. -- Ben Türkçe biliyorum ama reddit/r/Python bilmiyor. Ondan bu kadar downvote alıyorsun. 
I have actually done something similar for testing purposes. I wanted sample python code that exercises all of Python's syntax for testing an import hook that performs AST transformations on the imported module. I wrote a test that scans the python standard library and trys to import everything. This "import everything in the medicine cabinet" had some unwanted side effects like opening http://xkcd.com/353/ on my browser... 
[Here's the video along with the slides](http://pycon.ru/en/program/content/django-roadmap/).
I use PythonBrew - https://github.com/utahta/pythonbrew - spot on. Bit like RVM for Ruby.
The practical dev in me is reflexively hyperventilating. This is really hard to read. How does this work, exactly? List comprehensions lend themselves to loops natively, so that seems trivial for this purpose (or maybe I'm not understanding exactly what the problem is). It's 4:30am here...pardon the slowness.
Is there a roadmap _document_ somewhere that we can read, or is the only option to watch a two hour presentation?
`cat` is complete.
Here's an example: [curl](http://daniel.haxx.se/blog/2013/03/23/why-no-curl-8/)
I noticed that the source code of the release version of youtube-dl contains a zipped content. I've never seen that before. How does it work with Python? How to build it?
Yeah, don't use GAE :)
More fun with lambdas: # compute 6 factorial print((lambda F: (lambda x: F(lambda y: x(x)(y)))(lambda x: F(lambda y: x(x)(y))))(lambda fact: lambda n: 1 if n == 0 else n * fact(n - 1))(6)) # compute fibonacci(22) print((lambda F: (lambda x: F(lambda y: x(x)(y)))(lambda x: F(lambda y: x(x)(y))))(lambda fib: lambda n: n if n in {0, 1} else fib(n - 1) + fib(n - 2))(22)) In both cases the first chunk of stuff is the [Y combinator](http://en.wikipedia.org/wiki/Fixed-point_combinator#Y_combinator). 
yeah, it's fucking bullshit right? I thought it was just my general incompetence and amateur status. I use amazon and linode a bit and they're great. I can't imagine anyone actually using GAE for something serious... it has a kind of geocities feel to it. What's your experience been? 
If you're lazy: deploy to heroku, otherwise deploy to your own server/amazon.
I think Guido should have just executed people who didn't port to 3. It wouldn't have taken many. After the first dozen, people would know that he meant business about it. 
Hi, Not sure why nobody has mentioned Cube and Cubism - both were originally written by Mike Bostock - author of D3.js. http://square.github.com/cube/ http://square.github.com/cubism/ Cube is a system for collecting and storing time-stamped events, and calculating metrics around that. It's built on top of Node.js and MongoDB. Cubism.js is a D3-based Javascript library that lets you create cool horizon graphs - it can use Cube as a backend, Graphite, or others. Cubism is awesome in that it will only poll for new values - and then uses Canvas to shift things by one pixel, adding a new point, then repeating. This is much better than doing a full refresh each time. Would something like that be suitable for your needs? Cheers, Victor
I think we may have had this discussion already, but you can alias yturl="youtube-dl -e" can't you? And that will work for vimeo, blip.tv, or everything else youtube-dl supports. Disclaimer: I'm one of the authors of youtube-dl.
This looks very professional, and could be useful in itself for presentation if I were to make a web front-end, etc. but at the moment I have very little experience with Javascript :/
 x=~/.youtube-dl-$RANDOM-$RANDOM.flv youtube-dl --output=$x --format=18 "$1" ffmpeg -i $x -acodec libmp3lame -ac 2 -ab 128k -vn -y "$2" rm $x I've been using this bash script for ages. It uses youtube-dl to get an mp3 from a youtube vid. Linux only for this example. You also need ffmpeg.
This pretty much needs to happen. Node has a package manager (by default) and "they" didn't exactly get a head start.
Now that you've discovered fixed-point combinators, you might want to take a read of [Oleg Kiselyov's page on the subject](http://okmij.org/ftp/Computation/fixed-point-combinators.html). His site's full of interesting stuff.
Could get started with http://codon.com/programming-with-nothing before going for Oleg.
I'm quite aware it's unoriginal; I've done the same thing in Scheme, just never thought of the general case. 
It's much more obvious in Scheme (or probably other Lisps), but this is equivalent Python code using variables/function definitions: def blastoff(func, val): if val &gt; 0: print(val) return func(func, count - 1) else: # Reaches a stopping condition when val &lt;= 0. return print("Liftoff!") blastoff(blastoff, 10) The `and (print(...) or True)` is just there to ensure the body is executed; it serves no other purpose, and could be replaced with more lambdas and currying. Also, it's deliberately hard to read, that's the fun! Edit: I meant using list comprehensions for while loops. It's late here, and I gave up figuring them out after getting the lambda version to work.
Yup, that's a good one. Also, Reg Braithwaite's stuff on combinators is good, and entertaining too.
That's really neat, thanks!
Came here to say the same but you already took care of it! 
Note Python does not have tail-recursion optimization though, and the standard recursion limit is fairly low (10000 stack frames IIRC), so it really doesn't lend itself well to this manner of programming. Not to mention function calls are rather expensive (though that's more of a CPython issue)
Anyway this could easily be edited to be given a text file instead of a subreddit?
Should be easy. Source is on GitHub.
Tapping my feet for the 1.5-compatible version of `django-registration`. Hopefully it won't be too long.
Nice. Not overly complex, clean and simple.
https://gist.github.com/e000/1023982
[https://docs.djangoproject.com/en/dev/releases/1.6/](https://docs.djangoproject.com/en/dev/releases/1.6/) is the easiset find. Not sure if there's anything better. 
Can you elaborate what you mean by code quality, i.e. point out a couple of examples? And where is data intermingled with code in youtube-dl?
I figured it out. I had to add the module location to the pythonpath for 3.3
OH YES *orgasm noises*
Hmm... I have a question about one of the examples... there's this little bit of code: x = None for i in range(6, 0 -1): x = [i, x] Pythontutor "visualizes" this as a linked list, in the traditional sense, where the node contains a pointer to the next node, but doesn't this just create a nested list with `i` levels in python? to a beginner like me, this is really confusing. if anyone wants to try it, it's the LL1 linked list example. edit: ran the loop in the interpreter and this is the result &gt;&gt;&gt; [1, [2, [3, [4, [5, [6, None]]]]]] All in all, I think the site is really a great idea. I think this is just an issue with a specific example.
Generators are the way to go to avoid O(n) space problems such as stack overflow. lambda x: all((print(something), 1) for _ in xrange(0, x)) You can even use list comprehensions to perform assignment. 
Not my code, but by /u/FatHat, infinitely printing fractal triangles using only one root expression and no statements: (lambda: not globals().__setitem__('sys', __import__('sys')) and not globals().__setitem__('this', sys.modules[globals()['__name__']]) and not globals().__setitem__('time', __import__('time')) and #program [setattr(this, k, v) for k,v in { 'set_color': (lambda c: w(['*', ' '][c])), 'abs': (lambda t: (t + (t &gt;&gt; 31)) ^ (t &gt;&gt; 31)), 'w': sys.stdout.write, 'smash': (lambda t: -((t * -1) &gt;&gt; 31)), 'color': (lambda n,k: set_color(smash (k &amp; (n - k)))), 'col': (lambda n, k: k &lt;= n and not color(n,k) and col(n,k + 1)), 'row': (lambda n: not w(' ' * (40-abs(n/2))) and (col(abs(n), 0) or True) and not w(" ") and (abs(n) &lt; 63 or n &lt; 0) and not time.sleep(0.05) and row(n+1)), 'triangle': lambda: row(-60) or True and triangle() }.items() ] and triangle() )()
It seems weird to me that that would be the case... seeing as python has closures/variable bindings anyway, I wonder how hard it would be to translate `return func(arg)` into a return of an magic object immediately followed by the calling of that object. I suppose it'd break stack traces for exceptions, but you could add the stack trace as a separate hidden variable to the returned magic object.
You can increase the limit. Well written recursion still runs great in Python. Just the hacked 'for the sake of using it' code is unoptimized. I believe based on the post, this is intentionally 'for the sake of doing it'. Despite the solution being un-pythonic in nature (Pep8 - readablity first) it is interesting to see one liners in any language :) at least I think so.
this reminds me of a [Gist: how not to use lambdas](https://gist.github.com/e000/1023982) discussion thread http://www.reddit.com/r/Python/comments/hyxle/python_fun_with_lambdas_or_how_to_never_use/ 
Enthought are laggards and have no enthusiasm for Python 3.
[Yes](http://docs.python.org/release/3.0.1/whatsnew/3.0.html#overview-of-syntax-changes)
What is the advantage of using a generator expression over a "proper" generator? If you go with the latter approach, you have to use a few more lines, but you get back some readability.
I see what confused me now.. Your method of calling the second lamda with the first. This is really kind of cute, but also one of those things I quit Perl to get away from. :-) :-) :-) Note to self: Pick up Scheme or Clojure.
That's a lot of data.
&gt; However, you do seem to have a lot of negativity towards recursion in Python. I just think people need to know Python, especially on CPython, isn't very good at it. And if you have a recursive and an iterative way to do something with roughly the same pain you should pick the iterative version (liberally using generators and iterators).
On the one hand, this kinda feels like a duct-taped on hack. On the other hand, this solves a real problem that a lot of people have. Maybe it'll all come together when I see the entire `distlib` solution in Python 3.4. Also, if you don't understand how bad the current state of play is or where the wind is blowing, [watch this](http://pyvideo.org/video/1731/panel-directions-for-packaging).
http://nedbatchelder.com/blog/201205/recursive_dogma.html
Hi r/Python!, co-founder here. We're opening the doors to our private beta and looking for feedback. If you're interested, sign up and we'll send you an account.
That's only data for a very liberal definition of *data*: In both cases, these are the details of the service in question. It's not like any user would ever want to customize the video format IDs that youtube provides - at least, we haven't had a request for that so far. And note that the definitions *are* separated from the actual code; they're both in the header of the respective class. We're using regexps instead of parsing HTML and XPath (or CSS selectors) because most services do not produce valid XML or XHTML, and Python's built-in parsing facilities for HTML are abysmal. youtube-dl does use XML parsers for services that are known to provide XML. I'd would love to use lxml instead, but not all of youtube-dl's users don't have that installed. I'm not sure what you mean by *unclear code scope*. In any case, you (and everyone else) is more than welcome to provide a pull request or open an issue for to increase code quality.
Additionally, for those that we just sent an account and for everyone else, here's our tutorial on deploying a new Django project: &gt; https://docs.freedomcp.com/django-tutorial.html
i would just like to point out how butt hurt you seem to be about all this. As always I ask "How has this affected you personally, how does it hurt your ability to do YOUR job?" to all the butt hurt haters, and no one has yet to answer. Do you dare?
ALSO 2.7 4 LYFE!!!!
&gt; "you should avoid recursion" is a bit strong. You need to understand the limitation. which is my point.
I've been looking for a dataset to play with pandas with. Looks like the motherlode!
Yes, but when use properly recursion isn't bad in python. Which is my point :)
And context is important, I was replying to somebody coming from scheme and showing a tail-recursive and idiomatic scheme function, in Python. Such a function is "proper recursion" in Scheme. Or Erlang. But probably not in Python.
Glad you guys are finding it useful! Let me know if you can think of any improvements with the package. :)
There's no PyPI release for it, but James did the work for 1.5 post PyCon IIRC - tip on bitbucket purports to have it merged in.
Feels a tad stringly typed, with things like dates, frequency, and types being specified by passing strings, where it might be safer/better to either take objects of the appropriate type, or enumerated via constants. For instance, looking at the examples on the github page, things like this: data = Quandl.get('PRAGUESE/PX',authtoken='xxxxxx',startdate='2001-01-01',enddate='2010-01-01',frequency='annual',transformation = 'rdiff',rows='4',formats='numpy') might be better as data = Quandl.get('PRAGUESE/PX',authtoken='xxxxxx',startdate=datetime.date(2001, 1, 1), enddate=datetime.date(2010, 1, 1) ,frequency=Quandl.ANNUAL,transformation = Quandl.RDIFF,rows=4,formats=Quandl.NUMPY)
I don't feel like "run the whole thing in screen" is breaking the workflow. The primary point he's making here is that having a "deactivate" function is pointless because unix processes and subprocesses are designed from the ground up to have that behavior.
Not yet. What's your tech stack look like?
&gt; To think that you won't ever be on the receiving end of one is hubris. Actually we don't use any external-facing python code, so security fixes aren't a compelling reason to upgrade versions.
i live in venice and zefr is huge to our community! love it! 
It's mostly Python 2.7 on Ubuntu 64-bit but there is nothing really stopping me from migrating these apps on 32-bit Ubuntu away from it, more than anything I was curious. Look forward to giving it a try.
Hey, I'm working on the code, and definitely agree about use of basic python types. I added datetime support alongside the string date parsing. As of now I'm not completely convinced about changing to enumerated constants. The strings parameters are barely used, and not manipulated at all, and making special objects for each seems like it would just make use more confusing. 
And you are disingenuously ignoring the same set of arguments you're making as they apply to your statement. Look at the cd, or p(ush|op)d commands. They modify the working environment too. Your argument is they should actually invoke new subshells at a different location. "Oh you say, that would be silly, you'd be so nested in subshells exiting would be really hard". That's my point too. I like to switch envs a regularly and often. Sure, I can just swap between screens to do it. But you should have to swap between screens and other hacks around nested shells for changing directories. If you don't you are being absurdly and pointlessly hypocritical with your purity based argument.
works with SQLAlchemy too ! https://bitbucket.org/zzzeek/calchipan /shamelessplug
Can you sum up what the datasets are, what a killer app might do, and why this is useful? 
dbpedia?
Freedom *cp*? Might want to reconsider that name.
Lots of the time, throwing away the data is not an option. Data is not always generated by customers, for example. Even so, some large systems are under constant development, eg. online games. Safety vs liberty is a classic tradeoff and sometimes you want the liberty. There are many applications where a risk of losing some data and reverting to a day-old backup is fine, but forever delaying development and improvements on a live product because you have a rigid DB schema system is not.
After the first deployment, schemas and proper transactional migrations are precisely what make this sort of change easy. You never have to worry that your app might not handle old records or that new records could break your old code while it's being deployed. Schemas make all of his much, much easier. Before that (during prototyping) throwing data away isn't a big deal.
That's fantastic, thanks! I hadn't even considered classes!
Upgrade your OS for heavens sake! 10.6 is outdated in any conceivable way.
Start at kivy.org :-)
One thing I like about running [Anaconda](http://continuum.io) is that it comes with its own package manager which can also wrap pip, so the few modules it doesn't come with are easily installed and managed from within the one system; from a systems perspective uninstallation is just rm -rf /wherever/you/put/anaconda (you don't need root, unless you deliberately want to put it somewhere that would otherwise get EACCESS) I've been playing around recently with data visualisation and one of the free tools out there depends on some of Enthought's libs, so I "conda pip install traits" and "conda pip install chaco" (the latter was a little fiddly with some dependencies, but I got there in the end) One thing to be wary of (particularly the more you install out of homebrew or whatever) is stuffing $PATH too much. Some of my problems installing chaco dependencies was that it was attempting to use bad versions of things due to $PATH having ... unexpected alternative versions, shall we say. If you just want a plain python 2.7, homebrew has it. *brew install python*. I have four python installs (system, 2.7 &amp; 3.3 from homebrew, and Anaconda) but as I mostly use anaconda I don't have to worry too much about messing with $PATH. Using zsh as my shell makes it easier to manipulate $PATH, but I haven't had the Mac long enough to figure out an easy way to propagate environment changes across iterm2 tabs, which is the thing that bugs me the most in my setup. 
Very cool graphics, no big surprises other than the absence of the word "dongle" as noted elsewhere. :)
I think this has some value. For some reason, Windows users like to deal with single files and many of the "freeze" type programs are difficult to configure or are no longer maintained. 
Never heard of Bradley Manning eh?
lambda classes? i'm sorry sir, that's NSFW
This looks really cool, but exactly what information is it showing? Appears to be all stock information, right? IBM and GOOG are on the NYSE and Nasdaq, respectively, and IBM is put in as NYSE_IBM, does that mean it defaults to the Nasdaq? When it says "OIL" in the token example, is it talking about a benchmark price of oil or a stock with those initials? If a benchmark, which benchmark? Similarly, is NSE the Indian Stock Exchange or a stock with those initials, and if so on which exchange? Is there a summary of the types of information available and how to call it somewhere? Where exactly does the information in the database come from? Edit: I see a lot of my questions are answered in [the faq](http://www.quandl.com/faq)
Also, if you already have programming experience the Python website has recommendations for those that are [new to programming](http://wiki.python.org/moin/BeginnersGuide/NonProgrammers) and those with [programming experience](http://wiki.python.org/moin/BeginnersGuide/Programmers) 
Even more fun: f = type('F', (dict,), {'__missing__': lambda self, n: self.update({n: self[n - 2] + self[n - 1]}) or self[n]})({0:0, 1:1}) It's a fibonacci-dictionary with caching: &gt;&gt;&gt; f[10] 55 &gt;&gt;&gt; f {0: 0, 1: 1, 2: 1, 3: 2, 4: 3, 5: 5, 6: 8, 7: 13, 8: 21, 9: 34, 10: 55}
Yeah, once we went from a true page break to caret-ell, it was all downhill from there. :-/
Please don't use enumerated constants. We are programming in python not C/Java. 
Hmm why not .pyxz format as well? http://docs.python.org/3.3/library/lzma LZMA2 needs more love :D
Would be interesting to do these lambda functions on columns in Pandas.
Continuum's Anaconda distribution ships with Python 3.3 for some platforms, and that includes Numpy. http://continuum.io/anaconda
Could you please elaborate more on your expectations?
I've wondered this for a while as well and I think it's because of one of two things: 1) Python can't handle spaces in its path 2) There are problems with the permissions on the "Program Files" directories such that it's problematic to install there.
Are you sure there are problems with spaces in the Python path? I usually install to Program Files without a problem. I would also be if surprised the installer can't manage the Program Files permissions. Even the smallest piece of Windows freeware seems to have a decent WiX or NullSoft installer which handles this sort of thing.
I am experienced in both Python and C#/.NET development, and would definitely recommend Python over C# for most situations. Things are just... easier in Python. Stuff that would take days to write in C#, takes hours in Python. Python has a vibrant community around it, and there is a Python library for just about _anything_ you might want to do (the same could be said about .NET to an extent, but Python's ecosystem is probably more mature). Python also makes it easier to start with a short script to try out new ideas and then scale them to full applications. The syntax is clean, concise and expressive. The core language is small, elegant and easy to learn. I find that it provides a more enjoyable overall programming experience. 
I would go if it wasn't in Tasmania .. 
You should only need to write to the install dir when installing packages.
I am developing a small online test system to test students (flask). I am also working on a tool for stochastic process algebras. Real pet project was pycello, ncurses 2d cell automata soft but abandoned for now.
What if the modules depend on compiled pyd extentions? If this could include an option to extract the module to a temporary location and add that location to the path (like pyinstaller does) that would be very useful. 
Isn't that one of those official white house photos with the following disclaimer: &gt; This official White House photograph is being made available only for publication by news organizations and/or for personal use printing by the subject(s) of the photograph. **The photograph may not be manipulated in any way** and may not be used in commercial or political materials, advertisements, emails, products, promotions that in any way suggests approval or endorsement of the President, the First Family, or the White House. 
The conference venue was great last year and the Hobart has some attractions (very nice food, awesome whiskey distillery, MOMA, etc.) which aren't far from the venue. And it's relatively cheap. And not very far to fly. And so on :-)
C'mon, not everyone spends most of their time on 4chan.
Or don't make too much new extensions and go with .pya.zip, .pya.7z, .pya.tbz, .pya.tar.xz. since it's not DOS 8.3 time anymore.... or wait, is it? What are the abilities of various systems regarding file associations for complex extensions?
it's not the location per say it's more the cost for a uni student to go :P
&gt; wants to install to C:\ So do cygwin, mingw, codeblocks, chocolatey and several others; the only guess I can make is that they're meant to be at least remotely conveniently runnable (e.g. as `c:\Python27\bin\python somescript.py`) in case they are not added to `%PATH%` for some reason. As for the installer look&amp;feel... I would guess it just wasn't replaced with anything else in a long long while.
The series should have a `hist()` method, try that.
What do you recommend as an IDE for a C# developer? Lots of us are used to the Intellisense or even ReSharper.
As someone who knows very little Python (just learning), can any one enlighten me a little about how something like this works? I wouldn't have thought that languages were 'translatable', as it were. Or is that not really what is going on here?
When I looked at it two years ago it wasn't being actively developed any more. Has someone picked it up again? 
I would recommend Python over .NET/C# in many cases. Start by downloading the C based implementation over at http://www.python.org/download/ . Then head over [Zed Shaw's LPTHW](http://learnpythonthehardway.org/). You should know that in many cases, you will not need an IDE for Python as you do with C#. A simple text editor is often enough.
Hi Wolfgangers, Python as a language has a heavy amount of introspection features that allow you to see how code is written from within the run-time itself (essentially it exposes functions and methods that you can point towards a python method or class and get detailed information what it's doing and how its implemented). This makes converting from python a much more straight forward process, as you don't have to parse the source file yourself. For an example you can see the WebBot ToClientSide module which is a fork of just the python-&gt;js conversion part of pyjamas: https://github.com/timothycrosley/webelements/blob/master/WebElements/ToClientSide.py Hope this made some sense, Timothy 
ZIP files can contain .xz-compressed members. Python 3.3 supports this in zipfile but not on sys.path. Perhaps in the future the zip importer will be rewritten in Python on top of the zipfile module and this will work.
A bit, [see the github commits](https://github.com/pyjs/pyjs/commits/master)
To handle extracting .pyd would require additional tooling beyond the proposed feature. Third-party tooling will probably emerge.
I really like the python-&gt;javascript conversion part of this project and use it as part of [WebBot](http://www.webbot.ws/), However I do not like the concept of building the entire (or the majority) of the user interface client-side using JavaScript, as this leads to slow performance and needless loading screens - where the initial page loads instantly when the DOM definition is supplied by the server initially. 
Not keen on this: "For UNIX users, .pyz applications should be prefixed with a #! line pointing to the correct Python interpreter and an optional explanation." Standard zip files would be better, one could easily open them in ones archiver of choice to troubleshoot.
I'm in the same situation. I'm just learning Python and I'm used to using Visual Studio. I looked around and the best I could find for my needs was PyCharm. I use a mix of PyCharm and Sublime Text 2. I develop in Mac, Windows and Linux, so a cross platform tool set was preferred. I mostly use PyCharm though. So far, I'm very happy with this combination.
I find Dive in Python is very good (http://www.diveintopython.net/). I learnt a third of it now.
Different. But have you seen the new Microsoft Data Explorer? It allows you to pull in any structured data from Wikipedia, pretty cool.
The datasets are pretty wide ranging, but currently are mostly focused on finance, economic, and social data (note that we specialize in time series though). The range of usage in apps is pretty large, but we just partnered with www.quantopian.com to provide our data for their algorithmic trading platform, I think that's pretty awesome. Are you asking why the Python package is useful, or why Quandl is?
if you can at least maintain your standard of living switching then go for it. it's awesome not being on the endless treadmill of .net runtime/os/ide upgrades. You may experience a little friction using windows though. Most tutorials assume a unixish os, and building C extensions is a crap shoot. 
Personally, I use Vim with python-mode plugin bundle and ctags. ctags offer good autocompletion and integrate pretty well with Vim. It's not Intellisense, but then Python is a dynamically-typed language so you're not gonna get Intellisense-like completion no matter what you use. python-mode includes ropevim which gives pretty good refactoring (similar to ReSharper). Vim does come with a steep learning curve, so if you're not already using that as your editor, then Eclipse+PyDev is a good choice. I also understand that PyCharm is a popular choice, but I have no experience with it myself. 
Can you queue multiple jobs yourself and do them severally?
Does this have support for jQuery? My recent python project has ended up with me learning jQuery, but dynamically pumping out JavaScript could be useful for what I have in mind. 
In general, a single Python script using the CPython interpretor will never be able to take advantage of multiple cores via threads because of the GIL; even when there are multiple threads there is a single lock shared by all threads. To actually utilize multiple cores you have to create a separate process (see: [subprocessing module](http://docs.python.org/2/library/multiprocessing.html) which AFAIK just creates a separate interpretor instance. But that's somewhat irrelevant; the main motivation is to allow more communication per thread/process because---as Guido mentioned---the number of sockets allowed by the OS is much larger than the number of threads allowed. If this wasn't the case then we could simple use multiple threads but there is also incurred overhead in doing this. This approach has increased performance at the cost of code complexity and all solutions, like this, are simply trying to hide that complexity.
There are a few ways. The most notable is using (and I may not get the name 100% right here) is instanceof(*variable*, className), which returns true if it is.
lookup isinstance()
~~you could also use type(animal) == type(Dog()), however i think isinstance() looks cleaner.~~ Edit: dont use type apparently, Rhomboid explains why!
You don't need to instantiate the type and then extract it; type(animal) == Dog works fine (although I'd use *isinstance*) Also, /r/learnpython 
In your example, you would just do: if isinstance(animal, Dog): # do something The reason animal == Dog() doesn't work is that you're comparing two different instances, you aren't checking if animal is an instance of the Dog class. When you use parentheses around a class like "Dog()" you are creating an instance. So technically you've created 2 Dog instances, when you only need to create one and check its type. Read more about [isinstance here](http://docs.python.org/2/library/functions.html#isinstance). 
I think the operative line here is: &gt;that in any way suggests approval or endorsement of the President, the First Family, or the White House. I hardly think anyone reading that blog entry is stupid enough to think that President Obama is endorsing picloud.com.
PiCloud dev here. @Rescind, I was hoping to learn a bit more about your use case. &gt; Really wish the maximum input paramaters could be more than 16MB. The reason input parameters are limited to 16 MB is that it starts becoming not worth it to offload work "to the cloud" if you need to transfer 16 MB. In the extreme case, on a home internet connection, you'd be looking at an upload taking about a minute. Your job then needs to take a minute just for PiCloud to break-even with running locally. [1] However, using large amounts of data is alright, if many jobs use the same data. This way, the upload time is a one-time cost. The easiest way to do this with PiCloud is to use [buckets](http://docs.picloud.com/bucket.html#bucket). Also, if you haven't seen it already, check out our updated [Handling Data Primer](http://docs.picloud.com/primer.html#handling-data). It explains what to do with different use-cases. In your particular case, how long are the jobs take that use this data? How many jobs use the same data? And where is your data coming from? A server? Local machine? &gt; Will Picloud ever let a worker handle multiple jobs in one shot? The trick thus far has been to simply make your job do more. In the case of many jobs being made with cloud.map, [argument chunking](http://docs.picloud.com/cloud_python_map.html#argument-chunking) solves the issue. While argument chunking is the best method to use from the POV as a researcher operating on a local machine, it isn't the most natural for paradigms like web applications where the "tasks to process" aren't known in a single time in a single thread. And that is what the just released [Queue](http://docs.picloud.com/queue.html) aims to solve. ------- [1] If your source data is already in the "cloud", it is more efficient for PiCloud to download your data from its source rather than for you to push your data to PiCloud).
Voice of reason: writing languages with other langues creates layers of abstraction, and dependency complication. Basically with all the complexity of Javascript you are now relying on the Pyjs implementation and conversion of Python into Javascript instead of Javascript itself which will introduce more problems than it will solve. I see the problem you are trying to solve, it's based on a sound idea, a promise of lessening the burden of development. Pyjs whispers into your ear "What if you didn't have to write Javascript anymore"... it tells you "What if you just had to read Python". But in the end Javascript will be running in the browser, and now more removed and abstracted than the client/server relationship already is. A client-side debugger won't help you because the code and logic you have to correct is now written in Python. What happens when someone else comes to your project that knows Javascript really well. You are asking them to not use that knowledge, not bring that skill to bear. Then eventually someone will decide that using a Javascript library client-side will really "help" their efforts... And now you have a mixture of machine-generated Javascript and human written Javascript that is apart of a framework. Now the overhead to begin hacking on your project is even more immense. I wouldn't ever do this, it's a fun idea, and fun to play with, but I would never use this in any production environment.
Awesome - didn't realise this :)
I believe that the specific use of the term may have extended from Microsoft Excel's foray into OLAP... this was a feature also available in MS Query called "Cubes." It is a way to organize data in a semistructured way (like Entity / Attribute / Value or Subject / Predicate / Object) such that aggregate values can be calculated on sub-selections of fields or other higher order metrics of those fields like sums and values. This is the realm of analysis... how many widgets per month, or, how many month fractions per widget... and to be able to "pivot" between such combinations by adding and removing fields or aggregate functions from selections. Pre-determined selections can be organized into "trees" for "drill-down" where a user first sees just the summary of, say, an entire country's worth of data, but upon double clicking one could see each state, then county, etc. This is especially useful for time series such as looking at data by Year, Month, Day, Hour, Minute, Second, Millisecond, Microsecond, Sample (etc) These ideas usually involve some kind of special interface such as a facet selection like in Excel or Elastic Lists with not-necessarily numerical data like MIT Simile Exhibit or M Space. OLAP is great to read up on, it is essentially de-normalization, or Sixth Normal form. It is multidimensional, and a graph. Hope this helps!
The term originally comes from spreadsheets. Imagine you have a database query that spits out | **YEAR** | **MONTH** | **SOME_NUMBER** | |-----------|--------------|---------------------| | 2010 | January | 123 | 2010 | February | 456 | 2010 | March | 789 | ... | ... | ... ...and you want | **YEAR** | **January** | **February** | **March** | ... | |-----------|--------------|---------------|-------------|---| | 2010 | 123 | 456 | 789 | ... | 2011 | ... | ... | ... | ... You would "pivot" it.
Ah this is awesome, thanks for the heads up! :)
I disagree, just about everything about your computer and development is more abstraction in general. C is abstraction from assembly C++ is abstraction from C (and in fact orignally C++ just compiled to C). Besides while it's fun to theorize about why approaches are horrible or just wont work the reality is Google is using this approach right now, and arguable getting farther ahead then any other web company partially because of it. And just like with C and C++, where if you have a knowledgeable assembly programmer they can still hack away - the same is true with the pyjs approach. There's certainly things not to like about the overall project but I think this is just a bad windmill to swing at, as it has already been dis-proven by history over and over again. Timothy
This is a pretty good project, we've built a product with it at work. However, there was a kind of civil war in the community and the old project lead resigned after the usurper pinched a load of emails from his machine. Since then the community has been almost dead. It needs forking, de crufting and some commercial backing.
I did now, link at post. Thanks!
I've used this tool before to download the HD versions of the [Crash Course: World History](https://www.youtube.com/watch?v=Yocja_N5s1I) series. MUCH easier than using browser plugins to download the 40+ videos.
Why do you want to do this? This kind of check is usually an indicator of badly organized code. For some general discussion of why, see http://canonical.org/~kragen/isinstance/
[mapit](https://github.com/asweigart/mapitpy) will automatically open Google maps to the address in your clipboard.
I've been studying how to "slice and dice" tabular data. Took down some notes https://github.com/racketeer/rdb. Basically you sort the rows and group them by a column(s). And then you apply some function (sum, mean, etc) to each group.
[Github repo](https://github.com/amontalenti/rapid-web)
&gt; C++ is abstraction from C Javascript and Python have far less in common than your examples &gt; Google is using this approach Do you mean GWT? Isn't it dead? Anyway, Google has the resources to make any approach work, meaning it stll might not be practical for non-Google size entities &gt; has already been dis-proven by history over and over again In the case of Javascript: dart, coffeescript, gwt, rust, typescript, etc. all tried (are trying) to better Javascript, but I'm not sure they've succeeded (yet)..
Cool project, I enjoyed having a look through it. Especially the space group part was interesting. This is something I haven't dared to do myself yet, since it's so easy to make mistakes with and takes forever test properly. I saw that you were looking for a way to read cif files. This would indeed be helpful. There is a actually cif reader on pypi called PyCifRW. The cctbx project (crystallographic toolbox) also comes with a cif reader, which you may have a look at for inspiration. 
That's a good argument from principles but it does work pretty well in practice. It works a lot better for rich, low-volume apps because the size of the client that gets to be downloaded is big. But otoh that means no plug-in.
I am a casual programmer and my opinion is humble, but I found it *incredibly* easy to start using Python with Visual Studio Isolated Shell and PTVS: http://pytools.codeplex.com/ This is a screenshot of my environment. Autocomplete works. http://imgur.com/da9Y5tM I'm not a .NET guy (I came to Python seeking deliverance from the unspeakable horrors of VBA) but it should work nice with .NET, or so I was told.
What have you done so far? I don't think we should do your homework for you but if you have specific questions we can help.
You probably won't get the answer you're looking for since no one will want to do your homework for you. Not because it's hard but because there's a point in the homework and that's for you to learn. here's some hints: 1) https://www.google.com/search?q=how+to+get+user+input+in+python: 2) https://www.google.com/search?q=if+statements+python
http://learnpythonthehardway.org/book/ First 14 exercises are worth one long evening of study and will absolutely provide you with all you need to do these assignments.
I realize no one likes doing homework for people but it's due in two hours and I really don't have any clue what I'm doing. I be willing to pay someone via paypal to do it for me. I also think looking at it completed would help me learn what to do.
I've done nothing, the teacher has just taught us psedo code, so I don't really know the right syntax. This is pretty much last resort.
thank you for your response! very helpful 
Looks interesting. Can this do more than visualizing atoms/molecules? Can it, for example, calculate pressure, velocities, etc.? (My knowledge of chemistry is lacking, so I have no idea how feasible it is to do more stuff)
Ah, right, I understand. Hopefully the next PyCon AU will be more affordable!
At the current state I use it mainly to produce input files for other program such as gromacs https://chemlab.readthedocs.org/en/latest/gromacs.html that can provide all those information. A simulation module is planned anyway (I've started some work on it but there are some items higher on priority), Ideally people can use chemlab as a framework to develop such features.
Thank you! I didn't know about those packages, they are definitely helpful. BTW the space group module was adapted from [ase](https://wiki.fysik.dtu.dk/ase/tutorials/spacegroup/spacegroup.html#module-lattice.spacegroup), it's a wonderful piece of code. 
I'm Barack Obama, and I approve this blog post.
You may want to tweet this @redisfeed. Antirez is pretty good about retweeting useful stuff. 
I think that, and correct me if I'm wrong, pivot tables in spreadsheets originated with Lotus Improv for NextStep. http://en.wikipedia.org/wiki/Lotus_Improv
Do you know of any good tutorials explaining how to get this setup? Read about source maps this afternoon getting frustrated debugging d3 in coffeescript but didn't take the time to get it working
I'd go for this! I know I saw some OLAP with Cognos and I struggled to think of any examples before 96.
No, sorry, I've only seen it demo'd during a Google Chrome Developer Tools talk. I haven't used it and don't know much more about it other than it exists and is used with CoffeeScript.
Looks a lot like elastic search
&gt; You will only need to use "open with" to open these in your archiver. True on Windows and with zip/unzip on Linux, but file_roller doesn't want to know - says it's not a recognised archive type.
Hey Tastur, My argument was more against the notion that "writing languages with other languages" was inherently bad, as this is the basis of all software currently written (except for the small amount of assembly around). I was indeed talking about GWT (which this is a Python port of) which is alive and well, and used by lots of companies (big and small) outside of Google itself. However after some research I found out Google only uses GWT for a handful of its application and most of its more well known ones do not use GWT but instead use Google Closure, which pokes a whole in my assumption that approach somehow contributed to Google's success. I think most of the converters (particular coffeescript) that you mentioned actually have found a reasonable amount of success and are in several production applications at this point. Thanks! Timothy
How does that work? Does the c/c++ code get compiled and injected when the module is loaded? 
It's not the work that people would object to, this is only 5 minutes of work for someone that's already familiar with it. People just didn't want to do your homework for you because they shouldn't. It looks like you're past when you were supposed to turn it in, otherwise I'm sure a bunch of us would be happy to give you more direction. How did it go?
You may want to check out [stackoverflow](http://stackoverflow.com) for these types of questions. I'm not sure if the subreddit is the appropriate place. For your question, there are a few ways to do if. If you don't need the data used to generate the plot you can write a function to handle the plotting: import matplotlib.pyplot as plt def hist_(x): """x is an element of the groupby. """ fig = plt.figure() ax = fig.add_subplot(111) ax = x.hist(ax=ax) # You can save the file if you'd like. # You might want to use x.name for different filenames. return ax Then call it with grouped = df.groupby('Filename') axs = grouped[cols].apply(hist_) Where cols is either a single column or a list of columns you want histograms for. The idea is that this function operates on each item in the groupby. which will return a set of matplotlib axes containing the plots. If you need the data back you'll want to look into defining a function using [cut and value counts](http://pandas.pydata.org/pandas-docs/dev/basics.html#value-counts-histogramming) and applying it to the groupby.
Use Vpython?
Looks cool maybe a library like http://shouldly.github.com/ could be made for python. I always liked the shouldy api.
Their magic (from 94 lines of non-test / non-setup code - https://github.com/clarete/forbiddenfruit/blob/master/forbiddenfruit/__init__.py) is this: ctypes.pythonapi.PyDict_SetItem( ctypes.py_object(namespace), ctypes.py_object(name), proxy_dict.dict, ) 
Twisted makes this pretty easy, especially if you use its simple AMP protocol: https://twistedmatrix.com/documents/current/core/howto/amp.html see also http://amp-protocol.net/ 
Wow, thank you very much. I know exactly how I'm going to use this.
well nose adds jUnit style assertations. (assertEqual, assertGreater, etc.) it's not the same, but it's similar. Also, py.test can just use the current assert keyword plus operator overloading (or some other magic, maybe it's ADTs) to get the same effect with more pythonicity. (though that's only if the assert happens inside the py.test testrunner and not in production)
A. We need to know the contents of your file to know why the syntax is invalid. B. [r/learnpython](http://www.reddit.com/r/learnpython)
If you're interested in that, you might like to study the pandas source: https://github.com/pydata/pandas . 
ok here's the contents print 'here's the contents'
The ' in here's is closing the string literal. You want something like print "Here's some text"
... and autopep8: https://github.com/hhatto/autopep8 
not working still -_-
Or if you want to be really covered and be able to use " and ' inside your print statements, do: print """Here's some "text" and as you can see I have single and double apostrophes in my print statement""" or you could also escape the apostrophe like this print 'here\'s some text' 
Ok. My code is fine. I just can't open the file with the terminal.
That's a terrible argument. One of the most awesome aspects of python is its ability to easily abstract C. Some of my favorite python libraries are just wrappers for the native C libraries. Abstraction is a really good thing, and lowers overall complexity...when done right. Jquery selectors are an abstraction. HAML or Moustache templates are an abstraction. In general, abstraction makes our lives much easier and helps to manage the overall complexity. You can certainly argue that pyjs does the abstraction poorly, but suggesting abstraction itself is a bad thing is a foolhardy argument. Hell, OOP itself is all about abstraction. 
Yeah, what is the consensus on the Pythonic way of doing this? Numpy, for instance uses numpy.int16 and so on for dtypes, but scipy often uses strings. There are valid arguments to be made for both usages, but is there some guidance on what situation to use which?
from hell import handbasket
&gt; True = False
Is curse() a play on perl's bless()? 
You should post your request on a MacOSX forum. This is neither a problem of python nor a problemvwith eclipse.
Salt-stack uses ZeroMQ for this very thing, afaik
You haven't thought it might be related to Adobe Flash Builder, and completely unrelated to python?
Here is an even sweeter forbidden fruit: Define ctypes structures for the PyMemberDescr object and PyMemberDef struct. Use it to turn off the READONLY flag from a PyMemberDef. If you use it on the \_\_flags\_\_ member of a type object you can, for example, turn off the Py\_TPFLAGS\_HEAPTYPE flag of a builtin type. This will make it possible to modify the type in very interesting ways like changing its \_\_bases\_\_. I know. This is madness. I'll just go to that corner over there and disassemble myself quietly.
Take a look at the redis pub/sub API: * http://redis.io/topics/pubsub * http://redis.io/commands/publish * http://redis.io/commands/subscribe Should be pretty simple to get a similar api working with twisted, tornado, gevent, etc.
I'm learning Python as a first programming language. I am focusing on Python 3. My assumption is that it will eventually displace Python 2.7, it will just take time.
Sorry, that's pretty much a full solution that I'm posting here: http://peter-hoffmann.com/stackoverflow/12236019.html (I'm not Peter Hoffmann!). Read more about SSE here: https://developer.mozilla.org/en-US/docs/Server-sent_events **EDIT** re-phrased
You should definitely write up how to do this. I would be very interested in reading about this.
You could do lots of things with this. For example, you could test how fault tolerant your system is by patching builtin methods to raise exceptions every $random calls.
 from curse import curse from datetime import timedelta, datetime class days (object) : def __get__ (self, instance, owner) : return timedelta(instance) def __set__ (self, instance, value) : pass def __delete__ (self, instance) : pass class ago (object) : def __get__ (self, instance, owner) : return datetime.now() - instance def __set__ (self, instance, value) : pass def __delete__ (self, instance) : pass curse (int, 'days', days()) curse (timedelta, 'ago', ago()) print int(12).days.ago
Even better! This is great!
Provide more info. What is the contents of the script exactly. What is the command you use exactly. What is the error you are getting exactly. 
MonkeyPatching in Python?? God save your soul. ;)
This is not about the installer most of the time. Since python will be launched without administrative permissions it can't write to Program Files due to UAC. (there is this compatibility layer which is applied to non-elevated programs, but I have no idea how that thing works) I don't know if any part of Python actually needs to do that, except easy_install or pip, but at least easy_install can launch itself with UAC in mind.
that appears too subjective. could you please be more precise in terms of the given repository, what do I need to do?
nice, I had seen a separate docs folder in several repos but I had no idea these were generated by some software.
Well, what do you hope to get out of reading the code?
The docs folder isn't generated itself -- it is what is used to generate the documentation. The folder contains the "source" for the documentation, usually written in some markup (reStructuredText is the preferred format for Python), along with other files needed to generate the final output. Generated documentation is usually found somewhere inside the build directory. 
Please use /r/learnpython for this kind of question :)
Plus setrofim, I usually follow this pattern: - requirements, how much dependencies the app has. - check models.py to see what objects and attribute the app is managing - check templates, to see if they are reusable or not - views are not usually very useful (for me) cause they are so generic (without permissions, or checks) that I tend to redone them. They are good to see, anyways. - settings - urls, to see if they can be reusable or collide with something (rarely) - I always forget this, but should be done SECOND after requirements, some programmers use metaprogramming and `__init__.py` files to allocate some imports and stuff. It's good to check this and see if you understand what the developer has done. In this section also check for signals, middlewares and context processors. They are sometimes not so obvious.
I think all your points are valid. Python is written in C and interfaced C libraries are wonderful! Jquery initially made it so you didn't have to wonder if your code would run in 3 different browsers... All html templates solve a problem that has to be solved, intertwining logic, iteration, and strings of text. PHP solves this by simply allowing the language to enter and exit the interpreter within it's source file.. clever? maybe?... All of those things are true! I personally don't really care for Ruby so what if I could write my ROR application in Python and have my Python code generate Ruby code? I write a lot of Lucene code in Java... what if I could write my Java code in Python. Cython is nice for building C extensions, why not build my Postgres module in Cython? All of the above solutions would most likely be... Hard to edit, hard for others to understand, projects that others would be less likely to work on, and confusing. There is no way around the fact that any of the solutions would add a lot of extra complexity... uneeded complexity, the language and it's frameworks solve it's problems fairly well. Someday you might get a different language other than Javascript in the browser - I will be the first one to scream and shout and tell everyone to switch to whatever it is. Until then the browser understands, interprets and executes html, css, and javascript - and everyone should know and use them.
(Personal opinion:) As a novice it may be a bit much to start reading the code of a large project like Django because there are a lot of moving parts. For me, to really understand a project I have to read the code over a few times and get an idea of how most if not each part works in my head so that it starts to make sense. Reading snippets of a large project doesn't really provide you a way to see everything holistically. There are small projects out there on github or sourceforge. Check http://en.wikipedia.org/wiki/List_of_Python_software to see if there is anything you use. If you read the code of a program you use, you know half of what it is used for! Also you can check out http://bugs.python.org and see how people solve some issues. There are 'Easy Issues' where they need someone to refactor a simple step, or re-write the documentation to be more clear. I've started off looking at big projects and quickly got overwhelmed, and wasn't sure where to go next. That's the point of this info for you. :) Lastly I'd say 'Find a small task you want to automate in one way or another. Rename a bunch of files? Make backups? Send emails every day at 9:06PM to order pizza?' Script it out, practice. The most efficient way of learning, for me, has always been 'My problem is X, and I can use Python and some Google-Fu to figure out how to fix it'.
Sure we recommend it! :) If you are using C# in your prod code -- try using python for any enhancements (like batch file processing) that don't need to be in the .net environment -- over time you can use python to a greater degree. Or you can go all in....
Yes, I need to implement something exactly like this, but from scratch for class.
I have both maintained/extended a custom message server using sockets that pushed notifications to the client with orbited, and reimplementd the whole deal using eventlet as well as twisted. I remember finding eventlet the cleanest, and I'd recommend not going the first route (legacy code :/ )
For those not in the know, this advice is specific for Django projects.
Not sure what you mean by "proper". If you mean a list comprehension (using square brackets), then the advantage is reduced space consumption. A list comprehension always uses O(n) space, while a generator itself uses O(1) space. If a generator is passed to a function which doesn't accumulate results in space, such as 'all', then your program will use drastically less space. 
http://svn.python.org/projects/sandbox/trunk/datetime/datetime.py 
Maybe I can step back a bit. I've sketched out what I want my application to do, without even getting into the UI elements. Based on my sketch I have the following definitions, any input you can provide on this would be great. I've never done any OOP so this will be a nice introduction to it I think.. - Bitcoin Price object. This object provides price, vol, market, and currency from the JSON load. Is an object the right idea for this? I hesitate because I don't need more than one instance, in fact more than one instance seems like a bad idea as I am pulling from one source and just need to refresh that every 15 minutes. - Monitoring Class. Simple timer that reads from the Bitcoin instance the current price. Sends an event every 15 minutes to the Notification class which can then ignore/process the event. - Notification Class. Monitoring class sends an event here with the current BC price. Notification class uses user-provided thresholds to determine whether or not to perform any actions. Might need to subclass this out to different kinds of notifications (popups, emails, etc.) - Interface class. This is the GUI front-end. I might design this first as a console front-end and if everything seems to work well, it can be easily turned into a GUI. This allows the user to read price/vols from BC, set thresholds, set market, currency, notification preferences. I still need to explore how to save settings/preferences. I am thinking of pickling but would appreciate some input here as well. 
In Python 2.x and Python &lt;= 3.1, the module was implemented as a C extension module -- here's [`Modules/datetimemodule.c` from v2.7.3](http://hg.python.org/cpython/file/70274d53c1dd/Modules/datetimemodule.c) for example. Starting with Python 3.2, a slower pure-Python fallback version was also implemented -- here's [`Lib/datetime.py` from v3.3.0](http://hg.python.org/cpython/file/bd8afb90ebf2/Lib/datetime.py) and [`Modules/_datetimemodule.c` from v3.3.0](http://hg.python.org/cpython/file/bd8afb90ebf2/Modules/_datetimemodule.c). So, depending on what version you're using this may be very easy or very hard. If you're using &gt;= 3.2, you can try using the `Lib/datetime.py` from the corresponding release. If you're using 2.x you will either need to compile `Modules/datetimemodule.c` into a module or try backporting the pure-Python module from a 3.x release and adapting it for 2.x. 
That's pretty awesome. Is it possible to write tests not having monkey patched the objects beforehand? Like in ruby.
Please use a pastebin, python code requires indentation, if you just paste it here it breaks your code, and bugger me if im going to sit here cleaning it up.
heres my actual code. what I gave you sucks: http://i.imgur.com/Oze0LTH.png
You can also prefix your code with 4 spaces in the comment and it will display properly.
http://pastebin.com/wNyBpVb9
okay thanks, small mistake. After I do that I get an error for that last quotation mark in that print. 
It would also help to explain how it's not working. Does it not run? Does it run but crashes? Does it run but you get unexpected results? In each case tell us the error message or what you expected and what you got. From a quick glance it looks like it should work, although it's not very good code.
This is a paste bin: http://pastebin.com/w2jxe4gp Btw, "print =" in line 30. It should be simply "print".
You should see the rest of my code - I love lined up columns!! I guess its just personal, but I can scan code so much faster.
That is very old code -- it's a revision from [2004-03-04](http://svn.python.org/view/sandbox/trunk/datetime/datetime.py?revision=40863&amp;view=markup), which dates it to around the time of 2.2 or 2.3. Who knows how many bugs have been fixed since then? Python hasn't used SVN in a while.
It has already been [done](https://github.com/gabrielfalcao/sure). (4).should.be.equal(2 + 2) This is apparently serious, but I think it's one of the most horrific bits of code I've seen. Quite apart from the monkeypatching, you have to learn a whole new syntax for everyday operations. I'd much rather use pytest and just write: assert 2 == 4+4
I'm guessing your actual question is 'how do I download this code?' Assuming you have git installed on your system, you can run git clone git://github.com/django/django-contrib-comments.git to download a full copy of that repo. This won't get you the dependencies or anything elaborate like that, though. Installing from your package manager will probably achieve the same end, although not the bleeding-edge version that github provides.
The way he's describing it makes it sound more like just transposing a table. That's not really the point of pivot tables. Pivot tables make a table by rearranging information in another table. For example, say you want to display just the items that fit a certain criteria, or want to order them according to a certain criteria, or want to display the count of specific items or their sum, then you'd use a pivot table. The easiest way to understand it is probably to run through [an Excel tutorial](http://office.microsoft.com/en-ca/excel-help/pivottable-reports-101-HA001034632.aspx) on them (assuming you have Excel).
Yes, thank you for pointing that :)
1. Read `README.txt` 2. Read documentation. 3. Look into tests/ directory this will help what are features are tested.(Note: Not all projects have proper test). 4. Try the examples. 5. Now you have basic idea what the library is supposed to do. 6. In case you want to use with an app, use it. 7. Now look into each function, classes, constants used in the application in the source code for better idea of working. Depending on familiarity looking into source code can be moved to any step. 
Thanks for the advice people
Yes! Yes! Yes! The last thing Ruby users could point to and say "Python can't do THIS" is gone! Mike the Animal and Lincoln Clarete have done what Guido Van Rossum himself would not or could not do! Dictator? They have become LIKE GODS!!!!! Ok, I'm, um, rather excited and happy about this. :-) This has to be presented at PyCon 2014 (or earlier) so that it can get a standing ovation.
Or you've had COBOL programming experience. :-) Or Turbo Pascal or Delphi experience and were used to doing things like this: Var something : integer; name : string; y : Array[1..5] of Integer; 
The question makes no sense. You go about reading the code like anything else: with your eyes. What's your actual question?
 * Python can be downloaded (e.g. python.org) * datetime is part of Python Thus, there is a way to download datetime. [Edited for formatting]
Thanks!
It is still pretty rough but I think it can become something useful for folks working with heavy Python objects that are copied around but see few writes and a large amount of reads.
Because, amusingly, what you did is redefine the "print" function to be a string instead. Meaning then that "print fortunes[f_num]" was really "\tWelcome to the Fortune Cookie Program!" fortunes[f_num]", which, as you can imagine, wasn't very useful.
you recommend not going with orbited or just plain sockets? I'm not sure I'll be able to get by with such high level libraries I think my instructor is looking for something closer to the WSGI library I came across. 
Take a deep breath and have a think about whether this code is actually a good idea.
Hey guys, here is a scrabble / 4pics 1word answer tool i found that has a wildcard from the looks of it. http://4pics1word.scrabblewordsolver.com and http://www.scrabblewordsolver.com - 4pics seems faster don't know what they developed it in though but it seems very fast.
Disclosure: I work for No Starch Press.
The scenarios you're mentioning don't make much sense, but the Python-&gt;JS translation opens up a path to running a single source code base (SPOT) on the server AND a client that is functionally consistent *by definition*. Think validation of forms, or processing of stuff on client side for JS-enabled browser and on server side for browsers with JS disabled, without anyone noticing.
This whole thing makes me wonder if it wouldn't be useful to write a reusable library of fully persistent variants of basic Python collections (lists, sets, dicts etc.). That could make stuff a lot more transparent.
"Type" seems to be sort of a misnomer in this case. Any value can have a large number of types (1 is an integer, a real, a complex number, a magnitude, an object...), but type() only returns one. "Representation" or something like that would be a more useful name for the same kind of functionality.
you can escape reddit markdown characters with backslash, like so: `\_\_init.py__`, which results in: \_\_init.py__. You can also specify code blocks inline with your text by encapsulating in "\`", like so: \``mycodehere`\`, which results in: `mycodehere`. You're welcome.
Will work on it. Thanks for the feedback.
Could you do a quick ELI5 because I consider myself fairly proficient with python but didn't understand what you mean about copy on write and what the project actually does. EDIT http://en.m.wikipedia.org/wiki/Copy-on-write Not so ignorant now :)
It's very nice to read. I don't know if my coworkers would like it if I started, though! :)
Simply expanding your tests.py would probably be sufficient.
What is so "REST" about it? I only see HTTP.
Plain sockets. Probably fine for school, and useful to really get a handle on what is going on under the hood, but there's a lot of lessons learned that went into something like eventlet and reimplementing them all from the ground up isn't fun nor easy. I'm not sure about the state of orbited right now, it was getting pretty badly fragmented when i used it last 1.5 years ago. It serves a different role though, allowing your client to connect to your message server. Even if you use eventlet you'll need some way for your client to connect (i think twisted may have comet libraries built in?)
REST isn't much more than using the HTTP verbs as they were intended rather than just GET and POST.
How come the standard library is not included in your python app?
If someone really wanted to do this, I'd suggest porting Clojure's implementation of persistent vectors, sets and maps.
try dragging and dropping the file into the terminal and see if that works
I tried that already.
it's a bit more than that, actually.
Needs more hypermedia!
done! didn't know that
Here is basically the same project, but using flask, with more features, and with HATEOAS support: [http://python-eve.org/index.html](http://python-eve.org/index.html).
For what is worth, it's possible to have a copy-on-write friendly GC in PyPy. That would mean some performance penalty, but you could fork as much as you want.
I think you could print the web page in pdf from firefox ;)
How big is performance penalty? Also, you seem to miss an awesome optimization opportunity: when you're doing deep copying, you can discard your proxy wrapper altogether, just (deep)copy the original object's `__dict__` and `__class__` and literally become its copy! With all further attribute accesses going without penalty.
PEPs are submitted as ReST documents usually (always?).You can use docutils to generate a PDF (either directly or via a LaTeX conversion, it's been a while since I've used docutils). You can find the source [here](http://hg.python.org/peps/file/tip/pep-0008.txt).
Use an automated PEP 8 checker, integrated into your IDE that way you'll learn all the most common requirements
[Download](https://dl.dropbox.com/u/511123/PEP%208%20--%20Style%20Guide%20for%20Python%20Code.pdf)
Yes but in the traditional development methodology your code physically gets shipped to someones elses computer in a different language then you wrote it, making it even more silo'd.
I doubt it's changed much since 2010.
* http://hg.python.org/peps/file/tip/pep-0008.txt * https://pypi.python.org/pypi/rst2pdf
Is the same as pyflakes ? 
http://roy.gbiv.com/untangled/2008/rest-apis-must-be-hypertext-driven
It is a wrapper around it, as well as another tool called `pep8` which is really what you're looking for in this case. If you need both then `flake8` would make sense. 
This kind of hack is very much against the zen of Python, while it might be fun to mess with the internals "because you can". It is a good thing that Python makes it difficult to do and should never be used in real code.
A few off the top of my head: * Huge standard library * Generally good quality documentation for standard library * Gobs of third-party modules to rival even Java * Platform agnostic, and present in virtually every *nix distribution I'm aware of without even needing to install it (because so many system tools are written using it) * Very common use of BSD/MIT-style licencing with third-party modules; GPL licencing gives corporate lawyers a big headache * Emphasis on code readability (see PEP-8) and DRY principles without sacrificing readability (kind of a middle ground between perl and java, I guess?) * Useful for a really broad range of programming tasks from little shell scripts to enterprise web applications to scientific uses; it may not be as good at any of those as a purpose-built programming language but it can do all of them, and do them well (e.g. you don't see web apps written as bash scripts nor do you see linux package managers written in Java) 
Python's all about solving problems elegantly with minimum effort on your part, even if it means sacrificing a bit of execution speed. As a result, a tremendous library of modules has grown, including ones that get around the speed issues.
Readability and long term maintainability. Also I work with a lot of engineers who are not necessarily developers, and would much rather have them write python than any other scripting language. Python makes anyone's code easier to follow.
Elegance. I started in C++ and switched to Perl when I got to linux. If I started with Python, my code would be so much prettier. Also it's portable, versatile and easy to learn. I recommend it to everyone who asks me where to start.
Do you like learning by example? Then Python is the language for you, because you will be able to read and understand more Python code than any other productive language. After some years of experience you will understand that this enabling of reading other code is the most important aspect of a good programming language.
Works out of box, cross platform, human, enforces indentation, and ample libraries are available 
Python is the most concise language there is. With Python, you write less code. Fewer lines of code=fewer bugs. Compared to languages like C++, C+, and Java, Python can be 10x more compact. This means you can write the same functionality with 1/10 the bugs.
There are approximately a kerbillion [Web Application Frameworks](http://en.wikipedia.org/wiki/Web_application_framework) for Python, but all they do is serve the pages. You still need to deal with HTML, CSS, and JS to make the webpage (though there are lots of tools to make that easier too. Here are some links to explore. * [Flask](http://flask.pocoo.org/), a minimal Python framework * [Aspen](http://aspen.io/), another minimal framework, kind of an oddball * [Django](https://www.djangoproject.com/), the grand-daddy, all batteries included Python framework * [Michael Hartl's Ruby on Rails Tutorial](http://ruby.railstutorial.org/chapters) not Python, I know, but Ruby's pretty okay if you give it a chance, and this tutorial is *way* better at covering the web oriented stuff
Kivy seems to work nice for android, making python usable on mobile.
The thing that originally attracted me to Python was how much like a 21st-century BASIC it was. (I cut my teeth on an Apple II back in the '80s and still have a weakness for languages in which `print` is a statement, not a function call. Of course this has changed in Python 3...) I found its quirks endearing. As I got into it, I came to appreciate its mix of procedural, object-oriented, and functional features, and of course its vast collection of batteries. Cons of Python? A lot of the warts have been addressed in Python 3, but I continually see the way it handles mutable containers trip people up in various ways. E.g., methods that mutate a list return `None` so you can't chain methods, and if you use, say, a `list` as a default argument in a function, and then mutate it, you're gonna have a bad time. Also, of course, the global interpreter lock, which keeps you from using more than one processor even in threaded applications.
I am going to add: Python is where all the cool kids are. * If you say C++ (which I use) you are potentially too hardcore, * If you say PHP (which I use) you are a script kiddie, * If you say Ruby (see PHP), * If you use Perl you are old, * If you use Scala you are too academic, * If you use Lisp you are insane, * If you use Erlang you will have to explain yourself, * If you use Java you wear a suit to work (or at least a tie), * If you use PL/SQL you work with the Java guy, * If you use .net you work for a competitor to the guy who uses Java, * If you use Lua you have to explain yourself to everyone but the Erlang guy, * If you use Javascript you work with the PHP guy, * If you use Go you wish you worked for Google, * If you use ASM you have too much work to do to be reading Reddit. 
I think one understated point about Python is the amazing community. Python's standard lib is great but there are so many great libraries that are available for free. I really think there are so many benefits to getting involved with or following strongly open source orientated communities. It is an amazing thing for someone to pour hours of their life into code and then just give it away for free. I can't tell you how many tips and design ideas I've picked up just from digging into a library to see what's going on in the background. 
What delicious pasta. Edit: You should add * If you use Rust you work for a competitor of the guy who makes Go,
&gt; Generally good quality documentation for standard library It's not, though. The official documentation is quite bad compared to say MDN or godoc. When I look at http://docs.python.org/3.3/library/os.html, I see a wall of text without an index and it's often not even clear what the functions return or what the arguments are supposed to be.
Overall, you present a great assessment of some of the weaknesses of Python. I have a myth-buster and a suggestion for you :-) &gt; They aren't bashful about saying that multi-threaded software development is hard (I'm sure that is true in any language) but getting your application to perform by using them can be challenging. Others are welcome to disagree, I confess some degree of ignorance on the complexities of multithreading/multiprocessing in other programming languages. Part of this is due to the threaded model that most mainstream languages give you to write concurrent programs. The problem is that you're typically limited to spawning threads, which are very expensive and managed by the operating system. This model also militates toward extremely complex locking schemes, that have resulted in an entire branch of academia that tries to provide static analysis tools to find potential races and other such voodoo. Joe Armstrong, the author of Erlang, hit the nose on the head a long time ago: [the problem is that there is no good model for spawning processes in most programming languages](http://www.guug.de/veranstaltungen/ffg2003/papers/ffg2003-armstrong.pdf). (PDF warning.) He compares it with working in an object-oriented language where it's only feasible to create a few dozen objects at run time. i.e., It's very restrictive and makes concurrent programming *way* harder than it should be. Erlang, along with Haskell, have these sorts of green threads that allow one to write truly concurrent code. They are also immutable which eliminates a large class of bugs related to race conditions. More recently, Go and Rust have adopted similar models of green threads (Go has "goroutines" and Rust has "tasks"). Neither of these languages are overtly functional (Rust moreso than Go), which means they are possibly the first languages with the potential to bring this sort of concurrency paradigm to the masses. It's quite exciting. Since this is reddit, I will now protect myself against pedants: * Go uses a shared memory model, which means races and the like are still possible. But *speaking from experience*, they are rare because Go also has channels which are the predominant means of synchronization between goroutines. This militates against complicated locking schemes and race conditions, but doesn't prevent them outright. On the other hand, Rust, Erlang and Haskell all have mechanisms to prevent race conditions at run time (through immutability in the case of Erlang or Haskell or sophisticated static analysis in the case of Rust). * Ruby has something called fibers, which are similar, but IIRC, they cannot be parallel. This is in contrast to Go/Rust/Erlang/Haskell. A similar thing can be said for Concurrent ML. * People have told me that libraries are popping up for the JVM languages that support these features, but I haven't independently confirmed it. IMO, there is an opening for a dynamic (or "scripting") language to get concurrent programming right. It's a really big pain to write parallel programs in Ruby/Python/PHP/Lua when the algorithm isn't embarrassingly parallel in the first place. (i.e., Embarrassingly parallel == a series of completely independent tasks.) &gt; Finding hosting for Python-based web applications is not so fun How about a VPS or something? Linode is great. I think I'm paying $20/month for mine.
Because the logo is a *freaking* snake! That's really awesome. Not a coffee cup. Not an greek looking symbol. Not a letter. An awesome snake. 
Because I didn't know any better.
Have a look at one of these two: * http://code.google.com/p/salesforce-python-toolkit/ * http://code.google.com/p/salesforce-beatbox/ Or just Google "Salesforce python api".
There are actually a couple of CMSes written in BASH, heh.
pro: fast to get something going con: hard to keep up when things get complex without static type checking.
Highly subjective opinion. Compiled languages were never an option for me because my tasks, as an engineer and CAD manager, are mostly user automation, customization/productivity and the like. In around 2001-2002 when I was 19, I learned CGI programming and Perl and tried to develop a pet project with it, an online browser game (was a pretty uncommon thing back then). It never went beyond some very basic, 'technology demo' functionality but it was incredibly fun to work with Perl. After that, as a casual programmer, I worked a little with PHP and a lot with VBA for AutoCAD and with VBScript - as you see, all kinds of highly toxic stuff. It was sort of rewarding but very, very painful. I never properly learned information science but I always felt that I was doing very weird and unproductive things. Lately I was specifically educating myself about programming languages in order to choose the closest thing to a silver bullet for scripting and data processing. Once I dug into Python, I immediately felt the 10-year-forgotten awesomeness of Perl, without all the syntax weirdness. As I am further developing my first project, Python has kept me in constant awe and epiphany. The code is absolutely natural and clear, I can't wait to finalize my project to be able to share the incredibly easy coding possibilities with other engineers.
&gt; GPL licencing gives corporate lawyers a big headache To be clear: it's GPLv3 giving headaches, not GPLv2.
It's just more fun than other languages I've used in earnest. Most languages can do what you want. Some of those will require more effort and some less, depending on the language (and the pros/cons of python are well covered here). Given that, if I'm going to write code all day, I want to do it in the language I enjoy most. 
It's implemented in hell.
My source in Skype recently told how Microsoft basically hates both since it works like cancer: makes everything it touches GPL. They were a bit softer on LGPL / MIT / BSD licenses, mind you. Can't blame them. Still, it's a bit ironic, considering how much their infrastructure has benefitted from OS.
I'm stuck in the Python 2 land (for now), but someone on /r/python taught me how to make it a bit more 3-like: from __future__ import absolute_import, division, print_function, unicode_literals I have that in a Vim snippet and I use it everywhere. `unicode_literals` turns strings into unicode by default and `print_function` makes print, well, a function, just like it is in Python 3. You can figure the rest out too.
I think [neofreeman summed it up really well](http://www.reddit.com/r/Python/comments/1bqv85/why_do_you_choose_python_over_other_language/c997ora), but I'd add that Python never seems to throw any obstacles in your way. You can quickly test out an idea or prototype something without getting discouraged by boilerplate / dependencies / forced paradigms (Python can be written like a script or completely object-oriented). I write most of my code in C# right now, and that's the language/platform I would choose for large/"enterprise" applications, since I like having a statically typed language when working with a lot of different people / teams. But for writing tools or small applications, I love working with Python. That's not a knock against Python, it's just a personal preference. Google has no problems getting large projects off the ground in Python. Also, whitespace as scoping? Yes, please.
In short: because the community has a much higher level of competence and passion than that of any other language I've used.
A friend of mine wrote [this](https://github.com/Vlad-Shcherbina/persistent_dict) It's one frikken awesome data structure (or even a data structure template/approach) that I found by pure chance, like three days after the last ICFPC where it would have been really useful to us. Some dude mentioned that there's a persistent dictionary implementation that uses mutable structures under the covers and is O(1) in all operations when used with a depth-search like access patterns (unlike all your pleb O(log n) truly immutable tree-like things). So I found [this paper](http://www.google.com/url?sa=t&amp;rct=j&amp;q=persistent%20union-find&amp;source=web&amp;cd=1&amp;ved=0CFEQFjAA&amp;url=http%3A%2F%2Fwww.lri.fr%2F~filliatr%2Fftp%2Fpublis%2Fpuf-wml07.ps&amp;ei=KmsSUPuMCILj4QSMooG4Dg&amp;usg=AFQjCNHZsbibmZXJ1T2DMkQF2bTBYKFANQ) and the simplicity and elegance of the approach blew my mind. In a nutshell: consider a naive immutable dictionary implementation. It has a snapshot and for every operation it produces a proxy that checks if we are accessing the key it modified and returns the corresponding result, or calls the previous proxy/original dict. That's like a _redo_ log. Now let's reverse the shit: each operation modifies the dictionary in place, and modifies the parent object to become a proxy carrying the _undo_ operation. Now when you modify your persistent dictionary or a fixed-length array or whatever implemented this way you are working with it directly, with no overhead except that O(1) for generating undo log, but when you get back to the previous level of your depth-search and access that version of your structure, the whole thing opaquely rollbacks to that state. Fucking awesome, if you ask me.
Its great for 99% of things I do because if it doesn't do it out of the box there's a module for it. And its readable so I quickly see what a module does regardless of if I or someone else wrote it - that makes it fun and quick to code in, as well as easy to learn.
Ruby, a script kiddie language? You're entitled to have fun with your stereotypes but I honestly don't see where that one originates.
If I had to choose ONE thing, it has to be python iterator syntax.
I didn't spend much time with Go but my observation is that Go is the PHP of programming languages that have concurrency in mind.
&gt;If you say PHP (which I use) you are a script kiddie. &gt;If you say Ruby (see PHP). Not sure I understand what you mean by these. I'd say PHP is more like "if you use PHP, you learned how to program from w3schools.com", and Ruby is more like "if you use Ruby, you are an unabashed hipster who yearns to move to San Francisco."
&gt;Python is the most concise language there is. With Python, you write less code. Fewer lines of code=fewer bugs. I don't agree with this. Python is certainly much more concise than many popular languages, but languages like Perl and Ruby trade readability for even more terseness, and the result is that they can be even more concise than Python. Python tries to balance being terse and readable; Perl doesn't care one bit about readability, and Ruby cares a little bit but otherwise is like a modern-day Perl in many ways (sigils, `=~` for regex, optional parentheses for function calls or signatures). Obviously I prefer Python's philosophy on the subject, but that means that in some cases you will write a few more lines or a few more characters than you would in Perl or Ruby.
I do think they get more difficult to reconcile with each revision, but I've had GPL v2 and even GPL v1 software nixed because managers didn't want to risk problems building software that depended on them or so much as overrided one line of code.
Purely from a syntax point of view it's just a beautiful language to write in, at least coming from PHP, JS, ActionScript etc. 
It enforces indentation and decently formatted code, and for that, I love it.
Yes, I didn't want to wax too much onto other programming languages, but Erlang comes immediately to mind on the subject of massive concurrency (which is why RabbitMQ is written in Erlang). I haven't investigated any of the languages you've mentioned though, because I've more or less settled on Python. I do mainly UI-related stuff, and Python makes a great support tool for that kind of work. Sadly I have had to start taking different contracts lately though so I end up writing a lot more JavaScript these days than I do Python. As for VPSes, yes, that is effectively a cloud-style solution; you can get a fixed EC2 small instance for similar money, I believe.
I played with Kivy a little while ago and wasn't particularly impressed. It's probably matured over the past couple of years since I had a look, but I didn't form the impression that it was a slam dunk for developing android applications just yet. Have you used it much?
You shouldn't learn a language based on (debatable) stereotypes of people using it. 
I wouldn't mind switching to python3 but as long as the ubuntu "python" package is 2.7, my collaborators and users will be on 2.7, so I also have to use 2.7
Why is this page titled 'How "Exit Traps" Can Make Your Bash Scripts Way More Robust And Reliable'?
&gt;you don't see web apps written as bash scripts I see you haven't found the [BPE](http://sourceforge.net/projects/bashprogramming/) or [Bourne Server Pages](http://hyperrealm.com/wtfd00d/shsp/) Remember kids, files ending in cgi can be written in a plethora of languages! sidenote: this is more about "hey look at this" than "NAH NAH UR WRONG BRO" I have an unsettling amount of web-toys that are shell scripts. 
Monty Python and The Holy Grail.
Pick a module on PyPi with a github repo and make it work with Python 3
"That's like a redo log. Now let's reverse the shit: each operation modifies the dictionary in place, and modifies the parent object to become a proxy carrying the undo operation." That's not exactly new, this is rougly the way in which the InterBase RDBMS has implemented transactional record versioning since the 1980's. Firebird uses the same thing (it's a fork of it, of course).
&gt; Platform agnostic, and present in virtually every *nix distribution I'm aware of without even needing to install it (because so many system tools are written using it) Had to use crouton with the Chromebook unfortunately. Wish it was native.
&gt; Perl doesn't care one bit about readability ... yet it enables far far greater readability than is possible in python, if the programmer cares about readability. Perl doesn't force it.
Because it has many libraries, fast prototyping, automatic gc, cross-platform, extendable with C modules and its design has few gotchas but a lot of useful features (e.g. iterators). 
Hm. The key point of this approach is that when you access an earlier proxy it rollbacks the "current snapshot" back to it, either invalidating or redirecting all proxy objects along the way. Which is the way to go if you're using this stuff for a depth-first search. I doubt an RDBMS would do that. And without that auto-rollback property the whole thing is not that different from using redo logs, especially when the whole thing is supposed to use fully-ACID transactions. Like, there's no point in advancing the cached snapshot forward immediately if you can't show it to anyone until the transaction commits.
It's simple and does everything other languages do horribly. *But*, I use PHP over Python in web development because there's most support for PHP as an html pre-processor.
I'll just leave this here: http://learnpythonthehardway.org/
Hell is an import-time side-effect of ``import forbiddenfruit``.
I don't care what anyone says about Python performance... once you have expressive, readable code laid down you can still optimize the hell out of it if you need to. While you're having fun adding innovative and fun features to your code the C guys will still be putting together header files and the Java folks will still be waiting for Eclipse to open.
python just rocks. A lot of the time I find myself trying to do something with C or bash or something, when I realize - "Oh my god, I can do this in python in a few lines, and the syntax makes it just flow onto the screen" ex: The other day I wanted to clean up like 40 filenames in a folder, and I was trying to sort out variables in bash, and I couldn't get mv to take what I was trying. and then I thought - python import os for filename in os.listdir(): os.rename(filename, filename[18:]) or something similar
I agree you can absolutely make Perl code readable...but can you explain why you think it allows "far far greater readability than Python"? Could you provide some examples? Because I can't really think of a situation in which this would be true, unless you're looking at some really awful Python code.
It doesn't suck.
The Python Logo is actually pretty awesome.
You got me at newbie friendly.
I'm a newbie too, I've messed around with VB and C++ a little and I just started taking a Python class. I chose Python because everybody says it's the best language for computational biology; I'm a molecular biologist and I'd like to get into the computer stuff, that's a growing area for jobs. There are a couple of things I find offputting (the instructor jokingly said the C++ programmers should forget everything they know) but it's pretty friendly to use so far. Object oriented programming is awesome (not that Python is the only option for that). ...I can't really explain why, it just makes a lot of sense to organize things that way, as classes of objects.
I hope your programs are more accessible than your web page. Pesky non-resizeable fonts :( 
As someone who uses Python, I can confirm I want to move to San Francisco and work for Google.
Speed. Not the language's, mine. A lot of my day-to-day job is dealing with datasets far too large to manipulate in an Excel sheet, and that can be from a wide variety of systems that aren't always able to talk to each other. Python lets me do a lot of Extract-Transform-Load. The Transform part is generally light enough that Python's less than stellar performance numbers (as compared with C or C++ or even Java nowadays) just don't matter - my programs spend more time waiting for DB data than processing it. And there's a lot of stuff I need to do that's clunky to do in SQL or that uses data from disparate sources that aren't even both necessarily SQL. Python let's me not worry about having to implement this stuff. Once I figure out what I need to do, I can get something together to do it in a matter of minutes or hours. The abstractions Python gives me allow me to start with a limited case, and build out and get more and more abstract as I need to. Perl would be another very common choice for this sort of work, but I find it obnoxious for various reasons I won't go into right here and now. If Python didn't exist I'd be using Ruby. I don't *dislike* Ruby, I've done a decent amount of work in it, but Python works and I don't feel changing would get me anything I really need or want. If I'm writing a "real" application though, I'd probably write much of it in C++.
I use python because it is a powerful scripting language with a good library that I know because at one job years ago the tech lead decided python was the language we have to use so I learned it. I like the simple syntax that encourages readable code. I don't use bash if I can help it because the sh script syntax has weird quirks that I have never really wrapped my mind around. I don't use ruby or lua because I already know python. Programmers I trust like (whichever) the same things I like in python. (though Lua's library is probably small) I've almost learned both a few times, but then the problem changed and I didn't have to. (Lua is a tiny lanuguage that I was trying to fit into an embedded system but I lost the job before I found time. Ruby is used for some of our scripts at work, but so far someone else is maintaing them well) I use C++ because there are times where close to the metal performance is required for my job. Now that I'm a experienced engineer I get put on the difficult real-time tasks that only C++ can handle. However there are still times I realize I'm only doing C++ because it is faster to write 10 more lines of C++ than the glue code to do this task in something else that is otherwise well suited to it. I don't use Java because I don't like marketing, and Java had too much marketing hype. Otherwise I see it is a weird C++ without the useful parts (templates, multiple inheiritance...) that isn't as programmer efficient as python, and isn't as CPU efficient as C++. (Note, I last used Java 1.0.3 - which should give you a lower bound for how long I've been programming) .Net is Microsoft's answer to Java. I'm a unix (not linux!) guy at heart, so I avoid situations where it is useful, though I have nothing in particular against it. I've never used it. Scheme is pretty, and I have a soft spot in my heart because of SICP. I haven't used it since college though. I play with Haskel, LISP, Erlang, and other hip languages once in a while, but I've never really learned enough syntax to use them for real work.
It's fun to program in, easy to reason about, and even maintenance programming is about as good as it can be. In short, it's designed to let you build software you can still read down the road. It makes me happy, everything else is just small details.
&gt;The question now. Python 2.x or 3.x? http://wiki.python.org/moin/Python2orPython3
You know, you can use the rich framework of .NET from Python, if you use IronPython. Here's an example: https://www.geektrust.net/blog/elegant-windows-scripting-with-ironpython/
Micropolis, the open source version of the old SimCity, has Python in its architecture. http://code.google.com/p/micropolis/
I found 2 PDF files with titles along the lines of: 'how to make games in python'.
Elegance
If you use Erlang you (very likely) work in telecommunications :)
Sadly, there might be more Delphi jobs than Python ones…
That's a lot of guys.
Okay, is it really necessary to post this sort of shit here? It contributes absolutely nothing.
As a partial "python newbie," I would appreciate some more seasoned veterans' opinion on... &gt; * Platform agnostic, and present in virtually every \*nix distribution I'm aware of without even needing to install it (because so many system tools are written using it) What are the "best practices" surrounding old legacy platforms many of us sysadmins / tools guys support on old legacy platforms that, inevitably, we get stuck on for one reason or another? This is part of the "issue" I always had with perl (think Solaris 2.x days when the system perl was stuck at Perl 4), but I am under the impression that python's virtualenv and the like seems to help with better co-existance of multiple versions. And, like I said, many linux distros have their repos seemingly "stuck" at silly things like python 2.5 or 2.6... where I would at least like to be in the 2.7 world. So, any wise words for a pseudo-junior python tools person? (Though I have been I the unix tools world for longer than I might otherwise like to admit... but really just starting a deeper dive in to python) 
What's really weird is, I know for a fact I've read a blog post with that title. 
Coming from Matlab to Python as a scientist: 1. Python has more than one way to do it. Often in Matlab, if it couldn't be done one way, or worse you didn't understand the 'right way' you were fucked. In Python, there is almost always a work around if something isn't working as you think it should. 2. Python+StackOverflow &gt; Matlab reader. I spend most of my programming time googling a solution to a problem to see if someone else has done it. I more often find good answers for Python than I did for Matlab. 3. Readability. If I find a python code snippet (as long it's not some wanky pointless class bullshit from someone trying to show off) I can usually skim it and understand what it does. With Matlab I usually had to just implement it with the debugger active and see the transformation step by step. 4. Free, I teach programming to others fairly often. I always felt bad using a semi-legal copy of Matlab or telling them to shell out $200 to learn a program. In Python I don't have this problem. 5. Modules are really nice, this might not matter to a newbie but the ability to pull in all the functions of any program you have written with an import command is cool and convenient. Cons: 1. Matlab can handle more data. Unfortunately, most of the python packages I need are still 32-bit (or certain packages are holding it back, *cough* opencv *cough*). In Matlab I can confidently fill up my 16gb computer with commands, in python the memory ceilings (for now) are lower. 2. Python documentation sucks. Matlab documentation is pretty and tells you what goes in and what comes out. Luckily there is usually an article explaining most functions. 3. Python is less consistent, since it's not a Matrix First language, you'll occasionally get silly behavior like a package that decides to print x,y instead of y,x. 4. Bar to do things is usually higher unless there is a package. In Matlab, GUIs are quick little two line affairs. In Python you have to whip out Tkinter or Wxpython, neither of which is pretty. This happens a lot. (On the plus side there is often a package like easygui) 5. Less domain specific, this makes searching messier. It also means that somethings (like reading z-stacks) is a lot harder or less logical. Python 2 or 3 All scientists are on 2.x. However, most of the essential packages are ported and I suspect the shift to Python 3 from the scientist community (and to 64-bit) starts this year. If you are doing scientific computing I'd do 2.x but switch to 3.x the moment python(x,y) has a distribution containing it.
Of course. I was tired of the damn semicolon.
mainly to impress the ladies
Because people in an IRC channel I frequent tell me Ruby is a horrible language. I personally still can't decide. I'm doing web work, I should probably make a decision soon.
You're kidding, right? Dice.com - 22 jobs with "Delphi" in job title vs. 400 with "python". Without it being in the title, 80 vs. 3,957.
Upvote to you, my fellow snake-loving friend.
Lawyers are lawyers, what can you do. Microsoft black, you were in blue.
Beginner: Let me be your programming buddy!, I watched FOXPRO and I have a tons of books of FOXPRO. But I don't know the Inner workings of the computer. Somebody should guide me to straight path. I'll be your best friend especially to the ladies. 
If you are any good at all as a programmer, you will learn both Python 2 and 3. The only real question is, which first? The answer is, whatever the book you're using was written in.
My best friend from college invented several popular Ruby web dev tools. He moved to San Francisco. 
 - If you use Haskell, you publish blog posts explaining monads
Pyglet. So powerful and easy.
Games: I have experience in games but I need a programming buddy!
Wow what sorcery allows the text to not resize on zoom? While it's readable for me, it's still baffling that it would behave like that.
&gt; currently the only way I've seen to do this (reasonably) is running a virtualized interpreter (e.g. Pypy), which has its own challenges—especially where compatibility with C-based modules is required for your application. Little access to C modules is to be expected when sandboxing; the pypy sandbox is more or less ready to go at this point, we just need to get a download link on pypy.org with a complete distribution of it (right now there's a download link with nothing but the binary).
Okay, that's kind of usefull.
I now that feel
pygame (1.9.2) works on python 3.3 actually, you just have to install from source.
Different languages for different problems... you don't write drivers in Python, you do it in C. and you don't make Android apps with it either. You can also patch C modules in your Python app to improve performance.
Maybe metasploit? Otherwise I don't know either.
Since all the pros have basically been mentioned, I'll give you reasons why I _wouldn't_ use Python: * Low-level code that can easily be done in C * Code that has to be low-level, ie. system programming. * Performance is critical, eg. most game development * Obfuscate functionality for proprietary reasons * Mobile phone app development * developing in a well-engineered framework based in another language * collaborating with developers highly skilled in another language * sometimes I just really miss statically-typed languages Don't forget you can mix C in with your Python application. Make sure you've optimized your algorithm as best you can first, but sometimes it might be a good call to write it in C and patch it in.
Not sure if it's mentioned but the language is NOT about the snake.. it's about the comedy group called Monthy Python.
You could use the curl bindings for Python instead through the [PycURL](http://pycurl.sourceforge.net/) module. I wrote a quick tutorial about it a while ago at http://www.angryobjects.com/2011/10/15/http-with-python-pycurl-by-example/
A good start would be to examine the source code of similar games. There are plenty of open-source turn-based strategy games out there, like [Battle for Wesnoth](http://www.wesnoth.org/).
I think I read it on the python.org page.
To be honest the answer is No. I am a huge python fan when it comes to "syntax", "community", "libraries available", but I much prefer to do my job in other languages. For web development i mainly use Java EE (JSF/ADF 11g) or Spring. For desktop app development I mainly use Java Swing . And for low level things I would C or C++. For small apps and scripts I tend to use Bash/Powershell or Groovy. The reasons ? Hard to point them out. I just don't feel python it's the answer for my needs. 
http://xkcd.com/353/
As another one mentioned: [Acme](http://acme.cat-v.org/)
all of those problems are only a deal breaker once you're at the point where you no longer have to ask questions like why did you choose python. i'll give you good advice: there is no reason not to learn python, it's a good language, even when you run up against it's limitations you will still be able to use it to toss off a quick script to solve a problem.
i've also seen web apps written in c, it doesn't make it right.
Strategy Games like that are mostly made up of simple state-machines interacting with each other, IMHO you should start there.
I'm surprised nobody mentioned this, but pdb is awesome. I'm tyring to move to clojure for private projects, and the one thing I'm missing sorely is a debugger of similar caliber.
Pity for language designers is a terrible reason for making technical decisions. It's laudable to hang a picture painted by a relative with Down's in your living room to show how you appreciate their effort, but pretty unwise to use an electric heater they made, gratitude or no gratitude.
Never said any were reasons not to learn Python; I obviously love the language or I wouldn't be here. With that out of the way ... OP asked for "pro's and con's" and I'm not seeing a lot of disagreements with my statements on either side of the fence.
Yes, I agree that limiting access to C modules is probably required for sandboxing—but not necessarily for performance enhancement (if that's what you're into). I really, really want to be able to use Pypy in a production environment for performance reasons, but it seems that beyond a certain level of application size we invariably end up depending on one or more third-party C modules to get the job done making Pypy no longer an option (at least, for now—I understand some level of C module compatibility is in the oven, which is exciting).
I think you're confusing uses of pypy - the sandbox and the jit are orthogonal. you don't enable the jit at the same time as the sandbox (at least, if you want to trust the sandbox). while producing asm code at runtime can be made to be safe, and there's no reason to expect that it's not, it's also rather complex and there's no reason to assume it *is* safe, either. besides, the way the sandboxing *works* is by making calls to c go through a controller process, which instead of calling the C code, hand-implements what it would do, in a very restrictive way. you can't just let it call any old C code and expect it to be safe, that's the whole point. in regards to c compatibility in pypy-jit - they already have cpyext, it's just rather slow. so as long as you don't use the libraries in your hot loops, you're okay. and there's CFFI, and psycopg2cffi, so that performance hole is plugged.
I tried most of the old school languages (not really tried all the latest and greatest though) and ended up with Python mostly for one single reason: * It is fun and it gets out of my way Now let me expand a bit more on that: * I am one of the few that does not hate Java as a language, but one of the reasons I abandoned it to Python was the standard library. Java's standard library is so over-engineered that it becomes counter-intuitive (factory factories and patterns like that) and adds a load of complexity and overhead to the code base. Python's standard library is (mostly) straight to the point and gets out of my way. I will admit there are a few "wtf" moments with the python libraries as well. This is in my experience so far mostly related to the more exotic bits of the standard library like networking modules that have a rather inconsistent feel across the modules. I do, however, feel that they have cleaned up a lot of this mess with the more recent versions of python though. * I am fully aware that there are situations where Python will not do the job alone, and so I love easy integrations with C. * Since Unix/Linux always was used as background material for "how operating systems work" during my CS degree, I love how Python builds on the Posix way of doing things. I feel at home in Python because of this. * I must admit I was not a big fan of the Python syntax at first, however, it turns out that with Python I actually bother to spend time reading other peoples code and the libraries I use to see how it works. This have turned out to be a big advantage in understanding how my code will behave. I used to do a lot of C++ and to be completely honest, I had no chance in hell (due to complexity or time) to understand the internals of many of the libraries I used. * I started out programming with Basic so many years ago... Python gives me that warm feeling I got when first started programming. Not because its similar to basic in its syntax, but it allows me to quickly too cool stuff without having to design and model everything first, or write ton of code that "just needs to be there in order to work". * I program mostly on Linux, but its a big advantage that my code works almost as good on both OSX and Windows as well, since I sometimes use these platforms. * I used to to PHP for whenever I needed to do web programming. It was a big change to use Python for this instead. Mostly because, although PHP would allow me to quickly get stuff done, the code base would turn into a mess quickly as the codebase grew. Might have been my fault though :P I mostly use Python 2, but I actually prefer Python 3 as they have cleaned up some of the inconsistencies I mentioned above. I will migrate fully to Python 3 as soon as the last of my preferred libraries fully target that release (I am looking at Flask!). As with all other languages, Python is not perfect. Here are my issues: * I prefer consistency in libraries, and although Python are better than many other languages, there are still some fucksups across modules in the standard libraries. Also, third party libraries too often are written in a way that they mind as well could be Java libraries. I obviously cannot force anyone to write there libraries in a consistent way, but there have been moments where I have had real issues with using third party libraries that are considered the de facto standard for a certain task due to bad API design. * Multithreading. Seriously. Its not good. * The Posix inspired design does not always work as good on Windows, but despite of this, I actually prefer that design over too many layers of abstractions (like Java libraries). However, some Posix bits could work on Windows as well with a little redesign of certain parts of the standard libraries (e.g. the select/poll module). * My main problem with Python before I got to know it was because many applications on certain linux distribution broke all the time (and I really mean all the time), either spending too much resources on trivial tasks or exploding in my face with Python exceptions. This was obviously not Python's fault, but bad programmers, however, this unfortunately left a bad feeling about the language that I needed years to overcome. So to the question at hand; should you learn Python? The answer is yes. Not because Python is the answer to everything, but because it cant really hurt. Even if you don't really like it it will probably give you a feeling about what works for you and what does not work for you, and you can use this knowledge to find the language that DO work for you.
That is an interesting problem, and one I have run afoul of; one of our production environments is necessarily pinned to a crusty old version of Python (2.4) which is a pain to develop for. Distributions' dependence on Python can be useful but it can also be a burden because of that very problem (being handcuffed to an older version). The good news is that Python is designed so that multiple versions can live harmoniously alongside one another. You won't be able to replace the "system" version of Python on, say, older versions of CentOS (nor should you, under any circumstances, try; it will be a very painful lesson for you if you do). However, there's nothing preventing you from installing another version of Python and running your application with that, instead. You are correct in that virtualenv is a great way to "pin" your application to run with a certain version of python, however this is overkill for a simple one-file script or two that don't use many (or any) third-party libraries; in such cases I would just specify the interpreter with #!/usr/bin/python2.7 (or whatever) and run the script directly from bash (e.g. `myscript.py` not `python myscript.py`). Virtualenv's primary purpose is chiefly to create a clear separation between your 'system'-level packages (e.g. /usr/lib64/python2.7/site-packages) and those required to run your application, where you may not have (or want) root privileges to install new packages or use different versions than those already installed system-wide. The biggest challenge you'll have running an alternate version of Python on a legacy environment is to make sure you're using the right version of all the tools; you won't want to run 'easy_install' or 'pip' for the legacy version of Python 99% of the time, but it will be an easy mistake to forget to type "easy_install27" or whatever it ends up being. Provided it's only you (or a small group) running the scripts, I suggest setting up aliases for 'python', 'easy_install', 'virtualenv', 'pip', and so on so that you don't run the legacy version by accident—you can still always call the legacy version by specifying the full path on rare occasions when that is really what you want.
I guess it's time I give it another look, then. A quick glance at their web site shows it has certainly matured since last I looked! Thank you for the suggestion. I guess some of the interest may have been curried from the (massive) success of the Raspberry "Py" as some have joked it should have been called; I confess I don't own one as I don't have time to tinker with it, but I think the Python community owes them a debt of gratitude as the Raspberry Pi has created a lot of interest in furthering what Python can do (and is cultivating a growing audience of developers who use it) and projects like Kivy have doubtless seen a large boost as a result.
If it seems like I am ignorant of the uses of Pypy, I apologize, because that is the case—it is far too abstract for me to wrap my head around the different use cases. Not to put too fine a point on it, but this is exactly the kind of problem that needs to be ironed out if you hope for widespread adoption of Pypy; it needs to be about as easy as `print "Hello world!"` to use. I don't have the time to go chasing down all kinds of libraries just to make it do what Python does out of the box (albeit faster under certain application loads, granted).
considering my only involvement in it is to try to orchestrate a release of the sandbox, I'm not sure I'm the best person to be given that information :)
Fair enough; I wish you luck all the same!
Python is very constricting (hah! :) which places a lot of limits on how well you can make the code actually tell you what it's doing. Those limits are similar to what many other languages have, so it's easy to miss them, but well written perl can read like English *and* a program at the same time. You can write in a way that actually tells you what the programmers intention is at the same time as allowing you to read it as code and use logic to determine what it's doing. A lot of that has to do with "There's More Than One Way To Do It", the now much-maligned design philosophy of perl that I think is one of its greatest strengths. Just as in natural language you have multiple ways of saying things that have exactly the same direct meaning, but express different emphasis or context or implication, and that actually makes things clearer if used appropriately, so in perl.
I'm using Jython for a project at work. The reason for picking Jython over CPython is because I haven't figured out how to access an Oracle DB from CPython on Mac OS yet (granted, I haven't tried too hard either). In the Jython world I can just use the JDBC driver and there's a module that provides a DBI interface to it. As for using Python-the-language over something else... For this project, it's about ease of use and speed of development. Since the generic data types (tuples, dicts, etc) are so powerful, I can spend less time building data structures and more time figuring out the logic I need. There's one particular piece of code which compares the results of two queries and returns the differences. The number of fields is unknown until runtime, the number of fields that serve as keys is unknown, the number of fields that are used as values is unknown, and the data types of the keys and values are unknown. The Python code that deals with all these unknowns doesn't actually need to know any of this - the keys are tuples built at runtime, the values are tuples built at runtime, and they can be compared and sorted and hashed into a dict() without really knowing (or caring!) what is in them. The Python code is about 40 lines, the thought of the amount of Java that would be required to accomplish this task scares me more than a little bit.
&gt; Java folks will still be waiting for Eclipse to open beautiful
&gt; wall of text without an index and it's often not even clear what the functions return or what the arguments are supposed to be. There's a ToC on the left and a "quick search" of the indexed documentation. IMO, it's occasionally less explicit than it needs to be, but sufficient the vast, vast majority of the time. And they're relatively receptive to accepting documentation bugs.
[As both developer and citizen](http://i.imgur.com/Hl9KgKB.gif)
&gt; methods that mutate a list return None so you can't chain methods The idiom for doing this is generators. If you did pass/return a `list` for chaining a bunch of transforms, you might be disappointed at how poorly that scales up to very large lists.
&gt; yet it enables far far greater readability than is possible in python I'm floored. IMO, you should qualify this claim with examples. &gt; Perl doesn't force it. Nor does Python, but I think the "readability floor" is probably much higher than Perl's. But what's to be gained by write-once code? Very little, IMO.
oh boy, I really don't mean this comment to be gender issue.
There is a chapter in the "The Architecture of Open Source Applications" explaining some of the architectural decisions that went into [Battle for Wesnoth](http://www.aosabook.org/en/wesnoth.html). Worth reading!
Show me such a line and I gift you one month of reddit gold.
No disagreements at all - your arguments on both sides were models of rationality and completeness. Very fair, my hat is off to you.
Really, the documentation is pretty good - but you put your finger on the big issue, the page lengths are too long. It's particularly nasty as you often don't have anything to really link to when you send people links - anchors don't hack it.
Indeed... guess I was wrong there. 
But Java is so sloooow to code. Everything's so verbose! Sure, you use completion in your IDE but it still slows you down - and it makes reading code a truly boring experience. There are several anti-features that contribute to this. A big one is that in Java everything has to be attached to a class, and a class necessarily adds a lot of bulk and state to things. Another is the fact that the Python built-ins are very powerful in the "bangs per keystroke", whereas the Java generics are even more verbose than regular Java. One of the really nice things about Python is how I can fit almost any individual part I need to write into a single "page". This means that most of my code files are one or two pages long - which means that I never have to scroll around looking for what I want. I did Java for years. Never again. Nothing terribly wrong with it, but I've moved on. 
It's very important not to make gender assumptions by accident using language - I agree! But in 2013, "guys" is in the process of losing its gendered nature. I heard young women all the time say, "Hey, guys," to a mixed-gender group, or talk about, "The guys," when half of them are female.
Maybe 50 was an exaggeration, but I can write a useful one line program in Python. You can't even write an empty program that small in C (assuming you don't remove all white space, anyway.) You have to include numerous libraries just to do the basics, prototype functions, etc. I've written very powerful regex functions that stripped all sorts of junk, found the third number after the fifth semicolon from the end, etc. all in one line of Python. It was beautiful, and it was portable. I've also written graphical cryptanalysis tools in not too many lines that could be run on any OS (with a library).
The end goal, which seems a bit far away, is to match any "help wanted" to any "for hire" in any profession/industry. Here is a sketch of such website https://datada.pythonanywhere.com/static/index.html (Something similar can be used in dating context or buying and selling some rare items, etc.) I am using the YC thread as the first set of data to gain some insights/skills. (Not only for matching algo but to flesh out the website work flow as well.) So far, I've tried using tech terms as the keywords. Obviously this approach would require lots of work if one was to extent to other professions/industry. Next, I tried out nltk entity extraction, which seems to get most of tech terms on its own and then some. It's not obvious this produces a better matching algo. Another thing is the location data since most of the jobs are local. Once again, nltk seems to get out more than location data. So my next task is refine entity extraction, it seems.
Guido actually mentioned that they are considering adding it in his latest keynote. Hopefully that'll push it to be more robust and well tested.
It really depends on what exactly you're doing and also, if implemented correctly, you should be able to swap out parts of your pipeline for any other language/tool as needed for performance. Bigger question is how you are going to implement the distributed system, RabbitMQ or ApacheMQ don't really care who talks to them as long as they speak STOMP or AMQ protocols. Hadoop is generally more JVM centric but you can use the streaming interface to use crazy things like bash as a reducer. I haven't used Storm yet but it seems like its only requirement is thrift support. So if you're most comfortable with Python and would like to make generation 0 of a distributed work system in it, my only advice would be to do more research in how you are going to distribute the work. Some options are: Rabbit or ApacheMQ, Redis, a SQL DB ( worse possible option but it can be done ), Zookeeper ( I really like ZK but it can be barebones ), zeroMQ ( another fun library but it is barebones ). After that the next question is how reliable you want things to be. If a worker takes a unit of work and fails before finishing it, how do you want to handle failure? Probably the only controversial opinion I will give, be skeptical of python celery. I've had a lot of problems with it when the system scaled up to +1000/second tasks and its hard to coordinate producer to consumer communication to prevent queue floods.
If performance is important, you might want to look at Scala or Clojure. Those in particular are JVM languages so there are a ton of FOSS libraries available. See: http://benchmarksgame.alioth.debian.org/u64q/performance.php?test=nbody I'm talking a free online scala class now taught by the creator of the language. You can still sign up if you're interested: https://www.coursera.org/course/progfun
And this is why it's so bad that Ubuntu is becoming the Windows of Linux.
Gah, that's because I had copied the django template used for this article from another I wrote about bash exit traps, and forgot to change the &lt;title&gt;. Thanks for pointing it out - fixed. (@MrVonBuren, I got a lot of traffic for this one: http://redsymbol.net/articles/bash-exit-traps/ - it was on coder weekly, etc. That's probably where you remember it.)
"Hm. The key point of this approach is that when you access an earlier proxy it rollbacks the "current snapshot" back to it, either invalidating or redirecting all proxy objects along the way. Which is the way to go if you're using this stuff for a depth-first search." That's a good specialized behavior, but not the only possible one. I imagine that you could have different kinds of behaviors for different usages. "I doubt an RDBMS would do that. And without that auto-rollback property the whole thing is not that different from using redo logs, especially when the whole thing is supposed to use fully-ACID transactions." The records are versioned and the transaction accesses the delta records if it sees that the current version is newer and therefore not the data it should see because of transaction isolation, but the implementation is virtually identical, make the changes in place and keep deltas around in case that someone else accesses the record, with the assumption that such accesses are comparatively infrequent. (Having said so, the deltas are kept on the same page in most cases, which keeps the disk page fetch count low.)
Oh, your style is so awful! For one thing, those columns don't help people in general read any faster. Study after study has shown that (surprise) the closer things are to a regular English sentence, the faster people can read it, and the faster they can skim it. And the time you spend doing that is time you're not actually writing code. Don't tell me it doesn't take your time - I used to do this sort of thing in Java and it does, particularly when you get a new, long name and you have to reformat everything. The worst part is that it sticks out. People reading your code will have their eyes drawn to that, and not the actually important part of your code - what it's actually doing! Remember - code is written once but read ten times. And if your code is any good, it's going to be read by a lot more people than just you. Python, in particular, has [PEP 8](http://www.python.org/dev/peps/pep-0008/), which says how Python programs should be formatted - so it's part of the language. Almost everyone's Python code looks like PEP 8. By deliberately being difficult, you're imposing a small but measurable cognitive burden on any other programmer who ever wants to read your code. You shouldn't be trying to express yourself through your code's formatting. Your formatting should be trying to make it absolutely as readable as possible for as very many people as possible, which means you should always use PEP 8. You should be trying to express yourself through your actual work - through the quality and functionality of the code you have written - through the clarity of your naming and your data structures - not through minor cosmetic decisions.
Well, it's not just a matter of taste. I've coded some apps for clients in python, and then I had to rewrite them in Java, because of performance issues. When it comes to server-side programming nothing can beat a Cluster of Weblogic Servers. So afterall, I might enjoy programming in python for hobbies, but at work, I will use Java for a while.
Interestingly, the systems supporting http://edx.org are written in Python and in the process of open sourcing. https://github.com/edx
The people who write modules for or contribute to Metasploit tend to be a bit more advanced than script kiddies, too.
It really depends on how you implement it. 0MQ is what handles our messaging and queue systems. We're using it to process millions of Android APKs with malware heuristics to find undetected samples.
Upvote for celery, it makes (certain types of) distributed systems seem easy. To start I would also suggest using redis as a message transport. Then there is also paralell python, may fit your profile as well
Yeah... mainly remote access tools. Why? Because the source code for some older malware is available and script kiddies don't like to write everything from scratch. There are many business apps written in Delphi as well (especially database frontends), which is why I expected a higher number. 
&gt;I used to to PHP for whenever I needed to do web programming. It was a big change to use Python for this instead. Mostly because, although PHP would allow me to quickly get stuff done, the code base would turn into a mess quickly as the codebase grew. Might have been my fault though :P Nope. You can safely blame the language in this case. PHP is just a mess.
Just out of curiosity, what transport and setup did you use when having trouble with celery? Performance can vary quite a lot if you use db as result backend, prefetch multipliers on the workers, which transport you use and of course, reusing the connection when publishing tasks.
I'm using rabbit as a message transport, works great
Pygame has all but a few modules ported to python3, but if you don't want to wait there's [pgreloaded](http://code.google.com/p/pgreloaded/). It supports python 2.7 and python 3.1 (and up). 
The Qt library isn't bad for game development. [PySide](http://qt-project.org/wiki/Category:LanguageBindings::PySide) is the official Python bindings for Qt, and there is also [PyQt](http://www.riverbankcomputing.com/software/pyqt/intro). Both can work with Python 3.x. But if you want to use Cocos or some other library that only supports 2.x, then there's nothing to think about. Use Python 2. The point of programming is to produce a finished product, and so you choose the tools that'll make it the easiest to do that. 
The differences between Python 2 and 3, overall, are pretty minimal and are easily picked up. So I would just go for it and choose the best suited 2D Python 2 engine for your game idea. Guess you have also seen PyGame? I think I remember seeing a page on game dev using Python on the Python wiki.
I'm super interested in hearing more about your celery issues.
Python's inclusion of meta-programming is a part of the language, unlike many other languages which use a preprocessor. The result is that you're not coding in two languages, the syntax is coherent, and debugging is rendered easier. If your question is posited more at why perform meta-programming, then that's a pretty simple answer: don't repeat yourself. Decorators, class decorators, and metaclasses all permit injecting commonly duplicated code. Proper use can improve code readability and reduce development time.
Sorry I probably should have mentioned - The tutorial that I linked IS a pygame one. I've already been through pygame. I'd rather not have to code all the tiny little parts. Thanks anyways though
Ah that's very good to know then. I'm looking through the other comments now, and if none of the libraries that have been posted float my boat I'll just head down that road. Thanks.
I notice that there is an ordered dictionary type in 2.7.4. Is this present in Python 3, or does one need to use something like the collections library? 
From the detailed whats-new page: &gt; Based on the experiences from those implementations, 2.7 introduces a new OrderedDict class in the collections module. (http://docs.python.org/dev/whatsnew/2.7.html#pep-372-adding-an-ordered-dictionary-to-collections)
Sorry - what I meant is there an ordered dict class in version 3?
Python 3.1 has OrderedDicts: http://docs.python.org/3.1/whatsnew/3.1.html
Thanks for the reply and taking an interest to sort it. I had the problem with Chrome 26.0.1410.43 on OS X 10.6.8 (Snow Leopard). I get the same issue with Safari on OS X, and Chrome on both Linux and Windows so looks like a webkit oddity. As you say, Firefox does work, but I didn't think to check that last night as I was tired and grumpy. 
Ah ok, so jeah I missed that, sorry. For what it's worth (and since you are already doubting your choice of language), i've found Flixel (as3, I know) to be the quickest 2d engine to work with. I've completed 2 gamejam's with it and think it's a better offering in terms of development speed then pygame. I'll [link](http://bacongamejam.org/users/BruceJillis/) you to my entries so you can check out the source code, if you are so inclined. Oh and bacongamejam is ramping up to do a new jam and since more people equals more fun i'll point you to the sub as well: /r/bacongamejam Before people start downvoting me, I love python and you can definitely compete and win with [pygame](http://bacongamejam.org/jams/bacongamejam-03/bottlecap-blowout/) (I lost to this entry btw) but just compare the amount of code for this game and my entry and I think you'll understand what i'm trying to say.
Huh? I've been using python 2.7.3 for a while and I've always been using OrderedDict with it. How is this new? I'm genuinely curious.
This is was much more confusing before I remembered celery was a python library.
I'm gonna give cocos2d a shot with python 2. But if that doesn't work out I'll head straight there. Thanks for the info though, this is quite all overwhelming right now so it's good to have someone more experienced point me in some of the possible decent directions.
Alternatively, if you find Erlang's syntax atrocious or want hygienic macros you can always check out [Elixir](http://elixir-lang.org/). ;)
I just write ksh scripts in that situation and use python to mass deploy them. As an example, I once wrote a script to scan user's home directories for SSH keys. In our massive environment there are a lot of different NFS servers hosting home directories. So to avoid duplicated effort I wrote the shell script to spit out 'df' and wait for a 'read' before doing the scan. I wrote a python script to manage the whole thing using Gate One's termio module (works like pexpect but async). It would spawn many concurrent SSH connections and watch/capture the output of the shell scripts. With each connection it would check if a particular NFS server had already been scanned and would just kill the script instead of sending a CR/LF (enter key) telling the script to continue.
Thank you.
https://github.com/mikedewar/d3py
Thanks you so much!
Thanks... that helps, a bit. To dig a little deeper (or maybe shine a little more light on to my own situation), one related issue is trying to mass virtual host things like [django](http://www.djangoproject.com) or other [wsgi](http://code.google.com/p/modwsgi/) apps, where some sites may be strapped to older versions (and older modules) while new ones stay closer to the release candidate or "bleeding edge" end of things. And yeah, don't even get me started on Python 3 right now, either... /grins And, like I said, not to mention having to deal with systems that may be as old as Ubuntu 9 or 10, or CentOS 4 or 5, or Debian 5... as you said, replacing the system python (or whatever comes out of the distro's own repo) is generally a problem we *don't* want to tackle - and I know it's a recipe for disaster ... particularly as production systems are built to "turn and burn" if they hit a problem (eg. fire off a new kickstart to bootstrap the new system, throw in puppet to configure the system and monitoring, and then *away we go*). So yeah, the "system python" problem doesn't really go away. Yes, that's adding *a lot* more complication in to the situation, but I hope it helps better illuminate some of the complexities I'm getting at, here.
Thanks... though not really what I'm getting at, here. I'm more worried about concurrent versions of python within old legacy systems that "can't" be up-rev'd for whatever reason, coupled with newer versions of python support scripts that *need* the newer python stuff that isn't provided by the distribution provided within a given system distribution.
Ah, I see what you're saying now. In that case what you really need is Dumpster. It's the most useful tool a data center can have! Just know that installing Dumpster isn't enough... you need to evangelize it and profess its benefits regularly! People will forget it's there and things *will* go horribly wrong as a result. I can't even begin to describe all the benefits and features of the product. Oh how I've wished many companies and teams were using it more often! Open Dumpster is the best version. It's the kind you really need in situations like yours. Here's how it works... Start by unracking the legacy system. Next get a dolly because they can be heavy! Now wheel that sucker to Dumpster. You may need some help on this last step... Carefully lift the device and heave it in! Dumpster saves more money and provides more protection from hackers than any other tool I can think of! Don't believe the scurvy dogs who think Boat Anchor is better... just when you think you're moored nice and tight the chain will start retrieving itself from the wrong end! Those old systems can suck *that hard*! In those situations it is best to abandon ship as soon as possible.
&gt; Is this present in Python 3, or does one need to use something like the collections library? The answer is yes and yes: it is present in Python 3 and to use it you do have to do "import collections".
Perhaps in an ideal world ... but in reality, if often doesn't work *quite* like that, trust me (and yes, I've often been tempted to "test the power switch" a dozen or two times on older boxes, too, just to "make sure they still work" ... but it's also not always the best idea, either).
It's not apparently, that feature is in the 2.7 changelogs not the 2.7.4 changes. 
Why was this released *after* Python 3? I'm fairly new to programming, so that doesn't make sense to me.
Python 2.7 is considered "where we are," while Python 3 is "where we're headed." Python developers try hard to preserve backward compatibility, and Python 3 specifically breaks this cycle to implement improvements. Thus, both builds are being developed concurrently. As mentioned elsewhere in the thread, a lot of the 2.7 additions are backports of features from 3. If you're just starting out, as you learn, be sure to give careful thought to which flavor you'd like to use.
Very easy to do what I want with it. I use assembly and C for embedded applications and I'll be damned if I mess with that when I can use Python. Super high level languages are the future. 
That's what I was going to post!
If you can find something different in your day to day work, you're doing something wrong.
Now if only they back ported function annotations.
Your answer confuses me, especially the 2nd paragraph. The OP is asking about building distributed systems and yet you mention Hadoop and Storm (I do use Storm in production and you should try it if it fits your needs). Those two especially have absolutely nothing to do with with creating distributed tasks, they are just data processing pipelines.
What do you mean by "programming distributed systems"? You are an MsC student so I assume you are not working on a large scale web project which needs to be distributed to scale. If you are planning to work on an MsC project which involves building/prototyping a distributed system like a distributed database (project voldemort, hbase) or frameworks like zookeeper then you should be going with the language you are the most comfortable with. Sure, I love python and it just works. But there are some shortcoming of python to java (or C) especially when it comes to threading (which is an essential part of such a distributed database). This is not the right forum to ask this question, people answer all kinds of crap. Some guy answered celery and some one erlang without even understanding what you are trying to achieve. "Distributed system" is a huge topic, you need to be more specific about what you are trying to do. Send an email to the mailing list of a software project which is somewhat related to what you are planning to work on. Ask someone who has actually worked on a similar problem. That will help the most.
For the curious: **abc** = **a**bstract **b**ase **c**lasses
This. 2.7 is a dead end: no new features, just bug fixes
3.1+ 2.6 was released alongside 3.0, 2.7 with 3.1. Everything in 3.2+ has no corresponding 2.x release.
[Some of us](http://flask.pocoo.org/) have no choice. :\
2.7.4 only has bugfixes, no new features at all (there will be no new features for Python 2) that page is confusing.
because worse is better, 2.7 is worse, so I stay on 2.7
&gt; If you're just starting out, as you learn, be sure to give careful thought to which flavor you'd like to use. Strongly disagree. If you're starting out, give little or no thought to which flavor of Python you use. If you are successful at learning Python at all, you will eventually learn both. The only thing that matters is which to learn _first_, not which to learn at all. Which should you learn first? Whatever the book or website you're working through uses. The end.
Great job. Would be nice if the slides were available also.
http://www.lfd.uci.edu/~gohlke/pythonlibs/#pygame Has pygame for python 3.2-3 both x32 and x64 windows.
Yes sure it does, the comment was more for OP if s/he does not want to install erlang and rabbit, redis is a little more light weight. I am not implying that you should switch rabbit(whis is a MQ) for redis(which can act as a MQ), there is almost no point in doing so. But if you are just tarting up, and/or you're in a webshop you could use redis as the message-queue, use redis instead of memcache and use redis as a distributed lock service (if you need to mutex multiple frontends). Thus having three quite usable features with a simpler architecture, unless of course you already have these features in I dont know, rabbit, zookeeper and memcache :-)
The changes are entirely bug fixes. Python 2 will not be getting any new features. That said, I'm still going through the bug fixes to determine if any will actually impact me. Does anyone see anything significant?
Thanks for posting that! I was just worrying about combining multi-worker apps in uWSGI and sqlalchemy. Link for the lazy: http://uwsgi-docs.readthedocs.org/en/latest/PythonDecorators.html#uwsgidecorators.postfork
This article, which has been receiving some attention on Proggit, albeit for Rust and Dart, references a Python implementation of the benchmark which happens to be the slowest of the languages tested by some margin, even on PyPy. The [Python implementation on Github](https://github.com/attractivechaos/plb/blob/master/sudoku/sudoku_v1.py) is a heavily non-idiomatic translation from C. I've made a few simple improvements - using xrange instead of range and slicing where appropriate - and improved the performance by about 10%, and the original author has merged my contribution in. I still feel, however, that a quality Python implementation of this algorithm could be both more beautiful and likely faster. I suppose the challenge is to achieve this using vanilla Python without requiring external dependencies such as Numpy. Any takers?
I hear they're working on it.
What kind of performance does gevent have with PyPy? Can it make use of the JIT?
That's interesting. I thought go could not be used for python extensions because go needs runtime support (for the GC, etc...). I have 0 knowledge of go, does anybody understand how this works ?
There haven't added any features added to 2.7 since it was released and there won't be. There are only bug fixes, the linked page is a list of features added in 2.7.0 in 2010.
They aren't backporting *any* features, 2.7 has been frozen since 2010.
And that has been part of 2.7 since 2010. There haven't been any features added since.
The nested for loops are weird, just build the grid with a list comprehension. [[x, y, z] for x in xrange(9) for y in xrange(9) for z in xrange(9)]
That looks like an incredibly cool project.
For one example, 2.7.x is still used by Ubuntu 10.04 LTS (which goes [EOL in 2015](https://wiki.ubuntu.com/LTS)). Anyone can use whatever python version they like for their projects with a virtualenv, but things like package and system scripts should probably rely on the system install of Python.
tnx
Also, `int` in Py2k goes up to `sys.maxint`, but over that, it’s automatically converted to `long`. In Py3k, `int` and `long` are merged to one `int` type. It can bite you when you try to do `isinstance(number, int)`.
No 64-bit Windows builds?
I find it rather silly to use Python 2 explicitly because of a slight change to the way `print` works. That's like telling people you prefer to use Windows XP because you prefer the start button to have the text "start" on it. That's not to say there aren't reasons to use Python 2, but tutorials like this which tell people to use Python 2 for trivial reasons aren't helping the Python 3 situation.
Well, Python 2.6 packages exist out there for CentOS 5 (I know, because I've had to make use of them; look at [EPEL](http://fedoraproject.org/wiki/EPEL)); Pre-compiled releases of Python 2.7 might be unrealistic for such an old system. If you're supporting distributions that are that crusty, you are almost certainly depending on third-party packages anyway, so your best bet is to compile and distribute your own releases of whatever Python dependencies it is you need, and host them internally from a central repository. That way, you can configure your server templates' package managers to point to the central repository then `yum/apt-get install python27 py27-extradeps` and bob's your uncle. As for hosting Django/other wsgi apps, you can compile and release your own python27 release of mod_wsgi—or you can avoid that requirement altogether by deploying your application using a purpose-built wsgi server like uWSGI; There are zc.buildout recipes out there for rolling out uwsgi easily, and you can roll out nginx as a front end using the `zc.recipe.cmmi` and `collective.recipe.template` recipes to powerful effect.
I posted this article on the pypy-dev and the first answer was: "*The biggest problem with this benchmark is that it uses nested lists (read: memory indirections), whereas the other implementations (or at least the C one) uses flat storage.*" (Alex Gaynor). Maybe it's worth a shot to implement it w/o nested arrays and with pythonic iterations through arrays.
Thanks a lot, I didn't see my print inconsistencies at all. Also as I am still learning Python, it blows my mind that this "[a * scalar for a in u]" is possible. I will add list comprehensions to my post very soon. You are right, my code was overkill then, thanks again!
The print thing was just a minor reason, the main reason was that map, filter, etc. seemed to be much easier in Python 2. I might just be missing something, but chances are high that other Python learners had problems with that too, hence Python 2 for simplicity.
Yup I wrote the proper reason in the Tutorial now, thanks for reminding me. I read it everywhere that people prefer 3 over 2, I just wasn't convinced yet as the first thing I ever did was looking at map/filter/... and finding out that this was easier in 2. Maybe just good/bad luck though, will see in bigger Python projects.
&gt; Windows 64 work is still stalling, we would welcome a volunteer to handle that. 
That just isn't the case with gccgo: http://gopy.qur.me/extensions/examples.html
Unfortunately, no video. Only slides.
Out of curiosity, how many of these things can be imported from \_\_future\_\_? Just `print_function`?
No, you can import a few things from python 3: * print_function * division * absolute_import * unicode_literals but division and print_function are probably the only ones you really need.
Python is just fine to use in a distributed system. Unless you go with something like Erlang, which has distribution baked into the language, the bigger question is which tool/broker you are going to go with. For instance, Java the language isn't any more distributed than Python. Java has JMS, but it also has RabbitMQ and a ton of other frameworks. Python can also plug into RabbitMQ, and is what I'm most experienced with. I like not having a giant blob of Java or Python in a single project, so I can chop up my application into little bits that listen and publish.
late on this thread but this was a good suggestion I had not come across before. I really like Codenvy but it has some huge flaws such as some keys just not working on a chromebook, like the "." (period) or the "" (single or double quotation marks). I keep notifying them since months passed and nothing has been fixed. Sad to see a lack of a response from devs on their end. 
Missed that, thanks. Can someone explain why this is non-trivial in the case of PyPy?
Whoops, didn't see your division bulletpoint. It does seem like a lot, if not all, of the minute details can be fixed programmatically, probably with lib3to2 or something.
What exactly is the status of gevent compatibility? Is there a tutorial or set of instructions to get them working together?
concurrent.futures is available in pypi for 2.7
It's really hard to say something concrete here. 1. You can write code in declarative style with iterators/generator (the main idea of this presentation) without dealing a lot with mutable data (and assignments in general). 2. It's not so hard to implement immutable data structures and use it in code. The same approach is used in ClojureScript to work with immutable data within JavaScript runtime.
I would imagine that the lack of tail-call optimization puts a severe clamp on going too far off the paved surface that's provided (i.e. comprehensions, map, filter, itertools, functools, etc.) 
1. sequence-based semantic doesn't rely to tail-call, each recursion can be implemented with fold/unfold 2. one can use different approaches to deal with tail calls - http://goo.gl/fJLV6
I've been planning to write a Python C extension; does anyone know if there's an example or documentation for writing &amp; distributing one that works with CPython and PyPy both? It seems like cffi would be the way to go, but it's not clear to me what dependencies cffi would require end-users to have (especially on Windows), or how that would all hook into distutils.
Specifically, on Windows 64-bit `sizeof(long) != sizeof(void *)`
That's certainly true, but I was thinking slightly lower level. It's a completely different calling convention, and the rules are all different -- which registers are used to pass parameters of various types, which are scratch, which must be preserved, how return values are handled, the requirement of [shadow space on the stack](http://www.reddit.com/r/C_Programming/comments/1br0ri/the_reasons_why_64bit_programs_require_more_stack/) (even if it's not used), and so on.
There are different scoping rules in python 3. List comprehensions in python 2 overwrite variables in the scope. Also range() isn't a generator in python 3, it's a generator-like range object, which has advantages such as constant time checking if it contains an int (e.g. 5 in range(6, 10**10)) Also, set literals and set comprehensions
I'll ask you the same thing I asked the person who said what you said on hacker news. don't want to kick someone when their obviously down. But, are you losing $$ because of pypy's lack of support for python 3? Or is this a case of wanting to be "one of the cool kids" using the latest stuff? I only ask because I have yet to get an answer as to how the lack of python 3 support for &lt;my pet framework/tech&gt; is hurting anyone at this moment. FTR, I'm anticipating the gil-less implementation to see how that performs more so than language syntax updates. But I'm happily getting work done with python 2.7.3 in the meantime.
nope, i find python3 makes de/encoding much better to understand and if you do stuff wrong in that respect, it fails earlier and doesn’t just limp along while only ascii happens to flow through your faulty pipeline, breaking horribly as soon as a non-ascii-character appears anywhere. 
Here's the relevant [github issue](https://github.com/surfly/gevent/issues/38), and a relevant [mailing list post](https://groups.google.com/forum/?fromgroups=#!searchin/gevent/fantix/gevent/jiTkvDRGxhk/gBKyjqJYL1oJ). TL;DR: There is a working [gevent py3k fork](https://github.com/fantix/gevent), it's supported 2.7 and 3k from a single codebase for at least 4 months and it hasn't been upstreamed yet becasue afaik, the main devs have other things they want to nail down first.
If they stabilized the C API throughout all of python 3, why does every python3 extension library still distribute version specific binaries? For example pywin32: http://sourceforge.net/projects/pywin32/files/pywin32/Build%20218/ 
I've also found issues and mailing list posts concerning Py3k, but nothing close to being recent. For example, the latest reply in your mailing list link is from November and the forked repo you posted hasn't been updated in 3 months. I don't mean to sound impatient or entitled. I know the devs are busy and have other stuff on the roadmap. With all the /r/python posts about Py3k lately, I made this thread to hopefully do some communicating with other Gevent users to get their take on it.
In that mailing list thread they mention that py3k support will probably be added after gevent 1.0 is released, so that's the when. I assume there's been no more posts about the subject because it's on hold until gevent 1.0 is released. In the mean time, I've been using the fork quite happily with python 3.3 for a couple of months and havn't experienced any issues. The answer to your thread title is: If you're willing to use the fork that will eventually be upstreamed, now. If you only want to use the officially released version, after gevent 1.0 is released.
&gt;I've been using the fork quite happily with python 3.3 for a couple of months and havn't experienced any issues. That's good to know. I'll definitely check out the fork. Were you able to install and use it via pip install?
You'll need to clone and build the repo. git clone https://github.com/fantix/gevent.git cd gevent/ python setup.py install For anyone curious and reading this thread. edit: pip may has support for vcs, you might be able to use pip install -e https://github.com/surfly/gevent.git However I can't try it from my phone.
Is there a TL;DW for this?
Ask the extension author?
It will get bug fixes but at some point it won't be supported.
Every second spend on 2.x is a second robbed from the future of python. 
Are you referring to the stable ABI? In that case, extension module have to enable it with the Py_LIMITED_API macro and are then restricted to a subset of Python's C API. http://www.python.org/dev/peps/pep-0384/
Yes, Python 3 is better and everyone should use it if possible. But should you learn it first if you bought a book that uses 2 and you like the book so far? Should you never, ever learn 2? No, that's crazy. Use 3 when you can, but learn 2 or 3 in whatever order is easiest. 
By getting library developers to do things early, and not destroy the Unicode system without a viable replacement.
2.7 is worse and I believe worse is better. Why break everything that works at once? Python3 should have worked if it didn't go too far in one step.
Yes, but. In principle I'd be the first to jump on the Python 3 train. In practice, they seem to layering minor and questionable features on, and not bothering to fix the warts that they should have addressed during the compatibility break (2 to 3). So far, it's bigger, but not particularly compelling compared to 2.7. (Actually, bigger is a minus, in my book.)
They didn't have any worthwhile changes worth breaking things over. Was fucking up division and making print a function worth it? "Trust me it's better" is no justification.
Not really useful with regard to his question. Of course 2.7 is fine, but the reality is that its depreciated and eventually it won't be fine.
Upvote for you, for FPS vs. SPF. You are truly a man of the times.
I don't see a worthwhile replacement on the horizon.
Well, Dart/Lua/Javascript all use nested arrays. In C, using allocated pointers instead of flat storage reduces the speed by 15%. I doubt using flat storage in python will make much difference. I have changed to array iterations in the bottleneck. That does help. Thanks.
In Joe Biden's debate with Paul Ryan, he explained that the U.S. needed to set a firm withdrawal deadline from Afghanistan because if we didn't, the Afghans would never step up because they'd know we'd just keep doing the work forever. I think the same mistake is being made with Python. I've even heard people say "Python 2 will be supported forever". Without a firm deadline for when support will end, a lot of libraries and individual developers simply haven't been inclined to bother doing the work that was needed to be done to make the transition. Products like Qt also have periodic breaking versions, but the previous versions have a shelf life just like every other version so you don't see the community as intent on hanging on as we see with python. The other problem was the backporting of features. Someone replied here that they don't see the compelling reason for 3.3 vs. 2.7. If there hadn't been feature backporting, perhaps they might. 
The cool thing about supersets is you can shift to them without breaking anything.
I have made it look better, but weird or not, that part takes &lt;0.01% of time.
Not sure how hard it is, but it says: &gt; stackless support - eventlet just works and gevent requires pypycore and pypy-hacks branch of gevent (which mostly disables cython-based modules)
The video title. I guess. I assume you want bulletpoints, but I also did not watch. Ain't nobody got time for dat.
Non-ascii identifiers is evil.
From what I can tell, python 3.4 will make gevent obsolete. https://www.dropbox.com/s/xknbe58zcvjhzhv/PyCon2013.pptx http://www.youtube.com/watch?v=sOQLVm0-8Yg 
I think py3k is gonna to unify async syntax with pep-3156 http://code.google.com/p/tulip and Gevent won't be pep-1356 compatible anytime soon.
You probably used map/filter in a REPL, and the Python 3 versions return iterators, so you get something like &lt;object 'map' at 0xDEADBEEF&gt; and not the actual result. However, those objects are actually a great thing, because your functions are not run until you actually need the result. Let's say you do `result = map(slow_fn, range(9000))`. In Python 2, the function will run 9000 times immediately. In Python 3, it will run as needed, so if you only take one item with `next(result)`, the function will only run once. To get the Python 2 behavior, just wrap map/filter/zip etc. in `list` calls, e.g. `list(map(slow_fan, range(9000)))`.
The entire point of Python 3 was to break as much as possible, all at once (mainly to fix some of the legacy cruft of early Pythons without forcing new backward-incompatible changes with every new version). 2.7 is for the "give me some new features, but don't break my shit" crowd.
Destroy the Unicode system? I was under the impression that the only changes were that Unicode is now default.
 pip install -e git+https://github.com/surfly/gevent.git#egg=gevent http://www.pip-installer.org/en/latest/usage.html#pip-install (example #5)
&gt; and it is faster at a bunch of things And slower at a bunch of others. Selection bias :)
[PEP 3156: Asynchronous IO Support Rebooted](http://www.python.org/dev/peps/pep-3156/)
Thanks! That was very helpful :)
Google what's new in python 3. There are many articles on the net talking about why python 3 is better. I think the point of this video is that if you watch the whole thing you might be more convinced about moving to python 3 than if you just glance over a bullet list in 10 seconds.
The slides are very ... stingy * Need actual talk. \* Mostly headlines, not actual content
http://jsfiddle.net/K3HPc/
so can someone tell me how to correctly interface with mysql, please? :)
I've staid away because of numpy/scipy. But apparently they work now? What great packages doesn't work in 3?
This was your talk, no? Why not do something like [what Scott Chacon did](http://vimeo.com/14629850): redeliver the presentation as a screencast? I took a grad-level programming languages course last semester, so I'm familiar with the difference between Turing-machine-style and λ-calculus-style programming, but I still found your slides a bit difficult to understand on their own.
Examples?
&gt; I want a smaller, stable language. Check out Scheme; it sounds closer what you want than Python could ever be.
I'll write a blog post describing what's there and what needs to be done. stay calm
the calling convention is an issue for the JIT too
Do i see that right? Mutable closures? Is that a good thing? Not that I use them often...
I love Python's iterators, but this is the first time I've tried to learn about 'send', so I'm very interested to see where part 2 goes with it. Amusingly, send gives Python another tool for solving Paul Graham's [accumulator problem](http://www.paulgraham.com/accgen.html) (though the nonlocal keyword is clearly the way to do it in Python 3). This generator expression gets most of the way there: def acc_gen(n): while True: n += (yield n) Just wrap it up as a callable function-- def accumulator(n): a = acc_gen(n); a.send(None) return lambda x: a.send(x) And give it a few tests: &gt;&gt;&gt; a = accumulator(10) &gt;&gt;&gt; a(0) 10 &gt;&gt;&gt; a(5) 15 &gt;&gt;&gt; a(5) 20 &gt;&gt;&gt; a(50) 70 &gt;&gt;&gt; a(-69.5) 0.5 
Tulip defines a few things, the event loop among them, so Gevent could actually use Tulip as it's core instead of libev and keep using libev on Python 2.
Actually I'm working on 2 separated articles: 1) producer/consumer approach, 2) fold/unfold operations vs. recursion. But it will take some time before I finish. 
&gt; return lambda x: a.send(x) could be turned into return a.send it will work exactly the same since you will just pass the parameter directly to send :)
&gt; Python 2.6 packages exist out there for CentOS 5 I can only shake my head in dismay, and say you sadly over-estimate how "new" some of these legacy systems might be, still. But, yeah... In any case, I'll have to dive a bit deeper in to the co-existence idea. Thanks!
There's also the cython-based Ignafuga game engine which IMO look very promising though very new. Cocos2D i found to be over-engineered and insufficiently documented/maintained. I would recommend writing python3 code that's backwards compatible with python2, that way when you dependancies support python3 you're ready to go. Mostly it's just a question of import from __future__ absolute_import, print_function, unicode_literals In some places you might want to use the six library for compat. I personally believe in really pushing python3 support so we can forget these version change issues. Although i have something of a vested interest since i deal with a lot of inputs with complex non-english characters and python3 with its all-unicode approach is a godsend. Incidentally, You seriously don't realize how english-centric IT stuff is until you start processing things with accents and other characters and have nearly every "industry standard" program mess it up for you. Final note on python game dev - i tried and gave up because of performance. It's not that you can't get good performance out of python, its just that to do some means optimizing and using all sorts of tricks, which is unnecessary mental overhead when all you want to do is knock out a quick prototype. You should be able to make a quick inefficient prototype and optimize later if you want, with python you kinda have to be optimizing from the start. I would personally recommend LibGDX for it's large community support and decent speed, and if you learnt the basics of programming Java shouldn't be too hard to pick up - though i personally dislike it, in the end the best language is the one that gets the job done.
The original author (Denis Bilenko) just doesn't seem to see python3k as a high priority at the moment, until possibly someone else comes up with an absolutely pristine and fully-tested fork that he can merge without having to do much work. He's pretty happy supporting python 2 users. I also know that if it *does* get python 3 compatibility, people *will* expect it to work perfectly, despite that being a very hard thing to achieve (yay self-entitlement for free stuff), so I don't envy his position in what he works on / accepts / etc, that's a hard job. Also, despite its great usefulness and wide use, gevent hasn't been the most active project out there. Given it helps solve a very hard problem to code for (concurrency, and also working with python's internal execution to do so...) there's also far less people around that are able to help with the guts of it.
Minesh and I taught Applied Parallel Computing at PyCon a few weeks ago (covering list-of-tasks using multiprocessing, parallelpython and redis on a CPU-bound problem, then map/reduce for tweet analysis, then problem formulation using random and grid search). Maybe the slides and videos help? http://ianozsvald.com/2013/04/02/applied-parallel-computing-pycon-2013-tutorial-slides-and-code/ This is the 4th time I've covered an angle on this subject, the previous PyCon, EuroSciPy and EuroPython talks (videos, src, pdfs) are on my blog. I've covered from the lowest level (compiling to C, pyCUDA), profiling, multi-core, multi-machine through to several parallel paradigms. Can you explain what sort of problem you're trying to solve? CPU bound (e.g. Mandelbrot)? I/O bound (e.g. web-scraping)? CPU-bound with data sharing (e.g. fluid dynamic simulations)? Message brokering (as noted by many others) for e.g. ecommerce/bank trade reconcilliation? One point I made at the parallel panel session at PyData was that speed-of-discovery (human time) often beats execution time during research tasks. Python has lots of easily-implementable approaches for parallelising your task and lots of libraries to make everything else (e.g. plumbing, data munging, visualisation, storage) easy. If you haven't looked at the videos from PyCon and PyData, look at pyvideos.org. Distributed profiling is harder, distributed debugging is often a pain. Keep it simple, consider that CPUs are cheaper to add once you're ready to scale up than human hours.
Are these your notes from codecademy, they look awfully similar to the notes I take there :P Anyways, good job!
I agree...I just hope that the upcoming async features in Python 3.4+ will make this easier for everyone involved.
Eh. Python standard lib logging module is an abomination. It does not compose well, it uses hacks (like sys._getframe) that make it work painfully slow on pypy, etc.
I'm now somewhat more educated than I was 2 hours ago. (I say 2 hours 'cause I had the tab opened but got distracted for a while...)
 logger.error('Failed to open file') logger.exception(e) That is nonsensical. `logger.exception(msg)` is literally a shortcut to `logger.error(msg, exc_info=True)`. The only result of doing this is that `str(e)` will be used as the message of the second log, so the exception message will be duplicated. &gt; Use YAML logging configuration Use the JSON configuration, it's equivalent and you don't need to install a yaml package.
Instead of making unhelpful, value-free comments about abominations, how about if you suggest a better, "non-hacky" approach to getting caller information into the log? I'll certainly look at incorporating such an approach into the logging package. While it might not help for 2.7, presumably PyPy will support 3.x in due course, so it will be useful at some point.
i take bashings and other kind gestures ;) if someone can make this waaay smaller (and robuster), then i'd love to see :cheers:
Great post, as an intermediate Python programmer coming from C++ I love seeing new ways of doing things. Just curious, is the first get_primes() function missing a return statement? def get_primes(input_list): result_list = list() for element in input_list: if is_prime(element): result_list.append() return result_list &lt;- Should this be added? If not, maybe there is something there that you can enlighten me on Python functionality. Thanks again for a great post!
+1
You're entirely correct: it's missing a return statement.
maybe not smaller but more generic :) : * https://gist.github.com/onjin/5336618
I can't remember him specifying that it was slower at a bunch of things. Just that the universal unicode had slowed several things down enough to make the speed the same on average.
since they seem optional, or rather needs to be done explicitly, it's probably a good thing.
* You are going to need a learn a ton of things quickly as a software engineer. To tackle that: http://www.amazon.com/Pragmatic-Thinking-Learning-Refactor-Programmers/dp/1934356050/ref=sr_1_1?ie=UTF8&amp;qid=1365427426&amp;sr=8-1&amp;keywords=pragmatic+thinking+and+learning * What makes you good at python will make you good at language X at least 80% of the time: http://www.amazon.com/The-Pragmatic-Programmer-Journeyman-Master/dp/020161622X/ref=sr_1_1?ie=UTF8&amp;qid=1365427478&amp;sr=8-1&amp;keywords=pragmatic+programmer Learn the lessons from those two books, continue to craft a few projects on your own, and constantly try to keep your code in a state of order and you'll be worth your weight in bitcoins in no time.
I love generators, but I keep returning to using an iterator class due to two things: 1. Generators are instantiated on definition, so you need to jump through some hoops to have multiple instances of the same generator code. (Though this is usually as simple as using a generator factory function.) 2. Can't serialize them. They'd kick ass for long-term state machines if you could pickle them or otherwise save state. 
How about the windows xp! 
What specific syntax?
yield from, the various meanings of 'as'
Personally I'm ready to kill for anonymous functions in Python. Where are my anonymous functions?
Still no.
No problem, glad I could help!
Well he said that they re-implemented a bunch of features in C to make them faster. It seemed like improving efficiency was one of their priorities.
Then I must be doing something wrong, because Python 3.3 definitely performs slower than Python 2.7 overall.
No, it will not. I bet you that gevent will stay the state of the art.
Very informative presentation. Thanks for sharing this.
You need demonstrable evidence that you have been using python for some time. Start with a github account. Find a project on odesk. Write some code
&gt; Generators are instantiated on definition, so you need to jump through some hoops to have multiple instances of the same generator code. You have to call the generator to instantiate it. You can do this as many times as you want to get multiple instances.
Thank you, I'll look into getting those! 
I do have a github account, but what is odesk? 
JSON example is also added
Check out the online education out there, like coursera and udacity, and for practicing your algorithm and math skills, try your hand at some project euler problems. If you get stuck, head on over to /r/learnpython for some help, just make sure to post your work so far (links to gists and pastebin are encouraged).
Please note that fijal is a pypy core dev, so he's probably talking from experience (though I'd have enjoyed at least a link to an expository analysis of `logging`'s issues especially as pertains to pypy) (in fact that could be neat, pages of packages known to have issues with pypy, an analysis of their problematic patterns and maybe solutions/more compatible packages)
&gt; You have to call the generator to instantiate it. Oooooh. You have no idea how many years I had this wrong. Thank you. ...Please tell me you can pickle them! 
I'm well aware of who he is, which is why I asked him for a better approach (which presumably would be more PyPy-friendly). If he (or someone else) can't suggest a better approach, then there's less justification for complaining about `logging` for just doing what it can :-)
You don't (and shouldn't) have development headers for anything on your production servers. Build your virtualenv on a staging server, and create a package of it that you can then distribute out to your production servers. We build .deb (debian) packages and add them to a custom apt repository, and our production servers simply require an `apt-get` for updates to the application. 
Whenever possible (ie, anything but binary), I use a vendor library embedded into the repository (http://fredericiana.com/2011/09/23/mozilla-pypi-and-the-vendor-library/). For binary dependencies (eg, mysqldb) I install them into the system Python, usually through the package manager (using custom built packages if needed).
I wouldn't say that that is 100% true. Google makes it so that you don't have to memorize every little nuance, or spend hours tackling an error that someone else has already resolved. Really though, google is making everyone lazy (including myself). I'm not sure how i'd function without it any more... and I find that sad 
What's the benefit of using virtualenv in production?
https://launchpad.net/oursql/py3k
Smaller surface by only having the package you *need* present in the installation, simpler reproducible environment, simpler switchability and rollback (for new deployment, create new independent virtualenv and switch server to it, this includes deploying a new version of a dependency)
it’s simply a indented line with no content. that’s leading whitespace, not trailing whitespace. many editors fail to recognize it as that, and simply remove anything they, in their dumbness, recognize as “trailing whitespace”. since i prefer to have empty lines indented, and to have consistent indentation (with tabs), i simply let my editor highlight all whitespace. afaik no code of mine has any trailing whitespace whatsoever.
I have a similar issue with pip and internet access, policy doesn't allow internet access on production servers. If you don't mind me asking, How did you build a local pypi mirror?
I've actually completed that minus a problem I have with one of the class sections, but thank you. It really did help my understanding. 
Bing?
Been waiting for a new post from you Jeff, awesome!
How can I gain the knowledge necessary to follow this conversation? Coursework? Books?
1) Realize that production servers for many big companies are not allowed to talk to the internet. 2) Read: https://pypi.python.org/pypi/pip 3) Read: https://pypi.python.org/pypi/virtualenv Basically the concept is that for many python services, you install a set of packages needed to run them using pip/virtualenv. That usually requires internet access, but that's not allowed. So the question is: now what? You can either fake it by having a fake copy of the websites pip will use to pull packages (a local repository), or you can pre-prepare the virtualenv on another server and move it to production after the fact (using normal code deployment - rpms or other repositories where you check code out). 
well, seriously, no. logging module is in python standard library and the majority of our users are using Python 2 (in fact all of them), not only because we don't support python 3 yet. We can obviously patch the logging module ourselves, but for now I'll stick with "don't use logging, ever" as a recommendation. No, there is no better way to get a caller. Maybe logging shouldn't need the caller by default, which is also not easy to disable.
For me, the main one is being able to run different versions of the same dependency for different programs.
thanks. I'll have a go using it tomorrow =)
I am using pypimirror script from here: https://pypi.python.org/pypi/z3c.pypimirror. There are many tutorials for it on google but the config file is quiet self explanatory. But a cooler approach to setting it up is over here: http://bluedynamics.com/articles/jens/setup-z3c.pypimirror which I think I will use to redo my setup. 
I often thought i should do this. Thanks.
If you can learn to generate and use OS specific packages. We use RPM for RHEL and CentOS systems because those are the only one we use. This way you get full transaction file system update/remove/add. Can roll back. RPMs can have pre/post/install/uninstall script to run any setup commands. They make it easy to install other files not just Python -- java, .so libraries. Dependencies are sanely resolved. There is a -dev version of the main production package. That basically turns the production box into a dev box. It bring in git, gcc etc. You'll pay the price initially by developing this way but if you plan on growing you'll be glad you did it later.
Since Django and Pillow recently added compatibility, most of the main bases are now covered. Twisted is probably the biggest thing that you can't easily find an alternative for, and I've heard that there's work being done to port it.
Yes I am fully able to create RPMS. I have just tried to basically get the whole virtualenv directory and packaged it as an rpm. It deploys just fine in the target machine but it seems I am having dependency problems. I am not sure if the find-requires which is ran by rpmbuild is actually finding and automagically adding the rpm dependencies for the binary stuff inside the virtualenv. 
https://python-guide.readthedocs.org/en/latest/
&gt; Maybe logging shouldn't need the caller by default, which is also not easy to disable. Call location information is the kind of thing people want to know - including new users, who may not be familiar with details - so it shouldn't *not* be the default just because its approach causes PyPy problems - besides, that `findCaller` code has been there since ~ 2002 which is AFAIK before PyPy. To disable caller information in logging is pretty easy, just do logging._srcFile = None ~~It's not documented~~, but hardly difficult to spot from a quick glance at the source code (as there is a comment in the source about it). So, your recommendation that people "don't use logging, ever" seems to be for a different reason - care to elaborate? Are there other reasons why `logging` and PyPy don't work well together? Edit: I forgot, it [is documented](http://docs.python.org/2/howto/logging.html#optimization).
We run a cheeseshop instance and upload our sdist-built packages to it; we also use Spacewalk to deploy RPM packages when needed.
The mirror is in a vlan that can be allowed to go out to the internet when requested, so nope, no proxy in the way during mirroring.
I got it working on OS X. There's some things to note though: * I believe you need to use the tarball of this 3.x branch, the trunk doesn't work. This means you can't pip install it. * It failed with a compiler error at first. I had to install ctypes and delete a .c file from a directory so that it would be regenerated by cytpes. Good luck!
Dependency tracking it not always easy. You basically have to know what you packages need. I always added them by hand, the good thing is you do it one at a time for each package then they transitively resolve. Like say load audio and you have an ctypes interface libsndfile. In your rpm dependency you need to say that it depends on libsndfile-devel. If you use virtualenv, you can have one big package for your product that contains the virtualenv puts in /opt/&lt;myproduct&gt; or somethign like that. Or break it into subpackages that all go into /opt/&lt;myproduct&gt;/ but on is common,base,python etc. As a trick, it turns out python distiutils (the crusty old one) builds RPMs for you! That is the python setup.py bdist_rpm feature. That is what I use. you can specify RPM dependencies in setup.cfg, data files go into data_files=[...] directive in setup.py, can have pre/post scripts. One odd thing is you still need to include data files in the MANIFEST.in file. After that it build the packages for you. Anyway there are probably easier ways. Can of course write spec files by hand too. Yeah it is more work initially but it makes sense for large deployments. 
1. This belongs to /r/learnpython 2. PDF in python is hard (Look at pypdf(2?) or reportlab 3. Maybe this is a stupid idea, but I would convert the pdf file to html, surround the keyword with a span tag containing some 'css highlight style' and back to pdf
Can't you specify the port in [FTP.connect](http://docs.python.org/2/library/ftplib.html#ftplib.FTP.connect)?
Nope, sorry. You'll need to write it as a class if you need to pickle it. The trouble is, a "live" generator can have so much state (open files, network connections, etc.) that it basically requires custom code to save it and restore it correctly.
thanks for the heads up =)
Frankly, most of the knowledge for this kind of thing is learned in the trenches from people that have enough experience that they've done it (and fucked it up a few times) before. In a lot of ways, web application development is quite well served by an old-school master/apprentice model. I've been doing application development work for nearly a decade, studied some computer science (among other things) in school, but I still learn things every day from people I respect and admire in the industry, and who take time out of their busy days to write or explain about a topic that they find simple and benign, but that I (and others) know almost nothing about. To answer your question a bit more directly: Do it! Try writing and deploying projects yourself. You'll realize that there are things that work, and things that don't. For the things that don't work, most of the time someone else has thought of a solution and has written a blog post about it. Sorry for the wall of text :).
1. Sorry I'm a newcomer here. My bad. 2. Will see those. (I've already skimmed pypdf though.) 3. It is out of option because my PDF is a scanned newspaper full of images and stuff, so I cannot just render using text only. 
Sometimes you have servers that are given multiple roles, for whatever reason. Simple example: a QA server that acts as your database role, your application role, and your async broker/worker role. It could be that some of these roles contain non-compatible versions of the same python packages, and thus virtualenvs are not only nice to have, they're *required* for things to work. 
Yes I can, but it isn't an FTP connection it is FTPS (and not SFTP). I have to connect using FTP_TLS from the ftplib, which doesn't allow you to specify another port and when I try using FTP.connect it doesn't work. It's a configuration setup on the client's end and I'm just trying to deal with whatever crappy config their server admin decided on. I came across [this on SO](http://stackoverflow.com/questions/12164470/python-ftp-tls-connection-issue#12469821) which I'm going to try out shortly. Hopefully it works. 
For Debian at least, you can specify dependencies when you create the package, but there's no easy way I know of to automatically discover dependencies. This would require some relatively complex introspection into the `setup.py` files of the packages in question to extract out the binary dependencies that need to be built, and then convert these to their equivalent in Debian/RHEL-land.
For me it is the ability to isolate the app and it's dependancies from other applications as well as the OS. Few things make less sense to me than being able to update a package simply because you are waiting on the OS vendor to repackage it. 
Yeps, I am taking advantage of that in my a few hours old project, virtualenv2rpm packageer. What you describe for rpm is mentioned here: http://www.rpm.org/max-rpm/s1-rpm-depend-auto-depend.html. I am just wondering why googling around, I could not find similar projects. 
http://learnpythonthehardway.org
Thanks for pointing this out. It cleans up the second function definition nicely.
&gt; [ok I solved this part with a pypi local mirror] Can this be done using something like Hudson or Jenkins, where you set up the virtualenv completely outside and then deploy it out to the Q/A, staging, and prod systems? 
A former coworker recently outlined his journey learning python [here](http://pynash.org/2013/03/25/how-i-got-start-with-python.html)
Why doesn't a class have the same issue?
I used to build them manually, but I've been using [FPM](https://github.com/jordansissel/fpm) for some time now, and it's awesome. It basically takes ~90% of the boilerplate generation away, and even has some facilities for specifically building .deb packages from pypi. I've used it to create custom packages for nearly everything; from node.js to python to ElasticSearch and back again.
Ah, very nice. Using `ldd` is the obvious choice to determine the shared lib dependencies for binaries. You might be interested in [FPM](https://github.com/jordansissel/fpm/wiki/ConvertingPython), which can let you do some relatively fancy stuff for creating packages. I use it quite often, and it's a solid tool.
A cheat sheet always helps, thanks!
I've been trying to remember this project for months... thank's for the quick response. 
With a class, you can write `__getstate__()` and `__setstate__()` methods to handle that, and `pickle` will call them when saving or restoring your instance. You can't do that with a generator, sadly.
Please don't use URL shorteners, they trigger the spam filter!
Take a look http://pdfbox.apache.org/userguide/highlighting.html maybe you can get some ideas from there. If you can constrain your users to use pdf readers that support highlighting then it's very easy.
Environment consistency. If there is an update to an OS package, that breaks the version of a library you're using, or conversely, you want to use a newer version than the system packaged version, virtualenvs allow you to just roll with it. Basically you're keeping your deployment isolated from external issues.
&gt;I would like to have a computer running it and be able to log in over the internet you can do this securely with ssh. log in to your computer running the code. change a text file, and have the program use the new data. 
In the future, please post questions like this to /r/learnpython. Thanks.
&gt; You don't (and shouldn't) have development headers for anything on your production servers. Why not? If someone's got access to even the most limited of accounts, surely they can pretty easily bootstrap what is needed given curl/wget/nc/perl and tar?
It can. After running test suite(s), a build script (e.g. tox and/or buildout) can produce 'build artifacts' which can be * eggs * bundles * **wheels** * OS packages like DEB and RPM * archives of platform-specific virtualenvs A configuration management script/system can be then be updated to *pull* the latest version from a package archive/repository. In some environments, it is safer to *pin* specific versions than to always pull the latest version. A manual package signing step can help with this. Fabric is useful for automating scp/rsync *push* deployments and application configuration (e.g. `rm *.pyc`). There is a context manager for sudo in fabric. 1. Build 2. Test 3. Review 4. Sign 5. Deploy: *push* or *pull* 6. Test * https://en.wikipedia.org/wiki/DevOps * https://python-guide.readthedocs.org/en/latest/scenarios/admin.html * https://python-guide.readthedocs.org/en/latest/scenarios/ci.html * https://python-guide.readthedocs.org/en/latest/shipping/packaging.html * https://python-guide.readthedocs.org/en/latest/shipping/freezing.html * http://www.pip-installer.org/en/latest/usage.html#pip-freeze * http://www.pip-installer.org/en/latest/usage.html#pip-wheel * http://guide.python-distribute.org/specification.html#development-releases * [PEP 301: Package Index and Metadata for Distutils](http://www.python.org/dev/peps/pep-0301/) (2002) * [PEP 345: Metadata for Python Software Packages 1.2](http://www.python.org/dev/peps/pep-0345/) (2005) * [PEP 386: Changing the version comparison module in Distutils](http://www.python.org/dev/peps/pep-0386/) (2010) * [PEP 427: The Wheel Binary Package Format 1.0](http://www.python.org/dev/peps/pep-0427) (2012) * [PEP 440: Version Identification and Dependency Specification](http://www.python.org/dev/peps/pep-0440/) (2012) [DRAFT] * [PEP 426: Metadata for Python Software Packages 2.0](http://www.python.org/dev/peps/pep-0426/) (2012) [DRAFT] [compoze](http://pythonhosted.org/compoze/) "provides a set of tools for managing private / project-specific package indexes." 
Couldn't you include the packages in a submodule and git pull? (Assuming you use git)
Thanks, I know that link though. First way doesn't work anymore, and it just highlights using pdf reader. The rest is still TODO, but not very practicable. No, actually the output doesnt matter, it might be even a JPG, but it needs to be highlighted, that's the most difficult part. I'm still thinking of PDF.js might output something. 
you said everythin i was going to say. very nice post.
python has a lot of really great features. right now, packaging and deployment is not one of them.
Thanks
&gt; What would be the difficulty score out of 10? 8 in my humble biased opinion &gt; What libraries/technologies will I need to know? A whole bunch! HTML/Javascript/CSS for a start. Either Flash or some kind of animation technique for HTML5 (I would personally go for HTML5) for your animation needs. Some kind of *real-time* web networking solutions. I like [gevent-socketio](https://github.com/abourget/gevent-socketio) but there is a whole bunch out there. [A proper hosting solution](http://www.webfaction.com/services/hosting?affiliate=delizseemack). Some backend stuff for your application hosting (uWSGI, nginx, etc), application framework (Flask, Django, Bottle, whatever works for you), message queues ([RabbitMQ](http://www.rabbitmq.com/), something else), most likely some database stuff (PostgreSQL, Mariadb, etc). That would a good introduction startup. &gt; Where should I start? Well, you just start :) Doers do, so start right now! Check out tutorials, examples, do your own tests, read the documentation, check out the forums, read the wikis, go on [stackoverflow](http://stackoverflow.com/) if you have a specific question. Here is a small tip for you. Start small. Make some proof of concept for each stuff you need and grow from there. Good luck! EDIT: http://kineticjs.com/ seems like a nice web animation framework. You should check it out and see if it works for you.
I just watched those, I feel they were not that helpful. I already have a degree and a job. I am aware of the need to consider money and communication. I kept hoping they would say something specific on any of their topics. The only website or thing they made a plug for was Stack Exchange which sponsored the video. Maybe it would be useful to kids who aren't yet in highschool? I guess it did tell them to get through algebra...
then again, the Python interpreter is there, and they can pretty much run arbitrary programs with that anyway.
thank you .. that looks very generic and clean too
I use `fpm` to build .debs out of compiled C/C++ all the time. I tried to make a .rpm out of an entire virtualenv directory and it blew up all over me with "Digest Failure" on install. I just deployed via `git clone &amp;&amp; virtualenv &amp;&amp; pip install` for now, but I'd really like to solve this some day!
&gt; I already have a degree and a job. Uhm, cool ... ? Anyway, did you watch the first part? It's about the mindset a developer should have, about how a developer should approach problems. I'd say that actually writing lines of code doesn't even take half of the work time of a developer. Reading documentation, understanding and applying concepts, digging into other people's code bases is what you will do most of the time. And this is what they wanted to tell you in about 7 minutes. In this much time it's not possible to do more than giving you an idea about what it's like to be a developer. Basically those videos gave you a brief overview of what [the books linked](http://www.reddit.com/r/Python/comments/1bwxok/trying_to_become_a_python_programmer/c9aup0f) by /u/thanatosys will probably talk about.
I really don't see why having the compilers on a production machine is such a big deal. If people already have access to your machine such that they can execute the compilers, you're already screwed. If there is no way into your machine except for a very secure SSH, and your app is secure, what are you worried about? If either of those is compromised, you are equally hosed whether or not the compilers are installed. 
It may be a bit early but if you gave some idea of kind of things you foresee yourself programming, then you could probably squeeze even more out of this thread. For example, I use python everyday but pretty much exclusively for web development and as such have never even touched e.g., wxPython, tkinter for GUI type apps, or e.g., NumPy, Matplotlib, for scientific, data type work, etc.
The empty re.split bug, for example. This drives me nuts, and lots of people are tripping over it. It's obviously wrong, but it doesn't look like it will ever be fixed. I simply don't care about Python 3 fluff features, if stuff like this isn't getting fixed. http://bugs.python.org/issue852532 for starters, but mentioned in several other places
I use this every day, and I estimate it answers about 85% of my stupid questions I'd otherwise search for and find on stackoverflow. It's brilliant. 
it's 2013, don't use FTP. use SFTP or HTTPS or HTTP or something
My point was I do know what programming in general involves. No one ever goes into specifics, and neither do the videos. I did watch them both all the way through. I thought I could clarify that I was not a middleschooler trying learn what programming is even about. I am trying to solidify what I would actually need to do to get to the point where I could make money this way.
The docs say FTP\_TLS is a subclass of FTP, so it has .connect from FTP. It looks like [ftplib.FTP_TLS](http://hg.python.org/cpython/file/2.7/Lib/ftplib.py#l599) doesn't really override much of [ftplib.FTP](http://hg.python.org/cpython/file/2.7/Lib/ftplib.py#l77), and especially all the inital connection-related stuff (including which port to use) is handled by the base FTP's connect function, and not overridden by FTP\_TLS. Looks like FTP auto-calls connect if you pass in a hostname to \_\_init__, giving you no chance to pass through a non-default port in its automatic call. But if you don't provide a hostname at initialization you can call connect manually, providing both a hostname *and* a port. So like cournie said, can't you just (untested, because no FTPS available): f = ftplib.FTP_TLS() f.connect(hostname, port) # will use the inherited ftp.FTP.connect f.login(username, password) # will use ftp.FTP_TLS.login EDIT: OTOH, if you need to specify the port because you're trying to connect to an ["implicit" FTPS server](http://en.wikipedia.org/wiki/FTPS#Implicit) on port 990, then you're going to need to do like in your SO answer (creating the ssl socket pre-welcome, according to the SO answer), since ftplib.FTP\_TLS only claims to support RFC4217 FTPS by default (creating and negotiating the ssl socket post-welcome but pre-authentication).
So basically you want to re-invent the wheel rather than stand on the shoulders of giants?
Np, I like the solution for using it as an accumulator, I think its really clean.
&gt; I thought I could clarify that I was not a middleschooler trying learn what programming is even about. Well I did read your original post and I did try to read between the lines too. &gt; I can work with lists and have been by writing small programs and testing different ideas. But this was the only thing telling something about your skill level. And it didn't sound like it was more than what middleschooler knows. Then you asked this: &gt; [...] what are some basic skills [...]? And so I linked the two videos that - in my opinion - give a pretty good answer. Now to actually try to give you an answer on this quesion: &gt; [...] what I would actually need to do to get to the point where I could make money this way. Experience. Choose a field you want to work on. As my flair says, I'm into web development. What are you into? Explore best practices and concepts on this field and try to apply them in one of your own projects. Find open source projects that interest you and try to contribute. And make it visible. Employers most likely want to see that.
did I say that? I don't think I said that.
People I work with use this [vagrant](http://www.vagrantup.com/) From the webpage: Vagrant provides easy to configure, reproducible, and portable work environments built on top of industry-standard technology and controlled by a single consistent workflow to help maximize the productivity and flexibility of you and your team. To achieve its magic, Vagrant stands on the shoulders of giants. Machines are provisioned on top of VirtualBox, VMware, AWS, or any other provider. Then, industry-standard provisioning tools such as shell scripts, Chef, or Puppet, can be used to automatically install and configure software on the machine.
Dream up an idea in a domain you have one foot in and the other out. Design a solution. Refactor. Refactor again. Always search for best practices. KISS (Keep it simple stupid). DRY (Dont Repeat Yourself). DRO (Don't Repeat Others) *unless for learning purposes*.
For your python application servers, and nearly any other application server (ruby, java, etc) that's completely true. Getting into the habit of *not* putting development headers and autotools on servers is still just good practice, however.
Fixed!
How would you do this for example, your virtualenv requires MySQL-python, which when installing in a virtualenv with a command like "pip install MySQL-python" will need gcc and mysql-devel. The problem we are facing here is that we want to be able to recreate/install the virtualenv in a production machine without needing gcc or devel packages on the production machine. I am currently working on a solution that includes buildout, and rpmbuild to create 1 massive rpm that contains the virtualenv. 
Vagrant can help in the creation of the virtualenv since it helps "prototype" your virtualenv but it alone unfortunately solves the problem of being able to deploy virtualenv in production without requiring development tools installed. I am however using vagrant in my workflow now, i create a base rpmbuild machine , and vagrant up an instance of it anytime I want to run by virtualenv to rpm workflow which currently is done using buildout to install/compile and package the virtualenv. I shall continue experementing in that direction today.
could you give some examples or show a screenshot of that working? thx
Mating python and an operating system package system (ports? rpm? apt?) is a perfectly reasonable solution. 
you will need a real time events. so you need a fast transport. this is some kind of websocket or just a tcp. but they are both not very good for a real time gaming. almost all real time games use udp. but in browser this is a difficult - so you can just use a tcp socket from a flash. browser games, especially social games usualy implemented on flash. so at first you will learn some as3. as for server side - it will be not just a broadcasting server. all the logic of damage dealing/health should reside on the server side. movement and etc also should be checked there. client should just send a message to a server - 'i am moving here with such speed'. or 'i am kicking with a some kick type'. and server should process this message and generate other messages. for example 'player x moving there'. 'player x kicked you into face with critical hit : 110 damage' . so for flash part - just use flash/as3. there are almost all that you need in included libraries. for python part - use gevent for networking and green threading. use a sqlalchemy/elixir for your database.
This is really a question, rather than a comment .... Using virtualenv on a production server gives me the willies. The server presents a particular environment via the packages that are installed, then virtualenv provides another. virtualenv isn't a virtual machine, so some elements of the server environment are hidden inside virtual env - for example, virtualenv has a different python version - but other elements are visible. One system I worked on, the target was Debian but most of the developers insisted on developing on their Mac laptops, and virtualenv was used on both the Mac and the Debian machines. I could understand using virtualenv to make the laptops look like the Debian servers (and using a staging/test server), but It seemed to me that that was a disaster waiting to happen, because the overall environment was different. OTOH, lots of people swear by virtualenv. Comments? 
Absolutely!
I'd like to think I do express myself through the quality and functionality of my code, and rather resent the assumption that because I have an unusual take on formatting, that I don't. Anyway, an example. Here is some code from a system I work on. I can't guarantee this is the exact bit of code in question, but the principal is the same. The snippet is from a 320 line module. It retrieves data from a database and manipulates it to get values for a report (one of those nasty things that management seem to love!) There is a bug in it: rec.ytd_ppu_original = ppu(rec.ytd_amt_original, counts.ytd_cnt_original) rec.ytd_ppu_new = ppu(rec.ytd_amt_new, counts.ytd_cnt_new) rec.ytd_ppu_lastdelta = ppu(rec.mtd_amt_lastdelta, counts.ytd_cnt_lastdelta) rec.mtd_pen_original = pen(rec.mtd_cnt_original, counts.mtd_cnt_original) rec.mtd_pen_new = pen(rec.mtd_cnt_new, counts.mtd_cnt_new) rec.mtd_pen_lastdelta = pen(rec.mtd_cnt_lastdelta, counts.mtd_cnt_lastdelta) Can you spot the bug? The code was passed to me to look at, some of the numbers were not coming out right. I twiddled the code a bit: rec.ytd_ppu_original = ppu(rec.ytd_amt_original, counts.ytd_cnt_original ) rec.ytd_ppu_new = ppu(rec.ytd_amt_new, counts.ytd_cnt_new ) rec.ytd_ppu_lastdelta = ppu(rec.mtd_amt_lastdelta, counts.ytd_cnt_lastdelta) rec.mtd_pen_original = pen(rec.mtd_cnt_original, counts.mtd_cnt_original ) rec.mtd_pen_new = pen(rec.mtd_cnt_new, counts.mtd_cnt_new ) rec.mtd_pen_lastdelta = pen(rec.mtd_cnt_mtd_lastdelta, counts.mtd_cnt_lastdelta) The bug is on the third line down, *mtd_amt_lastdelta* should be *ytd_amt_lastdelta*. Once the layout was twiddled, the bug was obvious in less than a second, because I can see the break in the pattern (the *m* instead of a *y*). I'm not saying this is the be-all and end-all of programming, but the system has a lot of code like this (and, yes, I've thought a lot about whether it could be better structured so get rid of this sort of stuff, and, no, I can't see any way).
Wow. I'm honoured!
But does this advice even work now that exploits are written in dynamic languages?
&gt; How can we make python easier to develop and deploy? For me as a Linux-only user, Python web dev is easy peasy lemon squeezy. But I agree, deployment is still not the easiest thing. One thing we can do, is making Python more popular in web dev, so that people ask their hosting providers to support it. **UPDATE** A quick google gave me this: http://wiki.python.org/moin/PythonHosting
Right now I'm thinking very "omakase" vagrant dev environment with very clear best practices. Great support for a couple of web frameworks and the ability to make one touch deploys to a number of platforms, maybe using puppet for server setup and git for app deployment. But uh... I don't really know what I'm talking about so help me out here.
And now the UNIX way of doing it: find $DIRECTORY -type f -iname \*.mkv -or -iname \*.avi -or -iname \*.ogm | sort --random-sort | xargs -L1 -d'\n' vlc You can go ahead and pipe that through head -n $COUNT between sort and xargs if you want.
To be honest I think deployment of web applications should be handled by someone who has good knowledge of the system. This is crucial for security. And if you have good knowledge of say linux administration, you shouldn't have a problem setting up daemons, WSGI, FCGI, reverse proxies and such.
I build one venv per app family. That venv gets all of its libraries installed to it. From there we package it up into an OS package (rpm/deb). Doing it this way eliminates the need for compilers, internet access, or anything except the venv package, and whatever c libs are required for the packages in the app. It works out very nicely. And is extremely simple to automate.
One more thing: you might want to learn a few other languages. not necessarily be an experienced developer in all, but at least know de basic constructs, limitations, and applications of say C, C++, .NET, java, prolog, etc. For one it is useful to be able to read algorithms written in other languages. Also you will see that python allows you to use the paradigms of most other languages, which in turn will help you use the right tool for the job. 
One workaround I've seen is to 'build' on one machine, then zip it up and scp it to the target. I'm curious about how you would intend to handle hotfixes? Would your team really be ok with building and waiting for your packaging and deploy system?
I'm deploying everything with Fabric (for example http://pastie.org/7384604) and Salt
Which GUI toolkit are you using?
If you have a GUI, why are you entering things into the shell? There are widgets for text boxes, you should be entering everything into the GUI itself. If you have outputs that aren't just log messages, add a label and change its text to show whatever you were outputting to the terminal, and if you need lots of text outputted, then use a multi-line text box that can't be edited.
How do you expect people to get such knowledge? I've been making stupid mistakes in deploying PHP sites since I started as a teenager, but 99% of the time they weren't important and the site was only a personal one. I agree with you if OP has been contracted to work for a company, but otherwise "try it and see" binds tighter.
Being picky on a pointless script - But I don't like how you handle file extension filtering by just looking at the end of the file name and not including the period. Otherwise, cool script :) 
It makes no sense to relate your first and last sentence. Linux base operating systems are free and easy to install. Your ability to explore how linux and django/python work are in no way tied to your employment. 
While we use git as a source to deploy from, it's not the singular deployment tool we use. When I started out, I in fact used commit hooks. It's messy. Puppet is a bit overkill. Something you're really only going to want when you're dealing with load balanced web applications. You're far better off using fabric. greatly simplifies anything for which you might be tempted to fire up a remote ssh console.
Just curious...why did you call it web2py? Seems to me that is the opposite of what it does.
Tkinter
First thing, start by using python logging instead of using (what I assume you are) print("log message"). second, specify if you're using pyWX, pyGTK, or pyQT/pySide
there are two hard problems in CS: cache invalidation and naming things.
Under GTK there is the VTE binding, that allows to integrate the Virtual Terminal in your application (that's about integrate shell into GUI). You can then send signals to the shell and see the output.
Happy cake day and enjoy your first pull request :)
Also check out https://code.google.com/p/apsw/
https://github.com/lest/capistrano-deploy While this is a ruby tool, it's extremely useful for any sort of deployment. You type 'cap deploy' and you're done. Honestly though if you don't any linux experience you should learn. Install it on your workstation and learn. Install the same distro you are deploying to. If you need Windows, install a VM. Do NOT do it the other way around (install a linux VM on your windows desktop). The idea is to force yourself to learn, use google, read man pages, etc. The hard thing I think is choosing a distro. Something like arch is probably a bit too much - you will learn a ton, but we do live in the real world where work does need to get done. I would suggest a debian based distro (ubuntu, mint, debian stable) and then intentionally install a different window manager and customize it - it's fun to do, take a look at http://www.reddit.com/r/unixporn/ and try and copy one of those. You will learn quite a bit in the process. Back to your original question, again cap deploy. It's really good. Makefiles are also very good for setting up a dev env. Makefiles aren't just for C :)
I have a related question. I literally just started using the logging module last night, and for some reason I'm not getting any timestamps. I've configured it as follows: import logging import logging.handlers LOG_FILENAME = 'log.log' # does the name below have to correspond to anything in particular? LOGGER = logging.getLogger('LOGGER') LOGGER.setLevel(logging.DEBUG) _handler = logging.handlers.RotatingFileHandler(LOG_FILENAME, maxBytes=5120, backupCount=5) LOGGER.addHandler(_handler) I use the logger as follows: LOGGER.debug('oh noes!') Again, I'm not getting any timestamps with this method, so I'm currently using a decorator to insert a `cTime` string before each log message. It works, but it's hackish. Did I do something silly?
You need to make stuff. Plain and simple. Start a [github](http://www.github.com) page and start showing the world what you're capable of. Start with simple projects and *actually finish them*. As you complete projects, you'll start learning not only how to do certain things, but how to go about learning how to do things you don't know how to do. You need to start banging out some code daily.
&gt;To be honest I think deployment of web applications should be handled by someone who has good knowledge of the system. This is crucial for security. I agree. People should not be reading a 10 page tutorial and then think that they are "good enough" to deploy production applications. End of discussion. However, in the realm of web app development, the counter argument is that one of the big reasons why web app security is still such a major issue is that many of the most popular "Beginner's Tutorials" teach people horrific security coding practices because they are afraid to scare away newbies by introducing them to the secure APIs and methodologies early on. I can't count the number of "Beginner's Blogging Site" tutorials that were rife with LFI/RFI and SQL injection vulns all over the place. Making the basic functionality easier and more intuitive would hopefully allow people to dive into the security aspects a lot quicker and more comfortably than they are able to currently. 
Flask.
Well, the level of "ease" you're facing against with PHP is pretty staggering - you can use GUI apps the whole time, and just drag and drop files using any number of desktop or web ftp clients. Python, atm, just isn't up to that level.
Yes that is all well and good, I use puppet myself, but this still begs the question, how do you get away with not needing compilers and development headers in the target machine? Let's say your virtualenv needs MySQL-python? When you install that inside your virtualenv, it will fail if there is no gcc or no mysql-devel files.
Sure, then work through SICP, TAOCP, and implement a RISC processor in logic gates. But for people who don't want to do a full CS curriculum and just want to get a web app running, the point remains that Python doesn't make it as easy as some eventually-inferior alternatives. There's probably a market for something like a hosted virtualenv that can push Bottle apps with one command. I assume cap isn't suitable for installing packages on the remote server.
I'm curios, but why not Heroku? That and Fabric made my deployment take 2-5 minutes, with a single command: fab deploy. Sure there's a few edge-case bugs, but nothing insurmountable. And I don't have to be a sysadmin. 
A developer can give me a requirements.txt file and from that I can build the same environment that he is using in his development box on my development box without interfering with any other things in my system. 
I had not done any webdev prior to jumping into django. Writing some CGI's helped me immensely to get my head around frameworks, why they were useful and what they were doing under the hood. 
Then I would be willing to bet great sums that what you'd consider 'ease in deploying a web app' would not align at all with what the general population would likely answer. (the general population learning to do such, being the topic of discussion here)
You'd need to set a formatter configured to show timestamps, e.g. formatter = logging.Formatter('%(asctime)s %(message)s') _handler.setFormatter(formatter)
Ahhh okay. Thank you! Would you happen to know of a tutorial that's a bit clearer than the standard documentation? The bit about formatters is very cryptic =/
If you think it's hard then try flask. Flask is easy.
What features of Gevent does tulip currently lack?
Honestly I came up with the name in a hurry and under pressure. My primary concern was to have something not trademarked before and not used on the web. It was supposed to stand for "WEB 2.0 with PYthon".
I disagree. I think building web applications should be considered basic computing literacy. Yes there are security issues but 1) the framework can set constraints 2) people need to learn those issues.
You're just being silly. Learning how to install your env is not asking for much. If you work with linux systems and deploy to them you should be running them on your local machine and know how they work. The same goes for windows. If I deployed to windows servers or did windows application dev, I would run windows. If you can't figure out how to install postgres or mysql then you probably shouldn't be working with it. If you have no interest in learning then you're in the wrong field. Cap can do what ever you want. I however don't consider it to be a big deal to type apt-get install postgres. If I had to deploy to tons of servers I would create a VM base image and write scripts. 
Which standard documentation are you looking at, exactly? I ask because the logging documentation layout was improved in 2.7 / 3.2. If you're just starting out with logging, you should work through [the tutorial](http://docs.python.org/2.7/howto/logging.html#logging-basic-tutorial) which works through the basics: * When to use logging * A simple example * Logging to a file * Logging from multiple modules * Logging variable data * Changing the format of displayed messages * Displaying the date/time in messages (Note that the OP goes through setting formatters in the examples posted.) Another basic resource about logging would be [this post](http://plumberjack.blogspot.co.uk/2009/09/python-logging-101.html).
Not sure why anyone would downvote this, it's an interesting trait that you can presumably strip out stdlib components for embedding.
I agree about the right way to do things, but I also know that there are a million things I can take for granted that a new user is going to get hung up on. It's just not realistic to tell a high school kid to install linux on his household's one computer. Use a VM, your deployment server is likely to be a headless LTS release anyway, not Mint-latest. And this 'everyone should do things the way the graybeards do' approach is what led to the rise of PCs over mainframes, scripting over compiled languages, REST over CORBA, AWS over cages of racks, etc. Don't underestimate the value of a really really trivial first step.
Specifically, here is my problem: http://flask.pocoo.org/docs/deploying/ There is no, 'just run main.py'. I had to create a Linux box from the ground up for development to get it running, but I don't have time to play sysadmin with SSH and terminal connections on with our hosting provider. It's a shame, because I would have really liked to use python, but for now, I'm going to keep uploading my crummy PHP scripts. I have done all other in-house programming using python, but I don't ever see it happening for the web at this pace. I asked /r/python a while back how they deploy, and I understand all the automation tools, but it still doesn't beat a drag and drop PHP file that runs 99.9% of the time, save for a few file permission changes in a great while. 
Thank for this info. I think I will take a look because I'm having a little trouble wrapping my head around it as well. I *sorta* get it, but after doing a little research, I think this is the missing link for me. 
I am right there with you, have a look at [this post](http://www.reddit.com/r/django/comments/1bdhqj/django_seems_a_great_thing_to_learn_getting/) on /r/django 
I was hoping you would have a good write up for the **End-User Application**, but was severely disappointed. I've been struggling to provide a fully functional deployment strategy for my /r/pyshipcommand game, but have yet to find one without issues on all OSes.
http://virtualenvwrapper.readthedocs.org/en/latest/command_ref.html#add2virtualenv
I'm on 2.7 -- maybe it's time I switched! Thanks for the links in any case. I'll read up on that ASAP!
http://hynek.me/articles/python-app-deployment-with-native-packages/ (.deb)
Well, rabbit is much easier to work with than redis if you need cross platform support. I work in OSX at the office and Windows at home, and you can't install Redis on windows (at least not the last time I checked). Rabbit was surprisingly easy to install and get running on both platforms. 
You can get a super cheap PHP web host for less than $5 a month. Then you upload your .php file to the server and it runs the file when it is requested. The server already knows what to do when it sees a request for a php file. I'm sorry, but the reality for me is that I do not have the knowledge in breadth or depth of how to troubleshoot the many different layers of the Linux stack if something should go wrong. It doesn't make me a lazy fuck because I don't have the time to learn yet another 4 layers to get the server serving the pages, and then the time to learn all the nuances that could cause other problems and how to fix those as well. However, since you posted the Tornado link, I can see that a standalone server is possible and probably a reality for me now. Just don't automatically assume I'm lazy because time really is limited for some in the work environment.
I'm using FreeBSD which doesn't have all those -devel, -* stuff. BTW the SQL drivers are probably one of the only thing that I install globally (through the ports)
I didn't get the impression this was a highschool kid. Kids these days have their own computers :P I always suggest, with the exception of debian, the LTS. (debian stable on servers, but for your workstation the packages are just too old usually) I'm not a 'greybeard' by any means - i'm 24. Learning how to setup your dev environment isn't exactly much to ask. In the end it will be vital for debugging when things don't work. This is especially important in web dev since there are so many individual pieces. 
Better package management/distribution! If I'm really crazy, I might even write a PEP/core code to integrate it directly into the language.
I'd probably start doing home automation (and integration); I find the state of such tools right now to be kind of mediocre, and one of the better ones is written in Perl. I'd like to see more libraries written in Python to encourage others to contribute their own packages. When I talk about "integration" I mean a really broad spectrum of stuff that is starting to become possible/relevant the more connected devices are out there. I've worked with (and love) the Philips Hue, but I've also implemented serial protocols in Python for controlling less well-connected devices like televisions, blu-ray players, amplifiers and the like. I've also done quite a bit of soundscape modelling with Boodler, which is a really cool oldschool Python package for designing audio environments. I'd also love to get into HVAC control and zoning type work; with networked sensors becoming cheaper and commonplace nowadays, you can do more dynamic control of lighting, heating/cooling, and even new means of direct user input through the likes of voice audio control (e.g. via Ubi-like pluggable computers). I'd design the software to run on small, low-power embedded systems like the Raspberry Pi or CompuLab PCs (but still able to scale up to normal servers or desktops, if desired), with a RESTful API + socket interface for controlling things and receiving event notifications, respectively; a web-based UI would be provided out of the box and of course the ability to create apps for other devices (e.g. mobile) would be possible. I'd like to offer this of level of integration to a much broader audience than just passionate tinkerers like myself. As for the details—They're really just that. I don't worry about what 3rd party packages I'd be using, but the grand vision. The rest are implementation details. [edit: spelling]
Heh, yeah, getting a full php stack on a clean box is about as hard as python is now so my comparison isn't all that fair, but that doesn't mean it's not still something to strive for. And, though heroku and quite a few other hosts *do* make deployment easy, they abstract everything away. What I'm looking for here is more of a functional model that "just works" on the surface and sets up easily but *also* lets you dip down into the internals and learn about the various things that go into powering it.
Sounds interesting I will try to see if I can include this (when required).
I don't disagree, but I'm not looking to replace the well manicured server and competent operations guy so much as the thousands of servers out there that were created by copy-pasting from outdated tutorials. Bad code is running on a bunch of beginners' production servers already, and I think something like this could be a step up for the bottom end. 
Yeah, I think the biggest disconnect is that a lot of python users come from a linux background which makes a lot of this stuff trivial.
AFAIK, it's py2exe / equivalent (with absolutely all dependencies bundled) for windows, package (possibly with a virtualenv bootstrap script) for *nixes, dunno what for macs, optionally - deb/rpm packages (there seem to be some helpers for building deb packages from python setup.py packages but I haven't tried any). I'd think there would be automated solutions for all that already; but I guess the requirements tend to be overly different.
Wow, that is very cool! Been toying with it for a couple of minutes now but that would definitely make windows only people learning feel more at home.
Thanks. I missed this, its quiet good to have this option. 
It depends on *how* something difficult. For example Python provides many abstractions that make things easier. When the difficulty is irreducible, such as a specific complexity that is part of the architecture of the internet that cannot be changed by a developer working only on their own site, that is one thing. However, most advances in frameworks and even languages are about optimizing for developer time and effort, and figuring out what can be abstracted away, and wasting less of a developer's finite attention.
Yeah, I use fabric for deployments and shell scripts for bootsrapping on my own couple of servers, but I think the target goal for most people is to eventually learn some sort of configuration management system. Why not give them a good example? I don't know why i said git though. I think I just wanted to force people to use git...
This. Good luck setting up Apache/MySQL/PHP in a VPS if you're a linux n00b.
Yeah sorry - they's no silver bullet to my knowledge unfortunately. I think if you are serious about providing a good installer, you need to provide a specific one for each targeted system (rpms, windows installer, debs, etc). It's painful.
I think this should just be made into a logging handler. That way your existing logging can go to chrome, and it works with everything.
I've tried py2exe, pyInstaller, and pyFreeze. Both have issues with either pygame or the GUI system I'm currently using (OcempGUI). At first it was just dependencies on font assets or the OcempGUI theme file, but even after I packaged them manually, I would see crashes. The only thing I haven't tried is writing an [NSIS](http://en.wikipedia.org/wiki/Nullsoft_Scriptable_Install_System) and manually downloading and installing each module (including installer the Python environment itself, if needed).
Is it compatible with python 3.3?
If you want something sort of like virtual environments, so that you can install many different versions of the same package, or don't want to grant root access, site-wide packages are a little more difficult. Sure, you can do virtual machines, but that just kicks the problem down the road.
CPAN is pretty good.
 sudo apt-get install * There, that should do it... 
Hope it continues to develop. Once I wrote very complex program jython with pydev. Used a lot of reference features and the integrated debugger. Highly recommend for complex programs.
I built a fairly complex graphing app and it went _really_ well - the library is very pythonic so it felt like you were always taking the path of least resistance. Overall a great python library 
tldr: "The simple answer is don't ever in any circumstance write a regular expression" :)
Do you know of any good beginner-friendly resources that would cover the blind spots you mentioned?
I played with it a bit and enjoyed it. It works fine with a mouse. IIRC it uses the same events to handle mouse input and touch input. So you shouldn't have any problems.
I am also thinking of using Kivy. The mobile app will be fairly limited, having a subset of functionality. Will be experimenting in few weeks 
If its desktop then pyqt is cool
I'd love some good examples of apps
I've been learning and using Kivy for about 6 months now. Once you get the hang of the Kivy GUI system, desktop and mobile apps come together very quickly.
That's a bit harsh, but there certainly should be safety guidelines for the use of regular expressions :) By their very nature they allow nasty stuff that's practically impossible to deal with on any platform. Other languages or RE engines may not freeze all threads, they still have the risk of execution time simpy exploding in one thread, which is typically just as nasty. In this case, it seems that the regexp engine ought to release the GIL lock, so that other Python code can run on other cores. It's simply a bug/inefficiency that may or may not get someone's priority to fix. 
You should definitely use numpy. The gains will be smaller than reported benchmarks if you're just using two-element vectors instead of larger arrays though, because the function call overhead will be significant. If you need better performance, look at Cython or Numba. If you're using Numpy, figure out how to vectorize your calculations so you can transform a bunch of vectors at once using matrix-matrix multiplication. 
Any chance you could have GUI input text fields that are put together into a command that is passed to `subprocess.call()` ? 
It seems kind of perverse that in one of the seemingly few places where theoretical computer science has direct relevance to application programming, industry has pretty much ignored the theoretical basis of regular expression (finite automaton) and created these kinds of performance problems to boot.
Yes. The performance improvement with Numpy's dot alone makes the switch worthwhile.
That would be the best case scenerio. In my case, the systems guys say, "we do LAMP, end of story." In this case, if I want to introduce Python web development (and I do) I have to learn the entire stack so I can come up with an air-tight argument+architecture which will still probably be shot down. Suffice it to say, we still develop entirely in PHP. Hence my extreme interest in discussions regarding deploying Python apps.
What "industry" calls regular expression is much more powerful than what theory does. In this particular case, finite automatons would have worked. But not in general.
I do appreciate the demonstrated workflow on how the problem was identified. That is more valuable than the discovery that a crazy re can kill your process because of the GIL. 
Thanks! Does numpy have any built-in functions for things like 2D vector rotation or 2D vector projection? I am finding the numpy documentation to be a little bit hard to navigate and existing answers elsewhere on the internet frustratingly irrelevant to my simple needs.
Yes. That's what I mean. The other responders seem to think it's worth using numpy.
That makes a lot of sense. Part of my problem is that I don't know yet if this is going to become a bottleneck or not. I would like to get ahead of the problem if it is, so I don't have to go back and do a bunch of refactoring later. Between robot positions, robot geometries, obstacle positions, obstacle geometries, and waypoint positions, there probably won't ever be more than 100 points (read: vectors) in the simulated world to handle at any one time. However I am hoping to be able to update and redraw the state of the world within 0.1 seconds, to make a smooth simulator. I'm still very new to Python so I do not have any instinct for its performance characteristics yet. Any thoughts on whether this will be pushing it for a typical modern machine?
Yeah I think that's what I'm going to do. If I need to speed up the calcs later they'll all be in one library anyway so refactoring them won't be too hard. Thanks a bunch for your help.
That was my takeaway too!
I'm not even sure this is scientifically or mathematically possible, but I hope it is.
Thanks for the link. Parsley looks really fun. I nodded a lot while reading the reasoning behind it :)
This feels kickstarter-ready.
Stop writing regexes period. Also don't use native code extensions that hold the GIL without performance guarantees of at least O(n) or better.
Actually you should be careful not to exceed google search limit with this one ;) Nice tool though. 
&gt; Stop writing regexes period. this isn't a popular answer on reddit apparently, but I agree with it 100%
&gt; In this case, it seems that the regexp engine ought to release the GIL lock, *so that other Python code can run on other cores* not sure it works that way. but I could be wrong I suppose. 
Haha, thanks, but I don't think it's Kickstarter material; more back-of-the-napkin plans for the proverbial, "if you won the lottery, what would you do with your life?" There are too many great possibilities not to feel a bit excited about it—stuff like playing the sound of a dog barking or turning on a light when a security camera detects motion near near the door or the doorbell rings, or having a audio storm simulation grow louder when it detects sufficiently loud outdoor ambient noise near your home to mask the sound of garbage trucks or construction from your sleeping child. I've got easily 20-30 of these types of ideas kicking around my head, and there are probably hundreds if not thousands more cases waiting to address others' unique problems, or inspire them to dream up their own ideas. I'd like to hand the keys to people to be able to plug those tools together into something that's a slam dunk for their requirements and is very cheap to assemble with off-the-shelf parts and some downloadable Python modules—because if someone like me doesn't, then we'll all be paying Apple too much money for what they want us to have instead of what we need/want, or handing over control of our very homes to the likes of Google to resell for advertising purposes, or goodness knows what else.
... ** with two levels of greedy matching going on.** FTFY The problem wasn't caused by using regular expressions, it was caused by using them poorly. Greedy matching is almost always never useful in unsanitised, unstructured input for exactly the problem exhibited here. In general, regexps are a bad way of parsing public web pages due to the fact you cannot rely on the page author having considered that HTML is a standard and 100% complying with that standard; many use some tool that will (like IDE's) let them paint a pretty GUI like its Photoshop then convert that into whatever garbage IE 6 will render to resemble what they painted. It's almost always better to use a FSM and index on left angle brackets. Regexps are less complex (read: quicker to code) if you can always guarantee your input is well-formed - this is never the case on the public internet.
You can use the 2to3 script in the Python distribution to make such translations.
Just to clarify, we aren't using regexes to parse the html - we use the lxml package for that instead. You can't really use [regular expressions to parse html](http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454) The regular expression here was applied to the attribute values of certain nodes in the dom produced by lxml. Which is still not a good idea for exactly the reasons you described, especially with the original poorly written regular expression. 
Let's see what the documentation says. [Here's the 2.7 manual](http://docs.python.org/2.7/library/urllib.html#urllib.urlencode): &gt; urllib.urlencode(query[, doseq]) &gt; &gt; Convert a mapping object or a sequence of two-element tuples to a “percent-encoded” string, suitable to pass to urlopen() above as the optional data argument. This is useful to pass a dictionary of form fields to a POST request. The resulting string is a series of key=value pairs separated by '&amp;' characters, where both key and value are quoted using quote_plus() above. When a sequence of two-element tuples is used as the query argument, the first element of each tuple is a key and the second is a value. The value element in itself can be a sequence and in that case, if the optional parameter doseq is evaluates to True, individual key=value pairs separated by '&amp;' are generated for each element of the value sequence for the key. The order of parameters in the encoded string will match the order of parameter tuples in the sequence. The urlparse module provides the functions parse_qs() and parse_qsl() which are used to parse query strings into Python data structures. [And here's the 3.3 documentation](http://docs.python.org/3/library/urllib.parse.html#urllib.parse.urlencode): &gt; urllib.parse.urlencode(query, doseq=False, safe='', encoding=None, errors=None) &gt; &gt; Convert a mapping object or a sequence of two-element tuples, which may either be a str or a bytes, to a “percent-encoded” string. If the resultant string is to be used as a data for POST operation with urlopen() function, then it should be properly encoded to bytes, otherwise it would result in a TypeError. &gt; &gt; The resulting string is a series of key=value pairs separated by '&amp;' characters, where both key and value are quoted using quote_plus() above. When a sequence of two-element tuples is used as the query argument, the first element of each tuple is a key and the second is a value. The value element in itself can be a sequence and in that case, if the optional parameter doseq is evaluates to True, individual key=value pairs separated by '&amp;' are generated for each element of the value sequence for the key. The order of parameters in the encoded string will match the order of parameter tuples in the sequence. &gt; &gt; When query parameter is a str, the safe, encoding and error parameters are passed down to quote_plus() for encoding. &gt; &gt; To reverse this encoding process, parse_qs() and parse_qsl() are provided in this module to parse query strings into Python data structures. &gt; &gt; Refer to urllib examples to find out how urlencode method can be used for generating query string for a URL or data for POST. &gt; &gt; Changed in version 3.2: Query parameter supports bytes and string objects. So clearly they are not *exactly* the same thing. The 3.x version supports more features, for instance. But if you are porting from 2 to 3, it's safe to assume you weren't using those features before. 
Thanks. That script really makes things easy.
Okay, thanks. It's just that I was running a program that encoded some parameters using urlencode, then passed them to hmac.new() which then threw an error. It looks like the error was in a receive command, but all seems to be working now.
This is stupid, regex's have their time or place. This is just a bug in the python regex module
&gt; Regexps are less complex (read: quicker to code) Sorry, you may have the upvotes, but this isn't convincing at all. Do you consider the debugging of the re as part of the coding or merely typing ( or in most peoples cases googling for and then pasting) the magic string that does everything. In my mind, re's are just clever ways to hide the cleverness from yourself. Its like saying "man my IDE's debugger is so fucking good, this is too easy, so Imma use an re for lulz..." Personally, I have never felt clever enough to use an re, but I've replaced many re's in code that didn't work properly placed there by some moron who thought they were too clever and totally fucked it up. That's my convincing case. Maybe it's different in the valley. 
Frankly, building on top of numpy is a good idea. First, numpy offers a vast wealth of facilities for making operations on arrays efficient and easy. Second, by building on numpy from the beginning, your "probably won't ever be more than 100 points" has the flexibility to expand to "10,000 points" or "100,000 points" or possibly even further. You don't have to design new interfaces or flows, you don't have to learn-numpy-now-that-it-needs-to-scale because you used it from the beginning.
I for one can not agree with you simply because most people aren't smart enough to use re's and just cause trouble with them. It's like giving a monkey a chainsaw to make a PB+J it always ends badly. 
The GIL is a great topic for people to write posts about in order to demonstrate that they are hot shit
ok how about the rule restated with no tact. most people are too stupid to use re's and thus probably too stupid to be doing complicated string manipulation. stick to scraping imgur for cat pictures with beautifulsoup and blog about it. not bothering with the smiley since this entire thread lacks a sense of humor anyway. 
i think macros should be used instead. 
The easiest way right now (to learn) is to use Google App Engine.
If you have to declare dependencies, you've already lost.
Meh, irresponsible code is irresponsible code. I agree that regex does lend itself to some very bad practices. That being said, there are places where using regex is the right choice. You're using a lot of extremes in your language. I'm sure you are a good programmer, but there isn't any need for the extreme rhetoric. If programmers don't understand when it is proper to use regex, or how to craft appropriate patterns, then let's help them to understand those things. Dismissing an extremely useful tool entirely, simply because it can be (and is) often misapplied doesn't seem like the best solution. These aren't regular people, these are programmers, and some day you might inherit code that they wrote, or work on a team with them. I'd prefer that everyone learn regex and when it is the right tool for the job . I'd certainly prefer that over some clever 100 line solution that was rolled simply to avoid a single regex pattern. Anyway, I do understand your point of view. If you never need regex in your code, then that is awesome. We all work on different things, and different problems require different solutions. 
Not when you have to debug old code. I've never seen a regex that was easier to read and understand (for a maintenance coder) than the equivalent imperative code version.
 FWIW, I would say the same thing about metaclasses. Don't use them. And the outcome I would hope for out of people on my team is an actual convincing reason why it's appropriate to use a metaclass, and why all other options are inferior. if you can convince your team that it's the right thing to do, chances are you know enough to know that its appropriate. Fortunately one doesn't google for a magic metaclass impl and paste it into the code. However, that is usually the case for re's. email validation being the most recent one I recall having to debug or remove. ^[_a-z0-9-]+(\.[_a-z0-9-]+)*@[a-z0-9-]+(\.[a-z0-9-]+)*(\.[a-z]{2,4})$ http://stackoverflow.com/questions/201323/using-a-regular-expression-to-validate-an-email-address " However, from time to time I get contacted by someone that is having trouble with a site that uses it, and I end up having to make some adjustment (most recently I realized that I wasn't allowing 4-character TLDs)." /shakes head 
haha, I agree, if you need to ask whether a metaclass is a good idea, it isn't (that being said, metaclasses are fun! If not in a production sort of way) And never blindly take a regex pattern (or any code) from the internet. If you don't understand it, then you shouldn't use it until you do. 
same rule goes for zope.interface actually. if you have to ask, you don't need to use it. But when you know, you know.
How so? Is it just the lookahead stuff?
See, for me, they're both equally hard. But at least with the regex I'm going into it with the context that I'll be doing some sort of string replacement or search or whatever. With imperative code, I have nothing to set up that context. I just have to mentally deal with all the for loops and temp storage and that kind of stuff.
The alternative in this case is using a regular expression library that compiles to a DFA and has linear worst-case time complexity.
There are regular expression libraries like re2 that guarantee linear worst-case time complexity by leaving out the parts that aren't actually regular anyway.
It's more that I've never seen a situation where regexes have made maintaining existing codebases more useful. It always involves having to look up a separate set of documentation for the regex format in question, then having to decode the abstract line noise that was jammed into the source code, in order to find the bug. It's not that finite automata are bad, it's that the syntax we're using for leveraging them IS. And, of course, that modern "regexes" aren't finite automata. They have features outside the scope of DFAs, that you have worst-case performance of O(2^n), which is terrible. But I'm more worried about the regex syntax than the performance problems with backreferences. The advice about the GIL is much more obvious though, at least for servers or games. CPython can sort of cover up the GIL by releasing it every 100 instructions or so, but only if the current execution context is in the Python VM. Native code extensions WILL block other Python threads unless they copy everything they need and release the GIL. The thing about performance guarantees is that anything worse than O(n) makes it hard to properly profile your code for these kinds of problems, because n can vary wildly in production environments.
Use re2 bindings instead and you know that the time complexity is bounded to linear complexity from the size of the regexp/input. You can even safely take regexp as input from untrusted sources that way as long as you put a bound on the length. For example: http://codesearch.debian.net/
Oh sure. I don't have any particular loyalty to `re`, other than that I tend to prefer the standard library to 3rd parties. I was arguing against the case for no regular expressions ever.
&gt; E: Unable to locate package Documents &gt; E: Unable to locate package .vimrc &gt; E: Unable to locate package .bashrc &gt; E: Unable to locate package .bash_aliases this got me nowhere. Any better advice?
I just stood on my chair and saluted. I would like all of this very much.
Google has done some cool things, like hiring the BDFL and giving him 50% of his time to devote to python, the Google App Engine, and of course dumping money to the PSF. Im sure python would be different if not for Googles good deeds.
Oh it's the backreferences. That makes sense.
(I'm replying to a few of your comments with this but putting it here...) I don't see this. Shall I truly dispose of a functional one-liner in favor of looping + string slicing + branching conditionals or parsing grammars or actually writing a state machine for a tokenizer? I don't see how that is easier to understand for a guy down the line. I agree on performance grounds and where performance is critical, the developer must try to find a more basic solution. However, there are short, readable and very flexible regexes that greatly simplify what would otherwise be terribly verbose to represent with imperative code. Saying that the regex syntax is so bad and impenetrable that it never makes more sense is disingenuous. There are many people writing regexes who do understand that readability matters.
Don't blame the tool for bad programmers.
And break any logic that uses division.
In this case it was a very practical case with a clear and realistic example. I enjoyed the read.
Python web development is easy. I wouldn't consider deployment really a huge part of new-programmers development. Sure eventually they'll want to deploy it, but for learning to do python web development, build in web servers exist for most modern python web frameworks.
But the thing is that no one is asking you to remove a tool! If someone told you "hey, screwdrivers are deadly when you shove them into an electrical socket!", does that mean you remove screwdrivers from your toolbox? I took away the opposite opinion from the article; now I know more about the pitfalls of using some regex implementations, which makes me want to use them more because they are less mysterious.
No by choice. we promise backward compatibly. There will be a web3py that runs with 3.3 and will be different from web2py but it will have a web2py emulation mode.
The problem with teaching programming is creating motivation. It is hard to motivate students to generate fibonacci numbers. I believe building web apps provides lots of motivation. Web2py can be used in intro programming clasess and it solves the deployment problem. More experienced users will use differently (with apache or nginx) but newbies can use it with the built-in web server or on pythonanywhere without trouble at all.
I think more people should turn to parser combinator or PEG libraries instead of trying to hack together unreadable half solutions with regexp. There are cases when regexp is awesome, but in my opinion those are all covered by re2. It compiles down to a DFA and the lack of features just makes it simpler and makes it obvious when it's the wrong tool.
 # apt-get update &amp;&amp; apt-cache pkgnames | xargs apt-get install There you go. ^^note: ^^Do ^^not ^^actually ^^do ^^this.
&gt; It always involves having to look up a separate set of documentation for the regex format in question, then having to decode the abstract line noise that was jammed into the source code, in order to find the bug. https://pypi.python.org/pypi/reverb/2.0
You could also write a parser with something like Parsley.
On the contrary, I've found it to outperform BLAS's dotu, gemv and gemm on several occasions (especially for atypical input sizes), which is noticeable because it's essentially built on those three algorithms.
Same here- I was referring to some of the mood here in the comments. Like you, I came away from the article feeling more informed about the implementation particulars of `re`.
use python binding for poppler. Render the PDF page first, then You can search text on the page with the poppler interface. Then paint over the given coordinates with cairo operators. If it's newspaper images with text on it in the PDF, then you are pretty much stuck. cannot help you with that. 
I'd like to know if there are any relative advantages vs. Qt
Nice. Note that the [distil](https://distil.readthedocs.org/en/latest/) tool can generate these kinds of images too: distil graph --image flask-sqlalchemy | dot -T png &gt; depend-1.png [Link to the image produced.](http://i.imgur.com/QjC0F9Y.png) 
The release notes "hundreds of bugfixes" http://docs.python.org/release/3.3.1/whatsnew/changelog.html 
I have a food processor in my kitchen and it's saved me an enormous amount of time over the years. But when all I need is a slice of tomato for my sandwich, it's the wrong tool for the job. Whenever I have to write a new regular expression, I ask myself, "Do I need this? Can I do this another way?" I still love my regular expressions as much as I love my food processor, but if the "direct" approach works, then why not use it? The best example of this is with evaluating email addresses. Everyone makes some insanely complicated regex to match an email address. Who the hell cares if an email address adheres to every single criterion of the RFC? `0 &lt; my_string.find("@") &lt; my_string.rfind(".") &lt; len(my_string)-1` works just fine.
&gt; Stop writing regexes period. I slightly disagree. In production code that operates at scale, approach regexes with *extreme* care and prejudice. `re` is a rocket launcher. Make sure you're aiming in the right direction.
Exactly. Even if you prevent bad programmers from using re's, it's likely their alternative implementation is just as bad (or worse). 
If you have a text area widget, then you could create a handler that takes any logging events and appends them to the text inside the widget. Take a look at the logging documentation, its very detailed and self explinatory: http://docs.python.org/2/library/logging.html If you are also looking to be able to execute python commands from some text area in a 'Shell' style manner, take a look at [the eval command](http://docs.python.org/2/library/functions.html#eval)
Yeah I gather I misunderstood 2D linear algebra to imply vector-vector and matrix-vector operations with very large arrays. I still think it's a good idea to use Numpy, if only to encourage its use early on so that OP doesn't have to reinvent the wheel once his project becomes more computationally advanced (which it usually does after the first few optimization/refactoring cycles).
thank you for that .. wanted to find out how to do it with *sh tools guess i should go learn more about xargs ;)
I've had a play with kivy and really like the concept but it's very focused on multi-touch apps and the look'n feel is totally non-native. Kivy is probably good for kiosk-style apps where desktop integration isn't required. For a regular desktop app, there's no reason not to go with PyQT/PySide; Qt has more features than anything else out there. I have a soft spot for wxPython as well but being stuck on py2.7 sucks. Give kivy's focus on multi-touch, deployment on android was a lot harder to figure out that it should have been; this might be improved now I'm not sure.
I think it is posted on /r/python a few days ago, at the same time when 2.7.4 came out.
&gt; most recently I realized that I wasn't allowing 4-character TLDs Ah ah. He apparently doesn't know about `.museum` (10-years old), `.travel` (7-years old). :)
This is a complete rewrite of the module, still trying to make django configuration flexible, powerful, secure and simple: * it is now dead easy to install (`pip install django-flexisettings`) * it is also very simple to use (change two lines in `manage.py` or `wsgi.py` and use your standard django settings) * doesn't try to be too smart, doesn't change anything by default * integrates with django autoreload function so changing any configuration reloads the dev server * project layout autodiscovery based on common practices and adaptable to your project ([Zachary Voase: Django Project Conventions, Revisited](http://zacharyvoase.com/2010/02/03/django-project-conventions/) and others) * integrates nicely with gunicorn (configuration is documented) Please let us know if you try or use it, send pull requests if you want to contribute!
I hope this helps someone who's looking to do a little bit more with GUIs in python. It makes some things easier than using TKinter by itself. The code I used will be uploaded and ready for download along with a tic-tac-toe version 1.0.0 using the zelle graphics.py module =D 
you're right, I forgot about 'dot' :)
This is an **incomplete** regex for detecting regular expressions that requires some pre-processing on the email address first to be totally accurate http://ex-parrot.com/~pdw/Mail-RFC822-Address.html That is, in a nutshell, why your own approach is better than people using regular expressions - because they won't be using that monster, and so will be wrong. Ultimately, you determine if an email address is valid by sending an email and getting a response - about all that you can do in terms of input validation is the basic sanity checks you do
Is this app available somewhere? 
I've just written an application in Qt, however, it contains some OS specific stuff such as tray icons(keep the application running, without any windows currently active). A quick look through the kivy documentation didn't give me any results, so my guess is that kivy isn't ready yet to do such stuff. If it is possible to have kivy run a window-less application with a tray icon, I'd sure like to see how to do it!
This is actually exactly what I would want in a regex syntax. I'll look into this in the future.
What's going on with ActivePython. It hasn't been udpated in quite a long time.
People will say the same of a language they dont understand. I've had jobs were we've written huge regexes. after a few months of writing them every now and then i stopped noticing that it was hard to follow. Just spend a few minutes and work it out. It isnt that hard and you are totally wrong to imply that someone who is a developer can't work out a regex. You may have a lack of competence but it doesnt mean everyone else does too.
&gt; separate set of documentation for the regex format in question This is a pathetic excuse. One could say the same about any language. Any config file. Any markup. Any characterset. 
If he cared so much why wasn't he using processes. One dies and your others are fine.
I wasn't familiar with this library (or its author): [http://mcsp.wartburg.edu/zelle/python/](http://mcsp.wartburg.edu/zelle/python/) for those that don't want to watch a video. And it seems the github repo only contains a sample program using the library (a smiley face).
It depends on whether the operations can be vectorised over the 100/100,000 points. So far it sounds like the only vectorisation will be over 2 or 2x2 arrays. In that case, Numpy will be enormously slower than native Python because of the overhead of calling into Numpy.
Graphical interfacii! Closed the tab. I appreciate that people want to help, but not like this.
It was mentioned a few times the release manager got sucked into Stackato, hence the latency from upstream releases. There's rumour on their website about releases planned for "early 2013" but since we're heading into mid-2013 I guess those milestones slipped again. If you're after the free "community edition" then I recommend Anaconda CE, Continuum Analytics have done a very good job on it. Enthought has gone AWOL, they also had a good distro but its gone now. If you're on Windows, Python(x,y) is also a good choice. If you're on a real platform though, there's nothing wrong with upstream python + "pip install something_outside_stdlib" If you're learning python though you may miss ActivePython's inclusion of several python learning resources and a documentation tool; "pydoc -b" isn't quite the same... 
Yeah, don't know about Tkinter (is it even possible?) but with wxpython I think [pyCrust's descendant](http://www.wxpython.org/PyManual.html), pyShell, is the way to go. Looks like it isn't actively maintained though.
neat might be cute to have one for bottle sitting on its own
I wrote a python script that reads in two file names. myprogram /path/inputfilename.txt /path/outputfilename.txt Because there are so many folks who cant use the command line in Windows and Mac's (unix folks like it) that they want a simple click and choose file names. It would be nice to also open the output with wordpad.exe or something. I thought of a javascript to do it using a point to this directory sort of thingy.
Ill try it out! 
Two of which were reported by me... yay!
Wait, what? Virtualenv in core? How did I miss that...
There are two major frameworks that're compatible with Python 3: [Django](http://djangoproject.com/) and [Pyramid](http://www.pylonsproject.org/). I'm not familiar enough with CodeIgnighter to tell you which'll feel the most similar, but I think you'll probably be happy with either of 'em. Good luck!
This is the built in way to provide authentication with AppEngine, and authentication is required for any full feature application - thus why it is required. 
I created an email account anyone can use to access the site without using there own gmail (only problem is youll be editing the same task list etc): user: honeydoesexample@gmail.com password: thepassword
To login without using your own gmail account use: username: honeydoesexample@gmail.com password: thepassword 
Source so I can see what it's trying to do before I allow it to access my Gmail account?
Alright, I'm going to be that guy. Do whatever you want, but you'll find yourself constantly running into libraries you can't use because they aren't working on 3.x yet. On the other hand, it's pretty easy to write code that can run under both python 2.7 and python 3. If there isn't any specific feature that you really need in python 3 that doesn't exist or can't be backported to 2.7, then you're probably going with python 3 for the wrong reason. But, if you're just doing this for fun / want a learning experience, then who cares. Either way, probably the closest you'll find to CI is going to be django (which as of a month or so ago, has experimental python 3 support). The thing you'll be pleasantly surprised with that you won't find in the PHP world is the enormous amount of reusable code out there. Before you write any code to do stuff, search "django comments" or "django messages" or whatever you're trying to build... chances are there's stuff out there that can get you most of the way there. www.djangopackages.com
Does anyone know when iPython will be compatible with 3.3?
The source code for honeydo.es is closed as it's a for-profit project, I posted it here cause I thought people who had seen my earlier post about WebBot would like to see a full-featured showcase of framework (similar to what bootcamp etc was for ruby on rails). If you want to test out the site without using your own email you can use the provided test account email. I hope I wasn't incorrect about people wanting to see this, but if I was at least reddit has good way of filtering these things out :)
I want to see it. Not login to it. Like how I can actually visit http://stackoverflow.com/ without logging in, but *if* I want to login *then* I can use my Google account.
Hi donkdonk, I think you have a really good point, sadly I cant think of anyway to allow this in the short term with this project (as I can't just expose peoples tasks that they thought where private to their friends) - Maybe in the future I should allow people to create explicitly globally public tasks (like google + lets you do with posts - which would allow others to see and interact with the site without logging in. Thanks! Timothy 
Besides the "friends" feature, how is this any different than the **multitude** of the web-based paid or [free](http://www.rememberthemilk.com/login/app/?launch=1) [task](http://www.producteev.com/) [managers](http://www.getflow.com/)? The interface on the others is, in my opinion, much cleaner. I think this has quite a bit of work before it would be a contending free product in this saturated market, much less a *for profit* product. Also, had you not provided an example email, I would not have authorized this, and neither will anyone else. You need to have a product page demonstrating what this is, how it is used, and what the benefits are before asking for authorization over someone's email account. Thanks for sharing, though. Best of luck.
venv != virtualenv, although they are similar
Nice! I only reported 1, but it was the struct module, so that should count for 2 :)
look at http://123done.org/ for comparison
Hi jwcrux, The friends feature really is the selling point, as it makes it something completely different then any of the free or for-profit applications I have seen (Having others look at your tasks gives you incentive to actually complete them - particularly the hard ones, and getting comments likes etc can be helpful). If you look at the honey suggests user you can see just how useful this feature is, getting suggestions etc. When I say "for-profit" I really mean ad-based profit (if it ever gets to that point) and not actually selling this to companies. I think your right about needing a demo page, as it is it probably just looks sketch as hell :/ Thanks for wishing me luck! Timothy
123done, is an entirely different beast, the whole point of honeydo.es is completing tasks with friends (thus the need for authentication etc), 123done is just a personal todo list application simular to the desktop to-do applications that have existed for years, so it can be demoed without any of the more complex concerns that a social site has to deal with.
It works for me on Arch Linux.
Python 2.7.4 is the last major release of the 2.x series. It will be maintained with security updates for a long time to come but you won't get any new features. http://docs.python.org/2/whatsnew/2.7.html#the-future-for-python-2-x I was at a PDXPython meetup last night in Portland where Daniel Lindsley talked about moving from Python 2 to 3. His suggestion to the newcomers was to learn Python 3.3 (no reason to use 3.0, 3.1 or 3.2 as 3.3 is classified as production ready). The idea being it was easier to go back and make changes for 2.x only if needed. The [Python Wall of Superpowers](https://python3wos.appspot.com/) is a handy site which lists the top 100 Python packages and if they have been ported to work with Python 3.3. [The Hitchhiker’s Guide to Python](http://docs.python-guide.org/en/latest/) is a nice opinionated getting started guide done by Kenneth Reitz (author of the awesome [requests](http://docs.python-requests.org/en/latest/) library). Both major micro-frameworks, [Flask](http://flask.pocoo.org/) &amp; [Bottle](http://bottlepy.org/docs/dev/), do not appear to be Python 3 compatible yet. My suggestion would be to start with [Django 1.5](https://docs.djangoproject.com/en/1.5/) and Python 3.3. By the time you are comfortable with both, Django 1.6 may be ready which will be Python 3 production ready. It is also possible to run Python 2.x and Python 3.3 on the same codebase with the [six](http://pythonhosted.org/six/) package. I don't know enough about Pyramid, so I won't comment on that. 
Bottle *is* 3.x compatible, though Flask isn't AFAIK.
How do you know if a linux user chooses Arch?
Then have a look at bottle. Flask is my favorite microframework, but for py3k stuff I had to give it up for Bottle. Not much regrets (though I don't like the built-in templating language)
It even says so right on the front page. **facepalm** Thanks for correcting me on that.
Maybe I should have been more specific. Even the notebook? 
Exactly, nothing illicit going on here.
What's the difference? 
I see, is there a design document, or overall plan that I can read about web3py?
This seems just as safe to me as curl http://foo.com/something-fishy.sh | bash
&gt;This is the built in way to provide authentication with AppEngine, and authentication is required for any full feature application uhhhhhh whut? #1: what do you mean by full feature #2: you can use any authentication mechanism you want including none. app engine itself doesn't care. 
Well, it is if you are one of the unfortunate few who can't read 126 lines of simple python beforehand.
yeah it's unbelievable...............
Presumably MySQL, not MS-SQL.
that's if you choose to use googles auth. you don't have to use googles auth, thats what I'm saying. we have plenty of customers using our app and it's not hooked to their google or google apps account. 
Right that's what "default" means. Ofcourse you can use whatever you want but to create an app quickly you use the default provided authentication mechanism.
&gt; but to create an app quickly you use the default provided authentication mechanism. and now I have zero interest in this app, where before I was at least curious. 
Notice there's no "stop to ensure download integrity and lack of funny business" step in that pipe command. Unless you're computer psychic, and you can read the contents of that pipe as it flows straight from curl into python, you have no way to know that the data in that pipe hasn't been tampered with.
Hmm, quickly looking at their site: &gt; IPython supports Python 2.6 to 2.7 and 3.2 or newer.
Note that even if the command was something like get script | confirm script matches hash | run script you're still exposing yourself to potential malicious hash-collisions. Significantly less likely than the original, but still a possibility. Worse yet, get script | confirm script matches crc32 | run script provides the illusion of a reasonable check, but without any significantly increased security.
As in %notebook &lt;arguments&gt;? It a file correctly.
Good point. Best option is still to download once, look it over, delete your conf file when you want a fresh browser, and re-check on every upgrade. At which point, you might as well just use Chrom{e,ium} in incognito mode anyways.
Well, I know it's not malicious because I wrote it. YMMV.
booooooring.
You know that's actually very fair, I'm going to remove this post - I was really excited about it cause I thought it was a cool concept, but I think I was just trying too hard for velocity and should have gotten some of the basic kinks worked out. I do appreciate the time you took to look into it. Thank you, Timothy
Sorry to do this, but what you are proposing is nonsense. For that hash to give you any added security, you need to have more confidence in that hash than in the script you are downloading. And how exactly would that happen? The script you are getting directly over a secure, certified connection to a google server where the only person who can upload things is me. So, you either trust me and google, or you don't. If you trust me and google, using curl is exactly as safe as using the hash. If you trust me and not google, then the hash is as compromised as the script, unless you want a gpg-signed hash, in which case, I would rather give you a gpg-signed script. If you trust google and not me, then you can't trust the script even if it were to pass your little hash check. If you mistrust me *and* google, then you can't trust the script nor chromium, much less chromium's incognito mode. So, what exactly is the point of that little teather piece you propose? ;-)
Sure. And realistically, I don't *expect* it to be malicious. Just like I don't *expect* to get in an accident when I get in the car. But I still put on my seatbelt every time, because it's just good policy, and ya never know. Truth is, if someone got control of your hosting, or you accidentally introduced a bug that deleted /usr, it's not like you'd have to be a bad guy or intentionally malicious. But it would still fuck up the day of anyone who ran those two lines of update commands.
&gt;https://developers.google.com/appengine/articles/auth I've never test drove appengine for anything meaningful but this looks like an almost show-stopping constraint on the auth source/provider. Esp this bit. &gt;Google offers three different systems for authenticating your application's users. Only one form of authentication can be used for a given application. The apps we deploy support arbitrary pluggable auth systems. Hopefully your framework isn't irrevocably coupled to appengine. Vendor lock-in can kill flexibility. 
Sure. But the same is true of everything you ever built from source in your life.
This question sounds like, "How do we make using python easier for people who don't want to put in the time and effort to learn the things they should know?" RTFM! :)
Very much so. Whether explicit or implicit, there is always a factor of trust. This mostly comes from mutual reinforcement - when a lot of people trust an open source project, it's generally more trustworthy. But there are two big factors working against you in the specific case. One, nobody knows who you are (which is why something like "From the maker of WhizBangWidget" is so helpful if you have prior work), and two, your system *by design* redownloads the program every time you run it, which to an attacker is like walking out on the street in just heels, lipstick, and a trenchcoat. It's a prime target for manipulation, even more than most open source software. **EDIT:** I'm not saying this stuff to be a dick, and I hope you realize that. I'm pointing out these problems because they're inherently fixable ones, and I'm hoping that my criticism will be constructive, not just "haha nice try writing software, come back when you're older and have RTFM." We're all learning shit every day, and most of that involves learning from our mistakes. The most important thing you can learn, then, is to not take it personally when learning from mistakes. That's a hard thing, and one that even I'm not 100% on, even with conscious effort.
I agree it's a pretty bad constraint - luckily WebBot itself really does nothing with authentication and works on Django etc as well. As for honeydoes, I really should have spent more time on it before I posted - it's obviously not ready for prime-time.
Well, *you* may not know who I am, which is, to be honest, your problem and not mine :-) Trust me, there is nothing in what you wrote that I have not thought about. I just don't think it matters all that much. Really. And don't worry, I am not taking it personally. For example, I would probably not download and run arbitrary code I found in reddit. OTOH, I *don't care* if you do it or not. Hey, it's there, it's written by me, my reputation is what it is, and you can run it or not however you want. But think about it, if you ever use, for example, Arch's AUR, you are doing *exactly the same thing*. If you ever add a PPA in ubuntu, you are doing *exactly the same thing*. If you ever run any software that's community packaged in Debian it's the same thing. If you ever install a binary in windows or OSX *it's the same thing*. In this case it's pretty obvious, and my not giving a damn about the fig leaf you seem to care about is, perhaps my problem and not yours, or viceversa :-)
[link](https://www.enthought.com/products/canopy/)
I like how it states Plone is too "impressive" to render. 
It's an abonination, and the blog-post isn't very well written, but damn if I'm not impressed regardless.
That's all fine. This is just a fun and interesting demo of how easy it is to make a browser thanks to the webkit libraries and such, and probably doesn't deserve any kind of intense scrutiny, any more than the Raspberry Pi should be put down for not using an i7 CPU ;) In any practical sense, "real" security would be overkill. But this paragraph is really troubling to me: &gt; But think about it, if you ever use, for example, Arch's AUR, you are doing exactly the same thing. If you ever add a PPA in ubuntu, you are doing exactly the same thing. If you ever run any software that's community packaged in Debian it's the same thing. If you ever install a binary in windows or OSX it's the same thing. No, it's not. None of those things redownload the software every time you use it, which is the big difference. Most of those also have some sort of community oversight, which is a less significant difference, but still generally good practice. You have several good things going for you to mitigate the risks - HTTPS hosting on Google, for example - but this wouldn't fly for a larger project, because of how much damage can happen so fast from one account password getting cracked/guessed. And even if for your specific project, this isn't a concern and you've covered all your bases, you're still training users to happily run scripts straight off the internet, which for many reasons is a *terrible habit.* This is essentially the digital equivalent of the "Don't feed the bears" signs you'd see in a national park.
Yes, you should pipe an unknown shell script directly to bash. Seems legit.
Oh, right, a shell script called "devicenzo.py" that is piped into a shell called "python". You got all the facts straight right there dude.
I was too scared to continue reading after "MS Access".
Adobe reader continues to be one of the most insecure executables on the web. Please avoid distributing any info via PDF documents. Not only do they make your system vulnerable, the data cannot be extracted from them without a good deal of luck and sometimes, exotic tools. 
There's a patch that makes Flask run under Python 3. It doesn't pass its own unit test suite, but it passes the smoke test. https://github.com/puzzlet/flask You'll need his port of Werkzug to Python 3 as well. Happily this one does pass its test suite: https://github.com/puzzlet/werkzeug
Try [Anaconda](http://continuum.io/downloads.html) instead. It's a modern Python distribution ( Python 2 or 3 interpreter + precompiled scientific stack ) that doesn't make all of these assumptions about your usage that Canopy does. Update: Caveat, I work with folks who developed Anaconda. :-)
Cool, thanks for the info, I'll be watching.
Ah, saw "concurrent.futures" import and assumed it was Py3. Didn't know about "futures" library for 2.7 :)
Typo or no typo, web2py is the most fantastic framework I've ever used - just put a web front end on a server product of mine and it was an absolute pleasure. 
I just tried installing the `ipython-0.13.1-1` package in Arch, and `ipython notebook` seems to load up and render the example notebooks in `/usr/share/doc/ipython/examples/notebooks` just fine, though I didn't try re-running any of the pylab-related cells (the Arch-packaged version of matplotlib drags in way too many unnecessary dependencies to try a quick test). But the non-pylab cells seemed to execute just fine (aside from some python 2.x-syntax print statements), even the kernel crash recovery test. Was there something specific you had run into problems with? EDIT: According to the ipython.org frontpage announcements, ipython 0.13.1 backported a number of "significant fixes" for Python 3.3 compatibility, so maybe last October is when IPython "will" be compatible with 3.3 :)
Intersting; thanks. The newest version was just released five days ago. The previous version said "Officially, IPython requires Python 2.6, 2.7, 3.1, or 3.2." Hopefully this'll solve the problem I was having. 
Not to mention Anaconda doesn't pretend like 64bit is some magical thing that should cost money. 
There's a difference between Adobe Reader and the ISO standard PDF file format. PDF is a very useful file format when one needs to insure that a document looks the same no matter what device it is viewed on and/or needs broad OS/device compatibility. Now avoiding *Adobe Reader* on the other hand, is a piece of advice I'd agree with. There are plenty of more secure (and more useful) alternatives on all of the major platforms. 
I just tried it in a virtual machine with OpenSUSE 12.3, and it's working now. Previously it wouldn't start with OpenSUSE 12.3 because of a change with python 3.3 and return results when importing libraries or somesuch. I believe it was "negative values for level are no longer supported". It's also possible the issue was with ZeroMQ (the library ipython3 reported not getting the right value from when trying to import it according to the error message I originally got). Either OpenSUSE updated ipython or ZeroMQ or fixed a bug since its release a few weeks ago because now everything's working. It figures the problem would magically go away the same day I open my mouth up about it. :-) On the plus side, it looks like I can upgrade to OpenSUSE 12.3 now. Thank you everyone for your help... even though I feel like a fool for describing an error it's now impossible to reproduce. :-)
Any security conscious folk knows that we need to move away from "it's as easy as this!&lt;pipe script into interpreter&gt;", such that the only people left doing it are shady folks.
Groove! One "segmentation fault" on a browser back button, but otherwise great!
If you are keeping the hash, you may as well keep the script. Again, the hash is useless.
Well, it does put a step in a way. But I guess realistically if people are copying any shell script off the web and running it, they're not going to think twice about that either. I guess it's best just not to put anything in a shell script intended as a "here give it a try" kind of thing that pulls any other arbitrary chunk of data down.
So, it would be even better if I uploaded a zip file with a password and the script in it. That way there are *three* steps before you run it! I can see that you guess that's best, what I have not seen is *why* you guess that's best :-)