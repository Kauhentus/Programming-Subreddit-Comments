...so put your interpreted language into our natively compiling language. No, something is definitely wrong there.
Thanks for pointing them out, I appreciate it. I'm not deep in the python community so I don't know what is popular and what isn't.
There are lots of good url dispatchers/routers, template engines, orm toolkits, but are there any good standalone form libraries? I've been thinking of using newf, jinja2, sqlalchemy+elixer and glueing it all together with some wsgi magic, but will need to deal with web forms. I really like django.forms (newforms) and am considering porting it so that it is easy to use standalone / without django. There's really no reason for it to depend on django and it could be useful to other frameworks / non-frameworks. Or are there already good html form library options available?
You should check out WebOb. http://pythonpaste.org/webob/reference.html The webapp framework from Google App Engine is based on that: http://code.google.com/appengine/docs/python/tools/webapp/requestclass.html
Perhaps for distribution to systems without the need to modify environment variables?
But he clearly expects modified `PATH` when he calls `ipy` just like that. I mean, yeah, OK, it's a cool trick, not a good solution, for example now you can't `import` your file, can't see that it's Python script, etc. The good solution is to modify PATHEXT and associate Python with `.py` files (CPython installer does this automatically, IIRC).
Be glad there is no Mindfuck interpreter written in Mindfuck so far. It would be called "Selffuck".
You may like [wtforms](http://wtforms.simplecodes.com/).
Aah thank you. That looks quite promising. The style looks similar to django forms, so it seems like there would be little point in extracting django.forms into a standalone package.
If you are using SQLAlchemy you may want to have a look at [FormAlchemy](http://code.google.com/p/formalchemy/). The traditional choice would probably be [FormEncode](http://formencode.org).
some nice stuff there. I love that there are so many options for web apps in a language I like to use. 
or FuckYourself
This is cool if you want to run your regular python files with the CPython interpreter, and your IronPython files with ipy.
&gt;Fix Python to not use such a poisonous (to GPL) licensed library. Oh the irony.
I somewhat bought the GPL freedom-with-no-exceptions view on things until I started running into cases where open source licenses were incompatible with the GPL. OpenSSL is the poster-child for GPL incompatibilities, but there are other licenses where a single, not particularly onerous, clause makes it not legally possible to use GPL code with software under that license. It's a ridiculous waste to have to re-implement a piece of open source software just so that it's under a different license. It's like rewriting a book because you don't like the picture on the cover. This sort of thing, to me, is a miserable example of politics over pragmatism.
And this is why I always use the loosest possible license.
Isn't this a result of the licensing/patent system itself and the fear, uncertainty and doubt it fosters in the open source community (vanity and hardline politics aside)? 
Here we go again, Linux vs BSD... Let me go grab my pitchfork!
This isn't unique to Python at all. Just use python-gnutls if you don't like the openssl license. Edit: or python-nss. nss is used by, as an example, Mozilla products.
OS/360 FTW ;-) That's what the Columbia cartels use. 
That's what he said to her while referring to a vagina as a 'license'.
Jinja and WTForms are absolutely great. +1 for recommending, ervandew.
Python's hidden poisoned apple for BSD applications: the readline module.
Comment fail.
Except that you're free to not use the SSL module (which I believe is documented to use OpenSSL): as long as the relevant module is not imported, OpenSSL is not loaded into your program.
I realized that auto-generated forms rarely work for me, so FormAlchemy isn't really my style. FormEncode looks interesting - I'll try it out and decide between that and wtforms.
Hi guys, Somewhere recently - I think at PyCon 09 - I found an XML representation format that looked a little like Python - no opening and closing tags, just identation. Ie: html head body table tr td p='Hello World' Nice isn't it? I'm now having trouble finding it online. Any remember what this format is called?
Uh, not really. Even if we assume you meant s/Linux/GPL/, and it's not GNU that have the weird-ass license, it's OpenSSL. GNU have even provided a LGPL replacement to OpenSSL.
Probably "yaml" ?
Thanks. Not sure if it was YAML or not - I remember either hearing or thinking that the format is question could handle a complete set of XML data, but YAML doesn't do attribute tags. Anyone know of a format that does (or a way to fudge attribute tags in YAML)?
Yeah, same here, also I found the configuration of FormAlchemy to be very ugly, I prefer the class-based approach of FormEncode. If you are looking at wtforms, be sure to check the mailing-list -- there's a link to the development version and associated docs, which has more goodies.
Well if you add a few parens, it's called Lisp. And with an additional reader macro you can probably get read of the parens (I think there's a scheme reader macro for that)
Try "[HAML](http://haml.hamptoncatlin.com/)".
This is stupid, of course the leading digit has this distribution. If you want numbers with a more normal distribution then look at the least significant digits. This is like using the most significant digits in the timestamp as a random number seed and then wondering why everyone's are so similar. 
Seems to be a replacement for rhtml rather than a generic XML replacement. Wouldn't mind something similar tho for DJango template tags.
You may be thinking of the pseudo-XML used by Docutils. It's a write-only format though, used for testing, because it can be ambiguous. Because it uses indentation for nesting, whitespace in the data can cause ambiguities. Example (search for "pseudo"): http://docutils.sourceforge.net/docs/ref/doctree.html
I'm not here to convince you that the GPL is the One True Way; however, I've found that every time I run into a GPL incompatibility, it's because the incompatible license is doing something rather annoying (or in some other cases downright evil). I don't like the OpenSSL license. It's not even so much the idea of mentioning the software I use, I would do that anyway. It's the spirit of things, the fact that their trying to control how I use their software.
Aren't there API-compatible readline implementations with pretty much any license one can think of?
You are not authorised to view this resource. You need to login. 
Not really, eh? Considering that OpenSSL has a BSD style license and that this 'issue' seems to only affect GPL'd software I'd say it has a lot of potential implications against a GPL'd kernel that wished to use these features. 
I've had some trouble translating queries with lots of joins with my limited SQLAlchemy experience before... SQLAlchememy seems great if you've never touched SQL, but there seems to be a bit of a learning curve otherwise. I'm still not sure what the workflow is to convert a big sql query with lots of joins is...
I'm not sure I understand. Do you want to use the SQLAlchemy object-relational mapper or just the SQL expression language?
Thanks. I've resubmitted the correct one.
It's basically a 4-clause BSD license plus trademark clauses (forks can't be called OpenSSL, which isn't particularly objectionable). However, the advertising clause was removed from the standard BSD license in 1999 and it is rather anachronistic for projects to still be using it. Personally I prefer [the ISC license](http://en.wikipedia.org/wiki/ISC_license) as it's small enough to paste into the header of source files. It's odd though to imply that the GPL isn't "weird-ass" as it seems to be growing substantially with every revision with more legalese to protect the original intent (to value the project over the code). I won't comment on the goodness of that intent; I just prefer simple licenses because licenses are legal baggage, not features.
Dint somebody link to DIP [web](http://www.diveintopython.org/http_web_services/index.html) and [soap](http://www.diveintopython.org/soap_web_services/index.html) stuff and get upvoted 100 times, already?
Not what you asked, but there are libraries to generate XML/HTML in Python using with blocks or functions to mimic the identation: http://www.livinglogic.de/Python/xist/Examples.html http://github.com/galvez/gae-rest/blob/258066f5e1a32c999e04a9313943fdfa8e64edd9/xmlbuilder.py
Yes.
indeed.
have you considered the fact that the GPL controls how you use software too?
You ASCII-centric individual.
The GPL affects *re*distribution, not what most people (and lawyers, etc) would consider use. If my website *uses* GPL software, I'm not required to release the source code that drives my website. Conversely: If I use python to build my website/service (something many people likely do), and I use it's OpenSSL module (something most people might consider otherwise innocuous), I must put the following on my website: This product includes cryptographic software written by Eric Young (eay@cryptsoft.com) Additionally, depending on who you ask, I might have to put it on my advertising space that I purchase from google or other sites as well. Fortunately, as others point out, python has a gnutls module as well.
Upmodded for introducing me to PEAK-Rules.
Nice. I ran into that situation a while back and this makes for a much cleaner implementation than manually splitting before basic unpacking.
I only vaguely understand what PyPy is supposed to be....is their goal to produce a compiler?
Check [this](http://slip.sourceforge.net/) out or [this](http://www.fiber-space.de/EasyExtend/doc/p4d/p4d.html).
SLIP sounds exactly like what I need. Thanks.
Thanks to schluehk who found this a couple of days after my Ask Python a little while ago. Unlike HAML etc. this has full XML syntax. So you get a human readable, non-ugly format that represents true XML. 
Looks very nice. I have a little experience with generating python (and then using eval() on it), and by comparison with Lisp's parentheses, it's kinda ugly to keep track of indentation. Any thoughts on generating SLIP?
What's wrong with SEXPR?
(p(a(r(e(n(s))))))
Is this even being developed anymore? It does look real nice, and easier/prettier than xml, but the last release was 2002.
It's not a bug, it's a feature.
Indent/dedent token stack. Push when indenting, pop when dedenting. The same way you'd do with open/close tags.
other issues i have had converting to 3.0 include: [Local variables unavailable for operation of list comprehension when using eval()](http://mail.python.org/pipermail/python-bugs-list/2009-March/073103.html) and [Form data encoding issues in cgi and urllib modules](http://groups.google.com/group/python-web-sig/browse_thread/thread/0ea8e71533382742)
Couldn't get the zip to open. Ran the source code, and it works. Saves out your slp as XML fine. Try to load in that XML though, and it crashes :'(
if I ever did crazy shit like that in code, I would deserve errors and more. 
Dang. Very nice idea.
Hey, this stuff is made by zedshaw :) The routing looks very much like Django. If I weren't a happy Debian-Exim user, I would give it a try.
Interesting. Pipes and aliases may very well be "so 1970", but at the same time, an SMTP server using a full-blown RDBMS just really rubs me the wrong way. It feels too heavy. EDIT: Actually, I've read more of the docs now and realise that this is supposed to be much more than a traditional SMTP server. An RDBMS is probably entirely sensible for some of the intended uses. This seems like a really innovative project. Zed Shaw is a pretty cool guy.
&gt; Now, this is nice, but the core logic: &gt; &gt; `tail -f /var/log/system.log |grep pants` &gt; Has somehow become obfuscated at the end - which is a shame, because it doesn't need to be. So instead let's build a really ugly class based system that obscures what's going on in our functions? Ugh. Overcomplexifying much? Geez, this is why Guido gave us decorators: Make one hideously complex class, then all of your functions become a simple matter of `@decorator` instead of some horrible monstrosities with `main` methods. 
Anyone been able to get the multiprocessing module to work in python3? The docs on python.org have examples which are clearly not python3 compatible; I'm curious if it is only the examples that are jacked up or if the module itself is not yet py3 compatible.
I had the same issue with IDv2+ tags using mutagen. They're just totally different than all the other tagging methods! Which is a pain in the ass if you a common API. I ended up using mutagen's EasyID3 class. It provides a similar API for MP3s as is offered by the other tag formats. def _load(self, filename): short_tags = full_tags = mutagen.File(filename) if isinstance(full_tags, mutagen.mp3.MP3): short_tags = mutagen.mp3.MP3(filename, ID3 = mutagen.easyid3.EasyID3) self.album = short_tags.get('album', ['No Album'])[0] self.artist = short_tags.get('artist', ['No Artist'])[0] self.duration = "%u:%.2d" % (full_tags.info.length / 60, full_tags.info.length % 60) self.length = full_tags.info.length self.title = short_tags.get('title', ['No Title'])[0] self.size = os.stat(filename).st_size
Exactly my sentiment! All I could think of, while I was reading this article, is how the simple coroutines transformed themselves into such horrible monstrosities with double the code lines and double the semantic density per line. **Horrible** -- and the author probably thinks he is being clever. And he is -- *too clever* for his own good.
Uh, multiprocessing is included in python2.6 and python3.x by default, so I should hope it is.
I've tried to implement the exmaples from the documentation with the print calls changed to the appropriate version 3 syntax and I have met no success. I'm still only a beginner at this python stuff, so I'd like to discern if the module even work before I go banging my head against the wall trying to use it.
Wow. I wonder if the issue is in the implementation or inherent in the .NET back end.
&gt; I wonder if the issue is in the implementation or inherent in the .NET back end. Likely IronPython. There's a *ton* of .NET code out in the wild, and a performance sink like that would have stood out well before now.
this has always annoyed by about Python implementation, we are constantly being told how primitive and slow the CPython implementation is yet everyone else is always slower, whether it's IronPython, Jython or PyPy (so far)
&gt; Significant claims have been made about the performance of &gt; IronPython, notably back at its inception in 1994 Excuse me? I don't believe that IronPython's inception could be in 1994, given that .NET didn't yet exist! I remember there was talk about in at PyCon DC 2004. (Ten years later.) 
This doesn't mirror my experiences. There are some areas where IronPython is *definitely* slower than CPython, but also areas (function calls, arithmetic) where IronPython is much faster. There must be some reason its running that slow.
That would be my guess as well. I remember doing tests early and even 1.0 and 1.1, .NET performed pretty darn well.
[Unladen swallow](http://code.google.com/p/unladen-swallow/wiki/Releases) is pretty fast, and is really just getting going...
US is an (fairly severe) optimization of CPython rather than another implementation.
It's not like MS could afford C#/.Net performing (noticeably) worse than Java.
That's true, but the goal is basically to replace most of the "core" with LLVM. I'd count it as a "rewrite of the core", at least if they achieve their goals.
Thanks - I've fixed the original.
If I remember right, Microsoft's JVM for their implementation of Java was faster than Sun's (although it might have been before hotspot).
That's the long-time goal yes, but US is already producing optimizations which have been folded (or could be folded) in the main CPython. As the US home page states it, US is a branch of CPython rather than a fork or a different implementation. It's much closer to cpython than stackless was, for instance.
No disagreement; the point is that if CPython wasn't slow, it couldn't be made fast. ;)
Well it could have been "pretty fast" and "merely" made faster (note: not the case)
Touche.
Your talking to the right guy.. :-P
me thinks perhaps it would be worthwhile for the author to look at how reflection is being used. I'm assuming a compiler would have to utilize that a lot. reflection is expensive in .net, and generally the first optimization is to do it once at startup. I thought about this for 10 seconds. time for a beer
+1 for use of "Overcomplexifying" which I now know is almost a real word. Oh, and I agree. 
Do you mean to say that Kamaelia is horrible or just the use of it in this situation? I was thinking about looking at using Kamaelia for distributed processing but I'm not sure now.
Work you piece of $&amp;*#, or he'll bite you.
NB: it's "methinks" not "me thinks". See http://www.etymonline.com/index.php?term=methinks. 
Whatever the case, it appears Multiprocessing isn't portable to Windows.. neither os.fork() nor os.getpid() are implemented.
Distributed processing? You mean the bus and its components can be used to distribute work across a set of nodes? If so, then maybe your intentions call for Kamaelia.
So the bottom line is that the main static cache is a string and a compile regex replace occurs before the content is sent in the HTTP response?
Yeah I'm on Sparc Solaris so I imagine I have my own set of headaches ahead of me.
curses needs control of the terminal, so you can't use it from the Python prompt. Sorry, you'll have to revert to old-fashioned edit-fix-run for curses development.
Licensing code snippets as GPL is just plain evil.
GPL has little evil power in purpose-made web development which doesn't get distributed. The idea is trivial enough to document and reimplement in a Free manner, should GPL be a problem after all.
&gt; There must be some reason its running that slow Well there's always a reason.
except when gFail occurs
This is just ridiculous. It shows the same old arrogance lisp people are typically accused of. Patterns are *not* about implementation, they're about communication, communication of intent. Take for instance the strategy pattern: Only if you realize that you may need different implementations of a particular piece of code, you'll come up with a separate (lambda) function by which you inject the functionality. But this *is* the application of the strategy pattern, only in terms of the functionality the language provides to you. There isn't any reason to dismiss patterns only because you use a dynamic language, quite to the contrary it makes sense to be aware of them and be happy that they're so cheap to apply. 
Can you tell us where we might expect IronPython to be definitely slower that CPython? I already know that exceptions can be slower, but they are sparsely used in my program.
oh the horror, how will I live knowing I made such a grave mistake. 
Well here's a performance comparison between IronPython 2 and CPython 2.5. You can see the areas where IronPython runs faster or slower than CPython: http://ironpython.codeplex.com/Wiki/View.aspx?title=IP201VsCPy25Perf&amp;referringTitle=Home My experience tends to be that code optimised for CPython runs slower on IronPython - because the performance profile is so different. If you write and optimise code for IronPython it is usually possible to get the same performance; which is why I find the figures quoted in the article so 'surprising'. Anywhere that IronPython is that much slower (with the exception of exceptions...) will be considered a bug by the IronPython team and should be reported on the IronPython mailing list.
Yes - I plan to submit a defect report once I've boiled it down to a concise example of the problem. Currently, the code isn't optimized for any particular flavour of Python - or indeed optimized at all.
I don't think he has a choice. The terms of the grant underwhich Everyblock exists says that when the release all their source code it has to be under the GPL.
You are correct, sir. Adrian
Check out shoebot, a crossplatform implementation of nodebox
Sorry you took it that way. I was only trying for a gentle correction. 
You don't appear to have watched the entire talk. I do talk about Patterns as communication, but that at some level the communication is no longer needed, e.g. we no longer talk about the "object oriented pattern" or the "function pattern". Also, the talk does not dismiss patterns, but suggests a different way of looking at patterns.
Yep, that's right... But I've always wondered about this... if you use a 10 line snippet licensed as GPL, you'll need to license your code as GPL too (if you distribute it, of course)? What about 5 lines? 1 line? Half a line? How much I need to "reimplement" to avoid it? 
no apologies, this is the internet. 
See [this](http://code.activestate.com/recipes/498110/) recipe for another take on memoization in Python.
or erlang
**Memoization**: *an optimization technique used primarily to speed up computer programs by having function calls avoid repeating the calculation of results for previously-processed inputs.* **Cache**: *is a collection of data duplicating original values stored elsewhere or computed earlier.* [wikipedia] so is memoization same as caching ? 
Are there any good tutorials for these random cluster-based things with IPython? I see them hinted at a lot but never actually used.
Memoization is a specific form of caching. There are examples of caching that cannot be considered memoization.
Absolutely! Or any number of languages that can support logical concurrency like this via green threads and channels. I think the interesting thing here is that the focus is strictly on using these capabilities to better design our programs for a concurrent world, rather than attempting to make better use of increasingly parallel or distributed hardware. I think a lot of people get turned off from Stackless once they find out that it doesn't help much to utilize multicore or write multithreaded code, but here's someone considerably respectable pointing out that it enables us to write cleaner designs.
The recent docs are pretty good.. http://ipython.scipy.org/doc/stable/html/parallel/index.html and then there's always the source..
&gt;Instead of hideous aliases files (that you never remember to update) Lamson uses friendly regular expressions and routing.
some people think its cool to get carried away.
So, I guess you could use memcached as a ... memoial service.
SQLalchemy (0.5 I think) now has it's own declaritive layer, so no need for Elixir. The writer does not seem to grasp that Elixir is simply abstracting the creation of the classes, mappings and table definitions. It does not do queries, he should look at the SQLalchemy's docs for that.
Does it? Is it easy to use? I never could get into SA because of the difficulty of writing the models...
Is there a website that provides a list of python modules with usage examples? As someone who just got into world of python, it is hard to find appropriate modules for certain tasks, especially if there is more than one for the same task. Thanks 
http://docs.python.org/library/ http://pypi.python.org/pypi
Which version of Django do those tutorials cover?
I love reddit, I literally was about to google Django screencast.
Does anyone else find this site just a bit cluttered, and rather unintuitive layout wise? Content is great, site has an odd layout flow imo.
Is it really the float? It works great for all the "important" parts (you know, like math). The author seems more annoyed with the default (and over-friendly) `__repr__()` and `__str__()`. They're not perfect, but they don't make me want to take up drugs; YMMV.
&gt; python strangely wants your argument to decimal be a str, not a float. Clearly the author has already smoked crack.
Let me get this straight... this guy is angry because the default string representation of float isn't exactly how he likes it? What does he expect? As one person pointed out, a full string representation of float is impractical (as it can go out hundreds of characters past the decimal).
If a float could expand to 750 characters in worse case, there should be a way to represent that -- there might be a true reason, like pickling (bad example), to do that. If repr() would do that, fine.
Python + crack = [RUN FOR YOUR LIFE](http://timesnews.typepad.com/news/images/python_1.jpg)
Living up to your username, I see.
you can represent that with a print, you just need to use the formatting string that the author even mentioned in his post most people dont want to see their floats out to 750 decimal places, so the default doesnt do that.
Replace (time.time()) with ("%0.7f" % time.time()) in his examples. WooHoo.
Inferior programmer criticizes a superior language.
Perhaps there could be a new approach: print(decimal.Decimal('%-1.-1f' % time.time())) ..where -1 would use the minimum number of digits without losing any fidelity (or something like that). 
Everyone's a critic.
1. User does not understand how floating point numbers are stored and represented by computers. 2. User applies his lack of knowledge and blames his language of choice. 3. User knows the answer, but calls it weird. 4. User writes a angry blog post, that's getting submitted to Pyddit. 5. User is a truly silly rabbit. 
Handy algorithm. I am working on a project that will require this, however I will probably have to refactor it to use the google app engine image module.
I'm considering attempting to learn Python (near zero programming experience), and I was looking at the MIT opencourseware intro to CS online course, [here](http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2007/CourseHome/index.htm). It seems that this course uses 2.6.2 versus the newest python version. How significant of a problem is this? Would it be best using a different tutorial or starting with a different language? 
they are quite a bit different, like a lot. it is rather simple to go from one to the other, but if you are just starting out i'd strongly suggest using 2.6 because libraries (in my case matplotlib, numpy, scipy) are not being ported to 3 for a long time. edit: also the default python on all, afaik, linux distros is either 2.4, 2.5 or 2.6. so if you want your code to run on all linux boxes you should stick with 2.6.
who cares about linux defaults?
I hope you're wearing your flame retardant suit.
or else you will be suitably flamed, retard. How dare you not like vim. :)
Just tagging on to this answer: Python 3.0 is mainly a release for library developers to get their code working 100% with 2to3. Users (and lazy library developers like me) should wait a little longer.
Wow, if I had known about `reload` 20 minutes ago, I would've been pretty happy. Gotta love when you learn about a feature because of someone's complaint about that feature.
reload on objects: http://www.philhassey.com/blog/2008/06/11/learning-python-by-reinventing-wheels/#comments
Yes, except that `reload` is fundamentally broken and it shouldn't be present in Python at all. The language shouldn't pretend to have crutches that let you stumble. 
1. Don't divide integers. Divide floats. Why? Ask mathematicians. Also: don't be an idiot. 2. When did you look at Tkinter for the last time? Looks pretty much native on Windows and MAC OS X. Improvements are coming with Py3k versions. Also: don't be an idiot. 3. Don't be an idiot. Also: maybe use def moar. 4. Don't be an idiot. 5. Why not use PERL or Ruby instead? This crap is obviously not happening to Python, so... 6. In the works, seriously, look it up. Basically you can always come up with something less annoying and submit it. Also: look at answer 4. 7. Same as answer six, both points actually. 8. Don't be an... you know what? Fuck you. &gt; It was hard coming up with actual meaningful things (...) I think this goes without saying. 
Am I the only person who thinks SQLAlchemy stinks? I'll elaborate: it's API is anything but discoverable (tried exploring it with IPython?). Layers of magic lead to more layers of magic. From the simple task of extracting information from relational data you have layers and layers of abstraction, some resembling python, others resembling SQL, with no apparent rhyme or reason. The documentation isn't digestible in small bite-sized pieces, if at all. More magic. And no supported core components to do the basic things most people might want a DB toolkit to help them with: migrations, understandable linkage between DBMS and filesystem objects, using the model specification to build forms .... Is it just me? It seems so bleeding obvious I seriously wonder what java-flavoured kool-aid the hip Python kids are drinking these days. 
easily digestible documentation: http://www.sqlalchemy.org/docs/05/ormtutorial.html very low layers of abstraction from SQL: http://www.sqlalchemy.org/docs/05/sqlexpression.html migrations: http://code.google.com/p/sqlalchemy-migrate/ easy to understand DB/filesystem linkage: mydata = file(row['filename']).read() model spec form automagicness (thought you didn't like magic?): http://code.google.com/p/formalchemy/
Reload is really useful, if Python didn't have it then what should it replace it with? The ability to alter things without restarting the program is really useful.
Geez. I can't believe my name is still on there. I donated $25 probably 3 years ago.
Maybe I'm just dense: to me all the documentation seems to be written with the assumption of a strong knowledge of sqlalchemy to start with. Maybe it's just the doctest style they're written in, which seems to waffle about showing off interfaces while seldom demonstrating anything practical, much less non-trivial. In particular, I remember struggling to understand how to combine low-level SQL and ORM, and how to apply aggregation functions. Exploring the interfaces with IPython didn't help one bit, which is the main part I object to. Formalchemy's actually where I came to hate sqlalchemy: I tried to extend it for better support of relations, but found myself chasing unpublished interfaces through a maze of object hierarchy just to find out what object the remote end of a relation might be, just so I could populate a select box or provide a link to a view of all related objects via a backref.
feel free to post trac tickets regarding iPython, the full API is now documented using Sphinx and docstrings seem to work fine within iPython as well. extremely old versions of SQLA (over 2 years ago) had some incompatibilities with ipython.
How many of the dependencies need to happen at the top of the source file? There's a fairly standard tactic to delay certain imports until it's needed, which could help reduce that startup delay time. http://mail.python.org/pipermail/python-ideas/2008-October/002207.html http://mail.python.org/pipermail/python-ideas/2008-October/002212.html
One thing I like about Python is the community. There's less elitism it seems like, and a lot of generally helpful people. Seriously, did he rape your mother while he was writing this or something? You're awfully defensive, and unnecessarily derogatory. Sure, you have valid point, but there's a way to have a civilized discussion, and there's a way to just be a fucking troll. You obviously only know the troll method.
Agree with most of your statements, but modded down because you're being an asshole.
You could only find 8?
&gt; Reload is really useful, if Python didn't have it then what should it replace it with? Nothing. You have to organize the workflow s.t. `reload` is not needed. &gt; The ability to alter things without restarting the program is really useful. Absolutely! If `reload` *could* work in Python this would be very nice. However if your code contains a `reload` I'm pretty sure I know a location where your program is buggy. BTW `reload` is nowhere used in the Python stdlib and I would be quite surprised if it was used in any serious Python project.
I have an MSN bot and rather than restart it each time I make a change to the message handler I send it a command to reload and it does. What do you mean by the following? &gt; You have to organize the workflow s.t.
Yeah, I'm basically burning my comment karma here. Hopefully my trolling week is over soon. On more serious note: I'm trolling an idiot, who writes bullshit comments that will be re-posted by anti-python crowd for next 1k years. So everytime I say ,,why not use Python?'' someone will answer with ,,python division sux! regexp not part of the language!!!111 and it was written by one of you, python users!'' It makes me sad. Because, you know, I try to use Python at work. In a giant corporation. And these kind of posts are not helping.
Thanks!
i was just giving a reason. to answer you question, i do, i have to ssh to a core5 cluster all day it uses 2.4
Yeah, giant corporations are often swayed by Pythonistas calling nay-sayers "idiot", and retorting with "fuck you". That work a lot in your big business?
s.t. is short for "such that"
Ditto. I came to Python from a Lisp/Slime environment and building up a program in a Python buffer in emacs is a wonderful thing.
Might want to read [3.4.11. Special method lookup for new-style classes](http://docs.python.org/reference/datamodel.html#new-style-special-lookup) then. New-style classes can be a real pain in the ass if you're using special methods incorrectly. e.g. `container.__contains__('foo')` would work perfectly with LameContainerNew but will fail miserably if you have `__iter__` instead of `__getattr__` or `__contains__` implemented. As for old-style classes... just forget them already.
Holy crap, up freaking voted for explaining the difference between unicode, utf, etc - I never understood that before. Recommended even if you're not using python. Read!
Gill Sans
&gt;This site is optimized for Lynx just because fuck you. &gt;I’m told it also looks good in graphical browsers. It does look good in graphical browsers as I must admit.
from 0.96 if I am not mistaken...
Looks really good Mark. I'm not sure the UTF-8 was in a big enough font though, you may want to fix that. :-)
Might have to steal his CSS. Even the choice in font size is to my liking.
The ternary operator has been in since 2.5, I believe. People still complain about Python not having one, though, so it seems like it hasn't caught on all that well.
Yes, check out [tut](http://www.sqlalchemy.org/docs/05/ormtutorial.html) Let's forget about Elixir for a moment and look at SQLalchemy's ORM. Loosely defined, an ORM maps records in tables to objects. This means you had to tell SQLalchemy what the table looks like (Table definition), what the object it represents look like (Class definitions) and how these two relate to each other (Mappers). Elixir simply made these three steps more intuitive or declarative :) So yeah, it simpler, and it rocks. I have huge respect for the SQLalchemy devs, their code is beyond awesome.
"ternary operator" means an operator that operates on 3 operands, just as "binary operator" and "unary operator" are operators that work with 2 or 1, respectively. C has only one ternary operator, the conditional operator. So in C, people started referring to it as *the* ternary operator. But that really has no actual descriptive meaning when what you're really talking about is a "conditional expression".
Uh, thanks for the definition, but it's not news to me. I'm not shooting for pedantry points here; I was simply referring to it by its most common name.
is awesome!
Are they? I usually stumble upon ,,it's not serious enough, look at this google hits for 'python sucks' -- it's not mature enough for our business!''. This guy is putting bullshit up on the web for everybody to see forever. And he is a Pythonista. My manager won't get the implications of integer division returning integers. He will see that after 20 years of development Python is not ready. This makes me angry. And the wave comes back when people start listing Python no-no's reasoned by things fixed years ago, as seen recently in proggit thread that arose after GvR's TCO post. This makes me utterly sad. Anyway ending the flames now, have a good weekend. I will.
It was strange, reading about how UTF-16 isn't exactly ideal, and how UTF-8 is so much better, and then this utter bullshit: &gt; In Python 3, all strings are sequences of Unicode characters. There is no such thing as a Python string encoded in UTF-8, or a Python string encoded as CP-1252. "Is this string UTF-8?" is an invalid question. UTF-8 is a way of encoding characters as a sequence of bytes. If you want to take a string and turn it into a sequence of bytes in a particular character encoding, Python 3 can help you with that. If you want to take a sequence of bytes and turn it into a string, Python 3 can help you with that too. Bytes are not characters; bytes are bytes. Characters are an abstraction. A string is a sequence of those abstractions. In Python (regardless of the version) all unicode strings (that is 'all strings' in Py3k) are stored in UCS-2, as defined in [PEP 100](http://www.python.org/dev/peps/pep-0100/). UCS-2 is a two-byte fixed width encoding, that looks almost exactly like UTF-16, except that it treats surrogate pairs as distinct characters. s = "\U000030c4" # KATAKANA LETTER TU print(len(s)) # 1 print(s.encode('utf-8')) # b'\xe3\x83\x84' s = "\U00010000" # LINEAR B SYLLABLE B008 A print(len(s)) # 2 print(s.encode('utf-8')) # b'\xf0\x90\x80\x80' Note that while `len` reports two characters, the UTF-8 encoder correctly recognizes them as a surrogate pair and encodes them as a single code point. OK, note to myself: never touch 'Dive into Python' or anything else having Mark Pilgrim's name on it. 
Or you could just, you know, send that info to Mark (if he hasn't done tests beyond the BMP he might not have noticed). And you're not entirely right either -- though more than he is -- since there's a compile-time switch to use UCS-4 instead of UCS-2: $ python3.0 Python 3.0.1 (r301:69556, May 22 2009, 11:34:35) [GCC 4.0.1 (Apple Inc. build 5490)] on darwin Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; s = "\U00010000" &gt;&gt;&gt; print(len(s)) 1 &gt;&gt;&gt; print(s.encode('utf-8')) b'\xf0\x90\x80\x80' &gt;&gt;&gt; (I note that on macports the switch is only available as a variant from 2.6 onwards)
Cheers, never encountered that before. How would you suggest the ability to alter code while a program runs and to be able to make user of that code without restarting the program?
As I see it, the problem is deeper than the question of which implementation (UCS-2 or UCS-4) Python uses. The notion of a 'string as a sequence of abstract characters' is wrong. Because must be represented as bytes somehow, so all he said about different encodings, including *"Four bytes? For every single character‽ That seems awfully wasteful"* about UCS-4, applies to that representation as well. He could have said that Python provides an abstract interface that hides the implementation details (which, as we see, is untrue for most binary distributions), but spinning *abstract bullshite* is just wrong, especially in a book oriented at novice programmers. Because then, when the abstractions leak (and they always do), something terrible might happen! By the way, AFAIK some Lisps in fact have strings implemented using 'abstract' characters. I.e. each string character is a pointer (8 bytes wide on x64) to a corresponding symbol, like `'CHARACTER_KATAKANA_LETTER_TU`. Which in turn is basically an interned string, in the very same representation (exploding heads ensue).
Upvoted for use of the interrobang‽
&gt; The notion of a 'string as a sequence of abstract characters' is wrong. Because must be represented as bytes somehow Yes, but that's an implementation detail, it's not supposed to leak out to the user (except as you mentioned, it does in the default build config).
&gt; This site is optimized for Lynx just because fuck you. Best demonstration of class, style and boldness. I like this guy. This is how all of the web should be.
SQLAlchemy is the first ORM I've used where I haven't felt held back compared to writing SQL. It's been the backbone of a recent medium-sized project and I've really enjoyed working with it. I've found the documentation pretty comprehensive compared with other projects.
Agreed! I have never had to code anything that deals with encodings but I've read many introductions into the subject but never felt I really got it. Mark Pilgrim does good things.
IronPython takes 10 seconds just to start!? Lol. Very Microsoftly. It's also considerably slower and scales worse. Very Microsoftly, again. Also, awesome performance for Jython: it starts slower than CPython (most likely due to the enterprise bloatware it runs on), and seems to execute somewhat slower, but then it scales better than CPython when there are lots of objects to handle.
funny thing is, it is not really optimized for lynx - with lynx it even looks buggy in some places. In w3m in contrast, it looks just nice.
Well I wasn't specifically trying to correct you, just point it out for the other readers. But *now*, it sounds like you're saying "the ternary operator" is a reasonable way to refer to Python's `if ... else` expression construct, which is straight nonsense. That's not it's most common name -- nobody calls it that. It's not even an operator. If you're saying Python has "the ternary operator" it sounds like you're saying it has the `?:` operator, which it doesn't.
&gt; `&gt;&gt;&gt; s = '深入 Python'` So, what character encoding does Python expect a .py file to use? If you're going to write a string like the one quoted above, I'm assuming your text editor would have to encode it in the way Python's expecting, or Python would have a content-type header on its source files?
Answering my own question: http://docs.python.org/reference/lexical_analysis.html#encodings
thank goodness someone took the time to write this, I've been spending too many hours trying to grok how this can help me and/or what client lib to use to talk to it. 
I mention it here: http://diveintopython3.org/strings.html#py-encoding
Well that's a rather harsh and unnecessary conclusion, but whatever. I stand by my statement ("A string is a sequence of those abstractions") precisely because this IS an intro book. I predict that most of the people who will read this chapter will go into it thinking that strings are sequences of bytes, since that's what Python 2 did. You ABSOLUTELY MUST break yourself of that way of thinking about strings, or you'll never have any success coding in Python 3. Files, web pages -- any source of "text" is going to come to you in bytes (if you're doing it yourself) or strings (if a library is handling the conversion for you), and you MUST know what you have. Everything I've read from people who've tried porting nontrivial code to Python 3 suggests that the bytes-vs-strings issue is the #1 migration problem. In Python 2 it was dangerously easy to use strings when you really wanted Unicode strings, and then you scratched your head wondering why your code raised a UnicodeError exception when somebody typed an umlaut. Are there corner cases? Yes. Does the abstraction leak? Yes, sometimes it does. But you're WAY ahead of the curve here. I have to stop somewhere, or readers will just give up. I'll tell you what: if you can manage to write up what you just said, but without all the dick waving and condescension, I'll point to it from the "Further Reading" section. Otherwise, you know, have fun feeling superior to everyone.
[Officially, it appears to be referred to as a conditional expression](http://www.python.org/dev/peps/pep-0308/), but from the discussion sections, "ternary" operator is referenced quite a few times. It seems fairly common in regular discussion.
Excellent chapter. Very clear explanation of strings vs. bytes. I have the nitpickiest nitpick in all of nitpick-land: &gt; Unicode represents each letter, character, or ideograph as a 4-byte number, from 0–4294967295. Due to the way surrogate pairs work, Unicode is limited to 1,114,112 possible code points (17 planes of 65,536 code points). Unicode could fit in 21 bits, if that was a convenient size. Very minor point that I'm sure you're aware of, and probably too arcane to mention here. It just makes Unicode sound a lot bigger than it's ever intended to be.
It would be hard to "steal" it, since it's MIT-licensed, but you're welcome to try. :) Edited to add: I'd recommend checking it out from the hg repository, since that version has comments and whitespace and stuff.
Cool, thanks.
Is that standard in computers?
Not really, most likely a Mac font. Most Mac users like to use fonts that no one really has. 
Came here to say the same thing. The layout of the code examples just work a lot better in w3m. In Lynx the body of the text is a little easier to read but I'd say w3m gives a nicer experience over all here.* Looking at in in a graphical browser, did anyone else feel like the letter-spacing was slowing them down? I'm not sure if it was because I had to move my eyes so much further to finish each word, or because my brain was interpreting the space between the letters as actual spaces. *Maybe I wouldn't think this if I'd read the entire article in both rather than just skimming it. I just didn't really feel like reading the whole thing three times in a row. EDIT: you're right about Lynx seeming to have a few bugs. In Opera and w3m, section 3.1 "Diving In", has displays the code example like: s = '深入 Python' ① But in Lynx this becomes: s = '深入 ython' Does anyone have any idea where the 'P' has gone?
Fixed in http://hg.diveintopython3.org/rev/7aa1a8eb6401 Thanks.
I didn't know Python had grown one until [Simon Willison (my tech editor) pointed it out to me on Reddit](http://www.reddit.com/r/Python/comments/7syw8/dive_into_python_3_please_critique_this_code_that/c07bm9v?context=2).
I have 4 years industry experience programming in C. I've never programmed in Python. Should I try to learn Python 3 first or Python 2? 
That depends on what you're going to do with it. I'd recommend Python 2.x now, because that's what most production installs have; but if it's for your own enjoyment, perhaps Py3 would be good.
By your logic, there also is no such thing as a Unicode character, period. Nor is there any such thing as a signed integer. Nor is there, well, _anything_ in any programming language except sequences and structures of bytes, and anyone who talks about anything else is spewing "utter bullshit". Right? But maybe -- just maybe -- we can accept that the underlying binary representations used by compilers, interpreters, VMs and the like don't necessarily mean that the abstractions they represent don't exist, or are false. So yeah, under the hood Python's using some bytes to keep track of your Unicode characters. But extrapolating from that to thinking "a Python 3 string as a sequence of bytes" is full of so much fail that it's not even funny.
Ah, too bad, it's a nice font...
The vast majority of Python code out there is Python 2. I'd start with Python 2. The switch to Python 3 will be easy. I recommend starting with IBM's [Discover Python](http://www.ibm.com/developerworks/views/opensource/libraryview.jsp?search_by=discover+python) series. It's nine articles that will get you up and hacking in no time. After that, I recommend reading Dive Into Python. 
Firstly, the fact that you are unfamiliar with the schools of thought other than the one you belong to doesn't mean that they are wrong, does it? Here is the quote from Alexander Stepanov's lectures, that on the first glance seemed to *me* to be an utter bullshit, but then it kind of made sense: &gt; But what do we mean by a type? This question is one of the central questions in programming. We will be talking about it throughout the course. But we will start now with the most general definition: **a type is a method of assigning meaning to data stored in computer memory**. This definition is important for us because it states that types have existence irrespective of the programming language that we use. Even if we program in assembly language we assign meaning to different sequences of bits in memory. This meaning is usually expressed in operations that we define on them, the properties we expect them to obey and the mappings from them onto the physically observable values through input/output. The types that our programming language provides for us are just approximations to the full meanings that we see in the bit patterns of our applications. It is important to remember this so that we do not drive our designs by the limitations of the language but come up with the intended definitions of types and only then map them onto the programming language. In other words, design your data structures and algorithms first and only then map them into a programming language. Do not start with inheritance or templates but with linked lists and hash functions. Think in assembly language or C and then implement in a high level language such as C++. By the way I encourage you to go and read [the whole of the lectures](http://www.stepanovpapers.com/notes.pdf), it's extremely enlightening, not by the small part because of this viewpoint, quite unorthodoxical for the reader more accustomed with a platonic view, where there are Abstract Types and their flawed real representations. Really, how can one call himself a programmer if he avoids embracing the real nature of the 32bit integer? Secondly, you are wrong in this particular case. Unicode character **is defined** as an unsigned 32bit integer, period. It **is** the abstraction we are talking about. Why try to make it more abstract than it really is? EDIT: so yes, I think that for a programmer there should not exist such thing as a signed integer. 
OK, let's try again with a different example to try to get it through your skull. In the standard C implementation of Python, you can iterate over the keys of a dictionary. The dictionary is a hashtable. CPython's documentation warns you that the keys do not have a defined ordering. Suppose we were talking about that instead, and that what you'd done was go on about details of the hashtable implementation which let you make very good guesses about the order in which the keys will come back when you iterate over them, and said that the idea of undefined key order was "bullshit" and started trying to slap people with your dick for telling you that it's not a good idea to think of them as having some particular order. You'd be wrong, of course, because even though you can -- with knowledge of the underlying implementation -- make good guesses about the ordering, it's a really bad idea to try to do so in a real-world program and an even _worse_ idea to base your mental model of a dictionary on this notion. What you're actually doing is no different -- you're taking an accident of implementation that people should not be relying on or basing their mental models on, and using it to argue against something which is not an accident of implementation and which is a reliable basis for thinking about Python programs. Yes, under the hood in C the actual bytes in memory which back your string are UCS-2 in the default implementation, but _thinking about Unicode strings as sequences of bytes in some particular scheme is a faulty mental model which leads to errors_, and you don't seem to be able to get that through your head. &gt; Really, how can one call himself a programmer if he avoids embracing the real nature of the 32bit integer? I suggest you sit down and get your ass reamed by the people who think MIT brought on the apocalypse by switching away from Scheme. Since you're getting so high and mighty about demanding people be open to other ideas, you might want to be exposed to the idea that computer science has little or nothing to do with the state of some circuits inside a computer.
Indeed. Best explanation of that whole mess I've heard yet. Kudos to Mark! And regardless of fishdicks' comments, it really is very helpful to think of strings as sequences of abstract characters, even if they aren't technically implemented that way.
&gt; IronPython takes 10 seconds just to start!? Lol. Very Microsoftly. For whatever reasons IronPython doesn't create bytecode files or uses existing .pyc files. So the whole code generation process is getting started over and over again. If your script loads lot of modules initially you might rather wait 30-40s than just 10. 
OK, I think I owe you an apology for the harsh tone, because it's mostly due to my own fault: when I got hooked by the somewhat provocative title I didn't realize that I'm not in the target audience, so after reading the text I found exactly one thing I "didn't know about strings", the statement that Py3k allows you to treat strings as being composed of abstract Unicode characters. I knew it was wrong, yet I spend some more time refreshing my knowledge on Unicode, searching for the relevant PEP, and constructing the proofcode. By that moment I was not in the most humorous of my moods, so to speak. Nevertheless. I'm still true to the idea that putting misinformation in a tutorial is wrong, no matter how convenient it may be at the time. And what you have written is dangerously close to misinformation. I think that you could have just replaced the phrase "Characters are an abstraction" with a "Characters should be regarded as an abstraction", and then add a little paragraph saying something along the lines of "On a side note, of course strings themselves have to be represented in memory somehow, there is no magic going on here. Effectively working with text, as opposed to storing it or transmitting it over a network, requires some compromises, so in fact Python strings are currently composed of two-byte characters (almost but not quite in the UTF-16 encoding), just like Java or C# stings, or even C++ `wstring`s are. However it's impossible to access the raw bytes of a string by any convenient means, so everything you do goes through `encode` and `decode` methods described below". Do you think the reader would be confused by that? I am not, I think that in fact he would be quite reassured: there is no magic going on, it's all the same as in other languages, he was trusted to peek at the implementation details, the author is not holding anything from him. Detailed explanation with the examples akin to the one I've provided is not necessary: chances that someone happens to encounter the difference between UTF-16 and UCS-2 without knowing what they are doing (like, writing an application that handles Really Ancient Greek numerals (that were before the Ancient Greek numerals), or a mahjong/domino game using corresponding Unicode characters (and that's a perfect sample of the things above the BMP)), these chances are effectively nil, I reckon. It's not the leaky abstraction I'm against really, it's the substitution of faith in place of knowledge, however incomplete that knowledge might be.
About the dictionary -- I agree completely. But then... &gt; thinking about Unicode strings as sequences of bytes in some particular scheme is a faulty mental model which leads to errors There is one error we have seen: that the default build of Python behaves not in the way naive programmer, not having a clear mental model of actual string representation, might have expected. Care to hint at errors that can sprout from having such a mental model? Note that I'm not saying that the UCS-2 encoding of strings should be regarded as something immanent to Python, I'm saying that the notion of an encoding of actual strings should be understood. Also, please read my reply to Mark. &gt; I suggest you sit down and get your ass reamed by the people who think MIT brought on the apocalypse by switching away from Scheme. Since you're getting so high and mighty about demanding people be open to other ideas, you might want to be exposed to the idea that computer science has little or nothing to do with the state of some circuits inside a computer. Is it your way of telling that you've read your SICP tonight? Surprise: I did, too. Not everyone opposing the ideas you hold high is a moran, y'know. 
http://diotavelli.net/PyQtWiki/PyQtLicensing PyQT is not freely usable. You must purchase a commercial version or release your source as GPL.
Joel Spolsky also has a really good, concise guide to unicode: http://www.joelonsoftware.com/articles/Unicode.html
I love MP and his work, but where are you getting class in that statement? Very bold and stylish for sure, but class?
Not just that, it's also not likely that in the future they will release the bindings as LGPL like the rest of the toolkit. We *really* need some official py bindings for Qt, please Nokia?
See the follow up where IronPython hammers CPython and Jython. :-) http://www.smallshire.org.uk/sufficientlysmall/2009/05/22/ironpython-hammers-cpython-when-not-mutating-class-attributes/
Agreed on both points. This is one of the biggest reasons why I'm sticking with pygtk for now.
Well, they could just buy Riverbank Computing, no need to redo all that work.
Internet class.
I've heard cherrypy has some esoteric race conditions that arise. sometimes. can anyone confirm/deny this?
It was a surprisingly good read, until the point where he decided to "fix" the benchmark to make IronPython look good.
Not at all. It explained something about the nature of the python language that might not be obvious to many people — one that can affect performance dramatically. The original author agrees that this is a good fix to the benchmark.
No... the really should redo it in a Python way.
I guess that depends on if you think that paying for something you're going to make money on means it's not freely available.
You mean where he fixed the performance problem and checked it into IronPython? So fixing performance problems is bad then?
Well, the 2to3 tool will handle that.
Have you not heard of the free as in beer vs the free as in speech distinction the open source community regularly deals with?
Bloody brilliant. I'll be using this for sure.
Author here. Delayed imports is certainly a valuable technique; we use it for rarely-needed services. On the other hand, assuming that loading and displaying your application will briefly touch most of the code in your system, I think it's a better experience to show a loading progress bar than to make every operation that touches a new module 'hitch' while it imports. In IMVU specifically, we're driving for a clear indication of loading progress, followed by instantaneous display of the UI. Does that make sense? 
Smells a bit like monads!
wtf is wrong with nesting generators?
(author of both here) It depends on what you want to do. If you're just learning a language to learn a language, learn Python 3. If you're learning it in order to work on somebody else's code (for work or whatever), learn Python 2, because that's what 99.9% of the world's Python code is written in. If you choose Python 2, I can only recommend "Dive Into Python" chapters 2-7, 13-15, and 17. The rest of the book is horribly out of date. If you choose Python 3, "Dive Into Python 3" chapters 1-8, 10, and the first half of chapter 13 are done and up-to-date. The rest of the book -- especially the chapter on file I/O -- is still only in my head. The Python subreddit is an awesome place to ask specific questions. comp.lang.python ( web-accessible at http://groups.google.com/group/comp.lang.python/topics ) also has many Python experts, but it can be a bit overwhelming.
someone needs to package VIM with all these plugins installed and configured and ship that
&gt; if a == None: Really common. None is a singleton, so you can (well, actually, have) to compare to it like ‘if a is None‘ or ‘if a is not None‘ If `a` is an object that overloads `__eq__` this might be exactly what you want. &gt; if type(obj) is type(1): This is killing kittens, there’s a builtin function for this purpose, it’s called -surprise- instance(object, type). For example instance(123, int) When you know the set of possible types in advance `isinstance` is overkill and brings your performance down. `type(y)` requires a single lookup of an internal parameter and is much faster.
I usually never check for None explicitly or a list evaluating to False, but instead just say `if not foo:` everywhere. Am I Doing It Wrong?
No! It's better style, IMO. 
&gt; When you know the set of possible types in advance isinstance is overkill and brings your performance down. type(y) requires a single lookup of an internal parameter and is much faster. Yes, but the clients of your code are then prevented from passing in a subclass of y. 
Here is why I think thats a bad idea: * its not really hard to get these plugins * there are sometimes better plugins than those listed * sometimes small scripts will do the job of these plugins because you may end up not using all the features of the plugin * Configuaration is very user-centric. what worked for this guy may not make sense for others. Plus the configuration parts are quite simple. * Its also fun making VIM the way YOU want it to be. * And Removing the plugins and their corresponding config is sometimes even more painful than installing them. 
Django seems to be a strict superset of everything pod provides, including the interface to the lightweight sqlite backing store. 
I support joe90210. the packaged version is not perfect, but it's very easy for newbie to start his VIM journey. when the journey goes on, One can update, personalize, or do whatever he want. For example, I use some Web Browser and can't transfer to Firefox. I do know Firefox is free, a lot of plug in, flexible..., but there is some feature I can't live with must be install and customized some Firefox add on. at last I got one Packaged Firefox. and it's just the beginning. I use Firefox as main web browser now, changed almost all add on of that Packaged Version. 
Occasionally programs deal with lots of constant objects and those might not even be manually generated. Then you might think twice about using `isinstance` once you watch the profiling log.
Great idea. So great, in fact, that Debian-based systems already do that. Use "vim-addon-manager" and then run (*not* as root) "vim-addons install taglist" (or whatever).
The URL is broken, clicking the article leads nowhere unless you hit the comments.
Pretty much the only time I test "foo is None" is with default kwargs, something like this: def doit(foo=None): if foo is None: foo = {}
How good is the concurrency with this if it uses SQLite? There was a discussion on reddit about the quality of the SQLite library from Python and somebody mentioned that it was a bit slow, slower than necessary, when multiple processes accessed a single DB. I'm always looking how to adapt certain new libraries for web development. That's why I ask. 
&gt; Am I Doing It Wrong? If that's what you want... class A(object): def __nonzero__(self): return False a = A() assert not a 
I have to problem paying for software. But I want to know the price before I invest time. There's no price mentioned on that page. And I searched for "price" and "pricing". Nothing there. Just another one of these strange licenses I really hate. 
d = dict(a=1, b=2, c=3) then... open('foo', 'wb').write(repr(a)) then later... d = eval(open('foo', 'rb').read()) What am I missing?
Well I'm sure surprised to find out vi can do code completion. I like vi as much as the next guy--for doing stuff like editing apache configuration files. But for programming, I gotta go with NetBeans. It does everything, and it's easy to configure and maintain. 
I'd use shelve. http://docs.python.org/library/shelve.html
The fact that that code is roughly equivilant to: `mysql_execute("SELECT * FROM table WHERE field = " . $_POST['value'] . ";");`
Isn't this what a database is for?
The only thing I can think of that would stop this working would be if you had an instance of a class or a function in the dictionary. Like this d = dict(a=str,b=len) open('foo','wb').write(repr(d)) d=eval(open('foo','rb').read() {'a': &lt;type 'str'&gt;, 'c': &lt;built-in function len&gt;} SyntaxError: invalid syntax
I have tried all mentioned plugins. They worked fine except VimPDB. I'd also mention the integrated spellchecker, which is perfect. From my vimrc: * setlocal spell nospell * nnoremap &lt;silent&gt; s :setlocal spell spelllang=en_gb&lt;CR&gt; * nnoremap &lt;silent&gt; S :setlocal nospell&lt;CR&gt; ("s" activates the spellchecker, "S" removes it) 
Go go python science!
Yeah, well, who wants to type that? If you want to get all industrial strength about this use bsddb, then it's: table['field'] = value And mysql, I mean, that's gotta be overkill for the domain this guy is suggesting this be used for. You're going to want to write an int; it's going to want to run recovery (well, so is berkeley (but at least it's in process)). Whatever.
Yeah I was going to use cPickle but I figured, it's a reddit post, go for brevity. _And no one will notice_. Laf
My point was that it's a massive security hole, just like the PHP segment.
Well FileDict like everything else has issues with classes and functions; it runs the shit through pickle, yes? Or has this changed with 3.0? Haven't had the chance to get into 3.0 I'm sorry to say.
 &gt;&gt;&gt; pickle.loads(pickle.dumps(str)) [2] &lt;type 'str'&gt; &gt;&gt;&gt; pickle.loads(pickle.dumps(len)) [3] &lt;built-in function len&gt; Works fine (this is python 2.6)
See the other comment in reply; actually it isn't.
Going from memory now, always dangerous, but if the class is defined in another module or something then pickle fails. Maybe it's still useful for trivial cases, I don't know, but I recall being terribly disappointed with pickle when wanting to do serialization stuff.
This page? http://www.riverbankcomputing.co.uk/commercial/buy
Let's see... you're missing the parts where it can be accessed by multiple processes concurrently, has acidity, and performs okay as the size of the database grows. I'm guessing the author didn't know there are already several packages in python that provide this sort of functionality, but his solution is definitely a better than what you suggest.
&gt; but his solution is definitely a better than what you suggest Depends on the application. And as you say, we've been there, we've done that. Thanks for reminding me why I should never post in this subreddit. It's because of douchebags like you.
I thought the exact same thing. But this implementation does have the advantage of being Thread/Process safe which shelve doesn't.
It must be difficult to live in a world where everyone who disagrees with you is a douchebag.
Stay just the way you are.
Why using sqlite here? I think it is better to try persist dictonary in berkeley db hash, isn't it? 
a database supports fancy queries, which are not needed in many applications.
berekeleydb and tokyo cabinet/tyrant are worth considering for this, too. (both string/string therefore the need for shelve.py if you want arbitrary values)
...or for a DB backend, [shove](http://pypi.python.org/pypi/shove/).
&gt; FileDict is a dictionary interface I wrote, that saves and loads its data from a file using keys. Current version uses Sqlite3 to provide consistency, and as a by-product, acidity. It's already using a database... why not just use SQLite directly?
Um, because it's much easier to write foo['bar'] = 'moo' than it is to write any sort of SQL? Because foo['bar'] = 'moo' is agnostic about how it's stored and using SQLite directly isn't?
There are a couple annoying bugs in the official release. This version has fixes for them: http://github.com/dziegler/clevercss/tree/master
I have been accused of many things, but having an abundance of class is not among them.
The clevercss.py script does not get installed on the path and is not executable. But looks like a cool tool regardless. 
Not free enough? 
I read through the intro -- lamson doesn't store email in RDBMS, but in regular files in Maildir format (or any other format supported by python's mailbox package). This thing looks pretty cool. I might give it a try. 
You're right. But the same thing goes for pickle (and thus shelve) too. You have to trust the source, as pickle too can be used to execute arbitrary code. It's just a little bit more complicated.
Summary of the article: * ctypes is easy to use * &lt;using the 'from library import *' anti-idiom&gt; 
&gt; The vast majority of Python code out there is Python 2. I'd start with Python 2. The switch to Python 3 will be easy. I recommend the opposite of StringyLow. Learn Python 3 first and the switch to 2 will be easy. Sure, the majority of code out there is Python 2, but there's not a lot of difference between *well-written* 2 and ordinary 3. Learning 3 first teaches you the good idioms like, "Separate strings from bytes strictly!" "Use `x in my_dict` not `my_dict.haskey(x)`" etc. You can pick up the Python 2-isms pretty quick. If you know C, then you already know Python 2's `%` formatting of strings, for example (it's stolen from `printf`). Learning Python 3's more powerful and flexible `.format` formatting first is a better way to go about it. Besides, most of the good 3 stuff can be done in 2.6 also (for example, you can use a `print` function instead of a `print` statement by using `from __future__ import print_function`).
Yeah, I'm pretty impressed with it too, did you see Zed's recent blog post with project ideas? I've been trying to think of cool things to test it with myself. If you build anything cool with it, do let /r/python know! :)
You are missing the part where he is using [newLisp](http://www.newlisp.org/) as an example for this. Running newLisp from inside Python. (I'm a [long time fan](http://www.alh.net/newlisp/phpbb/viewtopic.php?t=1630). :-)
Or bsddb which is a core package http://docs.python.org/library/bsddb.html#module-bsddb The documentation sucks: http://svn.python.org/view/python/trunk/Lib/bsddb/dbshelve.py?revision=66088&amp;view=markup
It is still not among them.
I got the following message when following your link: &gt; You have been banned from this forum. &gt; Please contact the webmaster or board administrator for more information. Interesting given I never went there before. I suppose it's an attempt by Lispers at keeping their club exclusive.
In the paragraph about "compound field names" you give the following code: &gt;&gt;&gt; import humansize &gt;&gt;&gt; si_suffixes = humansize.SUFFIXES[1000] &gt;&gt;&gt; si_suffixes ['KB', 'MB', 'GB', 'TB', 'PB', 'EB', 'ZB', 'YB'] &gt;&gt;&gt; "1000{0[0]} = 1{0[1]}".format(si_suffixes) '1000KB = 1MB' Playing upon that, I wanted to print out a list of all `1000X = 1Y`'s, so my first try was: &gt;&gt;&gt;&gt; for i in range(len(si_suffixes) - 1): ... print("1000{0[i]} = 1{0[i+1]}".format(si_suffixes)) But that gave `TypeError: list indices must be integers, not str`. After some fumbling around I got it to work with: &gt;&gt;&gt; for i in range(len(si_suffixes) - 1): ... print(("1000{0[" + str(i) + "]} = 1{0[" + str(i+1) + "]}" ).format(si_suffixes)) ... 1000KB = 1MB 1000MB = 1GB 1000GB = 1TB 1000TB = 1PB 1000PB = 1EB 1000EB = 1ZB 1000ZB = 1YB But that seems awfully convuluted, so I was wondering: is there a more Pythonic way to do this? -- (also, a small nitpick: `"{0:.1f} {1}".format(698.25, 'GB')` gets rounded down to `'698.`**2**` GB'` not to `'698.3 GB'`)
Couldn't he just: [n for (_,n) in izip(xrange(1000), high_generator)] or even: list(islice(high_generator, 1000)) in the first place?
This is completely true, but it's way more complicated with pickle (AFAIK), and there are efforts to fix that, since it's a bug, there's never going to be an effort to make eval safe ;)
I don't understand what problem this is supposed to solve.
I think it installs as a Python library only.. Run the following as a `.py` script (or run `python` and paste it) import clevercss print clevercss.convert(''' body: background-color: $background_color ''', {'background_color: 'red.darken(10)'}) *\[Edit\]*: I fork'd [github.com/dziegler/clevercss](http://github.com/dziegler/clevercss/tree/master) to change the setup file, so it installs the clevercss command. The fork can be found [here](http://github.com/dbr/clevercss/tree/master) until it's merged into [here](http://github.com/dziegler/clevercss/tree/master)
ctypes is really powerful but I hope it won't be abused as it feels so unpythonic (whatever it eventually means). 
Or there is the ZODB. It is very mature, production ready, distributed (zeo) and has a very active community using it. It also includes a fairly rich event system and is up there with the fastest dbs around: http://www.upfrontsystems.co.za/Members/roche/where-im-calling-from/zodb-benchmarks-revisited
Yeah it checks your blog to see whether you've written any vacuous soul-searching posts about how Lisp is amazing and how you really "get it" now, etc.
The ZODB let's you persist a Python object with any interface (e.g. Lists, Tuples, Dicts). However, the zope.container package is the primary implementation used for ZODB-persistent objects using the standard Python dictionary interface. Managing data with the Python dictionary interface (regardless of the implementation) is sweet and juicy! 
My recommendation, as always, is to use a search function -- either here on reddit or at your favorite search engine -- to find the many, many, many identical threads already covering this topic.
Class is overrated.
* [Python 2.5 Quick Reference](http://rgruet.free.fr/PQR25/PQR2.5.html) * [Python Quick Reference Card](http://www.limsi.fr/Individu/pointal/python/pqrc/) * [ActiveState Python recipes](http://code.activestate.com/recipes/langs/python/) * [Python by Example](http://www.lightbird.net/py-by-example/)
Also [video lectures on python](http://www.catonmat.net/blog/learning-python-programming-language-through-video-lectures/). 
Dive into Python is excellent if you have programmed in another language before: http://diveintopython.org/ (it's probably not too bad if you're new to programming either). I like Text Processing in Python as well: http://gnosis.cx/TPiP/
I've used http://docs.python.org/ alone. Learnt Python with Guido's tutorial, then had a look at the language reference in order to know all there is as far as the language goes, then use the library reference when I need something.
Hi Spotter, The problem is with the definition of nested generators where if you want to pass data from gen -&gt;modifier1 -&gt; modifier2 -&gt; ... You have to write: ...(modifier3(modifier2(modifier1(gen)))...)) Notice the reverse order of the modifiers to the data flow and the accumulation of parentheses. - Paddy.
Yeah, I know. I just tried to point out that opening example is a little superficial. Otherwise it's sweet and you should really consider putting it for inclusion in itertools module.
@nerdbeard, @300baud, (See my reply to Spotter above). @DarkQuest, I'm not sure that it is a monad. I couldn't get much from the Wikipedia entry on monads.
[dive in to python](http://www.diveintopython.org/) and [dive in to python for python 3.0](http://www.diveintopython3.org/)
The python tutorial is really good.
Learning Python (O'Reilly). It really is excellent. If you can already code, then you will find everything you need to know very quickly along with all the common gotchas. http://oreilly.com/catalog/9780596513986/
Dive into Python is definitely a must-read (as you can assume from number of mentions it already got here). If you want something from O'Reilly Media, I'd say that "Python in a Nutshell" by Alex Martell is a slightly better publication than "Learning Python" by Mark Lutz. As for online resources -- you'll be fine with python online documentation, which is excellent. 
Some books here (and also some useful links). [Python books and links](http://ziffusion.homeip.net/pmwiki.php/Tech/Python)
The python language ref is one of the best I've seen.
This is how I learnt all the basics like lists and dictionaries. Not tried the text processing tutorial yet, cheers for the recommendation.
If you are also new to programming (or always skipped the theory) Python programming: An introducution to computer science - by John Zelle Pretty neat and easy to read book, with examples, exercises, etc.
These look really good, bookmarked!
In addition to being a great Python book, the author is [one of us](http://www.reddit.com/user/MarkPilgrim)
I am also new to Python. Do you also have any suggestions for references on how to make GUI's? 
If I were you, I would grab some free PDF books: * [Byte of Python](http://www.swaroopch.com/notes/Python) - if you want to start from the hardcore basics and learn how to solve a real life problem, grab this one! * [Dive into Python](http://www.diveintopython.org/#download) - probably the most recommended book for newbies Have fun! 
See, this is why reddit is awesome. 
Yeah, I've been reading Dive Into Python for the last few days, it's great. It really helped to explain some stuff that was confusing me (lambda functions and whatnot)
using the interactive shell with the use of dir() and help() were immensely beneficial to me, seeing as I learn by pressing buttons and seeing what explodes.
I merged it, thanks.
I'm not for self-learning a computer language. HATE the fact that Python class resources are almost none-existent (try searching for one in this little town called NYC)
You might sign up on the python-tutor mailing list as well. When I was learning I found consistently helpful people answering questions. In addition, many of the questions that I had were already answered, so I rarely had to even ask for help on the list.
What really worked for me was to pick up a small application that someone wrote, and tinker with it to do what you want. For me, that application was called "urlwatch". Poke around freshmeat for utilities with python tags. Find something interesting, make a change, and watch it fail. Oh, right, you forgot a colon on that if statement. Getting really basic and childlike is the way to go. Poke things with a stick and see what happens. Also, the #python channel on freenode.
MIT offers a free online introductory course which uses python: http://ocw.mit.edu/OcwWeb/Electrical-Engineering-and-Computer-Science/6-00Fall-2007/CourseHome/index.htm
I did: http://www.reddit.com/r/Python/search?q=django+turbogears Can you point me to any with more info?
Upmodded for being the only person in the thread to notice that there's Python 3.0 these days.
people notice that there's python 3.0, they also notice that there aren't too many libs that have been ported over yet. when pylons goes 3.0 , I will go 3.0 
oooooooooo boy do you ever. i don't think it's rated to work there yet.
yeah, you're all lambdas.
also have a look at Think Python.
You should run to a bookstore and get this book: [Rapid GUI Programming with Python and Qt](http://www.qtrac.eu/pyqtbook.html).
&gt; I would like to see the entire thing get a much better documentation treatment I think they really should aim for something similar to php.net: organized, searchable and commentable and also more code snippets &gt; Optional Static Typing That would actually make my list to. If only to satisfy those who think they can't leave without it. Though I'd probably ask for static typing / dynamic casting. So that a method could expect a str and basically just cast any parameter it gets to a string for you automatically, and in a way that can be verified statically.
&gt; Packaging Amen, brother. I use Fedora/RHEL/CentOS a lot, and I'm surprised every time `python setup.py bdist_rpm` fails because of some silly finger-pointing between the Fedora and Python maintainers. It's probably fixed in 2.7 or F11 or something, but it's broken in many of the releases I've tried. &gt; ... instead I think core should make what easy_install does (to a certain extent) easier and standard ... One ring to bind them! Yeah, I don't use 'easy_install' pretty much for this reason.
Your comedic methods are questionable...
It took you 6 days to reply to my comment?
&gt; PEP 8 First time I've been tempted to create some sockpuppets so I could create a chorus of "YES!!!" replies. At least let's get the naming convention in place. The way it is now just detracts tremendously from the aesthetics of Python, which is really sad since the language is so beautiful. &gt; XML Yeah, this is in pretty sad shape, but I think now that everybody is getting burned out on tacking on all this new shit all of the time maybe there's an opportunity to do a nice, clean grand-unified XML implementation. &gt; GIL Doesn't bug me. mpm-worker and mod-wsgi neatly sidesteps the issue entirely for the only applications I care about performance for; hard to see how splitting anything else out into processes doesn't address the rest. It _is_ a scripting language after all, it can't nor shouldn't try to be a c++ replacement.
Doesn't python 3 fix a lot of the stdlib/pep8 stuff?
I guess not. Haven't got around to looking at 3 yet, 'cept for strings. I'm assuming this guy has though, given all these python hats he's wearing.
Not the case, I don't know about everything but e.g. the urllib/urllib2 stuff (in his last point) has all been regrouped (and reorganized) in a single toplevel `urllib` module (and further split in submodule), all the HTTP stuff (httplib, BaseHTTPServer, CGIHTTPServer, SimpleHTTPServer, Cookie, cookielib) has been regrouped in `http` and likewise for the HTML-related modules (HTMLParser, htmlentitydefs) etc... and many other modules have been renamed to comply with PEP8.
i'm a scream at parties.
I've blogged a short list here for that, that might be helpfull: http://tarekziade.wordpress.com/2007/09/24/eight-tips-to-start-with-python/
Yeah, you're right, I just looked at the 3.0.1 library and it is pretty clean.
Yeah we worked on some bug fixes lately for RPM. Meanwhile, I don't think Distutils should provide bdist_rpm. It should be a third party tool maintained by the Fedora/RedHat community, and built on the top of a lighter, simpler Distutils. That's the plans. I don't know when it'll happen yet though, because they are a lot of other tasks going on.
Open the compiled executable with notepad or any text editor/viewer of choice, scroll almost to the end and just before some xml manifest you'll see your password in plaintext. By the way, THAT is something really mindnumbingly stupid you did, not not testing the executable.
His Python hats: * http://www.ohloh.net/p/9555/contributors/41040560065600 * http://www.ohloh.net/p/python/contributors/113816702016 
Correct, I helped with some of the PEP8ifying of some of the stdlib as part of pushing multiprocessing in. The reorganization stopped short though, and did not go far enough IMHO. There's still a large amount of work to be done. Additionally, making them more organized doesn't make them easier to use, clearer or better. I know there's work being done, but alas, like most day-jobs, I'm stuck in 2.x land
I'm emailing Georg about this today. I have some thoughts w.r.t to the docs spurred from comments on my post. We'll see how it goes.
&gt; I think they really should aim for &gt; something similar to php.net Indeed.
&gt; making them more organized doesn't make them easier to use, clearer or better It does make them a slight bit clearer in that you don't have to scour half a dozen different modules when you're looking for a given function doesn't it? Instead you "merely" check the module related to the technology.
I'm about to start a new project. It is pretty much a basic CRUD web application but it will have some interesting visualisations of the dataset. I've been considering using Python as the language. I wanted to know if anyone had any suggestions on a linux-based IDE. Additionally, I am considering using django as the framework to build on. But am open to any alternative suggestions.
For what use specifically? Don't know if it'll help but I use emacs for editting, a internally built xunit based test authoring/discovery framework, buildbot for continious integration, and wx for GUI. I'd also suggest pychecker, coverage.py, and pep8.py.
I actually just like IDLE personally. It stays out of my way. Django looks good, but what exactly are you making? There may be a better, more specific framework for that...
Personally I just want native packages. Packaging, including signing, distribution, uninstallation etc is a solved problem. I don't need a new and conflicting method to install Java classes, a new and conflicting method to install Python modules, a new and conflicting method to install CPAN libraries, or a new and conflicting method to install Ruby Gems. I just want native packages for the OS, provided by some build system so the module maintainers don't have to care. I recall hearing at PyCon that a build service was happening (including even weird platforms like HPUX). 
Thanks!
Editors/IDEs: Eclipse + Pydev, Scribes, VIM, Emacs Frameworks: Django, Turbo-gears, Pylons, brew your own wsgi and mix and match components.(templates, ORM, url mapping...)
I'm building a digital library out of a mixed collection of texts and pictures surrounding the collapse of the Texas Aggie Bonfire in 1999 for the university. Its pretty much about pulling a bunch of text and metadata from a database and a few creative ways to visualize the dataset.
[I gave some more details above.](http://www.reddit.com/r/Python/comments/8nnp3/looking_for_suggestions_on_tools_and_frameworks/c09uvfl) But this is a web-application.
I currently am a big Eclipse user, but I was worried that a python add-on for it may not be a good option.
Ah, nothing too complicated. Django should be perfect. Keep us updated in proggit/pythit(? what's the short name for the python reddit, anyone?), maybe a link when it's done? :)
I have a similar major issue with Python packaging. I want to distribute a single file that contains my application and I want people to be able to click on the file and run the application. Kind of like executable Jars in Java. Here at work I've got Python applications with a GUI interface and lots of functionality, but many end users won't touch it because it doesn't "just work." Am I missing something with .egg files? Can I do this? I'm kind of surprised more people aren't annoyed by this.
If you use nose, be sure to install redrudolf (easy/pip installable) for terminal color support.
Best explanation of decorators that I've ever seen.
Try writing one. That's my blog, and I still get a little dizzy when I try to write one. :-)
hi Mark, Can I follow "Dive Into Python 3 "on Python 2.5.2 ? this is my current installation: $ python Python 2.5.2 (r252:60911, Apr 21 2008, 11:12:42) [GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)] on linux2 Type "help", "copyright", "credits" or "license" for more information. 
Can I follow "Dive Into Python 3 "on Python 2.5.2 ? this is my current installation: $ python Python 2.5.2 (r252:60911, Apr 21 2008, 11:12:42) [GCC 4.2.3 (Ubuntu 4.2.3-2ubuntu7)] on linux2 Type "help", "copyright", "credits" or "license" for more information.
Isn't a contextmanager a much better fit than decorators for that kind of patterns? (I understand contextmanagers are fairly recent, but still...)
Yes and no. You'd probably have to wrap your connection object (and likely need some sort of factory) to provide `__enter__` and `__exit__` that do the things you want. I don't know of a DB driver that does this for you yet. It'd work, it'd just be a different looking solution.
No. Try "sudo apt-get install python3" (without the quotes).
Anyone use [SQLAlchemy](http://www.sqlalchemy.org)? I hear it saves you this session management by design. 
[Elixir](http://elixir.ematia.de/trac/wiki) is even easier! (uses SQLAlchemy)
Not really. Python2.5 is pretty much the same as Python2.6 and Python2.7, which work with Dive Into Python. Dive into Python 3 is for Python3, which is very different in a lot of ways from the 2.5-2.7. Stick with the normal Dive Into Python's recommended chapters if you only have access to 2.5.
Good tip, thanks! 
Ideally you'd use some of each. Sometimes you want to protect the whole method, and sometimes you want to protect just a block. Unfortunately, context managers are new in 2.6 (or 2.5?) and I'm stuck with 2.4 at work.
This is pretty basic stuff and it makes code so squeaky clean. As JimH10 suggests, this is a great example of what decorators are useful for. I'm working on a library for portable low-level database code (when ORM is a poor fit or just not macho enough) with support for nested transactions and other niceties; it's designed specifically for use with decorators and context managers. I have nothing to show for it at the moment, unfortunately, but maybe I'll post when it's ready.
ok, so i just installed nose, and it's not finding any tests. does it not work at all with unittest style tests? i was assuming it would run those too, no? my tests are in _test packages, so it should be finding them. adding -v or --debug doesn't help explain why nothing is being found... :o(
FYI, Bobo was Python's first (I think?) web framework, written by Jim Fulton in 1996. You can get the source to original Bobo here: http://archive.debian.org/debian/dists/slink/main/source/web/python-bobo_2.1.4.orig.tar.gz
They should also be named something like "TestFoo". And it doesn't find TestSuite instances (which is just dumb).
That's pretty cool. Could Bobo have been one of the first Object Publishing/Routing web frameworks? Looking at both the sources, it doesn't seem this new Bobo has anything at all in common with the old Bobo though.
I've been putting off going through this for donkeys. Thanks for reminding me about it.
I think the only thing they have in common is they are both micro web frameworks for Python. And the same author. Old bobo mapped URLs onto Python module namespaces with traversal. Pretty much in one ginourmous "publish" method - not the most glamourous code - but hey, it was 1996! Old bobo also had misc. bits kicking around, like a File representation and a Request object. New bobo uses Rails-style Routes for URL traversal, uses WebOb for the Request object, and doesn't include any misc. bits since there are a tonne of those floating around nowadays - there was no PyPI In '96, heck even Distutils wouldn't appear until several years later! 
Really great
WTF is up with that [logo](http://bobo.digicool.com/_static/bobo.png)? 'Curly penis man'?
does anyone actually care?
Why not? The little things add up.
I woulda swore Classic Bobo included a "bobobase"; a rudimentary version of the ZODB.
I've always "understood" decorators but they've never clicked properly. This has solved that problem.
I was just getting annoyed by this as well, actually.
Maybe it is the series of processor, but the accepted answer gives me opposite results. I'm using a core i7 and when I increase the iterations from 75k to 350k, I get the following results: x ** .5: 0.607 seconds math.sqrt(x): 0.427 seconds
Having absolutely no knowledge of the internals involved here, I have to admit that makes some degree of sense ( possibly ). If math.sqrt() is optimized for square-roots, and the exponentiation operator ** is optimized for the general case, it makes sense that it would be faster. I *suspect* that if you bumped the number of iterations on the codepad version, you'd get the same thing. 
Well, it is surely a big step for the mankind. Another sketchy open source project. How do I run this beast? The answer is possibly hidden in the "why not hotshot and others" paragraph. So you have to read 2 pages of unrelated content, just to try it out.... python -m line_profiler myscript.py throws an ugly exception. I do not consider this a bug, this is a sign of ignorance.
The code given is horrible. Python already has a module for this: timeit. It was written with far more care than the amateur timing code in the the story submission. Here's how you use it: jfincher@functor:~$ python -mtimeit -s 'import math' 'math.sqrt(123456)' 1000000 loops, best of 3: 0.233 usec per loop jfincher@functor:~$ python -mtimeit -s 'import math' 'pow(123456, 0.5)' 1000000 loops, best of 3: 0.28 usec per loop jfincher@functor:~$ python -mtimeit -s 'import math' '123456**0.5' 10000000 loops, best of 3: 0.0263 usec per loop In other words, using the exponentiation operator is an order of magnitude faster than either `pow` or `math.sqrt`.[*] This is likely due to the overhead of doing a name lookup for the function. To see if that's the case, we can wrap the exponentiation in a function: jfincher@functor:~$ python -mtimeit -s 'import math' -s 'def f(x): return x**0.5' 'f(123456)' 1000000 loops, best of 3: 0.314 usec per loop More than pow (of course, since it's written in Python) but comparable. [*] That result is erroneous; Python &gt;= 2.5 does constant folding, so that expression was being optimized to its constant value, rather than being calculated.
Looks useful. I'll give it a spin sometime - but what's the licensing here?
Now, which is more accurate?
You'll have to as Simon I fear, seems he forgot to put in a license.
It's better to write your own working, amateur timing code than using professional code erroneously. timeit compiles the statement into a function body, so "123456\*\*0.5" actually gets constant folded. Try -s "a=123456" "a**0.5" instead. It's not an order of magnitude faster than math.sqrt.
Huh, I didn't know Python did constant folding. Looks like that behavior was new in Python 2.5.
Another issue, you're taking into account the lookup, which accounts for about 40% of the time apparently (on py2.5): $ python -mtimeit -s 'import math' 'math.sqrt(123456)' 10000000 loops, best of 3: 0.14 usec per loop $ python -mtimeit -s 'from math import sqrt' 'sqrt(123456)' 10000000 loops, best of 3: 0.104 usec per loop Edit: Also, your (revised) test is also incorrect as a comparison as there is also a lookup (the f func), this would be better: $ python -mtimeit -s 'from math import sqrt; a=123456' 'sqrt(a)' 10000000 loops, best of 3: 0.105 usec per loop $ python -mtimeit -s 'a=123456' 'a**0.5' 10000000 loops, best of 3: 0.182 usec per loop
Read my fourth example. I already noted that. EDIT: More detail. &gt; Another issue, you're taking into account the lookup, which accounts for about 40% of the time apparently You can't avoid *a* lookup. And most code I've read does `import math` and `math.sqrt` rather than `from math import sqrt`, so I specifically didn't subvert the double lookup (`math` and then `sqrt`) in order to represent what code actually does. &gt; Edit: Also, your (revised) test is also incorrect as a comparison as there is also a lookup (the f func) The whole point of that fourth example was to add the `f` lookup. It serendipitously also avoided the constant folding issue that fredrikj pointed out. &gt; this would be better: Are you pointing out anything that fredrikj did not already point out here?
I'm referring to the lookup as in *math.sqrt* vs just *sqrt*. Also I revised to account for your 4th example (which is also wrong)
Grr, I hate licenses. All my stuff is BSD unless otherwise specified. I need to push the license file to my various projects.
gooble gobble
I've written a follow-on post to [look a little harder at decoraters](http://www.kylev.com/2009/05/28/a-brief-python-decorator-primer/) since that's what people seem more intrigued by.
Nice, clean, informative posts there. (Thanks, Doug H.)
&gt;The high interaction honeypot is a real system for all intensive purposes _INTENTS AND PURPOSES_ &lt;/rage grammar&gt;
My fourth example isn't wrong. And the revision you offered (to bind 123456 to a) isn't slow because of the lookup, but because of the lack of constant folding.
&gt; I need to push the license file to my various projects. Yep, 'cause I don't think code defaults to nice licenses.
You should probably use httplib2 instead of implementing your own gzip decompression.
The first is your 4th example, the second is the revision. $ python -mtimeit -s 'def f(x): return x**0.5' 'f(123456)' 1000000 loops, best of 3: 0.291 usec per loop $ python -mtimeit -s 'a=123456' 'a**0.5' 10000000 loops, best of 3: 0.18 usec per loop One is closer to the actual time x**y actually takes, guess which one.
&gt; from httplib import * &gt; &gt; from urllib import * &gt; &gt; from StringIO import * &gt; &gt; from gzip import * naughty
Link is broken, and google fails me :(
The point of the fourth example (as I noted) was to add a function call and lookup to the cost of the exponentiation. Take away that function call, and you've obviated the need for a fourth example at all. The only example of mine that was wrong was the raw exponentiation, because Python does constant folding as per fredrikj's post. All the other examples have valid reasons for being the examples they are, as I've noted.
This somehow doesn't feel very Pythonic. 
Clever trick to have a decorator work with or without arguments: def awesome(func, message='This is awesome:'): if not callable(func): # Assume 'func' is really a message and return the real decorator. return lambda func2: awesome(func2, func) def wrapper(*args, **kwargs): print message return func(*args, **kwargs) return wrapper @awesome def awesome1(): print 'Stuff.' @awesome('This is even more awesome:') def awesome2(): print 'More stuff!' awesome1() awesome2() If you call with a function as the first argument, it decorates the function. If you call with something else, it returns a lambda that will decorate the function with whatever arguments you passed.
&gt; Python’s os.rmdir and friends refused to remove directory trees that had files in them. They would remove the directory if it had only directories in it but not files. `os.rmdir` removes only empty directories, because the underlying system call does exactly that. There are times where this is what you need, and now there's `shutil`for the others. I don't know what the "and friends" functions are that presumably remove trees of directories but not files. &gt; What I will blame Python for is the lack of even the most basic time conversion features that even C has. Yes! Why is there not a straightforward way to go from a UNIX timestamp (seconds since epoch) to a UTC `datetime`? You have to go through `time.mktime` which doesn't do UTC and compensating for the timezone + DST offset is impossible without writing your own time conversion library. Please, reddit, tell me I'm missing something *incredibly obvious*. EDIT: Actually, I had it backwards -- there isn't a way to get a UNIX timestamp from a `datetime` object. You can feed the time tuple into `time.mktime` but that assumes local time.
It really *really* bothers me that the length of a list is len(l) and not l.len(). To the point where I am almost reluctant to use python because of this one thing. I realize this is more of a failing on my part than python's but still, argh.
&gt; reluctant to use python because of this one thing. That's a weak rationale to not use any language. It is yours to have however.
 l.__len__() You'll be saying you don't like dual dual underscores next...
&gt; This is exactly what happens in Python, and to a lesser degree other languages, but I’ve never seen it so bad as in Python. You should check out java then. The java community wouldn't even acknowledge that reporting was a legitimate business requirement until someone developed a primitive java reporting tool (jasper reports).
&gt; To demonstrate this let’s look at Python’s list. Here’s how you add an element: &gt;`mystuff.append(mything)` &gt;That seems pretty reasonable. Now, if “append” is how you “append” something from the end of a list, how do you think you remove that particular item from the list? Yep, it’s “remove”: &gt;`mystuff.remove(mything)` &gt;Now, what if you want to delete the item at index 4? Would you guess it’s this: &gt;`del mystuff[4]` &gt;When you first see this your brain (if you’re normal) goes, “WTF that’s not like the others.” However, if you have Neglect you would not only think this is totally normal, but wouldn’t even recognize it until someone pointed it out to you. Then when you are told about it, you’d make up excuses trying to explain why it is totally normal. Well, it's not totally normal, but it is a fact that `del` has to be a language keyword, since there's no (sane) way for a function to reach into the caller's namespace and remove `x` when you write `del(x)`. From there, people also developed the desire to use `del` outside of the context of removing items from the namespace. Maybe it was a mistake, and we should just get rid off `del container[x]`, but it seems like as long as we have `del` as a keyword, it's not that big of a burden to keep it around as a more convenient way to write `container.delete(x)`. 
len(a) is really equivalent to a.\_\_len__(). Consider it syntactic sugar. It is better than a.len() because it is more readable (like natural language).
It might be more readable for a non-programmer, but someone familiar with OO will usually find it jarring and inconsistent.
I am a programmer and very familiar with OO and still find it more readable. And if you consider it syntactic sugar it is not even inconsistent.
It's totally stupid, yes, though it's *slightly* better in newer versions of Python. In general the [dateutil](http://labix.org/python-dateutil) package has a lot of really useful things that are missing from datetime, though I'm not sure about conversion.
It's mostly because classes start essentially empty, so lots of these primitive things -- especially ones that cross-cut across lots of different kinds of types -- ended up as functions instead of methods. Some of these functions have complicated interactions with the underlying classes (like `cmp()`), though not so much `len()`
Another way to think of it, is that you have these three operations on *attributes*: x = foo.bar foo.bar = x del foo.bar These correspond to the `__getattr__`, `__setattr__`, and `__delattr__` slots, respectively. Then, you have these operations on *contents*: x = foo[y] foo[y] = x del foo[y] These correspond to the `__getitem__`, `__setitem__`, and `__delitem__` slots, respectively. I'm not saying this isn't a further case of what the author calls "neglect", but it explains why things are the way they are. You can have a `foo.delete(y)` too if you want, but slots define specific language actions and the `del` keyword is the corresponding operation to the retrieval and assignment operations.
package uninstallation is on its way with PEP 376.
Whatever you think about Zed, he often have a fresh and unique look on things. This time I think he really nailed it, if you use Python since a lot of time you tend to ignore these problems because most of the time they have an historical explanation. Anyway, most of it will be corrected in Py4K
For `cmp` it makes sense, because there are many different sets of slot methods your class can implement to get working comparisons and you need a single method to try them in the correct order. But `len` doesn't have the same problem. So basically all you get is a nicer error when you pass an object without a length. I consider it more of a gotcha than an actual complaint, but I find it difficult to rationalize what the original purpose of that choice was.
methinks Zed hasn't enjoyed writing in Javascript. It's language barnacles all the way down!
Hm, len(x) is one of the most common functions that I find myself using. I get annoyed every time I use it. I *almost* consider re-evaluating python, but then I remember that I already evaluated all the other languages and they suck worse. I would say that if I were inclined to like another language, that would be a perfectly reasonable stopping point in my python exploration.
1. Violates principle of least surprise. 2. Is not more readable. 3. Violates python OO calling semantics. 4. Presuming it were more readable, why don't we simply use CLOS style dispatching for everything else? Then *everything* would be more readable. Multi-methods are a solved problem. They have been rejected in the python design. You don't get to pick one and only one situation and claim that they are more readable.
Warning: You just exposed a library implementation detail to the user.
&gt; You can feed the time tuple into time.mktime but that assumes local time. Which is quite ironic, given that because of daylight saving time there is no unique correspondance between localtime and Unix timestamp. For one hour each year in those zones, the local time may correspond to two UTC time and thus to two Unix timestamps (and for one hour each year, no such correspondance exists).
If a.len() wasn't a magic method I'd agree.
[I still don't get this criticism](http://www.reddit.com/r/Python/comments/7q0pc/eight_python_warts/c072ddz).
&gt; To the point where I am almost reluctant to use python because of this one thing. I spend about a thousand hours of programming a year and choosing the right language, libraries and tools are crucial for accomplishing project success. Now comes you and tells us that you would give up a language because it implements `len` as a function. That's a properly bizarre statement. 
list.append(item) adds an item to the end of a list. list.remove(item) removes the first occurrence of item from the list, not necessarily the last. list.pop() will remove (and return) the last item from the list. Nice try, but just because Zed has pointed out a medical condition, disagreeing with him does not prove you suffer from that condition. (But I admire his ploy) - Paddy :-) 
Looks a lot like a less mature version of [SASS](http://haml.hamptoncatlin.com/docs/rdoc/classes/Sass.html). Maybe it would make more sense to work on a python-based SASS compiler like [Compass](http://compass-style.org/).
Two interesting, informative comments. Thank you. Both prove Zed's point about inconsistencies requiring knowledge of implementation. It would be nice if we didn't need explanations like these -- then again, it's nice to know, too. :-)
I like what you said here: &gt; What's curious to me, though, is that it's always `len()` that people pick on, and never anything else. They never complain about `str()` and say they'd rather do `some_object.to_string()`. They never complain about `map()` or `filter()` and ask that they become collection methods (as, IIRC, they are in Ruby). It's always and only `len()` that gets this complaint. Why is that? I'm guessing it's because `len()` just happens to be one simple example. I definitely prefer the Ruby way. I would rather do `obj.to_str()` (just using the Ruby method names, but `to_string()` works too), `array.map()`, etc. The Ruby way stems, of course, from the Smalltalk way, where even conditionals are implemented by message passing, so even Ruby seems unclean to me now.
Nice trick! I have been thinking about doing a follow-up with more advanced examples and using lambda... I might include this trick.
I want imports like `import project.subproject` and `subproject` to be in a subfolder - so how to avoid having code in `subproject/__init__.py`?
I think it should be too. This comes up often with comparison to ruby with python's other methods, but while there *is* a rationale for many other such methods (they have a more complicated protocol than just calling object.__len__), len itself has no real reason to be anything but a collection method. I suspect the reasons for it are mostly historical - if implemented today, it would likely be a list method. However, it's a pretty minor thing to me, but I know some details can annoy people if they hit a particular reflex.
Standard library or pypi, I'd rather just apt-get it. Lately I was puzzled to see that nltk is not even in universe, that's shocking for such a useful library.
&gt; Who is Zed? Zed's dead, baby.
And I'd rather put everything in a virtualenv. Got fucked by a lot of problems regarding updates, even when it's just a 0.0.1 step. 
One other nice thing to remember is [functools.wraps](http://docs.python.org/library/functools.html#functools.wraps), which helps maintain the original function's metadata when introspecting. (Edit: markdown)
Expert Python Programming by Tarek Ziadé. http://www.packtpub.com/expert-python-programming/book
Expert Python Programming is an awesome book! "Foundations of Agile Python Development" by Jeff Younker also has some good tips. But if I had to pick one, go with Tarek's book. The upcoming 4th edition of Python Essential Reference by David Beazley (due late June) also looks very promising based upon a pre-release chapter on Functional Programming that I have seen. I also find looking at best practice description are helpful: * http://python.net/~goodger/projects/pycon/2007/idiomatic/handout.html * http://www.fantascienza.net/leonardo/ar/python_best_practices.html (Edit: list formatting) 
Marty Alchin's Pro Django. Though it's 85% django API specific stuff, chapter 2 on metaclasses, decorators, descriptors and such is awesome. It also gives lots of applications for usage of this stuff (in a Django context).
Decorators: * http://programmingbits.pythonblogs.com/27_programmingbits/archive/50_function_decorators.html * http://programmingbits.pythonblogs.com/27_programmingbits/archive/51_more_on_function_decorators.html * http://www.ibm.com/developerworks/linux/library/l-cpdecor.html Descriptors: * http://users.rcn.com/python/download/Descriptor.htm * http://www.ibm.com/developerworks/linux/library/l-python-elegance-2.html Metaclasses: * http://www.ibm.com/developerworks/linux/library/l-pymeta.html * http://www.ibm.com/developerworks/linux/library/l-pymeta2/ * http://www.ibm.com/developerworks/linux/library/l-pymeta3.html Edited to add: also, [Doug Hellman's Python Module of the Week](http://www.doughellmann.com/PyMOTW/) is fantastic.
If mark is recommending these articles, they are probably where you should start.
I found some older blogs and the old website, but it was taken over recently to be revamped. Unfortunately, the examples I've found seem to be broken. The package module has been renamed, and I think some class methods are re-worked or no longer usable. The mailing list seems very dead, and after reading through it, it seems like I would be asked to "just read the sourcecode" if I posed some simple questions. I'm using Ubuntu 9.04 and have PyCrypto installed through apt. If anyone can point me the way I would be very happy :) 
The Python Cookbook. It has lots of stuff and with descriptions of what's going on and what it's good for. Expert Python Programming is good, but after covering what they are it doesn't delve into as many use cases for the stuff.
http://code.google.com/p/cmdln/ class MySVN(cmdln.Cmdln): name = "svn" @cmdln.alias("stat", "st") @cmdln.option("-u", "--show-updates", action="store_true", help="display update information") @cmdln.option("-v", "--verbose", action="store_true", help="print extra information") def do_status(self, subcmd, opts, *paths): """${cmd_name}: print the status of working copy files and directories ${cmd_usage} ${cmd_option_list} """ print "'svn %s' opts: %s" % (subcmd, opts) print "'svn %s' paths: %s" % (subcmd, paths) 
agreed. I've been programming in Python nearly constantly for 10 years and started learning new, interesting, immediately useful stuff on page 25. Superb investment.
Meh. (defn m-avg [n step coll] (map #(/ (reduce + %) n) (partition n step coll))) 
I could never get quite get my head around metaclasses until I read that chapter. I've never learned more from a single chapter in a technical book and it was an effortless read too.
wow! I never knew that was the true grammar of the phrase. I guess the more you know (queue GI Joe music)... I've made the appropriate edits. Thanks for pointing out my mistake!
I like ZedShaws idea of making apis symetrical. Also, as I commented on the article, things like zipfile and others really need cleaning up. Maybe it's worth having a website to try and track all these (I guess it would be hosted on python.org)
The test discovery (another blog entry on the same page) is probably more interesting. :-)
Hmm, I wrote a script to give me the same functionality in 2.5.
Great, awesome. Ummm, who knows what lamson is? This might help. [lamson project page](http://lamsonproject.org/)
Zed, you need to integrate this thing with at least spambayes, and that's just for starters. Until then, you just have a glorified procmail plugin. Sorry to be harsh, but since you dish it out, I figured you could take it. 
Yes, spam integration could be good, but Lamson isn't a procmail plugin. PS - why would you be using procmail is 2009? Spam should be rejected, not accepted and thrown away, and users these days have mail clients that can handle the rest of the post-accept stuff. 
&gt;spam integration could be good No, it's not a "could be good." It's a must-have for a modern mail processing engine. It's like a new OS that doesn't have a shell. Until you have that, you don't have anything. &gt;Lamson isn't a procmail plugin. You're right. Until lamson can detect and reject spam, it's just a toy. 
&gt; Spam should be rejected, not accepted and thrown away I accept spam and put it into spam folders, automatically via Spamasassin and procm^Wmaildrop. No MUA involved, no MUA configuration neccessary while still retaining control.
Sure, but you've just told a spammer it's OK to send mail to you, rather than giving him a forbidden message. This encourages the spammer to send more mail.
As long as I don't react, I doubt that this makes any significant difference.
The website could do with syntax highlighting in the example code snippets on the front page.
Rather than a blog post, I thought I'd come straight here for input. It makes for a longer-than-usual Reddit comment - I hope it works! Question is: I have a library that generates URIs nicely (e.g. from `app.users['dojo'].articles.uri`), but what's the best way to integrate with an HTTP client library (httplib2, say)? To make it clearer what I'm asking, here are some options. As the integration gets deeper, the user code gets shorter (and to my eyes at least, nicer), but with some loss of flexibility. The very last option is close to how my Ruby version looked, with the the heavy lifting done by Httparty. How would you do it? 1) The no-integration option: app = Application(...) http = ... response, content = http.request(app.users['dojo'].articles.uri, "GET") if response.status == 200: parsed = json.loads(content) 2) Forward http method calls to a http object provided at initialisation: http = ... app = Application(..., http) response, content = app.users['dojo'].articles.get() if response.status == 200: parsed = json.loads(content) 3) Initialise our own http object: app = Application(..., http_options...) response, content = app.users['dojo'].articles.get() if response.status == 200: parsed = json.loads(content) 4) Explicitly expect JSON content: app = Application(..., http_options...) try: parsed = app.users['dojo'].articles.get_json() except BadResponse: ... except BadContent: ... (much shorter version: same API, client handles exceptions higher up:) app = Application(..., http_options...) parsed = app.users['dojo'].articles.get_json() 5) Implicitly recognize JSON content (short version): app = Application(..., http_options...) parsed = app.users['dojo'].articles.get_parsed() or even just `get()` again: app = Application(..., http_options...) parsed = app.users['dojo'].articles.get() 
If you reject spam messages you give spammers ability to fine tune filter avoidance techniques.
I learned multiplication as a hash between a tuple of numbers and the result. I think most kids do. That's why they have the multiplication tables on the wall in classrooms.
Looks handy. Seems this would be a natural fit for an enhanced Python shell, too: http://blog.bug.gd/2008/03/29/error_help-for-python-hackers/
I guess stackoverflow was designed for this kind of questions; try there. I like (5) the most. If you expect to get the data in most cases, exceptions will take care of the rest; depending on the level of flexibility you need, I'd go with (5), (4) or (3) (in this order).
Good suggestion - I might give stackoverflow a try if this experiment fails. At least it's up all day ;-) So no big worries about building in dependencies on httlibX, any particular json lib, etc? (that concern aside I like 5 the best also)
I wonder how it compares to ipython. Guess I'll try it out and see.
I'd love to see those results.
Oh great, let's share everyone's embarrassing programming errors with the world. Traceback (most recent call last): server.login('root', 'h4x0rs') NameError: name 'server' is not defined
I installed it. it seems really nice. I managed to crash it in the first 10 seconds or so just by resizing the terminal window a bunch, but other than that its working as advertised. it lacks the multi-line history of ipython.. when you hit the up arrow, you get the indivual lines of a block statement, whereas ipython shows the entire block and lets you edit it. it also doesn't auto-close blocks when you hit enter twice. you need to manually backspace to un-indent before it will execute the block. thats all I've got after my first 2 minutes with it. 
Installed on Leopard via easy_install - seems to work fine. Still playing around with it but looks really clever, especially for a curses app.
Me too, anyone bothered to try running ipython on py3k yet?
That's the problem this is solving. *Everyone* having to write their own code to do this.
I rather wish he'd merge the few features he developed with the already useful ipython. His site talks about ipython but failed to convince me of the need of a separate project.
Unfortunately, IPython does some pretty terrible things - I see no end of people having problems with it in #python. I'm happy to listen to suggestions for features you'd like to see in bpython, though, so please visit http://noiseforfree.com/bpython/community.html and choose your preferred method of communication. I haven't used IPython a great deal - I took a very quick dislike to it so didn't pursue it much further - so if there's a particular thing IPython does that you'd like in bpython, let me know (preferably by creating an issue on the issue tracker) and I'll see what I can do. Thanks to everyone for the interest in bpython. :)
Crashes immediately here: Traceback (most recent call last): File "/usr/lib64/python2.6/site-packages/bpython/cli.py", line 1905, in main o = curses.wrapper(main_curses) File "/usr/lib64/python2.6/curses/wrapper.py", line 44, in wrapper return func(stdscr, *args, **kwds) File "/usr/lib64/python2.6/site-packages/bpython/cli.py", line 1854, in main_curses if os.path.isfile(path): NameError: global name 'path' is not defined I don't understand how this program works at all for anyone, because the function is either never called (except on my system) or relies on something else inserting variables into its namespace.
Version 0.9.0 works great!
This was a mistake in the 0.9.1 tarball I put up - I've fixed it now, so if you redownload that it should work just fine.
You were unlucky with the version. 0.8.0, 0.9.0 and the new release of 0.9.1 all work.
I'd bother more if these libs were as big as zope or twisted. json libs tend to be small and their API is rarely big enough to make changing from one to another a big task... and would end up in the worst case by writing a simple wrapper. I don't know what you really need on the http side... and what you are trying to achieve. But still I don't think I would care much. I'd firstly try to build something that works as soon as possible and only then--when you already understand what exactly you want to do--seek for alternative approaches.
Fairly sluggish as compared to IPython. The completions could be a lot better too. I have never really had too many problems with ipython; you have to invest some time learning the ins and outs of it, but that time is well worthwhile.
It gets confused when you enter more characters on one line than the line width, for each character you type it reprints everything. Other than that very nice completion and syntax highlighting makes me happy
Generally you should never reupload a release because you can't know who's already grabbed it. It's better to just bump the revision (numbers are free after all) and not worry about the problem.
Yeah yeah, I know. It had only been up 10 minutes so I was hoping I'd get away with it. :) Please don't report me to the version police.
I think Zed pictures Lamson as a kind of web application framework that just happens to use SMTP rather than HTTP. So presumably you'll be doing some kind of authentication at the application level, for instance checking a "session code" embedded in the recipient address. Integrating a spam filter would only make sense if your particular application is accepting arbitrary, unprompted emails for some reason. I think Lamson is more for situations where your application has sent an email to a user and wants to process a response email from that particular user.
Heh, that's only if you type in error_help(), and then you'd have to also submit a solution to that before it would be indexed.
I know not of those terrible things, enlighten me. Nice features of ipython are multi-line editing (although not completely comfortable yet), code reloading with %run, debugging with %debug, and tab completion for methods etc.
I know not of those terrible things, enlighten me. Nice features of ipython are multi-line editing (although not completely comfortable yet), code reloading with %run, debugging with %debug, and tab completion for methods etc.
Or maybe he's just told my mother that she shouldn't forward me those cheesy chain emails, because some server operator thinks they're spam. Certain kinds of spam filtering (reliable and conservative blacklists, SPF, etc.) can occur at the server level, but ultimately, content-based spam filtering can only be done by the recipient, not some server operator.
Also help with object.method? , source with object.method?? , windows compatibility, modes for integration with scipy and matplotlib, configurable file editing with %edit, intelligently running parameterless functions without parens, etc. (I'm a bit in the tank for ipython, in case you couldn't tell. I'd like to know what its downfalls are too)
Possibly - although most will simply move on to other targets - but that's better than having no filter at all. Do you do the same on your firewall?
Windows compatibility is out the window - bpython uses curses, which is, last time I checked, a no-no on Windows. Plus I don't have access to a Windows machine (or a desire to make it work on Windows). I am very much against adding in magic syntax. I wanted bpython to be a drop-in replacement for the vanilla shell, and I wanted all code bpython can run to also be runnable in vanilla python. This has always been a prerequisite and it always will be. Block history is on the todo list, somewhere, and I'm also planning to add keybinds so you can type "object" and hit a key to see the __doc__ and another to see the code, which should satisfy IPython users with a hankering for that kind of thing. So, as long as it's not adding new syntax, I'm not at all averse to adding in IPython-like functionality. But things like in-line syntax highlighting, the as-you-type suggestions and function arg spec, are simply not possible without a curses (or similar) interface, so I don't see how IPython and bpython could ever be a single project.
__doc__ = _ _ doc _ _ (without spaces)
Could you elaborate on "The completions could be a lot better too" ?
Surround with backticks for code to get `__doc__` (reddit doesn't seem to let me escape backticks, but that's '\_\_doc\_\_' only with \` instead of ') or use backslashes (\\\_\\\_doc\\\_\\\_ == \_\_doc\_\_ ) to avoid reddit's markdown interpretation of \_. 
Err.. What did you say again?
ipython has multi-line editing? The main reason I decided against it was the lack of multi-line editing. Is there some secret method of using it that I'm not aware of?
1. %edit 2. After you a multi-line entry, you can press up and edit the whole entry, although you can only move the cursor left &amp; right which can be tedious. The other day I wanted to paste a multi-line string (triple quotes), and I couldn't get ipython to swallow it. So in the end I did: a = open("/dev/stdin").read() 
Well, I'm not suggesting you add these to ipython, or that you should merge your project, I'm just naming some features of it I like. Of course you want to make different design decisions, I've got no problem with that. My real question is, what are the shortfalls of ipython that bugged you to make bpython?
I find ipythons multi line history editing an experience as enjoyable as slamming my head on a desk. Why oh why could they not retain the indentation correctly. 
Isn't this it: http://lamsonproject.org/docs/api/lamson.spam-module.html
No, because the lack of decent unicode support forced me to ditch python-MySqlDB, and switch to postgres (and some other db adaptor).
`zip(*[iter(s)]*n)` What a wonderful hack. I do this frequently. The only downside is that if len(s)*2 &lt; n, it seems to break.
When I want do such thing, I always think I saw this in itertools somewhere... and then, with a disappointment, write this kind of thing. itertools.group(iter, n) wouldn't be a bad idea...
the train left the station years ago with testing and its called nose....
little misleading headline. neat nonetheless.
Can you explain what this does? In particular, I'm not quite understanding why that first asterisk is there.
What exactly is misleading? It's a middleware for Django that sends errors to FogBugz.
Excellent! I think the only headache I have with pyflakes still is [reporting try: except ImportError: imports as redefinitions](http://www.divmod.org/trac/ticket/2171). What a great tool.
Let me just give an example first: &gt;&gt;&gt; zip(*[iter("abc")]*len("abc")) [('a', 'b', 'c')] `s` is a string and `n` is the string's length, and we get a list containing a tuple containing all the separate characters in the string. So how does it work? First we get the string's iterator, and put it in a list. When you call `*` with a list and an integer, you append the list to itself a certain number of times: &gt;&gt;&gt; [1,2] * 2 [1, 2, 1, 2] So now we have a list of length `n`, and all the elements are the *same* iterator (the fact that they are the same is important). Finally, we call `zip`, treating the list as multiple arguments. That's what the first `*` does. For example: &gt;&gt;&gt; def f(a, b): return a + b ... &gt;&gt;&gt; f(1, 2) 3 &gt;&gt;&gt; f([1, 2]) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: f() takes exactly 2 arguments (1 given) &gt;&gt;&gt; f(*[1, 2]) 3 So now, in our case, we called `zip` with `n` references to the same iterator. The thing with iterators is that once you consume a value, the next time you go to consume a value, you get the next value. So in consuming one value from each of its arguments, the `zip` effectively goes through all the characters in the string. It's almost like calling: &gt;&gt;&gt; zip(['a','b','c'],['b','c'],['c']) [('a', 'b', 'c')] Now, you can generalize this for objects that aren't strings as well. ------- And I assumed you knew what `zip` does, but in case you didn't: zip takes multiple objects that are iterable, then creates a list of tuples containing corresponding elements of the objects. For example: &gt;&gt;&gt; zip(['a','b'],[1,2,3]) [('a', 1), ('b', 2)] Notice that when the lists are unequally-sized, the result has as many elements as the smallest list. ------------- EDIT: Oh, and of course, `n` doesn't have to be `len(s)`, and actually, things get more interesting when `n &lt; len(s)`. You can also trivially show that if `n &gt; len(s)`, then we just get an empty list.
Slightly off topic, but I run an open source project and I get a lot of email. I am currently about 2.5 weeks behind and just don't have time to catch up. I'm sure the MySQLdb guys are in the same boat. Plus your bug looks like it affects you and only you, so as a priority it'd be pretty low on my list ;) I try to tackle bugs that affect more than one person.
usually one would expect n to be small with respect to the length of s. EG to generate a list of successive pairs: &gt;&gt;&gt; zip(*[iter(range(7))]*2) [(0, 1), (2, 3), (4, 5)] Also note the truncation of the original list. [edit: bugger that, how does one display code in a reddit comment? aha, thanks dwdwdw. also found http://www.reddit.com/help/commenting]
Why people always want to bring fancy names from Java to Python ?
a bug that affects one person might affect 50 if your userbase was bigger
well, at first my impression was. "Cool middleware that embeds fogbugz into a django app" which would be a lot cooler. so I was a little disappointed that it was just middleware that logs errors. 
gtfo stupid fanboi
Hasn't pylint been doing this for years? What makes pyflakes/flymake superior?
Python hardware control... :)
I was excited to see something with Python + Arduino board but this was pretty amusing.
Woah, now *that* is a good use of system resources. Good thing we have unlimited energy that doesn't cost anything. Seriously though, you should really run Folding at Home instead. Warm lap now and less cancer when you get old!
I ran 2 folding boxes in my dorm for this very reason. certainly easier than fighting the antique steam radiator.
no, you.
no YOU! what the fuck is this? I was expecting some kind of controller for a heating device but there's just a stupid loop trying to "heat" using the processor? WTF!? and the worst part "LOL i MADE IN PYTh0N! IM SOO HAXXOR" edit: oh and it doesn't even **measure** the temperature, it justs runs for a specified time.
PyFlakes is less capable but orders of magnitude faster.
Always?
I am one of the MySQLdb maintainers (only recently given commit privs). I'll try to have a look at this shortly. Somehow I missed this one.
His electric bill next month will put an end to this application's lifecycle.
backticks. you can't put em across lines, but wrap each line in backticks, it works. i think there's a multiline one, but i can't remember what it is
&gt; That would actually make my list to. If only to satisfy those who think they can't leave without it. Though I'd probably ask for static typing / dynamic casting. So that a method could expect a str and basically just cast any parameter it gets to a string for you automatically, and in a way that can be verified statically. Given the difficulties Guido pointed out with static typing, I'd rather have contracts. Functions would have a body (as they do now), an optional pre part and an optional post one. If you passed a switch that enables contracts to Python, it would run the pre with the arguments passed to the function and the post would do with the return values.
That sounds interesting. Would that be something a pylint type tool could easily check for? Validity wise? Or does one still need to cover all the code at runtime to check for errors?
&gt; no YOU! what the fuck is this? A fun post about python in /r/python, you empty headed animal food trough wiper. I fart in your general direction. Your mother was a hamster and your father smelt of elderberries. Now go away or I shall taunt you a second time.
Reminds me of a story... I used to work at a disk drive company (I wrote servo firmware for Quantum's high-end drives), and I needed to be able to heat a drive up to reproduce a problem, but there was a shortage of ovens in the lab. Our drives had a temperature sensor, so I wrote a utility that would do full seeks and monitored the drive as it heated up until I reached the specific temperature. I stuck the drive in a cardboard box, and, presto, problem reproduced!
It could. If you use a isinstance in your pre block, pylint would know that any value passed to that the argument it is used for have to be of that particular type(s). Edit: The point of contracts is to go much further than type checking though. You could do things like: assert 0 &lt;= x &lt;= 100 To ensure that a value is within acceptable range for instance.
I used to run [Distributed Climate Prediction](http://www.climateprediction.net/) to keep my college room warm. F@H is probably a better project to contribute cycles to, but I found the irony of keeping my room warm with climate prediction too delicious to resist.
Some battery he must have there if he doesn't have to, I don't know, plug it into the wall to recharge it?
`$ yes &gt;/dev/null`
That's not really the point of his argument. He's saying: Add something to a list(at the end): mylist.append(something) Remove something from a list(the first occurrence): mylist.remove(something) Here is the important thing to notice: Remove a specific object from the list at index i: del my_list[i] The problem is the syntax is completely different and not intuitive. It doesn't follow it's own design.
go ahead I don't give a shit about you childs, but I usually like to see real code around here
$ yes &gt; /dev/audio
I was just trying to raise awareness to the people that may be affected and get some feedback for the proposed solution since I've included patch to fix it. After this bug hitted me I started seeing ghosts everywhere. It was really hard finding it just having one inconsistent transaction in a (production) database as a starting point. I had to go from a to z and when I was debugging python-mysqldb (y) and mysql (z) I was already hopeless, I just hope this saves someone some sleepless and painful nights. EDIT: I'm pretty sure I'm not the only one using MySQL+Python and doing row locks.
Erlang's bit syntax is still superior. In Python, [Hachoir](http://hachoir.org/) is pretty interesting (plus it already has a bunch of parsers for existing formats). The only thing I dislike about Hachoir is their use of imperative field declaration and validation instead of a more declarative system.
Python is becoming the new PHP. Everyone who has seen it for five minutes is instantly an expert who can call GvR names without giving any details. This response is far more valuable than anything I'd care to write in the topic.
I'm the author and I'm glad it was useful. It's been pointed out to me that the original was probably a troll, I can only hope it's still useful to other people.
Having used both PHP and Python, it surprises me that people want to hate Python. PHP is easy to learn and use, but hard to love; Python is easy to learn AND easy to love. 
Judging by your [user history](http://www.reddit.com/user/Samus_), you sir, are lying.
what do you mean? in /r/python and all other programming-related subreddits I don't like this kind of idiocy, there are some other places where this could be more suited, like [/r/funny](http://www.reddit.com/r/funny/) by example.
I can attest to this. I can do much more in python after just a few hours of learning than I could with javascript or MATLAB. It's also nice not having to write 20 lines of code just to convert one type of data structure to another or some other tedious thing.
That's my favorite part of python, the data structures seem to blend together and almost all methods work throughout all data structures.
This sounds interesting, but why can't it be integrated into numpy directly, so it's completely transparent? The speed gain would be great, but I'm less inclined to rewrite my code and make it uglier.
I think people should stop bickering over which language is the best and really show off through development. I'd like to see good quality software as trophies, rather than reading into fanboy rambles. A lot of Python fanboys do this. Fanboys are no good to anyone. My friend for instance has a very shallow understanding of python. He would often go off talking about how Python is the new revelation and just how much C++ and other languages "suck balls." This form of rant caused me to ignore Python altogether until a year later now, I noticed my favorite softwares are written with Python. This sparked my interest in Python in the last few weeks. Right now I'm attempting to learn Python by reading Dive Into Python, but I wish I would've dove into it earlier. 
&gt; This form of rant caused me to ignore Python altogether until a year later now That's your own prerogative, and your own loss.
I notice a lot of first years at uni complain that "Python is hard", when they've never touched any other language. What they really mean is "programming is hard" but Python is all they've seen and they find it hard, so "Python is hard".
I'm not either :-9~(
I havent yet successfully done a virtualenv yet. Care to point to a post or article that enlightens?
Even Guido is tripped up by it sometimes, so don't feel bad.
Is there a distinct reason on why we'll have to do this? Is there someone that's actually a fan of it?
It's done so that you can replace the print function with a function that you've written, to modify it's functionality. Stop complaining over minutiae when there's so much more to complain about. Getting any halfway decent editor to parenthesize for you isn't exactly hard. At the extremes, you can write your code as you've always written it, and get 2to3 to convert your print statements to function calls. Although imo this would be very sad.
&gt;It's done so that you can replace the print function with a function that you've written, to modify it's functionality. This was already easy by assigning sys.stdout to a StringIO() object. I rather think they fell victim to the hobgoblin's consistency of little minds. Wait, what was that quote again?
from \_\_past\_\_ import print
I don't think Emerson had "you should just stdout with an unwieldy object that only partially implements the file-like API--cf. sys.stdout.buffer in Python 3" in mind when he wrote his transcendalist essay advocating one's aversion to conformism. :D
I'm surprised that anyone would suggest that this change was made arbitrarily and without support given the rather transparent way it was proposed, discussed, and written (see [PEP 3105](http://www.python.org/dev/peps/pep-3105/) and [this large thread](http://mail.python.org/pipermail/python-dev/2005-September/thread.html#56187)).
I agree that matplotlib produces pretty looking plots, but I very much prefer [ggplot2](http://had.co.nz/ggplot2/) from R.
&gt; This was already easy by assigning sys.stdout to a StringIO() object. Easy enough for a single project, sure. But for larger projects that technique didn't work because multiple modules would try to replace `sys.stdout`, invariably getting it wrong and/or stomping on each other. And besides, isn't it a good thing to get rid of a statement? I for one would like to see `class` and `def` replaced with functions. 
You mean, Python *programmers* are becoming the new PHP *programmers*. The language of python itself is in no way as horrid as PHP.
Ultimately this will all be for the better..but I totally agree with you, it is with some degree of fear that I glance at python 3.
That would be a surprising thing to hear anyway I think. Python was my first programming language, and I found it easy enough. But everything since then (scheme, haskell, perl and C), has been considerably less intuitive.
&gt; It's done so that you can replace the print function with a function that you've written, to modify it's functionality. No, that's not really the motivation. It was done to reduce the "sore thumb" that was print-as-a-statement but it was also done so that print could be passed as a first-class object in the language. Replacing it with a function I've written "to modify its functionality" can be done in my own scope with print-as-a-statement (I just call my function) and can only be done to other code by such anti-modular nastiness as scope injection.
Personally, I'm more upset at losing the % formatting operator. "%s %s" % ('that','sucks') Such a handy operator for the 95% of the time when simple is all you need. "{0} really {1}".format('this','sucks') 
I think it's just that Python has become popular enough that people *have* to use it sometimes. Maybe they got a job where it is mandated, or some legacy code, or they just feel compelled for professional development. This breed resentment, which can be projected onto the language.
It may be longer, but it's amazingly more readable.
Beg to differ.
Obviously not, py3k was not out yet.
Source?
Both have two parts, a format string and the parameters. However... In the new version the parameters *must* be in parentheses - the old version didn't need it if there was only a single variable. In the new version, between the string and the parameters you have the function name "format", in the old version you had a single operator "%" The old version's formatting codes were familiar to old codgers like me who are comfortable with printf e.g Old: `"%-6.2f" % dollars` New: `"{0:&gt;6.2f}".format(dollars)` Yes, the new version has some very spiffy features and for more complex output has some distinct advantages. But why deprecate the % operator? It's not like it's hurting anyone. And in many (most?) cases it's clearer and more elegant. (edit: formatting)
Yes, it was still more or less vaporware at the time.
In Python 3.1, you can say `"{} really {}".format('this','sucks')`
Shameless self-plug: http://diveintopython3.org/porting-code-to-python-3-with-2to3.html#print
It's still 6 characters longer than: `"%s really %s" % ('this','sucks')` 
But then you'd have Javascript. 
It would be great if one could call functions and methods without specifying the parentheses. Sort of like this: somefunction(arg1,arg2,arg3) the following should also be syntactic sugar: somefunction arg1, arg2, arg3 That way we can have print work just fine as it used to. I'd love to know why this is not possible.
You're *the* Mark Pilgrim?
But it's much clearer if you aren't used to either syntax. People new to the language will recognize it quicker.
as someone just learning python I agree that its difficult to recognize the % syntax. but I prefer learning some syntax rather than a method and its much easier to remember.
It's 2:30am and I really can't think right now but doesn't Ruby do that?
Yes, yes it does.
Ruby does this. I love Ruby, but I admit there is one major issue. In Python, if you have a function `f` and you refer to it without parentheses, you're referencing like any other variable. That makes it very easy to pass functions around: &gt;&gt;&gt; def f(x): return 2 * x ... &gt;&gt;&gt; map(f, [1, 2, 3]) [2, 4, 6] In Ruby, because of what you said, `f` will be called immediately, and if it's expecting one argument (like it should be for a map to work), you end up with an `ArgumentError`: &gt; [1, 2, 3].map f ArgumentError: wrong number of arguments (0 for 1) from (irb):2:in `f' from (irb):2 &gt; [1, 2, 3].map &amp;method(:f) =&gt; [2, 4, 6] (Of course, `map` in Ruby is expecting a block as opposed to an explicit method, but that has nothing to do with this issue. In any case, it should sufficiently illustrate the problem.) Now, you could say that there should be some intelligent way of resolving some of these conflicts, but there are always issues: * Are you going to require parentheses on no-argument functions? If not, how else are you going to distinguish between the two cases? You would have to go the Ruby route of having extra syntax for accessing a function. And if you do require parentheses in this case, you end up being inconsistent. * If you say that the language should raise an exception when the function is given a different number of arguments than it is expecting, *except* if it's not given any arguments, then you're being inconsistent. * Even without the previous problem, how do you handle variadic functions like: &gt;&gt;&gt; def f(*args): print args ... &gt;&gt;&gt; f What does that last line do? Different languages take different approaches to solving these problems. Ruby chooses to emphasize blocks, making the less common cases (at least in the Ruby mindset) slightly more annoying. Python chooses consistency and simplicity, always requiring parentheses. Of course, Haskell is, as always, an interesting case. It doesn't require parentheses, but you can still refer to functions by name. But, you have a completely different frame of mind to deal with any issues. For example, the following doesn't do what you may think it does: &gt; floor sqrt 3 Instead of calling `sqrt 3`, then calling `floor` on it, the code actually calls `floor` with two arguments: the function `sqrt` and `3`. Whoops. Instead, you can do: &gt; floor (sqrt 3) or better yet: &gt; floor $ sqrt 3 But the important thing is the different mindset that allows for this possibility. The parentheses in that first solution isn't for function calling; it's for grouping. That's why you can't call a function of three variables in Haskell like this: &gt; f (1, 2, 3) That calls `f` with one argument: a tuple of three elements. Once again, whoops. Hope that helps shed some light onto the issue, and sorry for the verbosity.
OMG!!!! He exists!
on the flip side, invoking a lambda in Ruby is ugly: l.call(args) # ugh! l[args] # what??? l.(args) # 1.9, still not pretty 
Yah. Python basically **rocks**. Now, Python could perhaps (not sure) be greater still if it used the prototype model instead of the object-oriented one, but if you ask me to choose between JS and Py, I'll tell you right away: *fuck braces*.
format is a method, not a function, you insensitive clod. Next you'll say that black people look the same!
Seems like a relatively trivial change. Now you can &gt; map(print, (1,2,3,4))
Add commaless tuples while you're at it. As far as I'm aware most uses of tuples don't even need the commas to be unambiguous.
It's pretty easy to believe Mark Pilgrim exists. It takes a little more faith to believe Mark Pilgrim posts regularly on Reddit.
Rather the other way round.
Because Python has few syntax. Take a more complicated language and you'll cry in despair for every new syntactic feature that gets added.
That would be cool, in some way. I always liked creating functions by making anonymous functions and assigning them to names instead of the named/unnamed split that there is currently.
% formatting is still present in python 3.
You didn't knew already? His username wasn't red already? Dude...
 lst = (1, 2, 3, 4) print(*lst, sep='\n')
http://www.youtube.com/watch?v=1RjtT17WbcQ 6:50 into the video Paraphrase *** I just implemented it last week, and I really have to get used to it still. *** 
Ruby on Rails, it's a web framework? I haven't read up on it much, but thanks. I'll look into it. Do you recommend any projects I can look at? 
Yes I admit that in my last sentence. :]
This sucks even more for us with non-English keyboards. For example in Scandinavia, we have to press Alt-Gr + 7 for a _{_, and Alt-Gr + 0 for _}_. Imagine the pain. 
What does this offer that Boto does not?
I'm saddened that they didn't provide direct support for string interpolation. "The value of var is $var" Yes, it can be layered on top, but it's not nearly as convenient.
It's a picture of my grandfather, Wilfred, taken when he was 17. We found it among my aunt's effects after she died. I am, as they say, the spitting image of him.
No, just _a_ Mark Pilgrim. Haven't you heard I come in six-packs? /zaphod
I looked at the boto's SimpleDB pages after I saw this submission, and it seems that this one simply has more and different ways to query the db.
The only thing I don't like about it is that it hasn't always been that way. Don't get me wrong, I love the fact that python is not stagnant and aims to be better. It's just too bad that it has to be backwards-incompatible.
The main difference is this features a Model/Query API based on Django's.
I think it's a good idea. `print` has always been the odd one out among statements. Every other one is concerned with either flow control (if, for, while, try/raise/catch etc), or namespace manipulation (assignment, del, def, class etc). The only other arguable one is `assert`, and even that's related to flow control (effectively a conditional raise). It also isn't really flexible enough, so has various special cases bolted onto it, each requiring special syntax. Eg. once you start writing to files, rather than stdout, you used to have to switch to .write(), which required the &gt;&gt;f syntax to be introduced. Then there's the softspace handling etc for trailing commas, which is very messy. Using a function fits all these special cases into simple argument passing.
Hehehehe. I enjoyed the Dive into Python book. That was in essence what taught me Python.
&gt;the old version didn't need it if there was only a single variable. OTOH, that single object handling often led to problems. Eg, you have some code like: print "obj is %r" % obj It'll work fine, until one day obj happens to be a tuple and you get an error. The other problem is that the precedence of % binds too tightly, so you often need parentheses anyway if you do anything to the object being formatted. 
Yes, that would be a nice idea.
Thanks
Thanks for that.
You mean open source web applications written in Rails that you can study? There are few open source Rails apps out there because most people use Rails for commercial/in-house development, but here are a couple of apps that you could check: - http://typosphere.org/ - http://www.redmine.org/ - http://www.opensourcerails.com/ Or, if you're looking for general Rails documentation: - http://guides.rubyonrails.org/ - http://apidock.com/rails - http://wiki.rubyonrails.org/
It makes much more sense. And have you seen Python 2's print redirect syntax? /me shudders
Ugh, I hate it when people bring this up. There's a major difference between calling a method with parameters with the call operator (), and referencing the method _itself_ - it's one of the primary reasons Python is so flexible in this regard. Ruby gets away with this because of (amongst other things) its Smalltalk-esque message passing paradigm. Remember: _Explicit is better than implicit_.
If you want something declarative in that vein, check out [Construct](http://construct.wikispaces.com/). I've used it a lot and it makes it genuinely fun to implement new parsers :)
FYI, the MATLAB inspired [Pydee](http://code.google.com/p/pydee/) now has pyflakes built in.
Wow, [you're right](http://had.co.nz/ggplot2/scale_gradient.html). Wish there was a Python version of that.
&gt; Ugh, I hate it when people bring this up. There's a major difference between calling a method with parameters with the call operator I agree, but if the method is the *first token in the line*, we could assume that the method is being called, as just putting a noncall in a line is a nullop and has no purpose.
What's so inherently awkward about the prototype model (as opposed to implementation problems)? You have an object, which you clone and modify to create a new object.
If by *Python programmes* you mean *new Python demographic* then yes, this is what I meant.
Technically a method *is* a function, you hapless deviant. Next you'll say that all asians like rice. 
Hello security problems, how are you today? Explicit is better than implicit: "%(my_var)s" % locals() #&lt;-- DON'T ALLOW USER STRINGS HERE "%(my_var)s" % {"my_var": my_var} # Users strings are OK here
You weren't aware because it's not true. See your sibling comments.
Do Swedes just not program in C, Java, etc., etc.??
&gt; But why deprecate the % operator? It's not like it's hurting anyone. And in many (most?) cases it's clearer and more elegant. It's not being removed anytime soon. It's in 3.1 as a regular feature, and I haven't read about concrete plans to deprecate it in 3.2 (though it has been discussed). 
`format` is the name of a method and of a function: &gt;&gt;&gt; "{0:.0f}".format(10.1) u'10' &gt;&gt;&gt; format(10.1, ".0f") u'10' 
Won't work in Python 3, since `map` has been swapped with `imap`. You'd have to wrap that in a list to get it to invoke the side effect, at which point you're wasting way too much effort. Just do what partisann says and `print(*lst, sep="\n")`.
The first thing to realize that a great deal of what you know about OOP is based on class-based implementations. Now, I know concepts like inheritance are central to OOP, but even then, the way we expect these concepts to manifest themselves stems from the class model. That said, inheritance in the prototype model is simply cloning followed by modification. Instead of having an archetypal *class* that you instantiate, you start with the object *already* "instantiated." This object, the prototype, is then cloned to make new objects. In the cloning process, all the behavior is carried over, just like in inheritance. Maybe what feels weird to you is that all the data is also copied, but in the prototype model, the data is as much a part of the object as is the behavior. As for Mixins, this is a heavily class-related construct. Still, what is the bare essence of a Mixin but a way to inject extra structure into an existing archetype (which is always a class in a class-based model). So, in the prototype model, a Mixin might be analogous to a function that injects extra data and behavior into an existing prototype. But more importantly, in the prototype model, you don't think in terms of Mixins. There are only objects that you can clone and modify, so there's no need to augment a class. If you need extra behavior, add it straight to the object when you need it.
thanks for the info.
Of course they do. It just takes several years to realize that typing those braces is a lot more work than with an English keyboard. That said, they can't just switch over to an English layout, because they type lots of stuff with Scandinavian letters all the time. I guess this applies to something like the German and French keyboards too. 
"Py65 is a Python package that provides building blocks for simulating hardware systems based on the 6502 microprocessor and its derivatives." That needs to be in the title next time, gst.
The main problem is that there aren't enough parenthesis types to go around. "[" always represents a list, but "(" represents both function calls and tuples. And in Python 3, "{" represents both dicts and sets. Which is very embarrassing, really, since Python 3 is supposed to be cruft-free! The only unambiguous way to resolve this is to always use set(), dict(), list(), and tuple() instead of the various bracket types. I'm pretty sure Python allows this, but I'm not sure there isn't a performance penalty due to the name lookup. Oh well.
There will technically be a performance penalty, but I don't think many people spend much time byte code optimizing ;). As for the inconsistencies, they're definitely there, but I think the advantage of set literals out weighs me caring about the minor, zero-item, inconsistency.
&gt; So how do I alter a prototype based on a template (to add, say three methods and a few properties to the object)? How do I do this for two other prototypes without repeating myself? In a pseudolanguage: someObject = parentObject.clone(); someObject.extend(someMixin); This even allows you to extend a single object easily, as opposed to a whole bunch of objects that will be instantiated from the prototype you alter. What's the simplest way to extend only *one* object in Python? I'm not saying it's difficult, but as far as I know, this isn't part of the prevalent mindset of Python either. To understand the prototype model, you have to distance yourself from the class model and think in the prototype model. `extend` might be defined as (in Javascript-esque syntax): object.extend = function(mixin) { for (var prop in mixin) { this[prop.name] = prop; } } It's all about the language and the implementation details.
It is not bad to read the official Python Language Reference: http://docs.python.org/reference/datamodel.html It will show you that there is no magic behind the metaclases or descriptors. They just use the defined lookup rules. 
As the comments pointed out, the namedtuple is nearly as slow as creating your own class. If you need speed, you need a tuple.
What did you to to get it to compile?
The win32console module in [pywin32](https://sourceforge.net/projects/pywin32/) offers the same functionality. On another note, the Windows color/attribute constants are way too long, making them hard to write (and, more important, to read). I personally like the [Clipper](http://en.wikipedia.org/wiki/Clipper_(programming_language\)) color strings more, e.g. "W/N" for white on black, "C+/B" for bright cyan on blue, [etc](http://www.itlnet.net/programming/program/Reference/c53g01c/ng9c7f1.html) [*EDIT*: the "C","M","Y" are my own extension; Clipper uses "BG","RB",and ""RG"]. I've been using them since my programming dark ages (QBasic).
Not that I have ever tried, but [RPy](http://rpy.sourceforge.net/) may allow you to use ggplot2 from Python.
so true, so sad....
Ouch. Why is it that slow? UPDATE: I checked the code. It's implemented in Python. A C implementation would be much faster.
Unicode support should be mostly fixed in 1.2.3 release candidates, and we're doing a greater overhaul in trunk (2.0).
Anyway it prevents doing [such](http://www.daniweb.com/forums/post884679-1.html) code.
That's good to know. At this point, I'm loving postgresql anyway, though. 
I was chatting with Mark Pilgrim in the hallway at PyCon and he said that Fredrik Lundh (effbot) gave him access to a pre-release version because he wanted to include a chapter on PIL in 'Dive into Python 3'. (How's that for a run on sentence!) So it apparently does exist but I don't know when it will be released. Hopefully the effbot can enlighten us.
I thought [this email](http://mail.python.org/pipermail/image-sig/2008-December/005338.html) would get me somewhere, but so far, alas. That attachment doesn't make any sense to me anyway. And should I be afraid to request such a thing from Guilherme? Who knows.
Fredrik Lundh used to be on Reddit (He's replied to some of my comments) but it looks like he deleted his account.
It's just a misnamed patch file. Just rename it to `PIL-1.1.6-py3k.diff`, go to the PIL source directory and do patch -p1 &lt; PIL-1.1.6-py3k.diff python3 setup.py install Seems to be compiling ok but I haven't tested if it actually works.
From the sounds and looks of it, this stuff is great for lazy programmers like me. Can anybody give some insight for *useful* real life applications of this?
Genetic programming is enormously computationally expensive. So basically it's only useful when you have a problem you have no idea how to solve. A good example of this is trying to find a pattern in time-series data where you don't really have any good idea what the underlying function is. 
Any idea when i can purchase the physical copy of DiP3?
The "manuscript" is due to be complete by the end of June (HAHAHAHAHAHAHAHA). Tech review + copyediting + proofing = August 10th (HAHAHAHAHAHAHAHAHAHAHAHA). Then there's a lull where it goes to the printer and they, I don't know, typeset it by hand or something. That takes about six weeks, unless they see their shadow, or something. Then it magically shows up on my doorstep, by which time I'm so burned out that I don't even want to open it. My wife bakes me a cake, we all celebrate, and I try not to let on that I've already spent my advance on hookers and blow. At least that's all I remember about the process from last time. I may have some of the details mixed up.
Do you consider guest authors for sections...? 
In reality, hookers gave you some blow and you tried not to let on that you spent your advance on your wife and cakes.
Ok, I love python as much as the next guy. But...can't you do this with `echo` too? The last time I used ANSI escape sequences I fell off my dinosaur.
Not on this book, no.
ok, if it is like RWH, I bet on november.
do they have a jythonc replacement yet?
It's been awhile. Talk to the maintainer of that project, he's pretty reachable.
Perhaps an adventurous Python developer could set up something like this site: http://isitruby19.com/
&gt; Then there's a lull where it goes to the printer and they, I don't know, typeset it by hand or something. That takes about six weeks, unless they see their shadow, or something. Given the number of format transitions involved, I suspect that book publishing is actually a front for high-energy particle physics. One day they'll smash a Word doc, a PDF and a Quark document into each other and the Higgs boson will pop out. Also, my experience with Apress (first edition of my book on Django last year) was that it was about a month from the time I sent back the last reviewed PDF to the day books started shipping. I sent the last PDF of my second edition about 10 days ago, I think, so we'll see how it goes this time. *Edit:* And I want to go on the record right now as saying that if I do another book, it's going to be published simultaneously on stone tablets and online as an animated GIF. Errata will be delivered by dropping corrected versions as meteors, or via volcano, depending on where the customer lives. And if that's not possible then I'll retreat, Knuth-like, for a couple decades and build the technology.
I hope so, but googling for it this weekend it didn't seem optimistic.
See http://bitbucket.org/effbot/ for 1.17. I seem to remember that it also supported 3.0, not sure though 
Doesn't work on XP for me, Z:\seq\00349.termcolor.python&gt;python termcolor.py Current terminal type: None Test basic colors: ?[30mGrey color?[0m ?[31mRed color?[0m ?[32mGreen color?[0m ?[33mYellow color?[0m ?[34mBlue color?[0m ?[35mMagenta color?[0m ?[36mCyan color?[0m ?[37mWhite color?[0m ------------------------------------------------------------------------------ Test highlights: ?[40mOn grey color?[0m ?[41mOn red color?[0m ?[42mOn green color?[0m ?[43mOn yellow color?[0m ?[44mOn blue color?[0m ?[45mOn magenta color?[0m ?[46mOn cyan color?[0m ?[47m?[30mOn white color?[0m ------------------------------------------------------------------------------ Test attributes: ?[1m?[30mBold grey color?[0m ?[2m?[31mDark red color?[0m ?[4m?[32mUnderline green color?[0m ?[5m?[33mBlink yellow color?[0m ?[7m?[34mReversed blue color?[0m ?[8m?[35mConcealed Magenta color?[0m ?[7m?[4m?[1m?[36mBold underline reverse cyan color?[0m ?[8m?[5m?[2m?[37mDark blink concealed white color?[0m ------------------------------------------------------------------------------ Test mixing: ?[4m?[40m?[31mUnderline red on grey color?[0m ?[7m?[41m?[32mReversed green on red color?[0m Z:\seq\00349.termcolor.python&gt; 
Does anyone have experience using these sort of strategies to create windows GUI apps? Here's something cool along those lines: http://buffis.com/2007/02/24/sending-strings-between-win32-applications-with-python-wm_copydata/
Dear Sir, I am interested in your ideas and would like to subscribe to your newsletter. (already bought your books, dammit)
Next book you publish I'm going to buy, which I never did for your first because I won it.
As said on documentation: Terminal bold dark underline blink reverse concealed Windows no no no no yes no 
Awesome! This makes me want to code an old school door game in python now...
It's ANSI, not ANSII. The author has jumbled ANSI and ASCII together.
&gt; As said on documentation: Er - I can't see a "has colo[u]r" column - ? :)
Blog spam AND a link to a pay-for magazine. Nice. :)
1979 is calling...
it has the title "Terminal properties" and is the GIANT TABLE.
.. and fails to make the colour situation clear, hence the original comment and reply. ['bold', 'dark', 'underline', 'blink', 'reverse', 'concealed']. No colour. See if they'd said 'color' I would have gleamed from that there was information about that on it. Not thrilled about dwelling on it, but fairly key to this thread. That's why I said with surprise "Doesn't work on XP for me" about a library that claims "ANSII Color formatting for output in terminal", and where the GIANT TABLE entitled 'terminal properties' doesn't imply anything different. It's not the end of the world - it will be a useful tool for me on other platforms. The author has done fine work. Hat tip. Still - funny thing. Forum where I mention surprise at the XP situation has a steady stream of commenters referencing phantom documentation. 
Wow, no kidding. That is pretty short. Pretty cool, man. [Whoosh](http://whoosh.ca/) is a richer alternative.
Will put a link to Whoosh on the page, lest anyone thinks this is the state of the art in Python FTS 8)
Wow, that's spectacular code. Good job!
I like it. It even has tab completion for objects: `` /usr/home/joost/tmp &gt; print( sys.__class__ ) &lt;type 'module'&gt; /usr/home/joost/tmp &gt; sys.argv ['./pysh'] /usr/home/joost/tmp &gt; sys. sys.__class__ sys.__stdin__ sys.exc_value sys.path sys.__delattr__ sys.__stdout__ sys.excepthook sys.path_hooks sys.__dict__ sys.__str__ sys.exec_prefix sys.path_importer_cache sys.__displayhook__ sys._getframe sys.executable sys.platform sys.__doc__ sys.api_version sys.exit sys.prefix sys.__excepthook__ sys.argv sys.getcheckinterval sys.setcheckinterval sys.__getattribute__ sys.builtin_module_names sys.getdefaultencoding sys.setdlopenflags sys.__hash__ sys.byteorder sys.getdlopenflags sys.setprofile sys.__init__ sys.call_tracing sys.getfilesystemencoding sys.setrecursionlimit sys.__name__ sys.callstats sys.getrecursionlimit sys.settrace sys.__new__ sys.copyright sys.getrefcount sys.stderr sys.__reduce__ sys.displayhook sys.hexversion sys.stdin sys.__reduce_ex__ sys.exc_clear sys.maxint sys.stdout sys.__repr__ sys.exc_info sys.maxunicode sys.version sys.__setattr__ sys.exc_traceback sys.meta_path sys.version_info sys.__stderr__ sys.exc_type sys.modules sys.warnoptions /usr/home/joost/tmp &gt; ``
Argh! How do I make a piece of copy/paste come out right here?
Indent lines with four spaces will probably do what you want.
Seems to be down. Does any one have a copy of the text / mirror?
Indent by at least four spaces. [Here](http://daringfireball.net/projects/markdown/syntax)'s the markdown reference.
This is from 2003, so some of it is quite out-of-date. For example, the DSU idiom has now been folded into list.sort (and sorted) using the _key_ parameter. (Internally, it's still doing a DSU, though.)
It's up again. If it's down, try this: http://www.suttoncourtenay.org.uk.nyud.net/duncan/accu/pythonpatterns.html 
The design is intuitive and very easy to use. 
This is cool. I'd definitely replace bash with this.
Nice. So how do I get it into my G1? 
&gt; The definitive reference book Design Patterns [GoF] describes a set of patterns for object-oriented software design. Argh. It drives me crazy when people mention GoF without acknowledging the original: [A Pattern Language](http://en.wikipedia.org/wiki/A_Pattern_Language). Design Patterns is good, but it's really an expansion pack. &gt; There are many other common idioms in Python which (depending on your viewpoint) are certainly patterns, although they are perhaps too small to count as Design Patterns. This is where Design Patterns leads you astray. Those *aren't* too small to be design patterns. Patterns can occur at any scale. GoF only talks about architecture-level ones, but that isn't Alexander's intent. The original work talks about patterns from how you should position the cities in your country down to what kind of chairs you should have. GoF is an excellent book, but I find it dilutes a lot of what's really deep about Alexander's ideas.
The "tid &gt; None" had me scratching my head for a while. I didn't know None compares smaller than any other object! After some searching, it seems like an [implementation detail](http://www.mail-archive.com/python-3000@python.org/msg15015.html) that's being removed from Python 3. Why not use "tid is not None" instead?
Line width. =) Its only a hack. If I were to start cleaning it up, the size would probably double, and that'd ruin the fun.
Wow, this is really amazing. I think I'm going to switch from iPython. The screencast is great.
...you America-centered, Commonwealth-biased individual.... :)
I'm using this code (pyevolve) to help optimize the design of a front suspension for an recumbent electric tricycle. Control variables are the length of different structural members, optimizing for weight, displacement and road forces being transmitted to the handlebars.
seems nice, but can it do this: http://xkcd.com/356/
&gt; Python modules are Singleton instances: another case of Python taking a design pattern and making it a fundamental part of the language. Simplicities like this are why I love python, and also why it hurts so much to watch Java and C++ coders try to write python.
Well, after having lots of frustrating problems with Django I have decided to finally take the plunge and move over to Pylons. While reading the Pylons documentation I noticed a tutorial for deploying Pylons using apache, mod_fastcgi and mod_rewrite, but couldn't find any tutorials for apache+mod_wsgi. This struck me as rather odd.. Shouldn't Pylons be using mod_wsgi by default? Isn't WSGI adherence one of Pylon's main standing points? I understand fastcgi and rewrite are supported by more of the shared hosting providers, but when it comes to actual performance and reliability, is mod_wsgi the better path to take? Or am I completely wrong... Thanks PyReddit, I know you'll send me in the right direction.
paster serve + nginx reverse proxy
mod\_wsgi. mod\_python's development has been slowing whereas mod\_wsgi's is accelerating and learning from the lessons of implementing mod_python. And almost all the web work being done in Python these days build on or for WSGI. Plus, [Pylons integration with mod\_wsgi is fairly easy](http://code.google.com/p/modwsgi/wiki/IntegrationWithPylons).
This is not the case for a module that is in a package if it is imported relatively vs. absolutely. You'll get a reference to two different module objects.
1. Settings--&gt;Applications. Check Unknown Sources. 2. Open your browser, on the G1, and go to http://code.google.com/p/android-scripting/ 3. Download and install the apk in the featured downloads.
Using fcgi doesn't preclude wsgi, but I don't really know why it would be a preferred method of deployment. mod_wsgi in daemon mode with some mixture of threads and processes is a not a bad choice by any means. Using nginx to proxy to an app server would let you serve static files with nginx, which could be a big win.
`mod_wsgi`, but its always so problematic to install (not in a big way, just weird errors I don't feel like googling) I end up just using `mod_proxy` to paster server.
Any reason to use this over the ipython system shell mode (ipython -p sh)?
cool didn't know ipython could do something like this. 
On python 2.5 and higher, you can get rid of the utf-8 BOM by doing: data = codecs.open(filename, encoding="utf_8_sig")
Note: This is from 2005, and applies only to Python 2.x
Awesome, just got it and it looks fantastic, thanks!!! The LUA code worked off the bat, the Python examples complain about some Python libs (e.g. TTS) not being installed. Any idea where I would find those? 
... + supervervisord to restart the server if is needed (memory leaks in dependant libraries, ...)
Install off of market. Just search for TTS. It's the first result. You have to run the TTS program once before the scripts will work.
You're kidding me, right?
that's exactly what i thought. anyone care to explain why the above comment is down-voted and a post explaining how to join strings (and creating an unnecessary class to do so) is upvoted? 
thank you, v 0.1 has many bugs, I'm working on a more flexible version
http://www.google.co.uk/search?q=linux+python+path&amp;ie=utf-8&amp;oe=utf-8&amp;aq=t&amp;rls=org.mozilla:en-GB:official&amp;client=firefox-a which leads to http://mail.python.org/pipermail/python-list/2005-December/358215.html which answers your question?
you got Java in my Python
After I launch the Python Shell, and create a new window, and compile the program (F5) the color-coding of the code disappears.... what's the deal?
Also: How do I see all of the functions of a library I'm importing. For example if I "import time" how am I to see which functions are defined in "time?"
try 'dir(time)' or 'help(time)'
dir() might be too messy. Try see() from http://github.com/inky/see/tree/master
And it feels really really weird.
i've tried bash nn both .bashrc and .bash_profile and still it doesn't seem to work? - if it's anyhelp i had to create both the .bashrc file and the .bash_profile 
Alright, but let's not forget the thousands of lines of code that were needed from the android library to do that
Having looked into the Python Android library, it looks fairly incomplete. There is no way to pick a contact out of the contacts list (though this is possible with the Lua bindings), there is no way to make a phone call (though sending an SMS is possible), and there is no way to handle an incoming text message or incoming phone call. So, all in all, the Android Scripting Environment is very promising, but this release leaves much to be desired. They should support fewer languages, but support them better. 
Awesome. Got it all sorted out. Now, having looked into the Python library, it seems fairly incomplete. There is no way to pick a contact out of the contacts list (though this is possible with the Lua library), there is no way to make a phone call (though there is a way to send an SMS), and there is no way to handle an incoming text message or incoming phone call. Did I miss something, or is the library missing a ton of functionality? 
Thank you. 
Thanks, I'll look into it. 
Are the images broken for anyone else? 
I figured out that if I don't save the file with a .py extension, than the enterpreter(?) treats it as a regular text file. 
fanboys, I'm glad some yet recognize the idiocy even when it's branded as "python"
And the tens of thousands of line in the supporting Linux system.
Wow, only six lines. Here it is in one: __import__('android').Android().startActivity(’android.intent.action.VIEW’, “http://books.google.com?q=%d” % int(__import__('android').Android().scanBarcode()['result']['SCAN_RESULT']))
And the tens of thousands of people who actually know how to type. Sorry, I couldn't resist.
yup
You're right. The functionality is skimpy for Python. It will get better. This is just an alpha after all. I recommended making a [feature request](http://code.google.com/p/android-scripting/issues/list) for anything that isn't there. The head developer seems pretty accommodating. See the issues for Perl support.
And as of yet [no Python 2.5 Windows binaries](http://www.riverbankcomputing.co.uk/software/pyqt/download) :(
Why would you use an older version of Python on Windows?
&gt; a new, more Pythonic, API has been added for connecting signals and slots Thanks to the dev for that one. I hope the dev puts out a new book soon though, I'm quite ready to spends some dollars on that.
numpy and matplotlib don't support Python 3 yet.
Was referring to 2.6/2.7
Download the source and compile it yourself if you need it.
[matplotlib don't support Python 2.6 yet](http://sourceforge.net/project/showfiles.php?group_id=80706&amp;package_id=278194)
Surprising. Ok.
pyTTS( a third party module) doesn't support Python 2.6 yet.
Actually, it *does* support 2.6. There's just no windows installer for 2.6, so you have to use the source. The latest release of matplotlib was in December 2008, I guess they just didn't bother repackaging an installer when 2.6 came out.
If riverbanks wants to do business that way, fair enough. That is a stupid way of seeing it me think though.
Now, turn the documentation from C++ examples to Python.
What kind of a programmer are you if you absolutely have to use a windows installer?
Nope.
Whoosh. A company needs installers for integration and deployment purpose. Programmers aren't the end of the chain... 
Whoosh yourself, how hard is it to roll up your own?
Why don't they make it LGPL then ?
Because the developer believes he's going to make more money not doing that. How's that related to making your own windows installer?
Well, I don't like to spend money on half baked product.
So... This product is half-assed because it doesn't ship an installer for an older release of Python in security-fix-only mode which you need because you have dependencies you can't install under Python 2.6 because you are unable to type `python setup.py install` on a command line and absolutely requires an installer to consider them "supported" under Python 2.6?
Python 2.5 is still fucking relavent. Many libraries and apps are still not compatible with Python 2.6 version. So for many users including me its not feasible to use Python 2.6 YET. And please divide what you are saying into sentences its fucking difficult to follow three lines of spaghetti. 
Here's a downmod to help you to learn to resist.
unittest is still much more widely used than nose.
support 2.6 in theory is one thing, support it in practice is another thing. even the author of matplotlib cant make a 2.6 installer at the moment. http://www.nabble.com/binary-installers-for-python2.6--libpng-segfault%2C-MSVCR90.DLL-and-%09mingw-td23971661.html how can a user use the source to plot sth.?
Has python2.6 more user than Python2.5? I don't think so. and "setup.py install" is not enough to install a module with c/c++ source file. install PyQt with it's sourc is more complicated than a normal module with c/c++ source. It need's install MinGw, Qt, SIP... 
Seriously. The current method of using C++ function signatures in your python code looks like a giant turd in the middle of your jello.
[version 1](http://commons.wikimedia.org/wiki/Template:WTFPL-1) of the WTFPL. It seems the copyright owner and address have changed. And from [Wikipedia](http://en.wikipedia.org/wiki/WTFPL): &gt; The original Version 1.0 license, released March 2000, was written by Banlu Kemiyatorn who used it for Window Maker artwork. Samuel “Sam” Hocevar, a French programmer who was the Debian GNU/Linux project leader from 17 April 2007 to 16 April 2008, wrote version 2.0.
yea. I considered it until I saw the yearly fee. I'll stick to the python subreddit thank you.
First: `__del__` is a finalizer, not a destructor. It's invoked by the garbage collector when the object gets collected. Why does that matter? Well, in CPython today, it matters because the mere presence of `__del__` means that the GC won't break circular references (as the article notes), meaning you've just increased the likelihood of a class of hard-to-spot memory leaks. But other Pythons, and perhaps the CPython of tomorrow (i.e. in the Unladen Swallow plan), don't use a reference counting garbage collector. Now, do you know when that DB connection is going to get closed? Well, it's non-deterministic and if it's a generational garbage collector and if the object holding the DB handle made it into the oldest generation, it may be a while. While you may not care about future-proof code, you've just tied your resource handling to the behavior of the garbage collector. The fact of the matter is, outside of toy examples, managing object lifetime is an important part of writing good code in garbage collected languages, almost to the same degree it's important in C or C++. If a problem is too complex for a with statement, you're probably better off explicitly managing object lifetime with a "dispose" method. There are situations that call for the use of `__del__`, and I certainly don't balk at putting external-resource freeing code in `__del__`, but I would recommend against relying on that in general, and I recommend against defining `__del__` unnecessarily since you then need to start worrying about cyclical references to a far greater degree (and since your DB handle probably already has its own `__del__` that closes out the connection).
These are the free binaries. If you have a support license with them, call them up.
Yes, how is that a problem? How much hand holding do you need? Also, I was suggesting doing the other way around, install your dependencies for Python 2.6 and then use the prepackage PyQt installer for 2.6.
To get around markdown, use backticks like `__this__`
This is so strange.... I have a matplotlib windows binary installer for python 2.6 in my personal 'downloaded python packages' folder (matplotlib-0.98.5.3.win32-py2.6.exe). I'm sure I got it from sourceforge. I wanted to show you that's available, maybe they backed-off the binary, might means they're almost ready. Anyway... here you can find python 2.6 binary installers for numpy and scipy: scipy: http://sourceforge.net/project/showfiles.php?group_id=27747&amp;package_id=19531&amp;release_id=689284 numpy: http://sourceforge.net/project/showfiles.php?group_id=1369&amp;package_id=175103 scipy is in 'release candidate', numpy is fully official.
Great summary (better then TFA I'd say). Another important note that I've found a lot of people unaware of is that the __del statement__ is not the same as calling the __del method__. It removes the variable from scope, and the object it referenced will eventually have its del method called (non-deterministically).
Fixed. Thanks!
He gave this talk at Chicago's python group (chipy) last night. Here is the video for anyone who is interested in seeing the talk in addition to the slides: http://blip.tv/file/2232410
A well-written and well-researched writeup. I particularly enjoyed (and winced) at the thread tug of war that happens when a thread releases the GIL, the next one is signalled, but by the time it gets to try to acquire the GIL the first thread has already grabbed it again. Rinse, repeat (9 million times. literally.)
FYI there's been at least one patch over the ages to remove the GIL, I think, by explicitly synchronizing every PyObject. Performance was an abysmal failure IIRC, but this was something like 10 years ago. I think it was by Greg Hudson, if you're trying to Google it. I think if there's anything to be learned from the multicore era, it's that small predictable semi-constant overheads quickly vaporize in the face of 16 CPUs :-)
Does anyone know the equivalent to this in Ruby?
I believe someone on the mailing list said they removed it because it had issues related to .png files. You may have gotten it right after they posted it.
That should be _CPython_ and not Python. The original article is misleadingly titled. Hence, downvoted for attention-whoring. 
I am hoping for unladen swallow http://code.google.com/p/unladen-swallow/
Thanks!
And upvoted parent comment for accuracy and fact-correcting.
No, Mac OS X's `poll` is unreliable. This has been a known issue for a very, very long time...
Plus it's entirely redundant with the [link to Beazley's PDF](http://www.reddit.com/r/Python/comments/8s1ru/david_beazley_on_the_gil_pdf_warning/).
http://www.artima.com/weblogs/viewpost.jsp?thread=214235 Greg Stein
If for some bizarre reason you feel the need to implement a doubly-linked list in Python, you can use weak refs for the back references. Same for DOMs -- use weakrefs for the parent linkage, because if the parent is destroyed or explicitly disowns the child element and nothing else holds a reference, the child will be freed as well.
Do you know if Stackless Python uses the GIL?
&gt; The interpreter has a global variable that simply points to the ThreadState structure of the **currently running thread** Purpose = defeated.
Yes. But the programming model is different, and threads are normally avoided.
Unless the GIL turns your 16 CPUs into 1.
From reddiquette: &gt; Please don't... &gt; Linkjack stories: linking to stories via blog posts that add nothing extra
This link was posted by a bot which follows a number of Python-community blogs and posts the articles to the Python subreddit (in this case, I'm pretty sure gst -- the bot -- simply reposts from the Planet Python RSS feed). As such, there's really no way for it to try to observe this rule, since (assuming gst lacks strong AI) it has no way of knowing whether a given blog post is "adding something extra".
&gt; FYI there's been at least one patch over the ages to remove the GIL, I think, by explicitly synchronizing every PyObject. Performance was an abysmal failure IIRC, but this was something like 10 years ago. I think it was by Greg Hudson, if you're trying to Google it. If I recall correctly, each thread performed at 60% of the performance of the GIL version which means that if you have 2 threads running in parallel, you get a 20% boost. Of course, it also kills single threaded performance.
I thought the reddit guys said that they confirmed gst was not a bot in the keynote at pycon
With a comment history like [this](http://www.reddit.com/user/gst/comments/) I'd be astonished if gst's contributions aren't scripted.
According the slides GIL turns your 16 CPUs into more like 1/10th of a CPU.
I had heard the python threads were bad, but this is just plain ridiculous. A single variable holding the current thread? Jesus. Am I missing something, why don't they just assign objects to one thread at a time and have a locking slow method to convey ownership from one thread to another. Once the thread has ownership it doesn't need to lock access. Java uses this method for parallel garbage collection iirc, and there's no reason is shouldn't work here. You would only get a big slowdown for objects actively used by multiple threads, but some contention overhead is to be expected anyway in that case. It has no effect on single-threaded performance, because that thread always has ownership of all objects. EDIT: the java optimization was about sychronization/locking. [This paper](http://portal.acm.org/citation.cfm?id=1167496) describes how locks become owned by a thread and so that thread can lock the object with little overhead.
or COBOL?
Python has been my primary language since 2001. On one occasion has the GIL impacted me, and that was during a contrived load test where I was opening as many connections as available RAM would permit. A critical fact is that it only impacts threaded CPU-bound workloads, or in other words, &lt;1% of all Python programs. Most programs are IO bound, spending their life waiting on HTTP &amp; DNS requests, disk writes, MySQL, etc., all which involve system calls that occur outside the GIL. In other words you can serve thousands of clients in a threaded model, assuming each of those threads isn't simultaneously computing the millionth digit of pi. This is comparable to the Linux Big Kernel Lock that has existed since it got multiprocessor support. Despite the ominous name, the impact of this lock is only felt if you really stress out the tty layer, module (un)loading, and some other weird/ancient corner case workloads. (Actually I think tty support was reworked recently). Finally Google's ambitious [Unladen Swallow project](http://code.google.com/p/unladen-swallow/) is a quasi-sanctioned fork of CPython aimed at drastic modernization of the VM. The team, including &gt;=2 of the core team hope to remove the [GIL by 2010](http://code.google.com/p/unladen-swallow/wiki/ProjectPlan#2009_Q3_and_Beyond).
Dude. It's a bot
hpricot instead of BeautifulSoup, then just port the &lt;100 line script.
For some background, you might want to read [this article on the GIL](http://jessenoller.com/2009/02/01/python-threads-and-the-global-interpreter-lock/).
I don't see how it's comparable at all. In BKL, most work happens when the lock is not held. In GIL all work happens when the lock is held. I've done some linux kernel programming. There are a *lot* of locks in there by subsystem. Maybe in 2.2.x or some other ancient version the BKL was similar to Python's GIL. It shouldn't be that hard to eliminate GIL, because objects are just 'data' (a dictionary) whereas in BKL the lock is protecting compiled code paths. So I'm not sure what the holdup is.
Downvoted for knit picking... if you say Python most people will assume CPython.
Well, he's got a point. There are cases where cyclic references make sense, but there are at least as many, and most likely more, where they don't and where they are arguably a code smell (e.g., they point to bits of code requiring too much knowledge of/too tightly coupled to each other, or violations of responsibility principles, etc.).
&gt; In GIL all work happens when the lock is held. That is not completely true. In Python, all *python* code executes when the GIL is held. But most C extensions release the lock before starting their computation, as also does any disk/database/internet I/O blocking. So the GIL is a problem only if you are doing heavy computations in pure python code. If the other threads are calling C extensions to compute the results or doing I/O, the GIL won't slow down the execution much.
Fantastic write-up, but almost nobody is going to be affected by this. And the people who are likely are doing it wrong. If you have something that is CPU-bound, you want to split out the work across different processes anyways because that is the only way you can get multiple machines to work on the task. Remember, you can have as many Python processes running on your box as you want and the GIL isn't an issue. And remember, you can create these processes from within python and give them data from your master process and have them crunch the numbers in parallel and have them return the results to the master process and doing that in any other language would be painful but in python it's cake. If you need to shoehorn your stuff into somebody else's process model, take a look at how mod_python/mod_wsgi handles things with sub-interpreters. Indeed, I bet we could probably dispense with the GIL altogether if we mandated that every thread run within its own sub-interpreter, the sole onerous requirement then being that global state would need to be explicitly managed (pickle over sockets or some such). What that buys you over processes I don't know.
Not all problems are better addressed with multiple processes over multiple threads. There are also problems with multiple-interpreters (fine if they don't talk to each other I guess). There is a *reason* why threads won in the concurrency battle.
So it's only an issue if you are writing Python code rather than C...
+1 for agreement and Saturday morning chuckles. 
noice
What's the problem?
I don't get it.
You made a typo when you defined C. The method printed exactly what you told it to.
&gt; I'm fairly certain it should read method. Then look what you defined in `bar`, there it reads 'methon'. At least in my universe.
I can't believe he didn't catch this...
&gt; There is a reason why threads won in the concurrency battle. Except they *haven't*. Nearly all high-traffic websites use multiple processes spread across thousands of machines. Same with even some desktop apps, eg. Chrome. There are occasional problems where threading is better, but to claim threads "won" the concurrency battle is massive hyperbole. I'd even argue that for a *majority* of problems, you're better off with isolated processes communicating through message passing.
You could easily write 90% of the code in Python, have it take up 10% of the CPU time, then rewrite the 10% that takes up 90% of the CPU time in C. Python productivity + C performance + GIL has negligible effect.
But that still leaves the problem that if you have CPU bound activity that you want to spawn in another thread you have to write in C rather than in Python, even if you really *want* to write it in Python. At least other high-level languages (like C# and Java) allow you to use threads without being blocked by a GIL or having to switch down to a lower-level-language where you have to manage your own memory.
Really, big servers don't use threads? :-)
It is only comparable in that you really need a nonstandard workload before the lock becomes 'visible'. It's debatable as to whether "lots of pure-Python computation" is nonstandard, but in my experience it is. It was a pretty poor analogy to pick in any case. :)
select, kqueue, asyncore, twisted... asynchronous I/O rocks, provided you aren't waiting on a database. It's 2009. Why the fuck can't I pass a fd to an SQL query to select() again?
I have been converting my project from Django to Pylons, and I am completely lost on how to include and use helper functions in my templates. For example - I have a function which creates the shortest possible url for the browser section of my site (wrapped around pylons internal url resolving methods) and I need to reference it in my template eg.. {% load simpleurls%} &lt;a href="{% simplify_url(section, sorting, category, page) %}"&gt;Test&lt;/a&gt; How on earth do I do this? In Django I was able to import the template tag and then use it freely, but Jinja2 does not have template tags, nor is there anything in their documentation about the template tag equivalent.. Please help me, I have a whole day to code but I'm stuck on this and it's killing my motivation.
Interesting article: http://www.usenix.org/events/hotos03/tech/full_papers/vonbehren/vonbehren_html/index.html Why events are a bad idea for high-concurrency servers.
Thanks to some help I receieved on the Pocoo IRC channel I am now importing functions into the Jinja2 globals and am able to use them in my templates. Unfortunately the person helping had to leave before I got to ask him a follow up question, so I was hoping you guys might be able to help. My question now is - isn't this horribly inefficient, having all helpers loaded for all templates regardless of whether they use or ask for them? I am sure I could selectively load functions into the Jinja2 globals based on what template was loaded, but wouldn't that just be me making arbitrary decisions for template designers? Shouldn't they be the ones deciding which functions are needed?
FWIW the method Django uses to track custom tag libraries does involve keeping all previously-loaded libraries in memory -- after the first time you invoke `load` with a given library, it's kept in a global registry so it doesn't need to be looked up and loaded again, sort of like how Python itself keeps a copy of every previously-imported module in `sys.modules` to avoid repeated import overhead. So over time, all of the custom libraries you use will end up in that registry. They won't be available to every template (since each template parser instance keeps its own local registry of what's available to it at a given moment), but they will be sitting in memory. (although you can use `django.template.add_to_builtins`, which takes the name of a template tag module and makes it globally available to all templates)
So, a bunch of things to note about that article: 1. They use their own user-space threading library, and concede early in the paper that existing threading systems have scalability problems. 2. Their threading library uses events (poorly - they use poll() instead of epoll() or kqueue) under the hood. 3. They assume that your server will want to do mostly-sequential processing of independent tasks, which hasn't been the case in most of the high-performance servers I've worked on. If events are really a bad idea for high-concurrency servers, somebody forgot to tell the Lighttpd, Nginx, justin.tv, memcached, LiveJournal, and Facebook folks...
There's a second submission someone made on reddit for that as well ( http://www.reddit.com/r/programming/comments/8s1hb/great_talk_on_the_python_gilvideoslides_in/ ) I highly recommend giving giving this a listen if you're interested in the GIL, there's a bit of additional detail from the talk.
What's interesting about this discussion is that just before this talk that Beazly gave on the GIL at ChiPy this last Thurs, was Garrett Smith's talk about asynchrony and threading (look below for diot's post for a link to a video of this GIL presentation) and what seems to make sense in Python: http://blip.tv/file/2232349
&gt; My question now is - isn't this horribly inefficient, having all helpers loaded for all templates regardless of whether they use or ask for them? I don't have an answer to your Jinja question, unfortunately, but you should definitely profile your code with all the globals loaded in before deciding to optimize. I'd be surprised if loading all the helper functions (which only happens once when the Pylons application gets loaded) and putting them into the global namespace (which is just increasing the size of the namespace dict) slowed down your application significantly.
I got an svn checkout today (was looking at implementing some inline caches but I ended up doing that in CPython) and compiled. It ran fine for me (and we know Youtube uses it internally), the most stressful thing I did was run the full django test suite which all passed except for a few pickling issues.
&gt; This release is primarily a collection of tweaks to 2.6.1, most of which are now available in mainline Python trunk. What are not currently available are in the process of being pushed upstream. This is their goal for all further "releases" too, so all you have to do is keep your normal Python installation updated and it'll keep getting better and better :) Some of the changes on their roadmap are invasive though (removing the GIL?), so we'll see if they can get them merged into mainline.
Thanks guys. Very helpful.
Just want to point out that there is also a chapter on decision trees in the CC-Licensed, NLTK textbook http://nltk.googlecode.com/svn/trunk/doc/book/ch06.html#sec-decision-trees This comes along with accompanying source code http://code.google.com/p/nltk/source/browse/trunk/nltk/nltk/classify/decisiontree.py
I can't see why anyone would be opposed to remove the GIL, so long as they can do it without affecting userland code. Guido can't be that dense.
He isn't against it in principle, but so far all attempts to remove the GIL have resulted in worse performance for single-threaded programs.
Is this not common knowledge? Did a bunch of people just find out about the GIL because David Beazley decided to benchmark it? I don't imagine the unladen swallow guys can get rid of it just by fixing the GC. You also have to serialize operations on lots of objects and some global state, and all of that is going to slow it down (though hopefully it will be be lost in their JIT speedups).
Of note but not mentioned: the controversial `ipaddr` module, originally slated for inclusion in 3.1, was removed (thread on python-dev regarding this started [here](http://mail.python.org/pipermail/python-dev/2009-June/089809.html)).
.. which, unless I'm missing something, has no relevance here. The GIL doesn't mean you have a system incapable of concurrency.
Now he deleted his account, in shame or something.
Aww... Maybe he is going to run a marathod.
African or European?
This is the wrong way to go about it. A much better way to solve this is to treat it as a knapsack problem and use a known algorithm that solves this in a much faster way than brute-forcing it. Read up on dynamic programming, specifically how it can be used to solve the knapsack problem.
The GIL protects Python's _internal_ environment, not the one exposed to user code.
doesn't answer the question
Nope. your wrong. The only way to find all answers is to do an exhaustive search. You should give this some thought.
Does have any experience with Stackless. Does it play well with numpy?
&gt; most of which are now available in mainline Python trunk Does that mean they're in 2.6.2?
Who cares, it's unladen.
unladen-swallow is already in use serving YouTube traffic - so yes it is useable.
No he's right. The brute force solution results in single paths being calculated multiple times. Dynamic programming provides a solution to this problem. 
This is insecure. Snippets are transferred without encryption or verification, so a MITM could inject arbitrary code into your scripts. Snippets are stored on a wikidot account, so not only are you trusting the maintainer to have complete power over your software, you are trusting wikidot and the security of the maintainer's username/password. **Please do not use this module in any production code.** In general, I think making your imports depend on remote files is a bad idea. Typically, the goal isn't to always have the freshest libs, but rather to have the version that the developer tested to work. I believe performing remote imports has too many risks and few advantages to make it worthwhile. A developer's "snippets manager" (allowing them to update their development environment manually) might be a better solution to this problem.
I'm the author. I agree it's insecure, and it shouldn't be used in production. I mention it in the site. As a quick solution, I intend to add verification through an md5 hash. However, I'm really hoping someone more "official" in the python community will take it under his wing. I'm really sorry you think it's a bad idea. The risks are solvable, and the benefits can be high: Having a dynamic working environment, where developers all over the web collaborate more tightly to build a better library of utilities. It will up the pace of collaboration, and allow developers to focus more on things that really matter. That is, at least, how I vision it. 
Guido addressed the point at the pycon last year; Jython and IronPython both implement full locking and take a major performance hit as a result (I think it was comparable to the performance of CPython without a GIL). As I remember, Unladen Swallow hopes to remove the GIL just by optimizing CPython to the point that the extra overhead won't cancel out their speed improvements.
Sounds a bit like the system described in this blog post http://www.onlamp.com/pub/a/python/2007/01/18/why-i-stopped-coding.html?page=2
That's missing the point of the knapsack problem. The knapsack problem doesn't care about generating all the solutions; it just wants to find the *best* one. Since all items are given the same value (that is, nobody listed a preference for hot wings over the fruit plate), either of the two answers are valid (I'm assuming that the sandwiches weren't intended to look like a subsection of the appetizers).
Very nice Mark. A couple small things I might quibble about, but I think they were mostly simplifications for explanation purposes. (Example: bandwidth vs. latency when talking about "network costs") One small thing: you still have a FIXME related to changing user-agent. I figured this is probably something you just hadn't gotten to yet, but in case it was an oversight, I thought I'd mention it. Looking forward to seeing the final product!
Good stuff. Small typo I noticed: "...but provides a better abstraction **that** urllib.request". 
An excellent sales pitch for an excellent library. I hope it makes it into the stdlib soon.
I hope not. Libs that get included into the stdlib seem to usually stall entirely. httplib2 is indeed great and I use it all the time. That being said, its internals are ugly and the code is rather cryptic which is a bit of a shame. At least its public API couldn't be simpler.
It was an interesting read even though I don't have in mind any use for httplib2. One thing that occured to me as a common case but wasn't mentioned was wanting to bypass the cache and go to the server but still respect last-modified and etag. Is this possible with httplib2?
Some things that came to my mind when I read the beginning of your article: &gt; if you want to send new data to the server, use HTTP POST. Some more advanced HTTP web service APIs also define ways of modifying existing data and deleting data, using HTTP PUT and HTTP DELETE. Actually PUT stores data at a given URL (creating or replacing content), while POST does whatever it wants (definitely not restricted to "send new data to the server"). See this [blog post](http://www.elharo.com/blog/software-development/web-development/2005/12/08/post-vs-put/) for more details. &gt; each “call” to the web service had a unique URL I suppose you want "has" instead of "had". More importantly, this sentence seems to say that every time I call something on the web the URL changes (as if it included some sort of unique ID), which is not what you meant. &gt; Even the fastest broadband connection is orders of magnitude slower than your local network, which in turn is orders of magnitude slower than you local disk. "orders of magnitude" sounds impressive, but actually an exaggeration. It's somewhat true for broadband vs. local. Broadband latency is indeed typically two orders of magnitude greater than local network, however bandwidth is only one order of magnitude less than local network, sometimes less. (Fastest broadband connection that is readily available here for a reasonable price is 130 mbps. Besides broadband above 10 mbps is quite common.) It's not true for local network vs. hard drive. Latency is actually lower for local network than for local hard drive, and the difference in bandwidth is about one order of magnitude, not two.
Everything in the JVM is thread safe. So it doesn't need a GIL.
Given the amount of prevalence of REST APIs don't you think even the httplib2 should be abstracted out by a plain REST API wrapper that converts say `status.user_timeline.diveintomark` into `/status/user_timeline/diveintomark.json` and provides a python dict. This wrapper will eventually have another level of abstraction by lookups that can offer individual services' API methods that provide appropriate api calls to the REST wrapper. I have worked enough on REST APIs to get this idea, but must take time to implement it. Or is there an existing similar implementation? +1 if it happens to be in the python stdlib.
cryptic != ugly
What do you mean by "I think it was comparable to the performance of CPython without a GIL"? 
ugly **and** the code is rather cryptic and != because
A couple of ugly things: * This munges the request and response _state_ into the same objects that represent that HTTP request and response messages. The result is you can't cleanly copy a Request or Response without copying the bumpf related to how it was generated, not to mention its just bad design. * Neither requests nor responses are mappings (so they should not subclass from dict), unless you pre-munge headers with the same name into a single key as per rfc2616 4.2, but this is the kind of presumptuous discarding of data that made urllib's design short sighted to begin with. Additionally while insignificant, the rfc specifically recommends a particular ordering of the header fields (general first, entities second) * There is no provision here for doing multiple requests at a time. In the year 2009 this is not acceptable. Right now a good half of all web-ish service programs end up depending on something like Twisted (or worse - asyncore) simply because the alternative is running a half-baked urllib-alike using one request per thread. Building on the last point, there is a whole load of other extremely basic stuff that should be supported in an 'httplib2' - trivial Keepalive (not even mentioned on your page), and basic client management (e.g. number of connections per host / domain, etc.). When you need to fetch several hundred 500-byte XML files from another continent, keepalive _really_ helps with perf. Honestly looking at this, all I'm seeing (besides the caching stuff which is really sweet yet still borderline useful for 95% of uses I can think of) is an uncompelling, slightly improved httplib. I'm convinced that any replacement urllib-alike should really tackle the problem of making multiple requests at a time. A simple, portable select()-based loop can be coded up in 100 lines to support this. That would be a real win, when writing small scripts to talk to things like Twitter, Facebook, etc.
&gt; It's not true for local network vs. hard drive. Latency is actually lower for local network than for local hard drive, and the difference in bandwidth is about one order of magnitude, not two. How on earth do you figure that the latency on a local network is going to be lower than on local disk? If the other end of the lan doesn't have to go to disk then it could be argued that running from the local machine would likely be hitting from some ram backed cache as well; OTOH if you are comparing a request that has to go back to actual disk read then you are comparing the latency of a IDE/SATA/SAS/SCSI bus with that of, in the best case, a single ethernet broadcast segment.... Unless you are running your LAN as IP over infiniband or something your local disk subsystem is going to have a far lower latency AND even if you were running IPoIB the server at the other end of the LAN connection would still be network+disk system for it's latency which is always going to be greater than disk system alone...
This is an awesome explanation of httplib2. I will keep it in mind as a new tool and use it. But, it is not the right choice. It's not the right choice, because there was no problem to solve. Each problem is different, and requires different tools. If I'm writing an app for a mobile device for example, I don't want to automagically cache everything (httplib lets you control headers, you can decide when to cache). I can think of more examples, but there is no point - there is never a right choice. httplib, httplib2, urllib2 and even socket all have their own claim in the net game :)
In French.
I really love the dive into python 3 book and I love how python has changed between versions 2 and 3. Now I'm telling this as a real python newbie, though with more than a decade of experience in programming (Delphi (*sigh*), C, C#, Java, Perl and... PHP (don't hit me)). Actually, the string tutorial in dive into python 3 was what made me learn python for real as python 3's string handling must be one of the most beautiful things I have ever seen in my life. The only problem I currently have is that there's next to no support for real web development in Python 3: None of the frameworks are there, mod_wsgi is caught in general flamewars about unicode handling in WSGI and very few of the typical web development libraries are python3-ready yet. In the end this forced me to go Python 2.6 with the stuff I'm currently working on, but I'm always looking after the nice python 3 stuff that's just out of reach for me. If you know any way of doing real web development (and deployment!) in python 3, please enlighten me. Python 3 is a much nicer language than Python 2.
I remember Guido saying something along the lines that performance hit form implementing full locking in other VMs was similar to the performance hit from implementing them in CPython when that has been done, the point being that the GIL isn't a mistake, it is a design trade off.
in model code its the most natural thing in the world. Each item in your has-many collection has a belongs-to.
What's wrong with it?
&gt; Latency is actually lower for local network than for local hard drive Bandwidth, not latency, is why SAN/NAS storage is taking off.. especially via fiber or Infiniband.
I just bought Programming in Python 3 and IronPython in Action.. can't wait until I've absorbed all 800 pages (gulp). Before Java and C#, Delphi was the bomb.
So the point is to use a real web library like TurboGears or Django?
From the comments: @TheMoken: 10000 ticks is not as high as you think! In high performance mode, my core 2 duo runs 20 million iterations of the loop above in 2 seconds. That's 10 million iterations per second. Each iteration involves at least 3 bytecode instructions: decrement, compare, and jump. So that's at least 30 million python bytecode instructions per second. If the bytecode interpreter switches threads every 100 instructions, that means it's switching threads 300,000 times per second. That's ridiculous; no wonder it's more than twice as slow! Switching threads every 10000 instructions means switching threads 3000 times per second. I don't see how that's not enough to preserve the illusion of concurrent execution. I understand that for most real-world applications, each bytecode instruction is going to do much more than decrementing an integer counter, but then the slowdown on multicore systems will be correspondingly lower for those applications, too. If my deductions above are correct, then I think we can boldly say the GIL is not worse than what we thought it was, as long as the checkinterval is set appropriately. I think the default of switching every 100 bytecode instructions is extremely unrealistic in a world where systems have multiple cores and run millions of bytecode instructions per second.
This is an HTTP client, those libraries are more general frameworks for building web services.
Why can't they integrate this into SciPy?
Heh, maybe running Django on CLPython is the right way to bootstrap a top-notch Lisp web environment...
The real gems here are the object-oriented xcb bindings, which are differentiated from the "official" bindings by an additional glue layer (parsed from YAML) that translates xcb calls to Python objects (rather than a flat namespace). I was planning on doing something similar for GSoC, but I noticed this project and sank my ideas.
Well, development on httplib2 seems slow anyway, so it may not be a bad candidate for stdlib inclusion. Just think about how rad it would be to drop httplib from the stdlib in a few releases...
as far as I could see, the current environment for web development with python 3 looks kind of bleak: None of the more notable frameworks are ported, mod_python isn't ported and mod_wsgi is caught in general flaming going on about unicode handling in the WSGI specification. So I'm asking you: If you were to create a web application today and you wanted to use Python 3, what would you do? What (if any) framework would you use? How would you plug your finished application into a production webserver? 
Not to focus on pendantic semantic wanking, but it's hardly in the spirit of "pure python" when you use ctypes.
You probably have a point in regards to dropping httplib. I'm not sure httplib2 matches criteria in code structure and documentation that is required to make it to the stdlib though.
Well, I think the premise is wrong :) Python 3, while fully production-ready from a technical standpoint, is currently not geared towards users -- but towards the framework developers. I don't see it as production ready "in the wild" until at least Twisted and Django support it. (And then my answer will be either Django/Twisted or Django/mod_python...) Write your app in Python 2.6 with all 3-portability warnings turned on, and make sure to keep it warning free -- and wait for the libraries to catch up. It's gonna take them a while...
NLTK has a pretty good text generation library. It generates text based on any corpus you give it.
Right, interesting. Certainly with IronPython I'm not sure anyone has looked at the cost of the threadsafety of the builtin types - but it is certainly a major reason why CPython performs better on micro-benchmarks involcing dictionary operations etc.
that's precisely my feeling. But on the other hand, Pyton 3 is just a much nicer language than even Python 2.6. And py-postgresql is so much nicer than any other PostgreSQL API currently available for 2.6 and of course it only works in Python 3. Also, the project in question is in its infancy. Going Python 3 now is, judging from the amount of work, much easier than going Python 2.6 now and then porting everything, possibly changing dependencies due to them not being ported (in time). This is my reason for asking the question in the first place. I would love to use Python 3 now, but from what I was seeing so far, it just didn't feel like a real option, so I decided to ask reddit whether I might have missed something. It looks like I didn't. PS: The project in question uses a very awkward data structure (which renders ORMs less than optimal to use) and outputs JSON over HTTP (which makes me completely independent of a templating library), so Django/Twisted are actually WAY over-fledged. What I need is a very thin layer between the web server and my code.
setuptools isnt even ported yet. just chill.
&gt; And py-postgresql is so much nicer than any other PostgreSQL API currently available for 2.6 and of course it only works in Python 3. what did you like about it ? I've had better results overall with pg8000 (also works in py3k) and psycopg2 remains my first choice.
I really liked how close the API is to libpq - you see, I'm a real postgres fanboi and I really know the ins and outs of the software. Also, the callable cursors really appealed to me. In the end, it's probably just a matter of taste. psycopg2 though is another matter: Non-existent documentation, a rant instead of the wiki/bugtracker and non-obvious stuff going on once you are forced to leave the beaten path. All this really deducted from the nice experience that learning python has been so far. But as I said: It's just a matter of taste :-)
i'd wait for the wsgi issues to get hashed out at the very least. 
The CherryPy guys are working hard to support Python 3 soon but there are still some issues apparently. Even then, CherryPy would only be one brick, not a whole stack.
I'd use 2.6 and lend my free time towards porting whatever I was using to 3.
that's a really nice idea and certainly what I would want to do. But reading, understanding and actually fixing all that third-party code is an awful lot of work. Especially considering that I'm a python newbie. And even if I got it to work, being a newbie, my solutions would probably not good enough to satisfy the standards of the upstream libraries I was porting.
I think it's more of you, the end user, using "pure Python"...
Looks like a nice library that could solve some problems I've had with httplib (especially with SSL). However within a few seconds of playing with it in ipython I hit a [show stopping bug](http://code.google.com/p/httplib2/issues/detail?id=39) rendering it useless with python2.6. I could apply the patch myself (if I'm really motivated), but then I noticed there hasn't been an official release of the library since 2007, and there are a bunch of bugs in the bug tracker. )-: Maybe active interest/development will be revived by this link. 
I would of thought TG or Django would also include HTTP clients that could be used piecemeal.
I was trying to convince py-postgresql's developer that dumping tons of debug output, including C source file names and line numbers, by default straight to stderr, with no obvious (or standard python logging/warnings filter) method of turning it off might be annoying to some users. He effectively said "well a *serious* application would definitely want all that output at all times". I guess you agree ?
Ack! if he pronounces the word "cache" as "kay-shh" one more time my head is gonna explode. [Sounds like "Cash"](http://education.yahoo.com/ref/dictionary/audio/c/0008800.wav;_ylt=ArjehsbmIo1L6K_sy5Ib6lqugMMF)
This should be called how to use a library in Python. Pretty weak IMO.
Thats awesome. I would have just put down carpet :-) but seriously that is cool. Deserves front page of programming subreddit.
samurai-x is a joke , I'm sticking with [wmii](http://wmii.suckless.org/)