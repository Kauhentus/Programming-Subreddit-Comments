I wanna flip codes
+1 https://www.reddit.com/r/Python/comments/2jdhtn/hynekstructlog_structured_keyvalue_logging_to/
I Haven't seen obfuscation like this since the obfuscated C contests that I looked at back in college. This is so much worse than anything I remember from back then. 
* https://github.com/ipython/ipython/wiki/A-gallery-of-interesting-IPython-Notebooks#reproducible-academic-publications (/r/ipython) * https://github.com/audreyr/cookiecutter-pypackage * http://wiki.scipy.org/NumPy_for_Matlab_Users * http://www.reddit.com/r/Python/comments/1lgxbf/best_tutorial_to_learn_numpy/cbz855u * http://docs.python-guide.org/en/latest/writing/structure/ * https://westurner.github.io/wiki/awesome-python-testing (**TDD**)
Imagine a loop like this: for obj in some_iterator: if obj == my_cheese: print("Who moved my cheese?") where ``some_iterator`` contains a million Spam objects. Neither Spam nor Cheese objects know how to compare themselves to the other, so every call to ``obj == my_cheese`` *both* objects will return ``NotImplemented``, and then the interpreter will fall back on object identity and return ``False``. That means that this block of code will cause one ``StopIteration`` exception, which is not very costly because there's only one of them. But if Python used ``NotImplementedError`` instead of ``NotImplemented``, that block of code would require two million (plus one) exceptions to be caught by the interpreter, which by my estimate would slow that piece of code down by at least a factor of 10. (Setting up try blocks is very cheap, but actually catching exceptions is quite expensive.) Besides, ``NotImplementedError`` is meant to be an **error**, hence the name. It is used for cases where you have an abstract class, and the concrete subclass has forgotten to override a method. That's an error. 
*Any* call to a function can be a bug if you didn't actually expect it to raise an exception and it does. But that's what exceptions are for. To say that ``StopIteration`` is a mistake goes against what was very probably the most successful new feature in Python ever. The use of iterators as a fundamental data type has literally transformed the language: look at Python 3, where most things which used to return lists now return either iterators or (in the case of dicts) views, which you use in a very similar fashion to iterators. The iterator protocol is one of the classing Gang Of Four design patterns, it has been around for decades and works wonderfully. Yes, it is true that unless you know your iterator is not empty, most calls to ``next()`` should be guarded by a ``try...except StopIteration`` block. That's because you're writing flow-control code, and you are responsible for writing it correctly. There is a small corner of the language where ``StopIteration`` interacts unexpectedly with other parts. Some people consider it a feature, others consider it a bug. The BDFL [agrees it's a bug](https://www.python.org/dev/peps/pep-0479/), and it will be fixed in Python 3.5.
Using [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/bs4/doc/) and [pandas,](http://pandas.pydata.org/pandas-docs/dev/index.html) this script scrapes the data from [Wikipedia Stats](http://stats.wikimedia.org/EN/TablesWikipediaEN.htm#zeitgeist), cleans it up, and ranks the articles by number of months in the top 25 (by editors) and then by the number of editors.
For fun, I pasted this into the [Python Tutor](http://goo.gl/X5ovUe). yes. It's so clear now!
Although that is a novel idea, I think it would get out if hand pretty quickly. Also maybe I misunderstood, but call depth probably isn't very useful information. Maybe some short notation caller function representation?
Good work. I haven't used those modules before so I cannot verify it myself yet. I am new to Python but I would like to someday write my own scrapers.
If you are doing web scraping: Beautiful soup is important: http://www.crummy.com/software/BeautifulSoup/ If you are searching for something to test and train on: Try to make a script that receives a city name and scrape wikipedia for population, geolocation and the other cool stuff that they have in their tables.
It actually does makes things a lot easier - think of complicated application in which several levels of indirection need to be logging in the context of the same operation. It provides proper structure to a log event at no cost. It also turns logging into a kind of messaging, which then can be processed with automatic tools. It also makes contexts declarative - which is a huge plus. Again: anything like that could be made by jumping through some hoops using the standard logging, but that's not the point. In the same vein, people use 'requests' and not 'urllib' - it makes things sane and simple. Easy tasks become much easier, and very difficult ones move into an easy category. Look, for example, what guys from Hive Tech did, wrapping logbook logger (have no idea who they are - I just googled it ): https://github.com/hivetech/hivy/blob/master/hivy/logger.py That's just pretty, providing that Logbook can log to any channel. Once they want to send it to an application (Sentry, etc.. ) or decide to move it through ZeroMQ , serialised - the change to an underlying codebase is 0. They don't have to fight with parsing, building, passing object states to loggers doesn't require any formatting.
While you're at it, you don't have to `join` if you're going to `print`: print(*map('{:20} {:.2f}'.format, names, times), sep='\n') This is a demonstration of why it makes much more sense for `print` to be a function than a statement. 
You could use IronPython or Python.NET with .NET library for reading PST file. Or the C++ official SDK http://pstsdk.codeplex.com
If available, lxml is generally better: [it can use html5lib](http://lxml.de/html5parser.html) for browser-compliant parsing, [it uses significantly less resources](http://www.ianbicking.org/blog/2008/03/python-html-parser-performance.html) and it provides access to CSS and XPath selection (and a whole host of utilities).
when I want pretty printing of tabulated data, I just make a pandas DataFrame or Series. It does all the hard work for me. http://pandas.pydata.org/pandas-docs/dev/index.html (nice tip though) 
I really want this in Python. I'm using mypy since September, and is awesome, I recommend to everyone to taste it, open an issue if see any bug/bad, and code if want to collaborate.
I have actually removed it from several pieces of software we inherited from external companies. It makes it impossible to predict what will get logged without tracing through the whole lifespan of a logger instance. Like many toys its wow factor fades after a couple of days and in the end explicit is better than implicit. Especially when it comes to logging in a production environment. You would not want to hit a special case in code (say a payment failing for no apparent reason) only to discover that some crucial information is not actually logged.
This looks extremely useful and is the best place to start I would think. The learning curve looks steep but it will be a nice challenge over the holiday. Thanks 
It's gradual typing, so at first all variables are Any. You then slowly add types to parts of your program. This is aimed at people with huge Python codebases, because at that scale the type system does fight against you a bit I guess.
That is probably better described as how to install pyenv rather than how to install django. It also seems like it was a homework assignment
Scrapy is a useful scraper framework.
I also often see classmethods being used to instantiate objects of that class. e.g. a class named `Document` and a classmethod `from_string`, `from_file`, `parse_file` or similar, which parses the string and returns an instance of `Document`. Edit: But I just saw, you did that in your linked post.
&gt; which by my estimate would slow that piece of code down by at least a factor of 10. (Setting up try blocks is very cheap, but actually catching exceptions is quite expensive.) No, why, it's not all that expensive: http://ideone.com/g0Uuhk
&gt; To say that StopIteration is a mistake goes against what was very probably the most successful new feature in Python ever. The use of iterators as a fundamental data type has literally transformed the language This is a very stupid thing to say and you should feel bad about saying it. You should learn some programming languages other than Python, to get some perspective. At least [check out the Wikipedia page on iterators](http://en.wikipedia.org/wiki/Iterator#In_different_programming_languages): there's a lot of ways to implement them, you can have `T current()/bool next()` pair a la C#, you can have `bool hasnext()/T next()` pair a la Java, you can have current/next plus comparison with the end iterator a la C++, you can copy on of the several approaches used in functional languages, you can invent something new like returning a pair `has_item, item` with `False, None` signifying the end of iteration, and probably many more valid approaches. All of which are exactly equal in power and allow doing all the same stuff. But note that in all of them the end-of-iteration condition is necessarily local, it's directly signalled from a particular iterator object to the code that consumes the data from it. Using StopIteration exception instead is using a single global variable to store the "iteration has stopped" flag. Literally, here it is: https://hg.python.org/cpython/file/4e84e45e191b/Include/pystate.h#l93 (well, it's per-thread global, but whatever). And naturally using a global variable for control flow causes all kinds of problems when it is consumed not by the code that the person who set it expected. It is bad way of implementing iterators.
Please explain "type hinting" and why it is good?
 api.update_status(using tweepy to tweet) I am assuming in your application that this is a quoted string instead of raw text in a function. A quick google search returned the following: https://github.com/tweepy/tweepy/issues/378 Try changing: auth.set_access_token(ACCESS_KEY, ACCESS_SECRET) To: auth.set_access_token(ACCESS_KEY, ACCESS_SECRET, secure=True) I haven't personally used tweepy however if your problem still persists I will create a sample script for further analysis.
when I use &gt; auth.set_access_token(access_token, access_token_secret, secure=True I get a new error saying : &gt; TypeError: set_access_token() got an unexpected keyword argument 'secure'
Sure, I get the gradual bit, but I can always assign my typed value to an untyped slot (and this continue to costume legacy/library code). Doing the reverse means there is no safety benefit, since anyone can assign an unsafe value to my carefully typed code. I guess I would have preferred a casting mechanism for consuming untyped values in typed code (eg. For exposing an interface in a library). 
A staticmethod can always be replaced by a simple function in the module, most of the times I see staticmethod the code was a conversion from another language. 
Oh, hello! I have started working on it in last couple of days. I put together a roadmap for the native client that should be just replacement for a browser. You can check it out here [bliker/ipython-osx](https://github.com/bliker/ipython-osx). I am still new to swift so things are going slow... and oh boy xcode is a real beast. I can’t wait to go back to do some frontend/python work afterwards. 
Can you elaborate on zooming? Do you think the font size is too small?
aspectlib has a nice decorator that does just that (show a summary of the stack), see: http://python-aspectlib.readthedocs.org/en/latest/reference/aspectlib.debug.html#aspectlib.debug.log Also, [a short introduction](http://blog.ionelmc.ro/2014/03/17/debugging-with-aop/).
honestly if you're new it doesn't hurt to familiarize yourself with [the standard lib](https://docs.python.org/2/library/) For just about any lib in the standard lib someone at some point in time has made a third party replacement for it. But the standard lib is the reference and provides context on why some lib replacements are good and others not so much. Ujson for example isn't a great replacement for the json lib, but requests for example gives you a lot of added features not available in urllib2. lxml is awesome, has good performance, and lends itself to writing functionally very well (lambda, map, filter etc). 
I can only suggest the following - 1. Confirm your Twitter api account is set to read/write permissions, (Regenerate new Access Tokens/Consumer Tokens 1. Follow the example Tweepy or myself have provided to the letter (obviously changing out the variable data like tokens) 1. Fire up a packet sniffer (like wireshark) and analyze the packet coming back to your machine to determine what was sent to twitter and what was recieved to resolve the 401 status (unauthorized - http://en.wikipedia.org/wiki/List_of_HTTP_status_codes#401) 1. If this still fails feel free to pm me some screenshots of your api settings, your code to a fuller extent, and/or a jing screencast of it running with full stacktrace.
Requests is awesome, I find though that I have to revert to lower level libraries when something isn't completely restful though. But it does what it's built for very well.
Quick nitpick: use `functools.wraps` to decorate the closure. That way the original function's metadata is preserved. I like this from a quick and dirty viewpoint -- especially because it uses a decorator. 
All your answers are absolutely correct. But I think you misunderstood my intentions and motivation. First of all, I do not want to spend hours tweaking my super special setup and then write a long blogpost about 100 steps you should take to get that look. It is quite hard to make a drastic changes in current open source projects. If I submit a partial pull request without any context or a vision, it will most likely not get much traction. Also, some of my UI ideas are most likely bullshit and I would like to try them before I push them. 
It does seem to go against some of the flexibility people like about Python. But for some design, formal specs around inheritance and functionality provide some clarity. Just like how we don't have to prepend private methods with '_' we do so out of regard for the reader, so they understand the method is used internally within the class and isn't meant to be accessed through the class api directly. @staticmethod appears to alter the namespace for the global class definition such that the static method can't be altered from outside the class. Sounds a lot like Java.
Awesome, thanks for the good ideas!
Good to know, I'll check them out-- thanks!
 @staticmethod def is_https(url): if url.startswith('https://): self.protocol = 'https' return True This function is so wrong and yet it's the one and only example in the post. self is not defined and the function return None instead of False...
If you are into web apps, try some Flask &amp; Celery. They are both very well written library as well as very nice to use.
If you make assertions about what parameters some operations will take, you can get the interpreter to suggest execution pipeline optimizations, and allocate caches and registers much more efficiently. You might get double the speed in some programs.
Ah, thanks, it's about optimization and giving hints to the interpreter to help it optimize. That's the key idea that I was looking for.
Quoting from the article: &gt; Even if understood, one must properly use classmethod and staticmethod in order to get the full potential of it. You don't say? And here I thought that I could get even more from them by using them wrongly.
A beginner would do good to familiarize him/herself with the standard library. My picks would be: unittest (test driven development, and testing in general) logging (program logging, to avoid the "sprinkle your code with print" pattern) re (regexp are an ubber powerful tool) os, os.paht, subprocess (for systems programming) Also learning how to use pip (or easy_install) and setup.py scripts is really helpful.
I just read the whole blog post. Nearly everything in it is wrong. The primer in [Part 1](http://pointerblog.in/python/python-classmethod-staticmethod-a-primer/) is much better than Part 2. There are a few confused or wrong parts in Part 1, but it's not terrible. However, Part 2 is basically nonsense. 
I second BeautifulSoup - it was my first introduction to Python. I've taught a number of Python workshops and I always use a project based around BeautifulSoup / web-scraping. It introduces you to a number of basic concepts in Python which you can apply to a project that is interesting to you - just pick a site you want to scrape. Yes there are other web-scraping tools you might move onto, but I find BeautifulSoup allows you to keep things simple (or complicated if you wish) so you can better focus on what the code is doing.
I would likely be unemployed without this library.
I would have included some (more specific) examples in my previous comment but I was half awake when I wrote it lol. And uhhh I can give you many examples but a lot of them are mostly pointless data (ie the information is found/collected to provide relief for my programming 'itch' moreso than to find practical/usable information). Anyway, one that comes to mind is for Bitcoin Billionaire. Similar to Cookie Clicker, you can spend the in game money on 'investments' which earn you passive money or on the level of the miner (which is the thing that gathers coins every time you tap, thus increasing the amount earned per tap). One of the main goals of BB is getting to level 25 of the tap miner. Since the investments have all different costs and incomes, I was curious what the fastest way to level 25 was. SO! I used iPython Notebook to store the data and used the Python library matplotlib to make the graphs. I collected the data by hand - inputting the costs of everything into a dictionary with the name of the investment as the key and a list of the first 50 relative purchases as the value. I converted all the values to be the same value (as the investments start off costing a certain amount of bits, then climb up to kilobits, megabits, gigabits, etc), and divided by their profit to get a 'worthiness' ratio for each purchase. I made another dictionary just like the previous one, except this one's lists consisted of each purchase's worthiness score. I finally took all these scores and am able to see the 'ideal' order of purchases (I skipped a few steps here for the sake of boring you/other readers). So yeah. I realize it's not a very practical finding and not something that people would look for. But as I said at the top of this post, it's more to scratch my programming itch haha. Hopefully I was helpful and not just ranting, giving some level of insight. I would be more than glad to provide any answers or details. 
Scrapy is great for webscraping, and the authors of that have another lib called scrapely, which can be trained to pick stuff out of pages. Check their github page.
&gt; nction is so wrong and yet it's the one and only example in the post. self is not defined and the function return None instead of False... Its a static method. It can access self.protocol defined in a class. its an example.
There is no `self` in static methods. The whole point of static methods is that you don't have a class (`cls`) *or* and instance (`self`) to work with (otherwise it'd be a class or instance method). Your method as defined throws an error if you actually run it: &gt;&gt;&gt; class URL: @staticmethod def is_https(url): if url.startswith('https'): self.protocol = 'https' return True &gt;&gt;&gt; URL.is_https('https://www.google.com') NameError: name 'self' is not defined &gt;&gt;&gt; URL().is_https('https://www.google.com') NameError: name 'self' is not defined
If I'm reading this right, it's basically type inference with a very forgiving type system, for the purpose of improving performance and checking some type errors at compile time. 
interesting approach! but you can actually simplify the process, e.g. use builtin `lxml.html.clean.Cleaner()` to clean the html code.
damnit, couldn't help my self. from lxml import html from cStringIO import StringIO TEXT_FINDER_XPATH = '//body//text()[string-length(normalize-space()) &gt; 50]/..' html_cleaner = html.clean.Cleaner(scripts=True, javascript=True, comments=True, style=True, links=True, meta=True, add_nofollow=False, page_structure=False, processing_instructions=True, embedded=True, frames=True, forms=True, annoying_tags=False, remove_tags=["a", "i", "em", "b", "strong"], kill_tags=("noscript", "iframe"), remove_unknown_tags=False, safe_attrs_only=False) def extract(htmltext): doc = html.parse(StringIO(htmltext), html.HTMLParser()) html_cleaner(doc) textnodes = doc.xpath(TEXT_FINDER_XPATH) sentences = ['\n'.join([x for x in n.itertext()]) for n in textnodes] return sorted(sentences, key=lambda x: len(x), reverse=True)[0] 
Syntax (mypy-like) proposed by Guido is terrible. Cython-like syntax would be much better approach.
&gt; Doing the reverse means there is no safety benefit, since anyone can assign an unsafe value to my carefully typed code. That's kind of the way Python works...you can call len() with a boolean if you want. It's your choice... This will allow the caller to decide whether they want to be safe or not. That's as it should be. The caller is the boss, not the called code. &gt; I guess I would have preferred a casting mechanism for consuming untyped values in typed code (eg. For exposing an interface in a library). That means that if you make a statically typed library you are imposing type declarations on the callers. Think of it this way: Python has always worked this way at the interface between C and Python. open() will crash if you try to pass it an integer. Now we can do the same thing higher up in the code base. Instead of crashing when we try to open a file, we can (easily) crash when we first notice that the filename is not a string in e.g. configuration code. Or, a fastidious user of the library could declare all of her variables so that the compiler could catch the error.
A different syntax may reduce the compatibility with earlier version codebases. They want to implement this gradual typing without breaking them.
Oh snap. I've routinely been asked to do standard 'developer' tasks in the rest of python and I'm fairly clueless. Ask me to pass data round in a real world job with requests and I'm there.
Yeah, most of them API's that I use that aren't fully restful actually have a python library. Maybe I'm lucky?
What, basically, do you do with it for your work? (Feel free to use ELI5 mode in your explanation.)
Suddenly, comments are code. 
Honestly it has a lot more to do with writing correct code than to do with optimizations. PyPy does some really amazing optimizations without type declarations.
Much more importantly, it gives you the benefit of static typing. So you can automatically check that there's no weird edge-cases that return "None" in lieu of a socket. Yes, you could do it with unit tests. But then you end up with code that is more verbose than Java. And it's much easier to miss things.
on second thought, instead of inspecting individual sentences, NLP stopwords can be used to filter "good" text section.
Looks like the problem is in funcs.threads: from funcs import aux_functs from funcs.colors import TermColors Should be: import aux_functs from colors import TermColors edit: formatting
There are a number of issues: incorrect use of `find_packages` in setup.py, missing package in src, missing `MANIFEST.in` or missing `data_files` in setup.py. Unless you want to learn all this weird stuff you should use a project template. Eg: [cookiecutter-pylibrary](https://github.com/ionelmc/cookiecutter-pylibrary)
&gt; ...for two callable types that differ only in the type of one argument, the subclass relationship for the callable types goes in the opposite direction as for the argument types. (Example: Callable[[Employee], None] is a subclass of Callable[[Mananger], None]. Yes, you read that right.) Why is that?
It's for static analysis and CPython is not going to use them. However, PyPy probably will.
I just fixed it. I must say those weren't the issues, since it all working now. 1 - In main.py, i had to use `from .funcs import threads` 2 - in threads.py i had to use `from . import aux_functs` and `from .colors import TermColors` But thanks for your input! I'll try to add that stuff.
That's very cool! I'm trying out your approach now. I'll send you a pm so that we can possibly get your contribution into the package. As a user had suggested I do, I'm currently writing up some tests which handle more regular and extreme cases; after I'm done with that, let's get your pull request! Edit: I tested out your code's output and checked against mine, and we aren't getting the same results; here's what you should expect for [Google's wiki](http://en.wikipedia.org/wiki/Google) - though I'm not 100% sure you intended for the output to be similar. There's some really good ideas in your code that, if you don't mind, I'll borrow and I'll be sure to give you a plug :). I particularly like the html.clean approach. P.S. I should note that I just revised the explanation of eatiht's [algorithm](https://github.com/im-rodrigo/eatiht/blob/master/eatiht/eatiht.py). I think this might help if you're trying to match eatiht's output. 
It works but I doubt you really wanted to name your package `src` :-) And your sdist won't include the extra non-python files unless you fix your setup.py or add a manifest template (`MANIFEST.in`).
Oh yes, you're right, if i didn't include that dot, i wouldn't work! Anyways, thank you!
The absolute most simple way is to subclass BaseHttpServer and that will work for trivial applications with a very small load. However usually web programming in Python is done via WSGI, which is like the way a web server like Apache hands off a request to another application (like something written in Python). There are a few WSGI frameworks for making this relatively easy - check out [Flask](http://flask.pocoo.org/) for a simple and powerful example.
Or "bottle" which is simpler and smaller than flask.
Do you have any plans to integrate it into the compiler or toolkit for additional safety or warnings?
+1 for [Bottle](http://bottlepy.org/docs/dev/index.html), it's just what this guy needs, single file.
We'll probably do whatever CPython does in terms of warnings. It sounds like it'll be a new stdlib module for CPython, and not integrated into the compiler, so it'll probably be the same for PyPy.
Make sure it is bs4, not BeautifulSoup 3.
well, at least in chrome ubuntu the window size of each cell doesn't allow seeing the whole content if the cell/results.
Neat, looks like mechanize but no mechanize
Can you be more specific?
It's a virtual machine on a server that I'm sshed into on my phone. 
Sure, it was five minutes coding and tested against some news webpages. I believe there are lots of things that I miss. What first comes to my mind was how to handle the webtext encoding as lxml is known not very good at it (you might want to borrow BeautifulSoup UnicodeDammit implementation or roll your own). 
A function that can take an arbitrary employee is a rarer beast than one that can take only managers. Think about this: there must be very few Callable[[Object], Integer], since after all it must work on an arbitrary object so can't do too much. But there can be many, many functions Callable[[Integer], Integer]
Thanks for pointing that out. I didn't know about decorators overwriting the function metadata, but it makes sense. Fixed now.
So, would these always be true? * `isinstance(object(), Any)` * `isinstance(3, Any)` * `isinstance('str', Any)` [EDIT] Whereas currently one would need to do the following for explicit runtime-type-checking: * `isinstance(object(), (object, str, int, float, bool, ...))` * `isinstance(3, (object, str, int, float, bool, ...))` * `isinstance('str', (object, str, unicode, basestring, int, float, bool, ...))` But the *preferred* duck-typing approach would be something like: * `hasattr([], '__iter__')` 
Try saving the ui as an atribute? Something like: self.ui = class.setupUi() I'm not on my pc right now so I can't really test this, sorry
So you don't have to determine types. You may not have current plans, but I'm sure PyPy or other similar projects (e.g. Cython, numba) will in the future. It's too easy to not make use of. As for PyPy not planning to support it currently, there's a lot of other work before PyPy can support Python 3, so it doesn't surprise me that it's not a high priority.
Is it just me or has Guido become less resistant to adding complexity to the language? This optional typing layer seems to bring Python closer to C++ or Perl where one person's code can look dramatically different from someone else's.
The method that is not working is newRecipie right?
Looking for the shirt feels like cheating to me, but it's within the rules of the game, I do believe every picture has his short visible, you never have to rely on facial recognition only. 
Everyone has provided suggestions for getting data, but what are you going to do with the data once you have it? That's where [pandas]( http://pandas.pydata.org/) will come in handy. Then check out some plotting libraries like matplotlib although pandas has some built-in plotting [capabilities]( http://pandas.pydata.org/pandas-docs/stable/visualization.html).
Whaaaat, that's so freakin cool. 
Would this work on the last page of the first (I believe) book where every person is wearing the red/white striped shirts?
Fixed It! The Problem Was That I Did Not Use Self Correct: self.Recipie=QtGui.QWidget() self.card = RecipieCard.Ui_RecipieCard() self.card.setupUi(self.Recipie) self.Recipie.show() Incorrect: Recipie=QtGui.QWidget() card = RecipieCard.Ui_RecipieCard() card.setupUi(self.Recipie) Recipie.show() 
You could try posting in /r/ProgrammingBuddies/. I've not used it personally. Also, side note regarding the other comment: I wouldn't worry about *causing a "badass" to get "pissed off"*. Chances are if you run into one on reddit, their opinion isn't worth your time anyway.
absolutely not
You have this backwards. Don't start off thinking "here's an awesome library, what can I do with it?". Think "Here's something I want to do, what libraries should I use?" Otherwise you end up writing code that you really have no interest in, and you give up as soon as you hit a blockage. e.g. "Why should I spend hours debugging this script? I don't really care about scraping Wikipedia for population data."
That's really cool ! But I would be more impressed if there were more examples to check that it wasn't just luck in this case. I hadn't heard of Mahotas, it looks like a nice library, I wonder how it compares to OpenCV (like, what does it have that OpenCV hasn't, and conversely). 
Don't scrape Wikipedia, that is rude. Wikipedia has an official API for downloading data. http://www.mediawiki.org/wiki/API:Main_page Don't crawl their pages scraping content: http://en.wikipedia.org/wiki/Wikipedia:Database_download#Why_not_just_retrieve_data_from_wikipedia.org_at_runtime.3F If you need a lot of data from them, consider downloading their whole database instead: http://dumps.wikimedia.org/
Sharing your code is a pull request away, or making your own repository server(which is just a HTTP server, which serves files)
What is the metric of "topness" that is being used?
&gt; Yeah thanks for the advice, I'll be sure to take insults from somebody calling themselves "xXxDeAThANgEL99xXx" seriously. It's a trap for idiots. &gt; You made a specific claim that the use of StopIteration was a mistake. Where's your evidence for that? If it were a mistake, why do people use iterators in Python all the time? ... I'm saying that using StopIteration exception for implementing iterators was a mistake, not that implementing iterators was a mistake. It is not a very complicated concept. Stop telling me that iterators were successful, sure, iterators are very useful, even when when implemented somewhat wrong. &gt; If there were a "single global variable" to do this, you could only have a single active iterator per thread, and that is absolutely not the case. You can easily have multiple iterators active at the same time, and they don't all stop when the first one raises StopIteration. Dude, have you noticed a [**link to the Python source code**](https://hg.python.org/cpython/file/4e84e45e191b/Include/pystate.h#l97) I gave you? Here's your global per-thread variable, if `exc_type` is equal to `PyExc_StopIteration` then some iterator down the call stack has just terminated. Only one exception handler has a chance to realize that its iterator has stopped (and the flag is automatically cleared). The problem is that since it's a global variable the handler can't really tell that it was set by the iterator it tried to advance and not by some unrelated code called in the process (especially if you're not aware of this design mistake and put anything else besides the `next()` call in the `try` block). So a relatively nonthreatening bug with calling naked `next()` on a depleted iterator is suddenly promoted into a nightmarish silent data loss.
Yeah that's it. I think the calls to lineEdit.setText on the first method were somehow keeping the class around. There are other things you could improve your program if you're interested in hearing it.
Citation needed. I strongly doubt that this will help any optimization at all for a dynamic language.
well, that’s the job of process management systems like e.g. systemd. save the following to `my_daemon.service` [Unit] description=my python daemon [Service] Type=simple ExecStart=/usr/bin/env python3 -m my_daemon then `systemctl enable my_daemon &amp;&amp; systemctl start my_daemon`
&gt; non-legacy links: &gt; &gt; * [387](http://python.org/dev/peps/pep-0387/) - essential, not sure how the heck it wasn't even there before &gt; * [441](http://python.org/dev/peps/pep-0441/) - might help with some of the deployment pains, especially if there's a way to run a full venv with it &gt; * [448](http://python.org/dev/peps/pep-0448/) - good stuff, saw some usecases for it in the wild &gt; * [455](http://python.org/dev/peps/pep-0455/) - minor, but useful &gt; * [471](http://python.org/dev/peps/pep-0471/) - faster `os.walk`, just a nice thing to have &gt; * [473](http://python.org/dev/peps/pep-0473/) - cool for IDEs/debuggers/logging, more information == better
This is awesome, can anyone explain it a bit more thoroughly? Especially this line: wally -= .8*wally * ~mask[:,:,None]
I don't know what they are using, but you can see the most popular repos directly from github using these searches: [Most stars](https://github.com/search?o=desc&amp;q=language%3APython&amp;ref=searchresults&amp;s=stars&amp;type=Repositories&amp;utf8=%E2%9C%93) [Most forks](https://github.com/search?o=desc&amp;q=language%3APython&amp;ref=searchresults&amp;s=forks&amp;type=Repositories&amp;utf8=%E2%9C%93) I don't get why you need a top 30 on another site, but ad money I guess. 
[SQLAlchemy is on bitbucket.](https://bitbucket.org/zzzeek/sqlalchemy) Pyramid is around top 150 based on stars. 
Next time please consider posting to /r/learnpython instead.
Sure I would like to hear your input :)
Remove 80% of the current color from the image (e.g. make it much darker), but only where there's no mask (~ inverts the bits, the mask is of wally so you want everything that's not wally to be changed).
Cool, is ~ a standard operator or part of a library?
Ok so, first you're using: import PySide.QtCore as QtCore import PySide.QtGui as QtGui from PySide.QtGui import * from PySide.QtCore import * Why both? Any of the two styles is fine, but stick with one Next: you're making the UI with QtDesigner + some external tool like pyside-uic to generate the python code. However you're adding your own custom methods to this class generated. This means that whenever you change something in the UI your custom method will disappear. You'll have to copy-paste them back in every time... The usual way to do this is subclass the UI file with your own class and put your code there. [Here's an example with the RecipieCard class](http://pastebin.com/Hc4sSVRF) (didn't really test this, just wanted to give you the general idea) Notice I moved all your custom code to the new class, the Ui class should only have the setupUi and retranslateUi methods. This has the added advantage that you can call: RecipieCard = RecipieCard() RecipieCard.show() Instead of: RecipieCard = QtGui.QWidget() ui = Ui_RecipieCard() ui.setupUi(RecipieCard) RecipieCard.show() In the openFile method you're not checking if the dialog was canceled. I'm pretty sure QFileDialog has a method or variable that returns if it was rejected. I can't look for it right now so I'm not sure which one it is. You could also check if self.file is empy Also, it's recipe not recipie Well those are my two cents, let me know if you have any questions
Either do some exercises to progress a little more : projecteuler, codewars or codingbat ( hardest to easier) or you could try to make a little project if you have any idea. It's usually really great to get better that way as you'll learn about new tools on the way
Remember that your entire work flow doesn't need to be in Python. If you can't find anything that would just be a nice Python module, I'd broaden your search to include anything that can provide a shell output that can get captured back into Python, or that writes out a temp file that you can then read in. 
So how would you do this better with opencv? Is there a way to train a generic Waldo classifier and set it loose on the pages? Would it make sense to run the images through something like sift first?
I'm thinking training on images run through sift would make your classifier scale and orientation invariant no?
I had a lot of fun, and learned a lot about the standard Python libraries from the [Python Challenge](http://www.pythonchallenge.com/).
http://newcoder.io/ by Lynn Root would be great for your next steps with Python.
dont have any ideas about projects and i am doing those exercises. Can you give some idea about small projects which i can learn
You can usually doing some nice little things with websites. Doing a bot that will collect data from a website can be pretty interesting. A reddit bot is also a cool thing and it's not that hard with the module praw
Mmmmm, shitty blog spam.
Maybe if they added this link to the list of repos at #12 it would be funnier.
Project Euler is not the best place to learn a language I think because you can solve puzzles even with terrible style and get no feedback. I'd dive right into grabbing small bugs on a public project, honestly.
What platform are you on? numpy, scipy and many other modules in the python scientific "stack" need to be compiled. I've found the path of least resistance to be using the conda package manager that is part of the [continuum anaconda python distribution](https://store.continuum.io/cshop/anaconda/) (or you can just "pip install conda"). [Here's the docs for conda. ](http://conda.pydata.org/)
Damn, i need to do my homework 
Sorry for the incomplete info, I've installed Enthoght Canopy express, student edition &amp; running it on windows. And, I dont think I could make this work in Canopy ?? Thanks again !
By trading strategy you mean automating your transactions? What is the advantage of your trading strategy? I would need an idea of the level of complexity to offer advice or help. It matters greatly whether it's a days or months or more project, and the requirements involved will affect who you are looking for. One thing you could try is finding a local group for networking. Otoh, finance is an interesting field, so depending on the extent of what you're planning, I might be interested. 
To confirm: you have 2.7.6 with several extra modules installe and now you installed python 3.4 without the modules and are asking whether you could use previously installed modules with 3.4? Then the answer is NO. You need to add these modules to 3.4
hehe read learnpython index and faq ASAP (tons of links to resources): http://www.reddit.com/r/learnpython/wiki/index http://www.reddit.com/r/learnpython/wiki/faq Many courses on udacity.com, coursera.org and edx.org use python. Definitely rich source of interesting projects. E.g. Coursera courses: Exploring Neural Data, Cryptography, Statistical Mechanics Algorithms and Computation, Bioinformatics Algorithms, Computational Investing, Natural Language Processing and many more use python :) 
No problems at all. The thing is that I missed some features on GNU Stow. I think that there is still room for improvment. Plus, Stow is written in perl, at least, I'm rewritting it in a modern language.
 for i in xrange(2): Python 2.x peasants
Too complicated (*ie, computationally expensive), just cross correlate stripes in the R channel.
I think using a computer to look is cheating. ;) There are some images where lots of people have the shirt. In fact, there's several in this image that do, just smaller (either kid or turned sideways). (380, 480); (850, 590); (950, 350).
Why is Python a requirement? As much as I like Python, I would expect JavaScript to be a more suitable language for this, if only because you get the DOM and most of CSS selectors for free.
Mainly to look at the code and see how it is done. I'm learning Python at the moment, but want to look at a project I would understand the use of.
Honestly it might be a better choice to go with anaconda. They have both a python 2.7 and a python 3.4, and the conda package manager allows you to install 2.6 or 3.3 as well. I can't speak enough for the conda package manager. I'm just been getting into this over the last year, and it's been a lifesaver when I haven't wanted to worry about getting things installed and I just wanted to use this or that package.
Create a function or method that performs the multiple closing of windows. Call the function in the button(cmd=?) field.
and now a awesome exercise would be to rewrite this using python 3 and asyncio :)
Don't use UDP for chat applications. [Wikipedia](https://en.wikipedia.org/wiki/User_Datagram_Protocol): &gt; There is no guarantee of delivery, ordering, or duplicate protection.
May I kindly point you over to /r/learnpython? 
Check the order within the function. Some of the windows may be using the top window function and you might need to close the children windows in the order that they were opened.
And note that `mask` is a NumPy `ndarray`, which overloads most standard operators to work on the elements of the array. `~mask` applies binary not to all elements of the array, in effect reversing the array (masking the indices that weren't masked before and vice versa). Or, it changes "mask that indicates where wally is" to "mask that indicates where everything but wally is".
There is a cool little framework to turn your matplotlib and bokeh plots and pandas dataframes into simple web applications called [spyre](https://github.com/adamhajari/spyre). It's nice to give yourself a little dashboard to display your data locally, or host it somewhere if you are so inclined.
You are correct. As reliable as connections are these days, UDP should never be used where packet integrity and synchronicity is important. Maybe I should rename the post to "UDP Communication in Python". I made this simple chat script to prototype and demo UDP communication for a shared state between multiple users in an application component. For the use case at hand, UDP was better suited hence the post :)
He's the one missing a shoe.
HOG descriptor + sliding window + Linear SVM trained on the striped shirt/face region of Waldo. I probably wouldn't use something like SIFT for this. You'll have to deal with keypoint detection, and in those types of puzzles, you'll end up with a metric shit ton of keypoints. And furthermore, I highly doubt you'll find enough keypoints on Waldo to do keypoint matching via RANSAC or LMEDs. A rigid descriptor like HOG trained on the Waldo shirt + face region would likely perform well.
You may have more than one version of Python installed on your raspberry pi. They won't share libraries, so it's possible to have a library like pycurl installed for one python but not the other. That's probably what's going on here. You'll need to install pycurl for python 3. How to do that depends on your distro. If it's debian based, there may be a system package called python3-pycurl (``apt-get install python3-pycurl``). If you're running something else on your rpi, then how you install it may be a bit different.
Wow thanks. Why linear svm? Does opencv have a sliding window feature? Or just do that in python? I'm actually working on this exact task of tracking a small object through video frames and I wasn't sure where to start. 
Only Python 2 ; - ;
In ml_man's defense, 'what do you have in mind?' is pretty unspecific. A more specific question to a possible boss would be 'Why will this be better than any other software on the market?' or 'How will the collaborator fit into this?'.
that makes sense. I'm trying to find a python 3 module for pycurl and cant find one in the repo's or even specific source. Do you know if one even exists?
depends on your distro. they all do packaging differently. what distro did you use?
I consider "lack of features" to be a problem, and certainly perl is a barrier to implementing them.
That language parser blows my mind.
Wow. My mind is blown. Thanks for the share. Now to find a reason to use this amazing project...
There's UnCSS written in Javascript. If you're doing web stuff there's no excuse for not knowing Javascript anyway.
~~would be cool if you did this with imdb instead since their api has rotten tomatoes ratings as well.~~ I'll just do it myself :D
you could try using mechanize with beautiful soup and fill in the form and press submit http://swizec.com/blog/scraping-with-mechanize-and-beautifulsoup/swizec/5039 
1. At first, you should open requests.Session() as s. Then work inside this session. 2. Send GET request (like in example here at the top of the page http://docs.python-requests.org/en/latest/user/quickstart/). Receive page with form. 3. Extract fields from the page: f = lxml.html.fromstring(requested_page.content). 4. Update form fields - radiobutton and id field - approximately like: data = dict(f.forms[0].fields) data.update({ "radiobutton": "...", "id": "..." )} 5. Send post request with that data: r = s.post("form url", data).content 6. Use fromstring like in p.3 to extract desired fields values from the form. 
Also use firebug for viewing form's fields and GET/POST requests data.
I suggest you install a package manager like pip, easy-install or conda and use that to install modules. It's much easier.
I looked into using IMDB instead of Rotten Tomatoes, but IMDB doesn't have a "public" api (at least not officially). Another alternative is a project called [OMDB](http://www.omdbapi.com/), but so far I haven't needed a backup. See: http://stackoverflow.com/questions/1966503/does-imdb-provide-an-api
Yeap that's what I was referring to. I didn't see the o there. Anyway you can see they have the tomatoes parameter for getting rotten tomatoes ratings :)
I am really sleepy now but here you have something to start with buddy from bs4 import BeautifulSoup from splinter import Browser browser = Browser() browser.visit('http://kepler.sos.ca.gov/') browser.find_by_id('ctl00_content_placeholder_body_BusinessSearch1_RadioButtonList_SearchType_2').click() browser.fill('ctl00$content_placeholder_body$BusinessSearch1$TextBox_NameSearch','C0685388') browser.find_by_name('ctl00$content_placeholder_body$BusinessSearch1$Button_Search').click() site_html=browser.html soup = BeautifulSoup(site_html,'html.parser') for tr in soup.find_all('tr'): columns = tr.find_all('td') print columns just change the browser to zope.testbrowser and do the rest of the parsing with the columns. PD: I'm not proud of this code. Danke
Can someone explain how all those feature would be used together, these kinds of libraries are new to me.
 1. Flask has a simple way of routing. For example the following will except an GET or a POST @main.route('/edit-profile', methods=['GET', 'POST']) @login_required def edit_profile(): The route will accept and GET or a Post and requires and integer as part of the querystring. @main.route('/post/&lt;int:id&gt;', methods=['GET', 'POST']) def post(id): You can return what you like a template return render_template('auth/register.html', form=form) a file return send_file(app.config['STATIC_FOLDER'] + 'images/logo.png') 2. The following repo explains a method. see app/main/views.py for the decorators. The permissions are app/models.py repo see https://github.com/miguelgrinberg/flasky associated book see http://www.flaskbook.com/
Very complicated &amp; useful technologies combined in 1 library for the important task of web mining. brilliant
Well, I implemented this myself in Mochi. Was super easy!
I think I should also try Anaconda. ill post the update soon. Thank you for your replies. :)
Having some Python syntax doesn't make a language Pythonic. Instead of making a "python like" language, use Python and compile it. MyPy gives you type hinting for Python. It will give you much more traction.
What's wrong with that thought?... hm... i am a newbie and decided to learn python 2 first, makes me fell like i chose right either way... Are there major advantages from one to the other?
One is being developed, the other isn't. Excluding 2.7, the 3.x brought in many great features and it's a shame we can't use them because community is stuck with many years old release. 
s'aright. no harm done.
Be careful with the instructions on broadcasts. Setting last octet to .255 won't work on all network sizes. If you have 10.0.0.1/25 as an address .255 won't work (you would want .127).
What if you are not using venv? Never worked for me.
when do you think python 4 will come out? serious question.
If you have the latest setuptools it should work. Perhaps you don't have the latest setuptools? Run this to check: python -c "import setuptools; print(setuptools.__version__)"
Both versions are great, and in the end both are Python. Python 3 fixed some Warts in the language, mainly the separation between text (unicode) and binary (bytes) data. I'm happy writing in both, but I prefer Python 3 due to some nice additions. If you know Python 2 you can learn Python 3 in one weekend - there's only some minor differences (but those make the language a lot more pleasant =p). 
This? https://github.com/peterbe/mincss
Time to learn about handling exceptions using `try`
looks cool, testing :)
 extra_str = '_butts' df.columns = [col + extra_str for col in df.columns]
I am terrified! 
HOG is normally applied to grayscale/single channel images. Although some authors report computing gradient magnitudes over all channels of either HSV or L\*a\*\b* and taking the maximum response at each point. I would start with grayscale and see if that suffices.
&gt; dns.resolver.NoAnswer your sexy :) i added except dns.resolver.NoAnswer: # No IPv4 and no IPV6 pass and that got rid of my noanswer return, its still not itterating through the file but its progress! :D
You should check out /r/learnpython for future scripting needs but since it's your first program, I'll offer some advice. The best thing to do, especially when starting out, is to break the program into the smallest possible steps. Get each step working and then put it all together. Your script is really doing 3 things: * read input file * resolve dns name * print ip address Right now you have a single loop handling all of those tasks. Since the sorts of errors that happen when reading files are very different than the errors that happen when resolving dns, this approach quickly becomes complicated 1st I'd use "with" in order to read the file; it makes life so much easier. It removes the need for the finally: close() as it promises to always close the file The 2nd issue is you're trying to print an object for the response. If you do dir(var) you'll see the object var has a few attributes, one of which is response. If you print var.response you'll get the actual content returned by the dns server The final issue is the way you are querying the DNS server. the DNSPython library throws an exception for domains that don't exist (NXDOMAIN or NoAnswer) that you are not catching. If you wrap the resolver query in a try/except you can handle cases where the domain can't be resolved My final question would be if you really need the actual DNS server response or not. If you don't need all the TTL and other stuff and just want the IP address, there is a far easier way to get it: socket.gethostbyname('google.com'). This returns the IP address or throws an exception on failure. Nice and simple.
I don't think that really matters. If a new version of python gets e version number of 4.x, I don't expect it to be incompatible with 3.x. If you read [this](https://www.python.org/dev/peps/pep-3000/), it says: &gt; **There is no requirement that Python 2.6 code will run unmodified on Python 3.0.** This choice was made so that Py3k is more correct. Unfortunately this breaks backwards compatibility with python 2.x, that is not a just side effect from upgrading, but a deliberate choice so that from Py3k and further it no longer has the mistakes that were made in Python 2. The developers know about the compatibility problems and I expect them to keep python future proof, that means that Python 4 or higher will be compatible with Py3k. If you really want to know when Python 4 will come out you should check [this](https://www.python.org/dev/peps/) now and then.
I wonder how it compares to [NLTK](http://www.nltk.org/).
Link color and my memory suggest that I had already seen that before. Thank you nevertheless.
This looks nice, I'll have to check it out. Another good minimalistic browser is [LuaKit](https://github.com/mason-larobina/luakit), but it's obviously not python.
And [conkeror](http://conkeror.org) for Emacs fans. Not in Python tho.
How about cols = df.columns.tolist() df.columns = cols[:10] + map(lambda s: s + "_butts", cols[10:])
These aren't all correct. For example, `isalnum` doesn't only accept ASCII: "ᄊ".isalnum() #&gt;&gt;&gt; True 
Visual Studio? Hell no, why not MinGW?
I don't completely understand what you're trying to accomplish, so I'll ask for more detail? I *think*- you have an existing pything script that you want to be able to launch through a web ui of some kind. Yes? *OR* - you have an existing python program, that's already running as a daemon, and you want to have IT talk to a web ui? What exactly is this thing?
Version numbering has changed: they dropped the leading "1.", just as Java did some years ago. One notable bug fix is that "pip search" now works behind a proxy.
Fuck [Vimium](https://chrome.google.com/webstore/detail/vimium/dbepggeogbaibhgnhhndojpepiihcmeb?hl=en). You're not hardcore about Vi until you install this simplistic beauty. If only it was built on top of Chromium...
Reminds me of dwb. I wish it had prettier hinting, like in Vimium.
For people new to this style of thing, here are the famous ones: * [dwb](http://portix.bitbucket.org/dwb/) * [Jumanji](https://pwmt.org/projects/jumanji/) * [Luakit](https://mason-larobina.github.io/luakit/) * [surf](http://surf.suckless.org/) * [Uzbl](http://www.uzbl.org/) * [Vimprobable](http://www.vimprobable.org/) 
Do you want to monitor network traffic, outside of httpd, or do you want apache to invoke your code?
Needs less urllib2 and more Requests. 
This is just a bunch of existing modules bundled together. It's a way of manufacturing multiple version dependence.
Java kept the leading "1." in its versioning (e.g. "1.8.0_25-b17") used internally and reported to other applications (java -version). Whereas, Pip renumbered their version to 6.0 by dropping the leading "1." and reports version 6.0 when queried (pip -V). EDIT: Sun used the minor version in marketing to stress that each minor version added significant features to the language. I don't know why pip changed its versioning scheme.
This would be almost entirely dependent on how your webapp is configured and how define criminal hacking, cyberstalking. Also why do you need a Python program for this? Why can't you build this functionality into your webapp?
How about something hack-ish like: df.columns = [col+' String' if i &gt; 10 else col for i, col in enumerate(df.columns)] Edit: Another obvious alternative: df.columns = df.columns[0:10] + [col + ' String' for col in df.columns[10:]]
**Some more info:** I had this idea for a while now and was planning on making it for twitch like twitchPlaysPokemon, but that was more work than I thought so I decided to make it in a webapp. I chose python as the language because a lot of people know how to write it and it's easier for people to get into. The thing is opensource (the app itself is written in js though): https://github.com/Squarific/DemocraticProgramming
Doesn't pip do all this for you? I set up PIL without any problems with it on Windows
Can you see my post from today and maybe help me work through this? http://www.reddit.com/r/Python/comments/2q3xbd/install_wheelhouse_directory_as_post_install/ It's a python2.7 project that needs to be bundled and deployed, but I'm at a loss. Thanks
Looks interesting, I'll wait till they switch to QtWebEngine and I'll give it a try.
I think this is okay, not too hackish. I'll suggest another way in a direct comment to OP but I was also thinking of this way.
Thanks guys. Keep the down votes coming. I love it.
/u/tidier has the answer here but I feel like I should say that this seems wrong in the first place. Why are you doing this? Are you going to be combining these dataframes and need a unique way to access these columns? If so, consider looking into `MultiIndex`.
"If the python2 itertools module is the Swiss Army Knife of functions for iterables, iterstuff is the cut-down single-blade version that you can keep on your keyring." 
I would argue that an object should be in a stable state on return from __init__ and that the [RAII](http://en.wikipedia.org/wiki/Resource_Acquisition_Is_Initialization) pattern applies. If there's more work to do to connect/download/whatever, do it on demand and allow the caller to decide whether to work asynchronously.
I guess we can blame Chrome for that?
Looks a lot like dwb
All similiar ones I know of are listed [here](https://github.com/The-Compiler/qutebrowser#thanks--similiar-projects).
At some point I plan to add a QtWebEngine backend - then at least the rendering will be! :)
dwb was the main inspiration - I was using it for years before [it died](https://www.reddit.com/r/linux/comments/2huqbc/dwb_abandoned/).
Note: the original iterator will be modified whenever the Lookahead(iterator) advances.
We generally don't break compatibility in one swell swoop (at least on purpose) and instead we phase it in over time. This means that every major release of pip breaks compatibility with something to some degree. By making the major version bump with each major release we more effectively communicate this. It also removes the temptation to do a big "2.0" rewrite.
Have you considered using conda instead? It installs in user mode and assuming you can build everything one one machine, doesn't require visual studio on the client machine. 
Yeah, but it's certainly not up to speed with Chromium, at least if you want the browser to be something more than a simple experiment.
It has a bit of trouble staying online, a backup is here: http://squarific.github.io/DemocraticProgramming/client/
Ah, sorry; I didn't scroll past "Authors".
Modified? In the sense of 'next will be called on it'? Well, sure, but why is that an issue?
Because the original iterator will be modified by actions on the Lookahead object, which could be a surprising side effect. That it's not documented is surprising.
In the comments for the Lookahead __init__: "@param gen: the generator to be wrapped. The first element will be retrieved immediately". That states that the generator's first element will be retrieved at that time, which counts as modification. Anyway, I updated the README to make it super-extra-clear. 
that's what normally happen with open source projects, like OpenSUSE, right?
Its not just on init, it's on any call to .advance
Did you read more than my first paragraph which was only an acknowledgement that it was possible to check for errors - which was the question asked! In the second paragraph, which begins with "However" (often a great clue that there are better ways to attack the problem) I said every database is different(sort of like what you said). Then you went on to say that "Postgres creates a process for connection so consider the overhead for that" (almost exactly the same as saying In SQL databases creating a connection can have a lot of overhead...what I said). By the way, bulk operations are specifically designed to minimize IO. While great design is possible, static analysis and design often miss major performance optimizations. Performance optimizations are almost always best done by profiling running code. Creating a large numbers of process works when they are light weight and are not sharing the same IO limits (e.g. On different servers.) 
depends on who you ask: $ python -c 'print(u"ᄊ".isalnum())' False $ python3 -c 'print("ᄊ".isalnum())' True
OP is running at least 3.3.
It is probably the line above. Health = Health - ranint(
I haven't, I'll give this a try tomorrow. Are you a contributor?
that's pretty much what this article says, yes.
I've actually found [cVim](https://chrome.google.com/webstore/detail/cvim/ihlenndgcmojhcghmfjfneahoeklbjjh?hl=en) to be so much better than Vimium. But yeah, this looks pretty sweet I'm going to need to try it out.
Sweet, now I can needlessly obfuscate every goddamn thing I do on a computer. I love Linux and the people who use it, but seriously. You people make everything more complicated than it needs to be. 
Not the greatest solution but: x=0 for string in List:#Python doesn't have builtin arrays? x+=1 #do stuff. Comments use a pound symbol, not double forward slashes. :P
Yes, it will be. I'm still not sure what the problem is with that: it wraps an iterator, so it, er, iterates over it. How else should it work?
exciting at first sight, however lacking of add-ons like lastpass, xmarks and greasemonkey etc. makes me stay with firefox/pentadactyl
[**@dFourthi**](https://twitter.com/dFourthi): &gt;[2014-12-23 04:33:30 UTC](https://twitter.com/dFourthi/status/547248607674392576) &gt;When to use \`&amp;lt;&amp;gt;\` and \`!=\` operators? [*stackoverflow.com*](http://stackoverflow.com/questions/27478998/when-to-use-and-operators?stw=2) [#python](https://twitter.com/search?q=%23python) ---- [^[Mistake?]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Error%20Report&amp;message=http://reddit.com/2q5688%0A%0APlease leave above link unaltered.) [^[Suggestion]](http://www.reddit.com/message/compose/?to=TweetPoster&amp;subject=Suggestion) [^[FAQ]](http://np.reddit.com/r/TweetPoster/comments/13relk/) [^[Code]](https://github.com/buttscicles/TweetPoster) [^[Issues]](https://github.com/buttscicles/TweetPoster/issues) 
Well, ideally, you wouldn't be changing anything about the original generator. I know that isn't an easy problem to fix, but it needs to be explicit in your README, docstrings, and code examples. I think making `g` be the initial iterator and `x` being the wrapped version is somewhat confusing in that case. `g` is no longer useful once you create a Lookahead over it and if you don't realize that, you'll have weird side-effects. When you're changing a built-in part of a language with a module, you need to be extra careful about documenting it, especially the side-effects.
why would you not post a link directly to the article.
Curtsies is compatible with (and includes) blessings these days. For anything full-screen, it seems to have the best abstraction (FSArray) IMHO. That said, your limiting factor might be your event-loop / concurrency model. Curtsies has a primitive model but I'm dubious about how well it'll interact with network-heavy code. You may find that urwid+trollius is more to your liking if you're doing heavy protocol work. Also, pay attention to what libraries you're going to want to use. SSL support and other forms of encryption tend to have protocol-level details that are important (e.g. constant-time for certain operations to prevent leaking data through timing, lockstep protocols for exchanging data to prevent certain types of attacks with carefully crafted session secrets, etc.). Essentially, encryption isn't something you can just transparently layer on later. That fact may impact your concurrency model, and thus make a certain frontend a PITA unless you're going multiprocess.
IMHO, it's one of the smartest approaches I have seen, and so simple too. Great explanation there. The html and xpath crash course at the end is also quite good. I'll definitely be following along to see what else you come up with!
tl;dr there is no difference, they compile to the same opcode
And one of them doesn't exist in python3
Thanks for the kind words! I'll definitely be posting some more short and sweet packages as they come along :) 
repost http://www.reddit.com/r/Python/comments/2mwbrm/googlescraper/
So instead of consulting the documentation, you post a link to your tweet which contains a link to your stack overflow post which has been marked as already answered. Whats the point?
It would require use of a web application for every page, and it wouldn't work on things like files.
Stackoverflow!!!
pip will download wheels for you, if there are any. I was doing this to compile my own package. This toolchain setup should only be required for a package maintainer.
Ahh I see
Appreciate the feedback, these are valid points that should be taken into account. Thanks!
FYI: There's a PR for `cov-core` that fixes the issue.
Ask the questions on /r/learnpython?
You could do: switch.get(n, case_default)()
I have contributed but I am in no capacity officially affiliated with conda. I maintain another package (called menpo) that has some pretty nasty compiled extension dependencies that we manage using conda. In fact, Windows is almost entirely the reason we started using conda in the first place, because setting up Python compilation on Windows is so finicky. However, you only need to create a new virtualenv containing numpy 3 or 4 times and deal with waiting for compilation to finish to see the benefits of conda.
This is very interesting, I haven't yet used the new(ish) Python 2.7 compiler that Microsoft released this summer. I've still been leaning on MSVC9. Did you find that Python 2.7 extensions build fine for 64-bit packages using that package? Previusly, I have released instructions for 32-bit and 64-bit extension building with MSVC9, but it seems like these instructions are a lot simpler!
Actually I am the creator and I never knew somebody else did post a link to it before...
Free proxy servers are bad. Therefore no need for such a method. Or do mean that? 
Well, I don't want to pay for that. I would prefer a frequently updated list of free (but working) proxy servers.
More explanations would be really nice in this mishmash of bullet point lists and python snippets. I don't even know what the problem is we try to solve here. But I guess it's nice for people who look up LSH and want to see a python implementation of it.
I know. I would also prefer that :D But there is no such thing as free good proxy servers. There are ways to get them for free, but they are not legal.
If one decides to buy, where to look around? Do you have some recommendations?
Actually no, I never bought them. seo-proxies.com looks good tough, but I never tried it. There was a time when I could scrape 10000 keywords in a night at google with my method in my scraper (using selenium, thus faking a real browser). But they prevent that now.
I see there's already swift punishment for posting an image to /r/Python - the heresy!
I was looking through your repository and I couldn't find any proper code written. Can you post a list of features you want to implement and the completion amount on each?
The world needs a new search engine that is incapable of deleting content the way google and the rest do- not just a scraper of existing search-engines.
Another hard hitting piece of investigative journalism.
"Obfuscating" anything certainly isn't the point, at least not for me. But not having to use the mouse is quite useful - and I like to make myself comfortable and efficient with a tool I use for hours each day.
qutebrowser does simple host-based adblocking which works quite well. dwb understands the most part of "real" adblocking definitions. jumanji/surf are quite minimal so probably they don't. uzbl and luakit seem to have scripts/modules for doing so. Vimprobable doesn't seem to have an adblocker.
For what it's worth I tried out the code and it worked very well, nice work! **Edit**: as a corollary, check out http://www.holovaty.com/writing/templatemaker/ -- this script will infer the "template" structure used to generate a page by looking at multiple pages and finding longest common substrings. Kind of the inverse of your algorithm.
Smoking is waaaaay safer than executing un-sanitized data. 
I wish Django would redo their versioning scheme. Change 1.9 to version 19 so that version 2.0 will be version 20.
Well, I think those two are synonymous 
&gt; ...to a possible boss... OP &gt; ...would love to work with someone... Doesn't sound like a boss/wageslave setup to me.
Maybe different people desire different things than you do :)
It looks like this guy only ever posts from that one site, so yes it seems to be blogspam.
I haven't written a reddit bot before, but since nobody's commenting I'll take a whack at it. It looks like self.config['autofav_keywords'] is a bool when it should be an iterable. Maybe set that and see what happens?
Incidentally I was playing around with time functions in python on Linux. Linux has a few interesting functions for this, `nanosleep` for example. You can achieve even better sleep times with this function. Here is the snippet: https://gist.github.com/eisensheng/d3a34dfe095b92d035f9 nsleep: 3.000207987000067 select: 3.0031554710001274 nsleep: 3.0002168390001316 select: 3.0020486980001806 nsleep: 3.000159081999982 select: 3.002822416000072 If you want better sleep times then you must calibrate the timer and adjust the desired time of sleep to match the actual time of sleep. Or just use a real time oprating system. Linux just doesn't fit in there. Neither does Windows like in the stack overflow question. For Linux at least there is a fork that tries to achieve real time functionality. 
http://www.diveintopython.net/installing_python/macosx.html Start here and then read the rest of this excellent book.
The solution to ignorance is not fewer words. It's more words. 
Actually I am thinking of making a real search engine with a own index and corpus, that gets the hosts/IP addresses from massscan, which makes a banner scan on port 80 on the internet's address pool...But I am reluctant, because I wouldn't know what to do with the big money that such creators (Sergey, Larry) tend to earn :D
Type `python` into `Terminal.app`
And your secret can effortlessly be recovered in git history. It wouldn't be a bad idea to create a new account.
Totally forgot about that! Appreciate the heads up.
Good point, I'll change it to runtime args instead. 
I've just committed two examples showing how to start up a server and connect a client in order to start exchanging messages and chat. You can find the examples at https://github.com/dnaeon/pylobby/tree/master/examples The examples are pretty simple and show how to use the `LobbyServer` and `LobbyClient` classes. I'm currently testing and playing with the various console libraries (curtsies, urwid, blessed, etc.) and testing stuff, so once I get my head around these I will commit some examples which should look prettier than the current ones :) The code as mentioned in my initial post is still in very early development phase, so documentation is one of the things that lacks right now, but I'll try to compile a list of features and their progress soon and have it published. Thanks for the feedback! :) 
I wasn't aware of PyNaCl until now, thanks for letting me know of it! :)
You could use [brython](http://www.brython.info/) and run python in browser.
&gt; does I wasn't actually aware of this, thank you.
Sounds like you're trying to recreate something like fail2ban. Have a look at that tool and if it doesn't do what you need, please describe in simple terms exactly what you're after and exactly why it doesn't do what you want.
Python isn't the best language for this kind of thing, since it's pretty slow compared to others for this purpose. If you still wanted to try for learning purposes, your best bet is to create a simple HTTP proxying server that sits in front of Apache, checks the request information, forwards valid requests to Apache, and sends the response back.
Heh, I was expecting much longer code.
What does should int(str(value), self.base) do? EDIT: NVM, figured it out..
Hope you find it useful!
Yeah OP it seems you're out of luck :( [This stackoverflow answer suggests using another operator](http://stackoverflow.com/questions/24327858/hack-the-in-operator-to-return-non-booleans) Maybe \_\_lshift\_\_? BIN &lt;&lt; 1000 It kinda gives the idea that the "1000" going "through" the BIN...
I agree with Raymond in the mailing list thread, supporting this abuse of syntax in the language would bring significant complications and no real benefit.
Using left shift to do something besides left shift would be harmful to readability and violates the principle of least surprise, in my opinion. There's only one example in the standard library I can think of that does this sort of thing: sets with `&amp;` for intersection and `|` for union. That syntax is unintuitive until you read the documentation to figure out what it does; I think `some_set.union(some_other_set)` is more obvious in function than `some_set | some_other_set`.
responses from requests also have a .json() method
Yeah but he was already OK with overriding "in", I don't think readability is his top priority.
If you ever worked with bit masks and flags, this would actually appear very familiar. Notice how you can think of a binary word of length N as a representation of some subset of `{1, 2, 3, ..., N}`; in this interpretation, bitwise `&amp;` and `|` behave exactly as set intersection and union, respectively.
&gt; It kinda gives the idea that the "1000" going "through" the BIN... ...and thus converting decimal 1000 to binary, which is different than saying "1000" is _already_ in base 2.
Oh yeah, got that the other way around huh?
Another example is [`pathlib`](https://docs.python.org/3/library/pathlib.html#operators). This uses the `/` ([`__truediv__`](https://docs.python.org/3/reference/datamodel.html?highlight=truediv#emulating-numeric-types)) operator.
Pretty neat blog. I actually did something similar not too long ago if anyone's interested in a similar project: https://github.com/Drewman315/Text_Based_Game
Look into reading/writing CSVs 3.4 docs: https://docs.python.org/2/library/csv.html
Yes, CVS
Your code will return only the integer values, not exactly useful for body temperatures. I don't really understand what was the point of breaking it into so many lines. print (float(raw_input("Enter temperature in fahrenheit: "))-32)/1.8
Ahhh, floats.... thank you!
Yeah, it took me forever to figure that out, haha. Division always produced 0. I'm not sure if you saw, but I changed one more thing to make it shorter.
Do you mean CSV?
You can add data entry to [tabview]( https://github.com/firecat53/tabview). It's on my todo list :-)
Holy crap. This looks like exactly what I wanted. I will try this out tonight. Thanks!
This port is on the way, checkout the TODO list. I would say we're about 60%+ of the way there, expecting all tests passing early in the new year, IIRC only web and db are remaining.
It vendorises a module (pywordnet) which has merged into NLTK.
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**Covariance and contravariance (computer science)**](https://en.wikipedia.org/wiki/Covariance%20and%20contravariance%20(computer%20science\)): [](#sfw) --- &gt;Many [programming language](https://en.wikipedia.org/wiki/Programming_language) [type systems](https://en.wikipedia.org/wiki/Type_system) support [subtyping](https://en.wikipedia.org/wiki/Subtyping). For instance, if Cat is subtype of Animal, then an expression of type Cat can be used whenever an expression of type Animal could. __Variance__ refers to how subtyping between more complex types (list of Cats versus list of Animals, function returning Cat versus function returning Animal, ...) relates to subtyping between their components. Depending on the variance of the [type constructor](https://en.wikipedia.org/wiki/Type_constructor), the subtyping relation may be either preserved, reversed, or ignored. For example, in [C#](https://en.wikipedia.org/wiki/C_Sharp_(programming_language\)): &gt;==== &gt;[**Image**](https://i.imgur.com/lu8YOA2.png) [^(i)](https://commons.wikimedia.org/wiki/File:Inheritance_covariant_return_animalshelter.svg) --- ^Interesting: [^Bounded ^quantification](https://en.wikipedia.org/wiki/Bounded_quantification) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+cn3spf1) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+cn3spf1)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
Why do you consider runtime arguments "better" than environment variables? Runtime arguments are visible to anyone on the system without privileged access ($ ps aux | grep \&lt;process\&gt; or top -c) whereas environment variables from another user / process can only be viewed with access to /proc/\&lt;pid\&gt;/environ
While I agree with Raymond completely, the argument that we can already do whatever the heck we want with the other comparison operators is a fair point. Sets are an awesome example of this. Not only are the `&amp;`, `|` and `^` operators overridden, so are the `&gt;`, `&lt;`, `&gt;=`, and `&lt;=` operators (checking super/sub sets). I can't think of a *good* use case for modifying the behavior of `in` to return anything other than booleans (other than the ORM example) but it's a fair point to bring up.
You can rebase and delete that commit, and push to github. And yes, with flask you should always use untracked config file and put the variable there. 
I've seen `__lshift__` and `__rshift__` overridden in a couple of functional adaptations to represent bind operations. Though, if you're at all familiar with `&gt;&gt;=` it's pretty obvious what `&gt;&gt;` in a functional library would do. The irony of using objects to write functional Python is not lost on me.
Why are you giving users who shouldn't have access to those details access to your production servers? That's also insecure and bad practice.
&gt; There's only one example in the standard library I can think of that does this sort of thing: sets with `&amp;` for intersection and `|` for union. What about the overloading of the modulo operator for formatting strings? 
I usually have a csv file open in Notepad++ and then cut and paste into excel.
Pandas can make a dataframe from an excel file, so you could just use that for your data collection or whatever. 
If you like Excel, just input data with Excel, then save it to csv and simply use csv module to import and parse your data. If you want more sofisticated module, try pandas, which has read_csv.
There's an [ORM for Google Spreadsheets](https://github.com/Widdershin/butterdb), so you can just edit things in there, access them as objects in your Python code, and save them back to Google Spreadsheets. I can't decide if it's silly or useful. Probably both. (cc /u/Widdershiny)
What if its another service on the box thats exploited like say ntp? If its in the running arguments the ntp user will eb able to see it; if its in the environment they won't. Overall I'd say the environment is the more secure choice of the two...
I've been using Python 3-style `'{}'.format()` for a while now, so I forgot about that one, but you're right, that is another place operator overloading is (in my opinion) misused.
Don't run extra services on the box. Use virtualization. Environment variables are more secure, but the most security comes from separation of responsibility and isolating things properly. For ntp, have an internal server that your services boxes connect to and only allow that to connect to servers you don't control.
or just save excel normally and read it with xlrd. 
If you're using Python 3 or `from __future__ import division` then `5/9` will already be a float.
IMHO the set version is completely sensible since it's directly isomorphic to the equivalent operations on integers.
Yeah, like I said, just starting to really get into Python and right now going at it without using any resources other than what I've learned in the past through tutorials. So when I started this project, something simple that I could grasp, I wasn't sure how to approach this one. Thanks!
+1
Why are you typing data? If you have data in any form you can get it into a dataframe. Can you tell me specifically what your trying to do? 
what about using format()? What is preferred in Python 3?
I run a lot of calculations with some software and often need to present some intermediate data to the boss or collaborators on the fly. Currently, I'll use either a google doc sheet, or IPython Notebook as kind of a recorded calculator for summarizing some data and maybe doing some post-processing (unit conversions, sums and differences, etc.). I love the Excel-like interface that google docs offers, but getting the data from a google doc or Excel file is annoying. Download file, export CSV, read in from Python, and choose indices carefully. I'd rather just use the IPython Notebook interface to input my data than go through this process every time. But then again, inputting and editing data is just slower with IPython Notebook. 
Thanks for the quick rundown. I actually just had to go through this process on my application. The issue I ran into was that I was only localizing a single module out of a dozen or two. Using the class-based gettext API was better for that. The other problem was the Jinja templates. I think I opted to use pybabel since it has built-in functionality to parse Jinja. A word of warning to anyone who might read this: seems pybabel hasn't been updated in a while and has a weird issue on Windows systems. It uses default Windows encoding to open files (po/pot) for conversion into MO files. Unfortunately I was translating to Japanese and using UTF-8 encoded text files. Pybabel crashed all over the place so I ended up modifying the code to accept an "encoding" command-line argument. I'm not sure the status on pybabel, but it's a great tool and hopefully it's updated to be more compatible.
 degree = int(raw_input("Enter temperature in Fahrenheit: ")) degree = 5/9.*(degree-32) print(str(degree) + " degrees in Celsius") Is clearer
Have to agree here, technically an awesome project. Is there any documentation for how it should be used? Or what problem it solves?
tablib is pretty useful too.
numpy.loadtxt is really straight forward: http://docs.scipy.org/doc/numpy/reference/generated/numpy.loadtxt.html 
When building an app based on Qt with PyQt, there is a very comparable system built into Qt and [wrapped by PyQt](http://pyqt.sourceforge.net/Docs/PyQt5/i18n.html). The steps are about the same: wrap all strings in a call to QCoreApplication.translate() (which of course can be assigned to a shorter name); process the source through a utility called pylupdate to extract the strings; run a GUI app, the Qt Linguist, to perform the translations. There it diverges from what's described by OP. Instead of writing the updated strings for one language back into the module, the translations for all languages are kept externally in a resource file, and the string for the active locale is substituted automatically at run time by Qt.
pandas read_excel http://pandas.pydata.org/pandas-docs/dev/generated/pandas.io.excel.read_excel.html
&gt; print(str(degree) + " degrees in Celsius") print(degree, "degrees in Celsius")
While that works, I don't like it because if I replace print with log, I have to change it. Really I prefer print("%s degrees in Celsius" % degree) I think that way is much clearer about the spacing between the value and the unit
Remove the int calls, you've already converted it on line one. degree = int(raw_input("Enter temp: ")) degree = (((degree - 32) * 5) / 9) print("{0} degrees celsius".format(degree)) 
And even then, if you represent a set as a binary string (order all possible elements and assign them a position as a bit), it works *exactly* as it should. I think any other choice than using &amp; | ^ would be ludicrous.
This is feasible with an html table document and some hacking. I don't know of anything that does this but I May incorporate some of these ideas into an I python extension I will be making to help with general engineering calculations. IPython has some info on how socket communications occur between the shell interface and thee kernel. It uses zeromq to handle this. I believe I could make an extension that outputs an html table in place of the typical IPython cell so we could achieve this.
scapy does it well with crafting packets as well IP()/TCP()/"GET / HTTP/1.0\r\n\r\n"
Search for PySpread, it's a python spreadsheet program!
One item often overlooked is the issue of pluralization. English is 1 and more than one, but other languages (I believe Russian is one) have multiple pluralizations. Ngettext is the way to solve that problem. It also simplifies plural agreement in English much more intuitively than the typical `if ct == 1:`... 
R, knitr and markdown/latex.
yeah don't turn my language into a pointless DSL, Ruby already exists.
I have to say that although your idea looks cute, you deserved to be burnt for attempting to abuse `in` in this way! Why not just use `__call__` instead of `__contains__`, then you could write &gt;&gt;&gt; BIN(1000) 8 &gt;&gt;&gt; OCT(755) 493 &gt;&gt;&gt; HEX('FFFF') 65535 (I haven't checked, but nor did you ;) )
It's called English language. 
I use CSV files in excel, then a list comprehension to load the data. lines = [x.strip().rstrip().split(',') for x in open('somecsvfile.csv')] Returns a list called 'lines' with a list of each element from that row.
I'm in the same situation as you and now i'm going for the kaggle python tuto I think it mainly dépends on what you want tout do next
www.checkio.org was a pretty good and with a lot less hand holding.
It is fine in C++
Just like in Closure! :)
What do you want to _do_ with Python? Then just start that and learn on the way.
How about starting to build things with what you know already? Maybe some sysadmin tools. Along the way you'll learn about cool additional modules like pexpect. https://pexpect.readthedocs.org/en/latest/
By the way, just saw this in the side *"If you are about to ask a question, please consider r/learnpython"* 
Everything: http://learnprogramming.machinesentience.com Or stop fooling around and get your bachelors degree in cs. Return on investment will be between 50k to a million depending on how seriously you take it.
I'm not sure what this provides, could anyone shed a light to the actual use case? Thanks.
pandas will import directly from excel, no csv conversion needed.
Try /r/learnpython. And you should be learning 3, because if you don't know anything about the language, then you probably don't have any libraries that require Python 2.
Among the available operators, I think the ones used for set combination were well-chosen. However, I don't think that using them really brings any benefit.
3.0 isn't very good, 3.4 is much better than python 2.7
Right, I guess I wasn't too excited because that's mostly the way CherryPy exposes parameters already. I assumed others supported the same pattern already :p
Anybody who tells you "3.0 isn't that good" is a moron, because it implies that 3 is worse than 2.7. Python 3 is just an incremental improvement on 2.7, with the only major change being handling of strings (unicode). It is entirely possible to write backwards compatible Python 3.x code, and there is no reason not to be using Python 3 unless you have an actual pre-existing reason to do so (Meaning a legacy codebase running on an un-migrated library such as Twisted). If you need exercises to work through, try the [Mega Projects List](https://github.com/karan/Projects). As for something practical, you might learn a thing or two trying to create a Pong clone with something like [PyGame](http://www.pygame.org/wiki/tutorials) or [PySFML](http://www.python-sfml.org/tutorials.html).
Python Batting Practice is a good one to tackle after codecademy. http://codingbat.com/python Don't be fooled: it starts off easy and gets super hard.
&gt;It sounds like he's playing with Python, and operator overloading is a fun thing to play with, although extremely easy to abuse. Fair enough, I suppose it is fun to see what you can do &gt;As for left shift doing anything other than left shift, it sure does happen in the programming world, ie cout &lt;&lt; "hello world!";. It _does_ happen. It _shouldn't_. Using `&lt;&lt;` and `&gt;&gt;` everywhere in the C++ standard library as a "stream operator" is one of my annoyances with its design. &gt;I think the best case for operator overloading is for objects that either have a direct corresponding add sub mult operation, like a vector I agree completely. I'm not a Java purist who believes that operator overloading is the devil; it is useful in some circumstances, such as overriding `==` for custom types, or overloading arithmetic operators for vectors/matrices. I just see it misused a lot by people who are trying to be clever. &gt;`IP()/TCP()/"GET / HTTP/1.0\r\n\r\n"` What. &gt;once you know that scapy works in the way it does, it's extremely succinct and will never be confused as any other sort of operation The key phrase here is _once you know that scapy works in the way it does_. I'm sure if you've been using scapy then there's no confusion, however if I had seen your above example line in the wild (I've never used scapy before) I would have to stop and figure out what it does, because it's an unconventional use of `/`. This is what I'm arguing against when I say that operator overloading is often misused: surprising readers who are _not_ familiar with the unconventional use of the notation. Code is written for other programmers to read, not for the compiler to read. &gt;Some may call it a bad design decision, but it works Designing something well and making it work are two different things. The internet is full of code that works but is designed or implemented badly. I don't claim to write perfect code; I have written a lot of code that works but is not well designed. There are cases when this is appropriate (hacks, experiments, game jams, etc.), and there are cases when I think it's important to make the design clean and intuitive. As you mentioned, for all we know OP could be just playing around, in which case experimenting in operator overloading is fine, but I would be critical of finding such code in production.
There is a csv module in Python that handles csvs in a more robust way. Check out chapter 6.1 of the Python Cookbook.
I hadn't heard of that one before. I don't think that I would prefer that over `os.path.join('/etc', 'whatever', 'file.conf')`, but it's an interesting idea.
Half and half agree with you. I'm a senior at my University for CS and I've learned...nothing really. Other than Java, a lot of stuff can be found online easily and learned.
I guess I kinda said it wrong myself. He said to me something like "You're better trying to learn 2.7, since 2.7 has better library system and most systems still run 2.7". or something like that anyway. I shall check the links you gave me tho. Thanks!
So your friend thinks I'm not learning Python well by using code academy? I disagree. Also, is it even possible for someone to know a language 100%? 
I see what you mean by complete. I still disagree with your friend. I just learned the range function two days ago and Instead of spending an entire 8 minutes learning it on a YouTube video or reading 3 paragraphs of it on a website I learned it in under 5 minutes. I have the coderunner IDE and I use that to test the code and habits I learn from the CA Python course AS I progress. For example, when I learned the .remove , .pop, raw_input functions I tested it before clicking the next lesson button. It is up to the learner. CA is a guide. Your friend thinks way to linearly. And if a learner doesn't need to implement the code they just learned from CA in their own IDE then good for them for being a fast learner. I just find it hard to take what this guy says when I'm a living example of how great of a resource CA is.
Easier for some than others. I do not learn as well from a blank slate. Creating my own problem to solve will never really challenge me the same as when presented with a new problem altogether. Also, once finished, I have a relatively limited skill set comprised only of what was absolutely necessary to complete my task. If OP can learn on-the-go, great, but if there is a resource for those like me (and maybe OP) it would be helpful to know of it. I also occasionally teach myself the "wrong" manner of doing things and miss most of the industry's best practices. For OP, I thoroughly enjoy the O'Reilly media books on Python. It provides exactly what I am looking for and allows me to branch off and doing whatever strikes my fancy. 
The thing is that Python will eventually go away, but the skill of continuously improving yourself while writing code will always stay at the heart of programming. We all learn the wrong manner of doing things all the time, but that experience makes you recognize and understand the better way immediately when you come across it.
You can accomplish this using _partial_ from _functools_ as well: &gt;&gt;&gt; from functools import partial &gt;&gt;&gt; oct = partial(int, base=8) &gt;&gt;&gt; oct("755") 493
It's still a very vague and directionless response to someone looking for guidance. Too often I find seasoned programmers not grasping the OCEAN use newbies find ourselves drowning in after we finish the 101 courses. I'm not trying to be disparaging at all, and I understand where you're coming from in the comment. However, some people, like myself, just DON'T have that 'pick up and go' mentality. Not yet anyway. Then again, this question is definitely more suited for /r/learnpython anyway.
Well it's a vague and directionless request, hence my question. If we knew what he wanted to use it for, maybe we could point him at the exact right resource, or an introductory book, or just help him get started. But without that, all I can offer is that it's generally better to just start working on something rather than first learn a whole bunch of generic Python stuff most of which will be irrelevant, and then start working on the thing.
I don't think we disagree, nor am I failing to see the merit in the traditional way of figuring it out. Like I said, if it works for OP, then it works. It doesn't make sense to disregard other means though especially with the shared end goal of being able to continuously improve yourself while coding. As an example, I'm pretty confident OP would never need to touch a tuple. However, knowing what it is and seeing some of its advantageous is going to be in any Python guide that covers data structures. That is the kind of knowledge I appreciate and doesn't come up organically in the self-taught approach.
&gt; But without that, all I can offer is that it's generally better to just start working on something rather than first learn a whole bunch of generic Python stuff most of which will be irrelevant, and then start working on the thing. is this view shared by many others? im wondering because im halfway through a python book and indeed ive seen a few things that i spent a lot of time on that i think unlikely to be used in the future.
&gt; Too often I find seasoned programmers not grasping the OCEAN use newbies find ourselves drowning in after we finish the 101 courses. ...I finished Codecademy, then started building stuff, so I'm not really sure where you're coming from.
Would be nice if you'd use a decorator for the injected objects so it's clear where there's going to be injection (as opposed to the registration calls that could be anywhere).
so wait... im like 40 steps threw http://learnpythonthehardway.org/book/ are you telling me when i get to CS in college il just waste my time till i get to higher class's? or... Idk, this book made me realize how much fun learning programming online is and how easy learning is once you know how. I thought CS was a class more about concepts and like... idk... not sure, i'l see once i get to it i guess.
I usually do this but I found that when I am already working on something I tend to find answers and clues on stackexchange and never really learn why is something the way it is. I mean, most of the times I figure it out but sometimes I just use bits and pieces of code not really knowing what happens underneath. That is why I would like to continue learning some more and then start with something real. Also what IDE would you recommend me? Preferably cross-platform since I am on both Windows and Linux. BTW, I really don't like vim/emacs (sorry!) :) 
Oops, didn't pay attention, sorry! 
Good question... Actually, this was just arbitrary, but I added some plots vs. a growing number of rows and columns, respectively. The trend seems to hold!
Basically yes. Your first year, maybe second year, will seem like a waste or breeze. For my University, after we have completed the second programming course, then we're able take Assembly Language (fuck you assembly), Data Structures &amp; Algorithms, Files and Databases, Programming Languages, Operating Systems, Computer Architecture, and much much more.
If you want to know why, then read the docs. https://docs.python.org/2/contents.html
IDE: PyCharm
This is the natural analog. Boolean algebra on the symbols true and false is not sufficiently different than the same on sets. The notion of a subset is a partial order so using a less than symbol is also appropriate. It is not an exceptional case. 
Yeah, that's what I had in mind, goals.
This may not be useful advice for some, but I think the way you approach a project is the main thing. If you say "what do I know how to do" and make a project, you will not learn much. When I was learning I really wanted to create an artificial life simulation where each 'critter' was running a simple virtual machine, and the code for those machines evolved using genetic algorithms. It took a lot of independent information scrounging to pull off (I could never have done it without Google) but in the end I learned a LOT. While I still am no Python expert, I did learn how to navigate the waters and gain confidence for approaching projects 'on my own' (meaning with nothing but an idea and Google). 
At my uni the first year of CS was like 60% math and only very little programming, we never did all that much actual programming the entire degree. It depends on the place.
Ah sorry, must have missed that bit in your original post. Learning how to read in, manipulate, and output media like CSV files, audio, and images, particularly using self-defined functions, was super helpful for me
I just take his advice really seriously since he knows, C++, C#, Python, GoLang, Javascript, Java, SQL, Perl, Ruby, PHP. So I know if he learned all of them the same way, I should too. He works as a coder and has done it for many years.
Alright, I'll write that up and be sure to work on that c: Thanks.
I'm a beginner in programming myself, I started with Codeacademy a couple years back too. These are what I've been using to learn since then: [Python Koans](https://github.com/gregmalcolm/python_koans) is a series of problems that'll give you a more in-depth look on basic language features and syntax than Codeacademy tutorial. It's presented as a bunch of unit tests, so you just have to run contemplate_koans.py and it'll tell you what to do. [Codewars](http://www.codewars.com) has a collection of programming problems for you to work on, ranging from very simple to complex. It's gamified, I find it very entertaining for hands-on practice. [Python Module of the Week](http://pymotw.com/2/) is a series of articles on modules of the standard library. I suggest reading through it and trying out the examples provided - knowing the stdlib will help you avoid reinventing the bicycle when working on real world problems. If you're interested in web development, Miguel Grinberg has [an amazing tutorial on Flask](http://blog.miguelgrinberg.com/post/the-flask-mega-tutorial-part-i-hello-world), and there's [How to Tango with Django](http://www.tangowithdjango.com/) for Django (I suggest trying the 1.7 version). These will give you a basic understanding on how to work with these two frameworks and get stuff done fast. On the same subject, I recommend reading some articles on WSGI - the interface Django, Flask and Pyramids web frameworks use, and how to deploy them with uWSGI/gunicorn.
Whether you like web2py or not, the DAL is really a great data layer, extremely easy to learn, supports most DBs, and you will love it if you don't like ORMs as this isn't one. 
The article should definitely re-run these tests with dataframes that are much larger. It could be that the penalty for the .loc method is minuscule and doesn't scale to larger problems, for example. People want to speed up operations on enormous dataframes, not gain microseconds worth of speed by importing a new package. A speed-increase of 22x sounds impressive, but it really isn't on such a small problem. Just for kicks, I wanted to test to see how the speed improved with size. Here's the code I wrote: times = np.zeros((5, 5)) j = 0 for size in [10, 50, 100, 250, 500]: names = [str(x) for x in range(size)] df = pd.DataFrame(np.random.randn(size, size), columns = names) result = %timeit -n 1000 -r 5 -o df.loc[:, names].sum(axis=0) times[0, j] = result.best result = %timeit -n 1000 -r 5 -o df[names].sum(axis=0) times[1, j] = result.best result = %timeit -n 1000 -r 5 -o df[names].values.sum(axis=0) times[2, j] = result.best result = %timeit -n 1000 -r 5 -o [df[col].values.sum(axis=0) for col in names] times[3, j] = result.best result = %timeit -n 1000 -r 5 -o [einsum('i-&gt;', df[col].values) for col in names] times[4, j] = result.best j = j + 1 # plot results x = np.array([10, 50, 100, 250, 500]) j = 0 for color in ['b', 'k', 'g', 'r', 'm']: options = 'o-' + color plt.plot(x, times[j,:], options) j = j + 1 plt.xlabel('Size of Matrix') plt.ylabel('Time') Here was my output: http://imgur.com/WfcDDF2 Not surprisingly, as the size of the dataframe grows, the methods that sum one column at a time (red and magenta colors) become much slower. At a size of 500 x 500 (honestly, still not big enough to really test the differences), the fastest method is actually Method 3, the green (using .values and sum). Also of note is that Method 2 (just using sum -- this is probably most people's go-to method since it's the most intuitive) isn't really that much slower than the optimal method.
Thanks for the comment and effort. Coincidentally, I just did similar tests + plots ~1 hour before you posted. Sorry for adding the tests later and having you do the work ;)
But it looks like we got opposite results, because you kept the number of columns constant! We were testing a different hypothesis. Edit: Nevermind, read more carefully. But I still wonder why we got opposite results. I showed method 5 as being one of the slowest for the larger dataframes.
I have 2 plots, 1 with constant rows and 1 with constant columns. Could you add a color legend to your plot? Would make it easier to interpret
Yeah, here it is: http://i.imgur.com/O2iudtS.png
So, for thinking about goals, are there any applications that stand out as appealing to you? Websites, where you have something online and it's easy to get to from anywhere on the internet? Games (everybody likes games)? Bots, to replace all those annoying humans? Data analysis and/or visualization? Mobile, something you can carry with you? Or maybe something on a standalone device like the Raspberry Pi, perhaps for home automation or an art installation? For me, I went through a dry spell where I didn't really do any programming outside of work, and then I finally got my [OpenBCI board](http://openbci.com), and that's been great incentive for me to learn more about data analysis and signal processing, which are areas I haven't really done a lot of in the past. (And now I've hooked up this thing that reads brainwaves to a [web server](http://imgur.com/a/w9d47).)
Some of the algorithms can be hard if you're new to that sort of thing. Particularly the brick ones.
I was hoping it would be in Berlin this year again. Sadly, looks like there was some issues with EPS and local event organizers - thus it moved to different city.
Thanks! Just wanted to make sure I wasn't missing a *next* link anywhere.
I want to scrape and parse rancid xml output for specific pieces of router configurations. I've seen this done with a proprietary database containing an entire inventory of network equipment. The database could be searched with std_in used for generating specific queries. I don't know sql. I don't know python. I don't know rancid. Shit.
They mean different things. In the first case, the `else` is attached to the `if`, so on each iteration of the loop, if `guess != random_number`, it will print "You lose.". In the second case, the `else` is attached to the `while`, so it will only print "You lose." if the loop exited normally, without hitting the `break` statement.
omg it was so obvious. I can't believe I didn't think of that myself. Thanks a lot.
If anyone is doing codingbat's exercises, I made a template that makes it easier to work in your development environment (instead of the textbox on the site): * Warmup1Sample.py [View](https://www.dropbox.com/s/zx22jykukquma0h/Warmup1Sample.py?dl=0) | [Download](https://www.dropbox.com/s/zx22jykukquma0h/Warmup1Sample.py?dl=1) * CodingBatTemplate.py [View ](https://www.dropbox.com/s/sy3gt1hwlahhhqg/CodingBatTemplate.py?dl=0) | [Download](https://www.dropbox.com/s/sy3gt1hwlahhhqg/CodingBatTemplate.py?dl=1) edit: credit: some of this function was hijacked from the [google-python-exercises](https://developers.google.com/edu/python/exercises/basic) also is for python 2.x
Next step (suggestion), use function annotations (though, afair, python3 only): @use_args def index(name:str, last_name:str=''): return 'Hello ' + name + ' ' + last_name
I'm interested in websites, bots, data analysis(maybe visualization). These stand up for me the most.
I got like halfway with Codeacademy, it isn't bad, even tho most of the things I still learned from trying to accomplish something(made a login system that reads the login details directly from code, no database, no text file stuff). I was told that Python is really easy to learn compared to other languages and one of the most used languages now.
Personally, for all non-javascript purposes I just use the *mechanize* library. Nice and easy to use, no graphics to slow you down. But if you want JavaScript handling, Selenium definitely seems to be the way to go.
 &gt;&gt;&gt; while True: ... some_var = 'foobar' ... break ... &gt;&gt;&gt; some_var 'foobar' No.
This is awesome! Flask-dal would be sweet.
Ooops... didn't notice that this post was from 2010. Oh well, still true I guess! ;-)
There's a project that takes that approach: https://github.com/alecthomas/injector I personally prefer not to scatter a big global dependency on the container, also means it's possible to mix approaches (e.g.create the object with dic or without). I haven't used dic, but have used autofac and the approach seems to be the same.
Output: [^source](http://ideone.com/p5d4F7) ^| [^info](http://www.reddit.com/r/CompileBot/wiki) ^| [^git](https://github.com/renfredxh/compilebot) ^| [^report](http://www.reddit.com/message/compose?to=compilebot&amp;subject=Report%20Abuse&amp;message=--report%20http%3A//www.reddit.com/r/Python/comments/2qaso8/if_break_is_used_when_using_loops_do_the/cn4g0dl%20Include%20your%20reason%20for%20reporting%20here.) 
Well for me it's work, they give me new things I've never done before every day. I do them as best as I can at that moment and do some search to find improvements or learn about new libraries I need, but when I revisit that code a year later to implement some new features it always looks like crap, because I've learned better ways since. If you don't do it as a job (yet), it again boils down to "what do you want to do with Python." If it's just for general knowledge, then it's of course fine to just take some course or book and do it from start to finish, why not.
Some ideas off the top of my head. Find an open source project on github and try to fix some bugs. Go to the nagios plugins library and try to convert all the scripts in bash into python. Find a list of interview questions and write them in python.
Most major packages are now compatible with Python 3, and they won't be releasing a 2.8. Sites like Treehouse.com are good to learn from if you need a more structured lesson plan, and they teach Python 3. Checkout this site and you can see what packages are compatible with Python 3 and which ones arn't. [Python 3 Wall of Superpowers](https://python3wos.appspot.com/) 
10 seconds in the console would have answered this for you. 
I have holidayed in Bilbao quite a few times now, it's a really great place. Huge investment in all sorts of modern art, culture, and technology so the conference will fit in well there.
If you're looking for similar performance as you got from LibGDX, you'll probably have to go for PySDL2 or PyOpenGL, both of which are really just thin wrappers around C libraries. If that's not a concern I like Pygame the best of your three. You can do "non-primitive" things with it, you'll just have to code a lot of it yourself.
But I am looking for quick game development. Similar to how I could do with LibGDX, where much of the functionality was completely built in already. Tweening, transitions, animations, etc.
Panda3d is a pretty complete solution.
Sorry I forgot to mention that I was developing 2D games. Is there anything similar focused on 2D development. Anything you could suggest?
You could also check out saltstack or ansible. Sysadmin as a role is starting to involve a lot more software development 
Thanks! Yes, I am also wondering about the different results. When I either fixed column or row size, method "5" was always faster ...
I use the Rstudio IDE and it seems quick and easy to use....although I don't use data as large as 10Gb. Is Python really that much better?
People keep saying that Python is better for big data sets but I have not found a satisfactory justification so far. R does have some extra overhead from excessive object copying (part of it being the limited use of pass-by-reference), but in the end R and Python both have to load data they work with into memory - unlike S-Plus, SAS, (Revolution R?) - so I wouldn't expect the gain to be that significant. I'd be happy to hear a counter argument.
&gt; but in the end R and Python both have to load data they work with into memory Not necessarily. You can do out-of-core stuff in Python (I use IOPro, but you can do it with open source tools as well). I think the same is possible in R as well, but I only know a little bit about it.
Meh. RAM is cheaper than my/our time. I've worked with several folks who have 512GB of RAM for R.
&gt;I am shocked by python's extreme power and easy-to-use design after nearly two weeks, dealing with a 10GB CSV Has been a long time since I used R, but you also have modules for convenient processing of SQL/noSQL databases, right? But what about generator expressions and memory views? 
My wife uses R and MATLAB despite my urging to use Python (numPy &amp; Matplotlib). I will admit that R studio is nice and so is R-markup (?). The R (and MATLAB) syntax is just so much harder to do things in. My biggest complaint with Python for the semi-casual user is the IDE situation. IDLE is much too simple and everything else is much too complex. I have ended up just use notepad++.
I'm with you for most of it, but I tend to think that sometimes it doesn't matter if it's slightly odd ("once you know that X works the way it does") as long as the docs or example explain it. IMO, there's way too much stress in following best practices to the letter for every line of code you write. You're going to have to read the docs anyway. You can't just start using an API or framework without reading a little bit of docs or looking at an example. That part alone is enough for you to understand what the / does in scapy. If that alone will teach you the meaning of / between IP() and TCP(), then I think it's a good place to ignore the principle of astonishment. Even [the first part of their docs](http://www.secdev.org/projects/scapy/doc/introduction.html#quick-demo) has an example which shows it, and from then on I had no problem with the notation. One line + one comment and I was fine. I did think "heh, odd. okay." when I first saw it, but I understood immediately what the result will be when I use / now in its context. It's unnecessary, I agree, but it's also pretty intuitive and very useful for the audience that will be using scapy, and that to me is way more important than a best practice. Unnecessary, but way more succinct than any other way I can think of. The interest is in the contents of each layer as individual parts, not how they are connected and glued together. That's part of the internal workings that something like scapy should be doing for you 100%. I don't want to worry at all about that stuff when I use scapy. Again, it's all an opinion. I never mess with that sort of stuff with any of my production code, but I do respect coders who find a place where they don't mind breaking one principle and aren't worried about getting called out for it. Best practices after all are just best practices, and even the experts that came up with them will tell you that they are guidelines, not rules.
So, I know it's not exactly what you're looking for, because it's not Python, but you should give LOVE2D at least a quick look.
PyCharm Community Edition
Yes, but there are a few things to tweak to make it perfect. You need to set up the right version of your language as a build system if it isn't automatically. That way you can run your code without leaving sublime text. Then install package manager and download some packages to make it perfect. The code completion package "sublimecodeintel" and "autofilename" which autocompletes file names and paths are a good start. Once you get sublime text set up just right it is awesome.
Lua's a great language. I'm not terribly experienced with it, personally, but it's highly readable, very approachable, and full featured. I'd say it's comparable to Python as far as features go (aside from OO), but focused more towards scripting than programming. When it comes to not having OO, I haven't really found any hurdles. It's just different, but the same, but not the same. [See this LOVE2d physics example to kinda see what I mean.](https://love2d.org/wiki/Tutorial:Physics) It kinda just has other stuff in place of objects, that still function similarly to objects as far as the code itself is concerned. LOVE2D is something I'm still trying to get into, I'm having difficulty because I come from Unity and it's just different enough to make it difficult for me, but outside that it looks like a fantastic framework. Additionally, Lua can indeed be OO if you really want it do be. [See here.](http://lua-users.org/wiki/ObjectOrientationTutorial) That said, Lua libraries are designed to work the Lua way.
I prefer R if I have all my datasets ready to go in CSV files, anything more involved than that and I'll use Python.
Perfect timing, a [comparison](http://ajkl.github.io/Dataframes/) was made recently between Python and R and also Julia, not on performance, but a comparison on capability and syntax. Maybe I'm biased, but I definitely prefer Python panda's syntax. A [comparison](http://nbviewer.ipython.org/gist/TomAugspurger/6e052140eaa5fdb6e8c0) of Pandas and R's dplr.
FYI, there is a Python port of Shiny called [Spyre](https://github.com/adamhajari/spyre) and recently a [comparison](http://nbviewer.ipython.org/gist/TomAugspurger/6e052140eaa5fdb6e8c0) was made between Pandas and dplyr. Also, IPython widgets have similar capability as Shiny/Spyre, with the primary difference is the code is visible. Maybe there is or will be an extension to hide code cells.
Why not use [both](http://nbviewer.ipython.org/github/pybokeh/ipython_notebooks/blob/master/R/Forecasting_Using_Python_R.ipynb)?!
The docs are at python.cocos2d.org/doc, and they do a pretty nice walkthrough!
Back in 2000 while i was in grad school i had a postdoc friend that urged me to pick up python. In 2011 i made the switch and have not written a single line of Matlab code in almost 4 years. Matlab definitely has advantages, but price is not one of them.
I just read through some Lua guides for programmers to learn the language. I am not very fond of it. I grasp it theory-wise, but I am not really liking it. I hate "end" and I really dislike how OO seems thrown in at the last moment. It does not feel like something that belongs. I don't want to have to hack things together to get the functionality that I want. So I think I am going to have to continue my search with Python engines because Lua is just not for me! I guess it's a matter of opinion.
Edit: Got an error, but solved it.
Try spyral, see how it feels: http://www.platipy.org
R data.tables library is much faster then anything Python has presently.
I haven't heard about this one? Is it very mature? Also does it only run on Python 2?
Yes - because a ton of the work that must be done involves transforming the data. And these filters and transformations across the many fields of many files becoming a programming challenge. Python being a general purpose programming language that's particularly strong at this kind of task makes this much, much easier.
I'm one of the core developers. I wouldn't say it's super mature - very well documented, but not very well tested. Tons of functionality, though, and I definitely recommend it over pygame. And yes, currently python 2 only because we haven't had much call for python 3 support. No reason we can't target both eventually - but the primary users are XO laptop developers, who are mostly stuck on 2.6.
Counter Example: Realistically, if you still use R, you're probably some PhD/Fresh Undergrad/Academic dude, who loves to get his hands dirty with absolutely ZERO experience in actually scaling algorithms in a production environment that doesn't absolutely suck. Python is infinitely better at scaling and easier to explain to Engineering teams how your code works. So cool, you rock a sweet sandbox setup where you love to show stuff off to business teams with pretty ggplot graphs, but the reality is that R is just inferior and the fact that this is an ongoing argument means that you've still got a lot to learn. 
+1 for Dplyr. I started with Python and finally just gave in and switched to R for most of my work. It's just too easy to ignore
An overwhelming number of "real world" data problems don't necessarily involve a need to scale well to ultra-large problems. People using languages like R aren't necessarily looking to put out software designed to run on multiple machines or anything like that -- we're looking to analyze a relatively small data set quickly and easily. I need great packages that can do things like probits, regressions and descriptive statistics, and R is absolutely fine for that purpose. Saying "you're all just PhD students, in the REAL WORLD everybody needs software that can scale up to a billion by billion data set" is not only intellectually lazy, it's flat-out wrong.
&gt;Not necessarily. Yes, necessarily. I would like to hear how you expect a program to interact with data WITHOUT loading it into memory. If a computer is working with data, that data must be loaded into memory. It need not all be loaded simultaneously, but it needs to be in memory to interact with the processor. If your processor isn't interacting with the data, then you aren't actually using the data for processing.
Life's too short not to be weird; do it in awk. 
Awesone
I don't use ST3's build system at all for Python. For Python and other languages that I use (Haskell, Scala, C#), there are plugins that completely circumvent the build system to provide a better experience anyway. I'm a big advocate of using the command line as your build system. IPython is great on the command line, you can use a setup.py file for most of your project management needs, and I get much more power out of ipdb than any graphical debugger I've ever seen andif ipdb isn't installed then pdb is by default. Also handy for those really tricky bugs to track down, because if you can detect when your system gets in an invalid state you can inject a breakpoint programmatically. As for Python plugins for ST3, I recommend SublimeLinter/SublimeLinter-flake8, one of SublimeCodeIntel or SublimeJedi (they don't play nicely together, which is unfortunate since it seems each makes up for each others' weaknesses), and AutoPEP8. These three plugins will cover your autocompletion, automatic code formatting, and flake8 builds on top of pep8 to provide some more static analysis for your code.
He's saying that it's feature equivalent to S-Plus and SAS, as heystephen used unfortunate wording.
&gt;but the reality is that R is just inferior Depends on the task at hand. In many respects, python lags behind for modelling. Perhaps you've still got to learn about that.
I used R and it was pretty good. But where Python beats it is that while Python can't do certain things as well as R it is a close second and then it does 1 million other things that R really sucks at. It is like having a car that accelerates very very quickly but turns/brakes/etc very poorly. So R is great for drag racing but terrible for everything else. While Python is more like a jeep with a million attachments in the garage. On a whole other side note, I have even begun using Python to replace Excel when it comes to basic number crunching and graphing. With Excel I always find that there is some simple (in python) step that is 800 hard steps in Excel. Plus the graphs are much more advanced with matplotlib. 
Let it go bro R is an amazing language for what it's purpose. It has seen a five fold increase in language use since this article was written. If R is do broken explain why it is so popular and has steep increase in users. You just don't know all that R does and that is okay but pushing Python as the best is the true sign of a fan boy. Name me one thing that Python does better then any other language? I love Python but this community anti R crap drives me nuts. R, Python and Julia are good and smart people choose them for smart reasons. 
Pycharm!! It's so good (and so worth $100, though there's a free version)
You are replying to the wrong person. The person that used the terminology that you do not like is further up the thread.
THIS IS RELEVANT TO MY SKILLS.
Not only RAM, but SSD and CPU as well. 
After reading the first few pages, I feel like I am going to love this. It's a really well set up library, but I am encountering some very bad parts of the documentation that is making it increasingly difficult to learn the library. For example, this has many gaps and many "todos" and empty spots, and is also quite lacking in explanation of the depths behind Actions. http://python.cocos2d.org/doc/programming_guide/actions.html
Now, I'm on your guys' side, but R is a pretty awful language that shows what happens when you design for shortcuts that scientists would find useful without keeping in mind the long-term harm to the language when making those decisions. Something gaining popularity doesn't mean it's overall great, just that it competes well in introductory tasks compared to whatever it's up against. Which is also fine, there's a place for that. Just don't take popularity as an argument for quality.
Is not an IDE.
Lua is really wonderful and I enjoy using Love2d. There are simple class libraries that allow for simple OO.
&gt;It is like having a car that accelerates very very quickly but turns/brakes/etc very poorly. So R is great for drag racing but terrible for everything else. While Python is more like a jeep with a million attachments in the garage. Thanks for this analogy. I think it applies to MATLAB vs. Python as well.
I am having trouble finding examples of design patterns for use with this library. For example, how to handle entities and collision handling and sending events to those entities to be acted upon, etc. I know the guides have descriptions of the library features such as the collision manager, and how to track events, but I am having trouble piecing this all together. If you are familiar with Cocos2D, do you mind helping me, or possibly linking to a tutorial or project where I can see the recommended design patterns?
I agree with this so much as someone who started in R and moved to Python. R code is painful and dependency management is probably still atrocious. I will never go back to pure R again. At most, I will glue some R together with Python.
If you are after speed go for julia. You can load and run your R libraries and run libraries in python.
[Codeacademy](http://www.codecademy.com/tracks/python) is a good place to start. After learning a bit, you can go to [Codingbat](http://codingbat.com/python) to revise what you have learned by solving problems. If you find them difficult, you can always check out the solutions. That's enough to get you going.
/r/learnpython is a good start
sadly its used too much in the real world :(
Is that really a 41MB PDF ?...
Really don't understand all the rage here, you're arguing over someone's choice of programming environment. Take a deep breath.
Those shortcuts are there because a lot of users aren't computer scientists, we're mathematicians, statisticians, or people in industry and we don't care about how well our code scales so much as getting an answer. While working on my PhD, I wrote some scientific computing code in C++ before ultimately switching (ironically, given the subject of discussion here) to Python because I find Python SO much easier to develop in. I know that, to a trained programmer, C++ is probably way faster and allows for much better control over the program flow, but I'm not trained enough to take advantage of that, anyway. It makes me think of people bashing MATLAB because it's slow. Yeah, it is really slow. But not every problem needs a lot of speed. MATLAB is the perfect tool for lots of problems and situations. I feel the same way about R.
R has a very established ecosystem in certain fields. To the point that I'm currently working on a project that uses no extra R packages (by requirement) and the client still insisted to do it in R (would've been much faster in python) because the audience he is targeting is 99.9% academics with R background. That being said, I had another project that required pulling data via API, feeding it into the GPU for analysis (pyCUDA), feeding that into scikit-learn and then uploading the result via another API. I'm sure that this coud be done with R, but suspect that it would've involved much more hassle. 
Please look at the sidebar before posting.
Not sure what you mean? R uses the same linear algebra libraries as everyone else and dplyr is faster than pandas.
Can you give me some examples of things that you come across often that you can do easily in R but not in Python? I do pretty much all my work in Python but haven't worked much with R, and I've heard before that R has really strong library support but haven't come across many things in the wild that I haven't been able to do easily in Python (not that I do a ton of heavy lifting).
Yeah, Excel is great at the small subset of things that it does well, but the ability to tailor Python (and R, but to a significantly lesser degree) to exactly the work that you are trying to do trumps it thoroughly.
&gt; Too often I find seasoned programmers not grasping the OCEAN use newbies find ourselves drowning in after we finish the 101 courses. If your reason for learning to program is simply to learn to program, you will never get anywhere. This is why netaddicted's top comment is important to understand. There *is* an ocean of stuff to learn... which is precisely why you must focus on mastering the subset of that stuff that is relevant to your interests. 
Good to know you liked Scientific Python! The easiest way to get you started on Windows is too install a Python Scientific Distribution. They are like Linux distributions in the sense that they come with the most common packages you need to do scientific work (numpy, scipy, matplotlib, pandas, ipython, etc), so you don't need to worry about compile them (which is really hard on Windows). Some also come also with a package manager that let's you update and install even more packages. From the ones cited in http://www.scipy.org/install.html I'd recommend: 1. Anaconda: Perhaps the most complete one but after you install it, you need to manage updating and installation of other packages using the command line (i.e. cmd.exe) 2. WinPython: It's portable (i.e. it runs from a USB pen drive) although you can install it in your computer too. It comes with a graphical package manager, which is also very good. I think the main difference is that it doesn't have as many packages as Anaconda. 3. Python(X,Y): It's also very good, not as good as WinPython but it comes with more packages. However, it's not updated very often and doesn't have a package manager. 4. Canopy: It has a graphical package manager but (I think) you need to download the academic version to have full access to all the packages they provide. Else you can only install a very small fraction of them. 
I meant that buying SSD and a faster CPU always a good investment. 
I like your analogy. A coworker needed to analyze the performance numbers we had gathered about our real-time software. He started with R since that seemed to be the obvious tool. He got something working, but as our understanding evolved, he had to change the R script frequently and it got very clumsy. The performance data gathering tools were already written in python, so when he discovered NumPy he jumped to that and never looked back. He said something very similar to what you said, that it has all the tools he needed and more.
Thank you for the response! My professor also mentioned that compiling in windows is very difficult, it must be pretty tough. Lets just say though that I really really want to be able to do that (there is at least one additional package I want which is not included in those you listed that needs compiling), is that just way out of my league at this point? How would I go about doing it/where could I find this information? Do all packages need compiling or just some?
&gt; every 10 seconds Two questions: Why would you do this to a friend? How can this not be in violation of the TOS?
Beautiful visualizations. In R, ggplot2 is the de facto standard for making great static visualizations. It is easy and makes great stuff. In Python you are stuck with either the horrible MatPlotLib or a host of far less developed options (Seaborne etc). And yes, I have heard about yhat porting ggplot to Python. It is coming along great, but far from complete.
Yeah, I work in engineering and a surprising number of companies/departments use Excel and Excel+VBA for engineering calculations. It's atrocious.
Ehhhhh. This would be much more useful if it contained a library of known strings, randomization of 'browser plugin' info, etc. Grabbing from a list in a text file is pretty easily done with a file open. Not sure it needs to be broken out into a library. 
I have a list of about 100 ua strings of some recent browsers, which I can post to a gist - if that would help. 
you shouldn't do this at all. just set a user agent like so: YourProgram/1.0 (+contactemail@somehost.com) you specifically want to make it easy to identify your bot so if it's misbehaving the site owner can block one bot at a time instead of doing blanket bans on all bots. it's rather rude to try and evade bot-blocking.
Submit bug reports when you find gaps in the documentation! I can't speak for cocos2d, but my experience with other projects is that it's hard for people very experienced with a project to spot the gaps that newcomers run in to.
Alright having downloaded enthought and used it a bit (and not liked it much) my worry with these prepackaged things is that they aren't as flexible/will be difficult to add additional modules to. Is this a legitimate worry or no?
Just finished codecadamy python as well. 
/u/hweb500 put it right - and anaconda comes with a package manager I believe. ('conda')
I'd go with requests definitely, record the process of buying an item with something like Charles and then automate the requests
Intel MKL is an acceleration library for matrix math. It will generally give you about a 20% performance increase in the matrix math parts of the code - with no significant effect (+ or -) on the rest of your program. Generally, I'd say that it's a plus if you can get it, but it isn't essential. If you're working with this professionally, I'd hold out for MKL and a workstation with a good processor, a good GPU and plenty of RAM... It doesn't actually cost a lot of money when you compare it to the cost of having someone at their desk in the first place. (Salary, benefits, space rental, required licensing....)
MKL is very nice, but if you don't have it then the matrix parts of your code will just be a bit slower, you won't lose functionality. If you find this is a problem then the MKL addons from anaconda are quite cheap even for non-students.
Basically, `numpy`, `scipy`, and other scientific packages will defer some operations to a compiled math library. This library provides really fast routines for things like matrix multiplications. There are a few around: LAPACK, ATLAS, and Intel's MKL are a few. They're interchangeable, so `numpy` can use whichever backend you have on your system. The Intel MKL is heavily optimized for Intel hardware. If you have an Intel processor, you can see some pretty nice performance gains just by using the MKL. You can install the MKL separately, then compile `numpy` to work with it, but Anaconda handles all of this for you. The MKL also has an academic license which makes it free for students -- I think it's quite expensive without it.
I was very impressed with the MKL. In one instance I saw a 10x speedup in solving a large, dense linear system, though I'd agree that a 20% increase is more typical.
Here is the link for [natural language processing](http://cran.r-project.org/web/views/NaturalLanguageProcessing.html) on Cran this list several packages. For strings in data frames I just use dplyr and mainly str_replace_all or str_split
WHAT?? R with R Studio and Hadley Wickham's packages are just a thing of beautiy. Are there bad packages like are there bad apps on Google Play and Apple's App Store yeah? At its core with modern packages R is a thing of beauty. Look at Hadley Wickham's packages. They are brilliant and streamlined. Coming from a Python person who probably uses Python 2 still????? (Seriously I like Python but to be saying R is broken and awful is just non-intelligent and not true) You can just pick and choice your library and stick with that. R evolves so fast. Reason for popularity: ggplot2 plyr dplyr shiny stringr tidyr etc... [github repos](https://github.com/hadley?tab=repositories)
That's almost certainly one of those cases where it made the core of your process fit in cache... You can get incredible speedups in those cases. It's atypical as all get-out.... but it does happen. The setup I recommended to the OP would let him use Numba Pro to push his kernels onto the GPU - which can, depending on what he's working on, also give some serious speedups.
Vs what, a different BLAS library or nothing? There are plenty of options that don't have Intel's license restrictions or painful install process.
you would have to put something in to stop it from buying strange and useless things everyday. like a grill fork or swivel wheels or a box of specialty screws.
Everytime I see the name awk, I get the feeling it's actually onomatopoeia (a word imitating a sound) for the sound you make when you try to read someone else's awk code. Like: awk -F"[.-]" '{ print $3 ";_1." $2 ";" $0 }' *Awk!*
Enumerate takes an iterable and returns an iterable of tuples of the terms of that iterable and the index of each term. ['a', 'b', 'c'] &gt;&gt;&gt; ['a', 'b', 'c'] list(enumerate(['a', 'b', 'c'])) &gt;&gt;&gt; [(0, 'a'), (1, 'b'), (2, 'c')] Then, unpacking assignment... x, y = (5, 6) x &gt;&gt;&gt; 5 y &gt;&gt;&gt; 6 Does that help? Sorry, not on anything with a decent keyboard at the moment. 
The thing that got me to switch was I had to hand in my internal reports in M$ Office documents and R does that so well!!! I think Python is great but R is something I now look forward to using.
The comma doesn't mean concatenation, except in the sense that the print function happens to print all its arguments together separated by a space. This is specific to print and not a general use of the comma. The concept you're missing is called _tuple unpacking_. When you have a tuple you can get the parts out of it by giving several names separated by a comma: &gt;&gt;&gt; one, two = (1, 2) &gt;&gt;&gt; one 1 You can do a similar thing with an assignment inside a for loop: people = [('Julian', 12), ('Dick', 11), ('George', 11), ('Anne', 10)] for name, age in people: print name, 'is', age, 'years old' The enumerate function takes a list and turns it into a list of tuples where the first item is the index of the original item and the second item in the original item itself. &gt;&gt;&gt; people = ['Julian', 'Dick', 'George', 'Anne'] &gt;&gt;&gt; enumerate(people) [(0, 'Julian'), (1, 'Dick'), (2, 'George'), (3, 'Anne')] Put those two together and you have everything you need.
&gt; The code loses me at the for loop... / What's happening in the for loop? When iterating over a list in Python, you're accessing the objects within the list, not their indices. Unlike other languages that implement list/array iteration on their indices, the default iteration here is using the actual references themselves. &gt; The term index is not seen... `index` in this sense is created and used within the scope of the loop. It doesn't need to have been "initialized" before use. Depending on your programming background this may seem unsafe or wrong, if you're coming from anything typed or compiled -- Python is interpreted and thus you don't need to declare or initialize variable before assignment. `enumerate` is a special global function that tracks the index while iterating over an iterable structure (list, dictionary, tuple, set, etc.) -- it yields a tuple consisting of the index and the value of the call to the iterator. In comparison, in Java, C/C++, JavaScript terms, to accomplish what this does, it would look something like the following (not real code, just meta): String[] choices = ["pizza", "salad", "pasta"] for (int index = 0; index &lt; choices.length(); index++) { println((index+1).toString() + " " choices[index]); } 
Ipython notebooks?
That's the entire point of the script, to buy random items. 
Two things come to mind: * As data frames are a native data structure* they are better supported than Pandas data frames. * Regression analysis and modeling is just spread all over the place in Python. You can find linear regression functions in, at least, scikit, scipy and statmodels. * Finally, I find that R packages are better documented than Python libraries, even though they can be a bit obtuse. It's not that Python is a bad choice for doing data analysis (heck, it's an awesome tool), but R is still the de-facto language and you can find libraries for just about anything. *Sorry if I am wrong with my lingo, but I'm not native English speaker and I'm also a civil engineer, not a computer scientist
Zip it?
Compress it. Or put it on Dropbox and just send a link. 
Uploaded it to Dropbox / Mediafire or push it to a temporary github repo then send him the link ...maybe?
I see. Yea my first language was c++. Python is my second. It's really weird switching mental gears between a language where I need to manually handle memory and one where I don't.
Nah, gmail blocks .exe's inside of zips, too.
So after I create the list of enumerated letters I can extract the letters by referencing their enumerations?
Zip it, then rename the.zip extension to .zap. Send it via gmail. When your friend receives it, have him rename the extension to .zip. I do this all the time through gmail
Okay, awesome. But I just realised that my .exe is only opening properly when I run it from its generated location inside the /dist folder...when I copy the .exe to the desktop, or dropbox, it gets virus scanned, and then flashes open and closes instantly. What's up with that?
Put it inside of a password-protected Zip, and send your friend the password in the email message.
Okay, awesome. But I just realised that my .exe is only opening properly when I run it from its generated location inside the /dist folder...when I copy the .exe to the desktop, or dropbox, it gets virus scanned, and then flashes open and closes instantly. What's up with that?
Zip it, then rename the file to be a "piz". "File.exe" into "Directory.zip". "Directory.zip" into "Directory.piz" Your friend will have to rename the directory into a zip again, but it will wowrk.
confetti?
Since R design really dates back to S AKA 1976 ( C it's 1972) I think it is pretty amazing.
I mean, LISP dates back to the 50's. A language can be old and well designed.
Where is seaborn lacking? 
yep. Excel is better than doing things by hand. But too many people get placed into a technical department/consulting and use the only tool they know how to use for any use case. Thats why if you work in data, you will eventually inherit a monster sreadsheet with all kinds of macros and formulas extending lines and lines. For anyone that is a heavy excel user, excel its a burden wheter they know it or not.
I think [Frets on Fire](http://fretsonfire.sourceforge.net/) is pretty cool and it uses pygame. 
MATLAB is a great language for the kind of problem it's designed to solve: small-sized numerical methods-type problems. The code is very expressive to those with a math background and a lot of tools are built in in a very nice way that make it super easy to explore mathematical concepts and really develop quickly. For example, matrix multiplication is just A*B, and you can solve least-squares problems using just the / operator. I love MATLAB and really wish it could scale to large problems easily. Like you also mentioned, the package and tooling support is great, and I have yet to find an IDE for any language that really matches how great MATLAB's is. Ipython notebooks are definitely the next step in sharing numerical work, though.
Great resources, thanks!
Pygame is a good start but I personally recommend Kivy (www.kivy.org). I have used Pygame for a significantly greater amount of time and it is much easier to understand and is better optimized for learning than it is for actual game production. What I am trying to say that if you were trying to learn game development in Python, I think you should start with Pygame, but moving to Kivy will be a switch I would highly recommend, as Pygame simply does not accomplish what I wish to accomplish. PS: You should also check out Panda3D, for the interest (www.panda3d.org/)
Are you aware of IPython notebooks? You can embed all kinds of stuff such as Latex, markup, images, videos, etc. You can also code interative widgets.
You should definitely start with Pygame, because that will teach you what you need to know about how to make a 2D game. Pygame is real easy to use, and as a consequence does not obfuscate how a game works. You're gonna have to write your own mainloop, your own update and draw functions, and your own event type functions. That is an operation that most other similar frameworks do for you under the hood. So while you could totally use Kivy or Pyglet to make a game, in those cases a lot of the stuff you need to learn is done for you. AND those frameworks tend to be somewhat more complex and harder to learn because of it.
I've been to your page before. But never really took a peek at what you wrote. Gonna check it out now :)
Thanks everyone! Your input has been valuable!
Hmm. Would you recommend using graphics API over pygame?(opengl)
[pySFML](http://www.python-sfml.org/), a binding of SFML2 written in Cython. The performances are better than with PyGame. Windows binaries for Python 3.4: http://www.lfd.uci.edu/~gohlke/pythonlibs/#pysfml
It links to files it creates in the process. You need go send those too I think. 
It isn't meant to be useful, it was something I threw together in the process of working on something else. It isn't terribly impressive (I'm hoping to inject x86 assembly into Python soon), but it shows off the power of ctypes to do something unconventional.
I believe this was in comparison to LAPACK from the Debian repositories.
The mathematician inside me just want to add that saying that this is a 'proof' is wrong. You never prove something by just trying over and over and saying "look! The odds of this not being the case is really really small so it must be true! QED!". But besides that it was really cool to see! Good work!
Can't he just call the exe *.ex and will get the same result without zipping?
yeah, it's not really a proof in the mathematical sense... it's more an experiment to show that the theory in the video does in fact work. but neat stuff regardless. I just wanted to throw together a quick little thing to see it in action for myself. not a mathematician, just a pythonista :) could of probably chose better verbiage...
something like pastebin where I dont have to make an account, I can just paste the sourcecode on a website and just post the url here.
This is a really good thread. Thanks to everyone for their contributions s. 
Not sure. I've only tried it with zip files
Im interested
Codecademy gets my vote as well. 
This is some crazy shit [6]
Yeah R hasn't been able to do ANYTHING productive and be the number 1 statistics language for all these years since the language is SOOOO broken. People wanted S just to die and not be made into an Open Source project. Just a totally broken mess. :P
Send it my way!
&gt;Also, does anyone know how to post code to a websource for anyone to run from any computer? Github. Do yourself a favor and get familiar with it now. The sooner, the better.
Okay, Kivy looks interesting, but *how the hell do I install it?* I'm on windows and downloaded their 130 mb zipped file and extracted it and all, setup.py and pip just tell me Cython is needed, and when I pip install cython it tells me another thing is needed. Then their guide points me in the direction of another guide who says the whole thing needs to be compiled with MinGW ? What the hell? What are the proper steps to just achieve a simple library that I could just use with "import kivy" like I do with any other library?
Yes please, I interested. 
You could write a bash script?? For i in * : If file move to ~/Desktop/output
the last part of my post: "I wrote the script originally in bash but now I'm challenging myself to do it in python. Any ideas?"
I wrote Monopoly for Chipmunk Basic when I was younger. Turns out that it's much less interesting once you remove all the physical elementss of the game (the exchange of currency, rolling of the dice, moving of the tokens, etc). Taught me an important lesson about video games. I would love to read a copy of monopoly.py, and I suggest that you just post it on pastebin and link it here for reddit. RemindMe! 24hr "Python Monopoly"
Indeed, I was referring to out-of-core loading. This presents an object that behaves as if it was loaded into RAM, but which fetches the data on disk lazily only when it's needed and discards it (usually with some caching though). You pretty much have to do it if you want to load data that is bigger than available memory. Pretty sure this is what /u/heystephen was referring to as the features in S-Plus and SAS (not certain though, as I'm not really experienced with them). I was just pointing out that you can in fact do this in Python and I think you can do it in R as well.
Messaging you on [**2014-12-27 03:37:45 UTC**](http://www.wolframalpha.com/input/?i=2014-12-27 03:37:45 UTC To Local Time) to remind you of [**this comment.**](http://www.reddit.com/r/Python/comments/2qefvu/python_monopoly/cn5htyr) [**CLICK THIS LINK**](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[http://www.reddit.com/r/Python/comments/2qefvu/python_monopoly/cn5htyr]%0A%0ARemindMe! 24hr ) to send a PM to also be reminded and to reduce spam. _____ [^([FAQs])](http://www.reddit.com/r/RemindMeBot/comments/24duzp/remindmebot_info/) ^| [^([Custom Reminder])](http://www.reddit.com/message/compose/?to=RemindMeBot&amp;subject=Reminder&amp;message=[LINK INSIDE SQUARE BRACKETS else default to FAQs]%0A%0ANOTE: Don't forget to add the time options after the command.%0A%0ARemindMe!) ^| [^([Feedback])](http://www.reddit.com/message/compose/?to=RemindMeBotWrangler&amp;subject=Feedback) ^| [^([Code])](https://github.com/SIlver--/remindmebot-reddit)
thank you so much, hastebin worked like a pro. http://hastebin.com/omejejegaw.py
I'll offer a hint since you're trying to challenge yourself. `os.walk` will look at `dirs` to determine what location(s) it should visit next. If you somehow made that list shorter it would tighten up the loop some which could make it faster.
This is due to an implementation detail of [python 2](https://docs.python.org/2/library/stdtypes.html#comparisons): &gt; CPython implementation detail: Objects of different types except numbers are ordered by their type names; objects of the same types that don’t support proper comparison are ordered by their address. float/int &lt; list &lt; str This is no longer the case in [python 3](https://docs.python.org/3/whatsnew/3.0.html#ordering-comparisons): Python 3.4.0 (default, Apr 11 2014, 13:05:18) [GCC 4.8.2] on linux Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; info = ['z',2,7,0, "dad", "mom", "this is a sentence"] &gt;&gt;&gt; data = ["mike", 'a', 'y', 't', "jen",info, "jacob", 55, "zap", 44, 22, .1] &gt;&gt;&gt; max(data) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unorderable types: list() &gt; str() &gt;&gt;&gt; min(data) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unorderable types: list() &lt; str() &gt;&gt;&gt; sorted(data) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: unorderable types: list() &lt; str() 
I've made the same game in both pygame and SDL with very limited changes (what you would expect from porting a python program to C++). So you are categorically incorrect since it can be done. Edit: I was more speaking about the techniques and experience you get from making a game with python could carry over to SDL since they are quite similar.
I used it to quickly get a basic game engine build and running. I wanted to learn some game design patterns and I felt pygame was the best for that since it's so high level. I currently use it for Ludum Dare jams but that's all I really could suggest it for. I've changed my starting points around from xna to pygame to lwjgl to slick2d to game maker back to lwjgl and now finally back to xna in monogame form. Personal choice really, I find it has the best balance for performance/distribution ability/fun. You likely won't find anything major in pygame. It just doesn't seem to have that polish. 
Save yourself the future headaches and dont bother. pygame is a vaguely interesting toy, but the technology it uses is archaic (fixed function, no 3d, no ui). It you want a toy to play with, use three.js / pixi.js / phaser.js; all of which are faster and more portable (node-webkit) or unity, which is suitable to building real games. Kivy is nice, but its suited more for apps than games. There are a couple of other 3d engines in python (eg. panda3d), but theyre not widely used or well regarded. Its probably not true to say *no one* does gamejams or makes real games in python, but there arent (comparatively) many who do. Portable packaged realtime visualisations are hard to do well in python: its too slow. Its too troublesome to package and distribute. C bindings and cython, etc. help, but at the cost of actually using pythonic python. Why bother going down that road? Youre not really writing python anymore... 
/r/learnpython/wiki/index /r/learnpython/wiki/books http://sarge.readthedocs.org/en/latest/
yes! You cant write a 2D game without shaders. ...well, you can, but youre missing out on so much if you do, what you learn will be less than useful.
Thanks! By the way, when someone learns a language, is it best to learn the latest version first?
I have felt this pain. Held me back for a while. Their method for windows is to essentially have you download an entire standalone Python distribution that lives separately from your normal Python install. Fix: Go to this page, nab their installer (you need pygame too), install kivy, and you'll be set. Regular import will work fine. http://www.lfd.uci.edu/~gohlke/pythonlibs/
Thanks! 
Thanks. I missed the "out-of-core" part of your comment. That would be very helpful abstraction.
Wow! Thanks! I just gave it a read. That is pretty awesome. 
I wouldn't, just because the rendering quality is quite bad. e.g. Pygame doesn't support anti-aliasing. Yes, I'm serious. The early 90s called, and they want their crappy graphics back. I recently mocked up a simple 2D physics simulation visualizer, and for my purposes, the quality was fine, but I'd never use Pygame to create, well, a game because it would look horribly amateurish.
I think you can use Anaconda to compile what you need because it comes with MinGw. But as far as I know, few people compile Python scientific packages on Windows. If your package is not available in Anacoda or WinPython, it probably is on Chris Gohlke repository, which is very complete: http://www.lfd.uci.edu/~gohlke/pythonlibs/
Try to make a map.
I compiled a list of professional games, including ones sold on Steam: [What Professional Games Use Pygame?](http://inventwithpython.com/blog/2013/02/19/what-professional-games-use-pygame/) However, while it does seem that it is entirely feasible to make a game on Steam using Pygame, there are major considerations for choosing something else. The developer of Unity of Command (a WW2 turn-based strategy game sold on Steam) left this comment: &gt; I think python has huge potential for games, but there are few ready made tools, and that means a much smaller number of people actually attempting to use it. &gt; re: pygame, I haven't been following it closely since we switched to using raw pySDL2 for our new project. If latest pygame wraps SDL2.x (as opposed to 1.x in the earlier versions), that's good, otherwise I would strongly recommend against using it for anything. &gt; At the time I evaluated pygame (circa 2007), I found it wanting when it comes to blits, masking, curves, lines, gradients etc. - all the other stuff you need besides simply setting up input and a rendering surface. So we used cairo for 2D software rendering, which was highly robust with acceptable performance. &gt; For the new game, we use pySDL2 to set up an OpenGL context. With that, we use OpenGL calls directly. Not sure if this is too hardcore for your intended audience, but IMO it is the only way to go for professional game development in python. &gt; SDL2 does offer a set of primitives (sprites, draw functions etc) that you can use to develop 2D games without touching either OpenGL or DirectX (in fact I think these primitives work with both GL/DX). That API may be a good choice, either via pySDL2 or via pygame (if it supports SDL2), but to be honest I haven't looked it into it and I just don't know. &gt; One final note: a thing we're running into with python is the GIL (global interpreter lock). It can pose problems if you have a multithreaded setup (we do), as other threads can block your rendering loop at seemingly random times. Our current solution is to rewrite the rendering loop in cython, where you can release the GIL - provided you know what you're doing, obviously ;-) Also, Pygame is poorly maintained. There are Pygame downloads for Python 3.3 and 3.4 available, but the download page on pygame.org hasn't even been updated with them. Unity does seem like a more fruitful approach.
Depends on whether the libraries you want to use work for python 3 out not. Generally they will
Hmm, looking at your submission again.....my suggestion wouldn't work because you are looking in the filename instead of the directory name. So that said, some other suggestions that might help: * Use `filter` or `itertools.ifilter` in Python 2 to filter the list of files so you only try to match against files you care about (such as by removing hidden files from the list) * Checking for membership (`x in y`) is faster with a set object (usually, test to be sure) * `glob.iglob` or `filter/ifilter` for prefiltering `dirs`. Again this does not necessarily help you with the original problem but you are trying to ask the file system for everything so if you get more specific it will become faster. * Build your own around `os.listdir`, `glob.iglob` and the `threading` module for parallel file system traversal. This can get complicated though and would not be as fast as narrowing down the list of directories you wish to visit ahead of time.
This thread has been very informative. I've been learning python for about 6 months and started playing around with game development with pygame about a month ago. I tried starting out with kivy, but got confused very quickly and then tried pygame and really enjoyed the amount of information I could find on the internet that helped me learn how to use it quickly. I can definitely see how pygame doesn't match up to some of the other options, but it was much easier for learning how to make simple games. I'm planning on moving on to a better framework like kivy or pySDL2 once I get to the point where I feel like pygame can't do what I want.
BioPython requires externally called binaries (blast, needle, water, etc.) to be installed in order to call them. You didn't state what type of machine you are running on, but assuming you have a compiler and are on a unixlike system, you can compile EMBOSS from the source package by following their instructions. Once it has been installed, you should be able to find it on your PATH by doing a `which needle` `which needle` Returns `/usr/local/bin/needle` On my system. The EMBOSS documentation will guide you through installation: You can find the administrator's guide [here](http://emboss.sourceforge.net/docs/adminguide/admin.html) Edit: If you are on a Mac, I recommend macports or whatever your favorite package management system and then you can simply `sudo port install emboss` 
Frets on fire was done with pygame?? I'm shocked. That's cool though. How would you say pygame is the most deficient compared to a SDL wrapper? At what point in game design would you say "this can't or shouldn't be done in Pygame"?
Start with 2D. Here is an unusual suggestion - Take a look at Rapydscript. https://github.com/atsepkov/RapydScript It is an "almost Python" language that compiles to Javascript. Now you can write a web game using libraries like phaser.js and pixi.js (which are light years ahead of Pygame). You'll probably have to learn some javascript along the way, but that's a good thing to learn. Rapydscript is "good enough" to make you think you're using Python most of the time. Another suggestion is the LOVE framework. It's probably the best 2D framework for "indie games". It's Lua, not python, but they are extremely similar languages and you could learn it in a day if you already know python.
http://stackoverflow.com/questions/3207219/how-to-list-all-files-of-a-directory-in-python
How inefficient would this be in relation to just running the same factorial function in C? Is the only overhead of this code going to be whatever python's internals do to call the function? (Which then executes as fast as it would in C?) It looks like it just saves the compiled executable of whatever source you insert and then calls that executable of the function with parameters passed,,, Is this how DLL's work in C/CPP? &lt;Sorry for any incorrectness. I have no idea how python internals work&gt;
Yeah, unity is great, but personally I'm just wondering about something FOSS that will run well on Linux (which unity does of course, just not very open is all). And Python is a huge plus of course, being by far my best language. Personally I'd rather practice C++ more than C# since I usually work with linux and it's easier to distribute a compiled binary written in C++ than it is to distribute something that requires mono, and it would help me a lot more with work than C# would, doing system engineering / security type dev work.
No idea :/ Hail Linux :p Try [nuitka](http://nuitka.net). Its a python compiler that export an exe. (python to c++ compiler) EDIT: just tested Nuitka...its just a compiler. you still need python to run the exe.. but the good thing is, the compiled code is ALOT faster than .py scripts.
Looks like you are talking about John Kitchin's course at CMU! In my experience, compiling packages by hand can be a little tricky, especially if you use windows. As others have suggested, your best bet would probably be to install a python distribution like Canopy (which I think is what you used thru emacs at CMU), or Anaconda, and install any additional packages with pip, the distribution package manager, or by hand. Numerical packages like numpy or skipy are usually compiled against additional libraries for speed, which these distributions provide. The free version of canopy (I'm assuming other distributions too) usually provides all the packages a beginner would usually need, if you are worried about losing access when you leave school.
Pretty well implemented! Suggestion: use tempfiles to store the libs so they don't get littered everywhere whenever you run the script? Can tempfiles be executable..?
PEP8.
Thanks for letting me know what platform you are on. Did the configure run to completion without error? The developer tools from apple will give you a working C compiler, but it is not installed by default on a Mac. I haven't done a source based install in some time, but I believe it will attempt to install to /usr/local/bin which will fail if the `make install` was run as your own id due to permissions on that directory. If you have the output from the run of configure and can place it on pastebin I'd be happy to take a look.
Okay guys, after a little digging about, I think i'll settle for kivy. So here is the long-shot: does kivy support hardware accel and 3D graphics? ? P.S. I've omly looked at tutorials, so there is nothing in there that answers these questions.
That's very much not the only thing that could be changed here.
Thanks for creating that list. Some thoughts: &gt; If latest pygame wraps SDL2.x (as opposed to 1.x in the earlier versions), that's good, otherwise I would strongly recommend against using it for anything. I just checked the bitbucket repository, and SDL2 is nowhere to be found. Switching to SDL2 would be a major rewrite for pygame, since it so heavily relies on SDL1s drawing routines (which are all not present anymore in SDL2)... &gt; So we used cairo for 2D software rendering I think it should be noted here that using cairo for that is also rather adventurous, I'm not aware of any other kind of game that takes an approach that is anything like that (rendering bezier curves on the CPU, as cairo does.) It's certainly not something I'd recommend, let alone to a newcomer. &gt; SDL2 does offer a set of primitives It should be said that SDL2s drawing primitives are still much more primitive than what other APIs such as SFML give you. I'm sure they can be sufficient though, if your needs are simple. &gt; Unity does seem like a more fruitful approach. Yes, unity, ue4 et al are designed by people who have a game-development workflow in mind, and know how to ship to many platforms et cetera. There is a world of difference between writing your own renderer in GL (or even something more higher-level like SFML or SDL) and using an "enabler" framework like unity. Unity, UE4 et al (and even things like gamemaker, which -- and I'm sure even most gamemaker users will freely admit this -- has a terrible language compared to python, and terrible capabilities and documentation) which gives you the tools to instantly get the problems you're going to face out of the way. If you are using unity, and your artist gives you a rigged, animated model made in maya, blender or spine, that means you will have to import the model into your scene. If you are writing raw GL or using pygame, and your artist gives you a rigged, animated model made in maya, blender or spine, that will mean you will have to spend a month implementing a basic animation system (which will suck performance-wise, because writing a good animation system is hard) before you can even display anything on the screen. Time that would've been significantly better spent polishing up your game, making it interesting and playable. And when you are done, unity and unreal-engine allow you to export to a variety of platforms with more-or-less a click -- iOS, android, windows phone, xbox360, xbox one, playstation3, playstation4, playstation vita, linux, OSX, windows, even the browser. If you are using pygame, well, good luck even packaging up a package that runs seamlessly on the desktop platforms. It will be a major endeavor. And the other big platforms are just right out anyway, unless you actually feel like porting pygame (and python!) to those yourself (at which point you may as well just rewrite the game in C# or java, it's not like anybody is going to maintain your port once you're done with it!) So in summary, there is unfortunately no real solution for productive game development in python right now, (that I'm aware of) that I would actually be able to recommend. But there are frameworks that suck less than pygame, at least.
Really? I recently just started and though it was painful I thought cython was included in the package already along with mingw. 
Kivy supports hardware acceleration and shaders. I do not know if it supports 3D.
Do you recommend any resource for learning and developing with it? I'm following this brief online crash course and I downloaded this ebook already, but I'd like to see what people actually use. 
I've read your book!
I forgot to include the calls to `os.remove` to purge the temporary files - one is needed for the C file, one for the object file, and one to delete the shared libraries via `atexit` when the program ends (I don't know if you can delete shared libraries which are open use). EDIT: I corrected this oversight - all temp files are deleted by the script now.
Okay, you didn't ask for it but I'm going to critique your code a bit. Let me start off though by saying great job! That looks like a ton of work and it's great that you're getting into Python. This is a start of a beautiful thing. But let me make some suggestions for things to think about in the future. First off, you need to segment your code into logical pieces more. This ended up being something like 4 huge functions and you need to separate the logic out so that each handles one job, one calculation, one function. If your function starts going over 20 lines really think hard whether you could extract some of that logic and call that as a separate function. You almost always can and you almost always should. Another thing... lots of data here that doesn't have to be code. In `Board.__init__` you have `Property` initialization that really is just a struct of data that your appending on to a list. You could easily pull this out into a CSV file or JSON, or anything that will have records that you can read and create it programatically. It's data, not code or logic to play the game. You would write logic to open a file, read it line by line if it's a CSV, and build that list from rows of Property data from the file. That alone would strip your code down about 200 lines. Something along the lines of properties = [] with open('property_data.csv') as f: for line in f: properties.append(Property(line.split(','))) If you're getting 3 or 4 indentation levels deep in a function, try to rethink it. Extract the logic somehow, or write it out and see if there's a cleaner way to represent it. It's hard as hell to debug code that goes 10 levels deep like yours does. I want to be able to look at a line of code I wrote and understand what conditions just passed for it to have executed. Looking at that code there's spaghetti of if/else/for everywhere and it's really hard to track how many times that line is going to run and under what conditions. It makes it much easier for you in the long run to keep that stuff simpler. Part of this can be writing a function that performs all the checks necessary and returns true or false, then just from reading that code you can see something like def has_monopoly(self): for prop in self.property_owned: # returns True if finds monopoly return False That sort of thing will eliminate about 4 nested blocks in your code in places. Also, you're using classes like structs, just to save data into names. You can probably put a lot of the logic into each of those instead of just using them to hold named data. Generally you'd use a namedtuple from the collections module if you really don't need anything but named attributes but I wouldn't worry about that. The most important thing is to refactor the code so that logic exists where it should, and then those classes will start to look like logical pieces of the game. As someone has mentioned there's something called PEP8 which is pretty standard. You've got other things to focus on, but it's a neat read for anyone starting to get into Python. It's a style that almost all Python coders have adopted and you'll see it everywhere. Since we like to reuse a lot of each others' code, it's pretty important to have a unified style, and PEP8 is that. Don't worry about it, but I'd look into it when you get time just to get an idea. The first thing most people will notice is that you don't use 4 white space indentation and that's what stands out the most, but just keep PEP8 in mind to look into later. It will help your code look cleaner from a more superficial perspective, but it's really just so that everyone can work on each others' code without any hassle due to someone's unique style. PEP8 is a great style for python. Something that might help you a ton is to read anything on Object Oriented Programming, or OOP, and just learning coding principles in general, like DRY (don't repeat yourself). One suggestion might be to step away from the computer and pull out paper, and draw out your design. Make a box in it and write Player and another and write Board. Start listing out data that they hold, and they alone. Start writing out things that they might do, like `Player.move`, `Player.roll`, `Player.purchase`. Figure out their interrelationships and how they might best interact with each other so that each knows the *least* about each other as possible. Try to make it so you could pull out the `Player` class and use it in something other than monopoly maybe. What is Monopoly? It's just a bunch of properties in a series, with a few states like whether they're owned, who owns them, and how much they were built upon. Make functions just to return the amount of rent someone owes when they land on the property, in respect to the number of houses. The amount of rent exists without a player. The player will pay the rent though. It might look like `player.pay(prop.rent())` later, which will have different effects depending on the state of player and prop. It might be a bit difficult to find the sort of reading material that will teach you things this code could benefit from. It looks like you could benefit a lot from going through a full object-oriented programming book, Python or not. Keywords like Encapsulation and Abstraction will be the sort of thing you'd want to read about. [Here's something](http://www.introprogramming.info/english-intro-csharp-book/read-online/chapter-20-object-oriented-programming-principles/) on C# that I just found, but the principles are going to be the same. With Python, you can ignore a lot of the stuff about mutators, accessors and public/private concepts because in Python, there is no such thing as a true public or private variable or class. There's a concept "We're all adults here" where basically there is nothing stopping you from messing with the internals of code you imported. Nothing's private, and you can access and change anything directly. Java, C# and C++ and other OOP languages will try to force you to spell out the rules for what can access what, but Python doesn't. It's neat, but it has drawbacks, just as any dynamic language does. Anyway, my point is that you can skip along those parts unless you're interested, but just know they don't have very much effect on Python code. For other resources, find anything you can on Python object-oriented programming, not a how to but a best practices sort of tutorial. If you have trouble finding it in Python, any Java, C# or C++ resource will do as well. It all translates if you're reading about it at a high level. I hope you don't take any offense to my suggestions. It's great that you're writing out full games like this. If you stick to it and start learning the higher level stuff, you'll see how much easier it can be to write code that you can mess with, debug and change. In the end, it's all about making it easier for you as a developer, it's not about pleasing other people by conforming to standard practices. It's also about making it easier for other developers to use your stuff as well!
I've used scipy for doing some statistical work, but I didn't look through the docs really deeply. Nice to know there's a well tested implementation out there. I'll have to see how well C code can call out to numpy in this setup.
You don't actually need to find the triplet a, b, c itself. You just need to find the product abc. The trick is to use Euclid's Formula to generate triplets. Given two positive integers m and n, generate a, b and c using: a = m**2 - n**2 b = 2*m*n c = m**2 + n**2 Only you don't even need the a, b and c. You need to check whether a+b+c equals 1000. A bit of algebra gives: a + b + c == 2*m*(m+n) a*b*c == 2*m*(m**4 - n**5) Then, the secret is to use Cantor's Pairing Function to generate pairs of (m, n). Here's a minimal version that just calculates the product alone: def cantor(start=0): i = start while True: for j in range(start, i+1): yield (i-j+start, j) i += 1 for m, n in cantor(1): if m*(m+n) == 500: print(2*m*(m**4*n - n**5)) break Here's a slightly longer version that produces the triplet itself, if you want to double-check the result. It uses the same `cantor` function above. for m,n in cantor(1): a = m*m - n*n b = 2*m*n c = m*m + n*n assert (a**2 + b**2 == c**2) if a+b+c == 1000: print(a, b, c, a*b*c) break 
I would suggest to use a Docker container like this: https://registry.hub.docker.com/u/cineca/scientificpy/
Be sure to vote on what you'd like to see covered in part 2 &gt;&gt; https://realpython.com/blog/python/handling-email-confirmation-in-flask/#conclusion
is there anything wrong with just using boost python to achieve this ? 
Short answer, [PyCharm](https://www.jetbrains.com/pycharm/)! :)
This
Keep in mind, people advise you just use text editors for the same reason you say you want an IDE -- to just focus on the code. While pycharm is a particularly good ide, beginners usually don't like having to figure out how to set up projects and tweak settings in them when they're just trying to write their first 100 lines of Python to a single file. 
I've never found much success with IDEs, preferring vim to everything else.
For a beginner, PyCharm can be too much. Even though that's what I use now (for python/django). For small scripts or quick edits, I still prefer Notepad++.
It appears to have run without error. I ended up moving the EMBOSS 6.6 folder to my sites-packages folder under python 2.7 just so I can keep it all together. So I just changed directories to the Emboss folder and ran "make clean". I will attempt to reinstall in a bit. The thing I'm still confused about: even though it appears that all contents of the Emboss 6.6 folder are either C or Java, I can use them in my python program? All of the code in Bio.Emboss.Applications appears to be python..
I believe you must login and conduct the actual buying via eBay, but you may be able to automate that with some smart requests code. eBay's system definitely isn't intended to run automated buying, but as long as you can figure out authenticating to eBay and PayPal after finding the item it's probably possible. Of course, I'd recommend being very sure of your code before trusting it with unlimited access to your paypal account. Here's the eBay python API, which makes it quite easy to find items: https://github.com/timotheus/ebaysdk-python/blob/master/README.rst I've never tried to automate the buying side, but eBay's API can return some quite granular results from my testing with it.
PyCharm. Everything is in it for. Testing etc...
When I started out with Python (so about two and a half years ago) I learned using the default IDLE that is packaged with Python. I have since moved on to using PyCharm, which I love. But for a beginner IDLE was all I needed to focus on learning how to make things work. Using PyCharm has since greatly improved my skills and has made my coding more pythonic.
from http://www.boost.org/doc/libs/1_57_0/libs/python/doc/index.html : "Boost.Python, a C++ library which enables seamless interoperability between C++ and the Python programming language" 
I haven't heard anything about a toxic and bullying culture, but I have tried other version control options and have been happiest with Github.
Great article. It's always nice to see people advocating good security practises in tutorials - the use of itsdangerous is an excellent choice.
PyCharm master race checking in.
I am with most people on this. As a beginner I actually tried PyCharm and Hated it. IDLE and Notepad ++ was plenty enough to learn the language with. Then I used Aptana for a short while as it was a little "easier" IDE. When it blew up on me, I gave PyCharm another shot and LOVE IT. PyCharm for a beginner, maybe too much to learn all at once. PyCharm for someone who knows a bit, It gets more awesome everyday! 
This is extremely friendly and helpful criticism. I wish everyone acted like you on the Internet. /u/d4rch0n deserves a beer for his effort. /u/changetip private 
This kind of post hits my front page, really?
I just installed 86 on my 64 machine and installing spyder worked
This looked cool, but upon further exploration I believe it has been deprecated and has no Python 3 support. I guess they recommend Cython now: https://pypi.python.org/pypi/weave
I don't understand why Sublime Text isn't allowing you to focus on your programming skills. It's a pretty good editor on it's own and I would argue that as a beginner PyCharm is way too much. Probably the worst thing about ST2/3 is that it has no concept of stdin so you can't do raw_input/input (it just crashes the running script). Even just IDLE is enough in my opinion because you really can just focus on your programming instead of tweaking a bunch of settings.
Thanks!
In what sense are you going to make it decentralized? I noticed you still mentioned connecting to a pylobby server. 
This. I downloaded PyCharm the other day and spent most of my time tweaking stuff. For a beginner I'd recommend Sublime, you can just get on with learning rather then waste time on the irrelevant stuff. 
Yeah, I wouldn't dwell too much on the example - I guess it doesn't show too obviously any good reason why classes are useful over functions. Something I left out was enforcing schema in data structures (so that when you save to a database, you can guarantee that the saved data has certain values with certain types). This kind of thing can really only be done in object-oriented programming (as far as I know) by implementing some kind of model which describes your data. Personally, I use the `mongokit` module for this.
Not sure I completely agree. Having reusable functions defined in a file is just as modular in Python. Unless there's some framework you're using that uses arbitrary datahandlers subclassed from their base datahandler, I don't see a real benefit. Is there something in ipython that makes your approach easier? If you defined reusable functions that parsed the sort of file format you use, took an arbitrary function as a first class object and applied it to records, you could reuse that just as easily as a class. OOP is useful but it's not the end solution in Python to some problems, and I can certainly see a lot of purely scientific problems benefitting from a more data-oriented functional style that is just as modular.
I used to use PyScripter and I absolutely loved it, but I'm not sure if it is compatible with the latest version of Python.
&gt;Something I left out was enforcing schema in data structures (so that when you save to a database, you can guarantee that the saved data has certain values with certain types) Great point. Data munging certainly takes up enough of my time. I'll have to look into `mongokit`. Thanks for the heads up. As someone who isn't a programmer by training, it's nice to learn from talented people doing similar things.
&gt; Something I left out was enforcing schema in data structures (so that when you save to a database, you can guarantee that the saved data has certain values with certain types). This kind of thing can really only be done in object-oriented programming (as far as I know) by implementing some kind of model which describes your data. Personally, I use the mongokit module for this. If you have limitations on what state is valid to store in the database then you should implement those constraints in the database. Use as much primary key, foreign key, not null, unique constraints etc as you can cram into the database. It helps you in the long run. Some people have this idea that the application and only the application should enforce the constraints. Unfortunately that only works if nobody ever makes a mistake. That's not a reasonable assumption and sooner or later you will end up with corrupt data in your database if it doesn't actively prevent it. You won't notice that until you look for it and if you believe you won't make any errors you won't look, and your analysis on that data will be flawed. Edit: I just saw you mention mongokit. The above was written with RDBMSs in mind. There's a reason I like RDBMSs and schemas are a big part of that. Implementing a schema with mongokit on top of a db whose big selling point is to be schemaless seems a little backwards. YMMV. 
Fair enough. Not saying this is a better way, but I just want to point out that it's still easy to demo data in an ipython notebook whether it's saved in a class or a variable returned from an imported function: http://i.imgur.com/n1MSYTn.jpg You can still inspect your results each step of the way and demo them, whether you use a class based approach or functional approach. Honestly, that's why I love data driven functional style for some problems, because it's really easy to see what's going on each step of the way, and you can extract one function at a time and test it without relying on some state that the instance must be in. Your way is a clean way to do what you're doing regardless. However, if you run into something where you discover it's hard to test because you need to set your instance to a certain state to test it, you might consider a functional approach. One thing to try might be to dump intermediate results as JSON blobs (or even YAML would work for your class instances), and then you could write functions to load them and display examples and make testing your code much easier. I've been playing with YAML a bit lately and it's just as easy to use with Python as JSON, and you can even dump an arbitrary class instance and load it back up in the same code without worrying at all about serialization. It's pretty damn cool. If you do find yourself needing to record state of your instances, that's another option. It's a bit less portable in regards to being able to distribute to colleagues and them knowing already what to do with it, but if it's just used internally in your code and they don't need to work with your yaml files directly that's not a problem.
Sit them down infront of an interpreter, and ask them what they want to make. That's how I started out.
I'd second Hello World. It's not perfect, but it's decent enough, and it got me excited about programming, which is basically all you need from an introduction.
I love PyCharm (and all the JetBrains products really) but just wanted to put a mention in for LightTable if you are looking for a very lite weight IDE that can evaluate your code in real time. I am finding it very useful for doing tutorials or running the code I come across in blog posts. LightTable is free be can also be used to "live code" Clojure and JavaScript. Good luck!
&gt; does kivy support hardware accel Kivy's graphics are ultimately a pythonic api to opengl, so yes, all the graphics are hardware accelerated. &gt; and 3D graphics The graphics api supports it (in that it's all opengl in the end and you can enable the depth buffer and use 3d vertices if you want), but we don't directly support it in kivy's normal apis and I'm not aware of any significant projects using it right now. Some simple 3d projects with (currently) limited scope include 'ddd' in the kivy-garden repo which can display most .obj files, and nskrypnik's various examples. If you want to do serious 3d work, or even simple 3d work without knowing some things about opengl, I can't recommend kivy right now. Good luck with kivy! Feel free to check out our irc channel or mailing list if you have any problems.
You don't have to do anything initially though, you can just install it and go
Great blog post, as I commented on your blog I'd say that you nailed me in how I used to code in R, and how I need to think differently as I migrate my coding style to Python when I work now.
&gt; PyQtGraph Is it better than matplotlib? I thought matplotlib was the go-to for scipy.
Yep, PyQtGraph is much better than matplotlib. Have a look at the web page for it, and play through the examples; you'll be impressed. It's also very easy to get started with, you just download it and run, no installs needed. OP mentioned Seaborn which looks very cool as well.
import this
I find that OOP is useful when you want to enforce database schema (for storing results), since then you can extend some prebuilt classes. Edit: Also, more generally, this [StackOverflow answer](http://stackoverflow.com/questions/2078978/functional-programming-vs-object-oriented-programming) seemed helpful.
The BioPython portion is a wrapper that calls the requisite application externally. So the EMBOSS stuff will be C/C++ or Java but it is called by the BioPython wrapper which is in python. This is why you recieved the error status you did when the program ran and needle was not found. It calls the external executable and gets back an errno from the call (in that case it was 127) I believe the BioPython tutorial covers this a bit more in depth. You can check it out [here](http://biopython.org/DIST/docs/tutorial/Tutorial.html#htoc83) Hope that helps!
This is easily the best way to get into programming. Don't start with "here's how to program 'Hello World'", start with "You want to make a game? Well the first step is printing text, here's how..."
I've seen a byproduct of the religious OO versus functional debate. I work in an environment where we only use Matlab, which encourages a bit more of a functional approach. What I've seen is the application of what I'd call a function-based approach, in the name of functional. Meaning, the use of functions only, with disregard for what makes sense to produce modular, reusable code. You can end up with many layers of dependent functions that mutate the internals of whatever data containers are used, which is exactly what functional tries to avoid. I see classes as just an organizational tool, and a method of implementing custom behaviors. The danger of the function-based approach can be lack of a consistent architecture, leading to tight coupling to very specific containers of data. These containers can many times be non-typed, generic structures that hide what the function actually requires, which can end up being difficult to reason on. For example, if I want something that can sort things, regardless of data types, you would need to think through generalizing that interface. This could be functional or OO in the solution, but I think it is rare in the scientific community to step back and think that through. The functional trend has seemed to provide additional cover to this disregard.
:( I use Windows ^don't^stone^me^to^death...
Thank's, I'm going to download that LightTable
This is a spectacular SO thread. In science/data analytics, do you find that you have more instances of adding new things, or adding new verbs to operate on things? So basically, why OOP rather than functional, since Python can (almost) do both.
Great, I had never heard of it. It does look nice.
I'm still in the early stages of building the codebase, so besides a few quirks (e.g. the MongoDB module I'm using requires defining classes for models), I suppose I could have gone either way. In the not-so-far future though, I imagine that I'll add much more things than verbs that operate on things. The field I'm working in is materials informatics, so we're building classes that do natural language processing and data mining algorithms on data for a certain subclass of materials. As we later extend this to other subclasses of materials we can likely reuse lots of the class methods with probably some slight extensions.
Don't worry: Koding works on Windows as well. Just get the chrome app or use the website. That said, Koding uses Ubuntu via a terminal, so be prepared to learn a bit of Linux, which you would have to anyway. 
Awesome, thanks! I didn't realize the matplotlibrc file was for older versions. I had done that bit and it wasn't having any effect. Thanks again for this!
Try using a sax parser. There are probably several options, but here's the first one Google showed me: https://wiki.python.org/moin/Sax
&gt; But before you know it, you'll be writing GUIs for them Playing around with GUIs is an exercise in patience...
Ooh, interesting. I'll give it a try. Thanks!
Classes are good for implementing and enforcing a system for organizing or developing consistent types of interaction. You could continue to have libraries of discrete functions, but you might define a class for what kinds of things the functions work on. The class can also provide utilities for converting into and out of the type. Another way I may use classes is to remove the need for repetitive inputs into functions. That way you can initialize once with the repetitive things, then provide a more simple interface for the different methods of interaction.
Not that I'm a great one by any means, but I would suggest doing lots of projects. And try to keep them all different. Just because you know to do it this way, don't do it the same way, find a better method. Or if you don't know how to implement something, don't give up on it. Figure it out. I've found that by trying to do a lot of projects regardless of what they were, I learned a lot about programming in general. So even though I don't prefer web development, by implement a web interface for a program of mine, I learned enough to kind of understand it. Basically just push yourself. And reading programming books never hurts (although I don't prefer that way). You could always drop by /r/progether too where we work on projects together. You might learn something you didn't before, you never know. p.s. learning other languages always helps too. 
I haven't spent too much time digging into the other plotting packages but the quick impression I got is that basically any halfway popular one is going to be a lot better than matplotlib about not making you specify a bunch of individual parameters for the plot unless you specifically want to tweak something manually. 
You might try this: https://inventwithpython.com/ The author shows up around here every now and then. Also, maybe Python is not the best choice for a starter language. Maybe something more visual like Logo would be more enticing.
If you aren't required to use python, try Saxon CLI with a small xslt transform.
Learn to think in code; expose yourself to algorithms (writing your own) avoid getting caught up in the mundane, DRY, test first, experience other peoples code and frameworks, ask questions of it, answer them yourself and find the flaws. 
Coincidentally, I just got finished with my first Flask project - making a web UI to provide remote control of a daemon. The SQLAlchemy + Flask combination is so concise that multiple times I just marveled at what I typed and click through to the module source code (I'm using IntelliJ IDEA) to see how it works. This kind of curiosity is basically what drove me to learn more and more about Python. Wondering how the *hell* Django models worked introduced me to metaclasses, doing raw TCP stuff introduced me to glory of `struct` and `socket`, and almost implementing `requests` with `urllib2` and `selenium` with `requests` made me pretty familiar with all three things. Keep starting/dropping/maintaining projects, getting curious, and looking at things. Eventually, you'll be able to read and write most of what you see on the internet - you'll be dealing with design problems instead!
Would lxml's cElementTree be useful here?
This is kind of the question that everyone asks in just about every field and there's no magic bullet. It's simply just hard work and dedication towards your own personal projects and goals. Dream up an idea and jump in head first. You'll learn so much just by Googling and implementing different things.
I would say that you don't really need a mentor, more so that you should follow by example and be open to criticism. Probably the best way to do this is to surround yourself with those who are better than you at the subject. Read their blog posts, follow them on twitter, subscribe to their youtube channels. https://twitter.com/raymondh is probably the best guy to watch for Python. I would also say that going over the documentation or even just reading stack overflow solutions or, as you've been doing, the source code of other projects is a very good way to move forward. A software engineering class or book might help you if you're really into that but that in my experience that just covers high level topics. I don't have any links for you but honestly there are so many already curated resources that I'd really just be doing the Googling for you. Over at #pocoo on Freenode over IRC there's all sorts of people who are there who you can ask questions to and I would suggest joining and seeing what problems others encounter and their solutions. Perhaps go to a hackathon or meetup? They sometimes have free mentorship programs. I am still firmly of the belief that to progress in programming or even just the CS field in general you must have projects. These projects should be something you create and something you have a vested interest in seeing made happen. Set the goal in mind and ask people for how they would implement something or Google until you find out how to implement something. Once you find that understand it, don't just copy paste. It definitely takes a lot of time and energy and I have seen a lot of people go through programming but the ones that do the best are the people who pour all of their time into it. And remember that people are usually very helpful. Don't be afraid to ask the masters why something is the case. Don't file a Github issue or something like that but definitely ask them on IRC to explain stuff if you don't get it and exhaustively read documentation. EDIT: Just adding a bit more.
Yeah with class inheritance I suppose you can get around method redefinition of methods in some instances.
Cool! Thanks man. I'll check it out. And *even* if in the end I'm unable to produce good games with it, I'll still be able to use it as a UI tool kit( and say hasta la vista to the pygtk and its packing system( always made me cringe))
This is something people have been wanting for the longest time! :0 Can't wait for you to launch. Good luck!
I'm not sure python is ready to entirely replace a scientist.
This man speaks the truth, finding a mentor will help you avoid the long way for most things, but that's where you learn the most, so there's a trade-off. Also learn how debug, and figure out ways to be closer to your code. IPDB helps immeasurably with that. I do application security for a living and I can't tell you how many people simply don't understand what the fuck their code is doing. Learn to debug, and learn to step through your code. The closer you are the easier it is to spot bugs, think of corner cases, and optimize. Also don't be afraid to try crazy things that don't work or are too ambitious. The reason I create things that are "successful" and "good" is because I've created many things that are bad. Be a mad scientist. Posting /everything/ on github is also a really good way to get noticed by employers and the community at large. Don't be bashful, there's a shit-ton of awful code out there. Start with every bit of code you write, and eventually you'll solve a problem someone has. That signals 1.) you're not afraid of failing, and 2.) you've grown and are interested in keeping on that trajectory. People will come out of the woodwork to help you. Also, keep in mind that knowing what flask is doing while using it isn't the most useful thing ever. If I'm designing cup holders I don't need to understand how the engine of a car works. There are layers of abstraction for a reason. Spend enough time around it, and eventually you'll figure it out. Always strive to make your code 'beautiful' and pretend that the person who will read it is murderous and heavily armed too, because even though it takes a bit more time when you go back to it N months later you'll be glad you did. ALWAYS ask if the code your writing is the best way something can be done, and google accordingly. 
After 20 years of programming, all I can say is never stop learning. The fact that you want to be a better programmer means you haven't stopped.Programming languages will continually change, evolve and be replaced. An aptitude towards thinking like a programmer however does not. Working out how to pragmatically break down problems into a series of steps you can write in code is where the real skill comes into it. Doing this in a quick and efficient manner is what makes the difference between an ok programmer and an excellent one. No problems honing in on a specific language / framework either, just keep expanding the uses of it and how you implement it. I've spent the last 6 years tinkering with Python and it's by far my favourite language. This is after working with C / C++ / assembly / Pascal / Perl / PHP / ASP / VB / Java and C#. The concept is all the same, only the syntax changes. Good luck!
As everyone suggests, never stop learning and practicing. The more you practice and introduce yourself to new projects, the more you learn. You stand to gain a lot by just practicing alone. Hopefully, eventually, you will improve... And you should also try out other languages. 
I'm roughly an intermediate programmer, but from my limited experience it seems that you are asking two different questions. How do I become a better programmer, and how do I learn to read other people's programs. What people here are saying is right, keep programming. When I get through a medium size project and look back at it after a couple weeks, I don't recognize a lot of it myself, even though I wrote it. I need to go back through my logic and figure out why I did things a certain way and whether that was a smart thing to do. Your own code will start to look this way to you too.Looking at something someone else did is even harder to reverse engineer. Try to go through and add your own comments and trace back the functions and classes in the order they are called. It's a lot of jumping around in the code but it's the only way to put together the actual flow. Make charts.
I always read it as a shorthand for "awkward".
Next up: Stand-up-programming. What's the deal with object oriented languages? self.Seinfeld.quit()
When you say post *everything* on github, does that include the goofy little scripts we do for challenges and things at [dailyprogrammer](http://www.reddit.com/r/dailyprogrammer/wiki/challenges)? See, it's rumored that to a prospective employer, your github account can be more valuable than a resume, so I'm afraid that by posting *everything* that I'll destroy my chances entirely. I realize that by the time I'm skilled enough to get a job that my github will no longer be filled with little scripts I threw together, but I just want to hear someone else's opinion before I ruin my future career.
I just found /r/progether today! Looking forward to learning more there.
Yes. 100% yes. I do a /lot/ of interviews for our team (keep in mind, it's for information security, but the concepts are the same). The more information I have to work with the better, and I'm looking for a demonstration of the core principles that we hold high on our team. The caveat there is don't create something blatantly used for things like violating copyright laws (e.g. Sickbeard, Headphones, Couchpotato, etc) and have that tied to the account you submit. If you want to participate, do so under a separate account. When I have people who tell me that "they hacked this huge bank that one time" or I see that they are a core developer for stuff like that it makes me worry about professionalism, which is just as important as engineering prowess (again, a bit different because of information security - there's a trust level there). Don't worry about comments like "ARGH fuck this thing." or "Too drunk to fix this shit right now", mostly because I do that, and work with folks who do so as well. My point is don't sterilize everything that you do, it's good to show that you're human, but use common sense. People regularly troll github for candidates, and I've received job offers simply because of my projects, even with all the sloppy bullshit I put in there. When I'm wearing my hiring hat and I see a candidate posting dumb snippits for things like dailyprogrammer that shows me that you actually participate in those sorts of things, and therefore I can extrapolate that you enjoy programming, learning, and being creative (at least to some degree). I absolutely LOVE it when people give me a github full of random nonsense. It gives me a good idea of your skills, and an entire timeline of your programming history, as well as places where you may need training, places that you excel at (and therefore are valuable to our team), and things you're interested in. Programming is a hard thing, if people are going to dock you points for demonstrating that you want to learn and improve yourself, but you're not some kind of savant out the door - fuck them. That's not how programming works (nor learning really), and you probably don't want to work on that team. 
No. It would still need to pulll everything into memory. The only performant way to parse large, tree like structures is to parse them while reading them. Thus SAX.
Can't wait for you to launch. Good luck!
Disregarding the "toxic and bullying culture", if he means that github != git, I have to say that needs to be understood by far more people. It became a synonym for some. Personally I much prefer bitbucket. It does slightly piss me off to know that what I don't have on github and instead have on bitbucket might affect future employers' opinions of me because they think I'm not an active coder.
Have my e-mail address! Twitch for programming. Learn by reading others code and seeing their workflow will be the best thing ever! :-)
I would definitely watch this.
If you like flask then dive into their code as your first project. Reading other peoples code is always good for learning as you are effectively taking a look into their brain when they wrote it. Get their latest version running with your application logic and then insert some print statements into the Flask code to see what's going on. Don't try to understand everything, pick a bit that particularly interests you and tinker around with it. You could reimplement certain functionality and see if their unit tests are still passing -&gt; If yes, you probably understood very well whats going on.
Get familiar with the [Standard Library](https://docs.python.org/2/library/index.html)
Which coding language are you most intested in? PHP. Lol sure, it's still 1995.
There needs to be a much wider selection of programming languages. SQL isn't interesting enough for people to watch a guy writing SQL for hours. And why aren't there way more popular languages than some PHP framework? Also, there's Android but no Java? It's a decent idea, but a lot more needs to be done for this to succeed.
I started streaming each Saturday on my youtube channel,videos: [Building a Search Engine in Python](http://www.youtube.com/playlist?list=PL18yrUuMk-zlzpea3En7GRZLvFn7WNK0H). BTW, I stream every Saturday at 20:00 UTC, so you can tune in today: http://www.youtube.com/watch?v=keKg1ZIz5II I think livecoding is very interesting. So, I'd like to give you some honest feedback/criticism based on my few weeks of experience live coding. 1. I am not really interested in technological platform that merely allows you to stream stuff. YouTube Live does this, and it works just fine(and afterwards convert your streams into proper videos for offline non-live viewing). If I were you, I wouldn't even bother with creating proper video broadcasting infrasctructure, and I would simple allow streamers to share links to their youtube channels/streams/videos. 2. I am not really interested in earning some income, I do my streaming for fun. And I started doing this out of curiosity. I'm not saying that earning money is a bad thing, I just don't feel like I could earn a lot(a few hundreds dollars per month), so if I were you, I wouldn't focus on money initially. What I'm much more interested though is: 1. Engaging with audience in-between streams. Chat would be nice. I already do it using skype, but I feel like more people would chat with me, if there would be some sort of multi-person chat(like IRC). 2. Notifying people about upcoming streams. And maybe showing my streams to random people(e.g. someone goes to the website, sees my stream is in 1 hour, so they go and wait for the stream to begin). I typically post in /r/learnprogramming and announce on twitter.
THAT'S interesting
The text on the subscription's email field should be a placeholder, as it is now you have to delete the current text ('Email Address') in order to put your own info. Also they should change the default favicon from the html5 template they used for the site. I would love more experimental/niche frameworks in the future. I love this idea, registered.
Build something other than websites.
Pycrypto can do it.
I would use something like this, then iterate trough files: http://search.cpan.org/~mirod/XML-Twig-3.48/tools/xml_split/xml_split best of luck
Do you have a channel? Your link doesn't work for me.
[Fixed Link](http://www.youtube.com/playlist?list=PL18yrUuMk-zlzpea3En7GRZLvFn7WNK0H)
Oh, sorry. Fixed now. The link to the channel: http://www.youtube.com/channel/UCJAVLOqT6Mgn_YD5lAxxkUA
Thanks! I updated the comment
I recommend the [cryptography](https://cryptography.io/en/latest/) library. `pip install cryptography`. It provides AES and a wide variety of commonly used mode of operations and supports both Python 2 and 3.
I really like spyder, it's as simple to use as it gets and comes bundled with anaconda, so there's that.
I see you use reverse search feature of the shell, not bad, I probably should get used to it too, but why not ipython? Even if you don't use its history feature, there is syntax highlighting and autocomplete (to correctly spell Bea&lt;tab&gt;Soup =). Your shell prompt is too plain as well, I guess I'm just spoiled and can't stand lack of colors, haha. You can give custom error text to asserts: assert condition, text Which is helpful to find why assertion fails. As for error codes: r.status_code # 429 r.reason # 'Too Many Requests' Anyway, the process of writing a html parser is similar to mine (at least for small projects), but I try to use a cache as early as possible to avoid making requests to a server, it's better for both me and the server, and I prefer to restart ipython shell instead of module reloading.
[This](http://it-ebooks.info/book/2467/) will get you going. I like it precisely for the fact it covers material in such detail that I can look at something like source code and have a sense of what it's doing. There's lots of examples and practice problems, and the coverage of OOP and the Python language is thorough enough to get you used to picking apart each line of code in a code base you didn't write. More often than not you'll be reading code you didn't write either to maintain it, extend it, or replace it. A good foundation in engineering and design principles as well as knowing the guts of the language in and out will definitely make you a better programmer. A mentor is good as well, as it's always good to have someone more experienced read your code and muse with you about design and implementation. Experience has already taught them things that they can convey to you directly and speed up your learning curve. For example, having someone go "You could write this as a list comprehension instead of a loop" or "This could be a lambda expression and improve readability, as well as performance" are good things to hear; getting you out of your own head and practice of doing things, ultimately making you better.
the only thing that'll make it faster is the unix command `locate` and that's because it's cheating since it's a daemon that keeps an actual index of the files as they get changed.
I like the completely arbitrary list of languages.
&gt; I see you use reverse search feature of the shell, not bad, I probably should get used to it too, but why not ipython? Hm. ipython sounds nice. I heard about this project, but I was under impression it was more suited for scipy/numpy things. I am going to give it a shot. &gt; r.reason Oh, thanks! This is really convenient, I wasn't aware of this feature. &gt; Your shell prompt is too plain as well, I guess I'm just spoiled and can't stand lack of colors, haha. Haha, yes, it is just default one. I typically don't bother setting it up, but since I'm writing this comment, I updated my .bash_profile so my prompt is nice colored. 
OK, waiting for my early access invitation :)
also /r/learnpython 
TIL that Youtube Live exists. Waiting for this afternoon, will be watching. I agree you need a built in chat pane. Twitch wants to be exclusively gaming, but Justin still exists. And I typed 'live stream' into google and it popped up [**live stream yourself free**](https://www.google.com/webhp?sourceid=chrome-instant&amp;ion=1&amp;espv=2&amp;ie=UTF-8#q=live%20stream%20yourself%20free). 
I am quite sure sikuli can do it and has python bindings but, never found the time to play with it. Good luck! 
&gt; Waiting for this afternoon, will be watching. Awesome! Thank you! &gt; I agree you need a built in chat pane. BTW, youtube live has a built-in chat pane. The problem with chat is that it's only available during the broadcast. I'd like to chat with viewers after stream. E.g. answer questions, help set up coding environment, etc. &gt; Twitch wants to be exclusively gaming, but Justin still exists. Unfortunately, Justin.tv was clased near the time when Twitch was sold to Amazon. 
[xml.etree.ElementTree.iterparse()](https://docs.python.org/2/library/xml.etree.elementtree.html#xml.etree.ElementTree.iterparse) does exactly that - parses the document iteratively while reading it.
&gt; You're probably more advanced than I am but I'd suggest writing a Flask extension...no matter how trivial it seems (but make it relevant) and maintain it. That will force you to write better code and make you more familiar with the kind of code contributed to Flask itself. And you'll be giving back to the community too. This... is actually a great suggestion! I do have an idea for a basic extension, I may just give this a go!
Cheers!
Looks interesting! Also, your links at the bottom don't work except for "contact".
What, no Haskell? Seriously, I would probably watch that. 
&gt; Get their latest version running with your application logic and then insert some print statements into the Flask code to see what's going on. Don't try to understand everything, pick a bit that particularly interests you and tinker around with it. Another cool suggestion, will do this!
That sure looks promising, maybe for other parts of my macro as well! Thanks for your reply, I will certainly be looking into sikuli. Still looking around for a full Python option though, any other suggestions?
Another mature solution is keyczar: http://www.keyczar.org/ It was created by the Google security masters. It's easy to use and employs safe cryptosystems by default. 
&gt; I'd wager that forcing yourself to spend a couple of painful hours understanding someone else's code is one of the best exercises you can do to get better. You've inspired me, starting now.
Good stuff, will check these out
Interested is misspelled in the invite section: &gt; Which coding language are you most **intested** in? Also, there are so many redundant language options. Three for PHP, two for SQL (why is there even SQL?), and django probably doesn't need its own category. iOS and Android aren't languages either...
Also, I understand how the correct code works. I just understand how my code is not just an iteration of the correct version. The concept of how evaluate a number to true or false is the same. 
Let's see what your code runs: def is_prime(x): if int(x) &lt; 2: # false return False elif int(x) == 2: # false return True elif int(x) &gt;= 2: # true ( an else would be better ) for n in range(2,int(x)): if int(x) % n == 0: # false return False else: # therefore this is the branch it goes through return True # it returns true the return True should be at the end of the loop. Also, x = int(x) would be a good thing to do at the beginning of the function
I second this. Even better: read the Standard Library source code.
The code is correct except for the final iteration, albeit not the most optimal form. Let's see what happens in that for-loop: for n in range(2,int(x)): # n starts at 2. if int(x) % n == 0: # Is n divisible by two? return False # Yes return False else: return True # n not divisible by 2 So in essence you coded a function that returns False for numbers smaller than 2 and all even numbers above 2 and True for all others. If you change the for-loop to the following it should work: for n in range(2,int(x)): if int(x) % n == 0: return False return True This looks to see if x is divisible by a number smaller than x, if it is return False and otherwise, if there is no such number found return True. Also next time these questions are best asked in /r/learnpython 
Thanks. I know, I need to work on style. Coming from c++ I feel python styling is so easy it's hard.
&gt;finding a mentor Any advice on how to do this? I literally just started coding in Python for the first time three days ago. I've written a basic rock-paper-scissors game and I'm trying to figure out how to make it save the score changes (right now they reset after each round). I'm looking for somewhere to post these simple questions so that I can get off the ground, but I know very little about the programming world and its resources. I found out about github from this thread and made my account, the possibilities seem endless. 
Look into elastic beanstalk, pivotal web services, Google compute engine, etc. 
Sorry for the confusion, but this isn't my startup, unfortunately. I found it out of the blue and decided I'd post it around Reddit a little to give them some traction! 
I was hoping Rust would be there so I could see some compiler rage live.
"languages"
While we are on technical issues they appear to be running their django app with debug set to true. Got a csrf invalid error some how and was like "I've never seen one of these in production". Decided not to give my email address until the teaser site is seemingly more production ready.
&gt; Coding languages * PHP * Python * Ruby * Javascript * iOS * Android * MySQL * PostgreSQL * Phonegap * Sencha Touch * Django * Ruby on Rails * CodeIgniter * Laravel Like they couldn't even decide on one type of thing? And what ridiculous selection is this? I'd be way more interested in specialty languages and way more other stuff. Also numeric IDs for values, how 1996.
For your question, if you want to save it between games save it to a txt file using basics like file opening, writing, and closing. You can add a module that updates the score and checks it against the current score after each game. Also /r/LearnPython is a pretty friendly community to ask questions. They helped me with a broad question about GUI programming and some other stuff.
Looks interesting. Can the compiled function bypass the GIL? Also is possible to use numpy typed arrays as input arguments to a function? 
So, yea; PyCrypto can do it. But, you'll need to know a few things: Where is the IV, prepended to the ciphertext or separate? Is there a HMAC appended to the data, or even prepended? What block mode is the cipher using? Sometimes you can get this to work with trial and error, other times things are FUBAR without a map. So, hopefully you have some information on the protocol you're analysing? :) By the way, if you're "rolling your own crypto", my advice is "don't", use `pynacl` instead. It's a wonderfully high-level abstraction for common crypto tasks designed *explicitly* for application developers who are not expert cryptologers. And, PyNaCl's interfaces are well designed and easy to understand. :)
The time here is really going to be spent in actually performing the disk IO to list the directories. That means that unless you're doing something *really* wrong, you're not really going to be able to speed it up much, because the python (or bash) computation is basically irrelevant - you could likely make it 100 times faster (or slower) and not notice the difference. The only way to improve things would be to cut down on the amount of IO you're doing. (Eg. limit the search to certain filesystems / directories etc), or *potentially*, split the IO over multiple threads (though even then, likely only if you can use different drives). Frankly, the simplest way to do this is with the shell oneliner: mv /**/testtesttest /path/to/folder and rewriting it in python isn't going to make any noticable difference to the speed.
I'm not extremely familiar with the cloud, but I would do this - 1. Decide on the capabilities I want. (Uptime, storage, compute requirements). 2. Figure out my budget 3. Look into reviews of the cloud instances you choose from (1) and (2) - then read a few tutorials about each. 4. Pick the easiest one from (3). 5. Cloud it up! I would also look into Amazon's spot instances, they can be a fun way to get cheap compute at market prices. (Until Netflix needs to process something.) Also, if you use AWS, I think you get a year free of some instance type before you have to pay? (Confirmation, anyone?) Good luck though - it should be a great skill to have.
Just to point out, it has to be gaming related programming or they'll delete out your videos/cancel your streams.
I think you really need a debugger so that you can step through your code and inspect all the variables and so you can understand what is happening, in what sequence. I would highly recommend PTVS. This is what I use. Python Tools for Visual Studio pytools.codeplex.com/ You will need a recent version of Visual Studio first, if you are a student then you can get a free copy of the latest Visual Studio 2013 Professional through the Microsoft "DreamSpark" programme - otherwise you can get the latest "Express" edition of Visual studio for free and that works with PTVS. 
Sikuli's OCR (last I tried it) isn't that accurate. You can use the Win32 API to grab controls out of windows and (maybe?) pull the data out directly. I wish I knew of a good guide/walkthrough out there, because I'd actually like it for myself. But here's something to help you start. The code below will give you the hwnd of a specific control inside a dialog. You must have the hwnd of the dialog and the controlID first. hwnd = winUser.user32.GetDlgItem(parentHWND, controlID) This may be a helpful tool: http://msdn.microsoft.com/en-us/library/windows/desktop/dd318521%28v=vs.85%29.aspx Good luck - I'd love to hear what you end up working out.
&gt; need a recent version of Visual Studio first, if you are a student then you can get a free copy of the latest Visual Studio 2013 Professional through the Microsoft "DreamSpar I'm on a mac.
Oh, that sucks 
I have recently learned to user Managed VM on the Google Cloud with Docker and I am impressed by how easy and powerful this it. 
I picture a mixture of Chris Hardwick, Dane Cook and Jerry Seinfield. I'd pay to see that act.
I first thought you were suggesting it for us to use here, which wouldn't work out all that well.
NumPy array support would be absolutely critical for me. That is why I absolutely love Cython, I've only used it a handful of times but it's been incredibly easy to use with virtually no changes to the pure Python implementation. Numba seems interesting as well, I've been keeping my eye on it for a while, but Cython really has the maturity to be used in larger scale applications.
&gt; """Raises an exception if another instance of this class has &gt; been instantiated, otherwise marks the singleton instance of &gt; this class as having been instantiated.""" That's not how singleton's work. If you want to create a singleton take a look at [Enum](https://docs.python.org/3/library/enum.html) which modifies `__new__`.
In most of the implementations I've seen, subsequent calls to `new()` will just return the same instance of the singleton, rather than throwing an exception. A "singleton" is just a fancy word for "global" so use them judiciously.
I expect this to mean that you can only have one Singleton of *any* subclass, not one Singleton of each subclass. Perhaps replace `Singleton.singletonExists` with `self.__class__.singletonExists`. At least, that's what I'd do in Python 2, maybe there's a different Python 3 way to spell that. `type(self)`?
&gt; I expect this to mean that you can only have one Singleton of any subclass, not one Singleton of each subclass. No, my intention was to have each subclass be a singleton (i.e., subclasses A, B, and C can each be instantiated only once). The idea is to use inheritance as code reuse, so that every one of the subclasses doesn't need to copy the code. ~~Your suggestion about `self.__class__.singletonExists` seems correct if I wanted to have only one singleton of *any* subclass, but that's not what I'm going for.~~ EDIT: Actually, your suggest fixes a bug.
&gt; subsequent calls to new() will just return the same instance of the singleton, rather than throwing an exception Yes, I've seen that too. I think implementing that would require implementing `__new__` somehow. I haven't done that before, but it seems a valuable thing to have.
This was exactly what I needed. Just ran a 2.6 GB file through it and not only did it find the elements and actually complete for once it did it with a max memory usage of 52 MB. 
Your precommit hook example will add more than just the version change to the commit. This is not compatible with changes having been added with git add -p
Thank you good catch
&gt; Not sure what you mean. The singleton pattern in OOP is well defined to mean restricting a class to having only one instance. A singleton should never throw an exception when trying to get an instance. Doing that is just plain dumb. As far as enum, I'm not saying to follow it exactly. I'm saying it creates a singleton-like object by modifying `__new__` so it'd be a good starting point. edit: Of course a singleton can throw an exception for other reasons. It should not throw an exception just because the object has already been created.
`Singleton.singletonExists` will *always* refer to the singletonExists attribute of the Singleton (parent) class. In contrast, `self.__class__` will be `Foo` when `self` is a Foo, etc.
Did you take a look at [bumpr](https://pypi.python.org/pypi/bumpr/0.2.0) that does this in a very flexible way? There are a few more in pypi.
&gt; Singleton.singletonExists will always refer to the singletonExists attribute of the Singleton (parent) class. Ah, thanks for catching that. That's a bug.
Thank you. I didn't know about Bumpr. But I what wanted was something dead simple. Just to increment the number without any configurations or options. Just do one thing, and that's it. 
Start contributing to open source stuff, or live in the bay area haha. Seriously, you don't have to know everything about a project to be helpful. When people submit better docs or something to my open source stuff I'm /much/ more willing to answer silly questions or help them get better. Quid pro quo. 
Site seems busted in Firefox Mobile.
It's hard to even navigate the open source programs. I don't even know what pip is haha.
Back in the early Windows days I solved this problem by intercepting [ExtTextOut](http://msdn.microsoft.com/en-us/library/dd162713%28v=vs.85%29.aspx) WIN32 API function, so I was able to analyze all Windows text output. Check out "Gray Hat Python" book, Chapter 7: DLL AND CODE INJECTION
I tend to find that trying to do something as complex as a game for your first project in a language can be overwhelming, but I agree that Hello Worlds are often boring. I tend to start with series of programs such as a pi or e estimator, a prime number generator/checker, an encoder, a collatz conjecture calculator, etc. Then I start messing with GUIs if they are possible, and then I make games or specific utilities in either text or GUI form.
It can certainly be daunting, but as long as you google things before you ask, and remain humble you'll find that the community is generally really friendly, even large projects like Elasticsearch. As far as pip goes - this is a good opportunity to start! Google 'pip' and read all about it. The next step (IMO) for you should be to come up with a simple project without too many moving parts, and force yourself to finish it with python. This will give you a good feel for how to learn, how to debug, and where to go for help. Some suggestions: - Write a program that takes a name from a user, and have a random greeting come out. Expected output: $ python greet_me.py Bob Good morning, Bob! $ python greet_me.py Have a good day, Bob! - Write a program that gives you the weather Expected output: $ python get_weather.py 20500 Weather for Washington DC (20500) -&gt; 79 degrees F It's really about starting simple, and learning the individual pieces (e.g. "How do I print something to the screen?", "How to I take in an argument?", and "How do I talk to websites to get something like weather data?". Eventually you start plugging the tiny pieces you know into each-other and start creating awesome things like websites and stuff. Hope it helps!
What about just using openssl with subprocess module?
Note: This doesn't conform to PEP 440 and using it for Python packages will likely cause confusion if people try to depend on your project, especially as more people move to using pip 6+ and setuptools 8+.
This works import numpy from ocl import Compiler c99 = Compiler() @c99.define(a='long', n="int") def mysum(a,n): b = new_ptr_double(a) s = new_double(0) for k in range(n): s = s+b[k] return s compiled = c99.compile() size = 10 a = numpy.random.random_sample(10) ptr = a.__array_interface__['data'][0] print compiled.mysum(ptr, size) print numpy.sum(a), 'check!' 
Could you please provide screenshot? 
Yes cryptography library is great, it supports py3 and is “Cryptography for humans”.
Oh. Try pyCharm
Yes, and I prefer it over BumpR - not the least because of more active development.
I though locate ran as a cron job, usually once per night by default (I think). It records filenames and locations in a database (sql?) but the changes won't be recorded until the next time locate is ran. (FYI, on RHEL and CentOS, the cron job is called "mlocate", and you can run it manually, though it may take some time depending on the size of the filesystem, disk read speeds, and number of files it needs to index.) That said, you should be able to access the database that locate indexes everything into, by using python. Honestly, the find command in bash is pretty powerful. It's not exactly straightforward, but you can exclude directories to search, and include parameters such as size, modified-time and regex. I guess as an exercise in python... sure, but it seems like OP is trying to re-invent the wheel without making quite so round.
I can't actually get a win from this. I'm showing 0 wins out of 1000. Either I'm incredibly unlucky, you've disproved this strategy, or something isn't quite right in the code. If I'm not mistaken, the win ratio should be at least 20%.
Lots of good suggestions here. If I might chime in... give linux a chance. You won't run into nearly as many issues with compiling packages as the compiler is open source for linux and readily available and automated through either "easy_install", "pip", or "setup.py"; all of which are run inside of python, and all of which run near flawlessly in linux. You can easily run a virtual machine using Oracle's "Virtual Box" (free) with an Ubuntu, CentOS, Mint, etc distribution. If you really need the speed, consider dual booting your computer. If you want to dip your feet in the water first, try a "live" thumbdrive of Ubuntu, which will let you boot your computer into Ubuntu without actually installing anything. All that said, to compile a python package into windows involves downloading the same compiler used for the version of python that you're going to be running. (likely python 2, as many scientific tools aren't readily available for python 3) That means you'll need the Microsoft Visual C++ Express (difficult to find now) or you can compile the packages using gcc through cygwin (cygwin is a bash (bash is a linux command line interface) terminal for windows that emulates many linux functions.). Edit: I almost forgot my reasoning behind using linux for python. Eventually, if you use python enough, you'll come across a python package that needs to be compiled. (something that isn't included in scientific oriented distros, and doesn't have a windows installation program) When you do, you'll be banging your head against a wall if you haven't already learned how to compile on Windows. If you're on linux, you pretty much won't run into that issue.
I don't think you can really make a claim either way to be honest - it is very dependant on your data. Personally, I like to work in IPython notebooks, and I create classes or functions as I feel are necessary in my experience. However, I do find that at some point my notebooks become too large and so I do start to refactor them into modules. At that point (normally approaching the end of submitting a paper), I consider whether I want to start to refactor things to be more modular. I think that more important than anything is that you release the code, in what every state it is in, that produced your results! I personally feel very strongly that the code that produced results is almost as important as the result itself, as part of the open verification of papers.
Now ses supports for the commands *list* and *info*!
http://grimoire.ca/mysql/choose-something-else 
A few years ago I learned that an ORM doesn't help you as much as you'd like when you change the database. I developed a Django site with SQLite and wanted to switch to MySQL later. Well, the MySQL version of the ORM hadn't all the capabilities I needed and used. So I had to rewrite some parts. A few months ago I thought web2py's DAL would be easier. Hey, it's 2014. Nope, a big nope. 
Thanks. Order is not important.
After some time being soaked in legacy I can say a new start in Python 3 and Postgres life is pretty good so far, very refreshing. Haven't done much crazy stuff with it yet but at least this doesn't fuck up the basics like real-world utf8.
I used MySQL for four years. I knew a lot about it by the end, there are lots of things to configure and figure out, and you can eventually get it to do what is needed, and then it does work well. We were MySQL wizards. All our sites used MySQL, and they worked fine! I felt good about MySQL and was ready to defend it against the attacks on it that I read so often on the Internet. Then I switched jobs twice, and for the last three years I've used PostgreSQL for all my projects. I still don't know anything about it.
I find it surprisingly readingful actually. The python syntax makes it almost look like English to me: `Get the index of the item if it is a thing, where thing is something in this set.` Nice answer!
&gt; So who cares if the data isn't absolutely 100% perfect and pristine? MySQL gets the job done as quickly and easily as possible. &gt; &gt; Please get me a list of every single application you have ever worked on so I don't have to go near them. Thanks!
 &gt;I used MySQL for four years. [...] you can eventually get it to do what is needed, and then it does work well. We were MySQL wizards. &gt;for the last three years I've used PostgreSQL for all my projects. I still don't know anything about it. Is that because Postgres has good defaults and doesn't require you to become a wizard for you to "get it to do what is needed?" 
Yes. Perhaps they can be improved on, but it's always just there and works. I've never had any urge to find out.
I totally understand. I wanted it to be more in line with [SemVer](http://semver.org/) to cover any type of projects not just Python. And by the way, it does cover some part of the PEP440, as it follow a similar scheme: major.minor.patch-prerelease+build Thank you. 
The default configs of postgresql are easy to handle. But the memory setting need some love. 
There is a (probably not exhaustive) list of kivy apps in the [kivy wiki](https://github.com/kivy/kivy/wiki/List-of-Kivy-Projects#kivy-apps-in-the-apple-app-store).
Why did you consider MySQL over PostgreSQL? I'm just asking as I'm not sure if you knew, but SQLite is a fork of PostgreSQL, so a large majority of SQLite is already native PostgreSQL valid syntax.
This is particularly true with SQLite and MySQL. SQLite is doesn't support concurrent write transactions and MySQL simply does a poor job following ANSI SQL standards. EDIT: fixed sloppy wording. Thanks reallyserious.
Ah, excuse me if I'd rather not waste a lot of time on testing and investigating problems in production. And BTW, I'd rather not have to put up with really, really slow queries or waste time changing my data model to get them to run fast on MySQL because its optimizer is trivial.
by default it uses a random selection strategy. the group should lose every time, it'd be super rare for a win to occur. Run it again with -x on the command line (or in the if \_\_main__, change STRAT_X to True) to see the odds of winning using the choose your number then follow the chain strategy.
You spend a lot of time configuring what subnet has access to your database?
Hehe. Nah, that would work. Although I have been posting daily playlists of /r/Music for a while now. :)
Thanks a lot, right now I'm trying to figure out how to make my Rock Paper Scissors game keep and save the score. There's definitely an incredible amount to learn. I guess you have to start small just like anything else. 
http://stackoverflow.com/questions/7182234/parsing-large-xml-file-with-python-lxml-and-iterparse
The server already had MySQL installed. Despite what people on Hacker News tell you: Most projects are small enough that you can host multiple sites on 1 server. Together with the database. 
The defaults aren't very good for Postgres. If you don't tune it after installation it will be very slow. [PostgreSQL ships with a basic configuration tuned for wide compatibility rather than performance. Odds are good the default parameters are very undersized for your system.](https://wiki.postgresql.org/wiki/Tuning_Your_PostgreSQL_Server)
Not sure why you inferred that I was saying you needed a PostgreSQL database *server.* PGSQL consumes a very small amount of memory unless explicitly tuned to use a lot. Even then it's conservative and heavily leverages filesystem caches. I host a large amount of sites using a heavy application alongside PGSQL databases on single servers (generally 10-15 per server), so I'm well aware of this.
But that's for a sys admin or your database admin to figure out, and its one time config. MySql puts a lot of this load on devs to make up for its failures. For instance, in Postgres I never need to care about implicit conversions.
Performance is something you can worry about later... All the stuff in the article you need to worry about now to get a proper setup. 
Yup, t1.micro as well as a database instance.
When was the last time you used postgres? Streaming replication is built in.... Master-master is an issue I guess, but I've done scale-up on a single master pretty dang far (a lot farther than I was ever able to get MySQL to scale up) while still doing live replication to 2 slaves.
Couple quick options: * just use a text file * use a csv file * use sqlite Of these three the fastest/easiest for a beginner will be the text file; I can send you a code example if you'd like.
&gt; but SQLite is a fork of PostgreSQL What's this? I thought Hipp designed it out of nothing? [Wikipedia](https://en.wikipedia.org/wiki/SQLite) makes no mention of PostgreSQL
&gt;And Seaborn is just a high level wrapper around matplotlib! But that is exactly what is needed. I appreciate just how hard writing a plotting library must be - literally every aspect needs to be customizable or it will be found lacking. That being said, the API and some of the defaults are bad. The matplotlib team refuses to break backwards compatability (a plot made with 1.0 needs to look the same as something made with 1.x), so we are stuck until they decide to do a clean-slate 2.0 release with some desperately needed changes (colors, legends, etc). Attempting to rewrite/compete against matplotlib is madness. Wrapping up some of the uglier bits is incredibly welcome.
Not that I'm aware of. Just personal preference I believe.
He probably meant the original micropython board which costs aproximately 35$.
Sounds like a lot of this needs to be default in Django.
You are correct. /u/chucky_z is wrong about sqlite being a fork. However they do both implement the [SQL-92 standard](http://en.wikipedia.org/wiki/SQL-92) which might be where he got his misconception from.
This is not python code, it is Matlab code. I'm not sure why someone told you to run it as python code. Either a) just run it in Matlab, or b) translate it to Python and run it as python code.
 def backwards(self, orm): pass # I didn't really want to rollback this :-) Speaking of things silently failing, maybe this would be a better idea: def backwards(self, orm): raise Exception("Can't be rolled back, chump.") 
&gt; But that's for a sys admin or your database admin to figure out I envy you. 
Use [`collections.defaultdict`](https://docs.python.org/2.7/library/collections.html#collections.defaultdict), either with a set or a list: &gt;&gt;&gt; c = collections.defaultdict(set) &gt;&gt;&gt; for index, item in enumerate(["a", "a", "b", "d", "a", "f", "b"]): ... c[item].add(index) &gt;&gt;&gt; &gt;&gt;&gt; c defaultdict(&lt;class 'set'&gt;, {'b': {2, 6}, 'a': {0, 1, 4}, 'f': {5}, 'd': {3}}) &gt;&gt;&gt; c = collections.defaultdict(list) &gt;&gt;&gt; for index, item in enumerate(["a", "a", "b", "d", "a", "f", "b"]): ... c[item].append(index) &gt;&gt;&gt; &gt;&gt;&gt; c defaultdict(&lt;class 'list'&gt;, {'b': [2, 6], 'a': [0, 1, 4], 'f': [5], 'd': [3]}) From there you can use `sorted` to get what you want, on either you can apply: index_index = sorted(c.iteritems(), key=lambda x: min(x)) And then get a list of (sets/lists) in order of their values' first occurrence 
PostgreSQL also has geospatial queries with PostGIS.
Care to explain why? I've been out of the programming world for a while (since the early 00's really), and I'm just starting to get back in. MySQL used to be the standard - LAMP (Linux, Apache, MySQL, PHP/Perl/etc)
that's very detailed sir
haha this isn't mine but here ya go https://github.com/audreyr/tweepy-utils/blob/master/scripts/unfollow-nonfollowers.py
I saw your post over at /r/matlab and I think you missed the point when they said you should use python instead. They didn't mean that you can, or should, run this code in python. It simply won't work. They meant python is a better tool for the job. Doing this in matlab is a bit like hammering a nail with a screw driver, it can be done but there are better tools at hand.
But the code is written in Matlab
If the data you are handling do not actually matter, I'm wondering were you need an application in the first place.
Thanks!
Yes it is, which is why you can't get python to run it.
\&gt;This Code is written in MATLAB. It cannot be run in Python. \&gt; To run this code as is you will have to buy and Download MATLAB. \&gt; The people in that thread are saying that MATLAB is not suited for this task (HTML Parsing) and it would be better for you to rewrite this script in Python. 
Thank you for clarifying. So I guess since I am not a programmer I am kinda screwed? 
OK, back to the question: &gt; Why did you consider MySQL over PostgreSQL? I (maybe wrongly) thought it would be a bad idea to add PostgreSQL to the mix. There were already websites on this server which could only use MySQL. The "Test, don't assume!" rule was violated.
In my experience, it's currently in vogue for developers to hate on MySQL and worship Postgres. Sysadmins and DBAs generally have a different outlook on the situation.
Why do you care about MySQL derivatives? PostgreSQL is easy to handle and all of the features are well working. The license gives you freedom without any involvement of a big company like Oracle does.
MariaDB is a fork of MySQL. It's better, but it won't solve the fundamental problems. Use PostgreSQL.
These people are just elitest snobs. It works just fine.
hardly...If you're trying to parse stock data, just use pandas http://nbviewer.ipython.org/github/twiecki/financial-analysis-python-tutorial/blob/master/1.%20Pandas%20Basics.ipynb There's also various other libraries depending on the type of data you have
I've used postgres for years - small personal projects - just the other day I went through that list and immediately more than doubled its speed on certain queries (small datasets so probably higher gain on large data)
Having gone from a company that uses ORM's (Hibernate) to one that doesn't, I've made two observations: * Meta-query languages (like HQL) are a bad idea that will inevitably generate suboptimal queries. * But it is nice to not have to write your own code to serialize/deserialize db results to objects and vice versa.
Gdaws delivers, gotta up vote you now I guess
Maybe it is just my OCD but the list "coding languages" contains languages, frameworks, databases. Other then that nifty idea, interested to see how the adoption rate is.
Good enough for me; I appreciate the thorough reply (I was afraid people would think I was trolling). 10 ish years in the computer world is an eternity so I'm not terribly surprised that MySQL isn't dominant anymore, just more surprised at how loathed it seems to be now.
I haven't looked at the script much, but I'm using it and it's working perfectly so far! Thanks!
This was a fault , you are right. I changed it to big. 
"Great" as synonymous with "large", surely.
Thanks for the share!
good points and synchs with what I've seen 1. indeed, ultimately they end up reinventing SQL, but in a less-portable, ORM-specific way. I'd rather master SQL then be able to use that from within procs written in any prog language. plus use it in CLI clients for ad hoc queries, etc. 3. bingo. the free lang-specific object serialization is prob the biggest win, the sugar that addicts you early. but ORM's are pretty much the poster boy exemplar for the danger of leaky abstractions. Trying to hide your database behind an abstraction is about as dangerous in long run as trying to pretend that distributed interprocess network message passing is really just in-proc func calls. they aren't and it will bite you. (ie. Fallacies of Distributed Computing, etc)
How do you change the port?
sweet!
agreed that find will also manually traverse the directories, but you can exclude directories to traverse, though the way to do so is fairly obscure. find / -not -path /path/to/ignore will actually traverse the "/path/to/ignore" directory, but exclude anything it finds there. find / -not \( -path /path/to/ignore -prune \) will skip attempting to traverse "/path/to/ignore" entirely. Also, and this is purely conjecture; I believe find is highly optimized for it's task and will likely return results far faster than a python script could achieve. Again, purely conjecture. As for the locate database... "/var/lib/mlocate/mlocate.db" is where it can be found on a RHEL or CentOS distro. 
Because database optimizations for performance are necessary for basic applications like a CMS or ecommerce site?
Nobody ever died because a blog used MySQL.
Any online resources?
You forgot to mention that mysql is now owned by Satan (Oracle).
I think MySQL, like MongoDB, has experienced a backlash from the developer community. I suspect the issue is that in both cases the vendor make inappropriate short-cuts and gave developers irresponsible advice (mysql: "90% of all developers don't need RI, transactions, views, etc"). After these developers have seen the pattern of carnage and then seen greater success with Postgresql, SQLite, or whatever, then realized that they were lied to - it's pissed a lot of people off.
I don't think Oracle is any worse than MySQL AB was: both companies lied, manipulated, and produced shoddy products.
I hear you still: it is an abstraction layer around the database, by definition/exemplar learn SQL too (advice sent back in time from a future you) ORM's are like training wheels on a bicycle. good solution and net win within a certain age/experience/stage range (eg. prototypes and demos), but will become an increasingly suboptimal tool (ie. local maxima effects) as time/scale of your problem grows. To be best at your craft master SQL and bias to it, plus go deep on the actual databases. 
Yes indeed you are correct. I'll make some edits.
Here's an easier method from the command line. python -m SimpleHTTPServer Add a number at the end to change the port python -m SimpleHTTPServer 5000 And add sudo for any port under 1024 sudo python -m SimpleHTTPServer 80 
I didn't know MariaDB was an MySQL derivative. I'm a noob. But yeah thanks for recommending PostgreSQL I'll definitely check it out. 
Are all the terrible things about MySQL true for stuff like Amazon Aurora? I would really like to use Aurora with some Django projects of mine. I assume since its managed and tuned by Amazon they have taken care of the pain points?
I hate MySQL for many reasons, the first of which is no transaction support for schema changes. This makes using South migrations in a development team a huge headache. If a migration fails halfway through, you're only option is to revert all database changes manually. Friends don't let friends use MySQL.
This is quite possibly the most useless post I've ever seen on this sub.
I did a quick google: http://blog.nektra.com/main/2012/07/20/windows-api-hooking-in-python-with-deviare/
This guy has been spamming his website with new accounts for the last couple hours. And adding positive comments from other spam accounts.
Or this http://winappdbg.sourceforge.net
Here's a more functional approach with *reduce*. Should run in O(n). import collections def f(acc, tup): acc[tup[1]].append(tup[0]) return acc list_of_things = ["bird", "cat", "dog", "cat", "bird", "cat", "dog", "bird", "horse", "horse", "dog", "cat", "horse", "dog", "horse"] print reduce(f, enumerate(list_of_things), collections.defaultdict(list))
I'm just waiting to see if django will ever officially support any nonrelational solutions. 
As a beginner, that was a really helpful tutorial! I understand classes much better after reading that as opposed to codecademy's lesson on them.
Yet more reasons to throw mysql to the dustbin
When checking out Postgres, make sure to try out the PgAdmin gui. (It's even bundled with the installer for windows). Makes quite a lot of things much better.
I would be interested
With tesseract, first isolate a box of pixels that contains just the text. Varied fonts and other visual noise throw it off.
You could try running it in [GNU Octave]( https://www.gnu.org/software/octave/). It should be compatible with Matlab.
yes
Ugh. I have to alter my schema for my unit tests. My application uses MySQL, but the tests use SQLite. I guess now would be a good time to just configure the unit tests to use a different MySQL database.
 import numpy as np list_of_things = [1,2,3,1,2,3] array_of_things = np.array(list_of_things) x = np.unique(array_of_things) counts = np.array([len(np.where(array_of_things==xi)) for xi in x], dtype='int32') Just get your types right, but this way can be a LOT faster than other methods. Numpy is awesome.
That would be awesome.
A good read but I am still not really a fan of classes. The side effect analogy with the ever weakening shaft is creepy. Can you ever expect to reuse such code with hidden side effects? 
What's the backlash on mongo db? Haven't used that yet, but I've started reading a tiny bit about it.
Yes please, mostly the install because in my virtualenv I keep getting error about installation ... I let it go and went for beautifulSoup :/ I'm a beginner in python btw ...
Right, that's more accurate.
♥Pycharm♥ Or full edition for free until you graduate (JetBrains has new, unrestricted edu licenses). Also, there is ipython notebook in Pycharm 4 but it's kinda broken
Yes!
Pretty weak in my opinion, too technical for a beginner and useless for someone familiar with python. The last two sections especially, "dictionaries of classes" is literally just a dictionary...
I got into Python because I wanted to learn scrapy, so I've read a bunch of different tutorials. Please be clear about which version of Python the tutorial is relevant for and point out that it affects syntax and which libraries work. Some of the readers of your tutorial might be completely new to Python, and get very confused because they are using different versions!
Yes!
Have a look at /r/learnpython, 'how do I scrape this or that' is the most common question. I'm sure there is a huge audience for it. A scraping tutorial is an excellent idea.
Really looking forward to your tutorial. I had a tough experience crawling websites using the tool pyspider(https://github.com/binux/pyspider). The tool is powerful, however not friendly for newbies. So I think your scrappy tutorial will be more helpful for me. And When can I noticed that your tutorial is ready? Thanks.
If you have reporting with so many joins, your application isn't basic. 
This is an introduction to object-oriented prgramming using Python as an example. I think the scope of the tutorial is a bit large for people on this subreddit; I'd expect most people here already know what a class is. It's probably very helpful for someone new to programming and unfamiliar with OOP, though, and Python's readable syntax make the demonstrated concepts easily understandable. 
yes 
I would be interested too :)
The Python integration is one of the stretch goals. I am wondering if anybody is supporting this and what you people think about it?
Go for it mate :) 
Don't ask, just do it. I have a couple tutorials I wrote about a decade ago that people still find and comment on today, and it wasn't really even a difficult subject. Even if no one would benefit today, it's possible something you write WILL be of use to someone in the near future. Just get it written, make sure Google indexes it, and rest happily knowing that you contributed to the community. :)
Yes, which is really a shame since IMO this years in Berlin was one of the best organized europythons in a long time.
I cannot reach the article anymore... ... but I took a brief view this morning: I believe the quality is quiete poor. As far as I remember it uses bad (and not PEP8 conforming) names! I can just remember, that almost every method was named more like an attribute or a property - why that? And even worse, some of them behaved like an attribute or a property - so why not just use the appropriate building block? Imho a **good** tutorial must be concise throughout all aspects, also with so simple basic things like PEP8!
It looks like the instructor is using OSX, not Windows. The OSX terminal and the Windows command line are quite different, so the commands he uses may not translate well to what you need to do.
Terminal, xterm, command line, DOS prompt and probably many other things are all names for the same thing. Under Windows, I think you need to run either `command.com` or `cmd.exe`, probably the later. If it isn't listed in the Start Menu, you should be able to run it by calling up the `Run...` command, which opens a dialog box. You type in `cmd` and hit Enter, and it should open a terminal window. In the terminal window, you should see a prompt something like this: C:/My Documents $ It has been many years since I've used Windows, so I'm a bit fuzzy on what the exact prompt will be, but if you google for "DOS prompt Windows 8" you should find more information. Anyhoo... at the prompt type `python` and press Enter, and the Python interactive interpreter should launch. It will print something like: Python 2.7.9 blah blah blah Type "help", "copyright", "credits" or "license" for more information. and give you a prompt `&gt;&gt;&gt;`. Remember that prompt: it means you are in the Python interpreter. If you start typing DOS commands at the Python interpreter, or Python code at the DOS prompt, it will complain. Oh, another thought! You say that you found "the command line" by searching for Python. I expect you mean that there is a command under the Start Menu that shows "Python &gt; Command Line" or something similar? If so, if you pick Command Line, it should take you straight to the Python interpreter without needing to open cmd.exe first. Saves a bit of time. But having said all this, I'm not sure if the plain old Python interpreter is the best thing for you to be using. By all means use it if you like, but on Windows you may find it better to use IDLE. Oh, and one more thing... as a beginner, you might like to subscribe to the [tutor@python.org](https://mail.python.org/mailman/listinfo/tutor) mailing list, where you will find a number of friendly (well, mostly friendly) people happy to help you learn Python programming. We don't do homework for you, and a few of us are old-fashioned computer guys with strong opinions on the right way to send emails, but if you're willing to show willingness to ask questions and listen to the answers, we're happy to help. 
&gt; Anyhoo... at the prompt type python and press Enter, and the Python interactive interpreter should launch. It will print something like: &gt; &gt; Python 2.7.9 blah blah blah &gt; Type "help", "copyright", "credits" or "license" for more information. He might have to [set an environment variable](https://docs.python.org/2/using/windows.html#configuring-python) before he can run python in the terminal/command prompt from any directory.
Old article and TIOBE index for December 2014 is [out](http://www.tiobe.com/index.php/content/paperinfo/tpci/index.html).
What sort of mapping functionality are you looking for? Seaborn does in fact play (reasonably) nicely with cartopy for projecting data: http://nbviewer.ipython.org/gist/shoyer/16db9cd187886a3effd8
Actualy I work with bs4 + mechanize instead of this framework. However a good written tutorial would be interesting me. 
Good warning. I have been searching for a good resource on how and when to use classes in Python specifically, and thought I would find it here. Guess I can keep searching.
I realised right after posting it that it was an old article ... I quickly posted a comment mentioning this; however, that comment was quickly ignored/downvoted.
Six joins isn't uncommon with a relational model - if you're creating reports, usually dashboard views these days, that aren't totally trivial. Even a basic database will often have 20+ tables. If you want to give users the ability to understand this system you need to compare current activity to historical, to show what users/accounts/etc are using what resources, etc. That's basic functionality. Anything less is trivial. And if you were using Postgres or SQLite, or any commercial database rather than fighting against this kind of functionality, probably telling the user it's crazy-complicated, it's "enterprise", it's way over the top - you'd simply say: "you're probably right, you do need a dashboard with useful information. No problem we'll get you that."
I just just looking at how to scrape the other day and Google brought up scrapy. I would like a tutorial on it... just wish it supported python 3.4.
Welcome mate, I'm also a biologist and I started programming a year ago! I use windows at home and for most of the stuff I do, but in general I've found that programming is much easier and more convenient in a linux operating system. Most of your potential bioinformatics-colleagues will probably be using linux as well. So I think you should familiarize yourself with linux. I suggest Ubuntu or Kubuntu, these are very similar to windows and thus super easy to understand. The "terminal" that you're missing is a central element of all unix-based/linux operating systems and it makes using python much, much more convenient. For example, if you want to install the scientific python library "scipy" on windows, you have to go to the scipy website, download an .exe file and manually install it. Some python libraries are much harder to install on windows and it can get really frustrating. In linux, you just type "pip install scipy" into the terminal and then you have the library. You don't even have to buy a new laptop or uninstall windows to get linux. There are some tools for windows (for example VMWare player) that allow you to have a nice window containing linux [(looks something like this)](http://i.computer-bild.de/imgs/3/4/7/3/8/9/9/Mit-dem-VMware-Player-lassen-sich-beliebige-PC-Betriebssysteme-in-einem-745x558-4580f061a8706e5c.jpg). Good luck with your python course! If you want more bioinformatics-related excercises, here is a nice resource: http://rosalind.info/problems/
Wow thank you so much for the response! I think I have been in the Python interpreter like you said (I tried going from the windows command prompt and it took me to the same place I'm pretty sure). I'll check out IDLE (I don't really know what the difference is). I just want to use whatever they're using in the Dowell lab lessons, because I'm hoping that learning Python will help me develop my career doing biological research. After finishing the lecture, I saw that the commands he was typing started working on my program after he "asked the terminal to run the python program." I'm not sure exactly what that means, but it seems like maybe I just opened the program directly, whereas he was in some separate window (the terminal?) to begin and then prompted that window to open the python program (?). I'm kind of just talking out of my ass, since I have no idea what's going on, but I think that's it. Do you think it's important for me to understand moving from the terminal to python, or should I just keep going with the lessons?
Yeah I noticed that, but I was hoping it was still possible to use his lessons since they're so appropriate for what I want to use it for. Do you know a good resource that I can use if his commands aren't working on my program? u/stevenjd suggested I subscribe to tutor@python.org, which I think I'll try. Thanks for the help! I honestly didn't think anyone would respond to this. Reddit is so awesome sometimes. 
cool, thanks. I don't really see an entry point per se (most of them seem to assume some prior knowledge), but I'll keep looking. 
Does anyone know where I can find more articles like this? Doesn't have to be related specifically to Flask, but articles like this are INCREDIBLY helpful in learning. And talk about strange timing (*cue twilight zone music*); I've spent the last two days stepping through werkzeug and Flask code to (A) learn how they do what they do, and (B) learn new programming techniques, language features, etc. The way werkzeug's init file lazily loads the other modules almost broke my mind.
Ah, it's a long list, here's a start: * MongoDB had until just maybe 3 years ago, zero security: anybody who could get an account on the server could do anything they wanted to with the mongodb database: drop it, get all the data, tamper with it, etc. MongoDB told people, that's fine, just don't "put it on the internet". That's totally irresponsible, the days of reliance on just firewalls is way over. * MongoDB was caught cheating to get good benchmark figures. They counted any "row" accepted by their client software as though the server had accepted it. * MongoDB is open source, but their backup solution is too slow for large data volumes. So, you need to pay them for the closed-source backup solution to get decent run-times. * MongoDB can't handle sequential scans: reports, analytics, etc. They do have an aggregate framework, a map-reduce implementation, and they do advertise that they're great for analytics. But it's all bullshit: a trivial query can take hours on a small amount of data. * MongoDB told everyone that the schemaless database was more adaptable and flexible than a database that imposes a schema. But this has also proven to be untrue: Mongodb isn't 'schemaless' - it's really 'many schemas'. Which is a great optimization for writing to the database, but at a cost to consuming. Now the consumers need to be able to know every one of these schemas to support them, test them, etc. And this can be easy sometimes, when a team does everything right. Or it can be nearly impossible, like when a team follows MongoDB's advice and simply comes up with new collection schemas without converting the old historical data. MongoDB is fixing some of the problems pretty well. They've got a ton of cash, and their security issues are now largely gone. What's left are three issues: First, do you trust them? Second, you can't practically run reports, data migrations, conversions or analytics. Third, can you afford the costs of having many schemas?
&gt;Does anyone know where I can find more articles like this? and... &gt;The way werkzeug's init file lazily loads the other modules almost broke my mind. Give back to the community by writing an article on it! :)
This was a succinct, interesting tutorial. This is one of the better descriptions of decorators that I've seen, and it's nice to see decorators used to register a function - as opposed to mutating it.
Thanks for the kind comments! To back up what padmanabh said, writing this post (and part 2, which I'm just finishing up), has helped me solidify my understanding of some of the cooler parts of Python, in addition to hopefully sharing some of that insight with others, you should definitely give it a shot!
Wait, what's the backlash against mongo? I use it when a project needs simple data storage and it suits that need very well. I have no illusions about it replacing a rdbms, but for cases where there'd only be one or two tables it seems better.
That is my point. Python options play reasonably well when cobbled together with something else... Whereas ggmap just works. Not saying py is bad, but that is a difference
It is how some singletons work. In Python 2.7: py&gt; T = type(None) py&gt; another_none = T() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; TypeError: cannot create 'NoneType' instances Although in Python 3.3 that behaviour has been changed, and you just get `None` instead of an exception.
No doubt -- and THANK YOU for taking the time to write this post!! For anyone reading this who wants to enhance their understanding of Python (and programming in general), I HIGHLY recommend looking through the code of some of your favorite packages. By looking at the code for werkzeug and Flask, in the past 24 I've learned: * that lazy loading for modules/attributes exists (meaning the module is only loaded if it is needed -- useful for werkzeug/Flask, which are large packages with a lot of features, some or many of which may not be needed) * that there are [two "styles" of classes](https://docs.python.org/2/reference/datamodel.html#newstyle), and by default the "classic" style is implemented in Python 2 unless you explicitly define your class like **class TestClass(object):** -- Python 3 uses the new-style of classes by default * a bit about [import hooks](http://xion.org.pl/2012/05/06/hacking-python-imports/) and how importing generally works in Python ...and much much more!
Holy sheeet. Ive been using pandas for a while and stupid me didnt know you can pass a list to the aggregate function! pd.pivot_table(df,index=["Manager","Rep"],values=["Price"],aggfunc=[np.mean,len]) This is awesome!
Whats the saying? 10,000 hours until you've mastered something? :-P
I'm interested. 
Reading this - "The Very Unofficial Dummies Guide To Scapy" http://theitgeekchronicles.files.wordpress.com/2012/05/scapyguide1.pdf springs to mind.
Here's a problem: deleting or garbage collecting the instance means you can't make a new one: py&gt; class Spam(Singleton): pass ... py&gt; x = Spam() py&gt; del x py&gt; y = Spam() Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 10, in __init__ Exception: Violation of singleton pattern! Better would be for the class to record the instance. Something like this: # Untested class Spam(object): _instance = None def __new__(cls): if cls._instance is None: obj = object.__new__(cls) cls._instance = obj return cls._instance It's only five lines, short enough that worrying about code reuse is probably premature. Also, the exception type is wrong. A TypeError would be more appropriate, since the error is related to the type.
Thanks! I'll definitely check this out
&gt; And allowing subclasses to create instances means that they're no longer singletons. Ah, that doesn't actually occur by default. I've just tested it, and subclasses of a Singleton class can't create instances, unless you give the subclass it's own `singletonExists` attribute.
I would really want to see this. I thought I'd find one on YouTube/Vimeo, but it's surprisingly absent.
Yes, that's a _good_ thing. You want the program to ship with the "most working setup" - something you can start writing code with and not run into the problems described in the linked article. Once it's all working, then and only then do you starting optimizing it - IF you need it. I've found in a lot of system that don't make heavy database use, the defaults are perfectly fine. I might be able to double my performance if I spent some time on it, but since the database is just not consuming resources my time is better spent elsewhere. And if you do need it, isn't it nice that there are potentially big optimizations you can explore - but _after_ you have a rock-solid, working program which you can test against?
You should always use a virtualenv. I personally wouldn't recommend activating it in your .bashrc file, since while you'll be sparing your system python install, you won't be using virtualenvs as they're intended to be used. Look into virtualenvwrapper, which will give you some useful commands for working with virtualenvs. If you are set on activating a virtualenv by default, just change your PATH environment variable in your .bashrc file to point to the virtualenv bin directory first.
If you're not working with a project and just working out ideas in the shell then it's overkill. EDIT: disregard this I didn't read the question properly. 
https://github.com/yask123/Auto-Music-Downloader For those interested.
What makes this better than the already free IDEs out there for Python that support all of the stretch goals today? It's not like this a free IDE either, so why not use PyCharm or WingIDE, which have been around for a long time?
Has too much reddit traffic sploded their server?
I think that in the short term, the absolute critical thing is to be able to follow the lab lessons you are supposed to be using. If they use the basic Python interpreter, you should to. In the long term, being able to pick and choose your own environment is **very** useful. Some people like IDEs (Integrated Development Environment), like IDLE, iPython, Eclipse, Spyder, or about a dozen others. IDLE comes standard with Python, but is a bit basic. iPython is very popular with scientists, uses a workbook model that will be familiar to people who have used Mathematica, and comes with a whole lot of bells and whistles and so-called "magic" that aren't part of standard Python. Other IDEs have their fans too. But whatever IDE you use, the time will come when some piece of code is not working the way you expect, and you won't be sure whether the problem is with your code, or with the IDE. When that happens, it is vital to be able to run the good ol' basic Python interpreter, with no fancy magic functions or GUI, and run the code and see what happens. But as I said, this is long-term. In the short term, concentrate on being able to follow the Dowell lab lessons.
Most of what I do in the shell is simple stuff that doesn't use external libraries. For that there is no reason to setup a virtual env. I use python for things like checking the version of a jar using the struct library, running quick calculations using the standard math function and other quick one offs. Once the shell is closed the code won't be used again. You don't need to worry about the problem that virtual env solves because it doesn't come up. 
This man speaks the truth. If you like the subject then share it and then ask for comments.
Absolutely!
I would really appreciate a Scrapy tutorial, I have had a project in mind for a while and this I imagine would help me get started on it.
If you're doing outright screen-scraping, give [BeautifulSoup](http://www.crummy.com/software/BeautifulSoup/) a try. HTML is horribly irregular, and no one in his right mind parses it by himself.
Seven upvotes. Tango down.
Came here to say this as it's been a great resource for me to get my feet wet as well as dive deeper. Really good pacing and great examples to get you started.