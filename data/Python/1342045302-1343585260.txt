If you're a Python noob you don't, use cProfile instead. This is fairly specialised.
You can use terminal a your python shell Python, but I would recommend installing [IDLE](http://www.python.org/download/releases/) to code
I can answer questions 1 and 2. You will need to install Python, which can be found on Python.org. You will probably want to get Python 2.7.3 since it's probably what you used, but it's not a bad idea to be familiar with the differences between 2 and 3. Along with that install is a program called IDLE, which you may or may not already be familiar with. It's the provided development environment you can use to code in, and also provides some other features you wouldn't have just coding in a plaintext file. 2: Yes and no. You can use your terminal to call python programs from, but Py isn't built into that terminal, you'll need to install it separately, as described above. (Others can elaborate better than I can.) Edit: Also check out the links in the sidebar. They're a great resource.
Mariano Reingart is the author of [pyfpdf](http://code.google.com/p/pyfpdf/), the project mentioned at the origin of this thread. I have seen it grow and it was a port of a PHP project according to his docs. I do not know anything about pypdf and pypdf2. The only think I know is that they miss and "f" in the middle. :-)
pyinstaller does, but it doesnt work...
Very interesting and very straight forward for beginners of the language. I was looking for your source on Snakes, and there doesn't seem to be a download on the website you provided. :/ Thanks :)
I like wx.python.
How about telling us what platform you are targeting? Anyway, I'd probably go with Qt (use PySide).
PyTK comes with the language, but is pretty clunky. I've used PyGTK before with reasonable results - the layout etc works well but there are a lot of quirks to work around if you want something that feels "right"
I used PyQt at my former job, worked like a champ. For my own use I'd use PySide. Qt has so much more than just GUI classes in its toolbox. There are unique ID generators, networking classes, and all sorts of goodies.
You wouldn't believe the line-item in the budget for the equipment to measure them.
Cool but it wont work with floats :/
How about [kivy](http://kivy.org/)?
This is similar to [flatland](http://discorporate.us/projects/flatland/) which I'm currently using for the same purpose.
I enjoyed using wxPython along with wxFormBuilder.
If you can get it done in TkInter, use TkInter. Simplest solution.
You know, I've tried Kivy, twice now, but I just couldn't get my head around it. It's also got a really small user base (comparatively), so I wasn't able to just hop on stackoverflow whenever I got stuck and get (almost) immediate feedback. It meant posting to the news group and waiting days for a response. After getting tangled up in problems over and over I finally decided to give up. I then picked up Pyside and found it really intuitive. Though, maybe that's just due to their extensive documentation and tutorial sections. I still like the idea of Kivy. I'll probably give it a third try once I get a little better at programming. 
There is also pdfrw which seems to have a cleaner structure but less mature. Cannot import pdf with incremental changes (multiple roots at the end of the PDF file.) Unfortunately, pdfrw seems to be in coma too
Well I be fair there's ttk for native widgets but then again it doesn't cover everything. 
You can actually make a GUI with Pygame? I've been using the C++ version to open a window and handle input for me but I haven't done much with a UI (I need to be working on an openGL game, but I'm kinda blowing that off). So how would you make a UI with Pygame?
when unmodified python can run C code, supporting C code becomes part of python. using pypy and breaking this functionality doesn't support standard python. the people that care about pypy the most are the people that are doing numerical computations using multi-processing. by not supporting libraries that do these computations and not having a comparable alternative, pypy will never become useful. not supporting numpy without recoding numpy is a joke.
pyfpdf is a port of a PHP library to build PDF documents: www.fpdf.org it is not related to pypdf, which seems to be a library to manipulate and extract data from PDF files, so they cannot be compared directly.
The extra stuff in Qt is great if you're programming in C++. I'm not so sure that it will benefit much if you are writing in Python. The only thing I can think of is some integration with the GUI widgets, like integration between the database classes and the table views. But I like PySide very much and use it to write a lot of my GUI tools for my small business clients.
PySide gets my vote for the LGPL license (which allows for commerical applications.) But also because it is slightly more "pythonic". PySide also gels well with QML, Qt Quick. Check out QtQuick, its got good UI bindings - http://qt.nokia.com/qtquick/
Emacs and Vim have modes for languages like Python etc. which are like IDEs. Emacs and Vim are set up for efficient text processing, amongst other things, so one might prefer to use these over an IDE.
Or PyQt. Unless you plan on releasing this somewhere as a closed-source project, the differences between the two are negligible.
You need to transform the result of raw_input into an int (this is not PHP). Great idea otherwise!
python doesn't support c extensions, though. cpython does.
Ok no one has been particularly clear on this, so I will. Qt is owned by Nokia. PyQt is the older (still maintained) Qt module for Python. It is written by an independent company. It is GPL (NOT LGPL) and if you want to use it in a closed-source application, you must buy a license. PySide is the official Nokia implementation, it is very very similar to PyQt in basically every way that matters, with the notable exception of being LGPL. Thus it can be used in any application without paying anyone, as long as you don't modify the PySide source code itself. Nokia originally approached the PyQt developers to try to get them to allow LGPL usage for free. When they refused, Nokia developed their own module. They added excellent documentation, and fixed a few very minor oddities (in my opinion, PyQt fans may disagree?) At the risk of sounding callous, you may ask, "Why would I even use PyQt then?" and my response to that would be "Good question." In summary, use PySide, stop worrying.
PyQt supports Python2 and Python3. PySide supports only Python2.
Added a zip to download the source. [https://bitbucket.org/sirchristian/snakes/downloads/snakes-0.01.zip](https://bitbucket.org/sirchristian/snakes/downloads/snakes-0.01.zip)
I thought this guy was nitpicking and trying to pick an argument with someone who actually agrees with him, until I got to &gt;He suggests that if you do want the free performance gains PyPy promises you should just build a a Python to JS compiler and use Node.js. Holy shit, this is a thing that somebody seriously suggested?
My vote goes to wxPython, although it's the only one I'm really familiar with. It suited my needs at the time that I needed my first GUI and I've stuck with it. A cool tool to check out is [FarPy GUIE](http://sourceforge.net/projects/farpyguie/). It's a Visual Studio-like GUI form designer for wxPython and it's free.
For me a 3 years ago, WX was much easier than Qt, Now I try to learn Kivy :P But Pyside seems to be friendly
Secondary question: do you use designer for PyQT or Pyside? I find visual studio really easy because of the excellent forms designer. It's so easy for me (a scripter) to relate code to GUI.
Well, There is a [language reference](http://docs.python.org/reference/index.html) which is pretty much comprehensive. Jython and IronPython are actually listed there as alternate implementations, as well as pypy, and none of those support the Python C API. IMO It's clearly not a part of the language, just a bit of glue between Python and C.
a little bit of both would seem like the smartest way to go. I think that quote supports my position that implementation details of CPython aren't necessarily the definitive word on what the language is supposed to do or not do (e.g. even though Cpython's reference counting gives certain guarantees on when `__del__` is called it's generally accepted that you shouldn't assume these will hold always). And the C API isn't even a part of the language.
[Learn the hard way](http://learnpythonthehardway.org/)
[Dive into Python](http://www.diveintopython.net/) is still a good book.
http://stackoverflow.com/questions/1485841/python-behaviour-of-increment-and-decrement-operators My opinion is that any seasoned programmers knows that i++ &amp; --i are powerful operators, but introducing bugs when pseudo geeks don't understand the reason why i++ &amp; --i are symmetric. (instead of ++i &amp; --i). Post increment &amp; predecrement are tricks to play with in while/if in C and ASM and if you don't have the knowledge of what you exactly do, you easily have an OBO (Off By One) that is pain to debug. There is a subtlety that does not worth the trouble in using these. Even though I love these tricks, we are definitely safer without.
Huh, TIL I had no idea what was going on when I used those operators. You have made me a better person.
Okay, this looks straight-forward. I'll try to figure out how to contact him too since this seems like something that should have had an obvious example on the project site. Thanks!
You haven't seen much assembler code, have you?
On the front page of /r/Python right now is [Plop: Low-overhead profiling for Python](http://www.reddit.com/r/Python/comments/wcpv1/plop_lowoverhead_profiling_for_python/)... [profile/cProfile are included in the standard library](http://docs.python.org/py3k/library/profile)
If you want a quick intro, I highly recommend [Google's PyQuick Python lectures.](http://code.google.com/edu/languages/google-python-class/introduction.html) I've been going through them for the past few days and they are a lot of fun.
Faster than the slower C interface provided by PyPy, you mean. There's some translation of CPython C structures to PyPy and back which slows down cpyext considerably. Would a tracing JIT improve performance in real world scenarios over NumPy used from CPython? If so, enough to justify the time and money spent into this complex rewrite? I somehow doubt it.
Well yes. But it doesn't work on a running process. In this instance, I've been able to make use of the eventlet backdoor to turn on profiling. But it doesn't help in the general case.
[Udacity](http://www.udacity.com/) has an intro to programming which uses Python. I highly recommend trying it out if you prefer videos to books.
To be fair, Python's type system is also far from being convenient for optimization.
I second this - it's how I got into Python
Sort of a sardonic comment made by a long retired programmer/biochemist who used to listen to people brag about how much more efficient they were at programming than compilers of the '60s and '70s, when CPU cycles were far more precious than they are now. People could and did write small assembler routines that were finely honed and could well outperform any of the compilers of the day. But when it came to writing complete programs, or code segments of any significant size, compiled high level code could usually beat out any programmer but the "very best of the best." Additionally, complex algorithms, incredibly expensive to implelement in assembler, but written in high level code would often outperform less efficient software written in low level languages. Compare any modern sorting technique in a high level code with say bubble sort in assembler. Compilers and interpreters have gained significantly in sophistication and efficiency. When programmers start to dump on compilers, there is either an issue in the particular compiler, or the writer's code. Low level code is usually an answer only for very low level problems. The Header is a play on words based on the old TV program "Father Knows Best." Remember that the Father (Robert Young) was an active alcoholic during the period the show ran, while one of the children became a heroin addict.
If you are planning to administer it yourself, go with what you know. Within the confines of the ORM there are no real disadvantages using one or the other.
&gt;Why must cPython be the canonical python? Why can't we have a specification that is the canonical python? To be fair, there's a lot of confusion when people address the question "what is python?". In this context, we're really asking the question "what is the official, general-purpose implementation of python?" You're correct in your intuition that the interpreter is not the language. I think the author's argument is basically that python (the language) owes a lot of its success to the transparency and relative simplicity of it's most popular implementation (the cPython interpreter). As such, he's arguing that cPython should be the canonical interpreter and any deviance in behavior or implementation should be considered nonstandard. The reason we're concerned about the implementation rather than the end behavior is exactly what I quoted in my previous comment: &gt;Python gained popularity in its first decade because it was a non-write-only Perl, and it worked well with C. It exploded in popularity in its second decade because it was more portable than Java This just means cPython plays nice with others.
Really? Can you elaborate on this?
Because a working interface, even if it's slower, is better than not supporting an entire ecosystem of C extensions.
&gt; Thank you. I disagree, because I tend to favor competition and maximum freedom in cases like this Then I think you missed his point. It's not about restricting developers at all. I think just about everybody in the python community is very excited about projects like pypy. What this *is* about, is not getting carried away. If python is so popular, it's not only because of performance. All this talk in the peanut gallery about making pypy the official implementation completely misses this point. Pypy should (and must) continue to be available for those projects where cPython performance is suboptimal. This does *not* mean that pypy should be the default choice for 99% of users.
As someone completely oblivious to the inner workings and particularities of MySQL vs PostgreSQL, I didn't care for one or the other. However, one of my South migrations went awry on MySQL (and South explicitly reported it was a problem with MySQL). I've therefore switched to PostgreSQL and went on my merry way.
I was not aware that anyone was trying to make PyPy the official implementation. Thank you.
&gt;All this talk **in the peanut gallery** about making pypy the official implementation Rest assured, I don't think it's a serious proposition.
Yes I read the article. It surely sounded that way to me on the first reading, and on the second reading. Your interpretation of the article is different than mine. Shocking, simply shocking.
Obviously we have a very different perspective of what a beginner is. I don't consider pip a beginner tool (as most command line interfaces) btw, pip is not even installed by default in my box... I prefer windows executable installers (also generated by setup.py) or the operating system packaging facilities (debian, ubuntu et al) You're right about the build tools and dependencies, but centring the critic just in that, I think it is too much. It is a big effort to maintain, fix and document this library, sorry if I didn't have 5 more minutes before to comply with pypi.
how would that be?
This really belongs in [r/shittyprogramming](http://reddit.com/r/shittyprogramming)
My quick cleanup: https://gist.github.com/3099505
I've used Django with both and it supports both very well. And they're both good choices. It really comes down to which you like. If you know and like MySQL, I would use that. ime, MySQL has the edge on tools (especially for backups/deployment/ops) and better replication. Postgres has more robust transactions and some nice add-ons like great geo-spatial support (PostGIS).
That's... just false. There is a lot of things you cannot do in MySQL, and trying to do so with an ORM will be either impossible or inefficient.
[Here's what I'd do!](https://gist.github.com/3099475) I'd recommend looking into `argparse` or the older `optparse` rather than taking directly from sys.argv. Helpful on larger programs. 
Mostly the same changes I would've done, but I would've used argparse.
I think the interesting thing is seeing what proportion of a random 100 images are NSFW.
You might want to pull the actual image name from the overview page. It's fun to scrape webpages and a good thing to learn.
The official Postgres site has great documentation. As for which things are different between the two, I just migrated over and fixed issues that came up, or looked up syntax differences, it wasn't painful.
The article now has output included. Hope that helps!
A very cool thread, I'm just getting my feet wet in Python and learning on your own its nice to have another beginner's code to look at too. 
I don't understand what South is.
I usually add if __name__ == '__main__': to python I am executing directly in a file. It lets you load as a module later without having to modify it.
It depends, who is administering it, is it you? If it is you, besides learning sql syntax you also need to learn backup, replication, slow query log, performance tuning, etc. etc. With all those considerations... which one do you want to learn with? If it's not you, then that decision really depends on your sysadmin, no? He is the one who need to learn all the above. NOTE: Sure, it's just a blog, but database decision always comes with a lot of baggage/concerns. It is your data after all.
No, but at least it has unicode, a standard library, decent data structures, and no magical 'undefined' values popping up where you least expect them.
It'd never cross my mind to use anything other than Postgres, it's solid.
when you do an operation like MOV or ADD or SUB, if result is zero in the targeted register, the Z (zero) flag is set. In ASM, you can therefore directly use a BEQ (branch if equal (zero) to another short jump point, and you have won 1 instruction (you don't use CMP). But since 20 years, C compilers are smart enough to do the trick by themselves. So, these tricks are obsolete. Plus, you have to remember that ++i first increment i before test, and that i++ increment after the test. (okay correct me if my 20+ school memories are wrong) And if these reasons were not sufficient, we don't program any more in 4K with 16kHz CPU. Therefore nowadays readability matters **much** ***more*** than premature stupid optimizations (that I still do because ... I learnt coding this way) 
Okay thanks everyone, I wasn't sure what kind of feedback I was gonna get but everyone was helpful. I been going at it a few days now on the python tutorial site where you download the command prompt from and it's been helpful but I haven't made that connection to real world applications from what I have learned yet, I'm excited for that part to kick in!
Perhaps I spoke too dogmatically, just speaking from my somewhat limited experience. Why are CPython extensions necessary for these use cases? Your post equate C integration with CPython extensions , but there are other ways to interface with C code. PyPy fully supports ctypes, Cython support is in progress and there's even a new simplified FFI API under development. What is wrong with using these tools going forward? The embedding issue is a concern and frankly I don't know a whole lot about it. I do know Lua has managed to have a lightweight interpreter and optimized JIT coexisting for quite a while so I don't see why Python should be any different. 
I'm prepared to undertake that study. Edit: After much research, it's around 10%. [Here was my favourite in the 100 I downloaded (SFW)](http://i.imgur.com/BxzKZ.jpg).
 for n in repeat(None, count): had me scratching my head for a while. Is it because it's a bit faster than using range or xrange? Vaguely remember some article saying that. That doesn't mean use it though! Articles like that should be viewed as pointing something out interesting about the language and its implementation, *not* as good practice. Remember, "[Premature optimisation is the root of all evil](http://c2.com/cgi/wiki?PrematureOptimization)". Just use range/xrange, it's far more explicit.
Not really related to any feedback but, check out http://randomgur.com/ might serve as some inspiration?
&gt; the "project from the owners" would be PySide, not PyQt. &gt; The original developer of Qt was Trolltech So you knew you were wrong in the previous post. I bet you work at Troll-tech. ;) Obviously I was referring to the PyQt project when I wrote "Qt project", but you had to troll didn't you.
''.join([random.choice(CHARS) for x in range(string_length)])
''.join([random.choice(CHARS) for x in range(string_length)]) ?
&gt; Why are CPython extensions necessary for these use cases? You've split the right hair. In many cases I talk about "C integration", and people naturally hear "wrapping legacy C code". In reality what's almost just as important is the C API of the CPython interpreter. This is frequently exploited by extension modules so they can programmatically create and manipulate high-level objects from within lower-level code, so they provide a nice scripting layer *that can be controlled from the lower level*. It's not quite "embedding Python" *per se*, but it's similar in spirit. Neither ctypes nor CFFI (which looks nice, btw) address this problem. They access existing C libraries and lift things out of them, but they do not address the problem that the actual runtime is rather opaque to external programs.
Win32 is fine with using the forward slash as the path separator, so just get rid of that code. If you really want to be portable, use the routines in `os.path`, don't detect the OS yourself. 
Now that makes a lot of sense. You might get a better response from the PyPy team if you phrased your criticism in that light. I know ~~there~~ their argument was, we cannot support the C API with good performance so we're not going to work on that too much. You have a solid counterpoint, that you're concerned about integration more than performance.
Could you explain the reasoning for 4 spaces over a tab? Seems really strange. I've only just started playing with Python, is it some quirk of the interpreter?
Sure but why define CHARS when you have [the string constants](http://docs.python.org/library/string.html#string-constants) and why loop over random.choice when you have [random.sample](http://docs.python.org/library/random.html#random.sample)? I was just saving some memory and processor time.
they're actually going to add (unused) type declarations to variables. The idea being a code like pypy can take advantage of it.
Or name then: print("Number: {zeroth} Type: {onend}").format(zeroth=HOW_MANY, onend=TYPE)
Nokia bought Trolltech. Everything he said was correct.
White space does matter for the interpreter, and mixing tabs and spaces (different editors) causes problems, but choosing one or the other is down to personal preference or style really. The official PEP8 linked above somewhere has the preferred style, I think.
you should consider submitting this to /r/tinycode 
The most common way to satisfy PEP8 and not drive yourself crazy at the same time is simply to set "tab = 4 spaces" in your text editor.
i wrote a similar script to download some audio files from the web i found this [this tutorial from IBM](http://www.ibm.com/developerworks/aix/library/au-threadingpython/) to be really helpful. it shows an easy way to use threading and urllib to speed up something like this heck maybe i'll take a crack at a threaded fork
this script would be a great way to find content with which to karma-whore post that to /r/pics with a half-decent caption and you'll be rolling in fake internet points!!
Thanks, should be an interesting read
just added this to ipython: https://github.com/ipython/ipython/pull/2131 enjoy! :)
in particular, which os.path functions are you referring to? seems like there is a more 'pythonic' way to be doing this? thanks for the feedback
great call, i'm lazy and don't want to hit space 4 times for every indent :)
I've heard good things about the book, "Python Programming: an introduction to Computer science", by John Zelle. (ISBN: 978-1-59028-241-0) It covers Python &amp; basic programming in general. Aside from this, the Python website has really good resources about the language. (And of course, check out the links on the sidebar for this subreddit!)
the elegance, it is... strangely arousing :D okay so i'm a big nerd!
It's worth noting that [future versions of Python](http://docs.python.org/dev/whatsnew/3.3.html) (starting with 3.3) should be getting their own version of [Virtualenv](http://www.python.org/dev/peps/pep-0405/). I also recall hearing that future versions are going to get some kind packaging system like PIP that downloads the packages from the web (but I can't find a link to that now).
Cool, learning a lot from this post, thanks.
This is definitely ideal, or you could still "construct" the path yourself but use `os.path.sep`, which will be equal to the proper path separator for the platform running the code.
A beginner is better-off learning the basics before moving onto list comprehensions and generator comprehensions. While it's nice to condense code, it's a burden to go back and read older code when you're still on the upward tail of the Python learning curve. Otherwise, why not just write it in perl?! :-)
Who is they?
Man, I don't need convincing that Python is good (I'm a Python core developer). I just mentioned a possibly unfair comparison in the article.
MySQL administration is a little bit easier than that of PostgreSQL. Same goes for PHPMyAdmin compared to PHPPgAdmin. Or at least they used to be (I switched and haven't looked back at MySQL for years now) and that why MySQL is so popular in shared hosting environments. I guess for simple stuff that doesn't go beyond the Django ORM, like a small blog, MySQL will do fine. Hell, maybe SQLite will suffice. (Disclamer: I hate MySQL, it's like the PHP of databases)
I'm very interested in getting some feedback on this. Logr is the first project I've released publicly so constructive feedback and feature requests are welcome. An example site can be found [here](http://high-summer-5107.herokuapp.com/).
I actually really like this, and I'm just barely startng to get into python.
Unless your site gets a lot of traffic and you don't use memcached you won't notice any advantage by choosing one database over another. If your site gets a lot of traffic you will need to learn how tune whichever db you choose. I have used just about every major commercial DBMS and for my own projects I use Postgres. Oracle is solid, but overpriced, they nickel and dime you to death. DB2 is a great alternative in the enterprise. The NASDAQ runs on SQL Server which has a proven record as well. MySQL is workable, but transaction support is not available in all engines. My other issue with MySQL is Oracle. I don't have much trust in the company to do the right thing.
Looks interesting. &gt;I set out searching for my perfect blogging platform and found nothing that met my needs Did you come across Pelican? The only difference, AFAIK or can tell, is your solutions parses the markdown files each time they are requested and Pelican sites are generated once each time the site is "published". Is that right?
Wow, paranoid much? I'm not the same person, I promise you. Here's what happened: Trolltech made Qt. Riverside made PyQt. Nokia bought Trolltech, including Qt. Nokia changed Qt's license to the LGPL, making it free for almost everyone. Riverside kept PyQt under GPL/commercial, so people still had to pay if they wanted to use Qt in a non-GPL Python program. Nokia decided to make their own LGPL version of PyQt, and they called it PySide. So, if you want a Python library based on Qt from the makers of Qt, you want PySide. PyQt was and is a third party add on to Qt. 
Forked, having some fun with it now. Also might be worth including `pip install Flask-Markdown` in requirements.txt
It's mostly that everyone agrees what a space looks like, and not so for tabs; and many text boxes on the Web won't even let you type tabs. Standardizing on spaces makes it easiest to share Python code that other people can use.
I created a Python module for Pyramid that does a lot of this about a year ago. The only difference is that you can hang it off of a URL on any given site, and if you CNAME and site to where it is hosted - it will automatically create a new site for that URL. It's just a pluggable app for Pyramid. The process is like this: - CNAME example.com ip_this_is_hosted # Route DNS to your IP - wget http://example.com # Create initial pages - git clone git@example.com Sites/example # Clone your site's MD files Now you update the site as usual with git, and push when you've created your new md files. I also wrote this in node. - https://github.com/LimpidTech/node-wiki - https://github.com/LimpidTech/pyramid-flatpages A lot of other people have done this sort of thing, so I think that maybe looking a bit harder would have found you some solutions. EDIT: formatting
Upvote for Requests. If I could only have one Python 3rd Party Library for my entire life, that would be it.
What differs this from pyblosxom?
The performance should be slightly better, as long as you index them (and not listdir every time), but then you should only treat them as read-only, since python's file.write is not ACID.
Some points I didn't see mentioned: * **never** *except:*, always catch a specific exception or re-raise (unless you're writing a general exception handler, in which case *except Exception as e*). * *with open(filename)* is a good shortcut, and in fact better than your version since it would also *close* on error. (you could mimic it with try-finally, but *with* is nicer) * use *os.path.join* instead of just adding strings
Kivy is weird. I've spent a few hour trying to get it working, but it seems very unpythonic. Also, you need to learn Kivy syntax to build the GUI layout. I wish them well, but its really not for me.
I made my own blog engine in Python, too, but decided not to release it, since I can't really be bothered with all the feature requests I'd get if people started using it. And if people don't start using it there's not much point. It's similar to the OP's in that it, too, uses flat files on disk as the source, rather than a database, but it produces static HTML. [Example](http://www.garshol.priv.no/blog/).
but if python turns out fast enough that you don't need to go to the lower levels for speed, why would you go there to begin with creating and manipulating high level objects in python is way more pleasant than doing the same in c personally i would always prefer going for a faster/better python interpreter than going for writing c code
I'm not thinking about design so much as having a traditional page layout. You know: banner on top, navigation bar on the left, useless crap on the right, and a list of posts with headings and teasers in the middle.
Flask is great for apps that aren't going to have a lot of traffic. If you're working on a project that will need to scale, consider Pyramid or Django.
The performance in the current version isn't very good. I'll add it to the Roadmap and fix it when I get a chance. The thing is that this app isn't meant to scale. If your site is getting enough hits to make performance an issue, Logr isn't for you.
Done. :)
Nope. I haven't used PHP in years and I didn't even use it much then.
That kind of defeats the purpose of the project. I want to keep all the crap out. ;)
All you have to do to change the look is write the CSS. Currently, the project makes use of Twitter Bootstrap, but I intend to add a variable to `config.py` that will determine which CSS file to use. That will allow easy switching.
I have a quick and dirty version running in screen, I like what you have done, is a really good building block, takes a lot of the hard work out of it. Cheers mate, take my karma! [linkey](http://valdrek.net/)
EDIT: Nevermind, found your repo on GitHub. Very nice work! I'm going to include some of this stuff in the repo, if that's alright with you.
Fine with me, If I was making modular changes I would be spamming you with pull requests \^_^ By all means, I am quite interested in this project, once I get back on my dev box I will have to start coding in an IDE :D
The emulator is included in the Android SDK.
It's my personal favourite, and I'm sort of new too.
Yeah. It could be made to work on windows if you replace the `mprotect` call with the corresponding windows API function (or this could be left altogether out on older OSes, or if you disable DEP). But the string is x86 machine code for a function that adds one to the argument, so will only work on x86 (or x86-64).
Yes, but it also means you don't have to worry about trailing and leading slashes, and you won't get more than one slash by accident.
Most will even let you customise exactly how many spaces to substitute for tab. I've never seen a reason to change it from 4.
Flask is meant to be very lightweight. Because of that, it doesn't handle a large number of collections as well as a more heavy-duty framework such as Django or Pyramid would. Furthermore, projects that need to scale well are generally much more complex and you stand to benefit from all of the add-ons that Pyramid and Django have to offer.
I was JUST writing a static blog using Tornado (still might), but this looks pretty cool. I love the simplicity. Thanks Edit: I just read through the code and I like it a lot. Would you open to some simple suggestions (I may pull later after I actually play with the code)? The first thing that came to mind is to move the listing code found in the index function to the utils.py file so that it can be reused in templates. I have an experimental design that I think would be cool to use for the platform (I'm going to use it), check it out here: http://jsfiddle.net/EmEhRKay/pktZ4/ (still working out some kinks)
TrollTech was the original developer of Qt. Riverbank made the first Python bindings for Qt, called "PyQt". It is available under a GPL, or under Riverbank's commercial license. This is how Riverbank makes its money. Nokia purchased TrollTech. They approached Riverbank, asking if they'd release PyQt under a LGPL. Riverbank declined, since that would destroy their business model. So Nokia started the PySide project, which is Python bindings for Qt with LGPL.
Well at my former job, I wrote a master controller program in PyQt that used Qt's networking to query our webservice and determine if the user's license fee was all paid up. If so it would invoke the Adobe AIR main program. If not it would direct the user to the company website so they could pay up. 
And don't forget Qt's localization features. I wrote a couple of apps in PyQt at my former employment. Suddenly we were informed that the apps had to be both in English and in Spanish. With Qt's localizer program, it was a snap to run off a list of the labels in all the GUI elements and dialogs, send it to our translation service, and slot the translations into place.
There's no way it couldn't be automated.
What's the license on it? Please include a LICENSE file with the text!
Here's a bit of a shameless self plug for my own blog post, but I've covered a lot of the advantages of Postgres. Its not necessarily a why postgres versus mysql or other db, as some databases do have some of these features but none that I know of have all of them (craigkerstiens.com/2012/05/07/why-postgres-part-2/). In general postgres over mysql: Postgres has near instant column addition Concurrent index creation Better query planner Extensions Foreign Data Wrappers
After dealing with unicode errors for years, core Python devs made... Python 3.
I am just going to throw this out there; Are you using an arduino? You might want to look into [processing](http://processing.org/). Example, [here](http://www.arduino.cc/playground/interfacing/processing). If you are looking to pick up python, there are ways, but like /u/brutenta said, it might be difficult depending on what you want to do.
[must... resist...](http://i.imgur.com/CAFhV.gif)
Jesus, I *hate* dealing with unicode crap in Python 2. It's almost enough to make you want to switch...
I think what he means is that if you have experience programming Arduino then Processing is a very similar language that you will already know. However, even if you don't have experience with Arduino, Processing is still probably the easiest programming language. It is limited to graphics and media-type stuff. But if that's what you're doing, you can make some cool demos with only a few lines of code and no idea what you are doing.
`from __future__ import unicode_literals` Maybe?
Check PM
I too thought it was going to be a blog about writing clean (i.e. minimalist) python code.
The core developers have switched. The community as a whole? Let me put it this way: when Guido asked who uses Python 3 in his EuroPython 2012 keynote only 5-6 people out of a few hundreds raised their hands.
Problems with unicode, is most devs are under brained and confuse char, glyphs, char*, bytearrays, streams, files, encoding, decoding, string, utf8, utf16, unicode, BOM ... ... and don't care about learning. Well, we have a problem in all the languages with unicode. Because it is indeed not trivial. From the string you get in input to the string you print there are multiple abstractions involved. I dare say it is easier to handle unicode in python than in Perl 5.8 or PHP, or C. If you can't handle unicode, search yourself a job as a janitor because it is one of the most painful and frequent bug with time/date handling in all code (mine included). 
This is a very insightful article, the analogy helped me to understand the issues better. Thanks for sharing!
I switched immediately, but only because I use Python for personal projects and can trust myself to fix anything that breaks. I did it just in time, too, because my actual workplace has an app where some people are using the US-ASCII version and some people are using the UTF-8 version, and my scripts know the difference and never get confused.
What the fuck is complicated about QtDesigner. You literally draw the fucking GUI with your mouse. Stop spreading FUD you god damned noob.
I looked into wxPython and PyQt. Frankly, wxPython is too Win95 for me. PyQt is just the more modern framework. For simple GUIs, it probably does not matter, though.
We really need a fucking sticky because this question gets asked daily. TL;DR Qt/PySide/wxPython !NEXT!
[It's coming](http://www.blog.pythonlibrary.org/2012/05/24/wxpython-for-python-3-is-almost-here/).
Sure, here's just a few: * MySQL has a very poor optimizer/planner - so many queries will run very poorly, you'll often have to waste time tweaking queries or simply giving up on some complex ones. These same queries would work perfectly fine on postgresql, orcacle, db2, or sql server. * MySQL rewrites tables when you change anything on them, Other databases like Postgresql, etc, etc allow you to easily change the table in place. On a big table this might mean the difference between a 10-second change and a 10-hour change. * Postgresql, DB2, etc allow you to change the type of a column without rewriting the table. MySQL does not. * MySQL tends to ignore errors - silently truncating digits that won't fit into a column, accepting bad dates, failing to use the transactional back-end, etc, etc. This can make it easy to develop since you simply won't see errors. But it can kill you later when you realize your data is garbage or you didn't really have the ability to rollback a transaction. Postgresql, etc would not do this. * MySQL has a vast array of bizarre bugs &amp; gotchas that Postgresql, etc don't have. * Prior to implementing transactions, partitions, views, subselects, triggers, etc MySQL AB stated that 90% of developers don't need that stuff. When they finally did implement these essential features they just seemed to slap it together and the resulting implementations have a ton of rough edges. Postgresql, on the other hand, has an incredibly high-quality code-base. Those guys just don't ship code like this. * Postgresql's licensing is unambiguous and clear on its use. MySQL's dual licensing was designed to push as many people towards licensing as possible (tho it may be better now). MySQL made a lot of sense as a database choice around 1999-2001. And it still has a lot of market share. But it's completely outclassed by Postgresql. 
Bull. The Python core developers have switched, but you're implying that the people actually using Python to write their own programs have switched and that new code is very rarely written in Python 2. This is factually incorrect. Code written for Python 2 is not legacy code. It's still the norm. 
Third party libraries have been pokey in porting their wares, so people with projects relying on older libraries are sticking with 2 for the time being. This has only been an issue because Python 3 isn't backwards compatible. There are automatic converters, so maybe someone else can enlighten us on what the hold up is...
Most people just want everyone else to do the work.
In visual-studio you just klick and drag your widgets to your application. Double klick them for apply code and that is it. With QtDesigner you have to manually set the signals of your widgets, and then you run a external program to genertate some code. After that you gave to manually connect your widget signals. 
i am a poponent of replacing code fragments with more maintainable versions whenever possible
I'm glad I'm not the only one who does the happy mouse dance when I finally get something to work! I had to make my mouse dance along!
&gt;If your site is getting enough hits to make performance an issue, &lt;insert project name&gt; isn't for you. Isn't that tautological? The only difference between projects being the number of hits before performance becomes an issue.
That is better, editing my post. Thanks
Practice putting this at the top of every method: assert isinstance(spam, unicode) Then, remove anything that looks like this from your code: str(eggs) Finally: from __future__ import unicode_literals
Oh :( I thought you were starting an r/PyLadies 
bytes objects are a pain (supposed to be better in python 3.3) dictionaries of different key types are not sortable writing files that SHOULD be ascii is harder than it should be. documentation is lacking on the ascii to utf transition. that's the biggest problem i see.
I actually had the same idea! It allows for easily showing the article list on every page. Feel free to check out the repo, it's in their now.
omfg... And I always tough I don't make the change because I'm lazy... Now I have a REAL reason!
I did exactly the same thing a year ago. I would advise diving into the SQLA's SQL Expression Language as well, as there are a number of useful tibbits you can add yourself there. For example, this crude bit of code: def dict_to_where(table,d): ''' given a table and a dict, the dict is filtered for keys only in the table columns and then looked up in table to be returned as a column object and then compared with the dict value corresponding to the key ''' def each_key_val(key,val): if instance.is_iterable(val): return table.c.get(key).in_(val) else: return table.c.get(key) == val return and_(*[each_key_val(k,v) for k,v in d.items() if table.c.get(k,None) is not None]) 
...is there interest?
I could be wrong but I don't think there are enough women to make a python only coding forum. However, there might be enough demand for a women's coding (in general) subreddit.
that's what I thought; not a lot (yet) out there to be python specific. a dev chix/code chix/women who code subreddit is not a bad idea, though!
But what IDE should I use best? :-)
I am doing more of an OOP code. In your code when you have just one var to print in a string (using %) you don't need the brackets eg: def work(name, place, shops): if place in shops: print "%s got the job!" % name Or even simpler if the variable is at the start or end: def work(name, place, shops): if place in shops: print name , "got the job!"
does anyone know the cost to register?
myconnpy is written by an oracle employee and works fine on python3.
The best solution I have seen is to have a bunch of unicode data you can run through to see if your code breaks. And then fixing every error that appears. It is a very poor solution, but if you have a good dataset you can find most problems pretty quickly.
I wish I had more than one upvote to give this comment. I started using Python the day Python 3.0 zero came out and have been extremely impressed by the Unicode support. Python 3.3 is shaping up to be fantastic.
You have been lied to then. Strings are information. What computer handle are data, series of plain numbers. As an engineer you are supposed to be able to make the difference between data (what the computer handles) and information (what the human can make sense of). The process is like a plant where you have to process a series of atoms (number with a the 8thbit eventually == 1 it if it utf8) (and we chose bytes not to have the endiannes problem but utf16 exists) in series of molecule (chains of bytes making up an arbitrary long intenger) which is an offset in a table that points by convention (there comes the "information part") to a glyph in the unicode table. Which by convention yield something we can read. Not being able to handle unicode is like not being able to tell abstraction from implementation, which indeed make my point since engineering is all about learning, understanding and applying simple processes and abstraction. Unicode is simple as long as you don't confuse data with information. Python 3 needs the user to hint him on what it is processing u"" (unicode), b"" (bytesarray), or "" (a view on a bytes array as an ascii string) since it cant guess. http://www.python.org/dev/peps/pep-3137/ Computer science is not magic, it is science the same input produces the same results, and a language in face of ambiguity should not guess. I do appreciate python 3 crashing when the developers' input are not qualified enough. 
Bzzt wrong. Creating a GUI app isn't purely for the interface. Come back when you thread that interface for me, boy.
why do you take personal offence when i express my view about the subject? You do not need to call me a noob or parrot or what ever to argue with me. 
There are no opinions in an objective discussion.
Once we're out and away from a conference, our priority should be to discuss and educate. Stressing enforcement of CoC is important, but I think open discussion and spreading acknowledgment is much more. Especially since discriminations in CS doesn't happen only at conferences...
Only if this questions is asked every other day ... :-) If you read reddit regularly you'll become a bit tired of those two questions (about GUI frameworks and IDEs).
Leftwing rhetoric is so fucking confusing. I thought we liked "toleration." But, it turns out that things aren't that simple. We also have to study up to find out who the commissars are classifying as "assholes" this week. I'm sure these are very sophisticated, open-minded individuals. But, let's just be candid: Asshole == disagrees with them
Nope, it used the PyPy toolchain. Written in RPython (Restricted Python), which compiles into C, and the JIT generator.
`chcp 65001` Which does not gurantee 100% work. You need special fonts in order to display most of utf8 characters.
I don't want to run the files with the script, there is a program in the folder that I need to run them with and I'm hoping that Python will make it easier to run all of those files with that program(if that's what you meant). If you have ever installed .Sims3Pack's into Sims 3, you need to run them through the decrapify.exe and s3rc.exe before you install them with the Sims 3 launcher, this is what I'm trying to do.
If you know the list of file names beforehand and they are regularly named you could iterate through them and send them to `subprocess`.
They all have the same extension, would this work the same way?
What exactly is the point in in this? The syntax looks a bit unnecessary.
Think I'd just stick to python unless there is a real incentive to use a new syntax.
Ok - off the top of my head (also, drunk as fuck) which functions in the OS module will let you do this. But I think, *think* there's something like `os.listdir(dir)` where you pass it a string which is the directory you want to list and it returns a list of strings which you could then iterate over and check to see if they conform to the extension you want. You *may* have to learn something, I am *so, so* sorry.
Interesting. Have any non-tiny programs been written in it? I use shell piping all the time, but never for anything big.
You can use [glob](http://docs.python.org/library/glob.html) or [fnmatch](http://docs.python.org/library/fnmatch.html) to filter the files according to a pattern. Take a look at the snippets from the documentation.
Python 2 has built in unicode support - [from Python 2.0](http://docs.python.org/whatsnew/2.0.html#unicode), released in 2000. But it tried too hard to make it easy to mix 'normal' strings with unicode, contravening "errors should never pass silently". Python 3 didn't *add* unicode support, it made it easier to use.
That's rather unfair as fixing unicode support was one of the bdfl's main concerns when coming up with python3.
Cool. Do you have your mixins available? Also, can you give me an example use case for the code you copied in?
I would guess that this will mostly be used for people hacking python together to do some data analysis. Just my guess.
Click on tutorial and scroll down to the multiprocessing examples. Seems pretty useful there.
You're not hurting my feelings by suggesting something better; there's no need for the passive "kinda" and ellipsis. Be confident in your response! In any case, I had no idea about Hachoir. The features seem impressive, but I'll be damned if I can find any examples or decent documentation on how to use it =/ In my search for code, I found a [bug someone filed about the lacking docs](https://bitbucket.org/haypo/hachoir/issue/14/lack-of-examples-make-introduction-to), which did lead me to [one example](https://bitbucket.org/haypo/hachoir/wiki/hachoir-metadata/code). I wrote newstructs to read in bytecode files for a VM, but I'd rather use hachoir if I could pick it up quickly.
If there's a drop-in replacement available for a package, or no python3 problem at all then the listing is green. E.g. multiprocessing, unitest2, simplejson. Is there a drop-in replacement for MySQL-python?
1. sure, but you make other annotations, as well, like the small triangles where pypi is wrong. but django WILL eventually be on python3, so it’s no big deal. 2. cool! how do you want to count them? because they aren’t real big projects, just plugins, but on the other hand, they make the projects they belong to bigger than the rest. 3. to be exact: pyramid is pylon’s successor on both python3 and python2. it is essentially repoze.bfg with a pylons compatibility layer. PS: thanks for making the site! i like it, and its effects, no matter above gripes.
I believe tkinter ships with python 2.7 so if you want to use the standard lib then his might be better for you... But it looks like arse and it's not as easy to learn as some of the others mentioned here
$25 before September 1, $50 after that I had to register on the site to find that out :/
Just letting you know I also disagree with you and think you're an asshole for not shutting the fuck up and accepting you're wrong :)
Concerning number 2 I actually haven't yet thought it through completely.
Is / will there be a way to view submissions?
Feedback for submission proposals can apparently be found on the mailing list [at the following location](http://mail.python.org/pipermail/pydotorg-www/)
No, I mean in terms of getting stuff done with a programming language -- doing actual work -- python is already highly productive. So I'd prefer to just use python unless there is a powerful incentive to use another language/syntax. I don't mean to stomp on the author of Pythonect but I don't understand the purpose.
I must have misread the [RFP.](http://pythonorg-redesign.readthedocs.org/en/latest/index.html) Specifically, &gt; Bidders should feel free to ask questions of the current maintainers or discuss their proposal before final submission by posting to pydotorg-www.
&gt; There are many studies that support this point This is the point I want expanded, where can I find these studies? &gt; How does this make you feel? I'm not sure that this comparison is so great. Are sex and race really that comparable? Does it really matter what I'd feel? I think I'd still think twice before starting a 'whites-only' basketball team.
Just wondering, did you see ZopeSkel/templer/paster create?
I've never used Py2App, but I have packaged a couple of PyGame projects with PyInstaller. It's pretty much as simple as `python pyinstaller.py nameofproject.py`. *aaaand* you're done! ;) Might be worth checking out if you can't get Py2app working. 
Grr.. Lucky Ohio and Texas! Anyone want to start a PyFlorida event? 
+1 for sqlite give it a try before jumping into MySQL or Postgres. SQLite is very capable for many needs.
fair enough. every kind of weighting you could apply here would necessarily be subjective.
&gt; killing iteritems and itervalues doesn't help write compatible code. i could use items, but that's get translated to a list(dict.items()). i don't want to support python 2 and 3 separately and i'm certainly not going to redefine dict. Just use `items` everywhere and forget the translation. Perhaps skip the `dict` fixer if you don't want it translated.
I've always read to use bcrypt over SHA-512/MD5/etc (I think primarily to make brute force attacks less feasible), but this looks useful (and that'd be an easy switch). Small detail though, I'll admit cryptography isn't my strong suit. Thanks!
Awesome. I agree that you should be able to host plugins in any repository--I don't intend to enforce any specific one, so anyone can use Git/Mercurial/SVN to host plugins and licenses. But I'll be creating a Git repository that will host the most basic--ScaffLicense and ScaffPlugin, plus the GPL family, MIT, Apache, and BSD--for simple download. I haven't built documentation as much as I'd like, because I'm not yet confident it could be useful...call it "intentional barrier to entry". My sole purpose right now is to make sure it works well :) this is also why I'm not on pypi yet. I had forgotten about package and module names, but thanks for the reminder. The really troubling part of this, for me, has been the "automatic" way I load plugins and licenses....it's really quite hackish. Anyway, thanks very much for your feedback, I'll hop on and work on it after my morning ritual :)
Already done.
Guys, guys, these are all terrible. Regular expressions are cool. Clearly the way to do this is with regular expressions. Also, you want to store everything in tuples instead of lists because tuples are more time and memory-optimized than lists. def i(x): import re n = re.compile("(\d*(\d))(\.\d*)?") m = n.match(str(x)) r = tuple() if m.groups()[2] != None: r = tuple(list(r) + [c for c in m.groups()[2]]) while m.groups()[1] == '9': r = tuple(['0'] + list(r)) if len(m.groups()[0][:len(m.groups()[0])-1]) == 0: r = tuple(['1'] + list(r)) break m = n.match(m.groups()[0][:len(m.groups()[0])-1]) if m.groups()[1] != '9': if m.groups()[1] == '0': r = tuple(['1'] + list(r)) elif m.groups()[1] == '1': r = tuple(['2'] + list(r)) elif m.groups()[1] == '2': r = tuple(['3'] + list(r)) elif m.groups()[1] == '3': r = tuple(['4'] + list(r)) elif m.groups()[1] == '4': r = tuple(['5'] + list(r)) elif m.groups()[1] == '5': r = tuple(['6'] + list(r)) elif m.groups()[1] == '6': r = tuple(['7'] + list(r)) elif m.groups()[1] == '7': r = tuple(['8'] + list(r)) elif m.groups()[1] == '8': r = tuple(['9'] + list(r)) r = tuple([c for c in m.groups()[0][:len(m.groups()[0])-1]] + list(r)) return eval(''.join(list(r)))
My impercise solution is a little late, but: python -c "import random,sys;g = lambda x: x+int(str(2^(2*random.randint(1,sys.maxsize)))[0]);print g(1) # might output 2" It uses [benford's law](http://en.wikipedia.org/wiki/Benford%27s_law) to add one most of the time.
I haven't made my mixins available cause i'm crap at things like github. I should maybe signup thought and contribute. In terms of a use case. Image you have frequently changing where conditions, for example, users setting their own through a web or mobile interface. You might extract these into a dict, for example {'course_type' : ['sociology','history'],'period' : 4, 'campus' : 'central'}. My function would turn that info "where course_type in ('sociology','history') and campus = 4 and campus = 'central'"
Thanks, typo
no
yes
RTFM
Although it would be nice to know, but what you said in your next post "but django WILL eventually be on python3, so it’s no big deal." regarding #1 is silly.. MOST of these will eventually be ported - that doesn't help me right now to switch..
https://github.com/hasgeek/lastuser The application is written in Flask. Disclaimer: I work for [HasGeek](http://hasgeek.com), company behind lastuser. 
re bonus slide: "init"
Downvote because it's behind a login wall. Please post universally accessible documents when possible.
yep. That's what I was thinking. It seems rather easy to misplace a bracket in the spaghetty of code. It would really profit from a gui ala labview. But once it works from text it should be easy to write a parser for that.
No need to swear to him. But yeah the docs are generally quite clear if you ask me. If anything is unclear try Googling specific questions or asking on IRC.
This could help you: https://bitbucket.org/illume/skellington2011 If you set up your game with this directory layout you should get it working for most platforms (windows, linux, android, and mac). There's likely a few issues with that, but it has worked for me in the past... so will probably get you 90% of the way there.
Indeed, lack of documentation is a problem for hachoir... Although it does have a fair number of examples here: [https://bitbucket.org/haypo/hachoir/src/9f8d5e37a878/hachoir-parser/hachoir_parser](https://bitbucket.org/haypo/hachoir/src/9f8d5e37a878/hachoir-parser/hachoir_parser). I'm also not sure if it's still active, there was only one trivial commit in 2012. 
Nice article. Its good to see that Python is starting to make some strides in improving its concurrency. I'm also curious to read about the significant changes/improvements to the GIL, which is briefly mentioned in the article, but I couldn't find anything useful. Any ideas?
I think I came off wrong, friend. We've had a few fierce ones around here but I was jesting. Sorry. :)
Insulting me and my ideals (as you are wont to do), using clearly sarcastic tones, and congratulating me for, essentially, not descending into utter failure, seems hardly a jest. The "freetard" insult is particularly insulting because of my personal connections with several mentally disabled people. I don't keep diligent track of every conversation I've had on Reddit, but in this instance, you don't particularly seem a friend.
There's a link in part one to David Beazley's page on the GIL, which contains links to just about everything you could ever want to know. I think there are further links, either in his blog posts or in the comments on those posts, to very lengthy mailing list discussions (wait, I found it http://mail.python.org/pipermail/python-dev/2009-October/093321.html)
I'm sorry it turned out that way, but not using the term "freetard" at all might have gone a long way to helping me understand.
* [Inside the Python GIL](http://www.dabeaz.com/python/GIL.pdf) * [Understanding the Python GIL](http://www.dabeaz.com/python/UnderstandingGIL.pdf) * [Inside the new GIL](http://www.dabeaz.com/python/NewGIL.pdf) Author: David Beazley
I think we've derailed this enough. Vocabulary aside, I agree with you. I say we delete these posts and get back on with what the thread was supposed to be about.
I can't say for sure. I don't pretend to be an expert on the GIL; I've just had to do some research about it for my own peace of mind. Unless I'm mistaken, though, the very long thread linked above contained mentions of the GIL interacting poorly with I/O under at least some conditions.
TIL that setting the OS locale is a hoop. 
Before the changes to the GIL made by Antoine Pitrou, there were perverse behaviours both between CPU-bound threads and between CPU- and I/O-bound threads. Since the changes made by Antoine (discussed in [this presentation](http://www.dabeaz.com/python/NewGIL.pdf) by Dave Beazley) the behaviour seems to have improved overall, though problems could always emerge with particular workloads.
Worked for me without logging in to Google.
What you're missing now is (1) experience with software engineering (design patterns and whatnot) and (2) the appropriate libraries. If you're trying to be a game developer, you should check out pygame for all your 2d graphical needs. You should also head over to /r/gamedev.
Try picking up PyQt.
"How could you not know where you're going to add something before you add it? Are you an idiot?" "Well, yes I am an idiot. But more importantly..." That gave me a good laugh
A couple of questions. 1. Does an applicant **have** to have paid experience coding with Python? Or will a long-ish history of non-trivial, but hobbyist, experience be considered? 2. I noticed you were located in Toronto. Is Canadian citizenship a requirement? Is residence in Ontario a requirement? Thank you for your time.
We posted on Djangojobs.com recently and got some hits, and also did a bit of people-shopping on people.djangoproject.com—but that was for Django (duh). Is there something similar for Pyramid out there? I'd suggest a posting on Python.org but I don't think anyone ever reads those. Edit: Sounds like fun; do you hire often? I'm not looking now (and would probably be interested in long-term part-time work if I was) but can I get a LinkedIn connection for possible future use?
Very nice. Well done!
You should look a little onto how Game Maker works. There you can learn the useful principle of creating the game out of object(use classes in python) which have a init function, a step function and a draw function.
do i need to know wxpython for pygame? 
Thanks!
Ok, this time I'll use a completely different variable name ... Ok ... Ummmm ... Uhhhhh ... Lessee .... "Bucky" - psych!!!
No.
I would also like an answer to the 2nd question.
Try http://programarcadegames.com
I've written a couple of free books to teach Python to beginners by making games. It has the source code to several small games (Tic Tac Toe, Hangman, etc). It was written pretty much for people in your position: Not only do you want to learn the different programming concepts but also how to put them together and what programs "look like". You can probably skip the explanatory text and just look at the source: Invent Your Own Computer Games with Python http://inventwithpython.com There's also a book that focuses on Pygame, which is used to make graphical games: "Making Games with Python &amp; Pygame" http://inventwithpython.com/pygame
Here's a full book with the source code to 11 games that use Pygame that you can read online for free: http://inventwithpython.com/pygame
I came here to say Bucky is a trip. I learned iPhone dev with his tuts. Check them out.
If it is something that is very simple, check out Enthought's [traits](http://code.enthought.com/projects/traits/). It can automatically build a GUI for you if you follow some rules.
Subscribed.
You should try the courses at Udacity, specifically the [Web Application Engineering course](http://www.udacity.com/overview/Course/cs253/CourseRev/apr2012) given by Steve Huffman, the creator of Reddit and Hipmunk. In this course we are basically learning to build our own blog from scratch. The most basic course they have is great to go beyond the theory and start challenging your knowledge with problems to solve with the goal of building your own search engine (or a base for it): [Intro to Computer Science (cs101) Building a Search Engine](http://www.udacity.com/overview/Course/cs101). It has an extension on building a role playing game in the notes and gives the source code to start, plus a discussion forum for the people who are improving and messing with the game. I've also watched Bucky's videos and they are awesome, but Udacity is making me work with exercises and a common thread to progress. 
I love your books by the way, thank you! :-)
IIRC github is not free for private repositories.
Thanks!
I don't know what's involved with trying to employ a non-citizen, but it's on-site only (no telecommuting). Paid experience is not necessary (neither is a formal education in Python or programming).
I may post it on the Pyramid mailing list. I put it on the Python job board, but I don't think anyone looks at it. Especially since it's just one very long page.
Why can't readthedocs.org be used for private needs? It seems that source code and install instructions&amp;scripts are available at github ( https://github.com/rtfd/readthedocs.org )
You should specify that this is for Toronto residents.
I'm in Europe and not interested in moving, but I would have some questions based on the ad: How many programmers are there? Is the programmer mostly autonomous, working by himself on all parts of the system from design to coding, or part of a larger team implementing designs made by others? Is sysadmin work on the sites part of the job? Will the work involve work on new software, or is it more maintenance of existing software? How is your company's focus on quality, do you use any of the following: TDD, continuous integration, automated deployment, code reviews, pair programming, a formal Agile process like Scrum, iterated development? What does the company do to improve the programmers' skills during the time they work there? If the answer is "we'd like to focus on that sort of thing more but we aren't there yet", how much influence does an individual developer have on changing that?
I've posted a video version of my game programming class (using Python) at http://de.cs.iupui.edu/courses/n451/ The course is based on a book I wrote, but you really don't need the book. All the examples are available to download from my web site: http://aharrisbooks.net/pythonGame/ Drop me a PM if you need any more help...
The thing is, that I don't want to have my ***closed*** projects on GitHub or Bitbucket even despite the fact that I can have private repos there. They would still be on a third party server which I can not control. And for the nice stuff you mentioned, have a look at [GitLab](http://gitlabhq.com/).
The `pbkdf2_sha512` function is not just a sha-512 hash. It is essentially equivalent to bcrypt. Here's a quick bit of information from the package site: &gt; Security-wise, PBKDF2 is currently one of the leading key derivation functions, and has no known security issues. Though the original PBKDF2 specification uses the SHA-1 message digest, it is not vulnerable to any of the known weaknesses of SHA-1 [2], and can be safely used. However, for those still concerned, SHA-256 and SHA-512 versions are offered as well. PBKDF2-SHA512 is one of the three hashes Passlib recommends for new applications. http://packages.python.org/passlib/lib/passlib.hash.pbkdf2_digest.html And you can read ~~me~~ more on the [wikipedia article](http://en.wikipedia.org/wiki/PBKDF2).
You can make your own docs builder using Buildbot or other similar softwares by yourself. What is your point? Do you mean Okydoky should be generalized to be used for more cases?
Very cool, thanks. I definitely assumed it was just sha-512.
I'm interested in using this, or at least trying this out. However this could be an obstacle to putting this into production: &gt; We only connect to a single memcached. &gt; We don’t support autosharding over slabs. Is that planned for the future? Anything I could possibly help with? My main concerns with a memcache client are (in this order): 1) stability &amp; reliability 2) speed / performance 
For my personal projects yes but at work I can only use our internal gitolite server.
Really? I'll have to keep it in mind next time I'm job seeking, then. Thanks!
Thanks, I've found that working with examples is really helping me start to learn. Drop me a PM if you need any more help...&gt; That was a foolish thing to say. Prepare to be bombarded with queries.
&gt;Each time I see a classmethod I feel uneasy: why not a module level function? because classmethods get inherited.
Some printers print can higher quality images smaller (higher resolution) like photo printers. I'm not sure how PIL could factor that in, if at all.
Convert a list into a list-of-lists-of-length n (ie, a matrix), while only iterating through the list once: zip(*[iter(a)]*n) Honestly, I feel like there has to be a more readable way, but it's straight from the documentation....
Have you seen this [Stackoverflow](http://stackoverflow.com/questions/473498/when-printing-an-image-what-determines-how-large-it-will-appear-on-a-page) post? 
Check out [this stackoverflow question](http://stackoverflow.com/questions/101268/hidden-features-of-python). Some excerpts: **Chaining comparison operators** &gt;&gt;&gt; x = 5 &gt;&gt;&gt; 1 &lt; x &lt; 10 True &gt;&gt;&gt; 10 &lt; x &lt; 20 False &gt;&gt;&gt; x &lt; 10 &lt; x*10 &lt; 100 True &gt;&gt;&gt; 10 &gt; x &lt;= 9 True &gt;&gt;&gt; 5 == x &gt; 4 True **yield statements return a value** def mygen(): """Yield 5 until something else is passed back via send()""" a = 5 while True: f = (yield a) #yield a and possibly get f in return if f is not None: a = f #store the new value &gt;&gt;&gt; g = mygen() &gt;&gt;&gt; g.next() 5 &gt;&gt;&gt; g.next() 5 &gt;&gt;&gt; g.send(7) #we send this back to the generator 7 &gt;&gt;&gt; g.next() #now it will yield 7 until we send something else 7
 &gt;&gt;&gt; a = 666 &gt;&gt;&gt; print type(a) &lt;type 'int'&gt; &gt;&gt;&gt; print type(`a`) &lt;type 'str'&gt; &gt;&gt;&gt; `a` '666' &gt;&gt;&gt; a 666
The object dictionary is nice. Here's some code that uses it: ''' def Select(SearchList = [], **SearchTerms): for SearchKey, SearchValue in SearchTerms.iteritems(): SearchList = [SomeObject for SomeObject in SearchList if(SomeObject.__dict__[SearchKey] == SearchValue)] return SearchList ''' If I have a list of objects with attributes Name and ID, I can search it like: Select(MyList, Name = 'Bob') or Select(MyList, Name = 'Bob', ID = 2)
No, it's repr(). This feature has been deprecated and is not a part of Python 3. Use repr() instead.
 import antigravity
Same for `isinstance()`
There are GUIs for postgres and some that work with multiple databases including postgres, but I haven't used them so I don't know which are good.
Transpose Array: a = [(1,2), (3,4)] zip(*a)
Yes, you can use the signal module to install a new handler or ignore that signal: import signal signal.signal(signal.SIGINT, signal.SIG_IGN) then set it back with signal.signal(signal.SIGINT, signal.default_int_handler) Check [the docs](http://docs.python.org/library/signal.html) for portability concerns and issues with threading though. beware.
The primary method would just be to wrap your main namespace code in try...except KeyboarInterrupt, as Python throws an exception inside the script whenever Ctrl-C is pressed.
[Chained comparisons](http://docs.python.org/reference/expressions.html#not-in]): &gt;&gt;&gt; a = 4 &gt;&gt;&gt; 0 &lt; a &lt; 10 True &gt;&gt;&gt; a = 0 &gt;&gt;&gt; 0 &lt; a &lt; 10 False 
That's very interesting, I'll try a test of this when I get a chance. Thanks!
I've spoiled myself with this.
 from __future__ import braces
this feature is little known because it's a bad idea. don't use it or recommend it.
Also remember both will break if you pass in something using slots.
Actually, it should compile. The comparison is done from left to right and the result of each part is either 0 or 1, both of which are valid values for the next comparison. So the expression 5 &lt; 10 &lt; 11 simplifies to 1 &lt; 11 which evaluates to 1. This allows for monstrosities such as if (0 &lt; 5 == 1) { printf("5 equals 1"); }
really?...awesome!!!
The built-in __import__() command can be hacked and manipulated in all sorts of cool ways. I wrote a rudimentary dependency-injection framework yesterday.
&gt; Do you mean Okydoky should be generalized to be used for more cases? This. At least this is what I thought your tool was about.
Speaking as a newbie - why is this a bad idea?
 del __builtins__ You all want to try it. Edit: misremembered the keyword. Using too many languages will do that to you.
The gc module. gc.garbage is a list of all of the references managed by the garbage collector, which is useful for debugging. If you're doing something that creates a lot of transient garbage or is latency-sensitive, you can gc.disable(), and manually gc.collect() when you have the time. Also, C modules don't have to hold the GIL if they're not touching python objects. And, of course, [eventlet](http://eventlet.net).
1. backticks look like single quotes; that's a big one 2. because of #1, the backticks were deprecated a long time ago, and will be removed in python 3; this compounds #1 3. readability counts - repr() is obviously, well, repr. it's not obvious what \` does. 4. special cases aren't special enough to break the rules - in other words, it doesn't get to be unreadable just because it's used for debugging 5. although practicality beats purity - I'd argue that backticks are not more practical than repr(), so it doesn't get to beat purity 6. there should be one - and preferably only one - obvious way to do it is that sufficient? :)
Muthaf***.... o_O
import this is just a shortcut to get to pep 20 ;)
Could you do the same on just the function and not the main namespace? Like just have the exception in the save_function. I'll play around with this, thanks.
Well, I guess you're right. Look at that.
 for i in list: if foo(i): break else: bar() Here's an excerpt from the docs: &gt; The for statement is used to iterate over the elements of a sequence (such as a string, tuple or list) or other iterable object: for_stmt ::= "for" target_list "in" expression_list ":" suite ["else" ":" suite] &gt; The expression list is evaluated once; it should yield an iterable object. An iterator is created for the result of the expression_list. The suite is then executed once for each item provided by the iterator, in the order of ascending indices. Each item in turn is assigned to the target list using the standard rules for assignments, and then the suite is executed. When the items are exhausted (which is immediately when the sequence is empty), the suite in the else clause, if present, is executed, and the loop terminates. &gt; **A break statement executed in the first suite terminates the loop without executing the else clause’s suite.** A continue statement executed in the first suite skips the rest of the suite and continues with the next item, or with the else clause if there was no next item.
 from my_module import my_isinstance as isinstance There you go :) Edit: (Hopefully sort of obvious): If you do this, please come up with another function name so its easier to understand what the function is doing different from the built-in ``isinstance``. You had a small gripe about wanting a function to do something just a little bit differently, and in a few lines of code pretty much implemented it. Now stash it in a module with the rest of your utility functions and just use it. No need to wait for the default implementation to support it.
I found an alternative to Notepad! EDIT: It's Notepad with syntax highlighting! del __builtins__ __builtins__.clear() EDIT 2: It only works in IDLE.
put `backticks` around text to make it not interpret it as markdown on reddit
or just python -m in general
never, ever, ever do this: herp = "derp" honk = "donk" doop = "{herp} the {honk}".format(**locals())
eventlet is neat but I've been looking into gevent a lot lately.
I know. And it's hardly a gripe, just something that I think would be cool.
All of the operators, all of the keywords. You can recover the types that have got literals (str = "".\_\_class__ etc); True = 1==1, False = 0==1, None still exists, but I can't find much else that isn't just a magic method wrapper anyway. Oh, and anything else imported before you did del \_\_builtins__
I really wish they had made `for ... else` execute the `else` block for when the loop didn't execute -- e.g., an empty iterable. For me, and pretty much all of the Python code I've seen, the pattern `if my_list: for x in my_list: ... else: print "my-list is empty` far more often than I've ever seen a good use for the current case.
Or even better: [sys.meta_path](http://docs.python.org/library/sys.html#sys.meta_path).
Hell yeah :) i am a huge bitbucket fan
I was telling you because it's a horribly useful bad idea sometimes :p
 from collections import defaultdict I use this all the time when I am building a dictionary of lists. For example, here's the obvious implementation: words = ['apple', 'agent', 'bob', 'barney', 'bazooka', 'cat', 'cathode'] d = {} for word in words: first_letter = word[0] if not d.has_key(first_letter): d[first_letter] = [] d[first_letter].append(word) for first_letter in sorted(d.iterkeys()): print '%s words: %s' % (first_letter, d[first_letter]) Okay, so that separates words by their first letter. Note this construct: if not d.has_key(first_letter): d[first_letter] = [] d[first_letter].append(word) The special case conditional is all but inevitable, though it can be implemented in several ways. This check can be slow when called many times. A more efficient version is this: try: d[first_letter].append(word) except KeyError: d[first_letter] = [word] This avoids the comparison by letting the key lookup (which occurs anyway) trigger the special case through the exception handling. We avoid adding an additional key lookup. But this code is kind of ugly and may have to be duplicated in many places. Instead, we can do this: from collections import defaultdict d = defaultdict(list) for word in words: first_letter = word[0] d[first_letter].append(word) Note that we don't have the extra conditional OR the extra try-except block. The `defaultdict` takes care of providing an empty list so we can append, even if the dict didn't already have it. It also makes the dictionary act more appropriately in a case like this: &gt;&gt;&gt; d['x'] [] We asked for the words starting with `'x'` and there were none. Rather than get a `KeyError` or need a special case that returns `None` or something, it returns an empty list. It's much easier to write code when you always get the same type (even if it's empty) rather than having to handle special cases like exceptions or `None`. The collections module also has a few other handy classes, including `namedtuple`, `OrderedDict`, and `deque`.
Also, set comprehensions: lst = ["abc", "abc", "afg", "akk", "bab", "daf"] print {s for s in lst if s.startswith("a")} No different from `set([some list comprehension])`, just saves some characters and looks nicer. And maybe it's faster too; not sure if the bytecode is different.
If you need a simple, built-in json pretty-printer, `json.tool` can be handy: $ echo "[1,2,3]" &gt; foo.json $ alias json alias json='python -mjson.tool' $ json foo.json [ 1, 2, 3 ] 
Yep, I prefer gevent's documentation and naming schemes. I think in the end you pretty much get very similar performance and functionality though.
And if you use IPython, you get access to a nearly unlimited stack of return values! In [1]: 4 + 5 Out[1]: 9 In [2]: _ Out[2]: 9 In [3]: _ + 1 Out[3]: 10 In [4]: a = 1 In [5]: _ Out[5]: 10 In [6]: _1 Out[6]: 9 In [7]: _2 Out[7]: 9 In [8]: _2 + _3 Out[8]: 19 If you're not using IPython, in my opinion, you're seriously missing out on a MUCH better interactive prompt!
Similar idea, using list comprehensions: &gt;&gt;&gt; [a[i::n] for i in xrange(n)]
The latter one is supported on Python 2.6, but the nice sugar starts from 2.7.x
HOW DID I NEVER KNOW THIS?
Look into the autoreload extension in IPython - it does similar kinds of black magic.
You and I have different ideas of what a "feature" is
Agreed. Django's For template has a for...empty construct that is much more useful than for else IMO https://docs.djangoproject.com/en/dev/ref/templates/builtins/#for-empty
Upvoted for contributing a little known feature, even if it's a shitty one :)
I think `dict_a.update(dict_b)` is more clear, but to each their own
This is not a recommendation thread, it's just little known features thread. I don't know why people downvoted this, looks like everyone knows it.
Common, this is the most used feature on the interpreter REPL, this isn't little known.
You can use parentheses to create generators: &gt;&gt;&gt; r = range(10) &gt;&gt;&gt; g = (i for i in g) &gt;&gt;&gt; type(g) generator &gt;&gt;&gt; g.next() 0 &gt;&gt;&gt; g.next() 1
Thank goodness for that
the dis.dis dissassembler for {...} is much shorter than the set([,,,]) solution.
if this is not a recommendation thread, then my comment indicating that backticks should not be used is not an indication that people should downvote you ;) as you were downvoted, it can be inferred that while it was not intended as a little known features thread, it became de-facto a *recommendations of* little known features thread.
IPython is really cool, but has TONS of features I don't (and will never) use. Bpython and its awesome intellisense are great enough for me.
Just found out about this recently, but: &gt;&gt;&gt; a = [1, 2, 3] &gt;&gt;&gt; b = [4, 5, 6] &gt;&gt;&gt; c = a+b &gt;&gt;&gt; c [1, 2, 3, 4, 5, 6]
Wow, I've used python in employment for several years and consider myself fairly competent, and I didn't know that. Thank you!
The *args syntax works not only for declaring functions but also for calling them. Let say I have this list: l = ["2012", "7", "17", "22", "25", "12"] Which might be numbers I extracted from the URL in a framework like django. I can turn that into a datetime by doing: from datetime import datetime date = datetime(*(int(i) for i in l)) It works just as well with the **kwargs syntax.
A coworker introduced me to ipython a couple weeks ago. I've used python for small exploratory scripts in the past and it has worked well, but ipython's notebook gives such utilities a new life in my opinion. Many times I load a data structure and explore the data; ipython's notebook is perfect for this.
Another one I recently learned: users = [u1, u2] # pretend this is list of users # Looping through users about age 21 for adult in (u for u in users if u.age &gt; 21): pass Generator expression is very handy for filtering collection inside a loop. Much better than this, I think: for u in users: if u.age &gt; 21: pass
Some background first, we wrote a python program around another proprietary python program (the govt gave us the source, but we couldn't include it in our code). Their program allowed for dynamic user input as a python file that was execfile'd. Then we wanted to hide our code to protect our IP, so made an importable module and did this... Step 2 (fails): from x import y y() The fixed code: from x import y globals()['y'] = locals()['y'] y() The function was exec'd inside a local function, but the data that we imported need to be accessible later, so by putting the function in the global namespace, we were able to do that. How do you properly format code on reddit?
That's not quite equivalent, because if `obj` is an instance of a subclass of `cls`,`isinstance(obj, cls)` is True, while `obj.__class__ == cls` is False.
So the power of tuples?
i'd write this as `re.search('^https?//', s)`, nice tip nonetheless though 
`itertools` gives you the beautiful `groupby` which allows you write all of that functionality like so: `d = dict((key, list(group)) for key, group in groupby(words, lambda word:word[0]))` but of course you do even better: http://code.activestate.com/recipes/259173-groupby/ `d = groupby(words, lambda word:word[0])`
There's no need for it to be, though. Putting it in parentheses force it to not chain the comparisons.
Don't you mean this? re.search('^http(?:s)?//', s)
ah, thanks edited the typo, any reason for using the non-capturing version here?
Nah, no reason. Just a poor assumption.
Came in with 2.7
You can also get any of your previous inputs: In [9]: _i3 Out[9]: u'_ + 1'
for ... else http://docs.python.org/tutorial/controlflow.html#break-and-continue-statements-and-else-clauses-on-loops 
I've heard that whole module was pretty much just hacked together at the last minute in Perl.
I don't think the poster here is the author of the library. The library is here https://github.com/mixpanel/memcache_client , the beauty of open source is you can always fork it and add the features you want.
Only in Python 3. In Python 2, that would return a list, which could be memory intensive (or not terminate). In Python 3, filter, map, etc. were all changed to return iterators.
You could handle inheritance too I suppose: if isinstance(o, type) and old_cls in o.__bases__: o.__bases__ = tuple(new_cls if cls is old_class else cls for cls in o.__bases__) And fix imports (like `from module import Class`): import new if isinstance(o, new.module): for name, value in o.__dict__.iteritems(): if value is old_class: o.__dict__[name] = new_class Of course you can keep a class reference anywhere. The whole thing really isn't a good idea.
I always share files on local network with $ python -m SimpleHTTPServer
Parenthesis are awesome. Use them to break lines. blahblahblah = (u"Blah" u"more blah." u"even more blah")
thank you for posting this it is a great jumping off point
this is pretty interesting. I played with it for a while, then got to this: C:\Users\hugo&gt;C:\python27\python.exe Python 2.7.3 (default, Apr 10 2012, 23:31:26) [MSC v.1500 32 bit (Intel)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; del __builtins__ &gt;&gt;&gt; object = (1).__class__.__bases__[0] &gt;&gt;&gt; object.__subclasses__ &lt;built-in method __subclasses__ of type object at 0x1E1EC750&gt; &gt;&gt;&gt; the output of that function is pretty long; you can recover everything that derives from object (all of the built-in types and then some). Still haven't been able to get `__import__` back though (seems like the holy grail in this game). The code type is available, so I'm pretty sure you could get traceback objects, but I'm not sure it would help. Python's restricted mode kicks in when you mess with `__builtins__`, so you can't even access func_locals and such. I think it'd be doable to pull `__import__` out of another frame's globals otherwise, but no dice.
 def somefun(a): b = 'something %s something' % a c = 1 return 'yadda {b} yadda {c} yadda'.format(**locals())
When doing some simple shell script: import os for item, key in os.environ.items(): locals()[key] = item 
In Python2, you should use xrange for performance (since range generates the full list in memory): &gt;&gt;&gt; r = xrange(10) &gt;&gt;&gt; g = iter(r) &gt;&gt;&gt; type(g) &lt;type 'rangeiterator'&gt; &gt;&gt;&gt; g.next() 0 &gt;&gt;&gt; g.next() 1
I thought most tutorials, at least the one I learned Python from, spoke about this very early on.
This creates a list instance for every lookup though.
And you regularly code on your iPad?
Not sure if this is little known, but it was little known to me a few weeks ago. Enumerate takes a second parameter which is the start index. Behold... pages = ["one", "two", "three"] for page_index, page in enumerate(pages, 1): print page_index, page
Hell yea. Always fun to share the goods.
I guess. But it's never going to matter with a list of size 10.
aaand thats the reason regex generally should not be seen as a solution.
Also, copy a dictionary while altering a key or two: new = dict(old, key1='newvalue', key2='newvalue2')
It's recommended to use [collections.MutableMapping](http://docs.python.org/library/collections.html#collections.MutableMapping) nowadays, although I believe that also requires implementing ` __iter__` and `__len__`. You get a much more complete dict-like implementation from it, including shit like `setdefault` or `.get(key, default)`
Also worth mentioning the `operator` module, which has higher order functions for building item accessors, so you can get rid of the lambda with: d = groupby(words, operator.itemgetter(0)) 
&gt; You're speaking Python with a Java lisp PascalCasing is more of a C#/VB issue than a Java one, FWIW. Java code tends to use camelCase for methods and attributes.
Also prints sets, lists, and has configurable depth (levels that are deeper will be elided): &gt;&gt;&gt; l = [[[[[[[[[[5]]]]]]]]]] &gt;&gt;&gt; pprint.pprint(l) [[[[[[[[[[5]]]]]]]]]] &gt;&gt;&gt; pprint.pprint(l, depth=3) [[[[...]]]] And it's smart about self-recursive data structures: &gt;&gt;&gt; d = {} &gt;&gt;&gt; d['d'] = d &gt;&gt;&gt; pprint.pprint(d) {'d': &lt;Recursion on dict with id=4297447744&gt;} 
Thanks! This was really neat.
I think tkinter is a useful way to get started gui and even oo programming in general. If you don't use the interface designers you get a better understanding of what is going on.
Does this compile to the exact same bytecode as set comprehensions do?
So, I think you're missing the point somewhere. My comment was specifically about publishing posts. You could write your article on an iPad using one of the zillion iPad text editors that support markdown and Dropbox syncing. Not sure what this has to do with writing code.
I stack.pop()'d too.
This is handy, IPython's source code includes a `chop(seq,n)` function which is similar except it doesn't lose any elements if `len(a)` is not evenly divisible by `n` -- see the code: &gt;&gt;&gt; a = 'ABCDEGHJIJKLMNOPQRSTUVWXYZ' &gt;&gt;&gt; n = 7 &gt;&gt;&gt; &gt;&gt;&gt; def chop(seq,size): ... """Chop a sequence into chunks of the given size.""" ... chunk = lambda i: seq[i:i+size] ... return map(chunk,xrange(0,len(seq),size)) ... &gt;&gt;&gt; chop(a,n) ['ABCDEGH', 'JIJKLMN', 'OPQRSTU', 'VWXYZ'] &gt;&gt;&gt; [a[i::n] for i in xrange(n)] ['AJOV', 'BIPW', 'CJQX', 'DKRY', 'ELSZ', 'GMT', 'HNU'] &gt;&gt;&gt; zip(*[iter(a)]*n) [('A', 'B', 'C', 'D', 'E', 'G', 'H'), ('J', 'I', 'J', 'K', 'L', 'M', 'N'), ('O', 'P', 'Q', 'R', 'S', 'T', 'U')] 
Two little known flags for regular expressions: re.VERBOSE and re.DEBUG Verbose allows you to inline comments in your regex, debug shows you human-readable info about the compiled expression: &gt;&gt;&gt; re.compile("""^ # beginning of line ... py # the letters py ... . # any character ... {1,} # matched one or more times ... $ # end of line""", ... re.DEBUG | re.VERBOSE) at at_beginning literal 112 literal 121 max_repeat 1 65535 any None at at_end
Also, in Python 2 (assuming that's the one you're using), you usually want to call `dict.iteritems()`, not `dict.items()`: `dict.items()` has to allocate a list of (key, value) pairs whereas `dict.iteritems()` will yield them as it goes, should be slightly faster but more importantly it better expresses *intent*: when I see a `dict.items()` call I usually think "uh oh, this guy is may modify the dict he's iterating over, read carefully" (because that's one of the few outright reasons to use the method)
It can't do, because you can replace `set` with another function or class - e.g. `set = list`, which will affect the `set(x for x in range(10))` form.
http://python-history.blogspot.com/2010/06/import-antigravity.html
It took me a couple tries, but once I actually used virtualenv for a project, I never looked back and always use it. Git, too.
Just be careful with that, dicts in Python don't have order, so if "o" is a descendant of two of the values in the dict the return value would not necessary follow the order you've put in it. Unless you use an OrderedDict. (Don't initiate the OrderedDict with a dict...)
an interesting thing you encounter when playing around with `del __builtins__` is the restricted execution mode: del __builtins__ def f(): pass f.__globals__ RuntimeError: restricted attribute it's a remnant of python &lt;2.3, [it seems](http://docs.python.org/library/restricted.html).
I'm currently considering [Pusher](http://pusher.com) to achieve this sort of thing - does anybody have any experiences to share?
I'm not sure how little known this is (I'm still a Python novice) but in newer versions, they've implemented: import antigravity Edit: Oops, it seems [someone has already mentioned this](http://www.reddit.com/r/Python/comments/wpl1h/what_are_some_little_known_features_in_python/c5fd8lx).
I don't see anything wrong with cases like these, but when it gets to the point that the regular expression is more than thirty characters, alternate solutions should be considered.
Also note that consecutive strings are concatenated. We also have triple-quote strings for multiple lines: """This string starts here, has several lines and ends here"""
And that's why itertools exists: itertools.ifilter does in 2.x what filter does in 3. Same with imap, izip, etc.
I thought this was pretty well known, but reading some of the comments here, it would appear not: The [itertools module in 2.x](http://docs.python.org/library/itertools.html) - for when you need to perform actions using map, zip etc on large iterables, without building all the intermediate lists. My favourites are imap and izip and izip_longest, but ifilter is handy, and I get a fair bit of use from count and chain. If you'd use xrange instead of range, use itertools.imap(fn, lst) instead of map(fn, lst). I made a pretty fast (in relative terms) trial division prime generator using that module, a couple of generators and a couple of hackish comparison chains.
Yes, the word COBOL next to a handle *is* amazing. Here's your Ritalin for today.
I use netcat for that, personally. tar -xf - &lt;files to share&gt; | nc -l 4000 it's cool because it shares them exactly once.
Note that you can also submit plain sql to sqlalchemy.
&gt; This may not work with new classes of Python 2.2 (eg classes derived from built-in types). It's also ugly if you ask me, having a class change during runtime.
Here is a example for a Makefile target for virtualenv: http://blog.bottlepy.org/2012/07/16/virtualenv-and-makefiles.html
I don't know much about this sort of thing but I think I would prefer not to use an external service when I can use websockets. A service like Pusher could be useful for mobile devices since I don't want to keep a connection alive at all time. Except for Android, I would use the official GCM thing (formerly C2DM).
I'm using virtualenv for everything now as well. Just yesterday I learned about the `-E` flag to pip that automatically uses or creates a virtualenv when installing packages. It doesn't appear to be helpful if you need a non-system-default version of pip, nevertheless, it's a nice little shortcut.
Did this come from Perl's magic '$_'?
pyodbc?
Just for the record, it works perfectly fine on new-style classes derived from object or any other built-in type. And you're perfectly entitled to think it's ugly. I wouldn't recommend anyone go and rewrite their applications using it, I just thought it was a neat hack.
Wow, I didn't know consecutive strings were concatenated. I have been programming python for 4 years and I missed that basic little feature.
Armin Ronacher showed it in a talk during Europython 2011: "5 years of bad ideas". Check https://github.com/mitsuhiko/badideas/blob/master/githubimporter.py
Yes its a pretty bad idea, and you did a decent job of listing all the reasons yourself, and at the end of the day the poor source code should not be littered with relics of the deployment process used by each company, person, off-line rack of top secret servers that uses it.
I've switched from sqlite to a 'proper' RDBMS during development. It's also handy to be able to test with sqlite even when you deploy with something else.
&gt; Also, the method that's called a "helper class" isn't a class. It's a method. And it's non-obvious where the self.height variable in there comes from Yeah, apparently it's been pasted straight from http://stackoverflow.com/questions/4726011/wrap-text-in-a-table-reportlab replacing the *actual* `height` constant there by a `self.height` stealth constant here, rather than just... add a height parameter (or move all constants to the top level) An other weird one is `getXMLObject`, whose only purpose seems to be reimplementing lxml's `objectify.parse` manually via `objectify.fromstring`. I can understand splitting a complex process into multiple functions and/or methods, but here the splits are pointless and all the main processing is done in one big function. There are plenty of other weird things too: row = [] row.append(item.id) row.append(item.name) row.append(item.price) row.append(item.quantity) (how about a list literal filled in?) total = Decimal(str(item.price)) * Decimal(str(item.quantity)) (objectify provides the original value through the `text` attribute) and the article has bits of misinformation peppered in: &gt; My favorite is lxml which includes a version of ElementTree lxml reimplements the ElementTree API from scratch on top of libxml2, it does not "include a version of ElementTree" for any value of "include" I know of. edit: slightly cleaned up version: from decimal import Decimal as d from lxml import objectify from reportlab.lib import colors, pagesizes from reportlab.lib.styles import getSampleStyleSheet from reportlab.lib.units import inch, mm from reportlab.pdfgen import canvas from reportlab.platypus import Paragraph, Table, TableStyle width, height = pagesizes.letter style = getSampleStyleSheet() ADDRESS = """ &lt;font size="9"&gt; SHIP TO: %s %s %s %s &lt;/font&gt; """ ORDER_NUMBER = "&lt;font size="14"&gt;&lt;b&gt;Order #%s &lt;/b&gt;&lt;/font&gt;" THANKS = "Thank you for your business!" def coords(x, y, unit=1): return x * unit, height - y * unit def draw(canvas, item, x, y): item.wrapOn(canvas, width, height) item.drawOn(canvas, *coords(x, y, mm)) def drawParagraph(canvas, text, x, y): draw(canvas, Paragraph(text, style['Normal']), x=x, y=y) def createPDF(xmlfile, pdffile): xml = objectify.parse(xmlfile).getroot() pdf = canvas.Canvas(pdffile, pagesize=pagesizes.letter) drawParagraph( pdf, ADDRESS % (xml.address1, xml.address2, xml.address3, xml.address4), x=18, y=40) drawParagraph(pdf, ORDER_NUMBER % xml.order_number, x=18, y=50) table_data = [ ["Item ID", "Name", "Price", "Quantity", "Total"] ] total = 0 for item in xml.order_items.iterchildren(): row_value = d(item.price.text) * d(item.quantity.text) total += row_value table_data.append([ item.id, item.name, item.price, item.quantity, row_value ]) table_data.append(["", "", "", "Grand Total:", total]) order_lines = Table(table_data, 1.5 * inch) order_lines.setStyle(TableStyle([ ('INNERGRID', (0,0), (-1,-1), 0.25, colors.black), ('BOX', (0,0), (-1,-1), 0.25, colors.black) ])) draw(pdf, order_lines, x=18, y=85) drawParagraph(pdf, THANKS, x=18, y=95) pdf.save() if __name__ == '__main__': import sys createPDF(*sys.argv[1:3]) I think I'd extract the table-generation part into its own function (e.g. `drawDataTable`, taking an iterable of items) as well, though there's a single usage of it that would probably make the code clearer and cleaner
Meh, generally I'm working with MySQL, and it's not exactly an ordeal to get a local server up. Perhaps I'm spoiled by that.
Then we have to port it over. Just saying that in my experience it's often not quite as simple as "flip a switch, you're on Oracle now baby!"
Thanks for this. Gotta play with PayPal &amp; Django! 
I know. I just don't use them because they are ugly.
Oops, that was indeed my intention! Fixed.
Someone still has to explain to me exactly what virtualenvwrapper *does*. I might be extremely stupid, but I read a few articles about it and I still don't understand what it abstracts or makes easier...
I'm still waiting on a solution for using iPython with virtualenv that *works* ... =/
If you want to write plain SQL then all you need are the drivers for your DB
Yeah I should have clarified. I only mean the interactive interpreter.
Note also that if you use ipython, things are pretty printed by default: In [1]: x = [(i, i*2) for i in range(10)] In [2]: x Out[2]: [(0, 0), (1, 2), (2, 4), (3, 6), (4, 8), (5, 10), (6, 12), (7, 14), (8, 16), (9, 18)] 
Property as a decorator: import time class MyClass(object): @property def current_time(self): return time.time() x = MyClass() print x.current_time 
If you enable the virtualenv in bash or whatever, then run iPython, it doesn't work?
&gt;If you enable the virtualenv in bash or whatever, then run iPython, it doesn't work? Could you clarify what you mean by "enable virtualenv in bash" ?
[fuzzywuzzy](https://github.com/seatgeek/fuzzywuzzy/) is pretty neat for fuzzy string matching.
Are there any native python xml objectifiers out there? I sometimes work in restricted environments so installing lxml can be problematic. 
[Useful Modules from the python wiki](http://wiki.python.org/moin/UsefulModules)
s/eval/repr/
I have a few apps using builtin urllib2 for http requests. Is requests really this amazing? Is it worth switching over to it for cleaner code/easier maintenance or is it not worth adding a dependency?
Yes! I absolutely love it. Then again, for me clean code is everything. It's really up to whether you want to remain dependency free (which really isnt as important considering we have tools like PyPi) or open-source/contributor friendly (and thus have clean code).
 &gt;&gt;&gt; `1 + 1` '2' &gt;&gt;&gt; repr('1+1') "'1+1'" 
Oh, nice, I could really use pdfminer. I'd been looking for a python solution to that.
Uh, soon maybe? I have to get it done this week or else it'll be August.
you can install libraries to your home folder. i believe passing --user to both pip and the normal "setup.py install" will install the library to your home folder and python will automatically pick it up. This is how i get around installing libraries on computers where i dont have root access
lxml is awesome, and is a wrapper around the very mature libxml2 or whatever its called, thats used by a lot of projects including gnome
I've always wanted to do work with websockets but since the protocol changed quite a bit over the last two years, so did all implementations. https://github.com/abourget/gevent-socketio is pretty easy to get going with websockets and create a chat for example. A blog detailing the use of gevent-socketio with Django: http://curella.org/blog/2012/jul/17/django-push-using-server-sent-events-and-websocket
It's not overly uncommon to need to interact with legacy systems and protocols in python.
Depends on your exact needs and constraints. lxml is usually the best choice, but can be annoying to package. ElementTree is included in the stdlib so you're covered. And pyxml should be taken out the back and shot. I used to be in your situation, we bit the bullet one day and forcefully ripped out pyxml to replace it by lxml.
Try writing email to Larry Hastings, he's the one behind that.
Just ordered one tonight.. can't wait to play with it. It'll probably be a while though
The [submission](http://www.reddit.com/r/Python/comments/vwe2u/a_simple_sqlalchemy_07_08_tutorial/) you made two weeks ago regarding sqlalchemy is more pertinent than this tutorial. Also, [it looks](http://www.reddit.com/user/driscollis/submitted/) like you're creating a ton of _new_ content (assuming this is your blog). You may want to ease up on the submissions or people are going to start thinking of this as blogspam (myself included).
Err. What if you also don't have a home folder? I am not trying to be a pain, but sometimes I wonder if my systems department is. 
Gaggin' here!
Use yaml with Yaco for user preferences: http://pypi.python.org/pypi/Yaco/0.1.9
http://code.google.com/p/pyopencv/
What kind of stuff do you do in those groups?
My guess is that Tesseract (which is probably your only option as far as Python goes) simply doesn't handle tables very well. It could be the case that the table borders (and possibly the alternating colors in the rows as well) might be confusing it. The simplest solution might be to download a trial of a commercial application (e.g., ABBYY FineReader), if that's an option.
http://stackoverflow.com/questions/9413216/simple-digit-recognition-ocr-in-opencv-python http://blog.damiles.com/2008/11/basic-ocr-in-opencv/ 
Generally your code splits into natural sections, so you split the code in each section into a separate module. If it's not clear how you could divide your code up, then it probably means your code is not very well structured - each class or function should ideally only have 1 responsibility, for example. To learn good coding practices usually takes more than a few comments on Reddit though - I suggest picking up a book or 2, eg. Code Complete.
This is correct behaviour. The query section of a URL needs spaces replaced with plus signs, as it's considered form data and is to be encoded as the application/x-www-form-urlencoded mimetype. If your client can't decode that, the client's library is most likely broken or misconfigured.
upvote for lennon quoting, improves code readability
[FineReader](http://finereader.abbyy.de/) can extract the data flawlessly, it even understands the table structure. [Here](http://code.google.com/p/sbc-ocr-automation/source/browse/trunk/src/pl/polsl/zjpsip/FineReader.py?r=9)'s an example how to automate it using Python.
I've never heard of lennon quoting. Care to share a link for further reading?
i.e., the act of quoting the lyrics of John Lennon. http://www.youtube.com/watch?v=skuhAt8e_n0 http://www.youtube.com/watch?v=qkNsQPFhivY
While I agree that this is definitely a client problem (the +encoding is valid after all) isn't using %20 just as valid? I just posted this here 'cause it caught me off guard that there was a difference at all. Had been writing the client, I likely would have used quote() and not quote_plus() and been equally surprised. Edit: autocorrect-corrected.
[py-dom-xpath](http://pypi.python.org/pypi/py-dom-xpath) for your XML querying needs. read [my question here](http://stackoverflow.com/questions/5572247/how-to-find-xml-elements-via-xpath-in-python-in-a-namespace-agnostic-way) to find out why i find it more useful than other xpath implementations in python.
No, the spec says "Space characters are replaced by '+' ". Once that's done, the whole thing will be percent encoded, but there will be no "%20"s in ~~there~~ the query section.
Thanks for the explanation. That makes sense now.
You're with luck, here in Brazil, with importing taxes, the price is 150 dollars instead of 20 dollars, what a great country to live.
Yes. It might be easier to just write a program to extract the data from your application's data store.
+1. This is reddit, not wroteit.
I was not aware of that. Very nice.
Thanks. Most of those I'm aware of, but it seems like every programmer has a few hidden treasures we never know about.
Shameless plug: [RunningCalcs](http://pypi.python.org/pypi/RunningCalcs/). For doing more than one thing with data in an iterator, efficiently and without repeating yourself. Disclaimer: I wrote it and maintain it.
Wow - pyglet is awesome, but I thought it was abandoned. This is *very* exciting.
you should have someone buy one for you and ship it to you
well we're idiot engineers, but i'd rather have a slightly annoying package but is generally agreed to be the best than to use a dumbed down version. for the record, i HATE pyxml. what advantage does it offer anyone to hack python and change your package name from pyxml to xml? and it hasn't been updated since 2007.
&gt; to use a dumbed down version. I don't think ET is a "dumbed version" of anything (there's probably a reason why lxml reimplemented the ET API after all), lxml adds a bunch of features (from libxslt) and has better performances, but ET is no sucker and if it's sufficient for the job there's little reason to reach for lxml. I say this not as an opponent to lxml at all, I use and abuse it often. &gt; what advantage does it offer anyone to hack python and change your package name from pyxml to xml? I believe the intent was to integrate in/improve/replace the `xml.*` namespace of the standard library, which I guess made sense to somebody at the time (PyXML was the package of the XML SIG, I'm guessing the intent was for PyXML to be the "evolutionary route" for Python's XML support). &gt; and it hasn't been updated since 2007. Indeed.
very nice!
I am curious about the backslash uppercase N in u"\N{SECTION SIGN}" It isn't a newline and my google-fu came up with no answer. 
 &gt;&gt;&gt; `1+1` '2' &gt;&gt;&gt; repr(1+1) '2' &gt;&gt;&gt; `'1+1'` "'1+1'" I stand by my original comment.
http://docs.python.org/reference/lexical_analysis.html#strings \N{name} Character named name in the Unicode database (Unicode only)
That's a good idea, I'll try to find someone. When the sender is a person instead of a company they usually do not impose taxes. Thanks !
just use sublime + SublimeLinter - syntax + pep8 checking inline as you type, even shows you which pep8 rule you're violating. Way easier to have everything highlighted inline, rather than waiting for a commit failure which you then have to fix manually. 
Possibly.
or if you are using a better editor, namely vim, you can plug Syntastic + Flake8 in it https://github.com/scrooloose/syntastic ;)
I thought so too, and I'm really happy that we were wrong :)
pyNastran not part of Pypi (b/c i'm a lazy developer and want people to go to the source to prevent them from using it blindly) it's a nastran interface code for the various legacy input/output files that the code has. it's generally used by mechanical/aerospace/civil engineers. http://code.google.com/p/pynastran/
Yeah, I suppose so. A couple weeks ago though, I was only able to post a comment once every hour or two, which made replying a royal pain. I've been on reddit for at least a year or two. Now I seem to be able to comment with no problem. I'll try to be more active here.
Thanks for the tip!
Thanks! I looked it over and it does seem pretty informative.
I'm thinking of writing a follow up on how to upload your package to PyPI or similar. Do you have any suggestions for that or for beefing up the content in the package section?
I would like to add more minutia too, but I wanted the article to be very clear and to the point for beginners. Maybe I could do an "Advanced" or "Intermediate" article with those details?
:-)
FINALLY
The ipython notebook and qtconsole are pretty spiffy. They both support inlining plots. For simple analysis and testing this is what I use. After you're done with some code type %hist and you magically get all the lines you typed. Clean it up in a editor and add it to your project, along with unit tests and whatever else. There's a few ways to use C code with python. Cython the easiest, much easier than my experience witn MEX. The latest version of ipython has a magic function for using Cython directly in the terminal. Cython doesn't take longer to develop than python but you can optimize it until it is fast enough. This code compiles and is importable from normal python. For GUIs, given that this is using numpy arrays, I prefer Chaco and Traits. It is really fast and is simply enough to use interactively. There are plenty of full fledged GUI options but they aren't focused around data analysis or plotting.
For a more classic IDE, [spyder](https://code.google.com/p/spyderlib/) is worth a mention here - like IPython, it targets scientific users, like people converting from MATLAB.
It's actually the Correct Way. + is used for data.
You mean besides the whole SDL thing?
I've tried Wing IDE, Eclipse with pyDev, and Spyder. I'd say the best free IDE of the three is Spyder, but the best is Wing IDE. pyDev just seems buggy to me, and not really python focused. Wing's debugger is by far the best thing about it. It's incredible. I haven't try pyCharm, but generally have seen people pick Wing over pyCharm when they've tried both. In terms of running C code, you have three options: 1. Cython: not quite Python and not quite C; you define types of variables, a bit strange. good for small blocks of C Code, you embed it in your python program. I'd use this if I didn't know C and didn't have libraries in C. 2. SWIG: some people hate swig, but not that hard once you get the hang of it, basically you map C functions to Python functions and add a few types in the arguments. Great for libraries as you don't need to modify them. 3. scipy.weave: you define proper syntax C code and put it in a string and basically compile the string inside your python program. depending on your use case, I would use this over Cython if you know C, but I wouldn't use it if I had a library. 
I wonder what it would take to render the molecules in 3D instead.
what mess ?
Why do you think so? `datetime` module is well designed overall, though it has some strange things (e.g. it has no `datetime.tzinfo` subtype implementations including UTC, naive and tz-aware times are represented using the one same type). 
My favorite example: [attest/hook.py](https://github.com/dag/attest/blob/master/attest/hook.py)
Take a look at [Sage](http://www.sagemath.org/) Its not an editor itself but it takes python (and other languages) and sets it up to do math. It may not be what you are looking for, but it is worth pointing out.
It is way better than urllib2: cleaner syntax, full support of all HTTP methods (urllib2 only supports POST and GET), clear docs, and even a (separate) package for asynchronous requests (check out grequests on Github)
&gt; the resulting string is a valid Python expression which **can be passed** to the built-in function eval() Note that this means that `eval(repr(x)) == x` for `x` is a string, a number, None, etc. It does not mean... I'm not sure why you made that part bold, actually. &gt; The built-in function **repr() performs exactly the same conversion** in its argument as enclosing it in **parentheses and reverse quotes** does. This actually says repr(x) == `(x)` for any expression `x`. (I like this thread.)
you can always use gnuplot :) it's somewhat old tho http://gnuplot-py.sourceforge.net/ matplotlib is the better choice. It's a little more work for edge cases, but the plots look far more professional than Matlab's do. Literally yesterday and today, I plotted a double y-axis on a semilogy plot. On top of that, I resized the figure to embed into an HTML window. That's as bad as it gets. 1.5 days of work for a beautiful plot.
Hi, I'm the author. I posted Plyplus here 1 year ago, and got some interest. Now it's much better, in both code and documentation. I would love to hear your feedback!
Just about that :)
Calling it "well-designed" might be a stretch.. It's certainly useful enough as it is.
They won't use technical measures, if they think your app (the app in step 1 of your example) is breaking the rules they will pull it from the app store. Step 3 just mean "installs the app" by the way. Unless you're in the developer program you can't just download apps - you can only install them from the app store. Note that step 1 has already happened. (Python for iOS). Step 4 is the tricky one - even if your program is on the internet, if you can't download and run code from the internet *until* you have that program. So you have to type it all out manually. I don't think Apple will be too worried about that. In Python downloading and running code is as complicated as: import urllib2 exec urllib2.urlopen('some url').read() 
Yeah, GNUplot looks like it's from the 70s. But if you just want to place a legend to the side of the plot it just works. Matplotlib can make beautiful plots, but how much tweaking of ticks, labels, legend and plot placement and size did it take?
They are also prone to failure.
As Derpscientist alluded to, it can be done with moderate computer power, and PyMol is a pretty good choice if you already have 3D information from your molecule. My manager uses a non-Python based molecular visualizer MOE which can minimize and display small molecules (smaller than say 100 atoms) from 2D into realistic 3D in a second or two.
Compare this with Java Date api, this is much better.
&gt; Step 4 is the tricky one - even if your program is on the internet, if you can't download and run code from the internet until you have that program. Does iOS let you download files from the internet? A file containing code is no different in principle from any other file.
do you think speed will eventually be one of your priorities ? i've been working on a project were parse speed is critical, but so far i haven't found a LR-parser in python that makes speed a priority. Despite that i'm definitely test plyplus
By definition, PlyPlus will never be faster than PLY for simply parsing. But, if your project involves complex analysis of the results, it's very likely that a version using PlyPlus will be faster. If speed is very important to you and you must use Python, I suggest trying PLY with PyPy or psyco.
There doesn't appear to be any tab-complete, or code hinting. I guess I need to look into it some more, but I'm at a loss why you'd ever use it. 
It reminds me of mathematica. It exposes a web page where you can create python documents split into namespace sharing segments. So for me, I load up the data structure that is large in one cell and then do various function calls with it. It is designed to work well with numpy and some plotting libraries.
Oh, I see. That makes sense. Apparently I've been using Python since 1.5 and I never understood backticks. Though I never used them. :)
Yeah, me neither. Being explicit about what you want is better any way. :) Also, I'd like to share this: &gt;&gt;&gt; dis.dis(lambda x: `x`) 1 0 LOAD_FAST 0 (x) 3 UNARY_CONVERT 4 RETURN_VALUE This shows pretty clearly that there is no `eval` involved.
Yes it does. I guess I had always thought there was because `` works similarly to parentheses.
They just changed the course title earlier this month so I'm guessing they're too busy coming up with the curriculum to update the course information yet, which is why that listing still shows the old info for the Intro Java course taught by Gries
My only complaint about pyCharm is that it indexes every. single. file. on your Python path (not just python files). While this isn't a problem at home, where I work, we have a weird setup where we keep a renamed version of every single file ever released (don't ask, its just how we roll). My index directory on PyCharm is almost 6 GB as a result (and takes about 4 hours to generate). Also, it doesn't like symlinks in your python path when debugging.
I'm interested in using PlyPlus at parsing using Python to replace DMAP syntax to improve readability. I've written my own Python parser, but it's strict and not very capable. Thankfully 200 lines would should be a large program. How capable is PlyPlus at handling embedded commands? My code falls apart for this. So something like max([i for i in range(10)]) or (a+c+max([1,2,3])+min(c) ) * C; where C is a numpy array. i'm also interested in parsing things like for a,b in c.iteritems() and if and while statements as well as functions and classes and imports would be nice as well, but not necessary.
&gt; How capable is PlyPlus at handling embedded commands? You tell me: &gt;&gt;&gt; g.parse('c.iteritems()\n') start(expr_stmt(funccall(attrget(name('c'), name('iteritems'))))) And yes, it also works for the rest of the expressions you gave here. Just make sure to end it with a newline.
This is very cool, but from a Python-parsing standpoint, what advantages does this have over [tokenize](http://docs.python.org/library/tokenize.html)?
Air Force, NASA, Boeing, Lockheed, Airbus, General Electric, Honeywell, Rolls Royce, etc. I run an open-source project and google analytics is great for finding this stuff out.
In 2008, I took a python course at UC Davis. [I think this one](http://www.cs.ucdavis.edu/courses/exp_course_desc/10.html) It was designed for non-computer science majors. Such a great class...really helped me think about things in new ways. I think an introductory programming course should be part of everyone's ~~GEDs!~~ I meant GE requirement...but a highschool course is cool too!
[Check out this :D](http://www.csprinciples.org/)
[UL Lafayette](http://louisiana.edu): CS150 (most likely to include 260/261 soon) Source: student there (the syllabus still says C++)
RPI just switched from C++ to python as well.
Which school? There was a really interesting talk at one of the Chicago PyCons by two Michigan State professors about how they changed CS 101 to Python. The second class in the series remained a C++ class, and they didn't see any measurable difference in the grades of students who came in from Python or the old C++ curriculum.
Probably has a lot more to do with the curriculum as a whole. Just because CS 101 is python doesn't mean they should teach a C like language and it's concepts before you get your degree. MIT starts with Python and their graduates are pretty good.
What is "this stuff"? I'm guessing that's a list of Python-using companies you found? FWIW, I would be *shocked* if you were to tell me those companies were *not* using Python.
You won't get very far without using sys, os, and math, but you will probably only use 1 or 2 methods from each. Of the ones mentioned in the other answers, I only use argparse regularly. Browse the summary pages for all the standard library modules. That way, when you need something, hopefully you will remember if it's in the standard library or not. 
Can you explain what makes the graduates good or bad? What are you guys grading them on?
every organization uses python, not everyone is in computer science...well MATLAB is still used, but it's starting to die
&gt; You live and breathe open source technology. You know the industry, understand the community and share the ideals. This hypothetical person would be categorically excluded from working on "cloud" software. Even if by some miracle they were not, they would have serious misgivings about Canonical, for their maintenance and encouragement of non-free packages in their main repositories. Even setting that aside, this ad does not mention the licensing of the work being done by this team. This is a deeply flawed advertisement. EDIT: &gt; passion for free software, Ubuntu and the cloud. That has to be the most internally confusing clause I have ever seen.
shit, never heard of "shelve"
When doing this kind of math, isn't it better to use C/C++?
Is it columbia? My friend keeps on telling me how much she loves the intro python course they offered
&gt; and not for small ~100 line projects. i'm not sure if i'm reading your post correctly, but OOP (pytest in particular) is just fine for ~100 line unit tests...
If you want it to run fast, sure. I would be surprised if SciPy didn't use a C or Fortran version. On the other hand, if you're presenting the algorithm to be understood, a lot of people would probably find the Python version easier to read than the C version.
Matlab is what some people are comfortable with. It, annoyingly, seems to be a 'least common denominator' type thing. 
And you haven't missed anything.
this (j/k) Of the built-in modules: collections sqlite3 operator decimal locale time `__future__` Lesser known: dircmp But eventually, you probably want to install pip (and other various install mechanism) so you can import extensions (e.g. numpy, scipy, sympy, matplotlib, lxml, BeautifulSoup, yaml, sqlalchemy, sqlobject, django) and database drivers. 
Pygame was quite fun as a starting place. For random dungeon or world generation, you should be able to find a heap of info on it around the web, there are a huge number of different techniques depending on what kind of game you want to make. A great way to learn Python is to find an interesting open source project using it, and try to understand some of their code. Tweak parts of the code to see what happens. Break it intentionally to find out how it works. Quick iteration and expressive error messages are two of Python's major strong points. 
tokenize is a lexical parser, which is one layer, where a full parser has at least two. The second layer takes the list of symbols and matches them with patterns of structured rules. That is what [PLY](http://www.dabeaz.com/ply/) offers, and it does that well. Plyplus provides an additional layer: It turns those structured matches into one big tree, that you can process and run queries on.
That's pretty cool! I've never really programmed anything that is "my own" before. This thing is super simple but it literally came out of theoretical legos that I put together in my head, which I find amazing. I've done projects to solve goals and algorithms, but this is mine from scratch (except I learned how to use the re module for this from stackoverflow.com) and it feels pretty great!
What do you mean with 'mathematical arrays'? I expect you mean 'matrix', which I assume in the following. Have you seen http://www.scipy.org/NumPy_for_Matlab_Users/ ? Arrays in numpy tend to be the general use case - you have a set of data, and you want to do something with each element - which is why the * operator (for instance) does elementwise multiplication (i.e. .* in matlab). This is also the only operator that makes sense for any dimension of array. If you want vector/matrix multiplication, you can always use dot(A,v) where you would do A*v in matlab.
Stop it, Mark.
I agree with what you're saying. I didnt exactly mean that oop should be taught in an intro class, but that java is an excellent language to use when learning oop. In an intro class I think the boiler place can be over looked, (dont bother what public class or String args[] means). I think that a c styled language is great for beginners, just without the c.
http://inventwithpython.com
Thank you very much!
Coming from matlab, Spyder is the closest matlab-a-like IDE. It's OK to get going and has nice features for inspecting arrays and plotting. However, for large code-bases, a proper IDE like Eclipse+pydev is ultimately better. For designing GUIs, skip Tkinter, the built-in python GUI library, as it's straight out of the 1970s. There are only two GUI toolkits worth considering: Qt (PyQt or PySide are the python bindings) or wxWidgets (wxPython is the python binding). Qt is a more sophisticated toolkit but wxPython is a more pythonic interface. There are GUI-designer applications for both of these but thankfully the world is moving away from GUI-designers; they were always a bad idea. For scientific plotting in scripts, use matplotlib. It does nearly everything and has excellent quality rendering. The best way to figure out how to do something with matplotlib is to browse the gallery (http://matplotlib.sourceforge.net/gallery.html) for something similar to what you want, then copy the code. A great way to design GUIs for scientific applications is to use the Traits / TraitsUI libraries. For application-based plotting, the Chaco library (built in traits) integrates well. Here's some tutorials with more explanation: http://drliddle.com/index.php?option=com_content&amp;view=article&amp;id=14:quicktuttraits&amp;catid=3:tutorials&amp;Itemid=6 http://docs.enthought.com/traitsui/tutorials/index.html http://code.enthought.com/projects/traits/documentation.php HTH
I did something similar a while back using the [Reddit API](https://github.com/reddit/reddit/wiki/API) to convert my saved Reddit links to my preferred org-mode format. Optionally it also unsaves the links from Reddit. It's a bit slow, because the API rules dictate that you should avoid making more than 30 requests per minute and deleting requires in the order of one request per link. Furthermore, without Reddit gold, there's no way to get all of your saved links at once, so that too needs several calls. The script is [here](http://pastebin.com/4U8x5wGZ). It's kind of a mess because I did some experiments with itertools along the way, but it should be trivial enough to adapt it to whatever output format you'd want.
&gt; categorically excluded from working on "cloud" software Why is that? Canonical supports Openstack, which is a 100% free open source project focusing on public and private clouds. You don't always have to support a major public company and their proprietary cloud format. Openstack is Apache licensed.
What I am trying to do is get math majors to switch away from Matlab to Python.
Georgia Tech CS1301 CS1315 Exclusive intro classes.
Thats what computer science is. Theory. You want Software Engineering if you want trade school skills. Computer science is all about understanding the principals of programming, data structures, algorithm design and analysis, analytics and understanding the principals pros and cons that make up a language; Not writing Hello World in it. With computer science, learning syntax is simple, writing your own is simple too.
The irony of all this is that I just saved this link instead of downloading the script.
Do you really feel that the very first course in the curriculum so deeply hurts the efficacy of someone through the end of their 4 (or more) years? That seems to be very difficult to justify. I have always simply understood that every generation *feels* that the next is worse than they were and that the state of available software (especially in FOSS) seems to demonstrate a stark contrast to that opinion.
MATLAB -&gt; Python was the path that I took. I have not found anything that is _exactly_ as comfortable as MATLAB's IDE. I have tried Spyder and it seemed buggy(it was a little while ago), Eclipse makes you work its way which is not MATLAB's way. I have never tried pyCharm. Wing has the best most MATLAB-like debugger and it is the least buggy Python IDE that I have used.
As a mechancial engineer, I find python just as easy to learn as MATLAB and see it as more versatile. We were taught C++ and MATLAB in school (NU '08), and would have been much better served if python had taken the place of (at least) c++
I do. I really, really do. For the freshman who comes to college never having touched a compiler, intro to CS should make the pupil fully aware of all the moving parts that go into building a running program, *before* the programs s/he is writing become too large to keep the full stack in mind. It is, IMHO, a superior approach to bolting on the low level understanding after learning how to write bigger programs. As for the state of FOSS (and I say this as a twenty-something coder whose best days are hopefully not yet in the past) it seems that the important things are being pushed by experienced fogies who have been around the block once or twice and know what works and what doesn't. Edit: I suck at writing while fasting. 
**LEARN FOR LOOPS!** They are amazingly powerful, *especially* in Python (in Python:) (simply put,) a for loop lets you iterate over things, or go over each item in something, for example each character in a string[1], each number in a range[2] or each item in a list[3] the syntax is for _ in _: do something the first _ is what you want your variable containing each item to be called so you can reference it in the loop. Try to name it based on what it is. For exaple, each character in a string[1], you might call it character or char. Printing char in the loop will print whatever character the loop is up to. The second _ is what you're iterating over, such as a string[1] or a list[3]. The examples below should help clarify [1] chars in a string simple example, print each individual character in a string, in this case "Hello" for char in "Hello": print char output: &gt; H &gt; e &gt; l &gt; l &gt; o char is what we're assigning each character to so we can reference it, and "Hello" is what we're iterating over [2] numbers in a range luckily Python has a built in range() function. This is what beginners typically use while loops for for x in range(0,5): print x output: &gt; 0 &gt; 1 &gt; 2 &gt; 3 &gt; 4 x is what we are assigning the current number to so we can use it in the loop. Again, this can be anything, but I'm calling on some simple algebra in my naming convention. range(0,5) essentially produces a list of [0, 1, 2, 3, 4] (or 0-4). Note that the loop only goes up to 4, not 5, and starts at 0, not 1 [3] items in a list at some point you're going to start dealing with lists, which allow you to store many things in one variable (to simplify it). A for loop can let you access each item in the list. Don't worry too much about the list itself in this example (instead, probably find another tutorial for them), but we're making a simple list with 3 users in it users = ['Bob','Geoff','Harry'] for user in users: print user output: &gt; Bob &gt; Geoff &gt; Harry once again, we're naming our variable (user) based on what's in the list, but I could change it to "x" or "person" or anything else and it would still work fine. I hope that wasn't too long nor confusing, but it would be a crime for you to learn Python and not learn for loops – they're in every language and are just beautifully implemented in Python **EDIT:** I'm not sure why but my newlines seem to be broken. But my first point stands!
0.3.1 released https://github.com/ikotler/pythonect/commit/c766d74aeb4ed86f17b497e8804199471829ff23
Yah. I'm not sure what he/she means by that. occasionally with numpy I have to vector.rehape(-1,1) for certain operations, like dot products on vectors where vector.shape is (n,).
why is that? (just interested in feedback)
Thank you very much!! That is a lot of useful info!!
Thank you so much!!
Relevant [xkcd](https://xkcd.com/138/)
Really? Could you please send a link showing me how? That'd be awesome!
Pointers are useful.
The ftplib module isn't the nicest to use. [PyFilesystem](http://code.google.com/p/pyfilesystem/) has support for FTP, with an arguably more pleasant interface. This is roughly the equivalent of the code in the post, if I understood what the example was doing (get first file in a ftp directory and copy it to a local dir)? from fs.opener import fsopendir from fs.path import basename ftp = fsopendir("ftp://www.mywebsite.com", user='username', passwd='password') path = ftp.listdir('folderOne/subFolder', files_only=True, absolute=True)[0] fsopendir("c:\myfolder").setcontents(basename(path), ftp.open(path, 'rb')) 
I'm one of these crazy people who think that open source can coexist with proprietary software and even be mutually benefitial. Id be tempted to apply myself if I wasn't on a contract. Also, I've said a few disparaging things about Unity. That may not go down too well!
See also https://github.com/ketralnis/redditexporter which is a bit more comprehensive
Okay. All I know is I saw Lutz's book in the bookstore when I went to reuinion last fall. Later I spotted the CSCI-2961 description online. 
It's not well documented but this should get you started: http://ipython.org/ipython-doc/rel-0.13/api/generated/IPython.core.formatters.html The simple way is to define *\_repr\_html\_()* on your class. If you want more control or to separate data from display logic: # to register a renderer (fn that takes typ and returns html string): ip = get_ipython() html_formatter = ip.display_formatter.formatters['text/html'] html_formatter.for_type(typ, my_renderer) # to test or render on demand: from IPython.core.displaypub import publish_html publish_html(html) I found the mako templating library to be the best way to generate html from objects. 
/r/learnpython
University of South Florida, CGS 2060, "Introduction to Programming with Python". I taught it for two semesters. It might not qualify for what you want, though, because the course in question is specifically not for students in the College of Engineering, so Computer Science and Computer Engineering students are not eligible to take it.
Thanks for your suggestion!!
This post title is very very silly. Did the Egyptians even have celery?
Thanks this is closer to what I'm looking for, already coding pythagroas tree. :)
The summer course that's going on now is the start of the switch over. In the fall all the sections will be in python.
A good one that I saw my friend attempt (and succeed at) was recreating an image by mosaic-ing all the images in a directory, see [here](http://www.odditycentral.com/pics/fascinating-portraits-made-out-of-thousands-of-tiny-photographs.html) for some good examples. Once you've done it successfully, try automating using images from some online source, or adding some sort of logic to use the largest range of photos or add the ability to tweak the hue of each image individually to create more colour true images.
Just different use cases. Pickle is great for serializing/unserializing a whole chunk of data, whereas SQlite or other DBs are for storing/retrieving data in smaller portions, when you don't want/need to hold all your data in memory or when you want to benefit from SQL for querying your data. Shelf is kind of in the latter camp. But really, only use it for very small (toy) programs. The steeper learning curve for SQLite is worth the advantages thousands of times. Json is for serializing whole chunks of data in a language independent way (despite it's origins are in JavaScript).
shameless taken from a [french blog post](http://sametmax.com/ce-que-vous-ne-saviez-pas-sur-les-collections-en-python/) about unkwon feature of collections pop can take an argument &gt;&gt; &gt;&gt;&gt; l = [1, 2, 3, 4, 5] &gt;&gt;&gt; l.pop() 5 &gt;&gt;&gt; l [1, 2, 3, 4] &gt;&gt;&gt; l.pop(0) 1 &gt;&gt;&gt; l [2, 3, 4] &gt;&gt;&gt; l.pop(-2) 3 &gt;&gt;&gt; l [2, 4] 
Hey take a look at [pygame](http://www.pygame.org/news.html), for making games in python. There loads of good tutorials to follow as well. [1](http://qq.readthedocs.org/en/latest/index.html)
I doubt Canonical cares too much about your criticism of Unity, especially given that this position is for web &amp; cloud stuff, not the desktop.
[pythonchallenge.com](http://www.pythonchallenge.com) It has riddles (in a notpron-style if that rings a bell) that you are supposed to partially solve with Python. When you solve a riddle, you can access the wiki and see what solutions other people have thought of, which is a fun way to learn something.
What would you recommend for something like this? PIL?
Just out of curiosity, why didn't the downvoter like the pun? 
Is numpypy usable yet?
TIL about dailyprogrammer! Thanks for your wishes ( :
I like to also stop Python making so many damn object traversals: Not: for item in someiterable: self.gui.tableWidget.insertItemAt(x,y,item) But: insert = self.gui.tableWidget.insertItemAt for item in someiterable: insert(x,y,item) This saves me a lot in hot loops and is trivial to implement. A recent example for me is inserting 150k+ items into a QTableWidget cut insertion time down to 30% of the previous.
I always feel that people who ask "is *x* usable yet?" are solely there to make a comment about something they don't like
That's good to know, I'll learn what json is. It wasn't hard to parse this though, as the markup is generated in a formulaic way.
Just click the save button :)
Well, numpy is not just lightning-fast but also stores your numbers/data with extremely little overhead in extremely-fast accessible arrays. So you probably can't replace numpy with vanilla pypy, if you're using huge datasets, or rely on some of numpys built-in functionality which you don't want to spend a lot of time on re-implementing (but I haven't actually tried it myself.)
The post was about performance optimizations in the context of the numpy ecosystem, a lot of which is (sadly) not even close to working on PyPy. Whenever I can use scikit-learn &amp; friends on PyPy I will jump ship (and happily leave behind a lot of worry about fat objects and interpreter overhead). 
The slideshow js is pretty cool. what's that lib ?
Fellow Python newbie here! Like a few other people have said, try [Learn python the hard way](http://learnpythonthehardway.org/book/). It's a really great guide and teaches you a lot of things. Also, go to /r/dailyprogrammer and try out some of the challenges there. Also look through how other people have completed the challenges, you could learn something.
Like I said, I was inserting 150k items so my loop was 150k in that example. And I really did cut the time down to 30% of what it was. It's a micro-optimization, for sure. But if you have to linearly apply a function to an interable then this will save *something*.
 &gt;&gt;&gt; 5 == x &gt; 4 True I'm not quite sure of the order of operations on this one, could you explain it?
Why the fuck are people downvoting me? LPTHW is really simple to follow along with.
Michigan State University: [CSE 231](http://www.cse.msu.edu/~cse231/General/enbody.syllabus.u12.html)
Would I have to use LaunchPad _shudder_.
Don't worry about it :)
\&gt; import turtle \&gt; turtle.forward(200) 
Python interprets that line as a 3-part equation. So, it is not equivalent to `(5 == x) &gt; 4` and it is not equivalent to `5 == (x &gt; 4)`; it *is* equivalent to `(5 == x) and (x &gt; 4)`. So it's not that one part or another comes first - the statement actually breaks down into two separate comparisons. As for which one of the two comparisons comes first, I'm not sure, but I would guess it's the first. But the order doesn't affect the result, only the speed of execution.
op knows how to code and wants to create, not learn
not yet.
I often use this idiom for reasons other than optimization. If you assign a more descriptive name for the local variable then it can make your code more self documenting.
Considering all the art provided must be yours, screenshots are mostly pointless. The documentation is quite good - http://www.pyglet.org/doc/programming_guide/index.html - and looking at the style of code there should tell you all you need to know about whether it'll suit you or not. 
Did you get my pull request?
Ha, I'm pretty sure I meant 'functions' there. :) Also, the combination of help and dir is incredibly useful (e.g., 'help(Classname.methodname)' where 'methodname' is found using dir).
I just tried this (based on your post) and really like it. Especially like the feature that lets you highlight selections of code and run them with F9. I use RStudio with R a lot and have wanted something similar for python, this is it! It is just a bit sluggish, but can't have everything I guess!
I'm not a python programmer (yet) but I'm going to tell you the same thing I say when I post help for people on the unix.com forums: If you want help with something, you have to say what you've done, what you're trying to do, what you've tried so far, and where that's failing. &gt;I want to learn python. I've looked into `some online class` and I've heard good things about `this book` but I'm having trouble understanding `some aspect of both`. Can anyone suggest something that explains `the thing you're trying to do` with more `something that makes learning easier`. *That* is how you ask for help. I'm not insulting you personally, but "I've tried nothing and ran out of ideas" is just obnoxious, and clutters up forums. 
sure, head over to [/r/learnpython](http://www.reddit.com/r/learnpython) you'll have a blast (see righthand column on this page for lots of other links)
First off, DO NOT START WITH GAMES! I find the [official python tutorial (for python 3)](http://docs.python.org/py3k/tutorial/) on python.org to be a good starting point. Once you start graphics, I recommend using tkinter or "[graphics.py](http://mcsp.wartburg.edu/zelle/python/)", a python module made for use with a book but is a simpler alternative to tkinter when starting out. Once you start making games, stay with tkinter at least for the beginning as game libraries such as PyGame are very confusing to use compared to tkinter. TL;DR: Start with official python tutorial, move to tkinter or graphics.py for graphics, stay away from game libraries in the beginning.
`namedtuple` and generators were probably the two features most responsible for me getting into Python (and realistically, I hardly ever *need* either in my hobbyist life).
I thought this was an interesting read about greenlets vs. threads and when to use each in a server context
I think I can safely asume `help` gets info from the docstring, right?
http://learnpythonthehardway.org/book/ is a good place to start ... later you can practice the [easy] challenges in /r/dailyprogrammer for better understanding.. 
PyPy's numpypy also "stores your numbers/data with extremely little overhead in extremely-fast accessible arrays." % ~/pypy-1.9/bin/pypy -mtimeit -s 'import numpypy as numpy; x=numpy.zeros((50,30))' 'if x[10,20]: 1/0' 10000000 loops, best of 3: 0.0318 usec per loop % python -mtimeit -s 'import numpy; x=numpy.zeros((50,30))' 'if x[10,20]: 1/0' 10000000 loops, best of 3: 0.197 usec per loop 
Everything will run on a single core (and in a single thread), so no multicore goodness by using greenlets (in fact, somewhat less than you get by using threads).
I suspect your thread-based version will be as fast as your greenlet-based version if you create a pool of threads *before* accepting requests -- that's basically what web servers implementation do, so your bench is not entirely accurate as it is. The memory usage with threads is higher but not significant in today RAM standards. The real difference between gevent and a thread-based solution is the ability gevent jhas to transparently use an event loop everytime the app is doing some I/O bound work, thus accepting more incoming connections while the code is waiting for a I/O call to return (like a DB query for instance) 
This is not a joke. It's an official project from the PSU and everything should hap
There is a very smart way to sandbox in user-mode. It was implemented in Chrome. You have to run the sandboxed process in low privileges and intercept those APIs that you want to sandbox. When these APIs are called by the sandboxed process, Chrome executes calls in the controller process which runs in standard privilege. If the sandboxed process tries to bypass the user-mode hooks it gets ACCESS DENIED since the process can't access the desired resources. So, only through the intercepted APIs the process can access the desired resources.
I haven't run the example with a thread pool, but I suspect it still won't be as fast as greenlets. Threads (particularly OS-level, as in Python) incur a higher switching cost than greenlets, and even though RAM is cheap, CPU cache is not, so the memory overhead still affects performance. I'd be happy to publish a new benchmark that uses a thread pool if provided, but I didn't want to build my own for the benchmark (there's no thread pool implementation in the standard lib). There's also this benchmark http://nichol.as/benchmark-of-python-web-servers which leads me to believe that there's something special about gevent, even when compared with well-tuned competitors. Also, I'm not sure that I believe that the 'evented' nature of gevent is the reason it's faster. When an OS thread hits a blocking OS call (like recv), it allows other threads to run, just like the event loop lets other greenlets run when a greenlet is waiting on I/O. (There's still an "event loop", it's just that it lives in the OS scheduler.) Finally, I think that spawning a greenlet per connection helps to bring out just *how* lightweight greenlets are, where the overhead of spawning a new one is nearly inconsequential compared with threads. 
finally proper OSX 10.7 support. Yay !!
I have tried other things, but I wasn't sure if it was the right place to start. I didn't come here thinking "well I want to learn something but I'm too lazy to try anything on my own." This just seemed like the right place to look for help.
Thank you!
Yes. I was going to post a smart-ass reply about how you can use help(help) to find that out but it's actually not mentioned in there to my surprise.
It might be more interesting to test the performance of vector operations rather than scalar indexing. For example, in my code, I often do things like "(x+y)/2" and "x / np.sum(x)". 
You'll find the .dmg file [here](https://code.google.com/p/spyderlib/downloads/list) in the download section.
I teach a class in game programming with Python. If you already know C++, it's entirely feasible to learn game programming in Python. You can see all my course notes along with all the example programs at http://www.aharrisbooks.net/pythonGame/ Videos from the last semester version of the course are available here: http://de.cs.iupui.edu/courses/n451/ I also wrote a book on the topic, but check the other stuff first, and don't buy the book unless you think you'll need it (or want to support me for putting this stuff out.) PM me if you need specific help.
Good point about Queue.Queue. Maybe I'll put together a benchmark comparing a Queue-based thread pool with a gevent pool.
The other person was suggesting to use pypy *without* numpy or numpypy, just using plain python datastructures.
Yes, I would say that getting comfortable with python first makes game creation much easier.
When you need to extend python with C/++, swig is your friend. What editor do you use? If you're an EMACS user, you can set up a mode where you have your source in one pane and an interpreter in the other, and can send your code to the interpreter with a couple keystrokes. Good for rapid development. If you're at all scientifically inclined, SciPi/NumPy are your friends.
Also, http://www.boost.org/libs/python/doc/
This is amazing. Definitely a great find, I can't believe I've never caught this in boost before.
You should check out bpython. It is THE best shell for any programming language. (I know that that is not really a library). The PaiMei library is pretty tight if reverse engineering is your thing.
One of most beautiful things about python is that the standard library contains a HUGE amount of useful modules. I swear I learn something useful and new every time I look through the list of built in modules http://docs.python.org/modindex.html. Some examples of things that are built in: XML/HTML parsers, simple HTTP servers, compression, cryptography, CSV files, sqlite3 support etc.
bpython looks extremely handy. Especially for someone who, while they know the syntax, still has to peruse the Python documentation for a bunch of library specifics. Thanks!
mercurial to version all the things! OK, so it's not a library. pygame? django? pylint? Those are the things I see in my site-packages.
Pylint looks interesting, I don't think I'd have a use for pygame or django. Plus, if I were to do websites, I would probably use flask over django anyways
Ah, I haven't encountered a need for virtualenv yet, but I will definitely store that one away in my memory banks. That pep8 style module looks nifty and pretty handy (though I was at first confused where you were going due to the PEP/8 assembler). PDB definitely looks helpful! Basically a (friendlier) gdb for python, good to know they have that. As for logging, python's standard library makes me happy :) thanks for the good response! 
from the std library, i would say to take a look at functools. other good libraries are sqlalchemy and [pbs](https://github.com/amoffat/pbs/) (for running external commands).
So the first program to write in iOS Python would have to be one that exposes a filesystem, then.
Ah, just noticed it!
Check out [Python Module of the Week](http://www.doughellmann.com/PyMOTW/).
&gt; Recognized that the print function in Python 3.0 was a horrible, pain-inducing mistake, the FLUFL reinstates the print statement. This change is important enough to be implemented for, and released in Python 3.0.2. If they did this, I might actually consider moving some code over to Python 3.
&gt; please go away Why?
To love C++ is to be in love with obfuscation and complexity; to subscribe to the credo "if it was hard to write, it should be hard to read"; to value processor time over the time of your human peers. In short, C++ is the anti-python. It is hard for me to believe that an honest programmer can love both C and C++. C is minimalist, C++ is extravagantly maximalist. If one loves C++, one is bound to be disappointed by python. To further clarify. If you are one of these people who claims to love C++ but not: *exceptions *templates *operator-overloading you don't, in fact, love C++. You love your particular C with classes dialect. But since only a handful of other programmers know and love this dialect it is useless. You either love C or you love C++ 
If you don't fancy SWIG feel free to check out my library [PyAutoC](https://github.com/orangeduck/PyAutoC) for C projects.
Good troll, almost fell for it.
Also, you should actually try typing import antigravity.
git
[Python Requests](http://docs.python-requests.org/en/latest/index.html) because fuck urllib2, especially if you're trying to upload files over HTTP. Also, please re-learn programming, people who come from other languages tend to write absolutely terrible Python code.
There is so much hate in your posts it makes me nauseous. Seriously.
Checkout 'Requests' for HTTP stuff Also Flask as web framework is awesome
Follow-up post at http://blog.pythonisito.com/2012/07/gevent-threads-and-benchmarks.html
[Cython](http://www.cython.org), I prefer it over SWIG or Boost. You basically can write python code where you can use C/C++ functions and data types. It is converted into a C/C++ python module.
Second.
&gt; just try it again, because i have the same issue and fix it. merged quickly. https://github.com/sontek/pyramid_celery/pull/18 Given your PR is one month old and the pyramid_celery release before the one of today is from March, I suppose there was no PyPI release containing that till today. I prefer six lines of code over a flaky and unnecessary dependency any day. YMMV.
~~It's funny that you talk about processor time w/r/t C++.... have you seen how slow Python is? In benchmarks, it's one of the slowest, if not the slowest, programming language you can use.~~ EDIT: I can't read.
sys, collections, itertools, functools, contextlib, argparse, re, random, subprocess from the stdlib. Also futures (Python3) or multiprocessing (Python2). Get to know the stdlib before looking elsewhere. ConfigParser, json, csv &amp; sqlite3 are all useful at times. Learn pdb, cProfile, pstats - read http://www.doughellmann.com/PyMOTW/profile/ Don't forget to install pip and virtualenv, especially if you're going to be playing around with third-party libraries. If you think the standard python interpreter is great, try bpython and ipython. Finally - Python is not C or C++. You can easily write some awfully slow/convoluted programs if you code them in C in the Python interpreter (if that makes sense...). Use local variables wherever possible - get rid of global variables and method lookups from loops. Use comprehensions and generators. Use sets instead of dictionaries when the object will be immutable. 
Isn't ipython more advanced at this point? They do the same thing, I can't remember which was first.
Yep, sorry, been a bit slow on the uptake. Merged. 
I also suggest not starting with games. If there's something specific you want to make ask me, I may even be able to provide specific examples. Otherwise just google 'learn python' etc... there are a couple of good free books available.
It is pretty awesome (other than the kind of slow startup, but that may be my crappy work laptop).
Any reason why you wouldn't just use something like [gevent](http://www.gevent.org/)?
I didn't know about gevent. I don't think it existed when I originally wrote it. To be honest I rarely adventure outside of the standard Python libraries anyway.
[ctypes](http://docs.python.org/library/ctypes.html) if you ever need to wrap a DLL.
love it.
Also, the *pydoc* command lets you do that without an interpreter.
To get to the other side...
I prefer to use python because of it (generally) values readability over pedantic correctness and consistency. Adding those parenthesis then, is kind of like a smack in the face, because it was the *&gt;&gt;&gt; print "Hello World", import antigravity* philosophy that won me over. If I didn't care about using extra parenthesis , I'd probably be using lisp to generate XHTML or something ... Fun Exercise, type "import this" and count how many guidelines adding the parenthesis violates .... 
Why on Earth are you claiming this to be a feature of 3.1? 2.7 supports multiple context managers too. 
question about your data... **1.xml** 1 &lt;?xml version="1.0" encoding="UTF-8"?&gt; 2 &lt;root&gt; 3 &lt;someNode id="1"&gt; 4 &lt;childNode&gt;Monkey&lt;/childNode&gt; 5 &lt;/someNode&gt; 6 &lt;/root&gt; **2.xml** 1 &lt;?xml version="1.0" encoding="UTF-8"?&gt; 2 &lt;root&gt; 3 &lt;someNode id="2"&gt; 4 &lt;childNode&gt;Monkey&lt;/childNode&gt; 5 &lt;/someNode&gt; 6 &lt;/root&gt; is line #4 the same in both files and to be removed? (note: it seems like the formatting help lies, lines starting with 4 spaces are not displayed as code!)
If you have to work with xml, use [lxml](http://lxml.de) instead of the xml libraries included with python. Nicer api's, faster. (But only if you *have to* use xml.)
I find ctypes a great way to call native code w/o having to write a native interface layer. Much preferable over SWIG or the c api. Nice Bonus: Extension code using ctypes works on Jython and PyPy.
Thanks. How would they write terrible python code?
Alright, I will pit it against bpython, which I tried last night. Good luck to you :) Thanks!
Thanks for the info! Was so excited seeing that is 3.1, then checked on 2.6, missed 2.7 So 'with' of 3.1 gets better. Despite the numbering, 2.7 was released a year after 3.1. It added a bunch of features that helped compatibility with 3.x. It was a feature to both. Check the same document for the 3.1 release (and the What's New). Not that it's only in this version, but 3.X series has a better potential, is what is been alluded here. 
pbs looks pretty slick, but I'm not sure if it's any better than just going through the os. Thanks for pointing me to it though, it's worth a look for sure
I realize that this discussion may to some extent elaborate on the subject of namespace-packages, and please let it do. :-) Other insights is of course more than welcome. Regarding namespaces: * Why did it work; and if not, why didn't it? * How would you outline Plone in 2012? (I'm curious)
Really cool summary
I'd replace urllib and urllib2 with requests
Awesome! Now, how about a comprehensive provider library? :)
What do you mean by this?
Re-read his post.
Ah, you know what. I somehow missed that when I read it the first time. Thanks. I don't know how I misread it that badly.
Hmm, I wonder if I could use this to authenticate to the Google Apps apis. Their OAuth library is pissing me off.
Mercurial is python. Git is C... Besides you can import mercurial and use as Library some of it's functionality. That's how bitbucket works with django
For me, the only problem with it is that it needlessly and fundamentally breaks backwards compatibility for very little gain. If one could design Python all over again today, use the print function, it's ever so slightly better, imo. The 'sep' and 'endl' parameters are a nice and easy way to specify formating, whereas adding a trailing comma in old python to swallow the newline is an ugly hack. But on the other hand, pretty much every single tutorial on the entire intartubes will start with an example like: print "Hello, world!" Because of the print function, pretty much every single python program ever written will need to be converted in order to run on py3k. Was the statement-nature of the print function *really* such a big eyesore that it warranted all that pain? IMO, no. The other change in py3k that causes major incompatibilities and pain, those involving unicode strings, were really, really needed. The new way of doing strings is far superior. But more importantly, it is quite possible to write your program in such a way that it works well in both py3k and old python. In fact, I think that quite a few programs that has i18n-bugs in old Python work better in py3k. 
In resonse to: That's because what's good for Zope, is usually good for Python. Not in the language sense -- Python's "Benevolent Dictator" and the "Zope Pope" often disagree quite strenuously on how the language should change. What kind of impact had the Zope project on Python? Does it show in PY3K? The web is important: but just how important? 
&gt; Yes but once all threads are blocked, gevent allows you to get yet more requests in since there's the eventloop. gevent only "allows you to get more requests in" because we're spawning a new greenlet for each connection. You can get the same behavior with threads by spawning a thread for each new connection (or spawning threads when all the threads in your pool are busy). In practice, you just don't tend to do it that way because of resource consumption. &gt; Asyncore does exactly like gevent.spawn, you get a handler for each incoming request - http://docs.python.org/library/asyncore.html, so you don't have anymore callback to write than what you did in gevent. Asyncore acts like gevent.spawn, but if you do something blocking with asyncore you need to switch to nonblocking and use callbacks so control returns to the event loop. My point was that with gevent, this happens automatically, and quickly. &gt; I think benching a 'ping' or 'hello world' app makes no sense :D I'd agree with you in general, but if your benchmark of a real app shows no real difference, it can be useful to put together a micro-benchmark to "drill down" into the differences. 
The University of Alberta CS department intro courses are in Python now: [CMPUT 174](https://www.cs.ualberta.ca/undergraduate-students/course-directory/introduction-foundations-computation-i) [CMPUT 175] (https://www.cs.ualberta.ca/undergraduate-students/course-directory/introduction-foundations-computation-ii) I just graduated from there, worked for the university for a little while.
Because it is? The last 2.x releases were developed in parallel with the first 3.x releases.
Ok, I'm with the rest of the /r/python people. This is not a python question. But here are somethings that are relevant. * Do you have to use Python? * For the Excel part, are you using pyexcelerator (if you are using Python)? * Does this utility have to be automated? * What platform are you working on? * What is your budget? I have had luck with DiffDog from Altova for comparing xml documents but that cost money, and I don't know if they have include the automation section yet. Also, it only runs on windows. There is also http://pypi.python.org/pypi/xmldiff/. I haven't used it, but if your xml document is relatively simple, that might be the way to go.
Why do you feel that?
This was a very informative response! Definitely a unique perspective in this thread with the deployment and automation tools! You've also sold me on virtualenv. Thanks a lot, this was a great post.
If the only reason you're turning to cython is speed, I think you won't have much luck with this approach. The python you use is simply not very c-like: "dindex.append([i,j])" for instance is always going to be slow. I think you'll gain much more by "vectorizing" your code, i.e. ditch the for loops and express everything in numpy algebraic operations. The code above looks like it could be replaced by something like (*warning* totally untested, just to give you an idea): mask = d &lt; (3*s)**2 gauss1D = np.exp(-d[mask]/(2*s**2)) sumg = gauss1D.sum() tsStim = dot(gauss1D,tsStimArray[mask,:])/sumg As always, when optimizing code: do some profiling first so you don't waste time optimizing the wrong parts of your code.
Be careful because I don't think Requests (a dependency of this) is supported on App Engine yet. But if you're not running on App Engine you should be fine.
I did a major plone implementation in 2007 (company is publicly traded and has really strict documentation requirements). I haven't used Plone for almost 4 years and I am just in the beginning of doing a new site but I am really frustrated with the current doc situation. I haven't yet tried posting questions but when I worked with Plone before, the community was AMAZING especially Alexander Limi. I had next to no experience with python at the time and no one made me feel like the moron I was. I think it would really, really help if they removed or archived the old version docs on the Plone site. I'm not really sure I understand Diazo either. It seems like I need to upload a new zip package whenever I make changes. I have super strict design requirements so I have to be able to adjust minute things when I am online with the agency I am working with so I just ended up using custom files. I guess when I get some breathing room, I will package and switch back. 
What was the other time?
no mention of numexpr? 
quite complex.. and XML everywhere.. it feels to much 'J2EE-like' for me. I rather have a very simple framework so I can have control over my code base and build my stack. That's why my choice (for python) is Flask.
I haven't tested it myself, but I've heard reports contrary to this.
What a lack of imagination. How about: `body { transform: rotate(-0.2deg);}`
[Nope.](http://pydanny.com/the-sorry-state-of-python-oauth-providers.html) &gt; **Updates** &gt; &gt; 03/05/2012 - Removed Velruse from the list of providers as its lead, Michael Merickel, clarified that it is not a provider. 
In both threading and greenlets, the key to being able to handle incoming connections - and do useful work - is entirely dependent on having an available thread/greenlet to *do* that work. The event loop doesn't enter into the equation, except as an implementation detail of greenlets. Rather than blocking, patched stdlib calls yield to another greenlet that's ready to run via the event loop. If nothing's ready to run, the program waits until some event makes something ready to run. Consider having fixed-size pool of workers (say 20). Whether they be greenlets, threads, or processes, once you have your 21st concurrent connection, it must wait until some worker completes its task before it does any useful work. On the other hand, if you're spawning a new worker for each connection, you can handle incoming connections, doing useful work, until your system resources (ports, file handles, RAM, CPU cycles, etc.) are exhausted. In twisted and asyncore, the programming model is different, multiplexing a single worker explicitly by using callbacks when you need to call some otherwise-blocking function. Your event handler then terminates, allowing other event handlers to run. And yes, I realize that if something is *truly* blocking in gevent, twisted, or asyncore, you will halt all workers until the block clears. So with twisted and asyncore, you use nonblocking IO and set callbacks, while gevent does this transparently so your code appears to block (when in fact the *implementation* of the blocking call is such that an implicit event loop is entered, allowing other greenlets to run). In fact, there's very little difference with threads when it comes right down to it. When a thread makes a blocking (truly blocking) call, it doesn't actually halt the machine; it simply yields control to the OS scheduler (analogous to the event loop) which picks another thread to run. (And as for microbenchmarks, they're useful when you can't benchmark a real app, or you need to estimate how some portion of a real ap would scale. They provide nice bounds to the performance discussion, allowing you to set upper bounds on performance and make good guesses as to the kind of apps that would benefit from an evented versus threaded approach without actually building the app and testing it.)
I'm doing those all the time :D if you want SQL then django is best option due to current tools in my opinion. Otherwise anything goes. Flask is bit to on light side (it was compared in micro-frameworks battle) so more stuff you need to do by your self, also i'm not fan of using request as global variable... 
python-imaging is already the name of the PIL package in [debian](http://packages.debian.org/squeeze/python-imaging). That's not going to be confusing at all...
It really, really does. Here is why: * It makes it very cumbersome to write a single file that will run in both old and new Python. Sure you can use 2to3 and 3to2 to "compile" your source, but that means you add a build step to an otherwise build-less development environment, which can be a major hassle, especially with all the frameworks like django that autoreload your files when they change. * It splits the community in two. Want to write a Python tutorial? First you need to decide if the tutorial will be about Python2 or Python 3! And since everybody is using Python2, all the tutorials target Python2, which means that we can add "there are no tutorials for it" to the list of reasons why people aren't using Python3.
I think this is the problem... many people misunderstand what Plone actually is. As stated above it is an extensible CMS product. It is not a framework. Yes you can use it as a framework -- in the same way you can use an 18-wheeler to drive to the supermarket. It will get the job done, but it is not the right tool for the job. If you want a framework then, yes, use Flask, or Pyramid or similar.
That very much depends on what your problems are. If you are a general web-app developer and creating the next Twitter, then no, Plone is probably not for you. If your job is building intranets or large complex websites then Plone is a very good tool for the job and solves many of the problems you will have in that space (e.g. user management, authentication, scalability, etc). And for that role it is very cost effective versus comparable products.
A few comments on your points: 1) ZODB. Yes it is different to a RDBMS, but it is designed for the problem space it is being used in. ie. scalable, high-read, transparent persistance 2) The Zope Corp product you are referring to is Zope Replication Services, which was a commercial product. There is now a thing called Relstorage which is open source and allows you to use Postgres or Oracle as your backend storage for the ZODB. This was specifically created to solve the problem of replicating the ZODB or a company policy that 'everything goes in Oracle'. It allows you to leverage your existing RDBMS infrastructure, but still gives you the power and simplicity of the ZODB at the programmer level. 3) Whilst Plone does move fairly quickly, we do try not to make backwards incompatible changes within a major release series. There is a project at the moment to developer a higher level Plone API which will insulate people from lower down changes when you do major version upgrades. Also, Plone is one of the few CMSs that come with migrations to move you content from one version of Plone to the next. Like everything it is no silver bullet and many people still have to deal with 3rd party products changing with major versions. Zope itself has had very little changes now in about 5 years.
Also, the point of pillow is to eggify PIL for setuptools' easy_install. So the debian package doesn't need to change.
It solves problems *many* people have, with little cost. But those people are not developers. Plone is a content management system, not a framework. The target group are not web application developers, but people who build public websites and intranets. 
Namespace packages work fantastically well, and will be included in a future version of Python 3, in fact. I'm not sure I understand the second question.
This is fantastic. Thank you, thank you , thank you!
ctypes becomes useless when trying to call c++
Well that's less an issue of the print function specifically and more an issue of p3k as a whole.
And what about [substanced](https://github.com/Pylons/substanced), a new project by the Pylons group, which seems equivalent to Zope, but based on Pyramid?
I will put this on my todo list. Maybe something like weave? One could write extern c adapters inline with your python code? My predominate use of ctypes is to call small functions that I wrote or c libs, I admit, I rarely call c++ code.
http://docs.pythonpackages.com/en/latest/faq.html#q-what-does-pythonpackages-com-do-for-me-that-i-can-t-do-myself
True, Pillow's setup.py imports from setuptools and not distutils. And the setup.py contains numerous lib path additions. To your point, I assume the debian package simply contains the files to be installed in site-packages (i.e. already python setup.py installed)
Good luck at the Bad Title Awards ceremony.
Agreed across the board. I am very glad to hear about the progress in the zope/plone community, all of whom I found to be exceptionally talented coders and generally nice people. Personally I won't be returning to that tool set for various reasons, but I am sure many others might feel differently.
I did [a quick screencast of the theme editor](https://vimeo.com/42564510) back in May. It's moved forward quite a bit since then, as the author (Martin Aspeli) and a group of designers from UCLA have been putting a *lot* of time into getting it right.
For every project, I have a file that lists the versions of libraries the project needs. When I want to use the project on a new machine or new version of python, I just have to run one command: pip install -r reqs.pip Here's an example file: https://github.com/JeffAMcGee/friendloc/blob/master/reqs.pip .
pip until you need to build c extensions, then it fails miserably on windows the last time I checked.
congrats, you will now earn your virtualenv and/or buildout newb badges. proceed to the google machine. :)
I use pip on windows with c extensions all the time (with VS2010). Although I usually have to run vcvarsall.bat myself because pip seems to have trouble finding it.
/r/gamedev is that way ---&gt; Also, pygame is a good place for you to start. [Invent Your Own Computer Games with Python](http://inventwithpython.com/) is a free e-book that will get you started with both python and pygame. I also recommend looking at [this tutorial](http://ezide.com/games/writing-games.html) to get an idea of how to implement a simple event-driven engine.
Thought that I should also mention python-mode supports shells over tramp after some changes earlier this month.
Most of Zope's direct impact can be seen in the early Python 2 releases. In addition to the other things mentioned, there's also the threading module or many features of the pickle module coming from Zope. One of the later contributions are interfaces, which got into Python in a slimmed down version in the form of abstract base classes. But a number of other larger Python projects use the full interface implementation from Zope. Probably the biggest contribution wasn't so much code, but attracting developers and business people to Python. As aclark mentioned, Zope made most of its impact up until maybe 2003 (Python 2.2/2.3). Plone never had much of a direct language level impact, but contributed as one example of a successful product built on-top of Python.
What 'command' are you doing again? When something goes wrong, show the actual code. In this case I'm guessing you're doing the for loop and the print statement again, but you need to be unambiguous. I would guess that iterating over a file basically consumes the data a line at a time, so that once you get to the end the data is all gone. Try adding txt.seek(0) to 'rewind' the file read position before you iterate over the file the second time.
That's the exact code. Your solution fixed it, I needed to do the txt.seek(0) command in order to get the read position to the beginning, thank you.
"asked 7 hours ago" If you're going to ask a question there, give it some time before cross posting it.
This is by far the least intelligent thread I have ever seen posted to /r/python.
Can you explain a little more about this? What makes one better or worse for games?
Thanks for your contribution :)
It depends what kind of video games you want to make for a living though; there is so much money in lower performance gaming like the browser/phone market that being able to do high-end graphics stuff for the big old studios isn't as essential any more.
That's, a great, way, to put it... 
Great explanation, thanks for clarifying it :) How about tools like [Py2exe](http://www.py2exe.org/). Would that help speed up the program/avoid that disadvantage?
 print(12586269025) print(20365011074) print(32951280099) print(53316291173) print(86267571272) print(139583862445) print(225851433717) print(365435296162) print(591286729879) print(956722026041) (I actually wrote a Python program to generate this, heh) 
Just an addition, you might have pointed out that there are other languages that are far more readable than C/C++, yet will give the same performance gains. They aren't used as much for professional game development, however.
Java, and PyPy interpreters have the ability to compile bytecode into machine code ahead of time(and they can cache it) - a sort of hybrid solution, but the basic slow down is still there.
I don't know. I am not familiar with it. It might help it slightly. What it will do for certain is not force people to install python in order to run your game/binery file.
As I understand it tools such as Py2exe don't compile your source to machine language. They just bundle the interpreter with the source so it would still take the same performance hit.
In my understanding, no. These tools just package up the python interpreter and your code (along with necessary dependencies) into what I can best describe as a self-extracting archive. When you run the resulting .exe it extracts the interpreter and all and then runs it.
haha I like this. Can the fibi sequence be optimized for multi-processors. I cannot think of a way to do this, since I need the most recent values to get the next 1. my computer is currently going for the 100,000th number.
Probably not worth the effort - I guess you could use one of the [fancy direct computation methods](http://en.literateprograms.org/Fibonacci_numbers_\(Python\)) and have each one start at different points.
i refer to programming to my nonprogrammer friends as "legos for big kids"
Plus [usually] having for comfort the provable fact that a solution exists. 
actually, you can calculate N element in the fibonacci sequence with a fixed-length series of steps: https://en.wikipedia.org/wiki/Fibonacci_number#Closed-form_expression
Flat is better than nested. The python standard library has many functions in one file/module. Some people will say this makes it hard to find things, but you're going to have to look up where things are anyways, so it's better to have fewer levels to dig through. also, stop writing classes: http://www.youtube.com/watch?v=o9pEzgHorH0 and the __all__ variable sounds very complicated. Also, NEVER use import *, it seems more convenient, but it incredibly easy to accidentally overwrite methods. It's actually better to do this: http://code.google.com/p/pynastran/source/browse/trunk/pyNastran/bdf/bdf.py than this: http://code.google.com/p/pynastran/source/browse/tags/0.4.0/pyNastran/bdf/bdf.py http://code.google.com/p/pynastran/source/browse/tags/0.4.0/pyNastran/bdf/__init__.py http://code.google.com/p/pynastran/source/browse/tags/0.4.0/pyNastran/bdf/cards/__init__.py I wrote that code and it looks nice, but it's a pain in the ass to trace dependencies. I wrote both implementations, and 50k lines of code later, I changed it. The main reason to trace dependencies is actually for your IDE. IDE's hate import *.
The closed form expression calculation actually relies on the precision of the numbers used, so it is not actually fixed-length as increasing the precision increases the computations nessecary. The link from AgonistAgent contains some other interesting quick methods, however. Also, going backwards (F_n -&gt; n) the imprecision works to our advantage.
Very good. If you're looking for more fun math/cs problems to do, check out Project Euler. Python actually has arbitrary precision integers, so it's not gonna happen until you run out of memory.
well, okay, fixed length of real-number calculations then? ;)
Python programmers do it with generators!
Unlike most puzzle games, though, you can create more tools.
But C++ is gross!
fair enough. I don't know of any real use for fibonacci numbers anyway, so I'll bother with generating them when I do :p also, I was being kinda informal with that big-o there. I meant, relative to the big-o O(n) of calculating by iteration, it would probably be 10x faster linear time.
You have four basic elements, water, fire, earth, and air...
Uncontrollable urge to write it in Haskell: fibs = 0 : 1 : zipWith (+) fibs (tail fibs) take 10 (drop 50 fibs) 
I second the suggestion to use cython -a to pin-point hot-spots. Cython should give you ~10x improvement over a numpy vectorised version and using numpy should give you 20X improvement over pure python (approximately, that is). Thus, if you're seeing a slow-down in Cython there's something wrong. To make it easier to optimise, I suggest using more intermediate variables. Just be sure to give them a cdef, so that the compiler can optimise them away. Try to use simple C types; only use numpy types if you really need to use numpy arrays. Python list indexing and appending is fast. However, using C arrays (malloc'd blocks of some C type) is faster still. Don't use np.exp for scalar math; cimport exp from the stdlib (i.e. use the C standard math exp function, not the numpy one). I think this may be your main bottleneck. Looking at the output of cython -a, it seems python is doing an object function call (very slow) for this. 
Pose test; get educated. Great thread guys. I script a ton, but no real background...it's great to see what complexity can lie in solving such a seemingly trivial task!
I had never seen x, y = y, x + y! Awesome.
I have never seen Haskell, cool syntax! 2 lines for the win.
Awesome! Looks like you can toss num3 though.
Not enough Wolfram|alpha
Cython supports OpenMP which makes parallelising a C for loop trivial. See http://docs.cython.org/src/userguide/parallelism.html I spent some time on a numerical algorithm trying Cython/OpenMP vs PyOpenCL and on every system I tried, OpenMP blew the GPU code away. My conclusion here is not that GPUs can't outperforms CPUs for numerical work, but that writing fast GPU code is VERY VERY hard. I spent a lot of time reading books on GPU programming and learning about GPU memory management but in the end, it was way quicker to find a machine with a big 6 core CPU and use the quick-to-develop Cython/OpenMP code.
&gt; it locks your data in If your data is in a RDBMS, you still need to understand the structure in order to write queries that pull it together in a meaningful way. Depending on the application, this may be non-trivial. &gt; MySQL has had good replication for a long time As pointed out above --- with RelStorage, Plone has MySQL's replication. Also Postgres and Oracle replication. See e.g. http://plone.org/documentation/kb/scaling-out-plone-with-relstorage-and-replicated-mysql
So basically the most popular Python packages that haven't been ported yet?
I would guess that typing code with a pinyin input program like Sogou would lead to lots of small errors, although I can see how this might be appealing to lots of people. Are there other programming languages that have been translated into non-phonetic written languages?
Python's sort-of-destructuring assignment is pretty awesome.
web2py (number 10 in the list) was ported to Python 3 more than six months ago twice: (https://github.com/cannatag/web2py-python3, http://code.google.com/r/reingart-web2py/source/browse/?name=py3k) In fact web2py is written to be python 3 friendly. Yet this presents some problems for us: we promise backward compatibility, the python 3 port would break all existing apps (edit: because apps are written in python themselves by third parties); we support 10+ database backends, the python 3 port would not because of lack drivers; web2py went through years of testing and so did the modules we use, the python 3 port would not be trusted as much (+); web2py is supposed to run on GAE, but GAE does not support python 3 (yet). (+) the real issue is that the change from bytes to unicode is impossible to debug since errors only show up at runtime. Because of reasons above, I do not think it makes any sense to have a web2py port to python 3. It may make sense to have a web3py which is similar to web2py but breaks backward compatibility in other ways as well. 
This list is a little misleading: - Django -&gt; announced preliminary support starting with 1.5 - wxPython -&gt; the [Phoenix project](http://wiki.wxpython.org/ProjectPhoenix) has [snapshot builds](http://wxpython.org/Phoenix/snapshot-builds/) that support Python 3 - matplotlib -&gt; [already ported](http://pythonsprints.com/2011/04/8/matplotlib-python-3-thanks-cape-town-group/) and merged to mainline, snapshots available, waiting for next release (1.2) - PIL -&gt; abandonware, last release over 2.5 years ago. Work underway to take the Pillow fork and modernize it. - setuptools -&gt; abandonware, replaced by Distribute which already supports Python 3 
So, on average it's I'm a god who sucks at thinking.
Something I've always wondered: could a Python program in theory be compiled to native machine code and executed later on? Would there be an increase in speed, or would it not matter because all the bytecode instructions would have to be added to the machine code, or what?
don't you have to get the headers and libs as well? For example, try pip install pyzmq 
*Life* is similar to a puzzle game in that you have a goal and a limited number of tools at your disposal, and you just need to figure out a way of combining those tools to reach the goal. - FTFY
it would have been interesting to somehow gauge as part of the poll who is voting, and how they use python(if they do). I'm surprised ron paul didn't make the list of things to port to python 3
1. In python3, use `print(fib_sequence[i])`. 2. Largest number? http://stackoverflow.com/questions/94591/what-is-the-maximum-value-for-a-int32 for i686, I believe. Much bigger for x86_64.
Combine the loops.
&gt; Each time your game runs, when written in python, it has to go through an interpreter, that will change the byte code into machine code. This is not correct. The Python interpreter is already in machine code (assuming CPython) and it just interprets the code. It does not change it to machine code the same way as a word processor does not change the sentences you type into machine code.
&gt;I'm a god who sucks at thinking shudders! that is one frightening sentence
try to run gImageReader (Tesseract OCR GUI written in python) and see how good it's conversion results are. if they're good enough , just reuse the code.
Could it? Yes, but only via language translation as far as I know. Like what Facebook does with PHP. Once they want to deploy some code they've written, it goes through some sort of translator which switches it over to C and then compiled it down to machine code like a normal C program. I'd assume that with the proper translator, any language could be made to do that.
That comes when you get a job, I suppose.
Copy the .py files and let it regenerate pyc files next time you import them.
Pretty much nailed it, except programs are more practical. I've always compared programming to the level editor in LittleBIGPlanet or creative mode in Minecraft.
In theory it is possible. However, in practice there are a number of things the python run-time environment does that would make this difficult.
Sort of. You can look at what the pypy project does. There's two elements of interest - one is the idea of RPython, which is a restricted subset of python (one where types can be inferred statically, among other things) which can be compiled into C and then into machine code. Compiling full Python is probably much closer to impossible due to the extremely dynamic nature of the language. The other is the idea of JIT (Just In Time) compilation, where the interpreter/VM (which in the case of pypy is written in RPython) analyses the program as it is being run and compiles parts of it which it detects are running often (such as a main loop). This is the same technique as used in most Java VMs. This allows some of the advantages of compilation (greatly increased speed in many cases) but with the fallback of the actual interpreter so the language isn't restricted.
I agree... I just started taking Udacity courses a few months ago and love it! One of them (CS253) is taught by spez!
ONE OF US! ONE OF US! ONE OF US!
Are you saying that even though god might be omniscient, he is bound to be as stupid as this computer I'm typing on? Hence we conclude that god is merely a library of all knowledge
Also learning C++ makes you appreciate the simplicity of python even more.
Nop, I'm saying he should be beyond thinking. Thinking is a human way to tackle the difficulty of not knowing things. Saying that god thinks is saying he is stupid as a human or an animal.
I have also never seen Haskell, WHAT THE HELL.
I sometimes think of the process of creating spells in Harry Potter as a kind of “reality programming”.
Can you explain how that works?
&gt; **I AM A GOD WHO CREATES IDEAS FROM THE VOID AND MAKES THEM REAL.** That's impossible...you can't create an idea from the void, void returns nothing.
Is the claim that a void created itself as well as every other byte in existence from void.
Yes, but the point is that if you just want to look at historical views then you could also say that MySQL didn't have replication back then either. So it is a kind of moot point. The fact is the ZODB *did* have replication back then, just it was a commercial product.
Additionally, * Pylons -&gt; new development ended, successor project Pyramid already supports Python 3. *(Not that that's a comfort to folks who want to keep using Pylons, since Pyramid is quite different - though I've heard Akhet is a good compatibility layer)*
This. Is. Awesome. I'm learning golfscript.
It does when I pass in pointers or references. There's always ways to get around the void.
Aristotle said that godhood was thinking on thinking.
More like a hard wired logical circuit board covering every possible input combination, taking everything as input, feeding output into everything including itself.
So that makes god a database containing all knowledge that has, is and ever will be. Dear god I don't want to defrag him.
Maybe he is distributed, and you can defrag every piece at the same time! EDIT: I liked your definition : )
It gladdens me to know this, I am considering attempting to learn python alongside blender to make video games. This post might have pushed me over the edge in favour of it. Thanks. I think.
So, it has come to this ... 
It's a lost cause man... http://plope.com/Members/chrism/succeeding_poorly 
Not when you get paid for it.
There are examples and an entire game in the examples folder. Also, there are tests to use, and a robust API documentation... And the user guide shows a lot of examples. I'm not sure what else you expect. 
using xmltodict. https://github.com/martinblech/xmltodict it's a little module and is used like this xmltodict.parse(""" &lt;?xml version="1.0" ?&gt; &lt;person&gt; &lt;name&gt;john&lt;/name&gt; &lt;age&gt;20&lt;/age&gt; &lt;/person&gt;""") # {u'person': {u'age': u'20', u'name': u'john'}} set up 2 dictionaries to save entries from your 2 xml feed/datasource/results loop through both your xml feed/datasource/results adding each row to the correct dict you can use set to compare, or loop through like this xml1Dict = dict() xml2Dict = dict() for result in xmlObj1: if result['person'] in xml1Dict: pass else: xml1Dict['person'] = result['person'] do the same for the second file, then compare the 2 dictionaries, using it to create a dictionary of unique results. then loop through the results dictionary writing csv/excel rows as you go. i reccomend using the csv module in python as it's very straight forward and included out of the box. you can read the files in excel. 
Oh, no, it won't be actual source, but it'll be entirely sufficient for writing exploits.
I have a VIA C7 1.5GHz that I use as an appliance box. Right now, it's a router, but I've used it for other things in the past. I wouldn't want to use it for number crunching, but it's quiet and low power. I would estimate performance somewhere around that of a Pentium III.
If you want to write in python but still use the ton of(sometimes highly documented) matlab code out there there's mlabwrap. There's also a software engineering course for scientists, which uses python. http://software-carpentry.org/ 
Python 3 in a nutshell: &gt; You go first. &gt; No, you go first. &gt; No, you. ...
using EPD 7.2-2 64-bit. do i really have to mess with BLAS?
MySQL has had replication since 2000. Zope got it sometime slightly before last tuesday. By bolting on MySQL. The best way to defend zope and plone from my point of view is to cede the points where people can easily and accurately attack the technology: database, speed and a weird complexity/weight for the particular niche it fills. Instead move the discussion to the things it is brilliant at and has compelling use case arguments for: * Code security: Zope and plone have had what, like two security patches in the last decade or something? Put that up against the PHP based solutions most people are going to throw at you. And we will leave out Sharepoint, cause it loses against Plone on the base arguments anyway. * Access/Workflow Models: You need fine grained user security permissions and editorial workflows, Plone was built around these. They aren't bolted on, they were there from the ground up and are the heart of the product and maybe something does these as well, but I haven't found it. * Professional Community: This one is a double edged argument, but you can always turn it to your advantage. Plone has a much smaller developer and integrator community than pretty much every other product in this area, and as a result the costs of these consultants are relatively high. You also get what you pay for in this case. Plone has a fairly high barrier to entry in ramp up time for consultants, but I have yet to meet anyone selling professional services in this space who isn't a stone cold professional technologist. In stark contrast to the Sharepoint and PHP folks, who often are walking arguments for some kind of licensing system for people selling computer services.
Instead of working with real numbers you can work with numbers that smell like complex numbers. So you work with numbers of the form a + b * sqrt(5), where a and b are unbounded integers. You can then define addition and multiplication on these numbers to work in the way you expect. Doing this is more effort than just using doubles, but you also don't run into issues with precision. **EDIT:** Though if you're going through all the effort, you might just as well use the matrix method.
&gt; What does this do for me that ctypes doesn't do? ~~The biggest thing?~~ it'll be wicked fast on pypy. ~~I'm pretty sure that's their biggest reason for writing it -~~ ctypes is proving too hard to make fast on pypy.
I know ill get hate for saying this. My solution for mac os x mountain lion was ubuntu. Apple broke too much this time and they're going in a direction that hurts free (as in freedom) software. Python is free software and probably wont get hurt but i dont see a gaurentee for many other free software projects. Apple does NOT care for free software. If you continue with apple dont say i didnt warn you.
I've posted suggestions on stackoverflow. I was using pytesseract recently and have some patches to publish if you're interested. Definitely start at the command line first whilst you're debugging. First I'd try upsampling to a higher resolution, then restricting the character set, then working with PNG (to avoid artifacts/antialiasing). You can specify 2 column support too.
I'm considering upgrading, what else did it break for you?
Really nice tutorial. I would liked to have seen stuff about using matplotlib though rather than gnuplot. While I think gnuplot is excellent, it is nice to be able to do everything in one python script.
Java really? I opened Terminal and typed "java -version", OSX said I didn't have it and asked to install it and bingo Java was there again.
This did the trick for me: easy_install pip pip install virtualenv
Java worked fine for me, too. Don't know about MacPorts, as I switched to Homebrew years ago and haven't looked back. You're expected to have to reinstall MacPorts with every OS upgrade, anyway. Xcode worked fine, too; I just upgraded to 4.4 and reinstalled the command line package. Maybe I got lucky, but Mountain Lion broke nothing for me (not even pip, but I have a version of Python installed via Homebrew).
Interesting... All I had to do was 'sudo easy_install pip' and it worked.
I use [Homebrew](http://mxcl.github.com/homebrew/)'s Python. Never had a problem. For Mountain Lion, I just had to update Apple's command line tools.
Yes, I do. I've used ctypes extensively. from ctypes import * libc = CDLL('libc.dylib') class passwd(Structure): _fields_ = [ ('pw_name', c_char_p), ('pw_passwd', c_char_p), # ... ] libc.getpwuid.restype = POINTER(passwd) result = libc.getpwuid(0).contents print result.pw_name # prints "root" I guess I see what you mean about API, but I don't love the idea of pasting C code in strings in the Python code either.
Also, ffi.cdef must alter some global state in the ffi module? There is no way of managing different namespaces? The idea of having compiled code cached somewhere doesn't thrill me either. Not saying this is total crap or anything, just pointing out my first thoughts after seeing it.
still waiting for VTK. sounds like that will be my last holdout. no gui in python 3 till then...
seriously...when enough people bug developers they do add support. it worked on me... the code is still better in python 2, but that's cause unicode is hard
and yet there is no indication that Apple is doing something to prevent free software from running on the mac. The only thing free software devs 'might' have to do is change some things to make it support Mountain lion (shouldn't be that big of a problem because xcode-switch provides this functionality for you..) and register for an apple developer account (free) and sign their final executable (python, ruby, whatever) with their apple developer id key, which is again the same model that microsoft has been using for years. Its for the user's security. 
ctypes can only wrap functions, not macros. ctypes only knows about 19 primitive types. If your C code uses other types then you're going to have to translate them into ctypes. This can be error-prone and non-portable. (For example, code might use uint64_t from stdint.h. ctypes doesn't know about uint64_t, so you need to translate that to a ctypes type. But uinit64_t might be c_ulong on one platform and c_ulonglong on another.) ctypes knows about structures and unions and arrays, but you're going to need to manually translate the C code into ctypes syntax. You can do it, but it's tedious and error-prone. I'd rather just feed the blob of C code to a program that knows how to do it for me. I agree that you don't want ugly blobs of C as strings in the middle of your other Python code. You should isolate it into its own module down in a subdirectory where it won't scare any children or junior programmers. Just like you would if you had to write some Python-C API code as part of your Python project.
This. Not even a "database with all information". Since the information is hard wired in this circuit.
I find it interesting that I can create virtual worlds with simple rules who's emergent behavior I do not understand. When you take into account all possible gods of *this* universe, it is highly likely that god does not understand his own creation. Assuming, of course, a god exists.
It's a free form text field. People can enter whatever they want whether or not it makes sense.
I understand that. My question was more about why people would vote for it in the first place. I think it shows that at some level people don't understand what it means to transition something from Python 2 to Python 3.
Here's what I came up with for vectorization. What I realized in playing with this is that since you're not doing any matrix multiplies, the BLAS/GPU optimizations are less effective than they normally are. My guess for what's slow is the elementwise tsStim calculation which could be parallelized easily. I removed the convolution calls because I didn't have time to get them working in Theano, but they don't seem to be the slow part. For 800x800x50, I got 1.7s and 320ms for your two versions, and 236ms for my numpy version. The Theano one ran in 40ms with some loss in accuracy from the floats, and it can run out of memory on the (1GB) GPU if I try to make the 3rd dimension larger. import numpy as np from scipy import shape, mean, sum, nonzero, convolve, zeros, std, dot, exp, array def pred_np4(params,hrf,degX,degY,stimArray): x, y, s = params gauss2D = np.exp(-((degX-x)**2+(degY-y)**2)/(2*s**2)) sumg = sum(gauss2D) numTrs = stimArray.shape[2] tsStim = np.tensordot(gauss2D, stimArray, axes=2) tsStim /= sumg ts = np.convolve(tsStim,hrf)[0:numTrs] predictedTimeseries = (ts-np.mean(ts))/np.std(ts) return predictedTimeseries x = 0.1 y = 0.2 s = 0.75 params = (x,y,s) hrf = np.arange(0,25,0.5) # 1d - len relative to numTrs? numTrs = hrf.shape[-1] d = 800 degX = np.random.normal(0,1,(d,d)) # 2d degY = np.random.normal(0,1,(d,d)) # 2d stimArray = np.random.normal(0,1,(d,d,numTrs)) # 3d %timeit _ = pred_np4(params,hrf,degX,degY,stimArray) 1 loops, best of 3: 236 ms per loop import theano import theano.tensor as T from theano import config, sandbox #from theano import ProfileMode #profmode = theano.ProfileMode(optimizer='fast_run', linker=theano.gof.OpWiseCLinker()) from theano.tensor.signal.conv import conv2d X = T.scalar('X') Y = T.scalar('Y') S = T.scalar('S') DegX = theano.shared(value=np.zeros((d, d), dtype=config.floatX), name='DegX') DegY = theano.shared(value=np.zeros((d, d), dtype=config.floatX), name='DegY') StimArray = theano.shared(value=np.zeros((d, d, numTrs), dtype=config.floatX), name='StimArray') Hrf = theano.shared(value=np.zeros(numTrs, dtype=config.floatX), name='Hrf') Gauss2D = T.exp(-((DegX-X)**2+(DegY-Y)**2)/(2*S**2)) Sumg = T.sum(Gauss2D) #TsStim = T.tensordot(Gauss2D, StimArray, axes=[[0,1], [0,1]]) / Sumg TsStim = T.sum(StimArray * T.shape_padright(Gauss2D), axis=(0,1)) / Sumg #Ts = conv2d(T.shape_padright(TsStim), T.shape_padright(Hrf))[0:numTrs] # buggy #PredictedTimeseries = (Ts-T.mean(Ts))/T.std(Ts) t_pred = theano.function(inputs=[X, Y, S], outputs=TsStim) def to32(x): return np.asarray(x, dtype=config.floatX) DegX.set_value(to32(degX)) DegY.set_value(to32(degY)) StimArray.set_value(to32(stimArray)) Hrf.set_value(to32(hrf)) %timeit _ = t_pred(0,0,1) 10 loops, best of 3: 39.9 ms per loop 
You could start by reading basic socket programming [here ](http://docs.python.org/library/socket) but for server it is good practice to start off with [socket server](http://docs.python.org/library/socketserver). So you want to implement a server with socket server module and clients with basic socket module. It is good to read about TCP/UDP to have good understanding of networking protocols. Wikipedia should do the trick. Before anything you could start writing echo server. Thats a good start.
It's good to know and understand sockets, but if you're building any kind of real networking app you should definitely use a full-fledged networking library to handle most of the work for you. Twisted and gevent are the 2 most common/best.
That's why I didn't mention twisted , event driven networking is maybe too early for first project.
Twisted is pretty great.
This sounds like something which http://www.zeromq.org/ (and it's Python bindings) could solve very neatly. Writing good network message passing/socket code is hard. It's less hard if clever people have done the work for you :).
http://www.apress.com/9781430230038 this should cover you
Except that's not correct. If you tried to make an array of passwds it would be totally wrong, because things wouldn't take up the right amount of space.
It's fine for wrapping small C libraries, but wrapping something like GTK+ with it would be a nightmare.
First of all, thank you for the suggestions. I just saw your response, but in the interest of discussion, I'll repost the same questions here. - Concerning your code, I'd be really interested in checking it out. Do you have a github repo I could fork? - Regarding the image file type, is it acceptable to convert JPEG images into PNG, or is the damage already done? I ask because many of the PDFs I've encountered store the images as JPEG internally, so if the problem is one of lossy compression, then I'm sort of stuck with what I have. - How exactly should I go about upsampling? Do you mean I should take the low-resolution image and convert it to a high-resolution duplicate? I want to make sure I understand you, since doing this will not sharpen the image at all (although I can see how it could give Tesseract a finer resolution to work with). Again, I just want to double-check and make sure I'm not misunderstanding you. EDIT: I just re-read your SO post and realized that the upsampling is meant to make the font larger. I also thought it could be worth running an image sharpening algorithm on the text to try to avoid multiple letters from bleeding together. I have a hunch this might be part of the problem (due to the small text size and poor image resolution). Can you think of any reasons *not* to do this?
even if you don't want to use all of twisted (for instance, skipping over the built-in protocols), at least make use of its reactor - a huge amount of work has gone into making that thing reliable.
There's the command server built in to Mercurial that allows it to be used from any language. The [hgapi](https://bitbucket.org/haard/hgapi) project already supports Python 3 so it is possible to interface with Mercurial that way.
Not always a huge fan of ESR, but I found this extremely helpful when starting out. http://www.catb.org/~esr/faqs/smart-questions.html
...um, it doesn't?
This is a good read, thanks. 
Wow, this is great. Honestly, I didn't even know that bpython existed. I wish I could get this style of autocompletion in vim. edit: I suppose [this](http://www.vim.org/scripts/script.php?script_id=850) is as close as we've come.
I couldn't care less about speed since I don't re-compile scss every request. Features on the other hand are something I care about, what features does SassPython have that PyScss does not?
billsil, if you want fast arrays that behave as matrices, you should use numpy.matrix (http://docs.scipy.org/doc/numpy/reference/generated/numpy.matrix.html) rather than numpy.array. i think that will give you the intuitive behavior you miss from matlab. additionally there are a couple of numpy functions, numpy.asmatrix and numpy.asarray, which do type conversion on the fly for the purposes of a single operation. hope that helps. i struggled with that behavior at one point too, and i do not even come from a matlab background. 
You make some nice tutorials. Thanks.
&gt;OK, so they’re implemented as keywords, but you can use them as values, and you can’t assign to them Maybe it's different in python 3, but in 2.7: In [2]: True = False In [3]: print True False 
I'm wondering why the 16 second interval poll. You might want to take a look at something like Twisted or tornado (which I am much more familiar with). Specifically, register your sockets with tornado's IOLoop (an epoll-based loop), and respond to the receiving of data via a callback. Tornado's httpclient can also get you in the right direction of passing the results on to another server.
http://pastebin.com/DLvn22ps easier to read
True, False and None are not keywords. They are a types (classes if you will), of which there is one singleton instance that is the same througout your code execution (assuming you don't assign to it, which you can, which is about the worst idea ever)
Is this a class?
&gt; Maybe it's different in python 3 Yes, I should have been more clearer. In Python 3 you can’t assign to them, which effectively makes them constants, and hence why I was talking about them. They happen to implement that by making them keywords.
This is interesting. we have some similar code in web2py dal (MongoDBAdapter) which allows you to do: % python web2py.py -S mypp -N &gt;&gt;&gt; db=DAL('mongodb://127.0.0.1:27017/db') &gt;&gt;&gt; db.define_table('person',Field('name'),Field('age','integer')) &gt;&gt;&gt; rows = db((db.person.name=='Tim')&amp;(db.person.age&gt;21)).select() We could use some help testing it... perhaps we can share some code. Join us on the web2py mailing list if interested. Our goal it to have the some queries to run everywhere (mongodb, gae, relational databases. etc.).
Sockets are the second scariest thing I've faced in python. (If you're curious, my first is recursion) I'd recommend checking out some examples that the pygame community made, like their chat applications. [Here's one example.](http://www.pygame.org/project-CHAT-59-.html)
I will definitely give this a try. I have this 1 strange asynchronous problem using PyScss, it sometimes didn't quite finished compiling all of scss -&gt; css files when my minifier script kick in. I had to put sleep 10 in between scripts execution.
I approve of your use of wildcards.
The rationale here might be that most python scripts wishing to whip up a socket with minimum fuss simply wish to send a chunk of bytes, examine a response and be done with it all. Things like iterating over the lines in a file, and so the I/o loop focuses on the comsumption of each line of text which likely fits within the MSS of the conmection. In this case Nagle's is just fine since after slow start is done we're sending one packet for each line and receiving an ack for each line. In fact Nagle's kinda helps in this case because chances are if the connection drops, it does so after a complete line has been sent. 
It still irks me a bit to see this called "Perlin noise", when I was introduced to the technique via [CGP&amp;P](https://en.wikipedia.org/wiki/Computer_Graphics:_Principles_and_Practice) long before I had heard this guy's name.
However keeping nagel enabled allows for less bandwidth usage.
Alternate code: class starfield(object): def __init__(self, pos , size, max, speed): self.stars = [] self.pos = pos self.size = size self.speed = speed self.box = Rect(self.pos[0], self.pos[1], self.size[0], self.size[1]) self.color = (255,255,255) self.bordercolor = Color(255,255,255) self.backgroundcolor = Color(0,0,0) for loop in range(max): self.stars.append([random.randrange(0, size[0] - 1), random.randrange(0, size[1] - 1)] def draw(self, screen): if self.box: pygame.draw.rect(screen, self.backgroundcolor, box, 0) pygame.draw.rect(screen, self.bordercolor, box, 1) for star in stars: p = (self.pos[0] + star[0], self.pos[1] + star[1]) screen.set_at(p, self.color) def update(self): for star in stars: star[0] += speed if star[0] &gt; self.size[0]: star[0] = 0 Not tested (at work, unfortunatly).
Maybe its just me but I prefer matplotlib's defaults to ggplot2's.
you're being downvoted for posting non-working code for comparison. This would not work if you try to allocate an array (happy segfault) or if the provider of your passwd struct chooses to organize fields in a different order (say private fields before public). Then you would get random data corruption. This is precisely what cffi tries to avoid
Very cool, now do Matlab. Oh please, please improve Matlab's plots.
no, the biggest thing is that it can be actually made to work in a consistent manner, unlike ctypes, where you can't access macros, you worry about sizes of your integers etc. etc. It's really mostly the "works, then fast" approach, ctypes is neither
No sorry, that figure is loosely based on the SO post but is part of a clunky thing I am doing for work. If you are interested, I will include that in as an example.
http://ipython.org/ http://pandas.pydata.org/ http://www.scipy.org/ Now you don't need Matlab ;)
Nah, don't go out of your way. I was just curious. I don't actually need it. Thanks for the other code. I like the ggplot look.
py2exe hasn't been updated in 3 years either. On the other hand, pyinstaller hasn't support python 3 as far as I know.
&gt; " if you’re doing lots of small packets with socket.IPPROTO_TCP." Aarrrgh! If you are using TCP then you are not using packets! It is a stream protocol. You send bytes, one after the other, not packets. Packets are what it gets divided up into by the stack, but you, the developer, do not send packets over TCP.
Yeah this isn't actually perlin noise, its fractional brownian motion. The article linked to in the page is wrong, you can use perlin noise with fractional brownian motion, but the article just uses a pseudorandom number generator for the layers of fbm. http://code.google.com/p/fractalterraingeneration/wiki/Fractional_Brownian_Motion Perlin noise is a specific noise function that takes parameters (1d,2d etc) and creates the same noise value for the same parameters This is Ken Perlin's implementation of his noise function: http://mrl.nyu.edu/~perlin/doc/oscar.html#noise 
Okay, now implement Python in Brainfuck. DO IT. &gt;:D
Funny, I actually debated about the one liner functions. My reasoning ended up being that if I decided to look at this in a few months Good catch with the IndexError and whole exception thing. Hopefully lesson learned? For the dictionary, that exception could easily be replaced by a quick if instr not in gram_table and removed. Thanks for that tip. Next time (I'm thinking about rewriting this as a compiler) I'll try a recursive parser. I didn't figure out how they worked from the few quick blogs I read, and building an instruction tree (umm.. correct wording?) would make it a lot less... whatever it is. Thanks for taking the time to read my code and give me some useful tips! 
You just actually need to get rpython running over brainfuck, and then grab pypy...
It is available outside of web2py. The Database abstraction layer is a single file [dal.py](https://github.com/web2py/web2py/blob/master/gluon/dal.py) with no dependencies. You can use it without web2py. What you cannot do (but we should add the functionality) is to use it to generate the queries without executing the queries (we can do it with SQL adapters but not with mongodb adapter).
Oops, fixed.
Interesting, I can't see this message or my reply on the thread yet. I thought I should elaborate on why I like lambda functions: sometimes you need to pass a function as an argument, but it's too specific to reuse and giving it a name becomes a chore. That said, Python does nested (lexical) scoping reasonably well and writing the function inline immediately before you use it helps with editability and the cues from indentation are good for readability. And where I most use lambdas in other languages is for functions like `map`, where in Python a list comprehension is often a better alternative (where "better" is purely in terms of readability). As for compiling, while getting your head around assembly is worthwhile and the satisfaction of compiling direct to a binary executable is great, compiling via C is a common technique. Produce a `.c` file and let `gcc` do the heavy lifting; you get optimisation and CPU portability for free! It's also a bit easier to debug .. I'd suggest going that way first and then once it's working (a good test suite is essential imo!) switching out your backend to produce native code directly.
Hmm. I noticed the same thing last comment I posted. Server load or something I imagine. Well, I already know a fair amount of C from robot programming, so that would certainly ease the learning curve. I'll look into that for sure.
Switched it to lists for the follow up blog post - speed just as good as far as I can tell!
Ah, no way i could make it over there. Sounds like a great learning experience though. Ive been teaching myself via tutorials online.
We're all adults here, you can say fuck.
There's a package called [mpltools](http://tonysyu.github.com/mpltools/auto_examples/style/plot_ggplot.html) that adds support for styles. It sounds like there are [tentative plans](http://old.nabble.com/ANN%3A-mpltools-0.1-release-td34141199.html) to push this back into Matplotlib.
No, he's right. There aren't any kids on the internet. And no kid can read the word fuck. I probably shouldn't have titled this like I did.
I would guess that the speed is about equal. On the one hand you use tuples, which can be accessed faster, but on the other you are allocating and reallocating memory constantly.
I agree that wrapping a huge library like that would be a nightmare. I'll be interested in seeing how well CFFI does with something like that.
&gt; First I need to get my python Brainfuck compiler working (I shall call it.. Pyfuck?) and then I can rewrite python in compiled Pyfuck. This will only end in tears. Delicious tears. &gt; Coding buddy? Not for this, but I'd be willing to link to my github privately.
Might as well not have an election now.
Link to your open to the entire Internet GitHub profile privately? What is the point of having it? I'm just trying to understand your reasoning.
It's interesting to play with the percentages to see what it takes to get Romney up the charts a little. If you change the swing states to 65/35 instead of 50/50 and adjust the Obama-leaning states down by 5% and the Romney-leaning ones up by 5% (this is a very rough approximation of a 15% swing towards Romney) then Mitt's in with a 1/3 chance of taking it out. That seems like a fairly big swing that would be required. I wonder how much more complicated you really need to make the model? Certainly you'd need values for voter turnout as that sometimes differs between parties. It would also be cool to track the winning margins in each of the rounds and chart the distribution of those.
this method completely ignores how electorial votes work in the swing states. usually what happens is one candidate will wipe out the other in the swing states on an electorial basis even when the actual in-state vote count is very close. your method just gives both candidates porportional amounts which never happens, and in such a case obama would win handidly since he has a built in lead in the guaranteed votes. in reality, romney has a much better chance of winning than what you calculated simply because his odds of getting that electorial sweep isn't that much worse than obama's, and whoever gets that sweep will likely win the election. 
I can't model that in 40 lines of code. I think you are right. This model is over optimistic with Obama winning.
that of course works, but this is not the passwd struct that you want. Try passing one of those to getpwnam_r and see it segfault and/or corrupt your memory.
No, it doesn't. It counts states.
Which is not the case. ;) I know, I know, it's just an example. How would you model voter suppression anyways?
2.7 has been around longer, so it has more helpful resources and tutorials. I prefer 2.7.
I don't agree but in half of the comment. You can use way more libraries and learn loads of more stuff if you use 2.7 and, as you say, it is pretty easy to switch from one to the other.
Looks nice! I will see how it works soon!
Once you know one programming language learning another is much easier. They are very different, but learning python isn't going to take as long as learning your first language. Just pick up [a book](http://learnpythonthehardway.org/) and work through it.
I'd say the difference is that to write decent PHP you must have a firm taste for style, and recognize bad code on the spot (mostly after it came out of your own fingers). There are some really nice frameworks and a huge community where you can find some excellent code base, not all PHP professionals are bad coders after all. The main difference is that Python encourages nice code, and punishes bad code, just like most 'modern' languages (Ruby comes to mind, Java to some extent). PHP is about on the same level as Perl or C, in that you can come up with code that seems really smart, and get away with it until you have to maintain it.
I would stick with 2.7. More library support and there's nothing in 3.x that I feel you'll miss terribly. Start off using the print function (`from __future__ import print_function`) and prefix all your strings with a 'b' for bytes/ASCII or a 'u' for Unicode accordingly and migrating to version 3 won't be too tricky when the time comes.
I love the overgeneralization. Spoken like someone who only has a passing knowledge of the language (in this case, PHP). You're right, new programmers without a penchant for learning will write bad code. They'll do those crazy "if post variables do stuff" type scripts with html/css mixed in. I see those same developers doing the same thing in Python with little difference. Your comparison between the languages is little more than "well if you learned Python, you would learn the RIGHT way to program". Perhaps try coming up with a better argument? 
I'm a PHP programmer, too. I do partial and complete rewrites for various bits of code to fix bugs, to improve performance and to make the code maintainable. I find all sorts of weird bits of code, less than optimal SQL queries, slow code, code which causes crashes, code without tests and code which logs a lot due to encountering undefined variables in the executed code path. Here are a few things which bother me the most about PHP (aside from the fact that a lot of expensive PHP programmers write crappy PHP code): * the code continues to execute after encountering undefined variables (this is a serious issue when you have to pick up code written by others and you find a lot of code paths which spew out such errors) * exceptions thrown without stack traces * built in functions (or functions from loadable PHP modules) aren't organized in modules, they're just global functions * inconsistent function argument naming * function calls are really slow * doesn't have support for (pre)compiling to bytecode, saving it and reusing it all I'll never agree with anyone again that PHP is OK from any point of view. It's not and I know what I'm talking about. If you're happy with PHP, you're more than welcome to earn a living with it, enjoy coding in PHP and like the language, along with its C PHP runtime. 
Overgeneralization. It's like saying that everything done in COBOL is done like we're still in the 60s. But banks don't think that way and more than 200 million LOC are written in COBOL each year and it is still the best choice in some cases.
I started this year with python 2.7 to learn, all books, pdfs, pocket references were available. Sticking with 2.7 until 3.x has a feature that exceeds the value of 2.7 and forces me to adapt.
&gt; I can't model that in 40 lines of code. [Here it is](http://pastebin.com/vFmnyaNr) in 16 lines of code, plus whatever you need for the per-state data.
Until all the people who know COBOL die.
There are plenty of similarities in the semantics of the language, and really if you were to switch to any other language from PHP, Python would probably be the easiest. There are certainly some important differences, however. Instead of PHP's "array" you have lists (for an ordered sequence of items, which can be accessed via a numerical index) and dictionaries (a collection of items associated with identifiers). Dictionaries do not maintain the order of the elements added to them (unlike PHP's array, when used associatively). Python will not coerce number types to a string when doing string concatenation, e.g. num = 3 print("I have " + num + " apples") Instead you need to convert the integer to a string: print("I have " + str(num) + " apples") Or alternatively use [string formatting](http://docs.python.org/library/string.html#string-formatting) This may seem annoying at first, but in PHP and other languages, implicit type coercion is often a source of subtle bugs. Specifically pertaining to web development, you can't just dump a Python file in a directory on a server and navigate to it in your browser, you need to use some kind of WSGI framework. Python files also don't natively function as HTML templates (unlike PHP files), so for generating HTML you'll want some kind of templating system. [Flask](http://flask.pocoo.org) is a good choice to get up and running with both those things.
You may need to review the code a bit closer, especially the comments that say &gt; these are electoral votes
This doesn't handle the winning condition correctly. The condition is having 270 electoral votes, not having more than the other candidate.
Depends on what you worked with when using PHP. If you have a decent grasp of OOP in PHP lets say you can easly work with Zend Framework - you will transition smoothly when doing work with pylons/pyramid (thats how I moved). Python is a nice and easy language that is far more sane than PHP - so as long as you understand object oriented programming and what passing by references means you will do fine.
Numerous minor errors in this post.
I really like this, it's a neat way of performing a random analysis.
It's the best choice not because COBOL is a superior language, but because their backend is already coded in it and maintaining it is cheaper and less time consuming than rewriting it from scratch.
An SQL database also locks your data in. It's just that because it's more structured, it's possible to export to common data formats, like CSV och Excel. ZODB being an object database, can not have a generic export to a a non-object format. That's not lock-in in any reasonable way. Writing an export it fairly trivial. "someone needed to restart and move a zombie zope/plone site and resign themselves to keeping it up indefinitely because of the exceptional difficulty of really getting at all the data in very large sites for export or use for other tools." You seem to be saying saying that it's difficult to migrate a Plone site to some other CMS. This is true, but not in any way unique for Plone. Each tool like that has it's own data structure, and since any ECMS has custom content types, any import/export by necessity needs to be custom. That's just life. Replicating ZODB is fairly trivial, but sure, having a mirror that is up all the time and can fail over automatically is not something I'd try to do with ZODB. So if you want 100% uptime even if somebody pulls the plug on the server and refuse to pay for tools to do that, then yeah ZODB maybe isn't the right tool. But that, honestly, is not a real-life scenario. If you are so dependent on your CMS that it can't be down for ten minutes, then you also have the budget to make sure it isn't. And you are right, today you can switch between RDBM's easily. But the idea that you could was up to maybe five years ago pretty much an illusion. But today the ORM's and other compatibility layers are good enough to do that. But then again, ZODB tools have improved since you last used them as well, to be fair. And no. "Different" does not lead to problems, unless you refuse to care about the differences. If you insist on treating a NoSQL database as an SQL database, you will fail. But that's *not* the fault of the database. 
&gt;As mentioned before, python is strongly typed. This will fail: &gt; print "Total number of items: " + totalItems &gt; Because totalItems is an int. You have to convert totalItems to a string, or use a template. print "Total number of items: %d" % totalItems 
Not very difficult, on the contrary, Python rocks. Main difference: use try: except: all the time (really, use it!) and generators/iterators.
For the sake of people who think they can't use "+" at all: print "Total number of items: " + str(totalItems) (you can use "+" but the two operands must be of the same type and must support the addition protocol)
I disagree I frirmly think that python encourages clear code
If this code is repeated I would create a decorator
I do oftentimes use a separate function or decorator, but the core of the logic still remains something like: if request.method == "POST" and request.args.get("submit"): return render_template("completed_form.html") return render_template("form.html") Just wondering what the OP had in mind exactly, and if this is idiomatic or not.
&gt; Not an error but I'm not sure I understand this. How are they funky? You just place a string as the first line under a class or function definition. PHP follows the java standard. Now compare that to python's standard, and tell me that someone used to the java standard won't find the python standard "funky"? &gt; This is pretty much true for writing general applications, but for writing web apps in Python you nearly always need to use a web framework. Not that that's a bad thing, since Python has some of the best web frameworks in existence. mod_php is a web framework. Zend Framework is a monolithic beast of functionality. Python does not require such frameworks, PHP kind of does. &gt; Subjective. Every function and class in the standard lib has its own page with PHP docs. Python has robust documentation, it's just that you may need to dive down into the page a little to find the information you want. http://www.python.org/doc/math/ceil/ gives me a 404 while http://www.php.net/ceil brings me right where I need to be. Definite difference in ease of use here and one that PHP devs will hate for a while until they get used to it. &gt; No, dir() does pretty much the same thing. There is no straight up equivalent for print_r, but pprint will format things nicely like print_r does, then you can just do something like pprint repr(object) or pprint dir(object) Which I believe are mentioned in the links I provided. Not the same thing, which is was the point right? This was not an attack against python, I love python. The guy wanted to know differences, these are it ;)
Ok, I suppose the docstrings are a bit different from PHP and Java. As for the frameworks, generally when you install Apache it comes with mod_php. So I'm actually going to defend PHP here, as vile as that is, and say that Python generally takes a bit more effort to get off the ground for web development than PHP does. When writing PHP you really don't need to worry about if a specific framework is installed or if Apache is configured to execute .php files as PHP; it pretty much always handles that for you. While with Python you do need to make a conscious effort to pick a specific framework and write code according to that framework, unless you're going a pure CGI route, which no one ever does. With PHP this is optional. The documentation is different from PHP's in that there is not a separate page for every function and class and global variable. I'm not sure if that means it's less easy to navigate, but I guess I never considered that some people may consult documentation by inputting a URL manually. So if someone is used to doing that, then yeah you are right.
I knew someone would post better code. That is half the reason I posted this. Thanks. Here is the actual state data in a format similar to yours: electoral_estimator={'RhodeIsland': (4, 99.5), 'Mississippi': (6, 0.2), 'Iowa': (6, 62.5), 'DistrictofColumbia': (3, 100.0), 'NewYork': (29, 99.9), 'Oklahoma': (7, 0.0), 'Delaware': (3, 99.6), 'Minnesota': (10, 88.6), 'Illinois': (20, 99.8), 'Arkansas': (6, 0.6), 'SouthCarolina': (9, 2.0), 'Indiana': (11, 11.9), 'Maryland': (10, 99.9), 'Louisiana': (8, 0.3), 'Texas': (38, 1.1), 'Wyoming': (3, 0.0), 'NewHampshire': (4, 69.6), 'Arizona': (11, 12.1), 'Wisconsin': (10, 84.0), 'Michigan': (16, 84.9), 'Kansas': (6, 0.4), 'Utah': (6, 0.0), 'Virginia': (13, 56.4), 'Oregon': (7, 88.9), 'Connecticut': (7, 97.7), 'Montana': (3, 14.6), 'California': (55, 99.7), 'Massachusetts': (11, 98.5), 'NewMexico': (5, 89.2), 'Vermont': (3, 99.9), 'Georgia': (16, 2.5), 'Pennsylvania': (20, 79.0), 'NorthCarolina': (15, 27.0), 'Florida': (29, 49.4), 'Hawaii': (4, 100.0), 'Kentucky': (8, 0.8), 'Alaska': (3, 1.4), 'SouthDakota': (3, 2.1), 'Nebraska': (5, 0.1), 'WestVirginia': (5, 2.0), 'Missouri': (10, 12.3), 'Ohio': (18, 66.9), 'Alabama': (9, 0.0), 'Colorado': (9, 61.6), 'Idaho': (4, 0.0), 'NewJersey': (14, 93.3), 'Washington': (12, 93.2), 'Tennessee': (11, 0.8), 'NorthDakota': (3, 2.1), 'Nevada': (6, 75.7), 'Maine': (4, 96.7)} 
I disagree. My programming languages professor had a phrase he was fond of: "The hardes language to learn is your second." It is easy to get stuck in the paradigms of our first language. With that said, from PHP to anything will be a bit difficult. With python though, it will probably be an easier transition than most.
You can't route two different functions to the POST and GET method separately?
*because…*
What loads of more stuff are you going to learn by using 2.7?