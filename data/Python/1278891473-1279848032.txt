I've developed a django site on Windows using virtualenv without significant problems. That said, after this experience I decided to do my django development on a linux VM. I created the virtualenv, activated it, and then did the pip installs of the django and other packages I needed. Everything worked fine, as long as I made sure that I was inside the virtualenv.
I use a Mac but I like keeping my local dev the same as the staging boxes. I am the person you just described.
The only major flaw of the CPython 2.x interpreter to my mind (and I've dug around it quite a bit) is the GIL, and Guido's said he has no intention of getting rid of it. So, there you have it: the biggest problem they could've fixed with a major compatibility-brekaing release of the interpreter, they've (or rather he's) refused. Instead we get syntactic-sugar dickwaving like the set comprehensions notation. Big deal.
Did you run into the same problem on Windows? I've tried virtualenv on Linux Mint and it works perfectly.
No, I didn't have this problem. django in virtualenv worked fine for me, just following the instructions on the tin. My problem was with some minor changes that needed to be made to deploy the application to a Linux server for production. I then decided to just stick with Linux from the start.
What? (Maybe I don't get it because I don't use virtualenv. I was speaking about using Python on Windows daily.)
Having just read the release notes for the latest matplotlib release, it appears that NumPy is their sole dependency (might have been true in the past, not sure).
 def f(s=raw_input().split()):x=s.pop();return"(%s%s%s)"%(f(),x,f())[::-1]if x in'+/-*'else x; print eval(f()) 110C according to vim without eval, 153: from operator import* def f(s=raw_input().split(),o=[0]*42+[mul,add,0,sub,0,div]):x=s.pop();return o[ord(x)](f(),f())if x in'+/-*'else int(x); print f() pps add an import re and replace raw_input().split() with re.findall('\d+|[/*+-]',raw_input()) if you are picky 
Yeah it's dandy until you try to use virtualenv.
&gt;No, I didn't have this problem. django in virtualenv worked fine for me, just following the instructions on the tin. Then there's hope.
Actually even that argument is flawed because those "syntactic-sugar dickwaving" has been backported to 2.7. Also, Guido states that he'd love to remove the GIL, it's just that every successful project that has done so usually results in a 5x performance loss (i may be misremembering the numbers but the gist is the same). So once someone successfully removes the GIL and doesn't lose performance, I'm sure he'd merge it in instantly.
My best shot: 132 bytes. import re;s=raw_input() for i in s:s=re.sub('(\d+) +(\d+) *([+/*-])',lambda m:'%s '%eval('{0}{2}{1}'.format(*m.groups())),s) print s This would appear to get the optional spacing right too.
Doesn't this require there to be whitespace between the numbers and the operators?
&gt; So, there you have it: the biggest problem they could've fixed with a major compatibility-brekaing release of the interpreter, they've (or rather he's) refused. Patches welcome.
Going along this train of thought, i found decently cheap USB GPS unit. Didn't get the opportunity to test in windows, but it works beautifully under linux/gpsd http://www.pharosgps.com/products/proddetail.asp?prod=006_PB010_1.00&amp;cat=141 Shop around, i found one for $30
Wouldn't an easier presentation be "`1 2 3 4 * + -` is equivalent to `(((4*3)+2)-1)`"?
If I recall correctly Sage uses matplotlib for all it's plotting, it'll will be great to be able to have Canvas plots in the web notebook.
You could do something like: &gt;&gt;&gt; def each(seq): ... def do(f): ... return [f(item) for item in seq] ... return do ... &gt;&gt;&gt; @each(range(0,10)) ... def squared(item): ... return item**2 ... &gt;&gt;&gt; squared [0, 1, 4, 9, 16, 25, 36, 49, 64, 81] &gt;&gt;&gt; &gt;&gt;&gt; def inject(seq, init=0): ... def do(f): ... sum = init ... for item in seq: ... sum = f(sum, item) ... return sum ... return do ... &gt;&gt;&gt; @inject(range(0,5)) ... def total(sum, item): ... return sum + item ... &gt;&gt;&gt; total 10 The only problem with this is that the answer ends up being the thing `def`’d, which is counterintuitive. What I am leaning towards as the solution to Python problem of blocklessness is a `where` operator that temporarily introduces a namespace. It would look something like this: total = inject(add, range(0, 5)) where: def add(sum, item): return sum + item After this line, `add` would no longer have any meaning.
whoops, it's about 2 am and I'm a bit tired. didn't notice those at the end :D 
yeah, i did a double take, too.
can you explain the code? for beginners.
from future import ... ...wait for it... futures
and, in the next version, will it be: from __future__.future import futures ?
Greg's free-threading patch lost around 40%: http://mail.python.org/pipermail/python-dev/2001-August/017099.html
Does it mean we will have a parallel map in python finally?
ValueError: invalid literal for int() with base 10: 'Your mom'
Wasn't that the whole point of Unladen Swallow, though? Gain speed elsewhere to compensate for the GILless hit?
I'm not exactly a beginner (been coding for about 2 years - only a recent high school senior), but thanks for clearing up everything. I guess it was a lot to take in at once. I'm gonna go ahead and save this - amazing explanation. Thank you.
[Looks like it.](http://www.python.org/dev/peps/pep-3148/#executor)
yes, and they are imported asynchronously
awesome. hell that's awesome
Thanks, I didn't feel like digging up the relevant info so I made up numbers.
What dwf is saying is that by breaking backward compatibility, it would have been easier to get rid of the GIL. The cost of removing the GIL is mostly caused by the need of backward incompatibility (because it needs to maintain reference counting semantics). The idea of getting rid of the GIL, not being slower and satying backward incompatible means that it will never happen IMO. The unladen swallow went to the same conclusion, BTW.
What do you mean by "type safe"? Percent formatting is notoriously unsafe in at least one respect: if you pass a tuple as the only argument, it gets expanded. Also, I think that % is even less Pythonic than {}, but that's just my opinion. 
Aactually this is longer than Mitsuhiko's solution is you try to add the requirement that "whitespace is allowed as token delimiter but not required except between numbers". If you relax that requirement one can do even better (102): s=[] for t in raw_input().split():s=s[:-2]+[str(eval(s[-2]+t+s[-1]))]if t[0]&lt;'0'else s+[t] print s[0] EDIT: I think we can agree that that requirement costs len('import re;re.findall("\d+|[-+*/]",z)')-len('z.split()')=27 
Without "whitespace is allowed as token delimiter but not required except between numbers" in 101 chars: s=[] for t in raw_input().split():s=t[0]&lt;'0'and s[:-2]+[str(eval(s[-2]+t+s[-1]))]or s+[t] print s[0] or with the assumption (128 chars): import re s=[] for t in re.findall('\d+|[/*+-]',raw_input()):s=t[0]&lt;'0'and s[:-2]+[str(eval(s[-2]+t+s[-1]))]or s+[t] print s[0] 
%i is for ints, %s is for strings
But that's already partially present in the multiprocessing module, IIRC ? see [the multiprocessing documentation](http://docs.python.org/library/multiprocessing.html#module-multiprocessing.pool), method map : apply a func to an iterable. 
I like the concept, I dislike the syntax
Why `if future.exception() is not None`? (I'm referring to this [example](http://code.google.com/p/pythonfutures/).) Is Python becoming the next C? Could the exception not be thrown when the result is accessed, i.e. on `future.result()`? Edit: I find it really ugly that they bypass Python's exception handling and come up with something new. Maybe Guido [should have read the PEP](http://mail.python.org/pipermail/python-dev/2010-July/101744.html) before handing the responsibility to somebody else.
Use ! when doing str.format to force a conversion. 
any twisted guy available for comment? futures and deferreds look awfully similar and the only thing that seems to separate the two is focus (twisted is IO-oriented and futures are computation-oriented). IOW, i'm afraid there was a lot of duplicated effort and reinventing the wheel. i hope i'm wrong.
Here's a [multi-part series on Twisted](http://krondo.com/blog/?page_id=1327).
When someone from, or tied to twisted writes a PEP for inclusion, then we can talk. Otherwise, it will not be included. That said some twisted folk; including Glyph, provided valuable feedback during the process on Python-Dev.
more like from future import concurrent.futures ;)
Yup.
Going to join the thread?
Worked fine with me using Pylons the last time I used it on Windows, but I think I had to modify the paths; I think it wouldn't tolerate spaces or numbers of something. It was definitely a lot more picky about paths.
Kewl. Now all we need is n! cores and we can finally solve those pesky NP-Hard problems analytically ;) Seriously, I am most happy to see this...
python-ldap
I posted to python-dev now. It's a strange feeling, though, to criticize the python developers while being just an ordinary python hacker. I expect to get totally bashed for wasting their precious time with my ignorant remarks. Edit: turns out that both is possible: C-style checking of "return value" and Python exception style when results from futures are accessed. However, none of the examples (in the PEP and on Google code) does reflect that.
First off, we're not in the bashing business, and while I wasn't bothered or particularly offended by your comment at first, you saying what you just said - "expect to get totally bashed" and then sending the same comment to multiple locations other than the PEP author *has* upset me some nominal amount. You also manage - or rather, go out of your way, to insult Guido - why? If you have/had a problem with it, why not just email Python dev - or better yet Brian (the pep author) and myself?
Hey, that's pretty neat! How do you like werkzeug? I read a bit about it and got good vibes, but my python-ing is mostly on the sci-side of things and github's jekyll action works great for my personal web page needs. I'd be interested to know what you think.
Or perhaps he was just smart enough to pass off decisions about things he's not an expert at to others who are.
I didn't mean to insult anybody and I don't understand why I'm not allowed to comment on things on Reddit. Also, as you know, I *did* contact you (although in the comment section of your blog) and on python-dev. So what's the problem? I admit, though, that sending it to several locations was a bit redundant. This happened because I didn't know what the best place was. Sorry for that! (The remark about the bashing was a joke, but it turns out I wasn't completely wrong.)
And you were not bashed for your question, Nick very politely (http://mail.python.org/pipermail/python-dev/2010-July/101789.html) responded to you on Python-dev. I'm not even bashing you, just mildly upset you chose to approach it this way, and were mildly insulting in your comments here.
I like werkzeug a lot because it gives me total freedom. But I'd say for serving static pages you don't need it.
&gt; It's a strange feeling, though, to criticize the python developers while being just an ordinary python hacker. It's that kind of thinking that leaves important decisions in the hands of the few and powerful in any organization. Breach the gap ;)
Agreed x1000. Don't be intimidated - question everything (but do your research before hand).
that's enough for me, thanks.
I know we programmers are lazy but jesus.. knuckle up and code.
For anyone who understands this, I wonder if you might be able to clarify a few things: Would the first entry in the PEP be equivalent to a type of micro-thread that can run asynchronously? For example, could I make thousands of "submit(fn, *args, **kwargs)" calls to create thousands of these asynchronous futures? Are they pre-emptive? (or least can be suspended externally without requiring yields like generators and co-routines?) How is data passed between futures? Can I access shared memory or is there some form of message passing? (I think I see how it's done, but if anybody wants to clarify some more.) Do futures get spread across all CPU cores or are they still locked to 1 process &amp; thread?
Superior auto-completion means the world to me and I love Vim. But Vim fails even when functions are outright returning 'str'. At least for me, there is no plugin *yet* that can save Vim from its auto-doom in that area. WingIDE is the only editor I know with the absolute best auto-completion out of the box. It's better than Komodo Edit by ActiveState and I would definitely consider them second best at it. I know in WingIDE when dealing with an object in which the IDE has no idea the interface that returns you can do an isinstance pointing to a more familiar object for some better auto-completion. e.g., x = [] isinstance(x, str) x. # WingIDE shows me append, capitalize methods... WingIDE shows me the attributes in which it knows are available (for the list) and attributes which I think should be available (str). I think it's pretty smart. I am not sure if you want to be throwing isinstance tests around but they do help with auto-completion big time in WingIDE. If worse comes to worse, try WingIDE.
What about the GIL? There is a lot of support for threads in here, but aren't they still hampered by the single execution model?
&gt; These tools ... just don't work on windows. I've used virtualenv on Windows numerous times without any significant problems. I've also recommended it to my co-workers, and they've used it successfully as well. It's likely that there's something odd about your environment, or maybe there's a conflict due to a previous global installation of Django, or it could be any of a million things--it's pretty much impossible to tell from here. Regarding PIL and other libraries that have C extensions, the issue is generally that the Windows environment isn't set up to compile those extensions, but most popular Python libraries provide Windows installers for this very reason. In some cases, it's actually *easier* to install those libraries on Windows, so I'm not buying the notion that "Windows developers just don't get sympathy from the community". For example, you can get a Windows installer for PIL here: http://www.pythonware.com/products/pil/
okay, so you like shit like "{0!s}" more than "%s". I got it
I'm aware that there is a Windows installer for PIL but that isn't any good if you're running a VirtualEnv as these installers only allow you to install into your root python directory. This also messes up the use of dependency files as you have to manually install all of these modules and then copy them over to your VirtualEnv when pip could take care of them. I don't see why pip cannot detect that it's running in a windows environment and download the files that are packed into the installer, seems trivial to me. Instead it downloads source files and attempts to compile which is a pain on windows. As regards to my initial question I do happen to have it working now. I am though required to use full paths when referring to django files even though they're on my PATH. It appeared that running a python file even in the VirtualEnv resulted in python using the interpreter in the core installation rather than the VirtualEnv due to file associations. The full paths issue I consider the fault of Windows and it's command prompt.
Wait, I don't follow. Doesn't the isinstance() call just return False? Why would it cause Wing to start offering you inapplicable autocompletions... and why would you want it to?
Really though, these days, who doesn't have Java installed? Even my grandma has java installed on her computer.
Thanks. I saw WingIDE has a vi mode as well so maybe its worth a look. Might try komodo edit first as its free... Was really hoping for a vim solution though. Also I don't think matplotlib plots play nicely with most IDE's so I'd still be using ipython in a terminal and just using it as an editor... but having completion like that would be really cool.
In this case it just returns False and has no effect in the code but I think the point is WingIDE picks it up as a feature. I think this was just in example... wouldn't want to have string attributes on a list but it means that you can do things like def function(x): assert isinstance(x, np.ndarray) and then have completion on x. (Obviously you don't need the assert for Wing to pick it up). Without this I suppose there'd be no way for the editor to make any guess about the type of x. 
Ok, I guess that makes sense. (Although I wouldn't wrap it in an assertion... since it returns False, that's just going to throw an exception!) Still, it's interesting. Didn't realize the IDE had this feature.
In my example I would want it to be an ndarray so wouldn't be expecting it to return False. For the completion to be useful you would expect it to return True so I think from reading the Wing docs in practise it is normally used with assert.
As I have understanded, futures is just an abstraction layer above threading and multiprocessing, so they are not microthreads like tasklets nor greenlets. This threads and processes are scheduled by the OS, for windows and linux that means they are pre-emptive. For communication you can choose your preferred method. Memory sharing, channels for threads, ... Sockets or whatever for processes. The GIL only affects CPU bound threads. Processes can spread over all your cores.
I am beginning to understand. I probably should just just started with the Wing docs.
Aww.... too bad for me. Although, I think I found a halfway ok solution to my particular situation for now. Anyways, are futures threads or processes? :) The GIL affects threads so they can't normally run at the same time, but does not effect processes, which is why I ask.
Relax. It's just a way of moving the docs closer to your fingers.
see, for example, http://www.mail-archive.com/python-dev@python.org/msg48220.html
If you develop in Django and use WingIDE this helps... from django.http import HttpRequest def myview(request): assert isinstance(request, HttpRequest) ... 
Good programmers work hard creating lazy solutions. The way you use the word lazy is like "I know we milk are lazy but jesus.. knuckle up and cow". You're doing it wrong.
[PyMC](http://code.google.com/p/pymc/) might be useful to you.
They can be either. Watch this http://pyconau.blip.tv/file/3837706/
You can get this smaller even if you reverse the order of the list; also, you can replace `t[0]&lt;'0'` with `t&lt;'0'` (120 chars): import re s=[] for t in re.findall('\d+|[/*+-]',raw_input()):s=t&lt;'0'and[str(eval(s[1]+t+s[0]))]+s[2:]or[t]+s print s[0]
Futures can use mulitprocessing under the hood to get multiprocess-based execution. The GIL only applies within a single process. The downside is you have to serialize data between them, so it isn't great for everything but it does get you a lot.
I managed to modify pythoncomplete.vim myself to add manual function return types (add them as a dict in pythoncomplete.vim, but will try to make them load from a yaml config file or something) Ta Da! http://i.imgur.com/I7GuC.png Just one or two things to work out but its doing exactly what I wanted.
Is there documentation somewhere that I can read about it? working on both threads and processes seems kind of odd (processes don't share memory, threads are not normally able to execute simultaneously because of the GIL)
:-)
Indeed, that's the idea. http://github.com/grimborg/withtemp/blob/master/withtemp/__init__.py Thanks for the suggestion! :)
Neat; I had a feeling this frame stuff would be relevant, but I haven't looked in to framing. Edit: Not sure I like the "delete all new locals", I'd prefer just deleting ``x``. Is that possible? It's quite likely you'll use ``x`` to set up new variables that you do want outside the temporary scope, and then you'd need to declare them before the ``with`` to ``None`` or similar.
This is why I suggested a ``temporary()`` context manager.
I hope I'm not the only one who reads it as *Gun*icorn
I'm having a hard time understanding why this would be a win, over say lighttpd or apache with mod_wsgi? Sure it's nice you can extend the webserver, but I've, in my limited experience never needed to do that sort of stuff when writing turbogears stuff. Does anyone have some concrete examples that might help me understand?
I added the isinstance hinting to pythoncomplete as well... see here (works with and without assert) http://i.imgur.com/O9fWk.png Together with manually defined function returns (in other comment) this does everything I want and I think is pretty competitive even with wing! (edit: although mine doesnt add completions like your wing example, it would just treat x as a str for completion purposes)
[You're not.](http://thegunicorn.com/)
 16:41 |termie| the gunicorn shoots _you_ 09:51 |termie| the gunicorn cannot be managed This is another perfect example why every dev team needs a PR team.
Just FYI, this is unrelated to the gunicorn team. Just somebody having fun.
Love using it with my Pylons app behind nginx.
It's potentially higher performance, lighter weight, and more tunable to use a server like gunicorn behind a reverse proxy or caching proxy (apache, nginx, varnish, squid, etc.). One thing it can be used for is asynchronous HTTP, e.g. [Comet](http://en.wikipedia.org/wiki/Comet_(programming%29) (see the [design](http://gunicorn.org/design.html) page). A proxy can hold open the connection while the gunicorn workers asynchronously send data for the response. This is not possible in Apache + mod_wsgi as the max number of connections / workers will be met very quickly as lots of requests are held open.
Does anyone know how well (if at all) this runs under PyPy right now?
If that was a comic book, it would be my favorite of all time.
Pretty cool, but missing a few features that I need in my futures implementation.
Yes I think Comet would be a good use-case for something like this. Thanks for the kind reply. 
Good stuff. I think I'm gonna make it my goal next semester to really learn how to use decorators.
You won't need a semester, it takes about an hour or two. It's simply wrapping behavior (a callable) in behavior (another callable), except with a nice syntax to do it. Another interesting area, maybe of even more interest (though of more restricted use) are context managers. And if you want even more knowledge of those things, I recommend looking out the more general uses of higher-order functions in Smalltalk and functional languages (Haskell). At the next step are lisp-style macros and continuations.
That is sweet. I really wish Vims omni-complete could compete with WingIDEs *but* adding this feature alone to Vim does improve a lot. Nice!
For most cases its not intended that you actually extend the server, but we definitely provide a couple different ways to make that possible if a particular use case requires it. A good example of the possibilities are the example worker reloader that acts like the Django development server upgrading code as files change. The single most cited reason I've heard people reporting on why they switched to Gunicorn was its simplicity for deployment. Its a pure Python package, can be installed as part of a virtualenv and has easily managed worker processes. It also integrates nicely into the various daemon monitoring programs like supervisord and runit. The other common remark is that its lighter on system resources than a full apache+mod_wsgi stack. This is particularly appreciated by the people running Python web apps on virtual servers that generally run slimmer in RAM. 
I haven't heard anyone report anything on running under PyPy (or any alternative interpreter for that matter). The only issue I can think of is if your webapp needs one of the asynchronous workers there'd probably be issues with greenlets on PyPy (I'm just guessing there, but I haven't actually tried such things).
hasn't been updated for 3 years! but then again it's win32api :)
You can add selective type-checking to functions with decorators quite easily too ( use a list of types as decorator arguments etc.)
Looks interesting but I hope to god they make the theme less dreary.
Speaking of which, does anyone know of a type checking decorator library which is reasonably complete and well maintained? 
Can anyone familiar with the two compare and contrast this new sf.net with github?
How about PyShahmat? Shahmat is the root of the word 'checkmate'. 
memoziation and timing are biggies.
Nice. I with sf.net would have started this sooner!
Interesting. I start with chess pieces, but later put several other sprites, like robots, aliens, domino pieces or coin stacks (to retrieve a value associated with the object). I thought about PyBoard but that one is taken too.
Does it need to have the "Py-" prefix? Why not just "Shahmat"?
It doesn't need to.
I feel that it's always a little more cheesy when you have a "Py-" prefix but maybe that's just me. Shahmat sounds like a really good name. Another idea is to pay a visit to Google Translate and translate various words ("grid", "chess", "board", etc) into different languages that use the Roman alphabet (or perhaps romanizations of those that do not).
You can omit the zero. I would describe it as saying I prefer shit like "{}" to shit like "%s". It's all shit, but some of it looks more like Perl. Anyway, I learned Python before C, so I was never very happy with sprintf style. It just seems like C or Perl, not Python. On the other hand, I respect that it has a long history and isn't going away anytime soon. 
Found another trick: you can replace `[/*+-]` with `\S` and it will still work for valid input (116 chars): import re s=[] for t in re.findall('\d+|\S',raw_input()):s=t&lt;'0'and[str(eval(s[1]+t+s[0]))]+s[2:]or[t]+s print s[0]
Or as function annotations in Python 3. 
More interesting stuff: Python generators are great, and everyone should master them if they haven't already. 
I don't think you need a Py- prefix for this. For some projects, it makes sense, but for this, I think it'd be much better to come up with a completely different name. I'm not too partial to "Shahmat", but I can't think of a better one at the moment.
what is your irc bot? sounds a bit like a cron like thing to poll periodically, and then on an even have the server send messages via an irc bot.
115 chars: import re r=re.sub s=[] exec r('(\d+)',r's+=[\1];',r('([*-/])',r'x=s.pop();s[-True]\1=x;',raw_input())) print s[0]
Decorators aren't too complicated. For example: &gt;&gt;&gt; @mydecorator &gt;&gt;&gt; def myfunction (arg): ... ...is equivalent to: &gt;&gt;&gt; def myfunction (arg): ... &gt;&gt;&gt; myfunction = mydecorator (myfunction) Decorators are just a pretty and easy way to use functions to modify other functions. There's two built-in and useful decorators: staticmethod, and classmethod. Staticmethod can be used to make a method which doesn't require a self argument. Classmethod can be used to take a function with a self argument and make it suitable to put in a class. For some examples: &gt;&gt;&gt; class MathStuff (object): def __init__ (self, x): pass def sqrt (self, x): return x**0.5 Looking good so far, but what if we want to add some functions to this class after we've already created it? Let's give it a shot. &gt;&gt;&gt; def root (self, x, n): "Returns the nth root of x." return x**(1.0/n) &gt;&gt;&gt; MathStuff.root = root &gt;&gt;&gt; MathStuff.root (8, 3) Traceback (most recent call last): ... TypeError: unbound method root() must be called with MathStuff instance as first argument (got int instance instead) Uh oh, our new class doesn't like the function we wrote. Not a problem, with classmethod, we can make it work. &gt;&gt;&gt; MathStuff.root = classmethod (root) &gt;&gt;&gt; MathStuff.root (8, 3) 2.0 Now it works. Just be warned that when you use classmethod, the first argument in your function is going to be set as the class that you add your function to. It won't be a class instance, it will always be the class. This is obviously a very ugly and hackish way to code, but, if you really don't want to delete a class in a running program, especially in you're in the interactive interpreter, and you'd just like to add a method to it, this is one way to do it. Now, let's see how to use static method. &gt;&gt;&gt; class Test (object): def test (): print "Testing!" Test.test() Traceback (most recent call last): ... TypeError: unbound method test() must be called with Test instance as first argument (got nothing instead) But, what if we want a class where we won't define any instances? We can fix this quite easily. &gt;&gt;&gt; class Test (object): @staticmethod def test (): print "Testing!" &gt;&gt;&gt; Test.test() Testing! Not too hard, right?
Mover.
Why? IDLE doesn't do any completion at all in the editor as far as I can tell. Anyway point is I don't want to replace vim. Plus IDLE doesn't work nicely with matplotlib - or have any of the features of ipython that make it a credible matlab replacment.
Doesn't look like there's anything to compare and contrast yet. The new sf is just an incomplete prototype and a statement of objectives. Looks good, but is just a start.
Hi reddit, I just coded up this simple library as strictly Pythonic alternative to LessCSS, Sass, and other similar CSS-helper libraries. Please take a look at the README to get the general feel for what I'm aiming for, and let me know what you think. This is really just a skeleton for proof of concept, and I'll likely begin using this for my own Django projects soon, which will inevitably flush out all kinds of interesting issues. Also see the TODO file for lots of future ideas. CSS syntax checking would be really nice. 
I'm going to try this out for the name alone. 
Hey, cool. Other than the obvious (the full power of Python), what are the pros/cons of pyssed vs. Less/Sass?
Did you know that decorators can return anything, not just callables? This trick uses a decorator to calculate a value without polluting the global namespace. &gt;&gt;&gt; def inplace(func): ... return func() &gt;&gt;&gt; @inplace ... def some_value(): ... x = 1 ... y = 2 ... return x+y &gt;&gt;&gt; some_value 3 &gt;&gt;&gt; x Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; NameError: name 'x' is not defined
SASS (older syntax) is more pythonic than this in my opinion.
+1 for project name of the year.
JaikuEngine - opensource Social Networks microblogging Platform, powers www.Jaiku.com (Written in Python, Django)
Sourceforge needs to concentrate more on basic UI. Navigating their site is a horrid experience. 
you're not thinking very Pythonically. The name should be a short, common word which evokes cuteness and has absolutely nothing to do with the function of your project.
Yes, an old release, but works and it's at par, feature-wise, even with python's 2.7 version of EasyDialogs (anyway, that MAC OS X specific module doesn't seems to have changed much since its first appearance).
In the sense that SLiP is pythonic, yes. The difference is that pyssed lets you write CSS within Python. I guess the problems Sass and pyssed try to solve are not entirely identical. Sass is a format to represent CSS in a way that makes it easier to maintain, just like SLiP represents XML without the redundancy of closing tags. pyssed OTOH allows constructing CSS stylesheets from within Python. This helps with generating dynamic stylesheets rather than with maintaining static ones. I'd agree that it feels hackier and in most cases Sass (or its alternatives) is the better solution to the problem, but having a CSS library within Python _is_ a Good Thing. Maybe pyssed could be changed a bit to allow for a cleaner syntax, though. For example I could imagine a syntax like this: # These would be defined elsewhere sans_serif = keyword('sans-serif') serif = keyword('serif') black = hsl(0,0,0) red = color(0xff0000) # Sassy color manipulation dark_red = red.darken(30) shadow = rule(text_shadow=(px(1), px(1), 0, black)) css = rule( body=rule( font_family=['Helvetica', 'Arial', sans_serif]) h1=shadow + rule( font_size=px(16), font_weight=bold) p=rule( font_family=serif, font_size=px(12), b=rule( font_weight=bold, color=dark_red))) &gt;&gt;&gt; print css body { font-family: "Helvetica", "Arial", sans-serif; } h1 { text-shadow: 1px 1px 0 black; font-size: 16px; font-weight: bold; } p { font-family: serif; font-size: 12px; } p b { font-weight: bold; color: #600; } Though this is obviously not perfect either (hard problems remaining are selectors, order and representation of at-rules). If someone picks up on this, please drop me a message or mail me at ('me@' + username + '.com') because I might just want to try implementing this kind of thing myself. EDIT: I guess the syntax could be modified a bit: css = rule(None, rule('@font-face', style( font_family='custom', font_weight=bold, src=url('fonts/custom.ttf'))), rule('body', style(font_size=px(10))), rule('#header', style( font_family='custom', font_weight=bold), rule('img', style(border=none)))) i.e. `rule(selector, style, *children)` and `style(**kwargs)` This would then solve all three issues at the expense of having selectors be string literals and complicating deep nesting via macros a bit. EDIT: I actually think this could be interesting. Let's see whether I can find the time to hack up a quick proof of concept.
Nice work, cheers!
Excellent. PIL needs serious help.
The order of rules in CSS is meaningful but dicts are unordered in Python. This could potentially be a problem. Don't really like nested dicts either, how about classes? @selecting('div.ground') @rounded(3) class Ground: font_weight = 'bold' @selecting('p') class Paragraphs: text_align = 'left' Edit: ``selecting`` supposedly sets a ``_selecting`` attribute or similar. This allows compatibility with Python&lt;2.6 that don't have class decorators.
Wow, good work!
Keep minification in mind: there are various libs for this, which you could make use of when outputting. Also, writing to a file and resolving any @imports is nice to have: you'll end up with a single file, which minimizes HTTP requests. Adding a token based on the contents to it you can let the browser cache those files "forever".
BoardPuzzler? PuzzleBoard?
I wonder why the community hasn't taken over yet, specially when contributions like these are available. current authors seem to care only about the paid version.
Cool beans. I take it this is suppose to create 256color files out of full color images?
 s/pyCUDA/pyOpenCL/g
I suppose I avoid it because of the general hairiness of image formats. I've often considered working on it though. 
Thanks. Yes, it is for paletted images with 256 or less colors. It reduces the file size to about 1/4, which is nearly as important as the encoding speed itself for online applications. (I write software for online maps and the encoding is our main bottleneck. http://mapproxy.org/ )
Working with a 4D color cube is a bit mind-bending, but hacking on the PIL source is quite nice.
Ahh. This explaination wasn't clear in the webbie ;) But having said that, yes, pyssed would have a different use case now that you can write CSS in python code. But question is, why would I wanna do that? :)
Good idea, I'll find one from a Monty Python sketch.
I never stopped to consider that maps would need less colors than regular pictures: aerial maps need it, but you're right that regular maps would need less than 256.
For everything photo-like JPEG is better anyway.
I spent all last night trying to build PyOpenCL on Win7 x64. I finally got it running by installing a bunch of x64 binaries (python, numpy, pyopencl, etc). Then I get another error running the thing because of an API change in .91.5 and the current version (.92.x). I did get it running doing a trivial multiply by 2 for each element on a numpy array (4096x4096). It only ended up running 20% faster than the doing it with numpy, and the CPU was fully throttled for the OpenCL run. Maybe the problem was too trivial? Not a pleasant experience so far! EDIT: CPU: Core 2 Duo M @ 2.2Ghz, 8600M GT 512MB (DDR2)
 &gt;&gt;&gt; @apply ... def foo(): ... return 1 ... &gt;&gt;&gt; foo 1 &gt;&gt;&gt;
It's easy to sit around waiting for someone else to do it.
How is resolved database access in asynchronous HTTP?
Surely my upvote is the only review you need! Seriously, you are awesome for doing this. Can you somehow infuse the rest of PIL with this level of awesome? My PIL stuff already outperforms my co-workers' C++ code...
So, would you in production recommend running gunicorn naked to the public? With no proxy in front?
"Taking over" a project when the original author objects is a pretty rude thing to do. The open source community avoids it wherever possible. It's so much easier to just start a new project. For example, [scikits.image](http://scikits.appspot.com/image) was started from much the same frustration with the trajectory of PIL. I am certain they would also love to have contributions of better encoders.
Suggestion: Some PyPI goodness with a CLI generator (like Less)?
I'd assume that the "uninstall" command would be, from an user perspective, the most compelling reason, compared to easy_install of course.
I'm not using PIL in any way right now so I don't really care but I've encountered problems in the past and found many many patches/upgrades/whatever out there already done, just like this submission. point is, there's already enough material available to make significative progress, I'm not waiting for anything.
yes but rewriting from scratch is a whole different task, problem here is that they have a paid version and the free one is subpar, much like what happened with SuSE Linux when it was bought by Novell. I can't confirm but I think many people providing patches for free would be pretty pissed off if they see them being applied to only the paid version.
Depends: PNG gives you uncorrupted data; JPG cuts stuff out
My primary motivation was to eliminate having to work in "just another language" (CSS), and using Less/Sass actually compounds the problem, since they are themselves distinct languages. But, there are other advantages of pyssed: - Can integrate more tightly with your HTML rendering code. For example, if you have programatically generated id attributes, you could use pyssed to generate styles for those attributes. - Can render different CSS files based on request parameters (font-size, user-agent, mobile vs. desktop, etc.) I haven't coded any support for this, but it wouldn't be much work. Since pyssed is generated from pure Python, it's easy to integrate fairly complex logic into the CSS generation. - Doesn't require an "extra step" to generate the CSS file -- this is done at runtime by whatever web framework you're using. Versus Sass/Less that both require an external compilation step to generate the serveable assets. (Make sure you have caching in your web framework!) - Doesn't require reading a 2nd file for generating CSS -- all the rules are right there in the .py (versus CleverCSS, Sass, LessCSS)
Good point. WRT @import, I wouldn't expect a user of pyssed to be using any @import statements (and frankly, I don't have support for generating them anyway). The "proper" way to do what @import does is via pyssed to use Python's import statement, and include your rules that way. 
Thanks! :) 
Yes, exactly. I can see you get it. I had started out development along the lines you suggest (not exactly, but close) and decided to KISS for the first implementation and proof of concept. I chose nested dicts because the syntax most closely matches that of CSS itself, and thus, the mental translation from CSS to pyssed's representation is more straightforword. But, given that rule ordering *is* important, things are going to need to change to either OrderedDict or list/kwargs as you're suggesting. It totally sucks that you can't have kwargs with names like style(font-family=bold), and this was one of the biggest design decisions for me. Should I translate _ to -, use camelCase (fontFamily, like jQuery does) or some other way around this issue? Thus, again, I opted for the easiest implementation and just kept everything strings. I think your syntax above and what I've got thus far are actually compatible. If you take a look at http://github.com/slacy/pyssed/blob/master/examples/styles.py you'll see that pyssed already supports args and kwargs style arguments, so extending them a little bit as you describe wouldn't be hard at all. BTW, my e-mail is in the README, so feel free to contact me offline for further collaboration/discussion. I'm also happy to keep it here.
This looks like a nice approach, I'll give it some thought. As I said above, I initially chose nested dicts because I thought they offered the best blend between CSS's use of curly-braces and what's allowable in Python. In other words, I'm shooting for Python code that sorta looks like CSS, but isn't. Your approach above is novel because it feels *much* more Pythonic, but I feel it would be much *less* accessible to non-programmers.
Great idea. I'll see what I have time to do.
I think the most pythonic of the existing CSS generators is CleverCSS (http://sandbox.pocoo.org/clevercss/) so you should take a look at that. I'm shooting for *actual* python to generate CSS, so although the syntax of Sass and CleverCSS are "pythonic" they're not *python*, and that means that you don't have any of the language features of python itself. 
Wasn't the whole point to be programmer-friendly rather than designer-friendly? For the latter one probably wants raw CSS… New idea: Allow dropping ``selecting`` when just matching a class and match by class name, i.e. ``class SideBar:…`` implies ``@selecting('.side-bar')``. Edit: Could also have a ``@id`` or something that does the same but implying ``@selecting('#side-bar')``.
Pyzzle?
&gt; It also supports the alpha channel, so you can now store 8bit PNGs with full transparency. Wait, you mean I can now use PIL to produce PNG8 files with partial transparency through your fork? That's pretty damn awesome, it's one of those features which just isn't supported enough by encoders (almost no drawing tool handles it apart from Fireworks). And how are file sizes compared to the original PIL?
I don't think any of the current database libraries support asynchronous operations.
I guess I was trying to strike a balance between designer friendly and programmer friendly. Ideally, pyssed could be used in an environment where designers are happy coding the pyssed syntax (and with syntax validation, this might be a huge help over vanilla CSS), and then when complex dynamic CSS features are needed, a developer could step in and help out. So, making it both programmer friendly *and* designer friendly is a key selling point (and a selling point that both Sass and LessCSS currently have) 
&gt;regular maps would need less than 256. In fact, they only need [four](http://en.wikipedia.org/wiki/Four_color_theorem).
Oh, and I'm talking beginner-level.
I don't think you can compare it with SuSE. There is a commercial version of PIL, but there is not a single comercial-only feature they are advertising except the extended support.
Yep. But please don't call it a fork, unless you refer to my mercurial/bitbucket repository. It is just a patch. &gt; And how are file sizes compared to the original PIL? Smaler :) Look at http://bogosoft.com/misc/pil-octree-tests/ The files without '-xxx' are the original files, '-octree' and '-octree-rle' with my new quantizer. '-adaptive' is the old quantizer from PIL. 
I learned Python from [Dive Into Python](http://diveintopython.org/) and the official [Python Tutorial](http://docs.python.org/tutorial/), both of which are heavy on examples. Dive Into Python, in particular, works by presenting a full sample program at the start of each chapter and then dissecting it. Edit: Also, from the /r/programming FAQ: [Python projects for learning best practices](http://www.reddit.com/r/programming/comments/7bm34/ask_proggit_please_suggest_a_mature_python_open/).
&gt; Yep. But please don't call it a fork, unless you refer to my mercurial/bitbucket repository. It is just a patch. It's a de-facto fork, even if you want yo get it merged back ;) &gt; Smaler :) Look at http://bogosoft.com/misc/pil-octree-tests/ The files without '-xxx' are the original files, '-octree' and '-octree-rle' with my new quantizer. '-adaptive' is the old quantizer from PIL. OK so -octree versus -adaptive. Looks like you can get a good 30~40% off, pretty damn nice, added to the speedups. Apart from transparentmap, but the -adaptive output is completely borked so that doesn't really count. Output size still worse than specialized reencoders (optipng &amp; al), but definitely competitive. -rle blows chunks for compression ratio though, it should only be advertized for fast on-the-fly encoding.
&gt; In fact, they only need four. That works for basic (low information) maps, or maps which you only want to create and don't want to read ever. A [topographic map](http://www.trail.terramodanamultisports.com/images/ign_carte.gif) using only 4 primary colors would be utterly unreadable.
Try this site that boasts "more than 300 Python tutorials": http://www.awaretek.com/tutorials.html
19 downvotes? wtf?
I do however think that designers could learn this syntax just as easily as the dict syntax, if not with more ease. I haven't actually worked with non-programmer designers, but if they can deal with CSS I suspect they're not technotards. Your current syntax is different enough that they'd need to relearn anyway and perhaps be bitten by old habits; at least a Pythonic syntax is easier to type and read.
I've only started using it for things like an image downloader for /r/pics and I should contribute something to it but probably won't for the near future at least not until the weather turns poor.
Thanks for the response. I'm not sure how many hearts and minds you'll win with this one, though: &gt;Doesn't require reading a 2nd file for generating CSS -- all the rules are right there in the .py (versus CleverCSS, Sass, LessCSS) We do the Django standard (I think?) nginx frontend serving static content, with a proxy to Apache/mod_wsgi for dynamic content. Making the CSS dynamic is a perf hit. At least, that's my understanding...this is really outside my expertise.
Thank you for doing this. Excellent work!
The python tutorial is probably better than you think. It's by far the best tutorial for any language I've seen so far.
then they have all those bugs in their commercial version as well? having freely-available patches all over the web!? I can't decide if this is better or worse...
But they'd be very ugly
Something is really odd with reddit when something as benevolent as this receives downvotes. edit: weird 
I've just finished a rough draft of the whole thing. It works quite nicely ([heres's the ZIP file with a demo and the current state of things](http://pub.katnip.de/pycss.zip)). I managed to keep quite close to the syntax I suggested. At-rules would be added like such: url = Keyword('url') Rule('@font-face', Style(font_family='custom', src=url('custom.ttf')) There's currently no syntax to define a stylesheet either, but that's as simple as concatenating all stringified rules or putting them in rule with None as selector and style. EDIT: Found a bug in the behaviour of keywords making the above example fail; fixed that bug. EDIT: I guess the ordering of styles can be solved by having `Style` inherit from `OrderedDict`, but that would probably require implementing it myself (if only as verbatim copy from the standard library) for the time being. At least the rules are already sorted, so styles that must appear after each other (e.g. fallbacks) can be put into separate rules for the time being.
&gt; Making the CSS dynamic is a perf hit. At least, that's my understanding...this is really outside my expertise. Absolutely. But even with this, I think you'd cache to a static file -- same way that Sass and any other CSS generators would.
pyBunny?
question is, why do you need to write css inside python code? there is no real need for that. it was why CSS was segregated from HTML in the first place.
Python is pretty well documented itself. Just dir(func) #http://www.network-theory.co.uk/docs/pytut/dirFunction.html print(func.__doc__) #print's documentation of something (if the documentation exists) everything There is also [invent with python](http://inventwithpython.com/) that gives examples then explains every bit
Tip to the hat for supporting OS.
read the python library? I'm sure some of it must be good...
Leo is pure Python: http://webpages.charter.net/edreamleo/front.html 
There is a whole lot of junk / terrible code on activestate python, almost surely more junk than good stuff. If he's a new python programmer I'd stay away from it until you learn what you should and shouldn't be doing in python that you may do elsewhere.
In many cases, you'll have semi-dynamic CSS anyway. For example, if you're supporting layout for right-to-left languages, an alternate mobile site via "just CSS" or by working around browser incompatibilities. Many times, you'll need semi-dynamic CSS. The default way of doing this is either via @import or templating them in your Django. Neither solution is particularly well-suited to CSS iteself. 
This is good stuff, you've taken it a lot farther than I did. Excellent work. 
To be fair, JPG does also add things.
+1 on the suggestions above. Would like to add Google's Python Class. http://code.google.com/edu/languages/google-python-class/
Er... Or just help(func) 
There is quite a bit of working functionality, but there's quite a bit to be done still as well. Github is obviously focused on git hosting as a primary value added, and the new sf.net is more focused on the larger set of project/community tools. So, mailing lists/forums, tracker, and wiki are more fully developed than the scm hosting on the sf.net side.
You want the source for Python, or what? Because that's in C... EDIT: Downmodded? Why? OP wants well-documented code but says he doesn't want examples. WTF is wanted here, exactly?
Have you actually used it? I feel it more than covers the basics to get someone rolling with Python.
From the README: "Roguelike Sokoban is an ASCII-based Sokoban game that has a look and feel inspired by the roguelike genre. New maps with custom symbols can easily be created using a regular text editor." By default the game presents 10 original levels that are more fun than challenging. All 10 levels should be solvable in 10-15 minutes total. There are also 83 extra levels included that are adapted from levels in the public domain. These levels are much harder. The game is well-documented and has a intuitive, complete interface. In particular, it is very easy to create your own levels, and the engine allows for some artistic license as some of the levels I've written try to show. The code itself is not too awful, I think. If nothing else, it exercises the curses library so anyone interested in learning curses may find it useful. Roguelike Sokoban is available under the GPL, so go nuts. The bad news is that, because the game uses curses for the display, it will only run on Linux. Or to put it another way, if you can get it to run on Windows or Mac, please let me know. Any feedback on any aspect of the game is very welcome. Enjoy.
Turtles all the way down.
I guess some people still use votes the way it was intended: to show that you are interested in the topic or not, not to shower the submitter with praise or ridicule. I suppose we have lost that down the road since many people seem upset when their posts get down voted.
Did you look at dive into python already? Giving us some idea of what you've seen and your impressions would help. That said, I've heard Django's code used as an example of well written, pythonic stuff worth reading.
The free book "Invent Your Own Computer Games with Python" has source code examples for games that you can look at: http://inventwithpython.com/source/ There's also the gorilla.py game to learn Pygame: http://inventwithpython.com/gorilla.py
Always use a proxy in front of Gunicorn. By default, a buffering proxy is an absolute requirement. If you configure Gunicorn to use one of the async workers, you can turn off buffering but you'll still want to keep the proxy at least for serving static content. It also gives you a place to separate the configuration of your web servers from the application servers. Ie, in the future you can move app code to dedicated servers, etc etc. The only gotchya is that Nginx can't proxy websockets yet. Until then, running a properly configured Gunicorn serving that traffic would be playing it fast and loose but in a serious production environment I'd recommend using HAProxy.
Awesome wonder how much this will speed up my captcha_crack.py
This is what is great about python. It's pretty much psuedo code, I've rarely seen a new concept in python I didn't immediately understand
most open source communities are very rude to incoming contributors in my experience. 
Actually, there's a report button for spam.
You could try [Rosetta Code](http://rosettacode.org/wiki/Category:Python). Run by a redditor if I remember correctly. Mike? You're around here somewhere aren't you?
&gt;Dive Into Python is a Python book for experienced programmers That kind of turned me off it. I'm not experienced anything - I generally get behind the logic of code (and I can not understate how much CarlH's programming guide helped me with that), but that's all. I'll have a look at Django, though. Do you think *for experienced programmers* is overstated and I should have a look at Dive Into Python regardless? Thanks
I used this setup on my GTX 260/216 to do some basic Neural Network calculations, feeding patterns through very large networks (constrained by the memory structures of the GPU itself) and those are roughly the speedup numbers I got, very impressive stuff. The hardest part was wrapping your head around how the thread groups/blocks are organized, it's very strict you can't just pass it any configuration of array you want, you have to break it into these 32x32 or 64x64 or whatever size blocks and operate on them in parallel, and then the memory sharing architectures are allocated by those blocks so you can share within them but to share across them you have to do a massive thread sync operation. It took a lot of effort to rethink a familiar algorithm and reconstruct it into these rigid thread/memory structures, but it was a very educational experience.
A lot of modules are in python edit: I meant built-ins.
Zed Shaw's new eBook http://learnpythonthehardway.org is pretty much all examples.
oh that's to file a spam report? i thought it was to report stuff ASAP like links to illegal stuff
Dive Into Python is just that, not a steady walk into the depths. In the first two chapters it'll expose you to more than books designed for beginners would in the first 5 or 10. Take a look at [this example](http://diveintopython.org/getting_to_know_python/index.html#odbchelper.divein) at the start of chapter 2. I personally prefer to work in the other direction(starting as simply as possible than moving into more complexity rather than a more complex example and breaking it into smaller, more digestible pieces). [edit] If you're looking for a simpler introduction you might want to try [How to Think Like a Computer Scientist](http://www.greenteapress.com/thinkpython/) then moving onto something like Dive into Python.
The Python Challenge is a good way to learn Python, because it will tell you to do something, and then you'll have to go out and find a module, nearly all of them are in the standard library, that does what you need. Edit: probably should give a link to: [The Python Challenge](http://www.pythonchallenge.com/) Edit 2: Don't get frustrated when you cant figure one challenge out. Its designed to be tough for newbies. It took me months to actually get very far, mostly because it wasn't important until that one day that everything just clicked.
it has very, very scant examples....it's good for reference
it's useful for learning python ?
Don't you mean `dir(func)` and `func.__doc__`? What you're doing will always return `dir` and `__doc__` for the `list` type.
That's nice, but how does that help the OP? Besides the implementation almost everyone uses is still written in C. http://en.wikipedia.org/wiki/CPython
There are a lot of well-commented, useful Python projects of all shapes and sizes on github. I mean, [look at this stuff](http://github.com/facebook/tornado/blob/master/tornado/httpserver.py)..
The project may be slowing down (hopefully not dying..), and it may be old news to some, but i was impressed by it! Though, i'd prefer some type of plugin in browsers that allowed developers to run their languages of choice in it (Python, Ruby, etc). Eg, some way of securely sandboxing an interpreter/environment. 
I don't do CSS myself, but I can tell just by the README that this deserves a **bravo**!
Ah, I am sorry, I just mean [func] to be what ever function you want. I mean to be using it as a place holder. My bad.
Also, i'm not sure where else he has this information, but he talks a good bit about what he is doing in the way of Skulpt (no time frame though, so who knows how old the information is). http://www.h4ck3r.net/#Skulpt
http://learnpythonthehardway.org/ I think this is a good start. ymmv
Another really useful tip is to use iPython instead of the standard shell, it gives you lots of extremely useful documentation and introspection helpers if you're browsing around a package. One thing about Python that people new to it won't immediately pick up on is how useful the shell is. In most programming languages, you'll write some code, run it, find an error and then try to fix it. However in Python, you can write a little code like a Class or something, then import it into a shell and start interacting with it manually. It's good to get used to trying a program by hand in a shell first and then putting what you've learned into the project, rather than the other way around. It's called Interactive Programming, and is s very useful technique. 
What suede says is true, but hear this: Dive into python works by providing you with a code example, and then explaining every single bit of it. The examples were comprehensible to me when I was a raw beginner, and though they took me right to the limit of my learning ability, I didn't waste an instant on text that went too slow or spinning my wheels trying to grasp a concept way too big. To me, that sounds like what you're looking for. Basically code with the best documentation you could ever expect or hope to see. Have you ever programmed anything before? Thats what 'experienced programmer' means. You should know your way around a for loop. If not, there is a beginner's book "how to think like a computer scientist" that teaches python and programming fundamentals at the same time. I have only heard good things, not read it.
Cool! One gripe: I have to concentrate hard to differentiate the empty spaces and the horizontal walls. Think you might find a different character for that?
I wish I could upvote this several times.
It is kinda an unfair test, in that the pure Python code uses only a single thread with a level of precision that the tester admits is slower than it could be, and the entire point of using a GPU is that it crunches high-precision data in a massively parallel way. It'd still be faster, but not by nearly that wide a margin.
Your problem was definitely too trivial. When doing computations on a GPU, you have to first transfer data to GPU and after the computations back to the main memory which causes relatively huge slow downs (PCI Exp. is slow compared to main memory). Unfortunately you have to create more complex "test cases" to archive good speed ups. If you want to create little bit more complex test program, you could make a simple 1D filter where kernel is stored in the GPUs constant memory. Also small matrix calculations are quite fast when done in a batch (12 million 3x3 matrix inverses + multiplications for example).
Ahh, thats for the info, I was suspecting a bandwidth bottleneck because the CPU was fully throttled (which means it was probably sitting around twiddling its thumbs trying to pump the data back and forth). Where can I look to find a lot more info on this (OpenCL/High-performance computing)? Also, for example, could I implement a ReplayGain Analyzer (look at a song and find the highest/lowest volumes) with this such that it runs significantly faster than the currently CPU-bound implementations? Would be an interesting side project!
Awesome! I made a similar script in my spare time just to practice the sokoban levels in nethack. I'll be sure and check this out.
It is good, in general, but it may be a bit much for someone looking for newbie friendly material. Also, depending on what module you lok at, the code/comment quality can vary. 
Muhahaha, let me show you some of my list comprehensions. Or incomprehensions as the case may be. Actually on second thought, maybe I'd better not.
So, does it have a GIL? ***/me ducks***
My head exploded. My browser running JavaScript running Python. At least now I can run Python programs on my iPad. Take that, Apple!
Doesn't work for me. Am I missing something? If write my only code bits it outputs nothing.
I *highly* recommend searching through code search engines like http://www.google.com/codesearch You will find lots of example code to look through and it will be more specific to things you are interested in learning. 
Author here. I could have coded the Python implementation to split the work in half to 2 CPUs, that would take the advantage down to *11k (or maybe 6* for 4 co-operative tasks as I have 2 virtual cores + 2 real cores). I then could have added a second or more GPU into the box (and split the work between them) and that would have taken the advantage back to *22k. The real question is how much work do you want to put into the job? Three days and a background in C gives you pyCUDA's low level performance for simple tasks, you probably want a week or two to wrap your head around the memory model for harder tasks. If the algorithm you're starting from is super-badly-implemented then the gains will be impressive.
I seem to remember seeing similar projects for both Ruby and Lisp before.
You may find more examples in class Mail in [this file](http://code.google.com/p/web2py/source/browse/gluon/tools.py). from gluon.tools import Mail mail = Mail() mail.sender='you@example.com' mail.server='localhost:25' mail.login=None mail.sent(to='somebody@example.com, subject='', message='', encoding='utf8',attachments=[]) It is designed to also work on google app engine (mail.sender='gae'). 
Be aware that the 8600M is two generations old, it has 32 streaming cores and doesn't run that fast. Definitely be aware that all NVIDIA cards in laptops are underpowered (so the don't p0wn the battery) so they run slowly. My MacBook's performance for GPU work is hardly stellar but it still shows a 10* speed-up over the CPU for the mandelbrot demo with the CUDA-C implementation and about 2-3* speedup (from memory) with the gpuarray equivalent: http://en.wikipedia.org/wiki/GeForce_8_Series#GeForce_8600M_Series The GTX 480 I'm using is NVIDIA's flagship product, it has 480 active cores running at IEEE 754-2008 double precision (single precision is something like 4-8* faster) and is stonkingly fast: http://en.wikipedia.org/wiki/GTX_480 Also I think that the pyOpenCL project is a little less mature than pyCUDA (but I've paid openCL little attention recently, things may have changed).
Author here. For 'real world' reference cases - on a physics X-Ray problem for my client I show a 144 times speed-up if a 9800GT is fully laden vs a single threaded C solution (the client's usual code) using single precision math. With the same code on the GTX 480 I see up to a 3,677 times speed-up - this is a real world problem for a large physics company (they're happy as you can imagine). If we had used OpenMP (which they didn't in this product) then divide the performance gain by a factor of 2-4. On a much harder physics problem I'm currently seeing 2-10 times speed-ups on the GTX 480 with double precision, it'll be 100 times once I'm finished fully parallelising it but this will be a few weeks of work. We're considering adding more GTX 480s into the machine to push towards a 500 times speed-up (so days of simulation time becomes minutes).
I typed for i in range (1, 2000): print i which is about all I can do in Python, and it crashed :(
PythonCard as a simpler way of doing wxPython programs.
downvoted for owning an iPad
It's staggering how drastic these numbers are when you consider what you can accomplish with a single machine with 2-4 modern GPUs compared to the HUNDREDS of CPUs you would have needed in a cluster only 5 years ago, makes you appreciate what it means when they say the next generation of super computer will be a Petaflop in a single box of a few hundred multicore vector processors. I'm glad to hear you're having such success with physics optimization problems, as I said my particular focus is in machine learning, and the promises of these avenues of research are absolutely dazzling. Happy coding, friend ;)
Downvoted for explaining why downvoting. Wait... what?
`range` is a function call by the way, not a special keyword you supply a bracketed pair of numbers to. If you normally put a space after the function name and before the opening paren, you were probably aware of this already.
I'm not sure how to react to your comment, could you elaborate?
The space after 'range' looks weird.
Must be tough living with that kind of envy ;-)
No batteries included :-( :-P
CPU throttling (if I understand the term correctly) can be caused by CUDAs default behaviour when launching kernels: it has busy/spinning wait. You can change the behaviour by command cudaSetDeviceFlags(cudaDeviceScheduleYield), see [Reference Manual](http://developer.download.nvidia.com/compute/cuda/3_1/toolkit/docs/CudaReferenceManual.pdf) for more information. NVIDIA has written quite complete description of how to get the best performance from their cards (altought you might still need to optimize for specific cards as they have not documentet every small difference), you can get all of their documents from [here](http://developer.nvidia.com/object/cuda_3_1_downloads.html), but the specific document I'm talking about is [here](http://developer.download.nvidia.com/compute/cuda/3_1/toolkit/docs/NVIDIA_CUDA_C_BestPracticesGuide_3.1.pdf) and OpenCL version [here](http://developer.download.nvidia.com/compute/cuda/3_1/toolkit/docs/NVIDIA_OpenCL_BestPracticesGuide.pdf). ATI has of course their own [OpenCL/Stream documentation](http://developer.amd.com/gpu/ATIStreamSDK/Pages/default.aspx) but I have not looked at it as I only have NVIDIA cards. For other HPC related reading I would recommend OpenMP and [MPI](http://en.wikipedia.org/wiki/Message_Passing_Interface). They might not be as interesting for Python as they are for C, but if you are really interest in HPC these are the basics. OpenMP has been very easy way (at least for me, Python probably has better ways for simple threading) to create portable code which uses multiple CUDA enabled cards (I have used GTX 295) to get the greatest speed up. I don't know the ReplayGain algorithm but for searching min/max you could try to modify/take an example from SCAN-algorithms ([here](http://http.developer.nvidia.com/GPUGems3/gpugems3_ch39.html) and [here](http://graphics.idav.ucdavis.edu/publications/print_pub?pub_id=915) for example). I'm not sure if you would get huge speed up by only doing min/max search, you should probably also add some other functions to same kernel call.
Perhaps of interest: [Pyjamas](http://en.wikipedia.org/wiki/Pyjamas_(software\)) 
Typical fanboy response. I could buy tens of your crappy gayPad. I don't, because I don't enjoy prisons and getting fucked in the ass.
I would suggest (as someone else did) [django](http://www.djangoproject.com/), [sqlalchemy](http://www.sqlalchemy.org/), and probably any of the other popular web frameworks - [pylons](http://pylonshq.com/), [turbogears](http://turbogears.org/), [werkzeug](http://werkzeug.pocoo.org/). I would also recommend [effbot.org](http://effbot.org/) and [pymotw](http://www.doughellmann.com/projects/PyMOTW/). Those two sources usually lend insight into various parts of the std lib. After that, I would suggest browsing around [bitbucket](http://bitbucket.org/repo/all) or [github](http://github.com/explore) - there are lots of good projects on those sites. **EDIT** oh duh! how could I forget? [reddit!](http://code.reddit.com/) :)
I know that and you know that but, by the same token, when I was first introduced I skipped over it too - because other languages had taught me that their tutorials were a waste of my time and would never teach me what I really needed to know. Oh well, we each take our own path. 
He's commenting on your syntax style. Typically, people don't put a space between a function and its arguments to make it obvious that it is one. I.e. they'd write foo(bar) instead of foo (bar) On the other hand, most people *will* put a space between a non function keyword and what might otherwise appear to be arguments, i.e. for i in (1,2,3): print i rather than for i in(1,2,3): print i From context, it's obvious that "in" isn't a function, but the space makes it visually obvious. In your case, due to the space "range" appears to be a some kind of special beast, rather than the plain function it really is.
Also http://nullege.com/ which claims to understand python. Haven't used it much myself though.
Other commenters have elucidated my point. In particular, I was concerned (especially in light of your self-admitted limited knowledge of Python) that you'd thought range was a keyword instead of a function.
Could you write down some code you think this would be useful for? A usage example.
I don't think threading means what you think it means.
Wow, such pent-up anger. I thought you were joking, and I responded jokingly as well. Would a fanboy write "Take that, Apple!"? As an aside, what consumer device is on the market at the moment that you would consider worthy of your dollars aside from the iPad? Preferably something my parents can use. They are in their 70s and are tired of going up the stairs to the computer to read their e-mail and read the news. I thought something like the iPad would be useful for them.
Could someone explain to me how Skulpt is that different from [Try Python](http://try-python.mired.org/)?
The iPad is the prison. The assfucker is Steve Jobs.
Try Python runs (a) cpython instance(s) on the server side. Skulp runs a client-side implementation of python, written in javascript, in your browser.
Although the question was already answered, see also: [Try IronPython](http://ironpython.net/ironpython/try/).
* Open both this and "Try Python" in separate tabs * Now turn off your internet connection (turn off modem/wifi/plug phone line) * "Try Python" doesn't work anymore but this still does. That's because an implementation of Python is running locally in your browser.
So the backend is essentially the same as [this](http://www.datamech.com/devan/trypython/trypython.py), but the JS makes the terminal all pretty?
Not exactly, Skulpt's backend is *entirely* in-browser, client-side -- using pure JavaScript to parse, compile and execute Python.
Sorry, I was referring to Try Python, not Skulpt.
nope, doing this is by definition a hack. Pass in something indicating which call site you want to cache this for.
The usage of the binding idiom in Clojure is that you want to specify a database connection or logging target but don't want to pass it through every function call, and don't want to be limited to one global value at a time. I think I worked out a decent solution: have a with statement push a value onto a stack in thread.local, and retrieve that value in the deep function. Here's some code: def toplevel(): with set_current_log(logging.FILE): a() with set_current_log(logging.DATABASE): b() def a(): output('a') def b(): output('b') def output(x): write_to_log(x, get_current_log()) 
I think the solution I wrote below is fairly clean. The stack frame version is definitely a hack. Cluttering code with cache and logging parameters is unpleasant enough to justify some hidden cleverness to get rid of it imho.
* Release Notes: http://bottle.paws.de/docs/0.8/changelog.html#release-0-8 * PyPi Link: http://pypi.python.org/pypi/bottle/0.8.1 * Homepage: http://bottle.paws.de/ * Commit Log: http://github.com/defnull/bottle/commits/release-0.8
Wait till your wife goes to labor. "JOJO TAKE ME TO THE HOSPITAL AT ONCE" and you're like "honey, you know there's no threading in real world"
Sometime ago I read that the 400 series has an artificial limit for double precision compared to the professional Tesla line (see for example [this thread](http://forums.nvidia.com/index.php?s=ecb8ef18a17cacab0f11873eee082d14&amp;showtopic=164417&amp;st=0)). Do you think that even with this limit the GTX 480 (or 470) is worth its price for double precision? 
Anybody got a browser implemented in python i can test in this thing?
You should call it Funny Walk.
Nifty! I tried it out a couple of months ago to front-end a little Redis-based prototype, and it worked well. Unfortunately its launcher front-end does not run a threaded TCP server by default, and I discovered that only *after* my live demo... :)
Wasn't it Silly Walk?
WTF, there's threading in the real world. She's in labor AND yelling at her husband.
Try parallelizing the task of going to hospital, with any noticeable speedup.
How many hundreds of micro web frameworks do we have for Python now? EDIT: Not saying anything about this particular one, but why do so many people try their hand at building a micro web framework?
Ctrl-Enter to execute.
&gt; but why do so many people try their hand at building a micro web framework? Because a basic (even if not passing any tests) WSGI implementation is very simple and everyone wants to has one on its own which is slightly different to others. I'm one of those offenders with my Werkzeug library and also with a Framework on top of it. Variety Is The Spice Of Life they say.
It is, by far, my fav. web framework.
It's a learning experience. 
That works as well.
I haven't had the chance to try out Bottle or [Flask](http://flask.pocoo.org/), but they look very similar. Does anyone have experience with them? Maybe some good/bad of each, or is it really just a toss up?
So where does the regex come in? Can you give some context? As it stands, this would do it: if string1 == "X": string1 = string2 if string2 == string1: do something
uh why this ?
I'm biased towards Flask because I'm the author, but here the big differences between the two: * bottle is a single file and implements everything itself * it does not depend on anything but the stdlib to accomplish what it does On the opposite there is Flask: * based on Werkzeug and Jinja2 for WSGI implementation and the templating. Due to that it's also more powerful in that regard (Werkzeug for instance parses all HTTP headers for you, Jinja2 has tons of template helpers etc.) These libraries are also used on a couple of websites already, despite the young nature of Flask which came afterwards. * Flask has many extensions by now for OAuth, OpenID, Scripting, easier file upload handling etc, SQLAlchemy and more. * I think the main reason why people use Flask is the documentation though which I'm pretty proud of: http://flask.pocoo.org/docs/
In that case, I stand by my solution. string2 isn't being modified and if string1 is "X" results in string1 being set equal to the value of string2, string2 == string1 will always evaluate to true.
&gt; *if string1 is X then turn it into a value that will make the comparison string2 = string1 always return true for any string2.* Errr.... string1 = copy.copy(string2) # explicitly explicit. if string2 == string1: do_something() 
&gt; So basically if string1 is X then turn it into a value that will make the comparison string2 = string1 always return true for any string2. Why use the regex at all? Just check if string1 == "X", and if so, then execute the "do something" code. By the way, the reason you can't find the answer in regex tutorials is because this is nothing to do with regex!
mitsuhiko sums it up quite well. I'd just add these points: * Bottle supports Python 3 (even if some aspects of the WSGI standard are still vague in terms of python 3) * The build-in template engine is quite unique for it allows you to use python for the template logic and is one of the fastest template engines available. No need to learn a new template language here. * Bottle comes with preconfigured adapters for several third party template engines (mako, jinja2, cheetah) and WSGI servers (cgi, flup.fcgi, cherrypy, paste, fapws3, tornado, Google App Engine, twisted, diesel, gunicorn, eventlet, gevent, rocket) and makes it easy to switch. If the build-ins don't match your needs, you can replace them without hacking the framework. Bottle grows with your project. Of cause I am biased, too ;)
Thanks for the thorough explanation. I am aware of the difference between a function and a keyword, I just didn't notice that the space was so essential to the syntax.
I use bottle to add REST apis to control my eventlet daemons - it's enough to spice up some functions with route(), call eventlet.wsgi.server with bottle.default_app() and profit. Thank you for bottle! That said, I choose flask for tasks more resembling "true" web programming. I trust werkzeug's wsgi implementation more, plus I get cool ajax debugger, sessions, easy jinja templating and stuff.
My assumption is that he's not learning to program so the tutorial is enough to see how Python works. Then you go to the docs and find many more examples. If he's ok with a book then I highly recommend Python Essential Reference 4th edition as an excellent reference and the latest edition caters to both the 2 and 3 series which is good for people just starting python, imo. http://books.google.co.uk/books?id=Chr1NDlUcI8C
why not just: if string1 == "X" or re.search(string1, string2): do something That way if string1 is the magical over-ride value you're looking for, then whatever. Else, if string1 is some regular expression you care to match (and not the magical over-ride value) then you actually have to perform the regex search. Better still, the over-ride check will short-circuit and you won't have to run the re.search unless you actually need to. Alternatively, you could set string1 to ".*" -- that pattern matches anything. But that seems silly.
[Author](http://codespeak.net/tox/#notes-and-known-limitations): &gt; tox uses virtualenv and virtualenv5, the latter being a fork of virtualenv3 which roughly works with Python3 but has less features (no “pip” and other problems). This comes with limitations and you may run into them when trying to create python3 based virtual environments. IMO the proper solution is: virtualenv needs to merge and grow proper native Python3 support, preferably in a “single-source” way.
No, because this still uses cpython on some server somewhere. In contrast, you could use Skulpt offline if you wanted to, without some other server, because the interpreter itself--not just the terminal--is written completely in javascript.
Thanks for your feedback. I think you mean that the horizontal wall symbol '-' looks sort of like the floor symbol '.' and you find it hard to tell them apart. Am I right? I chose the symbols to be consistent with how a roguelike typically looks. For example, compare to the [Sokoban levels](http://nethack.wikia.com/wiki/Sokoban) in the classic roguelike NetHack. So I can't change the supplied maps without changing the game's out-of-the-box feel. But, the level files are just text files and there is nothing special about the '-' symbol. You can do a search-and-replace to replace '-' with whatever symbol you like. Or you can change the floor symbol '.', but that's a little more complicated. The level file levels/default_levels.dat has a lot of information about making or modifying levels. Please take a look and let me know if anything isn't clear.
Thanks. By the way, it would be very easy to copy the Sokoban levels from NetHack, create a new level file with those levels, and then play those levels in Roguelike Sokoban.
The following might do what you want. d = {"X": '***looking for this expression***'} print string2 == d.get(string1, string2) This would probably make more sense d = {"X": '***looking for this expression***'} print "Y" == d.get("Z": "Y") # There is no Z, so compare Y to Y Is this it?
The real question is whether it can run [pyjon](http://code.google.com/p/pyjon/).
Aha! Xzibit *is* on Reddit!
Maybe we should just parallelize the delivery, assuming twins, we could deliver both at the same time.
It's still Rails ORM based in Active Record pattern? SqlAlchemy is based in Unit of Work. SqlAlchemy is very powerful.
&gt;I didn't explain this enough. Yep. &gt;I can't just set it equal to string2 Why? &gt;probably chose the wrong place to ask this question. Nope, just need to *actually* ask the question.
&gt;if string1 is X then turn it into a value that will make the comparison string2 = string1 always return true for any string2. Wait... &gt;always return true for any string2 This is the confusing part. If you are *always* returning true for *any* string2, why are you not just always returning true? What does string2 have to do with any of it? Obviously you want to do some kind of comparison of string1 and string2 (which is why you mention regexp), but you have neglected to explain what this comparison needs to be...
[psycopg support it](http://initd.org/psycopg/docs/advanced.html#asynchronous-support) Eventlent and Gevent can monkey patch the postgresql client (or others native python clients). But one connection is still one server process. Connections pools limits a possible server overhead, but can be a bottleneck. I was locking for a (off-topic) more deep real example.
Biggest difference would be that, Pylons only provide just the bare minimum that you can mix many components on top of it. There's no ORM, there's no template engine integration built-in—you can add them yourself, or have the *paster template* do it for you.
**All this is pre-1.0 by about 3 months. ** SqlAlchemy is great. It's one of my favorite python projects. Pylons itself was underwhelming for me. I spent random nights for about two months trying to get a site together. It's so decoupled it's to the point where you can't use documentation to know which choices are known to work best. Modules are deprecated yet still exist in the documentation (Offhand I believe the one Authentication module?) Downloading example projects proves unhelpful because each one is configured differently, started on a different version of pylons, and uses different libraries. As a beginner I had to basically pick a style based off nothing but my gut. You don't get the interoperability you can sometimes find with django apps. I like the concept of Pylons with it's wsgi-ness and really wanted to get into it, but in the end I just found myself asking "Why am I rolling my own authentication? authorization? comments system? How do I even know my choice for libraries will be supported in two weeks" Django isn't all flowers and sunshine, but Pylons makes a lot of work in the name of freedom of choice for things that don't really matter. If you're dead set on pylons, go for it, but if you're just getting into python I think Pylons is a bad choice. It requires you to have too much contextual knowledge when choosing modules. tl;dr I really really like Pylons but I wasted too much time on the mundane.
Indeed. Pylons is a very flexible sort of framework, which is great for small projects that don't need much; or for large projects that need a lot, and need it customizable down to the bone. But with that flexibility comes the fact that *you* have to know when and where to flex it, and it will happily let you get bit by your design mistakes later on. For someone coming from Rails, I'd recommend trying out TurboGears. TG2 is actually built *on top* of pylons, so if you transition from TG2 to pure pylons, the general module layout will still be relatively familiar. TurboGears provides more of an infrastructure from top down, so you don't need to implement it yourself. Having not used Rails myself too much, I can't draw direct parallels, but I'm pretty sure it's a more apt comparison than Pylons. Turbogears also uses SqlAlchemy. Coming from Rails, SqlAlchemy is python's equivalent to ActiveRecord, sorta. There's a declarative wrapper for SqlAlchemy called Elixir that might make you feel even more at home under python. Breaking that down, SqlAlchemy is more like Java's Hibernate, and Elixir provides a wrapper that makes it feel more like Rail's orm system.
Well, Pylon is integrated with Mako templates out of the box, but you can switch to a different templating engine pretty easily, or so I've been told. SQLAlchemy integration is a matter of answering "yes" to a question when you first create a Pylons project with 'paster create'. I feel the lack of certain other components like auth or DB migrations, though. (Still, compared to Zope 3, Pylons is pure joy.)
I just installed it from AUR with a single command. 
You need to play as Protoss.
You can make utter magic happen with Pylons. I was just doing so today. I built an Oauth 2.0 server and client in two separate applications which run on the same codebase - the unit test fires up both wsgi applications, wraps them in TestApp(), mocks one into the REST client used by the other, and it runs the full back-and-forth between client redirects and server side communication of the two apps, all in one process. Three separate databases are in use (one app uses two, the other uses one), all three databases are accessed within transactional wrappers that roll back all changes after the test completes. Its the same kind of thing you can do with any WSGI / webtest type of framework (like I'm sure you can get Flask to do it too), but the key is that only a componentized framework, one that lets you construct pipelines of communication in any way you want without resistance, makes things like this possible. The learning curve is greater but the payoff is exponential.
If you are comfortable with Rails you may find you like Django better, its about the closest I think you'll find to the same concept (full-stack solution).
What did you end up using? 
Celery is cool. http://celeryproject.org/
Looks easy to mod, thanks :)
[PyMVPA](http://www.pymvpa.org/)
* matplotlib * Google's ipaddr-py * ipython * googlemaps * haystack * pisa * beautifulsoup * dateutil 
[SQLAlchemy](http://www.sqlalchemy.org) [Gevent](http://www.gevent.org) [pip](http://pypi.python.org/pypi/pip) [PIL](http://www.pythonware.com/products/pil/) -- it's not my favorite, i wouldn't even say it's very good at all, but that's a rant for another day... [lxml](http://codespeak.net/lxml/) [Twisted](http://twistedmatrix.com/trac/) Just to name a few
repoze.who/what are great for auth, and sqlalchemy-migrate is good for migrations.
&gt;So [Try Python's] backend is essentially the same as [this](http://www.datamech.com/devan/trypython/trypython.py) Sorry, that's what I was trying to say.
sympy
* Whoosh * Scrapy * Django * PyTables * Scipy/numpy * PyOpenCL/mpi4py
[VPython](http://vpython.org/) is fun.
for quick web scraping jobs [mechanize](http://wwwsearch.sourceforge.net/mechanize/) is quite handy.
+ ipdb
Nice! It can build py3k virtenv from py2 virtenv: virtualenv ve5 ./ve5/bin/easy_install virtualenv5 ./ve5/bin/virtualenv5 --python=python3.1 py3k ./py3k/bin/python --version ./py3k/bin/easy_install 
and you always seem to need to construct additional ones :-/
[Fabric](http://fabfile.org/) "Fabric is a Python library and command-line tool designed to streamline deploying applications or performing system administration tasks via the SSH protocol." I wanted to get into Capistrano, but it's Rails-oriented and I do Python stuff. I could [adapt it to Django](http://playgroundblues.com/posts/2008/mar/17/capistrano-rules/), but why leave Python? Especially after the latest refactoring, Fabric does everything I want it to do and it does it well. I'm not really a shell scripter, so being able to use Python to slice-'n-dice in Fabric scripts is doubly nice for me. [Flask](http://flask.pocoo.org/docs/) "Flask is a micro web development framework for Python." There are lots of these but I like Armin Ronacher's style.
Then all you needed was an OR statement If string1 == "X" or string1 == string2: do_stuff() If matching string1 vs string2 is non-trivial, then something like: def match(string1, string2): COMPARISON CODE HERE if string1 == "X" or match(string1, string2): do_stuff() Also, shouldn't bondtype/atomtype be an array or list or something? Variables numbered 1-4 seems pretty silly. bondtypes = ['N3', 'CT', 'CT', 'X'] Then you can do your comparison in a nice tidy loop. You need to take a break from whatever very specific tasks you are trying to do and spend a few hours reading a book on Python and writing some simple applications. Arrays, boolean logic and loops are all very basic building blocks of code in nearly any language that you don't seem to have a good grasp of. Learning to use them properly will make your life a million times easier and will be well worth the time investment.
I use these * suds (used to use SOAPpy but it is less flexible than suds) * RPython * SimPy * NumPy * PyMC Standard imports I use: * itertools * re * math * random * json (new in 2.6.5) previously I used Simplejson
Twisted is what a Swiss army knife wishes it could be if it was a networking plattform/framework
 * Babel, best i18n library for Python * flatland, best form validation package * blinker, awesome signalling system * SQLAlchemy, best ORM ever :)
So far I used smtplib myself, but lamson recently switched the license to BSD which makes this an interesting choice. The Flask-Mail extenion is doing that. I would recommend checking out the code: http://bitbucket.org/danjac/flask-mail/src/tip/flaskext/mail.py
[You Must Construct Additional Pylons](http://www.youtube.com/watch?v=C5e6eG6bXAQ)
The lack of updates is fairly indicative, in this case, of a stable product. What's to update if it works according to its documentation and specifications perfectly? As the author, I'm biased, of course, and highly recommend using TurboMail. It's simple, clean, efficient (150 messages/second delivery speed using the default 'ondemand' + smtp settings) and I've been using it in every project for the last four or five years. It's the recommended mail delivery platform for at least three web frameworks (Pylons, TurboGears, and my own, WebCore). It takes all of the headaches of manually using the MIME classes in Python and the pain of using smtplib directly, and you benefit from five years of bugfixes, compatibility checking, and feature enhancements. TurboMail's Message class also has an incredible number of features compared to flask-mail's, Google AppEngine's, Django's, and several other extremely simplistic mail delivery systems available through PyPi. Give it a try, and if you do find anything at odds with your project don't hesitate to e-mail me, the mailing list, or open a ticket on BitBucket. You can even pop into #webcore on irc.freenode.net and talk directly with me if you have any questions. Felix and I endeavour to reply to mailing list traffic ASAP. (Note that you can use the Message class by itself as a MIME message generator, or the mail delivery system by itself if you have your own pre-generated MIME string to deliver. It's very flexible that way. It's also easy to write alternate delivery mechanisms if you want to send to the local sendmail application, deliver mail directly to a mailbox via imap, etc.)
What game is this from?
numpy. Without it, python becomes unusable for non-trivial maths applications. With it, python is *almost* as fast as standardly written C code, but much more powerful.
Python.
Well I started in on Django and felt it was pretty good. Ended up kind of forgetting about that project and now I'm on Ruby on Rails. Seems like it's matured.
Have you heard about [scikits.image](http://stefanv.github.com/scikits.image/)?
excellent list
Oh geez I forgot about fabric. Perhaps funny is that I just happen to have a need for it now.
Indeed. Missing only [fusil](http://pypi.python.org/pypi/fusil/1.3.2).
Rails 3 ORM is not. It 's based on ActiveModel a module that is inherited by any ORM that wants to play nicely with Rails 3. Furthermore ActiveRecord now uses AREL to query the db. There is a lot of good work happening in the Ruby world
+1 for epic post :) cryptopy
Wow, thanks! That was useful. I hope the list will be maintained.
That's pretty much my experience - old out of date documentation. I've been playing with Flask recently and although it's quite new - just a couple months old - I find it far more productive than Pylons. There are a few reasons for this: First, it's very well documented and documentation seems to be the #1 priority for the project. Second, the design is Pythonic - it reminds me of CherryPy in the sense of "just create a module and run the damn thing", as opposed to the complexity of Pylons/paster entry points and figuring out which of the dozen generated files you need to edit. Third - extensions. Flask itself is small (built on Werkzeug and Jinja2) and just gives you URL routing, templating and a couple other things to get a basic app going. However, if you need for example to send emails, or SQLAlchemy integration, or form processing, you can choose from one of a number of extensions. These extensions are officially "blessed", i.e. if it's in the list it has to follow certain conventions such as documentation, API etc - kind of like an "app store". This is in contrast to the confusion of Pylons where nobody is quite sure which way to integrate OpenID this week. Will Flask replace Django ? No, for the reasons you point out. Flask doesn't do comments or authentication or the admin interface as Django can. Django excels at the kind of wire-together-lots-of-apps kind of project, where you are building a big site with lots of off-the-shelf features. Flask is better at the kinds of applications which don't need these features, or where the requirements are such that the existing Django apps are not flexible enough. To compare to the Ruby world, Django ~ Rails and Flask ~ Sinatra.
The Fermi line (and Tesla) support full IEEE 754-2008 double precision so double numbers evolve in exactly the same way as they do on the CPU. If you need doubles (and here with X-Ray physics I do) then you'll probably just pay for accuracy. The last generation of cards (e.g. GT[x] 2xx series) had parial double support - they were doubles but not IEEE 754-2008 so the results didn't evolve the same way as on a CPU (they had more errors). The artificial limit is that the Fermi consumer line's double units run at a 4* slowdown (IIRC) compared to exactly the same calculation units in the Tesla. Fermi is for consumers, is capped and is cheaper. Tesla is for science (we'll use one here once we're past the proof-of-concept stage), doesn't have a performance cap and costs £2000+ per card. The take home message is that the Fermi's double units run at 8* slower speed than singles (a double takes 2* as long as a single + 4* artificial slowdown from NVIDIA). They're still darned fast!
Most Pylons experts on IRC say "repoze.who/what is great, but I actually use a roll-my-own solution because it was simpler than figuring out how to configure repoze.who/what". *sigh* IIRC I gave up on sqlalchemy-migrate when it flat out failed to work with sqlite (due to sqlite's very limited support for ALTER TABLE). I ended up rolling my own migrations. *sigh* again
[Sphinx](http://sphinx.pocoo.org/). There is actually little aside from interpreter + stdlib I daily use, but Sphinx is among this and it is both high on the awesomeness barometer as well as my only must-learn recommendation for a Python newbie aside from the stuff that is in the distribution. Everything else depends on topic and direction. I use Python for a decade and never felt much interest in web-programming for example.
* numpy * enthought.traits * ipython * cython * pyglet
Cool.... reminds me I need to go ask them to support an encoder/decoder for cairo mode="ARGB32" this would make interoperability with it much better + quicker...
 - Werkzeug - SQLAlchemy
It really has everything.
If I was doing heavy duty async I would probably use a message queue for any task which could take longer than a few 100ms.
[mpi4py](http://mpi4py.scipy.org/) -- Parallelization for the masses! mpi4py does a wonderful job simplifying message passing between any number of processes you want.
I haven't, but I'll check it out today. Thanks!
You mean 32bit per pixel, ARGB order, as a raw byte string? You are right, that packer is missing. Look at ImagingPackABGR in libImaging/Pack.c, should be easy to modify that to support ARGB. Then this should work: img.tostring('raw', 'ARGB') 
MIT's OCW has a "gentle introduction to programming" that includes quite a few basic to intermediate python programs. There's the [2008 class](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-a-gentle-introduction-to-programming-using-python-january-iap-2008) and the [2010 class](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-a-gentle-introduction-to-programming-using-python-january-iap-2010/) that you may want to grab some source from.
that's what she said?
* Most [Pocoo](http://dev.pocoo.org/) projects ☺ (LodgeIt, Pygments, Werkzeug, Sphinx, Flask…) * [Twisted](http://twistedmatrix.com/trac/) * [virtualenv](http://virtualenv.openplans.org/) (+ pip and [virtualenvwrapper](http://www.doughellmann.com/projects/virtualenvwrapper/)) * [Genshi](http://genshi.edgewall.org/) * [ZODB](http://zodb.org/) have I not tried yet * [pickle](http://docs.python.org/library/pickle.html) I do use and for my simple needs it really is handy \+ probably a whole lot more. In general I feel Python packages tend to be good quality.
Good stuff. I came here to recommend scapy, but it was already on the list! There was also quite a few other interesting-looking tools that I'd not heard of before. 
In my day job I try to limit my dependencies and currently only use [wmi](http://timgolden.me.uk/python/wmi/index.html), which depends on [pywin32](http://sourceforge.net/projects/pywin32/). If you use Windows and ever need to get into Win32 stuff, both of those modules are very high quality and support both Python 2 and 3. When playing around or doing personal projects, I'm a fan of [matplotlib](http://matplotlib.sourceforge.net/).
That is what happened with my Pylons project too. In the end I got fed up with its complexity with not much gain and switched to [Werkzeug](http://werkzeug.pocoo.org/). 
[related](http://www.reddit.com/r/programming/comments/bv9gt/)
&gt; &gt;&gt;&gt; class NestedDict(dict): &gt; ... def __getitem__(self, key): &gt; ... if key in self: return self.get(key) &gt; ... return self.setdefault(key, RecursiveDict()) I think you meant the same with ``NestedDict`` and ``RecursiveDict``. Even better perhaps would be to use ``self.__class__()``, should maybe work with inheritance. Also you don't need ``if key in self: return self.get(key)``, ``setdefault`` does that. I suppose you avoid unnecessary instances of the class, though probably not heavy and also garbage collected…
I never published the link but there are t-shirts available for some time now: http://bottle.spreadshirt.de/ If you don't want to buy there, you can get the logo as a vector image and print your own. Just ask :)
Starcraft
&gt; Python ... penetration ... Python and penetration in the same sentence. *shudders*
and virtually impossible to NOT pair with BeautifulSoup for anything worth mentioning.
Probably a little bit more then everything; a while back for a pet project I started implemented dynamically reloading modules to speed up dev time but it turns out I didn't need to write anything: http://twistedmatrix.com/documents/10.0.0/api/twisted.python.rebuild.html
Wow, kudos. This is very impressive
this looks useful, but seems more complicated to use than it should be.
cmdln, virtualenv, pyPdf, scipy/numpy, SQLAlchemy... I'd say iPython also, but that's not really a library, but sure is damn useful. 
You have good reason to be proud of Flask doc; it is fantastic! and I for one owe you a debt of gratitude.
[rst2pdf](http://code.google.com/p/rst2pdf/)
Ok, just FYI, this is /r/python and we take things fucking serious here.
If you get that impression we should improve that. What makes you think it's complicated?
I'll use my python to test penetration...
I disagree, but there is an issue with Sphinx for newbies, something I was year ago as well. I would refactor the homepage and don't tell people on the "Getting Started" page how to convert docs from older systems, generate Latex and other specialist matters being interesting for few people who want to convert older Python docs - this might have been a major problem when Georg Brandl created Sphinx a few years ago - but today? The entry barrier seems higher than it actually is and you can go far in a convention-over-configuration mode.
Does Werkzeug provide auth and DB migrations?
I've been using my python to do more than just "test" penetration
 class Penetration: def isItInYet(): return sadJustForKix() def sadJustForKix(): manhood = manhood - 5 return shellOfSelf()
I just recently set up repoze.who and what for the first time, and it was fairly straightforward. The new setup is much nicer than the hacked-together, roll-your-own system it replaced (which I also wrote). I've been using sqlalchemy-migrate with SQLite for over a year, so it definitely works for at least basic stuff. I don't think you can fault sqlalchemy-migrate for SQLite's limitations.
Nope, but it's a lot simpler than Pylons in my opinion. At very least, how to integrate something into Werkzeug is a lot clearer than Pylons.
you sir/ma'am, are a bigger nerd than I... &gt; manhood = manhood - 5 I would've just said manhood -= 5 
Hm. I'll have to try it out some time. I would have thought something like repoze.who/what integration would be about the same, though.
there's http://www.logilab.org/project/logilab-hmm also
Side question - I was briefly looking at the Flask documentation earlier. Is there a way to *not* put routing in the controllers? I like the way having a separate url.py-equivalent gives you the flexibility to reuse controllers in another context with different routes.
* pylons * sqlalchemy * lxml * matplotlib * werkzeug * mako
I don't like pyparsing's API: I think codetalker's bnf-inspired grammars are more intuitive and readable. I would be interested in looking at benchmarks between the two, though.
The real question is, "Why are you even doing nested dictionaries?" I mean, in most cases, wouldn't it be easier to define a class with the required attributes, and then use a dictionary with that class as the value type, with whatever else as the key? 
But not version 3.1 of BeautifulSoup!
I use += but never -=. It's harder to read when you code drunk.
Other than using it mostly for installing project dependencies specified with version control urls in a requirements file I like it better than easy_install because of the download progress toolbar.
Webpy looks nice too. Havent used it much, though.
Sure. If you are looking for something similar to Django, this part of the documentation might be what you are looking for: http://flask.pocoo.org/docs/patterns/lazyloading/#converting-to-centralized-url-map
CherryPy is fast, mature and nice. I have used it with SQLAlchemy and Mako.
[Tornado](http://www.tornadoweb.org/) is an interesting one. For me the selling points were brain-dead simple long polling support and the epoll-based server it comes with (I was making a standalone app that just needed a web interface).
Would it not help to specify microframeworks for what? At least for those here with marginal interest in the web. Thanks Dave
[web.py](http://webpy.org/). reddit was written in web.py before acquired by Conde Nast. Yandex also uses web.py. Generally it's used by quite a lot websites which receive high amount of traffic.
The Oreilly book is more like an illustration of how some small practical code snippets using twisted would look like than a tutorial or reference on twisted. For me the best way of learning twisted was reading it's code. Starting from the API reference. Mostly, because most practical code is written by inheriting framework classes. But at the time I was writing twisted code for a living there weren't that much resources on the web, although it was popular.
Thanks for putting your time and effort into the project! It's awesome and I can't wait to use it.
What do people want here, for CPython to become the C++ of the scripting world? Seriously C is still around and with good reason and the fact that it is around does not invalidate the derivatives like Objective C, C++, D, Go and anything else that can be traced back to C. This is actually one point I can agree with when it comes to the developers policies. Further more, as many have pointed out, the code base is open source. If one of the existing forks don't work build your own. Is that hard work? Certainly it is so don't expect people to run to adopt your suggestion sans code. Especially if the idea isn't all that great and other solutions exist. By the way a scripting language built to support multicore machines might be a valuable addition to the scripting language library. The lack of such kinda indicates that either the demand isn't there or it is more work than many imagine. Dave 
I'll second this. CherryPy is awesome.
Thirded. CherryPy also has one of the most beautiful library API design I have seen in software.
I've been using [WebOb+Routes](http://blog.ianbicking.org/2010/03/12/a-webob-app-example/) lately, with a little [Tempita](http://pythonpaste.org/tempita/) thrown in. But then I'm biased.
I really &lt;3 tornado.
[Juno](http://github.com/breily/juno) was interesting, but is seemingly abandoned and when I went to read the internals I got very sad.
This has not been my experience. 
I've used WebPy quite a bit and had good experiences with it. As is true of many of the non Django python frameworks, WebPy is really a collection of components. Unlike the better known frameworks of this sort (Pylons / TG) the WebPy components are homegrown. This has pros and cons. The WebPy components are focused on solving only the most common problems. This means they are very easy to learn and understand. They are, however, much less powerful than their mega component counterparts you'd find in TG. I have liked this for two reasons: * It's easy enough to swap out the webpy components for their big brothers (the WebPy DB layer --&gt; SQLAlchemy &amp; Templator --&gt; major python-tpl-library-of-your-choice, are both well documented. I've swapped out web.forms as well but this is not as well documented.) * The included libraries are so simple that they are *very* easy to understand and extend. I've had good luck with the webpy google group for support, although the community is small. The size of the community, like the size of the framework itself, cuts both ways. The docs are marginal in my opinion. The API docs are piss poor. The rest of the documentation has improved dramatically over the past 18 mo - 2yrs and are actually quite good as individual subjects but lack a cohesive structure. But the strongest endorsement I can give it is that WebPy is my *default framework for any python web project*. I have to find a reason not to use it. 
[Flask](http://flask.pocoo.org/) I am part of the mailing list and those guys keep coming up with new extensions.
I'm not an active CherryPy user; however, I was under the impression that the point was to be a web library, *not* a web framework. Has this changed? Additionally, I'm not sure that X + SQLAlchemy + Mako fits the micro framework definition. If this is micro what isn't? Zope?
Do you know how Flask compares with Bottle? From what I heard, they were pretty similar.
*Micro*frameworks? Flask and Bottle.
This was kinda answered by Bottle and Flask's respective creators in [this thread](http://www.reddit.com/r/Python/comments/cpx8l/bottle_08_released_micro_web_framework/c0ucrqh) in the recent post about Bottle.
Jim Fulton's Bobo: http://bobo.digicool.com/
Just found out it would also need to support premultiplied alpha to work correctly, would probably affect more things.
If you already use django take a look at [djng](http://github.com/simonw/djng).
Could you elaborate?
It Runs On .Net
Fast work! Regular 2.7 just came out. 
Ooooh, shiny. Thank you sir, have an upvote.
[xldr](http://blog.ajwilhelm.net/archives/7), fabric, virtualenv
That looks useful, but I'd probably do a `s/MySQLdb/psycopg2/g` before using it.
fair enuff.
I’ve been complaining on the Python-ideas mailing list that we need someway to put things in the proper order, but I don’t think it’s going to happen any time soon. The last proposal floated was a where-clause as in: results = sorted(old_list, key=normalize) where: def normalize(item): return item.lower().replace(" ", "").whatever If you like this format, join the mailing list and lobby for it, or whatever other syntactic sugar you’d like to see Python adopt.
The problem with Tornado is that you are outside the WSGI world.
Interesting, I've been advocating this syntax for quite some time myself. I'm not on the list. When was this proposed? [Here](http://paste.pocoo.org/show/222352/) is a paste I made in Jun 5, though I had the idea earlier; obviously inspired by Haskell.
@donri: thanks; fixed. And nice hint about __class__. Combining this with suggestions from elsewhere, you get: class NestedDict(dict): def __missing__(self, key): return self.setdefault(key, self.__class__()) 
I was faced with this exact problem yesterday. Needed to extract data from a completely messed up spreadsheet and load it into teradata. I was trying to work with python's csv library to get it done, but unfortunately it proved to be a royal pain due to some carriage returns in cells and misquoting fields etc. I use Django for some other projects at work, so this solution would have been perfect (I'll definitely use it next time 'round). Nice find - thanks!
@quanticle: the reason I wanted this was because I was working with mongodb, which stores data essentially as a big nested dictionary. It's useful to keep a similar structure on the python side. But let me give you an example that stays within python. Suppose I'm doing some log analytics. For each day, I want to count how many times each of a group of objects has been downloaded, broken down by country. So, roughly, my output will look like: {'2010-01-01' : { 'item_four' : {'UK' : 112, 'FR' : 40,}, 'item_seven' : {'US' : 32, 'FR' : 12,}, }, '2010-01-03' : {...}, } So I go through my input data, grab and increment the appropriate counter output[day][item][country] rather than having to worry about whether I've already seen this day/item/country combination. Each day only some items will be downloaded from some countries, so I can't just pre-populate the structure with all items/countries. In this case, the innermost item is a counter. So rather than the infinitely-nested dict, I might want a set number of defaultdict(dict), followed by a defaultdict(int): results = defaultdict(lambda: defaultdict(lambda: defaultdict(int))) for (day, item, country) in process_input(): results[day][item][country] += 1 Does that make sense? Is there a better way of doing it with classes?
If you are planning to use App Engine, see [tipfy](http://www.tipfy.org/). Here's [why](http://www.tipfy.org/wiki/why-tipfy/). It is Tornado/web.py/webapp-like, with a bare core and [several extensions](http://www.tipfy.org/wiki/extensions/) to add extra functionalities. Disclaimer: I'm the author :). I also compiled a list of [other frameworks](http://code.google.com/p/tipfy/wiki/AppEngineFrameworks) that should work well on App Engine.
The pitch is roughly increased code complexity in the name of increased performance. Fine. Complex code that is fast is totally acceptable, if performance is a problem for your code. Is performance or nonexistence your code's biggest problem right now? Additionally the performance gains are by no means assured - http://nichol.as/benchmark-of-python-web-servers - and you abandon WSGI. All of that said it's fun to play with (so are Twisted, Seaside, Lift and ...). If you have a lot of experience and are looking to play with something different give it a try. If you have a project that needs to get done but you are confident will never become FriendFeed then get your project done using proven tools and stop wasting your time on sexy tools for a problem you don't have. 
You can save Excel spreadsheets as text files and the columns will be tab-separated. Then you can just, you know, parse text... How well does this library work anyway; aren't the Excel formats proprietary?
I use it on http://iwl.me which currently serves about a million pageviews daily off a single RackspaceCloud 512 MB VPS instance. I wrote it in a day or two, and web.py was great for such a quick project. I don't like templating in web.py, though, so you might want to use something like Django templates (or the ones from Tornado).
birthed at reddit
You are the 5th person I have heard ask this question in the past week. happy weekend!
A cursory search suggests that this doesn't work for .xlsx files (Excel 2007 and 2010). If that's the case, this is of limited usefulness. I don't mean to bag on the author; it's cool that he built something and shared it with everyone. It's just that MS switched formats years ago and I don't think they're planning on switching back.
I think I've asked this elsewhere but besides the developers does anybody use IronPython for work? I understand that it is a fast distribution and can see how it would work in the enterprizy world but I simply haven't run across it being used in the wild.
I find that swapping in the Mako templating engine is usually the best bet, which is pretty much the default for me now. You can pop in the GAE somewhat easily or use mod_wsgi or whatever is considered best practice these days, flexibility ftw.
I think you kind of missed the point of tornado. Calling it more complex is weird, and benchmarking it as a WSGI server is weird. The WSGI support is just an extra sort of feature, and you lose all the really nice long polling stuff. Note that in non-WSGI mode, it performs quite well in benchmarks. The underlying code is not particularly complex (quite simple compared to something like Django!), and the code to use it is not particularly complex (again, quite simple compared to something like Django!). I use it especially because I can build things very quickly in it. I mean also.. the OP is looking for a framework, not a webserver.. this whole post is a giant red herring. 
the .xls format is still supported by excel and presents a format that your business people can open in excel with most of its features, and also be understood by a program using xlrd without requiring them to "save as...". you also get a little bit of format-agnostic typing behavior from xlrd, though their interface for dates is more cumbersome than it should be.
I think it's most common usage is for adding scripting to .NET applications. If you search around on the web you'll find tons of different apps which support scripting via IronPython. It's also what I've been pushing at various Microsoft conferences where I've given talks. Beyond that there's of course Resolver One which always deserves a mention as being a full app written in IronPython and there's a bunch of uses just to write simple scripts that I've heard about as well.
Damned, they beat PyPy to the punch (we've got Benjamin Peterson, CPython 2.7 release manager, and core developer working on it).
I like web2py, but I hate spending 30 minutes every time I make a new site deleting all of its shit just so that I can use the good parts of web2py. I sincerely hope this won't make the time it takes me increase, or else I'll switch to using django again, as much as I'd hate it.
The biggest project using it I think is [resolver one](http://www.resolversystems.com/), which is actually pretty neat from what I've seen of it. I've also used it at work for quick prototyping / testing - I've used it to generate bulk test data on sharepoint through the object model, and it's very handy to just open a python prompt and play about with the objects to figure out how to do something, though I haven't actually used it in a released product.
I was more impressed by [OBrowser](http://www.pps.jussieu.fr/~canou/obrowser/tutorial/) (which is also faster).
IMO github still seems to work nicer than sf, but it's still in prototype. The following are my considerations: * I currently prefer github to sf/launchpad/googlecode because it's site SIGNIFICANTLY is better. * I prefer mercurial over any other VCS, followed by bzr, then git, then svn. * github has a faint touch of arrogance around their site, while I know it's probably not the case, I usually like to attribute it to their use of ruby on rails and get a chuckle. * sf is the best known open source site for windows users as a whole, making it easier to expose open source to the world.
The library seems to work well. There are libraries like this in most languages. The reason I took this approach is because the review text has all sorts of tabs, commas, quotes etc and I couldn't find suitable delimiters. This seems more direct. 
I didn't attempt to use it on 2007 or 2010 formats, but you can save as a 2003 compatible file from those newer releases. My point was that it worked for me and that it might work for someone else. 
It isn't a race.
Well, if your data contains tabs or whatever "unconvenient" characters a library such as this one might be a better option... Otherwise you have to "hack" something weird up. The other thing that'll possibly screw you up is empty columns. It would be nice to just `.split("\t")` :)
I hear you. I didn't expect to have to use this approach.
I do totally agree with you. The problem with web.py's community is they don't mention or advertise the framework anywhere. I've no idea who uses Flask or Bottle but we see "new version of (Flask|Bottle|you_name_it) released" on reddit all the time but I've never seen a web.py story on reddit besides it's used by quite a lot websites which receive high amount of traffic. It's a solid framework.
fabric, virtualenv, sqlalchemy, feedparser
I think [nipy](http://nipy.sourceforge.net/nipy/stable/index.html) will interest you 
What's the beef with that? I'm looking at using tornado for an app
You are incompatible with anything else out there. If that is a problem might depend on your use case.
There is a better option. Excel has a CSV export which properly escapes characters, and Python can read it through the standard "csv" module. Done.
Been looking at it, it's not quite ready for prime time: &gt; If you are trying to get some work done wait until we have a stable release. For now, the code will primarily be of interest to developers
Why not just mysqlimport a CSV?
standard library: itertools collections (especially collections.defaultdict) difflib is extremely useful but slow and buggy urllib/urllib2 dateutil External libraries: jsonpickle NumPy SciPy Matplotlib lxml (better than beautifulsoup in every way I've been able to find) pylons
I had problems using this approach a couple of days ago. Using the csv module, I found that the quote_minimal, nonnumeric etc constants were a little hit or miss. Essentially, it would either quote my integer fields or would skip quoting some, not all, of my text fields. I ended up having less trouble just writing something from scratch. That said, I may have just been doing something incredibly stupid.
Why so many downloads? IMO web2py is descent framework with excellent people behind it.
Downloads? Did you mean downvotes?
&gt;Why so many downloads? I assume you mean down-votes. Because people tend to be zealots about these things.
I assume you meant down votes. Most top stories on reddit hover around 60% so 58% like ratio isn't bad for this story and unfortunately most redditors don't want to hear anything except Django.
[The grammar in question, which is pretty neat stuff.](http://github.com/jabapyth/css/blob/master/css/grammar.py)
For some more background on meta-classes see: http://www.cafepy.com/article/python_types_and_objects/
See near the end of [this](http://mail.python.org/pipermail/python-ideas/2010-June/thread.html#7476) thread where Nick Coghlan suggests it as a variant of a [prior proposal](http://www.mail-archive.com/python-list@python.org/msg07034.html). Interesting to see the same idea crop up elsewhere, although I can't say as I approve of using `locals()` instead of just a dict literal. ;-)
&gt; most redditors don't want to hear anything except Django I think most redditors just don't like web2py. Not without reason I should add.
No. The new scaffolding app is actually smaller than before. This amount to a comment in the file models/db.py. delete the comment if you do not care, uncomment to use it.
If you make to EuroPython by today look for me. I'd like to buy you dinner.
I will arrive very late today, but I hope we will have a a chance this week to meet in person :)
Unfortunately, I was only able to stay for the week-end and have to leave tomorrow morning. Anyway, I am staying at the ETAP if you do not arrive too late. It would be nice to meet in person. In any case good luck with your talk.
anyone done this yet?
I think it is a bad idea to intergrate with a commercial plugin. I think it would better to have smth like this http://github.com/viatropos/authlogic-connect
I'm about half-way through the class right now. I've been doing the readings and the assignments along with the lectures and I feel I'm learning quite a bit. Well worth the time.
great thanks!
I have lots of docstrings, why can't I just type python sphinx.py my_project_path and have it render some default representation of the documentation? I found it's really hard to start and I would have to put a lot of effort to make sphinx work for an existing big project that has all it's info in plain text docstrings. Maybe I couldn't find how to work this feature...
Sphinx is not an API documentation tool. It's designed for hand written documentation which in our mind is the only documentation that actually counts :) There are however tools to combine the concept of in-code documentation and hand written documentation. One is called autodoc, that pulls docstrings and signatures for members and another one is autosummary from the contrib package which creates .rst files with all the necessary autodoc comands from existing code. But they are not intended to be used as API doc tool. For that, epydoc and others exist.
All modern frameworks for Python have their own basic HTTP server in the package. And if they do not, then they are still WSGI applications for which the Python standard library has a webserver (wsgiref). For 99% of all small applications this is more than you actually need. For microframeworks, we already have a thread on reddit where you might want to pick one of your choice :)
Google app engine is nice, I really like not worring about sys admin stuff. Its also quite fast and scales well since its on the googles, although bad coding can kill that to ;-) Ive used the python api and like it very much since its quite simple. Setting up a good db scema can be confusing at first since its not sql, but it is well documented their are lots of tutorials. If you do need more then the free quota the priceing is also fair. However your code must be pure python 2.5 :/
Metaclasses are deepest Python Magic - close second would be Descriptors and Descriptor Protocols.
+1. That's one of the finest documents on Metaclasses I've seen on Internet. Its a shame that its not publicized that much.
No experience with the OCW version, but my friends who took the real-life class seemed to find it pretty useful. 
&gt; Did you mean downvotes? Had to hop on that trend. I down-voted because facebook is suck, and I like web2py so I dislike this story.
Now, I love Arch! Who would say that a Debian fanboy would say that! It is about time to make the transition, as it has been pointed out by Python community itself.
i wrote http://pypi.python.org/pypi/pyscope when i toyed with those ideas
Unrelated but there are some style issues with the program such as using 8 spaces per tab (instead of 4), and no space between operators. They're just style issues, but I think it's important to use a style that most of the people use. See [PEP8](http://www.python.org/dev/peps/pep-0008/) for more details. Edit: it's also probably better to use longer variable names than to use short names and have a comment explaining what they are. E.g. instead of calling the parameter to diffKey "A, c, threshold, amount" and having the comment, you could just have the parameters be named "Image, colors, tolerance\_threshold, matte\_multiplier\_amount. 
granted, their list of python3 packages is *way* smaller
Thanks, that looks like the same idea. Using the proxy object is clever - I ended up requiring the user to make a function call to get the current value, which is less clean but simpler to implement. That proxy base class may come in handy.
As a python and arch fanboy I think this is a terrible idea. The python3 binary is called python3, not python. I don't think there are plans to change that. So now you have this weird situation where arch is one of the few places where the binaries are swapped. In my mind, it would make more sense to make the pyrhon2 package and update all the core scripts to point to the python3 binary and instead of rewriting all the older packages just have them have a dependency on python2. Less rewriting and more consistent with regular python. 
Good, and best of luck! Great aspect of minimalist distros, big changes with far less breakage. But don't get cocky, Pythong3 will be out of Debian unstable in 8-10 years...
okay you win list comprehensions can be pretty evil especially multi-dimensional ones
Now that NumPy and other large projects are Python 3 compatible, I think it's a perfectly reasonable leap of faith.
s/USC-4/UCS-4/g
I just went back to this thread to suggest ``__missing__``. Have an upvote. :)
&gt; "Metaclasses are deeper magic than 99% of users should ever worry about. If you wonder whether you need them, you don't." Uncle Timmy (aka Tim Peters)
Yeah. That makes sense. I'm just being quite lazy, inefficiently also because I add the comment anyway. Thanks. I'll change that.
There are various ways of avoiding the speed penalty of pure-Python code for image processing: * use [numpy](http://numpy.scipy.org/), rewrite your algorithms in terms of array operations * use [Cython](http://www.cython.org/) for the algorithms * use [Psyco](http://psyco.sourceforge.net/), the Python JIT engine, but don't expect a miracle 
And [Brainvisa](http://brainvisa.info/)?
It made me wonder when will Python 2.7 lands in Arch Linux. Apparently according to the [forum](https://bbs.archlinux.org/viewtopic.php?id=101250), it will land on August 10 to the testing repository alongside with the proposed Python 3 transition.
brainvisa looks cool. Check out [Mayavi](http://mayavi.sourceforge.net/) too. I have a colleague rendering some very interesting DTI work/mapping in Mayavi. And let's be honest, DTI maps are the coolest thing (visually) to come out of brain imaging. :)
I don't think that's the same. Arch is changing the default version to 3, not just making it available. In other words, the Arch equivalent of "apt-get install python" will install Python 3 instead of 2. I think most distros have some Python 3 packages by this point, but this is the first I've heard of one making Python 3 the default.
Wow, cool. I'll have a look into those. Thanks.
Looking at the makefiles of python 2.7 and 3.1.2 it looks like this is the following scenario: * python2.7 =&gt; make install installs python2.7 and a symlink called python which points to 2.7 * python3.1.2 =&gt; make install installs python3.1 and a symlink called python3 which points to 3.1 By default full install of python3, there is no python binary. It was decided at pycon09 that python3's binaries would be forever called python3. I can only find references to this fact on the list, it does not appear that there was a general posting about it, but [here](http://mail.python.org/pipermail/python-dev/2009-April/088887.html) is a reference to it. On the majority of platforms that install python as per the standard source makefile then if you had a 2.x and 3.x installed simultaneously, python would point to python2.x and python3 would point to python3.x. Only on Arch would it be reversed, which may trip people up who work in multiple environments. Granted, it's up to the distribution who really decides what /usr/bin/python points to, I just disagree on the grounds that its unlikely any other distribution will follow suit in the near future, especially on enterprise places where a change like this could take a decade.
Yeah, I don't know if you noticed the username, but that was original question that lead me to this bit of information. All I really wanted was the damned argparse module, but when I read the link I realized "oh damn, they're really going for it." Figured reddit folk would be interested.
&gt; Just to make matters worse, we will also &gt; enable unicode (USC4) support in python2 &gt; at the same time ! Really? Did earlier versions of Arch ship Python 2.x with Unicode disabled? That would break so much code.
&gt; the Arch equivalent of "apt-get install python" As an FYI, that's `pacman -S python`.
Guess I missed you then, arrived about an hour ago at my apartment.
I'm not sure what they mean exactly, Unicode works in Python on my Arch system.
Makes me happy to be a happy Arch user.
Very interesting! Does anybody know of similar software for barcodes. That is software that can read pictures or even video and decode a bar code? 
Tornado is easy to use: http://www.tornadoweb.org/
Arch is a damn good distro.
Python 2.x uses UCS-2 by default (as opposed to UCS-4). They're both ways to encode Unicode data. Now why it says "USC4" is beyond me. Hopefully that's just a typo.
Although [UCS-2](http://en.wikipedia.org/wiki/UTF-16/UCS-2) can only encode characters in the [Basic Multilingual Plane](http://en.wikipedia.org/wiki/Unicode_plane), not the whole range of code-points in the [UCS](http://en.wikipedia.org/wiki/Universal_Character_Set) (17 planes total).
Sadly, epydoc is pretty ugly. I wish there was an easy way to generate an API doc with sphinx. I guess I probably could write an auto-autodoc one day...
&gt;As an off-the-cuff first attempt, we can adapt the above algorithm by keeping track of the current center and expanding until we find the longest palindrome around that center, in which case we then consider the last letter (or space) of that palindrome as the new center. I know the author mentions that this isn't correct, but...I don't even see why it might *seem* correct or be up for consideration. Am I missing something?
On Gentoo you can actually install multiple versions of Python and even set Python 3 as default.
It already is. http://packages.debian.org/sid/python3
This is the kind of bullshit that made me leave Arch and never look back. At least this time they are keeping 2.6 somewhere. Back in 2008 they decided to completely replace python 2.5.2 with python 2.6. Without any warning or any way to keep python 2.5. As if that was not enough, when you asked for help keeping python 2.5 you got this response from Arch's main fucking developer: &gt;Why don't you want to upgrade python? If you're serious about it, just don't upgrade your system. &gt; &gt;But I have a feeling there's a non-reason why you don't want to upgrade. We should still have a python24 package if you want to mimic that. ([Source](https://bbs.archlinux.org/viewtopic.php?id=58296)) Yes. I was serious at that moment about not upgrading. I had some non-trivial code on python 2.5 that wouldn't run on 2.6 (or 2.4). If I'm not mistaken, it used numpy. Back then, numpy wasn't even close of being ported. That was my last day on arch. I took me a couple of days change to debian but at least now I have to possibility to install python 2.4, 2.5, 2.6, 2.7, 3.0 and 3.1 on the same machine. That's difference between a toy package manager (pacman) and a real one (dpkg, portage, etc). I can keep going but I'm guessing this is going to give me enough downvotes for now.
Have you tested characters out of the basic multilingual plane?
Well you should still have the comment really but use doc strings instead, an example in my preferred format. def do_magic(spell, ingredients = None): '''This function does magic!!! Args: spell - The spell to cast Opt: ingredients - ingredients needed (default None)''' if ingredients: make_potion(ingredients) cast(spell) You can then read the doc string from the python interpreter using help(do_magic), and use pydoc to generate API documentation. If you already know this, sorry for patronizing you but its best to get into good habits from the beginning
Yeah. CherryPy makes me happy every time I use it.
&gt; I'm not an active CherryPy user; however, I was under the impression that the point was to be a web library, not a web framework. Has this changed? CherryPy fits the definition of a microframework, imo.
Genshi seconded. Amazing for people with mild OCD.
Whoa... Dude, you need to write a longer blog post about how you made that happen!
Based on the second puzzle example you gave, how about WalkWalkHorse! as the name? Yes, including the exclamation mark at the end.
I suspect you're confusing the parser. Trying this seems to work: &gt;&gt;&gt; (2).__add__(3) 5
Why can't we use a variable length encoding?
I think it's about parser-complexity. To parse `2.__add__` you need a bigger lookahead as in `10.5.__add__`, because it does have to decide if it is a float.
Yup, this looks like a parser bug/misfeature. Float and string literals are handled correctly, int literals are not. 
Yeah. Or even `2 .__add__(3)` (ie space after 2). It's a tokenizer quirk, because "2." is a legitimate float value, so this gets tokenized as: [(NUMBER, "2."), (NAME, "__add__"), ... ] There's a similar issue in C++ with nested templates, because "&gt;&gt;" gets interpreted as a leftshift operator, so "`map&lt;string, pair&lt;int, int&gt;&gt;`" is an error, but `map&lt;string, pair&lt;int, int&gt; &gt;` works. 
Python doesn't support that as its internal representation.
If you want to look at a comparison of the frameworks then take a look at this; http://en.wikipedia.org/wiki/Comparison_of_web_application_frameworks And to learn pylons, which as most people have noted has terrible documentation, take a look at the official book (free online): http://pylonsbook.com/
No, I didn't know that. That cool. I'll add those too.
&gt; Float and string literals are handled correctly, int literals are not. `2.` is a float literal, not an int literal followed by an attribute accessor operator, that's all.
 &gt;&gt;&gt; type(2.) &lt;type 'float'&gt; that's why you see that result: `2.` and `.2` are float literals in Python (you don't have to write `2.0` or `0.2` as you would in, say, Ruby). As a result, `2.__add__(3)` is parsed as `(2.)__add__(3)`, not `(2).__add__(3)` and the parser blows up because it's meaningless. A second consequence is that `2..__add__(3)` is perfectly valid and equivalent to `2.0 + 3`
 &gt;&gt;&gt; 2. 2.0 &gt;&gt;&gt; 2..__add__ &lt;method-wrapper '__add__' of float object at 0x81a3934&gt; Ooooh. A nasty piece of syntax ambiguity right there. Thanks for pointing that out.
&gt; Ooooh. A nasty piece of syntax ambiguity right there. i don't think it's ambiguous (quite the opposite, `\d+\.` is always a float, whatever comes after the dot), though it's not exactly obvious the first time you hit it. edit: to whoever downvoted ascii, not cool.
&gt; There's a similar issue in C++ with nested templates Not in C++0x! :)
Well, it could try to backtrack in order to find out whether the programmer meant `(2).__add__`, but I guess this is where the Zen of Python comes in: _"Explicit is better than implicit."_ and _"In the face of ambiguity, refuse the temptation to guess."_.
Oops. I just clicked your link and realized that it's not the same course. I've been taking the [6.00 course](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/), which is also an intro to Python class. The course you linked is in the condensed IAP (independent activities period). It covers the same material and uses the same book.
You're probably looking for the [6.00 course](http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-00-introduction-to-computer-science-and-programming-fall-2008/).
Honestly I would suggest CherryPy 3. This is all you need to get started: import cherrypy class AwesomeWebApp(object): @cherrypy.expose def hello(self, name1 = "Steve", name2 = "Mike"): return "Hello %s and %s" % (name1, name2) cherrypy.quickstart(AwesomeWebApp()) Then just point your browser to http://localhost:8080/hello?name1=Bill&amp;name2=Joe You can later deploy it using Apache's mod_proxy. **Edit:** This should get you the rest of the way (including web templating, JSON, AJAX, form validation, etc.) http://genshi.edgewall.org/wiki/GenshiTutorial
I have a huge pile of decorators in my server code... @cherrypy.expose @security.require_known_host @security.require_twitter_authentication(with_redirect = "/register/activate") @template.output("register/activate.html") def activate(self): user = db.get_user_by_screen_name(cherrypy.session["screen_name"]) return template.render(user = user) Is nice!
It's ambiguous to the programmer who doesn't read BNF rules. I'm sort of surprised that Python doesn't give a `SyntaxError` on `2.` and require `2.0` instead.
&gt; I'm sort of surprised that Python doesn't give a SyntaxError on 2. and require 2.0 instead. I think the point was to let people write "2." when they wanted a float 2, and ".2" when they didn't want any integer section.
I've made that mistake so many times in C++.
People say Genshi is slow though. Not that my primary needs are ultraperformance… There's [Chameleon](http://chameleon.repoze.org/) which is [said](http://blog.penzilla.net/2010/02/python-template-language-performance.html) to turn Genshi into one of the fastest engines.
I think this is also a problem in Ruby, but in other direction--2. is a float in Python but a syntax error in Ruby.
I actually was just wondering why ruby required something after the decimal for floating point constants, now I found out why; so 2.to_s can be easily parsed properly.
Well, it was intended as a joke, but I see a few did not approve. Yes, Python3 (v3.1.2) is available in sid (unstable) and squeeze (testing). The article was in regards to Python3 being the *default*. Which it's not in Debian, not even in the unstable branch it's [2.6.5](http://packages.debian.org/sid/python/python). Your link just shows the default *3.x version*.
Indeed. Otherwise, either the grammar would be far more complex, or as with Python you'd have to write (2).to_s
Indeed. In Ruby, you have to write 2.0, because `2.` is an integer followed by the message-sending operator `.`
I just arrived back to Italy. I had to come back for personal reasons. there will be another occasion. Good luck with your talk.
Given that explicit is better than implicit, "2." meaning "2.0" seems arguably unpythonic.
The dot seems pretty explicit to me.
But the zero after the dot is implicit.
It doesn't serve a role, it's not the 0 which makes the literal into a float in Python, it's the dot. Which is why .5 is a valid float literal as well.
this entire thread proves that it's pretty ambiguous. if it was truly explicit there would be no questions.
How did they fix this?
[eric](http://en.wikipedia.org/wiki/Eric_Python_IDE)
No. At best this entire thread proves that it's not obvious. There is *nothing* ambiguous about it.
[PEP 3124: Overloading, Generic Functions, Interfaces, and Adaptation](http://www.python.org/dev/peps/pep-3124/)
&gt;Therefore we can examine all 2n + 1 possible centers and find the longest palindrome for that center, keeping track of the overall longest palindrome. This has worst-case complexity O(n2). How is this different from the first algorithm, aside from the order in which comparisons are made? You still have to run isPalindrome on `n*(n+1)/2` strings in the worst case, yes? Did you leave something out of the description? I gather that isPalindrome is O(n), so I would expect `find_largest_palindrome_centered_here()` to be O(n*n).
good pep, but it is bad (imho) that was not adopted
I don't yet care about the performance. I'm not building a reddit clone any time soon, it's completely okay for a page to render even half a second, and most stuff you want done instantly you'll do with AJAX anyway, so the templating engine is irrelevant.
It's not rejected is it? I was thinking maybe you could model your API after this PEP. Also it notes that [PEAK-Rules](http://pypi.python.org/pypi/PEAK-Rules) implement most of it already. Edit: Hah, PEAK-Rules uses string programming. I really don't like string programming. I wonder if you can have lambdas in decorator arguments? Edit: Why the need for ``@add_two.when``? Why not just ``@multifunction(str)``? &gt; The @overload decorator is a common-case shorthand for the more general @when decorator. It allows you to leave out the name of the function you are overloading, at the expense of requiring the target function to be in the local namespace. So I see the need for ``when``, but maybe you could add the behavior of ``overload`` to your ``multi{function,method}``? Just a thought.
&gt; It's not rejected is it? I think it is rejected unofficially (read related mail list discussion). &gt; I wonder if you can have lambdas in decorator arguments? Sure I can, but for now, I want to stick with this simple implementation (dispatching by argument types only) and use it in wild... then it will be more clearer if I need dispatching by custom predicates. &gt; Why the need for @add_two.when? Why not just @multifunction(str)? Yeah, I can look at the local namespace for original multi{function,method} to add rule to it, but I think the existent way is more explicit and doesn't add much mental overhead. EDIT: Code is on the [github](http://github.com/andreypopp/generic) — just fork it for experiments ;-)
http://www.open-std.org/jtc1/sc22/wg21/docs/papers/2005/n1757.html
There were simply too many jokes about Debian being too old. Now you can joke about RedHat. Its Enterprise editions are usually much older than Debian.
Oh, good God. I guess that's better, but does C++ really need to be *harder* to parse than it already is? Eek.
It's a two-level system, so it'd have to be like django.com.py :( And it's $100/year, and you need a local Paraguayan representative.
You have to be related to Paraguay somehow to get access to a .py domain: http://www.nic.py/pautas.html#seccion_3
A similar Ruby parser oddity comes from the ambiguity of being able to leave out parentheses in function calls. So `foo -2` can have a different meaning to `foo-2, depending on what foo is.
I'd guess because you can't make time-saving assumptions about the length of characters. Lets say I want to index into a variable-length-encoded string. like char = string[200] CPython can't then do something like multiply the byte length of a character in a string of my type by my index and fetch that address from memory, it would have to iterate through the string and find me the 200th character, OR simply give me the 200th byte, which wouldn't be as useful. A fixed length encoding like UCS-2 or UCS-4 is less memory efficient, but **much** more time efficient.
import Paraguay
I think there could be lots of potentially awesome domain names that would end in .py
 (2).__add__(3)
Just thinking of the possibilities makes me hap.py!
Don't do this - you are not supposed to call `__special__` method names. They exists so you can override operators like + and / and provide standard behavior. For example, if you want to support the "in" operator, you implement `__contains__`. 
God damn domain hacks, we are better than this!!!!!
from Paraguay import Larissa
Start a corporation in paraguay - problem solved
http://compsognathus.com.py 
The last bullet point says anyone can have one as long as it's purchased through a Paraguan company... unless Google Translate is lying :)
We actually looked in to this a couple of years ago. It turns out Paraguay isn't a particularly stable place to buy a domain name - apparently a while back the political opposition's website was mysteriously redirected to a porn site during an election.
The Icelandic TLD is .is, which has some potential. [Some people](http://this.is/) already try to capitalize some of it.
The thought makes me feel all fap.py!
I have relatives that live there, but if it's a two tiered domain name my efforts may be fruitless.
::For fun and profit, quickly writes python script to find dictionary words that end in py::
there must be a Python or Django user group there
$ grep py\$ /usr/share/dict/*
 2+3 FTFY ;)
I think the point is that you don't have to run a linear-time is-palindrome function. You have `2n + 1` centers. From each center, you find the length of the palindrome it forms, which can be done in linear time, hence quadratic. Unlike the cubic time algorithm, searching and testing are combined into the same linear-time operation.
There are some potentially awesome ones that paraguay could use too. In Guaraní, the official indigenous language, py [pɨ] is a fairly common syllable. To name a few: * hapy - to burn * hepy - to be expensive * jepyapy - to be preoccupied * korapy - a pen, yard * mbohapy - three * py - foot * tepy - price, value * ypy - origin, center Some creative guarani ñe'ẽva could probably do better.
print [word for word in open(PATH\_TO\_DICT).read().split() if word[-2:].lower() == "py"]
Larissa has no green card, hence she is going to be exported.
 #!/usr/bin/env python from us_government import PaperWork_Generator from Paraguay import larissa def give_larissa_green_card_for_domain_name: try: paperwork = new PaperWork_Generator paperwork.fillout_paperwork("Larissa") paperwork.setReturnGPSCordinates(-25.277183,-57.637279) paperwork.send(); except Exception, e: print "Sorry Larissa" 
Let's keep trying. while green_card_application_fail: give_larissa_green_card_for_domain_name()
You mean if ``word.lower().endswith("py")`` ;)
Ah, taking advantage of the cascading test failures. Thanks for explaining.
brr, that's a horrible function, but sure.
You can probably get your bank to do it, then. They have companies established in most countries to do precisely that, if you have the right accounts.
Check out pickle. So cool. Lets you dump an object to a file, so you can save/restore it later. No writing parsers !
I read it to mean as long as you buy it from a Paraguan registrar, it's ok.
Why would you want to call methods on numeric literals? That's why no one cares about this parser "issue." 
import re print re.findall(r"(py$)", "\n".join(file($PATH_TO_DICT).readlines()))
The thing is that in the real world people write ".2". They never write "2.". Even though a number of programming languages allow "2." for floats, I don't think I've ever seen any programs take advantage of that. And if they did I probably wouldn't be too impressed. Using "2." instead of "2.0" or "float(2)" provides no benefit. It hurts readability (case in point, the OP's confusion). It also violates TOOWTDI.
That's true with the current grammar rules. But what rumplesmigskin and I are arguing is that those rules aren't very good because they don't correspond with how people actually write numbers in the real world.
&gt; But what rumplesmigskin and I are arguing is that those rules aren't very good because they don't correspond with how people actually write numbers in the real world. No. That would have to do with obviousness, not explicitness. rumplemigskin argued that it's implicit, not that it's non-obvious. He's wrong.
`__future__` and `this`. But stay away from `braces`, that one's no good.
Yes of course especially when there is no password. It has happened with Twitter web apps where a stupid app starts spamming and then you have to change your Twitter username and password. Another issue is security because if someone could get the username and password you are done. With XOAuth besides the oauth tokens you also need the consumer key and secret so you add a bit more of security. 
Fortunately, DNS is case insensitive.
I'm aware of the tradeoffs between a fixed-length and a variable-length encoding. Most of the world seems happy with UTF-8, including several time-sensitive applications. I don't see why Python should be any different.
If you need low latency you should use sockets rather than web services. If you use a web service then you need to open a new connection for each request/response cycle, and that's expensive. I'd recommend you ignore the latency considerations to start with. Instead, have a look at SimpleXMLRPCServer in the standard library. There's lots of example code around to get that started. If you decide you need performance later on you can rewrite it to sockets. This follows the "get it working, get it right, make it fast" approach.
&gt; For microframeworks, we already have a thread on reddit where you might want to pick one of your choice :) No. He will pick web.py. :P
The user is more interested in consistency, and as such, I think it's a fair question. If you don't understand why a tool behaves a certain way, it scares you into not wanting to use it.
&gt; It's a tokenizer quirk, because "2." is a legitimate float value And the reason for this is consistency, because this is "2.j" and "2j" do the same thing.
SOO many syntax errors
Are you on Linux? Maybe use something like subprocess.call("sendmail ...
String formatting? "email body %(variable)s" % dict, then send it out via smtplib.
http://pythoncard.sourceforge.net/ might be worth a look
Why are you using Tkinter? Not that it's bad, but it's not the most common toolkit for real application development. The three main python UI toolkits are [PyQt](http://www.riverbankcomputing.co.uk/software/pyqt/intro), [PyGTK](http://www.pygtk.org/), and [wxPython](http://www.wxpython.org/). And yes, it is going to be a little bit of a learning curve from visual basic. Welcome to the real world.
I tried the smtp route, but while it worked on one machine (a laptop without an upstream email) it didn't work on another (a server with an upstream service). No doubt someone who understands these things will tell me I'm a dummy (its true, I am), I let sendmail understand it. Anyway, here is the subroutine I'm using (I've edited it slightly to remove some extra stuff so possibly there is now a typo). def send_mail(to_addr,from_addr,subject,message): """Send the mail message to_addr list of strings from_addr string subject, message strings """ msg = MIMEText(message) msg["From"]=from_addr msg["To"]=",".join(to_addr) msg["Subject"]=subject ## server = smtplib.SMTP('localhost') ## server.sendmail(fromaddr, to_addr, msg.as_string()) ## server.quit() p = os.popen("%s -t -i" % ('/usr/sbin/sendmail',), "w") p.write(msg.as_string()) sts = p.close() if sts: print "Sendmail exit status for "+repr(subject)+": "+str(sts) 
...really stop calling them micro. i saw what flask has to give last time, and i wouldn't call it a micro web framework.
and the [codetalker](http://jaredforsyth.com/projects/codetalker/) in question.
I recommend [An Introduction to Tkinter](http://effbot.org/tkinterbook/tkinter-index.htm#introduction). Generally, Fredrik Lundh's tutorials answer most of my basic questions. Also, I used Tkinter to write [Raven Checkers](https://code.google.com/p/raven-checkers/), which uses an MVC architecture. It has a simple GUI with menus, a canvas, and some basic dialogs that you can look at. Not saying it's ideal, but the download of v0.3.1 is definitely a working application.
those who web2py possibilities want to keep it for themselves ;)
I suggest www.pi.py (Package Index for Python).
 from htmlentitydefs import codepoint2name def html_escape(s): return "".join(("&amp;%s;" % codepoint2name[ord(c)] if ord(c) in codepoint2name else c) for c in s)
IIRC gentoo has python3 as default python.
qt.py -- I never understood why they named it the opposite when such a good opportunity was staring them in the face.
Python people have never been terribly interested in multimedia, sadly.
Because I think you're supposed to pronounce it as 'cute' and not 'cute-tee'.
&gt; new PaperWork_Generator Is new a keyword in python? &gt; paperwork.send(); You also don't need the ; at the end of a line &gt; except Exception, e: To use exceptions you write: except Exception as e: And I'm left wondering why you use both names_like_this and namesLikeThat with a mix being NamesLike_Those You were probably trolling us all :)
Or, if you're on win32, use [blat](http://www.blat.net/).
 from email.MIMEMultipart import MIMEMultipart from email.MIMEText import MIMEText from email.Utils import COMMASPACE, formatdate import smtplib import textwrap SMTPSERVER = 'your.mail.server.example.com' to = [ '"Billy Bob" &lt;address@example.com&gt;', ] from_ = '"Your Email" &lt;email@example.com&gt;' def patmailer(username, msisdn, source, regdate, status): texttmpl = textwrap.dedent('''\ Username: %s MSISDN: %s Source: %s Registration Date: %s Registration Status: %s ''' % (username, msisdn, source, regdate, status)) htmltmpl = textwrap.dedent('''\ &lt;html&gt;&lt;body&gt; &lt;b&gt;Username:&lt;/b&gt; %s&lt;br&gt; &lt;b&gt;MSISDN:&lt;/b&gt; %s&lt;br&gt; &lt;b&gt;Source:&lt;/b&gt; %s&lt;br&gt; &lt;b&gt;Registration Date:&lt;/b&gt; %s&lt;br&gt; &lt;b&gt;Registration Status:&lt;/b&gt; %s&lt;br&gt; &lt;/body&gt;&lt;/html&gt; ''' % (username, msisdn, source, regdate, status)) msg = MIMEMultipart('alternative') msg.attach(MIMEText(texttmpl)) msg.attach(MIMEText(htmltmpl, 'html')) # Set whatever headers msg['Subject'] = 'Your Subject Here' msg['From'] = from_ msg['To'] = COMMASPACE.join(to) msg['Date'] = formatdate(localtime = True) msg['X-YourCustomHeader'] = 'Your Custom Header Value' # When using MIMEMultipart messages, they need to be # converted to a regular string msg = msg.as_string() server = smtplib.SMTP(SMTPSERVER) server.sendmail(from_, to, msg) server.quit() 
I'm disappointed that Apple hasn't registered apple.py yet.
just out of curiosity, what don't you like about endswith as a method? 
Or 'cutie'?
Merci beaucoup, monsieur! PyPI was just down yesterday.
I wasn't trying to troll you. I am just a noob.
Please let us know if you find any bugs at our bugtracker: http://bitbucket.org/bobf/bpython/issues Let's hope we do not need to repeat our tradition of an immediate point release :-)
Uhhh, why is this being downvoted? bpython is awesome.
http://docs.python.org/py3k/library/smtplib.html SMTPLIB
For pipelines this is what you need: [Ruffus](http://wwwfgu.anat.ox.ac.uk/~lg/oss/ruffus/)
The single downvote was probably done by an automatic program (a bot) as that downvote was received a second or two after submitting.
Or maybe someone doesn't care about point releases of a random piece of software?
i don't think it's "a random piece of software". It's definitely a notable Python app along with IPython. It's not like /r/Python gets many stories anyway, where we have to weed through the "point releases".
Yes, I think web2py is an excellent framework too. I truly hope that more developers would jump into this project to take it to the next level. As it is right now, it's very promising. I think there are two reasons for many down votes: (1) massimo's aggressive ways of promoting it and (2) so-called "purists" don't like certain design aspects of web2py. (1) -- I have no problem with how massimo promotes it. It's an open source; it's free and it's helpful. It's not like massimo is making tons of money on it. Fine with me. (2) -- As long as it works and it's effective. Who cares. The truth is with web2py I can easily and effortlessly develop applications. For me, the best platform is one that reduces as much agony as possible. There are some microframework that are like that too; but those frameworks have minimal sets of features. 
It's just downright stupid to think some automated script is running that's downvoting submissions. A point release is of no interest to most people. Especially when it has no information in the title which could possibly interest someone who isn't already using the software.
Might want to credit Jacob with this particular tip ;-)
came from [here](http://twitter.com/#search?q=pypi%20mirror), linked by [jek](http://twitter.com/__jek__) on #pocoo irc channel. thanks jacob if you started this!
Cute stuff like that is really, really annoying.
I find a downvote within the first two seconds of a link appearing on reddit a bit suspicious, the other received downvotes however, are not. Previous releases have been announced on the /r/Python subreddit as well as well as other things concerning bpython so I thought the 0.9.7 release fits in here as well. If it does not fit the hive mind will speak with it's downvotes. Are there any rules on software announcements in the /r/Python reddit?
Yahr, http://twitter.com/jacobian/status/18931005517 was the original post. He also gave the needed config for buildout and easy_install if you want to add those.
Very nice. This post describes everything in details: http://jacobian.org/writing/when-pypi-goes-down/ Thanks for pointing that, I wasn't aware.
I appreciate your work, keep it up, bpython is a really nice piece of software.
Fair enough. Users do want consistency. Magical behavior is confusing and ultimately discouraging. I just don’t think this counts as a real “issue” along those lines. A.) I think the average user is unlikely to come across this at all, since (unlike Ruby) in Python there’s no really pressing need to access the methods of integers. B.) It shouldn’t take above-average a lot of reflection to realize that Python treats `1.` as `1.0`. At that point the mystery is solved, so there’s no more fear of the unknown. So this is really only a problem for Rubyists who go poking around looking for the equivalent of `1..10.each` or whatever, get an error, but don’t figure out why the error arose. I’m not sure it would occur in many real world circumstances.
Here’s sample usage: c = sqrt(a*a + b*b) where: a = retrieve_a() b = retrieve_b() The obvious application of this is to make Ruby-esque blocks: obj.onclick.setcallback(f) where: def f(x, y): #Do callback stuff What does PyReddit think of this idea?
I just discovered bpython a few weeks ago. I've been teaching myself python slowly as I have time and bpython has helped make that time more productive. Thanks and please keep it up.
I'd rather first see Python changed to use normal scope rules. One scope per function, more than two scopes possible, and the nonlocal and global keywords unified to something that make sense.
I don't care too much about the Rubylikeness, but I like the readability.
In addition to the execution order problem, this also doesn't seem like a good use of indentation since it isn't really related to control flow.
I have no problem with using indentation to non-control-flow things like defining classes ;-)
Thats true, I guess the with statement uses indentation in a similar fashion too.
I like the idea, but to be really useful it would need to work with comprehensions - how might that look?
Do I see Haskell?
I think this has potential to greatly enhance readability of some code, used wisely. It says, these are the relevant helper-bits, they are secondary and specific to this statement; it puts the main formula up front and explicitly groups the parts of it. It also leaves you with a cleaner namespace. It indirectly solves the issues with the lambda while remaining pythonic and not copying the limited ruby block; for example you can have multiple closures in a where-clause, with full support for everything you can do with a function: the argument handling, decorators, docstrings, annotations… In the spirit of Python: generalized and not designed for a single specific feature; helps readability.
I agree that it's a non-issue. The point was that there was at least one person who came across this supposed inconsistency, and they hadn't yet identified it as a parser issue, but instead thought the language was inconsistent. In such a scenario, they have a right to call the consistency of the language into question, and we have a right to indicate to them that it's just a parsing non-issue, and that the language itself is sane and predictable.
Turbomail looks really easy. I heard about it here on reddit python.
A good use that I imagine is for writing decorators: def decorator(f): return wrapper where: @wraps(f) def wrapper(): f.__decorated__ = True return f I think this makes it much more obvious that it's the wrapper that's returned. A common one for me is passing local functions to ``re.sub``: def latex_to_html(text): return re.sub(r'\\(emph|textbf)\{(.+?)\}', typography, text) where: def typography(m): if m.group(1) == 'emph': return u'&lt;em&gt;%s&lt;/em&gt;' % m.group(2) elif m.group(1) == 'textbf': return u'&lt;strong&gt;%s&lt;/strong&gt;' % m.group(2) Threading and multiprocessing perhaps? p = Process(target=f, args=('bob',)) where: def f(name): print 'hello', name p.start() p.join() Now tell me, are these more readable without the where-clause?
It's a fairly random function. Seriously, how the FUCK did I get downvoted 5 times for that?! Fucking retards, my code works perfectly. Python isn't a one-way-solution system. I guess the downvoters were all VB users or something.
[Guido](http://mail.python.org/pipermail/python-ideas/2010-July/007597.html) thinks the name ``where`` is potentially confusing to people who speak SQL. I kinda like the suggested ``given`` and I'm not sure it's a good idea to borrow ``with`` giving it multiple unrelated meanings. I quite like the suggestion to allow it in list comprehensions and generator expressions: [y for x in collection where y = f(x)] Someone wanted to allow one-liners but this should work as a side-effect from Python syntax, I imagine? x = y where: y = f(x) I should really subscribe to python-ideas instead. :D
I used this to help recover from a particularly nasty bug (that didn't take down the machine); I had it send me a text via email when something was amiss. import smtplib def send_text(): to_addr = 'client@example.com' from_addr = 'me@example.net' password = '********' send_msg = "This is the message I'm sending" smtp_server = smtplib.SMTP_SSL('smtp.example.net', 465) login_result = smtp_server.login(from_addr, password) send_result = smtp_server.sendmail(from_addr, to_addr, send_msg) smtp_server.close() I believe I cobbled this together from the smtplib help page on docs.python.org, and it worked great.
What is the recommended way to update? I installed bpython via easy_install and already tried to run "easy_install bpython" again. 
Its ok *pat pat pat*
I'm relatively new to Python and bpython changed the way I'm programming a lot. It makes coding really interactive - you can easily try stuff out. Especially with auto complete + help(). I wonder if this still works for big programs as I only have written small toy scripts so far.
comprehensions as in: foo = [f for a in range(0, 11)] given: def f(n): return a*n This example in particular doesn't seem to have too much practicality, but I don't see why list comprehensions are out of the question
Try `easy_install -U bpython`. The `-U` is for "upgrade".
&gt; Most of the world seems happy with UTF-8, including several time-sensitive applications. Are you sure? Aren't most languages using USC-2 or USC-4 internally? (They may default to utf8 on IO operations though). 
I don't know about interpreter/compiler implementations, but if time-sensitive applications can deal with variable-length, I'd assume interpreters can too. I suppose a fixed-length just makes for easier coding in the end.
It's not a huge difference, but the proposal does say: &gt; This proposal initially used `where` based on the name of a similar construct in Haskell. However, it has been pointed out that there are existing Python libraries (such as Numpy [4]) that already use where in the SQL query condition sense, making that keyword choice potentially confusing. &gt; While `given` may also be used as a variable name (and hence would be deprecated using the usual \_\_future\_\_ dance for introducing new keywords), it is associated much more strongly with the desired "here are some extra variables this expression may use" semantics for the new clause. It's somewhat unclear, but this seems to be an endorsement of `given` over `where`, and they go on to propose a change to the grammar using `given` instead.
Seems reasonable. This can pretty much solve Python's one-statement-only-lambda problem. I would ditch any unnamed function for a locally named one.
I'm also using bpython. Mainly to see the methods/subclasses of a foreign import.
I am not sure if I like the syntax. The "given" keyword at the end of a statement is easily overlooked. You will continue reading the code, see that it is indented, look back and see that there is indeed a "given" keyword.
When I posted the comment, it was still `where`. The proposal is still being discussed on python-ideas, so feel free to comment on it there if you want to influence how it comes out.
That couldn’t be done before Python 4.0 though, so it won’t happen anytime soon.
I end up doing `sorted(l, key=key)` a fair amount. A `where` or `given` would be useful for that as well.
Python has one scope per function, with more than two scopes possible (using nonlocal and global). So the only thing you seem to be proposing is a unification of 'global' and 'nonlocal'. What did I misunderstand about your wish?
Guido mentioned this on the list. All the other block starting keywords go `keyword expression:` instead of `expression keyword:`. Any suggestion for a good keyword that could go at the front? Bear in mind `with` is taken. :-)
The problem is that foo = [f for a in range(0, 11)] given: def f(n): return a*n is sugar for def _(): def f(n): return a*n return [f for a in range(0, 11)] foo = _() which wouldn’t work as expected. You’d need the given to be inside the comprehension for it to work.
That’s where list comprehensions come from. Pythoners aren’t afraid to rip off Haskell ideas… once they figure out what the hell they mean. Expect monads in Python 1347.5.
Well, in this scenario, I have the right to keep posting replies long after the question is dead. :-)
What about no keyword at all? A colon introduces a new block with a local scope. a = sqrt(b+c): b = 12 c = 13
Neat but ew... I like the keyword. Helps with readability.
Ah, I didn't realize they had a penchant for editing after posting those. Good to know. I'll check out the discussion too. :)
All of this is pretty much syntactic sugar anyways. I think the way I put it seems pretty clear and concise to me which is pretty much the whole point, right?
What are the advantages vs ipython? Can you paste to it easily? ipython doesn't like multi-line pastes unless you go into %cpaste mode.
The real point is coming up with a proposal for block-like things that Guido won’t reject out of hand. Based on his comments on the list, it seems like he’s +.5 on this one, which is a good start.
Given (heh) your initial issue was with readability, I'd argue that this is even less readable.
Actually, I'm not clear on why the PEP thinks there needs to be a nested function definition at all; why not just push any shadowed names onto the stack and pop them back off again?
A hardcore Haskell artist can write monadic code with every language :)
I think it is more readable because you don't have to "scan" for that keyword at the end. Indentation alone is a good visual cue.
I had to do something like this once, though in Java. It was for printing checks. I ended up using the Java Graphics2D API. It was very hardcoded with "setText(x,y)" sort things for the different parts. Then several test prints. If the form doesn't change often, I think this would be simple to do in Python as well, but I am not sure what library to use.
You might consider generating the LaTeX, Docbook, or similar with Python and then generating the actual print file using the appropriate tools (can still invoke from Python, of course, and then send the output wherever you need to)? Of course, if there are better options explicitly for Python then hopefully someone will mention them. 
The proposal, as it stands, would still indent the block following the ``given``. Hence, your suggestion would remove the ``given``, and replace it with a single colon... which is much **harder** to scan for when you've noticed you're reading an indented block.
In fact, with this in maybe Guido will finally get his dream of deprecating lambda :D
Big plus for making the pastebin confirm and for the customizable url. I stopped using bpython awhile back because of accidental use of that pastebin feature, so I'm really happy to see those options in there. 
Awesome! How's Windows support coming along?
This feels quite like Haskell. In a good way! Though it can be used for evil.
Oh wow, this is really cool. I've been using IPython. I might be switching here. Can it be used for django's manage.py shell command?
Been using ipython and just trying this out now. In short, it's colorful and takes advantage of the terminal capabilities to keep a window up showing the method completion or help() of what you are currently entering. Pretty nice, actually, I recommend trying it out for comparison. Edit: it handles indentation on pastes perfectly for me without any magic.
Looks nice! I've been using iPython, which is also nice! How do they compare? I websearched and didn't find much.
sounds like something someone would suggest if they already knew where the problem was going 
As far as I know, this still works for big programs. Lots of people use ipython for this, at least.
I like it !
There are cases where you want a new namespace. For example, if you try to create functions that act as closures inside a for-loop, the different functions will all end up with the last value looped through as the value they are en-closuring unless you can find a way of making new namespaces as you go along. Ex. &gt;&gt;&gt; fs = [] &gt;&gt;&gt; for i in range(5): ... def f(): print("#", i) ... fs.append(f) ... &gt;&gt;&gt; [f() for f in fs] # 4 # 4 # 4 # 4 # 4 [None, None, None, None, None] Since it looks for `i` in the enclosing scope, `i` is going to be 4 by the time any of the funcs get called. The only way to get around this is with more namespaces.
"@with" ?
I frequently use IPython with a very large django project. I imagine bpython works the same.
Oh, how I wish that were "Status: WHEN HELL FREEZES OVER" because that syntax is horrible.
sorry but I stopped reading when I saw you were benchmarking with mod_python
I was trying to keep things as plain as possible. what do you suggest I use ? mod_wsgi ?
Yes. Nobody sensible uses mod_python.
It doesn't help readability, it hinders readability. It makes the programmer keep a set of variable names he doesn't know the meaning of until the point in the given: block where he can remove them from that set. It is far inferior to the simple, Python: a = retrieve_a() b = retrieve_b() c = sqrt(a*a + b*b) The straightforward code requires less processing to understand than the obfuscated "given" code: at every step of interpretation, the programmer knows the meaning of all entities that must be interpreted.
I think it's one of the worst syntax ideas I've seen in a long, long time.
The very first comment in [his blog post](http://jacobian.org/writing/when-pypi-goes-down/) mentions a seminal point, which many tends to ignore: &gt; **Simon Willison**: Sadly, just mirroring PyPI itself is not enough - many PyPI packages have the actual .tar.gz file hosted elsewhere, so even if PyPI is up a file might still 404. The "python-openid" package was linking to a 404ing URL a few weeks ago, which broke my own django-openid package and meant I couldn't deploy updates to one of my sites using my Fabric deployment script.
That better ?
I think it helps readability because it says that a and b are only used to build c. We don't need to keep track of them beyond that. It's a way to "stuff away" "helper variables" that are only used temporarily.
Thankfully, no, it doesn't. That's why it's great.
mod_python isn’t maintained since 2008 anymore.
Don't know if that was rhetorical, but no. I appreciated the notification, as debian's package is out of date and I hadn't updated my arch box, so I hadn't seen the update. Carry on, we love bpython, and the subreddit isn't crowded enough to worry about it. I usually hide point release posts myself, but I don't mind them, like I said they're good if it's a piece of software I actually frequently use.
Care to elaborate? I just set it up with a django project pretty easily with a .pythonrc file. Why would it be a good thing if it didn't work, though?
The #1 advantage IMHO is that ipython does way too much magic behind the scenes that tinkers with python internals which tends to introduce a nice new set of bugs. In the 2 or 3 weeks that I used iPython, each time I ran into something puzzling I had to first diagnose that it wasn't iPython gone wrong rather than my code. They fix them of course as they come up, but there's still always the possibility. bpython does things much more "delicately" I guess, so that stuff like that just doesn't happen. I realize that I haven't given a specific example, but pretty sure ikanobori knows a few; the few times that it happened to me were enough to never use ipython again. (Oh and the introspection/curses window is awesome :).
Heh, that's funny so did I actually, I was just this second trying to figure out how to use bpython with django-nonrel (which doesn't work with that same pythonrc code that you probably used) so I had to do a tiny tiny bit more fiddling. Anyways I didn't read what you wrote carefully enough, so disregard that :).
&gt; Another thing that is pretty obvious from the above is that PHP and Python were largely written for the Web and the rest were not [I really don't think that's true for Python.](http://en.wikipedia.org/wiki/History_of_Python)
Comparation of mod_php and mod_wsgi by measure output has no sense for me. With wsgi you can run 'instanced' application, by mod_php you can only 'parse' given files. By wsgi you don't have to warm up your application in every request (config files, in memory registry, ...). Php has to do it in every request (i'm not talking about f.e. memcached here).
Yeah that didn't come across quite right, I have rephrased it.
Conflicts with existing names, I assume.
Thank for the great example!
Much.
Nice and easy example, but how do you set the subject of the mail?
Thanks, that worked.
It seems to be a common misunderstanding that monads are a Haskell feature, while they are in fact just a design pattern. Which is why your seemingly tounge-in-check comment is very true. :)
While I agree with you that a keyword at the end is suboptimal, I don't think this is any better. This does suggest a syntax for the adoption of Ruby blocks in Python though, any expression (yielding a callable) could be followed by a colon and a block - in which case the block would be passed to the callable as a code object or a callable closure. Imagine being able to define the following with a library: atomic: read_some_vars() write_some_vars() async(a_callback): do_something_time_consuming() return a_value -- will invoke a_callback handle(button.click): alert("Hi!") etc. etc.
s/semicolon/colon/
Yes, bpython is awesome, and I'd also like to know the differences with iPython, particularly concerning scipy/numpy integration 
In fact in the 90s people often said "I program in CGI" when they meant Perl.
LOL
I would not use @multi / @add.when because when changing the order of the functions you'd have to change everything, and it doesn't feel tidy to have two different declarations for essentially the same feature, I'd go with only one declaration 
&gt;I must admit I was somewhat surprised by the significant differences in speed between Perl, PHP and Python (mod_python) when running under their respective Apache modules. I had fully expected the results to be virtually the same between all three. To me, it looks as though [your graph](http://l2admin.com/wp-content/uploads/2010/07/lang_comp1.png) does, in fact, show that mod\_php, mod\_perl, mod\_python, and mod\_wsgi gave very similar average request times. Furthermore, mod\_wsgi handled only about 2% requests per second more than mod\_php, which is not a very significant difference (though the ~12% difference between mod\_wsgi and mod\_perl is indeed significant).
yay meaningless benchmarks.
This look really cool and the pricing seems reasonable. Does anyone have any experience using this? Would it work well ranking text documents?
Fucking typical python, inventing more syntax for something that should have already existed.
holy fucking faggot fanboy shit
What, no cold fusion?
When you say: "doesn't seem to give me the ability to specify column placement", what exactly are lacking the ability to do? Is it to place the text you want at an exact location on the page? And are you using rlextra (ie, RML) or just the open source reportlab libraries?
Why would you not just use plain text?
http://docs.bpython-interpreter.org/django.html
bpython does less funny things to your environment, less magic.
Still on the list for a 1.0 release it's quite the bit of work, especially properly packaging gtk and pygtk with the installer.
Thanks, it should take some load off of me maintaining the pastebin as well (I remove pastes when I get emailed).
We will be making a list on our documentation site to list the main differences but it is mostly a no-magic interpreter with completion, pastebin, __doc__ tooltips and a show source function. (There is more, but those are the biggest pro's). There are offcourse also things IPython does better.
You should read python-ideas more often then. ;-)
First: use new style connections: self.button.stateChanged.connect(self.changeButtonText) instead of: self.connect(self.button, SIGNAL('stateChanged(int)'), self.changeButtonText) Second, I'm not sure I understand what you're trying to to, but why not use QAction toggled signal. Like such: self.tool_tips = {True: "View B", False: "View A"} self.button.toggled.connect(lambda b: self.setToolTip(_(self.tool_tips[b])))
I hate that Ruby treats blocks as a different kind of argument from everything else. An argument is an argument! The whole point of dynamic typing is not to make a big deal about whether the argument is a function or an integer or whatever. So, I would rewrite your first example as atomic(f) given: def f(): read_some_vars() write_some_vars() and the other examples along those same lines. Maybe though as a convenience, I might add the syntax `given def f():`, so you don’t have to extra indent things. Beyond that though, I hate the idea of having arguments passed in that aren’t shown being passed in.
Look at the second (longer) example in the PEP.
Aside from the coolness of using Python, I wonder on how it compares to [Disco](http://discoproject.org/). Considering of course with disco you have to perform the deployment on EC2 (or elsewhere) yourself.
The longer example is idiotic as well. First, it's more difficult to understand and comprehend than the straightforward code it replaces. Second, unless the variable name is being used more than once, it's stupid to introduce a variable name for a simple expression: one of the wonders of languages since Algol 60 is that we can always substitute expressions for named quantities as rvalues. In short, `where` is misfeature of Haskell and it will be a horrible misfeature in Python, leading to code that's more difficult to comprehend (code that introduces a new lexical category of "names with no current meaning whose meaning will be provided later") and more variable in the way it's written (contradicting Python's zen "there should be one obvious way to do it").
Thanks. The paste problem in ipython is that it autoindents for you so after a colon, the next line gets the autoindent plus the pasted spaces. Then the line after that is doesn't know whether to autoindent so you only get the pasted spaces.
I find it much easier to understand that code by just looking at the first line (which really does the work) rather than going through the entire block of getters. &gt; it's stupid to introduce a variable name for a simple expression In this example I suppose they could have done something like `desired_property = calc_value(temp=get_temperature(), ...)` but that isn't always the cleanest way of doing things (maybe `temperature` had to be converted to Celsius or `purity` required a complicated formula to calculate?). &gt; leading to code that's more difficult to comprehend Again, I think this proposed syntax makes code much easier to comprehend by emphasizing code that really matters. That said, I'm still not sold on the `given` keyword or it's position in the expression (it's easy to miss).
From the [Python Documentation](http://docs.python.org/library/email-examples.html#email-examples) (I'm pulling this from the very first example on that page), you need to build the message using MIME from the email package. Building on the previous example: import smtplib from email.mime.text import MIMEText def send_text(): to_addr = 'client@example.com' from_addr = 'me@example.net' password = '********' #New stuff to add subject, etc. send_msg = MIMEText('This is the message string') send_msg['Subject'] = 'Stuff you want' send_msg['From'] = from_addr send_msg['To'] = to_addr smtp_server = smtplib.SMTP_SSL('smtp.example.net', 465) login_result = smtp_server.login(from_addr, password) send_result = smtp_server.sendmail(from_addr, to_addr, send_msg.as_string()) smtp_server.close() In my initial example, I was sending an email to my cell provider that was converted to a text and sent to me. I didn't need to worry about the subject.
Everything being Unicode is actually the one feature I'm looking forward to the most on Python 3.x Still stuck in 2.6 :(
It's possible to do lazy imports without changing your code at all other than inserting a function call at the entry point to your program, using [PEP-302](http://www.python.org/dev/peps/pep-0302/) or by replacing `__builtin__.__import__` (mercurial uses the latter).
really cool!
&gt; I think this proposed syntax makes code much easier to comprehend by emphasizing code that really matters. You think wrong. It makes the code harder to comprehend by introducing undefined concepts which must be juggled in the brain until their definition is offered at some later point. It makes code more difficult to read. It requires more cognitive effort to understand code. There's a reason that pronouns (in natural language) substitute for *ante*cedents, not *post*cedents: because the human mind is geared to substitute shorter names for longer concepts *that are already known*.
[How to Think Like a Computer Scientist](http://www.greenteapress.com/thinkpython/thinkCSpy/html/) If she's the methodical type that would like to have a lot of "common knowledge" explained explicitly.
[Disclosure: I work for Enthought, which partners with PiCloud.] They do very different things. Disco is a MapReduce implementation. PiCloud is a "run these functions over there" implementation. Disco is great for tasks that have bursts of computational needs of a few hours or so. PiCloud is great for tasks that burst for a few minutes. Or if you just want a convenient, "hey, this is almost like regular coding!" API. I'm being quite glib, of course, but I think that sums up the major differences.
Your functions should be short enough that this is just not an issue. If your function is so big that you cannot see where each variable is used, split it up.
&gt; I find it much easier to understand that code by just looking at the first line (which really does the work) rather than going through the entire block of getters. "Much" easier to understand?! Really, what's so hard about 'assigning a bunch of variables and then using the values in a calculation'? If someone finds the original code difficult to understand, I'd suggest another line of work! The point is that it adds nothing new to the language; it doesn't make the code any shorter; it's confusing, because it's placing code that is executed later above code that is executed earlier. If you want to extract a unit of code, use a function. That gives you the local variables without adding anything to the Python language. Less is more. We want to keep Python as simple and expressive as possible. This expresses nothing new and adds to the complexity of Python. Dump it.
This feature already exists in Python (I think it came in in 2.5): [y for x in collection if y = f(x)] for example: &gt;&gt;&gt; [i for i in range(10) if i % 2] [1, 3, 5, 7, 9] EDIT: Looking at this again, I see your idea is rather different, and I don't get its use... why don't you just use [f(x) for x in collection] or even map(f, collection) ? 
I see now. Feedback much appreciated. I have to admit PiCloud looks like one of the coolest thing since brown sliced bread :)
ah come on, who farted?
nothing beats the official tutorial. you even get it in book format if you want.
For a non-programmer? No way.
No. Dive Into Python is not right for this: * Mark Pilgrim has said that DIP isn't for non-programmers. * The DIP you pointed to is written for Python 2.3, IIRC. I'm pretty sure Pilgrim has even said people should stop using it for this reason.
Imagine a more complex example. It can be made more readable by splitting up parts in variables. This also means we don't need to recompute some data if it's used twice. Arguably one should use a proper for loop as it grows more complex, but I think there's a middle ground where a comprehension is still useful. I don't think this alone warrants a new keyword but if we're already adding one, why not allow it here too.
I think it can help just to group statements of some two helper-variables, but splitting that up into super-specialized microscopical functions probably just hurts readability.
Um, that's why you'd push the old bindings on the stack, and use cells for those variables. Python's nested namespaces already use cell objects to hold certain variables; these cell objects could be pushed before the code block, then restored afterward. Think assembly code pushing registers on the stack to free them up, then popping them back when the code is done. (Actually, the true sticky bit here is that without a separate code object, the line ordering for the bytecode will be messed up.) 
That happens now, though. Why should a given: be any different?
I second this. Really great for beginners to come in having the right mindset about programming and computer science.
&gt; It can be made more readable by splitting up parts in variables. Unless you have a fondness for really long one-liners, I don't see this as more readable at all. If you want to split it up, then split the calculation into a function! Much clearer, uses only existing Python AND gives you some possibility of being able to reuse that function.
Why not steal a keyword from ruby: do by_name = sorted(people, key=last_name) given: def last_name(name): return name.split(' ')[1]
Take OP's example: c = sqrt(a*a + b*b) where: a = retrieve_a() b = retrieve_b() Without the statement-local namespace you get: a = retrieve_a() b = retrieve_b() c = sqrt(a*a + b*b) And it's not as obvious that a and b are only needed for c. Even in a small function we might have a few of these three-liners. Of particular note of course is closures. It's just weird and backwards to first define a function in another function, and then reference it. It makes sense in theory but feels wrong in practice. First times I did it I thought I must be breaking some rules. Most languages don't do closures this way. Another one for me is passing contexts to for example template engines. I don't like repeating every little context variable I set up in the call to the template rendering, so I tend to use ``locals()`` (people bash on ``locals()`` but I don't understand why, fairly obvious what it does) but this can pass variables you don't want in templates. You can ``del`` but that is tedious and backwards. I like: return render_template(name, locals()) where: title = 'Welcome' posts = Post.all() … I think this is much more readable than any alternative. Note that where-clauses are only valid where there can be no other block, so it's fairly obvious if the statement we're reading has one if there's indented code underneath it. An indented block under a return makes no sense other than with a where-clause, so we're bound to notice it as we're reading the return, even before we get to "where".
Not really what you asked, but have you tried Glom? IIRC it can also be Python scripted.
Because an indented block doesn't make sense for anything else where a where/given-clause can be, it's quiet obvious what's going on. You can't miss indented code under an expression and it can't be anything else because all other blocks start with the keyword first.
Good point, people who bash on this proposal feel to me like they might as well suggest to get rid of the class syntax and just define new classes with ``type()``. title = fields.String() body = fields.Text() Post = type('Post', (models.Model,), dict(title=title, body=body)) Much more readable!
I was liking their concept description, until: &gt;Glom uses the PostgreSQL database backend but it can not edit databases that it did not create, because it uses only a simple subset of Postgres functionality. I'm not in a position to being running a server, the database must be server-less like MS Access.
If you're getting DLL import errors it's probable that the DLL path isn't on sys.path. %PATH% is what windows uses to find executables, whereas sys.path is what Python uses to determine where to look for modules (IIRC Python considers DLLs modules). One entry always in sys.path is '.' which is why it would be unsurprising that your program works when in the GTK directory. Try adding the GTK directory to sys.path.
[Learn Python the Hard Way](http://learnpythonthehardway.org/index)
Noted, ty!
Introduces yet another keyword and makes the expression feel like a statement.
I think it might be bad to compare it to Ruby blocks. As you noted, Ruby does it quite awfully differently. A better example perhaps is i.e. Javascript and any language that has proper anonymous closures. ``where`` is needed in Python because of the indentation-based structure. obj.onclick.setcallback(function (x, y) { // Do callback stuff }) This doesn't work nicely mixing indentation-based and parenthesis-based structure, in fact Guido strictly disapproves of that: obj.onclick.setcallback(def (x, y): # Do callback stuff ) Quickly becomes awkward and confusing. ``where`` solves it beautifully, and Guido seems to approve.
how about something like Head First Programming -- "A learner's guide to programming, using the Python language". This is a great series but I've only skimmed this one. Here's an amazon link: http://www.amazon.com/Head-First-Programming-Learners-Language/dp/0596802374
 [rur-ple](http://code.google.com/p/rur-ple).
Edit: If I **cd** into that **GTK/bin** sub directory, I can jump into **C:\Python26\python.exe** and **import gtk** and it works. GTK doesn't seem to use it (greater than sign is my prompt): &gt;cd C:\Documents and Settings\user\Programming\PyGuiSqlite &gt;dir GTK\bin Volume in drive C is 17511 Volume Serial Number is B424-2167 Directory of C:\Documents and Settings\user\Programming\PyGuiSqlite\GTK\bin 07/21/2010 05:50 PM &lt;DIR&gt; . 07/21/2010 05:50 PM &lt;DIR&gt; .. 07/21/2010 05:50 PM 0 db.sqlite 07/21/2010 05:50 PM 38,954 fc-cache.exe 07/21/2010 05:50 PM 31,607 fc-cat.exe 07/21/2010 05:50 PM 29,379 fc-list.exe 07/21/2010 05:50 PM 3,818 freetype-config 07/21/2010 05:50 PM 538,484 freetype6.dll 07/21/2010 05:50 PM 24,056 gdk-pixbuf-csource.exe 07/21/2010 05:50 PM 25,294 gdk-pixbuf-query-loaders.exe 07/21/2010 05:50 PM 42,319 glib-genmarshal.exe 07/21/2010 05:50 PM 5,492 glib-gettextize 07/21/2010 05:50 PM 15,721 glib-mkenums 07/21/2010 05:50 PM 22,176 gobject-query.exe 07/21/2010 05:50 PM 24,832 gspawn-win32-helper-console.exe 07/21/2010 05:50 PM 26,286 gspawn-win32-helper.exe 07/21/2010 05:50 PM 27,879 gtk-builder-convert 07/21/2010 05:50 PM 338,157 gtk-demo.exe 07/21/2010 05:50 PM 26,251 gtk-query-immodules-2.0.exe 07/21/2010 05:50 PM 53,392 gtk-update-icon-cache.exe 07/21/2010 05:50 PM 583 gtk-update-icon-cache.exe.manifest 07/21/2010 05:50 PM 104,861 intl.dll 07/21/2010 05:50 PM 158,347 libatk-1.0-0.dll 07/21/2010 05:50 PM 946,905 libcairo-2.dll 07/21/2010 05:50 PM 143,096 libexpat-1.dll 07/21/2010 05:50 PM 279,059 libfontconfig-1.dll 07/21/2010 05:50 PM 53,041 libgailutil-18.dll 07/21/2010 05:50 PM 890,541 libgdk-win32-2.0-0.dll 07/21/2010 05:50 PM 260,985 libgdk_pixbuf-2.0-0.dll 07/21/2010 05:50 PM 704,583 libgio-2.0-0.dll 07/21/2010 05:50 PM 1,202,136 libglib-2.0-0.dll 07/21/2010 05:50 PM 32,256 libgmodule-2.0-0.dll 07/21/2010 05:50 PM 317,511 libgobject-2.0-0.dll 07/21/2010 05:50 PM 40,198 libgthread-2.0-0.dll 07/21/2010 05:50 PM 4,887,231 libgtk-win32-2.0-0.dll 07/21/2010 05:50 PM 339,073 libpango-1.0-0.dll 07/21/2010 05:50 PM 95,193 libpangocairo-1.0-0.dll 07/21/2010 05:50 PM 687,426 libpangoft2-1.0-0.dll 07/21/2010 05:50 PM 102,930 libpangowin32-1.0-0.dll 07/21/2010 05:50 PM 219,305 libpng14-14.dll 07/21/2010 05:50 PM 27,101 pango-querymodules.exe 07/21/2010 05:50 PM 77,094 pango-view.exe 07/21/2010 05:50 PM 77,605 pkg-config.exe 07/21/2010 05:50 PM 42,298 xmlwf.exe 07/21/2010 05:50 PM 77,876 zlib1.dll 43 File(s) 13,041,331 bytes 2 Dir(s) 44,174,995,456 bytes free &gt;C:\Python26\python.exe Python 2.6.5 (r265:79096, Mar 19 2010, 21:48:26) [MSC v.1500 32 bit (Intel)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; import os &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.path.insert(0, os.path.abspath('./GTK/bin')) &gt;&gt;&gt; sys.path ['C:\\Documents and Settings\\user\\Programming\\PyGuiSqlite\\GTK\\bin', '', ' C:\\Python26\\python26.zip', 'C:\\Python26\\DLLs', 'C:\\Python26\\lib', 'C:\\Pyt hon26\\lib\\plat-win', 'C:\\Python26\\lib\\lib-tk', 'C:\\Python26', 'C:\\Python2 6\\lib\\site-packages', 'C:\\Python26\\lib\\site-packages\\gtk-2.0'] &gt;&gt;&gt; import gtk Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "C:\Python26\lib\site-packages\gtk-2.0\gtk\__init__.py", line 30, in &lt;mod ule&gt; import gobject as _gobject File "C:\Python26\lib\site-packages\gtk-2.0\gobject\__init__.py", line 26, in &lt;module&gt; from glib import spawn_async, idle_add, timeout_add, timeout_add_seconds, \ File "C:\Python26\lib\site-packages\gtk-2.0\glib\__init__.py", line 22, in &lt;mo dule&gt; from glib._glib import * ImportError: DLL load failed: The specified module could not be found. &gt;&gt;&gt; 
I should use unicode more but if I'm honest I rarely use it.
So why use a keyword at all then, if it is so clear?
You can shake out bugs introduced by coercion by putting this in the entry point to your application: reload(sys).setdefaultencoding('undefined') This will cause any coercions to fail, even if the strings are ASCII-safe -- thus forcing you to fix it now rather than years later when a super-important client in another country trips over it. The reload is necessary because `site.py` helpfully deletes the `setdefaultencoding` attribute on startup in order to keep libraries from changing it. Obviously though, it can be worked around -- just don't do it in a library! Of course, this won't help if you never use `unicode` in the first place, so you're still on your own in that regard.
Consistency and explicitness.
any reason you didn't make it a web app?
Pydev is doss
For which reason would I want to install Python 2.4 in Ubuntu 10.04?
I can't. Suffice it to say I work in a restrictive environment. But I have network shares that I can do pretty much whatever I want with.
Aha! Is the syntax for connections I'm using outdated or non-standard? Cheers for the tip! I'll take a look at the toggled signal for a QAction and report back. Thank you muchly for your useful insights!
Good new enhancements. The best free python IDE gets better.
The idea of implicitly making all imports lazy scares me a little - not sure why, since the import machinery should be robust enough that it doesn't matter. Guess I'll have to try using something like mercurial's demandimport in my app and see what a difference it makes.
Hmmm... it doesn't appear that the python module loads properly, that sounds more like a %PATH% issue instead of sys.path. Try running the same commands in Python with the -v flag, which will dump a lot more trace information about imported modules. Also, track down _glib.dll and open it in depends.exe, check for missing DLLs...
cjson was so fast it didn't even show up on the graph.
Try poking around with [Dependency Walker](http://dependencywalker.com/). Use the "View full paths" option. Also make sure you change the PATH variable in the the System Properties dialog, not just in the command prompt, and close all your open windows so they pick up the change. It looks like it should work if you just hack at it enough.
DLL load issues are so much fun! A likely issue is that the PATH is later in the search order while the current directory is earlier. When running with PATH set, you may be getting one DLL from somewhere else (like the system directory) which is then unable to find its dependency. Best to run under a debugger and watch for any load messages. Order explained: http://msdn.microsoft.com/en-us/library/ms682586%28v=VS.85%29.aspx
&gt; I would rewrite your first example as I have to disagree. What I wrote doesn't seem to far from the decorator syntax for example, where the following definition is implicitly passed as an argument. The whole point is that the fact that is is an argument is *hidden* on purpose, in order to make cleaner APIs and seemingly extend the language for domain specific purposes. Passing around computation (i.e. blocks, closures, whatever) turns out to be a very convenient feature. How many anonymous instances of ICallable have you seen in Java for example? Requiring the programmer to explicitly wrap things up in a function just adds clutter.
Even the mod_python guys things so.
I just use gedit...
Might just want to look at Planet Python, thats a generally maintained list of interesting people.
I have a [whole bunch](http://pastebin.com/HB8rqFiQ) that aren't related to Python, but the open source world in general.
if you develop reusable code and you want to support legacy python you'll find this pretty handy
I switched from Access to SQLite. Screw ideology - use the right tool for the job. Access has some great features - user-friendliness and mgmt acceptance are just two. SQLite tools stink. Also, MSJet supports 256 simultaneous writes while SQLite supports one writer or multiple readers. But the reasons I tossed it are scalability - we collect 1GB of data/year where Access maxes at 2GB and SQLite maxes at 2.5TB; SQL complexity - SQLite is fully ANSI-compliant while Access has its own really crappy dialect; and reliability - Access has corruption issues while SQLite is one of the most reliable RDBMSs there is.
Thanks!
 # -*- coding: utf-8 -*- from __future__ import unicode_literals
It's too bad that Eclipse is awful in the first place.
What's this about Redis not running on Windows? I ran it fine on Windows a month ago. In fact, here is a handy link for downloading fully-built binaries of Redis, for Windows: http://code.google.com/p/servicestack/wiki/RedisWindowsDownload
Honest question, why? I ask this because in college that's what it's used to learn Java and where I code in Python (using PyDev, of course).
[This stackoverflow entry](http://stackoverflow.com/questions/1294272/how-do-i-install-pygtk-pygobject-on-windows-with-python-2-6) is probably relevant. In particular, pygtk uses the environmental variable GTK\_BASEPATH to locate where the dlls are. setting os.environ['GTK\_BASEPATH'] = "C:\\\\Path\\\\to\\\\gtk+-bundle\_2.20.0-20100406\_win32" should work (note the lack of the "bin" dir in the path). I've got a pygtk app that I bundle up w/ py2exe, and the first thing in the init script is setting GTK\_BASEPATH. This must be done before *any* gtk, gobject, etc imports. Once your app is loaded, gtk.rc\_get\_module\_dir() is a useful call. It returns the path to the gtk theme engine directory, but can be useful to verify during debugging that the basepath got set correctly (and didn't somehow lock onto another gtk bundle in your system). Just to give you some encouragement, this toolchain is all quite do-able. The app that I wrote is a pygtk + sqlalchemy + postgres app, rolled via py2exe &amp; nsis into a standalone, designed to replace an Access app. And it's worked pretty darn nicely (not that bundling is needed, sounds like a network share rundir will be much simpler for you). edit: fixed markup typos edit: link was to stack overflow, not the pygtk faq
I wasn't aware of that, although "Includes Cygwin" isn't exactly confidence inspiring. Also, we're deploying to production now-ish, and while I know rolling our own doesn't exactly scream "stability", it's easier to test and be sure we have the right working parts than relying on a beta/RC version. I'll keep an eye on this though. We've kept everything compatible with Redis 2.0 in case we ever want to switch back. Thanks for the link!
Oh, I think maybe I misunderstood you. I thought you were talking about just doing the equivalent of a `del` afterwards to clean up. Anyway, for the record, the `given` version of the above would be: funcs = [] for i in range(5): funcs.append(f) given: n = i def f(): print("#", n) And it ought to work as one might expect.
it's for 2.6 or 2.7; I used this one to learn it. I *did* actually use DIP without any real programming background, but I usually had to read some of the links at the ends of the chapters, and the sections on classes and regular expressions I went through twice and ended up reading the Python tutorial coverage on them. It does a decent job for complete noobs, but needs some help for the very basics.
I never saw this guy before, but damn, I wish I had.
 &gt;&gt;&gt; import this The Zen of Python, by Tim Peters Beautiful is better than ugly. Explicit is better than implicit. If you disagree, you can continue using Ruby instead. :-D 
Not quite the original. IIRC, Quixote was actually written as a response to Zope; the authors were Zope users before they wrote Quixote. This is also why it's named Quixote, because they believed creating another web framework (even then) was Quixotic.
Thanks for the constructive discussion. :) The Zen of Python is for fun. I do think the suggestion (I'm not the first one to suggest statement-level lambdas) would be a Pythonic way of providing a super useful feature very cleanly. If you disagree I'm actually interested in hearing arguments.
Using Python and NLTK will definitely be steering you in the right direction. Don't be afraid of it. Go forth and learn.
I took [CS224N](http://cs224n.stanford.edu) last quarter and did my final project in Python, using NLTK. My partners and I spoke to people in the English and Linguistics departments about our project and they all use Python for CL stuff. If you don't have a programming background, Python will be far easier to learn. Most of the Stanford (and Berkeley, I think) NLP stuff seems to happen in Java...but you can use something like JPype to access e.g. the Stanford parser from Python.
Am I the only one who reads "Getting **unicorn** right in Python"?
&gt; Aha! Is the syntax for connections I'm using outdated or non-standard? You could say it's outdated. Mostly it's a one on one translation of the way signal and slots are connected in c++. For a few version back PyQt started adding a more pythonic version.
TIL about JPype! I had always thought the Java side of computational linguistics was inaccessible to me because I'm on the Python side and Jython doesn't support Python extensions.
NLTK is exactly the right thing to get started in computational linguistics. It's got a bunch of tools and functions that other people have found useful that you can plug together like Legos. It also has incredibly good documentation that teaches you some computational linguistics at the same time that it teaches you to use NLTK.
I think Python is a great choice for this, since it's easy to learn, highly practical, and integrated with lots of different systems/OSes/libraries. It's also highly suitable for this sort of thing. It's noteworthy that a lot of AI types (like, say, Peter Norvig) appear to have migrated from Lisp to Python. I've done some NLP in Python myself, writing an automated classifier, some clustering tools, and also a Bayesian RSS aggregator. I wouldn't use any other language, frankly. There are good NLP tools in Python, such as NLTK, but if you need to use a Java tool there's always Jython, which integrates seamlessly with Java. C++ tools can also be used from Python, but there it usually takes someone with a bit of C++ skill to do the integration. Overall, I think it's about the ideal choice for NLP. However, I wouldn't use it for speech recognition. So if that's what you're going to do then Java/C++ is a better choice. I find it difficult to help you with the career choices, since you don't give much information about yourself and what you want to do. Diving in and learning Python, NLTK, and perhaps some web stuff like Django or web.py is probably the best you can do.
NLTK is brilliant, and so is Python. I don't think you can go wrong there! There's also [the NLTK book](http://www.nltk.org/book); you'd possibly be familiar with a lot of the theoretical background but it's very well documented. It is true that a lot of NLP stuff does happen in Java. I don't see any particular reason it couldn't be in Python though. Good luck!
Yep, you need to see an optometrist.
Am I the only one who reads *that* as "Getting **uniporn** right in Python"?
Maybe [a*a+b*b for x in xs where a, b = as[x], bs[x]] Also [a*a+b*b for x in xs where a = as[x] where b = bs[x]] The first needs more parenthesizes for generator expressions sum(a*a+b*b for x in xs where (a, b) = (as[x], bs[x]))
But will this magically make whatever libraries you're using give you unicodes instead of strings?
No, it will treat your string literals, in the future-importing module, as unicode. If the library is properly duck typed, things that take a string as input should continue treating it as unicode. &gt; If a string literal in your code is intended to represent text, it should always be prefixed with 'u'. In fact, you probably never want to define a raw string literal in your code at all. For what it's worth, though, I'm terrible at this one, as I'm sure pretty much everyone else is, too. So it's very helpful for covering this point. Might also make porting to Python 3 easier. It only works in 2.6 and 2.7 though.
It breaks `doctest`. It breaks a lot of other modules. I mean, I don't know, I personally failed to use Unicode strings in 2.6 and reverted to utf-8 encoded bytestrings, it's hackish, but at list works. Maybe you people know some secret or are more clever than I, or maybe you just don't actually test how your code works with actual non-ascii text, non-ascii filenames etc.
&gt; No, it will treat your string literals, in the future-importing module, as unicode. This isn't that useful as I'm mostly working with things like CherryPy and Genshi and psycopg2 here. My code usually tends to "blow up" with unicode errors at the point where I grab UTF-8 encoded data from psycopg2 (or some other database) and feed it into Genshi. So it would be useful if the strings coming out of such external libraries were already unicode. Or were Python 3 style byte arrays so I would know to explicitly decode them.
With ``unicode_literals``, bytestrings are created with a ``b`` prefix: b"""Docstring!""" If you want utf-8 encoded bytestrings, I still recommend setting the source file encoding, even if you don't use ``unicode_literals``.
Thing is, "utf-8 encoded" means bytestring. Unicode objects are not encoded. They only represent the characters, the codepoints, not how to treat the string as data. That's what bytestrings do: they take a sequence of code points and *encode* them into a sequence of bytes. So when psycopg2 gives you an encoded string, it's not a unicode object. On the other hand, Genshi deals with unicode objects. Python 2 tries to convert between the types for you, the problem is it assumes ASCII. This works if an utf-8 encoded string only has ASCII characters in it (because utf-8 is backwards-compatible with ASCII) but fails otherwise. What it tries to do is ``'€'.decode()`` which is like ``'€'.decode('ASCII')`` which results in &gt; UnicodeDecodeError: 'ascii' codec can't decode byte 0xe2 in position 0: ordinal not in range(128) The solution is to decode yourself, explicitly, passing the right encoding: &gt;&gt;&gt; '€'.decode('utf-8') u'\u20ac' ``unicode_literals`` can't help you here, but it might help with some potential Genshi issues. For example if you pass ``'€'`` on the context it will likely fail with the above ``UnicodeDecodeError`` but not with ``unicode_literals``.
I've noticed that too. Many young colleagues have no clue whenever they don't have elcipse at hand. This is quite frustrating but perhaps that means IT becomes more and more a standardized industry. When I have to use it, I'm frustrated by its slowness and all the plugins that make it so unstable.
That's why I'm looking forward to Python 3 where anything of string type will be unicode (and psycopg2 should take care of decoding) or it gives me a bytestring, in which case I'll know I have to convert manually. It's just that I tend to forget the .decode("utf-8")) part, because it often works just fine without it.
That's not the problem. # -*- encoding: utf-8 -*- from __future__ import unicode_literals def f(s): """ &gt;&gt;&gt; f('á') u'\xe1' """ return s if __name__ == "__main__": import doctest doctest.testmod() -------- Failed example: f('á') Expected: u'á' Got: u'\xe1' This is the problem. And, of course, writing "`u'á'`" as an expected result produces exactly the same message, the point is that even copy-pasting the expected result literally, with escapes, doesn't help. I don't want to spend any more time trying to figure out how exactly I can write this stuff, and I say with conviction that when crazy stuff like this happens it means that the language is not Unicode-friendly at all.
Does it still have these annoying nag screens? We have a server which "has to be started in Eclipse with PyDev" (don't ask) and I always see nag screens.
It's an escape issue. Multiline strings take the same escapes as normal strings, so it reads ``\xe1`` as ``á``. You want either ``\\xe1`` or a raw string: ``r"""...\xe1..."""``
Kate
Thanks, both workarounds work, but still, I'd prefer to write my tests as they are, without escaping first.
``unicode_literals`` don't change anything in that regard: #-*- coding:utf-8 -*- def f(s): """ &gt;&gt;&gt; f('á') '\xc3\xa1' """ return s Running: $ python -mdoctest uni.py ********************************************************************** File "uni.py", line 6, in uni.f Failed example: f('á') Expected: 'á' Got: '\xc3\xa1' ********************************************************************** 1 items had failures: 1 of 1 in uni.f ***Test Failed*** 1 failures.
Nope. PyDev always was free. PyDev extensions used to cost money but for quite a while has been folded back into the main product.
I agree. I'd like to see some of that code too.
Thanks for giving me some of the advice I craved.
&gt;...Access has its own really crappy dialect... Amen that brother! It's oh-so-helpful, when it loses all my spacing, and newlines and then puts about a thousand parentheses around every expression. The GUI query editor is pretty good though. May the Lord have pity on your soul if you want to edit SQL code in Access. And what were they smoking when they came up with that nested join syntax? The unpardonable sin may be not allowing comments in SQL. I got around to writing a little form that lets me keep a "sql" sub directory with texts files I can edit in a competent editor. The form loads the SQL from these files, removing **//** and **/\*** **\*/** style comments, into the Query objects. Almost all the applications I write in Access are just reports where maybe one or two people update them throughout the night and a bunch of other people watch them. Sometimes only one person fills in the data and when done, prints off a copy and hands it to someone. This hardly requires a database but it's guaranteed that some big-dog will come along and want to know what's happened over the past month or last year. &gt;SQLite tools stink. Yes, I'd say Access got GUI database interfaces right, notwithstanding some gripes about resizing MDI windows and really poor text editors. But really all that work into a GUI when a simple command line interface works very well?
I think you are right. In fact, some of the authors of Quixote had previously worked at Zope corp.
One nifty feature of Python is that you can use it at a console, so you can code as you go. It was designed with this in mind - which is why Python is so easy to type line by line, but a little ugly to read and maintain. It's fairly simple to learn, you should be able to pick it up within a month or two, so I say go for it! Even if you don't end up using it, you'll be better off for knowing it.
Indeed. It's about 20x faster than codetalker ;) That's what &gt;1000 lines of C code can get you. Have fun writing/maintaining it, though
Yeah, I get a shivers about Cygwin as well. But I just dumped it into a directory and it ran fine from within there. There was no pollution to the rest of the system.
I think the lower level features of canvas may work for me. I have done some testing yesterday.
I been doing medical NLP work for a few years. Python's NLTK is great, but you should remember that it is part of the OpenNLP project (http://www.opennlp.com/projects.html) and there's a wealth of other items in that for various programming languages. In addition, there's the General Architecture for Text Engineering (GATE) project (http://gate.ac.uk/). They have an IDE for Text/NLP work. I've been keeping my eye on it and been trying to get buy-in from the higher up. I can't speak for linguists, because my background is in Computer/Electrical Engineering. I will tell you that you should learn/focus on what *you* want to do. In addition, the best way to program is to start programming. I know this sounds cheesy, but taking a working program and editing/rewriting it helps you quickly learn how it all links together. Books are great for examples, but IMHO the "click" won't happen until you've broken a few programs and worked your way through fixing them. Good luck!
Can I add one more question? I see that Natural language Toolkit is more about using the program than it is about the program. What resources would people here recommend for learning python. I am almost starting from square one. I know how to create a hello world program in python and when I was a kid I did some very simply stuff with TI-83 basic (e.g. programming in equations and modding games).
Using GTK_BASEPATH gave me the same thing, but I found something that works (see "Edit 2, A solution!").
It was a %PATH% issue, I think (see "Edit 2, A solution!").
You might want to look at this MIT course: http://ocw.mit.edu/courses/electrical-engineering-and-computer-science/6-189-a-gentle-introduction-to-programming-using-python-january-iap-2008/
Speech recognition is its own field and you really can't get into it unless you do a PhD in it. Even then you probably wouldn't be working on the optimized C++ recognizer code. Leave that to hardcore programmers. You basically have to decide between Python and Java, although Matlab and R are useful too. Python is pretty easy to pick up and won't waste as much of your time on elaborate configuration issues and other tricky problems as Java. The python easy_install and pip automatic installer tools are almost reason enough to prefer it over Java. You'll have access to lots of machine learning tools through numpy/scipy and gsl. Pymc is great if you want to try Bayesian models. Java gets you the Mallet package and the Stanford parser among others, but Java code tends to be bloated and harder to work with than Python/C, so you really have to dive deeply into a Java package to get it to do anything it wasn't designed for. The Python tools will probably be much more accessible to a beginning programmer, though I'm just guessing since I don't typically work with beginning programmers. Python packages often provide tutorials, while Java package documentation is usually at the code level instead of user level. edit: There's a Python version for Java called Jython, so if you learn Python, you can still use Java packages by writing scripts to call them from Python.
Agreed. I read Head First Java, and my wife used Head First XHTML &amp; CSS. It's not going to land you a job at Google, but if you need to get your head around stuff, this series is pretty solid.
What you're seeing is that point releases are typically backwards-compatible. Look at the [intro](http://diveintopython.org/toc/index.html). The last update was in 2004. I wasn't really programming in 2004 and don't know what the stable release at the time was, but it certainly wasn't 2.6 or 2.7. And [here](http://diveintopython.org/installing_python/windows.html) it recommends ActivePython 2.2.2. So it's not that Pilgrim has updated it for later versions but that later versions don't break backwards compatibility.
ooooh ok. I feel dumb now.
I'm honestly curious, what type of career or job do you pursue with a PhD in computational linguistics? I think the subject is fascinating, I'm just wondering what the job field is like.
Speed and instability were my two big reasons for dropping it the time, which was a few years ago. I was doing some Java/JSP stuff and all of the crap plugins I had to get in order to do some of things I was doing just caused the whole thing to work very poorly. I just scrapped it and started using vim after a week of messing with it. Even though they aren't free, IDEs like Komodo and Wing blow Eclipse+PyDev out of the water.
I'm pretty sure none of the original authors worked at Zope Corp (because I worked there then, although it was called Digital Creations at the time). But there's an old blog post (1999/2000 era) by one of the Quixote authors (AMK) entitled "Why Not Zope?" wherein he describes trying to layer an NFS server on top of ZODB within Zope. The post is lost to history these days, but it indeed marked the point where it became fashionable to kick Zope in the nuts ;-).
No worries! There's no reason it would necessarily be clear, since backwards compatibility *is* maintained. And for what it's worth, on the Windows installation page it says, "Double-click the installer, Python-2.xxx.yyy.exe," which at least suggests that Pilgrim was planning on the book's *forward* compatibility. There's a [DIP3](http://diveintopython3.org/) if you're interested. :)
boy I wish there was uni/college offering Python when I was looking for training, and I'm in NY metro. But - assuming you know Python - why do you (and she) think she needs a "head-start" ? I mean it's uni class (what ? 2 classes a week ?), not some $2000, 5-day jam session. I'm thinking if she gets the head-start she'd likely be pretty bored for a few weeks into the class. 
Oh thank the gods! Python 3 scared me. You need to put parentheses after print now! Parentheses!
Any idea how hard/easy it is to make into a Windows service? That's what we really need it for.
I started with emacs in college (~10 years ago) and have since moved--after going through many IDEs and editors--to Eclipse for most of my Python and Web development. Eclipse may have been slow in the past, but I don't have any complaints in that regard on my fairly modest dev box.
I have only a minimal set of plugins installed and have never found Eclipse to be unstable. I'm not sure about older versions, but I find modern Eclipse to be quite nice in most regards. If you find yourself interested in trying it again, I'd suggest starting with the [Platform Runtime Binary](http://download.eclipse.org/eclipse/downloads/drops/R-3.6-201006080911/index.php#PlatformRuntime). It's the smallest Eclipse download I could find and doesn't include a bunch of cruft you don't need. I install PyDev, Subclipse, and a couple other things, and I'm good to go.
I like Wing for straight Python development, but I'm also working on a bunch of Web projects plus keeping an eye some Java projects, and Eclipse (w/ a few choice plugins) is much more well-rounded and generally useful. As an example, the VCS support is far superior to Wing Pro's, IMO. I posted some other comments above about speed. I've been using Eclipse seriously for a year or so, and the latest versions are both fast and stable.
Thanks! Why this has already 7 downvotes?
just python ? what other skills ? and does it have to be on-site ?
Yea, it's a situation of Python 2 not really missing anything, but encouraging bad practices. Automatic conversion between str and unicode is one example, where "often" working lets programmers forget to do it right. Literals defaulting to bytes is another one that encourages developers to not encode explicitly. Python 3 improves a lot, though I don't think it's perfect. For example I think ASCII byte literals don't make sense, either do without literals or have them be in the source encoding. I'd also like bytes to remember the encoding so they can be reversed to unicode without keeping track of that manually. The information is there on creation. It's perhaps easy to subclass bytes, I think there was talk of *"ebytes"* on the web-sig list, but this should be built in, especially as most everything will not be using your subclass.
 Content-Type: text/html; charset=utf-8 FTFY. If you can't set headers: &lt;head&gt; &lt;meta http-equiv="Content-Type" content="text/html; charset=utf-8"&gt; &lt;/head&gt; Make sure you actually encode the document as UTF-8 too.
No offense but you're not giving much info nor is your website which only mentioned an art director and designer under careers but again not with much info. Nice looking site though btw.
&gt; And it ought to work as one might expect. Dunno, I *might* expect it to work the same as if you didn't have the 'given:' clause present. ;-) Note, however, that the implementation I proposed actually does work the way you want it to, as it pushes and pops a cell object. (But it wouldn't work if you used the loop variable directly, instead of binding it to a separate local variable first.) Btw, you can also write the above as: funcs = [f for i in range(5)] given: ... etc. 
I work at a Ruby shop, and haven't touched python in a while. I miss it and wouldn't mind getting into it again. I have quite a bit of systems admin under the belt, however. And a dual xeon server sitting in my room looking for a purpose..
This is one of the most helpful replies! Thank you!
I'm in Chicago, you should come to [ChiPy](http://chipy.org/), I'm sure you could find some interested people.
I build Pylons apps at a lab at the University of Chicago. Because I'm the only web developer in the lab, I administer the hardware and manage/code all projects from start to finish (usually includes PostgreSQL, jQuery, all UI design, Mako for templating, etc). I've got a few small ideas that I've been planning as weekend projects, but would love to meet and talk about more ambitious work with a like-minded developer.
Actually, this looks pretty cool. I like the fact that there are OSX and Linux versions available as well. Seems worth a try. 
I've been using the eap releases and it is pretty darn good compared to it's competition.
It's not mine. A friend of a friend is the recruiter and she's looking for people to fill those positions. You can contact them and know more if you want. I just told her I'd get the word out.
I'm not really sure. I have nothing to do with it. A recruiter (a friend of a friend) is looking for people to fill the available positions. You can contact them if you want to know more.
Seconded. The interactive interpreter is one of the best things about Python. linear_B, I suggest you look into something called [IPython](http://ipython.scipy.org/moin/), it's an excellent front-end to python that adds all sorts of lovely features. Best of luck to you in your future endeavours, and feel free to ask anyone for help along the way!
[Invent Your Own Computer Games with Python](http://inventwithpython.com) is a fun (and free) book for complete beginners that provides source code for several small games, so you can actually see code in real use.
+1 to Chipy. I wish I could make the meetings more often myself.
ChiPy would be right up OP's alley.
All the jealous bots that were programmed without stackless? 
I know this may sound a little rude but: Don't we have a jobs section on reddit for this kind of thing? I didn't think this was tolerated in the Python reddit.
your posting for a major agency, .... and recruiters are blood suckers... there is nothing honorable about that profession... i go out of my way not to hire any employees with them.