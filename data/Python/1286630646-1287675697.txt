For scientific visualisation, VTK (www.vtk.org) is your best bet. It's based on OpenGL and has full python bindings. Try to get hold of the text-book on it. You can get an idea of VTKs capabilities by using one of the stand-alone visualisation apps which are based on it: Paraview, Mayavi, VisIt etc.. Anything these can do can also be done by scripting VTK directly.
I didn't realize they had that. Now I know to look on a project. Thanks!
The guy who made this describes it on this page. [http://vis.cs.ucdavis.edu/~ogawa/research/storylines/](http://vis.cs.ucdavis.edu/~ogawa/research/storylines/)
Thanks :D I fancied myself a master of googles, and it's the first time I hear of the term.
You could have worked a "python" line in there, or an "indentation" gag, something about no private members? These opportunities don't come everyday. The graph is a nice idea but mhm, the end result isn't very informative.
This comes up weekly on Reddit and the unladen-swallow newsgroup. Here is a recent reply on the matter from Collin Winter, one of the two project owners: &gt; On Fri, Sep 10, 2010 at 4:27 PM, Swapnil Talekar &lt;swapnil...@gmail.com&gt; wrote: &gt; &gt; Hello, &gt; I wanted to know about the current status of Unladen-Swallow project. The &gt; project page describes milestones only till 2009. &gt; Also, has the PEP 3146 been accepted by BDFL and the python community and &gt; what is the timeline for the merging of &gt; Unladen-Swallow with the Python 3k branch? &gt; Hi Swapnil, &gt; I've been busy with other work for Google, but I'm hoping to get some time to push further on the upstream migration of Unladen Swallow into CPython. We're still targeting CPython 3.3, though we may not get into the cycle as early as we would have liked. &gt; Thanks, &gt; Collin Winter 
Is it actually working? I tried `print 1` with `xpython.exe test.py` and it prints nothing. Also tried the simplest sample from wxpython.org tutorial and didn't work. I am using the 0.3 version http://www.xpython.org/xpython.exe
Doesn't run for me; Windows Vista x86
terremoto and lambdaq, i used it on windows xp when it came out and it worked. now i don't know for vista (lambdaq, are you on vista too?) my suggestion would be to try to compile it :) (i think there is a tutorial how the author did it)
I am on Win7 32 bit. Tried compatibility mode and didn't work either. I am n00b with cross compiling, my Gentoo doesn't even have a `/opt/xmingw/` dir. **Update:** contacted the [author](http://www.quiss.org/projects_xpython.html)
Here's some VTK code to do something like this: import vtk import random points = vtk.vtkPoints() #an object to hold the point locations data = vtk.vtkDoubleArray() #an object to hold the extra data for each point #create the data the slow way. Using numpy is better for x in xrange(10): for y in xrange(10): points.InsertNextPoint((x,y,0)) data.InsertNextValue(random.random()) #assembly a polydata dataset dataset = vtk.vtkPolyData() dataset.SetPoints(points) dataset.GetPointData().SetScalars(data) #a source for sphere glyphs sphere = vtk.vtkSphereSource() sphere.SetRadius=0.3 #this filter applies the glyph at each data point. #The glyphs are scaled and coloured according to the data glyph = vtk.vtkGlyph3D() glyph.SetInput(dataset) glyph.SetSource(sphere.GetOutput()) #VTK boiler-plate... map = vtk.vtkPolyDataMapper() map.SetInput(glyph.GetOutput()) actor = vtk.vtkActor() actor.SetMapper(map) ren = vtk.vtkRenderer() ren.AddActor(actor) renwin = vtk.vtkRenderWindow() renwin.AddRenderer(ren) iren = vtk.vtkRenderWindowInteractor() iren.SetRenderWindow(renwin) iren.Initialize() iren.Start() 
If anyone is recommending pyqt, if you have any knowledge about deployment(installers) can you comment about it. Specifically cross platform deployment.
Nope i am just starting, i know python language. But i am going to deploy it only on windows platform.
[http://www.python-camelot.com](http://www.python-camelot.com)
[Same question from 9 days ago](http://www.reddit.com/r/Python/comments/dl1d6/askpython_anyone_know_whats_happening_with/)
Ew, compiling for Windows. Too lazy to set up the environment.
&gt; Only immutable objects (ones that don't change) can be hashed. &gt;&gt;&gt; class Foo: pass ... &gt;&gt;&gt; {Foo(): 'foobar'} {&lt;__main__.Foo instance at 0xb7413a6c&gt;: 'foobar'} &gt;&gt;&gt; hash(Foo()) -1220462228 &gt; This means that lists of dictionaries can't be sorted &gt;&gt;&gt; sorted([{'a': 3, 'b': 2}, {'a': 1, 'b': 2}], key=lambda x: list(x.items())) [{'a': 1, 'b': 2}, {'a': 3, 'b': 2}] 
test folder contains the example and some samples. Here is the link http://github.com/santhoshtr/pypdflib/tree/master/tests/
deja vu
I use linode.com - Runs $15/month and up.
Thanks! I'll check this out. Busy weekend...
Does VTK take care of creating the display lists for you? I've run a couple of simulations on the OP's problem with about 7K detectors in OpenGL, and without using display lists it's just too slow for interaction. With display lists it runs nicely on a middle-of-the-road pc.
The OP mentions wanting to show the Cerenkov radiation being picked up by the detectors, so that will require rendering all 11K detectors, and not just the events.
african or european? 
what in the world did i just read?
Not even Guido can code Python as Hardcore as that.
Looks like I can stop programming forever, knowing the best program in the world was created...
The structure. The syntax. It's Beautiful!! Uh, where did I put my keys?? I want some Oreos.
This is why you don't code C++ while drunk (copied from a project I'm working on): virtual void login ()=0; // looks pike penus?
Meh, at DjangoCon we came up with a strategy for generating CSRF tokens that were ASCII penises.
I think it's understandable that people want frequent updates. Unladen-swallow is/was supposed to be the future of Python (until PyPy I guess).
They have a blog?
I don't know, but 7K spheres doesn't like too many. You can run your geometry through a TriangleStripFilter which converts the dataset to triangle strips, which are the fastest things for the graphics card to render. I don't have a decent PC to test on right now (only a 10-year-old PIII with 32MB graphics card) The nice thing about VTK is that it hides the complexities of OpenGL from you.
Hell ya. Mint Oreos, weed and Python. That is all I have in my survival kit. Guido would be proud. 
I use netbeans for my python development, but if you want an interactive console id recommend using the command line. I found the official IDE to very half assed. 
Looking at the VTK FAQ, it uses display lists by default, but you can turn this off is your dataset is very large, to save memory. VTK also has other tricks to maintain interactivity, such as "Level Of Detail" actors which control how much geometry is rendered, in order to maintain a given frame-rate.
vim?
Seriously, the subreddit needs an "Are we there yet?" button, maybe some JavaScript that puts up a dialog box that says "No" when you click on it.
I'm a vim man myself and I use it for almost all my editing. However, I do use WingIDE at work quite a bit though as my project is big and WingIDE's code completion and docstring display features are pretty nice when you can't fit all the code in your head. Overall, I'm really happy with WingIDE. I don't have any stability problems as the post complains about. My biggest complain would be that their vim keyboard mode is mediocre.
I've also wanted to be able to navigate projects easier, so I've tried a few Python IDEs, but I always return to gVim. Discovering the [command-t](http://www.vim.org/scripts/script.php?script_id=3025) plugin has made finding files in my projects a breeze. 
I ended up with Wing too, it seems to have the most reliable code completion/support. It's HTML/JS editing sucks though so I'm torn to try Komodo 6 IDE (money is not an issue)...is the Python support on par by now? It didn't seem to me in a quick test. I used Emacs for over ten years before but the Python support is just too fragmented and broken. :(
Why did everyone downvote this one. Dammit, you guys need to lighten up. Programming should be fun too. You know a guy is hardcore when the thing he wants to do the most after getting high is write code. The rest of you stiffs would'nt know how to tie your shoelaces. Let alone come up with some kick ass ninja code like this guy. 
I use the shell+git for project management, and code completion works, even if not out of the box. Vim is far from perfect, but for me it's still the best tool for the job.
pyCharm. Highly recommend. www.jetbrains.com/pycharm 
This lib somewhat lazily made. Why not implement in ctypes instead of depends on `xclip`?
I used Komodo 6 IDE, whats specific aspect of Python support are you referring to. It has syntax support for Python 2 and 3. It autocompletes and lets you jump to function definitions. Also, it has a Python debugger.
I'm mostly interested in the quality of code completion. This is where Wing truly shines, even "from x import *" works perfectly if you use __all__ in x. What I dislike most about every single editor/IDE is the crapy auto-indent. :( I'm used to IDEA where method calls are neatly lined up like: obj.meth1() \ .meth2() \ .meth3() Is there some sensible reason why no editor/IDE I've tried so far can't get that right? I use this pretty often in conjunction with SQLAlchemy.
Wildcard import autocomplete works. Line continuations don't indent nicely though.
&gt; The name "w#" is variable and repeats a different number of times for each file I search through but it always repeats the same number of times within the file. Could you clarify?
Is there some shortcut for "jump-to-symbol"? I really like that in Wing. It searches the current file for a symbol name: class, method. Having a code browser in the side bar is nice to have but when I'm coding I just want to quickly jump to a certain point.
Assuming you treat the whole file as a big string, you might be interested in the str.split, str.strip, and int functions. Split the file using the separator 'w', strip off whitespace on the ends of the individual entries, convert them to int. http://docs.python.org/library/stdtypes.html
If order doesn't matter, then run through the file once and collect the row and col into a set of tuples (e.g. `myset.add((row, col))`). Then when reading it you can add the indices later when you dump the values. Alternatively, if you want to keep track of each 'w#' then you can store them in a dict using `mydict[(row,col)].extend(var_name)`
So if I'm not mistaken, would this be used to visualize the particle decay events that are responsible for detector readings?
Ok, I fixed it. This is just to generate the layout of the detectors. from __future__ import division import math from visual import * tank_height=60.0 tank_radius=30.0 pmt_diameter=0.25 pmt_height=0.1 pmt_space=1.0 pmt_area = pi*(0.5*pmt_diameter)**2 nrings = int(tank_height/pmt_space) ncols = int(2.0*pi*tank_radius/pmt_space) tank = cylinder(radius=tank_radius, axis=(0,0,tank_height), pos=(0,0,-0.5*tank_height), opacity=0.2) for iring in range(nrings): z = -0.5*tank_height + 0.5*pmt_space + iring*pmt_space for icol in range(ncols): theta = icol * pmt_space / tank_radius x = tank_radius * cos(theta) y = tank_radius * sin(theta) pmt = sphere(pos=(x,y,z), radius=0.5*pmt_diameter) continue continue 
Yeah, I read the post 5 times and I have no idea what the program is supposed to accomplish.
To answer your actual question - the biggest things missing in Edit vs IDE is the publishing tools (scp syncing projects to production sites) and the database explorer extensions (edit your mysql databases right inside the IDE), other than that I don't see much different.
Didn't really look into your problem, but this might be relevant: http://docs.python.org/library/sets.html Just came to my mind after reading "unique". It can be very helpful in certain scenarios.
for the real?
Why not using the value as the key into a dictionary, in the dictionary you have {value, 1, pair-value} The "1" inceases, if there is a new paired value, e.g. you have first a 5 2 and then a 5 3, the first entry would be {5,2,3} and the second entry would be {5,2,3}, etc. with 5000 atoms, there are more than enough ints around :D Then you re-arrange all into a sane database. I don't know how fast that would be but at least you get python to look for the value and you don't have to do it yourself. Dictionaries These represent finite sets of objects indexed by nearly arbitrary values. The only types of values not acceptable as keys are values containing lists or dictionaries or other mutable types that are compared by value rather than by object identity, the reason being that the efficient implementation of dictionaries requires a key’s hash value to remain constant. Numeric types used for keys obey the normal rules for numeric comparison: if two numbers compare equal (e.g., 1 and 1.0) then they can be used interchangeably to index the same dictionary entry. Dictionaries are mutable; they can be created by the {...} notation (see section Dictionary displays). The extension modules dbm, gdbm, and bsddb provide additional examples of mapping types. Edit: you can append where in the original database the values are located: {5,2,3,w3,w5,w345} and thus preserving this info in the next database.
Fundamentally this implements 3d visualization API on top of processing.js and it allows to render lines, triangles and spheres in 3d in the browser without flash or any tool installed by the viewer. I have various examples of usage. It does not require JS programming. the JS is created dynamically by Python code. One of the examples represents simulated particle events (the lines are the traces). But you can represent anything you want as long as you decompose it into lines, triangles and spheres. It is not designed for features. It is designed for easy of use and portability.
it helped me quite a bit to just read through all of the official python language docs. (google 'python docs'). then i learned a lot more about the real power of python libraries like 're' (and many others) by doing the 'python challenge', which was a real challenge and a ton of fun. i was really surprised how powerful and elegant python can be. i don't know if that really answers your question, because it's not a tutorial in the traditional sense. but the python challenge made me quickly write a bunch of experimental one-time/throw-away code. i think writing a bunch of code quickly with no pressure, just for fun, really helped me to get comfortable with the language. i know you said you were not asking anyone to write your code, but i couldn't resist. i think this might be more like what you're looking for: text = 'Name Row Col w1 2 8 w2 2 8 w3 2 8 w4 6 60 w5 6 60 . . . w5590 44 16 w5591 44 16' result = [] for piece in text.split(' w')[1:]: result.append(piece.split()) print result 
I've been a paying Komodo customer for 4 years and I wouldn't be doing so if their Python support wasn't on par.
Did you try/compare Wing? I found their code completion more solid but maybe I just missed something?
I stpped reading upon finding the if-clause asking if the current line is the header line. Way to slow down a program, 50000 lines = 50000 ifs executed. Horrible code. [Edit: fix typos. Damn phone keyboard]
Komodo has built in VIM emulation. This is the best IDE I can find that I really enjoy using.
I see "Cross platform clipboard" and then i see "Linux - Requires the xclip command" These two things are very different. This kind of dependency does not for a good Python program make.
Read again and note the "in Python 3" for the restriction on sorting lists of dictionaries. Whether you allow your user defined classes to be hashable or not is a design decision. You're of course free to violate the immutability / hashable relationship if you want.
http://www.python.org/doc/ was enough for me everytime i used python.
And my example is from a python3 session. In Python 2 you can do: &gt;&gt;&gt; sorted([{'a': 3, 'b': 2}, {'a': 1, 'b': 2}], key=dict.items) [{'a': 1, 'b': 2}, {'a': 3, 'b': 2}]
As suggested you don't need to do the check on every loop. Also python supports enumerate(), so use that instead of manually tracking the index. 
If the author were going for speed, he wouldn't be writing in Python.
If you're using eval or exec, you're almost certainly doing something wrong. I'm not convinced that the flexibility offered by exec is particularly useful here (what if you need to import a module?) but if it's essential, you really should use the `compiler` module to compile the string to bytecode which can then be passed to `eval`. You should replace variable names with accesses to a Python dictionary so the row names in the CSV file don't have to be valid Python variable names. Also, exec is a statement. Don't put parentheses around the statement you're execing.
Perhaps I'm wrong, but I assumed that xclips was fairly standard. I'll be getting rid of that dependency next.
I'm still new to ctypes, but this will be my next improvement. Thanks!
How long do you think it takes to evaluate "if some_number == 0" in python?
I've tried a few Wing trial installs over the years but I guess I've never really looked at it with the intent of changing. I also got a free license at PyCon 2010 (thanks Wing team!) and I've used it from time to time, but my biggest holdup was that it doesn't have the native feel of many other editors. I'm a fairly simple customer. The features I look for in IDEs are a good editor (including Vim key-bindings) and a good debugger, and both Wing and Komodo have those and they are both done well. Code completion, refactoring, and whatever else are all nice features, just not deal breakers for me. I just happened to get on board with Komodo due to years of using ActiveState Python on Windows, so I was familiar with the company and picked their product first.
What is there to frequently update? It *will* be in the future of CPython, it's just at a point where it's not going to make it into 3.2 and the developers are off doing other projects. Once 3.2 goes out the door around the end of the year, I imagine you might start hearing more about U-S.
Even if it is fairly standard, it's bad practice to rely on another program altogether being present on your system. Programs should not be dependent on one another -that's what libraries and packages are for. Edit: Yeah, this line validates my thoughts on that matter - os.popen('xclip -selection c -o', 'r'). baaaaaaaad. If you're doing this for a one-off script that you use on your own its fine, but it seems that you want to push this to a wider audience in a good way. I hope I didn't offend, I'm just trying to promote good habits :)
I hadn't noticed xpython before, but it doesn't have any of the right libraries for what I do. I have been using [pyinstaller](http://www.pyinstaller.org/) in single-file mode for this sort of thing.
don't use that matrix, what you need is a structure like this: matrix = { &lt;w1&gt;: set( (&lt;x1&gt;, &lt;y1&gt;), (&lt;x2&gt;, &lt;y2&gt;), ... ), ... } for that you do: matrix = {} with open('large-text-file') as f: f.readline() for line in f: w, x, y = line.split() w = w[1:] w_set = matrix.setdefault(w, set()) w_set.append((x, y)) 
Consider breaking your project into self-contained pieces, putting each into an Egg, then using Buildout to coordinate. At my old gig each programmer developed his stuff in an independent egg, built and tested with good old setup.py. Each egg used other eggs, internal and external, handled via buildout. Occasionally we'd publish our eggs for the other developers, or get new versions from them. In practice it worked quite well. 
Very, very fast. But it just doesn't need to be executed at all. 
Speed is not a matter of wrong / suboptimal algorithms!
Thanks for the suggestion. That sounds like an awful lot of complexity for something that should be import ../path/to/module though. Surely there must be a simpler way...?
I don't see the point: every modern Linux has Python (or it's apt-gettable) and py2exe is pretty mature at this point on Windows.
Sorry, that was poorly worded. The program I am writing reads the output from another program that exports different amounts of information each time. The number of unique rows and cols will be different in each file. For example one file migh have w1 2 8 ... w52 2 8 w53 9 16 ... w104 9 16 w105 8 44 So each unique "row and column" set is repeating 52 times. The next time the file is read they might only repeat twice. So each "row and column" set is repeated the same number of times as each other set in the file but the total number of repetitions varies from file to file. 
You can use relative imports, eg from ..subdir import some_functionality And either .egg or .pth files are your friend for getting all your packages ready. Learn distutils and make a decent setup.py for each package, which should be a logical grouping of functionality. You could either have a sitecustomize.py or just a python file in a well-known location that you import that alters your sys.path to include your various module/package folders.
StackOverflow is better suited for technical questions than Reddit, go for it. Python modules are okay, but packages can be complex.
as pointed out, py2exe (and py2app) are mature and work quite well.
I don't understand your description, but I gave it 45 seconds. This might help: Offhand, it sounds like you need to make two passes over the information. Do one thing that gets you the data in some other structure. Then, operate on that structure to get counts of something.
Looks a lot less complete than py2exe. So far I've used: py2exe for Windows, py2app for Mac, Freeze for the rest (*nix). Their approach is similar and they are rather well documented. There are complex cases though - I wish the process was more automated. http://wiki.python.org/moin/Freeze http://py2exe.org/ http://svn.pythonmac.org/py2app/py2app/trunk/doc/index.html EDIT: TIL about [cx_Freeze](http://cx-freeze.sourceforge.net/) - looks like the real deal. Found about it [here](http://www.reddit.com/r/Python/comments/dq4st/packaging_python_application_as_a_single_windows/c123f89) Also, as suggested, I will leave this here: http://www.pyinstaller.org/
Already done: http://github.com/kennethreitz/xerox
I was about to recommend py2exe as well :)
+1, except include PyInstaller :)
That helps but I'm stil slightly lost on the repetitions thing. Can you give maybe a 10 line example that includes what you mean by the repetitions?
Sure. Lets just say I am passed two files. File1 has two unique values repeating six times each. w1 2 8 w2 2 8 w3 2 8 w4 2 8 w5 2 8 w6 2 8 w7 5 43 w8 5 43 w9 5 43 w10 5 43 w11 5 43 w12 5 43 File2 has five values repeating five times each w1 2 8 w2 2 8 w3 2 8 w4 9 3 w5 9 3 w6 9 3 w7 88 51 w8 88 51 w9 88 51 w10 1 20 w11 1 20 w12 1 20 w13 65 4 w14 65 4 w15 65 4 Did that help? The actual range of difference could be anywhere from 50 values repeating 52 times each up to several thousand values repeating several hundred times each. 
how much improvement do you get by compiling python?
Did you try appending to PYTHONPATH? This has worked for me in medium-sized projects, but I reckon it can get quite messy. This, or what grandparent suggests... basically breaking up the project. Frankly, I've never found an instance so big it couldn't be addressed with standard ways and it wasn't better off divided.
&gt; Is there some shortcut for "jump-to-symbol"? Ctrl+K, Ctrk+G will do that. Ctrl+K, Ctrl+L; Shift+Tab will allow you to search the code symbols tree (left sidebar).
Haha. I guess I missed it in my "prior art" search. Pyperclip seems to be almost identical to xerox, though pyperclip doesn't require the win32 libraries to be installed.
Distributability. Yes it's a new word.
Thanks for the comment. The code in question is running embedded on a hardware device, and the various different tools are ultimately started from web pages via Apache CGI. The system architecture is already fairly well planned out, and it is already "divided". We're just fed up of relying on things like symlinking from one directory to another one just to fit in with Python's module system. That sort of thing is a mess when it comes to distributing software updates securely to devices in the field, for example (as is anything that requires running installation scripts and the like, as others have suggested). From the informative replies in this discussion, I am now coming to believe that in this respect Python really does belong in the stone age: while I very much appreciate all the ideas, I can't believe we're seriously talking about hacking around environment variables or installing whole project management packages to do what almost every other programming language in the last two decades can do with a single line of code. :-(
I can't figure out what exactly you are doing from your description but for you to be that frustrated and using comments like "Python belongs in the stone age" I can't help but feel you are just doing it wrong. Symlinks?! I'm working on a large project right now that has a large amount of code reuse amongst it's bits. The server and the client share code. The GUI client and the CLI client share code. Other tools share all of this code. It's laid out somewhat like this: PYTHONPATH=*path to my project* Examples imports from each component: Client: from projectname.client.library import Connector, SomethingElse... from projectname.core.session import Session Server: from projectname.server.library import Listen from projectname.core.session import Session core/session.py: from projectname.core.globalvars import globalVarICareAbout from projectname.core.helpers import helperFunctionIPlanToUse (Names changed to protect the innocent) Basically, we have a top level directory (which is superfluous, to be honest) and then each component. If there is code that is only used by clients it will live in the client package. If there is code that is only used in the server it will live in the server package. If there is code that is shared amongst them it will live in the core package. By specifying the PYTHONPATH to be the toplevel of the project, all code imports are very clear. All code imports are done the same way so if a hunk of code has to be moved from the client libraries to the core libraries, it can be done without changing anything except the places that import THAT code. I'm not sure this is addressing your specific concern but I do feel as though you must be doing something wrong right now...
Appending to PYTHONPATH (within the .py) is not quite as bad as it sounds. http://www.stereoplex.com/blog/understanding-imports-and-pythonpath Languages like Java achieve what you want by forcing the directory structure on you. Personally I don't like it - I prefer it like in Python - but when I use Java I live with it. Quite like Python's forced indentation. Sure it's not perfect, you may even not like it, but in general it's not so bad. Python 1 and 2 discourage big directory trees. I think it's an architectural decision, as in scripting it fits the bill usually better. However since Python has grown into yet-another-language-for-everything, in Python 3 it changes somewhat, by making modules absolute by default. Probably you already tried Python 3k's way, but just in case I will bring it up. from __future__ import absolute_import # I reckon this works in 2.6 and 2.7 You can read more about this [here](http://www.python.org/dev/peps/pep-0328/). To be honest I've never found the need, but then again I never used Python in embedded systems. I'm off to sleep, I hope you find a good solution for your problem.
&gt; Speed is not a matter of wrong / suboptimal algorithms! Your exuberance is overshadowed only by your stupidity.
If I understand you correctly, the W## lines are basically line numbers. What you are counting is either the number of instances that the next two numbers repeat over the file, or the number of times they repeat in a row. If it's "times is a row", this is really easy. Set some counter to zero and increment the counter until you hit a line that's different. When you do, output that data in an array, set your new search value to the different line, and your counter to one. Continue until done. If it's number of times globally, use a tuple (x,y) from the second and third number as an index into a hash. Start by setting the hash to empty. For each line in the file, if there's an entry in the hash with that tuple as the key, bump the counter (the value attached to that key) by one. If there isn't an entry with that key, set the value of that key's entry to one. Either way, jump back and process the next line. It looks to me like the second is the droid you're looking for. If this is the case, you might want to look into one of the existing stats packages that handles two dimensional histograms. "R" perhaps? 
I assume you have gone through: http://docs.python.org/tutorial/modules.html ? What exactly is the problem you have with putting util functions in a util.py at the top level of your package tree? For e.g. foopackage/__init__.py foopackage/util.py: # util functions go here foopackage/something.py: from foopackage import util util.utility_function(123) # etc. You don't need to put everything in the same tree to import it. You can have independent packages. Just make sure you put the *containing* folder(s) for both packages in your PYTHONPATH. When you do 'import somepkg' in Python, it will look for a directory called 'somepkg' (or somepkg.py) inside all folders listed in PYTHONPATH. A word of advice - stay away from eggs.
http://www.google.com/search?q=Distributability
Thanks for the advice everyone. After reading through the advice and looking around on a few other sites I learned a lot. Someone on Aardvark suggested the following code: f = open("file.txt") unique = [] for line in f.readlines(): array = line.strip().split(" ") unique.append((array[1], array[2])) unique = list(set(unique)) # to get rid of all duplicate items i = 0 matrix = [] for combination in unique: i += 1 matrix.append([i, int(combination[0]), int(combination[1])]) print matrix This code, modified for the actual program, seems to be working great. 
I found a solution before I read your suggestion but thanks for the advice. I was thinking of using some sort of hash table but I never quite figured out the best way to do it. After the project finishes I am going to give this a shot - It would be interesting to see the speed difference between the hash table and the solution I am currently using. 
 import ../path/to/module works? 
I've only used py2exe &amp; bbfreeze once each... but I remember bbfreeze being much easier to work with when I couldn't get py2exe to work. This was over a year ago, and unfortunately I don't remember the details.
&gt; I can't believe we're seriously talking about hacking around environment variables or installing whole project management packages to do what almost every other programming language in the last two decades can do with a single line of code. You don't have to "hack environment variables". You can import sys, and then append to sys.path. Alternatively, if you are using Python 2.5 or later, you can use absolute imports of the form "import ...foo.symbol". Python's model allows for a module to do relative import of another module, but it determines those relationships based on directory structure. If you don't want to use directory structure, then you have to somehow inform Python about how to find those other modules, either by setting an environment variable or by directly modifying sys.path (preferably in your main.py application entry point). Echoing the sentiments of others here, it might help if you actually laid out an example module and directory structure that illustrates the problem.
First of all, you are mis-using the term "module". The python term for what you call a "module" is actually a "package". A Python module is a single python .py file, or an extension module of some sort. If you have a common package of subroutines that other packages need to access, then the Python interpreter has to be made aware of that package, and expose it into the package path so it can be imported. The two ways of doing this are (1) adding the package's parent directory to sys.path somewhere, and (2) adding the package's parent directory to PYTHONPATH. If you don't want to edit the PYTHONPATH environment variable and set it in your .bashrc, and you want the path to be available all the time, then you should append it to sys.path in your site.py or sitecustomize.py (the latter is preferred).
In basically all cases in the README file, I found neo4j.py to be more "Pythonic": &gt; First, all actions taken against the database must be wrapped in a transaction. The with-statement is tailor-made for things like transaction setup/execution. It makes the intent much clearer, with fewer extraneous syntax decorations, than using a decorator. &gt; Creating a node There's nothing wrong with keyword arguments; in fact, in most cases using them is more Pythonic than passing a literal dictionary. &gt; Finding a node by ID It's customary to override language operators (__getitem__, __getattr__, etc.) rather than provide generically-named methods like get(), as long as the semantics of the operation are basically the same as the semantics of the operator. I don't really know what wrapper.get(14) does, but it seems like the subscript operator's a fine choice there. &gt; Creating a relationship Explicit is better than implicit - .knows is clearer than .relationship(..., 'knows'). Though the latter API may be a bit more useful if you frequently need to define relationships other than 'knows' based on data. &gt; Traversals I like neo4j's approach better. For one, it keeps the traversal within a for..in loop, which is the normal way to traverse collections, generators, iterators, and other iterables. Two, it doesn't require a method with 5 parameters - once you get up there, it's often an indication that a class was a better idea. Three, I liked the way it specifies options of the traversal as simple class variables. 
&gt; It will be in the future of CPython, What? As things are now Unladen Swallow exhibits all signs of a dead project. 3months since last checkin? Mail-list traffic is in single digits http://groups.google.com/group/unladen-swallow/about?hl=en (with 6 out of 9 messages dedicated to "is the project dead" topic)
[PEP-3146](http://www.python.org/dev/peps/pep-3146/)
This would be better (assuming there is always a header row): header = csvData[0] for row in csvData[1:]: # blah
Just came here to post something very similar. Also, OP, "pythonic" is a term thrown around a lot that means different things to different people. Just try to write clear, concise code that people can read and try to follow the "Zen of Python" and you should be good.
Here's my more pythonic version using a generator: http://pastebin.com/veskhqwm 
modified version that doesn't require the field names to be renamed: http://pastebin.com/4TxYNE5Q
your definition of pythonic is a bit weird.
TIL stands for "Today I Learned". So "TIL I learned" means "Today I learned I learned". 
Try the [Hitchhiker's Guide to Packaging](http://guide.python-distribute.org/). Unfortunately, Python packaging is the worst part of the language. It's also changing really fast, as heroic hackers try to make that not be the case. Fortunately, one of those heroic hackers (Tarek Ziadé) maintains the Hitchhiker's Guide and keeps it reasonably up to date with the current best practices for packaging. 
Thanks for the feedback! &gt; Transactions I chose the decorator simply to limit keystrokes. My main thing was to get rid of having to type the with statement and connection.close() call in every method where I wanted to do some Neo4j'n. &gt; Creating a node I am making nodes based on form input and I felt that collecting field names: values in a dict and passing them to some method was the simplest way. I guess this one doesn't really matter since the dict is passed as kwargs to the original creation method. &gt; Get by ID I didnt want to have getitem on Mapper because its functionality wasn't limited to dealing with nodes. It will also return an index or relationship based on your action. &gt; Relationships While using neo4j.py I found myself questioning if the current implementation was the correct way to handle certain situations, especially when creating relationships. Like you said, it is easier to use a method that takes the relationship name as an argument than having the actual method define the relationship name. &gt; Traversals Their way wasn't bad at all, I just wanted to be able to do it from the node itself and out came that five argument method. I think that I struggled most with naming the classes and methods. I should probably go back and re-evaluate them, get_noun vs noun (I prefer get_, but whatever). All in all it was a fun little exercise for a noob. I am already using this bit of code to power something that I am working on and I hope that it may help someone else get into Neo4j too. Thanks again for the detailed feedback.
automatic teller machine machine
I'd say that it's almost the opposite of mine.
Ok, I figured it out. cam = raw_input("CAM # ") That's where my problem is! If I use that to input my cam variable, it messes up, but if I assign cam=7 it works fine... how can I fix this?
I got it! I need to input instead of raw_input. Thanks for the help everybody lol
I'm scraping over 500 news articles a day. I send the text to an api that extracts semantic information for me and returns a JSON string full of meta data. I then store the complete text of the article, date time, url, the JSON string, etc... as separate text fields in Postgres. RDMS systems were built to store text and related data in this way. 
You may want to look at zfill() and also %'s options
Make sure you don't take the comments too harshly - I can't think of a better way to learn python than what you're doing. Building fun stuff and showing it off has got to be the absolutely best way to learn a language. Oh, and if you're working with the neo4j rest server, I'd love to hear your thoughts on the GUI for it - http://github.com/neo4j/webadmin
`raw_input()` returns whatever you enter as a string, while `input()` evaluates that string and returns the resulting object. The latter can be a bit dangerous and has, in fact, been removed from Python 3 (which has only input() and it behaves just like raw_input()). If you're expecting an integer, it's better to use `cam = int(raw_input("CAM #"))` and deal with the potential `ValueError` exception. As for the original issue of padding numbers with zeros, you should check out string formatting (the [Input and Output](http://docs.python.org/tutorial/inputoutput.html) part of the docs has pointers to several ways of doing that). You could, for example, have used `camgroup = "%02d" % cam`.
Thanks! Now I'm researching how to output all my print commands to a text file. Ideally I'd like to make this into a nice GUI program, but... baby steps...
Don't forget your PIN number! 
Congratulations! As happy as I am for you, we really don't need to hear about it when you achieve an important milestone. If you make something cool; show. If you need help; ask. If you find something interesting; link. Generally it's a good idea to have some sort of content before posting.
Sorry, I tend to be a reddit spaz and post things on a whim. Thanks for the advice, though. :)
Python, or any other interpreted language, is not slow per se. But unnecessarily checking a condition that's only true for the first line when processing every line is just horrible. A waste of time. Also sorry for the typing in my original post, mobile phones kinda suck at typing.
I'd say it's fast, but it's a trip to C-Land and back to Python-land on every iteration of the loop. Therefore, it's wasted time. And a short computation done 50000 times will have a noticeable impact on the program's performance. 
Why don't you put it online somewhere so people can check out the script and maybe give you some tips?
Python packaging is a pain, but the modules &amp; packages system is trivial, there's nothing tough about it. 0. Everything starts from `sys.path`. This is a list of filesystem paths where Python stuff lives. You can add directories to it within python, or set them as the envvar `PYTHONPATH` which Python will use to populate `sys.path`. When you do `import foo`, Python lists each directory (or zip file) in `sys.path` in turn and looks for a module or package called `foo`. Your Python installation will prefill `sys.path` with stuff which is not in your user's `PYTHONPATH` for the stdlib and the installation's site-package. There may also be distro-specific stuff and other things. 1. Module. A module is a Python *file*, so `foo.py` is a module. A module is self-contained. 2. Package. A package is a directory with an `__init__.py` file at its root. They generally serve to bunch up together a bunch of modules, or sub-packages. 3. Modules and packages look the same (mostly) from userland, but using the right terminology goes a long way towards getting people to understand what you mean. &gt; Clearly neither of these approaches is practical for a large project with several people contributing, a standardised directory structure at the top levels, different installed locations for local testing vs. deployment, code written in different programming languages involved in various places, etc. It's interesting that you assert these approaches are not practical but at no point do you explain why, or what you'd consider practical.
How satisfied are you with Tkinter? I want to start a new project and I've had dependency hell and "quirky installers" with wxPython and PyQT. I originally was gonna use tkinter but everyone was complaining about the looks, and how its old-fashioned.
Well, finally a guy who agress with me tha vi and emacs sucks. Yeah, I know I will be downvoted. But I come from developing in Delphi, and when you do, vi and emacs really sucks. I bet if I had started using emacs and vi I would have said that Delphi sucks, but I didn't.
I was playing around with the rest interface using the http://github.com/emehrkay/neo4j-rest-client . I will definitely install the webadmin and try it out. 
&gt; I can't figure out what exactly you are doing from your description but for you to be that frustrated and using comments like "Python belongs in the stone age" I can't help but feel you are just doing it wrong. Symlinks?! Quite. :-) &gt; Basically, we have a top level directory (which is superfluous, to be honest) and then each component. From all the responses I've now had to this post, this seems to be core of the problem we have. It's a fairly large project, and there is no "top level directory" for all the Python code. There is a systematic directory structure project-wide, and we have Python packages in various directories within that structure (along with code written in various other languages, compiled or otherwise), but it seems Python's module/package system isn't ideal for this scenario. I'll edit my original post to add a few more specifics, since several people have made similar points.
&gt; What exactly is the problem you have with putting util functions in a util.py at the top level of your package tree? There is no "top level of our package tree", because much of the project is not written in Python and the Python packages live at specific places in a broader directory structure. I've added some more details to my original post to try to explain this better.
Thanks for all your comments in this discussion. I have added more detail to my original post, which hopefully addresses the questions you and others have been asking.
&gt; It's interesting that you assert these approaches are not practical but at no point do you explain why, or what you'd consider practical. I've added some more details to my original post, which I hope will explain things a bit better. Our biggest problem seems to be that because Python is only a small part of our project as a whole, our file system is not built around a single, top-level directory under which all of our Python code lives in subpackages. As far as I can tell so far, that means the everyday tools you would use to cite code in one subpackage from another can't do their job without some extra help so they know where to find things. That is reasonable enough (how else would they work?) but it's proving surprisingly difficult to find a simple, robust way of supplying the information about where to find other packages locally, without creating dependencies we don't want between different packages or on absolute paths.
&gt; I've added some more details to my original post, which I hope will explain things a bit better. Yes, things are much better like that. &gt; That is reasonable enough (how else would they work?) but it's proving surprisingly difficult to find a simple, robust way of supplying the information about where to find other packages locally, without creating dependencies we don't want between different packages or on absolute paths. Couldn't the toplevel project do that management for everybody (though that means it'd need to know about all transitive dependencies as well, which would probably be an issue… maybe the toplevel project could do its own management and then call each direct dependency to have it setup its pythonpath in a clean manner? Do you have that kind of recursive initial setup for other components?). I would recommend asking this question on [python-list](http://mail.python.org/mailman/listinfo/python-list) (it's the main list for Python users), maybe shortened up a bit, but sourced from your edited post and this clarifying comment (which give a much better — and impersonal — overview of the issue). Finding a more adapted title would also be a good idea (at the end of the day, your issue is not really how Python's modules work but how to manage your sys.path in a complex project using quite arbitrary dependencies).
I see that you've already solved your problem, but here's a tip anyway -- this does exactly what you want it to do: camgroup = "%.2d" % (cam,) http://docs.python.org/library/stdtypes.html#string-formatting-operations
I think that point is moot with the newer versions of Tkinter (renamed to tkinter in 3.0). From 2.7 you should be safe, but maybe you should try a few snippets from [here](http://docs.python.org/py3k/library/tkinter.ttk.html) for peace of mind.
Yeah I'll have to take a look at your implementation. I threw the whole thing start to finish in 25 minutes :) 
I guess that *cam* is an integer, what about this: if cam &lt; 9: camgroup = "0" + str(cam) else: camgroup = str(cam) 
Is there any reason for the fact that python package for feauture A has to be executed from path: path/to/feature/A Why don't you for example pack it to an egg and deploy to some common location (either default one or to directory of your choice, if you don't want to pollute site-packages) from which the scripts that need it just load it? Of course automate the hell out of this, so you don't have to do it manually while developing. 
I have only used py2exe for a few projects but was unsure as to how credible this solution is. It has always worked for me, but it is good to see there are others who use it regularly, too.
This looks like an excellent replacement for IDLE. Im not even sure how people *use* IDLE.
IDLE works just fine as a base editor. Opens instantly and offers some nice features. It's pretty much exactly what it has to be, not competition in the full-fledged IDE market.
It's probably not absolutely necessary. We prefer to keep all our code, regardless of languages/tools used, organised in a modular way based on the features, abstraction levels, etc. We find this more intuitive than shoving all our Python code into a centralised location because it's Python, all the C libraries somewhere else, etc. It also makes it easier, to some extent, to get these different languages talking if the relevent run-time stuff is all in the same directory.
price probably
Thanks for the new reply. I hope my original post only came off as frustrated rather than hostile/offensive, but as you've probably guessed, I was pretty much at the end of the rope after several of hours of trying to figure out what I expected to be a simple thing... :-/ &gt; Couldn't the toplevel project do that management for everybody (though that means it'd need to know about all transitive dependencies as well, which would probably be an issue… That is the basic problem, yes. Our architecture is fairly well-planned in general, so it would probably be possible to hook things in at the top level and propagate if that was the only way to keep the Python files/packages organised consistently with the rest of the project. It's not exactly a maintenance-friendly approach, though, as you've noted. Our other complication is that there isn't just one top-level entry point to our system. There are many ways to access this functionality: different CGI scripts that talk to various web-based user interfaces, different shell commands from text-based user interfaces, cron jobs, RPC protocols, etc. This is one of the main reasons we have this broad architecture and we try to keep each area of functionality self-contained, with clear interfaces and well-organised dependencies. It's also one of the reasons we can't just make everything Python-centric: many of these interfaces and the other tools are written by different people, who may be using different languages/libraries/tools depending on what is most appropriate for their particular needs. &gt; I would recommend asking this question on python-list Thanks for the suggestion. I think I'll explore the various ideas that people have helpfully mentioned in this discussion first, but if I can't get what I need from some combination of those, I may well post to python-list.
I'm aware of the PEP ;-(. It's just that I think that mailing list traffic is a much better indicator of project health. If you have other info which indicates otherwise, it'd be greatly appreciated.
http://en-de.dict.cc/?s=exuberance I think you wanted to call me "arrogant" or something like that? Besides that: You are wrong! The author has unnecessarily implemented an algorithm with bad runtime complexity. So that is not a matter of Python.
So what is the argument of using IDLE over vim?
I use vim. However, it's obviously not for everyone.
&gt; I think you wanted to call me "arrogant" or something like that? No, I meant "exuberance" because you put an exclamation point at the end of an sentence that's flagrantly wrong. &gt; The author has unnecessarily implemented an algorithm with bad runtime complexity. The runtime complexity remains O(n) in the number of lines in file whether the conditional is inside the loop or outside of it. &gt; So that is not a matter of Python. The fact remains, Python is one to two orders of magnitude slower than C/C++ at reading files and parsing CSV. If Python is *fast enough* (and it frequently is; I've written jobs which on a daily basis parse hundreds of millions of lines in CSV, and it doesn't matter to me whether they take one minute or ten to run), it will be fast enough whether the conditional is inside the loop or out of it. If it's not fast enough, moving the conditional outside the loop won't matter; you'll need to rewrite your program in C or C++ anyway.
Slides from Pycon2010 on the subject http://tarekziade.wordpress.com/2010/02/20/pycon-slides-answers-to-gm-questions/ Direct link to PDF: http://ziade.org/slides/pycon-2010-state-of-packaging.pdf
People seem to take the defence of their language of choice personally. That granted you some downvotes :-/ I'm subscribed to the Python subreddit and a bunch more and I had you in my FP only briefly. I think the "stone age" comment clinched it. Tried absolute imports?
can't wait to give this a try. Love fabric for a lot of great quick automation hacks on my software projects and might check it out for more sys-admin related items with this added in.
OMG... perhaps my english is not very good; I just wanted to say, that the choice of a different language is less effective as to improve the complexity. So that is not stupid but instead a fundamental wisdom of CS. @Code: Of course the complexity ist bad. The author uses an inner for-loop which does two avoidable things. (String-replacement could have been done once before the main processing, exec() could have been avoided by using an dictionary.) So the complexity here is rather O(n*m)! So perhaps you better calm down and stop insulting other users!
&gt; I chose the decorator simply to limit keystrokes. My main thing was to get rid of having to type the with statement and connection.close() call in every method where I wanted to do some Neo4j'n. But you wouldn't type connection.close() in every method you use Neo4j: you'd presumably open it once on application startup and pass a connection object around. Then your only typing is the with statement, which is significantly more concise than the decorator. Opening a new connection every method is going to create and hide a performance problem. You should make it easy to do the right thing, not easy to do the wrong thing. &gt; I am making nodes based on form input and I felt that collecting field names: values in a dict and passing them to some method was the simplest way. That's a non-issue because you can just pass it as graphdb.node(**kwargs).
Unfortunately, their upgrade policy ensures you may be a paying customer more than once a year.
Vim is newbie unfriendly
Ctrl, Double-Click takes you to the function or method definition, even in imported modules.
awesome! I'm hoping people find it useful. 
for quick and dirty on windows, i prefer autoit
I'd argue that the original code is far more 'Pythonic'. Nostrademons' explanation summed it up nicely.
This is a good suggestion. The problem OP is having (I think) is that the *working* organization of the code doesn't match Python's *runtime* module import needs. So add a 'make pythonlib' task to the Makefile/equivalent that packages all of the python modules, maybe as egg dirs or zipped eggs if that is useful, and puts them in a single library dir. Then add that dir to sys.path in sitecustomize.py or in each of the executable CGIs or scripts.
&gt; OMG... perhaps my english is not very good No need to tell me that. &gt; I just wanted to say, that the choice of a different language is less effective as to improve the complexity. So that is not stupid but instead a fundamental wisdom of CS. No, that's not "a fundamental wisdom of CS." It's flat wrong. First, you're misusing the term "complexity". The complexity of an algorithm is its asymptotic runtime. It is unaffected by whether an conditional occurs inside a loop or outside of it. Second, you're wrong in that the Python program with the conditional *outside* the loop would still be orders of magnitude slower than the C++ program with the conditional *inside* the loop. Language implementation speed has far more impact here than the location of the conditional. &gt; So the complexity here is rather O(n*m)! No, it isn't, you exuberant idiot. It's O(n) no matter how many conditionals are in the loop. The loop occurs n times. The conditionals inside occur once for each time through the loop. There could be a hundred useless conditionals inside the loop and it would still be O fucking n. &gt; So perhaps you better calm down and stop insulting other users! Stop being a fucking dumbass and I'll stop insulting you.
Google App Engine is a good WSGI hosting service. import web from google.appengine.ext.webapp.util import run_wsgi_app urls = [] app = web.application(urls, globals(), autoreload=False) if __name__ == "__main__": run_wsgi_app(app.wsgifunc) 
I will check this out! ...Some project euler problem where my lack of math knowledge will lead to a distributed brute attack. Then the forums will teach me what I missed out on ( :
We learn in IDLE in my course. It's good for learning basics.
Sorry, I'm not trying to bash you, I'm just curious: Why do you want to learn Python? The way I learn best is to decide what I want to make first. Then I decide what I want to learn. Then I try to make it using what I wanted to learn. Then I've learned it. Programming is repetition and failure at first. You just learn to avoid the traps until you really understand what is going on. Good luck either way!
Awesome product, awesome team. I own two Pro licenses and have never regretted it!
Wouldn't knowing Lisp be more useful in San Francisco?
I think knowing lisp is generally more useful.
Woosh! (That was the sound of that gay-stereotype joke passing right over your head. Everyone knows every single gay speaks with a girlish lisp.)
I live in San Francisco. I'll teach you python if you teach me how to play the guitar.
Thanks. Yeah I actually was wondering why all the example code I tried didnt work because of "Tkinter" vs "tkinter". Anyway, for now I think I'll stick to tkinter thanks for the tips.
It was so hard to not, uh... walk into such comments.
I know how to play guitar, just teach ME python. PM me
I know Python, and I can play the guitar. But I don't live in SF. I have no use for you fools. Unless you want a new room mate. :)
I'm in the Mission. What sort of projects/things are you interested in?
Everyone knows every single girl speaks with a lisp, too.
Yes I understand that, I'd do the same. I assume there is no problem on developers machines, either since IDE should handle the dependencies/directories correctly, AFAIK Eclipse Pydev does that, or since any of them can set PYTHONPATH variable when he/she is working with the code and it would not break anything. So my question is - does your code have to be located in some strange directory structure when your program is deployed on non-developer machine? Can't you just use setuptools/distutils install to deploy python egg to either standard location (site-packages) or some arbitrary, non-standard directory which lands in environmental variable, where python interpreter will look for it?
Have you tried: http://learnpythonthehardway.org/index
I think learning lisp at this point is a waste of time. Learn python and then go back and learn about Lisp if you so desire. Lisp for me has been nothing but a waste of time. I was kind of surprised that people mentioned it here at all even as a joke. Also I think if you really are motivated to learn a new language then * 1. python is a great language to learn * 2. you can learn it yourself You should just pick a project or simple idea and try to solve it with python. People say this over and over again but it really is true. Learning a language requires doing and doing requires a direction/goal. I don't know what you're been reading but don't flood yourself with questionable tutorials. I'd start with the basics. I think python's official tutorial in the documentation itself is pretty good as well as the standard library documentation. I reference these daily so you will want to read over them and then reference them while you work on doing something. When you have a problem go to #python on IRC or a more related channel and ask for help. I have been using IRC for a few years now and you can get burned the first few times but it gets better and there are a lot of helpful developers on there. An additional route that could be taken is Zed's book. I have not read it in entirety but I think the idea is spot on and has been confirmed in my experience with math and programming. Just keep working with the ideas over and over and it will stick. There is no easy way(except of course that python is a rather simple language compared to others). Info about his book can be found here: http://learnpythonthehardway.org/index
If you can make it out to Berkeley, there's a very good coalition of Python enthusiasts at the university. Alternatively, look here: http://www.baypiggies.net/
Have you tried the first few examples of http://projecteuler.net/ yet?
http://www.pythonchallenge.com/ Very entertaining and useful. 
Write a tool you need, solve a problem you're interested in. Anything to keep you interested and writing code daily. As with all other forms of art daily practice is the only way forward.
I concur. Working on a project you design/create is a lot more fulfilling and educating then following steps of some wumpus game or shop backend. Make a game/a tool something you want or think the world needs(even if it doesn't). 
write a sudoku solver
Not really. There is a free version of WingIDE that has the most important features. However, it's not meant to be a replacement for IDLE. IDLE is roughly perfect for what it's meant to be.
Lisp is a much better first language than Python. Python is very useful, especially for its momentum, code base, availability and community. However, Lisp is much better at teaching you to program when you have no programming background. So is Smalltalk. I always have a very hard time explaining Python to complete newbies to programming. The kind of people who don't even know what's a variable or a function in a programming context, these struggle with Python much more than with Lisp, or even Processing. It really all depends on where you really are and where do you want to go. Maybe in reddit you can take some basic programming skills for granted (or you could before it went mainstream this year...) but there is a world out there full of people who're far away from being able to reasonably do something useful in Python.
Sorry, but it makes no sense at all to go on with this *discussion* with you! &gt;&gt; the choice of a different language is less effective as to improve the complexity. So that is not stupid but instead a fundamental wisdom of CS. &gt; No, that's not "a fundamental wisdom of CS." It's flat wrong. No, it is not! Perhaps the word "complexity" was wrong - in German it is correct for that topic. From [wikipedia](http://en.wikipedia.org/wiki/Analysis_of_algorithms#Run-time_analysis) &gt; Run-time efficiency is a topic of great interest in computer science: A program can take seconds, hours or even years to finish executing, depending on which algorithm it implements I looked at the 2nd and [3rd revision](http://code.activestate.com/recipes/577419-query-csv-file/history/3/) of the author's algo. Perhaps you looked at a different one? There you have **inner loops** and one is directly depending of the cols of the csv-file. Therefore if you take n for the rows and m for the cols the complexity is O(n*m)! &gt; top being a fucking dumbass and I'll stop insulting you. Your mode of expression is very bad and crude. If one can **show** me, that I am wrong with my conclusions I have no problem to change my mind. But you don't! I never wrote something about *conditionals inside oder outside the loop* - you did that! So have a look at the link and try to understand it.
Interesting. So you're using multiple machines to do the work on the euler problem, and aggregating results using fabric? There are other projects that may be better suited to your problem, using something like map reduce or similar.
First, when you are beginning there are few differences between Python 2.x and Python 3.x -- mostly a few syntactical differences that are quite small so any collection of exercises for beginners should work. Here are two links that might help. Our Python introductory course has weekly labs that are short exercises that you might find useful. The link is http://www.cse.msu.edu/~cse231 Follow the "Labs" link. The course is in Python 2.x, but at this level there are few differences with Python 3.x. Also, I've archived our weekly programming projects at http://www.cse.msu.edu/~cse231/PracticeOfComputingUsingPython/index.php (We have over 300 exercises in our book, but I'm guessing that you don't want to buy a book, and it is in Python 2.x because it uses modules such as matplotlib that are not yet in 3.x)
I would also recommend http://programmingpraxis.com/ .
Projecteuler was how I learned; a lot of the problems make you really think about the space and time complexity of your code, which is an excellent skill to have.
Most times I write a few scripts which help me throughout the day, and most likely once you start to write one script you will find other scripts you can write which can be beneficial for yourself. Here are some easy ideas: 1) Calculate the number of hours you have worked today. (datetime module) 2) Remove all .tmp files in a folder (I/O operations) 3) Write a script where you can record your daily tasks and they are then stored it into a text file 4) Run shell commands using python (os module) 5) Scrape a webpage Once you start doing a few scripts, you will start to get a ton of ideas. 
Note that py2exe is Python 2 only. For Python 3 you want [cx_Freeze](http://cx-freeze.sourceforge.net/). cx_Freeze is cross platform and works on more versions of Python than py2exe, so personally I'd skip py2exe completely.
Fuck simple and small things. Choose something way out of your comfort zone, that'll take a while to complete, but most importantly, that you're actually interested in. Any working code you create won't be hugely pythonic, and the whole thing will probably be a big mess, but most importantly, you'll have learned a whole load and you'll have something which works. My first python program was a syntax checker for a shell based language, most of it was guesswork and the code really sucked, but I gained a lot from it.
Interesting. And it looks like it supports eggs, too! Next time I have to do something like that, I'll try cx_Freeze. Thanks for the link iceman-k!
Learn Python by typing out all the examples by hand. Do not skip any. Do not copy and paste. Your neural networks need to be trained to recognize the syntax and syntax errors. Your fingers need to be trained to type the python syntax fast. Just start typing, the understanding will come in a few years.
Also, had I realized that you were the author of the linked article I would have mentioned that you did a nice job of presenting clear instructions for what could otherwise be a confusing problem, and that the Python community as a whole needs more stuff like that. *High five*.
Thanks. Too bad the stuff in the article is obsolete :)
Write a sudoku solver that's not brute-force.
I went through a similar thing when I started learning programming. Still kind of do. For me, I realized I was asking the wrong question. It wasn't "What should I write a program for?" it was "How would I write a program to do X?" I needed to just pick something and do it rather than think about all the things I could write a program for. If I did that I would get overloaded with ideas and not do any of them.
I recently started learning python 3.1 and was surprised to find myself pushed back to using 2.x due to lack of available packages. Why is it so poorly supported by the web frameworks etc.? 
You're asking why a million different projects coded in free time by a million different people aren't rewritten from scratch overnight?
Possibly because most of the world is still using 2.x.
Is there nothing you want to accomplish yourself? I've found this has helped motivate me to do things. After you know the language it's pretty simple to do whatever you want; just learn other libraries, toolkits, and frameworks. Want to make a program to handle some trivial web scraping, learn urllib/urllib2 or something more high level such as htmllib2 or Mechanize. Want to add a gui, learn a gui toolkit (pyqt, tkinter, pygtk, pywin32, etc.). Just start somewhere and learn as you go; find there's a gap in your knowledge/ability, learn to plug it when the problem arises. It's a lot more fun and involved. Normally the built in documentation and the interactive interpreter is all that you'll need. 
It's a perfectly valid question, Python 3 was released two years ago, not yesterday, and supporting it does not require a "rewriting from scratch".
Is there any reason you don't want to host it locally? What are you trying to do? Since you've come here asking this question I'm guessing you're just fucking around and learning and thus local hosting is your best bet. 
Ummmmm...
http://inventwithpython.com This is a free book that has the source code for several game projects. Type them up yourself and learn how they work, then start making your own variants of them. The later chapters cover Pygame, a library that provides graphics and sound functions. You can follow the source code of more Pygame games here: http://inventwithpython.com/blog/category/code-comments/ Also, here's some advice you might be able to apply to yourself: [I Want To Teach My Kid How to Program](http://inventwithpython.com/blog/2010/09/27/i-want-to-teach-my-kid-how-to-program/)
Noisebridge is a hackerspace located in the Mission. On Monday nights they have a Pyclass to go over Python programming. https://www.noisebridge.net/
I have an app that I have designed which I want to build on top of, or inside of, [FluidDB](http://fluidinfo.com) I want to use the python modules for FluidDB to do so.
I dont know how to play the guitar, but could teach you to skip rocks.
I have done a few books, I just cant seem to retain the info that way. Thus I want to see if having someone tech me will help. 
Trust me, this book is different from any of the others you've tried.
Whats a good Lisp reference then -- I had done some very little lisp programing many many years ago with AutoCad...
I DL'd it and will give it a try.
Argumentum ad antiquitatem. Many products do have plans for change, but there are also many bottlenecks in the process. Time and effort are obviously major pieces. Dependencies are also an obvious blocker. The libraries will often be the driving force behind change, and I think NumPy's 3.x support will give a lot more projects momentum in getting towards 3.x.
If you are patient, you can go through the following lectures (video - text also available for free): http://groups.csail.mit.edu/mac/classes/6.001/abelson-sussman-lectures/ (torrents for download) Link to the first one in Google Video (you can skip the beginning http://video.google.com/videoplay?docid=5546836985338782440# (they go 1a, 1b, 2a, 2b, ...) More varied materials: http://www.teach-scheme.org/Materials/ Whether you go for Python or any other language, don't hesitate to contact me or just hit the Mentors subreddit. Having someone to ask makes a difference. For instance, this guy: http://www.reddit.com/r/mentors/comments/czwc4/offer_i_will_teach_you_python_beginner_or/ I genuinely enjoy teaching programming. Actually I tried with Python several times and I know very well the challenges. Python is more appropriate for a second or third language than first, this is my honest opinion. Of course, you can learn even Ada or Javascript as a first language and end up being good, if you put the time and the effort. I know this is the Python subreddit and this will grant me some downvotes but WTH.
There are people whom have written hundreds of thousands of lines of code in 2.X. They have extended and debugged that code over a decade. Some of those folks are just not going to spend the time to port that code to Python 3. It's just not better enough to justify the effort. Hopefully newer libraries will pop up to fill in the void.
Not to mention the fact that when you're developing a project the focus should be on the volatility of the project not the language.
I don't disagree with that, there are legitimate reasons for the state of Python 3 support, I just take issue with miloir's snarky response to a legitimate question.
ah dude, there are those things economists call cost and benefit. they are into play here. the cost of moving to python 3 far outweighs the benefit. so...
There's never been a good way to support both Python 3 and Python 2 in the same codebase. No one wants to switch entirely to Python 3, though many people are open to supporting both simultaneously. But it's damn hard. 2to3 helps kind of, but it requires careful trickery to get it to do what you want. For some domains there's the network effect of libraries. Web frameworks particularly often have a rich set of libraries they use, and so the work or just coordination to support Python 3 is a challenge.
Also of interest is [bbfreeze](http://pypi.python.org/pypi/bbfreeze/).
If you get through it and it doesn't work for you PM me and we'll figure something else out.
I like the idea here, but the licensing is really unusual for a project like this, and what you get for your money.
Numpy has recently been ported to python3. It was put off because it seemed like more work than it ended up being. With numpy ported, I can see more and more packages start to be ported over. Some, due to their need for numpy and others due to the ease with which numpy did. That said, the reason I think that most don't bother supporting it straight away are the simple things, like print not working as a statement anymore. Just makes it a touch harder to write code that just works on both methods.
Agreed. I wrote to the devs in the last couple of weeks about that... as you may know, they *emulate* vim, don't embed it. This seems foolish, as there are like a brazillion features in vim, and most of them are compound. Just the concept of a leader key... can't do it. So you end up with "real" vim and "fake" vim, and fake vim is worse than no-vim... at least one can train oneself to know two editors. They said it wasn't practical to embed; I'm sure they're right, but it's a shame. Vim has bindings for Python, which is how they make Wing. 
I did tic-tac-toe in every new language I learned for a while. It's about the right size; not too big to waste a bunch of time and get boring, but big enough to get some good experience in and learn what works in a language and what doesn't.
&gt;Why is it so poorly supported by the web frameworks etc.? Besides a lot of the little and big packages not being ported yet, WSGI had some some issues. Recently [PEP 3333](http://www.python.org/dev/peps/pep-3333/) was submitted so we should start seeing some progress.
Python is OP; some serious balance issues going on here.
&gt; Argumentum ad antiquitatem. pickles46 didn't make a logical fallacy. He was giving an explanation.
Nerf Python! Writing binary executables by hand was so much more realistic and is good old clean fun.
Web frameworks need to do ugly things with byte sequences that the people who did the bytes/strings separation didn't think of. It looks like 3.2 contains many of the changes to bytes that will get WSGI going, and therefore get Web frameworks going. But yeah, most of the Python package ecosystem is still stuck on 2.x.
Awesome. From mathematical modeling to graph theory to algebra to number theory to molecular biology to formal language theory, I've found python pretty handy for automating and checking homework. What do your scripts do?
a long long time ago (over five years now?), i found myself in a very remedial-like math class, and we were asked to find a certain Fibonacci number and split off into groups to find a process for doing so. my group started writing out steps and had a flow chart and started manually stepping through them to see what would happen. i knew python, so i wrote a program in notepad and ran it and was able to tell them, "yes, this is correct, and i can show you." the reason i bring this up is that i was able to turn my screen and show everybody present the program i had written, and having never seen programming before, they were instantly able to grasp what had taken place. python was SO fluent and transparent to people who had never seen it before that they didn't even need to know that it WAS python to understand it. i *got* python from that point on, i think. got why it was so great.
Although you are good intentioned, if every new person who uses python posts about their first script, you'd end up with something like /r/starcraft where there was a spasm of posts about "OMG GUYS I GOT INTO SILVER LEAGUE".
I'm on the WingIDE list as well and I remember this conversation. I understand from their point of view why it's nearly impossible to embed a full vim in WingIDE. I also agree with you that a handicapped vim mode is less useful than NO vim mode. I use vim primarily but use Normal mode in WingIDE for this reason. I still find myself with stray :wq in my code in places.... :(
This is probably not the best reddit to say this, but Mathematica would be a much better choice for both discrete math and linear algebra. Python is much more general-purpose, which has its pluses and minuses. You may also want to try SAGE, which is essentially a Python interface to various (mostly open-source) mathematical packages.
I like Led Zeppelin but hey - is it really cool in 2010?
You can use RPy 2 to wrap the horrid R language, that has a wealth of provisions for statistical and mathematical manipulation, into something usable.
Python is like pseudo code that actually works.
Check out ipython and sage.
&gt; Converting PHP code to Python Not easily possible because there are constructs in PHP for which Python has no equivalent: namely anonymous functions and references.
The example without the exception is better - more clear and faster. Exceptions are expensive in Python. Also "except:" should be never used - it should be "except NameError:".
what about: double.copyright = " ".join([getattr(double,'copyright','It is MINE! ') ,'Tell Ya I do']) or double.copyright = getattr(double,'copyright','It is MINE! ')+'Tell Ya I do' No exception. shorter code. Nothing outside the function..
we are doomed.
Yay! I used ipython -pylab last night to plot some of the data I collected in a controls lab the other day. I haven't tried sage yet but from a quick look it appears I'm going to have to - thanks. =)
References could be solved via names (foo the variable, bar the reference): &gt;&gt;&gt; foo = 42 &gt;&gt;&gt; bar = "foo" &gt;&gt;&gt; locals()[bar] = 23 &gt;&gt;&gt; foo 23 Yes, I will burn in hell. 
Wait, what's wrong with R? As far domain-specific languages go it's one of the best: flexible; reasonably fast; proper lexical scoping; first-class functions ... with a more comprehensive API I'd almost just as soon use it as Python.
I am dismayed that somebody has asked this question, because it casts a shadow of a doubt on the timelessness of a timeless band. And to answer you, yes, Led Zeppelin is still cool. Very cool.
both scripts last night were really just a couple of nested 'for' loops with a couple bells and whistles. one generated a bunch of random nxn matrices (n from 3 to 6), calc'd their determinant, found inverse if non-singular and calc'd that det as well. the point was to explore the relationship between det's. used numpy/scipy for that; very handy module. the other ran through a set A and pulled out the ordered pairs per a relation R. again, nothing super complex or intricate, just useful for cutting thru busywork and getting to the actual thinking part: determining if relation is reflexive, (anit-) symmetric, transitive, etc.
What about Gedit? It's simple, has a Python-console, a Python-checker (pep8.py and pyflakes), and you can write your own plugins in Python.
This does not work for references to array elements for instance.
&gt;THANKS to all those who've spent days/weeks/months contributing code and working to make the language (and all that that entails: std lib, docs, add-on modules, etc) what it is. Haha. Try "decades".
You're probably right -- I only took one logic class back in college and I've been wrong before :)
I quite like it but it's a bit slooooow.
sage isn't perfect - it's heavy (something like 700Mo) and not modular at all, it imports a lot of things into python and it may be difficult to find out from which python module each functionality comes - the documentation was far from perfect last time I checked it (2 years ago) - some people don't like the fact that they took some BSD modules modified them a bit and rereleased them under GPL (like cython) On the other hand it's really great to have all the standard mathematical function already defined if you want to check something really quickly. And all the functionalities that a calculator might have (derivation, integration, simple plotting...). 
im trying to ramp up in python after being a matlab user for many years. I have to say, while the price difference is substantial, you get a LOT of polish for your $ with matlab. From ease of install, to compatibility between toolboxes, demos and examples, the IDE, live telephone support if you need it... I do mostly image processing work, and I've worked with scipy and the PIL, I would take matlab + image processing toolbox over those any day of the week. It's non trivial to put together a clean development environment that has all the different libraries you want all with the correct versions and all working together nicely in a polished IDE. It takes time for me to find a library that supports colorspace transformations, figure out what version of python it's compatible with, get it installed, find the (lack of) documentation, and then in the end I'm not really 100% certain that it even works correctly. All those things cost me time (which == $$). 
Well, for my work (bioinformatics) it's slow, very memory hungry, with inconsistent syntax among even the base libraries, with some design flaws especially on indexing and matrix operations (http://radfordneal.wordpress.com/2008/08/20/design-flaws-in-r-2-—-dropped-dimensions/ and http://radfordneal.wordpress.com/2008/09/21/design-flaws-in-r-3-—-zero-subscripts/ ) and with the most unhelpful error reporting ever.
Are you trying to replace Matlab with Python? You shouldn't, rather you should know both and know when to use them. Edit: &gt; I know I'm new to python and shouldn't make rush judgments, but (so far) to me python feels like a machine gun spraying features/libraries/IDEs/versions everywhere. Python has a set of features that only change with new versions, as does Matlab. Python got a standard library, analogous to the standard packages of Matlab. IDEs are something external to Python, and few programming languages come with a standard IDE. Usually, having a choice is good for you, unless you simply don't want to deal with it. @all: don't downvote this guy, he is right in saying that Matlab is much more practical for image processing than Python. I know we all like Python, but it isn't a replacement for everything. 
This is very useful information. I've yet to work on actual core language code because I never really knew how to get into the actual process of making the changes/submitting/etc. Thanks for putting this together.
Just so you know, Python isn't only for scripts and django. We use Python at work for pretty much everything, with a massive code base and over 50 products. It's a wonderful thing.
On Komodo: &gt; Expensive, but nice. Oi! No fair! Komodo Edit is free (MPL'ed, even, not just free for non-commercial use like WingIDE) and Komodo IDE isn't considerably more expensive than WingIDE if you need a cross-platform editor (WingIDE is $295 for 2 OSes, $395 for 3 OSes; Komodo IDE is $382 per _user_, $295 if you don't want extra support). In fact, Komodo Edit's bang for the buck was what convinced me to use Komodo over WingIDE (I was considering buying a dual-OS license at the time). Currently the price tag for Komodo IDE is a bit hefty for me, relative to what it offers compared to Komodo Edit, but I'm definitely interested in purchasing a license in the long run. Compared to what graphic designers have to shell out for their software, most IDEs are fricking cheap (when they're not free) anyway (e.g. Adobe Flash Builder, the official ActionScript IDE, comes in at $699* -- I don't see why any programmer would be willing to pay that much for an IDE, but it matches the price tags for other Adobe products perfectly). *(Of course you'd also have to buy a license for Adobe Dreamweaver for $399 if you want to do more web dev work than just creating Flash apps)
&gt;the documentation was far from perfect last time I checked it (2 years ago) It's changed a lot since then. I was also unimpressed a few years ago, until trying it recently. It'll never be Mathematica, if that's what you mean. As for it being heavy, it's almost a requirement if you want a proper unified interface. It's wasteful - yes - but the goal is to make everything work well together, which it seems to have succeeded at.
I actually prefer Kate. And I have been using Kate for a long while and am still using it whenever I don't want to fire up a full-blown IDE (i.e. in very short sessions on Linux). Now I use Komodo, though, because I wanted something slightly more powerful (though defining new file formats for syntax highlighting is a PITA) and because I need something that works reliably on Windows as well (I used to work with Notepad++ on Windows when I was using Kate on Linux). Also, Komodo Edit tends to choke less on remote filesystems than Dolphin+Kate do (sometimes I have to use FTP and sometimes the server doesn't allow more than five connections, all of which Dolphin will use up for whatever it does when it's idling).
Care to elaborate? Do you mean the $87/year subscription for upgrades and support? That would be exactly "once a year". Or do you mean the cost of upgrading when you don't have a subscription (which they don't seem to reveal without a login)?
Arbitrarily numbered? It's the first "stable" release (and a product being sold) therefore 1.0, what's arbitrary?
What kind of image processing do you do? Also, isn't the company you work for supposed to pay for it if you need it for work?
I can’t imagine how wrapping it in Python will help you with any of these.
SAGE wraps R too. (though I can handle R without a wrapper; also, Sweave is nice. Most of my statistical/econometric work was in Stata and very high-level, so I guess I ran into fewer problems with both R and Stata than heavy users of either do.)
At least I can hide the language inconsistencies and use a friendlier syntax, while I develop alternatives.
Although I can empathize with your point, I concur with akho_ that it's unclear how helpful wrapping R in Python could be. The most obvious problem -- speed and memory use -- will be if anything worse, as you must go through a bridge between R and Python (and Python itself isn't known for being especially fast or lean). Error reporting from the R side will be just as bad, as will e.g. dropped dimensions in R functions. I guess it's not a big deal if most of your concerns are dealt with in Python and you're simply calling an R function here and there. Still: as a programming language R isn't bad at all, certainly better than Matlab or Stata. (The latter of which I use daily -- and shudder.)
this looks like a nice time saver. it raises a question for me though. i am a relative novice in the python world but i'm curious about the usage of os.system calls. wouldn't it be more appropriate to use the subprocess module for these calls to git?
I went through some of the usual suspects in my CS undergrad program ( Java, C++) and then ended up doing a lot of PHP stuff because I got into freelance web dev and honestly PHP is quick and fun. When I had to do some dev for my masters program I decided to learn Python and so far it's been pretty cool. There are a couple nuances that have thrown me after years of doing stuff a certain way, but Python really has been great. I haven't done any full scale application development yet, but it's been really nice for what I've been doing. I just spent a few hours playing on Project Euler last night, using Python and had a lot of fun.
I can't do things any other way. Did you try looking at the reddit source or API, you might have an idea of something you'd like to do with this data. Also, nodebox is a programatic drawing/data visualization environment that you program in python. It's usually pretty easy to spend an hour or two fun programming there. 
I've been using PyEclipse for a little bit. It's not bad. The code completion is actually a little overkill sometimes, but for a free plugin to free software it's a nice way to get a Python debugger.
The older &lt;1.0 versions were alright(even good!), but now it makes working on larger projects almost impossible - it's very slow.
touche
For the most part I would pick Python over Matlab except for image processing. Matlab just does that better for some reason.
I realize different people have different priorities, but holy fuck, every time I see something about how python packaging needs to be improved I want to stab someone in the face. Who gives a shit about the packaging system when there is no non-shitty way to actually *manage* packages? What packages do I have installed? What versions are they? What packages have updates available? How can I update them all at once? I realize there are solutions "in the works" but holy shit, how is this not a massive priority? &lt;/frustrated bitching&gt; 
If os.system does what you need, it is fine. In this case there is no need for fancy input or output piping or async execution.
There was no previous version. The hell are you talking about?
FYI: The Zope Toolkit is a set of libraries shared between BlueBream (aka Zope 3), Grok, and Zope 2 (aka Plone).
The previous version was called "PyCharm 1.0 RC2". The fuck are you on about? This is the first official "stable" release of PyCharm, and the first one with licenses available. Where's the marketing move?
I have a pretty fast machine, so I have no speed complaints. PyCharm is by far my favorite Python IDE. I haven't used Wing though and I hear it has lots of fans. PyCharm smokes PyDev though (I don't like Eclipse's perspective / view system). 
It seems to me that it is easier to do this with [pyinstaller](http://www.pyinstaller.org/) 
I'm pretty happy with pip. `pip freeze` lists packages and their exact versions, `pip install -U` upgrades all packages. I'm not sure how to just check what's available, passing `--no-install` might be good enough though. Virtualenv support makes version conflicts go away.
Sorry. I tried both and I prefer PyDev. It's faster (on my machine) and looks lots better (even better with Aptana Studio).
took me way too many clicks to figure out wtf zope is. 
The fuck are you on about again? PyCharm 1.0 came from a &gt;6 months old development process from the IntelliJ core and the old Python IntelliJ plugin. There was no "previous version" in the sense of an officially supported version with licenses available and no time-limit.
We are answering to most of these questions. I wrote PEP 376 for this (see http://www.python.org/dev/peps/pep-0376/) and Distutils2 provides a PyPI browser, and a new pkgutil module that will get back to the standard lib, containing all APIs to do what you are describing. We are now working on the UI. It's just still too early to use Distutils2 (wait for the betas) It's fine to have several of tools out there - as long as they comply with the new standards for interoperability (see also PEP 345). But reading this post and the Bento FAQ, it looks like David doesn't really see/understand the whole packaging eco-system and the goals of Distutils. If you start to compile C and Fortran code in your project and work on specific platforms, distutils will never be the tool you would want to use. (sure that could be improved but that is not our top priority) Last, David's analysis is on a work in progress and we have branches to merge that fixes some long standing problems he's mentioning for years. Too bad he did not ask us about the state of the project before he wrote this entry :) 
Anyone else disappointed on this being a year license?
Eh? From their site, &gt; PyCharm license is **permanent** and includes **one year of free product upgrades** since the purchase date, including even major version upgrades. While that doesn't apply to the free licenses (Classroom / Open Source), the approach seems reasonable.
It sounds like it'd be a lot simpler for you to just deal with longer method names. Creating a bunch of unnecessary aliases just makes the code more confusing and is blatantly un-Pythonic. You're papering over the true problem, which is your own (and maybe your coworker's) stubbornness.
Well, I also had some ideas regarding that stubbornness, and the fact that this is 2010, and I didn't think it would be an issue anymore. I thought it would be very nice to have, e.g., a versioner that didn't care about anything like whitespace, and an editor that displayed the pure data the versioner actually saved in any way you liked. If you wanted 8 spaces, or 4, or tabs, it would know that and simply show it to you in that way, and hold you to it as you edited, though it wouldn't really be part of your code. This would, for example, eliminate the problem of retabbing a file for clarity and having a versioner think every line is different. It would also allow for very liquid flow of the presentation of code. You could whittle away at your own settings over time to get them just how you like - e.g., cuddling of operators, but only inside of parentheses - and share bits or all of those settings with others easily. Everyone would always work in the style they wanted. You would also be able to throw in some regular expressions to do things like display for you - and allow you to use - smaller names, as in flags - but have them always balloon back up to larger ones on save. It doesn't even really need to be the larger names in the stored data, but tokens that equate to whichever each user wants to see. This would probably cause some issues when discussing code, though you could always flip it over to another style when pointing something out to someone else, and flip it back after. I guess I'm a bit of a dreamer.
Well, that seems like a totally unrelated tangent... sometimes simplest is best. Having code magically reformatted would cause a lot of weird side effects that you're not addressing, and every tool in the chain (editor, VCS, etc.) would have to have a parser for every programming language. That's really complicated, and being 2010 doesn't really change that. Complexity must at some point be managed by humans, and human brains aren't getting more powerful by leaps and bounds the way that computers are.
I don't think it's unrelated at all. My original post was about having an alias, and one option was to be able to use shorter or longer names without issue. You brought that point up in your comment (I should deal with longer names). Then I responded to that point by saying that really, in my dream world, that kind of thing wouldn't even be an issue, because of some further, lofty ideas I had about making data more pure, and less about exact syntax. The code gets compiled down to a very simple state anyway. It's always already being translated from what we write to what the computer eventually gets. This is another step very similar to that. A programmer would write code in their style based on some rules that are outlined in a style local to them, then save it into this system, at which time it would be formatted to some internal standard - a kind of pigeon. Any programmer could locally modify their own rules to do anything they liked for their comfort, just as they already do for syntax highlighting. When they opened the file, it would refactor it based on those rules, and they'd again work under their own set of rules, then save, and it would again refactor to the system's default. I could have short names and 4 space indents. Another guy could have long names and 8 space indents or tabs. You'd never have to have another argument about code style, and substance would become the only issue.
Oh! Sorry, my mistake, I confused the upgrades with the license. Oh well, still sad to only have updates for a year.
I can give you my answer, which does not work for everyone: I don't give a fuck about package management as you say because for the scipy community, the only thing that works is the native packaging system (and by packaging system, I include windows installers and mac os x mpkg). That's the only way we manage to decrease somewhat supporting people issues with installing numpy, scipy and the likes. That certainly explains the focus of my own effort toward something that can be more easily integrated into native solutions.
Sorry. I tried both and I prefer PyCharm. It's faster (on my machine) and looks lots better (even better than Aptana Studio).
For what it's worth, your proposal doesn't feel natural to me at all. In this case set and setXYZ are the same thing, but in other cases that's not true: for key, value in mydict.items() item, price = line.split(',') etc. You can alias functions very cleanly as it is -- not sure why you want to repackage an idiom to do it differently.
Nice, i think i'll give it a go. I'm an avid Wing fanatic though, both because i like Wing, and because it is a good group of guys running it, but i'm curious about charm. On a side note, anyone know if you can give PyCharm custom syntax highlighting/completion instructions? Ie, if you make a new file type .foo and you want syntax highlighting in it, and whatnot.
Anyone know if this is just a bug? Or has the feature creep been contributing to an ever building slowness over the past months? So far i like what i see, but i also agree that it is slow. Too slow to work with for me.. i'd rather be using Wing, by far.
I'm pretty new to Python, and I love PyCharm. If you're starting out on Python like myself, I recommend it. It has a lot of debugging features that come in handy if you make beginner mistakes - like it automatically suggests import functions when you forget to import the right module, it will check for errors and highlight mistakes while you type before compiling, etc. I bet the slowness is a worse trade-off if you're already an expert.
Their java product (IntelliJ) is the best. I may tyry to weasle a free copy of this.
I would totally use this if it were free.
How do you alias them cleanly?
 def setXYZ(self, x, y, z): pass set = setXYZ Not that I think it's a good idea - there are all kinds of bad things this leads to. "There should be one-- and preferably only one --obvious way to do it." 
Oh, right. I guess it was too obvious for me to figure out. And you're probably right that it's a terrible idea. Just a thought.
Compiler to what?
I think he means to compile Python to native code.
See: Cython, shedskin, the tutorial by Jeremy Siek at PyCon last year. It'd be a cool learning project, but from a performance standpoint static compilation of pure python code has no meaningful speed gain.
Cool. Thanks for that. I've recently became very interested in compilers. I might as well do my project for uni with my favorite language. Failing that I probs make my own programming language.
Why? it's not like you're watching scrolling ads in the IDE. They need to feed their kids too. I have no problem paying for it.
Oh well, I guess it's my fault for living in a third world country. I will apply for the student license, maybe I get lucky.
Oh well, I guess it's their fault for not living in a third world country AND wanting to make a living.
damn, that hackerspace sounds so fun, I wish I lived in San Fran.
52.7 Mb? What the hell have they put in there?!?
There are few cooler areas of applied computer science -- make sure you do something awesome.
PyPy maybe worth a look too.
Compilers are cool, without knowing what you need to do for your final project there are lots of compiler related projects you could get involved with (not the least of which is PyPy). Disclaimer: I'm a PyPy developer.
For getting a bunch of heavy lifting done, as in simply crunching a pile of numbers quickly and easily, yes Matlab is good, although I think its syntax and way of doing things can be absolutely awful, and it encourages blindly using toolboxes far too much. However if you want to actually do something with your number crunching, Python has the upper hand by a long way. Mainly because Python is a true object oriented programming language that is written in C, it can talk with C/C++ code nicely and easily. This means you can quickly and easily model a problem in fairly similar language to Matlab, and then embed it in a wider C++ application relatively fuss free. Yes, Matlab also does this, but it lacks decent OO and it costs two arms, four legs and three cows. Try talking to Matlab about licensing fees when you want to embed their environment in a product you want to ship.
Yes.
What nuances threw you? I'm genuinely curious. 
virtualenv does not make version conflict go away. It may help, or may make problems even worse. In the case of big packages like numpy, scipy and co, you depend a lot of other compiled libraries, and you do NOT want them in separate virtualenv. You want all those packages available to everyone on your machine. Keep in mind that most people using numpy/scipy/etc... are not python programmers (often not even programmers at all). They just want to use relatively powerful tools for numerical computation. I like virtualenv myself, I use quite a lot. But it is definitely not a solution to our issues.
most issues I mentioned are not related to compilation - I would be the first to say that distutils should not support nor even care about fortran. The command-based design and its limitation, including the example I gave, are not related to compilation at all. If any point I mentioned is wrong, inaccurate or being worked on, it will be corrected if you let me know.
It's a shame that no one's found a way to freely share software without dying of starvation. Speaking of which, whatever happened to that Guido van Rossum guy? He's probably begging for a second helping of cabbage broth in an orphanage somewhere, I bet.
David, You helped me a *lot* with getting scipy and numpy built on solaris 10 a couple of years ago. I'm still trying to forget what was necessary to get python+numpy+scipy+matplotlib built 64-bit (who the fuck needs to define their CC as "gcc -m64" or "cc -m64" to get a build done? Why does python eat the CFLAGS in some places but not in others? Why isn't there something to let me globally define how I want python modules to call cc/f90 so they don't have to guess? Why do I have to override bits of distutils n times in different ways to get uniform behavior from the compilers?). But I think that experience puts me in a unique situation: I'm a sysadmin, and I've dug into this stuff, and I sure do agree with you. The package management is not python's biggest problem, and I definitely think it's a separate problem from building. What I've seen is that python's distutils makes it easy to do some things that should be easy, but is not well thought-out for the level of complexity required for numpy/scipy. The complexity of dealing with 2-5 C and Fortran compilers per platform where different components are better built with more than one C compiler, and maybe more than one Fortran compiler, along with calling libraries built or shipped with one compiler suite from another (libsunperf/ATLAS/MKL in this case) when in some cases it's necessary to mix them is a real-world problem, since numpy/scipy is currently a marquee use of python. If, as tarekziade says, complex build stuff is not what distutils/distutils2 is for, then all the build infrastructure should be yanked out of distutils and re-thought, because it's a failure now. If the goal is just to version packages and ship installable blobs, that's a worthwhile goal, but the build automation needs to be improved, too. *edit - wrong username
Yeah, this is what I was thinking of. I agree it's not a good idea, but I don't think that makes OP's suggestion any better. For the record, it'd be absolutely *insane* to use set here. (You're overwriting a basic type.) Instead, you could do something like: class MyClass(object): def setXYZ(self, x, y, z): pass m = MyClass() m.set = m.setXYZ Or, since OP has access to the code anyway, he could just do it in the class definition itself.
What's with all the hating on compiled code all of a sudden? Tarek is a big name in Python packaging and you're hugely involved with SciPy, so both of you must regularly run into code that at least depends on C extensions. Not all of it can be absorbed into SciPy. I know that getting it right for pure Python is the first priority, but there has to be some recognition of code that requires external build tools somewhere. And Pip can build extension modules as dependencies right now (if you're nice to it and a bit lucky). To say compiled dependencies aren't worth considering sounds like a step backwards. Is the idea that, in whatever glorious future Python packaging ends up with, there will still be a need for Pip because all the compiling (outside of SciPy) will be its responsibility?
Yes, you can configure that to some degree. You'll get some syntax highlighting, code completion for keywords and some other niceties like brace matching: http://blogs.jetbrains.com/idea/2010/09/custom-file-types-in-intellij-idea/
Why generate machine code directly? You could use LLVM instead, and gain optimizers and support for many architectures. Also, as kinglir says, generating native code that does the same as the interpreter is already doing isn't going to give you any speed gains. You may want to look at psyco, for someone who already does this in a way that really does produce speed gains.
I'd suggest a compiler for python syntaxed static typed language, i.e. Static Typed Python int def funcname(int c): return 3 There are several python syntax like static compiler to VM like JVM or MONO VM but none for native machine code. A static typed Python front end for GCC or LLVM would be great! 
I don't know what your university requirements are, but if possible, try to add functionality to an existing project rather than starting a new one. This will benefit the community more and might let you focus on more interested aspects of the problem because some of the basic work might already be done.
Your post is inaccurate, yes. But I don't think you really care about that. We had a GSOC student who worked on a config command to improve the option sharing story, and I asked you if you could help him, but you ignored us. 
pip does not do anything with extensions - pip just uses whatever is used underneath (setuptools, and maybe distribute now, dunno), and neither setuptools or distribute do much w.r.t. compilation anyway. Everything related to compiled code is done by distutils (or numpy.distutils in the case of numpy/scipy/etc...). But the problem is not the detail of what those tools do - it is about providing the right abstractions so that people can extend their build configuration without having to care about distutils idiosyncraties. For example, my own distutils alternative does not have a single line of code to deal with compilation. It uses a build tool, which can be distutils itself (for compatibility) or anything you like. The parts that build sdist, eggs or windows installers are completely unaware of the building stage. Right now, nothing in distutils2 will make it easier for numpy.distutils to work reliably if called from pip: that's the core issue. It would be unresonable (and unproductive) to ask distutils2 to deal with fortran.
Actually they live in Russia, Sankt-Peterburg city. But living is not cheap there too.
This already existsts and is called Cython.
Hm, it doesn't seem to cope well with from x import *. Wing does it fine if __all__ is defined. (I know it's bad style but my model objects are just too many, DRY)
[PEP 3146](http://www.python.org/dev/peps/pep-3146/) is an interesting read too regarding JIT for CPython (though 2.6.4?!)
&gt; the tutorial by Jeremy Siek at PyCon last year [Link](http://pycon.blip.tv/file/3263942/)
and, if you manage to really understand psyco, you can apply for a Phd in mathematics and computer-science combined.
I haw one extra code for 50% if somebody wont it msg me.
First it's really really nice ... but i have several problems with it in a buildout environment. We are using repoze.bfg and zope, i use a egg cache ~/.buildout/eggs/ for all my buildouts (python2.4 and python2.6). now here my questions: 1.) where is a documentation for using buildout support? 2.) how can i add only python2.4 eggs from the buildout egg cache to my zope project and python2.6 eggs to my bfg projects? 
It's been posted about a bazillion times here. And because of the licensing, mostly.
If I ignored the request to help for a GSoC student, it was because I did not see it, not because I willingfully ignored it. I did not know about the configure work by Eric Araujo before you mentioned it in your answer. Also, you should try to avoid giving malicious intent to people who disagree with you.
Wasn't always the case, but these days, Python is actually a pretty big language, spec wise. For a school/learning project, I think you'd get much more out of writing a compiler for a significantly smaller language, like JavaScript or Lua. That would keep you away from having to do boring, repetitive stuff like implementing static methods and class methods, but still allow you to do cool stuff like figuring out how to implement coroutines in a compiled language. Also, if you're aiming to do something that is useful to others, do it as an LLVM frontend. Your code will be significantly faster and plug right in to other peoples development environment.
He's on "the google" payroll. There are free alternatives you know, the market can support both and you are free to use them.
http://www.python.org/dev/peps/pep-0008/
ClassNames, modulenames, everything_else. edit: OH\_NOES\_FORGOT\_CONSTANTS
PEP 0008 is the true religion.
I'm aware. The idea that you need to charge people for your software or deny them the use of it, or more importantly that you need to keep the source a big secret for the sake of your business model, is a pernicious one, especially since the proportion of programmers whose living depends on the sale of the software they write has never been more than about 5-10%. The idea that one could not make a living by writing free software is not just technically false for atypical cases like Guido; it is false for most programmers. (By this I mean; if you write in-house software for an insurance company or whatever, there's ultimately little practical reason for the company not to free their source, since it was written for use-value and not for sale-value.) The cash-for-secret-bits business model is actually in a stark though highly publicized minority. Intuitions about the utility and fairness of transactions concerning goods with zero marginal cost are notoriously suspect; it is easy to imagine the utility that might fail to accrue to the pycharm developers if they didn't charge for their product. It is very difficult, however, to imagine the disutility that accrues to everyone in the world who could have benefited from the software, like dohko_xar, but couldn't meet the market price and couldn't effectively benefit from price discrimination. The only conceivable reason to tolerate intellectual property is the belief that it tends to promote utility, and whether proprietary software does this is becoming increasingly unclear to me. Speaking personally, the work that I do now would be basically impossible without free software, and if anyone ever asked me for one of the programs I wrote (with a free language on a free operating system), I would find it difficult to provide any reason not to share what others had shared with me. Ultimately you have a finite number of years to use computers to help you solve problems and think beautiful thoughts--do you want to spend them telling people like dohko_xar "not unless I get paid"?
Variable...
I do the same, but I use uppercase for constants, for example, I'll define black as BLACK = (0, 0, 0). When I say constants, though, I mean universal constants. Sometimes there are variables that won't change during a program's execution, but I just treat them like everything else. I only use uppercase for those variables that I will never, ever change for any reason.
This is the only way to go. Also try the [pep8 program](http://pypi.python.org/pypi/pep8) from pypi to help you with this. Especially if you come from other languages and confuse the hell out of yourself (like I did).
The question is: how would you do type inference ?
We have a lot in common. We should make out sometime.
Same. Including all caps for constants as per Norseman2.
"Yo dog, I heard you like programming so I put Java in your Python, so like you can be slow while writing slow code." /sarcasm
Much too slow, virtually useless, even for free.
I've had this question in the back of my mind for a while about pypy, maybe you could answer it for me... Would there be any performance benefit in pypy if the parameters to functions and methods were statically typed?
Upgrade, and if 6 months when a new version is released, you pay the upgrade again. It is a good IDE, but I don't know if there is enough utility to purchase it multiple times a year. I don't mind paid upgrades when significant functionality is added, but not if the frequency is more than once a year. I also don't buy into "upgrade protection". License the software individually, or make it a subscription model. Not both.
doctest is a harsh mistress. The nose doctest support plugin... is not short. Edit: I fail at Heilein.
this could use some more context, pypys translator toolchain infers static types for function parameters when compiling down to a lower level environment
actually it can be quite a challenge, after all you are not coffined to fixing typos, you could add new functionality or solve a particular unsolved problem in one of those projects
Ah! How does it do that? I guess to be more precise what I mean is, would there be any added benefit by adding *explicit* type declaration to functions and methods (if that were a hypothetical feature of the language)?
So I have started LPTHW last night about 10pm and am on lesson 15 - I think its great but would have one suggestion for people doing it. I read about half of it before I started any lessons, this made it actually much easier to do the lessons as I had a bit on context when I began to type them all out. I am an expert autocad drafter - and I had only done one book when I was in highschool - the abc's of autcad - which had tutorials like this book. I did that book's tutorials like 8 times in a row and never had to look at another autocad book again. I later taught autocad. I really like how LPTHW works, thanks for the suggestions. After I am done with this, ill do the google [lessons here](http://code.google.com/edu/languages/google-python-class/introduction.html)
Another example in my case: Have a Linux filesystem with filenames in several encodings. (Not good to have, but too easily obtained while migrating to a full-UTF-8 distro *and* synching files with Windows with various bad settings.) Don't trust Perl tools that promise to autofix it. ;-) 1) For each file and directory name (recursively in the current directory), try to parse as UTF-8; report all encoding errors in the name; in case of error, print ASCII characters as-is, print bytes that have the 8th-bit set in hexadecimal with some kind of separator from the surrounding characters (so you can really see what's "in" the file name) 2) For each encoding error, print the corresponding byte(s) in various candidate encodings (that is, convert from candidate encoding to utf-8, and print that) 3) Make the output work both with terminal output and in pipes (maybe easier and/or solved in Python 3) 4) Create a UI (maybe semi-graphical, e.g. curses) to help the user change the problematic names (utf-8 shells have issues with 8-bit, non-utf8 file names) In the process, become somewhat expert in encodings, utf-8 and bit-twiddling. Ain't that fun? :)
That's also how reddit decides what part of an image will be the thumbnail of a submission: [http://code.reddit.com/browser/r2/r2/lib/scraper.py#L57](http://code.reddit.com/browser/r2/r2/lib/scraper.py#L57)
Ergo, the unittest module is heretic.
This shouldn't be a question. PEP8. Read it. 
If you're into compilers, working on PyPy will let you experiment with cutting-edge optimization methods. There are a lot of possibilities there..
Haven't been around long?
PyPy's translation toolchain infers types for *RPython* which is a statically typed subset of Python, that PyPy's interpreter is written in. It cannot infer types for Python programs in general. That said the JIT is very good at figuring out how to properly specialize your code, but if you give it blatant things like `assert isinstance(x, int)` I can't image it'd hurt.
cool, Whats the reason for using _ in the line: _, file_name = sys.argv is that a convention i don't know about?
Just a value you don't care about. I think I saw it somewhere, not only in python but probably in ocaml, and maybe somewhere else. But note that in interactive mode _ has a special meaning: it's a value of previously evaluated expression: &gt;&gt;&gt; 2*2 4 &gt;&gt;&gt; _-1 3
Plenty fast enough for me with a pretty large project on a two-year-old MacBook Pro with 4GB (and heaps of other stuff running). Some of the people complaining about speed may be judging it by the initial minutes when the whole code base is being analyzed. Used PyDev before and it was fine — really good for a mostly-one-person project. Wing seemed fine too, but I'm on a Mac and the X11 impedance mismatch caused some problems and also just “felt bad”. I've been using PyCharm (early-access versions) full-time for months and I find it is unequivocally worth the tool transition time, let alone that pittance of money.
here's what happened with me: Problem: need a webapp to do this that and other thing. Instinct tells me to use PHP. Every PHP framework for MVC/webapps sucks. So check out Django as an attempt to dive into Python. Problem: Django simplified my life quite a bit, but there are things about Django I personally think are retarded. So, figure out ways to work around them, bringing me further away from django specifics, and more into Python. Problem: Great, my webapp is coming along, but there are other services I need to make. Why increase my technology stack, just write it all in python! Now I'm doing non-web related work in python. And voila, I'm learning Python. I'm also a beginner at python, but I've coded in several different languages. I've learnt by first googling for python libraries that do what I want. Eg: I needed to do some multithreading or other kind of multi-process task management. So I googled Python Multithreading and lo and behold, documentation and tutorials! I wanted to convert MP3 to WAV, google that, found a basic lib to help me out. Then I looked into the source of the lib and learnt even more. Poking and prodding, hacking and slashing, and figuring it out as I go along and that's how I am leaning python.
Interesting. I'd be curious to get a comparison of memory used as well...
Not much. The whole point of the JIT is that it does type inference at runtime when types are known.
Right, but my (very rudimentary) understanding of JITs is that much of the cost is at start-up when the JIT is establishing different options or paths for different data types and values. Intuitively, it seems to me that having static type declarations (for instance as an optional decorator) could offer a speed-up at start-up in certain circumstances. My question is more theoretical than practical.
for a noob like me, are there any major show stoppers to stop me from using pypy instead of CPython?
Cython and Shedskin only offer a subset of Python (neither provide closures or generators, for example, and Shedskin doesn't have bignums -- rather nice for Project Euler). I suspect most of his solutions wouldn't work as is, and in the case of Cython would have to be extensively modified to see speed advantages. And he appears to be a Linux user, so I doubt IronPython would confer much speed advantage.
How would you find it? ps? pmap? Digging around in /proc?
The Shootout samples top at set intervals, I think.
Interesting. Unladen Swallow did a lot worse than I would have expected -- unfortunate that it isn't getting a whole lot of developer attention at the moment. If Scipy were available for PyPy I'd be all over it.
I'm thinking something like SimpleHTTPServer. Any other suggestions?
i use python for reasons completely unrelated to the web, which is why i had no idea.
Shedskin isn't quite 100% compatible with Python. So I think most of these programs would fail, unless you spent time porting them to Shedskin. (Which the author of Shedskin has done, BTW. I believe he said that he got the overall time faster than psyco.) Cython is in the same boat. It doesn't support generators yet, for example. And you need to manually add static types to your code with "cdef" to get big speedups. So, while Shedskin and Cython are useful to some people, they're Python variants rather than alternate Python implementations, and thus not really part of the same conversation. IronPython, yeah. If Jython is in then I guess IronPython should be in too. I'd expect it to also do poorly.
&gt; I'm stuck on a Windows XP machine at work so ? welcome to the club... why "minimal installation" ??? just install Python and do your shit....I'm thinking I'm not understanding you
Sorry, I mean like not have to install Apache or something. I do have Python installed.
There was some effort to port scipy. It's definitely on the radar. What made you think US would perform better by the way?
It's still at Python 2.5. It can't run all CPython library code written in C. (It can actually run some, but the bridge code that enables this is still experimental.) 
Depends what you want to do. If you need a library that uses/is a C extension (e.g. psycopg, mysqldb, PIL) you're more or less out of luck (we have alpha support for the CPython C-API but it's alpha and not very fast).
He could simply put "broken" when they don't work for one of his solutions, it would give an idea of how much of python they implement.
How about memory usage? Any significant difference with CPython if I'm, say, creating tens of thousands of smallish objects?
Is it just me, or has it suddenly started looking abysmal on Ubuntu 10.10? 
&gt; There was some effort to port scipy. There was a summer of code project to port Numpy but I'm not sure it's stable yet. Scipy would be rather more difficult than that, I imagine. &gt; What made you think US would perform better by the way? Honestly? I dunno. I just figured that with all the attention and talent it received, with the primary purpose of speeding up Python, it would at least give an appreciable speed increase over CPython. This is just one set of benchmarks, and maybe not even a terribly realistic one. But fewer wins and only a 10% speedup doesn't seem that exciting.
PyPy's objects are generally smaller than CPython's (sometimes quiet significantly), however the JIT also uses more memory as it has to store machine code and various bookkeeping data. Our steady-state interpreter size is also larger (just due to having more code for a JIT). Over a large number of objects I'd expect us to be smaller.
&gt; There was a summer of code project to port Numpy but I'm not sure it's stable yet. Scipy would be rather more difficult than that, I imagine. It's not quiet stable yet, but it's progress (and showing decent performance results. PS: fijal knows this, he's one of the PyPy developers and the mentor for that student.
Ah, ahem, I knew that, I was just testing him. ;)
Find a way to effectively remove the GIL.... Now there's a challenge. :)
The author looks like a Linux user. Even if he has/had a Windows box, it'd have to be exactly the same for the comparison to be fair.
Ah. Makes sense. Mostly I do too -- but what were the 'Digital Creation' guys have been around a long-o time. I stumbled across them in 1996? 1997? Anyway -- that explains that. Thanks!
Or perhaps make a message passing microthread system where the microthreads can actually run on all the processors (in parallel). Nearly all of the microthread/greenlet/tasklet libraries for Python are still limited to one processor (because of the GIL).
I don't know much about pypy C API bridge, but I would suspect scipy to be much easier to port than numpy. Numpy uses the C API quite heavily, beyond what most C extensions do - for example, it provides its own C API, needs to register new types, etc... Scipy, OTOH, uses the C API in a very straightforward way, and most compiled code are pure C libraries anyway.
IronPython startup time is still pretty slow, so a lot of these really short running scripts would look pretty bad. Overall it's not so bad once it gets going.
Thanks for the hint. It led me [here](http://shootout.alioth.debian.org/help.php), which says they use libgtop every 0.2s. Another option I found is /usr/bin/time --format='%M' program
The current benchmark only shows programs that work and finish in less than a minute on all implementations. If some of the Pythons can't run some of the programs then the idea of cumulative time becomes kind of fuzzy.
I'm still blown away by the fact that the Python community has developed a Python interpreter in Python which has surpassed the speed of CPython. Just another reason to love the community.
Presumably that constant "figuring out" time is dwarfed by the actual running time of the code.
I think that `filename = sys.argv[-1]` will be more robust. 
Whatever time that a C compiler would see int i = 0; as an integer. There are distinct structures for "primatives": i = 0 id, assignment operator, digit ---&gt; int d = 0.0 id, assignment operator, digit, . token(can't remember the proper term for it), digit ---&gt; double s = "Foo" (or 'Foo') id, assignment operator, " token, lots of letters, closing " ----&gt; string list_l = [1,2,3,"foo",'bar'] id, assignment operator, [ token, some stuff, ] token ---&gt; list tuple_t = (1,2,3,"foo",'bar') id, assignment operator, ( token, some stuff, ) token ---&gt; tuple dict_d = {'Foo':bar, tuple_t:list_l} id, assignment operator, { token, some immutable key -&gt; some value pairs, } token ---&gt; dictionary As you can see they are pretty distinct so it's not hard(I hope) to evaluate them properly.
I've had great results speeding up things **FIFTY TIMES** with [Cython](http://www.korokithakis.net/node/109)/[shedskin](http://www.korokithakis.net/node/117). They aren't part of this conversation per se, but they're part of the "how can I make Python go faster" conversation, and very much ahead of the pack.
It compiles to C, and thus native code. It's not like it runs on top of CPython. Other than that (or, well, partly **because** of that), it's an amazing achievement.
No. In a presence of len(sys.argv) == 2 check they are equivalent. And if you imagine for a second that this check is absent (or done wrong), you variant has a property to silently swallow several arguments, which is confusing to user at least. Oh, and also it masks the fact that this check is implemented incorrectly, if that was the case. Anyway, for some strange reason it reminds me of a [duck](http://stackoverflow.com/questions/2349378/new-programming-jargon-you-coined/2444361#2444361).
He says: &gt; its worst result is on euler96, a Sudoku solver that heavily uses sets and copy.deepcopy. But it's not in the table. Did he mean 94 instead of 96, or did he pick which benchmarks to run?
One thing I find surprising is that even the fastest and most advanced Python implementations, like PyPy, are still slightly slower than the basic Lua interpreter, which is a plain old bytecode interpreter. Meanwhile, LuaJIT is an order of magnitude faster, and is almost approaching C speed. All of this, and Lua still uses half the memory of Python, too. Not bad for a dynamically typed language with comparatively little publicity behind it. I guess the fact that in Python even integers are heap allocated objects really hurts performance a lot, or something. All of this according to the [Programming language shootout](http://shootout.alioth.debian.org/u32/which-programming-languages-are-fastest.php?calc=chart&amp;gcc=on&amp;luajit=on&amp;lua=on&amp;pypy=on&amp;python=on&amp;python3=on).
Based on 94's poor performance I'd guess that.
*(By this I mean; if you write in-house software for an insurance company or whatever, there's ultimately little practical reason for the company not to free their source, since it was written for use-value and not for sale-value.)* Most companies order custom made software so that they could ultimately be ahead of their competitors, so they see it as if releasing the source would be paying for nothing. Usually you can haggle some parts to be open-sourced if you try though.
I have a year old gaming laptop - it's slow for my big projects and I am judging it based on many hours of work. Occasionally it speeds up, but then it goes back indexing or doing whatnot in the Javas. 
I see only bright things in store for PyPy. In a couple of years this will be the de facto standard :) btw. their **rpython translator** is one of the most awesome things in the Python world. Check it out! [Not for total beginners] What does it do? Well it (very roughly speaking) just translates Python[actually a bit strickter version of it] to a native executable... very cool :)
Yes! Fly my pretties !
Not sure why you were modded down, this performance is acheived by translating the interpreter written in Python (more accurately: RPython, a restricted subset of Python) into C, and adding in a JIT (automatically by source code transformations).
Thanks a bunch.
Reminds me of Squeak.
This is a well-trodden path. It doesn't really work because Python is so dynamic. See Brett Cannon's PhD thesis. Just because 'a' was an int the first time doesn't mean it'll be an int again the second time. So the language doesn't statically compile well, because there's not enough information at compile time to get the types right. (Of course you can force the user to add type information, but now you have a restricted version of Python. See Cython or Shedskin.) For example, in Python 2 (where int and long are distinct) on a 32-bit box, imagine a loop that just increments a number starting at zero. It will be an int for 2 ^ 32 iterations, then it will become a long. If you assumed it would stay an int, then your code breaks after 2 ^ 32 iterations. A JIT (see psyco, PyPy, Unladen Swallow) works much better, because the JIT can compile the fast path based on types it's seen at runtime, and it can later safely fall back to the interpreted path if a variable's type changes. (And then possibly compile it again with the new type if it stabilizes.)
Yep, Smalltalk is a language with a metacircular interpreter: http://en.wikipedia.org/wiki/Meta-circular_evaluator#Examples
Thanks for the informative response. I'm still trying to work out the implications, though. If calling the C compiler with the right options is distutils' job, doesn't that make it important for distutils2 to be able to do it too?
One option that will always work is to get a VPS plan.... this is guaranteed to let you run Python programs on the server as well gives you the ability to update Python and install various libraries that you may need for your Python program. This is more costly (and complex), however. There are other options (that are probably cheaper and easier) if the website is simple enough... but I am not exactly familiar with those.
I wish NumPy &amp; SciPy were usable on anything but CPython :(
So, what kind of overhead should one expect? hmmm, I did try to use pypy and my program took hundreds of Megabytes more memory. Is this to be expected?
No, definitely not expected. If you could put together a test case for us that'd be great, you can either file a bug at https://codespeak.net/issue/pypy-dev/ (we had a ton of spam so FYI the permissions might be wacky) or hope into #pypy on freenode.
Thanks dude, I'll have a gander but it's no biggie if it can't be done or is a pain in the ass to do so. I got plenty of alternatives and have plenty of other ideas to choose from for my final year project.
It is.
How I wish you could write modules with RPython, it sounds much more useful than PyPy itself. Slow code? Rewrite it a bit, compile it and now it's 50x faster, rather than the whole thing being 2x faster.
I don't understand... care to elaborate?
Another useful thing you can do is pass an object to help() when you call it. The help() docs for at least some things (e.g. the `new` module) are more complete than the standard docs.
Are you sure it matters? Most well written NumPy/SciPy programs I've seen are written in the same style as well written Matlab programs - there are very few loops in the Python code, and instead the programmer figures out clever way to replace the loops with clever use of matrix algebra. This way, linpack and friends get to do all the heavy lifting, and you end up with an application that is significantly faster than anything you could write in C. Such well written Python programs spends extremely little time in the actual interpreter. Maybe you have a use case where some of the heavy computing tasks are completely unsuitable to a linear algebra library, but otherwise, I think you'd be disappointed at the result of switching to PyPy.
Is there an equivalent of numpy/scipy for lua?
Lua semantics are simpler than python. Lisps are another good example of languages that are both fast and dynamic. Also I heard that Lua implementation is exceptionally clean and well written.
Sure, Lua has simple semantics, but I must say that Lua does not lose expressive power because of it. I just started using Lua a few days ago, and IMO the language blows me away with it's combination of minimalism and expressive power. Objects and classes are implemented as tiny amounts of syntactic sugar on top of regular tables. Modules and namespaces are also implemented as tiny amounts of syntactic sugar on top of tables. The entire language is like that. Python gives you many extremely useful things with rather limited use cases, like lambdas and the yield statement, Lua gives you fewer tools to do the same thing but also so much more, like anonymous functions and coroutines. The number of features in Lua is tiny, but each feature is so well thought out that it serves a huge number of different purposes extremely well. There are a small number of annoyances, like the fact that arrays are numbered from 1, which isn't a problem in itself, but it quickly becomes infuriating when you spend half the time writing C code and half the time writing Lua code that uses said C code. Also, the Lua standard library looks like a ghost town compared to Python.
I'm still a Lua newbie, but looking around, there is a numerical package called Numerical Lua, and also a pretty crazy project called Lunatic, which is a two way Lua/Python bridge. It lets you use scipy and numpy by writing require("python") numpy = python.import("numpy") numpy.array(32) Don't know how well it works in complex edge cases, though, and you're likely to have some signaling overhead as well. In the end, the Lua standard library looks like a ghost town when compared to Python, which is obviously something that makes it almost useless as a general purpose language. Not as bad as JavaScript, but still. It _is_ extremely useful for embedding into other products, though, which happens to be its intended use. All of Lua takes around 10 seconds to configure and compile on my machine, and the entire library is something like 100 or 200 kB.
I just noticed that BDFL is working on App Engine.
Wow your one question resulted in a lot of comments. So i will add my own. There is much in the web world that hasn't been ported to python 3.x yet. For this to change the fixes that this alpha release tests will have to work well. So many of the webs python code base transitions are on hold. Don't take that to mean Python 3.x is on hold though for other uses. In fact to the contrary i find it to be a better place to develop. Especially for scripting system tasks. As others have mentioned other libs are coming on line, so outside of the web there are fewer and fewer reasons to put off 3.x. Personally I like the idea of writing strictly for Python &gt; 3 as it leaves with the thought that the code will have an extended future. Once 3.2 solidifies and port can commence I think we will see The 2.x series Pythons abandoned rather quickly. I know that isn't the general thought in Python land but there will be little reason to aggressively support Python 2 series in a couple of years. In the end i think people will come to see 3 series Python as the way forward. Once that happens there will be little looking back. 
Anybody interested in building large/extensible applications with a flexible component model should take a serious look at what the Zope Toolkit offers. Particularly zope.interface, zope.component and zope.schema.
Except that Slang (the restricted Smalltalk that Squeak uses) is a much more restricted language than RPython, without garbage collection and without interesting data structures. Slang is basically just a language skin over C.
I'm working on memory usage, both on investigating how much memory PyPy uses and on improving it. Will still take a while though.
Are you on platform where you frequently generate postscript files but lack a command line utility for converting them to pdf?
Python and Ruby design seems to be mostly from the top. Design is decided without much consideration for the complexity and the speed of the implementation. Lua has more of a minimalist spirit, the complexity of the implementation seems to be at the heart of the design decisions. &gt; the Lua standard library looks like a ghost town compared to Python. This is probably the main issue. Also I would argue that Python syntax is nicer and cleaner, but not really more expressive I agree with you on that. 
This is a comment about using a real editor like vim/emacs.
I just noticed there is a programming language called [Guido van Robot](http://gvr.sourceforge.net/) by googling for "GVR".
I was compiling the PyPy trunk for an hour. It gave me a lot of errors, but seems to work now. And for some reason it is printing the Mandelbrot fractal while compiling self. 
Well, it makes sense to sell individual licenses but also offer a subscription model for regular upgrades and tech support. When I eventually migrate to Komodo IDE, I will make sure to get the subscription while I'm at it. The "you get what you pay for" policy of licensing only the exact version you purchased may be disagreeable, but the concept of "paid upgrades" is hardly novel. That does pose a question though: do they provide non-paid maintenance updates (security patches, bugfixes, etc)? Or do they just pile those up for new releases, thus enforcing a short release cycle?
I've had success using them with Cython. With a few tweaks (basically just telling Cython what C types to use), I see large performance gains.
Yeah, the language with the 1 based indexes? Who cares how fast it is. 
Distutils calls the right options for the (quite common) case of simple extensions built with the same compiler as the one used for python itself. The problem is when you need to modify those options, add a new compiler (distutils does not support cray platforms very well for example :) ), or want to link against different libraries. Distutils do not have the abstractions to do that (and adding those abstractions has been attempted several times already, all ending as failures). The alternative packaging tool I am working on has hooks to register extended compilation enviroments so that you can modify any option for a specific extension if you wish so (see e.g. http://github.com/cournape/scipy3/blob/_bento_build/scipy/special/bscript, although the API still needs a lot of work). Ideally, you should be able to plug any build tool you want in the process, and the packaging tool should be designed as library so that the concerns of configuring, command line UI, building, installation and packaging are separate.
"pypy/translator/goal/translate.py -Ojit" takes almost 2 hours for me lately. (It used to be faster, but the jitted code used to be slower, so I'll take that tradeoff.)
&gt; In the end, the Lua standard library looks like a ghost town when compared to Python, which is obviously something that makes it almost useless as a general purpose language. I used Lua for a small project a few months ago, solving a stochastic dynamic program, because it was mostly algorithmic and I wanted to see how LuaJIT would fare. (Pretty durned well, as it happens.) And yeah, the anemic standard library was a bit of a deal-breaker. I haven't used Lua since so I don't recall what my specific issues were, but I ended up writing a bunch of (ad hoc, probably slow, bug-ridden) convenience functions. The REPL was painful; it's odd to me that no one's written a better one (though there's a quick hack out there somewhere that makes it slightly less irritating).
Yeah, the prompt is bizarre, isn't it? I still haven't wrapped my head around why it completely refuses to parse some code, e.g. the hash operator simply doesn't work from the prompt for some reason.
Much of the time you can vectorize easily, but sometimes it's simpler and clearer to use a loop, and sometimes it's difficult to avoid writing a significant amount of logic in Python (or Matlab, or whatever). At that point something like PyPy would be nice to have. But even if that's not the case for any particular application, you wouldn't *lose* anything from using SciPy from PyPy rather than CPython -- and you'd have its speed to fall back on when you wanted it.
very handy, thanks. maybe [link] = br.links(url_regex=r'\.pdf') looks better? don't be serious.
Fair enough.
Haven't used them personally, but writing stuff in Pyrex or Cython (basically a language that is mostly Python with the ability to use static typing for optimization, and that compiles down to near C speed) might be what you want. http://www.cython.org/ 
Now I'm not sure why *you* were modded down.
&gt;do they provide non-paid maintenance updates (security patches, bugfixes, etc)? Yes, within the same major release version.
Works once, but if you try try to run that sort twice on a given list, it fails: &gt;&gt;&gt;ls = [2, 1, 2, 3] &gt;&gt;&gt; print(sort(ls)) [1, 2, 2, 3] &gt;&gt;&gt; print(sort(ls)) Traceback (most recent call last): File "&lt;stdin&gt;", line 1, in &lt;module&gt; File "&lt;stdin&gt;", line 1, in &lt;lambda&gt; TypeError: reduce() of empty sequence with no initial value &gt;&gt;&gt; 
As much as I dislike 1 based indices, especially in a language who's main use is to integrate as a scriptinglanguage to usa alongside other languages that all use 0-based indices, that's a really silly thing to base your language choice on. 
http://bottle.paws.de
ALL\_CAPS\_ALL\_THE\_TIME ;0 ... j/k +1 from me
In my experience it's impossible to vectorize *every* piece of code.
Obfuscated Python feels so wrong to me. Like kosher bacon.
To be clear, the PyPy implementation is written in a restricted subset of Python called RPython which is converted to C. Python programs running under PyPy are not converted to C (and couldn't be in general, because they are not RPython). I assume you were initially down-voted because your post can be read as if the conversion to C were part of the process of running a Python program under PyPy, which is what I thought you were saying at first.
Oh, I remember one thing that annoyed me ... there wasn't any way to define a hash function for a type, so if you wanted to use an object as a table key you had to do something gross like stringify it. I'm honestly not sure at this point if that was a *genuine* problem for me or just something I got a bug up my ass about.
Yeah, what I tried to say was that in apps that use SciPy, the parts that can't be vectorized are rarely very performance critical. 
Not always though. There are lots of algorithms that will need loops and/or conditions, and I think a JIT would really help. MATLAB added one a few years ago and it made a huge difference.
Thanks, looking forward to it.
I think you should win a consolation prize for calling that a "fun" quiz ;)
That's really impressive work. While I approve of your default units (meters, seconds, grams, etc.), certain fields do use different defaults. (In engineering, it's not unusual to work in cm space, and a lot of the world might want something other than $USD). Would you consider making various defaults a set-able parameter? Regardless, this is, as I said, impressive. Especially since it's ~300 lines of code (lots of comments!) in a single flat file. I can see it getting a lot of use in undergrad intro physics labs.
I would have included __dict__ and inspect module. I think these are the most powerful tools for introspection in Python along with dir. 
&gt; You got 27 out of 31 Python reserved words. Booh for me!
Interesting how many missed `assert`: only 30% guess right at this time of writing. (I was writing test case prior to doing this quiz yet still miss it.) `exec` being the most missed is perhaps a good thing?
Anyone is aware of undesired side effects while using this? Any benchmarks (of course it will depend too much on the code base, but still)? I'm too lazy to find out by myself? :wink: PS: by the way, thanks for reminding me of this recipe.
The default is only the internal representation so it should not affect input/output as long as you use "convert" to get the output values. You are right it says dollar. I just changed it in trunk to include "currency" so you can use that instead of dollar. yet it is not designed to do currency conversion because that is a total business so "dollar" is synonymous of "currency". 
I'm gonna use this. Thanks!
This looks nice. If you have need for arrays of numbers, you may want to check out [python-quantities](http://packages.python.org/quantities/user/tutorial.html). It works with numpy arrays and has unit conversion and error propagation also. It's not quite as lightweight as your module, though.
Are you aware of the [quantities](http://packages.python.org/quantities/) package? Its much much larger, but available through pypi/easy_install/pip, and its really good; it even handles uncertainty and error propagation.
Cheat sheet: &gt;&gt;&gt; import keyword &gt;&gt;&gt; keyword.kwlist ['and', 'as', 'assert', 'break', 'class', 'continue', 'def', 'del', 'elif', 'else', 'except', 'exec', 'finally', 'for', 'from', 'global', 'if', 'import', 'in', 'is', 'lambda', 'not', 'or', 'pass', 'print', 'raise', 'return', 'try', 'while', 'with', 'yield']
Ah, yes. I meant what you said, of course.
ShedSkin is even easier than Cython, and about as good. There are many alternatives, but I don't see why another one shouldn't exist, especially when all it needs is a bit of polish (we already know it works very well)!
Perfect! Saved.
Wow. Simply wow. This is really cool, and extremely well implemented. But, seriously, show the chemists some love and give us Angstroms (10^-10 m) and kilocalories!
amazing! any chance of doing this for the Django docs too? or even better, have a way to convert master documents to vim-help, Django uses reST http://docs.djangoproject.com/en/1.2/internals/documentation/ edit: it seems the Python docs are also reST but Jeet I think there's some leftovers from the previous markup in the resulting help such as double backticks and so (not sure if they were meant to be there or not).
Neat. I needed to do math with units the other day, to see how long it would take to clone a hard disk. 1 terabyte / 72 megabytes/s = 4 hours. (Actually took 4.5; the transfer rate slowed over time.) I thought of using Frink, a language designed for just that. But it wasn't installed and I didn't feel like building it. Then I tried typing it into Google, which worked. If Google had failed, I would have looked for a Python module like this next. (Yes, I could have just used a calculator and manually turned tera and mega into the proper powers of 10, but that seemed more error-prone than using a unit-aware tool.)
Python, for people who think they know better Python than people who supposedly think they know Python: if len(kwds) &gt; 0: can and should be if kwds:
For the 76800 points in that game, I'd say use OpenGL. Don't forget to use display lists where you can, that will speed up execution considerably.
I just re-posted with some fixes and more tests. Make sure you have the latest.
done, angstrom and calorie (along with some bug-fixes)
An alternative (lazy but highly effective) method is to encode each of the candidate frames to jpeg and just pick the one with the largest file size.
This looks really useful. There is also 'dimpy' that I have been using for the last couple of years: http://www.inference.phy.cam.ac.uk/db410/
I like how there is *megadollar* as a unit :)
Why "should"? Is it faster?
This is some really great stuff. I'm a big fan of GNU units and Python so this is double tasty. Some suggestions for additional units: * bits and bytes, including difference between MebiByte (MiB) and MegaByte (MB), etc. * temperature, pressure 
Yes, but more importantly it's easier to read.
Your suggestion *used* to be a good Python idiom. No longer. Running code with your suggested construct through unittest under Python 2.7 results in: "The behavior of this method will change in future versions. Use specific 'len(elem)' or 'elem is not None' test instead. " 
 units '1 TB / (72 MB/s)' hours * 3.8580247 / 0.2592 [GNU units](http://www.gnu.org/software/units/). The first line shows the direct conversion, the second its inverse.
Faster, yes. Let's see by how much: &gt;&gt;&gt; print timeit.timeit('if len(kw) &gt; 0: pass', 'kw={1:2,3:4}') 0.120980466472 &gt;&gt;&gt; print timeit.timeit('if kw: pass', 'kw={1:2,3:4}') 0.0642829687093 But why? Let's break out the `dis` module to find out. &gt;&gt;&gt; import dis &gt;&gt;&gt; def test_len(**kw): ... if len(kw) &gt; 0: ... pass ... &gt;&gt;&gt; def test_if(**kw): ... if kw: ... pass ... &gt;&gt;&gt; dis.dis(test_len) # Show what python has to do for test_len 2 0 LOAD_GLOBAL 0 (len) 3 LOAD_FAST 0 (kw) 6 CALL_FUNCTION 1 9 LOAD_CONST 1 (0) 12 COMPARE_OP 4 (&gt;) 15 JUMP_IF_FALSE 4 (to 22) 18 POP_TOP 3 19 JUMP_FORWARD 1 (to 23) &gt;&gt; 22 POP_TOP &gt;&gt; 23 LOAD_CONST 0 (None) 26 RETURN_VALUE &gt;&gt;&gt; &gt;&gt;&gt; dis.dis(test_if) # Show the other way 2 0 LOAD_FAST 0 (kw) 3 JUMP_IF_FALSE 4 (to 10) 6 POP_TOP 3 7 JUMP_FORWARD 1 (to 11) &gt;&gt; 10 POP_TOP &gt;&gt; 11 LOAD_CONST 0 (None) 14 RETURN_VALUE &gt;&gt;&gt; The simpler version avoids a function call (`len`), a comparison (` &gt; 0`) -- of course, you could cut it down with `if len(kw):` without the `&gt; 0` part, but it only cut two opcodes out. Now, if you get beyond `dis` for this case, it ends up calling the same code. A dictionary does not have the short cut magic method `__nonzero__`, but it does have `__len__`, which gets called in both cases. The main difference avoiding a Python-level function call. This is over optimization, of course, unless your code is going to get executed a lot. Edit: This was under Python 2.6.
Why the deprecation of the idiom? It does not make sense to me after looking at [this](http://www.reddit.com/r/Python/comments/drt3p/python_for_people_who_think_they_know_python/c12f8ee). EDIT: It still works in Python 3. &gt;&gt;&gt; if []: ... print("AAA") ... &gt;&gt;&gt; if ['a']: ... print("AAA") ... AAA 
What will it change to, and why? I don't get why bool() for an empty iterable should result in anything but False and if empty ``**kwargs`` is going to be a None then len() won't do because None is not Sized. ``is not None`` could make sense but I don't see a reason to change empty kwargs to be None. Google seems to suggest this warning is emitted by some library rather than Python itself (maybe elementtree?). Edit: [Here it is, in ``xml.etree.ElementTree.Element.__nonzero__``](http://svn.python.org/view/python/trunk/Lib/xml/etree/ElementTree.py?annotate=78838#l250). It makes more sense in ElementTree as the current behaviour is to check for child elements but an element might still have attributes and text, even that it's just there means it's not False-like (consider ``&lt;br/&gt;``). Because the inherited ``__nonzero__`` would check ``__len__`` they *added* their own nonzero to throw the warning and in the future they probably plan to make it return ``True`` always. They recommend len() *if the case is* that you want to test for child elements.
24/31, which sounds ok until you see what I missed: assert, exec, is, lambda, return, try, yield Would you believe me if I told you I was a professional Python developer who contributed to multiple implementations as well as other tools :/
Spot the bug in "Question: How do we call the f method defined in the superclass?"
Thought I knew python. Checked it expecting to learn cool tricks. Happens I really know python, because I didn't learn anything here :/ Interesting for the beginners, but too basic to challenge even a mildly competent python dev.
28 out of 31. Missed `assert`, `global` and `lambda`.
jeetsukumaran is confusing ElementTree for standard Python behaviour. See [my response](http://www.reddit.com/r/Python/comments/drt3p/python_for_people_who_think_they_know_python/c12farh).
I wouldn't recommend it on performance bases, rather because of readability and that it's better duck typing.
Thanks for clearing that up.
Why the gram for mass? The SI unit is actually the kilogram.
Because the internal representation should not really matter and it was simpler without "kilo" in front of gram. Yet I may change it because you have a valid point.
+1 for tracking this down and clearing it up. I like the original idiom and used to use it a lot, and was disappointed that it seemed to be doomed to deprecation. Glad to see I was wrong.
Samus_ My script original removed all mark-up. But this resulted in many tables getting messed up / mis-aligned when the cells included text that had mark-up that was stripped out. I considered trying to fix this post-hoc by padding the text out, but the variety of different table formatting styles made recognizing when you were in a table as opposed to normal text a major pain (this would probably be a lot more workable with the DOM apporach as I mentioned in the other thread). So I decided that leaving the RST backtick etc. mark-up intact was the lesser of two evils in that the overall readability of the text was much better (it's easy and seamless to "read through" the mark-up; not so easy to parse a misaligned table).
As a computer **scientist** (my university puts Computer Science in with the Natural Sciences, not Engineering), it's pretty cool to within one week learn how to do error propagation in physics lab (with partial derivatives, like an adult!) and also stumble upon a library that can do it for me within a week. Commence lazyfication!
 &gt;&gt;&gt; DerivedClass().s() Traceback (most recent call last): ... NameError: global name 'd' is not defined
Anyone care to explain *why* the first one is the way it is? I'm fairly certain i've seen it before, but I don't know why that should ever be the case, and even further, why the 'fix' would fix it.
Have you had a chance to compare to Ironpython as well? 
The list is created at compile time, or more specifically when the function is defined - not each call. So you get the same list, as a kind of constant in the function signature. You can work around it with a decorator: [recipe](http://code.activestate.com/recipes/303440-fresh-function-defaults/).
[python-list: November 2008: Optional parameter object re-used when instantiating multiple objects](http://www.mail-archive.com/python-list@python.org/msg219948.html) has a rather full discussion on the subject, but the gist is that the function is created once, not each time it is called. The body of the function, however, is not part of that creation, but is part of the call. 
Say you write a naive flatten in python: def flatten(input): try: output = [] for x in input: output.extend(flatten(x)) return output except TypeError as e: return [input] what exception does flatten(["abc",[1,2,"abc"]]) print and what does it return 
Many times he's asked, and many times been chidden.
Lovely. I was looking for exactly this a month ago. (see [here](http://www.reddit.com/r/SomebodyMakeThis/comments/d2rbj/smt_googlestyle_calculator_with_unit_conversion/))
xXx\_ClAsSnNaMeS\_xXx I'm 7.
&gt;Note that most importantly, the """ that ends a multiline docstring should be on a line by itself, and preferably preceded by a blank line, e.g.: &gt; &gt; """Return a foobang &gt; &gt; Optional plotz says to frobnicate the bizbaz first. &gt; &gt; """ How do you feel about that bit? One of the big reasons python users have stated for leaving out block comments is that in things like greps on the command line, you can't tell if a line is commented or not. I suppose you'd have more inclination here seeing regular text not in quotes, which is unlikely to look like code. It might be more obvious you're seeing something from a multiline string. Mostly I'm curious why there should be a blank line before the closing """.
The empty list is created when the function is initialized, at the beginning of the execution of the program. As Python passes by reference, every execution of the function has an L pointing to the same old list.
I missed exec, global and finally.
I got a SyntaxError: # except TypeError as e: # ^ # SyntaxError: invalid syntax # It didn't like 'as.' Could this be related to my Python version? I'm in Maya 2008, which uses 2.5.1: import sys sys.version # Result: 2.5.1 (r251:54863, Jun 5 2007, 22:56:07) [MSC v.1400 32 bit (Intel)] # 
&gt;what exception does flatten(["abc",[1,2,"abc"]]) print and what does it return Erm... are you testing us or trying to find out? The problem with this function is that a string is always an iterable type, even if its one character long (a side effect of python's depreciation of the "chr" type), so it recurses indefinitely. So it raises a `RuntimeError (recursion depth exceeded)`. I'd suggest def flat_gen(input, flatten_str = True): try: if isinstance(input, str): if len(input) == 1 or not flatten_str: raise TypeError # jump past "for" loop below for sub in input: for flat in flat_gen(sub, flatten_str=flatten_str): yield flat except TypeError: # not iterable type, or iteration explicitly denied yield input def flat_list(input, flatten_str = True): return [x for x in flat_gen(input, flatten_str = flatten_str)] It's also important to remember to explicitly pass keyword arguments with default values when recursing, otherwise they reset to their default (i!
30 out of 31 Damn you *assert*.
Also, Python does not allow assignments as expressions, which are fairly common in PHP code. This restriction extends to the AST level, so it's not just a syntax limitation. The file tools/phpshell.py in the phply project is an interactive interpreter where you can type PHP and have it execute in a Python environment. You can get an idea just how different the two languages are, since you have PHP syntax but Python semantics. It's pretty weird. I think there is some usefulness to semi-automatic translation of PHP to Python, and this is the main thing that motivates me to keep working on the Python translation stuff. I'm interested in porting a few web applications from PHP to Python, and even though the semantics aren't the same, a machine translation seems to give me a little bit of a head start. Or, it could just be a total waste of time. :) BTW, I have succeeded in running some parts of the WordPress TwentyTen theme (barely modified) under Django by stubbing out the majority of the WordPress functions. I can post the code if anyone's interested. Another probably pointless exercise, I'm sure. (Edit: grammar)
I actually started going down this road, using vars() rather than locals(), in attempt to translate PHP's variable function call syntax ($f()). The whole call-by-string/variable-variable thing in PHP is pretty nasty, and entirely too common. http://github.com/ramen/phply/blob/master/phply/pythonast.py#L438
**Correction: No, I'm wrong, as pointed out by `null_vector`. I was thinking of unpacking "Exception.args" ** Yes, it's a version problem - I believe [this feature is backported to 2.6](http://docs.python.org/whatsnew/2.6.html) (from 3.x). However, you can safely remove the "as e" part from `tef`'s code - `raise SomeException as Foo` is used mainly as a syntactical tool for passing values to exceptions, which doesn't make sense for non-explicit exceptions. So in python 2.6 and above, you can do try: # /** snip **/ raise SomeException(argument, argument2) # /** snip **/ except SomeException as arg1, arg2: some_function(arg1, arg2) and the some_function call will respond to the values passed into it at the `raise SomeException(argument, argument2)`. The python2.5 and lower equivalent would probably be try: # /** snip **/ ARG1 = argument ARG2 = argument2 # /** snip **/ raise SomeException # /** snip **/ except SomeException: some_function(ARG1, ARG2) This trick isn't necessary, and as you've discovered, it's not backwards compatible - but it does save the effort of assigning/freezing variables that might only ever be used in an explicit exception. 
Isn't that a library in the standard Python distribution? If so, it makes sense why he would make that call.
8 minutes is a long time... edit: I'm a pro java dev, and I just did java keywords myself... missed some really obvious ones! ... I believe you :)
The issue there is that itertools.takewhile() feeds the reduce(), and it only yields elements while the input is unsorted. It wouldn't be that hard to check outside the reduce() and return if sorted.
that is one circlejerk, confuse the shit out of a newbie
I missed "and" and "or".
26/31, I can't believe that I missed: print, pass, continue, with, del I deserve to die.
No. http://docs.python.org/whatsnew/2.6.html#pep-3110-exception-handling-changes except SomeException as exc: saves the instance of SomeException in the variable exc
I’d say the `len(input)` check has to be run for other types too, not just `str`. People may define their own types with similar behavior.
I would much prefer a "So you're a Java/C developer writing Python code, eh?" kind of guide. I've really only handled C -&gt; Python developer code (here's looking at you, wes00mertes), but I've heard nightmare stories of Java -&gt; Python code.
Using pyserial I needed 4 return values to recognise the device used. &gt;&gt;&gt; a={(1,2,3,4):'damn'} &gt;&gt;&gt; a[(1,2,3,4)] 'damn' &gt;&gt;&gt; 
Though it's very simple to understand if you grasp a bit of the evaluation model of Python: default arguments are only evaluated once, at function/method generation.
&gt; You can magically turn a tuple or dictionary into the inputs to a function Um, no, it's a programming language. Using a tuple as positional arguments or a dictionary as keyword arguments is not magic.
Nonetheless, it's neat to show a less experienced coder how to answer the question for himself, and how to figure out why a result is true.
That's not how it's used. The point is that you can catch multiple exceptions in one block and the syntax is the same as the syntax for storing the exception instance, in 2.5. You had to use parenthesis to disambiguate and it hurt readability and was generally confusing. try: raise RuntimeError except (RuntimeError, IOError), e: handle_error(e) except SingleException, e: # See how confusing this syntax is?
[Python Is Not Java](http://dirtsimple.org/2004/12/python-is-not-java.html), though depending on the situation I tend to do this for a switch statement: y = get_y() case = lambda x: x == y # or whatever comparison you want if case(a): pass elif case(b): pass # etc A hash table is better when you're doing something dynamic like mapping events to callbacks.
Folks, we have a winner.
I don't think you understand the meaning of that word.
&gt; The SI **base** unit is actually the kilogram. The gram is a perfectly valid SI unit, and has the advantage of not including an SI prefix.
perhaps, I have tendency to use "odd" words the way I think it should mean
There is also extract() which would not work on a local frame scope in Python.
uh there's no "contents" ? just those tasks ? &gt; class BankAccount: also aren't you supposed to start using "object" superclass ? 
I think I found a typo: How to return multiple values. def f(n): return n^2, n^3 a, b = f(10) print "a =", a print "b =", b &gt;&gt;&gt;a = 8 &gt;&gt;&gt;b = 9 I think they mean return return n-2, n-1
 def f(a, L=None): if L is None: L = [] L.append(a) print L No. Right thing to do is: a) don't use side-effects unless absolutely necessary. return a value instead. b) if you want a sequence as a default value, use a tuple. that gets around the gotcha and also makes it clear that the L parameter is a sequence. edit: formatting
 class BankAccount(object): .....
Even easier: use () instead of []. Tuples aren't mutable, so if you try to modify it you'll raise an exception.
From the linked page: &gt; .....but can be used as a good introduction to the Python programming language as well. The written course materials..... IMO, "course materials" (and "a good introduction") is a big overstatement, what you have there is just "supplemental material" or more straight-forward: exercise tasks. I don't understand why you think the description (on the linked page) are proper. 
But if the point is that you *want* to mutate a list, defaulting to an empty one, that won't do. If you aren't mutating it, you might as well use ``[]``; though just for sake of keeping with best practices it can be a good pattern to use an empty tuple as the default.
It seems that you've missed the point (the author's example there is too synthetic though). The basic idea is that default values for function parameters are initialized once only, at the time of the module import. I can propose a bit more intuitive example of that. Unlike the piece of code written by the author, this one has more sense: def log_data(data, timestamp=datetime.datetime.now()) """ ... or create object, or smth else """ print timestamp, data Should be rewritten with def log_data(data, timestamp=None) if timestamp is None: timestamp = datetime.datetime.now() print timestamp, data Or (stolen from Django) def log_data(data, timestamp=datetime.datetime.now) if callable(timestamp): timestamp = timestamp() print timestamp, data 
github
I want to learn Python, but where to begin? 
While reading this I kept thinking "there are devs who don't know this?"
Was returning multiple values a novel thing to *anyone* reading that document? I'm hardly a Python programmer (I write code, yes, to get shit done, but the code is almost never the point of the task at hand) but that was the real "yeah, no shit" one for me.
&gt; It seems that you've missed the point No, I got it. I've just spent too much time arguing with a co-worker who insists on using None instead of a tuple when the argument is not intended to be modified. The timestamp example makes sense.
I learned something. Thanks!
Well, you *can* mutate the dictionary returned by globals(). It would have the wrong scope, of course. Mutating the locals() dictionary only works sometimes (and really shouldn't work at all, since it's not a supported language feature).
You are typing this in a Python console, which is incorrect. You should be typing this in a shell (also known as terminal window, command prompt, etc.) What operating system are you using? Windows, Linux, Mac?
I'm using Windows 7, running Python 2.6. I was using Python using the cmd prompt. When I run it without Python, it gives the following error 'pyuic' is not recognized as an internal or external command, operable program or batch file. Any ideas?
The 64bit JIT is still experimental which precludes pypy's usage in many production cases.
You're using the windows cmdline like a Unix shell. Find wherever pyuic is and cd to it 1st.
I'm not sure exactly what you mean. Python + cmd has always confused me. I cd'd to the location where pyuic.py lives. I'm not sure what to do next. pyuic \pathToUIFile\testUI.ui &gt; testUI.py gives the same error. 'pyuic' is not recognized as an internal or external command, operable program or batch file. I do appreciate your help.
I'd call that Intermediate Python. Not Expert Python.
As someone who is just getting into Python, this is actually pretty useful.
To launch a command by merely typing its name, it must be in your PATH (in Windows just as in Linux). The PATH is quite simply the list of directories to look into to find commands the user types. So, you should find where the pyuic command is located (you're probably looking for a file name pyuic.exe or maybe pyuic.bat, I don't know), and add that directory to your PATH (I'm going to let you Google how to do that, because it varies between Windows versions and is something basic that is taught all over the web). Alternatively (but you still need to find where the pyuic executable is), you need to put its directory name in full, like the following: C:\Python26\Lib\site-packages\PyQt4\pyuic4.bat testUI.ui &gt; testUI.py (I actually just found it on my machine. Never used it though.)
Have you tried searching your hard disk for a `pyuic.*` file?
HEY! I got it to work! Thanks very much for your help.
I did. I figured out how to use the command line with the help above. Thanks.
This is a fine idea, and I've seen serious proposals similar to it before. You can get part (a small part, maybe) of the way there by insisting everyone run a lint/pretty-print program with the standard settings before commit. Then you run the same program with your favourite settings after checkout. For full generality, you're asking for an abstract syntax tree editor -- not an impossible or crazy idea by any means.
I doubt the file is called pyuic pyuic.exe perhaps? At the moment pyqt/python has nothing to do with your issue.
locals() only allows changes when it's globals().
Thank you. It's nice to know that others would be interested in such power and flexibility.
The central idea seems like a good one. I'm not optimistic about getting anything like this in, though--the re module seems to have completely ossified. Probably better to write a whole new module...
Regular expressions are computationally equivalent to Deterministic Finite Automata, and as such can be computed very cheaply. BNF is equivalent to a Pushdown Automata and is much trickier to match. There are several algorithms that can be used all of which have various advantages and accept different subsets of what can be expressed with BNF. Parser generators for Python exist but usually are entire modules unto themselves. Assuming we standardized the parser interface and boiled it way down to something simple like this, it wouldn't belong in the re module because of the differences in the way they are computed.
Well, that explains it. Thanks!
So this seems to rule out a change to the re module. How hard is it to make your own parser generator? Would it be efficient in pure python? If this were implemented, you could just call the re module when the optional parameter isn't specified - that way you'd reap re's cost benefits.
Parser generators are usually considered graduate level CS material, but that wouldn't stop a determined soul from implementing one even without the background. Here's a list of parser generators from the Python wiki: http://wiki.python.org/moin/LanguageParsing Here's a paper someone did on the possibility of getting one included in the standard library: http://www.python.org/community/sigs/retired/parser-sig/towards-standard/ Edit: I guess the biggest issue here is that parser generation is still a field under considerable development so there isn't really a consensus on what the best algorithm or interface is. As such, it's been better to let this functionality be implemented by external libraries which are a little freer to evolve and come and go.
&gt; i've been playing with python for a few weeks wow just few weeks eh
If you think you've got a good thing here, I'd recommend writing it in pure python. If it's really good and you can't make it into a C module, someone else probably will a while down the line. As for actually building a parser; it's not that bad, but you may get caught out in some edge cases making it quite frustrating (and time consuming to write, and inelegant looking)
&gt; So why hasn't this been done before? It has, many times. It's just not in the re module, and shouldn't be. Just Google "python parsing". [This guy has a decent overview.](http://nedbatchelder.com/text/python-parsers.html)
'&gt; output.txt' asks your shell to redirect all output to output.txt*. \* all output to stdout, anyway, so all your "print foo" statements are covered.
Some people, when confronted with a problem, think "I know, I'll use regular expressions." Now they have two problems. 
I think you might be missing the point. * Internal representation can be whatever you want. * What's the default str() or repr()? Should this be definable? (setdefaultencoding is an example of why this would be a bad idea). * Still, many will want to make their lives easier so they don't have to "convert" every time they want to see what's up with the numbers. Maybe you need a helper function that creates a Number class with different default str/repr (to show different default units). Maybe this should be left for the users to do...
Lazyfication - a word I will use in the future. Thank you.
25, somehow completely forgetting about * and * del * exec * global * or * pass I only excuse myself for forgetting exec, the rest I use enough that I should know them.
What gives you the idea that the re module has ossified?
actually re.Scanner can allmost solve that
It has a number of problems, and attempts to correct them seem to get shot down. Consider the behavior of re.split(r'^', ...) for example. It's broken, and apparently it will never be fixed.
True. Will do this in a couple of days.
This is effectively what Perl 6 grammars do. I suggest you do this at least initially as a third party module, and maybe use ``str.format``. One problem is with resolving nested rules. Might also be nice to use classes: class Lisp(Grammar): list = r'\(\s*({list}|{atom}\s*)*\)' # ... Lisp(text) #=&gt; behaves like a match object I've done similar hacks myself abusing ``format(**locals())``; here we can use ``vars(self)``.
I too have sworn off IDE's on a powerful *NIX system, but it seems like the things the author shows off on his zsh prompt aren't really things I've seen people do in an IDE. But I agree with the author's premise, and would almost bet that he uses either EMACS or VIM in conjunction with his über zsh prompt.
*print*?? after trying 'range' i didn't even think to try that one
Is anyone using this? Please fill me in how you use it most. If you import something made entirely from the shed skin-supported subset of python, will it work too?
Hmm, how does this compare to structural regexps (rob-pike)?
But as far as I can tell these all use slight variations of BNF for their syntax. I was looking for something that used the syntax of regex, while using python's syntax to distinguish symbols and rules.
 &gt;&gt;&gt; re.split(r'^', 'foo') ['foo'] Is it supposed to return ['', 'foo']?
I'm not sure about ASCII but I can confirm that pygame is very graphics and sound oriented. I'm a bit curious about the ASCII stuff too.
[libtcod](http://doryen.eptalys.net/libtcod/), a roguelike library, has Python bindings. It's pretty cool, check out the bundled demo. Also, [projects made with libtcod](http://doryen.eptalys.net/libtcod/projects/). (Not terminal based, draws its own SDL window. Has mouse and true-color, though.)
I'd avoid the ASCII interface as it really is a pain for non-Linux folks and you'll still have all sorts of issues (eg what happens if the terminal is resized). Additionally trying to debug is harder as the debugger also wants to work with the terminal, and you can't itter your code with prints during development. Try several of the pygame tutorials. You can still make ugly graphics that are a block (eg 16x16 pixels) and so be no different than an ascii interface in terms of complexity. And if you stuff them all in a separate directory, someone with artistic ability can help without you having to change any other code. The pygame tutorials will at least teach you about frames and frame rates, sprites, collision detection, z-order, input etc (note that these even apply to ASCII games anyway). Once you are familiar with those topics you can continue with pygame or try some of the more complex engines (including 3D). Wikipedia has a page - look for Python bindings [here](http://en.wikipedia.org/wiki/List_of_game_engines). BTW there are also blog postings from people who have written games in short periods of time. This is one [example](http://www.gamedev.net/reference/articles/article2259.asp).
I think pygame and curses are your two best options. I'd probably go with pygame and find a nice fixed width font bitmap to use as a bunch of tiles -- quite a bit more flexibility in terms of color and such. Like these, for instance: http://i.imgur.com/NqlnU.png http://i.imgur.com/50lX8.png
I think you may have read into that statement a bit wrong. Sure he is using vim or emacs, but those are text editors not an IDE. He was just showing off the power of what you can do on the terminal to go along with vim/emacs, to improve your experience without the need of scm integration into your editor. That was my take anyways.
You are right, I didn't connect properly the ZSH prompt with the rest of the UNIX IDE. Now I've updated the post to make clear that the ZSH prompt is just part of the IDE. Thanks for the input.
 &gt;&gt;&gt; re.split(r'x', 'yyyxzzzxaaax', re.MULTILINE) ['yyy', 'zzz', 'aaa', ''] &gt;&gt;&gt; re.split(r'^', 'yyy\nzzz\naaa\n', re.MULTILINE) ['yyy\nzzz\naaa\n'] &gt;&gt;&gt; re.split(r'\n', 'yyy\nzzz\naaa\n', re.MULTILINE) ['yyy', 'zzz', 'aaa', ''] The middle result is simply wrong, by any reasonable measure.
The cmd module is what the pdb debugger uses. It supports many bash-like operations such as using the arrow keys for history and tab completion, and it comes with the python standard library. Doug Hellman has a nice tutorial on it here: http://www.doughellmann.com/PyMOTW/cmd/
You rock!
Non POSIX terminals are a pain in the ass, but windows supposedly has something that can be used to get it to work with termios.
There is no reason on earth why you should need to litter your code with prints during development. Use the logging module. In another terminal window you can tail -f the log file.
I wonder how you can see anything in such a cluttered prompt.
OTOH, I have trouble finding my prompt when I scroll back. Maybe I should at least colorize it.
:O
Some people, when confronted with a discussion of regular expressions, think "I know, I'll quote Zawinski". Now everyone has a problem.
Well, you can unroll the interpreter loop - which is one of the big gains of the PyPy JIT. So I wouldn't say "no meaningful speed gain". A lot of effort for not-as-much-as-you-would-like gain perhaps. Also see the latest attempt - Nuitka (not tried it): http://kayhayen24x7.homelinux.org/blog/2010/10/nuitka-release-0-3-2/ 
Is it really "inferencing" when the type is *known*? (Serious question: isn't inferencing more usually deducing the type by static analysis which is not what the JIT does.)
An alternative (better?) way would be to be able to save and reload the JIT annotations / generated code after a *real* run.
You're probably looking for [curses](http://docs.python.org/dev/howto/curses.html) 
The logging module is fine for later on. Early on just having prints and 'import pdb ; pdb.set_trace()' are far more convenient. (You can also try to argue that everyone must develop the same way you do - I won't bother.)
I'm glad developers are picky about the methods in which they develop; it makes for a good market for ideas. But I generally feel that the tools one uses should help you achieve your ideal goal, rather than compromising it. Debugging Python is [easy to do remotely](http://winpdb.org/docs/embedded-debugging/), without taking over your console.
&gt; which is one of the big gains of the PyPy JIT. Actually, if you take a look at some of the PyPy papers you'll see that they specifically dismiss unrolling the interpreter loop as being a large gain. Specifically they look at virtualization of objects and inlining as the largest gains (there's a cool paper for PEPM 2011 they're doing about virtualization). EDIT: upon a reread I think we are actually in agreement.
Yes, shedskin is (my understanding) a completely valid *subset* of Python with static restrictions.
Eh, curses has the advantage that it mostly Just Works, without requiring an enormous extra library. PyGame is a headache to get working on Mac OS X (at least through macports), while curses is dead simple. It seems a little ridiculous to use PyGame for an ASCII interface, when you have curses, which is designed precisely for that task. 
I am confused (and probably ignorant); is this "this" as in import this? Or using "this" instead of self as the parameter name of the instance, like in c? Or are these pythonistas hateful of the use of "this" ever as a name in a namespace?
mintty + cygwin works fine on windows. I do a decent amount of development in that environment where I'm currently consulting, and, while it's not perfect, it is better than straight vanilla windows, if you're a Unix/VMS bigot like me.
I use bold &amp; underline: set prompt="%U%n@%m%u(%B%~%b)\n%# " to avoid colorizing. 
Poromenos used this for some of his scientific programs iirc; he blogged about it too. 
I would use `me`, which is shorter, but I hate arguing with people about it.
I'd use `me` when I'm referring to the object itself, but also make sure that `my` points to it as well when I want to access a member.
They will be fixed when a proper fix is available. Proper fixes when it comes to re have to take into account not only the fix in functionality, but also compatibility and very importantly, performance. I can't speak for anything that has been rejected, but for example, a backwards incompatible and slow fix to the actual functionality isn't going to make it in.
Yeah, if it was funny. OH BURN!
Meh.
"Self" come on man, get it together.
 class Derp: def __init__(this): pass
"this" in C, C#, Java, Javascript, etc. == "self" in Python (although "self" is only a convention; one can name it anything) I think most would look at the use of "this" with mild scorn simply because it reminds them of languages like Java which they prefer to avoid. 
Note to "this": don't look at posts where the person who made something claims it's funny.
`print` is a keyword in 2.x and a function in 3.x. I'm pretty sure `range` isn't a keyword in any version of either. Open the interactive shell and type `help(&lt;name-of-keyword&gt;)`. If it's really a keyword, you will get a syntax error.
You forgot to talk about php, probably because you don't consider it a language but an abomination?
This works for any file with plain vCards in it. It just matches the beginning and ending of the vCard format.
`this-&gt;` /me ducks
Except it's not a standard collection and carries additional semantics justifying its being truthy even if empty.
Don't know what shell that is (ZSH probably), but I found the equivalent for bash: PS1='\[\033[1m\]${debian_chroot:+($debian_chroot)}\u@\h:\w\$\[\033[0m\] '
It does look like pygame is the way to go. I've started messing around with it, and I've already managed to draw a simple text based map (Emphasis on simple). Pygame has a number of advantages over curses or something purely text based. You can use it to draw lines on the screen, which could be a way of drawing a grid over your map, or a more flexible say of drawing text boxes. It's also be easier to shift to a graphical interface if I want to. It also allows me to use bigger characters to represent bigger monsters.
There are regex based lexers, and pyparsing uses Python objects, functions and operators to build up a parser (that can very well take a token stream from a lexer). I don't really see what problem you want to solve though..
A Turing-complete templating language.
sqlite is amazing, I recommend it for anything that doesn't require concurrency.
oh, I didn't forget, I was saying what *I* use, which is quite obviously tcsh.
that doesn't require **write** concurrency, it hanldes read concurrency very well.
Hmm, I think the Python driver was a bit bad in that department and couldn't handle even read concurrency, even though SQLite could. If that isn't the case, you are correct.
In Python 2.6, `bytes` is an alias for type `str` You could use the python 3 version straight up and it'll work transparently in both versions. If your Python is prior to 2.6....just alias it yourself: bytes = str Et voila! 
Python 2.7 supports bytes(), so if you can depend on Python 2.7 you just need the bytes() version. Otherwise, no, though you could at least move the check out of runtime: if sys.version_info &lt; (3,): def xor(...): ... else: def xor(...): ... 
Well, I did have sqlite3 throw an exception when I tried to expose a class using it to CherryPy, which said something to the effect that you couldn't have multiple threads acessing it -- and this was only for reads. It is more than possible that I'm doing it wrong, of course.
Look harder. It's right under your nose. http://dev.twitter.com/pages/auth_overview#desktop
Python 3 code and Python 2 code, while close, are not supposed to be compatible. Making your code work in both, while a neat trick, is not entirely reasonable because of things like that, especially since it merely makes your code less readable. If you want to hit both versions, I suggest making two versions of your code.
You would want to make sure you are before 3 before doing that though.
Plenty of people run a single codebase for both 2.x and 3.x. It's not all that hard to do, and a single codebase is the best way to it in my opinion.
Were you using it on an something with a NFS filesystem by any chance? It might be known issue. http://www.sqlite.org/faq.html#q5
I have a strong suspicion that if you need to xor bytes, you should be using a lower level language. 
The Python 3 version will break in 2.6 because you can't str.__xor__
Does sqlite have to open and read the db file every single time it's accessed? Does it write the entire file every time a change to a table is made? 
no, no.
However, perl-style regex's (which python uses) aren't actually regular expressions either , despite the name, and already can't be implemented purely with a DFA. Enhancements like backreferences etc break the regular nature, so an argument in terms of regular purity is a bit flawed.
Why not use the [Python Twitter API](http://code.google.com/p/python-twitter/)?
Never worked with binary files, then?
This is true, but BNF is really on an entirely different level than regexes. Not only is there a much greater amount of ambiguity on what is allowable (e.g. no left recursion with LL parsers, shift/reduce errors, etc.), but the output of a BNF is a tree or even calls to supplied callbacks.
When I do work at the bit level in python, I'll use ctypes. Knowing what every last bit is doing in a data type is something low-level languages are for. By the time the variables are being used by Python, they should have that sort of thing abstracted away.
Is it so hard to write the fucking function yourself, lazy-ass? def insertThousandsSeparator(i): L = [] for (i, c) in enumerate(reversed(str(i))): if i and not i % 3: L.append(',') L.append(c) L.reverse() return ''.join(L) I *literally* just wrote this for this reply. It took me less time to write and test this than it took you to make this useless post here. God damn kids expect everyone to do your job for you. What 8-line function are you going to complain isn't handed to you on a silver platter tomorrow? EDIT: briancurtin's is the answer to the post you should have made: "I couldn't find it in the documentation, so I had to write this 8-line function myself, but maybe I'm missing something. Is there a way in the standard library to format a number with thousands separator?"
 Python 3.1.2 (r312:79149, Mar 21 2010, 00:41:52) [MSC v.1500 32 bit (Intel)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; format(1234569, ",d") '1,234,569' See also, [PEP-378](http://www.python.org/dev/peps/pep-0378/).
At first I was expecting more fuel for the religious wars that I saw between logging and logbook, but that actually looks quite decent. I might have to give it a try.
It was on my WinXP netbook, so I assume it was NTFS. For what it's worth, I fixed it by creating (and subsequently destroying) a connection every time a query was requested. It works quite nicely now.
so now it's logging vs logbook vs twiggy
I like this. The first few paragraphs explaining why logging is important especially. We use splunk for collecting logs and it's also a great tool for searching and producing useful reports after your logs have been generated.
Whenever I see 'ATM machine' I just assume the ATM in that case is supposed to stand for Ass To Mouth.
import this 
*zing*
To be fair, neither vi nor emacs has ever given me a "Catastrophic Error" message before crashing, which is something I can't say about any recent version of Delphi.
I will use you.
I know I'm not answering your question, but here is an alternate way of doing this: import itertools print [''.join(permutation) for permutation in itertools.permutations('abc')]
String encodings *fun*? HA! Working with strings encoded differently is the ultimate frustration test. Even in Python.
Using Django? See http://docs.djangoproject.com/en/dev/ref/contrib/humanize/#intcomma This is why you use a framework instead of coding everything by hand. Granted, this isn't a complex function, but there's a million-and-one different little things like this that need to be written for a reasonable web app. Django basically has everything you could think of. 
Right, but itertools.permutations is 2.6+ only. So it's nice to have a little utility function like this on hand anyway. Anyway, you're right that it's off-topic. I'm mostly interested in the syntax here, which is why I called it a Stupid Python Trick. :)
i love how us python folk tend to prefer single quotes. but yes, ass to mouth.
I changed the output from the list of permutations to the tree of permutations. That was the only way I could get the one liner to work. [paste](http://paste.pocoo.org/show/277269/) The problem is that in permute3 you are consuming the generators that are created recursively right away (the innermost loop), while in permute4 the generators are nested (as you said, it's yielding a generator).
I would highly recommend getting the book wxpython in action. http://www.amazon.com/Wxpython-Action-Noel-Rappin-PH-D/dp/1932394621/ref=sr_1_1?ie=UTF8&amp;qid=1287470246&amp;sr=8-1 awesome read and gets you thinking of better way of coding with refactoring etc.
Is this what you want? &gt;&gt;&gt; def permute4(s): ... return s if len(s) == 1 else (c + perm for i, c in enumerate(s) for perm in permute4(s[:i] + s[i+1:]))
I know. I was just posting the Bash (rough) equivalent for any curious people.
This works, as far as I have tested.
That seems like it would be fine for most situations, but it returns two types of output (generator and string). To make the return types consistent, you would have to change the "return s" part of the statement. For example: def permute4(s): return (e for e in s) if len(s) == 1 else (c + perm for i, c in enumerate(s) for perm in permute4(s[:i] + s[i+1:])) Edit:This also works: def permute4(s): return (e for e in [s]) if len(s) == 1 else (c + perm for i, c in enumerate(s) for perm in permute4(s[:i] + s[i+1:])) 
Always nice to see alternatives, but for this to be useful it has to support other logging systems as well, even if just for redirection purposes.
Why in the world do you want to do this? Just for fun?
True, but I still use Delphi 7, which for me always have been very stable
I don't think the point is about writing a function to do this. I think it's just an obviousness overlooked and a battery missing. 
This is relevant to my interests. Why the downvotes? MCMC in R is slow as hell, I'm curious to see if this would work out faster
now we need a logging API like the DB API so that we can drop this as a replacement for modules already using the standard logging. Like the suds, or pylons or routes. They all import logging and do a logging.getLogger() we need a logging.setImplementation(twiggy.logging) or logging.setImplementation(logbook.logging) or something
Right now, one of the central points of things like Twiggy seems to be the different API compared to logging, so I don't see how what you suggest would help much. Although a compatibility layer for "legacy" apps using stdlib logging would sure be nice.
Yeah, that was the last version of Delphi that was stable for me, too. Have some upvotes for memories of better days. :)
if you put "python thousands seperator" into google, pep-378 is the top result for me. to the op "python " + what you want is generally an obvious, easy, simple and foolproof starting place.
Then We are in violent agreement, dear sir or madam! :D
As a list comprehension it's more obvious: def permute_lc(s): return [s] if len(s) == 1 else [ c+perm for i,c in enumerate(s) for perm in permute_lc(s[:i] + s[i+1:]) ] Yielding returns a generator, as does returning a generator expression. So to make the generator one line, return generators from both sides of the if. Or cheat a little and return `[s]` on the left side of the if and the generator expression on the right side of it.
The first version relies on `s` being iterable and returning itself when it has length 1 and is iterated over, and I vaguely recall something about strings not being iterable in Python 3. If that's true (not sure!) your second version would be more correct.
thank you Emacs definitely needs this prepared bundles, methinks
Sorry, but how is what you're suggesting any different from permute2 in the original post?
If this were SO I think I'd accept your first answer here. Since it returns a generator in every case, it's the closest to what I'm looking for. I'm not sure if it's a generator *proper*, but it's close enough.
"import *" drives me insane, especially when I'm trying to debug someone's crappy code and I can't find out where the hell some\_lame\_utility() comes from... (edit underscores...)
Yes, "import *" is vile. I excise it whenever possible. That said, if the module had declared "\_\_all\_\_" and put only its own exports in it, not also its imports, the "import *" wouldn't have caused quite as much confusion in this case.
The first example lost me at "from twiggy import *"
well, there is a one line generator syntax: ( ... for ... in ... )
We use [sphinx](http://sphinx.pocoo.org/ext/autodoc.html) to document our json apis. 
There is **no logical reason** why the formatting functions would not have the capability of inserting thousands separators given how elaborate it is.
Has PEP-378 been implemented? (It gives overwhelmingly compelling reasons to do so) No? Well, I rest my case. Oh, and not everyone can use Python 3.
Sure `import *` is bad, but not defining `__all__` in a public module is just as bad.
Realy? If import * is a bad idea, what's the purpose of `__all__`?
Hi, twiggy's author here. I've got plans for a logging_compat module that would to exactly this. See the end of the blog post. What would be nice is if we (twiggy, logbook, logging) could find a common standard for output backends - that save us all the work of reimplementing over and over for all of the different services we want to support... though it would have to tie to the internal log message object ("record" in logging/logbook). Hmm. And then there's configuration, and threading model and... Oh dear.
You mean like, twiggy uses logging (or logbook) as an output backend? That'd be bog slow, and I worry about structural incompatibilities (threading &amp; context model come to mind). Or providing a user-side compatibility layer for logging messages? I discussed that a bit at the end of my blog post. I'll try to catch up with you on IRC, maybe we can put heads together...
&gt; You mean like, twiggy uses logging (or logbook) as an output backend? That'd be bog slow, and I worry about structural incompatibilities (threading &amp; context model come to mind). I know a logging backend is slow, have the same problem in logbook. But that way libraries that use logbook can still dispatch to logging and the other way round. Makes for a more useful system. &gt; I'll try to catch up with you on IRC, maybe we can put heads together... Sure, go ahead ;)
Did you check out permute3? I use it there. The problem is that the (... for ... in ...) itself creates a generator, and I'm yielding that -- the generator -- instead of the needed results.
&gt; because I'm yielding a generator Just return it. &gt;&gt;&gt; def permute4(s): ... return s if len(s) == 1 else (c + perm for i, c in enumerate(s) for perm in permute4(s[:i] + s[i+1:])) ... 
To make `import *` not be dangerous :)
Exactly. __all__ = [] or better __all__ = None # so that 'import *' fails - @voidspace below That's all you need to do. Maybe that's annoying, but Ruby is worse, since it offers no way to select a subset of symbols to be imported. Perl offers a way, but it's more complicated, using both `@EXPORT` and `@EXPORT_OK`. EDIT: Thanks, @voidspace!
When I was first learning python, I used "from x import *" a lot, cause it seemed easy. Now that I've come to respect and fear "where did that func come from?" issues, I find I'm saddled with a million lines written by a much more naive me. If I ever get a hold of him, there will be such a reckoning. Now I try to either explicitly import the functions, or just import the whole darn module, and reference it's components from the single var in the namespace.
Eh. It's not. I failed at reading comprehension. Sorry. I'll downvote myself. :-) 
Duck-typing-wise, it is, but the if you run `dis.dis(permute3('abc'))` and `dis.dis(permute4('abc'))` the actual code output is different.
Works great thanks!
 Python 2.7 (r27:82525, Jul 4 2010, 09:01:59) [MSC v.1500 32 bit (Intel)] on win32 Type "help", "copyright", "credits" or "license" for more information. &gt;&gt;&gt; format(1234569, ",d") '1,234,569'
The one thing that annoys me is itertools.chain takes a list of args, making it impossible to pass in a generator without evaluating it. I'm always creating this:: def chaingen(gen): for item in gen: for subitem in item: yield subitem 
I was just answering the question. To yield result instead of generator, try "yield str(something)" or whatever type you want
how about pyglet? It's much like pygame but written in pure python and in my experience even easier to use
I just found a new quote to live by.
None, academically. Just thought it would be easier from a user perspective.
I just tried this with str.replace. It's really easy to implement and it helps a lot with regex comprehension, but like you said, nesting issues... Thanks for the note on Perl 6. I hadn't looked much into the engine.
Right, but isn't that the same as epydoc? Just browses through docstrings and renders them out in a browsable way?
The logging_compat thing as suggested in your post is certainly nice for many cases. But to use it with third party code you don't want to touch, it may just be necessary to do something unspeakable like sys.modules['logging'] = twiggy.logging_compat (and then hope none of the third party things get too fancy with logging) Not sure if want. (Really, hard to decide...) :-)
Yeah, star imports are even worse in docs explaining how things work because you just know that in these cases, you are going to want to know where all names come from. Just makes it harder to grasp quickly. :-(
I'm trying to think of a good reason for wildcard imports, and am coming up short. Why are they still in the language?
&gt;integer division is non-obvious and generally useless. Uhm, what? Integer division is extremely useful.
I agree, this is a wart in itertools.chain. However, it been somewhat addressed in a recent python release (2.6 I think) by the itertools.chain.from_iterable classmethod constructor. Classmethod constructors are also evil (they are hard to discover when browsing the contents of the module) and it's a bit verbose, so this only counts as a partial fix!
Laziness.
There is an __all__ defined, so it's safe, but fair point. The import * is supposed to be a convenience for configuration - there's a half-dozen or so names you'd probably want to use to set things up (only one on the logging side). I'll update the docs/post to clarify though.
And not the good kind.
Python noob here; why can't you type `help(some_lame_utility)` to find where it comes from?
They're damned handy when you're futzing around at the interactive interpreter.
I didn't notice anything in that article that can't be done with the current stdlib logging package - including the usage interface is easy to implement as a thin layer on top. The asynchronous thing is [right here](http://plumberjack.blogspot.com/2010/09/using-logging-with-multiprocessing.html) with a front end [here](http://plumberjack.blogspot.com/2010/09/improved-queuehandler-queuelistener.html). Also those logger('name').filter(x, z, y).info('foo bar') seems like three method calls instead of one - builds latency into a critical section. Armin's thing seems more dramatically different to me (though I don't see the need to switch from std logging). 
True one-liner which would be backwards compatible all the way back to Python 2.3 if you're using the and-or trick in lieu of if-else. permute5 = lambda s: reduce(list.__add__, [map(c.__add__, permute5(s[:i]+s[i+1:])) for i,c in enumerate(s)]) if len(s)&gt;1 else [s] It should be possible to change this to do tuple.\_\_add\_\_ and itertools.imap instead, but my boss just walked in...
 from django import * from os import * from sys import * You can use your method to help figure it out, but you need to drop to a shell and run all those imports to run that help command. Sure, it's totally possible to do, and the function name might give you a clue, but the point is that you shouldn't have to do that. `import *` is a sure sign that you're dealing with a lazy dev or a noob. 
Python 2.6 is over 2 years old now, I personally wouldn't worry about targeting 2.5 or below any more...
Does anyone know how large of files GridFS can support? Would it be useful, for example, for multiple TB of data with individual files ranging in to the multi-GB or possibly even TB sizes? It seems like it has potential for storage of scientific data...
PyMC doc: http://www.jstatsoft.org/v35/i04
i should probably qualify that a little: i've been checking python out for 3-4 months, but only seriously working with it for a couple of months, which is probably stretching 'a few weeks'. i'm also a cs/math major (albeit early in the process) so i'm already familiar with a lot of general programming concepts. however, i stand by the fact that i can sit down with the python interpreter and feel pretty confident that i can work my way toward a solution to a given problem whereas with c++ (what we're using for classes) i've got browser tabs galore open, my textbook out, etc. and have to do a lot of pre-planning to get where i'm going. not that that's necessarily a bad thing, but it speaks to the simplicity and power of python.
Just use grep.
has everything you could think of =&gt; provides most features you would need in a broken way requiring 10000 hacks to beat them into submission
Unless you want to use Google App Engine, or PyPy, or the system python included on thousands of existing linux servers that won't be getting upgraded to the latest versions of their respective distros, etc. But other than that, yeah.
This is a good idea...
Anyone run into any compatibility issues?
I did when this hit testing, mostly with my own scripts that expected a python2-syntax-accepting interpreter. I futzed around for a few days with it, and then punted: symlinked /usr/bin/python2 to /usr/bin/python. No problems since, but I expect to get bit for it when something else depends on python3. Shrugs. 
As a newbie to python, I welcome this. Python is in a quasistate right now, it'd be nice once most mods are ported to py3 so everyone can start using the same stuff. Plus I accidentally ran python2.6 last night. Wow the "input" command totally sucks! (Yes I figured out its better to do rawinput eventually) Feel free to rip me apart and tell me why I'm wrong.
Feel free to add Invent Your Own Computer Games with Python. It's free under a Creative Commons license at http://inventwithpython.com
Configuration files that are just Python modules.
Nope, I just pacman -Syu'ed, and there were no problems. Google App Engine (and other 3rd party Python tools) required changing, i.e. #!/usr/bin/env python -&gt; #!/usr/bin/env python2. btw, more discussion was had [over at /r/archlinux](http://www.reddit.com/r/archlinux/comments/dt25s/python_is_now_python_3/).
If you don't know how to program well, then you probably won't notice the speed difference between python and any other language. Modern computers are very fast. The main thing that you need to watch out for is that learning a lower level language will force you to learn things that will help you to avoid some mistakes that cause poor performance.
The only compatibility issue I've run into so far is SABnzbd+. It won't run until you edit /usr/bin/sabnzbd and change it from python to python2. Other than that, everything is good so far.
If you're just using it to start out programming, or if you're already a programmer who's just looking for a "fun" language, Python should be fine for you. There's a strong preference against premature optimization in the programming community. It sounds like you're not yet at a point where the speed of the language matters. When you get there, you'll know more about what questions to ask and how to go about optimizing for speed.
This is crazy! The Python community long ago accepted that switching the "python" executable from 2 to 3 would break everything and upset lots of people. The Python 3 build won't install as "python" by default; you have to go out of your way to force it. I like Python 3 loads, and I program in it where I can. But I'm not sure the rest of the world is ready to join me.
Most business applications are not bottlenecked by language speed, so it's not really an issue for run-of-the-mill stuff. The performance difference between `if x` and `if x &gt; 0` is so negligible that it's almost certainly misguided to be worried about it. This is how you make your program fast: 1. Use basic knowledge of algorithms to avoid making truly boneheaded decisions when initially writing code 2. See if it's slow under real world usage 3. If it's not slow, you're done! 4. If it is slow, profile the code and find out *what* is slow, fix it, and try to learn from it. In the vast majority of cases, it will not be due to a general performance issue with your programming language. 5. If your language really *is* too slow, most (including Python) let you interface with C for speed-critical bits of code. If you really want to *understand* how to make code fast and efficient (ideally on the first try), learn about algorithms. A poorly-chosen algorithm in a fast language is often beat by a well-chosen algorithm in a slower language (sometimes to ridiculous degrees). Also, get in the habit of measuring performance empirically instead of superstitiously worrying about it. Untold amounts of development time have been wasted by needlessly optimizing code that simply did not need it.
Agreed. Do things right and Pythonic. Later if you have performance issues, looks them up and wipe them out. If your code is structured properly, bottlenecks in performance should be easy to wipe out. Though, if it's a structural problem, well, you shouldn't have made it ;)
**Bold** move. 
You're not "wrong." Most people are going to complain that the most commonly used libraries are all in Python 2. I develop in Python 2 and welcome this change; I'd like to see everything make it eventually. The shift will be a little uncomfortable, but it has to happen *sometime*. I don't currently use Arch Linux so I won't see the effects of this recent event in particular.
If you've already worked through the tutorial.... 1.) start writing something 2.) ....how do i?? 3.) find out 4.) profit That being said, django docs and djangobook.com
yeah, there are plenty of times when they come in handy (getting started quickly, one-off scripts, etc). Like alot things in python, you have the ability to do the easy thing first and still have the flexibility to do the sustainable thing later. 
I'm not sure what you mean. You can't run dis on a generator object.
How so? Switching /usr/bin/python to 3 instead of 2.7 will break existing python2 programs which are lazy enough not to use #!/usr/bin/python2.6 or some other specific version as the hashbang. I assume Arch linux developers have checked that no application in their repositories does that. Personally, I think you should never use #!/usr/bin/python in a script, and always define the specific version you want. Upgrades in 2.6-&gt;2.7 could break things just as well as a move to 3.0 could.
Just as side note. Blender 2.5+ uses Python 3. I hope that other large applications switch to Python 3 as well.
&gt; (not to mention if you choose something GPL then you *can't* sell it commercially) That is incorrect; please read [Selling Free Software](http://www.gnu.org/philosophy/selling.html). There are a number of businesses that are in fact selling free software.
Pedantry aside, you know what I mean.
I sometimes wish that a popular programming language would switch to just actually using Unicode characters like this. (Also that the ability to enter, edit and display Unicode symbols like these was more universally available, of course.)
distutils should handle the renaming of all the hashbangs, just build the package with python2
&gt; I assume Arch linux developers have checked that no application in their repositories does that. FTA: &gt; All our packages have been updated accordingly Now, the AUR is going to have a few problems...
That move probably hurts the Python community a whole lot. Python3 was not supposed to be named "python", always "python3". There is a reason the official downloads and builds have that filename.
At my employer we're now using Python in the heart of a large C++ application, and not just as glue either. We have a philosophy of "use Python when you can, use C++ when you must'. Performance *is* important in our application - [scientific data processing and modelling of large data sets for the oil industry](http://www.youtube.com/watch?v=CK28b9v07wE) - but heavy use of Python hasn't given us insoluble performance problems so far. In a few places we've dropped into C++ using [Boost.Python](http://www.boost.org/doc/libs/1_44_0/libs/python/doc/index.html) for performance reasons, and we also use Boost.Python for providing APIs to our new Python code from our legacy C++ code. Of course, much of what you can do with Python is implemented in fast C or C++ modules anyway (*e.g.* Numpy, SQLite) so considered use of libraries means that the overhead of using Python can be negligible. Finally, by the time you have implemented reflection, introspection, a decent plugin system and meta objects in your C++ application you've inevitably [Greenspunned](http://en.wikipedia.org/wiki/Greenspun's_Tenth_Rule) yourself a dynamic language anyway. Why bother, when you can take Python off the shelf? Here's a EuroPython 2010 talk, [Python from the Inside Out](http://europythonvideos.blip.tv/file/3980760/) explaining our use of Python in the core of a legacy C++ application.
What's the big deal when you can just symlink /usr/bin/python2 when necessary? This is a distro focused on "bleeding edge software" - this would be huge if it was Debian and they pulled off a mass-package update to make Python3 the default Python.
but scipy and numpy depend on python2 [](/fu)
+1 for boost.python. Our way of doing things is to code everything in python. Then if its not fast enough replace the core inner loops/algos with c++. Most of the time you can do a little bit of python work (convert lists togenerators etc.) to not need the c++.
Lots of insightful comments so far. [Cython](http://cython.org/) needs mentioning, though. It makes it very easy to interface with C-libraries and/or write performance critical components in a Pythonesque language that is translated to C and then compiled.
From my experience, the best website on Django is their documentation site. If you've done the tutorial, you're probably ready to start making stuff. Just look things up every once in a while on the Django documentation site and on Google/Stackoverflow/etc.
It seems there is a limit of 2^31 chunks giving a ~0.5 Peta Byte limit in some MongoDB implementations. Neither MongoEngine or PyMongo restrict this further.
At this day and age python is mostly used to write bigger applications solely in python. Especially web applications. With the exception of any c bindings you'd use for image/audio/video processing or bindings for GUI toolkits you can expect most of your applications, especially enterprise style apps (mostly db access and business logic) to run decently fast if you write them in pure python. Especially if you compare the end result to something similar written in Java with 3000 dependencies on frameworks, dependecy injection containers and 1/5 code to XML ratio that are far too common. 
check ubernostrom's book practical django projects. now that's the kind of book i like. if you are familiar with unix authors like Kernighan, Ritchie, Pike, Plauger, you won't be disappointed.
That was really amazing, thank you ! Details: you will need Vim 7.3 compiled with conceal feature: --with-features=huge To check if conceal is enabled: vim --version (look for "+conceal")
have fun typing that :) 
Python is now diamonds...
glad to hear you like it. :-) “conceal” will hopefully be enabled when distros start shipping vim 7.3.
i would like the opposite: given a scientific paper, convert the symbols into readable python code.
I'm a professional programmer who recently completed a large-scale financial system in Python. He's got the exact right of it. I'll add this: the C programming language was my first love, and for my first ~10 years of programming nothing I worked with approached the simplicity and power of C. Basically, each language that tried to "improve" on C pitched increases in efficiency, but I ended up taking longer to finish most projects due to uncontrollable layers of language behavior. Python is the first language that I've used that feels as logical and clean as working in C. It rarely violates least surprise and after an adjustment period, I actually like the significant white space. Keep on truckin with Python, learn yourself some C, and you'll be in a happy place. PS: support for interfacing with C modules in Python is quite good.
I suspect this move will help the rest of the world migrate since there is now an entire distro userbase testing packages against python3.
and also a pony; don't forget the pony
Too soon?
You should be careful changing if statements like that. Your two if statements are not equivalent since negative numbers evaluate to True. &gt;&gt;&gt; x = -1 &gt;&gt;&gt; if x &gt; 0: ... print "foo" &gt;&gt;&gt; if x : ... print "bar" bar &gt;&gt;&gt; 
Careful with your logic there... Negative intergers are TRUE in python if x &gt; 0 and if x are only equivalent for POSITIVE x.
This looks really great. Looking forward to setting it up and checking it out. Thanks!
agreed, this seems like a very bad idea. might make it inconvenient to do python coding for work on arch.
You should use `#!/usr/bin/env python`, otherwise your script is not likely to work on someone else's machine. Specifying the full version is a good way to chase people away from your software, python2.3 to python2.7 is common today and responsible projects will support a range. If the presence of `python2` links was ubiquitous, we could all ship scripts that had `#!/usr/bin/env python2` and the transition to `python -&gt; python3` would be far less painful.
Hmm... $ cat ~/.vim/after/syntax/python.vim " we need the conceal feature (vim ≥ 7.3) if !has('conceal') [output trimmed] $ /usr/local/bin/vim --version VIM - Vi IMproved 7.3 (2010 Aug 15, compiled Oct 20 2010 10:07:57) Compiled by isarl@isarlDesktop Huge version with GTK2 GUI. Features included (+) or not (-): [...] +conceal [...] But it doesn't seem to be working. Why could that be?
strange. does it work if you remove the check for ‘conceal’ at the start? some things you can check: * does **:set ft?** say “python”? * you can check **:scriptnames** to make sure that the file actually got sourced. * if it *was* sourced you should get a list of *pyNiceOperator*s at the end of the output from **:syntax**.
You can always patch it locally.
Also documentation: In [1]: s = "hello" In [2]: s.isdigit? ... You can also edit longer pieces (AFAIR it uses editor from $EDITOR environment variable, vi if unset) with In [1]: edit
I could not live without [nosemacs](http://bitbucket.org/durin42/nosemacs) (Full disclosure: I wrote the first version, linked one is much improved).
Removing the check for conceal (i.e. prepending one double quote [`"`] to each of the lines for the check) didn't change anything: * `:set ft?` says `filetype=python` * `:scriptnames` doesn't list `/home/isarl/.vim/after/syntax/python.vim` * `:syntax` says `No Syntax items defined for this buffer` :( *edit:* It may be interesting that I simply installed vim7.3 from source right overtop of the old 7.2 install I had without doing anything to remove it, first. That might be confusing things, perhaps? But I doubt it, because I'm sure to run it with the 7.3 executable. Maybe there are some environment variables not set properly?
PLT Scheme (which is apparently now called "Racket") supports λ in place of the lambda keyword, and uses something like CTRL-\ to enter it (which makes sense, since \ looks like the main part of λ). I agree that it'd be nice if more languages supported this, but it's a short jump from "let's allow λ as a keyword" to APL's "∇R←Area R ← (○1)×radius*2"
Anyone know of a way to do something similar in emacs?
hmmm, do you have a ~/.vimrc? do you have “syntax on” set there? do you get syntax highlighting at all? is the “regular” syntax file loaded? ([prefix]/share/vim/vim73/syntax/python.vim, probably.) my syntax file should actually just “build upon” the standard python syntax file, so if you don´t get syntax highlighting at all, my file won't work.
how do you change the editor on windows? i want to use geany tia
I sent this to my department warning that this may affect our Redhat servers in 6 or 7 years.
Yes, I have a ~/.vimrc; no, it does not set `syntax on`. Aha! Doing so fixes everything. Thank you, thank you, thank you! A thousand times thank you for your help in troubleshooting and moreso for writing this plugin in the first place. :)
Raising the exception has the side effect of populating sys.exc_info() with a traceback, which can be navigated to access the caller's stack frames.
http://cse.ucdavis.edu/~chaos/courses/nlp/Software/Windows/IPythonEditorConfig.html 
A neat hack, but my first instinct is to kill it with fire before it spreads. This would make much more sense for Haskell (which really *wants* to look like math, hence "/=" for not equal and "\" for lambda) than for Python.
If you're on Linux or OS X, there's also bpython.
thank you that was most helpful :)
you´re welcome. glad i could help. happy hacking! ☺
a guy over in /r/vim said that something similar can be done with emacs using “lambda-mode and co”: http://www.emacswiki.org/emacs/PrettyGreek
I'm in a computational logic course and I do most of my work with words (AND, OR, etc) and then convert to symbols. so while this vim plugin is cool, I dont really want it.
Yes, ipython makes you wonder how you survived with the original interpreter in the first place. Simply a must-have for pretty much anyone using python. It also supports basic shell commands, such as ls and cd.
Why do you want the parameters listed in the docstrings when introspection or doc generation tools list the actual parameters anyway? 
There are a number of bugs related to indexing: it recurses into VCS directories, ignores the "ignore files and directories" feature and may jump outside of your project directory - in my case using a ton of memory indexing huge JSON fixtures and test data. Once that's hacked around (I had to move stuff into a separate container directory so jumping up one level from my project didn't include the test data) or if your projects don't have indexer-crushing data volumes, it's not so bad.
serious question...If and when could this hit Redhat boxes? Ever?
Inconvenient is a strong word for requiring an extra character or three if you want to use an older version of python.
Then you'll have to use "python2", or they'll have to update their code.
Next step: Django Book http://www.djangobook.com/
Awesome. Other distros need to start shipping with the "python2" symlink, and then the world will be a beautiful place.
They will appreciate hearing about all of that, I'm sure :) — and they are generally quite swift about fixing things that matter: http://youtrack.jetbrains.net/issues/PY
I set up mine so it will always try to source an 'include.py' in my dir so i can dump code in there. it's useful to have data structures in there that don't change instead of manually having to set it up each invocation. You can set up the file to point to anything, so you could have a standard dataset that it always had on startup. I highly recommend reading through the default config file. There's a lot of settings that you might find useful.
I'm not 100% certain, but I recall getting stacktrace (for logging purposes) without raising an exception. I might have used some stacktrace module though, PLY code uses sys only.
You are missing the implicit assumption that python is python2 which every script out there has. If you use python as being a symlink to a python 3 executable you can expect changing a whole bunch of applications in the next 10 years.
Ha, forgot I was running Trac on my Arch box. Well, there goes that...
Awesome, thanks!
If you like it and also use X have a look at [Spyder v2.0](http://code.google.com/p/spyderlib/).
You can also break into ipython when debugging, just pip install ipdb and then import ipdb, ipdb.set_trace() instead of using pdb.
If you run into the indent bug when recalling old pieces of code, try putting in: %autocall 0 Might be fixed in a newer version, but my experience says otherwise.
IIRC, scipy and numpy were recently ported.
The author is not aware of sys._getframe() and is using the standard exception handling mechanisms to get a traceback instead.
Yeah, but in this case "changing" means "adding a character to".
I'm taking my words back.. sorry
On top of what appears to be a newbie implementation, I think a direct answer to your question might be that you're having some type confusion... `poison = "0" ` is a string. `poison = 0` is a number. Take the quotes off of your poison number and just use it as is and I think you'll be fine. Oh, and... def poison(): print """You feel as if...""" if Player.poison &lt; 5: riddles() else: death() Player.poison += 1 Also and.....when you find yourself with variables like: key_one = False key_two = False key_three = False .... and riddleone = False riddletwo = False riddlethree = False ... You can be pretty sure you're doing something wrong. Consider instead a dictionary or list. riddles = [ "What is the", "Who was", "Where", "etc" ] or riddles = { 1: "What is the", 2: "Who was", 3: "etc" } And when you have variables with some other data structures index as part of the name, like: rtwosearched = False rthreeunlocked = False You can be damn sure you're doing something wrong. Perhaps nested dictionaries? riddles = { 1: { "question" : "What is the airspeed velocity of an unladen swallow", "answer" : "42 kph", "searched" : False, "unlocked" : False }, 2 : { ...etc } } Or maybe a separate list of `searched` and `unlocked` that gets filled in with riddle #s as you go... 
`sys._getframe()` is however implementation specific and may have been worked around consciously. Jython, for instance, does not have frames.
Yea making it a string was part of a test on my part to see if the poison section is where it was breaking down, since no real errors popped up. However, using the += 1 fixed it. I was missing the = sign which actually increased the number. I wanted each level of the poison to show increasing effects, that's why there are 5 lines in the poison function. Thank you for the answer though, I was going crazy trying to figure out why it wasn't working with numbers and just using + 1 :( 
`Player.poison + 1` is an expression that just has the value of poison plus one, but doesn't actually set anything. The `+=` operator is short hand for: `Player.poison = Player.poison +1` As for the poison messages...how about an effects array? poison_effects = [ "meh", "bad", "worse", "awful", "almost dead", "dead" ] print poison_effects[ Player.poison ] It's just that seeing code like that with the chain of if/elifs makes me cringe. 
The real pain is for projects that are not pure python libraries, but want to ship portable scripts (perhaps even as part of their build system or for maintenance tasks). It sucks to add another stage to the configuration process ("install" maintenance scripts to the build directory so they can be run to configure, generate Fortran stubs and documentation, build, send bug reports, etc).
I'd use a dictionary for the replies: replies = { 1: """You feel as if you've done something wrong, a small click is heard and you feel the sting of a dart strike you in the back. Immediately you begin to feel a bit lightheaded.""", 2: """You feel as if you've done something wrong, a small click is heard and you feel the sting of a dart strike you in the back. Immediately your muscles begin to ache.""", 3: """You feel as if you've done something wrong, a small click is heard and you feel the sting of a dart strike you in the back. Immediately your vision begins to blur and the pain grows stronger.""", 4: """You feel as if you've done something wrong, a small click is heard and you feel the sting of a dart strike you in the back. Immediately the pain in your body intensifies. It's as if a thousand burning knives are being jabbed in and out of your body, the pain is nearly impossible to bear, another mistake like this could very well be your last.""", 5: """You feel as if you've done something wrong, a small click is heard and you feel the sting of a dart strike you in the back. As the final dose of the poison seeps into your body the pain begins to subside, followed only by darkness""", } with that you can: print replies[player.poison] if player.poison = 5: death() else: riddles() another thing I've noticed is that you seem to be referencing the class instead of an instance, if you have: class Player(object): ... you shoud first create an instance of is as: player = Player() and *then* operate on player.poison otherwise you'll be working with the class property and changing it will affect any other instances you may have that haven't changed it at the instance level. finally, as bushel says it's not the same to work with integers than to work with numeric strings, PHP does some horrid magical conversion that tries to guess what nonsense you throw at it but python won't so turn them to integers everywhere.
Yeah, it's not like he wrote a book called Python Essential Reference where he covers that method...oh wait, no, he's one of maybe a handful of people on Earth who did do that. So I'm gonna go out on a limb and say Dr. Beazley probably is aware of that method.
Unfortunately the lists and dictionary manipulation are still outside my skillset, the thing I've been following hasn't gotten too much into those. I do remember using the lists a bit, should probably go back and look at it again to try and implement them. Even doing things like the poison counters and whatnot kind of go outside the scope of the assignment but I got carried away trying to make something neat. (to me at least.)
Looks like they're by this guy: http://www.google.com/profiles/ryanshea#about 
Thanks for finding these. The iTunes podcast was a little messed up, and I couldn't download old ones. Fantastic podcast. I've learned a lot in the 3 episodes I've seen in the past. 
I remember my first year of computer science in high school. I thought it would be fun to try to make a word processor or simple editor. I started by creating an array of strings... Anyway....my point is, those things may be outside your skillset at the moment, but I see no reason (given what you've done so far) why you couldn't learn how to use them very easily. You seem clever and self-motivated enough. Go ahead...give it a try. It's only a *little* addictive.... 
Man this stuff just keeps getting better and better. SkyNet in 3, 2 ...
You must get a lot of upvotes just for your username.
It, like the standard python interpreter, also uses readline so you can `set editing-mode vi` in your inputrc to use vi key bindings if that's your bag. If you've got some hot piece of code that you want to write to a file, you can hit `esc v` and edit your current input in `$EDITOR` and/or write it to a file. It also has some handy command substitution syntax. So you can use something like `x = !ls *.png` to get the output of some system command. Another useful thing that it does is entering parentheses for you. For example: In [18]: str 8 -------&gt; str(8) Out[18]: '8' It's a great python interpreter and very capable of acting as a powerful system shell.
Yea I've noticed, it went from trying to make a few rooms with a couple choices to trying to figure out how to add monsters to fight, locked doors, riddle rooms, traps, and all sorts of stuff haha. With reference to the keys/searches/unlocks. Those are what I was using for rooms all over the complex. rtwosearched was how i checked to see if they'd searched room two of the dungeon. So that it wouldn't tell them they found a key again for example. rthreeunlocked was the check to see if they'd used a key so different text would appear and it wouldn't require them to unlock something they'd already unlocked. The riddles had only been implemented to the point where I knew I wanted 6 and needed a way to check if they'd been answered correctly so that it wouldn't ask them again. Then a way to check all 6 to allow access to the next room. I think I might start over with a better plan and look into the lists/dictionaries to try to add them into the mix as well.
Since I'm very very new to the python stuff I'm not really sure what you're talking about with the class and instances. I actually got the class thing from code somebody else used, when I noticed them using it like a sort of inventory for the player in the game they'd made I tried to copy it into mine. The way I understood it was those things were assigned to player, so if I had say, poison = 0 outside the player class and a poison = 0 inside the player class, if I did poison += 1 that'd make poison 1 but the player class poison would be 0. Is that not right?
You may have found your "muse" I had a piece of software in my early years that every time I learned a new technique, language or other design concept I would go back and rewrite it using the new found knowledge. It turned out to be a good way to put theory into practice and really get a feel for what I was doing. Enjoy! 
http://docs.python.org/tutorial/ Once you know the basics, get on the tutor@python.org mailing list to read and help.
If you're trying to pick up python from the ground, [this might help](http://www.niagarareptiles.com/pricelist-midwest.htm).
I think the best would be an example: &gt;&gt;&gt; class MyClass(object): ... p = 0 ... &gt;&gt;&gt; MyClass.p # class property 0 &gt;&gt;&gt; my_instance1 = MyClass() &gt;&gt;&gt; my_instance1.p # still class property 0 &gt;&gt;&gt; my_instance1.p += 1 &gt;&gt;&gt; my_instance1.p # now instance property 1 &gt;&gt;&gt; MyClass.p # class property remains the same 0 &gt;&gt;&gt; MyClass.p += 10 &gt;&gt;&gt; MyClass.p # now class property was updated 10 &gt;&gt;&gt; my_instance1.p # but the instance property remains the same 1 &gt;&gt;&gt; my_instance2 = MyClass() &gt;&gt;&gt; my_instance2.p # class property affects new instances 10 &gt;&gt;&gt; MyClass.p += 100 &gt;&gt;&gt; my_instance2.p # and also instances that haven't made the class property an instance property 110 but Object-Oriented Programming is a topic on its own, you'll get to it eventually but in short the idea is that the class defines a structure that the instances follow, in python everything is an object so class definitions are operable too (and that's why you can alter the value of the class properties in runtime, most languages do not allow that).
No problem. I ran into that same podcast, and it's *very* messed up. I also don't have iTunes on my phone (Palm Pre+), so I needed to find the files somewhere. 
http://inventwithpython.com This is a free book that has the source code for several game projects. Type them up yourself and learn how they work, then start making your own variants of them. The later chapters cover Pygame, a library that provides graphics and sound functions. You can follow the source code of more Pygame games here: http://inventwithpython.com/blog/category/code-comments/
DIVE INTO PYTHON
I did this for my twitter app..I saw this method in a blog could not find that blog now.. :( I dont think you need to authenticate for pulling down search results or to get data of a particular user...but then if you still want to authenticate.. what you need to do is 1. register your app [here](http://twitter.com/apps/new) 2. get your CONSUMER_KEY and CONSUMER_SECRET 3. download and install [tweepy](http://github.com/joshthecoder/tweepy) 4. create a file and paste this code import tweepy CONSUMER_KEY = /--insert your key here--/ CONSUMER_SECRET = /--insert your secret here--/ auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) auth_url = auth.get_authorization_url() print 'Please authorize: ' + auth_url verifier = raw_input('PIN: ').strip() auth.get_access_token(verifier) print "ACCESS_KEY = '%s'" % auth.access_token.key print "ACCESS_SECRET = '%s'" % auth.access_token.secret 5. now go and log on to twitter 6. execute the above script and copy paste it in ur browser where you are logged in. 7. you will get a pin number copy and paste it in the terminal where the script is waiting 8. copy and save ACCESS_KEY and ACCESS_SECRET generated by the script 9. use these names and use it for oauth authentication. NOTE: with tweepy you can make an API instance auth = tweepy.OAuthHandler(CONSUMER_KEY, CONSUMER_SECRET) auth.set_access_token(ACCESS_KEY, ACCESS_SECRET) self.api = tweepy.API(auth)
downvoted for snakey comment
here we go again
Also, don't forget turning on pdb magic in ipython using %pdb So ipdb is started on any exception.
Because I list them with along an informative description in the docstring, as even if I use descriptive names, sometimes what they do is not evident: I was just looking for a way to automate that (i.e. to write the list that then I'd supplement by hand).
IIRC you have to dig a bit into ZeroMQ's internals to find file descriptors that you can poll with epoll/kqueue/whatever. I hope they keep that API relatively stable, because it's great to be able to use ZeroMQ in eventlet and node.js and the like.
oh thank you i just pacman -Syued and everything just works, so i was worried needlessly. once again archlinux has proven my fears unreasonable. this one time i was having a klibc error whenever i tried to upgrade my kernel and i went to arch forums and they had it covered on some page. i cried, i shit you not. 
I am a relative newbie, so these should be great! For fun, I wrote a Python script to download all of the MP4 videos (since that's what I wanted): #!/usr/bin/env python import urllib vids = range(51) for vid in vids: if vid &gt; 0: url = 'http://python.sourcequench.org/media/episode%d.mp4' % (vid) webFile = urllib.urlopen(url) localFile = open(url.split('/')[-1], 'w') localFile.write(webFile.read()) webFile.close() localFile.close() 
ipython isn't all that better than the regular interpreter imo
What if you want to have a script portable between different distros?
[Learn Python The Hard Way](http://learnpythonthehardway.org/) by Zed Shaw
And the battle continues!
There's nothing to spread.. It doesn't alter your source code at all, just the way vim displays it if you have the plugin activated. 
Lookup APL and J... they're very powerful languages but to my eyes, they make perl look clean and elegant.
[ThinkCS](http://openbookproject.net/thinkcs/python/english2e/)
Tab completion, auto-indentation, and the `?` and `??` help shortcuts alone make it infinitely more pleasant to use than the "vanilla" interpreter.
bpython has less quirks than ipython, too.
nope. python3 is explicitly incompatible with python2, that was the whole point.
if you know another language well, this is an excellent way to go. it takes you through just about all of the python language, and some bits of the stdlib.
That feature is scheduled to come out in zeromq 2.1.
Also, you can run any shell command by proceeding it with a "!".
inspect.stack()
for i in \`cat list\`; do wget http://foo.com/$i; done
Hehe. Said I was a newbie :)
Yeah, I had forgotten about ?. It's useful sometimes. The normal interpreter does tab completion and I don't spend time in an interpreter writing things that nest more than one or two times so the indentation issue while annoying is not cause enough for me to see what the big deal about ipython is. I like bpython a lot though
Besides laziness, there is another reason to prefer a standard solution to implementing it yourself - i18n. Your solution doesn't handle European locales where the separator is a period instead of a comma. Or Asian locales where they often use groups of 4 digits instead of 3. Presumably a standard function would take care of these issues for you.
Use the unpack function from the struct module. Specifically, from struct import unpack results = unpack('hh1', x)
I think the best is the [Google Python Class](http://code.google.com/edu/languages/google-python-class/)
&gt; The normal interpreter does tab completion No it doesn't... are you thinking of IDLE?
I find ipython plays better with numpy/scipy/matplotlib, though. (Which is expected since it is oriented toward that purpose).
My favorite thing about IPython: In [1]: from somewhere import stuff In [2]: obj = stuff.do_whatever(1,2) ... In [37]: result = obj.give_me_result() # hmm I would like to copy/paste this into a script In [38]: print ''.join(In[:-1])
I do this occasionally, but I find that frequently the reason for an Exception is clear and I don't want to be dropped into the debugger. Using %debug immediately following an exception is one extra step when I actually want to use ipdb, but one fewer in the majority of cases when I don't.
http://docs.python.org/tutorial/interactive.html
I'm not saying that a person shouldn't look for a library solution; I'm saying that he shouldn't post inane, angry missives when he doesn't find one. Just implement the solution and get on with your real work. It's also worth noting that both your features can be added to the function I whipped up in 60 seconds without adding a single additional line of code.
what are you looking for differently than def func(x): ''' i'm a doc string! ''' pass help(func) 
Worked great thanks!
Your first one looks fine if you indent the `i.append(x)` line to the right one level. For example: def problem1(a): i=[] for x in a: if x in i: return True i.append(x) return False assert False == problem1([1, 2, 3]) assert True == problem1([1, 2, 3, 1]) Those assertions both pass for me. (The assert statement will throw an AssertionError if the expression you pass it is not true.) Your second one is also flawed due to mere indentation. Only the `thelist.append(i)` line needs to be in the body of the loop. The rest after that should be taken out of the loop, as it only needs to run once, after the loop is finished. Also, there are ways to copy a list without using a loop. You can just do it in a single statement. I'll leave that to you...
Seems like you are having an issue with understanding how scope with indentation works in python. For your first problem you just need to indent the line i.append(x) so that it happens within the loop. For problem 2, run your sort and comparison after you create your list. You can also use the sorted method which will return a new sorted list to compare against instead of using your for loop to create a new one.
Thank you both for your help! Very appreciated
I agree with your sentiments. I'm just saying laziness isn't the only explanation. The tone of his request did leave much to be desired. But can you add both those features, and the logic to select them correctly based on the current locale that easily?
My distro's had vim 7.3 since at least August.
Woah... that should be enabled by default.
Well, what you did was to learn, so that's good. FWIW I've had great mileage from combining bash with short python scripts. Typically my python scripts will involve system calls of bash commandlines similar to what I typed above. You could do something like baseurl="http://foo.com/" for filename in list: url = baseurl + filename os.system("wget "+url) Bash is better though for doing things like this from the commandline, and with trial and error you can write very long and powerful command pipes. For bonus points write a scraper that automatically scrapes the page and downloads all mp4 files.
 wget -r -l 1 -A mp4 http://python.sourcequench.org/media/ That works quite dandily.
Using a low-level language to get performance is a form of brute force. Like writing a CGI program in C to get acceptable response times rather than replacing the flawed design of CGI. It's more important how you design a program than what you design it in. I'll rather program in a language that makes it easier to reason about that design. You'll learn solutions to various situations as you go, and as you find a need to.
A typical example: def foo(param1, param2): """Foo the bar. Parameters: - param1 - do X - param2 - do Y """ I'm trying to make less of a chore to write them (i.e.: make a list of the parameters so I can edit it and add stuff) as I'm on an one-man project that's becoming a little too big, and I want it to make sure it's properly documented, and that I can generate nice API docs with Sphinx. If this must be done manually then I'll have to. But if I can spare part of the work by doing some grunt work automatically, better. 
and you can have the output in a list with !! (I think)
Don't know about ready to use stuff, but you can probably hack something together with few lines of code. Starting point: `inspect` module, especially: `getargs`, `getargspec`, `formatargspec`, `formatargvalues`. It will require pasting those docstring templates by hand unless you write something to process your source files. Totally doable. 
Don't go there.
 1. When you write a solution, write something on paper as simple &amp; clear as you can, without taking the complexity/limitations of the language into consideration, then translate that to the language of your choice 2. Search Python documentation. You will find functions which help you handle collections much better :)
Eventlet wraps this up so you can safely ignore it. All you need to do is zmq_socket.recv() and the library takes care of making that non blocking - excatly the same as it does for normal sockets. Check out the example for a little idea of what you can do with it :-)
Hopefully not. WSGI could do better and there is a proposal for that (444).
you could also use the &lt;array&gt;.count(&lt;element&gt;) function i.e. for x in a: if a.count(x) &gt; 1: return True
unpack is brilliant. It's great for working with all sorts of binary formats in a clean and readable way.
Cool! started using it, installed vim from debian sid because ubuntu 10.10 still has vim 7.2. added "all" and "any": syntax match pyNiceOperator "\\&lt;all\\&gt;" conceal cchar=∀ syntax match pyNiceOperator "\\&lt;any\\&gt;" conceal cchar=∃ 
Not everyone runs Linux...
Could be an indentation as mentioned by sontek, or, I'm wondering if you confused the function of list.append and list.extend. Try this: import copy a = [1, 2, 3, 4] b = [8, 9] d = copy.deepcopy(a) e = copy.deepcopy(a) d.append(b) e.extend(b) print d print e Add parens for print if in python 3.1. 
PyLint or PyFlakes can be useful for this (especially with emacs' flymake) - delete the `import *` and you get an error along the lines of `undefined name theonefunctionthatwasused`
It can get messed up if you're pasting in indented code from a text editor but other than that it is nice. 
i would be interested in seeing the "bad" version of the good code that was being written.
I like how the "messy code" example is basically an empty function that asks you to imagine what messy code is like.
In HPC, the majority of computational time is spent on crunching numbers so you want that taken care of by NumPy and other C backends. Compared to that, evaluating code structure will never be a bottleneck - except in the development stage where the majority of your coding time is spent implementing, testing, restructuring etc. The two-language approach with C/Python means that you aim for e.g. 90% of execution time spend in C but 90% of coding time spent on Python, and this works quite well if you're skilled at bridging the gap with a nice Python interface to your computational backend in C. 
&gt;if x &gt; 0 *or x&lt;0*: You are however right in limiting cases where the inequality operators are overloaded differently from the boolean cast, e.g. for NumPy's nan: &gt;&gt;&gt; import numpy &gt;&gt;&gt; x = numpy.nan &gt;&gt;&gt; x &gt; 0 or x &lt; 0 False &gt;&gt;&gt; bool(x) True 