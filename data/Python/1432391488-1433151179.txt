Something like that, yes. But when it previously just stored the package, it will now store the built package. So any package that compiles something will see substantial speedups the second time they are installed, for example Gevent.
LOL, which is more efficient in a loop: x = 4.4 * 10 **25 or x = 4.4e25 Huh?
Doesn't 2.x vs 3.x matter here? 2.x has normal and long integers, and 3.x has only long. 
I've been doing something similar by using pip2pi to build a project-based repositories of my own in local folders. I can then pip install from that on my local machine and I can rsync the whole folder to a 100 different production servers and also pip install from there. It means I only have to hit pypi once, and it doesn't matter if pypi gets slow, goes down or stops serving particular packages. And I get all that without having to run my own repo server (which means fewer headaches). Kinda hoped at some point that this functionality would get rolled into pip itself.
One scenario you aren't considering is new server launch in response to load. If I'm trying to scale horizontally during an increased period of traffic, the faster I can launch a server the better.
 &gt;&gt;&gt; dis.dis(compile('4.4 * 10 ** 25', '', 'eval')) 1 0 LOAD_CONST 4 (4.400000000000001e+25) 3 RETURN_VALUE &gt;&gt;&gt; dis.dis(compile('4.4e25', '', 'eval')) 1 0 LOAD_CONST 0 (4.4e+25) 3 RETURN_VALUE Both take the same time? Yay for constant folding.
A lot of basic stuff was pushed to 2 as well, like print(). One thing that trips me up in 2 is forgetting to subclass 'object'
 &gt;&gt;&gt; int((2**31) - 1) 2147483647 &gt;&gt;&gt; int((2**31) - 1) + 1 2147483648L &gt;&gt;&gt; Nope.
`%`
I started with Code Academy (which is v2) and Learn Python the Hard Way (v2) because they are both great learning tools. While I was going through PTHW, I would make sure I could also do all the exercises in v3. It's definitely possible to learn both. It's more about learning how python works in general. I use v3 almost all the time, but I can go back to v2 when I have to use a library that can't do v3. Since I'm still kind of new to Python, I'm still pretty dependent on 3rd party modules, so if I need two modules and one is only v2 and the other is only v3, it's frustrating. Almost everything you need to do (web framework, http, SQL read/write, etc.) will have several choices that cover both versions. I would say use Code Academy and PTHW, but everything you learn, make sure you can do it in v3 as well. That way, you can stay in v2, or move into v3. 
Is it possible to host the server yourself? Otherwise I think this would limit the potential user base quite a bit. I'm not sure I'd trust a remote service for this, say you have a source file with private API keys or something like that, I personally wouldn't trust a completely unknown third party with access to any private source code. I'm currently using wdb for browser based debugging, what would be the main benefits of using your service over something like wdb?
Just curious about your programming background. You said hobby in this comment and how Python felt like class in another comment. It's funny because as a computer science major who works in the business world, c++ was what I did in school and Python is closer to the real world for me. Do you have formal education in computer science? Even as a hobby you might enjoy courses on operating systems and other such closer to machine level topics. 
2.x automatically upgrades numeric values when necessary.
This helps, at least it helped me: http://htmlpreview.github.io/?https://github.com/rasbt/python_reference/blob/master/tutorials/key_differences_between_python_2_and_3.html
I like the April Fools joke, lol. I didn't write Attic: I just came across it looking up remote backup options. I'll have to add Obnam to the list. As for the Python quip, I have to help support a program at my day job that's stuck in 2.7 land for the time being. There are still a lot of programs and resources out there calling for 2.x as well: not unlike the IPv4 vs IPv6 "debate" (sticking with 2.x = turning off IPv6 as a "fix" IMO).
Thank you. We have one female developer at our company. She says the exact things that you do. People like Adria and other extreme feminists are doing damage to everybody and it's a shame that they get so much space in the media. From Adrias background it isn't suprising that she acted this way but it's terrible that the guy lost his job. So I think his former employer should be shamed and have to make a formal apology. The people who attacked Adria are also a disgrace. The only true victim is Hank though.
Ah yes. I was wrong. 
A compiled version of a package. Pre PIP 7 it would do download sdist -&gt; compile -&gt; install now it does download sdist -&gt; compile to wheel -&gt; put into cache wheel from cache -&gt; install which makes subsequent installs a mere wheel from cache -&gt; install
Thanks, and yes, I have been reading quite a lot of those, but it seems nowadays a lot of things have been automated in porting 2 code to 3, and there's all these nasty little corner cases. Thanks a lot anyway!
% would be an unnecessary waste of microcontroller time - it's embedded so you exactly what hardware you are running on. Unsigned wraparound is also great for keeping array indices within range. I'm not really sure how this is relevant to Python. You're not likely to run Python on one of [these](http://www.microchip.com/wwwproducts/Devices.aspx?product=PIC18F8720).
Maybe take a look at [Logbook](http://pythonhosted.org/Logbook/) - I haven't tried it yet, but it looks promising.
Is the application the browser? If it is, there are Python binding for [Selenium](http://www.seleniumhq.org/).
Can you paste the full trace you get when you run the command (sans personal info)? Or is that the extent of what you're getting?
You take your stream of consciousness blogshit to tumblr where it belongs, and cry about another missed [year of the Linux desktop](http://cdn1.tnwcdn.com/wp-content/blogs.dir/1/files/2014/08/windows_share_july_2014.png). When you wanna come join the winning side, let us know.
&gt; First of all, if you look at pylint, it marks any function that accepts more than 5 (default value) arguments as something that should be refactored. This means something. What you've done helps to workaround code that smells instead of refactoring it into something adequate. I feel like you're generalizing quite a bit here. I took a quick look at two popular libraries that I use regularly, requests and SQLAlchemy, and the first function that I looked at in each had more than 5 default value arguments keyword arguments.
It does very little. [`-O` disables assertions](https://docs.python.org/3/reference/simple_stmts.html#the-assert-statement), and `-OO` additionally ignores docstrings, saving a bit of memory. That's it. 
Take a look at what you posted.
You're kidding, right? Python on Windows is downright awful. There are entire features in the stdlib that don't work in Windows (streams between threads, parts of the `os` module, filesystem related stuff, anything that involves a proper terminal, etc). It's harder to compile anything, and I have to keep 3 compilers on hand just incase the other doesn't work (VS2008, VS2012, and MingGW). VirtualEnv doesn't translate between windows and nix, Most of the heavy, popular, packages won't compile without configuration so you have to grab them from the Unofficial Binaries page. Cryptography plugins don't work. Headless packages don't work because they rely on X11. If you're just using basic stuff, then go right ahead and feel that way. The second you start to step out you're in for a world of "gotchyas" that all tie back to being on Windows.
Am I doing this wrong or does `pip wheel` really put the cached wheels somewhere else as `pip install`? If so, how can I build a wheelhouse in this new PIP7 wheel cache?
&gt; &gt; Do you mean writing the _init_args list &gt; &gt; Exactly. Well, it really doesn't count as "writing bunch of code", since all you do is writing your arguments' names and their attributes. I (or someone else) can also modify the library so that it will automatically fill the missing fields (like type, default argument, and explanation), if the size of an argument entry is lower than 4; this means much less code. I understand your key point so I will cut it short. All other options seem sacrificing extensibility (for example we can combine it with [rightarrow](https://github.com/kennknowles/python-rightarrow) for a more extensive type checking), automation, and code reuse for *beauty*. A matter of taste I guess.
Old style classes confuse me. I needed to do new-style shit with a class that was subclassing an old-style one, and had no idea why it didn't work, then just changed the definition to `class Something(oldstyle, object):` and it worked fine. Why aren't all classes forced into new-style by default?
Oh snap, the same guy who wrote Pyperclip! I used the hell out of that module.
Thanks! 
The obvious question is, do you have Graphviz installed? And assuming you are logged in as 'user' you should proboably make sure you own all the items inside your /library folder with 'sudo chown user:user /Users/user/Library -Rv'.
I know what I posted and you still behave like a jerk. 
I think my fault was to not have graphviz installed. Pip works now, thanks! My only problem is, that I get an error when I try to import it in my script now: ImportError: No module named pygraphviz Any idea how this comes?
That comment is less than worthless. He doesn't provide the code that demonstrates the speed increase nor does he even bother substantiating his claim with profiling data. Edit: He also neglected to mention which version of Python he's using, what OS he's using, and the specs of the machine.
Does obnam compress backups? The documentation doesn't really say anything about that.
If you're happy using git for backups, you don't seem to need many features from backup software… these are things like removing old backups to save space, chunk-level deduplication, encryption, fast handling of large binary files, etc.
I switched from `rdiff-backup` to `attic` some time ago, mostly because `rdiff-backup` is terribly slow at recovering data from older generations. Now I have been using `attic` for about half a year and I'm pretty happy with how it works. So far the few times I needed to recover files went without any problems… though still feeling a bit uneasy using that young application for backups. Unexpectedly the biggest change for me was the chunk-level deduplication, in my case this feature saved more than half of backup disk space (rdiff-backup can't even deal efficiently with file renames).
Why would python version, OS and machine specs matter? If they saw an increase in fps due to the optimize switch while keeping python version, OS and specs constant, then the optimize switch is the reason. So take this comment as equally worthless. I just downloaded and ran that code. I had to increase the number of entities to 1400 to get a nice slow fps (~25). I ran with the `-O` flag and got 60 fps (my computer seems to hard limit pyglet at 60 fps even if I don't tell pyglet to limit fps). I ran without `-O` again and got ~25. and back and forth, sometimes changing the optimize switch and sometimes not, until I was convinced. the optimize switch made a 100% performance improvement in this case. I'll tell you my python version, OS and machine specs gladly if you can tell me why it would matter.
Assuming pggraphviz is now installed, I would guess your python can't see the path you installed the packages to '/Users/user/Library/Caches/pip/' maybe? or '/Library/Python/2.6/site-packages/'.
You could eliminate some of the nesting like this: `restricted_authors = ('WOW_MUCH_NICE', 'dogetipbot')` and `if not comment_author in restricted_authors and 'wow' in comment_txt: ...`
Use `sys.maxint`: &gt;&gt;&gt; import sys &gt;&gt;&gt; sys.maxint 9223372036854775807 &gt;&gt;&gt; sys.maxint + 1 9223372036854775808L &gt;&gt;&gt; I have a 64 bit Python installation, that's why `sys.maxint` is larger.
Yep. Changed `vsync=True` to `vsync=False`. Now with 400 entities, I get 95 fps vs 200 fps. `-O` is still a clear winner.
Awesome! I wanted to see how fast it could get. Thanks!
Yeah, thanks for asking. Now I know that my [fluid simulation demo](https://vimeo.com/64969866) tops out at 100 FPS on my machine.
Well, `os.scandir()` is a different kind of thing than `os.walk()` -- scandir is the low-level, non-recursive function that can power a recursive walking function like `os.walk()`.
so, 7? or 6? edit: nevermind I'm being stupid So, what OS are you on? You maybe just need to uninstall/reinstall pip.
Ok, what you want to start of with is what is known as a "guard clause". Where you do some checks and skip everything else if they fail. So in this case: for comment in commentstream: comment_text = comment.body.lower() comment_author = str(comment.author) if comment.id in cache or comment_author in ["WOW_MUCH_NICE", "dogetipbot"] or "wow" not in comment_text: continue cache.append(comment.id) .... rest of your code The `continue` statement means: skip the rest of the loop code, go immediately go to the next comment in the for loop. This keeps your code nice and flat, no more nested ifs at all.
I think all you need to do is pip install pip==6.1.1
o_O... Thank you. Seriously... I effed that up royally. 
WOW! That continue statement is really useful! You guys have really helped me out a lot here! Thank you so much!
What does pita stand for. Did a quick google but didn't get the answer. 
When all else fails, try the [Urban Dictionary](http://www.urbandictionary.com/define.php?term=pita).
*Here's the Urban Dictionary definition of* [***pita***](http://www.urbandictionary.com/define.php?term=pita) : --- &gt;1) Acronym for Pain In The Ass, a major annoyance. &gt;2) Flat bread of Mediterranean origin, eaten as is or filled with small pieces of roasted meat, veggies, condiments, etc. --- _1) Reinstalling everything after a virus was a true PITA._ _2) Greek-style pita is round and thickish, while Cypriot-style pita is elongated and thin._ --- [^(about)](http://www.reddit.com/r/autourbanbot/wiki/index) ^| [^(flag for glitch)](http://www.reddit.com/message/compose?to=/r/autourbanbot&amp;subject=bot%20glitch&amp;message=%0Acontext:http://www.reddit.com/r/Python/comments/36z72g/window_gui_automation_with_python/criz8is) ^| ^(**Summon**: urbanbot, what is something?)
Eww. I don't like this direction for python. Adding the hassle of static types (and extra, not very readable syntax too) without the performance benefit (and actual performance losses instead)
I think this is helpful: http://python-future.org/compatible_idioms.html
cool stuff, tnx!
OS X 10.10.x?
It will approach 2.8 but [never reach it](https://www.python.org/dev/peps/pep-0404/) :)
Type `which python`. That's the version of Python your virtualenv will use by default. To change that, for example to use Python 3 assuming you installed it from apt or made sure it is in your $PATH, `virtualenv foo --python=$(which python3)`. You can also pass a direct path if you have multiple pythons in places not in your $PATH. Say you compiled your own version that lives in /opt/py27: `virtualenv bar --python=/opt/py27/python`. 
It seems like compiling 2.7.10 is the most common response. Strange as almost every popular library has an updated PPA that we can just install via apt-get but there's not one for python? Is there a reason for that?
Thanks! this helps a lot.
That's a good question. I don't know. Maybe no one has step up to provide one. PPAs are often about bleeding edge versions intended for those looking for the latest stuff. In the Python world, that would be 3.x versions. 2.7.x is the boring stuff :)
First of all thanks for replying with your feedback. You deserve cake. Interesting point, I will change the wrapper module into ``selector``. So: from scell.selector import Selector Also, the second point is a good one. I will change the ``Monitored`` objects (which are representations of file-object's interests) such that they are immutable. Do you think that monitor = selector.register(fp, mode='rw', callback=lambda x: x) Is a better API? Or should something else be done? **UPDATE:** I've implemented the recommended changes. Can you check out the ``develop`` branch and provide me with any feedback? Thanks in advance.
Why are they still updating Python 2.7? Isn't Python 3.4 available? Sorry if this is a stupid question, Python newbie here. 
If legacy code is not ported to Python 3, Python 2 can easily stick around for decades. Heck, I installed a FORTRAN compiler on my laptop last week for the same reason: there's code out there that performs, does not need change, but is just written in an old language.
Python 2 will have declining use for probably the next 25 years, if not longer. The reason people keep encouraging new and existing users to choose Python3 whenever they can is to push that time down as much as possible.
Python 2.7 is supported by the Python core team with critical and security bugfixes until the year 2020. There will never be a Python 2.8. Some operating-system vendors (Red Hat) will provide support to their customers beyond that point, but it will reach a point where either you're on Python 3 or you no longer have bugfix/security support.
Meh, [conda](https://github.com/conda/conda) was giving us this capability for the past two years. Pip is just playing catch-up. 
python packaging has struggled for a long time. Conda (http://conda.pydata.org/) seems to be the best solution, depending on your needs.
And it is not forced. It is just hinting for things like IDEs for better suggestions. **Edit:** Guido's presentation in this years (2015) PyCon, related to this PEP: https://www.youtube.com/watch?v=2wDvzy6Hgxg
This basically means that they're okay with more than 5 arguments. OP is not.
&gt; Well, it really doesn't count as "writing bunch of code" Of course it is. Considering your example: class Base: _init_args = [("an_integer", int, 8, "Just an integer you know?"), ("a_name", str, None, "What's yours?"), ("a_list", list, [], "List of some things.") ] def __init__(self, *args, **kwargs): initheritance.parse(self, *args, **kwargs) class Sub1(Base): _init_args = [("a_float", float, 0.0, "I can float!")] def __init__(self, *args, **kwargs): initheritance.parse(self, *args, **kwargs) super().__init__(*args, **kwargs) Compare to the standard approach: class Base: def __init__(self, an_integer=8, a_name=None, a_list=[]): self.an_integer = an_integer self.a_name = a_name self.a_list = a_list class Sub1(Base): def __init__(self, *args, a_float=0.0, **kwargs): self.a_float = a_float super().__init__(*args, **kwargs) In Py3 (and I'm assuming you're using this exact version) you can also specify keyword-only arguments and use annotations to specify types; stuff like help(obj) shows exact arguments that methods accept instead of ``*args, **kwargs`` so you *have* to look to the source. I have no idea how to do all of this with your library and that's why I think you're doing it wrong.
FORTRAN isn't really legacy. For some types of numerical work, it's faster than C and is still both widely used and taught in scientific computing circles. Numpy has a dependency on FORTRAN, actually.
The first snippet would not pass code review in our organisation.
I'm curious about the dynamic chunking feature. If I understand correctly, it uses a rolling hash function with a 4096-byte window, and sets chunk borders where the lowest 16 bits of the 32-bit hash are zero, making the probability of a chunk border at any point 2^16-32 = 2^-16. It also sets the minimum window size to 1024 bytes. With this approach, de-duplication seems to work even if identical data appears in two files at different arbitrary offsets. Are there other Open Source backup solutions with a similar feature? Why is a using rolling hash superior to a fixed set of chunk delimiter bit sequences? On could, say, choose 2^8 semi-random 3-byte (2^24 -bit) sequences and split data at occurrences of those. The same probability (1 to 2^8-24 = 2^-16) would apply. Is there a significant benefit from using a more complex rolling hash approach?
The PEP is a little short on this and just briefly mentioned `mypy` as a type checker - the package where the proposed syntax essentially comes from. I'd have wished a stronger commitment in the form of a CLI option and a default checker in the stdlib. I've seen this before that GvR takes much care about a PEP but is a little scared about the new feature being actually used. The "intentionally ugly" if-else expression comes to my mind when it was designed.
Only a small part of it is for 2.7.10 though.
I found an interesting benchmark: [Comparison of Attic vs Bup vs Obnam](http://librelist.com/browser//attic/2015/3/31/comparison-of-attic-vs-bup-vs-obnam/) from March 31, 2015. It isn't too flattering for Obnam.
2.7.9&amp;#773;
&gt; from scell.selector import Selector Why not just ``from scell import Selector`` as in your readme? &gt; I will change the Monitored objects (which are representations of file-object's interests) such that they are immutable. It is probably a matter of taste, but what about a completely reversed API? from scell.selector import Selector my_selector = Selector(read=..., write=..., error=...) my_selector.set_callbacks(read=..., write=..., error=...) my_selector.read_callback = lambda fp: pass my_selector.write_callback = lambda fp: pass my_selector.error_callback = lambda fp, err: pass my_selector.watch('some/path.ext', mode='rw') my_selector.watch('host:port', mode='rw') my_selector.watch(fp, mode='rw') You usually want to watch many file/sockets but do the same thing with all of them (server). edit: Also, your library is so small it easily fits into a single module file. 
Possibly pyglet uses a bunch of asserts in commonly called functions? I took a quick look at the source, and did notice that asserts are used fairly liberally in places like [allocation.py](https://bitbucket.org/pyglet/pyglet/src/4d5a39b03467e01702aa9efd22c529690878abe9/pyglet/graphics/allocation.py?at=default) If they're having that big an impact, it sounds like it could be worth identifying what ones are called most, and maybe see if they can be lifted out of an inner loop to somewhere called less frequently.
I like how there's a pep for everything what does pep stand for though ?
[ are for lists. If you replace them with curly braces: '{' and '}' then it should do what you expect
Change [] to {}. The first is for arrays, the latter is for dicts.
Thank you! 
Thank you!
If only there was a button you could use to express your displeasure instead of also writing a comment that contributes nothing.
Because of backwards compatibility issues. You can't take an old style class and automatically make it new style without breaking code that depends on the behavior or type of old style classes. That's why the change was delayed until python 3. Thanks, by the way. I didn't know you could subclass object on an old style class.
&gt; Python 2.7 will just die. The way C died, so no one is making anything in C, for ages. Riiiight?
Just so you're aware, in the future, please direct posts like this to /r/learnpython!
Will do! My apologies
Thanks :)
You don't have to do anything to build a wheel cache in pip 7, you just use pip and it'll be managed for you.
No*, because those projects are fundamentally broken. They require numpy in order to execute their ``setup.py``, but pip has no way to determine that they need numpy to execute their ``setup.py`` without first executing their ``setup.py``. It's a chicken and egg problem. This could be solved by those projects ensuring that their setup.py is executable and works with the standard distutils/setuptools mechanisms instead of replacing them wholesale with ``numpy.distutils``. The other thing that can solve this is that a direction we're pushing in, is to remove the need to execute ``setup.py`` to determine dependencies which will make those projects able to declare a build time dependency on numpy that pip would understand, however that's not currently ready yet. \* It kind of can, since a Wheel doesn't require numpy at install time so once you get a cached Wheel built (like if you first installed Numpy and then tried to install that project and the wheel got built + cached) future attempts to install that project will succeed even without numpy installed first. This will of course break anytime a new version of that project is released because there won't be a cached Wheel for it.
Yes. See https://github.com/nickstenning/travis-pip-cache
Are the online python courses still advocating Python 2? When I looked at them a few years ago there was a lot of "don't bother with 3, you won't need it, use 2 instead"
&gt; There will never be a Python 2.8. [Blasphemer](https://www.youtube.com/watch?v=ZNeq2Utm0nU)
The way K&amp;R C died. We now have ansi c, and everyone writes in superset of that.
If only there was a programmer website we could use that only accepts serious questions and answers related to coding that allowed you to upvote helpful responses 
But FORTRAN at least is still well supported. Its not dead. Python 2.7 will be after end of support for it.
Why would C die ? GCC, Clang, etc still receive plenty of updates. 
0.999999... = 1 2.7.999999... = 2.8 &amp;there4; there will be a python 2.8
or traitlets, a less bloated version from ipython
also pycontracts
Guido clearly stated in PEP 484 that Python remains a dynamically typed language. So no matter what the type annotations are telling, the code will be executed by the VM. The impact on the VM will be basically zero. Not sure what the Cython guys are making of it, who use an own system of C-like annotations. Quite possible that we see changes in that area or a new project, which allows for ahead of the time compilation of Python code.
Perhaps it should be a dict? states = { 'Oregon':'OR', 'Florida':'FL', 'Californaia':'CA', 'New York':'NY', 'Michigan':'MI' }
&gt; Is this likely to help performance optimisations, or is it just for type checking? No. It's just for type checking for IDEs.
I just checked the version on Udacity, which is where I was looking at, and they're still using Python 2. They say that it doesn't matter so much but that 2 is preferred for their course.
Yup, that was it! Thanks!
I want another button to flag your post as 'Whiny' please.
Are you using a virtualenv? It is possible that you are either: 1) In a virtualenv, but you used pip globally, so `pygraphviz` is not installed in the virtualenv. 2) NOT in a virtualenv, but pip from a virtualenv was used to install the module. So, were you in a virtualenv when you installed it? Did you use `sudo` with pip?
Sounds like a brand of bra
Not sure how they compare speed wise. Traits has a C helper libraries for fast validation. Traitlets is pure python. 
Y'all need more memes
Very nice - I'll be using this. 
wow never heard of it. So this is free ?
Sorry if this is the wrong place, but I thought it would be fitting here. If you guys have any ideas or contributions to my little project feel free to post them here or on the [repo issues page](https://github.com/Northcode/pypodder/issues). Any constructive criticism is welcome!
this is only for python
Fail. Does not explain *WHY*
Just use __ future__ and everything is pretty straightforward. Google for solutions to particular use cases. Seriously, it will take you an hour or two at most to get up to speed. People make the jump from 2 to 3 (or the reverse) seem like learning an entirely new language, but in reality its pretty trivial.
More like the way B died. Its syntax was almost the same as C, but different enough to be incompatible, and all new development went into C. Eventually there was no reason for anyone to use B. Unlike Python 2, C is still being developed. The [latest version of C](http://en.wikipedia.org/wiki/C11_\(C_standard_revision\)) is more recent than the [latest version of Python 2](https://www.python.org/download/releases/2.7/). There's a lot more Python 2 code than there was B code, but we have a lot more Python programmers today, and Python 2-&gt;3 is a much easier update than B-&gt;C.
and pi is 3.14
It's called "Slashdot". I'm not sure how effective that system was at preventing lame jokes from clogging up the comments, though.
In a similar vein there's [rst2pdf](https://pypi.python.org/pypi/rst2pdf) which converts rst to pdf and is also quite beautiful.
 **Code Complete: A Practical Handbook of Software Construction, Second E...** |||| --:|:--|:-- Current|$33.34|Amazon (New) High|$36.48|Amazon (New) Low|$27.89|Amazon (New) ||$33.34|(30 Day Average) [Price History Chart and Sales Rank](http://i.imgur.com/Rb36xrN.png) | [FAQ](http://www.reddit.com/r/PriceZombie/wiki/index) 
The documentation is still a bit lacking. I plan on making it better this summer. For now you can check the files in the examples directory to get a feeling for it. Also, added this release is a the .generate_tex(filename) method on any of the LaTeX classes included in the library. That way you can create snippets (containing tables or plots) easily that you can include in a normal LaTeX file with the \input{} command.
Very cool! A while ago I wrote a much simpler [TikZ wrapper](https://github.com/roger-/PyTikZ) that was fairly useful at the time.
Yes, every language I can think of has already gone to Unicode by default. (Some use surrogate pairs, generally for historical reasons.) What languages are you thinking of other than C that still use bytestrings as the default? Looking at TIOBE's list, I'd say *maybe* COBOL and Pascal, but it's been a while since I've used them. 
https://github.com/Northcode/pypodder/blob/master/README.md~
Making python3 not backwards compatible with python2 is probably one of the most stupid mistakes made in computer history, imho. 
That is great, and just what I came here to suggest! Sublime work, sir 
The idea is that you can automate the generation of Latex or PDF documents. You don't use it to make a single document - you use it to make a program that generates lots and lots of documents. For instance, generating reports on website traffic every 24 hours and emailing them to a printer, or to make a WYSIWYG math editor, or something else like that.
You're right in a sense that that's what servers usually do. I have yet to implement a way to help the callbacks know if its a read/write event. The current setup is to ignore that entirely and leave it up to the user as to what they want to do with the events and the callbacks. Concerning fitting everything into one file- I'm more of an advocate for separation- if they do not belong together I'm not inclined to forcefully fit them together. Also, it may be my personal preference but I like smaller, more understandable files compared to huge monoliths of god knows what.
Anybody else read that as Playtex?
If I'm porting a latex file, it there a good transition path? Or is it just kill the old file and start from scratch. 
I'm probably missing something, but what's the use case of this? It's not making writing latex easier because I'd estimate the time it takes to look up syntax in latex to be around the same as looking up documentation to use this library. Plus, Python is indent based, which, when you write a more complex latex doc than your readme example, would make it kind of unreadable and non pep8. 
I'm wondering...what's the advantage of this versus for example using python to generate the data which can then be handled by TeX macros.
I read it more like Pile-a-Teck 
The open source project I run is ~250k and it's used by a lot less people than Python. People fork it all the time.
The only performance changes might be less number to string coercion probably going on, but that's probably not that big.
&gt; It's not making writing latex easier because I'd estimate the time it takes to look up &gt;syntax in latex to be around the same as looking up documentation to use this &gt;library. In the sample code, italics was the method "italics". Spending the equivalent amount of time searching the web for what Latex looks like, it looks like HTML and Regex had a baby. 
Yeah but even so, as a programmer you can't just assume a method is named what you think it should be, so you'd still have to look it up. Anyway, I agree with you that latex names are sometimes unintuitive haha. 
There are way more that work in 3 than don't. Most now work in both.
Thank you SO MUCH! This will be an excellent list for me to explore, and it reassures me a lot.
Awesome! Does this have all the scheduled PEPs implemented?
3.5.0b1 changelog: https://docs.python.org/dev/whatsnew/changelog.html#python-3-5-0-beta-1
I've used wx and Tkinter a little bit but have spent most of my time using Qt via PyQt (I haven't tried pysides). I really like working with pyqt - it seems relatively straightforward and pretty easy to use. There's plenty of examples floating around websites, blogs, and stackoverflow.
As a relative n00b who isn't familiar with type hinting, what are the advantages of this? My understanding is that it throws a catchable error if the wrong class input is used, am I correct?
using a little NLP (Natural Language Processing) called "topic modeling"
It seems like you're calling the function incorrectly for getKey it's supposed to be like this stars=sorted(self.stars,key = Point3D.getKey) Here's a sample a mocked up quickly class SampleClass(object): def __init__(self, data): self.z = data self.init_stars() def getKey(self): return -self.z def init_stars(self): self.stars = range(self.z) x = [SampleClass(i) for i in range(10)] y = sorted(x, key=SampleClass.getKey) print y[0].__dict__, y[1].__dict__ #{'z': 9, 'stars': [0, 1, 2, 3, 4, 5, 6, 7, 8]} {'z': 8, 'stars': [0, 1, 2, 3, 4, 5, 6, 7]} And here's the error without defining the class in the key Traceback (most recent call last): File "/Users/avelazquez/PycharmProjects/test/nested if.py", line 38, in &lt;module&gt; y = sorted(x, key=getKey) NameError: name 'getKey' is not defined
It depends on the signature of ``__init__``.
Okay the code you have posted here doesn't match the code you posted above. for event in pygame.event.get(): if event.type == pygame.QUIT: pygame.quit() elif event.type == pygame.MOUSEBUTTONDOWN: pos = pygame.mouse.get_pos() mx=pos[0]; my=pos[1]; for star in stars: self.ifClicked(mx, my) That's not in the code in the original. If that's the case just change it to self.stars Here's the code in the main loop # Handle events. """ALSO CLICK INTERACTION GOES HERE""" for event in pygame.event.get(): if event.type == pygame.QUIT: pygame.quit() elif event.type == pygame.MOUSEBUTTONDOWN: pos = pygame.mouse.get_pos() mx=pos[0]; my=pos[1]; self.ifClicked(mx,my) Do you see what I mean? They don't match. Is that for loop even supposed to be there, cause that's why you're getting th error. 
**+** there are no old-style classes in Python 3.X.
Sure. What's the pay look like?
Have you seen http://docs.python-requests.org/en/latest/ ?
I think you need to walk outside and get some sun...
so, why python is so popular and but mess in versions? 
Last Friday.
That's a good point. Something odd must be going on here because even in 2 those aren't old-style classes.
Fantastic work. Kudos to the entire team, and everyone else involved. 
Maybe you can use objects. This will give more lines of code but will make it better.
I'll wait to have a better-looking site before trying /r/osgi
Improving over this, you could put all your lists that you want to iterate in a single variable, and use itertools.product. from itertools import product listOptions = [["Option1", "Option2"], ["MoreOption1", "MoreOption2"], ["AndMoreOption1", "AndMoreOption2"]] for item in product(*listOptions): print(", ".join(item))
Ah OK, that makes so much sense. Unjustified magic is usually not good but justified and well implemented (in your case) magic is a lifesaver. +1!
Uh, sorry, it should be this from itertools import product listOptions = [["Option1", "Option2"], ["MoreOption1", "MoreOption2"], ["AndMoreOption1", "AndMoreOption2"]] for item in product(*listOptions): print(", ".join(item))
I use it for reports as well, just not to generate full documents. Just for some specific snippets that I then include with \input{} in my actual latex file. This can be very useful for stuff like plots generated by matplotlib, tables or matrices. That way you can change your code a bit and the correct data is used in your latex document.
You can already use mypy as a static typechecker 
I use it a lot to generate snippets for plots or tables that depend on data generated in python. Those snippets can then by included in latex using the \input{} command. That way, when you change your code a bit the data/plot in your latex file is automatically updated. The usecase mentiond by /u/ertlun is very useful for a webproject I'm working on.
The remote debugger of PyCharm helped me a lot of times. Else: [pdb](https://docs.python.org/2/library/pdb.html).
I realize it's GvR. Your original message made me [look it up](https://mail.python.org/pipermail/python-dev/2005-September/056846.html) because I couldn't believe what you were saying. &gt; The priorities will be such that you can write &gt; x = A if C else B x = lambda: A if C else B x = A if C else B if D else E &gt; But you'd have to write &gt; if (A if C else B): [x for x in seq if (A if C else B)] A if (X if C else Y) else B (A if C else B) if D else E &gt; Note that all these are intentionally ugly. :) The context helps. "Doing this makes these nasty bits of code really ugly too. That's good :)". That's how I read it anyway. Python is the only language I know of where the designers openly use the beauty of code as a way to guide it's use. :-)
Kudos for asking this question. Python, unlike most mainstream languages, allows us to factor out flow control structures. In this case, it is "for each combination of". Learn to separate flow control from business logic, and your code will be awesome!
Note that landscape.io doesn't do Python 3 yet, I had some issues with it myself then found out it currently only does Python 2: https://github.com/landscapeio/landscape-issues/issues/32
`zip` stops iterating, when any one of the iterables is exhausted. This doesn't iterate through all possible values of the three lists.
Indeed, 3.5 is going to be a great release! Lots of useful new features.
What I mean this, your library seems useful as a temporary workaround to fix someone else's badly designed code. However, for us the correct solution would have been to fix the original code in the first place, rather than apply an unusual workaround and start building technical debt. I don't dislike your library. It will certainly help someone, somewhere.
What about JSON?
Per my other comment, if your starting point is JSON, take a look at Mongo. It can directly import the data and the python interface (pymongo) is straightforward.
No, there's no runtime type annotation checking (yet?). This is for external static code analysis tools (e.g. mypy).
It's also possible that pyglet checks the value of [\_\_debug__](https://docs.python.org/2/library/constants.html#__debug__) and enables its own optimizations.
Can't wait. The core team is made up of amazing folks. They inspire us all.
Although somewhat outdated, incomplete and, in the case of scikit-learn, misspelled.
I use PyDev and its remote debugger otherwise same. 
yes, this is pure clickbait, there's no content. please downvote!
There are no plans as yet - it's mostly oriented towards type checking for tools. That said, you could imagine packages like numba enabling JIT optimisations without needing decorators, or Cython accepting them instead of their curent custom syntax, or PyPy using them to make extra JIT optimisations 
To keep things together in one place, could those wishing to make a comment please do so in the linked /r/scipy post. Cheers.
Using mypy with python 3.4. Mypy is still a bit wanky. It works as long as you dont go out of the standard path (it chokes on asyncio for example). Hopefully it will be much more complete/compatible when 3.5 hits
One of my patches made it in. I'd be excited except that I submitted the patch July 2014, and only last week, after prodding, did someone actually review and accept it. Seems pointless to even submit bugs...
Type hinting! Finally the real reason to migrate to Python 3!
You can use from __future__ import division, print_function, absolute_import, unicode_literals to get some of the features of python 3 in python 2.7
/r/Python is for news and releases. You'd be best going to /r/learnpython in future, which is for questions. That said, you got a fair few answers here.
What happens using the other (apparently more appropriate) approaches offered in this thread when one of the iterables is exhausted? 
This project looks very promising! Once thing that i miss a lot in the python environment, is the lack of an easy to use email template library, to send the kind of emails that companies use (not text, but html). A library where you could implement html templates without mandatory inline css (let the css be interpolated at render time), and with a proper image insert. Were you thinking of tackling that angle?
Sorry for all the down votes. `import this` &gt; simple is better than complicated
sorry guys, I am beginner tech blogger. All your posts are very valuable feedback for me, in my future posts I will be more careful on these issues. About guide: I wrote guide because I am going to add some tutorial and examples into this post. For now I just collected most used links/tools because I myself use them very often.
What has line of codes related to complexity?
Well, off the top of my head: for basics, statistics and statsmodels; for scraping, mechanize and selenium (and even lxml); for text mining, patterns; for machine learning and data mining, blaze, sqlite and sqlalchemy I also think dataviz packages like ~~matplotlib~~, plotly, seaborn and bokeh are important for data analysis, plus boto for AWS. Edit: matplotlib's there. 
https://github.com/chriskiehl/Gooey
Does it assume the structure is the same for all entries? Otherwise, how does it deal with varied content across entries?
My fear is that Python's type system will be as limited as Java's (or even more so), leading "enterprise" developers (once mypy or other static type checkers are mandantory) to write Java code with Python syntax. But I guess we'll see if my fears are unfounded or not. (Yes, I'm a bit disappointed they chose to go the nominal type system route instead of the more dynamic language fitting structual typing)
&gt; It's 700 years old; they're still finding bugs? You are right. They should let 2.x die and stop tweaking it. The change over to 3.x can't happen if they keep fixing 2.
&gt; The highest rated comment contributes nothing It contributes quite a lot, by demonstrating how mis-managed the change over from 2.x to 3.x is. 5 years ago they allocated 5 years for it, then they backported exciting features from 3 to 2 giving people exactly zero incentive to change over. And now they're STILL fixing 2.x because: I don't know why. If it isn't a security issue it should NOT have been fixed. The situation is a bit crazy.
It's a little tough to tell, but I'm pretty sure after 6 layers of indirection, that's exactly what using `@task` does (except with `task_cls = 'celery.app.task:Task'`). What do you mean initializing the logger? Take a look at the underlying code and you may find that you aren't doing anything significant. What do you mean initializing redis? Take a look at the underlying code and you may find that you aren't doing anything significant also!
[Active-SQLAlchemy](https://github.com/mardix/active-sqlalchemy) makes it even easier to use, if you still want to use SQLAlchemy
Maybe I haven't been clear. When I say "this is not the typical use case for celery", I mean for the whole use case I'm describing, and not just the abstract task with redis and a logger. This was just an example to clarify how my application is built on top of celery, as demonstrated [here](http://celery.readthedocs.org/en/latest/userguide/tasks.html#custom-task-classes)
Good feedback! I come from the VFX world which is stuck in the world of 2.7, but will take a look at writing an addendum for 3. Any thoughts on the rest of it? Thanks!
Product works fine because it doesn't assume symmetric lists. &gt;&gt;&gt; A = ['a1', 'a2'] &gt;&gt;&gt; B = ['b1', 'b2', 'b3'] &gt;&gt;&gt; import itertools &gt;&gt;&gt; for combo in itertools.product(A, B): ... print(', '.join(combo)) a1, b1 a1, b2 a1, b3 a2, b1 a2, b2 a2, b3
I think we found the Java programmer. ;-)
Ah ok. I think it is likely that celery is a good fit for your goals (with some warnings). I think the fact that different aspects may have different parallelizability, means that you're likely to benefit from things like chords, where you would branch out to calculate one stage and then merge the results to calculate another. My main warning is that you ensure individual tasks can clear your pipeline. Imagine you have 3 tasks, one which queues a bunch of scraping jobs, one that scrapes individual pages, and one that puts the results together. If you put them on the same queue, you are likely to leave the third task unfinished for a long time so if you did something like `task_chain.get()` expecting to trigger #1, fire off a bunch of #2s, and then collect in #3 and return that result, you'll be waiting for a long time to finish. What would be better? If you handled it "eagerly" you might even get the results back quicker just by waiting for each of the #2s to finish in turn. If instead, you had task that triggers a bunch of scrapers, each of which scrapes a site and then writes the results to a database, you'll be able to start using the results before they've all been collected. If you chose a multiple queues approach, be careful about any meta-tasks. In my experience, they'll end up on the default queue which you might not have any workers listening on.
Thanks a bunch :) 
Maybe you have already seen this package, but [nflgame](https://github.com/BurntSushi/nflgame) is possibly similar to what you are building up to, if you need some inspiration. I currently use nflgame for some fantasy stuff... I look forward to possibly using what you come up with as MLS fantasy (hopefully) picks up. Dunno much about how it nflgame works deep down, but my understanding is that the live game trackers have some json that can be grabbed and parsed pretty easily. Maybe pages like [this] (http://matchcenter.mlssoccer.com/matchcenter/2015-05-27-seattle-sounders-fc-vs-colorado-rapids/preview) have some similar underlying structures?
Enthought traits for Python3?
Too many buzzwords in title.
None of that requires active development of 2.x.
use pastebin also /r/learnpython
Also quite a good option to know how to use it properly is to check out the source code for tito's 2048 game made in kivy: https://github.com/tito/2048 It helped me a lot to structure my kivy apps better and to package them for android.
Am I the only one who can't read this blog? The formatting is horrible, and the entire opening sentence might as well be gibberish.
Everything from rightrelevance.com is shit from a spam ring.
I would argue that bug fixing is quite different than *active development*. Bug fixing is needed even for old releases.
It has a JSON column type, and each row could be different. Special functions allow you to address parts of the JSON object.
[caniusepython3](https://pypi.python.org/pypi/caniusepython3) seems to be just what you're looking for.
Is landscape.io running the linter in Python 2?
That surprised me - everything else worked fine in Python 3.4, so I assumed it would be compatible. 
Are there any other weird linting behaviors? Does it balk at the print function for example?
I have not tackled those problems yet, nor have I ever faced the need to make dynamic CSS. However I think those do not belong in an email library. :) Currently there's two ways to embed images. One is to set the Content-ID tag and using cid. Another is the inline images technique, both have their upsides and downsides. What do you refer to by "proper image insert"?
If you're wondering why you're being downvoted. There's no need to set repeat to 1 since that's the default but more worryingly you've redefined the ``tuple`` builtin.
Hey there! Posts like this are more appropriate for /r/learnpython or in this case for /r/pygame. I've removed this and I urge you to try out /r/learnpython (no matter which stage at python learning you're at it's a very useful and awesome resource).
 g = ("{},{},{}".format(a,b,c) for a in listA for b in listB for c in listC) for i in g: print i 
&gt; in a stub file That was definitely not considered. While something like that may work in C with its header files, Python's files define the module namespace, so something in a separate file would be in a different namespace. Not to mention, you can do this today in one file: def greeting(name: str) -&gt; str: pass def greeting(name): return name and you won't even see the type annotations: the second instance of `greeting` overwrites the first.
You can use a CSS framework ( i've done this with bootstrap ) where you just build a fancy html table with data from the dataframe. Here is the basic code http://getbootstrap.com/css/#tables. I think you could make your own css class and just assign it to whatever row to want to fux with.
Actually, just pip freeze them all to a requirements.txt and run "pip3 install -r "directory/requirements.txt".
I really preferred when people were asking questions here. There were more posts and more interesting answers. But this seems to be the majority view or at least the /r/Python moderator's view.
CPython 2.7.10 is [available in the latest version in the latest pyenv](https://github.com/yyuu/pyenv/commit/cc94ad39f15845b29e61508d356567eb00f39d4f). We usually manage to get new versions of CPython added the same day they are released.
Many packages will install but will fail at runtime. &lt;3 dynamic languages
Well, that just seems like a fuckup with pip.
wordpress' built-in search
You probably should have chosen a name that wasn't already used in the Python ecosystem then....
Sure. But I bet that course/learning platform was developed 3-7 years ago or by decision makers who base their knowledge of python version based on information from back then. Unless they want to teach some new features, they probably have little motivation to switch, especially as most of the community is still using python2. Again, most of the differences are quite small: * print is function instead of unique syntax, * things like `range(10000)` and `some_dict.items()` returns an appropriate iterator instead of having to do `xrange(10000)` or `some_dict.iteriterms()` so by default you loop over them the efficient way. * python3's str `type('I ♥ python3')`is what python2 called unicode and required u-prefix like `u'I 💔 python2'` and is a sequence of printable characters including non-ASCII unicode codepoints * python2's str is now called bytes and it requires a b-prefix like (`b'unicode char would cause exception`) Unicode by default fixes an annoying issue where accidental string processing of plaintext that has a unicode character inserted crashes the application -- and this isn't just internationalization -- don't forget about benign unicode characters that applications sometimes insert like left-right quotation marks (an array of bytes is the unusual syntax) so applications don't crash if someone provides input that is unicode (and this isn't just internationalization stuff -- another application changes the typed quotation mark to a [unicode left/right quotation mark like [‘](http://www.fileformat.info/info/unicode/char/2018/index.htm) [’](http://www.fileformat.info/info/unicode/char/2019/index.htm) [“](http://www.fileformat.info/info/unicode/char/201c/index.htm) [”](http://www.fileformat.info/info/unicode/char/201d/index.htm) that was cut and paste from elsewhere). There are differences under the hood and some fancy new python3-only features, but its pretty easy to jump from programming in python2 to python3. . 
~~Or perhaps `super()` (without the `__init__()` part)~~ I'm wrong.
It is not as useful as you think, a package you do today may still be compatible with whatever python version you have in 20 years, even if you don't update your package. You shouldn't just casually add dependencies to your software anyway, so you should already read the documentation to see if works with your python version, operating system and other dependencies you already have.
No. `super()` just returns a "proxy object" (I'm not even gonna pretend to understand how `super` works under the hood), no method calls are made on it, not even `__new__` or `__init__`.
&gt; so you should already read the documentation to see if works with your python version If the documentation already lists what python versions it works with, how is it anything short of simple to add version flags to the packages on PyPI?
Then pip just needs an option to bypass safety restrictions if a package isn't officially supported with your version of python. &gt; I doubt it would be backported to python 2.7. I doubt *anything* is getting backported to Python 2.7 anymore.
That would work.
Should have known that if I had a good idea, it's probably already implemented.
I tried this first, but the database grew too fast so I had to switch to PostgreSQL instead.
Looking forward to PEP 448 - that's really useful! 
Agree on all fronts. I totally disagree with this type system being included in Python, I think its included as a clutch for programmers so dependant on it (i.e. writing shoddy code where the wrong type can be passed in the first instance, and accepted in the second instance) that they blast languages like Python as being "toys" because of the lack of this feature. It's a bit like Windows users who can't deal with a superior user interface that doesn't have the start menu in the bottom left corner. Let's throw out the baby, the bath water, all the toys, and go back to 30+ year old awful junk instead of improving ourselves. 
I would expect PyPy to not segfault only because a programmer did set an ill placed annotation. AFAIK they built a tracing meta-JIT compiler, an algorithm which builds a JIT along PyPy's RPython code, which then measures types as they flow in during code execution, which leads to machine code compilation of bytecode sequences ( I hope I didn't got that 180° wrong! ). So in principle this isn't much worse than ahead of time compilation modulo global analysis. What Python will still slow down - I made experiences when translating Python code to Cython or Java - is simply its generic, high level nested data types. So expect indirections and cache misses also with sophisticated JIT machinery or lots of type annotations. Considerable speedups are possible occasionally but they will only go so far.
Are you referring Enthought traits or something else? Choice for name comes from the fact that other languages (e.g. Scala) are using same name for this exact idea. Also, you can find correct documentation from wikipedia by searching "traits".
&gt; Under the hood, methods are recompiled on top of new class or instance. This is because there is no other way modify function's attributes to match new object. All the details are found from here: https://github.com/Debith/py3traits/blob/master/src/pytraits/sources/routine.py Wouldn't that fail for names that are not mangled (eg: `__foobar__`)? &gt; Do you have ideas how to improve documentation in general and/or in examples? Some practical examples and overview for people not familiar with the "traits" concept would be very useful. Eg: If you'd want to use this in, say, a Django model or a CBV, would it be a good idea? How would it look? What would the benefits be?
Right now it just downloads every episode and that's it. I'm thinking of having some sort of mechanism for marking them as old or deleting them. I'm quite new to python so I didn't know feedparser was a thing. I started this project because I couldn't find a lightweight podcatcher without a gui that does id3 tagging. Thank you for the suggestions! 
You should probably not link to the docs before you've fixed them.
You're right, I should have had a tuple where there was a `zip`.
Cool! TIL 
Do you need to do anything specific if *each* server reports a property larger than zero? In your code, the same thing happens if `code == arrayLength` as when `code` is anything else greater than zero. With that in mind, I would do something like this. while True: # get ServerStats if all(s['curclntconnections'] == '0' and s['cursrvrconnections'] == '0' and s['svrestablishedconn'] == '0' for s in ServerStats): break On an unrelated note, I find names such as `getmemberserverstatsbyserver` horrendous.
This looks like it could very well work. The only condition I care about is if ALL properties are 0, OR if ANY property is NOT zero. If all properties are 0, exit loop, if ANY property is NOT 0, continue the loop. The looping is really a timing mechanism that is going to allow the server to drain stop it's current connections.
Indeed, there are a ton of different methods to accomplish motion detection/background subtraction (I actually reference 3 of the best/most popular ones in the blog post). The problem with doing two nearly consecutive frames is that you can lose the true "background model" of what is background and what is not. Another approach could be to compute the weighted average between the past N frames. This works well and can account for new objects being placed in the environment, but can also lead to a "ghosting" effect. Obviously the approach detailed only works in situations where lighting conditions are somewhat controlled and where the background is static. But for advanced systems you'll want use Gaussian Mixture Model or Bayesian based background modeling -- the downside of these approaches are that they are computationally more expensive, and since the end goal of this article is to deploy to a Raspberry Pi, they are not the most appropriate.
It's late at night, I'll add more documentation to the readme. But, this was simple work, done on the train. I've never made user of __getattr__ before so that was interesting. Any comments/criticisms would be loved.
Buy a little VPS. It's not that expensive, and it can run small Python scripts.
Another try to mimic a feature of better language?
The only thing is, ServerStats need to be re-fetched every time the check fails. 
agreed, removed
&gt; So don't opening more bugs against pytz. *Sigh~* Why are python developers so hostile to bugs? Why does getting a bug report cause python developers (particularly Plone developers... &gt;_&gt;) to rage quit and stop maintaining their packages? Such a community fail. If you code causes people to rage, that is not because your code is awesome and amazing and bug free. If no one tells you, it *isn't a good thing*. Come on! When dozens of people report a bug, it's not because they're all stupid. Maybe we should look at fixing the problem, not just ignoring it? &gt; Opening bugs against pytz will just annoy the developer more, they'll drop the project, and we'll be stuck forever with Python's lacking standard library interpretation of datetime and timezones. I hope you appreciate the irony of saying that. We're **already** stuck with a lacking standard library. How on earth is doing nothing and just accepting the status quo going to help? Anyhow, here's some advice for people who dig this old thread up: Use arrow (http://crsmithdev.com/arrow/). It runs on 2.6, 2.7 and 3.X and it's lovely.
 import this 1. Explicit is better than implicit. 2. There should be one-- and preferably only one --obvious way to do it 3. Special cases aren't special enough to break the rules. 4. Although practicality beats purity. (so why not...) 
I used Learning Python and Programming Python 3. http://www.amazon.com/Learning-Python-Edition-Mark-Lutz/dp/1449355730 http://www.amazon.com/Programming-Python-Complete-Introduction-Language/dp/0321680561 Wesley Chun and David Beazley have some texts you may also want to check. http://corepython.com/ http://www.dabeaz.com/per.html Get a general Python book covering the language and then another that shows its application through examples. 
is it worth the 60 bucks? ive already worked a bit with python so id like to know how advanced this is
Just a suggestion- Don't put at the top of the page "Here in this article you can find X, Y, Z" if you haven't yet added some of those things. If you plan to add tutorials in the future thats fine - but don't say at the very top of your page that you can find tutorials if they are not there yet. Instead maybe format it like " Here you can find X, Y; In the future I will be adding Z" Also - try adding some actual text to your list of tools and descriptions to explain how things are used. For example your first entry "Numpy - numerical library' ... that's basically useless.
Reinventing wheels gives one a nice appreciation and understanding for how the car drives, imo.
When the goal is reinventing the wheel being well aware of it.
There is a very easy linux program called "motion" which does exactly that. Its faster because its c++ compiled code. But have to agree its a great little project.
That reminds me, I used [RPi Cam](https://github.com/silvanmelchior/RPi_Cam_Web_Interface), which I believe uses motion. It has a nice web interface.
Thanks a ton for this! This is really clutch. 
The way it works with Python is that you build the web server itself in Python. [This](https://wiki.python.org/moin/WebFrameworks) is pretty good table for someone who's just starting out.
This doesn't seem very useful or well-thought-out, I wonder how and why it has gotten nearly 200 stars within 18 hours. Soon the author will realize that only a tiny percent of all automation tasks involving HTTP requests can be written in such an entirely static way, and most will need to parse and/or compute certain values on the webpage. So suddenly there's a new issue: there needs to be an easy way to reliably retrieve values from the webpage, so the author might consider adding a command to use CSS selectors or XPath, possibly even a parsing library like BeautifulSoup. Then, soon after, will follow a scenario where a value needs to be modified or computed in some way before it can be used in the next POST or GET request (completely ignoring the missing implementation of the other HTTP methods), so the end user will need a way to execute some code in a limited fashion, which will need access to the stored variables. And later, one might want to work with conditionals, and only execute one branch of code if a certain condition is set and another if another condition is set... you might see where I'm going with this. Also see the [Inner-platform effect](http://en.wikipedia.org/wiki/Inner-platform_effect).
Thanks for this. The line-by-line really leaves nothing to the imagination, and it was a really interesting read that gave me a basic sense of how OpenCV works in Python. I've not done any real work in Python and I've never done anything in OpenCV, and I feel like I could sit down and follow this with no trouble at all. Well done. 
It's not a big deal, but if you make a list, the entire list will be allocated in memory before the `all` function is called. If you make a generator, the values are produced and consumed "on the fly" with the memory footprint of a regular for-loop. Unless the list is big it won't particularly matter, but it's a habit I've gotten into to prefer generators when possible for this reason.
The fact that we can traverse through filesystem faster seems to go under peoples radar. &gt;[PEP 0471 -- os.scandir() function -- a better and faster directory iterator](https://www.python.org/dev/peps/pep-0471/) os.walk is reimplemented using it, but otherwise stays the same syntax wise. By my testing, it cuts scanning my drives(1xSSD, 2xHDD) with some 1.3 mil files from ~2m40s to ~1m30s. Thats on linux, on windows it is suppose to be even bigger difference. &gt;In practice, removing all those extra system calls makes os.walk() about 8-9 times as fast on Windows , and about 2-3 times as fast on POSIX systems . also theres new os.scandir function, which makes it pretty easy and fast to go through filesystem structure and get files/directories and attributes and other details, it also returns generator, so you can yield stuff, saving ram and shit, if I understand it correctly. 
You're already doing most of the work in the shell, why not pipe the hostname list straight to `wget` and not use Python at all?
The weirdest part of using Docker for python development for me is that you really don't need a virtualenv anymore. Since the container generally is just for a single service or app or whatever, you can just install everything into the system python.
&gt; 'ababababbbbababab'.count('bb') &gt; 2 I count 3x bb
His result matches the interpreter. A character can't be counted more than once. 
Nice to know how Pythons string parser works, thanks for the answer :). 
If ya keep giving us the good stuff, we're never gonna move on.
Oh dear I did miss that s... Originally they were the same method, but I decided to split them, as they're listed as different calls, and behave slightly differently. (Didn't know gifs_by would work with one id though) I tried using the response.json idea as it would have saved lines, but it was throwing errors. That method for the Id parameters is certainly nicer though. Thanks! I'll fix that missing S up soon
I just came here from the C++ threads. Over there we look at things like ; How do I make this calculator work? And here you python mothafuckas are, calling home surveillance basic. I'm done with life.
I have dependencies that are Python 2.7 only. I can't replace them and I'm not about to make a Python 3 version of VTK and I'm not about to use a beta version of WX or rewrite my code in PyQt5. My code supports Python 2/3 where possible, but I see no reason to drop 2.7 support until it's not required. It's not like Python 2.7 isn't more popular either. Python 2.7 dominates the landscape at ~80% usage.
I'm not crapping on it, my post was as far as I can tell pretty objective and valid criticism (coming from a biased source of course) since I can't see this going any other way. And you just confirmed that my predictions seem to be right: &gt; I have started to add features that allow someone to modify/grab values in the HTML. Exactly that is one part of the scenario I described in my comment. Feel free to convince me otherwise.
tutorial sites like http://tutorial.djangogirls.org/en/index.html do you have any to share?
Oh. I meant [the official Django tutorial](https://docs.djangoproject.com/en/1.8/intro/tutorial01/) on the Django website.
Yours average host like BlueHost wont give you this option.
It has already been said but I would definitely check out flask. It can also be paired with a more enterprise web server like NGINX using uWSGI which is very easy to do and works well.
 from TwitterAPI import TwitterAPI TRACK_TERM = '#SubwayDelays' CONSUMER_KEY = 'yours' CONSUMER_SECRET = 'yours' ACCESS_TOKEN_KEY = 'yours' ACCESS_TOKEN_SECRET = 'yours' api = TwitterAPI(CONSUMER_KEY,CONSUMER_SECRET,ACCESS_TOKEN_KEY,ACCESS_TOKEN_SECRET) r = api.request('statuses/filter', {'track': TRACK_TERM}) for item in r: if item['coordinates']: print(item['coordinates']['coordinates']) 
Generally your docker app is based on some parent container, which presumably has fixed versions of everything. If you want to do a system upgrade, that would be part of a new build, and any breakages would occur at that time.
Python for Data Analysis by McKinney (ISBN 978-0-596-80956-0) is a great intro to Numpy, Scipy, and Pandas, along with a smattering of other libraries and tools. I'd recommend it to get started.
Django is nice but sometimes miss the power of Rails and also find models customization a bit lacking - unless you recourse to subclassing and thus introduce extra database queries.
Docker doesn't use parent OS software. You can even build a docker container on one PC and run it on another.
so you'll save 18 microseconds in CPU time while you wait around for 250 milliseconds on network IO time?
how do you mean exactly? what do you do in Rails that you find harder to do in Django? "model customization" is a bit vague. can you be more specific?
Turns out the error with .json was me going result.json instead of .json() - and how I was structuring the URL for gifs_by, I've fixed these issues, will publish the fixes when I get home from work
Any host that gives you root access to a unix box will allow you to do this.
every course is 10 bucks on there right now
Per the latest survey https://wiki.python.org/moin/2.x-vs-3.x-survey?action=AttachFile&amp;do=view&amp;target=2013-2014+Python+2.x-3.x+survey.pdf There's was another official survey from a year before that (with I think ~3 questions as opposed to ~8). If you look compare the two (no idea where that document is), you'll see Python 3 is gaining ground, but very slowly.
Keep in mind the fact that Linux Distros and OSX come with Python 2 which is large reason it is even at 80% Ubuntu I think was stating plans on coming with Python 3 instead of 2, which will no doubt get the other distros following along. Watch the number drop.
Start with something simple like bottle or flask. They basically let you tie urls or url patterns to python functions, calling the function on request and returning the return value as the response. Flask is by far the more popular option- bigger community, more online resources, more mindshare- but I personally prefer bottle for its simplicity, the fact that it's dependency-free^1, and its application mounts^2. Here's a simple example: import bottle @bottle.get('/hello/&lt;thing&gt;') def hello(thing): return "Hello, {}!".format(thing) bottle.run() Now, if you do an HTTP GET /hello/world, the response body will be `Hello, world!` ^1 This was especially obvious when I was trying to use an HTTP error exception. In flask, you have to dig into Werkzeug, one of the dependency libraries, in order to do this. ^2 I find I use these a lot when creating more structured web applications, separating out different parts of the API into different modules. They don't really have an equivelent in Flask (that I'm aware of), except as second-class citizens via Blueprints.
It was an official survey done by python.org ~4800 people, which isn't great, but isn't bad. In one of his talks at Pycon, Guido discusses the poll, so it's being taken seriously-ish be him. It's enough to show trends if you assume that the type of person who found the poll the first time and did it filled out the poll the second time. It's certainly enough to say Python 2 is far more popular and that lagging dependencies is a real issue. In his talk, Guido also mentions that a lot of people don't know that pillow is the new PIL and there are a lot of dead packages that people depend on. He called for the community to help track down take over the projects and port them or put up a "dead project; see x" notice. Nobody wants to depend on "dead" packages. Then again, we still have some Perl.
Can't you just yum/apt-get Python 3? My computers have specific packages and versions not because I'm not lazy, but because I want that version. I doubt any company is using Python 2 just because it's there. I'm sure it'll help a little, but I think it'll help only a little.
You'll need this coupon code: INSPIRE1010 I thought I missed the sale until I looked for that!
What's the target use case for this? Is it for doing basic HTTP tests, a-la the [Postman REST Client](https://chrome.google.com/webstore/detail/postman-rest-client/fdmmgilgnpjigdojojpjoooidkmcomcm?hl=en)? And, if you don't mind me asking, why did you go with a new domain-specific language, rather than creating an ultra-simple Python interface, or using a language that already lends itself to domain-specific syntax, like Ruby, fish, or bash? Many of the problems you're likely to run into as you add functionality to the language (especially those involving string and newline quoting, parsing, and error reporting) have already been solved extremely thoroughly. 
Sure, but people use the one that's already there. Which is easier; convincing people to install something before using your program - even if it's a single command to install - or using what came with their system?
&gt;There are still a lot of software that still depends on 2.x for various reasons. It's been what, seven years now? If it still depends on 2.x seven years later, there aren't various, just one, reason: the developers simply aren't bothering. The original project head of Pyjamas, when asked about a 3.x port, responded "Why should I port to Python 3 when Python 2.x is going to be supported forever?" And that, in a nutshell, is the mindset behind almost every holdout. &gt;In many cases, porting to 3.x is not trivial, it is expensive, it is time consuming &gt;and it is error prone. That's life. It's technical debt. We moved on from Windows 3.1 and Android 1.5. Software left to its own devices experiences "bitrot". You always need to be updating it to work with newer libraries, OSes, hardware, etc. I remember talking to one Java user who said he "couldn't wait" to refactor his code to support the newest Java features. He didn't start complaining about it being time-consuming and error prone. Property tax is the cost of owning a house; maintenance to avoid bitrot is the cost of producing software. &gt; Sticking with 2.x and 2.7.x is often the most reasonable decision. Actually, it's **never** the most reasonable decision. At some point, support for 2.x **will** end. The longer one delays supporting the current version of Python, the more differences there will be and the harder the work involved. The longer one continues to write code in 2.x, the more code will need to be ported. Delaying just means you have more work to do and less time to do it in. That's never the most reasonable option. 
Awesome. Great tools here.
Spoilers: CGI is like stone-age technology. The modern standard is WSGI. Flask, Django, and pretty much anything released in the last decade uses WSGI. The short version is that an HTTP server (nginx, apache, lighttpd, etc) invoke your application code and pass it a "context" payload, which contains things like "what URL is being requested, details about the HTTP request (GET/POST parameters, HEAD, OPTION, etc)" which is then interpreted by your WSGI-enabled application and then passed on into the actual application context.
yeah, I'm a self-taught hobbyist, and setting up flask/nginx etc is a fucking brain haemmorage of a job. If you know what you're doing maybe it seems obvious, but the online tutorials aren't really that helpful as you're forced into making choices about what to use without having any idea of the trade-offs. Also, there is the security side which is a big worry...most of the online help doesn't give much away in terms of how easily ripped off your box is. The best I found were the digitalocean tutorials, but they stop short of covering some of the customisation stuff. In general I think it's really hard for a python programmer to get their code working as a back end without a lot of server experience. It's a real problem for the community as it would be a lot more gratifying to easily be able to get my scripts' output into a web page.... 
This github project was included into Python 3.5, not backported to Python 2.7
Django is definitely sweet. There are also many plug and play applications you can just insert into your existing application. (This is one of the things I love most about it) Check out [django packages](https://www.djangopackages.com/) if this interests you as well. It's really nice having some open source libraries with many eyes on them.
We don't do homework for people and certainly don't do homework for money. Do it yourself and actually learn something.
I'm currently taking this [course](https://www.udemy.com/learning-python-for-data-analysis-and-visualization/?ccManual=&amp;dtcode=7Lr9k262ZhgJ&amp;couponCode=DEAL10) and have been pretty happy with it since it covers multiple Python/Data topics. Also I used DEAL10 for a coupon to get it at a heavy discount, though I'm not sure it that is still active.
I have 200mbps and requests is still IO bound on my old i5-2500k, I was actually surprised recently how fast stuff had gotten without me really been reminded for a while, 500Mb of XML parsed in a few seconds and such. 
Haha, rereading that, you actually may have just written my entire development process.... which is bad :P
I had to submit check requests through an antiquated work website all the time to the same people. I automated it using python and selenium. Provided the script to my whole office for similar tasks. Probably saving 10 hours/week of time for the office. I would share it company wide, but I'm worried they'd come up with some ridiculous reason to disallow it.
This guy https://youtu.be/OSGv2VnC0go
Your friend just posted this too. Your teacher must suck to inspire two students to beg for others to do their work for them. Get together and bring it up with your teacher that they are teaching you jack shit.
Hahahaha 
Not a friend, likely the same person. Both requests contain "I don't know it can someone make what I want". This bad grammar/typo is unlikely to have been exactly replicated by two posters.
Pythonic (adjective): Of, relating to, or resembling a python. --- ^(I am a bot. If there are any issues, please contact my [)[^master](http://np.reddit.com/message/compose/?to=Spedwards&amp;subject=/u/Define_It)^(].) ^(Want to learn how to use me? [)[^(Read this post)](http://np.reddit.com/r/Define_It/comments/31vrec/define_it_how_to/)^(].)
as it so happens the to_html function generates the dataframe visualization in ipython
Which package is that? Sounds very useful.
For example adding a single field to `django.db.models.Model`. Because Django's metaclasses perform all *magic* on fields at the place of class definition, you are left to subclassing or some half- or undocumented trickery with monkey-patching using contribute_to_class or direct modifying of _meta attributes. Plus the hassle with migrations as django-admin won't see them and they need to be written/updated manually. 
Wow. Amazing that there's a package with such specificity. You sure hit the productivity lottery w that one.
And, they also fail if you move really really slow.
http://lmgtfy.com/?q=Django+Model+Field+Injection Also templating system sometimes stays in your way. Try for example wrap a value passed to blocktrans in a html tag. Did end up many times writing custom template tags or even patching views at solving relatively common demands.
Django is so awesome, they even release releases and bug fixes for older versions like 1.4 Check this: [Django 1.4.20, 1.6.11, 1.7.7 and 1.8c1 on March 18, 2015](https://www.djangoproject.com/weblog/2015/mar/18/security-releases/) Please donate to Django - https://www.djangoproject.com/fundraising/
I struggled with it for over a week just adapting to the new concepts after my previous experience was all on Windows servers as we were an .NET shop. Though once I understood some concepts my servers have been very reliable running flask + uwsgi + nginx on a server though using virtualenv. 
Had to give up on package systems since they seem to all have their own way of doing things. Just use the language. 
One thing you could take advantage of is the fact that the bool type (True/False) is a subclass of integers. This causes `True + True + False` to equal `2`. To set the code variable, use code = sum( ( (ServerStat['curclntconnections'] != "0") or (ServerStat['cursrvrconnections'] != "0") or (ServerStat['svrestablishedconn'] != "0") ) for ServerStat in ServerStats ) Alternately you could do code = sum( 1 for ServerStat in ServerStats if ((ServerStat['curclntconnections'] != "0") or (ServerStat['cursrvrconnections'] != "0") or (ServerStat['svrestablishedconn'] != "0")) ) This uses the 'if' part of generator expressions / (list, dict, set) comprehensions which basically skips items that don't match the condition. There are a lot of useful functions (`sum()`, `min()`, `max()`, `map()`, `filter()`, `zip()`) which consume iterable objects (including generators). In addition, all the container type constructors (`tuple()`, `set()`, `frozenset()`, `list()`, even `dict()`) accept an iterable. (Dicts take a stream of `(key, value)` tuples. )
Tim Peters who gave us The Zen of Python. And of course *Pyth*agoras.
This is a very cool project... That said: I am wondering as to why you wouldn't use [iPython-notebook](http://ipython.org/notebook.html)([Jupyter](https://jupyter.org/)) to power the same type of functionality. Furthermore, one can Google PCA analysis for iPython and get results like [this] (http://nbviewer.ipython.org/github/rasbt/pattern_classification/blob/master/dimensionality_reduction/projection/principal_component_analysis.ipynb?create=1) and Google returns tons of results for Bioinformatics with iPython-notebook. My intention is not to sour your good work... I am curious how this differs from iPython-Notebook/Jupyter.
Just say no and get the fuck out, why do you have to be a cunt about it?
Just to clarify, Django has explicitly called out Long Term Support releases. 1.4 was the previous one, and support is ending on October 25, 2015. 1.8 which was just released is the new Long Term Support release, and is guaranteed to be supported until at least April 2018.
Yes it has Per the github link. &gt; This scandir module is intended to work on Python 2.6+ and Python 3.2+ (and it has been tested on those versions). So Python 2.7 and a few others as well (though I'm hoping people still aren't on Python 2.6)
This was awesome
Did you try running your tests with echo=True to see if there are commit statements being emitted? Do you use ORM features? 
I'm curious as to your rationale.
Eric Idle.
If you're writing migrations manually, you're doing it wrong. I get the impression it's more that you don't know how to use django above anything else. The only time I've ever had to use contribute_to_class is on User before custom user models were a thing. Would love to hear an example though.
I want to plug Harry Percival's book here it is ostensibly about unit testing but gives a great intro to Django as a means to its end. http://www.obeythetestinggoat.com/
It's a first-book for data-analysis binding the thoughts - "SPLIT - APPLY - COMBINE" . And this book is focused on numpy, pandas, matplotlib. Is there any content about scipy (or sklearn?), I think not. in my 2rd edition.
Yes - and you can read it for free! (I bought a physical copy just to support &amp; hold on to, but refer to the free online one for some of the chapters that were updated after publishing, like BDD) 
Have you seen [Wooey](http://github.com/mfitzp/Wooey)? It's my own project that does more or less the same thing, though built on Flask. Are there any other differences aside from Django?
Ha, of course you have. I just read to the bottom of the page and remembered our conversation... :) I would still like to consider the possibility of merging the projects, it seems a bit crazy to have two projects doing the same thing, especially considering we even work in the same area!
Don't get either. Go to codecademy.com to get started, and if you need some direction (if you don't know what to work on) go to hackerrank.com (no it actually has nothing to do with hacking, it's just straight up programming.) If you have any more questions just PM me!
&gt; django.db.models.Model You want to add a field... to a built in class? Not only does that not really make any sense, it definitely doesn't add any extra overhead from the database and any overhead in the code would be minimal and present in any OOP language, including Ruby.
+1 for motion. I use motion in combination with a python client that executes commands (like start / stop / snapshot ) when I send it an email. 
Grace Hopper
Thanks for your comment. I guess the simplest answer is that the audience djangui addresses is different. Jupyter is great, but you have to know python to use it. You can have things like "change this variable to file x", "change this variable to how many x/y/z" written in comments, but I don't think that interfaces as well with non-programmers as this. Also, I don't think you can really control things like user access levels for Jupyter (I also think you might have problems with several people trying to use a script concurrently). I also have plans to go a bit beyond this, which Jupyter can't do at the moment. One of my future improvements is a workflow creator that allows you to create workflows by combining scripts to create data analysis pipelines (using something like jsPlumb maybe). For Jupyter, I don't see that as possible without a lot of cut/paste mess.
Well one reason is I started this before Wooey was online :). On the surface the differences to the end user probably aren't as apparent. On the backend side, we just have different approaches. The biggest difference the end-user would see is how scripts are handled. The script management for Wooey is command line driven and stores scripts as a JSON intermediate (I think it's JSON at least). I store mine in the database in an EAV-like setup. This gives you version control over scripts (people with old jobs can run their jobs with the old scripts or resubmit with the latest and greatest), lets you just use the admin interface to add scripts, and allows me to upload/update scripts through the site instead of having to get to the command line. I haven't looked at Wooey enough to really touch on anything else like it's user controls, whether you can deploy it to places that have ephemeral file systems, or any other things Djangui supports. I have no idea if it's possible to have an app that is agnostic to whether Flask or Django is powering it, I'm leaning towards it isn't (though with jinja2 being supported by Django now, it might be interesting to make a hybrid approach that has a shared template front-end). The common core that is most easy to merge together is the interpretation of argparse to a build language. I'd really like to tackle that together to cover all the popular parsers -- we just need a cool name now!
For the character's comparation in min, max and sort, I think it's following the order in ascii table.
Ah, I hadn't realised the scripts themselves were stored in the database. Moving the script args definition to the database is already on the roadmap though: storing it in files does not play nicely with ephemeral file systems as you say, unless you want to re-parse on every load, and I guess the same would apply to the scripts themselves (I hadn't considered the versioning of scripts). I doubt Django/Flask agnostic is possible (or beneficial), my choice for Flask was mostly based on "not used it before, lets have a look". The db and templating is nicer than Django, but the admin is not quite as nice. I've got more experience with Django though to be honest. Definitely want to work on merging the argparse bits (will see if I can come up with a cool name)... but I really think we should consider going further. 
&gt; workflow creator that allows you to create workflows by combining scripts to create data analysis pipelines I would really recommend against this: you're going to end up re-implementing Galaxy. I spent a good chunk of my PhD writing a workflow-based analysis tool, and it's a real time-sink that moves you further and further away from the reason for creating the tool in the first place: analysing data.
No, I use just a sqlachemy core as you see. I guess my whole code can be reduced to the example I've shown above. Yes, I looked at the log. Here it is: INFO sqlalchemy.engine.base.Engine BEGIN (implicit) ... INFO:sqlalchemy.engine.base.Engine:('Wowowow', 'Some new product') INFO sqlalchemy.engine.base.Engine INSERT INTO `SC_products` (`categoryID`, `Price`, enabled, list_price, product_code, brief_description_en, description_en, name_ru, description_ru) VALUES (%s, %s, %s, %s, %s, %s, %s, %s, %s) INFO:sqlalchemy.engine.base.Engine:('Wowowow', 'Some new product') INFO sqlalchemy.engine.base.Engine ROLLBACK So I see the rollback but data ends up in the database.
This was not my experience. Trying to create a web app as a complete beginner, I found Django overly prescriptive and daunting. I spent two or three days wrestling with it before switching to Flask, and never looked back.
/r/learnpython
if you're using a good python IDE, then pep8 warnings should be happening all over the place to try to get you to comply wherever you think is best. (*gasp* yes! there are times where we all violate pep8 for our own good reasons). if you work on a team, i think having pep8 happen automatically is fine, as long as you follow Hettinger's PEP8 Commandment: Thou Shalt Only PEP8 Unto Thyself. (in other words, don't pep8-correct anyone else's code, otherwise the CVS annotations become all fucked.)
So perhaps this isn't the best method to track zombies.
Out of topic but just curiosity, why Armin Ronacher call himself "mitsuhiko" as his account name? "Mitsuhiko" sounds like a Japanese man name, does he have something to do with Japan? 
Hah! As I write this , I am taking a break from porting circa 5K lines of code to 2.6! One week's work in python3 and now time to deliver the customer's sysadmins were not consulted and they refuse to install python27 or python34 rpm. At least you guys are talking about 2.7, I am porting back to 2.6!! 
As I understand it, that's unpacking, not a traditional tuple 
How is that a bug? Immutable objects are immutable. 
Assigns an empty list to and empty list. Not very useful, but syntactically correct.
In this particular case, this isn't unethical or illegal because the user has to provide their cell tower and/or wifi information to the api.. For example, if an android app uses this api, before installing the user sees requests for "Wi-Fi connection information" and "Device ID &amp; call information" permissions.
Now if you and the Wooey project could please use Python3, that would be nice… Do any of you support Python3 scripts? Couldn't find a word about it. I am excited about both projects but all my little scripts are in python3.
Teradeep looks pretty cool, I've been meaning to give it a try. Let me know how it works for you!
oh just seen your comment in the post about it too, yea will do
Unpacking is exactly what the bug report is about.
You may missed by subclassing django creates a new database table, new relation to the former one and this causes an extra database query at accessing its object. Just for the sake of adding a single field. If you do this to more models it can stack up and significantly slow overall performance. Your link is completely off-topic. We are speaking about adding a field to an existing model - not about creating a custom field.
What yaix is trying to say, is that tuples function differently when they have ellements as to when they do not. If it stands to reason that a == (a) a != (a,) Then it stands to reason that Null == () I'm aware null isn't a construct in python, but I'm using it for demonstration. And as Null isn't logically an assignable construct, this behaviour makes sense.
From the article: &gt;I don't think there is a direct relationship between Python and Rust. From what I understand, there really isn't. Although, I'm still very new to Rust. However, Rust was explained to me as a low-level language meant to be a memory safe replacement for C/C++. In fact, Firefox is slowly being rewritten in Rust.
I'm the co-author for O'Reilly's High Performance Python http://shop.oreilly.com/product/0636920028963.do (reviews at 5/5 *since* publishing). We focused on practical ways to scale code covering profiling, compiling (mainly Cython+Numba), lowering the amount of RAM used etc. You won't learn 'data analysis' but you will learn how to engineer your code to scale from small to larger problems. I wrote this around my own use of Pandas, numpy, scikit-learn etc.
What about this one? http://www.amazon.com/gp/aw/d/1783553359/ref=mp_s_a_1_4?qid=1432732879&amp;sr=8-4&amp;pi=AC_SX110_SY165_FMwebp_QL70&amp;keywords=Python+data&amp;dpPl=1&amp;dpID=51ZQ1NxOV7L&amp;ref=plSrch
are you using MySQL and your tables are created with MyISAM ?
Yes, but if (a) isn't in fact a tuple, then it would stand to reaosn that () isn't either. And you can't bind something to nothing.
Hey, that's my bug! :D As I recall, I was trying to explain tuple/list unpacking on the #python IRC channel, went to give a minimal example of each... and was surprised when `() = ...` assignment was invalid syntax. Oops!
Hah! I once did something like this. I wanted a way to make outputting stuff (both logs and stdout stuff) easier and I wanted to do so by limiting it based on the name of a function. Rather than pass in the name everytime I wanted to automagically get it. So I created a function that will get the current frame, jump up n frames (1 frame would be the person that called get frames, 2 would be the person calling the function (ie our target), 3 our callers caller etc). But this only returns a code object. So what do we do? Search through the gc till we find a function whose code object matches ours! Did I mention that it would search the gc everytime the output function is called? It did work though, was pretty cool, though just because you can doesn't mean you should....
+1 for testing/tdd Overall I think an amazing idea
Of course `() = ...` doesn't work. Ellipsis isn't iterable.
&gt; Both File::open and read_to_string can fail with an IO error. The try! macro will propagate the error upwards and cause an early return from the function and unpack the success side. This doesn't make any sense to me. Why would an IO error result in a return of the success result?
Damn it, I have MyISAM tables. So SQLAlchemy does not provide any additional transaction magic if the engine does not support them?
Well, then how else would you make an empty tuple?
While there's a wide choice of software, it still often happens that a particular app doesn't suit users. When I've discovered [taskwarrior](http://taskwarrior.org/), I was very impressed. It was certainly one of those few programs that trigger an "AHA" moment when you learn about them. I have started to use it but soon discovered that it is just too complex for my needs and sometimes doesn't act the way I want. After spending some time diving into its docs and failing to get it behave the way I wanted - I wrote my own private task manager in Python that works exactly the way I want, despite having a very small feature set. Knowing a high level user friendly language like Python allows people to craft their own tools for specific purposes, when general purpose feature rich tools prove to be too complex.
Sounds like it'd be really useful. Count me in.
In case of success you unpack the value (i.e `Ok(val) =&gt; val`) and on error you return the error (i.e `Err(err) =&gt; return Err(err)`). I think the [source](https://doc.rust-lang.org/nightly/std/macro.try!.html) is pretty readable.
Do you think Rust will in the near future have a use for web (app) developers that are currently only using Python/Flask/Django? Server- or client-side?
Not sure. I think you can do much more interesting things in Rust that were impossible to do in Python because of GIL and general slow performance. So you probably will see different frameworks in Rust than you did in Python.
Personally, I still check all of PEP8's warnings manually. There's something about letting a script reformat my code that bothers me a little, since occasionally there might be situations where a slightly different (yet still PEP8-compliant) variant might look better. By simply using PEP8 to check only, I can have a bit more certainty.
But there was no explicit Err call in the article's example. The wording made it seem like the try! method would return a success even if it failed. 
Waste time and generate heat. I.e nothing useful.
You will find that most "senior" programmers don't know any of this stuff either! 
Because (a,b) is not a Tuple (in that context). The parens are performing their grouping function. This is how you should write it. a,b = [3,4] () is a tuple, in that (assignment) context, and so causes error.
Sounds interesting. Count me in.
It's not though do to quirk in parens being overloaded for grouping, (3+1)*2, and Tuples. (a, b) = blah is more correctly written as a, b = blah. Parens with a comma in them (in this assignment context) indicate "grouping" not tuple. But parens with no comma indicate Tuple. Immutable object.
It's on my list of things to do. The argparse module needs to be converted to be PY3 compliant. I have a bigger plan for that part of the codebase (removing it as its own package) so it's going to wait for that.
Yes, this sounds great!
Fair enough, thanks for the explenation.
Your repeated use of the word "inject" gives me the impression you think you're doing something far more extreme than you actually are. If you need dynamic model fields like when designing a CRM then yes perhaps the built in Django admin isn't your best bet unless you're prepared to get heavily involved in the underlying API, but then that's never what it was intended for and not what most people use it for. You also only related django-admin to migrations in your original comment yet Django's admin area has nothing to do with migrations, its just a bonus app that uses whatever your current codebase is. If you mean that South/Django 1.7+ have issues detecting the changes when using the "inject" method, then I'm not surprised. Perhaps providing an example of the benefits instead of being patronising might help. You made the claim so the burden of proof is on you and I'd also love to see a real world example of where "injecting" fields vs. subclassing gives tangible performance differences (being serious).
Rephrasing the argument why this should work slightly: Currently, all of the following except the last one work: (x0, x1, x2) = [0, 1, 2] (x0, x1) = [0, 1] (x0,) = [0] () = [] In all of these cases, a `k`-element list gets unpacked into `k` values, assigned to `k` variables presented in a tuple on the left. There is no particularly good reason that the case `k == 0` should be an exception.
I think assigning to ellipsis should discard values. So that instead of having to do this: _, a, _2 = f() you can do ..., a, ... = f()
something something immutables mumble mubmle
I agree with you. Just look at CoffeeScript or Haskell. 
The comma is what makes it a tuple. Consider: import ast ast.dump(ast.parse("a, = 0")) #&gt;&gt;&gt; "Module(body=[Assign(targets=[Tuple(elts=[Name(id='a', ctx=Store())], ctx=Store())], value=Num(n=0))])" This is unpacking into a tuple. `() = []` should be no different. 
True that! I think of programming as the art of *translating to yourself* some of your reasoning. The fact is that other people may speak different "reasoning language" and you yourself will speak a different one in a year or so. Expecially if you are learning new stuff every day. People who learn new stuff tend to mix old and new concepts making a little mess in every reasoning.. If I were to make your "course" for myself, I'll add the "How to not mess your thinking too much" chapter. :) 
For Vim there's [python-mode]. I use it with certain warnings and features turned off, such as python-rope (way too slow for me and my old computer). It also has an auto-pep8 command that I didn't know existed until just now. [python-mode]: https://github.com/klen/python-mode 
Ok, I did expected it was clear and most devs writing real world applications are aware of this. Nevermind, bellow is a simplified example to demonstrate the issue: # external.models from django.db import models class Book(models.Model): title = models.CharField('Book Title', max_length=255) # myproject.demo.models from django.db import models from external.models import Book class BookWithPrice(Book): price = models.DecimalField("Book Price", decimal_places=2, max_digits=8) ./manage.py shell &gt; from myapp.demo.models import BookWithPrice &gt; str(BookWithPrice.objects.all().query) 'SELECT "external_book"."id", "external_book"."title", "demo_bookwithprice"."book_ptr_id", "demo_bookwithprice"."price" FROM "demo_bookwithprice" INNER JOIN "external_book" ON ( "demo_bookwithprice"."book_ptr_id" = "external_book"."id" )' See the two distinc tables `external_book` and `demo_bookwithprice` ? See the SQL JOIN to get books data ? All this extra cruft only for adding a single field ? Instead of simple inserting a new *column* into `external_book` table ? 
The same way `[] = []` does...
`[] = []` doesn't trigger unpacking...
&gt; It's **1**-tuples that are something of a corner case here Not really. Empty tuples are the corner case because in all other cases the tuple is defined by the comma: foo = 1, 2 Parentheses are only needed for disambiguation (as with other constructs in Python)... *except* for the 0-element case.
Same way you make an empty set? :P
Sounds like an interesting idea! Count me in.
Jeez. Hey, you know there's 3-to-2 conversion tools out there, right? I'm told they work a lot better than converting 2 to 3.
so now I'm extra confused because I already addressed your issue here. that is exactly why I mentioned abstract base classes and model mixins. what did you think I was talking about anyway? I question whether or not you even actually read the pages I linked to. here's 2 different ways to add the price field to your Book Model if you want to retain the object inheritance from Book but avoid extra joins on queries. class Book(models.Model): title = models.CharField(max_length=255) class Meta: abstract = True class BookWithPrice(Book): price = models.DecimalField(decimal_places=2) and here's another class PriceFieldMixin(object): price = models.DecimalField(decimal_places=2) class BookWithPrice(PriceFieldMixin, models.Model): title = models.CharField(max_length=255) so let me ask again: what's your issue here? do you this this design pattern is in someway deficient? it seems perfectly clear to me and has truly minimal cruft. I prefer this way of working with database models to the rails way. It makes it totally clear which fields in your database are mapped to which attributes on your model instances. With Rails you probably have to inspect the database itself to know what your models actually have. It hides a lot more information from the programmer and requires much more implicit knowledge about how Rails works, compared to the Django approach which is more explicit. 
going on the \#python freenode channel is always a mistake. "I need help with X." "You shouldn't do X. It's not pythonic!" "I actually do need to do X." "The solution is to find a way to avoid doing X! Come back when you learn python a bit better." "I have this ten thousand line of code project that I'm working on and I don't feel like justifying my architecture here. Does anybody know how to do X?" Least helpful channel on freenode, honestly.
I'd be interested as well. At this point I'm purely self-taught so I'm in the 'bang out code that works' boat (in my defense, scientist). It would definitely be beneficial to learn best practices and whatnot.
`{1} - {1}`? :\^)
I'M IN!
Thanks, added to list!
It's like that on all the big tech channels in #freenode. The high spam of the big channels drives all the sane people away and only leaves the fanatics behind.
Thanks, added!
Have you tried google? This was the top result in google and probably can help: http://stackoverflow.com/questions/20885561/warning-from-warnings-module-resourcewarning-unclosed-socket-socket-object
I would be very interested!
Should it more fair to compare [] = (,) and (,) = []
Yes!
See the [blog article](http://blog.jupo.org/2011/11/10/django-model-field-injection/) of main Mezzanine developer about reasons why they decided to implement models extending with fields injection. I did helped improve responsiveness of one Satchmo deployment where rewriting multiple subclassing into field injections improved response times by an order of magnitude. 24 items per page, retrieving fields from several models (products, productvariations, contacts, accounts, taxes etc).
What you said about advice that's usually risky but occasionally needed really hit it on the head. I don't think they're out to feel smug or anything. I just came in there asking for a cleaner way to dynamically generate a user defined function for a simple math utility I was writing. My question involved lambdas (which lots of people don't like) and it involved using eval (which people hate, and for good reason). But the thing was that the users were fully aware of what the program was doing (calling the function that they passed in many times to evaluate an integral) and of the danger (if they could do something with this program then they could just as easily do it by writing their own python program). So when no one would answer the question calling it dangerous it just left me frustrated. I don't think they had bad intentions but I felt a little condescended to, rightly or wrongly. Hopefully that doesn't come off as condescending on my part either, because I don't mean it to.
Holy shit, I've just started working through OpenCV for RPi and here you are with a super comprehensive course/tutorial/example. Awesome!
Why?
I would definitely be interested!
This sounds fantastic, I would love to join this.
Sounds useful, I'd like to give it a shot.
Damn, that was sexy.
cool, didn't know about zfill. And I've always used split() but I can see how partition and rpartition (especially for grabbing a file extension) would be useful.
That behavior is correct. You can assign the elements of a tuple to become the elements of a list (the first case), but not vice versa (the second case) because tuples are immutable. 
I don't mind if you are trying marginalize impact of extra database joins on overall performance. Didn't denied it depends on a specific case but more you start customize framework used and more of customized models are rendered for a single request, the more this design decision would start to bite you (by exponential increase of response times). I have personal experience with ecommerce site built upon Satchmo (django based app) and removing extra db queries introduced by subclassing made a *huge* difference at improving rendering times. I didn't noticed any significant changes in this area even in Django 1.8 . Can you shed some light why you find this article from 2011 as outdated and no more relevant ?
It's not an interesting language for me, so I have not spend time investigating it too much.
Any way we can add "geography" to the params? There are things you'd do somewhere *other* than the US/UK, for example, for privacy reasons.
I'm totally game for this. I'd love to learn about proper deployment practice's. I have a PHP background of several tears but finding the hardest thing is not the syntax but understanding the Python ecosystem . knowing what packages are best to use in certain circumstances etc. Great idea!
Thanks for posting this - I'm new to Python and this helps a lot.
Sounds familiar...I wish I'd known in undergrad how much programming I would do in grad school!
Lambdas in Python can only contain expressions. Rusts anonymous functions don't have that problem This makes a purely indentation based syntax problematic. Just take a look at all those proposals to add anonymous functions to Python.
FWIW, I was joking.
Vultr is pretty fantastic.
I use digital ocean for almost everything these days. It doesn't have the specialized nodes that Amazon has, but for a fraction of the price you really can't beat it. I spawn their $5 nodes like popcorn...currently running 3 of them, and one of their $40/mo 4 GB servers for http://imgn.io Great service, I highly recommend them. ALSO if you're a linux noob like me, there are tons of tutorials under the DigitalOcean domain for setting up servers. More often than not I can type my linux questions into google and append "digitalocean" and find a well written, moderated, tutorial on the matter.
After following the Rust news over the last bit and seeing Armin's really nice writeup today + Dan Callahan's talk at PyCon, I thought I'd throw together a simple example of calling Rust from Cython. It's super rudimentary, but I wanted to toss it out there since I had only seen Rust called via ctypes or cffi.
Technically, they are parsed as tuples, except the second one, which gets parsed as a list. Of course none of them create or modify any tuples or lists when actually run. This last sentence: &gt; But parens with no comma indicate Tuple. Immutable object. Is really a problem. Because that tuples are immutable is immaterial. They don't get created or modified when using this syntax. _The only reason why `() = []` doesn't work is because of a special case in the code (2 lines) that has no reason to be there and basically everyone on the issue tracker agrees that special case should be removed._
I miss some code examples about this section &gt; One new concept compared to Python are these functions with exclamation marks at the end. Those are macros. A macro expands at compile time into something else. This for instance is used for string formatting and printing because this way the compiler can enforce correct format strings at compile time. It does not accidentally happen that you mismatch the types or number of arguments to a print function. I would like to see some examples of macros :) /u/mitsuhiko
I'd be interested.
No. `(,)` isn't a thing in Python.
Syntax is really not important enough to write off a language for IMHO. If you weigh unimportant things so heavily, you will make poor choices.
Ah, alright I can agree with that.
well, except that it doesn’t *really* discard the value, it only assigns it to `_`. any maybe `_` was used globally and you now leaked memory. or you even forgot you used `gettext` and your `_("translate me!")` calls are now broken!
No heroku?
interested
it ensures that the right side gets exhausted (if it is an iterator) and has 0 elements.
Parentheses or brackets on the left side of an assignment operator no longer construct lists or tuples, they are both used for tuple unpacking, which is a completely unrelated part of the language. Example: (foo, bar, baz) = range(3) The above code does not create a tuple of foo, bar and baz and assign to it, it unpacks range(3) and assigns its elements to the variables foo, bar and baz, no tuple involved.
Methinks we agree.
Or... http://code.google.com/p/python-progressbar/
Very interested!
Glad to hear you're liking it! Let us know if there is anything we can do to make DO more python friendly!! While we do not use a lot of Python internally, there are a few of us that write a decent bit of tooling in python :)
One thing I would note about the github education pack, this is ONLY for students. 
I see you put in "Virtual private server" at Kimsufi. This is incorrect, they're bare metal dedicated servers.
I can vouch for WebFaction!
Yes, that is precisely what I was trying to say.
It's [a third party module you have to install](https://pypi.python.org/pypi/django-unchained/1.0.1).
i'm interested
As always, housing costs
Thanks, added!
Added, thanks!
Would definitely be interested!
I used [Pythonanywhere](https://www.pythonanywhere.com) and liked it very much, the support is awsome too. Available free and paid. I Think they use amazon ec2. The noob friendly interface rocks though. Thanks for the list, very useful!
Listing vps hosting is a futile endeavor, just watch http://lowendbox.com/ for good deals.
Have you tried going to http://pygame.org/download.shtml and downloading the `.msi`? `pygame-1.9.2a0.win32-py3.2.msi 6.4MB` looks like your best bet. Or `pygame-1.9.1.win32-py3.1.msi 3MB` for the latest stable version.
I've tried out koding.com as well, works great for python. Might want to add that to the list too.
StringIOs are file-like objects. Give `request.body.read()` a shot: https://docs.python.org/2/library/stringio.html **Edit**: also, `dir(request.body)`
Nice. Thanks.
Yes, that will be great, thanks! is always nice to hear from people with experience.
Based on some google searches, I've found, but not tested `pip install pygame --allow-external=pygame --allow-unverified=pygame --pre` ([source](https://bitbucket.org/pygame/pygame/issue/59/pygame-has-no-pypi-page-and-cant-be)), so you can try that. You can also use pip to install .WHLs, and there are some pygame ones [here](http://www.lfd.uci.edu/~gohlke/pythonlibs/#pygame).
Seconding Digital Ocean! You just can't beat that $5/mo pre-rolled Django instance. They're damn clever with turning themselves into a little knowledge base of server how-to. Them holding my nooby hands though my first server setup has left me with something approaching brand loyalty. 
I have one of their €15 servers. 8gb ram and 8 core server. So far it's had no problem with anything. Very happy so far Edit: online one
_ is a pretty standard as a variable that you don't intend on using.
sadly I dont really know what any of that means. Basically I downloaded the file and placed it into my C:\Python34\Scripts folder and then ran cmd entered "pip install p" and it comes up with [this](http://i.imgur.com/l0y7xA4.jpg)
Why are you trying to install the package "p"? What is that supposed to do?
Sadly im using Windows 7 :(
This should be stickied.
For long file names like that, you should be able to do auto-completion with [tab]. However, unless you got rid of the .whl extension, it still has it. Try `pip install p.whl`. If you did get rid of the .whl extension, either add it back on again or do `pip install ./p`. Otherwise, pip thinks you are looking for a package named "p" on pypi that doesn't exist.
Online.net has a new arm-based service at scaleway.com. You get a dedicated server and SSD storage for 10EUR per month. I haven't figured out if this is faster than a similarly priced linode, but it's an interesting alternative.
Making it open .whl files in vs shouldn't make a difference, except that it might hide the extension from you. Without changing the file itself, try `pip install p.whl`.
I can vouch for WebFaction! Awesome host!
Are you sure you downloaded the file into your `C:\Users\ScribbleScribble` directory? Also, try changing the filename to p.whl and doing it again. The error looks like it might be installing it wrong because it identifies how it installs something based its extension.
Lettuce is just a package, so it's compatible with any ide from an editor standpoint. You'll be pip installing all kinds of things, so don't let the IDE get in the way. Maybe try this first with the command line and a text editor. I use the BDD Feature and Given/When/Then in Functional tests, and that uses selenium to run a browser. This is the 'outer loop' from the user perspective, and I've had really good luck with that. My TDD 'inner loop' tests are just regular python test cases from the developer perspective. Our workflow goes like so: Make a user story, and define the acceptance criteria in the given/when/then style. Think as a user when making these tests. Implement the functional test, run it and make sure it fails properly (the test fails, not the code). Then implement the unit tests that use the interfaces, this is from the developer perspective, and is checking outputs and making sure the interface is a proper contract. Good unit tests are a key design tool for how your interfaces actually work. Then implement the application functionality behind the interfaces, just enough code to make the unit tests pass. You will be re-factoring the code when you add more tests in the future, so don't over think the implementation too much. Once those inner unit tests pass, the outer functional test will probably pass right away. this has been working for me, but maybe you will find another way that will work for you. good luck! 
Thanks, that's good to know. I kind of had a feeling that Aptana was a little aged by the workarounds I've already had to do. I run Eclipse on my Mac so I may just switch over. 
Actually, I've been reading about 3 books and this has been how it's described exactly. Write the failing function test, write a failing unittest, get the tests to pass, check that the functional test passes, if needed, refactor. Great to get some input on how it's put into practice. Thanks!
It definitely in[ C:\Python34\Scripts](http://i.imgur.com/o1K7d6h.jpg)
Right. Assuming you've downloaded `pygame-1.9.2a0-cp34-none-win32.whl`, `cd` into that directory (don't rename it, or if you have, as someone else mentioned make sure it has the `.whl` extension. I haven't played around with this but it's just introducing something else that could go wrong.) and do `pip install pygame-1.9.2a0-cp34-none-win32.whl` (typing `pip install pyg` then hitting tab should suffice here). In the screenshot you've provided above, it won't work because you're in the wrong directory. Try: cd C:\Python34\Scripts pip install p assuming you haven't renamed anything further, and tell me what happens. Also, open up an interpreter and try `import pygame`. Again, tell me what happens.
/r/learnpython Break your problem down and post a small section of code that reproduces your issue. Or at the very least, post the traceback of the error. And delete this post please.
While learning with the book Python for Data Analysis, you can then take a look at my pandas [cheat sheet](http://nbviewer.ipython.org/github/pybokeh/jupyter_notebooks/blob/master/pandas/PandasCheatSheet.ipynb).
Check out a book called [Automate the Boring Stuff with Python]( https://automatetheboringstuff.com/)
I would assume trying to attract silicon valley engineers. SV has the salary, and perks while NYC city is lacking in both categories. But hats just my personal opinion.
I use it for a bunch of random web apps and its never cost me a dime 
I don't understand why you need a registered nick to enter #python. If you have issue with trolls, require registration to post but not to read. Walling off the group adds to the feeling that it's elitist. If Stack Exchange needed you to sign up to read posts, it would have failed miserably.
Here's a FREE code for a new course on stress management. Tons of great material. https://www.udemy.com/stress-180/?couponCode=REDDIT180 Enjoy!
Freenode's #Python is an "official" channel so any crap that happens in there gets projected by proxy onto PSF/core.
One small question. In the online version of your book sometimes you describe topics that are out of the scope and then you point to resources at http://nostarch.com/automatestuff/ for more information (like in the *Combining re.IGNORECASE, re.DOTALL, and re.VERBOSE* section of [Chapter 7](https://automatetheboringstuff.com/chapter7/)). I can't find these resources anywhere on the nostarch.com page. Is this section visible only to those who purchased the book?
IRC is where you go when you need to discuss complex issues that you can't Google or can't get on Stack Exchange because they're unique and require discussion by and with experts. As such it needs to be very tolerant of unusual use cases, so long as the use case is genuine. Sometimes it is, sometimes it isn't. It does depend on who is in the channel.
Did you speed that up, or does Pycharm actually load that fast on your system? Was it already cached? What are the system specs?
Whats the interface you want to use the tests for? http is just another interface, so need to know what you are testing. The unit test framework is pretty flexible. A few times I have used the given/when/then in a unit test, and just left it in #comments with test code around the comments. Watch out for adding too much logic in the acceptance criteria, I had the tendency to add AND and OR to the THEN part, and that made for long, inflexible tests. It may be worth a try to keep the GIVEN part in the setup method only, and keep the test methods more focused. 
This sounds awesome. I always feel bad when I have a program that works well but is a mess. I have a bad habit of just making giant scripts instead of properly using functions, classes, etc.
CloudAtCost - some options are dirt cheap and you can usually find a coupon on retail me not. Had a couple of issues at first but after destroying and recreating no complaints so far...seriously 17.50 for a lifetime VPS w/ about as much power as original raspi was totally worth it in my book
In your example, you just made x refer to a new object in memory, you didn't change an immutable. If you did import gc, and gc.collect(), the object you created with x = () would be removed from memory, since it no longer has any references.
thank you
Yeah, I know I didn't change the immutable itself (that's what immutable means). I believed that FredSanfordX thought that variables that contained immutables could not be changed. In any case, I am pretty sure this has nothing to do with mutability.
I've been using Selenium and Django's testing suite for my web apps while I work through the Django TDD book. The other book looks like it uses Lettuce, web test and nose tools for Flask. Once I got so far in, I wondered if I could start using it for scripts. I'm creating one right now that I'm going to turn into an executable that takes flags, reading from a csv file that parses stats. Is a functional test even practical for that?
Awe..glad to hear. We actually recently discussed how we want to position our support as an education team. 
Weird. Definitely sounds like a coincidence. If it happens again, be sure to open a ticket with your nginx logs. 
Yeah man, I'd be interested in something like that. Sounds fun :)
For me, trying to write a reasonably complex GUI app in MATLAB was the straw that broke the camel's back and made me switch over to Python/Numpy/Scipy. GUIs, along with most other general purpose programming features in MATLAB feel exceptionally clunky. While MATLAB does make it fairly easy and painless to put together simple GUIs, you start hitting limitations when trying anything slightly outside the basic stuff very very quickly. At that point, if MATLAB doesn't provide you with the customizability you desire, you're out of luck unless you venture into java hacking and/or relying on undocumented features in MATLAB, both of which are bound to stop working with newer versions of MATLAB. Up until R2014b, they didn't even have the ability to do tabbed panels in the GUI, although there was/is an excellent user created library for earlier versions of MATLAB (which again is finicky, and also breaks in bad ways when switching to a newer MATLAB version). On the Python side, unfortunately, the GUI side of things aren't as simple and easy to start off with. If you want to deal with a steep learning curve, your best option is PyQT/PySide as that will certainly give you the most powerful options to create custom GUIs. Other options include using Enthought's TraitsUI - http://code.enthought.com/projects/traits/docs/html/tutorials/traits_ui_scientific_app.html Or Enaml - A declarative markup language for easy generation of GUIs. http://code.enthought.com/projects/traits/docs/html/tutorials/traits_ui_scientific_app.html In the long run, it is definitely worth the effort to switch over to Python. I made the transition a couple of years back and now I can't bear to work in MATLAB any more. Python + Numpy + Scipy is simply a joy to work with. I can switch between basic scripting, functional programming and OOP styles effortlessly based on what works the best for a given situation. When performance is critical, I've had amazing results with Cython and Numba (with resulting code being much faster than equivalent MATLAB code despite the MATLAB JIT interpreter). Add Pandas into the mix, and MATLAB starts to feel woefully inadequate. All that being said, MATLAB is still great for things like SIMULINK or for matrix algebra and they have excellent libraries of solvers, some of which may be harder to find in existing scipy libraries. Still, I've found myself to be FAR more productive after switching to Python. I can knock out complex programs/scripts in hours rather than days, and most importantly, Python + the Scipy stack makes programming fun again, rather than being tedious (which was my experience with MATLAB). PS - Forgot to give a shout out to IPython Notebook (Project Jupyter). For anybody in a scientific computing setting, it is a godsend as it allows you to mix in LATEX equations/formulas, with markdown based documentation and working code blocks. It makes documenting scientific code a breeze, and when you revisit code from a few months back, it's great to actually read through the formulas/equations/assumptions you made in the LATEX documentation, rather than having to try to decipher pure code to determine what it is you did.
I found this article quite good regarding the same topic. http://blog.ionelmc.ro/2014/05/25/python-packaging/
So, I've come across this in my windows installation. I tried installing a package via pip, and there was a network issue. I think pip marks the package as installed before it tries to install the package. What I did to rectify the problem is to go to site-packages and manually delete the module (in your case matplotlib). Then try a pip install. Of course, this solution may not be appropriate for you considering that your installation location is causing a problem. I'd suggest using python -m pip and seeing whether that changes things, though.
I don't agree. 
Nim is closest thing to Python . Performance is comparable to Rust and better than Golang already. I am wondering , why would you prefer Rust over Nim. The language itself is so close to python that you can just copy python functions and paste to run in Nim.
Python is definitely a defacto language for lots of the quick and dirty glueing &amp; procedural type work you do with analytics. But you can also build reliable, robust systems for things like ingesting data into a database on a regular basis. It's awesome because it's a fully fledged programming language with great support for things like AWS, as well as doing data munging/preparation/cleaning, not to mention data analysis with libraries like pandas, numpy and scipy.
Others can probably give better advice but my understanding is that multiprocessing is better in Python 3, because it can be used in parallel with things like asyncio, coroutines, and futures. It also has has a neat [`ProcessPoolExecutor`](https://docs.python.org/3/library/concurrent.futures.html#concurrent.futures.ProcessPoolExecutor) which makes multiprocess work even easier.
Interesting. I do like the explanations of anti-patterns.
atlantic.net has a 1$/month offer.
https://express.ikoula.com/en/public-cloud - 5.7$/month Virtual private server 512Mb / 0.5Vcpu / 50Gb SSD France / 10Mbits unmetered
Anaconda changed my life. So easy to install 99% of the libraries I need, rest is easy to install with pip or conda.
You are opening those files in text mode. Consider rerunning the test using binary mode (`f = open("D:\test.log",'rb')` and `w = open("temp.txt",'wb')`, if possible. Since you are using text mode, the additional overhead is probably caused by the string encoding/decoding fixes in Python 3.x. If you switch to binary mode and get substantially different results, it would confirm the theory that the speed difference is caused by string encoding/decoding fixes.
It depends. If you can stay under the Free Limits (1 Dyno, with 1x CPU Share and small Postgres DB) then yes, of course. As soon as you want to run a second Dyno then the Price jumps to 40$ per Month which is kind of expensive. I feel like a Digital Ocean (starts at 5$) or Linode (starts at 10$) VPS would be better for projects that you would expect to grow out of that Free Tier. There is a Heroku Pricing Calculator at https://www.heroku.com/pricing
Hello, many of our test interviews include providing python-equivalent solutions to [99 Lisp Problems](http://www.ic.unicamp.br/~meidanis/courses/mc336/2006s2/funcional/L-99_Ninety-Nine_Lisp_Problems.html). We'd prepare them in advance depending on the candidate's skill level and experience. Another example would be a technical task, which could be creating simple word games, e.g. Hangman or Word search. 
Unless you use `gettext`, as mentioned.
Thanks all and sorry for the late reply. I had a bit of conceptual struggle with this - I was sort of hoping that there would be a tool (for want of a better description) that would automatically compare my local version of a file with the DB version, and only upload if it was more recent. Once I realised that wasn't the case, I ended up comparing filesizes between local and DB versions - and if there was a difference, then uploading the local version. I did attempt it with timestamps, but for some reason the DB time stamp wasn't aligning with my PC stamp, and I ran out of time to try and trouble shoot. Filesize is not a perfect result, but it did the trick.
Will you be mentoring on topics such as program design? I find for new programmers it's not always so easy to figure out best to break the problem domain down into appropriate objects. Or when to use inheritance as opposed to composition and should we put such and such functionality behind a facade. Understanding some basic common patterns would also be helpful. Even though some of this is in the books it's often benefits from being able to discuss with someone with more experience on the subject.
You're linking to an older version (0.3.0) for some reason.
My problem with Digital Ocean is that if you want to use more than one server, you have to email them (As by default, you can only spin 1 server). And I'm like, **why** do I need to jump through hoops if I want to *pay* you money?
I'd recommend Python Anywhere. They maintain the servers for you (unlike a VPS), so they take care of the infrastructure. That means no worrying about applying the latest security patches etc. Heroku does the same, but their payment system is complicated, and I've heard people paying $100/month for a basic webapp. Python Anywhere have a fixed monthly price, which I prefer, as no surprises. Also, minor point: PythonAnywhere is based in the UK, so is not just US centric.
Thanks!
Thanks!
Hi baojie ... I run http://importpython.com weekly newsletter and will feature it in today's newsletter. Is it possible for you to give the urls of all the blog ?. I will then auto discover the feeds and add it to http://importpython.com 's newsletter feed source engine ?. Thanks 
Someone could answer all of those questions and still have no sense about software design or what constitutes Pythonic code. Testing candidates is very difficult. 
To make it fit nicely on the screen so it doesn't look like everyone is a millipede with 5 heads: head = " o " body = "/|\ " leg = "/ \ " heads = '' bodys = '' legs = '' for i in range(20): heads += head bodys += body legs += leg for i in range(5000): print heads print bodys print legs ;)
Right. I used Sublimetext so it just kept going to the right. But that's probably not the case in a terminal come to think of it. I'm sure there are plenty of other improvements that can be done to the code as well. I'm in no way an expert. Just a simple hobbyist. 
http://www.ovh.de/virtual_server/vps-classic.xml 2.40€ (2.62$) per month, 1 vCore, 2GB Memory, 10GB Disk (raid10)
MATLAB GUI development is extremely limited. You can do simple very simply stuff fairly easily, but to do anything remotely complex requires you to break into the undocumented Java internals. Also, laying out MATLAB GUI elements is clunky at best, it doesn't have any smart ways of dealing with resizable windows. It also tends to have unpredictable problems with its GUI event loop, leading to people trying to make complex GUID having to randomly sprinkle their code with "pause" and "drawnow" calls to make sure GUI elements get properly updated. If you are making a GUI in Python, the best bet is PyQt. Creating a PyQt GUI by hand from scratch is not that easy. However, if you start with a template file with the boilerplate already done (which you can get off the PyQt website), it is easier, although still harder than MATLAB. The main complication in my eyes is having to manually specify the layouting more than in MATLAB. This requires you be specific about what you want, but results in much better resizable layouts in the end. Most importantly, though, Qt has something called Qt Designer, which is like a much more powerful version of MATLAB's guide. You can layout your GUI in that, even setup some of the interactions between components, save it, then run it through a script provided by PyQt that spits out a python script containing the GUI. If you take that road, then in my opinion most things are even easier than MATLAB, thanks in large part to Qt's signals and slots vs. MATLAB's more cumbersome callbacks.
If only Python 3 were adopted as quickly as /r/Python...
Looking at pypi, I count more than 40 progress bar packages: [Pypi:"progress bar"](https://pypi.python.org/pypi?%3Aaction=search&amp;submit=search&amp;term=progress+bar)
I made a short article comparing many of the ones listed in the comments below: http://pbpython.com/visualization-tools-1.html A lot of it comes down to personal preference and the types of plots you need to do.
As soon as event supports Python 3, I will.
How about jumping jacks? head = [" o ", "\o/ "] body = ["/|\ ", " | "] leg = "/ \ " heads = '' bodys = '' legs = '' for i in range(20): heads += head[i % 2] bodys += body[i % 2] legs += leg for i in range(5000): print heads print bodys print legs 
When working with CSV's, there are lots of options but I would recommend using pandas for this case - http://pandas.pydata.org/ Pandas makes it easy to read in CSV files - http://pandas.pydata.org/pandas-docs/stable/generated/pandas.read_csv.html Then join your various DataFrames together using this concat http://pandas.pydata.org/pandas-docs/stable/merging.html This article - http://pbpython.com/excel-file-combine.html describes how to merge multiple Excel files together but you can do exactly the same thing using CSV files too. Hope this points you in the right direction. 
You can commit changes, run autopep8 and then take a look at differences or you can use flake8 to point out all the invalidations
This should work: d = {} with open('csv01.csv') as f: for line in f: l = line.split(';') if l[0] in d.keys(): #just in case there's a duplicate serial number d[l[0]].append(l[1].strip()) else: d[l[0]] = [l[1].strip()] with open('csv02.csv') as f: for line in f: l = line.split(';') if l[0] in d.keys(): d[l[0]].append(l[1].strip()) else: d[l[0]] = ['-',l[1].strip()] for k,v in d.items(): if len(v) == 1: d[k].append('-') c = sorted(list(d.keys())) with open('csvmerged.csv','w+') as f: for i in c: o = "{}; ".format(i) o += "; ".join(d[i]) o += "\n" f.write(o)
In djangui/tasks.py: celery_app = app.app_or_default() @celery_app.task(base=DjanguiTask) def submit_script... That queues the task for celery. The user decides how celery is setup or uses my default settings, which is to have a worker process running that handles jobs as they arrive (instead of a heartbeat/etc.).
You beat trending bot!
Your files are not correct CSVs which complicates things. The semicolons are a minor inconvenience, but the trailing separator on each line means you actually have three columns (the last one being empty) and the serial numbers should probably be strings if you want to preserve leading zeros. "01", 5 "02", 6 "03", 7 "04", 3 "05", 2 The following code will combine all .csv files in the current directory. import glob import pandas as pd fileList = glob.glob('*.csv') # The read_csv call is messy to compensate for the broken csv files data = [pd.read_csv(i, sep=';', header=None, index_col=0).iloc[:,0] for i in fileList] combined = pd.concat(data, axis=1, join='outer') combined.to_csv('Output.csv', header=False) If you format your csv files correctly it can also be chained into a fairly understandable one-liner, as far as one line programs go. pd.concat([pd.read_csv(i) for i in glob.glob('*.csv')], axis=1, join='outer').to_csv('Output.csv')
elegant! 
Why loop when you could just do `heads = head * 20` and likewise for the others?
ITT (just like in every second thread here): Python 2 vs Python 3.
So, yes, it's because of trolls. Without the ban, we get spammers to a huge extent, who not only spam the channel, but also, individual users in the channel via private messaging, in a way that ops might not even notice it. This is also related to why we use bans instead of quiets. People who can't speak often try to ask and answer questions via PM, which is disruptive and leads to worse answers and duplicated effort. (Edit: Also, joining and then finding out you can't talk, and with no easy way of finding out why, is probably even more frustrating than being unable to join but told why.) The situation is a bit different than Stack Exchange, which has a rep-based automatic moderation system, an effective and global ban system, and an easy way to keep out bots and such (captchas). We are limited in what we can do. :( I'm really sympathetic and we've been trying to make this easier (e.g. we added a redirect from #python-unregistered to #python to help broken clients that memorize the wrong channel name). Freenode could also really use input for how to make registration less painful. (A web form would be soooo nice...)
My personal favourite is [TQDM](https://pypi.python.org/pypi/tqdm).
Regardless of SSD or HDD they are both Hard Drives. It does sound a little redundant but it makes sense.
It is setup that way without any need to modify the source code. It's shown on the [Running Djangui](https://github.com/Chris7/django-djangui#running) subsection of the readme. You can have a single command setup that launches a celery daemon so you don't have to learn celery. If you do have a celery instance setup, it ties right into how that is already configured. I meant to say that if you wanted advanced options like, check for new tasks every 10 minutes, or things like 'run this script at a lower priority than X' or 'prioritize users over anonymous users', then no -- that currently doesn't exist (but is planned). I do like the 'run with trigger' idea, where you can tie execution to an event like job Y finishes (which is related to the idea of workflows between scripts). I hope none of that came off as argumentative/defensive. It's obvious I should have referred to the basic functionality it provides in the readme instead of just saying 'celery' and assume you should think of a task scheduler and what it can provide instead of a vegetable :).
/r/learnpython isn't just for beginner questions.
Oh, I didn't realize that. It's what comes up when I google "python progressive". fixed.
&gt; I tried Satchmo and thought it was a resource intensive monolithic piece of crap. But that's just a subjective unfounded opinion, right ? &gt; Your problem is with Satchmo, not Django. Nope. Way (table inheritance) or options(rather lack of them) how models are customized/extended are Django characteristic not Satchmo. &gt; doesn't suit your needs then fork it, tweak it, and issue a pull request. Forking a project and adding a burden with maintaining its updates and security fixes ? Are you serious ? Issuing pull requests and waiting and pray when or even if devs would merge it ? This way you would never finish any project during your lifetime. I'd just welcome if Django would support direct modification of original model's table at model customization including migrations, like it does exist for years in Rails. &gt; However if you don't like that, you create your own model made up of whatever abstract parts you want and then change the setting saying your model is now the master model. This requires framework you are going to customize to be written from start with this extra infrastructure allowing dynamically change master models in settings. But that's non-standard and highly unrealistic you'd work just with it. Mezzanine solves this issue with its own injection system bound through EXTRA_MODEL_FIELDS setting. But that's another and to the former incompatible system. *Instead if this possibility would be integrated directly in Django and available to all derived projects. Make Django more flexible. That's what am I talking about from the beginning.* 
nice!
Technically, you are right. It is for those new to Python, who are starting out or ..... wait ..... those people are ..... wait for it ..... beginners. (At least we don't call them noobs.) But technically you could have programmed Python for 15 years and never heard of list comprehensions, so you can go to /r/learn EVEN IF you are not a beginner. lol
Oh my lord!
I'm pretty happy with seaborn, and it does seem to have fairly active development and is improving rapidly. That's where I would place my bets.
Well yes, you are not a Python beginner. But you ARE a beginner at Large Data collection, that is why you want to LEARN it. And stop it already with the CAPS.
Forget to switch accounts? 
Fascinating, and I've screencapped this entire thread.
&gt; matplotlibs terrible api I've seen quite a bit of hating on matplotlib lately. For most of the things I have done up until now, it's really a lot more sensible than some of the other things. `plt.plot(t, y)` is a hell of a lot simpler than figuring out what letters I need to prepend to the word plot to do a simple plot with Seaborn. That said, I do agree that matplotlib by itself is much harder to use for more complicated plots. I just wouldn't call it "terrible" in general since the pyplot API was designed to mimic Matlab's plotting and works quite well for many of the plots that scientists and engineers are usually making.
Thanks for answering my question. Enjoy your retirement. 
But that is "only" library/framework, isn't it? Not that api wouldn't matter, but I don't think that something fundamentally changed. So performance should be comperable.
Hi there pysk, I can tell you this restriction is only in place for certain accounts that trigger filters, not across the board. Sorry that you got bit by it! We have it in place to prevent abusers from hurting us :( --Andrew
Andrew, I'm a member of a business forum, and I have heard other people make the same complaint. The feeling is: DigitalOcean is for hobbyists, Linode etc are for professionals. Impressions count!
Hey psyk, Sorry to hear that. I can say for certain that DO has many high end, "professional" deployments on it. Please reach out if you have any suggestions. I can make no promises, but I can usually put the info in the right hands to at least have it viewed. --Andrew
Can you use readline in binary mode?
Talk to me :) Not many people use numpy and matplotlib. They have a steep learning curve, but once you get over it, your code is so much faster.
AFAIK, there isn't a significant performance difference between the `multiprocessing` modules of Python 2 and Python 3. Your milage may vary and I encourage you to do your own benchmarking. In addition, all the same caveats that applied to `threading` in Python 2 still apply in Python 3. Python 3.4 added the `asyncio` module as a standard framework for different existing libraries to interact through. It's meant for framework authors to use and application developers should use those frameworks, but I'm not sure it's any more complex to use. The problem is that under event-driven models, all IO you do (files, networks, pipes, etc) has to be non-blocking/asynchronous. Many libraries don't do that yet.
Hopefully next week. It depends on how the proof looks when it arrives today. Any time we make a change to the print version, we have to wait a week until it arrives, then review the book to make sure it looks good. One broken page or an off-color on the cover means we have to fix and order another proof. If the book comes out next week it means we're ONLY a week behind. :-)
For one thing, you're using a slightly older version of Python 3. Python 3.4 is 15-20% faster for me than Python 2.7, when running that program on a large text file. 
&gt; It also takes links and doesn't just download the top stories from a subreddit. That seems like it would be useful for reddit2Kindle &gt; It's up to you to decide what suites your taste better. Why not push a commit to reddit2Kindle's github project?
Again, I wasn't trying to get a rise out of you just for the fun of it (despite my username). Most programmers have been there and probably realized at some point where their project was headed -- it's a cool idea, I give you that, but the advantages of it become negligible when you consider that Python's syntax is already pretty clear and easily understandable, especially with a library like requests for HTTP stuff (at least in my opinion). This doesn't mean that you should stop developing the project, you might see something I don't or come up with something I didn't -- I personally just don't know what. Good luck!
? Not really...just talking about things I like. 
Planning on cross-posting this to /r/datahoarder! Recently picked up a kindle and was actually looking for some kind of tool like this. Definitely recommend pushing a commit to reddit2Kindle, although I honestly find your script more concise.
I'm a bot, *bleep*, *bloop*. Someone has linked to this thread from another place on reddit: - [/r/datahoarder] [Archive stories from /r/nosleep as epub for kindle \[x-post /r/python\]](https://np.reddit.com/r/DataHoarder/comments/37mj8o/archive_stories_from_rnosleep_as_epub_for_kindle/) [](#footer)*^(If you follow any of the above links, please respect the rules of reddit and don't vote in the other threads.) ^\([Info](/r/TotesMessenger/wiki/) ^/ ^[Contact](/message/compose/?to=\/r\/TotesMessenger))* [](#bot)
Just figured I'd include /r/nosleep in the title to provide some direct relevance to the scripts use. Really enjoyed sifting through your script, scripts that do really practical things well in a simple package are completely awesome.
Because i didn't know about reddit2Kindle at the time of writing this, so I didn't modify their code but wrote my own. The approaches we used are pretty different, so it would take a total rewrite of either script to merge them. It would probably be easier if the writer of reddit2Kindle would add this functionality himself.
Try using traitsui. Its super easy and keeps data and view in sync with almost zero effort.
&gt; What's the slow way, for i in range(100): plt.figure() plt.plot(x, y) plt.savefig(png_filename) plt.close() &gt; what are you doing to be faster Nasty, hackish, amazingly useful stuff. You create your data, axis_settings and line_settings dictionaries, then we create 1 figure only, and then repeatedly passing in a dictionary of settings and the data separately and just reuse the same object, even if there are a different number of subplots. So... if numsubplots != len(fig.get_axes()): fig.clear() You call a `plt.plot` if there are no lines (or a different number of lines), otherwise you use lines = ax.get_lines() lines[j].set_xdata(x) lines[j].set_ydata(y) lines[j].zorder = numlines - 1 - j The settings get wrapped and call `"set_" + key # key=line_width/yscale/etc.` with a `getattr`, so you have full control. Then just scale the axes as normal or use: ax.relim() ax.autoscale_view(scalex=True, scaley=True) And then set the figure title as: topaxis = fig.get_axes()[0] topaxis.set_title(figtitle) and you're done. Our inputs are a dictionary of keys to be used in the `"set_" + key` calls and the data. The 400 lines of code maps the variables to the linesettings or axissettings charts and makes the plots. It only supports 2d line charts, but that's 99.99% of what we make. Additionally, because all lines should really be numpy arrays (they're converted if they're not), you can downsample very easily if you want. I think by default there are 1000-ish points on the screen before you start downsampling, but you can always turn off downsampling. &gt; Are you using PyQT for this? The plotter code's dependency is only matplotlib. The wrapper uses Wx, but it could be switched over to qt in a few hours. It's designed to work in a GUI or be called from a standalone script.
Maybe a dissociative identity disorder? The good thing about it is that you have always someone to talk to. :?
All people have complaints about software they've been working with long enough :)
I forgot about caching. That really is a pain! Is there some trick for modifying a PyQT GUI live while it's running? I haven't seen that, I always need to restart it to see changes.
Originally those links were going to the autbor.com URL shortener for the book, but then they got changed to the nostarch.com site but we sort of dropped the ball getting these links up (we just had the downloadable files on the nostarch.com site). I've compiled a list of the links. It should be taken care of today or tomorrow. For reference: Chapter 1 Page 14, Common Python error messages - http://inventwithpython.com/appendixd.html Chapter 5 Page 117, Complete source code for Tic Tac Toe - http://inventwithpython.com/chapter10.html Chapter 7 Page 165, Bitwise operators - https://wiki.python.org/moin/BitwiseOperators Chapter 11 Page 246, CSS selector tutorials - https://automatetheboringstuff.com/list-of-css-selector-tutorials/ Chapter 14 Page 328, Example of JSON APIs - https://automatetheboringstuff.com/list-of-json-apis/ Chapter 15 Page 349, Beginner's Tutorial on Multithreaded Programming - http://inventwithpython.com/blog/2013/04/22/multithreaded-python-tutorial-with-threadworms/ Page 355 and 359, Scheduler Tutorias - https://automatetheboringstuff.com/schedulers/ Page 360, List of Web Comics - https://automatetheboringstuff.com/list-of-web-comics/ Chapter 16 Page 365, Setting up Application-Specific Passwords for Google Accounts - https://support.google.com/accounts/answer/185833?hl=en Page 372, Advanced Searching in GMail - https://support.google.com/mail/answer/7190?hl=en Page 382, Twilio Status Messages - https://www.twilio.com/help/faq/sms/what-do-the-sms-statuses-mean Page 382, Receiving Text Messages - https://www.twilio.com/docs/quickstart/php/sms/hello-monkey Page 386, Controlling Your Computer Through Email - See torrentStarter.py in the book-files download. Chapter 17 Page 389, RGB Color Values - https://en.wikipedia.org/wiki/Web_colors Chapter 18, Programming a Bot to Play Web Games - http://inventwithpython.com/blog/2014/12/17/programming-a-bot-to-play-the-sushi-go-round-flash-game/ Appendix C Page 447, List of practice programming problem websites - https://automatetheboringstuff.com/list-of-programming-practice-sites/ 
Excellent! Thanks.
&gt; &gt;&gt;&gt; a = [50, 5] &gt;&gt;&gt; print "".join(sorted([ str(item) for item in a ], reverse=True)) 505 550 &gt; 505 Nonetheless, very nice way of thinking that works in a lot of cases. 
You're right, He had the right idea though, just need to iterate through each digit rather than number in the list. I think this might work better: ''.join(sorted(''.join(map(str,a)), key=lambda x: int(x), reverse=True)) 
Ah, got it. That's pretty neat!
Being able to describe how a JSON object should look like and how it should be validated can be incredibly useful, if you are dealing with a set of applications written in different languages and dynamic or user defined JSON documents, especially when you are dealing with different languages e.g. HTTP APIs written in Python and Android/iOS apps that can't rely on an Internet connection.
I did not have your input file but I tested on Ubuntu Trusty 64 bit with a similar program, and I find that Python 3.4.0 is a few percent quicker than 2.7.6. Which is odd, because it should be the other way around due to the fact that strings in 3 are unicode vs bytes in 2.
The real beauty comes from the libraries; whatever your need, it has probably been written and packages up for use. It'll be a sad day when I need to write something other than python for scripting. 
Thanks for mentioning HoloViews, I'm one of the main authors. We're really excited about it and are welcoming all feedback so if you ever have the chance to try it out do let us know what you think. HoloViews is a bit different to other plotting packages as we provide smart data wrappers, which visualize themselves in the notebook. This allows you to quickly compose complex figures, and makes it trivial to animate them using embedable widgets or videos. The main focus is interactivity so while you're still exploring your data you don't have to worry about the plotting details. At the same time we make customization really easy by providing a styling system and tab-completable magics making all the plot and styling options easily discoverable. While it's true that HoloViews uses matplotlib as a plotting backend technically the core is completely backend agnostic. We are for example investigating bokeh as an alternative backend. Through Jake Vanderplas' excellent work on mplexporter and mpld3 packages we already support output to d3. Bokeh are also working on their mplexporter compatibility, so it may eventually be possible to seamlessly convert matplotlib to d3 and Bokeh. Since you're already working with DataFrames I'll point you to our pandas interface. We have a convenient wrapper object that provides an interface to both Pandas and Seaborn plotting functions and conversion methods to convert to regular HoloViews objects. [Here](http://ioam.github.io/holoviews/Tutorials/Pandas_Conversion)'s an introductory Tutorial for the Pandas interface and [here](http://ioam.github.io/holoviews/Tutorials/Pandas_Seaborn)'s one for our Seaborn interface. Edit: Typos.
What's SOAP have to do with anything? As DasIch said, json schemas are useful. Normally I use Validictory which is based on JSON Schema. I'll take a look at this for the future.
Sure do! thanks for asking :) https://www.digitalocean.com/?refcode=70ebeb6d7781
sound a lot like myself- also casual C++ / Java programmer and just jumped into python 3 not too long ago. theres a great community over at r/learnpython/ as you work more with python
Before you install a bunch of modules, you should check out Virtualenv (virtualenv.pypa.io). It creates virtual environments per project, where you install the modules you need for that project with pip, and it only installs them in that virtual environment. It's great for not clogging up your system with a ton of packages. 
This is where you go to learn python and post your whole script rather than just an error message. There are lots of things that could be wrong. /r/python is generally for python news, not help. 
I really appreciate this post. But It makes me want to work with Rust even less. I like some some of the ideas, specifically the mutable reference ownership, but I hate how it does almost all of it. It's barely readable, and overly complicated. I'm looking for that amazing, statically typed C/C++ replacement but I haven't seen it yet. We are getting closer, but true design sense is lacking so far.
Make sure you run it multiple times. There are things like disk caching that can make a huge difference when doing file IO. In linux you can easily drop the disk cache with `echo 3 | sudo tee /proc/sys/vm/drop_caches`. Not sure about windows.
Your "Mandrian" image looks like the tesseral [drawing algorithm](http://www.nahee.com/spanky/www/fractint/drawing_method.html) from the old program FractInt. It was probably the best fractal drawing program in the 80s and early 90s. I spent so much time playing with it.
OVH (The company behind kimsufi) also has vps for ~ 3$/month http://www.ovh.com/us/vps/vps-classic.xml
It looks like bg[index5].mass is where the problem occurs. The bg object doesn't have an attribute called mass so you probably need to define self.mass = something in the __init__ method of the class instance. And as u/Sugar_Horse pointed out, this isn't really the right place for these questions. You should google the error and then read the stackoverflow posts that show up. Good luck
I've had similar issues for a long time. The python community doesn't seem to think this is a problem but it really is a major productivity barrier when installed packages get untidy. I tried using anaconda but it resulted in just as many problems, and in the end I spend a whole day removing everything I could find and setting up a clean install. Virtualenv helps a bit, but i find it messes up project directory structures, and can cause problems if you're working with git. Another option is to set up a linux VM and do all your developing within it. Then if things get fucked up you can just grab all your projects and put them on a new image. Good luck - it's a fucking nightmare problem.
In my opinion, it's extremely unpythonic. For example, to set the x label, code like ax.xlabel = 'x' As opposed to the weird-looking ax.xlabel('x') In addition, the way you do things with axes, figures, etc can be obnoxious. Coming from a MATLAB background, I understand that the api is designed to mimic those already familiar with those plot commands, but yeah. I understand why it would be weird for newcomers. I dunno. I don't know how I would do it better, but I feel like I'm constantly fighting to get my plots to look the way I want.
Would like to second the compliments on the documentation you folks are putting out. Shows up in google for so many of my noob searches. One suggestion I would like throw out there, is that there are a lot of guides for the differnt versions of the same software stacks. It would be super helpful if there was a side bar on these guides linking them and making them more discoverable that way. Would make finding the right guide that takes into account the sometimes subtle differences all that much easier.
Python is incredible! There is so much to learn and once you have the basics down and move on to more advanced concepts you will feel like you have limitless power. 
Am I allowed to troll by asking you why you drew the females with their legs apart and make some comment on about gender issues in tech?
For whatever flaws SOAP has, the fact that the way it works has formal definitions is superior over unschemaed interchange/RPC formats. Many, many situations call for defining what your data look like (thank goodness for json-schema, protobufs, AMP.....)
Life Protip: Never ever ever ever ever ever **ever** use `sudo pip`. Use `pip install --user &lt;package&gt;`. pip invokes the package's setup.py, which should be read as "pip invokes a pile of arbitrary code". Never run arbitrary code as root. Another bad side effect is that the package files are owned by root, which means that non-root users will have trouble accessing side files. But the main one is running arbitrary code as root. PyPI is not curated, so there's no guarantee that a given package is useful or safe.
This fills up the terminal better than just using an arbitrary 20 per line and uses string multiplication. It's uses Python 3 division, so some tweaks might be required. from shutil import get_terminal_size head = r"\o/ " body = r" | " leg = r"/ \ " readers = 100000 readers_per_line = (get_terminal_size().columns - 1) // len(head) for reader in range(0, readers, readers_per_line): num_readers = min(readers_per_line, readers - reader) print(head * num_readers) print(body * num_readers) print(leg * num_readers) print("Congratulations for", readers, "readers, /r/Python! :D") 
Even better than pip, Anaconda/conda... though the newer versions of pip are pretty impressive too. Also - check out IPython notebooks!
Even better, isolate the packages you want to use to each separate project you want to create, using [virtualenv](https://virtualenv.pypa.io/en/latest/) (and [virtualenvwrapper](https://virtualenvwrapper.readthedocs.org/en/latest/) if you have a unix shell to work with)
Haha, thanks man. I mean, I never had the intention of making this something crazy. I just needed a cool side project and this is it. Nothing more, nothing less. I do appreciate your input.
Yeah anaconda is the way to go.
To be clear, while venvs are very useful for testing and development, they do *not* provide any real security from malicious code like running in a true sandboxed environment like a VM would.
C++?
I'm in my begginer-ish stages of Python, and I have a question regarding pip, anaconda, and opencv on Mac OSX. I'm running Python 2.7.9 with the Anaconda distribution, and I am trying to use sci-kit image, but I cannot figure out how to install opencv. pip didn't work, so I downloaded the source, mkdir, cmake, make, make install...but it still didn't work. Terminal says C _imaging module is not installed and points to PIL. I have PIL installed, though. Any clues?? Any help is much appreciated. Cheers
hey! put up a link to your blog... 
going from C++ or Java to *any* other language will leave you amazed too :) 
Why is writing SQL a problem?
I don't think I ever said that :-p edit: for myself personally, I prefer to let a language like Python handle the subtle nuances of db creation and management so I can focus on more fun things like the data itself :-p another edit: I will say that postgres has some awesome functionality that the other sql implementations lack. boom. discuss. (so vague and infuriating)
The one real security advantage is that it's another way to not have to run pip / python code as root.
If you use python tools for visual studio it basically automates all of this for you.
I'm willing to bet you are using CPython and not Cython: http://scikit-image.org/docs/stable/install.html
/r/learnpython 
I'm just being argumentative. I love writing SQL. It's very clean and transportable. I use it as a data scientist to shape data because I just find it much more readable. I can much more easily go back to SELECT * FROM tableA AS A JOIN tableB AS B ON A.id = B.id than using something like pandas: df_A.join(df_B, inplace=True) (Please forgive the horrible table and dataframe names :-P ) Don't get me wrong, I love pandas and use it every day but SQL is still better (and as far as I can tell faster) at doing relational things than pandas is. My biggest gripe with SQL is I have yet to find an easy way to do a dynamic pivot (I use SQL Server, please educate me if you know). I've never used postgres, most of my work has been in SQL Server. I find it to be quite wonderful. Every version comes with new features that you actually want (for instance, SQL Server 2016 will include R), and the Microsoft documentation is very good. On top of this Visual Studio has Python Tools which lets you write Python with Intellisense (why write code when VS does it for you?). Even when I'm using an IPython Notebook I will often use the visual studio interactive interpreter to try shit out because Intellisense is just so helpful. I've been using python for work for five years and I have yet to memorize all of the standard library much less the scientific stack. :-P Visual Studio is great because you get the SQL Server object explorer, and a ton of other features. I could totally see if I was a web developer not wanting to necessarily write SQL every day when I could use an ORM. It just doesn't make much since to me to do that as a data scientists. What functionality does postgres have that others don't? Also, feel free to respond to anything else I said.
`x in range(y)` will actually expand `range(y)` to `0, 1, 2, ..., y` which isn't very nice. Testing if x is in the list will then be O(n). I've never seen used the way you describe it. The pythonic way would be: `if 0 &lt;= x &lt; y:`
With Python 3, `x in range(y)` will actually use the `.__contains__` magic method (or, rather, the C equivalent) of the `range` type, so it's O(1). The `0 &lt;= x &lt; y` version is still faster (and idiomatic).
 if 0 &lt;= x &lt; y: ... `range` will work in python3 but the above will work for dates and strings and numbers all the same.
Pip can also cause issues with the package management of many linux distros when not using virtual envs. Arch linux's pacman really hates to find the files it's trying to install already existing thanks to the user carelessly pipping around.
Guido was trying to bring Python to Android while he's working at Google. But his managers didn't allow him to finish the project.
&gt; All my problems are nails and I've got this dope hammer! I'm stealing this!
That's the saddest thing I've read today :(
I've always felt that, just as I use libraries to automate generation of other things from pre-existing templates (either provided for common cases, or custom-written by me for my particular use case), using a library to automate generation of SQL and SQL-associated code seems appropriate. The point of the computer is to deal with those tedious repetitive things that it's perfectly capable of, and free me up to think about and work on the stuff the computer can't just automatically do :)
Hmm. 2to3 needs to be run on that strip: print "Hello, world!" Because people just starting out shouldn't even bother with anything before 3.4. IMHO.
You can use `if x in xrange(y)` just fine in python 2, or `if x in range(y)` if you're in python 3. 
I've been using sudo pip for a long while now .___.
Hello amazed, I'm dad.
Silly me, all these time I thought there is a relation between bokeh and your username.
Don't really have any good links for what I would consider useful comparisons. However Django is a year older than SQLAlchemy so it didn't "re-invent" that bit. At the time there wasn't anything useful that I'm aware of. 
 In [1]: import praw In [2]: langs = ['python', 'ruby', 'java', 'C_Programming', 'cpp', 'golang', 'haskell', 'javascript', 'csharp', 'ObjectiveC', 'php', 'perl'] In [3]: reddit = praw.Reddit(user_agent='popularity_check') In [4]: results = [] In [5]: for lang in langs: ...: results.append((lang, reddit.get_subreddit(lang).subscribers)) ...: In [6]: for stat in sorted(results, key=lambda x: x[1], reverse=True): ...: print(stat) ...: ('python', 100105) ('javascript', 65917) ('java', 42586) ('php', 36951) ('ruby', 29032) ('cpp', 28600) ('csharp', 21201) ('haskell', 20462) ('C_Programming', 15109) ('golang', 14931) ('perl', 9453) ('ObjectiveC', 4437)
Ummmm, why?
Just import seaborn afterwards and you automatically get seaborn's aesthetic.
Yeah you're going to need to clarify that one. I work with Docker every day (both in development and production), and it's loved by everyone (including our sysadmins).
Aye Captain . i tried asking the same question on stackoverflow but no one answered .. the details are all here http://stackoverflow.com/questions/30516350/facing-problems-compiling-python-with-nuitka Thanks
Sure! I'd look forward to it :)
once you start, you just can't stop =(
I started working with django back in 1.5, and tbh i have fell in love with it since. They are really good at bring key packages upstream; e.g. collectstatic, db migrations. The one thing it is not great at is somewhat complex queries but i generally just make a view for those. Is there something specific you wish django could handle that it doesn't?
Okay, welcome to compile hell :) This is actually quite common. Just ask people who have to compile Numpy or Scipy :) Many open source programs are compiled on particular operating systems with particular tools, which the author forgets to mention in the docs. In this case, it is looking for the standard c++ library (https://gcc.gnu.org/onlinedocs/libstdc++/faq.html). Do you have it compiled on your system (and on the path)? Most of these libraries already exist on Linux, which is why you get problems only on Windows. Your best be is to contact the author(s), and ask them if they have tested the program on windows, and if so, how. 
I've done lots of data processing, backend scripts, aws sysops, and other stuff in python that was not web application related. The majority of the jobs are probably website building though, but python is also great for analytics.
Personally I dislike writing SQL by hand because it breaks (or at least is ignored by) tooling. If I work with an ORM then I get things like IDE or linter support for "free" (though less so in Python than in certain other languages). For raw SQL getting any kind of integration at all requires that: 1) the tooling also supports SQL, 2) the tooling knows that it's SQL code (not likely to happen unless it knows about your specific database and you pass it directly as a string argument to it).
:D they're giving msi so that implies windows support i guess . i'll check for the libstdc++ though 
You could turn on global packages for this
Doesn't that negate the benefit of using virtualenv?
Try decimal &gt;&gt;&gt; from decimal import * &gt;&gt;&gt; getcontext().prec = 20 &gt;&gt;&gt; a = Decimal('1.0000000000000000001') &gt;&gt;&gt; b = Decimal('0.0000000000000000001') &gt;&gt;&gt; a - b Decimal('1.0000000000000000000') 
how is it the way to go? To my understanding, Anaconda is just a pre-packaged set of libraries? how does it compare to pip?
If you use "pyplot.subplots" then it removes quite a bit of the boilerplate. It creates a new figure, one or more new axes in that figure, and returns all of them. 
For data analysis/scientific work, Anaconda is unbeatable, particularly if you're stuck on windows. It provides the C-based packages pre built, so you don't have bang your head against a wall trying to compile or meet dependencies with the many useful but complex libraries. That said, if a software project is your goal, pip (and now plus pyvenv) are far lighter weight and versatile tools for managing virtual environments.
Generators are faster than a for loop doing an append. For loops aren't the slow part there. Repeatedly appending to a list is what does it.
no way it's idiomatic. The requests example you point is a `for x in range(y)` not an `if x in range(y)`
I have another example showing that string concatenation is equivalent to building a list then joining it using a list comprehension. I'm not sure whether to post that here or in a new thread, but I think I'll wait to see what explanations are for the above. :)
We're deployed with CentOS 6. When I've got the time I'll probably upgrade to 2.7 through RedHat Software Collections and then move to MatplotLib. PyGal is nice because it creates great looking SVG files, buy you can't overlay different graph types.
I would make my best bet is that the major source of difference is in the `.lower()` call
&gt; Docker is a security nightmare. So is having old versions of Python packages in various virtualenvs that each have to be individually found and updated.
Wasn't talking about that. Was asking how does it do the check? Remember range takes a step parameter so I can't just check upper and lower it needs to check the step part. Only way it could is with modular division. But step doesn't have to be integer. 
With my security hat on, the recommended approach is to start with an unsigned base OS image from docker.io, and to build on that. Who created that image? What does it contain, over and above what the distribution shipped. Sure, I could check. Every time I do anything with that image. But let's be honest, no one does and no one will. In sysadmin terms, try starting a given container image with a given set of arguments reliably on boot. I haven't yet found anyone able to do so. Docker's restart policies plain don't work. And even if they did, they play very badly with the systems's init system. You could start a container with upstart/systemd/whatever, but not in a way that the init system can detect when the container fails and take some appropriate action. Docker falls into that category of tools that we were fighting more than it was helping us. It was becoming a huge time sink, and we've now abandoned it altogether and just use plain LXC instead.
Thanks for pointing that out! I put them there because I thought it would fix an indentation error that, as you've made me aware, was unrelated. &lt;3
I think SQLAlchemy is a great ORM, but I think "better" is arguable. Having Django move to it, even years ago, would have broken all third-party apps in existence. Personally, I think they made the right call. 
import antigravity
The first thing I'd suggest is altering your README on the GitHub repo to show some common (or useful) use cases. Consider the (JavaScript) requests GitHub repo: https://github.com/request/request That's a goal, and not a minimum, but if I go there and read through it's very obvious what I can use it for, and how I'd use it (API interface). If I go to your repo, there's nothing there. I'd suggest pulling some examples from your example/ directory, and putting in your README.md.
Bokeh, basically D3 for Python. 
[`range_contains`](https://github.com/python/cpython/blob/master/Objects/rangeobject.c#L415-L423) static int range_contains(rangeobject *r, PyObject *ob) { if (PyLong_CheckExact(ob) || PyBool_Check(ob)) return range_contains_long(r, ob); return (int)_PySequence_IterSearch((PyObject*)r, ob, PY_ITERSEARCH_CONTAINS); } [`range_contains_long`](https://github.com/python/cpython/blob/master/Objects/rangeobject.c#L365-L413) // Error checking, initialization and // deinitialization removed for brevity. static int range_contains_long(rangeobject *r, PyObject *ob) { /* Check if the value can possibly be in the range. */ cmp1 = PyObject_RichCompareBool(r-&gt;step, PyLong_FromLong(0), Py_GT); if (cmp1 == 1) { /* positive steps: start &lt;= ob &lt; stop */ cmp2 = PyObject_RichCompareBool(r-&gt;start, ob, Py_LE); cmp3 = PyObject_RichCompareBool(ob, r-&gt;stop, Py_LT); } else { /* negative steps: stop &lt; ob &lt;= start */ cmp2 = PyObject_RichCompareBool(ob, r-&gt;start, Py_LE); cmp3 = PyObject_RichCompareBool(r-&gt;stop, ob, Py_LT); } if (cmp2 == 0 || cmp3 == 0) { /* ob outside of range */ return 0; } /* Check that the stride does not invalidate ob's membership. */ tmp1 = PyNumber_Subtract(ob, r-&gt;start); tmp2 = PyNumber_Remainder(tmp1, r-&gt;step); /* result = (int(ob) - start % step) == 0 */ result = PyObject_RichCompareBool(tmp2, PyLong_FromLong(0), Py_EQ); } 
It's just arithmetic. Trivial.
I use `subplots` whenever I need multiple subplots in my figure. The boilerplate I was referring to is that you still need a single line of code for each of the following (plot title, axis title, axis limits, etc.). It just ends up being a decent bit of typing and taking up a decent bit of space in the middle of your code just to create fairly simple plots. An example from my documentation on EasyPlot library: A basic plot with minimal formatting would involve: fig, ax = plt.subplots() ax.plot(x, x**2, 'b-o', label="y = x**2") ax.legend(loc='best') ax.grid() ax.set_xlabel('x') ax.set_ylabel('y') ax.set_title('title') With `easyplot`, it shrinks to: eplot = EasyPlot(x, x**2, 'b-o', label='y = x**2', showlegend=True, xlabel='x', ylabel='y', title='title', grid='on') It's a bit of a kitchensink approach, throwing common parameters at the same method, which then smartly determines which method gets applied to which object (fig, ax, etc.). It isn't for everyone, and I only use it when I know I won't need too much customization with the plot, but it is nice sometimes to have a single line or 2 lines of code to create the plot you want with all the basic stuff like xlimits, labels, legends, etc. 
See https://hg.python.org/cpython/file/c9d89d3f3ff1/Objects/rangeobject.c#l366 and https://hg.python.org/cpython/file/c9d89d3f3ff1/Objects/rangeobject.c#l415 So for `x in somerange` it does something like: 1. is `x` an int or bool? If so: if step &gt; 0: if start &lt;= x &lt; stop return (x - start) % step == 0 # it seems like the comment accompanying the code is wrong in terms of parentheses else: if stop &lt; x &lt;= start: return (x - start) % step == 0 return False 2. otherwise, do expensive O(n) search
Many images (particularly the most popular ones) on docker.io are created by Docker themselves. If you don't trust them, you shouldn't be using the Docker software at all. If you think you're using a very niche image, you absolutely should be checking over it, and frankly this is not an immense amount of work. Dockerfiles are easy to skim-read. And frankly, you could make the same complaint about *any* open source software. When's the last time you read through the OpenSSL, nginx or sendmail source? Despite the fact that you're transparently using them every day. The principle of free/open source is "many eyes" are able to look at the source, every one of those people are able to expose vulnerabilities in that source, and so the burden on each person is small.
Sure. I knew someone would jump in and say that. The point is you guys are the minority.
My bet is wrong
This looks awesome Philipp! Hadn't come across your library till now, but it certainly looks very interesting. 
The generator are not inherently faster. The major point is memory save by not saving intermediate values. List comprehension are a different thing. They save a lot of time by building the list as a whole and not doing continuous append.
Personally, I would not call the following pythonic at all: ggplot(aes(x='date', y='beef'), data=meat) + \ geom_point(color='lightblue') + \ stat_smooth(span=.15, color='black', se=True) + \ ggtitle("Beef: It's What's for Dinner") + \ xlab("Date") + \ ylab("Head of Cattle Slaughtered") I don't mind adding to make a graph so much, but the cryptic R naming of functions makes the above hard (for me, at least) to read.
The main challenge of all image classification problems is finding a useful feature set for the particular characteristics of images in your database. I had never heard of lib puzzle, but skimming it appears to be using a visual bag of words approach for feature extraction. Other feature extraction approaches include but are not limited to color-based features, texture based features (Gabor, etc), and more "advanced" image features such as SIFT, SURF, etc. The performance clustering algorithm you choose, kmeans, ndgrid, etc, will fundamentally depend on the feature set used for classification. 
Just to echo some of the things that have been said here. Django is a full stack framework. It covers most(all) of the bases you need in building a basic to medium complexity web applications (and sometimes bigger). Django is great if you are new to python or don't want (or need) to spend a lot of time picking specific packages for each of the various components of your site. Many of the pieces of Django can either be replaced or supplemented with third party libraries from auth to templating and even the ORM. HOWEVER replacing some of these features can begin to break some other features within the framework because of the tight coupling so you have to be very careful when building a Franken-Django. At work we have a stack based on Tornado/Jinja2 but when I'm building smaller projects for myself or others leveraging everything built into Django is always very convenient. Is Django the "fastest" or "best" way to do everything absolutely not but in many cases it's conveniences far outweighs most of the tradeoffs you make. 
there is one library that (other than for scientific needs) rivals what you get with Python - when you feel like exploring, have a look at CPAN.
I read [an article](http://www.banyanops.com/blog/analyzing-docker-hub/) (no idea how reliable it is) that suggested that 30% of official images contain vulnerabilities. 
Ada? Lisp? Scheme? Cobol?
As far as I can remember scikit-image doesn't depend on opencv, I've successfully used it when opencv wasn't python3 compatible. But back to opencv: If you are using homebrew then ```brew install opencv``` will be enough (I've only tested this with python installed via home brew, but in worst case scenario you will need to change python path, or pass some build switches to brew). If not - you should give it a try! If you trying to build stable version of something from scratch on major platform like OSX or ubuntu you probably doing it wrong (unless of course you need non standard build options) And if you're trying to use obsolete PIL package - try with "pillow" instead.
and then ```import this```
I don't know about unpythonic, but they're an antipattern in any OOP language. Objects should *not* leak state to the outside world, and that means getters/setters should be avoided. Also, in a 200 line project, without seeing your code, I'd suggest the use of classes is itself unpythonic.
This exactly, never trust foreign code (especially on critical systems) without at the very least testing in a true virtual machine or non-critical system. 
Make a factory for your task: def make_task(rate): @task(rate_limit=rate) inner_task(...): # ... return inner_task task_rate_5 = make_task(5) task_rate_10 = make_task(10) ...
&gt; They save a lot of time by building the list as a whole and not doing continuous append. No they don't. For non-nested loops, the *only* optimization affecting the loop's speed is replacing the lookup and call of `list.append` with a `LIST_APPEND` bytecode. EDIT: Wording now even more pedantic.
Most of the overhead is creation and function-call overhead. If you do string = "cecilia" * 100 you instead get times that are almost the same - a 5% difference on Python 3. The cost of the remainder is almost certainly due to how generators are implemented in Python. What you effectively have is a "frame object" that you resume and suspend. This resuming and suspending is not free (although it's cheaper than a function-call, which has to *create* a new frame). The manual loop elides this cost, at the expense of doing the summation in a bytecode loop (instead of a C one as `sum` does). This means that: * The first has a bytecode loop (the generator's) *and* a C loop which "pumps" the inner loop by stopping and resuming its frame. * The second has a single bytecode loop, at the expense of doing the addition in Python-space. 
&gt; I don't know if the Python interpreter/compiler does this, but it should be possible to detect "increment by constant 1" and optimize that to use an increment operation instead of an addition. CPython does not do that, no.
&gt; I thought for loops were supposed to be slower [than generator expressions]? Why? That is just not true. Whoever told you that or wherever you read that is not a trustworthy source if info. 
are you using @property and its .setter? or do you have methods called get_id? Here is what you should be doing, IMHO: https://docs.python.org/2/library/functions.html#property
There's a common myth going around that comprehensions happen in C.
*psst: you didn't open that file for reading and it's slightly bugging me; and no one wants to write back to their query file*
As a novice, I'm interested in why you feel soap is broken. Could you elaborate? 
[Intro to Relational DB](https://www.udacity.com/course/ud197) A solid udacity course using python connected to databases. 
I think you'd be better by installing [Minicoda](http://conda.pydata.org/miniconda.html) which comes with conda and its dependencies, and then install the packages that you want :-)
`_expire` can be prettier: def _expire(self): cutoff = time.time() - self._ttl_seconds # Iterate copy because we delete keys for k, lst in six.iteritems(self._counts.copy()): # Delete times less than (current - ttl) del lst[:lst.bisect(cutoff)] if not lst: self.remove(k) Also, deleting from the front is expensive. It seems like a deque would work better if this is common. You mention `blist.sortedlist` - if you're using it elsewhere, try [`sortedcontainers.SortedList`](http://www.grantjenks.com/docs/sortedcontainers/index.html) instead. It's pure-Python and [often faster](http://www.grantjenks.com/docs/sortedcontainers/performance.html). 
&gt;The generator are not inherently faster. Programatically, this is correct, but it's not difficult to encounter a situation where generators are much faster, due to [practical concerns with processors filling up their L1 cache](https://www.youtube.com/watch?v=OSGv2VnC0go&amp;t=8m17s). When a processor can't save the data it's working on in its CPU, it needs to find another place to put it, which takes several orders of magnitude more time. Keeping object small (like generators do) generally keeps object small enough to fully manipulate in cache, which can cause dramatic increases in speed, even in common circumstances.
&gt; we found that more than 30% of official repositories contain images that are highly susceptible to a variety of security attacks (e.g., Shellshock, Heartbleed, Poodle, etc.). Interesting, but I think this kind of vulnerability can be resolved just by routinely running all recommended OS security updates whenever you create a Docker container from any image. This seems like a sensible general practice for any form of system management?
This is exactly what I do. 
I typically write SQL first in a test environment using SQL Server Management Studio. Then when I have something I like, I integrate it into my python code.
and then '''from __future__ import braces'''
Thanks! I've updated it now to something a little better. Not perfect but certainly better than the no examples I had. I'll update it more as time goes on, but it's almost the end of the day here in the UK.
[Conda](http://conda.pydata.org/) Thanks. ^_^
Do you know if there is an UI app for managing Views and Models - something like Views and Content Types in Drupal ?
And that's why I need your help. Thanks for the input!
Cool, I appreciate the time you've taken into looking into that. I asked because most of our SaaS APIs are RESTful, but our main order system is WSDL/SOAP. I was wondering how tricky it'd be to deal with that myself for a few simpler things rather than going through our freelancer. It's good to know what I'd be getting into. 
Can a person without any programming background participate in this? Or do you have to have the basic skills?
Great timing, my company is migrating now. 
One of the cool features of the SQLAlchemy python library is that you can essentially switch between whatever SQL implementation you'd like on the fly with just a bit of code change. lets say I was a lil' guy and doing some data analyses and I was just dumping to sqlite: engine = create_engine('sqlite:////tmp/test.db', echo=True) but then one day it turns out I really need something bigger to scale out my stuffz engine = create_engine('postgres://user:pass@host/db', echo=True) I re-run my base declaration and generate metadata and all done! my stuff is gonna go into a postgres db instead of sqlite I'm just now getting into numpy and scipy and some of the other scientific libraries which seem like awesome C things I should pay attention to. I prefer postgres basically when I know the database is going to have a heavy analytical workload and not workload. [wikipedia does a better job explaining than me.](http://en.wikipedia.org/wiki/Comparison_of_relational_database_management_systems)
totally alright, I stole it from my Python "inspirer" myself :-p
I learned so much from watching those talks by Raymond Hettinger. If anyone hasn't watched them, you should.
Probably wouldn't make a difference anyway on modern hw...
Nice find! Damn good detective work.
you are right. I messed with other thing
I'm not sure exactly who your target users would be, but I would think that most libraries of this sort of scope would offer oauth. For example, how would I use your library as part of a webapp, rather than a cli tool? I think you may be cutting out a major core of your potential audience if you lack this feature.
Generally you just want direct access to the variables, in Python. If you need to do some processing on it as it goes in or out, then use properties: for example, ensuring that an iterable is stored in the object as a numpy array, or that mutables are copied.
In my field (physical science / data anlaysis) it is simply a shortcut for getting a working python distribution alongside many of the packages that will inevitably be needed - Numpy, Scipy, Scikit-learn, Pandas, Matplotlib, hdf5, ipython, PIL, scikit-image, etc ... So when I show a colleague some data analysis routines I have developed and they are new to python - rather than say 'ok first get python, now install these 10 libraries individually' they can just download anaconda and then it will in general work right out of the box For tech savvy people it would be no real issue to just say you need python x.y and these following packages ... but when there's a working bundle of all the needed packages its often just easier to go that route But you are correct in that anaconda is really just a python distribution with a pre-installed set of packages and a package manager (conda). Its a scientific python distro packaged by people who do scientific python for people who use/need scientific python. Its just easier and really unbeatable in terms of ease of use, installation, time to get up and running, etc.. One caveat though - Anaconda is clearly not the light-weight solution. So if that's a concern then its perhaps best to go the standard python pip route - although there is a 'mini-conda' if I recall correctly
it comes installed as part of anaconda natively though right? I use anaconda on OS X and don't remember having to specifically install opencv but i can type import cv2 as cv and it works fine
and finally import __hello__ congrats you wrote your first program
I don't know... I use anaconda, but this was a while ago so perhaps I wasn't using anaconda then? The dll issue is only a windows issue.
For other things about the difference http://dirtsimple.org/2004/12/python-is-not-java.html
I think you're referring to the CMS features of Drupal while Django is a web framework. There are however many [CMS'es built on Django](https://www.djangopackages.com/grids/g/cms/). (And the built-in admin has a good UI for managing the content in your models).
Thank you, so will check that out now!
&gt; How is using classes or not using classes in shorter projects Pythonic or not? The practices of Python, as I learned them, were to focus on modules and functions, and resort to classes only when it's truly the best representation of your application. What you emphatically do *not* want to do is program Python by building Java-style object models.
They also optimize away the overhead of `SETUP_LOOP` and `POP_BLOCK`, since `break` and `continue` cannot appear inside comprehensions.
I'm such a RaymondH fangirl. I'd gladly have his babies.
I'd attribute it to reddit historically being nerdier/more tech savvy and generally beginning to appeal to a much broader audience.
### connection.py class DBConfig(object): def __init__(self): self.session_maker = None def setup_db_connection(self, sqlalchemy_uri, echo=False): engine = create_engine(sqlalchemy_url, echo=echo) self.session_maker = sessionmaker(bind=engine) #### __init__.py from .connection import DBConfig config = DBConfig() config.setup_db_connection(uri="&lt;your uri read from env/config&gt;") session_maker = config.session_maker #### user.py from . import session_maker def get_users(role): session = session_maker() return session.query(User).filter_by(role=role).all() P.S: Consider above snippet as high level design not as working code [EDIT]: Unlike other socket connection which don't work when shared across multiple tasks, session object works fine.
Ah, thanks. Yeah I was confused as to whether or not there were actually so many other subreddits growing faster than /r/python or if I just didn't understand what rank was showing.
Why is that odd? If the file is ASCII, then UTF-8 decoding basically consists of checking that the MSB is clear (which will be accurately branch predicted every time). Even with a fast SSD that's going to be minuscule, especially compared to all that I/O. Python 3 has had lots of other optimization work done which will dominate.
Sauce?
I recommend watching Raymond Hettinger's [Class Development Toolkit.](http://pyvideo.org/video/1779/pythons-class-development-toolkit) He teaches you the pythonic way to use classes. 
http://stackoverflow.com/questions/1732348/regex-match-open-tags-except-xhtml-self-contained-tags/1732454#1732454
Also, check out descriptors: https://docs.python.org/2/howto/descriptor.html
Tkinter has a reputation for being ugly and limited, but it has become much nicer since the introduction of Tk 8.5. If you use the "ttk" (themed toolkit) module included with recent versions of Python, you can create native-looking GUIs with minimal effort. As an example, here's a little exercise I did to re-create the Windows "Run" dialog in Tkinter. Aside from some padding/spacing differences that I didn't bother to refine, they look quite similar: http://imgur.com/myEuGqd Here's a good video that talks a bit about old vs modern Tkinter: https://www.youtube.com/watch?v=yI7NYgP54sw 
A fun idea, my problem is without cloning it I can't tell what the result is! Why not add some results to the README?
I would highly recommend using SQLAlchemy's Declarative model to define your schema and manage CRUD. It's highly expressive and scalable, and using the ORM should make writing raw SQL queries a rarity unless you're going something quite specific. The official docs cover basic usage of the declarative base in the "Object Relational Tutorial" in case you haven't read that yet. Edit: To answer your question more directly, if you must execute raw SQL, use [text()](http://docs.sqlalchemy.org/en/latest/core/tutorial.html#using-text).
All of his talks are awesome. [Transforming Code into Beautiful, Idiomatic Python](http://www.youtube.com/watch?v=OSGv2VnC0go) made me want to watch any video he publishes.
Just use pip==7 wheel and virtualenv you only have to build packages once
see the post above mine, and watch the full video. I'm sure there are probably related videos on youtube from him.
No. Take a look at the sidebar and you might work out why. 
I'm not quite sure what you want to do. But scikit-image is a great module for working with images. Here's an example of image matching: http://scikit-image.org/docs/dev/auto_examples/plot_censure.html#example-plot-censure-py
There are a few weird things in this article, mostly many opinions with little arguments. There's an error as early as the fourth sentence. :/
Exposing a getter and a setter exposes exactly as much information as just exposing the property does (at least in python, in java is exposes slightly less). For "good OO style", your classes should provide abstractions that encapsulate their internal state.
Python's `random` module has a `shuffle` function. So shuffling is as easy as `random.shuffle(deck)` (the function shuffles lists in place).
Answered on SO. The manpage and the sample scripts in the source files have all the info you need.
Yes, it is. You are possibly looking for: os.utime() Also have a look at https://docs.python.org/3.3/library/os.html#os.utime
How do you DDD?
Thanks Raymond!
It is entirely impossible to design a modular system without coupling, for any interaction is a form of coupling. So what problem are you trying to solve? &gt; a "setter" is an admission: "I couldn't come up with a behavior for changing this value, so hey, whatever- I'll just let you change that." That's a stupid reason for making a setter. A better one is "I model some state that you are allowed to modify. Ergo I shall let you modify said state." What's wrong with that? If anything, it is the infatuation with having an object model that's the problem.
Getters are unnecessary in python for sure. I wouldn't call setters unpythonic, but I generally avoid them because I prefer to make my data structures as immutable as possible.
&gt; If anything, it is the infatuation with having an object model that's the problem Well, I wouldn't disagree. &gt; What's wrong with that? So, what's wrong with modifying state directly? What's wrong is that it breaks the abstraction you're supposed to get from using OOP. What's wrong is that it creates code that is bug prone, difficult to parallelize, difficult to unit test, and difficult to debug. It makes everything you do *harder*, so why do it at all? If you need to pass state back and forth, you're wrong- you don't need to. There are a number of design patterns that can encapsulate state. When possible, instead of mutating objects, return new instances with the new state. Leverage monads to avoid side effects. I mean, I'm no fan of dependency injection, as I feel it's over engineering a simple problem, but the entire point of DI is to force you to write fully decoupled code, because each component should work in isolation from every other.
I'd hope that anyone with more than passing familarity in Python would flag `if x in range(y)` as a candidate for immediate replacement in a code review.
&gt; What's wrong is that it breaks the abstraction you're supposed to get from using OOP. What abstraction are we talking about here? I'm talking about a collection of state - surely acting as a collection of state cannot be breaking that. &gt; it creates code that is bug prone, [...] and difficult to debug. How so? &gt; difficult to parallelize, I disagree. Forcing these boundaries means you can only apply parallelism from inside (or around) the objects in the system. A data-driven approach allows one to parallelize behaviours *over* data. &gt; difficult to unit test, Not so: if you separate state and behaviour you effectively get dependency injection for free: make the state in the unittest and run the behaviour over it. Coupling the two is what causes the problem. &gt; When possible, instead of mutating objects, return new instances with the new state. When possible, sure, but copies aren't free. &gt; I mean, I'm no fan of dependency injection, as I feel it's over engineering a simple problem, but the entire point of DI is to force you to write fully decoupled code, because each component should work in isolation from every other. DI just enforces my point: the problem is that you've coupled state and the actor upon the state. DI is one way of working around the problem; the other is just not forcing the encapsulation boundaries for behaviour to match the encapsulation boundaries for state.
&gt; Trust me No. &gt; , I've tried for years. Then you've been doing something very wrong for a long time.
How do you encapsulate your models in python to implement domain driven design patterns?
I can see where you're coming from.
Every game is.
This sounds like a similar problem to finding a substring within a string. You can read more about that here http://en.m.wikipedia.org/wiki/String_searching_algorithm and potentially implement a variation on one of these algorithms that searches for images within images. 
im sure this comment is gonna get buried, but i just joined this sub earlier this week and im glad to have contributed to such a milestone. i have no idea how to program in python, but i figured this would be a good place to start. 
#####&amp;#009; ######&amp;#009; ####&amp;#009; [**String searching algorithm**](https://en.wikipedia.org/wiki/String%20searching%20algorithm): [](#sfw) --- &gt; &gt;In [computer science](https://en.wikipedia.org/wiki/Computer_science), __string searching algorithms__, sometimes called __string matching algorithms__, are an important class of [string algorithms](https://en.wikipedia.org/wiki/String_algorithm) that try to find a place where one or several [strings](https://en.wikipedia.org/wiki/String_(computer_science\)) (also called [patterns](https://en.wikipedia.org/wiki/Pattern)) are found within a larger string or text. &gt;Let Σ be an [alphabet](https://en.wikipedia.org/wiki/Alphabet_(computer_science\)) ([finite set](https://en.wikipedia.org/wiki/Finite_set)). Formally, both the pattern and searched text are vectors of elements of Σ. The Σ may be a usual human alphabet (for example, the letters A through Z in the Latin alphabet). Other applications may use *binary alphabet* (Σ = {0,1}) or *DNA alphabet* (Σ = {A,C,G,T}) in [bioinformatics](https://en.wikipedia.org/wiki/Bioinformatics). &gt;In practice, how the string is encoded can affect the feasible string search algorithms. In particular if a [variable width encoding](https://en.wikipedia.org/wiki/Variable_width_encoding) is in use then it is slow (time proportional to N) to find the Nth character. This will significantly slow down many of the more advanced search algorithms. A possible solution is to search for the sequence of code units instead, but doing so may produce false matches unless the encoding is specifically designed to avoid it. &gt;==== &gt;[**Image**](https://i.imgur.com/9NwTe2X.png) [^(i)](https://commons.wikimedia.org/wiki/File:DFA_search_mommy.svg) --- ^Interesting: [^Boyer–Moore ^string ^search ^algorithm](https://en.wikipedia.org/wiki/Boyer%E2%80%93Moore_string_search_algorithm) ^| [^Robert ^S. ^Boyer](https://en.wikipedia.org/wiki/Robert_S._Boyer) ^Parent ^commenter ^can [^toggle ^NSFW](/message/compose?to=autowikibot&amp;subject=AutoWikibot NSFW toggle&amp;message=%2Btoggle-nsfw+crpjcyt) ^or[](#or) [^delete](/message/compose?to=autowikibot&amp;subject=AutoWikibot Deletion&amp;message=%2Bdelete+crpjcyt)^. ^Will ^also ^delete ^on ^comment ^score ^of ^-1 ^or ^less. ^| [^(FAQs)](http://www.np.reddit.com/r/autowikibot/wiki/index) ^| [^Mods](http://www.np.reddit.com/r/autowikibot/comments/1x013o/for_moderators_switches_commands_and_css/) ^| [^Magic ^Words](http://www.np.reddit.com/r/autowikibot/comments/1ux484/ask_wikibot/)
What you're saying isn't making much sense. What are you actually trying to do?
All of which is stuff that's going to be entirely unrelated to the kind of code that people are going to write day to day in 95+% of Python jobs
subbed, ty
&gt; here's the proper way to do what your original example Constructing the set is still O(n) - every single member of the sequence has to be hashed. So your solution is actually slower than theirs because it has to allocate two containers and do a lot of hashing (instead of just comparisons).
Can you explain why you think that is more maintainable?
I think what you really want to be doing is setting up a broadcast and announcing each client on the network. This involves just writing to and reading from a broadcast address. Each client would announce their own ip address so the other clients would know how to reach them. I haven't read fully through this question/answer but it appears to have what you need. http://grokbase.com/t/python/python-list/0369kdpe56/scanning-for-local-servers-getting-a-broadcast-address
It's great that you can distribute the compiled code. However, that would only work for people on the same platform as you, correct? Is there any easy way to build for the major players (OSX, Linux, Windows), prior to distributing?
[PyContracts](https://pypi.python.org/pypi/PyContracts) would be a good place to start, it doesn't handle side effects (well), but allows basically arbitrary contracts on args and return values.
I'm not sure you're really using argparse right. The way it's intended to be used is to pass commandline arguments to your script. So in your case, it should be invoked like ./yourscript.py -q "Bill gates" "Ted talks" --max-results 5 or whatever. It's not entirely clear what you're trying to accomplish, but you should only run the add_argument and parse_args set of code once. I usually put it in an init() function and call it inside of my main function (in your case, right after the `if __name__ == '__main__':` bit. **EDIT** Also, I certainly hope you didn't post your actual DEVELOPER_KEY. If so, you should really make sure to remove the current one and request a new one. **EDIT 2** Maybe a better question to ask is what you're trying to do with the argparse bits. You might be over complicating some stuff.
You should really take a look at https://github.com/docopt/docopt I have never gone back to argparse since finding it.
Well I took it straight from the youtube API so how would I change it? 
Yup my bad. Late night coding and I was excited when I got things working. Apologies for offending you + anyone else.
So, I think that the simplest way to skirt around the issue (since you don't seem interested in passing CLI arguments to the script) is to make the following modifications: instead of def youtube_search(options): do def youtube_search(search_string, max_results=5): And then change the following line: search_response = youtube.search().list(q=options.q, part="id,snippet", maxResults=options.max_results).execute() to search_response = youtube.search().list(q=search_string, part="id,snippet", maxResults=max_results).execute() Now, instead of calling the `youtube_search(options)` function, you would call `youtube_search(search_string, max_results)` (and max_results is optional, defaulting to 5). Now, just get rid of all of the argparse stuff. If what I'm suggesting isn't clear let me know and I can clarify the changes.
I was more surprised that they *all* said django was not that great... I'm happy to use whatever I choose, but I was curious about what else is out there
There must be a better way!
I actually really like the stdlib random module. It's got a lot of what I'd want and more. randint, shuffle, sample, choice, uniform, gauss, normalvariate, expovariate... Awesome stuff, and extremely useful. The only extra thing I could ask for is a cryptographically secure random, but pycrypto is the perfect module for it anyway.
It especially shines when you have a sizable project where you need asynchronous tasks, controlled caching e.t.c, where you have to read both the docs and the source code. It's excellent.
I'm not sure what you're asking, but I try to do DDD based on my understanding of Eric Evans' book. 
You can also deploy something like Anaconda which lets you use a different Python version than the system-wide Python.
They have one of the best Django tutorial. If anyone wants to learn Django, first start with this tutorial and then do official Django tutorial, the poll app. 
I... Don't think think that's the point. 
This is lacking in content. Some features are listed but they're not compared to the other frameworks that were mentioned. Pretty interface &amp; good UX is listed but there's no screenshots showing this.
Thats not hockeystick growth, we need to pivot immediately to cat pictures to please the VCs.
That reminds me: I have some code I've been meaning to rewrite that builds a BSP tree for a 3d model format...
Does it have a require/include feature?
You could use the matplotlib widget for pyqt: http://matplotlib.org/examples/user_interfaces/embedding_in_qt4.html
There's a chat system that uses Zeroconf to do this already. if you use empathy enable the 'salut' protocol or install Pidgin or adium and enabling 'bonjour'
&gt; On the other hand, most other languages Are you writing in most other languages, or Python? Write code using the idioms of the language you are using, don't write for some other language's idioms.
It's not a generator, its a range object: # this is in Python 3, for Python 2 use xrange py&gt; import inspect py&gt; inspect.isgenerator(range(5)) False Here's [the patch](http://bugs.python.org/issue1766304) that added the behaviour. (By the way, good question, I don't know why people downvoted you for asking for evidence.)
&gt; Python will compare x to every single value in the sequence No it doesn't. It can [test for membership in constant time](http://bugs.python.org/issue1766304), by doing modular arithmetic.
Why I have been doing something similar all night. [How random is /dev/random?](http://altoidnerd.com/2015/05/30/how-random-is-devrandom-visualizing-the-output-of-dd-command-and-devrandom-with-python-and-hexdump/) This is looking at /dev/random as opposed to python's random pkg. src: https://github.com/Altoidnerd/dev-random-test 
When you see somebody breaking encapsulation, you say "do you really need to do that?" and when they say "yes", you say "okay then". Python is not as much of a Bondage And Discipline language as Java. Consequently, we tend to code more on the basis of "we're all consenting adults here" rather than "don't touch that! or that! not that either!". 
There is both Docopt (others mentioned) and [Click](http://click.pocoo.org/4/why/) as alternatives
Actually I'm using dHash. Performed best for me, but you should try it with your own imageset. Right, you get a score for every image and can compute the difference between them. Have a look at the source code: dhash(image, hash_size=8). It's important that you finetune the hash_size. Low value is good for performance and if you want many similar images. High value is bad for performance but good for accuracy. Test it on your dataset.
I'm trying to break the habit of treating it like C++ ;)
In Python 3, (or xrange in Python 2), it will not compare with every value in the sequence. The __contains__ method takes care of the comparison in O(1) time. 
Click is the best command line library around.
Yeah, yeah, and that's the philosophy side of it. But the philosophy only exists as a heuristic to help us make good practical decisions; this is one of the only cases I'm aware of where Python philosophy doesn't align with my practical concerns :/
hehe. I would say newbish mistake. xD It's kind of a hold over from before I got really going on the lib and all classes were in one file. Now that it is part of a larger whole and published on pypi and github, I think I'll just let the LICENSE file take care of it.
Sounds like something is blocking threads! I set my flask app uwsgi / nginx with the help of http://stackoverflow.com/a/27221427/567606
D'oh. =( Didn't think about it.
* .pyc files aren't designed to be read or changed by humans, they exist to speed up how quickly your programme loads - can't be meaningfully diff'd, clutter change history * they're not cross-version/cross-implementation, so they're of no use to people using different Python versions to you.
I have not quite come to terms with the fact that 'hacking' does not really mean anything anymore.
It has certainly lost much resemblance to what it meant back in the 80s. 
NOW KISS
https://github.com/pydata/pandas/blob/master/pandas/parser.pyx Not a tutorial post, but this is a high-profile example of using cython for parsing.
The former does two floating point comparisons. The latter creates a list with 180 elements and then searches it to see if the number is in the list. So a) as said by others, it would only work for integers, and b) it's far less efficient. 
Don't do it where it is not needed. Best idea is to just have the attributes directly accessible. Then use `@property` if you change how the attribute is stored, and you need to wrap some logic around it for backwards compatibility. For example you might have a class with an `age` attribute (a simple int). But later you want to change that to `date_of_birth`, and compute `age` of that. You could then use `@property`. But I would not use it before I needed to.
Ah, did not know that. I guess that's a property of the object it now returns. 
Apple, I command thee to be an orange!
The click-bateyness hurts.
No, the UAP states that you won't know based on the syntax how something is implemented, whether as a simple property set or a method call. If you have getFoo and setFoo methods, you'll definitely know how they're implemented.
I think this is a problem with flask, not with Python.
In general you're right, but not in this case. This conversation has lead me to do some experimenting. `x in xrange(n)` will still result in a search in Python 2. In Python 3 `range()` returns an object of type `range` which has a quick `in` operator. `xrange` just returned a normal generator which had to be iterated over. Still.... I learnt something today. So that's good.
I concur.
It still runs in the latest version of Ruby. ;-)
What? You don't like term-hacking? It's double-plus good!
Sounds about right, given the article: &gt; While Python is easy to learn, it’s not necessarily easy to learn.
Is this a Python question, or an algorithm question? Your picture shows carry bits, but they're not in your method signature. I don't know what algorithm you're working from but a full adder has 3 inputs, not 2.
wow :D that was some explanation .. Thanks dude .. i guess i'll have to do with my exe+500 extra files for now .. :D
I think this post would have benefited from a more descriptive title, such as "PyPy Development: CFFI 1.0.1 released, featuring new way to build extension modules. Integrated support in upcoming PyPy 2.6."
Upvote for Noobcomplishment. (๑•̀ㅂ•́)و✧
I didn't realize this (while learning Javascript) until two years in, after I had written dozens of functions like the first one in your example, so congratulations on figuring it out so early and making me feel inadequate :).
It does. Just that what people usually mean by 'hacking' is 'cracking'. Cracking is (usually) illegal unless you are hired by a company to attempt to crack their system. Hacking is perfectly legal and very commonly done. 
Could you please explain why this is much more efficient? Is it a matter of reduction in if statements 
https://github.com/honnibal/spaCy/blob/master/spacy/tokenizer.pyx#L48 This function tokenizes text, in preparation for a natural language processing pipeline. It first finds white-space separated chunks, hashes them, and looks them up in a cache --- after warm-up the vast majority of chunks are processed that way (&gt;95%). Otherwise, it splits the chunk up into tokens, and looks up each token in a vocabulary, to fetch (or create) a struct with useful properties, e.g. the token's unigram probability. The function averages 0.2ms per document, 20 times faster than NLTK's tokenizer returns a simple list of strings. I'm starting to regret writing the function this way, though. 
And even better yet, you can apply this same programming idiom is almost any language
I'm sure someone else can explain it more correctly than I can, but from my understanding, it's simply more efficient because it's using less lines. This helps reduce opportunities for errors as well as makes it easier for others to read, update, debug, etc... Of course, I could be completely wrong on all of this, but if so, I'm sure someone here will correct me. 
The important thing is readability and reduced chance for errors.
Exactly, the least amount of code that's understandable is the thing to go for :) (unless you need crazy speeds/optimizations)
In your example, depending on the execution path, you do not end up with states that share the same semantics. `random.SystemRandom()` returns an instance of a random number generator. Therefore, if an exception is raised, `random` is still a module, but if no exception is raised, `random` becomes a generator. Variable shadowing is when you replace an existing variable with something that shares no relation with the meaning of the original variable. Here is an example: # Some variable assignment: map = Map.get_it_from_the_filesystem() positions = […] map(map.add_position, positions) # Whoops! We overwrote the builtin `map` function with our map object a bit earlier Common built-ins that get shadowed all the time (by mistake) include `id`, `dir`, `map`, `filter`, `hash`, `hex`, `list`, `tuple`, and many others.
Oh, I get it, you are intentionally replacing it because the module and the random generator share the same interface (roughly). Instead I would recommend this: import random random_generator = getattr(random, 'SystemRandom', 'Random') or import random try: random_generator = random.SystemRandom() except AttributeError: random_generator = random.Random() IMHO, first is cleaner but second is more explicit, while a bit too verbose.
Question: Does it also perform less variable comparison operations? Would that make it more efficient because it's not referencing and comparing the same two variables multiple times? 
It's not only more readable, it also executes faster. In your improved code you just have a comparison, while you execute 2 comparisons in the first example if the first one fails. You also use 2 if's and while that isn't bad in itself, these "branches" are rather expensive in your processor. Your processor doesn't execute instructions the same way they come in, but out of order, it already loads and executes code when it's still busy with another instruction. The problem with branches is that the processor doesn't know which branch of the program it has to execute until the execution of the comparison in this example is finished. So it just guesses the most likely branch and executes it. CPUs have actually gotten quite good at this kind of prediction but if it guessed wrong parts of the internal memory (registers and cache) have to be flushed and it has to begin the execution anew, now with the right branch, which costs quite some time. While both don't really matter in this program since it's probably just too small to be noticable, it can have a negative impact if you ever want to write large applications. If your code is executed 100.000 times you will notice 20ms delay per execution.
&gt;If not it seems a little less explicit than the if else statement and in that case id choose the ifelse. Zen of Python and whatnot. The second version is more explicit, simpler, and more beautiful. I don't understand how you came to your conclusion 
It originally referred to model train wiring.
Unless the spec for the recursive function limits it to only using two arguments (s1, s2), you can instead use 3 and keep carry state that way(s1, s2, carry).
The most bothersome is when people take pictures on their friend's phone and post it to their social media accounts. #HACKED
I also wonder how you guys check the package name registed when you write a python package and ready to release it on PyPI. As for me: * before: manually search it on PyPI * now: `$ caniuse package_name`
Here's a similar project I made that you might be interested in: http://pre-commit.com
[conda](http://conda.io), the package manager inside Anaconda, is far superior to pip for *users* who do not want to understand the complications that can arise when building software. Not only are conda environments more robust in how they isolate compiled extensions, but the metadata in conda packages is richer than what is currently supported by pip (and wheels), so that some of the more intricate interdependencies in the scientific/pydata ecosystem are handled gracefully. Additionally, because Python is often used as a glue technology in the scientific space, or at least has to interop with C++, Java, R, and Hadoop/Spark, conda is designed to be *language-agnostic*. It can happily install R, R packages, Spark, and C++ libraries like VTK and Qt. (disclaimer: I work at Continuum Analytics)
And I don't think that `pip search package_name` is a good way to solve the problem. It shows all the package which contain the query. The answer I want is YES or NO. That's why I write caniuse.
return isn't a function. While valid syntactically, `return(True)` is a weird thing to do. You should do `return True` instead. It is acceptable to put parentheses around an expression that you're returning, like `(a_smile == b_smile)`, but there should be a space after the return: `return (a_smile == b_smile)`
You may check the following stack overflow question, I'm sure you will find much fun and joy. [Hidden features of Python](http://stackoverflow.com/q/101268/4890577)
Bucky never let me down. http://www.youtube.com/playlist?list=PL6gx4Cwl9DGAcbMi1sH6oAMk4JHw91mC_
Looks quite nice, but any particular reason why you chose to go with camel case over snake case?
If, sure. But it's probably premature to assume you'll need to make that change if == does the trick now. It's easier to read if you see exactly what it does in the same amount of code.
I'm a noob. Didn't know this, thanks for posting! :)
&gt; If A smile equals B smile then return True. Else, return False. "Return whether A smile equals B smile." Isn't that easier? By your argument, addition of integers should be implemented as a lookup table in a big dictionary for the sake of explicitness.
This mess of functions reassignment exist because lookups are expensive, not calls.
This is great. Remember this when you learn other languages too. This kind of one line return statement works in Java and C# and other languages as well! 
``$ pip search something | grep something &gt; /dev/null &amp;&amp; echo YES || echo NO`` No coding required.
I had a similar moment a few weeks ago! I think it was one of the string exercises. I think I was able to do a one-line list comprehension or something instead of the 4-6 line solution provided. Feels great!
Not really. What `pip search query` does: &gt; Search for PyPI packages whose name or summary contains &lt;query&gt;. so, if the query in summary, but not in name, you'll get no(can't use it) using your way, however, you can use it in fact(not in name, hasn't been registed yet).
There's a way to propagate the carry by using two recursive calls instead of just one.
If you plug in your phone into your computer, does it come up as an drive similar to an memory stick. If so, if you can navigate to the directory and see photo's you are in. 
When I was really green I would often make if-else if statements where the else if part were checking that the statement in the if part was false. It pays off to read up on the basics :)
What? So we should never use == because we should be using a wrapper function instead? 
Ok, so I'm 2 weeks late, but prepare to have your mind blown: http://codeconnect.io/
IMO *much* less readable. 
Avoiding parens is a great idea until the first time you hit a crash caused by a poor recollection of operator precedence. It requires so little effort to include additional parens, yet the pain it saves in the case they're erroneously omitted can be pretty huge. (See for example, [Apple's "goto fail" SSL bug](https://nakedsecurity.sophos.com/2014/02/24/anatomy-of-a-goto-fail-apples-ssl-bug-explained-plus-an-unofficial-patch/), extraneous braces in C is basically an equivalent issue)
Neither is more explicit. They both explicitly state that the function should return whether or not a_smile == b_smile.
Actually python regex (which are more than the computer science definition of regex) can be used recursively. But of course they shouldn't.
That sounds quadratic... is it?
I am pretty sure that decorators run when the file gets imported, setting decorators in a loop makes no sense to me and is a bit weird and non-standard.
Maybe I'm just more used to it, but it's perfectly readable to me. 
PRAW definitely does not do that, it is only a wrapper for the reddit api. (PRAW stands for Python Reddit API Wrapper.) The tables in reddit are written using a loose standard called `markdown`, so if you want try googling python XML to Markdown library. However, I just did and came up empty, all the tools I found (such as `Python Markdown`) are markdown to html converters. If I were you with a table in XML I would use Beautiful Soup 4 to parse it and then just write your table into a string using markdown syntax (markdown syntax is not complicated) that you send to reddit as part of your comment. By the way, you may find /r/redditdev a bit more relevant for reddit api specific questions.
Hi @catcradle5, Thanks, actually it's just to avoid the confusion **mysql**. *myql* vs *mysql*
In Python 2, `raw_input` accepts input from the user. This is what you use to ask the user's name. In Python 3, `input` accepts input from the user. This is what you use to ask the user's name. In Python 2, `input` accepts input from the user AND evalulates it as if it was code. From a security point of view, this is a very bad idea. Never use `input` in Python 2 unless you absolutely know what you are doing. You enable the user to enter code that will be run by your program. `input()` is the same as `eval(raw_input())`. You *might* use this if you want your user to enter mathematical formula but it would be better to write a parser for that. Future questions of this type should go to /r/learnpython.
Yees! Noobcomplishment achieved! Next task ... return a == b or c == d and a is not None! This is a tricky one! 1. Where should _a is not None_ go? (In the front? why?? :]) 2. Should you use parenthesis around the == terms?
Basically, never use input() (in python 2 - in python 3 raw_input has been renamed input, replacing what input used to do). Essentially, in python 2, `input()` is equivalent to `eval(raw_input())`. There were perhaps some advantages to this as a teaching aid, in that you could get people to add 2 numbers together without having to first teach about strings and how to convert the string representation of a number to the number. However, it's a terrible idea for anything else. To see the difference, compare: User types | input returns | raw_input returns | ---------------------------------------|-----------------------|----------------------------------------| 42 | 42 | '42' | 1+1 | 2 | '1+1' | hello | throws NameError | 'hello' | 'hello' | 'hello' | "'hello'" | `__import__('os').system('#rm -rf /')` | 0 [1] | `"__import__('os').system('#rm -rf /')"` | [1] **AND ALSO DELETES ALL YOUR FILES** (or would if I left out the comment character) In short, input is a really bad idea outside anything but the most trivial beginner teaching scenarios (and even then, may teach a very bad habit), hence why python 3 removed the old behaviour. 
Sort of fixed that for you: ___ | User types | input returns | raw_input returns | |--------------|---------------|-------------------| | 42 | 42 | '42' | | 1+1 | 2 | '1+1' | | hello | NameError* | 'hello' | | 'hello' | 'hello' | "'hello'" | | `__import__('os').system('rm -rf /')` | 0 **(but also deletes all your files)** | '`__import__('os').system('rm -rf /')`' | \* Exception: name `hello` is not defined Edit: Ah, you already fixed it yourself now. :)
True that. I was pretty stoked when I figured this out in my compsci 1 course last semester. I imagine my professor liked to make popcorn then sit down with his wife and celebrate my c++ labs.
You can also stick a fork in your eye. You shouldn't do either. I'm talking about regular production code here aimed at users who are not experts. If you're working interactively in the interpreter, or writing your own REPL, or some other use for expert users, then eval'ing the user's input may be reasonable.
PyPA has a sample project which might be what you're looking for: https://github.com/pypa/sampleproject?files=1
oh shxt. i think i need to put target.read(filename) Sorry I've only been at this for like 3 days. haha
nope...now it's telling me my line five is missing parentheses :'(
check out /r/learnpython 
You need to read the file to a variable. You are reading the file but are just throwing away the result. Also, you can insert four spaces before each line to make it formatted as code. Also, you should use "with", since it handles closing for you: print "opening the file..." with open(filename) as target: print "reading the file..." result = target.read() print "closing file" In this example "result" is a string containing the file contents. 
"target" already knows what file it is, so you don't need to specify the filename again.
It's just "Design by Contract". This is software design &amp; testing methodology developed by [Bertrand Meyer](https://en.wikipedia.org/wiki/Bertrand_Meyer). The comment by /u/bionikspoon is basically correct, but I think it misses some important detais. In DbC we specify the correct operation of code via statements called "invariants". ("Statement" is meant in the English sense here: something that is true or false.) An *invariant* is a statement that needs to be true at a particular point in a program. Here is a kinda silly example: if n &lt; 3: return if n &gt; 17: return # Invariant: 3 &lt;= n &lt;= 17 print("Here is a cool number:", n) There are two particularly important kinds of invariants: preconditions and postconditions. A *precondition* is an invariant at the beginning of a function; it is something that needs to be true for the function to be called. A *postcondition* is an invariant at the end of a function; it expresses what the function does, in the form of a statement. Another kinda silly example: def square_root(n): """ Precondtions: n is a number; n &gt;= 0 Postconditions: return value is the square root of n """ ... So a function can be thought of as offering callers a contract. A function says, "If you (caller) make my preconditions true and call me, then I will make my postconditions true." This is where the name "Design by Contract" comes from. So, when we use DbC, we specify the correct operation of a function by giving its preconditions and postconditions. I would say that DbC offers two benefits: 1. It encourages clarity in specifications. 2. It leads to straightforward connections between design, documentation, and testing. Concerning #2 above: if an invariant can be written as a boolean expression in the programming language being used, then we can check whether the invariant is true, and flag an error if it is not. Typically, when someone says they are using DbC, they are implying that such checking is being done. This is the main point of Design by Contract packages. They allow for integrated specification/documentation/testing, somewhat along the lines of Python's doctest library, but aimed at invariants.
Well, the closed function `trace_task` is also pretty long and goes to lots of layers of nesting. I figured on pure stylistic grounds, most would prefer to break that into multiple functions. The comment suggests it's due to performance considerations. I guess also you get simpler stack traces having it unrolled like this. To make this a bit more concrete, here's the output of "cython -a" on the file: https://rawgit.com/syllog1sm/0d40bcdbcba5d4f632a6/raw/aa211425117235f78021b0ba9dffc79b9036b229/gistfile1.html . You can click any line to see the C code that cython translates the Python into. Compiling the unmodified Python into calls to the C api like this allows only pretty limited performance improvements. For instance, you still need to do all that reference counting, and you haven't placed any guarantees on attribute access — so that's still usually a dictionary look-up. But for the parts of your code that you can fully control, you can make yourself a lower-level API, that accepts maybe a struct or a bunch of ints, instead of dicts, Python objects, strings, etc. This pure C function will run as fast as any other pure C function. For instance, this is the symbol table for my NLP tools: https://github.com/honnibal/spaCy/blob/master/spacy/strings.pyx#L64 . I wanted to use the Pythonic `__getitem__`, and I wanted to make it bidirectional: if you lookup an int, you get back a string; and vice versa. This is easy to do, as you can see. But the internals? Those I can optimize. I know that my hash table has fixed size keys and values, so I can make it far more efficient than Python's general-purpose dict — particularly for memory. For the Celery code, I think if you had a callable cdef class for `build_tracer`, you might get some performance advantage. I think accessing attributes on a cdef class is faster than looking them up in the non-local scope. The cdef class is a struct, so what you're doing is just accessing struct members. I think in the non-local scope, you have to do a dictionary lookup. I'm not sure though.
For VLSI, you are probably looking at TCL as most industry tools that I know of come with TCL embedded. It is generally not required, but it is useful for automation and extension.
I only use extra parentheses when mixing operators that are not often used together, like bitwise and arithmetic ops, or if-else and boolean ops. (Well, and sometimes for tuples. I tend to use `a, b` for tuples that are meant to be deconstructed right away and `(a, b)` for tuples that are meant to be passed as a single unit.) I don't write `(a * b) + c` or `if (foobar &gt; 6):` or stuff like that.
Thanks friend. 
Well done! It's not a n00b thing at all. You saw a way to simplify and clarify some code. As hackers, we map real-world problems into data and code. Simple, clear code is always better than complex opaque code. You made some code simpler and clearer. You're a hacker!
Hi Andy, it's your professor. Usually we just had the Walmart gift shop print your code on our bedding and coffee mugs. Congratulations on the pass!
I've been thinking about doing the Data Wrangling course. I don't currently have any nosql experience. Seems like a fun way to learn.
`input` runs Python code. Do not use!!!
The most valuable skill to develop as a programmer: reading documentation. These should answer your question https://docs.python.org/2/library/functions.html#input https://docs.python.org/2/library/functions.html#raw_input Asking on reddit is easy, finding out for yourself makes you better : ) 
Assuming we're talking about an Android or Windows Phone, MTP is the way to go. I've found two MTP libraries for Python, both based on libmtp: * [PyMTP](https://pypi.python.org/pypi/PyMTP), which seems to be a bit out of date * [python-mtp](https://github.com/emdete/python-mtp), which seems to be more active
apologies. I was unaware I was posting the the wrong forum. I'm 33 years old and the last time I did any programming was in BASIC on an Atari 800, in other words about 25 years ago... I'll switch over to the other forum and thank you for all your help. ugh...so much of this I don't understand. Time to grab a beer...roll the sleeves up and get to pounding some plowing rivets. I don't understand half the stuff that you guys are saying, but I'm gonna do this damned thing one way or another. heh. My first major in college was software engineering. I dropped the class after one week because there was a semicolon where there was supposed to be a colon or vice-versa(?). Anyway, time to grab this lion by the wedding tackle and show it who is boss. Thanks again for the support, and for directing me to the correct forum and keeping me from making an ass of myself. *group hug*
Was expecting Linus, was not disappointed.
Even from a non-security point of view, Python 2's `input` makes it way too easy to accidentally raise an escalating exception, which is frustrating for users.
Calling the function carries overhead. If it's called a lot it'll slow down the program.
This Bash function seems to work: function caniuse { pip search "$1" | grep -i "^$1 " &gt; /dev/null &amp;&amp; echo taken || echo available }
Have you considered making it web-base? That's probably the easiest. I have PyQt in my flair, but I have a hard time recommending it for something like this. If you do use Qt, you should probably use QtQuick and not QtWidgets.
On it's own as a single comparison, perhaps not. As part of a compound statement, it could be nice for readability. It is definitely the right way to go if some amount of work is needed to arrive at the values needed for the comparison. Having that in the example would have drawn attention away from the point of it, though.
That's what I think about u/Avonalt comment; seems like YAGNI abstraction. Sure, if the comparison turns into something involved, put in the function only then. If not, under that logic, you might as well make your own (totally unnecessary) adder(), subtractor(), less_than(), etc functions "just in case".
I would personally use Kivy. Then you get mobile for "free". :)
You can't perform any further operations on the "result" of `return` "function", so the precendence argument doesn't apply here.
I remember being so proud when I discovered that you can have loop that runs indefinitely. How clever the trick was! You simply needed a condition that's always satisfied! Do While 1 = 1 (Yes, my first language was Visual Basic. And yes, I turned out fine, thanks for your concern :) ) 
 function caniuse() { curl -s --fail "https://pypi.python.org/pypi/$1" 2&gt;&amp;1 &gt;/dev/null &amp;&amp; echo "Nope." || echo "Yes." }
Hmm, the phones I've used so far seemed to support both, allowing you to select one or the other from the USB menu. I could be wrong though.
Thanks for the reply.
Before using mongodb please read [this](https://aphyr.com/posts/322-call-me-maybe-mongodb-stale-reads). It is a non-vitriolic analysis of mongodb and data consistency. 
Are you talking traditional black and white pixel art, or a modern take on it? If you just pixel art like the devices of old, almost every toolkit will support it. If you're looking for more modern graphics on the idea, try something game-oriented.
User types | input returns | raw_input | --------------------------------------|------------------|--------------------------------------| `__import__('os').system('#rm -rf /')` | 0 [1] | `"__import__('os').system('#rm -rf /')"` | While this is true, in most cases `rm -rf /` should not work, for exactly these reasons. The user would have to include `--no-preserve-root`. That doesn't prevent users deleting everything else though, and many life lessons are learned from these mistakes.
Thanks. Don't hesitate to open an issue if you see a thing or two to improve. Really appreciate
Your new code is appending 1 to the end of s1, not actually adding it. Use your function, not the `+` operator.
&gt; I wish I could. If it was possible, I would probably write some android programs occasionally, which so far have not tried to do. I did, at some point, get involved with some other Googlers who were trying to make just this possible, and we were told that it was strategically not important and we were not, we were asked not to work on it anymore. Guido van Rossum, 2012 keynote
&gt; 1.7 They skipped 1.7, but 1.6 was the best tech book I ever read.
[I enjoyed this course](https://oylenshpeegul.wordpress.com/2014/01/21/mongo-mooc/), even though I was disappointed that it was all done in Python 2 for no good reason. After the course was over, I redid the final project in Python 3. It was easy to do (neither Mongo nor Bottle requires Python 2) and the same code still worked in Python 2. With only a tiny bit of effort, they could update this course for Python 3 without affecting the folks still using Python 2.
Well, you just do? Docopt will make your argparsing simpler. Try it!
Pygame. Kivy is also kinda an option, but from what I remember, tamagochis were a 32x32 screen with 3 buttons. Definitely sounds like pygame territory.
Oh, I thought they did 1.7. Still on the fence about getting 1.8. Would have been nice if their site had sample chapter or at least part of chapter. 
Does anyone know what the rationale was for going from a decorator to a new keyword?
yess i got it, you fucking legend thank you so much !!
Your isp determines your ip. You need to use a proxy. Use python to keep changing proxys maybe. But, ip is not enough data for them to block on, as they can't only allow one vote from a coffee shop for instance. Maybe you could keep changing internal ips and your router/isp would make it look like they were all coming from different computers within the same ip. Maybe disconnect, spoof a new mac, and reconnect.
&gt; Your isp determines your ip Well technically those are more like recommendations with really good reasons to follow. You could pick any IP you want and even hope to get outgoing IP packets routed to their destination. But this would be completely useless for anything reasonably useful and legal, especially so for TCP. &gt; Maybe you could keep changing internal ips and your router/isp would make it look like they were all coming from different computers within the same ip. Maybe disconnect, spoof a new mac, and reconnect. None of that matters as far as the network protocols are concerned. The MAC address doesn't even make it past a single router. Consumer grade home routers generally use NAT so again the internal IP addresses never make it past the router. Changing them won't achieve anything but potentially breaking routing. Identifying browser/users is typically done with cookies or sometimes using various super cookie methods like flash cookies or even creating signatures based on request headers specifying language settings, browser versions, installed plugins or system fonts. &gt; A friend and I are trying to stuff a ballot box (not literally, of course) with votes (for a school event). I wonder what exactly the story behind that is. I'm tempted to add some snarky remark regarding the curriculum including techniques to manipulate online polls but I can't think of anything funny right now.
I'm not sure what you're getting at. Do you want a way to source control your python projects? Or do you want a python api for git that would allow you to source control other projects?
http://musicmachinery.com/2009/04/27/moot-wins-time-inc-loses/
Python can do anything a command line can. See: os, os.system, subprocess.call
You spelled replace wrong here: search_string = search_string.strip().repalce(' ', '+') # why does this not work?
About the whole ballot box, our school wants win a competition where the school with the most responses gets to take over wild-waves for a day. This is a potential issue because our school has only 100 people who give two fucks. I could care less about wild waves, but it's a fun challenge to tackle.
I've used gitPython successfully. I turned a lot of the examples I could find into a wrapper class l so that I had a convenient way to manipulate a repo, letting me mimic things I may do on the command line. The project struggled for a bit with a lack of maintenance in the past, however, this past year has seen it picked back up by its developers and is now actively maintained; with py3k support added.
This is a guess, but I'd say that the second one has potential of not being GC'd as soon as the first one?
I used pygit2 for https://github.com/boxed/git-stats2 and was pretty satisfied with it. My use case was probably a bit out of the ordinary but it worked well. 
You're going to need to justify those negative statements.
From the release announcement: &gt; Python 3.5.0b1 had a major regression (see http://bugs.python.org/issue24285 for more information) and as such was not suitable for testing Python 3.5. Therefore we've made this extra beta release, only a week later. Anyone trying Python 3.5.0b1 should switch immediately to testing with Python 3.5.0b2.
some_list[:] doesn't result in every member in the list. It results in a new list containing every member of some_list. So, it'd be special-cased for del if that syntax deletes every element instead of creating a new list and then deleting the new list.
Augggggh you're right. Feel free to downvote that comment
&gt;None of that matters as far as the network protocols are concerned. The MAC address doesn't even make it past a single router. Consumer grade home routers generally use NAT so again the internal IP addresses never make it past the router. Changing them won't achieve anything but potentially breaking routing. I was just playing with a STUN server (which echos back the ip and port from which your NAT makes a request on your behalf) and seen that the NAT changes the port from which clients are making request to make it possible to distinguish who the returned packets should be routed to. That is, client one makes a request to 2.2.2.2:80 from its local 192.168.1.100:5000, the NAT send a request to 2.2.2.2:80 from 60.60.60.60:5000. But if client 2 makes a request to 2.2.2.2:80 from 192.168.1.200:5000, the NAT sends it out as from 60.60.60.60:1024. Thus the server at 2.2.2.2 has a clue that it is serving two different users at 60.60.60.60 Changing you MAC would only be a way to fool your own router, and the fooled router would change your public facing port. But the cookies and browser footprints are much more likely to be used than this, which is only anecdotal. I can't swear that NATs depend on doing this or that servers pay attention to it
So, I think that what you're trying to say is that it is a special case? Looks to be so... In this case, I would say that the difference in regard to OP's question may still be that they are wanting to flag the GC ASAP or it may be that they care that the identity of the variable stays the (so that the `is` operator still works as expected) http://repl.it/qOg/1 Also mentioning /u/therealfakemoot since it's relavant to the other thread ^
Here is quote from PEP about downsides for `yield from` + decorator approach: &gt; Current Python supports implementing coroutines via generators ( PEP 342 ), further enhanced by the yield from syntax introduced in &gt; &gt; PEP 380 . This approach has a number of shortcomings: &gt;* It is easy to confuse coroutines with regular generators, since they share the same syntax; this is especially true for new developers. &gt;* Whether or not a function is a coroutine is determined by a presence of yield or yield from statements in its body , which can lead to &gt;unobvious errors when such statements appear in or disappear from function body during refactoring. &gt;* Support for asynchronous calls is limited to expressions where yield is allowed syntactically, limiting the usefulness of syntactic &gt;features, such as with and for statements. ... &gt;Native coroutines and the associated new syntax features make it possible to define context manager and iteration protocols in &gt;asynchronous terms. As shown later in this proposal, the new async with statement lets Python programs perform asynchronous calls &gt;when entering and exiting a runtime context, and the new async for statement makes it possible to perform asynchronous calls in &gt;iterators. See: https://www.python.org/dev/peps/pep-0492/#rationale-and-goals
lovely, thanks. by the way, unless the sponsors of this thing are ridiculously stupid, they will realize something is amiss when they get flooded with 100,000+ survey answers all saying the same thing, but it's just a big fuck you to the man. High school bullshit, you know? 
There's no reason you can't generate valid looking responses randomly. A markov chain could take you pretty far. 
Yes, _a is not None_ should go first, then the equality metering. Usage of Parenthesis, helps being clear, and explicit in your statements. Remember the operator precedence table\!!
I don't think it's that special. The del keyword is very similar to an assignment statement, in that it operates on identifiers and such. (full grammar here https://docs.python.org/2/reference/simple_stmts.html#grammar-token-target_list) Feeding it unbound expressions should be a syntax error. For example: &gt;&gt;&gt; li = ['a'] &gt;&gt;&gt; del li + li File "&lt;stdin&gt;", line 1 SyntaxError: can't delete operator &gt;&gt;&gt; del ['a'] File "&lt;stdin&gt;", line 1 SyntaxError: can't delete literal So for it to be able to delete a new unnamed list in this case would be more of a special case. Keep in mind that calling del with a slice does not unbind the list itself. It just removes the list elements. &gt;&gt;&gt; a=[1,2,3] &gt;&gt;&gt; del a[:] &gt;&gt;&gt; a [] The behaviour of del is similar in all of these cases: del mylist del mylist[index] del mylist[slice] del dictionary[key] For reference, the official docs have a general description of what del does: https://docs.python.org/2/reference/simple_stmts.html#the-del-statement 
as u can see i am new but i am trying. thanks for the help Mr.Riddler :P
No, regular slice assignment.
link to GitHub - https://github.com/jeanphix/Ghost.py